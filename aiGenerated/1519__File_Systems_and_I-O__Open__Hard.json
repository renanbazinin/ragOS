{
  "metadata": {
    "source": "ai_generated",
    "subject": "File Systems",
    "topic_hint": "File Systems and I/O",
    "requested_type": "Open",
    "requested_difficulty": "Hard",
    "generated_at": "2026-02-08 11:02:53",
    "examples_used": 3,
    "token_usage": {
      "prompt_tokens": 4088,
      "output_tokens": 4062,
      "total_tokens": 14899
    }
  },
  "question": {
    "id": 9,
    "type": "Open",
    "topic": [
      "File Systems",
      "I/O",
      "Journaling",
      "Crash Recovery"
    ],
    "content": {
      "text": "נתונה מערכת קבצים VSFS שבה קבצים קטנים (עד 64 בתים) מאוחסנים ישירות בתוך רשומת התיקייה שלהם. כל רשומת תיקייה מכילה: שם קובץ, סוג קובץ, הרשאות, זמני יצירה/גישה/שינוי, ו-64 בתים עבור נתוני הקובץ אם הוא קטן. אם הקובץ גדול מ-64 בתים, רשומת התיקייה מכילה מצביע ל-inode של הקובץ במקום את הנתונים, וה-inode מכיל את שאר הנתונים והמצביעים לבלוקי ה-DATA שלו. המערכת משתמשת ב-metadata journaling (כלומר, נתוני DATA אינם נכתבים ללוג).\n\nנתונים נוספים:\n*   גודל בלוק: 4KB.\n*   גודל inode: 256 בתים.\n*   גודל רשומת תיקייה: 128 בתים (כולל שם קובץ מקסימלי של 32 בתים, מטא-דאטה נוסף, ו-64 בתים לנתונים קטנים או מצביע ל-inode).\n*   גודל מצביע ל-inode: 4 בתים.\n*   כל בלוק DATA של תיקייה יכול להכיל 4096 / 128 = 32 רשומות תיקייה.\n*   זמן Seek ממוצע: 10ms.\n*   זמן סיבוב דיסק מלא: 8ms.\n*   קצב העברה: 50 MB/s.",
      "code_snippet": null,
      "options": null
    },
    "sub_questions": [
      {
        "id": "9.1",
        "text": "משתמש מבצע פעולת קריאה של קובץ בגודל 50 בתים. הקובץ נמצא בנתיב `/home/user/smallfile.txt`. ידוע כי התיקיות `/home` ו-`/home/user` מכילות כל אחת 100 רשומות (קבצים/תיקיות). אף cache אינו מכיל מידע רלוונטי. חשבו את הזמן המינימלי לביצוע פעולת הקריאה. יש לתאר את רצף פעולות ה-I/O הנדרשות ולנמק כל שלב. ניתן להניח שהרשומה של הקובץ `smallfile.txt` נמצאת בבלוק ה-DATA האחרון של התיקייה `/home/user`.",
        "code_snippet": null,
        "options": null
      },
      {
        "id": "9.2",
        "text": "משתמש מבצע פעולה של כתיבה לקובץ `smallfile.txt` (הקובץ הקטן מהסעיף הקודם) אשר גורמת לגודלו להפוך ל-100 בתים. תארו את רצף פעולות ה-I/O (קריאות וכתיבות לדיסק) הנדרשות לביצוע הפעולה, בהתחשב בכך שהמערכת משתמשת ב-metadata journaling. הציגו תרחיש קריסה יחיד (crash) לאחר אחת מפעולות הכתיבה לדיסק, אשר יוביל למצב לא עקבי במערכת הקבצים. הסבירו מדוע המצב לא עקבי וכיצד גישת ה-metadata journaling מנסה להתמודד עם בעיות כאלה, ומה מגבלותיה במקרה זה. יש להניח שאף cache אינו מכיל מידע רלוונטי.",
        "code_snippet": null,
        "options": null
      }
    ],
    "points": null,
    "solution": {
      "is_present_in_file": true,
      "correct_option": null,
      "explanation": "פתרון שאלה 9:\n\n**סעיף 9.1: חישוב זמן קריאה מינימלי**\n\n1.  **קריאת בלוק ה-superblock:** נדרש לקרוא את ה-superblock כדי למצוא את ה-inode של תיקיית השורש (`/`).\n    *   I/O: 1 קריאת בלוק.\n2.  **קריאת בלוק ה-DATA של תיקיית השורש (`/`):** נדרש לקרוא את בלוק ה-DATA הראשון של תיקיית השורש כדי למצוא את הרשומה של `/home`. נניח שהרשומה נמצאת בבלוק הראשון.\n    *   I/O: 1 קריאת בלוק.\n3.  **קריאת בלוקי ה-DATA של תיקיית `/home`:** תיקיית `/home` מכילה 100 רשומות. כל רשומה היא 128 בתים. לכן, התיקייה תופסת 100 * 128 = 12,800 בתים = 12.5KB. זה דורש 4 בלוקים (12.5KB / 4KB לבלוק = 3.125, כלומר 4 בלוקים). כדי למצוא את הרשומה של `/user` (שנניח נמצאת בבלוק האחרון של `/home`), נצטרך לקרוא את כל 4 הבלוקים.\n    *   I/O: 4 קריאות בלוקים.\n4.  **קריאת בלוקי ה-DATA של תיקיית `/home/user`:** בדומה ל-/home, תיקיית `/home/user` מכילה 100 רשומות, ולכן תופסת 4 בלוקים. כדי למצוא את הרשומה של `smallfile.txt` (שנניח נמצאת בבלוק האחרון של `/home/user`), נצטרך לקרוא את כל 4 הבלוקים. הנתונים של הקובץ (50 בתים) נמצאים ישירות בתוך רשומת התיקייה שנקראת בשלב זה.\n    *   I/O: 4 קריאות בלוקים.\n\n**סה\"כ קריאות:** 1 (superblock) + 1 (root dir) + 4 (home dir) + 4 (user dir) = 10 בלוקים.\n**סה\"כ נתונים נקראים מהדיסק:** 10 בלוקים * 4KB/בלוק = 40KB.\n\n**חישוב זמן מינימלי:**\nהנחות לזמן מינימלי:\n*   אין זמן seek או rotational latency בין קריאות בלוקים רצופים (כלומר, הבלוקים של כל תיקייה רצופים, והבלוקים של התיקיות השונות רצופים באופן אידיאלי).\n*   זמן ה-seek וה-rotational latency מתרחשים רק פעם אחת בתחילת הפעולה.\n\n*   **זמן seek:** 10ms (נתון).\n*   **זמן rotational latency ממוצע:** 0.5 * זמן סיבוב מלא = 0.5 * 8ms = 4ms.\n*   **זמן העברה:** (סה\"כ נתונים נקראים) / (קצב העברה) = 40KB / 50 MB/s = (40 * 1024 בתים) / (50 * 1024 * 1024 בתים/שנייה) = 40 / (50 * 1024) שנייה = 0.00078125 שנייה = 0.78125ms.\n\n**זמן כולל מינימלי:** 10ms + 4ms + 0.78125ms = **14.78125ms**.\n\n**סעיף 9.2: מעבר קובץ קטן לקובץ גדול, תרחיש קריסה ו-metadata journaling**\n\n**רצף פעולות ה-I/O הנדרשות:**\n(הנחה: קריאות ל-bitmaps ולבלוקי תיקיות לצורך איתור ועריכה כבר בוצעו)\n\n1.  **קריאת בלוק ה-DATA של תיקיית `/home/user`:** נדרש לקרוא את הבלוק המכיל את רשומת הקובץ `smallfile.txt` כדי לעדכן אותה (מכיוון שהקובץ גדל מעבר ל-64 בתים, הרשומה תשתנה ממכילה נתונים למכילה מצביע ל-inode).\n2.  **קריאת בלוק ה-inode bitmap:** נדרש לקרוא את בלוק ה-bitmap כדי למצוא inode פנוי.\n3.  **קריאת בלוק ה-data bitmap:** נדרש לקרוא את בלוק ה-bitmap כדי למצוא בלוק DATA פנוי.\n4.  **כתיבת בלוק ה-DATA החדש:** כתיבת 100 הבתים לבלוק DATA חדש שהוקצה. (זו כתיבת DATA, אינה נכנסת ללוג ב-metadata journaling). **(כתיבה לדיסק)**\n5.  **כתיבת טרנזקציה ללוג:**\n    *   כתיבת Transaction Begin Block (TxB) ללוג. **(כתיבה לדיסק)**\n    *   כתיבת העותק החדש של בלוק ה-inode bitmap (עם סימון ה-inode החדש כתפוס) ללוג. **(כתיבה לדיסק)**\n    *   כתיבת העותק החדש של בלוק ה-data bitmap (עם סימון בלוק ה-DATA החדש כתפוס) ללוג. **(כתיבה לדיסק)**\n    *   כתיבת ה-inode החדש (עם מצביע לבלוק ה-DATA החדש וגודל קובץ 100 בתים) ללוג. **(כתיבה לדיסק)**\n    *   כתיבת העותק החדש של בלוק ה-DATA של תיקיית `/home/user` (עם הרשומה המעודכנת של `smallfile.txt` שמצביעה ל-inode החדש ומנקה את הנתונים המוטמעים) ללוג. **(כתיבה לדיסק)**\n    *   כתיבת Transaction End Block (TxE) ללוג. **(כתיבה לדיסק)**\n6.  **fsync:** לוודא שכל הלוג נכתב לדיסק. **(כתיבה לדיסק – flush)**\n7.  **כתיבת מטא-דאטה למיקומם הסופי:**\n    *   כתיבת בלוק ה-inode bitmap למיקומו הסופי. **(כתיבה לדיסק)**\n    *   כתיבת בלוק ה-data bitmap למיקומו הסופי. **(כתיבה לדיסק)**\n    *   כתיבת ה-inode החדש למיקומו הסופי. **(כתיבה לדיסק)**\n    *   כתיבת בלוק ה-DATA של תיקיית `/home/user` למיקומו הסופי. **(כתיבה לדיסק)**\n\n**תרחיש קריסה ואי-עקביות:**\nתרחיש קריסה בעייתי יתרחש אם המערכת קורסת **לאחר שלב 4 (כתיבת בלוק ה-DATA החדש למיקומו הסופי) ולפני שלב 6 (fsync של הלוג)**.\n\n**הסבר מדוע המצב לא עקבי:**\nבמצב זה:\n*   בלוק ה-DATA החדש (המכיל את 100 הבתים) נכתב לדיסק ואף מסומן כתפוס ב-data bitmap (כי ה-bitmap נכתב ללוג אך הלוג לא מחויב). מצד שני, ייתכן שבלוק ה-data bitmap לא נכתב לדיסק כלל (אם הקריסה התרחשה לפני כתיבה ללוג). נניח שהקריסה התרחשה *אחרי* כתיבת בלוק ה-DATA החדש, *אבל לפני* כתיבת TxE ללוג או fsync של הלוג.\n*   הלוג לא נכתב במלואו או לא בוצע לו fsync, ולכן הטרנזקציה כולה לא נחשבת למחויבת (committed).\n*   כאשר המערכת תעלה מחדש, היא תבצע recovery על בסיס הלוג. מכיוון שהטרנזקציה לא מחויבת, הלוג יתעלם מכל הפעולות שהיו חלק מטרנזקציה זו, והשינויים במטא-דאטה לא ישוחזרו.\n*   התוצאה תהיה שרשומת התיקייה עבור `smallfile.txt` עדיין תכיל את 50 הבתים המקוריים, ה-inode החדש לא יוקצה (או לפחות לא יקושר למטא-דאטה במערכת הקבצים), ובלוק ה-DATA החדש שהכיל את 100 הבתים יהפוך לבלוק \"יתום\" (orphaned block) – בלוק שתפוס בדיסק (אם bitmap עודכן) אך אין שום מטא-דאטה שמצביעה אליו, או שהוא פנוי אך מכיל נתונים לא רלוונטיים. זהו מצב של **דליפת נתונים** (data leak) ואי-עקביות במערכת הקבצים.\n\n**התמודדות עם הבעיה בגישת ה-metadata journaling ומגבלותיה במקרה זה:**\nגישת ה-metadata journaling, כשמה כן היא, מתמקדת בהגנה על מטא-דאטה בלבד (כמו inodes, בלוקי תיקיות, ו-bitmaps). היא מניחה שנתוני ה-DATA עצמם פחות קריטיים לעקביות מבנה מערכת הקבצים, ולכן אינה כותבת אותם ללוג.\n\n*   **הגנה על מטא-דאטה:** במקרה של קריסה *לאחר* שלב 6 (fsync של הלוג) אך *לפני* שלב 7 (כתיבת המטא-דאטה למיקומו הסופי), ה-recovery ימצא טרנזקציה מחויבת בלוג וישחזר את המטא-דאטה (inode bitmap, data bitmap, inode חדש, בלוק התיקייה המעודכן) למיקומם הסופי. במקרה זה, עקביות מערכת הקבצים (הקשרים בין בלוקים, inodes, ורשומות תיקיות) נשמרת, והקובץ יהיה נגיש עם 100 הבתים החדשים.\n\n*   **מגבלות במקרה זה:** הבעיה שהוצגה (בלוק DATA יתום) נובעת מהעובדה שבלוק ה-DATA נכתב למיקומו הסופי *לפני* שהטרנזקציה (שמקשרת את המטא-דאטה ל-DATA) מחויבת. גישת ה-metadata journaling אינה מגינה על יחסי התלות בין נתוני ה-DATA לבין המטא-דאטה המצביעה עליהם. היא לא מבטיחה שנתוני ה-DATA יהיו \"נכונים\" או שיהיו ניתנים לגישה לאחר קריסה אם המטא-דאטה לא הספיקה להתעדכן. במצב של metadata journaling טהור, כמו שתואר בשאלה, לא ניתן למנוע לחלוטין את הבעיה של בלוקי DATA יתומים במקרה כזה, מכיוון שנתוני ה-DATA אינם חלק מהלוג.\n\n    כדי לפתור בעיה זו, מערכות קבצים רבות משתמשות בגישת \"Ordered Journaling\" (כמו ב-ext3 במצב `ordered`). בגישה זו, נתוני ה-DATA נכתבים לדיסק ומוודאים שהם נכתבו (באמצעות fsync או סדר כתיבה קפדני) *לפני* שהמטא-דאטה המצביעה עליהם נכתבת ללוג. זה עדיין לא מבטיח שנתוני ה-DATA יהיו עקביים במקרה של שכתוב, אך זה מונע מצב של בלוקים יתומים. עם זאת, השאלה מגבילה אותנו ל-\"metadata journaling\" בלבד, מה שמשאיר את הפגם הזה קיים. הפתרון המלא יותר (Data Journaling) היה כותב גם את נתוני ה-DATA ללוג, אך הוא יקר יותר."
    },
    "difficulty_estimation": "Hard"
  }
}