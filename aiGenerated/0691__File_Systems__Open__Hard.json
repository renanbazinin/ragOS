{
  "metadata": {
    "source": "ai_generated",
    "subject": "File Systems",
    "topic_hint": "File Systems",
    "requested_type": "Open",
    "requested_difficulty": "Hard",
    "generated_at": "2026-02-07 23:37:11",
    "examples_used": 3,
    "token_usage": {
      "prompt_tokens": 4084,
      "output_tokens": 5279,
      "total_tokens": 23878
    }
  },
  "question": {
    "id": 9,
    "type": "Open",
    "topic": [
      "File Systems",
      "Disk I/O",
      "Consistency",
      "Performance"
    ],
    "content": {
      "text": "נתונה מערכת קבצים VSFS עם מאפיינים ייחודיים:\n- גודל בלוק הוא 4KB.\n- גודל inode הוא 256 בתים. בכל inode יש 10 מצביעים ישירים, 2 מצביעים עקיפים בודדים, ומצביע עקיף כפול אחד. גודל מצביע הוא 4 בתים.\n- קובץ שגודלו אינו עולה על 128 בתים, נשמר במלואו בתוך הרשומה של התיקייה המכילה אותו (Small File Optimization). במקרה כזה, ה-inode של הקובץ פשוט מציין שהקובץ הוא 'קובץ קטן' (למשל, באמצעות דגל ב-inode) ואינו מכיל מצביעים לנתונים. הנתונים עצמם מאוחסנים ברשומת התיקייה.\n- רשומת תיקייה עבור קובץ קטן מכילה: שם הקובץ (אורך משתנה, עד 250 בתים), גודל הקובץ (2 בתים), ו-128 בתים של נתוני הקובץ. כלומר, סה\"כ אורך שם הקובץ + 2 + 128 בתים.\n- רשומת תיקייה עבור קובץ גדול מכילה: שם הקובץ (אורך משתנה, עד 250 בתים), גודל הקובץ (2 בתים), ומספר ה-inode של הקובץ (4 בתים). כלומר, סה\"כ אורך שם הקובץ + 2 + 4 בתים.\n- ה-inode של תיקיית השורש מאוחסן ב-superblock.\n- מהירות הסיבוב של הדיסק (RPM) היא 7200.\n- זמן ה-seek הממוצע של הדיסק הוא 10ms.\n- קצב ההעברה המקסימלי של הדיסק הוא MB/s 50.\nיש לפרט ולנמק את כל החישובים בכל סעיף.",
      "code_snippet": null,
      "options": null
    },
    "sub_questions": [
      {
        "id": "9.1",
        "text": "1. מהו הגודל המקסימלי של קובץ הנתמך במערכת קבצים זו?\n2. מהו המספר המקסימלי של קבצים קטנים (Small Files) שניתן לאחסן בבלוק נתונים יחיד של תיקייה, אם כל שמות הקבצים הם באורך 8 תווים (כולל תו מסיים)?",
        "code_snippet": null,
        "options": null
      },
      {
        "id": "9.2",
        "text": "משתמש ביצע פעולת קריאה של 10KB מתוך הקובץ `/home/user/data/largefile.txt`. ידוע שקובץ זה נוצר במקור כקובץ קטן בגודל 50 בתים, ולאחר מכן הורחב על ידי הוספת נתונים עד שהגיע לגודל כולל של 1MB. נתון שאף cache אינו מכיל מידע רלוונטי לביצוע הפעולה. כל מרכיבי הנתיב (`home`, `user`, `data`) הם תיקיות. יש להניח שאורך שם קובץ ממוצע בתיקיות הוא 8 תווים. מהו הזמן המינימלי שתיקח פעולה זו? יש לפרט את כל הבלוקים הנקראים ואת סדר הגישה אליהם, ולנמק מדוע זהו הזמן המינימלי.",
        "code_snippet": null,
        "options": null
      },
      {
        "id": "9.3",
        "text": "תאר תרחיש בו משתמש מוסיף נתונים לקובץ קטן קיים (Small File) כך שגודלו הופך להיות גדול מ-128 בתים, והוא הופך ל'קובץ גדול' (Large File) הדורש בלוקי נתונים ו-inode מלא. הסבר נקודה ספציפית במהלך פעולה זו שבה קריסת מערכת עלולה להוביל למצב לא עקבי במערכת הקבצים, ותאר את חוסר העקביות. הצע פתרון למניעת חוסר עקביות זה, בהנחה שמערכת הקבצים משתמשת ב-metadata journaling (כלומר, בלוקי הנתונים נכתבים ישירות למיקומם הסופי בדיסק ולא ל-journal).",
        "code_snippet": null,
        "options": null
      }
    ],
    "points": null,
    "solution": {
      "is_present_in_file": true,
      "correct_option": null,
      "explanation": "פתרון שאלה 9:\n\n**סעיף 9.1:**\n1.  **גודל קובץ מקסימלי:**\n    *   גודל בלוק: 4KB = 4096 בתים.\n    *   גודל מצביע: 4 בתים.\n    *   מספר מצביעים בבלוק עקיף: 4096 / 4 = 1024 מצביעים.\n    *   מצביעים ישירים: 10 * 4KB = 40KB.\n    *   מצביעים עקיפים בודדים: 2 * (1024 מצביעים לבלוקי נתונים * 4KB/בלוק) = 2 * 4MB = 8MB.\n    *   מצביע עקיף כפול: 1 * (1024 מצביעים לבלוקי עקיף בודדים * 1024 מצביעים לבלוקי נתונים * 4KB/בלוק) = 1 * 4GB = 4GB.\n    *   סה\"כ גודל קובץ מקסימלי: 40KB + 8MB + 4GB = 4,303,396,864 בתים.\n\n2.  **מספר קבצים קטנים בבלוק תיקייה:**\n    *   גודל בלוק: 4KB = 4096 בתים.\n    *   רשומת תיקייה לקובץ קטן: שם הקובץ (8 תווים = 8 בתים) + גודל הקובץ (2 בתים) + נתוני הקובץ (128 בתים) = 8 + 2 + 128 = 138 בתים.\n    *   מספר רשומות מקסימלי בבלוק יחיד: 4096 בתים / 138 בתים/רשומה = 29.68. כלומר, ניתן לאחסן **29 קבצים קטנים** מלאים בבלוק נתונים יחיד של תיקייה.\n\n**סעיף 9.2:**\nלצורך חישוב הזמן המינימלי, נניח את התרחיש האופטימלי ביותר שבו כל הבלוקים הנדרשים לקריאה ממוקמים ברצף פיזי על הדיסק, ולכן נשלם רק על זמן ההעברה הכולל של הנתונים, ללא זמני seek או rotational latency נוספים מעבר למינימום ההתחלתי (אם בכלל).\n\n**הבלוקים שיש לקרוא, לפי סדר הגישה:**\n1.  **בלוק ה-Superblock:** מכיל את ה-inode של תיקיית השורש. (1 בלוק)\n2.  **בלוק נתונים של תיקיית השורש (`/`):** כדי למצוא את רשומת התיקייה עבור `home` ולקבל את מספר ה-inode שלה. (1 בלוק)\n    *   רשומת תיקייה עבור קובץ גדול (כמו תיקייה): שם (8 בתים) + גודל (2 בתים) + מספר inode (4 בתים) = 14 בתים.\n3.  **בלוק ה-inode של תיקיית `home`:** כדי לקבל את המידע על התיקייה, ובפרט את המצביעים לבלוקי הנתונים שלה. (1 בלוק)\n4.  **בלוק נתונים של תיקיית `home`:** כדי למצוא את רשומת התיקייה עבור `user` ולקבל את מספר ה-inode שלה. (1 בלוק)\n5.  **בלוק ה-inode של תיקיית `user`:** כדי לקבל את המידע על התיקייה. (1 בלוק)\n6.  **בלוק נתונים של תיקיית `user`:** כדי למצוא את רשומת התיקייה עבור `data` ולקבל את מספר ה-inode שלה. (1 בלוק)\n7.  **בלוק ה-inode של תיקיית `data`:** כדי לקבל את המידע על התיקייה. (1 בלוק)\n8.  **בלוק נתונים של תיקיית `data`:** כדי למצוא את רשומת התיקייה עבור `largefile.txt` ולקבל את מספר ה-inode שלה. (1 בלוק)\n9.  **בלוק ה-inode של הקובץ `largefile.txt`:** כדי לקבל את המידע על הקובץ, ובפרט את המצביעים לבלוקי הנתונים שלו. (1 בלוק)\n10. **בלוקי הנתונים של הקובץ `largefile.txt`:** יש לקרוא 10KB. גודל בלוק הוא 4KB. לכן נדרשים 10KB / 4KB/בלוק = 2.5 בלוקים. כלומר, יש לקרוא **3 בלוקים** מלאים (4KB כל אחד). (3 בלוקים)\n\n**סה\"כ בלוקים לקריאה:** 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1 + 3 = **12 בלוקים**.\n\n**חישוב זמן הקריאה המינימלי:**\n*   סה\"כ נתונים להעברה: 12 בלוקים * 4KB/בלוק = 48KB.\n*   קצב העברה מקסימלי: 50 MB/s = 50 * 1024 KB/s.\n*   זמן העברה: 48KB / (50 * 1024 KB/s) = 48 / 51200 שניות = 0.0009375 שניות.\n*   זמן העברה במילישניות: 0.0009375 * 1000 ms = **0.9375ms**.\n\n**נימוק לזמן המינימלי:** ההנחה היא שכל 12 הבלוקים ממוקמים ברצף פיזי על הדיסק, ולכן ניתן לקרוא אותם בפעולת העברה רציפה אחת, לאחר seek ו-rotational latency ראשוניים, אשר זמנם זניח ביחס לזמן ההעברה הכולל או מושמט בתרחישי 'מינימום זמן' כפי שנראה בדוגמאות.\n\n**סעיף 9.3:**\n**תרחיש:**\nמשתמש יוצר קובץ בשם `myfile.txt` בתיקייה `/home/user/data` עם תוכן של 50 בתים. הקובץ מסווג כ'קובץ קטן' (Small File), ונתוניו (50 בתים) נשמרים ישירות בתוך רשומת התיקייה של `myfile.txt` בבלוק הנתונים של `/home/user/data`. ה-inode של `myfile.txt` מסומן כ'קובץ קטן' ואינו מכיל מצביעים לנתונים.\nלאחר מכן, המשתמש מוסיף לקובץ `myfile.txt` עוד 150 בתים של נתונים, כך שגודלו הכולל הופך ל-200 בתים. כעת, הקובץ גדול מ-128 בתים, ולכן הוא צריך להפוך ל'קובץ גדול' (Large File) ונתוניו צריכים לעבור לבלוקי נתונים ייעודיים, ורשומת התיקייה צריכה להכיל את מספר ה-inode שלו במקום את הנתונים.\n\n**נקודת קריסה ואי-עקביות:**\nרצף הפעולות הנדרש למעבר מקובץ קטן לגדול, תחת אילוצי metadata journaling, יכלול בדרך כלל:\n1.  הקצאת בלוק נתונים חדש (או יותר) עבור הקובץ `myfile.txt` (בלוק DATA).\n2.  כתיבת כל התוכן החדש של הקובץ (200 בתים) לבלוק הנתונים החדש שהוקצה. (פעולה זו נחשבת לכתיבת DATA ולכן מתבצעת ישירות למיקומה הסופי בדיסק, מחוץ ל-journal).\n3.  **התחלת טרנזקציה ב-journal (כתיבת TxB).**\n4.  כתיבת המצב החדש של ה-inode של `myfile.txt` (סימון כ'קובץ גדול', עדכון גודל, עדכון מצביעים לבלוק הנתונים החדש) ל-journal.\n5.  כתיבת המצב החדש של רשומת התיקייה של `myfile.txt` בתוך בלוק הנתונים של `/home/user/data` (הסרת 50 הבתים המקוריים, הוספת מספר ה-inode של הקובץ, עדכון גודל) ל-journal.\n6.  עדכון ה-bitmap של הבלוקים ב-journal (סימון הבלוק החדש כבשימוש, ושחרור הבלוק הישן אם היה בשימוש כלשהו ב-inode). (במקרה זה, אין בלוק ישן לשחרר, הנתונים היו בתוך רשומת התיקייה).\n7.  **כתיבת TxE ל-journal.**\n8.  **ביצוע fsync ל-journal** (כדי לוודא שהטרנזקציה נכתבה לדיסק).\n9.  כתיבת ה-inode המעודכן של `myfile.txt` למיקומו הסופי בדיסק.\n10. כתיבת בלוק הנתונים המעודכן של תיקיית `/home/user/data` למיקומו הסופי בדיסק.\n\n**נקודת הקריסה הבעייתית:** אם המערכת קורסת **לאחר שלב 2 (כתיבת נתוני הקובץ החדשים לבלוק הנתונים החדש)** אך **לפני שלב 8 (ביצוע fsync ל-journal)**, כלומר, הנתונים החדשים נכתבו לדיסק, אך המטא-דאטה (ה-inode ורשומת התיקייה) לא עודכנו באופן אטומי ב-journal.\n\n**חוסר העקביות:**\n*   **נתונים אבודים (Lost Data) ודליפת מקום דיסק (Disk Space Leak):** בלוק הנתונים החדש שמכיל את 200 הבתים של הקובץ נכתב לדיסק, אך ה-inode של הקובץ ורשומת התיקייה עדיין לא עודכנו כדי להצביע עליו. כתוצאה מכך, הבלוק החדש מוקצה אך אינו נגיש דרך מערכת הקבצים. הוא הופך ל'בלוק אבוד' ומהווה דליפת מקום דיסק.\n*   **נתונים מיושנים (Stale Data):** רשומת התיקייה עבור `myfile.txt` בבלוק הנתונים של `/home/user/data` עדיין מכילה את ה-50 בתים המקוריים של הקובץ, ומציינת שהקובץ הוא 'קובץ קטן' בגודל 50 בתים. קריאה עתידית של הקובץ תציג את הנתונים הישנים והגודל הישן, למרות שהנתונים החדשים כבר נכתבו במקום אחר על הדיסק.\n*   **חוסר עקביות ב-inode:** ה-inode של הקובץ עדיין מסומן כ'קובץ קטן' ואינו מכיל מצביעים לנתונים, בניגוד למצב הרצוי.\n\n**פתרון למניעת חוסר עקביות (Metadata Journaling):**\nהבעיה נובעת מכך שנתוני הקובץ הקטן נשמרים בתוך המטא-דאטה (רשומת התיקייה). כאשר הקובץ גדל, הוא עובר שינוי מבני הכולל גם העברת נתונים וגם שינוי במטא-דאטה. כדי להבטיח עקביות מלאה תחת metadata journaling, יש לטפל בשינוי רשומת התיקייה ובשינוי ה-inode כפעולה אטומית אחת.\n\n**הפתרון המוצע: גישת Copy-on-Write (CoW) לבלוק התיקייה:**\nבמקום לעדכן את בלוק הנתונים הקיים של התיקייה במקום, ניישם גישת Copy-on-Write לבלוקי תיקיות:\n1.  **הקצאת בלוק נתונים חדש (או יותר)** עבור הקובץ `myfile.txt`.\n2.  **כתיבת כל התוכן החדש של הקובץ** (200 בתים) לבלוק הנתונים החדש שהוקצה. (פעולה זו נכתבת ישירות למיקומה הסופית בדיסק).\n3.  **התחלת טרנזקציה ב-journal (כתיבת TxB).**\n4.  **הקצאת בלוק נתונים *חדש* עבור תיקיית האב** (`/home/user/data`).\n5.  **העתקת כל הרשומות הקיימות** מהבלוק הישן של תיקיית `/home/user/data` לבלוק הנתונים החדש, תוך **דילוג על הרשומה הישנה של `myfile.txt`**.\n6.  **הוספת הרשומה *החדשה* של `myfile.txt`** לבלוק הנתונים החדש של תיקיית `/home/user/data` (רשומה זו תכיל את מספר ה-inode של הקובץ, גודלו החדש, וללא נתונים פנימיים).\n7.  **כתיבת המצב החדש של ה-inode של `myfile.txt`** (סימון כ'קובץ גדול', עדכון גודל, עדכון מצביעים לבלוק הנתונים החדש) ל-journal.\n8.  **כתיבת המצב החדש של ה-inode של תיקיית האב** (`/home/user/data`) ל-journal, כך שיצביע על בלוק הנתונים *החדש* של התיקייה.\n9.  **עדכון ה-bitmap של הבלוקים ב-journal:** סימון הבלוקים החדשים (בלוק הנתונים של הקובץ ובלוק הנתונים החדש של התיקייה) כבשימוש, וסימון הבלוק הישן של התיקייה כפנוי.\n10. **כתיבת TxE ל-journal.**\n11. **ביצוע fsync ל-journal**.\n12. **יישום השינויים למיקומם הסופי בדיסק:** כתיבת ה-inode המעודכן של הקובץ, כתיבת ה-inode המעודכן של תיקיית האב, כתיבת בלוק הנתונים החדש של התיקייה, ועדכון ה-bitmap הראשי.\n13. **שחרור בלוק הנתונים הישן של התיקייה** (הוא כבר סומן כפנוי ב-bitmap כחלק מהטרנזקציה).\n\n**מדוע פתרון זה מטפל בבעיה:**\nאם המערכת קורסת **לפני שלב 11 (טרנזקציה לא בוצעה במלואה)**: הבלוק הישן של תיקיית `/home/user/data` נשאר שלם ועדיין מצביע על `myfile.txt` כקובץ קטן עם 50 בתים של נתונים. הבלוקים החדשים שהוקצו (בלוק נתוני הקובץ ובלוק הנתונים החדש של התיקייה) אינם נגישים ממערכת הקבצים וניתן לשחררם במהלך שחזור או באמצעות כלי fsck.\nאם המערכת קורסת **לאחר שלב 11 (טרנזקציה בוצעה במלואה)**: במהלך שחזור, ה-journal יבוצע מחדש (replay), וכל השינויים במטא-דאטה (ה-inode של הקובץ, ה-inode של התיקייה, ובלוק הנתונים החדש של התיקייה) ייושמו באופן אטומי. מערכת הקבצים תהיה במצב עקבי, כאשר `myfile.txt` מופיע כקובץ גדול עם 200 בתים של נתונים, ובלוק הנתונים הישן של התיקייה פונה.\nפתרון זה מבטיח שאף קריסה לא תגרום לחוסר עקביות במטא-דאטה, שכן כל השינויים הקריטיים (כולל השינוי במבנה רשומת התיקייה) מבוצעים כחלק מטרנזקציה אטומית אחת."
    },
    "difficulty_estimation": "Hard"
  }
}