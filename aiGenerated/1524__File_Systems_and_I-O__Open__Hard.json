{
  "metadata": {
    "source": "ai_generated",
    "subject": "File Systems",
    "topic_hint": "File Systems and I/O",
    "requested_type": "Open",
    "requested_difficulty": "Hard",
    "generated_at": "2026-02-08 11:07:38",
    "examples_used": 3,
    "token_usage": {
      "prompt_tokens": 4088,
      "output_tokens": 3500,
      "total_tokens": 14416
    }
  },
  "question": {
    "id": 1,
    "type": "Open",
    "topic": [
      "File Systems",
      "I/O"
    ],
    "content": {
      "text": "מערכת הקבצים FastFS תוכננה לביצועים גבוהים בפעולות על תיקיות. במקום לאחסן רשומות תיקייה כרשימה שטוחה בבלוקי נתונים, כל בלוק נתונים של תיקייה מכיל טבלת גיבוב (hash table) של שמות קבצים למספרי Inode. גישה זו מאפשרת זמן חיפוש ממוצע של O(1).\nכאשר רשומת תיקייה מתווספת או נמחקת, FastFS משתמשת בגישת Journaling ייחודית:\n1.  בלוק הנתונים של התיקייה (טבלת הגיבוב) נכתב *מיד* לדיסק.\n2.  לאחר מכן, נכתבת רשומת Journal המתעדת את השינוי (לדוגמה, `ADD filename inode_num` עבור הוספה) יחד עם מספר ה-Inode של התיקייה.\n3.  ה-Journal נשמר (committed) לדיסק (באמצעות `fsync`).\n4.  לבסוף, ה-Inode של התיקייה (לדוגמה, `mtime`, `size`) וכן ה-Inode של הקובץ החדש (לדוגמה, `nlink`) מתעדכנים ונכתבים לדיסק.\nנדרש לענות על הסעיפים הבאים תוך התייחסות למבנה ולשיטת ה-Journaling המתוארים.",
      "code_snippet": null,
      "options": null
    },
    "sub_questions": [
      {
        "id": "1.1",
        "text": "תארו תרחיש (לדוגמה, יצירת קובץ חדש) שבו קריסה במערכת FastFS, המשתמשת ב-Journaling המתואר, עלולה להוביל למצב לא עקבי במערכת הקבצים. הסבירו במדויק את חוסר העקביות שייווצר.",
        "code_snippet": null,
        "options": null
      },
      {
        "id": "1.2",
        "text": "בהינתן השימוש בטבלאות גיבוב עבור בלוקי נתונים של תיקיות ב-FastFS, ובהנחה שגודל בלוק קבוע (לדוגמה, 4KB), דון בהשלכות של יצירת תיקייה גדולה מאוד (לדוגמה, 100,000 קבצים) על ביצועי ה-I/O של הדיסק עבור פעולות כמו `ls` (שקוראת את נתוני התיקייה) ו-`find` (שעוברת על תיקיות). התייחס הן ליצירה הראשונית של תיקייה כזו והן לפעולות עוקבות עליה.",
        "code_snippet": null,
        "options": null
      },
      {
        "id": "1.3",
        "text": "הציעו שינוי לשיטת ה-Journaling של FastFS שיפתור את בעיית חוסר העקביות שזוהתה בסעיף 1.1, תוך ניסיון לשמר ככל הניתן את מהירות פעולות התיקייה. תארו את הרצף החדש של פעולות הדיסק והסבירו מדוע הוא מבטיח עקביות.",
        "code_snippet": null,
        "options": null
      }
    ],
    "points": null,
    "solution": {
      "is_present_in_file": true,
      "correct_option": null,
      "explanation": "פתרון:\n\nסעיף 1.1:\nתרחיש חוסר עקביות: יצירת קובץ חדש בשם `myfile` בתיקייה `/my_dir`.\nרצף הפעולות:\n1.  הקצאת Inode חדש (נניח Inode X) עבור `myfile` וכתיבתו לדיסק.\n2.  קריאת בלוק הנתונים של `/my_dir` (טבלת הגיבוב).\n3.  שינוי טבלת הגיבוב של `/my_dir` כדי לכלול את הרשומה `(myfile, X)`.\n4.  **כתיבת בלוק הנתונים המעודכן של `/my_dir` למיקומו הסופי בדיסק.**\n5.  כתיבת רשומת Journal: `ADD /my_dir myfile X`.\n6.  שמירת (Commit) ה-Journal לדיסק (`fsync`).\n7.  עדכון ה-Inode של `/my_dir` (לדוגמה, `mtime`, `size`).\n8.  עדכון ה-Inode של `myfile` (לדוגמה, `nlink`).\n\n**קריסה לאחר שלב 4 ולפני שלב 5:**\nחוסר העקביות שייווצר:\n*   בלוק הנתונים של `/my_dir` בדיסק כבר מכיל את הרשומה `(myfile, X)`.\n*   ה-Journal אינו מכיל כל מידע על הוספת `myfile`, מכיוון שהקריסה אירעה לפני כתיבת רשומה זו ל-Journal.\n*   ה-Inode של `/my_dir` בדיסק אינו מעודכן (הוא עדיין משקף את המצב שלפני הוספת `myfile`, לדוגמה `mtime` ו-`size` לא השתנו).\n*   ה-Inode של `myfile` (X) עשוי להיות עם `nlink=0` (אם שלב 8 לא בוצע).\n\n**תוצאות השחזור (Recovery):**\nמכיוון שה-Journal ריק (אין טרנזקציות לא מחויבות), מערכת הקבצים לא תבצע שום פעולת שחזור.\nכאשר יופעל בודק העקביות (fsck), הוא ימצא את הרשומה `(myfile, X)` בבלוק הנתונים של `/my_dir`, אך יגלה שה-Inode של `/my_dir` אינו מכיר אותה. זהו מצב לא עקבי שבו רשומת תיקייה קיימת אך התיקייה אינה \"מודעת\" לה. כמו כן, אם Inode X נמצא עם `nlink=0`, הוא ייחשב לקובץ יתום.\nfsck יתקן את המצב על ידי מחיקת הרשומה `(myfile, X)` מבלוק הנתונים של `/my_dir` (כדי להתאים ל-Inode של `/my_dir`), ובמקרה הטוב יעביר את Inode X לתיקיית `lost+found` או פשוט ימחק אותו. התוצאה היא אובדן נתונים למשתמש (הקובץ `myfile` נעלם) למרות שחלק מהנתונים נכתבו לדיסק.\n\nסעיף 1.2:\nהשלכות יצירת תיקייה גדולה מאוד (100,000 קבצים) עם טבלת גיבוב בבלוקי נתונים:\n1.  **ריבוי בלוקים וגישות לדיסק:** טבלת גיבוב עבור 100,000 קבצים (כל רשומה דורשת מספר בתים) לא תוכל להשתלב בבלוק יחיד בגודל 4KB. התיקייה תדרוש מספר רב של בלוקי נתונים, כאשר כל אחד מהם מכיל חלק מטבלת הגיבוב או מנגנון שרשור/קישור לבלוקים נוספים. הדבר יגרום לריבוי פעולות קריאה וכתיבה לדיסק, שכן כדי לגשת לנתוני התיקייה (למשל, עבור `ls`), יהיה צורך לקרוא את כל הבלוקים הללו.\n2.  **ירידה בביצועי O(1) ממוצע:** עם מספר כה גדול של רשומות, הסיכוי להתנגשויות (hash collisions) עולה משמעותית. פתרון התנגשויות דורש גישה למיקומים נוספים בתוך הבלוק או לבלוקים אחרים. במקרה של ריבוי בלוקים, הדבר יכול לגרור קריאות דיסק נוספות, מה שיפגע בביצועי ה-O(1) הממוצע המובטחים בתיאוריה.\n3.  **פרגמנטציה ו-I/O אקראי:** סביר להניח שבלוקי הנתונים הרבים של התיקייה יהיו מפוזרים פיזית על הדיסק (פרגמנטציה). פעולות כמו `ls` או `find`, הדורשות קריאה של כל רשומות התיקייה, יגררו גישות I/O אקראיות רבות, מה שיפגע קשות בביצועים עקב זמני seek ו-rotational latency גבוהים.\n4.  **ביצועי יצירה:** יצירת 100,000 קבצים דורשת 100,000 עדכונים לטבלת הגיבוב. אם כל עדכון דורש קריאה, שינוי וכתיבה של בלוק נתונים שלם (או מספר בלוקים), פעולת היצירה תהיה איטית ביותר. בנוסף, כל הרחבה של טבלת הגיבוב לבלוקים חדשים תגרור הקצאות בלוקים נוספות וכתיבתם.\n5.  **צריכת זיכרון:** טבלת גיבוב גדולה כזו תדרוש כמות משמעותית של זיכרון במטמון (cache) כדי לשפר ביצועים. אם התיקייה גדולה מדי עבור המטמון, הביצועים יסבלו עוד יותר.\n\nסעיף 1.3:\nכדי לפתור את בעיית חוסר העקביות תוך שמירה על ביצועים, נשנה את סדר הפעולות ב-Journaling לגישת \"Ordered Journaling\" עבור מטא-דאטה, בדומה ל-ext3. המשמעות היא שהנתונים עצמם (בלוק הנתונים של התיקייה) נכתבים לדיסק לפני שרשומת ה-Journal המתארת את השינוי נכתבת ומוכנסת ל-Commit.\n\n**רצף הפעולות החדש (ליצירת קובץ `myfile` בתיקייה `/my_dir`):**\n1.  הקצאת Inode חדש (Inode X) עבור `myfile` וכתיבתו לדיסק (או ל-cache).\n2.  קריאת בלוק הנתונים של `/my_dir` (טבלת הגיבוב).\n3.  שינוי טבלת הגיבוב של `/my_dir` כדי לכלול את הרשומה `(myfile, X)`.\n4.  **כתיבת בלוק הנתונים המעודכן של `/my_dir` למיקומו הסופי בדיסק.** (פעולה זו חייבת להסתיים לפני שלב 5).\n5.  **כתיבת רשומת Journal:** `ADD /my_dir myfile X` (רשומה זו מציינת שהנתונים כבר נכתבו).\n6.  **שמירת (Commit) ה-Journal לדיסק (`fsync`).** (פעולה זו מבטיחה שה-Journal עמיד לקריסות).\n7.  עדכון ה-Inode של `/my_dir` (לדוגמה, `mtime`, `size`).\n8.  עדכון ה-Inode של `myfile` (לדוגמה, `nlink`).\n\n**הסבר מדוע גישה זו מבטיחה עקביות:**\n*   **קריסה לפני שלב 6 (לפני ה-Commit של ה-Journal):**\n    *   בלוק הנתונים של `/my_dir` עשוי להיות כבר כתוב לדיסק (שלב 4).\n    *   אך רשומת ה-Journal לא נכתבה או לא בוצעה לה `Commit`.\n    *   במהלך השחזור, ה-Journal יהיה ריק (או יכיל טרנזקציות קודמות). לכן, מערכת הקבצים לא תדע על פעולת ההוספה של `myfile`.\n    *   בודק העקביות (fsck) ימצא את בלוק הנתונים של `/my_dir` עם הרשומה `(myfile, X)`, אך יגלה שה-Inode של `/my_dir` אינו תואם (הוא לא עודכן). הוא יסיר את הרשומה מבלוק הנתונים של `/my_dir` ויטפל ב-Inode X כקובץ יתום (אולי ימחק אותו או יעביר ל-`lost+found`).\n    *   **התוצאה:** אובדן הנתונים של הקובץ `myfile`, אך מערכת הקבצים נשארת במצב עקבי. אין מצב של \"Ghost\" רשומות או הפניות שגויות.\n\n*   **קריסה לאחר שלב 6 (לאחר ה-Commit של ה-Journal):**\n    *   בלוק הנתונים של `/my_dir` כתוב לדיסק (שלב 4).\n    *   רשומת ה-Journal נכתבה ועברה `Commit` (שלבים 5 ו-6).\n    *   במהלך השחזור, מערכת הקבצים תקרא את ה-Journal ותבצע replay של הטרנזקציה. היא תראה את רשומת `ADD /my_dir myfile X` ותשלים את הפעולות שטרם בוצעו (שלבים 7 ו-8).\n    *   **התוצאה:** פעולת יצירת הקובץ תושלם בהצלחה, ומערכת הקבצים תהיה במצב עקבי לחלוטין.\n\nגישה זו מבטיחה שכל עוד ה-Journal לא עבר `Commit`, לא תיווצר עקביות פנימית. ברגע שה-Journal עבר `Commit`, מובטח שפעולת השחזור תוכל להשלים את הפעולה ולשמור על עקביות. היא עדיין שומרת על ביצועים יחסית טובים שכן היא כותבת את נתוני התיקייה ישירות למיקומם הסופי ולא ל-Journal, ומספר הכתיבות ל-Journal מצומצם."
    },
    "difficulty_estimation": "Hard"
  }
}