[{"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Processes"], "difficulty_estimation": "Easy", "content": {"text": "מהי האשליה העיקרית שמערכת ההפעלה מנסה ליצור עבור תהליכים, בהינתן שישנם מעט מעבדים אך תהליכים רבים?", "code_snippet": null, "options": ["א. שלכל תהליך יש מעבד ייעודי משלו ושהוא רץ במקביל לכל שאר התהליכים.", "ב. שלכל תהליך יש גישה בלעדית לכל הזיכרון הפיזי של המערכת.", "ג. שכל התהליכים נמצאים תמיד במצב \"Running\".", "ד. שלתהליך אין הורה או ילדים קשורים."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, האתגר המרכזי של מערכת ההפעלה הוא שלמרות שיש מעט מעבדים והרבה תהליכים, היא רוצה לתת את האשליה כאילו יש לנו המון מעבדים, וכי הכל רץ במקביל, בו זמנית. זוהי מהות הווירטואליזציה ברמת התהליך, ליצור אשליה של משאבים רבים וזמינות מתמדת. לכן, אפשרות א' היא התשובה הנכונה. אפשרויות ב', ג' ו-ד' שגויות על פי החומר: לתהליך יש מרחב כתובות משלו ולא גישה בלעדית לכל הזיכרון הפיזי; תהליכים עוברים בין מצבים שונים ולא תמיד נמצאים ב-'Running'; ולתהליכים יש קשרי הורה-ילד ונוצרת היררכיה."}, "_source_file": "0001__Virtualization__Processes__MC__Easy.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 16:49:42", "_subject": "Virtualization", "_context_lectures": [2, 4]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Processes"], "difficulty_estimation": "Easy", "content": {"text": "איזו אשליה מרכזית מערכת ההפעלה מנסה ליצור עבור תהליכים, למרות מספר מוגבל של מעבדים פיזיים?", "code_snippet": null, "options": ["א. לכל תהליך מוקצה כל הזיכרון הפיזי של המערכת באופן בלעדי.", "ב. נראה כאילו כל התהליכים רצים בו-זמנית ובמקביל.", "ג. כל תהליך יכול לשנות באופן חופשי את מצבם של תהליכים אחרים.", "ד. לכל התהליכים במערכת יש מספר מזהה (PID) זהה."]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר ההרצאה, האתגר המרכזי של מערכת ההפעלה הוא לתת אשליה כאילו יש לנו המון מעבדים ו'כאילו הכל רץ במקביל, בו זמנית', למרות שיש מעט מעבדים פיזיים והרבה תהליכים. זוהי מהות וירטואליזציית המעבד. אפשרות א' אינה נכונה, שכן לכל תהליך יש מרחב כתובות משלו, אך לא את כל הזיכרון הפיזי באופן בלעדי. אפשרות ג' אינה נכונה, מכיוון שלתהליך אין דרך לשנות תהליך מעבר לתהליך ההורה שלו. אפשרות ד' אינה נכונה, שכן אין שני תהליכים עם אותו מזהה באותה מערכת."}, "_source_file": "0002__Virtualization__Processes__MC__Easy.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 16:49:52", "_subject": "Virtualization", "_context_lectures": [2, 4]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Processes"], "difficulty_estimation": "Easy", "content": {"text": "מהי האשליה שמערכת ההפעלה מנסה ליצור ביחס להרצת תהליכים במחשב, למרות שיש מספר מוגבל של מעבדים?", "code_snippet": null, "options": ["א. שלכל תהליך יש מעבד ייעודי משלו וכל התהליכים רצים בו-זמנית במקביל.", "ב. שלכל תהליך יש גישה בלעדית לכל הזיכרון הפיזי של המחשב.", "ג. שכל הקבצים הפתוחים של תהליך נשמרים באופן קבוע על הדיסק הקשיח גם לאחר סיום התהליך.", "ד. שכל תהליך מקבל מזהה (PID) חדש בכל פעם שהוא עובר למצב 'Ready'."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. מתוך חומר ההרצאה, ב'Lecture 2 (chunk 7)', מצוין כי 'האתגר: יש מעט מעבדים אבל הרבה תהליכים, ומערכת ההפעלה רוצה לתת את האשליה כאילו יש לנו המון מעבדים (כאילו הכל רץ במקביל, בו זמנית)'. מערכת ההפעלה יוצרת אשליה זו על ידי ניהול תזמון המעבד בין התהליכים השונים במהירות גבוהה, מה שגורם למשתמש להרגיש שכל התהליכים פועלים במקביל, למרות שבפועל רק תהליך אחד (או מספר מוגבל של תהליכים, בהתאם למספר המעבדים) רץ בכל רגע נתון."}, "_source_file": "0003__Virtualization__Processes__MC__Easy.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 16:52:30", "_subject": "Virtualization", "_context_lectures": [2, 4]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Processes"], "difficulty_estimation": "Medium", "content": {"text": "על מנת שמערכת ההפעלה תוכל לנהל מספר רב של תהליכים בו-זמנית וליצור אשליה של ריצה מקבילה, היא שומרת מידע רב עבור כל תהליך. איזה מהבאים *אינו* נכון לגבי מאפייני תהליך או המידע שנשמר עליו?", "code_snippet": null, "options": ["א. לכל תהליך יש מרחב כתובות זיכרון משלו, הכולל מקטעים כמו Text (קוד), Data (נתונים גלובליים), Heap (הקצאות דינמיות) ו-Stack (משתנים מקומיים וארגומנטים).", "ב. כל תהליך מקבל מזהה ייחודי (PID) שאינו משותף עם אף תהליך אחר במערכת, וניתן לאחזר גם את מזהה תהליך ההורה שלו.", "ג. מערכת ההפעלה שומרת עבור כל תהליך את מצבו הנוכחי (למשל, Running או Ready), את מצב הרגיסטרים במעבד בעת הקפאתו, ואת רשימת הקבצים הפתוחים שהוא מחזיק.", "ד. תהליך יכול לשנות ישירות את מצב הריצה (state) של כל תהליך אחר במערכת, כל עוד הוא מכיר את ה-PID שלו, ובכך להשפיע על הקצאת המעבד."]}, "solution": {"correct_option": "ד", "explanation": "הטענה הנכונה היא ד' כי היא אינה נכונה. על פי חומר ההרצאה, 'לתהליך אין דרך לשנות תהליך מעבר לתהליך ההורה שלו' (Lecture 4, chunk 2). מערכת ההפעלה היא זו שאחראית לנהל את מצבי התהליכים (Running, Ready) ואת שיבוץ המעבד (scheduling), ולא תהליכים עצמם באופן ישיר. האפשרויות א, ב, ו-ג נכונות: א. לכל תהליך מרחב כתובות משלו הכולל Text, Data, Heap ו-Stack (Lecture 2, chunk 7). ב. לכל תהליך PID ייחודי וניתן לאחזר את ה-PID של ההורה (Lecture 2, chunk 19; Lecture 4, chunk 2). ג. ה-PCB של תהליך מכיל את מצבו הנוכחי (state), מצב הרגיסטרים (CPU context) ורשימת הקבצים הפתוחים (Lecture 2, chunk 19; Lecture 2, chunk 34)."}, "_source_file": "0004__Virtualization__Processes__MC__Medium.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 16:52:46", "_subject": "Virtualization", "_context_lectures": [2, 4]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Processes"], "difficulty_estimation": "Medium", "content": {"text": "כיצד מערכת ההפעלה יוצרת את האשליה שכל התהליכים רצים במקביל, למרות מספר המעבדים המוגבל?", "code_snippet": null, "options": ["א. על ידי מעבר מהיר בין תהליכים, תוך שמירת מצבו (context) של התהליך הנוכחי וטעינת מצבו של התהליך הבא להרצה.", "ב. על ידי הקצאת ליבת מעבד ייעודית לכל תהליך פעיל במערכת.", "ג. על ידי מתן אפשרות לתהליכים לגשת ישירות למרחבי הזיכרון זה של זה.", "ד. על ידי שמירת כל הקוד של התהליכים במקטע זיכרון משותף אחד לגישה מהירה."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין בשיעור מדגיש כי \"האתגר: יש מעט מעבדים אבל הרבה תהליכים, ומערכת ההפעלה רוצה לתת את האשליה כאילו יש לנו המון מעבדים (כאילו הכל רץ במקביל, בו זמנית)\". אשליה זו מושגת באמצעות מנגנון של החלפת הקשר (Context Switching) מהירה. כאשר תהליך מופסק (Descheduled), מערכת ההפעלה שומרת את כל המידע הנדרש עבור הריצה שלו, כולל \"מצב הרגיסטרים במעבד\" ו\"מצב הזיכרון\". לאחר מכן, היא טוענת את המצב השמור של תהליך אחר ונותנת לו לרוץ (Scheduled). מעבר מהיר זה בין תהליכים, תוך שמירה וטעינה של ה-CPU context ומידע נוסף (כמו קבצים פתוחים), יוצר את האשליה של ריצה מקבילית. אפשרות ב' אינה נכונה מכיוון שהיא סותרת את הנתון על מספר מעבדים מוגבל. אפשרות ג' אינה נכונה כיוון שלכל תהליך יש \"מרחב כתובות משלו\", והוא אינו ניגש ישירות לזיכרון של תהליכים אחרים. אפשרות ד' אינה נכונה, קוד של תהליכים נמצא במקטע ה-Text במרחב הכתובות הפרטי של כל תהליך, ולא במקטע זיכרון משותף לכלל הקוד של כל התהליכים."}, "_source_file": "0005__Virtualization__Processes__MC__Medium.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 16:52:59", "_subject": "Virtualization", "_context_lectures": [2, 4]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Processes"], "difficulty_estimation": "Medium", "content": {"text": "על מנת ליצור את האשליה שכל תהליך רץ באופן בלעדי על מעבד משלו ובעל מרחב זיכרון ייעודי, למרות קיומם של מעבדים בודדים וזיכרון פיזי משותף, מערכת ההפעלה מבצעת מספר פעולות. איזה מבין ההיגדים הבאים מתאר נכונה היבט מרכזי באופן שבו היא משיגה 'וירטואליזציה' זו עבור תהליכים?", "code_snippet": null, "options": ["א. מעבר מהיר בין תהליכים על אותו מעבד (Time-Sharing) והקצאת מרחב כתובות וירטואלי נפרד לכל תהליך.", "ב. הקצאת מזהה תהליך (PID) ייחודי לכל תהליך, אשר מבטיח לו גישה בלעדית למעבד.", "ג. מתן אפשרות לתהליכים לנהל באופן ישיר את המעברים שלהם בין מצבי Ready ו-Running.", "ד. אחסון כל המידע הקשור לתהליך (כמו הקשר מעבד, מיקומי זיכרון, וקבצים פתוחים) באופן בלעדי במערכת הקבצים."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. מערכת ההפעלה יוצרת את אשליית ה'וירטואליזציה' של מעבדים וזיכרון על ידי שני מנגנונים עיקריים המוזכרים בחומר:\n1.  **וירטואליזציה של מעבדים (CPU Virtualization)**: החומר מציין \"האתגר: יש מעט מעבדים אבל הרבה תהליכים, ומערכת ההפעלה רוצה לתת את האשליה כאילו יש לנו המון מעבדים (כאילו הכל רץ במקביל, בו זמנית)\". זה מושג באמצעות תזמון (scheduling) ומעבר מהיר בין תהליכים (Time-Sharing) על ידי מערכת ההפעלה, כך שלכל תהליך נדמה שהוא רץ באופן רציף על מעבד משלו.\n2.  **וירטואליזציה של זיכרון (Memory Virtualization)**: החומר קובע במפורש \"לכל תהליך שרץ יש מרחב כתובות משלו (את הזיכרון שלו)\". מערכת ההפעלה מקצה לכל תהליך מרחב כתובות וירטואלי נפרד, המבודד אותו מתהליכים אחרים ומעניק לו אשליה של זיכרון ייעודי.\n\nאפשרויות ב', ג' ו-ד' שגויות:\n*   **ב'**: מזהה תהליך (PID) הוא אכן ייחודי, אך הוא אינו מבטיח גישה בלעדית למעבד; המעבד משותף בין תהליכים רבים, כפי שמשתמע מהצורך ליצור אשליה של ריצה מקבילה.\n*   **ג'**: המעבר בין מצבי תהליך (כמו Ready ו-Running) נשלט על ידי מערכת ההפעלה (\"ברגע שהחלטנו להפסיק את התהליך... ולהריץ תהליך אחר במקומו... מערכת ההפעלה בוחרת את התהליך הבא להרצה\"), ולא על ידי התהליך עצמו.\n*   **ד'**: המידע על התהליך (כמו הקשר מעבד, מיקומי זיכרון וקבצים פתוחים) נשמר ב-PCB (Process Control Block) ובאזורי זיכרון שונים (RAM), ולא באופן בלעדי במערכת הקבצים. מערכת הקבצים אכן מעורבת ביצירת התהליך ובאחסון קוד התוכנית, אך לא בכל המידע התפעולי השוטף של התהליך."}, "_source_file": "0006__Virtualization__Processes__MC__Medium.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 16:53:17", "_subject": "Virtualization", "_context_lectures": [2, 4]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Processes"], "difficulty_estimation": "Hard", "content": {"text": "מערכת ההפעלה יוצרת אשליה עבור תהליכים כאילו הם רצים במקביל ונהנים ממשאבים ייעודיים (כגון מעבד וזיכרון), אף שבפועל קיימים מעבדים פיזיים מעטים וזיכרון פיזי משותף. איזה מבין התיאורים הבאים מסביר בצורה הטובה ביותר כיצד מערכת ההפעלה משיגה אשליה זו, בהתבסס על המידע שנלמד על מאפייני תהליכים ומחזור חייהם?", "code_snippet": null, "options": ["א. באמצעות ניהול מצבי תהליכים (Ready, Running), החלפת הקשר (context switch) הכוללת שמירת מצב המעבד (רגיסטרים) וקבצים פתוחים ב-PCB, והקצאת מרחב כתובות זיכרון נפרד לכל תהליך, מערכת ההפעלה מדמה ריצה מקבילית ומשאבים ייעודיים.", "ב. על ידי יצירת היררכיית תהליכים (אב-בן) ושימוש במזהי תהליכים (PID) ייחודיים, מערכת ההפעלה מאפשרת לכל תהליך לשלוט במשאבי בניו ולקבל עדיפות בגישה למעבד.", "ג. האשליה מושגת בכך שכל תהליך הוא מופע דינמי של תוכנית, ונוצר על ידי שיתוף פעולה בין המעבד, הזיכרון ומערכת הקבצים, מה שמבטיח הקצאה חד פעמית של משאבים בעת היצירה.", "ד. כל תהליך מקבל מרחב כתובות זיכרון משלו המחולק למקטעים (Text, Data, Heap, Stack), ובכך מובטח שכל תהליך יקבל את כל הזיכרון הדרוש לו באופן בלעדי, מה שיוצר את האשליה של מעבדים רבים."]}, "solution": {"correct_option": "א", "explanation": "האפשרות הנכונה היא א'. מערכת ההפעלה אכן יוצרת את האשליה של ריצה מקבילית ומשאבים ייעודיים על ידי מספר מנגנונים מרכזיים המוזכרים בחומר הלימוד:\n1.  **ניהול מצבי תהליכים והחלפת הקשר (Context Switching):** חומר הלימוד מציין כי \"מערכת ההפעלה רוצה לתת את האשליה כאילו יש לנו המון מעבדים (כאילו הכל רץ במקביל, בו זמנית)\". זה מושג באמצעות מעבר בין מצבי Ready ו-Running. כאשר תהליך נבחר לרוץ (scheduled) הוא עובר ל-Running, וכאשר הוא מופסק (descheduled) הוא עובר ל-Ready. תהליך זה כולל שמירה של ה-CPU context (כמו רגיסטרים) ומידע נוסף (כמו קבצים פתוחים ומיקומי זיכרון) ב-PCB (Process Control Block), כפי שצוין בחומר הלימוד \"שמירת מצב הרגיסטרים במעבד כשהקפאנו את אותו התהליך, מצב הזיכרון (המיקומים וכו') שקשורים לאותו תהליך, מה הקבצים הפתוחים שאותו התהליך מחזיק\". זה מאפשר למערכת ההפעלה להחליף תהליכים במהירות ולתת אשליה של ריצה בו-זמנית.\n2.  **מרחב כתובות זיכרון נפרד:** חומר הלימוד מציין במפורש \"לכל תהליך שרץ יש מרחב כתובות משלו (את הזיכרון שלו)\". מרחב כתובות זה מורכב ממקטעים (Text, Data, Heap, Stack) ומבודד כל תהליך מזיכרונם של תהליכים אחרים, ובכך יוצר אשליה של זיכרון ייעודי ובלעדי.\n\nאפשרות ב' שגויה מכיוון שהיררכיית תהליכים ומזהי PID קשורים לזיהוי וקשרי גומלין בין תהליכים, אך אינם מסבירים כיצד נוצרת האשליה של מעבדים רבים או משאבי זיכרון ייעודיים.\nאפשרות ג' שגויה מכיוון שהיא מתארת את הגדרת התהליך כמופע דינמי ואת מרכיבי היצירה שלו, אך לא את המנגנונים ששומרים על אשליית הריצה המקבילית והמשאבים הייעודיים לאורך זמן. ההקצאה אינה \"חד פעמית\".\nאפשרות ד' חלקית נכונה בכך שהיא מזכירה את מרחב הכתובות הנפרד והמקטעים, המהווה חלק מהאשליה של זיכרון ייעודי, אך היא אינה מתייחסת כלל למנגנונים הקשורים למעבד (כמו ניהול מצבים והחלפת הקשר) ובכך אינה מסבירה את האשליה של \"מעבדים רבים\" או ריצה מקבילית."}, "_source_file": "0007__Virtualization__Processes__MC__Hard.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 16:53:32", "_subject": "Virtualization", "_context_lectures": [2, 4]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Processes"], "difficulty_estimation": "Hard", "content": {"text": "כיצד מערכת ההפעלה יוצרת ומקיימת את האשליה של ריצה מקבילה של תהליכים רבים על מעבד יחיד, למרות שרק תהליך אחד יכול לרוץ פיזית בכל רגע נתון?", "code_snippet": null, "options": ["א. מערכת ההפעלה מבצעת החלפת הקשר (context switch) על ידי שמירת כל המידע הנדרש עבור ריצת התהליך הנוכחי (כולל מצב הרגיסטרים, מיקומי זיכרון וקבצים פתוחים) כאשר הוא עובר למצב Ready, וטעינת המידע של התהליך הבא שנבחר להרצה.", "ב. מערכת ההפעלה מקצה לכל תהליך מרחב כתובות זיכרון ייעודי משלו (Text, Data, Heap, Stack), ובכך מונעת הפרעה בין תהליכים ומאפשרת להם לרוץ כאילו הם היחידים במערכת.", "ג. תהליכים מרובים מקבלים מזהים ייחודיים (PID) ונוצרת היררכיית אב-בן, מה שמאפשר למערכת ההפעלה לנהל אותם ביעילות ולהריץ אותם במקביל.", "ד. מערכת ההפעלה מונעת מתהליכים לשנות תהליכים אחרים שאינם תהליך האב שלהם, ובכך מבטיחה עצמאות מלאה בין תהליכים ומונעת תלות הדדית."]}, "solution": {"correct_option": "א", "explanation": "האשליה של ריצה מקבילה של תהליכים רבים על מעבד יחיד מושגת באמצעות מנגנון החלפת הקשר (context switch). כאשר מערכת ההפעלה מחליטה להפסיק את ריצתו של תהליך אחד (המכונה 'Descheduled') ולהעביר אותו ממצב 'Running' למצב 'Ready', היא שומרת את כל המידע הנדרש כדי שתוכל לחדש את ריצתו של התהליך המופסק בדיוק מהמקום בו הופסק. מידע זה, כפי שמצוין בחומר הלימוד, כולל את מצב הרגיסטרים במעבד, מיקומי הזיכרון (כגון ערימה ומחסנית), ורשימת הקבצים הפתוחים של התהליך. לאחר מכן, היא טוענת את המידע השמור של התהליך הבא שנבחר לריצה (המכונה 'Scheduled') ומעבירה אותו ממצב 'Ready' למצב 'Running'. מחזוריות מהירה של פעולות אלו יוצרת את האשליה של ריצה בו-זמנית על מעבד בודד, כפי שמתואר בחומר הלימוד: \"האתגר: יש מעט מעבדים אבל הרבה תהליכים, ומערכת ההפעלה רוצה לתת את האשליה כאילו יש לנו המון מעבדים (כאילו הכל רץ במקביל, בו זמנית)\".\n\nאפשרויות ב', ג' ו-ד' מתארות היבטים שונים של ניהול תהליכים והווירטואליזציה שהמערכת מספקת, אך אינן המנגנון הישיר המאפשר את אשליית הריצה המקבילה על מעבד יחיד:\n- אפשרות ב' מתארת את מרחב הכתובות הפרטי של כל תהליך, אשר אכן תורם לבידוד בין תהליכים, אך אינה מסבירה כיצד הם רצים ב'מקביל' על מעבד אחד.\n- אפשרות ג' מתארת את שימוש במזהים ייחודיים (PID) והיררכיית אב-בן, שהם חשובים לניהול וזיהוי תהליכים, אך אינם המנגנון המייצר את אשליית הריצה המקבילה.\n- אפשרות ד' מתארת הגבלה ביכולת תהליך לשנות תהליכים אחרים, מה שתורם לאבטחה וליציבות המערכת, אך אינה קשורה ישירות ליצירת אשליית הריצה המקבילה על מעבד יחיד."}, "_source_file": "0008__Virtualization__Processes__MC__Hard.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 16:53:49", "_subject": "Virtualization", "_context_lectures": [2, 4]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Processes"], "difficulty_estimation": "Hard", "content": {"text": "בהינתן שמערכת הפעלה יוצרת אשליה של ריבוי מעבדים וזיכרון ייעודי לכל תהליך, על אף שישנם משאבים פיזיים מוגבלים ומשותפים (מעבדים וזיכרון RAM), איזה מבין המנגנונים הבאים הוא הקריטי ביותר לאפשר את אשליית הבידוד המלא בין מרחבי הכתובות של תהליכים שונים?", "code_snippet": null, "options": ["א. ניהול מרחבי כתובות וירטואליים נפרדים לכל תהליך, הממופים לזיכרון הפיזי על ידי מערכת ההפעלה.", "ב. שמירת מצב הרגיסטרים וקבצים פתוחים של תהליך במבנה ה-PCB בעת מעבר הקשר.", "ג. יצירת היררכיית תהליכים (אב-בן) המאפשרת לתהליך הורה לשלוט בבניו.", "ד. הקצאת מקטעי זיכרון קבועים (Text, Data) ודינמיים (Heap, Stack) בתוך מרחב הכתובות של כל תהליך."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין בשיעור קובע כי מערכת ההפעלה רוצה לתת את האשליה 'כאילו הכל רץ במקביל, בו זמנית' וכי 'לכל תהליך שרץ יש מרחב כתובות משלו (את הזיכרון שלו)'. מנגנון זה, של ניהול מרחבי כתובות וירטואליים נפרדים לכל תהליך, הוא המפתח ליצירת אשליית הבידוד המלא בזיכרון. למרות שהזיכרון הפיזי משותף, מערכת ההפעלה ממפה את הכתובות הווירטואליות של כל תהליך לכתובות פיזיות שונות, ובכך מונעת מתהליכים לדרוס זה את זיכרונו של זה ומעניקה לכל תהליך תחושה של זיכרון ייעודי משלו. זוהי הליבה של וירטואליזציית הזיכרון.\n\nאפשרויות אחרות:\nב. שמירת מצב הרגיסטרים וקבצים פתוחים ב-PCB (Process Control Block) היא קריטית עבור מעבר הקשר (Context Switch) ומאפשרת את אשליית הריצה הרציפה של כל תהליך על המעבד, אך היא אינה המנגנון העיקרי לאבטחת בידוד *מרחבי הכתובות* בין תהליכים שונים.\nג. יצירת היררכיית תהליכים (אב-בן) קשורה לניהול תהליכים ולמבנה שלהם במערכת ההפעלה, ואינה נוגעת באופן ישיר למנגנון שאחראי על בידוד מרחבי הכתובות הווירטואליים בין תהליכים.\nד. הקצאת מקטעי זיכרון (Text, Data, Heap, Stack) מתארת את הארגון הפנימי של הזיכרון *בתוך* מרחב הכתובות של תהליך יחיד, אך אינה מסבירה את המנגנון המבטיח את הבידוד *בין* מרחבי הכתובות של תהליכים שונים."}, "_source_file": "0009__Virtualization__Processes__MC__Hard.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 16:54:02", "_subject": "Virtualization", "_context_lectures": [2, 4]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Process Lifecycle"], "difficulty_estimation": "Easy", "content": {"text": "מה המשמעות של תהליך הנמצא במצב \"Running\" במחזור החיים שלו?", "code_snippet": null, "options": ["א. המעבד מריץ כרגע את הפקודות שלו.", "ב. התהליך מוכן לרוץ וממתין למערכת ההפעלה שתשבץ אותו.", "ג. התהליך סיים את ריצתו אך הרשומה שלו עדיין קיימת בטבלת התהליכים.", "ד. התהליך ממתין להשלמת פעולת קלט/פלט."]}, "solution": {"correct_option": "א", "explanation": "לפי חומר ההרצאה (Lecture 2, chunk 34), אם תהליך נמצא במצב \"Running\", המשמעות היא \"שהמעבד מריץ כרגע את הפקודות שלו\". אפשרות ב' מתארת את מצב \"Ready\", שבו התהליך מוכן לרוץ אך עדיין לא שובץ למעבד. אפשרות ג' מתארת תהליך \"זומבי\" (defunct). אפשרות ד' מתארת מצב של המתנה לפעולת קלט/פלט, אשר אינו אחד המצבים העיקריים המתוארים במפורש בחומר ההרצאה בקשר למצב \"Running\"."}, "_source_file": "0010__Virtualization__Process_Lifecycle__MC__Easy.json", "_topic_hint": "Process Lifecycle", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 16:54:10", "_subject": "Virtualization", "_context_lectures": [2, 4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Process Lifecycle"], "difficulty_estimation": "Easy", "content": {"text": "מהו המצב המתאר תהליך שמוכן לרוץ וממתין שמערכת ההפעלה תבחר אותו כדי שירוץ על המעבד?", "code_snippet": null, "options": ["א. Running", "ב. Ready", "ג. Zombie", "ד. Descheduled"]}, "solution": {"correct_option": "ב", "explanation": "לפי חומר ההרצאה (Lecture 2, chunk 34), המצב 'Ready' מתאר תהליך ש'מוכן לרוץ'. מערכת ההפעלה בוחרת את התהליך הבא להרצה מתוך רשימת התהליכים שנמצאים במצב זה. מצב 'Running' מתאר תהליך שרץ כרגע על המעבד. 'Zombie' (Lecture 5, chunk 6) מתאר תהליך שהסתיים אך רשומתו עדיין קיימת בטבלת התהליכים. 'Descheduled' הוא פעולה (לא מצב) שבה תהליך מופסק ועובר למצב 'Ready', ולא מצב בפני עצמו."}, "_source_file": "0011__Virtualization__Process_Lifecycle__MC__Easy.json", "_topic_hint": "Process Lifecycle", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 16:54:22", "_subject": "Virtualization", "_context_lectures": [2, 4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Process Lifecycle"], "difficulty_estimation": "Easy", "content": {"text": "מהי המשמעות של תהליך הנמצא במצב 'Running' (רץ) במחזור החיים שלו?", "code_snippet": null, "options": ["א. המעבד מריץ כרגע את הפקודות של התהליך.", "ב. התהליך מוכן לרוץ אך ממתין לתורו במעבד.", "ג. התהליך סיים את ריצתו אך רשומתו עדיין קיימת בטבלת התהליכים.", "ד. התהליך הופסק באופן יזום והוחזר למחסן ההמתנה."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה (Lecture 2, chunk 34), תהליך הנמצא במצב 'Running' הוא תהליך ש'המעבד מריץ כרגע את הפקודות שלו'.\nאפשרות ב' מתארת תהליך במצב 'Ready'.\nאפשרות ג' מתארת תהליך 'זומבי' (defunct).\nאפשרות ד' מתארת את הפעולה 'Descheduled' שמעבירה תהליך ממצב 'Running' למצב 'Ready', ולא את מצב 'Running' עצמו."}, "_source_file": "0012__Virtualization__Process_Lifecycle__MC__Easy.json", "_topic_hint": "Process Lifecycle", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 16:54:31", "_subject": "Virtualization", "_context_lectures": [2, 4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Process Lifecycle"], "difficulty_estimation": "Medium", "content": {"text": "לפי חומר ההרצאה, מהו המצב שאליו עובר תהליך שהיה במצב Running (רץ) והופסק על ידי פסיקת שעון (timer interrupt), ומה קורה למידע שלו?", "code_snippet": null, "options": ["א. הוא עובר למצב Ready, ומערכת ההפעלה שומרת את ה-CPU context שלו (לדוגמה, ערכי הרגיסטרים) ואת מצב הזיכרון שלו.", "ב. הוא עובר למצב Blocked, וכל המידע הקשור אליו נמחק מהזיכרון כדי לפנות מקום לתהליכים אחרים.", "ג. הוא נשאר במצב Running אך מפסיק לבצע פקודות עד שהמעבד יתפנה.", "ד. הוא הופך לתהליך Zombie, ומחכה שאביו יבצע עליו wait."]}, "solution": {"correct_option": "א", "explanation": "כאשר תהליך במצב Running מופסק על ידי פסיקת שעון (timer interrupt) או קריאת מערכת, הוא עובר למצב Ready. תהליך זה נקרא Descheduled (הוצא מלוח הזמנים). במצב Ready, התהליך מוכן לרוץ אך ממתין לתורו לקבל את המעבד. חשוב לציין שבעת המעבר ממצב Running למצב Ready, מערכת ההפעלה שומרת את כל המידע הנדרש עבור חידוש הריצה של התהליך, כולל ה-CPU context (כמו ערכי הרגיסטרים במעבד) ואת מצב הזיכרון הקשור לתהליך. מידע זה נשמר ב-PCB (Process Control Block) של התהליך ומאפשר למערכת ההפעלה לשחזר את מצבו המדויק ולהמשיך את ריצתו מאותה נקודה מאוחר יותר (כפי שמפורט ב-Lecture 2, chunk 19 ו-chunk 34). אפשרות ב' אינה נכונה מכיוון שהתהליך לא עובר למצב Blocked במקרה זה, ומידע לא נמחק אלא נשמר. אפשרות ג' אינה נכונה מכיוון שהתהליך אינו נשאר במצב Running אם הוא הפסיק לבצע פקודות. אפשרות ד' אינה נכונה מכיוון שתהליך זומבי הוא תהליך שסיים את ריצתו אך רשומתו עדיין קיימת, ואינו תוצאה של פסיקת שעון (כפי שמפורט ב-Lecture 5, chunk 6)."}, "_source_file": "0013__Virtualization__Process_Lifecycle__MC__Medium.json", "_topic_hint": "Process Lifecycle", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 16:54:43", "_subject": "Virtualization", "_context_lectures": [2, 4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Process Lifecycle"], "difficulty_estimation": "Medium", "content": {"text": "מהי הסיבה העיקרית שמערכת הפעלה אינה מפנה באופן אוטומטי תהליכי זומבי (defunct), גם לאחר שסיימו את ריצתם?", "code_snippet": null, "options": ["א. מכיוון שתהליך האב עדיין מצפה לקרוא ל-wait() על תהליך הבן כדי לאסוף את סטטוס הסיום שלו.", "ב. מכיוון שתהליך זומבי נשאר במצב זה עד שתהליך ה-init יאמץ אותו ויפנה אותו.", "ג. כדי לאפשר לתהליכים אחרים לבצע דיבוג (debugging) על מצבו האחרון של התהליך שהסתיים.", "ד. מערכת ההפעלה אינה מזהה תהליכים במצב זומבי ודורשת התערבות ידנית."]}, "solution": {"correct_option": "א", "explanation": "ההסבר מהחומר המצורף (הרצאה 5, קטע 6) קובע במפורש: \"מדוע מערכת ההפעלה לא עושה פינוי לתהליכים שהם זומבים? מכיוון שתהליך האב עלול לעשות לתהליך הבן wait.\" תהליך זומבי הוא תהליך שסיים את ריצתו אך רשומתו עדיין קיימת בטבלת התהליכים. מערכת ההפעלה משאירה את הרשומה הזו עד שתהליך האב יקרא ל-`wait()` כדי לאסוף את קוד היציאה של תהליך הבן. אם מערכת ההפעלה הייתה מפנה את הזומבי אוטומטית, תהליך האב לא היה יכול לקבל מידע זה. לכן, תשובה א' היא הנכונה. תשובה ב' מתארת מצב שבו תהליך הופך ליתום (orphan) לאחר סיום תהליך האב, ואז `init` מפנה אותו, אך זו אינה הסיבה שמערכת ההפעלה אינה מפנה זומבים באופן כללי. תשובות ג' ו-ד' אינן נתמכות בחומר ההרצאה."}, "_source_file": "0014__Virtualization__Process_Lifecycle__MC__Medium.json", "_topic_hint": "Process Lifecycle", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 16:54:55", "_subject": "Virtualization", "_context_lectures": [2, 4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Process Lifecycle"], "difficulty_estimation": "Medium", "content": {"text": "מה מתאר בצורה הטובה ביותר תהליך \"זומבי\" (Zombie Process) במחזור חייו, ומדוע מערכת ההפעלה אינה מנקה אותו מיד?", "code_snippet": null, "options": ["א. תהליך שנמצא במצב \"Ready\" ומוכן לרוץ, אך המערכת מסמנת אותו כ\"defunct\" עד שתהליך האב יקרא לו wait().", "ב. תהליך שהסתיים בהצלחה ושוחרר מזיכרון המערכת, אך מזהה ה-PID שלו נשמר לזמן קצר למטרות תיעוד.", "ג. תהליך שהסתיים, אך רשומת ה-PCB שלו עדיין קיימת בטבלת התהליכים (מסומנת כ-\"defunct\"), מכיוון שתהליך האב שלו עדיין פעיל ועלול לבצע wait() עליו.", "ד. תהליך תקוע במצב \"Running\" שאינו מגיב, ומערכת ההפעלה ממתינה לתהליך האב שיסיים את ריצתו כדי להפוך את הזומבי לבן של init."]}, "solution": {"correct_option": "ג", "explanation": "על פי חומר ההרצאה (Lecture 5, chunk 6), תהליך זומבי הוא \"תהליך שהסתיים אבל הרשומה שלו עדיין קיימת בטבלת התהליכים\" והוא מסומן במילה \"defunct\". הסיבה שמערכת ההפעלה אינה מנקה אותו מיד היא \"מכיוון שתהליך האב עלול לעשות לתהליך הבן wait\". אם תהליך האב עדיין רץ, הוא עשוי לקרוא ל-wait() כדי לאסוף את קוד היציאה של תהליך הבן. לכן, אפשרות ג' מתארת במדויק את המצב והסיבה.\nאפשרויות א' ו-ד' שגויות מכיוון שתהליך זומבי אינו במצב \"Ready\" או \"Running\"; הוא כבר סיים את ריצתו. אפשרות ב' שגויה מכיוון שרשומת ה-PCB עדיין קיימת, והסיבה העיקרית היא לא רק תיעוד אלא הצורך לאפשר לתהליך האב לאסוף מידע."}, "_source_file": "0015__Virtualization__Process_Lifecycle__MC__Medium.json", "_topic_hint": "Process Lifecycle", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 16:55:09", "_subject": "Virtualization", "_context_lectures": [2, 4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Process Lifecycle"], "difficulty_estimation": "Hard", "content": {"text": "תהליך במערכת הפעלה עובר ממצב \"רץ\" (Running) למצב \"מוכן\" (Ready) כאשר הוא נשלף מהמעבד (Descheduled). איזו מהטענות הבאות מתארת בצורה הטובה ביותר את המטרה העיקרית של שמירת הקונטקסט של המעבד (CPU context), כפי שמצוין ב-PCB, בהקשר של מחזור חיי התהליך והווירטואליזציה?", "code_snippet": null, "options": ["א. לאפשר לתהליך לחדש את ריצתו בדיוק מהנקודה שבה הופסק, ובכך לשמר את אשליית הסביבה המבודדת והרציפה שלו.", "ב. למנוע מהתהליך להפוך ל\"זומבי\" לאחר סיום ריצתו.", "ג. לעדכן את שדה ה-state ב-PCB למצב \"Ready\" בצורה יעילה.", "ד. להבטיח שתהליכי הבן שלו לא יהפכו ליתומים במקרה של סיום בלתי צפוי."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין ב-PCB, כולל ה-CPU context (כמו רגיסטרים), נשמר כאשר תהליך מוסר מהמעבד (Descheduled) ועובר למצב Ready. שמירה זו חיונית כדי שכאשר התהליך ייבחר שוב לריצה (Scheduled), ניתן יהיה לשחזר את מצבו המדויק של המעבד (CPU) ואת כל המידע הנדרש (כמו מיקומי זיכרון, קבצים פתוחים) בדיוק כפי שהיה לפני שהופסק. זהו עקרון יסוד בווירטואליזציה של המעבד, שמאפשר לכל תהליך להרגיש כאילו הוא היחיד שרץ על המעבד באופן רציף, למרות שהוא למעשה עובר בין מצבי ריצה והמתנה. אפשרות ב' אינה נכונה מכיוון שמצב זומבי קשור לסיום תהליך ולאי ביצוע wait על ידי האב, לא להסרה מהמעבד. אפשרות ג' אינה נכונה מכיוון שעדכון ה-state הוא פעולה נפרדת ופשוטה יותר משמירת קונטקסט. אפשרות ד' אינה נכונה מכיוון שהיא מתייחסת ליחסי הורה-בן ולטיפול ביתומים, נושא שאינו קשור ישירות לשמירת קונטקסט בעת הסרת תהליך מהמעבד."}, "_source_file": "0016__Virtualization__Process_Lifecycle__MC__Hard.json", "_topic_hint": "Process Lifecycle", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 16:55:23", "_subject": "Virtualization", "_context_lectures": [2, 4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Process Lifecycle"], "difficulty_estimation": "Hard", "content": {"text": "תהליך בן סיים את ריצתו בהצלחה, אך תהליך האב שלו, שעדיין פעיל, אינו מבצע עליו קריאת מערכת wait. בהתבסס על המידע הנתון, מהו המצב בו יימצא תהליך הבן, ומהו המנגנון העיקרי שמערכת ההפעלה תסתמך עליו כדי לוודא שמשאביו יפונו לבסוף, גם אם תהליך האב לעולם לא יקרא ל-wait?", "code_snippet": null, "options": ["א. תהליך הבן יימצא במצב \"זומבי\" (defunct). מערכת ההפעלה תמתין לסיום ריצתו של תהליך האב; ברגע שתהליך האב יסיים, תהליך הבן יאומץ על ידי init, אשר ידאג לפנות את רשומתו.", "ב. תהליך הבן יימצא במצב \"מוכן לריצה\" (Ready). מערכת ההפעלה תזהה חוסר פעילות ותעביר אותו למצב \"מושהה\" (Suspended) ולאחר מכן תפנה את משאביו באופן יזום.", "ג. תהליך הבן יימצא במצב \"רץ\" (Running) אך ללא פקודות לביצוע. מערכת ההפעלה תשלח אות kill -9 לתהליך הבן כדי לפנות את משאביו.", "ד. תהליך הבן יימצא במצב \"זומבי\" (defunct). מערכת ההפעלה תפעיל טיימר מיוחד, ולאחר פרק זמן קצוב תפנה את רשומתו באופן אוטומטי, ללא תלות בתהליך האב או ב-init."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. כאשר תהליך בן מסיים את ריצתו, אך תהליך האב שלו (שעדיין פעיל) אינו מבצע עליו קריאת מערכת wait, תהליך הבן נכנס למצב \"זומבי\" (defunct). במצב זה, תהליך הבן כבר אינו רץ ורוב משאביו שוחררו, אך רשומת ה-PCB שלו (ותוכם מידע כמו קוד היציאה) נשארת בטבלת התהליכים. מערכת ההפעלה אינה מפנה רשומות אלו באופן יזום, כיוון שהיא מצפה שתהליך האב יקרא ל-wait על מנת לאסוף את קוד היציאה ולפנות את הרשומה. אם תהליך האב לעולם לא יקרא ל-wait, הדרך העיקרית לפינוי רשומת הזומבי היא כאשר תהליך האב עצמו יסיים את ריצתו. במקרה כזה, כל תהליכי הבנים שנותרו (כולל הזומבים) מאומצים על ידי תהליך init (תהליך מספר 1), אשר ידוע בכך שהוא דואג לפנות את רשומות הזומבים שלו, ובכך משחרר את ה-PCB של תהליך הבן. אפשרויות ב', ג' ו-ד' אינן נכונות: תהליך שהסתיים אינו יכול להיות במצב \"מוכן לריצה\" או \"רץ\". מערכת ההפעלה אינה מפנה זומבים באופן יזום באמצעות טיימר או אות kill -9 ישירות לתהליך הזומבי, אלא ממתינה לפעולת האב או לסיום האב."}, "_source_file": "0017__Virtualization__Process_Lifecycle__MC__Hard.json", "_topic_hint": "Process Lifecycle", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 16:55:41", "_subject": "Virtualization", "_context_lectures": [2, 4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Process Lifecycle"], "difficulty_estimation": "Hard", "content": {"text": "תהליך P מסיים את ריצתו בהצלחה, אך תהליך האב שלו, אשר עדיין פעיל, אינו מבצע קריאת מערכת wait. כתוצאה מכך, P הופך לתהליך 'זומבי'. בהתייחס למבנה ה-PCB ולמחזור חיי התהליך כפי שתוארו בחומר, איזה רכיב מבין רכיבי ה-PCB הבאים הוא **החיוני ביותר** להישארות התהליך במצב זומבי ולתהליך הפינוי העתידי שלו, ומה הסיבה לכך?", "code_snippet": null, "options": ["א. מצב המעבד (CPU context) ומיקומי הזיכרון (Memory locations) של התהליך, כדי לאפשר למערכת ההפעלה לשחזר את ריצתו במידת הצורך.", "ב. מזהה התהליך (PID) ומזהה תהליך האב (PPID) שלו, יחד עם מצב התהליך ('defunct'), על מנת לאפשר לתהליך האב לבצע עליו wait או ל-init לאמץ ולנקות אותו במקרה הצורך.", "ג. רשימת הקבצים הפתוחים (Open files) ומידע על הרשאות המשתמש הקשורות לתהליך, כדי להבטיח שחרור נכון של משאבי מערכת.", "ד. מצב הריצה (Running) או מוכנות (Ready) של התהליך, יחד עם נתוני התזמון שלו, כדי שמערכת ההפעלה תוכל לשבץ אותו מחדש להרצה."]}, "solution": {"correct_option": "ב", "explanation": "תהליך זומבי הוא תהליך שהסתיים אך הרשומה שלו בטבלת התהליכים (PCB) עדיין קיימת. על פי חומר ההרצאה, הסיבה העיקרית לכך היא שתהליך האב 'עלול לעשות לתהליך הבן wait' על מנת לקבל מידע על סיום הבן. ה-PCB מכיל את מזהה התהליך (PID), את מצבו (state) ואת התהליכים הקשורים אליו (related processes), ובפרט את תהליך האב. לכן, ה-PCB חייב לשמר את מזהה התהליך (PID), את מזהה תהליך האב (PPID) ואת מצבו כ-'defunct' (זומבי). מידע זה חיוני כדי לאפשר לתהליך האב למצוא את התהליך הזומבי ולבצע עליו wait, או במקרה שתהליך האב יסתיים, כדי שתהליך init (אשר על פי החומר, לא משאיר זומבים) יוכל לאמץ את התהליך הזומבי ולפנות את רשומתו. אפשרויות אחרות אינן נכונות: תהליך זומבי אינו מיועד להמשך ריצה ולכן מצב המעבד ומיקומי הזיכרון (אופציה א) אינם נשמרים; קבצים פתוחים ומשאבים אחרים (אופציה ג) משוחררים בדרך כלל עם סיום התהליך; תהליך זומבי אינו במצב Running או Ready (אופציה ד) ואינו מיועד לתזמון מחדש, אלא הוא תהליך שהסתיים."}, "_source_file": "0018__Virtualization__Process_Lifecycle__MC__Hard.json", "_topic_hint": "Process Lifecycle", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 16:56:03", "_subject": "Virtualization", "_context_lectures": [2, 4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Context Switching"], "difficulty_estimation": "Easy", "content": {"text": "מהו אחד מהעדכונים המרכזיים שמערכת ההפעלה מבצעת במעבד במהלך \"החלפת הקשר\" (context switch) בין תהליכים, בהקשר של ניהול זיכרון?", "code_snippet": null, "options": ["א. עדכון ערכי ה-Base&Bounds במעבד.", "ב. עדכון קוד התוכנית בזיכרון הראשי.", "ג. שינוי מצב הריצה של המעבד מ-kernel mode ל-user mode עבור התהליך החדש.", "ד. מחיקת כל הנתונים של התהליך הקודם מהזיכרון."]}, "solution": {"correct_option": "א", "explanation": "המנגנון של \"החלפת הקשר\" (context switch) כולל פעולות שונות שמערכת ההפעלה מבצעת כדי להעביר את השליטה מתהליך אחד לאחר. בהקשר של ניהול זיכרון, חומר ההרצאה מציין במפורש כי \"מערכת ההפעלה שומרת ב-pcb עבור כל תהליך את ה-Base&Bounds שלו... ואז ב-context switch כשמתבצעת החלפה בין תהליכים, מערכת ההפעלה מעדכנת את ה-Base&Bounds במעבד\" (Lecture 2, chunk 15). עדכון רגיסטרים אלו במעבד חיוני כדי שה-MMU יוכל לתרגם כתובות וירטואליות לכתובות פיזיות באופן נכון עבור התהליך החדש, ולוודא שהתהליך לא חורג מגבולות הזיכרון שהוקצו לו. פעולה זו מחייבת הרשאות kernel mode."}, "_source_file": "0019__Virtualization__Context_Switching__MC__Easy.json", "_topic_hint": "Context Switching", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 16:56:17", "_subject": "Virtualization", "_context_lectures": [2, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Context Switching"], "difficulty_estimation": "Easy", "content": {"text": "איזה מידע נשמר או נטען באופן טיפוסי במהלך מנגנון ה-Context Switch (החלפת הקשר) בין תהליכים?", "code_snippet": null, "options": ["א. מצב רגיסטרי המעבד (CPU context), מיקומי זיכרון, וקבצים פתוחים.", "ב. רק כתובת ההתחלה של קוד התוכנית (Text segment).", "ג. רק גודל ה-Stack וה-Heap של התהליך.", "ד. רק כתובות ה-Base וה-Bounds של התהליך בזיכרון הפיזי."]}, "solution": {"correct_option": "א", "explanation": "מנגנון ה-Context Switch נועד לשמור את כל המידע הנדרש עבור ריצתו של תהליך אחד, כדי שניתן יהיה לטעון תהליך אחר, ולאחר מכן לחזור ולהמשיך את התהליך שהופסק מאותה נקודה. לפי חומר ההרצאה (chunk 20), מידע זה כולל את מצב רגיסטרי המעבד (CPU context), מיקומי זיכרון (Memory locations), וקבצים פתוחים (Open files) שהתהליך מחזיק."}, "_source_file": "0020__Virtualization__Context_Switching__MC__Easy.json", "_topic_hint": "Context Switching", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 16:56:25", "_subject": "Virtualization", "_context_lectures": [2, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Context Switching"], "difficulty_estimation": "Easy", "content": {"text": "איזו מהאפשרויות הבאות מתארת בצורה הטובה ביותר את מנגנון ה-Context Switch (החלפת הקשר) במערכת הפעלה?", "code_snippet": null, "options": ["א. העברת השליטה הבלעדית מהמעבד לתהליך משתמש יחיד עד לסיומו.", "ב. שמירת מצבו של תהליך רץ, הוצאתו מהמעבד וטעינת מצבו של תהליך אחר כדי שימשיך לרוץ.", "ג. ביצוע קריאות מערכת (system calls) כדי לאפשר גישה לפעולות מורשות (privileged operations).", "ד. עדכון רגיסטרי ה-Base&Bounds במעבד על מנת להגן על מרחב הזיכרון של תהליכים."]}, "solution": {"correct_option": "ב", "explanation": "מנגנון ה-Context Switch, כפי שמתואר בחומר ההרצאה (Chunk 16), הוא התהליך שבו מערכת ההפעלה 'מוציאה' תהליך אחד מהמעבד, שומרת את מצבו (כפי שמפורט ב-Chunk 20, כולל רישומים, מיקומי זיכרון וקבצים פתוחים), ולאחר מכן 'טוענת' תהליך חדש למעבד כדי שימשיך את ריצתו מהנקודה שבה הופסק. אפשרות ב' מתארת במדויק פעולה זו. אפשרות א' מתארת את רעיון ה-Direct Execution שבו תהליך שולט באופן מלא במעבד עד לסיומו, אך לא את מנגנון ההחלפה עצמו. אפשרות ג' מתארת קריאות מערכת, שהן מנגנון למעבר בין User Mode ל-Kernel Mode וביצוע פעולות מורשות (Chunk 24), אך אינן ההגדרה המלאה של Context Switch. אפשרות ד' מתארת פעולה ספציפית שמתרחשת במהלך Context Switch בהקשר של ניהול זיכרון (עדכון Base&Bounds, Chunk 15), אך אינה תיאור כולל של כל המנגנון."}, "_source_file": "0021__Virtualization__Context_Switching__MC__Easy.json", "_topic_hint": "Context Switching", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 16:56:39", "_subject": "Virtualization", "_context_lectures": [2, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Context Switching"], "difficulty_estimation": "Medium", "content": {"text": "מהי אחת הסיבות המרכזיות לכך שמערכת ההפעלה נדרשת לפעול במצב ליבה (kernel mode) במהלך ביצוע החלפת הקשר (context switch) בין תהליכים?", "code_snippet": null, "options": ["א. עדכון רגיסטרי ה-Base וה-Bounds במעבד, המאפשרים ניהול זיכרון תקין עבור התהליך הנכנס.", "ב. כדי לאפשר לתהליך החדש גישה ישירה ובלתי מוגבלת לכל משאבי המערכת באופן מיידי.", "ג. לשמור את מצב הרגיסטרים של המעבד (CPU context) עבור התהליך היוצא בתוך ה-PCB שלו.", "ד. למנוע מהתהליך הנכנס לבצע פעולות בעלות הרשאות גבוהות לפני שקיבל את השליטה המלאה במעבד."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה (Lecture 6, chunk 15), במהלך החלפת הקשר (context switch), מערכת ההפעלה שומרת ב-PCB של כל תהליך את ה-Base וה-Bounds שלו. כאשר מתבצעת החלפה בין תהליכים, מערכת ההפעלה מעדכנת את רגיסטרי ה-Base וה-Bounds במעבד (רגיסטרים אלו קיימים גם במעבד) כדי להגדיר את מרחב הזיכרון של התהליך החדש. עדכון של שני רגיסטרים אלו במעבד מותר אך ורק במצב ליבה (kernel mode), ולכן זוהי סיבה קריטית לכך שמערכת ההפעלה חייבת לפעול במצב זה בעת ביצוע החלפת הקשר."}, "_source_file": "0022__Virtualization__Context_Switching__MC__Medium.json", "_topic_hint": "Context Switching", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 16:56:52", "_subject": "Virtualization", "_context_lectures": [2, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Context Switching"], "difficulty_estimation": "Medium", "content": {"text": "במהלך החלפת הקשר (context switch) בין תהליכים, איזו פעולה קריטית מבצעת מערכת ההפעלה בנוגע לניהול זיכרון, ומדוע פעולה זו דורשת הרשאות מיוחדות?", "code_snippet": null, "options": ["א. מערכת ההפעלה מעדכנת את רגיסטרי ה-Base וה-Bounds במעבד כדי להבטיח את הגנת הזיכרון של התהליך החדש, ופעולה זו מותרת רק ב-kernel mode.", "ב. מערכת ההפעלה שומרת את כל תוכן הזיכרון של התהליך היוצא לקובץ גיבוי, וזה דורש הרשאות מיוחדות כדי לגשת לדיסק.", "ג. מערכת ההפעלה מקצה מקטעי זיכרון חדשים לחלוטין עבור התהליך הנכנס, וזה דורש הרשאות kernel כדי לשנות את מפת הזיכרון.", "ד. מערכת ההפעלה מאפשרת לתהליך המשתמש לעדכן באופן ישיר את רגיסטרי ה-MMU כדי לייעל את ביצועי הגישה לזיכרון."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. במהלך החלפת הקשר (context switch), מערכת ההפעלה מפסיקה את ריצת התהליך הנוכחי, שומרת את מצבו וטוענת תהליך חדש (על פי chunk 16). חלק קריטי מתהליך זה, כפי שמפורט ב-chunk 15, הוא עדכון רגיסטרי ה-Base וה-Bounds במעבד. רגיסטרים אלו חיוניים לניהול הזיכרון ולהבטחת הגנת הזיכרון של התהליך החדש על ידי ה-MMU. עדכון רגיסטרים אלו הוא פעולה מיוחסת (privileged operation) שמותרת רק ב-kernel mode, ולכן רק מערכת ההפעלה יכולה לבצעה. זה מבטיח שאף תהליך משתמש לא יוכל לשנות את גבולות הזיכרון שלו באופן עצמאי ולגשת לזיכרון של תהליכים אחרים או של ה-kernel.\n\nאפשרויות ב' ו-ג' אינן מתארות את הפעולה הקריטית והספציפית ביותר לניהול זיכרון בהקשר של Base&Bounds ו-kernel mode כפי שמתואר בחומר. שמירת כל תוכן הזיכרון לדיסק אינה חלק סטנדרטי מ-context switch רגיל, והקצאת זיכרון חדש לחלוטין אינה תמיד נדרשת (התהליך הנכנס משתמש במקטעי הזיכרון שהוקצו לו כבר). אפשרות ד' שגויה לחלוטין, שכן היא מציעה שתהליך משתמש יכול לעדכן רגיסטרים של ה-MMU, דבר שמנוגד ישירות לדרישת ה-kernel mode עבור פעולות אלו (chunk 15 ו-24)."}, "_source_file": "0023__Virtualization__Context_Switching__MC__Medium.json", "_topic_hint": "Context Switching", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 16:57:07", "_subject": "Virtualization", "_context_lectures": [2, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Context Switching"], "difficulty_estimation": "Medium", "content": {"text": "מהי הסיבה העיקרית לכך שעדכון רגיסטרי ה-Base וה-Bounds במעבד, כחלק ממנגנון ה-Context Switch, חייב להתבצע במצב Kernel Mode?", "code_snippet": null, "options": ["א. כדי למנוע מתהליך משתמש לשנות את גבולות הזיכרון שהוקצו לו ולגשת לזיכרון של תהליכים אחרים או של מערכת ההפעלה.", "ב. מכיוון שרגיסטרי ה-Base וה-Bounds מכילים מידע קריטי לביצוע System Calls, אשר נגיש רק במצב Kernel Mode.", "ג. כי רק במצב Kernel Mode ניתן לבצע גישה ישירה לזיכרון הפיזי של המחשב.", "ד. מפני שעדכון רגיסטרים אלו דורש השהייה של כל התהליכים האחרים במערכת, פעולה שרק ה-Kernel רשאי לבצע."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה (Lecture 6, chunk 15), עדכון רגיסטרי ה-Base וה-Bounds במעבד מותר רק במצב Kernel Mode. הסיבה לכך היא שרגיסטרים אלו משמשים את יחידת ניהול הזיכרון (MMU) כדי לוודא שכל גישה לזיכרון על ידי תהליך המשתמש נמצאת בתוך גבולות הזיכרון שהוקצו לו. אם תהליך משתמש היה יכול לשנות רגיסטרים אלו באופן עצמאי, הוא היה יכול לעקוף את מנגנון הגנת הזיכרון, לגשת לזיכרון של תהליכים אחרים או של מערכת ההפעלה, ובכך לפגוע באבטחת ויציבות המערכת. לכן, פעולה זו היא פעולה מיוחסת (privileged operation) שרק מערכת ההפעלה יכולה לבצע במצב Kernel Mode במהלך Context Switch, כדי להבטיח את הפרדת הזיכרון והגנתו."}, "_source_file": "0024__Virtualization__Context_Switching__MC__Medium.json", "_topic_hint": "Context Switching", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 16:57:22", "_subject": "Virtualization", "_context_lectures": [2, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Context Switching"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על אתגר השליטה במנגנון ה-Context Switch, ובהתחשב בכך שפעולות קריטיות כמו עדכון רגיסטרי ה-Base&Bounds במעבד מותרות רק ב-kernel mode, איזו מסקנה נכונה לגבי אופן ביצוע החלפת הקשר (Context Switch) על ידי מערכת ההפעלה?", "code_snippet": null, "options": ["א. מערכת ההפעלה יכולה לבצע החלפת הקשר גם ב-User Mode, כל עוד התהליך הרץ לא מבקש פעולה מוגנת.", "ב. על מנת לבצע החלפת הקשר, מערכת ההפעלה חייבת תמיד לעלות ל-Kernel Mode, מכיוון שפעולות קריטיות לניהול תהליכים דורשות הרשאות אלו.", "ג. מנגנון ה-Direct Execution מאפשר למערכת ההפעלה להחליף הקשר על ידי \"הקפאת\" התהליך הרץ ישירות, ללא צורך בשינוי מצב ההרשאה.", "ד. החלפת הקשר מתרחשת רק בתגובה לקריאת מערכת יזומה של התהליך הרץ, ובכך מבטיחה מעבר ל-Kernel Mode לצורך הביצוע."]}, "solution": {"correct_option": "ב", "explanation": "מנגנון ה-Context Switch כולל פעולות שדורשות הרשאות גבוהות, כפי שמצוין בחומר ההרצאה. בפרט, עדכון רגיסטרי ה-Base&Bounds במעבד, אשר הכרחי לניהול זיכרון של התהליך החדש שנטען, מותר רק ב-Kernel Mode. מכאן שמערכת ההפעלה חייבת לעלות למצב Kernel Mode על מנת לבצע את תהליך החלפת ההקשר באופן תקין ובטוח, ובכך להתגבר על אתגר השליטה כשהתהליך הרץ שולט באופן מלא במעבד ב-User Mode. אפשרות א' שגויה כי פעולות קריטיות כמו עדכון Base&Bounds דורשות Kernel Mode תמיד. אפשרות ג' שגויה כי מנגנון Direct Execution מעניק שליטה מלאה לתהליך הרץ, ומערכת ההפעלה אינה יכולה 'להקפיא' אותו ללא מעבר הרשאות. אפשרות ד' שגויה מכיוון שהחלפת הקשר אינה מתרחשת 'רק' בתגובה לקריאת מערכת, וקיימים מנגנונים נוספים (כמו פסיקות תזמון) שמאפשרים למערכת ההפעלה להשיג שליטה ולבצע החלפת הקשר."}, "_source_file": "0025__Virtualization__Context_Switching__MC__Hard.json", "_topic_hint": "Context Switching", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 16:57:43", "_subject": "Virtualization", "_context_lectures": [2, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Context Switching"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על אתגרי מנגנון ה-Context Switch, ובפרט אתגר ה\"שליטה\" של מערכת ההפעלה, איזה מההיגדים הבאים מתאר בצורה המדויקת ביותר את הקושי בשיטת \"Direct Execution\" ואת הפתרון החלקי שקריאות מערכת (System Calls) מציעות בהקשר של ביצוע פעולות פריבילגיות כחלק מהחלפת הקשר?", "code_snippet": null, "options": ["א. בשיטת Direct Execution, מערכת ההפעלה מאבדת שליטה מוחלטת על המעבד בזמן ריצת התהליך, מה שמקשה עליה לבצע עדכוני Base&Bounds ברגיסטרי המעבד במהלך החלפת הקשר, שכן פעולה זו דורשת Kernel Mode. קריאות מערכת מאפשרות לתהליך לעבור מרצון ל-Kernel Mode, ובכך להחזיר זמנית את השליטה למערכת ההפעלה כדי לבצע פעולות אלו.", "ב. שיטת Direct Execution מבטיחה ביצועים אופטימליים בכך שהיא מונעת את הצורך ב-Context Switch תכוף, אך היא דורשת מהתהליכים לבצע את כל פעולות הזיכרון בעצמם. קריאות מערכת מאפשרות למערכת ההפעלה לנהל את הזיכרון עבור התהליכים, אך אינן קשורות ישירות לאתגר השליטה בזמן החלפת הקשר.", "ג. אתגר השליטה ב-Direct Execution נובע מכך שמערכת ההפעלה אינה יכולה לשמור את כל הרגיסטרים ומיקומי הזיכרון של תהליך מושהה. קריאות מערכת פותרות זאת על ידי שמירת מצב התהליך באופן אוטומטי ב-PCB לפני כל מעבר ל-Kernel Mode.", "ד. בשיטת Direct Execution, מערכת ההפעלה חייבת להמתין שהתהליך יסיים את ריצתו לחלוטין לפני שהיא יכולה להחליף תהליך. קריאות מערכת מאפשרות לתהליך להודיע למערכת ההפעלה על רצונו לסיים, ובכך לזרז את החלפת הקשר."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה, בשיטת Direct Execution, כשתהליך רץ, הוא שולט באופן מלא במעבד (chunk 20), מה שיוצר את אתגר ה\"שליטה\" עבור מערכת ההפעלה (chunk 16). קושי זה בא לידי ביטוי בכך שמערכת ההפעלה אינה יכולה לבצע פעולות פריבילגיות, כמו עדכון רגיסטרי ה-Base&Bounds במעבד במהלך Context Switch, פעולה אשר חיונית לניהול הזיכרון ודורשת Kernel Mode (chunk 15). קריאות מערכת (System Calls) מהוות מנגנון שבאמצעותו תהליך יכול לעבור מרצון מ-User Mode ל-Kernel Mode, ובכך להחזיר את השליטה למערכת ההפעלה ולאפשר לה לבצע את הפעולות הפריבילגיות הנדרשות, כולל אלו הקשורות להחלפת הקשר ולניהול זיכרון (chunk 24). התשובות האחרות אינן מדויקות: ב' מטעה לגבי הצורך ב-Context Switch וניהול הזיכרון; ג' אינה מתארת נכונה את אתגר השליטה או את תפקיד קריאות המערכת בשמירת ההקשר; ו-ד' מציגה תפקיד שגוי לקריאות מערכת בהקשר של סיום תהליכים ואינה מתייחסת לעיקר אתגר השליטה בפעולות פריבילגיות."}, "_source_file": "0026__Virtualization__Context_Switching__MC__Hard.json", "_topic_hint": "Context Switching", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 16:58:01", "_subject": "Virtualization", "_context_lectures": [2, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Context Switching"], "difficulty_estimation": "Hard", "content": {"text": "בהתחשב באתגר ה\"שליטה\" בהחלפת הקשר (context switch), ובדרישה לפעולות מיוחסות (privileged operations) כמו עדכון רגיסטרי Base&Bounds במהלך החלפה, איזה מנגנון בלעדי המתואר בחומר הלימוד מאפשר למערכת ההפעלה להשיב לעצמה שליטה מתהליך משתמש רץ ולבצע פעולות אלו?", "code_snippet": null, "options": ["א. התהליך מבצע קריאת מערכת (system call), אשר מעלה את הרשאותיו ומעבירה את המעבד למצב ליבה (kernel mode), ובכך מאפשרת למערכת ההפעלה לבצע את הפעולות המיוחסות הנדרשות להחלפת הקשר.", "ב. מערכת ההפעלה מריצה ללא הרף קוד ברקע במקביל לתהליך המשתמש, ובכך שומרת על שליטה רציפה ומבצעת החלפת קשר בכל עת.", "ג. התהליך הרץ מוריד את הרשאותיו באופן יזום למצב משתמש (user mode) כאשר הוא מגיע לסוף יחידת הזמן שהוקצתה לו, מה שמאפשר למערכת ההפעלה להשתלט.", "ד. מנגנון Direct Execution מבטיח שהתהליך ירוץ עד לסיומו המלא, ורק אז מערכת ההפעלה משיבה לעצמה שליטה לביצוע החלפת קשר."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר הלימוד מציין במפורש כי \"כשנהליך רץ, זה אומר שהמעבד מבצע את הפקודות של אותו תהליך, ולכן בזמן זה מערכת ההפעלה לא רצה\" (Lecture 2, chunk 16), מה שמדגיש את אתגר ה\"שליטה\". על מנת שמערכת ההפעלה תוכל לבצע החלפת הקשר, היא זקוקה לשליטה ולפעולות מיוחסות. המנגנון היחיד המתואר בחומר הלימוד שמאפשר לתהליך משתמש לעבור למצב ליבה (kernel mode) הוא קריאת מערכת (system call): \"ברגע שתהליך מבצע קריאת מערכת – ההרשאות שלו עולות. מתבצעת החלפה מ-user mode ל-kernel mode\" (Lecture 2, chunk 24). במצב ליבה, מערכת ההפעלה יכולה לבצע פעולות מיוחסות כמו עדכון רגיסטרי Base&Bounds במעבד, פעולה ש\"מותר רק ב-kernel mode, לכן רק מערכת ההפעלה יכולה לעשות זאת\" (Lecture 6, chunk 15). לכן, קריאת מערכת היא הדרך המתוארת בחומר שבה מערכת ההפעלה משיבה לעצמה שליטה לביצוע פעולות קריטיות בהחלפת הקשר.\n\nאפשרויות ב', ג' ו-ד' אינן נכונות:\n*   אפשרות ב' סותרת ישירות את הכתוב בחומר לפיו מערכת ההפעלה אינה רצה כאשר תהליך משתמש רץ.\n*   אפשרות ג' מתארת מנגנון של הורדת הרשאות יזומה שאינו מוזכר בחומר הלימוד.\n*   אפשרות ד' מתארת את מנגנון ה-Direct Execution שבו התהליך רץ עד לסיום, והוא אינו מתאר כיצד מערכת ההפעלה משיבה שליטה מתהליך רץ על מנת לבצע החלפת קשר במובן הרחב (הכולל קדם-אמפטיה)."}, "_source_file": "0027__Virtualization__Context_Switching__MC__Hard.json", "_topic_hint": "Context Switching", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 16:58:24", "_subject": "Virtualization", "_context_lectures": [2, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["System Calls"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של מנגנון קריאות המערכת (System Calls) במערכת הפעלה, כפי שתואר בחומר ההרצאה?", "code_snippet": null, "options": ["א. לאפשר לתהליכי משתמש לבצע פעולות מיוחסות (privileged operations) באופן בטוח ומבוקר על ידי מערכת ההפעלה.", "ב. להבטיח שתהליכים לעולם לא יוכלו לגשת לזיכרון ה-kernel.", "ג. לשלוח סיגנלים בין תהליכים שונים לצורך תקשורת.", "ד. לאפשר למערכת ההפעלה לוותר על שליטה במעבד לטובת תהליכי משתמש."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, מנגנון קריאות המערכת (System Calls) נועד לפתור את בעיית האבטחה. הוא מאפשר לתהליכי משתמש, הפועלים במצב משתמש (user mode), לבקש שירותים מוגבלים (privileged operations) ממערכת ההפעלה, הפועלת במצב ליבה (kernel mode). הציטוט הרלוונטי הוא: \"המנגנון של ה-system call עוזר לנו להתמודד עם בעיה אחת מבין השתיים שהיו לנו: בעיית האבטחה נפתרה. ברגע שהוספנו שני מצבים למעבד, ונתנו מנגנון של קריאת מערכת, מנענו גישה של תהליכים לרכיבי חומרה, ותהליך לא יכול לבצע מה שהוא רוצה אבל עדיין יש לו את האפשרות לבקש שירותים ממערכת ההפעלה והיא תבצע זאת עבורו בצורה בטוחה.\" לכן, המטרה העיקרית היא לאפשר גישה בטוחה ומבוקרת למשאבי חומרה ולשירותי מערכת שדורשים הרשאות גבוהות."}, "_source_file": "0028__Virtualization__System_Calls__MC__Easy.json", "_topic_hint": "System Calls", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 16:58:37", "_subject": "Virtualization", "_context_lectures": [2, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["System Calls"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של קריאת מערכת (System Call) במערכת הפעלה, כפי שתואר בחומר ההרצאה?", "code_snippet": "```c\n#include <stdio.h>\n#include <fcntl.h> // For open()\n#include <unistd.h> // For close()\n\nint main() {\n    int fd;\n    // The open() function is a library call that typically\n    // makes a system call to the OS kernel to open a file.\n    fd = open(\"example.txt\", O_CREAT | O_WRONLY, 0644);\n    if (fd == -1) {\n        perror(\"Error opening file\");\n        return 1;\n    }\n    printf(\"File opened successfully with file descriptor: %d\\n\", fd);\n    close(fd); // close() also involves a system call\n    return 0;\n}\n```", "options": ["א. לאפשר לתהליכי משתמש לבצע פעולות מורשות (privileged operations) באופן בטוח, תוך העברת שליטה למצב ליבה (kernel mode).", "ב. להעביר הודעות (signals) בין תהליכים שונים לצורך תקשורת.", "ג. לאפשר גישה ישירה של תהליכי משתמש לטבלת התהליכים (process table) של מערכת ההפעלה.", "ד. לוותר על שימוש במעבד ולהחזיר את השליטה למערכת ההפעלה באופן וולונטרי (yield)."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה (Lecture 2, chunk 28 ו-24), המנגנון של קריאת מערכת (System Call) נועד לפתור את בעיית האבטחה ולאפשר לתהליכים במצב משתמש (user mode) לבקש שירותים מרכיבי חומרה או לבצע פעולות מורשות (privileged operations) בצורה בטוחה. כאשר תהליך מבצע קריאת מערכת, ההרשאות שלו עולות ומתבצעת החלפה ממצב משתמש למצב ליבה (kernel mode), מה שמעביר את השליטה לגרעין מערכת ההפעלה כדי שיבצע את הפעולה המבוקשת בצורה מבוקרת ומאובטחת.\n\nאפשרויות אחרות אינן נכונות:\nב. העברת הודעות (signals) בין תהליכים היא מנגנון נפרד, ובעוד שקריאת מערכת יכולה לשמש לשליחת signal, זו אינה המטרה העיקרית של קריאות מערכת באופן כללי (Lecture 5, chunk 9).\nג. חומר ההרצאה מציין במפורש כי לתהליכי משתמש אין גישה ישירה לטבלת התהליכים (process table) של מערכת ההפעלה; גישה זו שמורה ל-kernel בלבד (Lecture 2, chunk 17).\nד. 'yield' היא קריאת מערכת ספציפית שנועדה לוותר על המעבד באופן וולונטרי, אך זוהי מטרה מאוד ספציפית ואינה המטרה העיקרית והכוללת של כלל קריאות המערכת (Lecture 2, chunk 29)."}, "_source_file": "0029__Virtualization__System_Calls__MC__Easy.json", "_topic_hint": "System Calls", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 16:58:53", "_subject": "Virtualization", "_context_lectures": [2, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["System Calls"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של קריאת מערכת (System Call) עבור תהליך במצב משתמש (User Mode)?", "code_snippet": null, "options": ["א. לאפשר לתהליך לגשת ישירות לרכיבי חומרה.", "ב. להעביר את השליטה למערכת ההפעלה כדי לבצע פעולות מיוחסות (privileged operations) בצורה בטוחה.", "ג. לשלוח אותות (signals) לתהליכים אחרים.", "ד. לעדכן את טבלת התהליכים (process table) בקרנל."]}, "solution": {"correct_option": "ב", "explanation": "קריאת מערכת (System Call) היא מנגנון המאפשר לתהליך הרץ במצב משתמש (User Mode) לבקש ממערכת ההפעלה לבצע עבורו פעולות הדורשות הרשאות מיוחדות (privileged operations), כגון גישה לחומרה, ניהול קבצים או הקצאת זיכרון. כפי שצויין בחומר ההרצאה, ברגע שתהליך מבצע קריאת מערכת, מתבצעת החלפה ממצב משתמש למצב קרנל (kernel mode), מה שמאפשר למערכת ההפעלה לבצע את הפעולה בצורה בטוחה ומבוקרת. מנגנון זה פותר את \"בעיית האבטחה\" בכך שהוא מונע מתהליכים גישה ישירה ומסוכנת למשאבי המערכת, תוך מתן אפשרות לבקש שירותים ממערכת ההפעלה שתבצע אותם עבורם בצורה בטוחה."}, "_source_file": "0030__Virtualization__System_Calls__MC__Easy.json", "_topic_hint": "System Calls", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 16:59:07", "_subject": "Virtualization", "_context_lectures": [2, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["System Calls"], "difficulty_estimation": "Medium", "content": {"text": "מדוע תהליכים במערכת הפעלה נדרשים להשתמש בקריאות מערכת (System Calls) על מנת לבצע פעולות כגון גישה לחומרה או הקצאת זיכרון, במקום לבצען באופן ישיר?", "code_snippet": null, "options": ["א. קריאות מערכת מאפשרות למערכת ההפעלה לשמור על שליטה ובטחון, בכך שהן מונעות מתהליכים גישה ישירה לרכיבי חומרה ומאפשרות להם לבקש שירותים בצורה בטוחה.", "ב. קריאות מערכת משמשות בעיקר לשיפור ביצועים על ידי אופטימיזציה של גישה לזיכרון והפחתת מיתוגי הקשר.", "ג. קריאות מערכת הן הדרך היחידה לתקשר עם תהליכים אחרים במערכת, בדומה לאופן שבו Signals עובדים.", "ד. קריאות מערכת נחוצות רק במערכות הפעלה מודרניות, בעוד שבמערכות הפעלה ישנות יותר תהליכים יכלו לגשת לחומרה באופן חופשי."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. לפי חומר ההרצאה (Chunk 28), מנגנון קריאות המערכת (System Calls) נועד לפתור את 'בעיית האבטחה' במערכת ההפעלה. על ידי הוספת שני מצבים למעבד (User Mode ו-Kernel Mode) ומתן מנגנון של קריאת מערכת, נמנעת גישה ישירה של תהליכים לרכיבי חומרה. תהליכים אינם יכולים לבצע פעולות מיוחסות (privileged operations) באופן עצמאי, אך הם יכולים לבקש שירותים אלו ממערכת ההפעלה, והיא תבצע אותם עבורם בצורה בטוחה במצב ה-Kernel (Chunk 24, 28). אופציה ב' אינה נכונה מכיוון ששיפור ביצועים אינו המטרה העיקרית של קריאות מערכת בהקשר זה. אופציה ג' אינה נכונה מכיוון שקריאות מערכת מיועדות לבקשת שירותים ממערכת ההפעלה ולא לתקשורת ישירה בין תהליכים, בניגוד ל-Signals (Chunk 9). אופציה ד' אינה נכונה מכיוון שהצורך בקריאות מערכת נובע משיקולי אבטחה ושליטה בסיסיים, ולא רק ממאפייני מערכות הפעלה מודרניות; הבעיה של שליטה וגישה לחומרה הייתה קיימת גם בעבר, והמנגנון פותר אותה באופן יסודי."}, "_source_file": "0031__Virtualization__System_Calls__MC__Medium.json", "_topic_hint": "System Calls", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 16:59:22", "_subject": "Virtualization", "_context_lectures": [2, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["System Calls"], "difficulty_estimation": "Medium", "content": {"text": "מהו התפקיד העיקרי של קריאת מערכת (system call) במערכת הפעלה, על פי חומר ההרצאה?", "code_snippet": null, "options": ["א. לאפשר לתהליכי משתמש לבצע פעולות מיוחסות (privileged operations) בצורה בטוחה, על ידי העברת שליטה לגרעין (kernel) ושינוי מצב המעבד.", "ב. לספק גישה ישירה ובלעדית לתהליכי משתמש לטבלת התהליכים (process table) בתוך ה-kernel.", "ג. לשמש כמנגנון תקשורת עיקרי בין תהליכים שונים (inter-process communication) באמצעות שליחת סיגנלים (signals).", "ד. לאפשר לתהליך לוותר מרצון על השימוש במעבד ולהחזיר את השליטה למערכת ההפעלה, כפי שהיה נהוג בגישה השיתופית (cooperative approach)."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, התפקיד העיקרי של קריאת מערכת הוא לפתור את \"בעיית האבטחה\" ולמנוע גישה לא מורשית של תהליכים לרכיבי חומרה. קריאת מערכת מאפשרת לתהליכי משתמש לבקש שירותים מיוחסים (privileged operations), כגון גישה לחומרה או הקצאת זיכרון, ממערכת ההפעלה. תהליך המבצע קריאת מערכת מעביר את השליטה למערכת ההפעלה (ה-kernel) ומשנה את מצב המעבד מ-user mode ל-kernel mode, מה שמאפשר ל-kernel לבצע את הפעולה בצורה בטוחה ומבוקרת עבור התהליך. אפשרות ב' אינה נכונה מכיוון שנאמר במפורש כי \"לנו אין גישה לטבלת התהליכים, זה שייך למערכת ההפעלה ורק ל-kernel יש גישה אליה\". אפשרות ג' אינה נכונה מכיוון שסיגנלים הם מנגנון לתקשורת בין תהליכים או הודעות ממערכת ההפעלה לתהליך, בעוד שקריאות מערכת הן מנגנון רחב יותר לבקשת שירותים מיוחסים. אפשרות ד' מתארת שימוש ספציפי ופחות נהוג כיום (קריאת yield בגישה השיתופית), ולא את התפקיד העיקרי והכללי של קריאות מערכת באבטחה ובניהול משאבים."}, "_source_file": "0032__Virtualization__System_Calls__MC__Medium.json", "_topic_hint": "System Calls", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 16:59:36", "_subject": "Virtualization", "_context_lectures": [2, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["System Calls"], "difficulty_estimation": "Medium", "content": {"text": "איזו בעיה עיקרית מנגנון קריאות המערכת (system calls) בא לפתור במערכת הפעלה?", "code_snippet": null, "options": ["א. לפתור את בעיית האבטחה ולאפשר לתהליכי משתמש לבקש שירותים מוגנים (privileged operations) ממערכת ההפעלה בצורה בטוחה.", "ב. להבטיח שמערכת ההפעלה תשמור על שליטה רציפה במעבד כשתהליך משתמש רץ.", "ג. לאפשר תקשורת ישירה ובטוחה בין תהליכי משתמש שונים (IPC).", "ד. לנהל את טבלת התהליכים (process table) בתוך ה-kernel ולאפשר לתהליכי משתמש לגשת אליה."]}, "solution": {"correct_option": "א", "explanation": "מנגנון קריאות המערכת (system calls) נועד בראש ובראשונה לפתור את בעיית האבטחה. על פי חומר ההרצאה, 'בעיית האבטחה נפתרה. ברגע שהוספנו שני מצבים למעבד, ונתנו מנגנון של קריאת מערכת, מנענו גישה של תהליכים לרכיבי חומרה, ותהליך לא יכול לבצע מה שהוא רוצה אבל עדיין יש לו את האפשרות לבקש שירותים ממערכת ההפעלה והיא תבצע זאת עבורו בצורה בטוחה.' (Lecture 2, chunk 28). קריאות מערכת מאפשרות לתהליכי משתמש לבצע פעולות מוגנות (privileged operations) כמו גישה לחומרה או הקצאת זיכרון, בכך שהן מעבירות את השליטה ל-kernel שמבצע את הפעולה עבור התהליך בצורה בטוחה.\n\nאפשרות ב' שגויה מכיוון שחומר ההרצאה מציין במפורש כי בעיית השליטה הרציפה של מערכת ההפעלה במעבד נותרה בעיה נפרדת שקריאות המערכת לא פותרות באופן ישיר: 'נותרה לנו בעיה שנייה – איך מערכת ההפעלה שומרת על שליטה במעבד? ברגע שתהליך רץ, המעבד מריץ אותו פקודה אחרי פקודה ואז מערכת ההפעלה לא רצה ולא יכולה להריץ קוד.' (Lecture 2, chunk 28).\n\nאפשרות ג' שגויה מכיוון שתקשורת בין תהליכים (IPC) מיוחסת בחומר ההרצאה בעיקר ל-signals: 'סיגנלים יכולים גם לשמש לתקשורת: אם תהליך אחד רוצה להודיע משהו לתהליך אחר (לשלוח סיגנל).' (Lecture 5, chunk 9).\n\nאפשרות ד' שגויה מכיוון שלתהליכי משתמש אין גישה ישירה לטבלת התהליכים (process table) והיא מנוהלת על ידי ה-kernel בלבד: 'לנו אין גישה לטבלת התהליכים, זה שייך למערכת ההפעלה ורק ל-kernel יש גישה אליה.' (Lecture 2, chunk 17). קריאות מערכת מאפשרות לבקש שירותים, לא לגשת ישירות או לנהל מבני נתונים פנימיים של ה-kernel."}, "_source_file": "0033__Virtualization__System_Calls__MC__Medium.json", "_topic_hint": "System Calls", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 16:59:51", "_subject": "Virtualization", "_context_lectures": [2, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["System Calls"], "difficulty_estimation": "Hard", "content": {"text": "למרות שקריאות מערכת (system calls) גורמות למעבר ממצב משתמש (user mode) למצב ליבה (kernel mode), ומאפשרות למערכת ההפעלה לבצע פעולות בשם התהליך המבקש, מדוע מנגנון זה לבדו אינו מספק על מנת להבטיח שליטה רציפה של מערכת ההפעלה במעבד?", "code_snippet": null, "options": ["א. קריאות מערכת פותרות את בעיית האבטחה אך אינן מספקות מנגנון למערכת ההפעלה להחזיר לעצמה שליטה יזומה כאשר תהליך רץ ברצף מבלי לבצע קריאת מערכת.", "ב. קריאות מערכת מיועדות רק לגישה לחומרה ואינן קשורות כלל לשמירת שליטה במעבד.", "ג. מעבר למצב ליבה באמצעות קריאת מערכת מוגבל בזמן וחוזר אוטומטית למצב משתמש לאחר פרק זמן קצר.", "ד. תהליכים במצב משתמש יכולים לעקוף קריאות מערכת ולגשת ישירות למשאבי חומרה, ובכך למנוע שליטה של מערכת ההפעלה."]}, "solution": {"correct_option": "א", "explanation": "הסבר: קריאות מערכת אכן מאפשרות למערכת ההפעלה להשיג שליטה באופן זמני ולבצע פעולות מורשות (privileged operations) בצורה בטוחה, ובכך פותרות את בעיית האבטחה. אולם, כפי שמצוין בחומר ההרצאה, \"נותרה לנו בעיה שנייה – איך מערכת ההפעלה שומרת על שליטה במעבד? ברגע שתהליך רץ, המעבד מריץ אותו פקודה אחרי פקודה ואז מערכת ההפעלה לא רצה ולא יכולה להריץ קוד.\" (Lecture 2, chunk 28). כלומר, אם תהליך רץ במצב משתמש ואינו מבצע קריאת מערכת, מערכת ההפעלה אינה מקבלת שליטה בחזרה באופן יזום. גישת ה-Cooperative approach, שבה תהליכים היו אמורים לבצע קריאות מערכת כמו `yield` כדי לוותר על המעבד, נחשבת לבעייתית מכיוון שהיא \"סומכת יותר מדי על התהליכים\" (Lecture 2, chunk 29). לכן, קריאות מערכת לבדן אינן מספקות שליטה רציפה של מערכת ההפעלה. אפשרות ב' שגויה מכיוון שקריאות מערכת קשורות גם לשמירת שליטה (כמו ב-`yield`) וגם לביצוע פעולות אחרות מעבר לגישה ישירה לחומרה (כמו הקצאת זיכרון או פתיחת קובץ). אפשרות ג' שגויה כיוון שאין הגבלת זמן על שהות הליבה במצב ליבה; הליבה חוזרת למצב משתמש רק לאחר שסיימה את פעולתה. אפשרות ד' שגויה לחלוטין, שכן מנגנון קריאות המערכת והמעבר בין מצבים נועד בדיוק למנוע מתהליכים במצב משתמש לגשת ישירות למשאבי חומרה."}, "_source_file": "0034__Virtualization__System_Calls__MC__Hard.json", "_topic_hint": "System Calls", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:00:06", "_subject": "Virtualization", "_context_lectures": [2, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["System Calls"], "difficulty_estimation": "Hard", "content": {"text": "מנגנון קריאות המערכת (System Calls) מהווה בסיס לפעילות מערכות הפעלה מודרניות. בהתבסס על החומר הנלמד, איזה מההיגדים הבאים מתאר בצורה המדויקת ביותר את תרומתו ומגבלתו של מנגנון קריאות המערכת בהקשר של שליטת מערכת ההפעלה במעבד ובאבטחת המערכת?", "code_snippet": null, "options": ["א. קריאות מערכת פותרות את בעיית האבטחה בכך שהן מאפשרות גישה מבוקרת לפעולות פריבילגיות, אך אינן מבטיחות שמערכת ההפעלה תשמור על שליטה במעבד אם תהליך משתמש לא יבצע אותן באופן יזום, כפי שבא לידי ביטוי בגישה השיתופית.", "ב. קריאות מערכת מבטיחות שמערכת ההפעלה תמיד שומרת על שליטה מלאה במעבד על ידי העברת שליטה ל-kernel בכל עת, ובכך פותרות הן את בעיית האבטחה והן את בעיית השליטה.", "ג. קריאות מערכת משמשות בעיקר לתקשורת בין-תהליכית (IPC) באמצעות סיגנלים, וכך מאפשרות למערכת ההפעלה לקטוע תהליכים ולשמר שליטה.", "ד. קריאות מערכת הן מנגנון מיושן ששימש בעיקר במערכות הפעלה שיתופיות, ואינן רלוונטיות עוד לשמירה על אבטחה או שליטה במערכות הפעלה מודרניות."]}, "solution": {"correct_option": "א", "explanation": "החומר הנלמד מציין במפורש כי \"המנגנון של ה-system call עוזר לנו להתמודד עם בעיה אחת מבין השתיים שהיו לנו: בעיית האבטחה נפתרה... נותרה לנו בעיה שנייה – איך מערכת ההפעלה שומרת על שליטה במעבד?\". כלומר, קריאות מערכת פותרות את בעיית האבטחה בכך שהן מאפשרות לתהליכי משתמש לבקש שירותים פריבילגיים מה-kernel בצורה בטוחה (מעבר מ-user mode ל-kernel mode). עם זאת, הן אינן פותרות את בעיית השליטה הבלתי תלויה של מערכת ההפעלה במעבד, שכן תהליך משתמש עלול להיכנס ללולאה אינסופית מבלי לבצע קריאת מערכת, ובכך למנוע מה-OS להריץ קוד משלה. הגישה השיתופית (Cooperative approach), אשר הסתמכה על קריאות מערכת כמו `yield` כדי שתהליכים יוותרו על המעבד, נחשבת ל\"פחות נהוגה כיום\" ובעייתית בדיוק בגלל שהיא \"סומכים יותר מדי על התהליכים\". לכן, קריאות מערכת תורמות לאבטחה אך אינן מבטיחות שליטה מלאה ועצמאית במעבד."}, "_source_file": "0035__Virtualization__System_Calls__MC__Hard.json", "_topic_hint": "System Calls", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:00:21", "_subject": "Virtualization", "_context_lectures": [2, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["System Calls"], "difficulty_estimation": "Hard", "content": {"text": "על פי חומר ההרצאה, מנגנון קריאות המערכת (system calls) פותר את בעיית האבטחה בכך שהוא מאפשר לתהליכי משתמש לבקש שירותים מורשים מהגרעין בצורה בטוחה. עם זאת, נותרה בעיה נוספת בהקשר לשליטה של מערכת ההפעלה על המעבד. איזו מבין הטענות הבאות מתארת בצורה הטובה ביותר את המגבלה המהותית של קריאות מערכת, כשלעצמן, בשמירה על שליטה רציפה של מערכת ההפעלה על המעבד, כפי שנדון בגישה ה\"שיתופית\" (Cooperative approach)?", "code_snippet": null, "options": ["א. קריאות מערכת תלויות ברצונם הטוב של התהליכים לבצע אותן; תהליך שלא יבצע קריאת מערכת לא יחזיר את השליטה לגרעין.", "ב. קריאות מערכת מבוצעות תמיד במצב משתמש (user mode) ולכן אינן יכולות לשנות את הקשר התהליך.", "ג. קריאות מערכת אינן מסוגלות לגשת לטבלת התהליכים (process table) ולכן אינן יכולות לנהל את תזמון המעבד.", "ד. קריאות מערכת מיועדות רק לתקשורת בין תהליכים (IPC) ואינן קשורות לשליטה על המעבד."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר ההרצאה מציין במפורש שמנגנון קריאות המערכת פותר את בעיית האבטחה על ידי העברת השליטה לגרעין (kernel) במצב מורשה (kernel mode) לביצוע פעולות מסוכנות. אולם, ההרצאה מדגישה כי \"נותרה לנו בעיה שנייה – איך מערכת ההפעלה שומרת על שליטה במעבד?\" ומציגה את הגישה ה\"שיתופית\" (Cooperative approach) כדרך התמודדות. בגישה זו, מערכת ההפעלה סומכת על התהליכים שיבצעו קריאות מערכת (כמו קריאת `yield` שנועדה לוותר על המעבד) או שיתרחשו אירועים, כדי להחזיר את השליטה לגרעין. הבעיה המהותית בגישה זו, כפי שצוין בהרצאה, היא ש\"יש סומכים יותר מדי על התהליכים\". אם תהליך מסוים אינו מבצע קריאות מערכת, או אינו מבצע את קריאת ה-`yield`, מערכת ההפעלה מאבדת את השליטה על המעבד ואינה יכולה לתזמן תהליכים אחרים. לכן, קריאות מערכת כשלעצמן אינן מספיקות להבטחת שליטה רציפה ובלתי תלויה של מערכת ההפעלה על המעבד."}, "_source_file": "0036__Virtualization__System_Calls__MC__Hard.json", "_topic_hint": "System Calls", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:00:40", "_subject": "Virtualization", "_context_lectures": [2, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Signals"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של סיגנלים (signals) במערכת הפעלה, כפי שתוארו בחומר הנלמד?", "code_snippet": null, "options": ["א. לאפשר למערכת ההפעלה להודיע אירועים לתהליכים, או לתהליכים לתקשר ביניהם.", "ב. לטפל באופן בלעדי בפסיקות חומרה (hardware interrupts).", "ג. לוודא שתהליכי בן (child processes) תמיד יסיימו את ריצתם לפני תהליכי אב (parent processes).", "ד. למנוע מצב של לולאה אינסופית בתהליכים."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה (Chunk 9 ו-10), סיגנלים מתוארים כ'אירועים של התהליך, הודעות שמערכת ההפעלה רוצה להודיע לתהליך שלנו' וכן ש'סיגנלים יכולים גם לשמש לתקשורת: אם תהליך אחד רוצה להודיע משהו לתהליך אחר (לשלוח סיגנל)'. לכן, האפשרות הנכונה ביותר היא שאותות מאפשרים למערכת ההפעלה להודיע לתהליכים על אירועים, וכן לתהליכים לתקשר ביניהם."}, "_source_file": "0037__Virtualization__Signals__MC__Easy.json", "_topic_hint": "Signals", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:00:50", "_subject": "Virtualization", "_context_lectures": [4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Signals"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של סיגנלים (Signals) בהקשר של תהליכים במערכת הפעלה?", "code_snippet": null, "options": ["א. לאפשר למערכת ההפעלה להודיע אירועים לתהליכים, או לתהליכים לתקשר ביניהם.", "ב. לנהל את הקצאת הזיכרון בין תהליכים שונים.", "ג. לאפשר לתהליכים לעצור את ביצועם ולעבור למצב המתנה (waiting) באופן יזום בלבד.", "ד. לאבטח את המערכת מפני גישה לא מורשית לקבצים."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה (Chunk 9), סיגנלים מוגדרים כ'אירועים של התהליך, הודעות שמערכת ההפעלה רוצה להודיע לתהליך שלנו'. בנוסף, נכתב ש'סיגנלים יכולים גם לשמש לתקשורת: אם תהליך אחד רוצה להודיע משהו לתהליך אחר (לשלוח סיגנל)'. לכן, המטרה העיקרית של סיגנלים היא להודיע על אירועים לתהליכים ולשמש לתקשורת ביניהם."}, "_source_file": "0038__Virtualization__Signals__MC__Easy.json", "_topic_hint": "Signals", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:01:00", "_subject": "Virtualization", "_context_lectures": [4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Signals"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, מהם סיגנלים (signals) בהקשר של תהליכים במערכת הפעלה?", "code_snippet": null, "options": ["א. אירועים או הודעות שמערכת ההפעלה שולחת לתהליך, או שתהליך אחד שולח לתהליך אחר.", "ב. מנגנון המאפשר לתהליכים לבצע קריאות מערכת (system calls) באופן אסינכרוני.", "ג. סוג מיוחד של תהליכים קלים (lightweight processes) המשמשים לטיפול בפסיקות חומרה.", "ד. חלק מטבלת דפי הזיכרון (page table) של התהליך המשמש לניהול זיכרון וירטואלי."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מגדיר במפורש סיגנלים כ'אירועים של התהליך, הודעות שמערכת ההפעלה רוצה להודיע לתהליך שלנו'. הוא מוסיף ש'סיגנלים יכולים גם לשמש לתקשורת: אם תהליך אחד רוצה להודיע משהו לתהליך אחר (לשלוח סיגנל)'. לכן, אפשרות א' מתארת במדויק את תפקידם ומהותם של הסיגנלים כפי שהוצגו. אפשרויות ב', ג' ו-ד' מתארות מושגים שאינם תואמים את הגדרת הסיגנלים בחומר ההרצאה."}, "_source_file": "0039__Virtualization__Signals__MC__Easy.json", "_topic_hint": "Signals", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:01:15", "_subject": "Virtualization", "_context_lectures": [4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Signals"], "difficulty_estimation": "Medium", "content": {"text": "בהתייחס לטיפול בסיגנלים, אילו מהאפשרויות הבאות מתארת נכונה דרכים למנוע יצירת תהליכי זומבי (zombie processes) באמצעות הסיגנל SIGCHLD?", "code_snippet": "void signal_handler(int signal) {\n    if (signal == SIGCHLD) {\n        int rc = wait(NULL);\n        printf(\"child terminated %d (pid:%d)\\n\", rc, getpid());\n    }\n}\n\nint main(int argc, char *argv[])\n{\n    struct sigaction act;\n    sigemptyset(&act.sa_mask);\n    act.sa_handler = signal_handler;\n    act.sa_flags = 0;\n    \n    sigaction(SIGCHLD, &act, NULL);\n    if (fork()) {\n        while (1);\n    }\n}", "options": ["א. על ידי הגדרת פונקציית מטפל (signal handler) לסיגנל SIGCHLD המבצעת קריאה ל-wait(), או על ידי התעלמות מוחלטת מהסיגנל באמצעות SIG_IGN.", "ב. רק על ידי הגדרת פונקציית מטפל לסיגנל SIGCHLD המבצעת קריאה ל-wait().", "ג. רק על ידי התעלמות מוחלטת מהסיגנל SIGCHLD באמצעות SIG_IGN.", "ד. על ידי שליחת סיגנל SIGKILL לתהליך הבן מיד לאחר יצירתו."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מתאר שתי דרכים עיקריות למנוע יצירת תהליכי זומבי (zombie processes) באמצעות הסיגנל SIGCHLD. הדרך הראשונה היא להגדיר פונקציית מטפל (signal handler) עבור הסיגנל SIGCHLD, שבתוכה מתבצעת קריאה לפונקציית המערכת wait(). קריאה זו גורמת למערכת ההפעלה לאסוף את משאבי התהליך הבן שסיים את ריצתו ולמחוק אותו, כפי שמודגם בקוד המצורף. הדרך השנייה, כפי שצוין בחומר, היא להתעלם מוחלטת מהסיגנל SIGCHLD על ידי הגדרתו ל-SIG_IGN. במקרה זה, מערכת ההפעלה מנקה את התהליך הבן מיד עם סיומו, מבלי להודיע לתהליך האב, ובכך מונעת יצירת זומבים. לכן, תשובה א' היא הנכונה שכן היא כוללת את שתי השיטות הללו. תשובות ב' ו-ג' שגויות מכיוון שהן מציגות רק אחת מהשיטות כבלעדית. תשובה ד' אינה רלוונטית למניעת זומבים באמצעות טיפול ב-SIGCHLD, ואינה מתוארת בחומר כדרך למנוע זומבים בהקשר זה."}, "_source_file": "0040__Virtualization__Signals__MC__Medium.json", "_topic_hint": "Signals", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:01:31", "_subject": "Virtualization", "_context_lectures": [4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Signals"], "difficulty_estimation": "Medium", "content": {"text": "מהי ההקבלה התיאורטית המרכזית של סיגנלים (signals) במערכת ההפעלה, וכיצד הם משמשים לניהול תהליכים, על פי החומר הנלמד?", "code_snippet": null, "options": ["א. סיגנלים הם מנגנון המאפשר למערכת ההפעלה להודיע לתהליכים על אירועים שונים, בדומה לאופן שבו פסיקות (interrupts) מטפלות באירועים ברמת המערכת, ומאפשרים לכל תהליך להגדיר דרכי טיפול מותאמות אישית לאירועים אלו.", "ב. סיגנלים משמשים בעיקר לתקשורת בין-תהליכית (IPC) בלבד, ומאפשרים לתהליכים להחליף נתונים ביניהם בצורה מסונכרנת.", "ג. המטרה העיקרית של סיגנלים היא למנוע מצבי מרוץ (race conditions) בין תהליכים, על ידי נעילה אוטומטית של משאבים משותפים.", "ד. סיגנלים מיועדים לטפל בגישה לא חוקית לזיכרון על ידי תהליכים, ומפעילים שגרות טיפול ייעודיות בתוך הליבה."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. החומר המצוין בהרצאה קובע במפורש כי \"אם נגיד שפסיקה זה כמו אירועים במערכת ההפעלה, אז signals זה אותו דבר עבור תהליכים.\" זה מדגיש את ההקבלה התיאורטית המרכזית בין פסיקות (interrupts), שהן אירועים ברמת המערכת, לבין סיגנלים, שהם אירועים ברמת התהליך. בנוסף, נכתב שלכל תהליך יש \"מעין טבלת אירועים כזו, של משהו שנקרא signal, ולכל אירוע יש קטע קוד שמטפל בו,\" וכי \"אנחנו יכולים להשפיע על הטבלה הזו.\" זה תומך בכך שתהליכים יכולים להגדיר דרכי טיפול מותאמות אישית לאירועים אלו.\nאפשרויות ב', ג' וד' אינן נכונות:\nב. למרות שסיגנלים יכולים לשמש לתקשורת בין-תהליכית (\"סיגנלים יכולים גם לשמש לתקשורת\"), זו אינה מטרתם התיאורטית העיקרית והבלעדית, וההסבר מתעלם מההקבלה לפסיקות.\nג. החומר לא מזכיר כלל את תפקידם של סיגנלים במניעת מצבי מרוץ או נעילת משאבים.\nד. \"גישה לזיכרון לא תקין\" מוזכרת בהקשר של פסיקות המטופלות על ידי מערכת ההפעלה, ולא כשימוש ישיר של סיגנלים המיועדים לטיפול בתוך הליבה עבור תהליכים. סיגנלים הם אירועים ברמת התהליך."}, "_source_file": "0041__Virtualization__Signals__MC__Medium.json", "_topic_hint": "Signals", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:01:48", "_subject": "Virtualization", "_context_lectures": [4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Signals"], "difficulty_estimation": "Medium", "content": {"text": "על פי חומר ההרצאה, מהו תפקידו העיקרי של האות SIGCHLD ושל פונקציית הטיפול (signal handler) בו במניעת תהליכי זומבי?", "code_snippet": "void signal_handler(int signal) {\n    if (signal == SIGCHLD) {\n        int rc = wait(NULL);\n        printf(\"child terminated %d (pid:%d)\\n\", rc, getpid());\n    }\n}\n\nint main(int argc, char *argv[])\n{\n    struct sigaction act;\n    sigemptyset(&act.sa_mask);\n    act.sa_handler = signal_handler;\n    act.sa_flags = 0;\n    \n    sigaction(SIGCHLD, &act, NULL);\n    if (fork()) {\n        while (1);\n    }\n}", "options": ["א. האות SIGCHLD נשלח לתהליך האב כאשר תהליך בן מסיים את ריצתו, ופונקציית הטיפול בו קוראת ל-wait כדי לאסוף את משאבי הבן.", "ב. האות SIGCHLD מורה לתהליך האב להתעלם מסיום ריצת הבן, ובכך מונע היווצרות זומבים באופן אוטומטי ללא צורך בקריאה ל-wait.", "ג. האות SIGCHLD מאפשר לתהליך האב לבטל את תהליך הבן לפני סיומו, ובכך למנוע מצב של זומבי.", "ד. האות SIGCHLD מציין מצב שבו תהליך הבן נכנס ללולאה אינסופית, ופונקציית הטיפול בו מנסה להרוג את הבן."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה, כאשר תהליך בן מסיים את ריצתו, מערכת ההפעלה שולחת אות SIGCHLD לתהליך האב. אם תהליך האב הגדיר פונקציית טיפול (signal handler) עבור אות זה, פונקציה זו תופעל. בתוך פונקציית הטיפול, קריאה לפונקציית המערכת wait (כמו wait(NULL) בדוגמת הקוד) מאפשרת לאסוף את משאבי התהליך הבן שהסתיים, ובכך למנוע את הפיכתו לתהליך זומבי. אפשרות ב' מתארת דרך אחרת למנוע זומבים, על ידי הגדרת התעלמות מהאות (SIG_IGN), שבמקרה כזה מערכת ההפעלה מפנה את משאבי הבן באופן אוטומטי מבלי שהאב יצטרך לקרוא ל-wait. אפשרויות ג' ו-ד' אינן מתארות נכונה את תפקיד ה-SIGCHLD."}, "_source_file": "0042__Virtualization__Signals__MC__Medium.json", "_topic_hint": "Signals", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:02:01", "_subject": "Virtualization", "_context_lectures": [4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Signals"], "difficulty_estimation": "Hard", "content": {"text": "תהליך אב יוצר תהליך בן. מהי ההבחנה התיאורטית המרכזית בין הגדרת הטיפול באות SIGCHLD של תהליך האב ל-SIG_IGN (התעלמות מוחלטת) לבין הגדרת פונקציית מטפל מותאמת אישית (custom handler) שקוראת ל-wait()?", "code_snippet": "void signal_handler(int signal) {\n    if (signal == SIGCHLD) {\n        int rc = wait(NULL);\n        printf(\"child terminated %d (pid:%d)\\n\", rc, getpid());\n    }\n}\n\nint main(int argc, char *argv[])\n{\n    struct sigaction act;\n    sigemptyset(&act.sa_mask);\n    act.sa_handler = signal_handler;\n    act.sa_flags = 0;\n    \n    sigaction(SIGCHLD, &act, NULL);\n    if (fork()) {\n        while (1);\n    }\n}", "options": ["א. בשני המקרים, מערכת ההפעלה מונעת היווצרות תהליכי זומבי, אך רק במקרה של SIG_IGN האב לא מקבל הודעה על סיום הבן.", "ב. במקרה של SIG_IGN, מערכת ההפעלה מונעת זומבים באופן אוטומטי, בעוד שבמקרה של מטפל מותאם אישית, תהליך הזומבי נוצר אך נמחק מיד על ידי קריאת wait().", "ג. במקרה של SIG_IGN, מערכת ההפעלה תמיד תיצור תהליך זומבי כדי להבטיח שהאב יוכל לבדוק את סטטוס הסיום של הבן מאוחר יותר, בעוד שמטפל מותאם אישית מונע זאת.", "ד. ההבדל העיקרי הוא ש-SIG_IGN מאפשר לאב להמשיך לפעול ללא הפרעה, בעוד שמטפל מותאם אישית גורם להשהיה קצרה של האב בזמן ביצוע ה-wait()."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה, בשני המקרים – בין אם תהליך האב מתעלם מסיגנל SIGCHLD באמצעות SIG_IGN, ובין אם הוא מטפל בו באמצעות פונקציית מטפל מותאמת אישית שקוראת ל-wait() – מערכת ההפעלה תדאג למנוע יצירת תהליכי זומבי. ההבדל המהותי והמפורש בחומר ההרצאה הוא שרק במקרה של התעלמות מוחלטת (SIG_IGN), מערכת ההפעלה לא תשלח הודעה לתהליך האב על סיום תהליך הבן, אלא תפנה את משאביו באופן מיידי ושקט. לעומת זאת, כאשר מוגדר מטפל מותאם אישית, הסיגנל נשלח, פונקציית המטפל מופעלת, וקריאת ה-wait() שבתוכה היא זו שמבצעת את ניקוי המשאבים של הבן. האפשרויות האחרות אינן מדויקות: אפשרות ב' אינה מתארת את ההבדל המהותי בנוגע להיווצרות זומבים (החומר מציין ש-SIG_IGN מונע יצירתם מלכתחילה); אפשרות ג' סותרת ישירות את החומר הקובע ש-SIG_IGN מונע זומבים; ואפשרות ד' מתארת תוצאת לוואי ולא את ההבחנה התיאורטית המרכזית בנוגע למנגנון מניעת זומבים והודעות."}, "_source_file": "0043__Virtualization__Signals__MC__Hard.json", "_topic_hint": "Signals", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:02:23", "_subject": "Virtualization", "_context_lectures": [4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Signals"], "difficulty_estimation": "Hard", "content": {"text": "מהי ההבחנה המהותית בין טיפול בסיגנל SIGCHLD באמצעות פונקציית מטפל המבצעת קריאה ל-wait(), לבין הגדרת הטיפול ב-SIGCHLD להתעלמות מוחלטת (באמצעות SIG_IGN)?", "code_snippet": "// signal2.c\nvoid signal_handler(int signal) {\n    if (signal == SIGCHLD) {\n        int rc = wait(NULL);\n        printf(\"child terminated %d (pid:%d)\\n\", rc, getpid());\n    }\n}\n\nint main(int argc, char *argv[])\n{\n    struct sigaction act;\n    sigemptyset(&act.sa_mask);\n    act.sa_handler = signal_handler;\n    act.sa_flags = 0;\n    \n    sigaction(SIGCHLD, &act, NULL);\n    if (fork()) {\n        while (1);\n    }\n}", "options": ["א. בשני המקרים מובטח כי תהליכי זומבי לא ייווצרו, אך רק בשיטת ההתעלמות המוחלטת מערכת ההפעלה מפנה את משאבי תהליך הבן באופן מיידי וללא צורך בהתערבות יזומה של תהליך האב.", "ב. טיפול באמצעות פונקציית מטפל מאפשר לתהליך האב לבצע פעולות נוספות (כמו רישום לוגים או עיבוד נתונים) בתגובה לסיום תהליך הבן, בעוד שבהתעלמות מוחלטת פעולה כזו אינה אפשרית.", "ג. רק שימוש בפונקציית מטפל המבצעת wait() מבטיח ניקוי נכון של משאבי תהליך הבן; התעלמות מוחלטת עלולה להוביל לדליפת משאבים.", "ד. ההבדל העיקרי הוא בביצועים: טיפול באמצעות פונקציית מטפל הוא יקר יותר מבחינת משאבי מערכת מאשר התעלמות מוחלטת."]}, "solution": {"correct_option": "א", "explanation": "ההבדל המהותי טמון באופן שבו מערכת ההפעלה מטפלת בסיום תהליך הבן ובמשאביו. כאשר SIGCHLD מוגדר להתעלמות מוחלטת (SIG_IGN), החומר הלימודי מציין במפורש: \"אך ורק במקרה כזה של התעלמות מסיגנל sigchld, מערכת ההפעלה לא תיוצר זומבים. כלומר, היא מיד תפנה אותו ורק לא תודיע לו, כי הוא רואה שאנחנו מתעלמים מ-sigchld.\" משמעות הדבר היא שמערכת ההפעלה מבצעת ניקוי מיידי של משאבי תהליך הבן ללא שליחת הסיגנל לתהליך האב וללא צורך שהאב יקרא ל-wait(). לעומת זאת, כאשר מוגדרת פונקציית מטפל המבצעת קריאה ל-wait(), מערכת ההפעלה אכן שולחת את הסיגנל SIGCHLD לתהליך האב (כלומר, מודיעה לו), ופונקציית המטפל של האב היא זו שמבצעת את הקריאה ל-wait() כדי לאסוף את משאבי הבן ולמנוע זומבי. לכן, רק במקרה של התעלמות מוחלטת, מערכת ההפעלה מבצעת את הניקוי באופן עצמאי ומיידי, ללא מעורבות או התראה לתהליך האב. אפשרות ב' מתארת תוצאה או יכולת הנגזרת מההבדל המהותי (היכולת לבצע פעולות נוספות בזכות קבלת הסיגנל), אך אפשרות א' מתארת את המנגנון הבסיסי השונה בין שתי הגישות."}, "_source_file": "0044__Virtualization__Signals__MC__Hard.json", "_topic_hint": "Signals", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:02:50", "_subject": "Virtualization", "_context_lectures": [4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Signals"], "difficulty_estimation": "Hard", "content": {"text": "בהתייחס לטיפול בסיגנל SIGCHLD למניעת תהליכי זומבי, כפי שתואר בחומר הקורס, מהי הטענה הנכונה ביותר לגבי ההבדל המהותי בין הגדרת הטיפול ב-SIGCHLD כ-SIG_IGN לבין שימוש בפונקציית טיפול (signal handler) ייעודית המבצעת קריאה ל-`wait()`?", "code_snippet": "void signal_handler(int signal) {\n    if (signal == SIGCHLD) {\n        int rc = wait(NULL);\n        printf(\"child terminated %d (pid:%d)\\n\", rc, getpid());\n    }\n}\n\nint main(int argc, char *argv[])\n{\n    struct sigaction act;\n    sigemptyset(&act.sa_mask);\n    act.sa_handler = signal_handler;\n    act.sa_flags = 0;\n    \n    sigaction(SIGCHLD, &act, NULL); // Setting a custom handler\n    if (fork()) {\n        while (1);\n    }\n    // Contrast this with: sigaction(SIGCHLD, &(struct sigaction){.sa_handler = SIG_IGN, .sa_flags = 0}, NULL); \n}", "options": ["א. כאשר SIGCHLD מוגדר כ-SIG_IGN, מערכת ההפעלה מבצעת את איסוף המשאבים של תהליך הבן באופן אוטומטי ואינה שולחת את הסיגנל לתהליך האב כלל, בעוד שעם handler, תהליך האב מקבל את הסיגנל ואחראי לקרוא ל-`wait()`.", "ב. בשני המקרים, תהליך האב מקבל את הסיגנל SIGCHLD, אך רק במקרה של SIG_IGN מערכת ההפעלה מונעת מצב זומבי באופן אוטומטי ללא צורך בקריאה ל-`wait()`.", "ג. השימוש ב-SIG_IGN מונע מצב זומבי ביעילות רבה יותר מכיוון שהוא מאפשר לתהליך האב להמשיך בפעילותו ללא הפרעה, בניגוד ל-handler הדורש הקפצה של הקשר (context switch) לביצוע.", "ד. ההבדל העיקרי הוא ש-SIG_IGN מאפשר לתהליך האב לשלוח סיגנלים נוספים לתהליך הבן גם לאחר סיומו, בעוד ש-handler מונע זאת."]}, "solution": {"correct_option": "א", "explanation": "האפשרות הנכונה היא א'. חומר הקורס מציין במפורש: \"אך ורק במקרה כזה של התעלמות מסיגנל sigchld, מערכת ההפעלה לא תיוצר זומבים. כלומר, היא מיד תפנה אותו ורק לא תודיע לו, כי הוא רואה שאנחנו מתעלמים מ-sigchld.\" \nמשמעות הדבר היא שכאשר SIGCHLD מוגדר כ-SIG_IGN, מערכת ההפעלה מטפלת באיסוף משאבי תהליך הבן באופן אוטומטי לחלוטין ואינה שולחת את הסיגנל לתהליך האב כלל (כלומר, האב אינו מקבל התראה). לעומת זאת, כאשר מוגדרת פונקציית טיפול (handler) עבור SIGCHLD, מערכת ההפעלה אכן שולחת את הסיגנל לתהליך האב, והאב נדרש לבצע קריאה ל-`wait()` בתוך ה-handler כדי לאסוף את משאבי הבן ולמנוע מצב זומבי.\nאפשרות ב' שגויה מכיוון שהיא טוענת שבשני המקרים האב מקבל את הסיגנל, בניגוד למצוין בחומר לגבי SIG_IGN.\nאפשרות ג' עשויה להכיל היבטים של יעילות, אך אינה מתארת את ההבדל המהותי כפי שהודגש בחומר, וההסבר על \"הקפצת הקשר\" אינו מפורט במובן זה בחומר הקורס.\nאפשרות ד' שגויה לחלוטין מכיוון שלא ניתן לשלוח סיגנלים לתהליך שסיים את פעולתו."}, "_source_file": "0045__Virtualization__Signals__MC__Hard.json", "_topic_hint": "Signals", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:03:15", "_subject": "Virtualization", "_context_lectures": [4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["CPU Scheduling"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, מהו הפתרון המוצע לניצול יעיל יותר של המעבד במצב שבו תהליך מבצע פעולות קלט/פלט וגורם לזמן מעבד מבוזבז?", "code_snippet": null, "options": ["א. פירוק התהליך למספר \"ג'ובים\" קטנים ועצמאיים, המאפשר חפיפה בביצוע עם תהליכים אחרים.", "ב. הגדלת העדיפות של תהליכים עתירי קלט/פלט על מנת שיסיימו מהר יותר.", "ג. שימוש באלגוריתם תזמון מסוג Round Robin עם חלון זמן קצר מאוד.", "ד. הקצאת מעבד ייעודי לטיפול בפעולות קלט/פלט בלבד."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה (Lecture 3, chunk 16) מתאר מצב בו זמן מעבד מבוזבז כאשר תהליך ממתין לפעולות קלט/פלט. הפתרון המוצע לבעיה זו הוא לשנות את ההתייחסות לתהליך אחד ארוך. במקום זאת, מפרקים את התהליך למספר \"ג'ובים\" קטנים יותר, שכל אחד מהם מייצג מקטע עבודה קצר (לדוגמה, תהליך A באורך 30 מילישניות עם I/O כל 10 מילישניות מפורק ל-3 ג'ובים של 10 מילישניות: A1, A2, A3). גישה זו מאפשרת למתזמן (כדוגמת SRTF המוזכרת בהרצאה) לבצע \"חפיפה\" (overlap) יעילה יותר בין ג'ובים שונים, כלומר, להריץ תהליך אחר (כמו B בדוגמה) בזמן שאחד מהג'ובים הקטנים של התהליך המקורי ממתין לקלט/פלט, ובכך לנצל טוב יותר את זמן המעבד."}, "_source_file": "0046__Virtualization__CPU_Scheduling__MC__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:03:25", "_subject": "Virtualization", "_context_lectures": [8, 2, 3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["CPU Scheduling"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, מהו הפתרון המוצע לבעיית בזבוז זמן מעבד הנגרמת כאשר תהליך מבצע פעולות קלט/פלט תקופתיות?", "code_snippet": null, "options": ["א. פיצול התהליך למספר תתי-ג'ובים קצרים יותר, המאפשרים למתזמן לבצע חפיפה (overlap) עם תהליכים אחרים בזמן ההמתנה לקלט/פלט.", "ב. שימוש באלגוריתם תזמון מסוג SRTF בלבד, ללא כל שינוי במבנה התהליכים.", "ג. הגדלת ה-Quantum (פרוסת הזמן) של המעבד כדי למזער את מספר החלפות ההקשר (context switches).", "ד. מתן עדיפות גבוהה יותר לתהליכי קלט/פלט על מנת שיסיימו את פעולותיהם מהר יותר."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מתאר כי הבעיה של בזבוז זמן מעבד כאשר תהליך מבצע פעולות קלט/פלט תקופתיות נפתרת על ידי שינוי ההתייחסות לתהליך. במקום להתייחס אליו כאל ג'וב אחד ארוך, הוא מפוצל למספר תתי-ג'ובים קצרים יותר. גישה זו מאפשרת למתזמן (לדוגמה, SRTF) לבצע חפיפה (overlap) ולתזמן תהליכים אחרים לרוץ בזמנים שבהם התהליך המקורי ממתין לפעולות הקלט/פלט שלו, ובכך מנוצל זמן המעבד בצורה יעילה יותר. האפשרויות האחרות אינן הפתרון הספציפי שהוצג בחומר ההרצאה לבעיה זו."}, "_source_file": "0047__Virtualization__CPU_Scheduling__MC__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:03:37", "_subject": "Virtualization", "_context_lectures": [8, 2, 3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["CPU Scheduling"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, מהי הגישה המוצעת לשיפור ניצול המעבד במצב שבו תהליך מבצע פעולות קלט/פלט וגורם לזמן מעבד מבוזבז?", "code_snippet": null, "options": ["א. לפרק את התהליך למספר \"תת-ג'ובים\" עצמאיים המגיעים בזמנים שונים, ובכך לאפשר חפיפה בתזמון.", "ב. להשתמש תמיד באלגוריתם תזמון מסוג SRTF, ללא קשר למאפייני התהליכים.", "ג. להגדיל את חלון הזמן (time slice) עבור תהליכים המבצעים פעולות קלט/פלט.", "ד. להקפיא את התהליך הממתין לפעולת קלט/פלט ולהעביר את השליטה המלאה במעבד למערכת ההפעלה באופן בלעדי."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה (chunk 16) מתאר את הבעיה של ניצול מעבד מבוזבז כאשר תהליך ממתין לפעולות קלט/פלט. הפתרון המוצע הוא \"שינוי פשוט בנתונים שלנו\": במקום להתייחס לתהליך אחד ארוך, יש לפרק אותו למספר ג'ובים קצרים יותר (לדוגמה, תהליך A באורך 30 מילישניות עם I/O כל 10 מילישניות יפורק ל-3 ג'ובים בני 10 מילישניות כל אחד). גישה זו מאפשרת למתזמן לבצע חפיפה יעילה יותר בין ג'ובים, ובכך לנצל את זמן המעבד שבו התהליך המקורי היה ממתין לפעולות קלט/פלט, כפי שמודגם בתרשים: CPU: A1 B A2 B A3 B. תשובה ב' אינה נכונה מכיוון שהשימוש ב-SRTF מוזכר כדוגמה למתזמן שניתן להשתמש בו עם הגישה החדשה, אך לא כפתרון העיקרי או הבלעדי לבעיה זו. תשובות ג' ו-ד' אינן מוזכרות כפתרונות לבעיה זו בחומר ההרצאה הנתון."}, "_source_file": "0048__Virtualization__CPU_Scheduling__MC__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:03:52", "_subject": "Virtualization", "_context_lectures": [8, 2, 3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["CPU Scheduling"], "difficulty_estimation": "Medium", "content": {"text": "לפי חומר ההרצאה, מהי המטרה העיקרית של פירוק ג'וב המבצע פעולות קלט/פלט למספר ג'ובים קטנים יותר (תת-ג'ובים) בהקשר של תזמון מעבד?", "code_snippet": null, "options": ["א. לאפשר חפיפה יעילה יותר (overlap) בין חלקי הג'וב לבין ג'ובים אחרים, ובכך להפחית את זמן הסרק של המעבד ולשפר את ניצולו.", "ב. להפחית את כמות ה-context switches הנדרשים במהלך ריצת הג'וב המקורי.", "ג. לפשט את לוגיקת המתזמן (scheduler) ולהימנע מטיפול מורכב בפעולות קלט/פלט.", "ד. לאפשר למתזמן (SRTF) לזהות בקלות רבה יותר את זמן הריצה הכולל של הג'וב המקורי."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מתאר מצב שבו ג'וב (A) מבצע פעולות קלט/פלט, מה שמוביל לזמן סרק של המעבד אף על פי שקיימים ג'ובים אחרים (B) שיכולים לרוץ. הפתרון המוצג הוא לשנות את ההתייחסות לג'וב A: במקום להתייחס אליו כג'וב אחד ארוך שכולל המתנות ל-I/O, מפרקים אותו למספר תת-ג'ובים קצרים יותר (לדוגמה, A1, A2, A3 שכל אחד אורך 10 מילישניות). על ידי כך, המתזמן יכול לבצע חפיפה (overlap) בין תת-ג'ובים אלו לבין ג'ובים אחרים (כמו B), ובכך למלא את חלונות הזמן שבהם A ממתין לפעולות קלט/פלט. פעולה זו מפחיתה באופן משמעותי את זמן הסרק של המעבד ומשפרת את ניצולו הכולל, כפי שמודגם בתרשים: CPU: A1 B A2 B A3 B. לכן, המטרה העיקרית היא לאפשר חפיפה יעילה יותר ולשפר את ניצול המעבד."}, "_source_file": "0049__Virtualization__CPU_Scheduling__MC__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:04:07", "_subject": "Virtualization", "_context_lectures": [8, 2, 3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["CPU Scheduling"], "difficulty_estimation": "Medium", "content": {"text": "לפי חומר ההרצאה, איזו בעיה מרכזית בתזמון מעבדים נפתרת על ידי פירוק ג'וב בודד (הכולל פעולות קלט/פלט) למספר תת-ג'ובים קטנים יותר, ושימוש במתזמן כמו SRTF?", "code_snippet": null, "options": ["א. זה מאפשר למתזמן למלא חלונות זמן מבוזבזים (wasted CPU time) שנוצרו עקב המתנה של ג'וב לפעולות קלט/פלט, ובכך להגדיל את ניצול המעבד.", "ב. זה מבטיח הוגנות טובה יותר בין ג'ובים שונים ומונע מצב של הרעבה (starvation) עבור ג'ובים קצרים.", "ג. זה מקטין את כמות ה-context switches הנדרשים ומפחית את התקורה (overhead) של מערכת ההפעלה.", "ד. זה מפשט את לוגיקת המתזמן ומאפשר לו לקבל החלטות מהירות יותר ללא צורך בידע מוקדם על זמני I/O."]}, "solution": {"correct_option": "א", "explanation": "החומר מתאר מצב שבו ג'וב (A) ממתין לפעולות קלט/פלט, מה שיוצר חלונות זמן מבוזבזים במעבד שאינם מנוצלים, גם אם יש ג'ובים אחרים (B) שמוכנים לרוץ. הפתרון המוצע הוא לשנות את ההתייחסות לג'וב A, ולפרק אותו למספר תת-ג'ובים קצרים יותר (לדוגמה, A1, A2, A3, כל אחד באורך 10ms, במקום ג'וב אחד באורך 30ms עם הפסקות I/O). גישה זו מאפשרת למתזמן (כמו SRTF) לבצע חפיפה (overlap) בריצה של תת-הג'ובים של A עם ג'ובים אחרים (B), ובכך למלא את חלונות הזמן שבהם A היה ממתין לפעולות קלט/פלט. התוצאה היא ניצול טוב יותר של המעבד והפחתה משמעותית של זמן מעבד מבוזבז, כפי שמודגם בתרשים: CPU: A1 B A2 B A3 B."}, "_source_file": "0050__Virtualization__CPU_Scheduling__MC__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:04:20", "_subject": "Virtualization", "_context_lectures": [8, 2, 3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["CPU Scheduling"], "difficulty_estimation": "Medium", "content": {"text": "לפי חומר ההרצאה, איזו גישה מוצעת לפתרון בעיית בזבוז זמן המעבד הנגרמת מהמתנה של תהליכים לפעולות קלט/פלט (I/O), וכיצד היא משפרת את ניצולת המעבד?", "code_snippet": null, "options": ["א. פיצול תהליך יחיד למספר תת-ג'ובים עצמאיים, כאשר כל תת-ג'וב נחשב לג'וב נפרד עם זמן הגעה וזמן ריצה משלו, מה שמאפשר למתזמן (כמו SRTF) לבצע חפיפה יעילה יותר עם תהליכים אחרים במהלך המתנות לקלט/פלט.", "ב. תזמון תהליך אחר לרוץ בזמן שתהליך ראשון ממתין לקלט/פלט, אך ללא שינוי בדרך ההתייחסות לג'ובים, מה שעדיין עלול להותיר חלונות זמן ריקים במעבד.", "ג. שימוש במנגנון Direct Execution כדי לתת לתהליך יחיד שליטה מלאה במעבד עד לסיומו, ובכך למנוע את הצורך בהחלפות תהליכים תכופות.", "ד. הסתמכות בלעדית על הידע המוקדם של זמן הריצה הכולל של כל ג'וב כדי לתזמן אותם בסדר אופטימלי ללא הפרעות, תוך התעלמות מהצורך בחפיפה במהלך I/O."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מתאר בעיה של בזבוז זמן מעבד, גם כאשר מתזמנים תהליך אחר לרוץ בזמן שתהליך ממתין לפעולת קלט/פלט (I/O). הסיבה היא שגם לאחר שתהליך ה-I/O מסתיים, אם לשני התהליכים נותר זמן ריצה דומה, המתזמן עשוי להמשיך לתזמן את התהליך השני, ולהשאיר חלון זמן ריק שאינו מנוצל (כפי שמתואר ב-Lecture 3, chunk 15). הפתרון המוצע, כפי שמצוין ב-Lecture 3, chunk 16, הוא לשנות את ההתייחסות לתהליך: במקום לראות בו ג'וב אחד ארוך שכולל המתנות ל-I/O, יש לפצל אותו למספר תת-ג'ובים קצרים ועצמאיים. כל תת-ג'וב מייצג מקטע ריצה של CPU בין פעולות I/O. על ידי טיפול בכל תת-ג'וב כג'וב נפרד עם זמן הגעה וזמן ריצה משלו, המתזמן (כמו SRTF) יכול לבצע חפיפה (overlap) יעילה יותר עם ג'ובים אחרים, ולמלא את חלונות הזמן שהיו מבוזבזים בעבר. לכן, אפשרות א' מתארת במדויק את הגישה וההסבר שניתנו בחומר ההרצאה."}, "_source_file": "0051__Virtualization__CPU_Scheduling__MC__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:04:38", "_subject": "Virtualization", "_context_lectures": [8, 2, 3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["CPU Scheduling"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על החומר שהוצג, כאשר תהליך יחיד (לדוגמה, 'A') מבצע פעולות קלט/פלט לסירוגין ומשאיר את המעבד במצב המתנה, הוצג פתרון שבו התהליך מפוצל למספר \"תתי-ג'ובים\" (לדוגמה, A1, A2, A3) כאשר כל תת-ג'וב מייצג מקטע ריצה של המעבד בין פעולות קלט/פלט. מדוע פיצול זה, בשילוב עם מתזמן מסוג SRTF, מאפשר ניצול טוב יותר של המעבד וחפיפה יעילה יותר בין ג'ובים, גם אם סך זמן הריצה של התהליך המקורי נשאר זהה?", "code_snippet": null, "options": ["א. פיצול התהליך לתתי-ג'ובים מאפשר למתזמן SRTF לראות כל מקטע ריצה כג'וב חדש ועצמאי המגיע בזמן שונה, ובכך להפעיל את לוגיקת התזמון המונעת שלו (preemptive) בצורה אגרסיבית יותר כאשר תת-ג'וב חדש (או תת-ג'וב שסיים I/O) מגיע, ולהחליף תהליך אחר בעל זמן ריצה ארוך יותר שרץ כרגע.", "ב. פיצול התהליך מקטין את זמן ה-I/O הכולל של התהליך, ובכך מפחית את חלונות הזמן הריקים שבהם המעבד אינו מנוצל.", "ג. מתזמן SRTF אינו יכול לתזמן תהליכים בעלי פעולות קלט/פלט אלא אם הם מפוצלים, ולכן הפיצול הוא תנאי הכרחי להפעלתו.", "ד. הפיצול מאפשר למערכת ההפעלה להקצות יותר זיכרון לתהליך A, ובכך להפחית את הצורך ב-page faults ובהמתנה לדיסק."]}, "solution": {"correct_option": "א", "explanation": "הפתרון לניצול מעבד טוב יותר, כפי שהוצג בחומר הלימוד (Lecture 3, chunk 16), טמון בהתייחסות לתהליך A, שמבצע פעולות קלט/פלט לסירוגין, לא כאל ג'וב יחיד וארוך, אלא כאל סדרה של תתי-ג'ובים קצרים (לדוגמה, A1, A2, A3), שכל אחד מהם מייצג מקטע ריצה של המעבד. כל תת-ג'וב כזה נחשב לג'וב עצמאי המגיע בזמן שונה (כאשר מקטע ה-CPU הקודם הסתיים או ה-I/O הסתיים). מתזמן מסוג SRTF (Shortest Remaining Time First) הוא מתזמן מונע (preemptive). כאשר תת-ג'וב חדש (כמו A2 או A3) \"מגיע\" או תת-ג'וב קיים (כמו A1) מסיים את פעולת הקלט/פלט שלו והופך להיות כשיר לריצה, המתזמן בודק את זמן הריצה שנותר לו ואת זמן הריצה שנותר לתהליך שרץ כרגע (לדוגמה, B). אם לתת-הג'וב של A יש זמן ריצה קצר יותר ממה שנותר לתהליך B, המתזמן SRTF יבצע החלפת הקשר (context switch) ויריץ את תת-הג'וב של A. זה מאפשר למתזמן למלא את חלונות הזמן שבהם התהליך המקורי A היה ממתין לפעולות קלט/פלט, ובכך למקסם את ניצול המעבד ולבצע חפיפה (overlap) יעילה יותר בין ג'ובים שונים, כפי שמודגם בתרשים \"CPU: A1 B A2 B A3 B\" בחומר. האפשרויות האחרות אינן נכונות: ב' שגויה מכיוון שהפיצול אינו מקטין את זמן ה-I/O הכולל; ג' שגויה מכיוון ש-SRTF יכול לתזמן תהליכים עם I/O, הפיצול הוא לשיפור היעילות; ד' שגויה מכיוון שהיא מתייחסת לניהול זיכרון (page faults) ואינה קשורה ישירות לפתרון בעיית תזמון המעבד על ידי פיצול ג'ובים."}, "_source_file": "0052__Virtualization__CPU_Scheduling__MC__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:04:57", "_subject": "Virtualization", "_context_lectures": [8, 2, 3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["CPU Scheduling"], "difficulty_estimation": "Hard", "content": {"text": "בהתייחס לבעיית בזבוז זמן מעבד הנגרמת על ידי תהליכים בעלי פעולות קלט/פלט תקופתיות, כפי שתוארה בחומר הקורס, ובהינתן שאלגוריתם תזמון קיים כמו SRTF ממשיך לשמש, איזה שינוי מהותי באופן שבו המתזמן 'רואה' את ה-workload הוא הכרחי כדי לאפשר חפיפה יעילה יותר בין ג'ובים ולמקסם את ניצול המעבד?", "code_snippet": null, "options": ["א. פיצול תהליך יחיד בעל פעולות קלט/פלט למספר 'תת-ג'ובים' נפרדים, כאשר כל תת-ג'וב נתפס על ידי המתזמן כג'וב עצמאי עם זמני הגעה וריצה משלו.", "ב. הגדלת תדירות ה-context switches באופן כללי כדי לאפשר לתהליכים רבים יותר להתחלף במהירות.", "ג. הענקת עדיפות גבוהה יותר לתהליכים המבצעים פעולות קלט/פלט על מנת שיסיימו את המתנתם מהר יותר.", "ד. שימוש בטכניקת Direct Execution כדי לאפשר לתהליכים לרוץ ללא הפרעה עד לסיום פעולת הקלט/פלט שלהם."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר הקורס מתאר מצב שבו תהליך כמו A מבצע פעולות קלט/פלט תקופתיות, מה שגורם לזמני המתנה ובזבוז של זמן מעבד. המתזמן מנסה בתחילה להריץ תהליכים אחרים (כמו B) בזמן ש-A ממתין, אך מודגם שגם זה לא מספיק כדי למנוע חלונות זמן ריקים במעבד. הפתרון המוצע, כפי שמצוין בבירור ב'Lecture 3 (chunk 16)', אינו דורש שינוי באלגוריתם התזמון עצמו (לדוגמה, SRTF ממשיך לשמש), אלא שינוי מהותי באופן שבו ה-workload מוצג למתזמן. במקום לראות את A כג'וב יחיד וארוך, הוא מפוצל למספר 'תת-ג'ובים' קצרים יותר (לדוגמה, A1, A2, A3), כאשר כל אחד מהם נתפס כג'וב עצמאי עם דרישות זמן ריצה והגעה משלו. גישה זו מאפשרת למתזמן לבצע 'חפיפה' (overlap) יעילה יותר, כלומר, כאשר תת-ג'וב אחד של A ממתין לקלט/פלט, המתזמן יכול להריץ תת-ג'וב אחר של A (אם זמין) או ג'וב אחר (B), ובכך למלא את חלונות הזמן הריקים ולמקסם את ניצול המעבד. האפשרויות האחרות אינן מתארות את הפתרון הספציפי והמהותי שהוצג בחומר הקורס לבעיה זו: הגדלת תדירות context switches (ב') לבדה לא פותרת את בעיית ה-I/O wait באופן אסטרטגי. הענקת עדיפות (ג') לא בהכרח מאפשרת חפיפה יעילה של זמן מעבד בזמן המתנת קלט/פלט. ו-Direct Execution (ד') היא ההפך הגמור, מכיוון שהיא מונעת החלפה ותזמון מחדש במהלך ריצת תהליך, ובכך מחמירה את בעיית ניצול המעבד."}, "_source_file": "0053__Virtualization__CPU_Scheduling__MC__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:05:25", "_subject": "Virtualization", "_context_lectures": [8, 2, 3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["CPU Scheduling"], "difficulty_estimation": "Hard", "content": {"text": "על פי חומר ההרצאה, בתרחיש שבו תהליך (A) מבצע פעולות קלט/פלט תקופתיות, והמתזמן (כמו SRTF) מתקשה למנוע בזבוז זמן מעבד כאשר תהליכים אחרים (B) זמינים לריצה, הוצג פתרון שבו תהליך A מפוצל ל\"ג'ובים משניים\" (sub-jobs). מהו ההבדל המהותי בגישה זו המאפשר למתזמן למלא את זמני ההמתנה של A לפעולות קלט/פלט בתהליכים אחרים, ובכך לשפר את ניצול המעבד?", "code_snippet": null, "options": ["א. הפיצול מאפשר למתזמן לראות כל חלק של A כג'וב עצמאי עם זמן ריצה קצר ידוע (למשל, 10ms), ובכך לתזמן תהליכים אחרים (B) באופן אופטימלי לרוץ בזמני ההמתנה של A לקלט/פלט.", "ב. הפיצול מאלץ את תהליך A לוותר על המעבד באופן יזום בכל פעם שהוא מתחיל פעולת קלט/פלט, ללא תלות ביכולות המתזמן.", "ג. הפיצול מאפשר להשתמש באלגוריתם תזמון חדש ומתקדם יותר מ-SRTF, אשר תוכנן במיוחד לטפל בג'ובים מפוצלים.", "ד. הפיצול מפחית את העומס על זיכרון המטמון (cache) של המעבד, ובכך מקצר את זמני הגישה לנתונים ומפנה יותר זמן מעבד לתהליכים אחרים."]}, "solution": {"correct_option": "א", "explanation": "הפתרון המוצג בחומר ההרצאה מתבסס על שינוי באופן שבו המתזמן תופס את התהליך (A). במקום לראות את A כג'וב ארוך אחד, הוא נשבר ל\"ג'ובים משניים\" קצרים ועצמאיים (לדוגמה, כל אחד באורך 10 מילישניות), כאשר ידוע מראש שכל אחד מהם מסתיים בפעולת קלט/פלט. גישה זו, כפי שצוין בשיעור, מאפשרת למתזמן לזהות באופן יעיל את הנקודות שבהן A ייכנס למצב המתנה לקלט/פלט. בכך, המתזמן יכול לתזמן תהליכים אחרים (כמו B) לרוץ בחלונות זמן אלו, ובכך למנוע בזבוז זמן מעבד ולשפר את ניצול המעבד הכולל. חומר ההרצאה מציין במפורש \"נשתמש באותו מתזמן (SRTF) אבל עם חפיפה של ג'ובים (overlap)\", מה שמפריך את אפשרות ג'. אפשרות ב' אינה נכונה מכיוון שהשינוי הוא באופן שבו המתזמן רואה את הג'ובים, לא שינוי בהתנהגות יזומה של התהליך A. אפשרות ד' אינה רלוונטית לפתרון שהוצג בחומר ההרצאה בנוגע לניצול מעבד בזמני המתנה לקלט/פלט."}, "_source_file": "0054__Virtualization__CPU_Scheduling__MC__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:05:42", "_subject": "Virtualization", "_context_lectures": [8, 2, 3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Scheduling Algorithms"], "difficulty_estimation": "Easy", "content": {"text": "מהו המנגנון העיקרי שבו משתמש אלגוריתם תזמון \"הגרלה\" (Lottery scheduling) כדי להקצות זמן מעבד באופן פרופורציונלי?", "code_snippet": null, "options": ["א. בחירת התהליך בעל ערך ה-PASS הנמוך ביותר ועדכון ערך ה-STRIDE שלו.", "ב. הקצאת \"כרטיסים\" (tickets) לתהליכים וביצוע הגרלה אקראית לבחירת התהליך הבא.", "ג. ריצת תהליכים בסדר הגעתם (First-Come, First-Served) מתחילתם ועד סופם.", "ד. חלוקת תהליכים ארוכים לתתי-תהליכים קצרים לצורך חפיפה עם פעולות קלט/פלט."]}, "solution": {"correct_option": "ב", "explanation": "אלגוריתם תזמון \"הגרלה\" (Lottery scheduling) הוא מתזמן מסוג \"חלוקה פרופורציונלית\" (proportional share). המנגנון העיקרי שלו מבוסס על הקצאת \"כרטיסים\" (tickets) לכל תהליך. ככל שלתהליך יש יותר כרטיסים, כך גדל הסיכוי שלו לזכות בהגרלה ולקבל את זמן המעבד. בכל פעם שיש לבחור תהליך לריצה, מתבצעת \"הגרלה\" אקראית, והתהליך שזוכה מקבל את זמן המעבד. אפשרות א' מתארת את מנגנון ה-Stride scheduling. אפשרות ג' מתארת את אלגוריתם FCFS. אפשרות ד' מתייחסת לטיפול בתהליכי קלט/פלט באמצעות פיצול ג'ובים, ולא למנגנון ליבה של תזמון פרופורציונלי."}, "_source_file": "0055__Virtualization__Scheduling_Algorithms__MC__Easy.json", "_topic_hint": "Scheduling Algorithms", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:05:55", "_subject": "Virtualization", "_context_lectures": [3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Scheduling Algorithms"], "difficulty_estimation": "Easy", "content": {"text": "מהו המנגנון העיקרי שבו משתמש אלגוריתם תזמון ה-\"Lottery scheduling\" כדי להקצות זמן מעבד באופן פרופורציונלי?", "code_snippet": null, "options": ["א. על ידי בחירת התהליך עם ערך ה-PASS הנמוך ביותר.", "ב. על ידי חלוקת \"כרטיסים\" (Tickets) לתהליכים ועריכת הגרלה.", "ג. על ידי הרצת הג'וב שהגיע ראשון עד לסיומו.", "ד. על ידי פיצול ג'ובים לתת-ג'ובים קטנים יותר."]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר ההרצאה, אלגוריתם ה-Lottery scheduling מקצה זמן מעבד באופן פרופורציונלי על ידי הקצאת 'כרטיסי הגרלה' (Tickets) לתהליכים. לאחר מכן, נערכת 'הגרלה' ובוחרים ג'וב מנצח. ככל שלתהליך יש יותר כרטיסים, כך גדל הסיכוי שלו להיבחר ולקבל את זמן המעבד. אפשרות א' מתארת את מנגנון ה-stride scheduling. אפשרות ג' מתארת תזמון מסוג First-Come, First-Served. אפשרות ד' מתארת טכניקה לטיפול בקלט/פלט, למשל בשילוב עם SRTF, ולא את מנגנון ההקצאה הפרופורציונלית של Lottery scheduling."}, "_source_file": "0056__Virtualization__Scheduling_Algorithms__MC__Easy.json", "_topic_hint": "Scheduling Algorithms", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:06:04", "_subject": "Virtualization", "_context_lectures": [3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Scheduling Algorithms"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, מהו העיקרון המרכזי שבו מתזמן \"הגרלה\" (Lottery scheduling) משתמש כדי להקצות זמן מעבד באופן פרופורציונלי לתהליכים?", "code_snippet": null, "options": ["א. הוא מקצה \"כרטיסי הגרלה\" (tickets) לתהליכים ובוחר באופן אקראי זוכה, כאשר לתהליכים עם יותר כרטיסים יש סיכוי גבוה יותר להיבחר.", "ב. הוא עוקב אחר ערך \"PASS\" וערך \"STRIDE\" עבור כל תהליך, ובוחר להריץ את התהליך עם ערך ה-PASS הנמוך ביותר.", "ג. הוא תמיד מריץ את התהליך עם זמן הריצה הנותר הקצר ביותר.", "ד. הוא מריץ תהליכים לפי סדר הגעתם, מתחילתם ועד סופם."]}, "solution": {"correct_option": "א", "explanation": "מתזמן \"הגרלה\" (Lottery scheduling) פועל באמצעות הקצאת \"כרטיסי הגרלה\" (tickets) לכל תהליך. בכל פעם שיש צורך לבחור תהליך לריצה, מתבצעת הגרלה אקראית. ככל שלתהליך מסוים יש יותר כרטיסים, כך גדל הסיכוי שלו לזכות בהגרלה ולקבל זמן מעבד. באופן זה, מושגת הקצאה פרופורציונלית של זמן המעבד בהתאם למספר הכרטיסים של כל תהליך. אפשרות ב' מתארת את אלגוריתם Stride scheduling. אפשרות ג' מתארת את אלגוריתם SRTF (Shortest Remaining Time First) המוזכר בחומר. אפשרות ד' מתארת אלגוריתם מסוג FCFS (First-Come, First-Served)."}, "_source_file": "0057__Virtualization__Scheduling_Algorithms__MC__Easy.json", "_topic_hint": "Scheduling Algorithms", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:06:18", "_subject": "Virtualization", "_context_lectures": [3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Scheduling Algorithms"], "difficulty_estimation": "Medium", "content": {"text": "איזו טענה מתארת באופן הטוב ביותר את הגישה הייחודית של אלגוריתם תזמון Stride Scheduling לחלוקה פרופורציונלית של זמן מעבד, בהשוואה לאלגוריתם Lottery Scheduling?", "code_snippet": null, "options": ["א. הוא מבטיח חלוקה פרופורציונלית מדויקת יותר לאורך זמן על ידי מעקב דטרמיניסטי אחר זמן הריצה היחסי של כל תהליך באמצעות ערכי PASS ו-STRIDE.", "ב. הוא מאפשר לתהליכים 'לנפח' באופן זמני את חלקם בזמן המעבד על ידי הוספה דינמית של ערכים ל-STRIDE שלהם.", "ג. הוא מסתמך על בחירה אקראית של תהליך לריצה מתוך קבוצה של תהליכים זמינים, כאשר ההסתברות תלויה במספר ה'כרטיסים' שברשותו.", "ד. הוא מותאם במיוחד למצבים שבהם זמן הריצה של כל ג'וב אינו ידוע מראש, ומחלק את זמן המעבד באופן שווה בין כל התהליכים."]}, "solution": {"correct_option": "א", "explanation": "האלגוריתם Stride Scheduling משתמש בערכים דטרמיניסטיים (PASS ו-STRIDE) כדי להבטיח חלוקה פרופורציונלית של זמן המעבד. לכל ג'וב מוגדר ערך STRIDE, המייצג את חלקו היחסי, וערך PASS שמתעד כמה זמן הוא רץ עד כה. המתזמן בוחר תמיד את הג'וב עם ערך ה-PASS הנמוך ביותר, ולאחר הריצה מוסיף את ערך ה-STRIDE שלו ל-PASS שלו. גישה זו, כפי שמתוארת בחומר ההרצאה ('כשנרצה לבחור ג'וב לריצה, נבחר את הג'וב עם ה-pass הנמוך ביותר, ואז כל ריצה נוסיף את ה- stride שלו לערך ה-pass שלו'), מובילה לחלוקה פרופורציונלית מדויקת ודטרמיניסטית לאורך זמן. לעומת זאת, Lottery Scheduling מסתמך על בחירה אקראית באמצעות 'כרטיסים' (אפשרות ג'), ו'ניפוח כרטיסים' (Ticket inflation) הוא מנגנון השייך ל-Lottery ולא ל-Stride (אפשרות ב'). ההנחה בחומר ההרצאה היא שזמני הריצה ידועים עבור האלגוריתמים הנידונים (אפשרות ד' שגויה)."}, "_source_file": "0058__Virtualization__Scheduling_Algorithms__MC__Medium.json", "_topic_hint": "Scheduling Algorithms", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:06:33", "_subject": "Virtualization", "_context_lectures": [3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Scheduling Algorithms"], "difficulty_estimation": "Medium", "content": {"text": "מהו ההבדל העיקרי בין אלגוריתם תזמון Lottery Scheduling לבין אלגוריתם Stride Scheduling בדרך שבה הם מקצים זמן מעבד באופן פרופורציונלי?", "code_snippet": null, "options": ["א. Lottery Scheduling משתמש בהגרלה אקראית של כרטיסים, בעוד ש-Stride Scheduling משתמש בערכי PASS ו-STRIDE כדי להבטיח תזמון דטרמיניסטי.", "ב. Lottery Scheduling מתמקד במניעת רעבון (starvation), בעוד ש-Stride Scheduling מתמקד בהקטנת זמן ההמתנה הממוצע.", "ג. Stride Scheduling דורש ידע מוקדם על משך הריצה המדויק של כל ג'וב, בעוד ש-Lottery Scheduling אינו דורש זאת.", "ד. Lottery Scheduling מאפשר לג'ובים להגדיל או להקטין באופן זמני את מספר הכרטיסים שלהם (ticket inflation), בעוד ש-Stride Scheduling אינו תומך במנגנון גמישות דומה."]}, "solution": {"correct_option": "א", "explanation": "ההבדל העיקרי והמהותי בין שני האלגוריתמים טמון במנגנון התזמון שלהם. Lottery Scheduling הוא אלגוריתם הסתברותי המקצה זמן מעבד באופן פרופורציונלי על ידי בחירה אקראית של ג'וב מנצח מתוך מאגר כרטיסים (Tickets), כאשר הסיכוי לזכות פרופורציונלי למספר הכרטיסים שבידי הג'וב. לעומת זאת, Stride Scheduling הוא אלגוריתם דטרמיניסטי המבטיח הקצאה פרופורציונלית על ידי ניהול ערכי PASS ו-STRIDE לכל ג'וב. הוא בוחר תמיד את הג'וב עם ערך ה-PASS הנמוך ביותר, ולאחר הרצתו מעדכן את ערך ה-PASS שלו על ידי הוספת ה-STRIDE שלו. שיטה זו מבטיחה תזמון מדויק וצפוי יותר לאורך זמן, בניגוד לאקראיות של Lottery Scheduling. אפשרות ד' מתארת תכונה של Lottery Scheduling שאינה קיימת ב-Stride Scheduling, אך היא אינה ההבדל העיקרי במנגנון הליבה של הקצאה פרופורציונלית, אלא תוספת גמישות."}, "_source_file": "0059__Virtualization__Scheduling_Algorithms__MC__Medium.json", "_topic_hint": "Scheduling Algorithms", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:06:45", "_subject": "Virtualization", "_context_lectures": [3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Scheduling Algorithms"], "difficulty_estimation": "Medium", "content": {"text": "באלגוריתם תזמון Stride Scheduling, כיצד מושגת הקצאת זמן מעבד פרופורציונלית בין תהליכים שונים, ומה המשמעות של ערך ה-STRIDE?", "code_snippet": null, "options": ["א. תהליך בעל ערך STRIDE נמוך יותר יקבל זמן מעבד רב יותר, מכיוון שערך ה-PASS שלו יגדל לאט יותר, מה שיגרום לו להיבחר לעיתים קרובות יותר.", "ב. תהליך בעל ערך STRIDE גבוה יותר יקבל זמן מעבד רב יותר, מכיוון שערך ה-PASS שלו יגדל מהר יותר, מה שיבטיח לו עדיפות בבחירה הבאה.", "ג. ערך ה-STRIDE קובע את משך הזמן שתהליך ירוץ בכל פעם שהוא נבחר, ללא קשר לערך ה-PASS.", "ד. הקצאת זמן המעבד נקבעת באופן אקראי על בסיס ערך ה-STRIDE, בדומה לאלגוריתם Lottery Scheduling."]}, "solution": {"correct_option": "א", "explanation": "אלגוריתם Stride Scheduling נועד להקצות זמן מעבד באופן פרופורציונלי. לכל תהליך מוגדר ערך STRIDE וערך PASS (שמתחיל מ-0). בכל פעם שיש לבחור תהליך לריצה, נבחר התהליך בעל ערך ה-PASS הנמוך ביותר. לאחר ריצת התהליך, ערך ה-STRIDE שלו מתווסף לערך ה-PASS שלו. משמעות הדבר היא שתהליך בעל ערך STRIDE נמוך יותר יגרום לערך ה-PASS שלו לגדול בקצב איטי יותר, ולכן הוא יישאר עם ערך PASS נמוך יחסית למשך זמן רב יותר, מה שיגדיל את הסיכויים שלו להיבחר שוב ושוב. כפי שמצוין בחומר ההרצאה: 'אם A יהיה בעל ערך 100 ו-B יהיה בעל ערך 200, אז זה אומר שנרצה להריץ את A פי 2 פעמים כל פעם שנריץ את B'. לפיכך, STRIDE נמוך יותר מקנה עדיפות גבוהה יותר וזמן מעבד רב יותר, ואילו STRIDE גבוה יותר פירושו פחות זמן מעבד. האלגוריתם פועל באופן דטרמיניסטי ולא אקראי כמו Lottery Scheduling."}, "_source_file": "0060__Virtualization__Scheduling_Algorithms__MC__Medium.json", "_topic_hint": "Scheduling Algorithms", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:07:02", "_subject": "Virtualization", "_context_lectures": [3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Scheduling Algorithms"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על החומר שהוצג אודות אלגוריתמי תזמון פרופורציונליים, Lottery Scheduling ו-Stride Scheduling, איזה מהיתרונות הבאים מתאר בצורה המדויקת ביותר את Stride Scheduling בהשוואה ל-Lottery Scheduling, במיוחד בהקשר של השגת הקצאת זמן מעבד יחסית מדויקת וצפויה על פני פרקי זמן קצרים?", "code_snippet": null, "options": ["א. Stride Scheduling מאפשר לתהליכים להוסיף או להוריד לעצמם כרטיסים באופן זמני (Ticket Inflation), מה שמגביר את הגמישות בתגובה לשינויים בעומס.", "ב. Stride Scheduling מבטיח חלוקה פרופורציונלית של זמן המעבד באופן דטרמיניסטי ומדויק יותר לאורך פרקי זמן קצרים, בניגוד לאופי ההסתברותי של Lottery Scheduling.", "ג. Stride Scheduling מטפל ביעילות רבה יותר בתהליכי קלט/פלט על ידי פיצול אוטומטי של ג'ובים לתת-ג'ובים קצרים יותר המאפשרים חפיפה.", "ד. Stride Scheduling מונע לחלוטין מצבי רעב (starvation) עבור תהליכים בעלי עדיפות נמוכה או מעט כרטיסים, מה שאינו מובטח ב-Lottery Scheduling."]}, "solution": {"correct_option": "ב", "explanation": "החומר המצורף מתאר את Lottery Scheduling כאלגוריתם שבו הבחירה נעשית 'באופן אקראי' על ידי 'כרטיסי הגרלה', מה שמקנה לתהליכים 'עדיפות גבוהה יותר (עם יחס מסוים)' או 'נבחר בהם בהסתברות גבוהה יותר'. אופי זה של בחירה אקראית, גם אם הוא פרופורציונלי בטווח הארוך, עלול לגרום לחוסר דיוק ואי-צפיות בהקצאת זמן המעבד בפרקי זמן קצרים. לעומת זאת, Stride Scheduling מתואר כאלגוריתם דטרמיניסטי שבו 'נבחר את הג'וב עם ה-pass הנמוך ביותר, ואז כל ריצה נוסיף את ה- stride שלו לערך ה-pass שלו'. מנגנון זה מבטיח התקדמות פרופורציונלית עקבית ומדויקת יותר של כל התהליכים, ובכך משיג חלוקה צפויה ומדויקת יותר של זמן המעבד גם בפרקי זמן קצרים.\n\nא. אפשרות זו שגויה. 'Ticket Inflation' היא תכונה המתוארת בחומר בהקשר של Lottery Scheduling, לא Stride Scheduling.\nג. אפשרות זו שגויה. הטיפול בתהליכי קלט/פלט על ידי פיצול ג'ובים לתת-ג'ובים מוזכר בחומר כ'גישה נפוצה' עבור מתזמן SRTF, ולא כתכונה ייחודית או אוטומטית של Stride Scheduling.\nד. אפשרות זו שגויה. אף שהאופי הדטרמיניסטי של Stride Scheduling הופך אותו לעמיד יותר בפני רעב מאשר Lottery Scheduling (שבו תהליך בעל כרטיסים מעטים יכול תיאורטית לא להיבחר לזמן מה), החומר אינו דן במפורש במושג 'רעב' עבור אף אחד מהאלגוריתמים, וכן הטענה 'מונע לחלוטין' היא חזקה מדי ולרוב אינה מדויקת במערכות מורכבות ללא תיאור מפורט נוסף."}, "_source_file": "0061__Virtualization__Scheduling_Algorithms__MC__Hard.json", "_topic_hint": "Scheduling Algorithms", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:07:21", "_subject": "Virtualization", "_context_lectures": [3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Scheduling Algorithms"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על אלגוריתמי התזמון הפרופורציונליים שהוצגו בחומר השיעור, איזה מהם מבטיח חלוקה מדויקת ועקבית יותר של זמן המעבד ביחס לשיעורים המוגדרים, בפרקי זמן קצרים יחסית, ומדוע?", "code_snippet": null, "options": ["א. תזמון הגרלה (Lottery scheduling), מכיוון שהוא מאפשר התאמה דינמית של כרטיסים (ticket inflation) ובכך מגיב במהירות לדרישות משתנות.", "ב. תזמון פסע (Stride scheduling), מכיוון שהוא מבוסס על ערכי PASS ו-STRIDE דטרמיניסטיים, אשר מבטיחים בחירה עקבית של התהליך עם ה-PASS הנמוך ביותר.", "ג. תזמון הגרלה (Lottery scheduling), מכיוון שההסתברות לבחירת תהליך מחושבת מחדש בכל קוואנטה, מה שמבטיח התכנסות מהירה ליחסים הרצויים.", "ד. תזמון פסע (Stride scheduling), מכיוון שהוא מאפשר פירוק תהליכים לתת-משימות (sub-jobs) ובכך מאפשר חפיפה יעילה יותר של פעולות קלט/פלט."]}, "solution": {"correct_option": "ב", "explanation": "תזמון פסע (Stride scheduling) מבטיח חלוקה מדויקת ועקבית יותר של זמן המעבד בפרקי זמן קצרים מכיוון שהוא אלגוריתם דטרמיניסטי. הוא עוקב אחר ערכי ה-PASS של כל ג'וב, המציינים כמה זמן הג'וב כבר רץ באופן יחסי. בכל נקודת החלטה, המתזמן בוחר את הג'וב עם ערך ה-PASS הנמוך ביותר ומוסיף ל-PASS שלו את ערך ה-STRIDE שלו. מנגנון זה מבטיח שהיחסים הפרופורציונליים יישמרו באופן עקבי ומיידי, ללא התלות באקראיות של הגרלה, כפי שקורה בתזמון הגרלה (Lottery scheduling). בעוד שתזמון הגרלה מתכנס ליחסים הרצויים לאורך זמן רב, בטווחים קצרים הוא עלול להציג סטיות בשל אופיו ההסתברותי. תזמון פסע, לעומת זאת, שומר על פרופורציה מדויקת בכל בחירה. אפשרויות א' ו-ג' מתארות היבטים של תזמון הגרלה אך אינן מדגישות דיוק בטווח קצר כמו תזמון פסע. אפשרות ד' מתייחסת לטכניקה המשמשת עם מתזמנים כמו SRTF כדי לטפל בקלט/פלט, ולא למנגנון הליבה של תזמון פסע לחלוקה פרופורציונלית."}, "_source_file": "0062__Virtualization__Scheduling_Algorithms__MC__Hard.json", "_topic_hint": "Scheduling Algorithms", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:07:37", "_subject": "Virtualization", "_context_lectures": [3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Scheduling Algorithms"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על תיאור אלגוריתמי התזמון Lottery Scheduling ו-Stride Scheduling בחומר השיעור, מהו ההבדל המהותי במנגנון הפנימי שלהם אשר משפיע על אופן מימוש ההקצאה הפרופורציונלית של זמן המעבד?", "code_snippet": null, "options": ["א. תזמון Lottery משתמש במנגנון 'כרטיסים' (Tickets) המאפשר העברה והגדלה דינמית של כרטיסים בין תהליכים, בעוד שתזמון Stride מסתמך על ערכי PASS ו-STRIDE קבועים מראש ללא יכולת שינוי.", "ב. תזמון Stride מבטיח הקצאה פרופורציונלית דטרמיניסטית ומדויקת על ידי מעקב אחר זמן הריצה המצטבר של כל תהליך באמצעות ערך ה-PASS, ובחירה עקבית של התהליך עם ה-PASS הנמוך ביותר, בניגוד לתזמון Lottery המבוסס על בחירה אקראית והסתברותית.", "ג. תזמון Lottery דורש ידע מוקדם על זמן הריצה הכולל של כל ג'וב כדי לחשב את מספר הכרטיסים שיש להקצות לו, בעוד שתזמון Stride אינו דורש מידע זה.", "ד. תזמון Stride מתמודד טוב יותר עם תהליכי קלט/פלט (I/O-bound jobs) על ידי פיצול ג'ובים לתת-ג'ובים קטנים יותר, בעוד שתזמון Lottery אינו מספק מנגנון דומה."]}, "solution": {"correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. תזמון Stride מתואר כאלגוריתם דטרמיניסטי: הוא עוקב באופן עקבי אחר ערך ה-PASS של כל ג'וב, המייצג את כמות הזמן שהג'וב רץ עד כה (באופן יחסי), ותמיד בוחר את הג'וב עם ערך ה-PASS הנמוך ביותר. לאחר מכן, ערך ה-PASS של הג'וב הנבחר מתעדכן על ידי הוספת ערך ה-STRIDE שלו. מנגנון זה מבטיח הקצאה פרופורציונלית מדויקת וצפויה לאורך זמן. לעומת זאת, תזמון Lottery מתבסס על מנגנון הסתברותי ואקראי: הוא מקצה 'כרטיסים' לג'ובים, ובכל נקודת זמן מבצע 'הגרלה' אקראית כדי לבחור את הג'וב הבא שירוץ. למרות שהוא משיג הקצאה פרופורציונלית בממוצע לאורך זמן, ההחלטות הבודדות הן אקראיות.\n\nא' שגויה מכיוון שאמנם Lottery מאפשר גמישות עם כרטיסים (העברה והגדלה), אך ההבדל המהותי אינו רק ביכולת השינוי, אלא בטבע האלגוריתם עצמו – הסתברותי מול דטרמיניסטי. Stride מיועד להבטיח פרופורציה מדויקת באמצעות מנגנון דטרמיניסטי של מעקב ובחירה.\nג' שגויה מכיוון שהחומר מציין הנחה כללית ש'אנחנו יודעים את זמן הריצה של כל ג'וב' עבור האלגוריתמים הנדונים, ולא דרישה ספציפית לאחד מהם. בנוסף, הקצאת הכרטיסים ב-Lottery או ערכי ה-STRIDE ב-Stride נועדו להקצאה פרופורציונלית, לאו דווקא על בסיס זמן ריצה כולל.\nד' שגויה מכיוון שהתמודדות עם תהליכי קלט/פלט (I/O-bound jobs) על ידי פיצול ג'ובים לתת-ג'ובים הוזכרה בחומר השיעור בהקשר של שיפור ניצול המעבד עם מתזמן ה-SRTF, ולא כמאפיין ייחודי או מבדיל בין Lottery ל-Stride."}, "_source_file": "0063__Virtualization__Scheduling_Algorithms__MC__Hard.json", "_topic_hint": "Scheduling Algorithms", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:07:59", "_subject": "Virtualization", "_context_lectures": [3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Memory Management"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, מהי הנחת יסוד מפשטת מרכזית של אלגוריתם ה-\"free list\" כפי שתואר בתחילה כ\"פשוט ויעיל\"?", "code_snippet": null, "options": ["א. כל הבלוקים בזיכרון הם בגודל שווה.", "ב. הזיכרון מחולק תמיד למקטעים בגודל קבוע של 4KB.", "ג. המשתמש תמיד משחרר זיכרון באותו סדר שבו הקצה אותו.", "ד. הכתובות של בלוקים פנויים סמוכים תמיד נבדלות בביט אחד."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מתאר את אלגוריתם ה-\"free list\" הפשוט כיעיל מאוד כאשר הוא מניח ש\"נחלק את הזיכרון לבלוקים ונחזיק רשימה מקושרת שתגיד לנו מה הבלוקים פנוי.\" ובמיוחד מציין ש\"כל הבלוקים באותו גודל\". הנחה זו מפשטת מאוד את הניהול, שכן אין צורך לנהל גדלים משתנים או למיין את הרשימה. בהמשך ההרצאה מצוין כי אם מנסים להחיל את אותם כללים על גדלים משתנים, זה הופך להיות בעייתי.\nאפשרות ב' אינה נכונה, שכן גודל הבלוקים (100MB בדוגמה) אינו קבוע ל-4KB.\nאפשרות ג' אינה נכונה, שכן ההרצאה מציינת בהקשר של ניהול ערימה (heap) ש\"המשתמש יכול להקצות זיכרון ולשחרר אותו בסדר אחר\".\nאפשרות ד' מתייחסת למאפיין של אלגוריתם \"Buddy Allocation\" ולא של \"free list\" הפשוט."}, "_source_file": "0064__Virtualization__Memory_Management__MC__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:08:08", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Memory Management"], "difficulty_estimation": "Easy", "content": {"text": "איזו תכונה מהותית מייחדת את אלגוריתם ניהול הזיכרון \"free list\" כאשר הזיכרון מחולק לחלקים שווים בגודלם?", "code_snippet": null, "options": ["א. כל הבלוקים הפנויים ברשימה הם באותו גודל, מה שמפשט את ניהול הרשימה.", "ב. האלגוריתם דורש מבנה נתונים מורכב כדי לעקוב אחר גדלים שונים של בלוקים.", "ג. הוא יעיל במיוחד לטיפול בבקשות הקצאת זיכרון בגדלים משתנים מאוד.", "ד. הבעיה העיקרית שלו היא איחוד (coalesce) של בלוקים פנויים סמוכים בגדלים משתנים."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין מתאר את אלגוריתם \"free list\" שבו הזיכרון מחולק לחלקים שווים בגודלם. הוא מציין במפורש: \"כל הבלוקים באותו גודל\" ו-\"לא צריך למיין את הרשימה\", מה שמדגיש את פשטות הניהול הנובעת מכך שכל הפריטים ברשימה זהים בגודלם. אפשרות ב' אינה נכונה מכיוון שמבנה הנתונים פשוט כאשר הגדלים קבועים. אפשרות ג' אינה נכונה, שכן החומר מציין ששיטה זו \"לא מציאותית\" ו\"בעייתית\" עבור גדלים משתנים. אפשרות ד' מתייחסת לבעיה שאלגוריתמים כמו Buddy Allocation באים לפתור, ואינה רלוונטית ל-free list עם בלוקים בגודל קבוע, שם איחוד בלוקים לא נדרש באותה צורה."}, "_source_file": "0065__Virtualization__Memory_Management__MC__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:08:18", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Memory Management"], "difficulty_estimation": "Easy", "content": {"text": "איזו טענה נכונה לגבי אלגוריתם ניהול הזיכרון \"free list\" כאשר כל חלקי הזיכרון הם בגודל שווה?", "code_snippet": null, "options": ["א. הוא מאוד יעיל ופשוט ליישום וניהול.", "ב. הוא מתאים במיוחד לטיפול בבקשות הקצאה בגדלים משתנים.", "ג. הוא פותר ביעילות את בעיית איחוד שטחי הזיכרון הפנויים (coalesce) על ידי פיצול הזיכרון.", "ד. הוא דורש מבנה נתונים מורכב לניהול רשימת הבלוקים הפנויים."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, כאשר אלגוריתם 'free list' מנהל זיכרון המחולק לחלקים שווים בגודלם, הוא מתואר כ'מאוד יעיל וזה מאוד פשוט'. זאת מכיוון שכל הבלוקים זהים בגודלם, מה שמפשט את תהליך ההקצאה והשחרור ואינו דורש מיון או מבני נתונים מורכבים. אפשרות ב' אינה נכונה, מכיוון שהחומר מציין במפורש כי האלגוריתם הופך לבעייתי כאשר מנסים להחיל את אותם הכללים על גדלים משתנים. אפשרות ג' אינה נכונה, שכן Buddy Allocation הוא האלגוריתם שבא לפתור את בעיית ה-coalesce על ידי פיצול הזיכרון. אפשרות ד' אינה נכונה, מכיוון שהפשטות של האלגוריתם במקרה של בלוקים שווים בגודלם אומרת שאין צורך במבנה נתונים מורכב, אלא רק רשימה מקושרת פשוטה של בלוקים פנויים."}, "_source_file": "0066__Virtualization__Memory_Management__MC__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:08:26", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Memory Management"], "difficulty_estimation": "Medium", "content": {"text": "איזו בעיה מרכזית באלגוריתמי ניהול זיכרון נפתרת ביעילות על ידי שיטת Buddy Allocation, וכיצד היא עושה זאת?", "code_snippet": null, "options": ["א. בעיית ה-coalesce (איחוד שטחי זיכרון), על ידי פיצול הזיכרון לבלוקים בגודל חזקת 2 ואיחוד קל של בלוקים שכנים פנויים.", "ב. בעיית ההקצאה של בלוקים בגודל קבוע בלבד, בכך שהיא מאפשרת הקצאת זיכרון בכל גודל נתון.", "ג. בעיית ה-internal fragmentation (פיצול פנימי), על ידי הקצאת הזיכרון בדיוק בגודל המבוקש ללא בזבוז.", "ד. בעיית ניהול רשימת הבלוקים הפנויים (free list) המסובכת, על ידי שימוש במבנה נתונים פשוט המכיל רק מצביעים."]}, "solution": {"correct_option": "א", "explanation": "שיטת Buddy Allocation נועדה לפתור ביעילות את בעיית ה-coalesce (איחוד שטחי זיכרון פנויים קטנים לבלוקים גדולים יותר), שהיא סוג של פיצול חיצוני. האלגוריתם עובד על ידי פיצול הזיכרון לבלוקים בגודל חזקת 2. כאשר משתמש מבקש זיכרון, המערכת מפצלת בלוק גדול יותר לשני \"חברים\" (buddies) בגודל חזקת 2, עד שמגיעה לגודל המתאים (או הקרוב ביותר בחזקת 2). היתרון המרכזי הוא שבעת שחרור זיכרון, קל מאוד לזהות את ה\"חבר\" של הבלוק המשתחרר (באמצעות שינוי ביט אחד בכתובת). אם שני ה\"חברים\" פנויים, ניתן לאחד אותם מיידית לבלוק גדול יותר, ובכך להפחית פיצול חיצוני ולשפר את ניצול הזיכרון."}, "_source_file": "0067__Virtualization__Memory_Management__MC__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:08:40", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Memory Management"], "difficulty_estimation": "Medium", "content": {"text": "איזו טכניקה לניהול זיכרון מתוארת בחומר ההרצאה כפתרון לבעיית ה-coalesce (איחוד שטחי זיכרון פנויים) על ידי פיצול הזיכרון לחצאים ואיחוד בלוקים שכנים כאשר הם משתחררים?", "code_snippet": null, "options": ["א. Buddy Allocation", "ב. Free List עם בלוקים בגודל קבוע", "ג. Slab Allocation", "ד. Free List עם בלוקים בגודל משתנה"]}, "solution": {"correct_option": "א", "explanation": "הסבר: שיטת Buddy Allocation נועדה במיוחד לפתור את בעיית ה-coalesce, שהיא איחוד בלוקים פנויים סמוכים לבלוק גדול יותר. לפי חומר ההרצאה, בשיטה זו, כאשר זיכרון מבוקש, הוא מפוצל לחצאים שוב ושוב עד שמגיעים לבלוק בגודל מתאים. כאשר בלוק משוחרר, המערכת בודקת את ה\"שכן\" (buddy) שלו – בלוק בגודל זהה שכתובתו נבדלת בביט אחד בלבד. אם גם השכן פנוי, שני הבלוקים מאוחדים לבלוק אחד גדול יותר (למשל, שני בלוקים של 8KB יאוחדו ל-16KB), ובכך נמנעת פיצול פנימי ומקודמת יצירת בלוקים גדולים ורציפים. שיטות ה-Free List, בין אם עם בלוקים בגודל קבוע או משתנה, אינן מתוארות כבעלות מנגנון מובנה וברור לפתרון בעיית ה-coalesce בצורה זו, ו-Slab Allocation מתמקדת בהקצאת אובייקטים בגודל קבוע ולא בפתרון כללי ל-coalesce של זיכרון כללי."}, "_source_file": "0068__Virtualization__Memory_Management__MC__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:08:54", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Memory Management"], "difficulty_estimation": "Medium", "content": {"text": "בהתבסס על חומר ההרצאה, מהו היתרון המרכזי של אלגוריתם Buddy Allocation בהשוואה לניהול זיכרון באמצעות רשימת בלוקים פנויים בגודל קבוע, במיוחד בהקשר של התמודדות עם פיצול זיכרון?", "code_snippet": null, "options": ["א. היכולת להקצות זיכרון למקטעים בגדלים משתנים ללא צורך במבנה נתונים מורכב.", "ב. מניעת Overheads של ניהול זיכרון (כמו header) עבור כל בלוק שהוקצה.", "ג. התמודדות יעילה עם בעיית איחוד שטחי זיכרון פנויים סמוכים (coalesce) ויצירת בלוקים גדולים יותר.", "ד. הקצאת זיכרון מהירה יותר עבור אובייקטים קטנים וקבועים בגודלם, כמו אלו המשמשים את ליבת מערכת ההפעלה."]}, "solution": {"correct_option": "ג", "explanation": "על פי חומר ההרצאה, אלגוריתם Buddy Allocation \"בא לפתור את הבעיה של coalesce (איחוד שטחי זיכרון בודדים ופנויים)\". שיטה זו מפצלת בלוקי זיכרון גדולים לבלוקים קטנים יותר לפי הצורך, וברגע שבלוקים שכנים פנויים הם מאוחדים בחזרה ליצירת בלוקים גדולים יותר. בכך, Buddy Allocation מתמודד ביעילות עם פיצול זיכרון חיצוני ומאפשר הקצאות גדולות יותר. רשימת בלוקים פנויים בגודל קבוע, לעומת זאת, מתוארת כלא מציאותית עבור גדלים משתנים ועלולה לסבול ממצבים בהם לא ניתן להקצות זיכרון נדרש למרות שיש מספיק זיכרון פנוי בסך הכל, עקב פיצול."}, "_source_file": "0069__Virtualization__Memory_Management__MC__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:09:12", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Memory Management"], "difficulty_estimation": "Hard", "content": {"text": "איזה אלגוריתם ניהול זיכרון תוכנן במיוחד כדי לטפל ביעילות בפרגמנטציה חיצונית על ידי פישוט איחודם של בלוקי זיכרון פנויים סמוכים, ומהו המנגנון העיקרי שלו להשגת מטרה זו?", "code_snippet": null, "options": ["א. Free List עם בלוקים בגודל קבוע – הוא שומר רשימה של בלוקים פנויים זהים בגודלם, ולכן אינו מתמודד עם פרגמנטציה חיצונית באמצעות איחוד, אלא מונע אותה על ידי מבנה קבוע.", "ב. Buddy Allocation – הוא מפצל את הזיכרון לבלוקים בגדלים שהם חזקות של 2, ומאפשר איחוד מהיר של בלוקים שכנים פנויים על ידי בדיקת ביט בכתובת הזיכרון שלהם.", "ג. Slab Allocation – הוא מקצה בלוקים בגודל קבוע עבור אובייקטים ספציפיים, מה שמפחית פרגמנטציה פנימית אך אינו מיועד לפתור ביעילות פרגמנטציה חיצונית רחבה באמצעות איחוד בלוקים בגדלים שונים.", "ד. Free List עם בלוקים בגודל משתנה – הוא שומר כתובת וגודל לכל בלוק פנוי, אך איחוד בלוקים סמוכים דורש סריקה מורכבת של הרשימה או מבנה נתונים מורכב יותר למציאת שכנים, ואינו \"מפושט\" כפי שמתואר."]}, "solution": {"correct_option": "ב", "explanation": "האלגוריתם Buddy Allocation תוכנן במפורש כדי לפתור את בעיית ה-coalesce (איחוד שטחי זיכרון בודדים ופנויים), שהיא הדרך להתמודד עם פרגמנטציה חיצונית. לפי חומר ההרצאה, הוא מפצל את הזיכרון לבלוקים בגדלים שהם חזקות של 2. כאשר משתמש מפנה בלוק, האלגוריתם בודק את ה\"חבר\" (buddy) שלו – בלוק שכתובתו נבדלת בביט אחד בלבד. אם גם ה\"חבר\" פנוי, ניתן לאחד אותם במהירות לבלוק גדול יותר, ובכך לפשט מאוד את תהליך האיחוד ולשחזר שטחי זיכרון גדולים יותר. אפשרות א' (Free List עם בלוקים בגודל קבוע) אינה דורשת איחוד במובן של coalesce מכיוון שכל הבלוקים באותו גודל; היא מונעת פרגמנטציה חיצונית מורכבת אך אינה \"פותרת\" אותה באמצעות איחוד יעיל של בלוקים שונים. אפשרות ג' (Slab Allocation) מתמקדת בהקצאה יעילה של אובייקטים קטנים וקבועי גודל, בעיקר כדי להפחית פרגמנטציה פנימית וניהול תקורה, אך אינה מציעה מנגנון יעיל לפישוט איחוד בלוקים פנויים בגדלים משתנים. אפשרות ד' (Free List עם בלוקים בגודל משתנה) אכן סובלת מפרגמנטציה חיצונית ודורשת איחוד, אך חומר ההרצאה מציין שהרשימה המקושרת הופכת \"מורכבת יותר\" ואינו מתאר מנגנון \"מפושט\" לאיחוד, בניגוד ל-Buddy Allocation."}, "_source_file": "0070__Virtualization__Memory_Management__MC__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:09:31", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Memory Management"], "difficulty_estimation": "Hard", "content": {"text": "נתאר מצב שבו מערכת ההפעלה מבצעת הקצאות זיכרון רבות בגדלים שונים, ולאחר מכן משחררת אותן בסדר אקראי. כתוצאה מכך, הזיכרון הפיזי מתפצל למקטעים פנויים קטנים ולא רציפים, בעוד שנדרשת הקצאה גדולה יותר שאינה יכולה להתבצע למרות שסך הזיכרון הפנוי מספק. בהתבסס על חומר ההרצאה, איזה אלגוריתם לניהול זיכרון מציע פתרון מובנה ויעיל ביותר לבעיה זו של פיצול זיכרון חיצוני (External Fragmentation), באמצעות איחוד (coalesce) של שטחי זיכרון פנויים?", "code_snippet": null, "options": ["א. אלגוריתם Buddy Allocation", "ב. אלגוריתם Free List עם בלוקים בגודל קבוע", "ג. אלגוריתם Free List עם בלוקים בגודל משתנה", "ד. שימוש ב-Slab Allocator"]}, "solution": {"correct_option": "א", "explanation": "השאלה מתארת מצב של פיצול זיכרון חיצוני (External Fragmentation), שבו יש מספיק זיכרון פנוי בסך הכל, אך הוא מפוצל למקטעים קטנים ולא רציפים שאינם מאפשרים הקצאה של בלוק גדול. חומר ההרצאה מציין במפורש כי אלגוריתם Buddy Allocation 'בא לפתור את הבעיה של coalesce (איחוד שטחי זיכרון בודדים ופנויים)'. האלגוריתם מפצל בלוקים לגדלים שהם חזקות של 2, וכאשר בלוק משתחרר, הוא בודק את ה'שכן' שלו (buddy) ואם גם הוא פנוי, הם מאוחדים לבלוק גדול יותר. מנגנון זה נועד במיוחד להתמודד עם פיצול חיצוני על ידי איחוד שטחים פנויים.\n\nאפשרויות אחרות:\nב. אלגוריתם Free List עם בלוקים בגודל קבוע הוא פשוט ויעיל אך אינו מציאותי לטיפול בבקשות בגדלים משתנים, והוא סובל מפיצול פנימי אם גודל הבקשה קטן מגודל הבלוק. הוא אינו מיועד לאיחוד בלוקים פנויים בגדלים שונים לצורך יצירת בלוקים גדולים יותר.\nג. אלגוריתם Free List עם בלוקים בגודל משתנה מתמודד עם גדלים משתנים, אך חומר ההרצאה מציין במפורש שהוא 'יכול לקרות מצב שחלקנו את מה שיצא למשל יש חלק של 10kb יש חלק של 5kb ואחריו תפוס ואחריו 5kb פנוי. ונניח שהמשתמש מבקש 15kb, אין לזיכרון כנל לתת לו.' זהו תיאור מובהק של פיצול חיצוני, והחומר אינו מפרט מנגנון מובנה ויעיל לאיחוד בלוקים עבורו, אלא רק מציין שהרשימה תהיה 'יותר מורכבת'.\nד. Slab Allocator מיועד להקצאת אובייקטים בגודל קבוע ונפוץ (לרוב עבור אובייקטים של ליבת המערכת) ואינו פתרון כללי לניהול זיכרון משתנה בגדלים שונים או לטיפול בפיצול חיצוני של זיכרון כללי."}, "_source_file": "0072__Virtualization__Memory_Management__MC__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:10:14", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Fragmentation"], "difficulty_estimation": "Easy", "content": {"text": "מהו המצב המתואר כ\"קיטוע פנימי\" (Internal Fragmentation) במערכות הפעלה?", "code_snippet": null, "options": ["א. מצב שבו מערכת ההפעלה מקצה למשתמש יותר זיכרון ממה שהוא ביקש, מה שמוביל לבזבוז.", "ב. מצב שבו יש מספיק זיכרון פנוי בסך הכל, אך הוא מפוזר במקטעים קטנים ולא רציפים, ולכן לא ניתן להקצותו לבקשה גדולה.", "ג. מצב שבו תהליכים ארוכים אינם מקבלים זמן מעבד בגלל הגעת תהליכים קצרים רבים.", "ד. מצב שבו הזיכרון הפיזי מנוצל במלואו, ולא נשאר שום זיכרון פנוי עבור תהליכים חדשים."]}, "solution": {"correct_option": "א", "explanation": "קיטוע פנימי (Internal Fragmentation) מתרחש כאשר מערכת ההפעלה מקצה למשתמש יחידת זיכרון גדולה יותר מהכמות המדויקת שביקש. העודף הלא מנוצל בתוך היחידה המוקצית נחשב לבזבוז. חומר ההרצאה מגדיר זאת במפורש: \"מצב בו אנחנו נותנים למשתמש יותר זיכרון ממה שהוא ביקש. זה בזבוז.\" אפשרות ב' מתארת קיטוע חיצוני, ואפשרויות ג' ו-ד' מתארות מצבים אחרים שאינם קיטוע זיכרון."}, "_source_file": "0073__Virtualization__Fragmentation__MC__Easy.json", "_topic_hint": "Fragmentation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:10:22", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Fragmentation"], "difficulty_estimation": "Easy", "content": {"text": "מהו קיטוע פנימי (internal fragmentation) בהקשר של ניהול זיכרון במערכת הפעלה?", "code_snippet": null, "options": ["א. מצב שבו המערכת מקצה למשתמש יותר זיכרון ממה שביקש בפועל, מה שמוביל לבזבוז.", "ב. מצב שבו יש מספיק זיכרון פנוי לטפל בבקשה מסוימת, אך הוא מפוצל למקטעים קטנים ומרוחקים.", "ג. בעיה המתרחשת כאשר תהליכים ארוכים אינם מקבלים זמן מעבד עקב תהליכים קצרים המגיעים כל הזמן.", "ד. מצב שבו זיכרון פיזי מומר לזיכרון וירטואלי כדי לאפשר ליותר תהליכים לרוץ במקביל."]}, "solution": {"correct_option": "א", "explanation": "האפשרות הנכונה היא א'. על פי חומר ההרצאה, קיטוע פנימי (internal fragmentation) מוגדר כ\"מצב בו אנחנו נותנים למשתמש יותר זיכרון ממה שהוא ביקש. זה בזבוז.\" מצב זה מתרחש כאשר מערכת ההפעלה מקצה בלוק זיכרון גדול יותר מהכמות המדויקת שנדרשה על ידי המשתמש, וכתוצאה מכך חלק מבלוק הזיכרון המוקצה נשאר בלתי מנוצל."}, "_source_file": "0074__Virtualization__Fragmentation__MC__Easy.json", "_topic_hint": "Fragmentation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:10:34", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Fragmentation"], "difficulty_estimation": "Easy", "content": {"text": "מהו קיטוע פנימי (internal fragmentation) בהקשר של ניהול זיכרון, על פי חומר ההרצאה?", "code_snippet": null, "options": ["א. מצב שבו מערכת ההפעלה מקצה למשתמש יותר זיכרון ממה שביקש בפועל.", "ב. מצב שבו קיים מספיק זיכרון פנוי בסך הכל, אך הוא מפוצל למקטעים קטנים ולא רציפים.", "ג. מצב שבו תהליך מסוים אינו מקבל זמן מעבד או משאבים אחרים לתקופה ארוכה.", "ד. פעולה של פיצול בלוק זיכרון פנוי גדול לשני בלוקים קטנים יותר, האחד עבור הבקשה והשני נשאר פנוי."]}, "solution": {"correct_option": "א", "explanation": "קיטוע פנימי (internal fragmentation) מוגדר בחומר ההרצאה כ\"מצב בו אנחנו נותנים למשתמש יותר זיכרון ממה שהוא ביקש. זה בזבוז.\" (Lecture 6, chunk 9 ו-8). אפשרות א' מתארת במדויק הגדרה זו. אפשרות ב' מתארת קיטוע חיצוני (external fragmentation). אפשרות ג' מתארת תופעת הרעבה (starvation) של תהליכים, ואילו אפשרות ד' מתארת פעולת פיצול (split) בניהול זיכרון, שהיא טכניקה ולא סוג של קיטוע פנימי בפני עצמו."}, "_source_file": "0075__Virtualization__Fragmentation__MC__Easy.json", "_topic_hint": "Fragmentation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:10:42", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Fragmentation"], "difficulty_estimation": "Medium", "content": {"text": "מהו המאפיין העיקרי של קיטוע פנימי (internal fragmentation) בניהול זיכרון במערכת הפעלה?", "code_snippet": null, "options": ["א. מצב שבו מערכת ההפעלה מקצה למשתמש יותר זיכרון ממה שהוא ביקש בפועל, מה שמוביל לבזבוז.", "ב. מצב שבו יש מספיק זיכרון פנוי בסך הכל כדי למלא בקשה, אך הוא מפוזר במקטעים לא רציפים ולכן לא ניתן להקצותו.", "ג. מצב שבו תהליכים ארוכי טווח אינם מקבלים זמן מעבד מספיק בגלל הגעת תהליכים קצרים יותר.", "ד. מצב שבו הזיכרון הפיזי קטן משמעותית מהזיכרון הוירטואלי שמערכת ההפעלה מספקת לתהליכים."]}, "solution": {"correct_option": "א", "explanation": "קיטוע פנימי (internal fragmentation) מוגדר במפורש בחומר ההרצאה כמצב שבו 'אנחנו נותנים למשתמש יותר זיכרון ממה שהוא ביקש. זה בזבוז.' (הרצאה 6, קטע 9, וגם הרצאה 6, קטע 8). אפשרות א' מתארת בדיוק מצב זה. אפשרות ב' מתארת קיטוע חיצוני (external fragmentation), כפי שמוסבר בהרצאה 9, קטע 2 ובהרצאה 5, קטע 30. אפשרות ג' מתייחסת לבעיית הרעבה (starvation), כפי שמוסבר בהרצאה 9, קטע 2. אפשרות ד' מתארת את עקרון הכללי של וירטואליזציה של זיכרון, אך לא את המאפיין הספציפי של קיטוע פנימי."}, "_source_file": "0076__Virtualization__Fragmentation__MC__Medium.json", "_topic_hint": "Fragmentation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:10:58", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Fragmentation"], "difficulty_estimation": "Medium", "content": {"text": "איזו מהטענות הבאות מתארת נכונה סוג של קיטוע זיכרון (fragmentation) כפי שהוגדר בחומר ההרצאה?", "code_snippet": null, "options": ["א. קיטוע פנימי (internal fragmentation) מתרחש כאשר מערכת ההפעלה מקצה למשתמש יותר זיכרון ממה שביקש בפועל.", "ב. קיטוע חיצוני (external fragmentation) מתרחש כאשר כל הזיכרון הפנוי בוטל לחלוטין ואין אפשרות להקצות זיכרון נוסף.", "ג. בדפדוף (paging) קיימת בעיה מובנית של קיטוע חיצוני (external fragmentation).", "ד. פעולת ה-coalesce משמשת לפיצול בלוק זיכרון גדול לשני בלוקים קטנים יותר."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר ההרצאה מגדיר במפורש 'internal fragmentation' כמצב בו 'אנחנו נותנים למשתמש יותר זיכרון ממה שהוא ביקש. זה בזבוז.' (הרצאה 6, קטע 9). \n\nאפשרויות אחרות אינן נכונות: \nב. זוהי אינה ההגדרה של קיטוע חיצוני. קיטוע חיצוני מתאר מצב בו יש מספיק זיכרון פנוי בסך הכל, אך הוא מפוזר במקטעים קטנים שאינם רציפים, כך שלא ניתן לספק בקשה לבלוק גדול ורציף (הרצאה 9, קטע 2; הרצאה 5, קטע 30).\nג. חומר ההרצאה קובע במפורש כי הטענה שבדפדוף יש בעיה של קיטוע חיצוני 'לא נכונה' (הרצאה 9, קטע 2).\nד. פעולת ה-coalesce משמשת לאיחוד שטחי זיכרון סמוכים פנויים לשטח אחד גדול יותר, בעוד שפיצול בלוק זיכרון מתבצע באמצעות פעולת split (הרצאה 5, קטע 32)."}, "_source_file": "0077__Virtualization__Fragmentation__MC__Medium.json", "_topic_hint": "Fragmentation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:11:10", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Fragmentation"], "difficulty_estimation": "Medium", "content": {"text": "מהו המאפיין העיקרי של קיטוע חיצוני (external fragmentation) בניהול זיכרון?", "code_snippet": null, "options": ["א. קיים מספיק זיכרון פנוי בסך הכל כדי למלא בקשה, אך הוא מפוזר במקטעים קטנים ולא רציפים.", "ב. מערכת ההפעלה מקצה לתהליך יותר זיכרון ממה שהוא ביקש בפועל.", "ג. זיכרון מתבזבז בגלל שתהליך ממתין למשאב ואינו יכול להשתמש בזיכרון שהוקצה לו.", "ד. סך הזיכרון הפיזי הזמין קטן מסך הזיכרון הווירטואלי המבוקש על ידי כל התהליכים יחד."]}, "solution": {"correct_option": "א", "explanation": "קיטוע חיצוני (external fragmentation) מתאר מצב שבו יש מספיק זיכרון פנוי בסך הכל כדי למלא בקשת הקצאה מסוימת, אך זיכרון זה אינו זמין כבלוק רציף אחד אלא מפוזר במקטעים קטנים ולא סמוכים. כפי שצויין בחומר ההרצאה, 'קיטוע חיצוני קורה כאשר יש לנו שטח מסוים של זיכרון שאנחנו מנהלים וכל מיני קטעים בו תפוסים בצורה כזו שנשאר לנו זיכרון פנוי אבל לא מספיק, למשל עבור הקצאה גדולה שרוצה הרבה זיכרון אבל אנחנו לא יכולים לספק אותה למרות שסך כל הזיכרון כן מספיק, זה קורה בגלל שהזיכרון הפנוי שלנו קטוע ומחולק לכל מיני מקטעים קטנים כך שיש לנו הרבה זיכרון פנוי אבל כל חלק הוא קטן מדי'.\nאפשרות ב' מתארת קיטוע פנימי (internal fragmentation), שבו המערכת מקצה יותר זיכרון ממה שהמשתמש ביקש. אפשרויות ג' ו-ד' אינן מתארות קיטוע זיכרון באופן ישיר."}, "_source_file": "0078__Virtualization__Fragmentation__MC__Medium.json", "_topic_hint": "Fragmentation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:11:20", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Fragmentation"], "difficulty_estimation": "Hard", "content": {"text": "נתון כי מערכת הפעלה משתמשת בוירטואליזציה של הזיכרון כדי לאפשר למספר רב של תהליכים, שלכל אחד מהם מוקצה מרחב כתובות וירטואלי גדול (למשל 4GB), לרוץ בו-זמנית על זיכרון פיזי מוגבל (למשל 8GB). איזו טענה לגבי בעיות קיטוע (fragmentation) במערכת כזו היא הנכונה ביותר לפי חומר ההרצאה?", "code_snippet": null, "options": ["א. קיטוע פנימי (internal fragmentation) הוא בעיה בלתי נמנעת עקב הקצאת זיכרון ביחידות בגודל קבוע, בעוד שקיטוע חיצוני (external fragmentation) נמנע במידה רבה תודות ליכולת של הזיכרון הווירטואלי למפות דפים פיזיים לא רציפים למרחב כתובות וירטואלי רציף.", "ב. קיטוע חיצוני (external fragmentation) הוא הבעיה העיקרית, שכן ריבוי תהליכים המשתמשים בזיכרון וירטואלי גורם ליצירת 'חורים' רבים בזיכרון הפיזי שקשה לאחד אותם.", "ג. קיטוע פנימי (internal fragmentation) וגם קיטוע חיצוני (external fragmentation) אינם מהווים בעיה משמעותית בזיכרון וירטואלי, מכיוון שמערכת ההפעלה יכולה לאחד (coalesce) שטחי זיכרון פנויים באופן דינמי.", "ד. הבעיה המרכזית אינה קיטוע אלא הרעבה (starvation) של תהליכים ארוכים, מכיוון שהזיכרון הווירטואלי נותן עדיפות לתהליכים קצרים יותר."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה, קיטוע פנימי (internal fragmentation) מתרחש כאשר 'אנחנו נותנים למשתמש יותר זיכרון ממה שהוא ביקש. זה בזבוז.' בזיכרון וירטואלי, הממומש לרוב באמצעות דפדוף (paging), זיכרון מוקצה ביחידות בגודל קבוע (דפים). אם תהליך זקוק לפחות מזיכרון של דף שלם, יתרת הדף מבוזבזת, וזהו קיטוע פנימי. לעומת זאת, חומר ההרצאה קובע במפורש כי 'טענה: בדפדוף יש בעיה של קיטוע חיצוני (external fragmentation). הטענה לא נכונה.' הסיבה לכך היא שוירטואליזציית הזיכרון מאפשרת למפות דפים פיזיים שאינם רציפים לתוך מרחב כתובות וירטואלי רציף עבור התהליך, ובכך נמנעת הבעיה של זיכרון פנוי מפוצל שאינו מספיק לבקשה גדולה למרות שסך הזיכרון הפנוי מספיק. אפשרויות ב', ג' ו-ד' אינן נכונות: ב' סותרת ישירות את הנאמר לגבי קיטוע חיצוני בדפדוף; ג' שגויה משום שקיטוע פנימי אכן קיים בזיכרון וירטואלי, ו'איחוד' (coalesce) רלוונטי יותר לניהול בלוקים בגודל משתנה ולא לטיפול בקיטוע חיצוני בזיכרון וירטואלי; ו-ד' מתייחסת לבעיית הרעבה (starvation), שהיא בעיית תזמון מעבדים ולא בעיית קיטוע זיכרון."}, "_source_file": "0079__Virtualization__Fragmentation__MC__Hard.json", "_topic_hint": "Fragmentation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:11:40", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Fragmentation"], "difficulty_estimation": "Hard", "content": {"text": "בהתחשב בתפקידה של וירטואליזציית הזיכרון, ובפרט מנגנון הדפדוף (paging), בניהול זיכרון המערכת, איזו מהטענות הבאות מתארת נכונה את סוגי הקיטוע (fragmentation) שעלולים להיווצר או להימנע?", "code_snippet": null, "options": ["א. וירטואליזציית הזיכרון באמצעות דפדוף פותרת לחלוטין את בעיית הקיטוע החיצוני אך עלולה להציג קיטוע פנימי, כיוון שתהליכים מקבלים דפי זיכרון בגודל קבוע גם אם אינם מנצלים את כולם.", "ב. וירטואליזציית הזיכרון באמצעות דפדוף פותרת לחלוטין את בעיית הקיטוע הפנימי, אך מחמירה את בעיית הקיטוע החיצוני עקב הצורך בניהול טבלת דפים מורכבת.", "ג. וירטואליזציית הזיכרון אינה משפיעה על סוגי הקיטוע, שכן קיטוע הוא תמיד בעיה של הזיכרון הפיזי בלבד, ללא קשר לאופן שבו מערכת ההפעלה מציגה אותו לתהליכים.", "ד. וירטואליזציית הזיכרון באמצעות דפדוף גורמת הן לקיטוע פנימי והן לקיטוע חיצוני, שכן היא מחלקת את הזיכרון למקטעים קטנים רבים."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר ההרצאה מציין במפורש כי \"טענה: בדפדוף יש בעיה של קיטוע חיצוני (external fragmentation). הטענה לא נכונה.\" כלומר, מנגנון הדפדוף (paging), שהוא ליבת וירטואליזציית הזיכרון, מונע קיטוע חיצוני. הסיבה לכך היא שהזיכרון הפיזי מחולק למסגרות (frames) בגודל קבוע, וניתן להקצות כל מסגרת פנויה לכל דף וירטואלי, ללא צורך ברצף פיזי. לעומת זאת, חומר ההרצאה מגדיר קיטוע פנימי כ\"מצב בו אנחנו נותנים למשתמש יותר זיכרון ממה שהוא ביקש. זה בזבוז.\" בדפדוף, תהליכים מקבלים יחידות זיכרון בגודל קבוע (דפים). אם תהליך זקוק לזיכרון שאינו כפולה מדויקת של גודל הדף, הדף האחרון שהוקצה לו לא ינוצל במלואו, מה שמוביל לקיטוע פנימי."}, "_source_file": "0080__Virtualization__Fragmentation__MC__Hard.json", "_topic_hint": "Fragmentation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:11:58", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Fragmentation"], "difficulty_estimation": "Hard", "content": {"text": "וירטואליזציית זיכרון מאפשרת לתהליכים להאמין כי עומד לרשותם מרחב כתובות רציף וגדול, גם כאשר הזיכרון הפיזי מפוצל. בהתחשב בכך ששיטת הדפדוף (paging), המהווה מימוש נפוץ לוירטואליזציה זו, אינה סובלת מקיטוע חיצוני כפי שצויין בחומר הלימוד, איזה סוג של קיטוע נחשב ל*פשרה* או *תוצאה אופיינית* של ניהול זיכרון המבוסס על יחידות הקצאה בגודל קבוע (כדוגמת דפים) במערכות מודרניות?", "code_snippet": null, "options": ["א. קיטוע פנימי (Internal fragmentation), מכיוון שיחידות הקצאה בגודל קבוע (כמו דפים) מובילות לעיתים קרובות לחלל לא מנוצל בתוך הבלוק המוקצה האחרון של תהליך.", "ב. קיטוע חיצוני (External fragmentation), מכיוון שהזיכרון הפיזי מתפזר לאורך זמן, מה שמקשה על מציאת בלוקים רציפים גדולים.", "ג. אף סוג של קיטוע, שכן וירטואליזציית הזיכרון מבטלת לחלוטין את בעיות הקיטוע.", "ד. גם קיטוע פנימי וגם קיטוע חיצוני, מכיוון שוירטואליזציה רק מסווה את בעיית הקיטוע, אך אינה פותרת אותה מהיסוד."]}, "solution": {"correct_option": "א", "explanation": "החומר מציין במפורש כי \"בדפדוף יש בעיה של קיטוע חיצוני (external fragmentation). הטענה לא נכונה.\" (Lecture 9, chunk 2). משמעות הדבר היא שדפדוף, כמימוש נפוץ של וירטואליזציית זיכרון המשתמש ביחידות בגודל קבוע (דפים), פותר את בעיית הקיטוע החיצוני. עם זאת, החומר מגדיר קיטוע פנימי כ\"מצב בו אנחנו נותנים למשתמש יותר זיכרון ממה שהוא ביקש. זה בזבוז.\" (Lecture 6, chunk 9). כאשר מערכת ההפעלה מקצה זיכרון לתהליך באמצעות דפים בגודל קבוע, ייתכן שהחלק האחרון של הזיכרון המוקצה לא ינוצל במלואו, מכיוון שגודל הנתונים של התהליך אינו בהכרח כפולה מדויקת של גודל הדף. שטח לא מנוצל זה בתוך הדף האחרון מהווה קיטוע פנימי, וזוהי פשרה אופיינית בשיטות ניהול זיכרון המבוססות על הקצאה ביחידות קבועות."}, "_source_file": "0081__Virtualization__Fragmentation__MC__Hard.json", "_topic_hint": "Fragmentation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:12:17", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Virtual Memory"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, כיצד נקראת יחידת הזיכרון אליה מחולק הזיכרון הוירטואלי של תהליך לחלקים שווים?", "code_snippet": null, "options": ["א. דף (Page)", "ב. מסגרת (Page Frame)", "ג. סגמנט (Segment)", "ד. שטח כתובות (Address Space)"]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מציין במפורש: \"לוקחים את הזיכרון הוירטואלי של התהליך ומחלקים אותו לחלקים שווים. לכל חלק אנחנו קוראים **דף**.\" (Lecture 6, chunk 25 ו-26). 'מסגרת' (Page Frame) היא יחידה בזיכרון הפיזי, 'סגמנט' אינו היחידה שבה מתבצעת חלוקה שווה של הזיכרון הוירטואלי לפי החומר, ו'שטח כתובות' הוא מרחב הזיכרון הכולל, לא היחידה הקטנה אליה הוא מחולק."}, "_source_file": "0082__Virtualization__Virtual_Memory__MC__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:12:26", "_subject": "Virtualization", "_context_lectures": [6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Virtual Memory"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של וירטואליזציית זיכרון (Virtual Memory) במערכת הפעלה?", "code_snippet": null, "options": ["א. לאפשר לכל תהליך גישה למרחב זיכרון גדול יותר ממה שקיים פיזית במחשב.", "ב. לפשט את ניהול הזיכרון על ידי שימוש במנגנון base&bounds.", "ג. להבטיח שכל 4GB של זיכרון וירטואלי לתהליך יהיו תמיד טעונים בזיכרון הפיזי (RAM).", "ד. למנוע גישה בלתי מורשית לדיסק הקשיח על ידי תהליכים."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, וירטואליזציית זיכרון נועדה לאפשר למערכת ההפעלה לספק לכל תהליך '4GB של זיכרון' (chunk 10), למרות ש'בפועל אין לנו מספיק זיכרון לכך'. הזיכרון הוירטואלי הוא 'זיכרון שלא באמת קיים' פיזית במלואו, אלא ממופה לזיכרון פיזי ולעיתים אף לדיסק הקשיח. כך, תהליכים יכולים לפעול כאילו יש להם מרחב כתובות גדול מאוד מבלי לדרוש את כל המשאבים הפיזיים בו זמנית. תשובה ב' אינה נכונה מכיוון ש'אין לנו בכלל base&bounds' בווירטואליזציית זיכרון (chunk 25). תשובה ג' אינה נכונה משום ש'רוב התהליכים לא משתמשים ביותר מ-1GB ולכן לא צריך להחזיק את כל השטח הזה בזיכרון אם לא משתמשים בו' ו'חלק מהזיכרון של התהליכים מופנה להארד-דיסק' (chunk 10). תשובה ד' אינה נכונה מכיוון שהמטרה העיקרית היא לא מניעת גישה לדיסק הקשיח, אלא ניהול זיכרון יעיל המשתמש גם בדיסק הקשיח."}, "_source_file": "0083__Virtualization__Virtual_Memory__MC__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:12:36", "_subject": "Virtualization", "_context_lectures": [6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Virtual Memory"], "difficulty_estimation": "Easy", "content": {"text": "על פי החומר הנלמד, באיזו יחידה בסיסית מערכת ההפעלה מחלקת את מרחב הכתובות הווירטואלי של תהליך?", "code_snippet": null, "options": ["א. סגמנטים", "ב. בלוקים", "ג. דפים", "ד. מסגרות"]}, "solution": {"correct_option": "ג", "explanation": "החומר הנלמד מציין במפורש כי מערכת ההפעלה לוקחת את הזיכרון הוירטואלי של התהליך ומחלקת אותו לחלקים שווים, ולכל חלק כזה אנו קוראים 'דף'. 'מסגרת' היא יחידת חלוקה של הזיכרון הפיזי, ולא של הזיכרון הוירטואלי. 'סגמנטים' מתייחסים לשיטת ניהול זיכרון שאינה בשימוש בזיכרון וירטואלי המבוסס על דפים (כפי שצוין שאין יותר base&bounds). 'בלוקים' הוא מונח כללי ואינו היחידה הספציפית לחלוקת הזיכרון הוירטואלי."}, "_source_file": "0084__Virtualization__Virtual_Memory__MC__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:12:46", "_subject": "Virtualization", "_context_lectures": [6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Virtual Memory"], "difficulty_estimation": "Medium", "content": {"text": "במערכת הפעלה המשתמשת בזיכרון וירטואלי, מהו תפקידו העיקרי של רכיב ה-MMU (Memory Management Unit) ואיזה מבנה נתונים הוא מנצל לביצוע תפקיד זה?", "code_snippet": null, "options": ["א. ה-MMU אחראי לתרגום כתובות וירטואליות לכתובות פיזיות, והוא נעזר ב\"טבלת הדפים\" (Page Table) של התהליך לצורך כך.", "ב. ה-MMU אחראי להקצות 4GB של זיכרון פיזי לכל תהליך, והוא משתמש ברגיסטרי base&bounds כדי לוודא גישה חוקית.", "ג. ה-MMU אחראי לניהול הדיסק הקשיח כהרחבה לזיכרון הפיזי, והוא משתמש במבנה נתונים ייעודי לניהול קבצים.", "ד. ה-MMU אחראי לחלוקת הזיכרון הפיזי לדפים שווים בגודלם, והוא שומר את המידע הזה ב-kernel."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה, ה-MMU (Memory Management Unit) הוא רכיב חומרה שתפקידו לקבל כתובת וירטואלית ולתרגם אותה לכתובת פיזית (chunk 14). לצורך תרגום זה, ה-MMU נעזר ב\"טבלת הדפים\" (Page Table), שהיא מבנה נתונים הנשמר עבור כל תהליך ב-kernel ומכיל את המיפויים בין דפים וירטואליים למסגרות פיזיות (chunk 28). אפשרויות ב', ג' ו-ד' מתארות תפקידים שאינם התפקיד העיקרי של ה-MMU או שהן שגויות בפרטים לגבי אופן פעולת הזיכרון הווירטואלי (למשל, ביטול השימוש ב-base&bounds בזיכרון וירטואלי, chunk 25)."}, "_source_file": "0085__Virtualization__Virtual_Memory__MC__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:12:58", "_subject": "Virtualization", "_context_lectures": [6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Virtual Memory"], "difficulty_estimation": "Medium", "content": {"text": "מהי הסיבה העיקרית לשימוש במנגנון הזיכרון הוירטואלי על ידי מערכת ההפעלה, וכיצד היא מאפשרת זאת לכל תהליך?", "code_snippet": null, "options": ["א. לאפשר לכל תהליך לקבל מרחב כתובות גדול ועצמאי (לדוגמה, 4GB) גם כשיש פחות זיכרון פיזי זמין, על ידי חלוקת הזיכרון הוירטואלי לדפים ושימוש בטבלאות מיפוי לזיכרון הפיזי.", "ב. לייעל את השימוש בזיכרון הפיזי על ידי אחסון כל הנתונים החשובים בכונן הקשיח (הארד-דיסק) בלבד, ובכך לפנות את ה-RAM לשימושים אחרים של מערכת ההפעלה.", "ג. להחליף את מנגנון ה-base&bounds במנגנון המאפשר לתהליכים לגשת ישירות לכל הזיכרון הפיזי במערכת ללא צורך בתרגום כתובות.", "ד. לאבטח את הזיכרון על ידי מניעת גישה של תהליכים למרחבי זיכרון של תהליכים אחרים, אך רק כאשר כל הזיכרון הוירטואלי של התהליך נמצא במלואו בזיכרון הפיזי."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. הזיכרון הוירטואלי מאפשר למערכת ההפעלה לספק לכל תהליך מרחב כתובות גדול ועצמאי (לדוגמה, 4GB), גם אם בפועל אין מספיק זיכרון פיזי זמין לכל התהליכים יחד. כפי שצוין בחומר ההרצאה: \"אנחנו כביכול מספקים לכל תהליך 4GB של זיכרון כשבפועל אין לנו מספיק זיכרון לכך. הדבר נעשה ע\"י וירטואליזציה של הזיכרון\". מערכת ההפעלה משיגה זאת על ידי חלוקת מרחב הכתובות הוירטואלי של התהליך לחלקים שווים הנקראים \"דפים\", וחלוקת הזיכרון הפיזי ל\"מסגרות דפים\" (כפי שמתואר ב\"לוקחים את הזיכרון הוירטואלי של התהליך ומחלקים אותו לחלקים שווים. לכל חלק אנחנו קוראים דף\"). היא מחזיקה \"טבלאות דפים\" (mappings) הממפות כתובות וירטואליות לכתובות פיזיות (\"מערכת ההפעלה מחזיקה מיפויים\"). רכיב ה-MMU משתמש בטבלאות אלו לתרגום כתובות בזמן אמת. תשובה ב' שגויה מכיוון שאף על פי שהארד-דיסק משמש כמקום אחסון נוסף (swapping), מטרת הזיכרון הוירטואלי אינה לאחסן *את כל* הנתונים החשובים שם או לפנות RAM לשימושים אחרים באופן בלעדי. תשובה ג' שגויה כי הזיכרון הוירטואלי אכן מחליף את מנגנון ה-base&bounds, אך הוא דורש תרגום כתובות על ידי ה-MMU ואינו מאפשר גישה ישירה לזיכרון הפיזי. תשובה ד' שגויה חלקית: הזיכרון הוירטואלי אכן מספק בידוד ואבטחה בין תהליכים, אך הוא עושה זאת ללא קשר לשאלה אם כל הזיכרון הוירטואלי של התהליך נמצא במלואו בזיכרון הפיזי או שחלקו נמצא בהארד-דיסק."}, "_source_file": "0086__Virtualization__Virtual_Memory__MC__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:13:16", "_subject": "Virtualization", "_context_lectures": [6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Virtual Memory"], "difficulty_estimation": "Hard", "content": {"text": "מערכת ההפעלה מממשת זיכרון וירטואלי כדי לספק לכל תהליך אשליה של מרחב כתובות רציף וגדול (לדוגמה, 4GB), אף שבפועל הזיכרון הפיזי מוגבל ומפוצל, וחלקים ממרחב הכתובות הוירטואלי כלל אינם קיימים בזיכרון הפיזי או נמצאים על דיסק. בהקשר זה, מהו התפקיד המהותי ביותר של **טבלת הדפים** (Page Table) בשיתוף עם ה-**MMU**, המאפשר למערכת ההפעלה לנהל ביעילות את המשאב הפיזי המוגבל ולהגן על תהליכים זה מזה?", "code_snippet": null, "options": ["א. טבלת הדפים מאפשרת ל-MMU לתרגם כל כתובת וירטואלית לכתובת פיזית מדויקת, ללא צורך שהדפים הוירטואליים יהיו רציפים בזיכרון הפיזי, ובכך מונעת גישה בלתי חוקית של תהליך אחד לזיכרון של תהליך אחר.", "ב. טבלת הדפים משמשת בעיקר לאחסון קוד התהליך והמחסנית שלו, ומאפשרת ל-MMU לאתר אותם במהירות כאשר התהליך מופעל, ובכך משפרת את מהירות הטעינה של תהליכים חדשים.", "ג. טבלת הדפים מאפשרת למערכת ההפעלה להגדיל את נפח הזיכרון הפיזי הזמין על ידי שימוש בדיסק הקשיח כהרחבה ישירה של ה-RAM, ללא כל תלות ב-MMU.", "ד. טבלת הדפים מבטיחה שכל 4GB הווירטואליים של תהליך יוקצו באופן רציף בזיכרון הפיזי ברגע שהתהליך נטען, תוך שימוש ב-base&bounds כדי לאכוף גבולות אלו."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'.\n\n**הסבר עבור א' (נכון):** החומר המצוין בשיעור מסביר כי זיכרון וירטואלי מחלק את מרחב הכתובות של תהליך ל'דפים' (pages) ואת הזיכרון הפיזי ל'מסגרות' (page frames). טבלת הדפים היא מבנה נתונים לכל תהליך, הנשמרת בקרנל, ותפקידה העיקרי הוא למפות דפים וירטואליים למסגרות פיזיות. ה-MMU (Memory Management Unit) הוא רכיב חומרה המשתמש בטבלת הדפים כדי לתרגם כתובת וירטואלית לכתובת פיזית. יכולת המיפוי הזו מאפשרת לדפים וירטואליים להיות מפוזרים באופן לא רציף בזיכרון הפיזי, ובכך מנוצלים ביעילות מקטעי זיכרון פנויים קטנים. יתרה מכך, ה-MMU בודק חוקיות גישה (לדוגמה, אם תהליך ניגש לכתובת שאסור לו), ומייצר שגיאה במקרה של גישה בלתי חוקית, ובכך מספק הגנה בין תהליכים שונים.\n\n**הסבר עבור ב' (לא נכון):** החומר מציין במפורש ש\"לא מעניין את מערכת ההפעלה אם זה קוד/מחסנית/ערימה\" בהקשר של חלוקת הזיכרון לדפים. טבלת הדפים ממפה כל חלק ממרחב הכתובות הווירטואלי (ללא קשר לסוגו) לזיכרון הפיזי. תפקידה העיקרי אינו שיפור מהירות טעינה ספציפית, אלא ניהול תרגום כתובות והגנה.\n\n**הסבר עבור ג' (לא נכון):** אכן, מערכת ההפעלה יכולה להשתמש בדיסק הקשיח כמקום אחסון נוסף לדפים (swapping/paging), אך היא אינה מגדילה את נפח הזיכרון הפיזי (RAM), אלא יוצרת אשליה של זיכרון גדול יותר. יתרה מכך, תרגום כתובות לדפים שנמצאים על הדיסק עדיין מתבצע באמצעות ה-MMU (שמייצר Page Fault כאשר הדף אינו ב-RAM), כך שאינה פועלת \"ללא כל תלות ב-MMU\".\n\n**הסבר עבור ד' (לא נכון):** החומר מציין במפורש ש\"עכשיו אין לנו בכלל base&bounds\" וכי הזיכרון הווירטואלי מתחלק לדפים שאינם בהכרח רציפים בזיכרון הפיזי. המטרה של זיכרון וירטואלי היא בדיוק לאפשר הקצאה לא רציפה בזיכרון הפיזי וכן לא לטעון את כל 4GB של תהליך בבת אחת אם אינם בשימוש."}, "_source_file": "0088__Virtualization__Virtual_Memory__MC__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:13:47", "_subject": "Virtualization", "_context_lectures": [6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Virtual Memory"], "difficulty_estimation": "Hard", "content": {"text": "תהליך מנסה לגשת לכתובת זיכרון וירטואלית מסוימת. רכיב ה-MMU (Memory Management Unit) ניגש לטבלת הדפים של התהליך כדי לבצע את התרגום הנדרש, ומגלה שהדף הוירטואלי המכיל את הכתובת אינו ממופה כרגע למסגרת פיזית בזיכרון הראשי (RAM), אלא נמצא על הדיסק הקשיח (או אינו טעון כלל). מהי התוצאה המיידית של גילוי זה על ידי ה-MMU וכיצד מערכת ההפעלה צפויה לטפל במצב זה?", "code_snippet": null, "options": ["א. ה-MMU יפעיל פסיקת \"כשל דף\" (Page Fault), ומערכת ההפעלה תטפל בפסיקה על ידי טעינת הדף מהדיסק הקשיח למסגרת פנויה בזיכרון הפיזי, ועדכון טבלת הדפים.", "ב. ה-MMU ינסה לתרגם ישירות את הכתובת הווירטואלית לכתובת פיזית על הדיסק הקשיח, ויבצע גישה ישירה לדיסק כדי לאחזר את הנתונים.", "ג. התהליך יופסק באופן מיידי על ידי מערכת ההפעלה עקב ניסיון גישה בלתי חוקית לזיכרון.", "ד. מערכת ההפעלה תקצה לתהליך מרחב זיכרון וירטואלי חדש בגודל 4GB ותעתיק אליו את הנתונים הקיימים של התהליך."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. תפקידו העיקרי של ה-MMU הוא לתרגם כתובות וירטואליות לכתובות פיזיות בעזרת טבלת הדפים של התהליך. כאשר ה-MMU מגלה שטבלת הדפים מצביעה על כך שהדף הוירטואלי אינו טעון כרגע בזיכרון הפיזי (RAM) – מצב המכונה \"כשל דף\" (Page Fault) – הוא אינו מבצע גישה ישירה לדיסק. במקום זאת, ה-MMU מפעיל פסיקה (interrupt) המכונה \"כשל דף\". מערכת ההפעלה, כחלק מטיפול בפסיקה זו, לוקחת אחריות על טעינת הדף הנדרש מהדיסק הקשיח (שבו הוא מאוחסן, כפי שמצוין בחומר הלימוד כי \"חלק מהזיכרון של התהליכים מופנה להארד-דיסק\") למסגרת פיזית פנויה ב-RAM. לאחר הטעינה, מערכת ההפעלה מעדכנת את טבלת הדפים של התהליך כך שתשקף את המיקום הפיזי החדש של הדף, ואז מאפשרת לתהליך להמשיך בביצוע הפקודה שגרמה לכשל הדף. אפשרות ב' שגויה מכיוון שה-MMU הוא רכיב חומרה המטפל בתרגום כתובות ל-RAM ואינו מבצע פעולות קלט/פלט ישירות לדיסק. אפשרות ג' שגויה מכיוון שגישה זו אינה \"בלתי חוקית\"; היא כתובת וירטואלית לגיטימית שהתהליך רשאי לגשת אליה, אך היא פשוט אינה זמינה כרגע ב-RAM. אפשרות ד' שגויה מכיוון שמרחב הכתובות הוירטואלי של התהליך הוא קבוע, והבעיה אינה יצירת מרחב חדש אלא מיפוי דפים קיימים לזיכרון הפיזי."}, "_source_file": "0089__Virtualization__Virtual_Memory__MC__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:14:01", "_subject": "Virtualization", "_context_lectures": [6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Virtual Memory"], "difficulty_estimation": "Hard", "content": {"text": "בהינתן שתהליכים מרובים פועלים בו-זמנית, וכל אחד מהם רואה מרחב זיכרון וירטואלי של 4GB, בעוד שהזיכרון הפיזי הכולל במערכת מוגבל בהרבה, מהו התפקיד התיאורטי המהותי של טבלת הדפים (Page Table) הייעודית לכל תהליך, מעבר לתרגום כתובות גרידא, המאפשר למערכת ההפעלה לקיים אשליה זו ולנהל את משאבי הזיכרון ביעילות?", "code_snippet": null, "options": ["א. טבלת הדפים מספקת מיפוי גמיש בין דפים וירטואליים שאינם בהכרח רציפים לבין מסגרות פיזיות שאינן בהכרח רציפות (או למיקומי דיסק), ובכך מאפשרת למערכת ההפעלה לנהל פיצול זיכרון וניצול יתר, ולשמר את אשליית מרחב כתובות גדול, ייעודי ורציף לכל תהליך.", "ב. טבלת הדפים אוכפת הגנת זיכרון בכך שהיא מבטיחה שכל תהליך יוכל לגשת רק למרחב הווירטואלי שלו בגודל 4GB.", "ג. טבלת הדפים משרתת בעיקר אופטימיזציה של מהירות גישה לזיכרון על ידי שמירת תרגומי כתובות וירטואליות-לפיזיות ב-MMU.", "ד. טבלת הדפים מבטלת את הצורך בזיכרון פיזי על ידי מיפוי כל הכתובות הווירטואליות ישירות לדיסק הקשיח."]}, "solution": {"correct_option": "א", "explanation": "האפשרות הנכונה היא א'. החומר המצויין בשיעור מדגיש כי זיכרון וירטואלי הוא אשליה (\"זיכרון שלא באמת קיים\") שבה כל תהליך חושב שיש לו 4GB, בעוד שהזיכרון הפיזי מוגבל. מערכת ההפעלה מנהלת זאת באמצעות \"מיפויים\" (Lecture 6, chunk 10). זיכרון וירטואלי מחולק ל\"דפים\" וזיכרון פיזי ל\"מסגרות\" (Lecture 6, chunk 26). טבלת הדפים, הייעודית לכל תהליך, היא מבנה הנתונים השומר את המיפויים הללו (Lecture 6, chunk 28). תפקידה המהותי הוא לאפשר מיפוי גמיש של דפים וירטואליים למסגרות פיזיות שאינן חייבות להיות רציפות, או אפילו לדיסק הקשיח (\"חלק מהזיכרון של התהליכים מופנה להארד-דיסק\", \"יכול גם להיות שתהליך בכלל לא יהיה בשום מקום\") (Lecture 6, chunk 10), ובכך לטפל בפיצול זיכרון ולאפשר ניצול יתר (oversubscription) של הזיכרון הפיזי. זהו המנגנון המרכזי המאפשר את אשליית מרחב הכתובות הגדול, הייעודי והרציף לכל תהליך.\n\nאפשרות ב' אינה התפקיד התיאורטי המהותי ביותר בהקשר לשאלה. הגנת זיכרון היא תוצאה חשובה של מנגנון הזיכרון הווירטואלי וה-MMU (Lecture 6, chunk 14), אך המיפוי הגמיש הוא זה שמאפשר מלכתחילה את האשליה של 4GB לכל תהליך על זיכרון פיזי מוגבל.\n\nאפשרות ג' מתארת למעשה את תפקידו של ה-TLB (Translation Lookaside Buffer), שהוא מטמון בתוך ה-MMU, ולא את התפקיד העיקרי של טבלת הדפים עצמה בהקשר של יצירת האשליה וניהול משאבים.\n\nאפשרות ד' שגויה לחלוטין. החומר מציין ש\"חלק מהזיכרון של התהליכים מופנה להארד-דיסק\" (Lecture 6, chunk 10), לא כולו, וכי ה-RAM הפיזי עדיין קיים ומשמש (Lecture 6, chunk 28). הדיסק הקשיח משמש כהרחבה או אזור החלפה (swap space), לא כתחליף מלא לזיכרון הפיזי."}, "_source_file": "0090__Virtualization__Virtual_Memory__MC__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:14:22", "_subject": "Virtualization", "_context_lectures": [6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Paging"], "difficulty_estimation": "Easy", "content": {"text": "מהו תפקידו העיקרי של ה-MMU (Memory Management Unit) בתהליך הדפדוף?", "code_snippet": null, "options": ["א. תרגום כתובת וירטואלית לכתובת פיזית.", "ב. קביעת גודל הדף בזיכרון הווירטואלי.", "ג. ניהול מזהי התהליכים (PIDs) במערכת ההפעלה.", "ד. שמירת קוד התהליכים בזיכרון הפיזי."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, ה-MMU הוא הרכיב העיקרי שעוזר בתהליך התרגום מכתובת וירטואלית לכתובת פיזית. הוא לוקח כתובת וירטואלית (המחולקת למספר דף והיסט), משתמש במספר הדף כדי למצוא את מספר המסגרת המתאים בטבלת הדפים, ומשלב אותו עם ההיסט ליצירת הכתובת הפיזית. שאר האפשרויות אינן מתארות את תפקידו העיקרי של ה-MMU."}, "_source_file": "0091__Virtualization__Paging__MC__Easy.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:14:30", "_subject": "Virtualization", "_context_lectures": [4, 5, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Paging"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, מהו תפקידו העיקרי של רכיב ה-MMU בתהליך הדפדוף?", "code_snippet": null, "options": ["א. תרגום כתובות וירטואליות לכתובות פיזיות.", "ב. קביעת מספר הביטים לכתובת וירטואלית.", "ג. אחסון טבלת הדפים של כל תהליך בזיכרון.", "ד. פיצול טבלת הדפים לחלקים בגודל דף."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, ה-MMU הוא הרכיב העיקרי המסייע בתהליך תרגום הכתובות. ההרצאה מציינת במפורש: 'הרכיב שעוזר לנו בתהליך התרגום הוא ה-MMU שמתבצע המרה מכתובת וירטואלית לכתובת פיזית שבה הנתונים הרצויים נמצאים.' תפקידו של ה-MMU הוא לקחת את מספר הדף הווירטואלי, לפנות איתו לטבלת הדפים ולקבל ממנה את מספר המסגרת המתאים (PFN), ובכך להשלים את הכתובת הפיזית יחד עם ההיסט."}, "_source_file": "0092__Virtualization__Paging__MC__Easy.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:14:41", "_subject": "Virtualization", "_context_lectures": [4, 5, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Paging"], "difficulty_estimation": "Easy", "content": {"text": "מהו התפקיד העיקרי של יחידת ניהול הזיכרון (MMU) בתהליך הדפדוף?", "code_snippet": null, "options": ["א. לבצע המרה מכתובת וירטואלית לכתובת פיזית.", "ב. לנהל את מזהי התהליכים (PIDs) במערכת.", "ג. לאחסן את טבלת הדפים של התהליך בזיכרון.", "ד. לקבוע את גודל מרחב הכתובות הוירטואלי של תהליך."]}, "solution": {"correct_option": "א", "explanation": "ההסבר הנכון הוא שאחד מתפקידיו העיקריים של ה-MMU (Memory Management Unit) הוא לתרגם כתובות וירטואליות לכתובות פיזיות. כפי שמצוין בחומר ההרצאה, \"הרכיב שעוזר לנו בתהליך התרגום הוא ה-**mmu** שמתבצע המרה מכתובת וירטואלית לכתובת פיזית שבה הנתונים הרצויים נמצאים.\" ה-MMU משתמש בטבלת הדפים של התהליך כדי למצוא את המסגרת הפיזית המתאימה לדף הוירטואלי, אך תפקידו המרכזי הוא ביצוע התרגום עצמו."}, "_source_file": "0093__Virtualization__Paging__MC__Easy.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:14:51", "_subject": "Virtualization", "_context_lectures": [4, 5, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Paging"], "difficulty_estimation": "Medium", "content": {"text": "מהו התפקיד העיקרי של יחידת ניהול הזיכרון (MMU) בתהליך תרגום כתובת וירטואלית לכתובת פיזית, על בסיס טבלת הדפים של תהליך?", "code_snippet": null, "options": ["א. ה-MMU מפרק את הכתובת הוירטואלית למספר דף וירטואלי (VPN) ולהיסט. את ההיסט הוא מעביר כפי שהוא, ואת ה-VPN הוא מנצל כדי לאתר בטבלת הדפים את מספר המסגרת הפיזית (PFN) המתאימה.", "ב. ה-MMU משתמש בכתובת הוירטואלית כולה כדי לחשב ישירות את הכתובת הפיזית, ללא צורך בטבלת דפים.", "ג. ה-MMU משתמש בהיסט כדי למצוא את מספר הדף הוירטואלי, ורק לאחר מכן פונה לטבלת הדפים כדי לקבל את הכתובת הפיזית המלאה.", "ד. ה-MMU אחראי רק על הקצאת דפים חדשים לזיכרון הפיזי, ואינו מעורב בתהליך תרגום כתובות קיים."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה, ה-MMU הוא הרכיב שמבצע את ההמרה מכתובת וירטואלית לכתובת פיזית. הוא עושה זאת על ידי פירוק הכתובת הוירטואלית לשני חלקים: מספר הדף הוירטואלי (VPN) וההיסט (Offset). ההיסט נשאר ללא שינוי (מתורגם כמו שהוא), בעוד שמספר הדף הוירטואלי משמש כאינדקס לטבלת הדפים של התהליך. מטבלת הדפים, ה-MMU מאחזר את רשומת הדף (PTE) המתאימה, ומתוכה הוא משיג את מספר המסגרת הפיזית (PFN). שילוב ה-PFN עם ההיסט יוצר את הכתובת הפיזית הסופית. האפשרויות האחרות אינן מתארות נכונה את מנגנון התרגום כפי שתואר בחומר."}, "_source_file": "0094__Virtualization__Paging__MC__Medium.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:15:04", "_subject": "Virtualization", "_context_lectures": [4, 5, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Paging"], "difficulty_estimation": "Medium", "content": {"text": "מהו התפקיד המרכזי של ה-MMU (Memory Management Unit) בתהליך תרגום כתובת וירטואלית לכתובת פיזית במערכת הפעלה המשתמשת בדפדוף (paging)?", "code_snippet": null, "options": ["א. ה-MMU מפרק את הכתובת הוירטואלית למספר דף וירטואלי (VPN) ולהיסט, ומשתמש במספר הדף הוירטואלי כדי לאתר בטבלת הדפים את מספר המסגרת הפיזית (PFN), תוך השארת ההיסט ללא שינוי.", "ב. ה-MMU משתמש בכתובת הוירטואלית כולה כדי לחפש ישירות בזיכרון הפיזי ללא צורך בטבלת דפים.", "ג. ה-MMU אחראי על הקצאת זיכרון וירטואלי לתהליכים חדשים ועל ניהול ה-PID שלהם בלבד.", "ד. ה-MMU משנה הן את מספר הדף הוירטואלי והן את ההיסט על מנת ליצור כתובת פיזית חדשה לחלוטין."]}, "solution": {"correct_option": "א", "explanation": "ההסבר הנכון הוא א'. על פי חומר ההרצאה, ה-MMU הוא הרכיב שמבצע את ההמרה מכתובת וירטואלית לכתובת פיזית. הוא עושה זאת על ידי פירוק הכתובת הוירטואלית לשני חלקים: מספר הדף הוירטואלי (VPN) וההיסט (Offset). ההיסט נשאר ללא שינוי בתהליך התרגום (\"ההיסט מתורגם כמו שהוא\"), בעוד שמספר הדף הוירטואלי משמש כאינדקס לטבלת הדפים של התהליך. מטבלת הדפים, ה-MMU משיג את מספר המסגרת הפיזית (PFN) המתאים לדף הוירטואלי. ה-PFN יחד עם ההיסט הבלתי משונה יוצרים יחד את הכתובת הפיזית הסופית בזיכרון."}, "_source_file": "0095__Virtualization__Paging__MC__Medium.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:15:15", "_subject": "Virtualization", "_context_lectures": [4, 5, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Paging"], "difficulty_estimation": "Medium", "content": {"text": "איזה מהתיאורים הבאים מתאר בצורה המדויקת ביותר את תפקיד ה-MMU בתהליך תרגום כתובת וירטואלית לכתובת פיזית במערכת הפעלה המשתמשת בדפדוף (paging)?", "code_snippet": null, "options": ["א. ה-MMU מחלק את הכתובת הווירטואלית למספר דף וירטואלי (VPN) ולהיסט. ההיסט נשאר ללא שינוי ומשמש כהיסט בכתובת הפיזית, בעוד שמספר הדף הווירטואלי משמש לאיתור רשומת טבלת הדפים (PTE) המתאימה, ממנה מופק מספר המסגרת הפיזית (PFN) ליצירת הכתובת הפיזית הסופית.", "ב. ה-MMU משתמש בכתובת הווירטואלית כולה כאינדקס לטבלת דפים אחת גדולה, אשר מכילה מיפוי ישיר מכל כתובת וירטואלית ספציפית לכתובת פיזית מקבילה.", "ג. ה-MMU אחראי רק על שמירת טבלת הדפים בזיכרון, בעוד שתרגום הכתובות בפועל מבוצע על ידי המעבד באמצעות חישוב מתמטי המבוסס על גודל הדף.", "ד. ה-MMU מחלק את הכתובת הווירטואלית למספר דף וירטואלי ולהיסט, ולאחר מכן מחליף את שניהם במספר מסגרת פיזית חדש המתקבל מטבלת הדפים."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. לפי חומר ההרצאה, ה-MMU הוא הרכיב שמבצע את ההמרה מכתובת וירטואלית לכתובת פיזית. הוא עושה זאת על ידי חלוקת הכתובת הווירטואלית לשני חלקים: מספר דף וירטואלי (VPN) והיסט (offset). ההיסט מתורגם 'כמו שהוא' (כלומר נשאר זהה בכתובת הפיזית) ומשולב עם מספר המסגרת הפיזית. מספר הדף הווירטואלי (VPN) משמש את ה-MMU לפנות לטבלת הדפים של התהליך. מטבלת הדפים, ברשומת הדף המתאימה (PTE), מופק מספר המסגרת הפיזית (PFN). לבסוף, ה-PFN משולב עם ההיסט כדי ליצור את הכתובת הפיזית המלאה. אפשרויות ב', ג' ו-ד' מתארות תהליכים שגויים או תפקידים שאינם של ה-MMU כפי שתוארו בחומר ההרצאה."}, "_source_file": "0096__Virtualization__Paging__MC__Medium.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:15:28", "_subject": "Virtualization", "_context_lectures": [4, 5, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Paging"], "difficulty_estimation": "Hard", "content": {"text": "מדוע טבלת דפים ליניארית (Linear Page Table) נחשבת לפתרון לא מעשי במערכות הפעלה מודרניות, גם כאשר תהליכים רבים מנצלים רק חלק קטן ממרחב הכתובות הוירטואלי העצום שלהם?", "code_snippet": null, "options": ["א. ה-MMU אינו יכול לאנדקס ביעילות טבלת דפים ליניארית גדולה בשל מגבלות חומרה בתהליך התרגום עצמו.", "ב. עלות ההחלפה בין הקשרים (Context Switching) בין תהליכים הופכת לגבוהה מדי, מכיוון שנדרש לטעון מחדש טבלאות דפים ענקיות.", "ג. טבלת דפים ליניארית דורשת הקצאת בלוק זיכרון פיזי רציף גדול עבור טבלת הדפים של כל תהליך, ללא קשר לניצול הזיכרון הוירטואלי בפועל, מה שמוביל לבזבוז משמעותי של זיכרון פיזי.", "ד. רשומות טבלת הדפים (PTEs) עצמן צורכות כוח עיבוד רב מדי מהמעבד במהלך תרגום הכתובות עקב מורכבותן."]}, "solution": {"correct_option": "ג", "explanation": "הבעיה המרכזית בטבלת דפים ליניארית, כפי שנדון בחומר השיעור, היא גודלה. במערכת 32 ביט, מרחב הכתובות הוירטואלי הוא 4GB. אם גודל הדף הוא, לדוגמה, 4KB (2^12 בתים), אזי קיימים 2^20 דפים וירטואליים. אם כל רשומת טבלת דפים (PTE) דורשת, נניח, 4 בתים, אזי טבלת דפים ליניארית מלאה תתפוס 2^20 * 4 בתים = 4MB של זיכרון פיזי. זיכרון זה, בסך 4MB, חייב להיות מוקצה עבור טבלת הדפים של *כל* תהליך, ללא קשר לשאלה האם התהליך מנצל בפועל את כל 4GB ממרחב הכתובות הוירטואלי שלו. רוב התהליכים מנצלים רק חלק קטן מהזיכרון הוירטואלי הפוטנציאלי שלהם. לכן, טבלת דפים ליניארית תוביל לבזבוז עצום של זיכרון פיזי לצורך אחסון טבלאות דפים שרובן ריקות (מכילות רשומות לא תקפות עבור דפים וירטואליים שאינם בשימוש). זו הסיבה שההרצאה מציינת שהיא 'לא בשימוש'."}, "_source_file": "0097__Virtualization__Paging__MC__Hard.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:15:43", "_subject": "Virtualization", "_context_lectures": [4, 5, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Paging"], "difficulty_estimation": "Hard", "content": {"text": "למרות שטבלת דפים ליניארית נחשבת לגרסה בסיסית ונוחה, מדוע היא אינה נמצאת בשימוש במערכות הפעלה סטנדרטיות כיום, כפי שמרמז חומר ההרצאה?", "code_snippet": null, "options": ["א. צריכת זיכרון גבוהה מדי לאחסון טבלת הדפים עצמה, במיוחד במרחבי כתובות וירטואליים גדולים.", "ב. מורכבות יתרה ביישום רכיב ה-MMU לתרגום כתובות באמצעותה.", "ג. חוסר יכולת לתמוך בריבוי תהליכים בעלי טבלאות דפים נפרדות.", "ד. קושי בטיפול בהיסט כתובת (offset) בתוך הדף."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מציין שטבלת דפים ליניארית \"אינה בשימוש\" מיד לפני שהוא מתחיל לדון בחישוב כמות הזיכרון שטבלה כזו תופסת במערכת סטנדרטית של 32 ביט עם מרחב כתובות וירטואלי של 4GB. הקישור בין שתי האמירות הללו מרמז שהסיבה העיקרית לאי-השימוש בטבלאות דפים ליניאריות היא צריכת זיכרון גבוהה מדי עבור אחסון טבלת הדפים עצמה, במיוחד כאשר מרחב הכתובות הוירטואלי גדול (כמו 4GB במערכת 32 ביט). האפשרויות האחרות אינן נתמכות בחומר ההרצאה: ה-MMU מתואר כמנגנון פשוט יחסית לתרגום כתובות, החומר מציין שלכל תהליך יש טבלת דפים משלו, וההיסט מתורגם ישירות ללא שינוי."}, "_source_file": "0098__Virtualization__Paging__MC__Hard.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:15:59", "_subject": "Virtualization", "_context_lectures": [4, 5, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Paging"], "difficulty_estimation": "Hard", "content": {"text": "במערכת הפעלה 32 ביט, המשתמשת במרחב כתובות וירטואלי של 4GB, נניח שגודל דף הוא 4KB. בהתחשב בכך שכל רשומת טבלת דפים (PTE) דורשת 4 בתים לאחסון, מהו גודלה הכולל של טבלת דפים ליניארית עבור תהליך בודד?", "code_snippet": null, "options": ["א. 1MB", "ב. 4MB", "ג. 16MB", "ד. 256MB"]}, "solution": {"correct_option": "ב", "explanation": "התשובה הנכונה היא ב'.\nכדי לחשב את גודלה הכולל של טבלת דפים ליניארית, עלינו לדעת כמה דפים וירטואליים קיימים ומה גודל כל רשומת טבלת דפים (PTE).\n\n1.  **חישוב מספר הדפים הוירטואליים:**\n    *   מרחב הכתובות הוירטואלי הכולל הוא 4GB, שזה 2^32 בתים (כפי שצוין בחומר הלימוד: \"מחשב 32 ביט- זה אומר שמרחב הכתובות שלו הוא 32 ביטים כלומר כל כתובת וירטואלית היא 32 ביטים, כלומר 4GB\").\n    *   גודל דף הוא 4KB, שזה 2^12 בתים.\n    *   מספר הדפים הוירטואליים = מרחב כתובות כולל / גודל דף = 2^32 בתים / 2^12 בתים = 2^(32-12) = 2^20 דפים.\n    *   (חומר הלימוד מציין ש\"לאיזה מספר דף הוא ניגש... כמות הביטים שיש בכתובת הוירטואלית תלויה במרחב הכתובות של התהליך\" ו\"ההיסט תלוי בגודל הדף – מספר הביטים לייצוג ההיסט הוא לוג 2 של גודל הדף\", מה שמאפשר לחשב את מספר הדפים הווירטואליים על ידי חלוקת מרחב הכתובות הכולל בגודל הדף).\n\n2.  **חישוב גודל טבלת הדפים:**\n    *   גודל כל רשומת טבלת דפים (PTE) נתון כ-4 בתים.\n    *   גודל טבלת הדפים הליניארית הכולל = מספר הדפים הוירטואליים * גודל כל רשומת PTE = 2^20 דפים * 4 בתים/לרשומה = 2^20 * 2^2 בתים = 2^22 בתים.\n    *   2^22 בתים שווה ל-4 מגה-בתים (4MB), שכן 2^20 בתים הם 1MB.\n    *   (חומר הלימוד מזכיר ש\"טבלת דפים ליניארית... יש בה את כל הרשומות ששייכות לתהליך כלשהו והן יושבות ברצף\" ו\"אם נחשב כמה זיכרון תופסת טבלת דפים ליניארית כזו (גם טבלת הדפים צריכה מקום בו היא תאוחסן)\").\n\nלכן, גודלה הכולל של טבלת דפים ליניארית עבור תהליך בודד במקרה זה הוא 4MB."}, "_source_file": "0099__Virtualization__Paging__MC__Hard.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:16:20", "_subject": "Virtualization", "_context_lectures": [4, 5, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Page Tables"], "difficulty_estimation": "Easy", "content": {"text": "מהי הסיבה העיקרית לשימוש בטבלת דפים רב-שכבתית (Multi-Level Page Table) במערכות הפעלה?", "code_snippet": null, "options": ["א. לחסוך בזיכרון פיזי על ידי אי הקצאת רשומות עבור חלקי מרחב כתובות וירטואליים שאינם בשימוש.", "ב. להאיץ את תהליך תרגום הכתובות הוירטואליות לכתובות פיזיות.", "ג. לאפשר שימוש במרחב כתובות וירטואלי גדול יותר ממה שמתאפשר עם טבלת דפים שטוחה.", "ד. לפשט את עבודת יחידת ניהול הזיכרון (MMU)."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מציין כי 'רוב התהליכים לא משתמשים בכל הזיכרון של מרחב הכתובות שלהם' וכי הרעיון הוא 'נציא את כל השטח האפור, נצמצם אותו לפחות רשומות'. כמו כן, נכתב במפורש 'Entire page of entries invalid? Don't allocate it'. כל אלה מצביעים על כך שהמטרה העיקרית של טבלת דפים רב-שכבתית היא לחסוך בזיכרון פיזי על ידי אי-הקצאה של טבלאות דפים שלמות עבור חלקי מרחב כתובות וירטואליים שאינם בשימוש. אפשרות ב' אינה נכונה, מכיוון שטבלאות רב-שכבתיות לרוב מוסיפות צעדי גישה לזיכרון ובכך מאטות את התרגום. אפשרות ג' אינה הסיבה העיקרית, למרות שהיא מאפשרת ניהול יעיל יותר של מרחבי כתובות גדולים. אפשרות ד' אינה נכונה, שכן ה-MMU הופך להיות היררכי ומורכב יותר, כפי שמצוין בטקסט: 'ה-mmu שלנו נהיה היררכי'."}, "_source_file": "0100__Virtualization__Page_Tables__MC__Easy.json", "_topic_hint": "Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:16:31", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Page Tables"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של שימוש בטבלת דפים היררכית (Multi-Level Page Table) במערכות הפעלה?", "code_snippet": null, "options": ["א. לחסוך בזיכרון פיזי על ידי אי-הקצאת טבלאות דפים עבור חלקים לא בשימוש במרחב הכתובות הוירטואלי.", "ב. להגדיל את מהירות הגישה לזיכרון על ידי צמצום מספר הגישות לטבלת הדפים.", "ג. לאפשר לתהליכים לגשת לזיכרון פיזי גדול יותר ממה שזמין במערכת.", "ד. לפשט את תהליך תרגום הכתובות עבור יחידת ניהול הזיכרון (MMU)."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מציין כי רוב טבלת הדפים אינה בשימוש עבור תהליכים רבים, וכי רעיון טבלת דפים היררכית (Multi-Level Page Table) הוא 'לצמצם אותו לפחות רשומות' ו'אם דף שלם של רשומות אינו חוקי? אל תקצה אותו'. המטרה העיקרית היא לחסוך בזיכרון פיזי על ידי כך שהמערכת לא מקצה מקום בזיכרון לטבלאות דפים עבור אזורים במרחב הכתובות הוירטואלי של התהליך שאינם בשימוש. אפשרויות ב' ו-ד' אינן נכונות מכיוון שטבלאות דפים היררכיות דווקא מגדילות את מספר הגישות לזיכרון לצורך תרגום כתובות ומסבכות את תהליך התרגום עבור ה-MMU. אפשרות ג' מתארת את הרעיון הכללי של זיכרון וירטואלי, אך לא את היתרון הספציפי של טבלת דפים היררכית."}, "_source_file": "0101__Virtualization__Page_Tables__MC__Easy.json", "_topic_hint": "Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:16:41", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Page Tables"], "difficulty_estimation": "Easy", "content": {"text": "מהי הסיבה העיקרית לשימוש בטבלת דפים רב-שכבתית (Multi-Level Page Table) במערכות הפעלה?", "code_snippet": null, "options": ["א. כדי לחסוך בזיכרון פיזי המשמש לאחסון טבלת הדפים עצמה.", "ב. כדי להאיץ את תהליך תרגום הכתובות הוירטואליות לכתובות פיזיות.", "ג. כדי לאפשר לתהליכים לגשת ליותר זיכרון וירטואלי ממה שקיים בזיכרון הפיזי.", "ד. כדי לפשט את המימוש של החלפת הקשר (Context Switching) בין תהליכים."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין בשיעור מדגיש כי רוב התהליכים אינם משתמשים בכל מרחב הכתובות הוירטואלי שלהם, מה שמוביל לכך שחלקים נרחבים מטבלת הדפים אינם בשימוש (ה'שטח האפור'). הרעיון של טבלת דפים רב-שכבתית (Multi-Level Page Table) נועד לטפל בבעיה זו על ידי צמצום מספר הרשומות והימנעות מהקצאת זיכרון פיזי לחלקי טבלת דפים שאינם רלוונטיים או אינם בשימוש. על ידי פיצול טבלת הדפים ליחידות בגודל דף ומעקב אחריהן באמצעות 'page directory', ניתן להימנע מהקצאת דף שלם של רשומות אם הוא אינו חוקי או אינו בשימוש, ובכך לחסוך משמעותית בזיכרון הפיזי שנדרש לטבלת הדפים עצמה."}, "_source_file": "0102__Virtualization__Page_Tables__MC__Easy.json", "_topic_hint": "Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:16:50", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Page Tables"], "difficulty_estimation": "Medium", "content": {"text": "מהו היתרון המרכזי של שימוש בטבלת דפים רב-שכבתית (Multi-Level Page Table) בהשוואה לטבלת דפים חד-שכבתית?", "code_snippet": null, "options": ["א. הפחתה משמעותית של כמות הזיכרון הפיזי הנדרשת לאחסון טבלאות הדפים, במיוחד עבור תהליכים שאינם מנצלים את כל מרחב הכתובות הוירטואלי שלהם.", "ב. האצת תהליך תרגום הכתובות הוירטואליות לכתובות פיזיות על ידי ה-MMU.", "ג. פישוט מנגנון ניהול הזיכרון במערכת ההפעלה.", "ד. הגדלה של כמות הדפים הפיזיים (physical frames) הזמינים במערכת."]}, "solution": {"correct_option": "א", "explanation": "טבלת דפים חד-שכבתית דורשת הקצאת רשומות לכל מרחב הכתובות הוירטואלי של תהליך, גם אם חלקים גדולים ממנו אינם בשימוש (השטחים ה'אפורים' המוזכרים בחומר הלימוד). הדבר מוביל לבזבוז משמעותי של זיכרון פיזי. טבלת דפים רב-שכבתית, המאורגנת במבנה דמוי עץ וכוללת Page Directory, מאפשרת למערכת ההפעלה לא להקצות דפים שלמים של רשומות טבלאות דפים עבור אזורים לא מנוצלים במרחב הכתובות הוירטואלי. כפי שנאמר בחומר: 'אם דף שלם של רשומות אינו חוקי, אין צורך להקצות אותו'. יתרון זה מוביל לחיסכון ניכר בזיכרון הפיזי הנדרש לניהול טבלאות הדפים. אפשרות ב' אינה נכונה מכיוון שטבלת דפים רב-שכבתית בדרך כלל דורשת יותר גישות לזיכרון (עבור ה-Page Directory ולאחר מכן עבור ה-Page Table עצמו), מה שעלול להאט את תהליך התרגום. אפשרויות ג' ו-ד' אינן נכונות מכיוון שהן אינן היתרון המרכזי או שהן שגויות במהותן."}, "_source_file": "0103__Virtualization__Page_Tables__MC__Medium.json", "_topic_hint": "Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:17:06", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Page Tables"], "difficulty_estimation": "Medium", "content": {"text": "מהו היתרון העיקרי של שימוש בטבלת דפים היררכית (Multi-Level Page Table) בהשוואה לטבלת דפים ברמה אחת?", "code_snippet": null, "options": ["א. הקטנת צריכת הזיכרון הפיזי הנדרש לאחסון טבלאות הדפים, על ידי אי הקצאת רשומות לאזורים לא מנוצלים במרחב הכתובות הוירטואלי.", "ב. פישוט לוגיקת תרגום הכתובות של יחידת ניהול הזיכרון (MMU).", "ג. שיפור קצב הפגיעות (hit rate) במטמון ה-TLB.", "ד. אפשרות לניהול מרחבי כתובות וירטואליים גדולים יותר באופן ישיר ויעיל."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין בשיעור מדגיש כי רוב התהליכים אינם מנצלים את כל מרחב הכתובות הוירטואלי שלהם, מה שמוביל לשטחים 'אפורים' (דפים לא בשימוש) בטבלת הדפים. הרעיון המרכזי מאחורי טבלת דפים היררכית (Multi-Level Page Table) הוא 'להוציא את כל השטח האפור, לצמצם אותו לפחות רשומות' ו'אם דף שלם של רשומות אינו חוקי, אל תקצה אותו'. בכך, היתרון העיקרי הוא חיסכון משמעותי בזיכרון הפיזי הנדרש לאחסון טבלאות הדפים, על ידי כך שלא מקצים זיכרון לחלקי טבלת דפים המכסים אזורים לא מנוצלים במרחב הכתובות הוירטואלי."}, "_source_file": "0104__Virtualization__Page_Tables__MC__Medium.json", "_topic_hint": "Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:17:19", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Page Tables"], "difficulty_estimation": "Medium", "content": {"text": "מהי הסיבה העיקרית לשימוש בטבלת דפים היררכית (Multi-Level Page Table) במערכות הפעלה מודרניות?", "code_snippet": null, "options": ["א. כדי להפחית את מספר הגישות לזיכרון הפיזי במהלך תרגום כתובות.", "ב. כדי לאפשר שימוש בדפים בגדלים שונים עבור אזורים שונים במרחב הכתובות הוירטואלי.", "ג. כדי לחסוך בזיכרון פיזי על ידי אי-הקצאת טבלאות דפים שלמות (או חלקים מהן) עבור אזורים ריקים או לא מנוצלים במרחב הכתובות הוירטואלי של התהליך.", "ד. כדי להגביל את גודל מרחב הכתובות הוירטואלי שכל תהליך יכול להשתמש בו."]}, "solution": {"correct_option": "ג", "explanation": "ההסבר: טבלאות דפים היררכיות (Multi-Level Page Tables) נועדו לטפל בבעיה שבה רוב מרחב הכתובות הוירטואלי של תהליך אינו בשימוש, כפי שצוין בחומר הלימוד: \"רוב התהליכים לא משתמשים בכל הזיכרון של מרחב הכתובות שלהם. רעיון: נציא את כל השטח האפור, נצמצם אותו לפחות רשומות\". במקום להקצות רשומות טבלה לכל כתובת וירטואלית אפשרית (גם אם אינה בשימוש), המבנה ההיררכי מאפשר ל-Page Directory להצביע רק לחלקי טבלת הדפים הרלוונטיים. אם אזור שלם במרחב הכתובות הוירטואלי אינו בשימוש (כלומר, \"Entire page of entries invalid?\"), אין צורך להקצות את טבלת הדפים המלאה עבורו בזיכרון הפיזי (\"Don't allocate it\"), ובכך נחסך זיכרון רב."}, "_source_file": "0105__Virtualization__Page_Tables__MC__Medium.json", "_topic_hint": "Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:17:30", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Page Tables"], "difficulty_estimation": "Hard", "content": {"text": "על פי החומר הנלמד, מהי ההשלכה המרכזית והמורכבת ביותר של מעבר מטבלת דפים ברמה אחת (Single-Level Page Table) למבנה טבלת דפים רב-שכבתית (Multi-Level Page Table), בהתחשב הן בניהול הזיכרון והן בתהליך תרגום הכתובות?", "code_snippet": null, "options": ["א. חיסכון משמעותי בזיכרון פיזי עבור מרחבי כתובות דלילים (sparse), אך עלייה במספר הגישות לזיכרון הפיזי הדרושות לתרגום כל כתובת וירטואלית לכתובת פיזית.", "ב. הגדלה קבועה של צריכת הזיכרון הפיזי עבור טבלאות הדפים, תוך הפחתה במספר הגישות לזיכרון הפיזי הנדרשות לתרגום כתובות.", "ג. אין שינוי מהותי בצריכת הזיכרון הפיזי, אך שיפור משמעותי במהירות תרגום הכתובות בשל מבנה הנתונים דמוי העץ.", "ד. פישוט תהליך תרגום הכתובות ב-MMU והפחתת זמן השהיה, תוך שמירה על רמת זיכרון פיזי דומה לטבלה ברמה אחת."]}, "solution": {"correct_option": "א", "explanation": "החומר המציין כי \"רוב התהליכים לא משתמשים בכל הזיכרון של מרחב הכתובות שלהם\" וכי הרעיון הוא \"נציא את כל השטח האפור, נצמצם אותו לפחות רשומות\" וכן \"Entire page of entries invalid? Don't allocate it\" מדגיש את החיסכון בזיכרון פיזי עבור מרחבי כתובות דלילים (sparse address spaces) על ידי אי-הקצאה של דפים לא בשימוש בטבלת הדפים. יחד עם זאת, ההסבר על ה-MMU שנהיה היררכי (\"לוקח מספר מסוים לרמה הראשונה, מספר אחר לרמה השנייה וכן הלאה\") ועל הצורך לגשת לזיכרון כדי למצוא את הדף הספציפי, מצביע בבירור על כך שתרגום כתובת וירטואלית לכתובת פיזית דורש כעת מספר גישות לזיכרון הפיזי (לדוגמה, גישה לספריית הדפים ואז לטבלת הדפים עצמה), מה שמגדיל את זמן השהיה (latency). לכן, אופציה א' מתארת נכונה את הטרייד-אוף המרכזי של מבנה טבלת דפים רב-שכבתית."}, "_source_file": "0106__Virtualization__Page_Tables__MC__Hard.json", "_topic_hint": "Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:17:46", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Page Tables"], "difficulty_estimation": "Hard", "content": {"text": "בהקשר של טבלאות דפים היררכיות (Multi-Level Page Tables), חומר ההרצאה מציין שגם לאחר הפיכת טבלת הדפים למבנה עץ ושימוש ב-Page Directory, ה-Page Directory עצמו עלול להיות 'עצום' ולתפוס שטח זיכרון רב (למשל, 128 דפים). איזו אסטרטגיה מוצעת בחומר ההרצאה כדי להמשיך ולצמצם את צריכת הזיכרון עבור מבנה טבלת הדפים במקרה זה?", "code_snippet": null, "options": ["א. הקטנת גודל הדף הפיזי (page size) כדי לאפשר יותר דפים בזיכרון הפיזי.", "ב. הוספת רמה היררכית נוספת למבנה טבלת הדפים, כלומר יצירת 'מדריך למדריך' (directory to the directory).", "ג. שימוש בטבלאות דפים הפוכות (Inverted Page Tables) במקום טבלאות דפים היררכיות.", "ד. אחסון כל ה-Page Directory בזיכרון מטמון (cache) ייעודי ב-MMU."]}, "solution": {"correct_option": "ב", "explanation": "חומר ההרצאה מציין בפירוש כי למרות שטבלאות דפים היררכיות נועדו לצמצם את שטח הזיכרון הלא מנוצל על ידי אי-הקצאת דפים אפורים, ה-Page Directory עצמו יכול לתפוס שטח רב ('עצום', 'תופס 128 דפים'). כדי לטפל בבעיה זו, מוצעת האפשרות 'Can add a directory to the directory!', כלומר, הוספת רמה היררכית נוספת. גישה זו מאפשרת לצמצם עוד יותר את ההקצאה על ידי אי-הקצאה של חלקים ב-Page Directory עצמו, בדומה לאופן שבו ה-Page Directory המקורי אינו מקצה טבלאות דפים שלמות שאינן בשימוש. אפשרויות אחרות אינן מוזכרות כפתרון לבעיה ספציפית זו בחומר ההרצאה, או שהן אינן פתרון מבני לגודל ה-Page Directory."}, "_source_file": "0108__Virtualization__Page_Tables__MC__Hard.json", "_topic_hint": "Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:18:15", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Multi-level Page Tables"], "difficulty_estimation": "Easy", "content": {"text": "מהו היתרון המרכזי בשימוש בטבלאות דפים היררכיות (Multi-Level Page Tables) בהשוואה לטבלת דפים ברמה אחת?", "code_snippet": null, "options": ["א. חיסכון משמעותי בזיכרון פיזי על ידי אי-הקצאת רשומות טבלה עבור חלקי מרחב הכתובות הוירטואלי שאינם בשימוש.", "ב. האצת זמן הגישה לזיכרון הפיזי עבור כל תרגום כתובת.", "ג. פישוט ארכיטקטורת יחידת ניהול הזיכרון (MMU).", "ד. תמיכה במספר גדול יותר של דפים וירטואליים בכל תהליך."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין בשיעור מסביר כי הרעיון המרכזי מאחורי טבלאות דפים היררכיות (Multi-Level Page Tables) הוא לצמצם את כמות הזיכרון הפיזי הנדרש לטבלאות הדפים עצמן. נאמר במפורש: \"רוב התהליכים לא משתמשים בכל הזיכרון של מרחב הכתובות שלהם. רעיון: נציא את כל השטח האפור, נצמצם אותו לפחות רשומות.\" וכן \"No need to allocate!\" עבור דפים לא תקפים או לא בשימוש. זה מוביל לחיסכון בזיכרון פיזי, ובכך הופך את אפשרות א' לנכונה ביותר."}, "_source_file": "0109__Virtualization__Multi-level_Page_Tables__MC__Easy.json", "_topic_hint": "Multi-level Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:18:25", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Multi-level Page Tables"], "difficulty_estimation": "Easy", "content": {"text": "מהי הסיבה העיקרית לשימוש בטבלאות דפים רב-שכבתיות (Multi-Level Page Tables) במערכות הפעלה?", "code_snippet": null, "options": ["א. חיסכון בזיכרון פיזי על ידי אי-הקצאת דפי טבלה עבור חלקים לא בשימוש של מרחב הכתובות הווירטואלי.", "ב. האצת תהליך תרגום הכתובות מכתובת וירטואלית לפיזית.", "ג. הגדלת גודל מרחב הכתובות הווירטואלי הזמין לכל תהליך.", "ד. פישוט ניהול הזיכרון על ידי ביטול הצורך במטמון TLB."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מציין במפורש כי 'רוב התהליכים לא משתמשים בכל הזיכרון של מרחב הכתובות שלהם. רעיון: נציא את כל השטח האפור, נצמצם אותו לפחות רשומות.' וכן 'Entire page of entries invalid? Don't allocate it'. טבלאות דפים רב-שכבתיות מאפשרות למערכת ההפעלה לא להקצות זיכרון פיזי עבור טבלאות דפים (או חלקים מהן) של אזורים ממרחב הכתובות הווירטואלי שאינם בשימוש, ובכך לחסוך באופן משמעותי בזיכרון. האפשרויות האחרות אינן נכונות: טבלאות רב-שכבתיות דווקא מוסיפות גישות זיכרון בתהליך התרגום (ולכן לא מאיצות), אינן מגדילות את גודל מרחב הכתובות הווירטואלי הכולל, ואינן מבטלות את הצורך ב-TLB (אלא ה-TLB נחוץ יותר כדי למזער את עלות הביצועים שלהן)."}, "_source_file": "0110__Virtualization__Multi-level_Page_Tables__MC__Easy.json", "_topic_hint": "Multi-level Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:18:37", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Multi-level Page Tables"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של שימוש בטבלאות דפים היררכיות (Multi-Level Page Tables) במערכות הפעלה?", "code_snippet": null, "options": ["א. לחסוך בזיכרון על ידי אי-הקצאת רשומות טבלה עבור חלקים לא מנוצלים במרחב הכתובות הוירטואלי.", "ב. להאיץ את תהליך תרגום הכתובות הוירטואליות לכתובות פיזיות.", "ג. לפשט את ניהול הזיכרון עבור תהליכים מרובים הפועלים במקביל.", "ד. לאפשר תמיכה בגדלים גדולים יותר של זיכרון פיזי (RAM)."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מציין במפורש כי המטרה העיקרית של טבלאות דפים היררכיות היא 'לצמצם אותו לפחות רשומות' ו'לא להקצות' דפים שלמים של רשומות אם הם לא בשימוש (שטח אפור). רוב התהליכים אינם משתמשים בכל מרחב הכתובות הוירטואלי שלהם, ולכן טבלאות דפים היררכיות מאפשרות לחסוך בזיכרון על ידי אי-הקצאת טבלאות דפים עבור חלקים לא מנוצלים אלה."}, "_source_file": "0111__Virtualization__Multi-level_Page_Tables__MC__Easy.json", "_topic_hint": "Multi-level Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:18:49", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Multi-level Page Tables"], "difficulty_estimation": "Medium", "content": {"text": "מהו היתרון העיקרי של שימוש במבנה טבלת דפים היררכית (Multi-Level Page Table) בהשוואה לטבלת דפים לינארית (Single-Level Page Table)?", "code_snippet": null, "options": ["א. חיסכון משמעותי בזיכרון פיזי על ידי אי-הקצאת דפים עבור אזורים לא מנוצלים במרחב הכתובות הוירטואלי של תהליך.", "ב. האצת תהליך תרגום הכתובות הוירטואליות לכתובות פיזיות.", "ג. תמיכה במרחבי כתובות וירטואליים גדולים יותר באופן מהותי.", "ד. פישוט המורכבות של יחידת ניהול הזיכרון (MMU)."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין בשיעור מדגיש כי רוב התהליכים אינם מנצלים את כל מרחב הכתובות הוירטואלי שלהם. הרעיון המרכזי מאחורי טבלאות דפים היררכיות הוא \"לצמצם אותו לפחות רשומות\" על ידי אי-הקצאת זיכרון פיזי לדפים שלמים של רשומות בטבלת הדפים שאינן בשימוש. לדוגמה, מצוין \"Entire page of entries invalid? Don't allocate it. No need to allocate!\". לכן, היתרון העיקרי הוא חיסכון משמעותי בזיכרון פיזי. אפשרויות ב' ו-ד' שגויות, שכן תרגום כתובות בדרך כלל איטי יותר (דורש מספר גישות לזיכרון) וה-MMU מורכב יותר. אפשרות ג' היא תוצאה עקיפה של חיסכון בזיכרון, אך היתרון הישיר והמוצהר הוא החיסכון עצמו עבור מרחבי כתובות דלילים."}, "_source_file": "0112__Virtualization__Multi-level_Page_Tables__MC__Medium.json", "_topic_hint": "Multi-level Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:19:00", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Multi-level Page Tables"], "difficulty_estimation": "Medium", "content": {"text": "מהי הסיבה העיקרית שבגללה מערכות הפעלה משתמשות בטבלאות דפים היררכיות (Multi-Level Page Tables)?", "code_snippet": null, "options": ["א. כדי להאיץ את תהליך תרגום הכתובות הוירטואליות לכתובות פיזיות.", "ב. כדי לצמצם את כמות הזיכרון הפיזי הנדרש לאחסון טבלאות הדפים עצמן, במיוחד עבור אזורים לא מנוצלים במרחב הכתובות הוירטואלי.", "ג. כדי לאפשר גמישות רבה יותר בהגדרת גדלי דפים שונים עבור תהליכים שונים.", "ד. כדי לפשט את ארגון הזיכרון הפיזי ולמנוע פיצול חיצוני (external fragmentation)."]}, "solution": {"correct_option": "ב", "explanation": "החומר המצוין מדגיש כי רוב התהליכים אינם משתמשים בכל הזיכרון של מרחב הכתובות הוירטואלי שלהם, וכי הרעיון הוא 'נציא את כל השטח האפור, נצמצם אותו לפחות רשומות'. טבלאות דפים היררכיות, כמו ה-Multi-Level Page Table, נועדו לחסוך בזיכרון על ידי הפיכת טבלת הדפים למבנה דמוי עץ ואי-הקצאה של דפים שלמים של רשומות שאינם בשימוש (כפי שמתואר ב'No need to allocate!'). ה-page directory מכיל מצביעים רק לחלקים הרלוונטיים של טבלת הדפים, ובכך נמנעת הקצאת זיכרון מיותרת."}, "_source_file": "0113__Virtualization__Multi-level_Page_Tables__MC__Medium.json", "_topic_hint": "Multi-level Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:19:12", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Multi-level Page Tables"], "difficulty_estimation": "Medium", "content": {"text": "מהו היתרון העיקרי של שימוש בטבלת דפים רב-שכבתית (Multi-Level Page Table) בהשוואה לטבלת דפים שטוחה (Single-Level Page Table), כפי שמתואר בחומר ההרצאה?", "code_snippet": null, "options": ["א. חיסכון משמעותי בזיכרון פיזי על ידי אי-הקצאה של טבלאות דפים שלמות עבור אזורים לא מנוצלים במרחב הכתובות הוירטואלי.", "ב. הגדלה מהירה יותר של מרחב הכתובות הוירטואלי מעבר למה שניתן להשיג בטבלה שטוחה.", "ג. שיפור ביצועים בתרגום כתובות באמצעות הפחתת מספר הגישות לזיכרון הראשי עבור כל תרגום.", "ד. תמיכה מובנית בזיכרון וירטואלי בגדלים שונים (Variable Page Sizes) ללא צורך במנגנונים נוספים."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מציין במפורש כי רוב התהליכים אינם מנצלים את כל מרחב הכתובות הוירטואלי שלהם. הרעיון המרכזי מאחורי טבלאות דפים רב-שכבתיות הוא \"נצמצם אותו לפחות רשומות\" ו-\"Don't allocate it\" כאשר \"Entire page of entries invalid?\". מבנה זה, המכונה גם \"עץ\" או \"היררכי\", מאפשר למערכת ההפעלה לא להקצות זיכרון פיזי לטבלאות דפים שלמות (או לחלקים מהן) שאינן בשימוש. לדוגמה, אם חלק גדול ממרחב הכתובות אינו ממופה, אין צורך להקצות Page Table עבורו, ורשומת ה-Page Directory המתאימה תצביע על חוסר תוקף. זה מוביל לחיסכון משמעותי בזיכרון פיזי, שהיה מוקצה לטבלאות דפים בגישה שטוחה עבור אזורים אלו."}, "_source_file": "0114__Virtualization__Multi-level_Page_Tables__MC__Medium.json", "_topic_hint": "Multi-level Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:19:26", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Multi-level Page Tables"], "difficulty_estimation": "Hard", "content": {"text": "על אף שמנגנון טבלאות דפים היררכיות (Multi-level Page Tables) נועד לחסוך בזיכרון על ידי אי-הקצאת רשומות דפים שאינן בשימוש, מהו אחד האתגרים המשמעותיים שעדיין נותרים בגישה זו, כפי שמשתמע במפורש מחומר ההרצאה?", "code_snippet": null, "options": ["א. ספריית הדפים (page directory) עצמה עלולה לתפוס נפח זיכרון פיזי גדול מאוד, כפי שצוין שהיא יכולה לתפוס \"128 דפים\" בדוגמה מסוימת.", "ב. תהליך תרגום הכתובת הוירטואלית דורש מספר רב יותר של גישות לזיכרון הפיזי, מה שפוגע בביצועים.", "ג. מורכבות חומרת ה-MMU גדלה באופן דרמטי בשל הצורך לנהל היררכיה של טבלאות.", "ד. פיצול (fragmentation) הזיכרון הפיזי גדל כיוון שטבלאות הדפים מפוזרות על פני דפים שונים ב-RAM."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר ההרצאה מציין במפורש: \"אנחנו חסכנו זיכרון, אבל לא מספיק. נשים לב שה-page directory תופס יותר מדי, הוא תופס 128 דפים.\" הדבר מדגיש כי למרות שמנגנון טבלאות דפים היררכיות חוסך בזיכרון על ידי אי-הקצאת טבלאות דפים שלמות שאינן בשימוש, ספריית הדפים (page directory) עצמה יכולה להיות גדולה מאוד ולצרוך כמות משמעותית של זיכרון פיזי, ובכך להוות עדיין עלות זיכרון משמעותית.\nאפשרויות ב', ג' ו-ד' מתארות בעיות או מאפיינים אפשריים של טבלאות דפים היררכיות, אך הן אינן מודגשות במפורש בחומר ההרצאה כ\"אתגר משמעותי\" הקשור ישירות לחיסכון בזיכרון, באותו אופן שבו הודגשה צריכת הזיכרון של ספריית הדפים עצמה. אפשרות ב' מתארת פגיעה בביצועים ולא עלות זיכרון ישירה של המנגנון. אפשרויות ג' ו-ד' אינן נתמכות במפורש על ידי חומר ההרצאה שסופק."}, "_source_file": "0115__Virtualization__Multi-level_Page_Tables__MC__Hard.json", "_topic_hint": "Multi-level Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:19:42", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Multi-level Page Tables"], "difficulty_estimation": "Hard", "content": {"text": "טבלאות דפים מרובות רמות (Multi-Level Page Tables) תוכננו במטרה לחסוך בזיכרון על ידי הימנעות מהקצאת רשומות עבור אזורים לא בשימוש במרחב הכתובות הוירטואלי של תהליך. עם זאת, איזה היבט, כפי שהודגש בחומר ההרצאה, מהווה אתגר או מגבלה בהקשר של צריכת זיכרון על ידי מבני התרגום עצמם?", "code_snippet": null, "options": ["א. ה-Page Directory עצמו יכול להיות גדול מאוד ולצרוך כמות משמעותית של זיכרון פיזי, למרות החיסכון בדפי טבלאות דפים פנימיים.", "ב. כל רשומה בטבלת הדפים (PTE) דורשת כעת מספר רב יותר של ביטים כדי לייצג כתובת פיזית, מה שמגדיל את גודל הטבלה הכולל.", "ג. הצורך לאחסן מצביעים לדפי טבלאות דפים ב-Page Directory מוביל להכפלה של הזיכרון הנדרש עבור כל דף וירטואלי ממופה.", "ד. מערכת ההפעלה נדרשת לבצע סריקה מתמדת של ה-Page Directory כדי לזהות ולשחרר דפי טבלאות דפים ריקים, מה שיוצר תקורה משמעותית בזיכרון."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר ההרצאה מציין במפורש כי בעוד שטבלאות דפים מרובות רמות נועדו לחסוך בזיכרון על ידי אי-הקצאת דפי טבלאות דפים עבור אזורים לא מנוצלים במרחב הכתובות הוירטואלי ('נציא את כל השטח האפור, נצמצם אותו לפחות רשומות'), ה-Page Directory עצמו עלול להיות גדול מאוד. ההרצאה מציינת: 'אם נסתכל עכשיו על הזיכרון, נראה שה-page directory table שלנו הוא עצום... אנחנו חסכנו זיכרון, אבל לא מספיק. נשים לב שה-page directory תופס יותר מדי, הוא תופס 128 דפים.' זה מדגיש שה-Page Directory עצמו מהווה תקורה בזיכרון, ולמרות שהגישה ההיררכית חוסכת זיכרון באופן כללי, היא אינה מבטלת לחלוטין את צריכת הזיכרון על ידי מבני התרגום."}, "_source_file": "0116__Virtualization__Multi-level_Page_Tables__MC__Hard.json", "_topic_hint": "Multi-level Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:19:57", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Multi-level Page Tables"], "difficulty_estimation": "Hard", "content": {"text": "מהי הסיבה העיקרית לשימוש בטבלאות דפים היררכיות (Multi-Level Page Tables) במערכות הפעלה מודרניות, וכיצד היא מושגת?", "code_snippet": null, "options": ["א. חיסכון בזיכרון פיזי על ידי אי-הקצאת דפי טבלאות דפים עבור חלקים לא מנוצלים במרחב הכתובות הוירטואלי, במיוחד עבור תהליכים שאינם משתמשים בכל הזיכרון שלהם.", "ב. האצת תהליך תרגום הכתובות הוירטואליות לכתובות פיזיות על ידי צמצום מספר הגישות לזיכרון.", "ג. פישוט ניהול הזיכרון הוירטואלי והרחבת מרחב הכתובות הוירטואלי האפשרי לתהליך יחיד.", "ד. שיפור אבטחת המערכת על ידי בידוד מרחבי כתובות של תהליכים שונים ומניעת גישה בלתי מורשית."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. טבלאות דפים היררכיות (Multi-Level Page Tables) הוצגו במטרה לחסוך בזיכרון פיזי המשמש לאחסון טבלאות הדפים עצמן. רוב התהליכים אינם מנצלים את כל מרחב הכתובות הוירטואלי העצום העומד לרשותם. בטבלת דפים ליניארית (שטוחה), יהיה צורך להקצות רשומות לכל דף וירטואלי אפשרי, גם אם אינו בשימוש, מה שמוביל לבזבוז זיכרון משמעותי עבור 'שטחים אפורים' ובלתי מנוצלים. טבלאות דפים היררכיות פותרות זאת על ידי חלוקת טבלת הדפים ליחידות בגודל דף (page-sized units) ושימוש ב'מדריך דפים' (page directory) כדי לעקוב אחריהן. אם דף שלם של רשומות בטבלת הדפים אינו תקף (כלומר, הטווח המקביל במרחב הכתובות הוירטואלי אינו בשימוש), אין צורך להקצות אותו כלל בזיכרון הפיזי. החומר המצוין בפירוש: 'רוב התהליכים לא משתמשים בכל הזיכרון של מרחב הכתובות שלהם. רעיון: נציא את כל השטח האפור, נצמצם אותו לפחות רשומות.' וכן 'Entire page of entries invalid? Don't allocate it. No need to allocate!' מה שמאשש את מטרת החיסכון בזיכרון.\n\nאפשרויות ב', ג', ו-ד' אינן נכונות: \nב. האצת תהליך תרגום הכתובות אינה הסיבה העיקרית. למעשה, טבלאות דפים היררכיות דורשות מספר גישות לזיכרון (לדוגמה, גישה למדריך הדפים ולאחר מכן לטבלת הדפים הספציפית) כדי לבצע תרגום כתובת, מה שעלול להאט את התהליך בהשוואה לטבלה ליניארית ללא מטמון. האצה מושגת בדרך כלל באמצעות TLB (Translation Lookaside Buffer).\nג. בעוד שטבלאות דפים היררכיות מאפשרות תמיכה במרחבי כתובות וירטואליים גדולים בצורה יעילה יותר מבחינת זיכרון, המטרה העיקרית היא חיסכון בזיכרון עבור טבלאות הדפים עצמן. ניהול הזיכרון אינו הופך לפשוט יותר; הוא למעשה מורכב יותר מבחינה מבנית.\nד. שיפור אבטחת המערכת ובידוד תהליכים הם יתרונות בסיסיים של מנגנון הדפדוף (paging) באופן כללי, ולא מאפיין ספציפי או יתרון ייחודי של המבנה ההיררכי של טבלאות הדפים. המבנה ההיררכי מתמקד ביעילות ניהול טבלת הדפים עצמה."}, "_source_file": "0117__Virtualization__Multi-level_Page_Tables__MC__Hard.json", "_topic_hint": "Multi-level Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:20:14", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["TLB"], "difficulty_estimation": "Easy", "content": {"text": "מהי הפעולה הראשונה שמבצע ה-MMU כאשר מתרחשת גישה לזיכרון וירטואלי, בהקשר ל-TLB?", "code_snippet": null, "options": ["א. בודק אם המיפוי לכתובת הוירטואלית קיים ב-TLB.", "ב. ניגש ישירות לטבלת הדפים כדי למצוא את המיפוי לכתובת הפיזית.", "ג. מעדכן את ה-TLB במיפוי חדש שהתגלה בטבלת הדפים.", "ד. יוצר trap למערכת ההפעלה עקב חוסר מיפוי."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, בכל פעם שיש גישה לזיכרון וירטואלי, ה-MMU \"קודם יבדוק את ה-TLB\". רק אם המיפוי לא קיים ב-TLB (כלומר 'miss'), אז הוא יבצע את התהליך הארוך יותר של חיפוש בטבלת הדפים. לכן, הפעולה הראשונה היא תמיד בדיקת ה-TLB."}, "_source_file": "0118__Virtualization__TLB__MC__Easy.json", "_topic_hint": "TLB", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:20:23", "_subject": "Virtualization", "_context_lectures": [8, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["TLB"], "difficulty_estimation": "Easy", "content": {"text": "מהו השלב הראשון בחיפוש כתובת פיזית על ידי ה-MMU כאשר ניגשים לזיכרון וירטואלי?", "code_snippet": null, "options": ["א. ה-MMU ניגש ישירות לטבלת הדפים (Page Table) כדי למצוא את המיפוי.", "ב. ה-MMU בודק תחילה את ה-TLB (Translation Lookaside Buffer) עבור המיפוי הנדרש.", "ג. ה-MMU שולח trap למערכת ההפעלה כדי שהיא תמצא את המיפוי.", "ד. ה-MMU מחשב את ה-PFN (Page Frame Number) ישירות מהכתובת הוירטואלית."]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר ההרצאה, בכל פעם שיש גישה לזיכרון, ה-MMU \"קודם יבדוק את ה-tlb\". ה-TLB הוא רכיב חומרה מהיר במעבד המשמש כמטמון למיפויי כתובות וירטואליות לפיזיות. בדיקתו תחילה מאפשרת קיצור משמעותי בזמן הגישה לזיכרון אם המיפוי כבר קיים בו (TLB hit)."}, "_source_file": "0119__Virtualization__TLB__MC__Easy.json", "_topic_hint": "TLB", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:20:32", "_subject": "Virtualization", "_context_lectures": [8, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["TLB"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של ה-TLB (Translation Lookaside Buffer) במערכת הפעלה?", "code_snippet": null, "options": ["א. לקצר את זמן הגישה לזיכרון הפיזי על ידי שמירת מיפויי כתובות וירטואליות לכתובות פיזיות.", "ב. לאחסן נתונים של דפים שנגשו אליהם לאחרונה מהדיסק.", "ג. לנהל את סדר הגישה לדפים בטבלת הדפים (page table) עבור תהליכים שונים.", "ד. להבטיח שכל הדפים של תהליך מסוים יהיו בזיכרון הפיזי באופן רציף."]}, "solution": {"correct_option": "א", "explanation": "ה-TLB הוא מטמון חומרה מהיר הממוקם במעבד, ותפקידו העיקרי הוא לשמש כזיכרון מטמון (cache) למיפויי כתובות וירטואליות לכתובות פיזיות שנעשה בהן שימוש לאחרונה. מטרתו היא לקצר את זמן הגישה לזיכרון על ידי הימנעות מהצורך לבצע חיפוש ארוך בטבלת הדפים בכל גישה לזיכרון וירטואלי. אם המיפוי נמצא ב-TLB (TLB hit), הגישה מהירה מאוד. אם המיפוי אינו נמצא (TLB miss), הוא נשלף מטבלת הדפים ולאחר מכן מעודכן ב-TLB לשימוש עתידי, כפי שמתואר בחומר הלימוד: 'מה ש-tlb נותן לנו זה קיצור בגישות לזיכרון'."}, "_source_file": "0120__Virtualization__TLB__MC__Easy.json", "_topic_hint": "TLB", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:20:42", "_subject": "Virtualization", "_context_lectures": [8, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["TLB"], "difficulty_estimation": "Medium", "content": {"text": "מהי המטרה העיקרית של הוספת מזהה ASID (Address Space ID) לרשומות ה-TLB?", "code_snippet": null, "options": ["א. כדי לאפשר ל-TLB להחזיק רשומות רק עבור דפים הנמצאים בזיכרון הפיזי (RAM).", "ב. כדי למנוע מצב של TLB miss כאשר מתרחש context switch בין תהליכים שונים.", "ג. כדי להבחין בין רשומות TLB השייכות לתהליכים שונים ולאפשר שמירת רשומות של מספר תהליכים במקביל.", "ד. כדי לקצר את תהליך החיפוש בטבלת הדפים במקרה של TLB miss."]}, "solution": {"correct_option": "ג", "explanation": "ה-ASID (Address Space ID) מתווסף לכל רשומה ב-TLB על מנת לזהות לאיזה תהליך (מרחב כתובות) הרשומה שייכת. פתרון זה מאפשר ל-MMU להבחין בין רשומות TLB השייכות לתהליכים שונים. כאשר מתבצע context switch בין תהליכים, ה-TLB לא צריך להתרוקן לחלוטין. במקום זאת, ה-MMU יכול להשתמש ב-ASID כדי לוודא שרשומות ה-TLB הרלוונטיות לתהליך הנוכחי הן אלה שנעשה בהן שימוש, תוך התעלמות מרשומות של תהליכים אחרים שעדיין נמצאות במטמון. זה משפר את הביצועים על ידי שמירת מיפויים של תהליכים שונים במקביל ב-TLB ומניעת הצורך לטעון אותם מחדש לאחר כל החלפת קשר. אפשרות א' מתייחסת ל-Present bit, ואפשרויות ב' ו-ד' אינן המטרה העיקרית או המדויקת של ה-ASID."}, "_source_file": "0121__Virtualization__TLB__MC__Medium.json", "_topic_hint": "TLB", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:20:54", "_subject": "Virtualization", "_context_lectures": [8, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["TLB"], "difficulty_estimation": "Medium", "content": {"text": "חומר הלימוד מציין: \"אם נעשה עכשיו context switch, הבעיה תהיה ש-TLB לא יהיה מעודכן עבור התהליך הנוכחי.\" מהו הפתרון העיקרי המתואר בחומר הלימוד להתמודדות עם בעיה זו ב-TLB?", "code_snippet": null, "options": ["א. לרוקן את כל רשומות ה-TLB עם כל החלפת קשר (context switch).", "ב. להוסיף לכל רשומה ב-TLB מזהה מרחב כתובות (ASID) כדי להבחין בין רשומות של תהליכים שונים.", "ג. להגדיל באופן משמעותי את נפח ה-TLB כך שיוכל להכיל מיפויים מכל התהליכים הפועלים.", "ד. לדרוש מכל התהליכים להשתמש באותו מרחב כתובות וירטואלי כדי למנוע התנגשויות."]}, "solution": {"correct_option": "ב", "explanation": "חומר הלימוד מציין במפורש כי הפתרון לבעיה שבה ה-TLB אינו מעודכן לאחר החלפת קשר הוא: \"נוסיף לכל רשומה ב-TLB מזהה נוסף שנקרא ASID (address space id) שיציין לאיזה תהליך הרשומה הזו שייכת וכך ניתן להבדיל בין רשומות של תהליכים שונים.\" פתרון זה מאפשר ל-TLB להחזיק מיפויים מתהליכים שונים במקביל מבלי לרוקן את תוכנו, ובכך משפר את הביצועים. האפשרויות האחרות אינן מתוארות כפתרון בחומר הלימוד, או שהן אינן יעילות/אפשריות."}, "_source_file": "0122__Virtualization__TLB__MC__Medium.json", "_topic_hint": "TLB", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:21:06", "_subject": "Virtualization", "_context_lectures": [8, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["TLB"], "difficulty_estimation": "Medium", "content": {"text": "מהו הרצף הנכון של פעולות ה-MMU בעת גישה לכתובת וירטואלית, אם המיפוי אינו נמצא ב-TLB (TLB miss), אך הדף הוירטואלי אכן נמצא בזיכרון הפיזי (RAM)?", "code_snippet": null, "options": ["א. ה-MMU ניגש לטבלת הדפים, מוצא את המיפוי, בודק שה-Present bit הוא 1, מעדכן את ה-TLB, וממשיך בגישה לזיכרון הפיזי.", "ב. ה-MMU יוצר Trap למערכת ההפעלה באופן מיידי, מכיוון שהמיפוי לא נמצא ב-TLB.", "ג. ה-MMU ניגש לטבלת הדפים, מוצא את המיפוי, בודק שה-Present bit הוא 0, ורק אז מעדכן את ה-TLB.", "ד. ה-MMU מעדכן את ה-TLB עם מיפוי ריק, ויוצר Trap למערכת ההפעלה."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, כאשר מתרחש TLB miss, ה-MMU אינו יוצר trap מיד אלא ממשיך לחפש את המיפוי בטבלת הדפים (Lecture 7, chunk 29). אם המיפוי נמצא בטבלת הדפים וה-Present bit שלו הוא 1 (כפי שמשתמע מהשאלה שהדף נמצא בזיכרון הפיזי), אז ה-MMU מתרגם את הכתובת, מעדכן את ה-TLB עם המיפוי החדש כדי לזרז גישות עתידיות לאותו דף, ורק אז ממשיך בגישה לזיכרון הפיזי (Lecture 8, chunk 10). לכן, אפשרות א' היא הנכונה.\nאפשרות ב' שגויה מכיוון ש-TLB miss אינו גורם ל-trap מיידי; ה-MMU מנסה תחילה לגשת לטבלת הדפים. אפשרות ג' שגויה מכיוון שאם ה-Present bit הוא 0, הדף אינו ב-RAM, וזה מוביל ל-trap (Page Fault) ולא לעדכון ה-TLB עם רשומה כזו (ה-TLB מחזיק רק רשומות עם Present bit=1). אפשרות ד' שגויה מכיוון שה-TLB מתעדכן במיפויים תקינים ולא ב\"מיפויים ריקים\", ו-trap אינו תוצאה ודאית של TLB miss."}, "_source_file": "0123__Virtualization__TLB__MC__Medium.json", "_topic_hint": "TLB", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:21:18", "_subject": "Virtualization", "_context_lectures": [8, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["TLB"], "difficulty_estimation": "Hard", "content": {"text": "תהליך מנסה לגשת לכתובת זיכרון וירטואלית. ה-MMU מבצע את פעולת התרגום. בהינתן הרצף הבא:\n1. בדיקה ב-TLB מניבה 'TLB miss'.\n2. ה-MMU ניגש לטבלת הדפים ומוצא את ה-Page Table Entry (PTE) המתאים.\n3. ה-'Present bit' ב-PTE זה מוגדר ל-0.\n\nמהי התוצאה המיידית של רצף אירועים זה, ומה קורה בהמשך?", "code_snippet": "for (int i = 0; i < 10; i++; ++i) {\n  ++a[i];\n}", "options": ["א. ה-MMU יוצר 'trap' למערכת ההפעלה, כיוון שהדף אינו נמצא בזיכרון הפיזי (RAM), וה-TLB אינו מתעדכן במיפוי זה.", "ב. ה-MMU מעדכן את ה-TLB במיפוי שנמצא בטבלת הדפים, ולאחר מכן מערכת ההפעלה מטפלת ב'page fault'.", "ג. ה-MMU ממשיך לחפש את המיפוי ברמת טבלת דפים גבוהה יותר, ורק אם לא ימצא שם, ייווצר 'trap'.", "ד. התהליך מופסק באופן מיידי על ידי החומרה כיוון שניסה לגשת לכתובת לא חוקית."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה (Lecture 8, chunk 10), כאשר ה-MMU ניגש לטבלת הדפים עקב 'TLB miss' ומוצא PTE שה-'Present bit' שלו מוגדר ל-0, משמעות הדבר היא שהדף אינו נמצא בזיכרון הפיזי (RAM). במצב כזה, ה-MMU אינו יכול לתרגם את הכתובת הווירטואלית לכתובת פיזית תקינה, ולכן הוא יוצר 'trap' למערכת ההפעלה. תפקיד ה-'trap' הוא להודיע למערכת ההפעלה על האירוע, ולאפשר לה לטפל בו (לדוגמה, לטעון את הדף מהדיסק לזיכרון). בנוסף, ה-TLB מחזיק רק רשומות שה-'Present bit' שלהן הוא 1, ולכן מיפוי עם 'Present bit' 0 לא יעודכן ב-TLB. אפשרות ב' שגויה מכיוון שה-TLB אינו מתעדכן במיפויים שבהם ה-'Present bit' הוא 0 (Lecture 8, chunk 10). אפשרות ג' שגויה מכיוון שה-'Present bit' מוגדר ב-PTE עצמו, וערך 0 מצביע על היעדר הדף בזיכרון הפיזי, ולא על צורך בחיפוש נוסף בטבלת דפים. אפשרות ד' שגויה מכיוון שהחומרה יוצרת 'trap' למערכת ההפעלה, המאפשר למערכת ההפעלה לטפל במצב, במקום להפסיק את התהליך באופן מיידי וללא התערבות."}, "_source_file": "0124__Virtualization__TLB__MC__Hard.json", "_topic_hint": "TLB", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:21:33", "_subject": "Virtualization", "_context_lectures": [8, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["TLB"], "difficulty_estimation": "Hard", "content": {"text": "תהליך P1 רץ, ולאחר מכן מתרחש context switch לתהליך P2. תהליך P2 מבצע כעת גישה לכתובת וירטואלית. בהתחשב בכך שה-TLB מכיל רשומות עם מזהה ASID (Address Space ID) עבור תהליכים שונים, וכי הדף הפיזי המתאים לכתובת הוירטואלית הנדרשת על ידי P2 אינו נמצא כרגע בזיכרון הפיזי (כלומר, ה-Present bit עבור ה-PTE המתאים בטבלת הדפים של P2 הוא 0), מהו הרצף הנכון של האירועים שיגרמו ל-MMU להעלות Trap למערכת ההפעלה?", "code_snippet": null, "options": ["א. ה-MMU יבצע בדיקת TLB, יקבל TLB miss (עקב ASID שאינו תואם או אי-קיום רשומה), יגש לטבלת הדפים של P2, ימצא שה-Present bit של הדף הוא 0, ויעלה Trap למערכת ההפעלה.", "ב. ה-MMU יזהה מיידית את חוסר הדף בזיכרון הפיזי עוד לפני גישה ל-TLB, ויעלה Trap.", "ג. ה-MMU יבצע בדיקת TLB, יקבל TLB hit (בזכות רשומה קודמת של תהליך P1 ללא התחשבות ב-ASID), ואז יגש לכתובת פיזית שגויה ויעלה Trap.", "ד. ה-MMU יבצע בדיקת TLB, יקבל TLB miss, יעדכן את ה-TLB עם מיפוי חדש מתוך טבלת הדפים (למרות שהדף אינו ב-RAM), ורק אז ינסה לגשת לזיכרון הפיזי ויקבל Trap."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. להלן ההסבר המפורט, בהתבסס על חומר ההרצאה:\n\n1.  **בדיקת TLB ראשונית:** חומר ההרצאה קובע במפורש ש\"בכל פעם שיש גישה לזיכרון, [ה-MMU] קודם יבדוק את ה-tlb\". לכן, כל גישה לכתובת וירטואלית מתחילה בבדיקת ה-TLB.\n\n2.  **TLB miss עקב ASID:** השאלה מציינת שה-TLB מכיל רשומות עם ASID. כאשר מתרחש context switch מ-P1 ל-P2, ה-TLB עשוי להכיל רשומות של P1 או רשומות קודמות של P2. אם קיימת רשומה עבור הכתובת הוירטואלית אך ה-ASID שלה אינו תואם ל-P2 הנוכחי, או שאין רשומה כלל עבור כתובת זו של P2, יתקבל **TLB miss**. ה-ASID מונע מצב של \"TLB hit\" שגוי על רשומה של תהליך אחר, כפי שמצוין בחומר: \"נוסיף לכל רשומה ב-tlb מזהה נוסף שנקרא ASID (address space id) שיציין לאיזה תהליך הרשומה הזו שייכת וכך ניתן להבדיל בין רשומות של תהליכים שונים.\"\n\n3.  **גישה לטבלת הדפים:** לאחר TLB miss, ה-MMU יגש לטבלת הדפים כדי למצוא את המיפוי. \"אם המיפוי לא קיים [ב-TLB], נעשה את התהליך הארוך (נלך לחפש בטבלת הדפים)\".\n\n4.  **בדיקת Present bit:** בטבלת הדפים, ה-MMU ימצא את ה-PTE המתאים לכתובת הוירטואלית ויבדוק את ה-Present bit שלו. \"ה-mmu ניגש לטבלת הדפים ומחפש את המיפוי שם, ובודק את ה-present bit\".\n\n5.  **העלאת Trap:** מכיוון שהשאלה קובעת שה-Present bit הוא 0, משמעות הדבר היא שהדף אינו נמצא בזיכרון הפיזי (RAM). במצב זה, \"ה-mmu יוצר trap למערכת ההפעלה\".\n\n**מדוע שאר האפשרויות שגויות:**\n*   **ב.** שגויה מכיוון שה-MMU תמיד בודק את ה-TLB תחילה לפני שהוא מנסה \"לזהות\" משהו לגבי מצב הדף בזיכרון הפיזי.\n*   **ג.** שגויה מכיוון שהשימוש ב-ASID מונע TLB hit עבור רשומות של תהליכים אחרים (כמו P1) לאחר context switch. ללא ASID, אפשרות זו הייתה יכולה להיות נכונה.\n*   **ד.** שגויה מכיוון שה-TLB לא מתעדכן עם מיפוי של דף שאינו נמצא ב-RAM (כלומר, ה-Present bit שלו הוא 0). חומר ההרצאה מציין ש\"ה-tlb מחזיק רק רשומות שה-present bit שלהן הוא 1\" וכי עדכון ה-TLB מתבצע \"אחרי שנמצא את המיפוי\" (משמע, מיפוי חוקי לדף ב-RAM)."}, "_source_file": "0125__Virtualization__TLB__MC__Hard.json", "_topic_hint": "TLB", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:21:54", "_subject": "Virtualization", "_context_lectures": [8, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["TLB"], "difficulty_estimation": "Hard", "content": {"text": "בהינתן מערכת הפעלה שאינה מיישמת מזהי מרחב כתובות (ASID) עבור רשומות ה-TLB, איזו פעולה קריטית סביר שתתבצע על ה-TLB במהלך החלפת הקשר (context switch) כדי להבטיח את תקינות תרגום הכתובות עבור התהליך החדש?", "code_snippet": null, "options": ["א. ה-TLB יישטף (flushed) לחלוטין מכל הרשומות שלו.", "ב. ה-MMU יבדוק את ה-Present Bit של כל רשומת TLB לפני השימוש בה.", "ג. ה-TLB יאוחזר מהזיכרון הראשי עבור התהליך החדש.", "ד. מערכת ההפעלה תעדכן באופן סלקטיבי רק את רשומות ה-TLB השייכות לדפים פעילים."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין בשיעור קובע כי \"אם נעשה עכשיו context switch, הבעיה תהיה ש-tlb לא יהיה מעודכן עבור התהליך הנוכחי. הפתרון לכך: נוסיף לכל רשומה ב-tlb מזהה נוסף שנקרא ASID (address space id) שיציין לאיזה תהליך הרשומה הזו שייכת וכך ניתן להבדיל בין רשומות של תהליכים שונים.\" מכאן נובע, שאם מערכת אינה משתמשת ב-ASID, ה-TLB יכיל מיפויים השייכים לתהליך הקודם. כדי למנוע שימוש במיפויים שגויים אלו עבור התהליך החדש, יש צורך לנקות (לשטוף) את כל רשומות ה-TLB. פעולה זו מבטיחה שהתהליך החדש יתחיל עם TLB \"נקי\" ממיפויים שגויים, גם אם זה כרוך ביותר TLB misses בתחילה. שאר האפשרויות אינן פתרון לבעיה זו: בדיקת ה-Present Bit רלוונטית לשאלה האם הדף בזיכרון הפיזי ולא לאיזה תהליך הוא שייך; אחזור TLB מהזיכרון הראשי אינו מנגנון קיים עבור מטמון; ועדכון סלקטיבי אינו אפשרי ללא מזהה תהליך (כמו ASID) ברשומות ה-TLB עצמן, שכן המערכת לא תוכל להבחין אילו רשומות רלוונטיות לתהליך החדש."}, "_source_file": "0126__Virtualization__TLB__MC__Hard.json", "_topic_hint": "TLB", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:22:10", "_subject": "Virtualization", "_context_lectures": [8, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Copy-on-Write"], "difficulty_estimation": "Easy", "content": {"text": "מהו היתרון העיקרי של מנגנון ה-Copy-on-Write (CoW) בהקשר של יצירת תהליכים חדשים (באמצעות `fork`)?", "code_snippet": null, "options": ["א. הוא מאפשר לשתף את כל הזיכרון בין תהליכי אב ובן לצמיתות, ללא צורך בהעתקה כלשהי.", "ב. הוא מפחית את צריכת הזיכרון הפיזי על ידי דחיית שכפול דפי זיכרון עד לניסיון כתיבה אליהם.", "ג. הוא מאיץ את קריאת הנתונים מהדיסק על ידי טעינה מראש של דפים סמוכים.", "ד. הוא מבטיח שכל תהליך יקבל עותק מלא ופרטי של הזיכרון מיד לאחר ה-`fork`."]}, "solution": {"correct_option": "ב", "explanation": "החומר המצוין בשיעור 4 (chunk 4) מתאר את מנגנון ה-Copy-on-Write באופן מפורש: \"אם זה עותק, לא צריך לשכפל בפועל את הזיכרון, זו פעולה יקרה. במקום זה ניתן לחסוך את ההעתקה הזו, ולהגדיר שהזיכרון הזה משותף לשני התהליכים (האב והבן), עד שאחד התהליכים יעשה פעולת write. רק בנקודה הזו, מערכת ההפעלה מוצאת מקום חדש בזיכרון, יוצרת עותק של מה שהיה בו ומשנה את מה שהתהליך רצה לשנות.\"\nלכן, היתרון העיקרי של CoW הוא חיסכון בזיכרון פיזי על ידי דחיית שכפול דפים עד לרגע שבו אחד התהליכים (אב או בן) מנסה לשנות את תוכן הדף. אפשרויות א' ו-ד' מתארות מצבים שאינם תואמים את CoW, ואפשרות ג' מתייחסת לטכניקות אופטימיזציה של דיסק שאינן קשורות ישירות ל-CoW."}, "_source_file": "0127__Virtualization__Copy-on-Write__MC__Easy.json", "_topic_hint": "Copy-on-Write", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:22:20", "_subject": "Virtualization", "_context_lectures": [8, 9, 4, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Copy-on-Write"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של מנגנון Copy-on-Write (CoW) ביצירת תהליך חדש (למשל, באמצעות `fork`)?", "code_snippet": null, "options": ["א. למנוע שכפול מיידי של זיכרון בין תהליך אב לבן, ובכך לחסוך פעולה יקרה.", "ב. לאפשר לתהליכים שונים לכתוב לאותו דף זיכרון משותף בו זמנית ללא יצירת עותקים.", "ג. להבטיח שכל דפי הזיכרון של תהליך הבן ישוכפלו באופן מלא מיד עם יצירתו.", "ד. לטעון דפי זיכרון מהדיסק ל-RAM בצורה מקובצת (clustering) כאשר מתרחש Page Fault."]}, "solution": {"correct_option": "א", "explanation": "ההסבר הנכון הוא א'. כפי שמוסבר בחומר ההרצאה (הרצאה 4, קטע 4), מנגנון ה-Copy-on-Write נועד לשפר ביצועים על ידי מניעת שכפול מיידי ויקר של כל זיכרון התהליך בעת יצירת תהליך חדש (למשל, באמצעות `fork`). במקום זאת, תהליך האב והבן חולקים את אותו זיכרון פיזי. שכפול הזיכרון מתרחש רק כאשר אחד התהליכים מנסה לבצע פעולת כתיבה (write) לדף משותף, ורק אז נוצר עותק חדש של אותו דף ספציפי עבור התהליך הכותב. זה חוסך את הצורך להעתיק את כל הזיכרון אם התהליך הבן לא משנה את כל הדפים או משנה רק מעטים."}, "_source_file": "0128__Virtualization__Copy-on-Write__MC__Easy.json", "_topic_hint": "Copy-on-Write", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:22:30", "_subject": "Virtualization", "_context_lectures": [8, 9, 4, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Copy-on-Write"], "difficulty_estimation": "Easy", "content": {"text": "מהו העיקרון המרכזי של מנגנון Copy-on-Write (CoW) במערכות הפעלה, כפי שתואר בחומר הקורס?", "code_snippet": null, "options": ["א. הזיכרון משוכפל באופן מלא ובבת אחת עם יצירת תהליך חדש, כדי למנוע עיכובים עתידיים.", "ב. הזיכרון משותף בין תהליכים ללא קשר לפעולות כתיבה, ומערכת ההפעלה מטפלת בקונפליקטים.", "ג. הזיכרון משוכפל רק כאשר אחד התהליכים (האב או הבן) מנסה לבצע פעולת כתיבה (write) לדף משותף.", "ד. הזיכרון משוכפל מיד עם יצירת תהליך חדש על ידי fork, אך רק הדפים הפעילים ביותר."]}, "solution": {"correct_option": "ג", "explanation": "על פי חומר הקורס (Lecture 4, chunk 4), מנגנון Copy-on-Write (CoW) נועד לשפר ביצועים על ידי הימנעות משכפול מיידי של זיכרון בעת יצירת תהליך חדש (שכפול של תהליך קיים). במקום זאת, הזיכרון מוגדר כמשותף בין התהליכים (האב והבן). השכפול בפועל של דף זיכרון מתרחש רק \"עד שאחד התהליכים יעשה פעולת write. אם אחד התהליכים יבוא וישנה משהו בזיכרון... רק בנקודה הזו, מערכת ההפעלה מוצאת מקום חדש בזיכרון, יוצרת עותק של מה שהיה בו ומשנה את מה שהתהליך רצה לשנות\". לכן, התשובה הנכונה היא שהזיכרון משוכפל רק בעת ניסיון כתיבה לדף משותף."}, "_source_file": "0129__Virtualization__Copy-on-Write__MC__Easy.json", "_topic_hint": "Copy-on-Write", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:22:40", "_subject": "Virtualization", "_context_lectures": [8, 9, 4, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Copy-on-Write"], "difficulty_estimation": "Medium", "content": {"text": "מהי המטרה העיקרית של מנגנון ה-Copy-on-Write (CoW) בהקשר של יצירת תהליכים חדשים (לדוגמה, באמצעות fork())?", "code_snippet": null, "options": ["א. למנוע שכפול מיידי ויקר של זיכרון התהליך האב לתהליך הבן, ולאפשר שיתוף דפים עד שאחד התהליכים יבצע פעולת כתיבה.", "ב. לאחד את טבלאות הדפים של תהליך האב והבן לדף אחד בלבד, ובכך לחסוך מקום בזיכרון הפיזי.", "ג. לשפר את ביצועי הגישה לדיסק על ידי דחיית כתיבת דפים שהשתנו לדיסק עד שיתאספו מספיק שינויים.", "ד. להבטיח שכל תהליך בן יקבל עותק מלא ופרטי של כל דפי הזיכרון של האב מיד עם יצירתו, כדי למנוע התנגשויות."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. מנגנון ה-Copy-on-Write (CoW) נועד לשפר ביצועים ולחסוך במשאבי זיכרון בעת יצירת תהליכים חדשים (לדוגמה, באמצעות `fork()`). במקום לשכפל באופן מיידי את כל זיכרון האב לתהליך הבן, שהיא פעולה יקרה, מערכת ההפעלה מאפשרת לשני התהליכים לשתף את אותם דפי זיכרון פיזיים. שכפול בפועל של הדף מתבצע רק כאשר אחד התהליכים (האב או הבן) מנסה לבצע פעולת כתיבה על דף משותף זה. בשלב זה, מערכת ההפעלה יוצרת עותק פרטי של הדף עבור התהליך המבצע את הכתיבה, ומשנה את טבלת הדפים שלו כך שתצביע על העותק החדש. זאת כפי שמתואר בחומר ההרצאה: 'אחד הדברים שמערכת ההפעלה עושה בשביל לשפר ביצועים: אם זה עותק, לא צריך לשכפל בפועל את הזיכרון, זו פעולה יקרה. במקום זה ניתן לחסוך את ההעתקה הזו, ולהגדיר שהזיכרון הזה משותף לשני התהליכים (האב והבן), עד שאחד התהליכים יעשה פעולת write' (הרצאה 4, קטע 4).\nאפשרויות ב', ג' ו-ד' אינן נכונות:\nאפשרות ב' מתייחסת לאיחוד טבלאות דפים, בעוד שלכל תהליך יש טבלת דפים משלו (הרצאה 7, קטע 1). CoW אינו מאחד טבלאות דפים, אלא משנה את המיפויים בדפים בודדים לפי הצורך.\nאפשרות ג' מתארת מנגנון לשיפור ביצועי הגישה לדיסק באמצעות קיבוץ כתיבות (clustering), שאינו קשור ישירות ל-CoW אלא למנגנוני ניהול דיסק אחרים (הרצאה 8, קטע 41).\nאפשרות ד' מתארת את המצב ש-CoW נועד למנוע – שכפול מלא ומיידי של הזיכרון, שהיא פעולה יקרה ולא יעילה."}, "_source_file": "0130__Virtualization__Copy-on-Write__MC__Medium.json", "_topic_hint": "Copy-on-Write", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:22:57", "_subject": "Virtualization", "_context_lectures": [8, 9, 4, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Copy-on-Write"], "difficulty_estimation": "Medium", "content": {"text": "כיצד מנגנון Copy-on-Write (CoW) משפר את ביצועי מערכת ההפעלה בעת יצירת תהליך חדש (fork)?", "code_snippet": null, "options": ["א. הוא מונע שכפול פיזי מיידי של כל זיכרון תהליך האב לתהליך הבן, ובמקום זאת משתף דפים עד שאחד התהליכים מנסה לשנות אותם.", "ב. הוא טוען דפים מהדיסק ל-RAM בקבוצות גדולות יותר, ובכך מקטין את מספר פעולות הקריאה לדיסק.", "ג. הוא מאפשר לכל תהליך גישה בלעדית לטבלת דפים משלו, ובכך מבטיח הפרדה מלאה בזיכרון מרגע ה-fork.", "ד. הוא שומר דפים שהשתנו בזיכרון ומבצע כתיבה לדיסק רק כאשר מצטברים מספיק שינויים."]}, "solution": {"correct_option": "א", "explanation": "מנגנון Copy-on-Write (CoW) מיועד לשפר ביצועים בעת יצירת תהליך חדש באמצעות קריאת המערכת `fork`. במקום לשכפל באופן מיידי את כל מרחב הזיכרון של תהליך האב עבור תהליך הבן (שהיא פעולה יקרה), CoW מאפשר לשני התהליכים לשתף את אותם דפים פיזיים בזיכרון. השיתוף נמשך עד שאחד מהתהליכים (האב או הבן) מנסה לבצע פעולת כתיבה (write) לדף משותף. רק בנקודה זו, מערכת ההפעלה יוצרת עותק פרטי של הדף עבור התהליך המבקש לכתוב, ובכך נמנעת העתקה מיותרת של נתונים שאינם משתנים. אפשרות ב' ו-ד' מתארות מנגנונים של קיבוץ קריאות וכתיבות לדיסק (clustering), ואילו אפשרות ג' אינה מתארת את היתרון הספציפי של CoW, אלא היבט כללי של הפרדת טבלאות דפים, תוך התעלמות מהשיתוף הראשוני של הדפים הפיזיים."}, "_source_file": "0131__Virtualization__Copy-on-Write__MC__Medium.json", "_topic_hint": "Copy-on-Write", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:23:07", "_subject": "Virtualization", "_context_lectures": [8, 9, 4, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Copy-on-Write"], "difficulty_estimation": "Medium", "content": {"text": "בהקשר של יצירת תהליכים חדשים באמצעות `fork`, מהו העיקרון המרכזי של מנגנון Copy-on-Write (CoW)?", "code_snippet": null, "options": ["א. הזיכרון של תהליך האב ותהליך הבן משותף בתחילה, ועותק נפרד נוצר רק כאשר אחד מהם מנסה לבצע פעולת כתיבה לדף זיכרון משותף.", "ב. כל דפי הזיכרון של תהליך האב משוכפלים מיד לזיכרון נפרד עבור תהליך הבן בעת קריאה ל-`fork`.", "ג. רק דפים המכילים קוד הניתן לקריאה בלבד משותפים בין האב לבן, בעוד שדפי נתונים משוכפלים מיד.", "ד. מנגנון CoW מאפשר טעינה מקדימה של דפים מהדיסק ל-RAM כדי להאיץ את יצירת התהליך."]}, "solution": {"correct_option": "א", "explanation": "האפשרות הנכונה היא א'. מנגנון Copy-on-Write (CoW) נועד לשפר ביצועים בעת יצירת תהליכים חדשים (כמו ב-`fork`) על ידי הימנעות משכפול מיידי ויקר של כל זיכרון האב. במקום זאת, הזיכרון משותף בין תהליך האב לתהליך הבן. העותק הנפרד נוצר רק בנקודה שבה אחד התהליכים מנסה לשנות (לכתוב ל-) דף זיכרון משותף. כפי שמצוין בחומר ההרצאה (Lecture 4, chunk 4): 'אם זה עותק, לא צריך לשכפל בפועל את הזיכרון, זו פעולה יקרה. במקום זה ניתן לחסוך את ההעתקה הזו, ולהגדיר שהזיכרון הזה משותף לשני התהליכים (האב והבן), עד שאחד התהליכים יעשה פעולת write.' אפשרות ב' מתארת את המצב ללא CoW, שבו כל הזיכרון משוכפל מיד. אפשרות ג' אינה מדויקת, שכן CoW חל על כל דפי הזיכרון המשותפים ואינו מוגבל רק לדפים הניתנים לקריאה בלבד. אפשרות ד' מתייחסת לטעינת דפים מהדיסק, שאינה קשורה ישירות לעיקרון הפעולה של CoW בעת `fork`."}, "_source_file": "0132__Virtualization__Copy-on-Write__MC__Medium.json", "_topic_hint": "Copy-on-Write", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:23:19", "_subject": "Virtualization", "_context_lectures": [8, 9, 4, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Copy-on-Write"], "difficulty_estimation": "Hard", "content": {"text": "מערכת הפעלה המיישמת מנגנון Copy-on-Write (CoW) יוצרת תהליכי בן (child processes) על ידי שיתוף דפי זיכרון עם תהליך האב (parent process). בהתחשב בכך, איזו מהפעולות הבאות מהווה את המנגנון המרכזי שמופעל ברגע שתהליך בן מנסה לבצע פעולת כתיבה (write) לדף זיכרון משותף עם האב?", "code_snippet": null, "options": ["א. מערכת ההפעלה מבצעת page fault, מאתרת דף פיזי חדש, מעתיקה את תוכן הדף המשותף לדף החדש, ומעדכנת את טבלת הדפים של תהליך הבן כדי שתצביע על הדף החדש.", "ב. ה-MMU מזהה את ניסיון הכתיבה, מוחק את הדף המשותף מהזיכרון הפיזי, וטוען עותק חדש וריק של הדף מהדיסק עבור תהליך הבן.", "ג. תהליך הבן מקבל הודעת שגיאה (segmentation fault) והפעולה נכשלת, מכיוון שדפים משותפים אסורים בכתיבה.", "ד. מערכת ההפעלה מעדכנת ישירות את טבלת הדפים של תהליך הבן כך שהדף המשותף יהפוך להיות פרטי (private) ויאפשר כתיבה, ללא צורך בהעתקת תוכן."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. מנגנון Copy-on-Write (CoW) פועל כך: כאשר תהליך בן נוצר באמצעות fork, דפי הזיכרון של האב והבן משותפים, אך הם מסומנים כקריאה בלבד (read-only) עבור הבן. ברגע שתהליך הבן מנסה לכתוב לדף כזה, מתרחשת הפרה של הרשאת הזיכרון, מה שגורם ל-page fault. מערכת ההפעלה מיירטת את ה-page fault, מאתרת דף פיזי חדש פנוי, מעתיקה אליו את תוכן הדף המשותף המקורי, ולאחר מכן מעדכנת את טבלת הדפים (page table) של תהליך הבן כך שה-Page Table Entry (PTE) הרלוונטי יצביע על הדף הפיזי החדש והפרטי שלו. רק אז מתאפשרת פעולת הכתיבה לדף החדש. תהליך זה מתואר בחומר הלימוד: \"רק בנקודה הזו, מערכת ההפעלה מוצאת מקום חדש בזיכרון, יוצרת עותק של מה שהיה בו ומשנה את מה שהתהליך רצה לשנות.\" אפשרות ב' שגויה מכיוון שאין מחיקה של הדף המשותף או טעינה מהדיסק (במיוחד כשהחומר מציין שאין swapping). אפשרות ג' שגויה כיוון שמטרת CoW היא לאפשר כתיבה תוך שמירה על הפרדה. אפשרות ד' שגויה כיוון ששינוי מצביע בטבלת הדפים ללא העתקה פיזית של הנתונים יגרום לכך שהאב והבן יראו תוכן שונה מבלי שהנתונים הועתקו בפועל, וזה נוגד את עקרון הבידוד."}, "_source_file": "0133__Virtualization__Copy-on-Write__MC__Hard.json", "_topic_hint": "Copy-on-Write", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:23:38", "_subject": "Virtualization", "_context_lectures": [8, 9, 4, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Copy-on-Write"], "difficulty_estimation": "Hard", "content": {"text": "תהליך אב יוצר תהליכי בן באמצעות קריאת המערכת `fork`. נניח שלתהליך האב יש קוד בגודל 10 דפים בזיכרון ועוד 5 דפים של מחסנית. כמו כן, נתון שכל טבלת דפים תופסת דף אחד בזיכרון הפיזי. בהתבסס על מנגנון ה-Copy-on-Write (CoW), מהי כמות הזיכרון הפיזי המינימלית הנוספת שנדרשת *מיד* עם יצירת תהליך בן חדש, לפני שמתבצעות פעולות כתיבה כלשהן על ידי הבן?", "code_snippet": null, "options": ["א. דף אחד (עבור טבלת הדפים של הבן).", "ב. 6 דפים (דף אחד לטבלת הדפים ו-5 דפים למחסנית משוכפלת).", "ג. 16 דפים (10 דפים לקוד, 5 דפים למחסנית, ודף אחד לטבלת הדפים).", "ד. 15 דפים (10 דפים לקוד ו-5 דפים למחסנית)."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. מנגנון ה-Copy-on-Write (CoW) נועד לשפר ביצועים ולחסוך זיכרון פיזי בעת יצירת תהליכים חדשים באמצעות `fork`. במקום לשכפל באופן מיידי את כל זיכרון תהליך האב (כולל קוד ומחסנית) עבור תהליך הבן, CoW מאפשר לשני התהליכים לשתף את אותם דפים פיזיים בזיכרון. שכפול בפועל של דף מתרחש רק כאשר אחד התהליכים (האב או הבן) מנסה לבצע פעולת כתיבה לאותו דף, ובנקודה זו נוצר עותק של הדף הספציפי. לכן, מיד לאחר יצירת תהליך בן, הדפים המכילים את הקוד (10 דפים) והמחסנית (5 דפים) משותפים עם האב ואינם דורשים הקצאת זיכרון פיזי חדש. הדבר היחיד שכל תהליך בן חייב לקבל באופן ייחודי מיד עם יצירתו הוא טבלת דפים משלו, אשר על פי הנתון תופסת דף אחד בזיכרון הפיזי. לפיכך, הזיכרון הפיזי המינימלי הנוסף הנדרש עבור תהליך הבן הוא דף אחד בלבד עבור טבלת הדפים שלו."}, "_source_file": "0134__Virtualization__Copy-on-Write__MC__Hard.json", "_topic_hint": "Copy-on-Write", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:23:59", "_subject": "Virtualization", "_context_lectures": [8, 9, 4, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Copy-on-Write"], "difficulty_estimation": "Hard", "content": {"text": "בהינתן מערכת הפעלה המיישמת מנגנון Copy-on-Write (CoW) בעת יצירת תהליך בן באמצעות `fork()`. תהליך אב כולל 10 דפי קוד ו-5 דפי מחסנית. טבלת הדפים של תהליך נכנסת לדף זיכרון פיזי אחד. מהי כמות הזיכרון הפיזי המינימלית, במונחי דפים, שתהליך הבן יצרוך *מיד* לאחר קריאה ל-`fork()` (לפני ביצוע פעולות כתיבה כלשהן)?", "code_snippet": null, "options": ["א. דף אחד, המיועד לטבלת הדפים של תהליך הבן בלבד.", "ב. 6 דפים, הכוללים את טבלת הדפים ואת המחסנית.", "ג. 15 דפים, הכוללים את דפי הקוד והמחסנית של תהליך האב.", "ד. 11 דפים, הכוללים את דפי הקוד של תהליך האב וטבלת הדפים של תהליך הבן."]}, "solution": {"correct_option": "א", "explanation": "מנגנון Copy-on-Write (CoW) נועד לחסוך שכפול מיותר של דפי זיכרון יקרים בעת יצירת תהליך בן באמצעות `fork()`. במקום לשכפל מיד את כל דפי הזיכרון של האב (קוד, נתונים, מחסנית), תהליך הבן מקבל גישה לדפים הפיזיים המשותפים עם האב. השכפול בפועל של הדף מתבצע רק כאשר אחד התהליכים (האב או הבן) מנסה לבצע פעולת כתיבה לדף משותף.\n\nעם זאת, לכל תהליך חייבת להיות טבלת דפים משלו ('לכל תהליך יש טבלת דפים משלו'). טבלת הדפים הזו היא הכרחית למיפוי מרחב הכתובות הווירטואלי הייחודי של כל תהליך לזיכרון הפיזי. לכן, גם עם CoW, תהליך הבן יצרוך מיד דף זיכרון פיזי אחד עבור טבלת הדפים שלו, כפי שצוין גם בחומר הלימוד ('כל תהליך שנוצר גם צריך דף עבור טבלת הדפים שלו').\n\nדפי הקוד והמחסנית (10 ו-5 דפים בהתאמה) אינם משוכפלים מיד; הם משותפים בין האב לבן עד שמתבצעת פעולת כתיבה. לכן, כמות הזיכרון הפיזי המינימלית שתהליך הבן יצרוך מיד היא דף אחד בלבד עבור טבלת הדפים שלו."}, "_source_file": "0135__Virtualization__Copy-on-Write__MC__Hard.json", "_topic_hint": "Copy-on-Write", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:24:16", "_subject": "Virtualization", "_context_lectures": [8, 9, 4, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Address Space"], "difficulty_estimation": "Easy", "content": {"text": "מהם שני החלקים העיקריים המרכיבים כתובת וירטואלית לצורך תרגום כתובות?", "code_snippet": null, "options": ["א. מספר דף וירטואלי (VPN) והיסט (Offset)", "ב. מספר מסגרת פיזית (PFN) והיסט (Offset)", "ג. אינדקס ספריית דפים (Page Directory Index) ואינדקס טבלת דפים (Page Table Index)", "ד. גודל מרחב כתובות וירטואלי וגודל דף"]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה (במיוחד בפרקים 6.32 ו-7.19), כתובת וירטואלית מורכבת משני חלקים עיקריים: מספר הדף הוירטואלי (VPN) וההיסט (Offset). ה-VPN מצביע על הדף הוירטואלי הספציפי בזיכרון, וההיסט מציין את המיקום בתוך אותו דף. לדוגמה, בפרק 6.32 מוצגת כתובת וירטואלית המחולקת במפורש ל-VPN ול-Offset. אפשרויות ב', ג' ו-ד' אינן מתארות את שני החלקים העיקריים של הכתובת הוירטואלית עצמה; מספר מסגרת פיזית (PFN) הוא חלק מהכתובת הפיזית המתורגמת, ואינדקסים של ספריות וטבלאות דפים הם חלוקה פנימית של ה-VPN במקרה של טבלאות דפים רב-שכבתיות."}, "_source_file": "0136__Virtualization__Address_Space__MC__Easy.json", "_topic_hint": "Address Space", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:24:26", "_subject": "Virtualization", "_context_lectures": [5, 6, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Address Space"], "difficulty_estimation": "Easy", "content": {"text": "במערכת הפעלה המשתמשת בטבלאות דפים (paging), למה מחולקת בדרך כלל כתובת וירטואלית?", "code_snippet": null, "options": ["א. מספר דף וירטואלי (VPN) והיסט בתוך הדף (Offset).", "ב. מספר מסגרת פיזית (PFN) וגודל הזיכרון הפיזי.", "ג. כתובת התחלה של התוכנית וכתובת סיום של התוכנית.", "ד. גודל ה-Stack וגודל ה-Heap."]}, "solution": {"correct_option": "א", "explanation": "במערכת הפעלה המשתמשת בטבלאות דפים (paging), כתובת וירטואלית מחולקת לשני חלקים עיקריים: מספר דף וירטואלי (VPN) והיסט (Offset) בתוך הדף. ה-VPN משמש לאיתור הרשומה המתאימה בטבלת הדפים, שממנה נגזר מספר המסגרת הפיזית (PFN). ההיסט נשאר ללא שינוי ומשמש לאיתור המיקום הספציפי בתוך המסגרת הפיזית. חלוקה זו מתוארת בחומר ההרצאה, לדוגמה, במבנה הכתובת הוירטואלית המוצג ב-Lecture 6 (chunk 32) כ- \"VPN | Offset\". אפשרויות ב', ג' ו-ד' אינן מתארות את החלוקה הבסיסית של כתובת וירטואלית למטרות paging."}, "_source_file": "0137__Virtualization__Address_Space__MC__Easy.json", "_topic_hint": "Address Space", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:24:37", "_subject": "Virtualization", "_context_lectures": [5, 6, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Address Space"], "difficulty_estimation": "Easy", "content": {"text": "כיצד מחולקת כתובת וירטואלית על ידי יחידת ניהול הזיכרון (MMU) לצורך תרגום כתובות?", "code_snippet": null, "options": ["א. אינדקס ספריית דפים (Page Directory Index) ואינדקס טבלת דפים (Page Table Index)", "ב. מספר דף וירטואלי (VPN) והיסט (Offset)", "ג. מספר מסגרת פיזית (PFN) והיסט (Offset)", "ד. מצביע מחסנית (Stack Pointer) ומונה תוכנית (Program Counter)"]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר ההרצאה (Lecture 6, chunk 32), כתובת וירטואלית מחולקת לשני חלקים עיקריים: מספר דף וירטואלי (VPN) המזהה את הדף הוירטואלי, והיסט (Offset) המציין את המיקום בתוך הדף. חלוקה זו מאפשרת ל-MMU לאתר את הדף המתאים בטבלת הדפים ולאחר מכן למצוא את המיקום המדויק בתוך המסגרת הפיזית. אפשרות א' מתארת חלוקה נוספת של ה-VPN במקרה של טבלאות דפים היררכיות (Multi-Level Page Table), אך החלוקה הבסיסית ביותר של כתובת וירטואלית היא ל-VPN והיסט. אפשרות ג' מתארת את רכיבי הכתובת הפיזית, לא הוירטואלית. אפשרות ד' מתייחסת לרגיסטרים של המעבד ואינה קשורה לחלוקת כתובת וירטואלית לצורך תרגום."}, "_source_file": "0138__Virtualization__Address_Space__MC__Easy.json", "_topic_hint": "Address Space", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:24:47", "_subject": "Virtualization", "_context_lectures": [5, 6, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Address Space"], "difficulty_estimation": "Medium", "content": {"text": "מהי הסיבה העיקרית לשימוש בטבלת דפים היררכית (Multi-Level Page Table) במערכת ניהול זיכרון (MMU)?", "code_snippet": null, "options": ["א. כדי להפחית את כמות הזיכרון הפיזי הנדרשת לאחסון טבלת הדפים עצמה, במיוחד עבור מרחבי כתובות דלילים.", "ב. כדי להאיץ את תהליך התרגום של כל כתובת וירטואלית לכתובת פיזית.", "ג. כדי לאפשר לתהליכים שונים לחלוק את אותם דפים פיזיים ללא בעיות הגנה.", "ד. כדי להגדיל את הגודל הכולל של מרחב הכתובות הוירטואלי שתהליך יכול לגשת אליו."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מתאר את טבלת הדפים ההיררכית (Multi-Level Page table) כמבנה דמוי עץ, שבו ה-'page directory' מכיל מצביעים לכל החלקים של ה-'page table' (Lecture 7, chunk 16). מבנה היררכי זה נועד בעיקר לנהל ביעילות מרחבי כתובות וירטואליים גדולים. במקום שכל טבלת הדפים תהיה חייבת לשהות כולה בזיכרון הפיזי (מה שדורש כמות עצומה של זיכרון עבור מרחבי כתובות גדולים), טבלה רב-שכבתית מאפשרת לטעון לזיכרון הפיזי רק את החלקים הרלוונטיים של טבלת הדפים (כלומר, ה-'page directory' וטבלאות הדפים הספציפיות לאזורי זיכרון וירטואלי פעילים). זה מפחית באופן משמעותי את טביעת הרגל של טבלאות הדפים בזיכרון הפיזי, במיוחד כאשר מרחב הכתובות הוירטואלי של תהליך הוא דליל (כלומר, לא כל הדפים הווירטואליים ממופים או נמצאים בשימוש). לכן, אפשרות א' נכונה.\n\nאפשרות ב' אינה נכונה מכיוון שבדרך כלל, חיפוש רב-שכבתי כרוך במספר גישות לזיכרון (אחת עבור ה-'page directory', ואז אחת או יותר עבור טבלאות הדפים), מה שיכול להיות איטי יותר מחיפוש חד-שכבתי.\nאפשרות ג' מתארת תכונה כללית של דפדוף (paging), אך טבלאות דפים רב-שכבתיות אינן משפרות באופן ספציפי את השיתוף או ההגנה מעבר למה שטבלאות חד-שכבתיות מציעות; ההגנה מנוהלת באמצעות ביטים בתוך רשומות טבלת הדפים (PTEs).\nאפשרות ד' גם אינה נכונה. גודל מרחב הכתובות הוירטואלי נקבע על ידי מספר הביטים בכתובת הוירטואלית. בעוד שטבלאות דפים רב-שכבתיות מאפשרות לנהל מרחבי כתובות וירטואליים גדולים מאוד, הן אינן מגדילות את הגודל הטבוע; במקום זאת, הן הופכות את ניהול המרחבים הגדולים הללו לפרקטי על ידי חיסכון בזיכרון פיזי עבור טבלאות הדפים עצמן."}, "_source_file": "0139__Virtualization__Address_Space__MC__Medium.json", "_topic_hint": "Address Space", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:25:02", "_subject": "Virtualization", "_context_lectures": [5, 6, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Address Space"], "difficulty_estimation": "Medium", "content": {"text": "בהינתן מערכת המשתמשת בטבלת דפים רב-שכבתית (Multi-Level Page Table), עם מרחב כתובות וירטואלי בגודל 1GB, גודל דף של 512 בתים, ו-128 רשומות PTEs בכל דף, מהו מספר הביטים המוקצה לכל אחד מהרכיבים הבאים בכתובת וירטואלית: Offset, Page Table Index, ו-Page Directory Index?", "code_snippet": null, "options": ["א. Offset: 9 ביטים, Page Table Index: 7 ביטים, Page Directory Index: 14 ביטים.", "ב. Offset: 9 ביטים, Page Table Index: 14 ביטים, Page Directory Index: 7 ביטים.", "ג. Offset: 5 ביטים, Page Table Index: 7 ביטים, Page Directory Index: 18 ביטים.", "ד. Offset: 9 ביטים, Page Table Index: 8 ביטים, Page Directory Index: 13 ביטים."]}, "solution": {"correct_option": "א", "explanation": "הסבר מפורט:\n1.  **חישוב גודל ה-Offset:** גודל ה-Offset נקבע על ידי גודל הדף. גודל דף של 512 בתים הוא 2 בחזקת 9 (2^9), ולכן ה-Offset דורש 9 ביטים.\n2.  **חישוב גודל ה-VPN (Virtual Page Number):** מרחב הכתובות הוירטואלי הוא 1GB, שזה 2 בחזקת 30 (2^30) בתים. לכן, הכתובת הוירטואלית היא באורך 30 ביטים. גודל ה-VPN הוא סך הביטים בכתובת הוירטואלית פחות גודל ה-Offset: 30 - 9 = 21 ביטים.\n3.  **חישוב גודל ה-Page Table Index:** נתון שיש 128 רשומות PTEs בכל דף. 128 הוא 2 בחזקת 7 (2^7), ולכן ה-Page Table Index דורש 7 ביטים.\n4.  **חישוב גודל ה-Page Directory Index:** ה-Page Directory Index הוא יתר הביטים של ה-VPN לאחר שחישבנו את ה-Page Table Index: 21 - 7 = 14 ביטים.\n\nלכן, החלוקה הנכונה היא: Offset: 9 ביטים, Page Table Index: 7 ביטים, Page Directory Index: 14 ביטים. חלוקה זו תואמת במדויק לדוגמא המופיעה ב-Lecture 7, chunk 24, המדגימה את פירוק הכתובת הוירטואלית."}, "_source_file": "0140__Virtualization__Address_Space__MC__Medium.json", "_topic_hint": "Address Space", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:25:16", "_subject": "Virtualization", "_context_lectures": [5, 6, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Address Space"], "difficulty_estimation": "Medium", "content": {"text": "בהתבסס על קטע הקוד וההסברים שסופקו בחומר ההרצאה, היכן יאוחסן התוכן שאליו מצביע המשתנה `z` (כלומר `*z`) במרחב הכתובות הוירטואלי של התהליך?", "code_snippet": "int x;\nint main(int argc, char *argv[]) {\n    int y;\n    int *z = malloc(sizeof(int));\n}", "options": ["א. באזור ה-Text, שכן הוא מייצג קטע קוד של התוכנית.", "ב. באזור ה-Data, שכן הוא משתנה גלובלי או קבוע.", "ג. באזור ה-Stack, שכן המשתנה `z` עצמו הוא משתנה מקומי לפונקציה `main`.", "ד. באזור ה-Heap, שכן הזיכרון עבורו הוקצה באופן דינאמי באמצעות `malloc`."]}, "solution": {"correct_option": "ד", "explanation": "התשובה הנכונה היא ד'. על פי חומר ההרצאה (Lecture 5, chunk 24), המשתנה `z` עצמו הוא משתנה מקומי ולכן מאוחסן ב-Stack. עם זאת, התוכן שאליו מצביע `z` (כלומר `*z`) מוקצה באופן דינאמי באמצעות הפונקציה `malloc`. זיכרון המוקצה באופן דינאמי בזמן ריצה באמצעות `malloc` מאוחסן באזור ה-Heap של מרחב הכתובות הוירטואלי של התהליך. אפשרויות א' וב' שגויות מכיוון ש-`*z` אינו קוד ואינו משתנה גלובלי או קבוע. אפשרות ג' שגויה מכיוון שה-Stack מאחסן משתנים מקומיים וארגומנטים לפונקציות, אך לא את הזיכרון הדינאמי שאליו מצביע משתנה מקומי זה."}, "_source_file": "0141__Virtualization__Address_Space__MC__Medium.json", "_topic_hint": "Address Space", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:25:30", "_subject": "Virtualization", "_context_lectures": [5, 6, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Address Space"], "difficulty_estimation": "Hard", "content": {"text": "בהינתן מערכת המשתמשת בטבלת דפים היררכית (Multi-Level Page Table) כמתואר בחומר הלימוד, עם מרחב כתובות וירטואלי של 1GB (2^30), גודל דף של 512B (2^9), ו-128 רשומות לכל דף טבלת דפים (PTEs per page), מהו היתרון המרכזי של מבנה היררכי זה, בהשוואה לטבלת דפים בודדת (Single-Level Page Table) עבור מרחב כתובות וירטואלי בעל שימוש דליל (sparse)?", "code_snippet": null, "options": ["א. חיסכון משמעותי בזיכרון פיזי על ידי אי-הקצאת דפי טבלת דפים עבור חלקים לא בשימוש של מרחב הכתובות הוירטואלי.", "ב. קיצור זמן הגישה לזיכרון פיזי באמצעות צמצום מספר הגישות לטבלאות הדפים.", "ג. הגדלת מספר הדפים הפיזיים הזמינים למערכת על ידי שימוש יעיל יותר בביטים של הכתובת הווירטואלית.", "ד. פישוט תהליך ניהול ההחלפה (swapping) בין זיכרון פיזי לדיסק."]}, "solution": {"correct_option": "א", "explanation": "חומר הלימוד מתאר את טבלת הדפים ההיררכית (Multi-Level Page Table) כבעלת מבנה דמוי עץ, כאשר ה-Page Directory מכיל מצביעים לחלקים שונים של טבלת הדפים. יתרון מפתח של מבנה זה, במיוחד עבור מרחבי כתובות וירטואליים המשמשים באופן דליל (כלומר, רק חלקים קטנים ממרחב הכתובות הוירטואלי בשימוש פעיל), הוא היכולת שלא להקצות זיכרון פיזי עבור טבלאות דפים שלמות שאינן בשימוש. לדוגמה, אם אזור מסוים של מרחב הכתובות הוירטואלי אינו ממופה לשום דבר, אין צורך להקצות את דפי טבלת הדפים התואמים לו. אפשרות ב' שגויה מכיוון שטבלת דפים היררכית דווקא מגדילה את מספר הגישות לזיכרון לצורך תרגום כתובות (לדוגמה, גישה ל-Page Directory ולאחר מכן ל-Page Table). אפשרויות ג' ו-ד' אינן יתרונות ישירים או מרכזיים של מבנה טבלת דפים היררכית כפי שמתואר בחומר."}, "_source_file": "0142__Virtualization__Address_Space__MC__Hard.json", "_topic_hint": "Address Space", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:25:51", "_subject": "Virtualization", "_context_lectures": [5, 6, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Address Space"], "difficulty_estimation": "Hard", "content": {"text": "בהינתן המאפיינים הבאים עבור מרחב כתובות וירטואלי במערכת המשתמשת בטבלת דפים היררכית (Multi-Level Page Table), ובהנחה שכל טבלאות הדפים מאוכלסות במלואן:\n*   גודל מרחב כתובות וירטואלי: 16KB\n*   גודל דף: 32B\n*   גודל רשומת טבלת דפים (PTE): 2B\n*   ב-Page Directory יש 32 רשומות, וגודל כל רשומה בה הוא 2 בתים.\n\nמהו סך הזיכרון (בבתים) הנדרש לאחסון כל מבני טבלת הדפים (ה-Page Directory וכל טבלאות הדפים מהרמה השנייה) עבור תהליך בודד?", "code_snippet": null, "options": ["א. 1088 בתים", "ב. 512 בתים", "ג. 1024 בתים", "ד. 64 בתים"]}, "solution": {"correct_option": "א", "explanation": "כדי לחשב את סך הזיכרון הנדרש למבני טפי הדפים, עלינו לנתח את חלוקת הביטים בכתובת הוירטואלית ולחשב את גודל כל רמה בטבלה ההיררכית:\n\n1.  **חישוב ביטי הכתובת הוירטואלית וההיסט:**\n    *   מרחב כתובות וירטואלי: 16KB = 2^14 בתים. לכן, כתובת וירטואלית היא באורך 14 ביטים.\n    *   גודל דף: 32B = 2^5 בתים. לכן, ההיסט (Offset) הוא באורך 5 ביטים.\n    *   מספר ביטים ל-Virtual Page Number (VPN): 14 ביטים (סה\"כ) - 5 ביטים (היסט) = 9 ביטים.\n\n2.  **חישוב ביטי ה-Page Directory Index:**\n    *   נתון שב-Page Directory יש 32 רשומות. 32 = 2^5. לכן, ה-Page Directory Index הוא באורך 5 ביטים.\n\n3.  **חישוב ביטי ה-Page Table Index:**\n    *   מכיוון שה-VPN הוא 9 ביטים וה-Page Directory Index הוא 5 ביטים, הרי שה-Page Table Index הוא 9 ביטים - 5 ביטים = 4 ביטים.\n    *   כל טבלת דפים ברמה השנייה מכילה 2^4 = 16 רשומות PTE.\n\n4.  **חישוב גודל ה-Page Directory:**\n    *   מספר רשומות ב-Page Directory: 32.\n    *   גודל רשומה ב-Page Directory: 2 בתים (לפי הנתון).\n    *   גודל ה-Page Directory = 32 רשומות * 2 בתים/רשומה = 64 בתים.\n\n5.  **חישוב גודל טבלאות הדפים ברמה השנייה:**\n    *   מספר טבלאות דפים ברמה השנייה: מכיוון שה-Page Directory מאוכלס במלואו, ישנן 32 טבלאות דפים ברמה השנייה (אחת לכל רשומה ב-Page Directory).\n    *   גודל טבלת דפים אחת ברמה השנייה: 16 רשומות PTE * 2 בתים/PTE = 32 בתים.\n    *   גודל כולל של כל טבלאות הדפים ברמה השנייה = 32 טבלאות * 32 בתים/טבלה = 1024 בתים.\n\n6.  **סך הזיכרון הנדרש:**\n    *   סה\"כ = גודל ה-Page Directory + גודל טבלאות הדפים ברמה השנייה = 64 בתים + 1024 בתים = 1088 בתים.\n\nלכן, התשובה הנכונה היא א'."}, "_source_file": "0143__Virtualization__Address_Space__MC__Hard.json", "_topic_hint": "Address Space", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:26:14", "_subject": "Virtualization", "_context_lectures": [5, 6, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Address Space"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על מערכת זיכרון וירטואלי המשתמשת בטבלת דפים היררכית (Multi-Level Page Table), נתונים הפרטים הבאים:\n*   מרחב כתובות וירטואלי: 1GB (2³⁰)\n*   גודל דף: 512B (2⁹)\n*   מספר רשומות PTEs לכל דף: 128 (2⁷)\nבהינתן חלוקה זו, כמה רשומות (entries) יכולה להכיל טבלת ה-Page Directory?", "code_snippet": null, "options": ["א. 2¹⁴", "ב. 2²¹", "ג. 2⁷", "ד. 2⁹"]}, "solution": {"correct_option": "א", "explanation": "הסבר:\n1.  מרחב הכתובות הוירטואלי הוא 1GB, כלומר 2 בחזקת 30 בתים, ולכן כתובת וירטואלית מיוצגת על ידי 30 ביטים.\n2.  גודל הדף הוא 512B, כלומר 2 בחזקת 9 בתים, ולכן ההיסט (Offset) דורש 9 ביטים.\n3.  מספר הביטים של ה-Virtual Page Number (VPN) הוא סך הביטים פחות ביטי ההיסט: 30 - 9 = 21 ביטים.\n4.  המערכת משתמשת בטבלת דפים היררכית (Multi-Level Page Table). הנתון \"מספר רשומות PTEs לכל דף: 128 (2⁷)\" אומר שכל טבלת דפים מהרמה השנייה (Page Table), שנמצאת בעצמה בדף זיכרון אחד, יכולה להכיל 2 בחזקת 7 רשומות. משמעות הדבר היא שאינדקס ה-Page Table (החלק ב-VPN שמצביע על רשומה בתוך טבלת דפים ספציפית) דורש 7 ביטים.\n5.  את יתרת הביטים של ה-VPN משמשים לאינדקס ה-Page Directory. מספר הביטים לאינדקס ה-Page Directory הוא: 21 (VPN ביטים) - 7 (Page Table Index ביטים) = 14 ביטים.\n6.  מספר הרשומות שיכולה להכיל טבלת ה-Page Directory הוא 2 בחזקת מספר הביטים של האינדקס שלה. לכן, 2 בחזקת 14 רשומות.\nהאפשרות הנכונה היא א'."}, "_source_file": "0144__Virtualization__Address_Space__MC__Hard.json", "_topic_hint": "Address Space", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:26:33", "_subject": "Virtualization", "_context_lectures": [5, 6, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Threads"], "difficulty_estimation": "Easy", "content": {"text": "מהי ההתנהגות של חוט (thread) שקורא לפונקציה `pthread_join`?", "code_snippet": null, "options": ["א. החוט הקורא הופך חסום (blocked) וממתין עד שהחוט שצוין כארגומנט יסיים את ריצתו.", "ב. החוט הקורא ממשיך לרוץ במקביל לחוט שצוין, ללא המתנה.", "ג. החוט הקורא מסיים את התהליך כולו באופן מיידי.", "ד. החוט הקורא מבטל את ריצת החוט שצוין ומסיים אותו."]}, "solution": {"correct_option": "א", "explanation": "כפי שנלמד בחומר ההרצאה, כאשר חוט קורא לפונקציה `pthread_join(th, ...)`, החוט הקורא (החוט שביצע את הקריאה) הופך להיות חסום (blocked) והוא ממתין עד שהחוט שצוין כארגומנט (`th`) יסיים את ריצתו. רק לאחר שהחוט הממתין לו מסיים, החוט הקורא ממשיך בביצוע השורות הבאות בקוד. אפשרות ב' אינה נכונה מכיוון ש-`pthread_join` היא פונקציית המתנה. אפשרות ג' אינה נכונה מכיוון שסיום תהליך שלם אינו ההתנהגות הישירה של `pthread_join`. אפשרות ד' מתארת את `pthread_cancel` ולא את `pthread_join`."}, "_source_file": "0145__Concurrency__Threads__MC__Easy.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:26:42", "_subject": "Concurrency", "_context_lectures": [10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Threads"], "difficulty_estimation": "Easy", "content": {"text": "איזו מהטענות הבאות נכונה לגבי הפונקציה `pthread_join`?", "code_snippet": null, "options": ["א. כל חוט יכול לעשות join לכל חוט אחר באותו תהליך.", "ב. רק חוט אב יכול לעשות join לחוט ילד.", "ג. קריאה ל-`pthread_join` גורמת לחוט שאליו מצטרפים להיחסם.", "ד. הפונקציה `pthread_join` משמשת ליצירת חוט חדש בתהליך."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מציין במפורש: \"כל חוט יכול לעשות join לכל חוט אחר באותו תהליך, ולא צריך יחסי אב וילדים.\" לכן, אפשרות א' נכונה. אפשרות ב' שגויה מכיוון שאין צורך ביחסי אב-ילד. אפשרות ג' שגויה, שכן החוט שקורא ל-`pthread_join` הוא זה שנחסם וממתין, ולא החוט שאליו מצטרפים. אפשרות ד' שגויה, `pthread_join` ממתינה לסיום חוט קיים, בעוד ש-`pthread_create` היא הפונקציה ליצירת חוט חדש."}, "_source_file": "0146__Concurrency__Threads__MC__Easy.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:26:50", "_subject": "Concurrency", "_context_lectures": [10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Threads"], "difficulty_estimation": "Easy", "content": {"text": "מהי ההשפעה העיקרית של קריאה לפונקציה `pthread_join` על החוט המבצע את הקריאה?", "code_snippet": "int pthread_join(\n    pthread_t th,\n    void **thread_return);", "options": ["א. החוט המבצע את הקריאה ממשיך בריצה רגילה במקביל לחוט שעבורו נקראה הפונקציה.", "ב. החוט המבצע את הקריאה נחסם (blocked) וממתין עד שהחוט שעבורו נקראה הפונקציה יסיים את ריצתו.", "ג. החוט שעבורו נקראה הפונקציה נחסם באופן מיידי וממתין לאישור מהחוט המבצע את הקריאה.", "ד. החוט המבצע את הקריאה מסיים את ריצתו באופן מיידי."]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר ההרצאה, כאשר חוט מבצע קריאה לפונקציה `pthread_join`, הוא 'הופך להיות blocked כלומר הוא נחסם והוא מחכה' עד שהחוט שעבורו נקראה הפונקציה יסיים את ריצתו. רק לאחר שהחוט הממתין לו מסיים, החוט הקורא ממשיך בביצוע. האפשרויות האחרות אינן מתארות נכונה את התנהגות `pthread_join`."}, "_source_file": "0147__Concurrency__Threads__MC__Easy.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:27:00", "_subject": "Concurrency", "_context_lectures": [10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Threads"], "difficulty_estimation": "Medium", "content": {"text": "איזו טענה נכונה לגבי השימוש בפונקציה pthread_join בהקשר של חוטים באותו תהליך?", "code_snippet": null, "options": ["א. רק חוטים שנוצרו על ידי חוט האב יכולים להצטרף (join) אליו.", "ב. כל חוט בתהליך יכול להצטרף (join) לכל חוט אחר באותו תהליך, ללא צורך ביחסי אב וילד.", "ג. קריאה ל-pthread_join חוסמת את החוט הקורא רק אם לחוט המצטרף יש ערך החזר.", "ד. pthread_join משמשת בעיקר לביטול חוטים (cancel threads) ואינה גורמת לחסימה."]}, "solution": {"correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. לפי חומר ההרצאה, 'כל חוט יכול לעשות join לכל חוט אחר באותו תהליך, ולא צריך יחסי אב וילדים'. אפשרות א' אינה נכונה מכיוון שהיא מציגה הגבלה של יחסי אב-ילד שאינה קיימת עבור pthread_join. אפשרות ג' אינה נכונה מכיוון שקריאה ל-pthread_join תמיד חוסמת את החוט הקורא עד שהחוט המיועד מסתיים, ללא קשר לשאלה אם יש ערך החזר או אם הוא נאסף, כפי שמצוין בחומר: 'הופך להיות blocked כלומר הוא נחסם והוא מחכה'. אפשרות ד' אינה נכונה מכיוון ש-pthread_join נועדה להמתין לסיום חוטים ולחסום את החוט הקורא, בעוד שביטול חוטים מתבצע באמצעות פונקציה אחרת (pthread_cancel)."}, "_source_file": "0148__Concurrency__Threads__MC__Medium.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:27:14", "_subject": "Concurrency", "_context_lectures": [10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Threads"], "difficulty_estimation": "Medium", "content": {"text": "איזו מהטענות הבאות מתארת בצורה הנכונה ביותר את אופן הפעולה והמאפיינים של הפונקציה `pthread_join`?", "code_snippet": "pthread_t thread_id;\nvoid *thread_result;\n\n// ... יצירת thread_id ...\n\nint status = pthread_join(thread_id, &thread_result);\n// לאחר שורה זו, thread_id סיים את ריצתו, וערך ההחזר שלו נמצא ב-thread_result", "options": ["א. חוט המבצע קריאה ל-`pthread_join` נחסם (blocked) וממתין עד שהחוט שאליו הוא מצטרף (th) יסיים את ריצתו. כל חוט בתוך התהליך יכול לבצע join לכל חוט אחר באותו תהליך.", "ב. הפונקציה `pthread_join` מאפשרת לחוט הקורא להמשיך בריצתו באופן אסינכרוני תוך כדי בדיקה תקופתית אם החוט שאליו הוא מצטרף סיים, בדומה ל-busy-waiting.", "ג. `pthread_join` יכולה להתבצע רק על ידי חוט האב (parent thread) שייצר את חוט הילד (child thread), ובכך לקבל את ערך ההחזר שלו.", "ד. קריאה ל-`pthread_join` תמיד גורמת לסיום מיידי של התהליך כולו ברגע שהחוט שאליו הצטרפו סיים, ללא קשר לסטטוס של חוטים אחרים בתהליך."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה, כאשר חוט מבצע קריאה ל-`pthread_join`, 'הוא הופך להיות blocked כלומר הוא נחסם והוא מחכה' עד שהחוט המיועד יסיים את ריצתו. בנוסף, חומר ההרצאה מציין במפורש כי 'כל חוט יכול לעשות join לכל חוט אחר באותו תהליך, ולא צריך יחסי אב וילדים'.\n\nתשובה ב' שגויה מכיוון ש-`pthread_join` היא קריאה חוסמת (blocking) ולא אסינכרונית או מבוססת busy-waiting. busy-waiting הוא מנגנון סנכרון שונה המוצג בחומר ההרצאה (במנגנון הדגלים), אך אינו קשור לאופן הפעולה של `pthread_join`.\n\nתשובה ג' שגויה מכיוון שחומר ההרצאה קובע במפורש כי 'כל חוט יכול לעשות join לכל חוט אחר באותו תהליך, ולא צריך יחסי אב וילדים', מה שמפריך את הטענה שרק חוט אב יכול לבצע join על חוט ילד.\n\nתשובה ד' שגויה מכיוון ש-`pthread_join` גורמת לחוט הקורא להמתין לחוט ספציפי אחד בלבד, ואינה גורמת בהכרח לסיום מיידי של התהליך כולו. סיום התהליך תלוי בגורמים אחרים, כמו קריאה ל-`exit()` מכל חוט, או במקרה מיוחד של `pthread_exit` מהחוט הראשי הממתין לסיום כל החוטים האחרים, אך לא `pthread_join`."}, "_source_file": "0149__Concurrency__Threads__MC__Medium.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:27:31", "_subject": "Concurrency", "_context_lectures": [10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Threads"], "difficulty_estimation": "Medium", "content": {"text": "איזו מהטענות הבאות מתארת נכונה את פעולת הפונקציה pthread_join?", "code_snippet": null, "options": ["א. הפונקציה גורמת לחוט הקורא להיחסם (blocked) עד שהחוט המיועד (target thread) מסיים את ריצתו.", "ב. הפונקציה מאפשרת לחוט אב בלבד להמתין לסיום ריצתם של חוטי הבן שלו.", "ג. הפונקציה מיועדת ליצירת חוט חדש בתוך התהליך הנוכחי.", "ד. הפונקציה מביאה לסיום מיידי של החוט המיועד, ללא קשר למצב ריצתו."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה (Lecture 10, chunk 31), כאשר חוט מבצע קריאה ל-pthread_join, הוא \"הופך להיות blocked כלומר הוא נחסם והוא מחכה\" עד שהחוט שהועבר כארגומנט יסיים את ריצתו. טענה ב' אינה נכונה, מכיוון שחומר ההרצאה מציין במפורש: \"כל חוט יכול לעשות join לכל חוט אחר באותו תהליך, ולא צריך יחסי אב וילדים\" (Lecture 10, chunk 32). טענה ג' אינה נכונה; pthread_join משמשת להמתנה לסיום חוט קיים, ולא ליצירת חוט חדש (לשם כך קיימת pthread_create). טענה ד' אינה נכונה; pthread_join אינה מביאה לסיום מיידי של חוט, אלא ממתינה לסיום הטבעי שלו או לסיום מבוקר על ידי pthread_exit. הפסקת חוט באופן מיידי מתבצעת על ידי pthread_cancel."}, "_source_file": "0150__Concurrency__Threads__MC__Medium.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:27:41", "_subject": "Concurrency", "_context_lectures": [10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Threads"], "difficulty_estimation": "Hard", "content": {"text": "נתון קטע הקוד הבא:\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n\nvoid* worker_thread(void* arg) {\n    printf(\"Worker thread: Starting work...\\n\");\n    sleep(5); // Simulate long computation\n    printf(\"Worker thread: Done.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid;\n    printf(\"Main thread: Creating worker thread.\\n\");\n    pthread_create(&tid, NULL, worker_thread, NULL);\n    printf(\"Main thread: Calling pthread_exit().\\n\");\n    pthread_exit(NULL); // Key point\n    printf(\"Main thread: This line will not be reached.\\n\");\n    return 0;\n}\n```\nבהתבסס על קטע הקוד שלעיל והבנתך את אופן פעולת `pthread_exit()` כאשר הוא נקרא מהחוט הראשי, מה תהיה התוצאה הסופית של התהליך?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n\nvoid* worker_thread(void* arg) {\n    printf(\"Worker thread: Starting work...\\n\");\n    sleep(5); // Simulate long computation\n    printf(\"Worker thread: Done.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid;\n    printf(\"Main thread: Creating worker thread.\\n\");\n    pthread_create(&tid, NULL, worker_thread, NULL);\n    printf(\"Main thread: Calling pthread_exit().\\n\");\n    pthread_exit(NULL); // Key point\n    printf(\"Main thread: This line will not be reached.\\n\");\n    return 0;\n}", "options": ["א. התהליך יסתיים מיד לאחר קריאת `pthread_exit()` בחוט הראשי, ולפני שהחוט `worker_thread` יסיים את פעולתו.", "ב. התהליך ימשיך לרוץ עד שכל החוטים שאינם החוט הראשי (במקרה זה, `worker_thread`) יסיימו את פעולתם, ורק אז התהליך יסתיים.", "ג. הקריאה ל-`pthread_exit()` בחוט הראשי תגרום לשגיאת זמן ריצה (runtime error) מכיוון שחוט ראשי אינו יכול לצאת לפני שכל החוטים הצאצאים שלו סיימו.", "ד. החוט הראשי ימתין באופן פעיל (busy-wait) עד ש-`worker_thread` יסיים את פעולתו, ואז התהליך יסתיים."]}, "solution": {"correct_option": "ב", "explanation": "החומר המצורף מציין במפורש: \"מקרה אחד מיוחד: כשהחוט הראשי קורא ל-()pthread_exit, כלומר כאשר החוט הראשי מסתיים ע\"י הקריאה הזו, הוא לא מסיים את התהליך. מערכת ההפעלה מחכה עד שכל החוטים בתהליך הזה יסיימו ורק אז התהליך יסתיים. כלומר, כאשר החוט הראשי קורא לקריאה זו, הוא מסיים מבלי לסיים את התהליך.\" בהתאם לכך, בקטע הקוד הנתון, החוט הראשי קורא ל-`pthread_exit(NULL)` אך התהליך כולו לא יסתיים מיד. במקום זאת, מערכת ההפעלה תאפשר לחוט `worker_thread` להמשיך בריצתו ולסיים את פעולתו (כולל ההמתנה של 5 השניות). רק לאחר שכל החוטים שאינם הראשי (במקרה זה, `worker_thread`) יסיימו, התהליך כולו יסתיים. זאת בניגוד לקריאה ל-`exit()` מכל חוט, שהייתה גורמת לסיום מיידי של כל התהליך וכל החוטים שבו."}, "_source_file": "0151__Concurrency__Threads__MC__Hard.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:27:57", "_subject": "Concurrency", "_context_lectures": [10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Threads"], "difficulty_estimation": "Hard", "content": {"text": "בהינתן תהליך המכיל מספר חוטים (threads), כולל חוט ראשי (main thread) וחוטי עבודה (worker threads), ובהתבסס על מנגנוני הסיום וההמתנה של חוטים, איזו מהטענות הבאות נכונה ביותר?", "code_snippet": null, "options": ["א. חוט עבודה יכול להמתין לסיום של חוט עבודה אחר באמצעות pthread_join, וזאת ללא קשר ליחסי אב-בן ביניהם. אם החוט הראשי יקרא ל-pthread_exit, הוא יסיים את פעולתו אך התהליך ימתין לסיום כל חוטי העבודה לפני שיסתיים.", "ב. רק החוט הראשי יכול להמתין לסיום של חוטי עבודה באמצעות pthread_join. אם חוט כלשהו, כולל החוט הראשי, יקרא ל-exit(), רק אותו חוט יסיים את פעולתו בעוד שאר החוטים ימשיכו לרוץ עד לסיום טבעי או קריאה ל-pthread_exit מצידם.", "ג. במימוש של User Threads, מערכת ההפעלה מודעת לכל החוטים הפועלים בתוך תהליך ומבצעת את תזמונם, אך היא אינה מאפשרת לחוטים להמתין זה לזה באמצעות pthread_join כיוון שאין להם מזהים ייחודיים ברמת הליבה.", "ד. קריאה ל-pthread_join תמיד חוסמת את התהליך כולו עד שהחוט המיועד מסתיים. אם החוט הראשי קורא ל-pthread_exit, כל החוטים האחרים בתהליך יסיימו באופן מיידי כדי למנוע מצב של חוטים יתומים."]}, "solution": {"correct_option": "א", "explanation": "הטענה הנכונה ביותר היא א'. לפי חומר ההרצאה (chunk 32), 'כל חוט יכול לעשות join לכל חוט אחר באותו תהליך, ולא צריך יחסי אב וילדים'. זה מאשר שחוט עבודה יכול להמתין לחוט עבודה אחר. בנוסף, חומר ההרצאה (chunk 40) מציין במפורש כי 'כאשר החוט הראשי קורא ל-()pthread_exit... הוא לא מסיים את התהליך. מערכת ההפעלה מחכה עד שכל החוטים בתהליך הזה יסיימו ורק אז התהליך יסתיים'.\n\nטענה ב' אינה נכונה מכיוון ש'כל חוט יכול לעשות join לכל חוט אחר' (chunk 32), ולא רק החוט הראשי. כמו כן, 'exit() on any thread will exit all threads!' (chunk 40), ולא רק החוט הקורא.\n\nטענה ג' אינה נכונה מכיוון שבמימוש של User Threads, 'מערכת ההפעלה לא מכירה חוטים, אלא רק תהליכים' (chunk 17), ולכן היא אינה מודעת לכל החוטים ואינה מתזמנת אותם ברמת הליבה.\n\nטענה ד' אינה נכונה מכיוון ש-pthread_join חוסם את ה'חוט שביצע את הקריאה' (chunk 31) ולא את התהליך כולו. כמו כן, כפי שהוזכר לעיל, קריאה ל-pthread_exit מהחוט הראשי גורמת למערכת ההפעלה להמתין לסיום כל החוטים, ולא לסיום מיידי שלהם."}, "_source_file": "0152__Concurrency__Threads__MC__Hard.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:28:15", "_subject": "Concurrency", "_context_lectures": [10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Threads"], "difficulty_estimation": "Hard", "content": {"text": "בהתייחס למימוש חוטים ברמת המשתמש (User Threads), מהי ההשלכה העיקרית על תהליך המכיל חוטים כאלה, כאשר אחד מחוטיו מבצע קריאת מערכת חוסמת (blocking system call)?", "code_snippet": null, "options": ["א. רק החוט שביצע את הקריאה החוסמת ייחסם, וספריית החוטים ברמת המשתמש תעביר את בקרת המעבד לחוט משתמש אחר באותו התהליך.", "ב. התהליך כולו ייחסם, שכן מבחינת מערכת ההפעלה, היא רואה רק את התהליך כיחידת ביצוע אחת ואינה מודעת לחוטים הפנימיים שלו.", "ג. מערכת ההפעלה תזהה את החסימה ותמיר באופן אוטומטי את חוט המשתמש לחוט ליבה, כדי לאפשר לחוטים אחרים באותו תהליך להמשיך לרוץ.", "ד. ספריית החוטים תבקש ממערכת ההפעלה לבצע קריאת מערכת לא חוסמת במקום, כדי למנוע את חסימת התהליך."]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר ההרצאה, במימוש חוטים ברמת המשתמש (User Threads), 'מערכת ההפעלה לא מכירה חוטים, אלא רק תהליכים והיא מנהלת תהליכים'. המשמעות היא שמבחינת מערכת ההפעלה, 'אין דבר כזה חוטים, יש תהליך שמריץ דבר אחד בכל רגע נתון'. כאשר חוט משתמש אחד מבצע קריאת מערכת חוסמת (blocking system call), מערכת ההפעלה רואה זאת כפעולה חוסמת של התהליך כולו, שכן היא אינה מבחינה בחוטים בודדים בתוך התהליך. לכן, התהליך כולו ייחסם עד להשלמת קריאת המערכת, וזוהי הסיבה המצוינת בחומר ההרצאה כ'חיסרון בגישה' במקרים של 'פעולה שהיא blocking'."}, "_source_file": "0153__Concurrency__Threads__MC__Hard.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:28:38", "_subject": "Concurrency", "_context_lectures": [10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Multi-core Processors"], "difficulty_estimation": "Easy", "content": {"text": "מהו אחד היתרונות המרכזיים של תזמון מעבדים מרובי תורים (Multi-queue multiprocessor scheduling) במערכות מרובות ליבות, כפי שמתואר בחומר הלימוד?", "code_snippet": null, "options": ["א. הוא מאפשר לכל המעבדים לשתף תור עבודה יחיד ביעילות.", "ב. הוא משפר באופן טבעי את ה-cache affinity (זיקת מטמון).", "ג. הוא מבטל את הצורך בחוטי ליבה (kernel threads).", "ד. הוא מפחית את מספר ה-context switches הנדרשים בין תהליכים שונים."]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר הלימוד (Lecture 15, chunk 29), אחד היתרונות המרכזיים של תזמון מעבדים מרובי תורים (Multi-queue multiprocessor scheduling) הוא שיש לו 'cache affinity באופן טבעי: ברגע שג'וב מסוים מגיע, הוא מקבל תור, משויך למעבד ותמיד הוא יורץ על אותו המעבד.' יתרון זה מודגש כפתרון לבעיות שהיו בתזמונים קודמים בהקשר של זיקת מטמון. אפשרות א' אינה נכונה מכיוון שתזמון מרובה תורים פירושו שלכל מעבד יש תור משלו, ולא תור משותף. אפשרויות ג' ו-ד' אינן מוזכרות כיתרונות מרכזיים או ישירים של שיטה זו בחומר הלימוד."}, "_source_file": "0154__Concurrency__Multi-core_Processors__MC__Easy.json", "_topic_hint": "Multi-core Processors", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:28:48", "_subject": "Concurrency", "_context_lectures": [10, 12, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Multi-core Processors"], "difficulty_estimation": "Easy", "content": {"text": "איזו גישת תזמון במערכות מרובות מעבדים (multi-core processors) משפרת באופן טבעי את ה-cache affinity?", "code_snippet": null, "options": ["א. תזמון המעביר ג'ובים בין מעבדים שונים בכל קוואנטה.", "ב. תזמון המשתמש בתור משימות יחיד עבור כל המעבדים.", "ג. תזמון מרובה תורים למעבדים (Multi-queue multiprocessor scheduling), שבו לכל מעבד יש תור משלו.", "ד. תזמון שבו כל חוט (thread) מומר לתהליך (process) נפרד לפני ריצה."]}, "solution": {"correct_option": "ג", "explanation": "על פי חומר ההרצאה, תזמון מרובה תורים למעבדים (Multi-queue multiprocessor scheduling) מטפל בבעיית ה-cache affinity באופן טבעי. בגישה זו, לכל מעבד יש תור משלו, וברגע שג'וב מגיע הוא משויך לתור של מעבד ספציפי ורץ תמיד על אותו המעבד. דבר זה מבטיח שהנתונים שהג'וב משתמש בהם יישארו במטמון הפרטי של אותו מעבד (cache affinity), ובכך משפר את ביצועי המערכת. לעומת זאת, גישות כמו תזמון המעביר ג'ובים בין מעבדים (כמו SQMS שהוזכר כבעל cache affinity גרוע) פוגעות ב-cache affinity."}, "_source_file": "0155__Concurrency__Multi-core_Processors__MC__Easy.json", "_topic_hint": "Multi-core Processors", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:28:58", "_subject": "Concurrency", "_context_lectures": [10, 12, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Multi-core Processors"], "difficulty_estimation": "Easy", "content": {"text": "מהו היתרון העיקרי בשמירה על 'זיקת מטמון' (cache affinity) במערכת מרובת ליבות?", "code_snippet": null, "options": ["א. שיפור ביצועים על ידי גישה מהירה יותר לנתונים מהמטמון המקומי של המעבד.", "ב. הפחתת עומס החלפת ההקשר (context switch) בין תהליכים.", "ג. פישוט התקשורת בין תהליכים (IPC).", "ד. הבטחת מקביליות אמיתית לכל ה-threads במערכת."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, 'אידיאלית, היינו רוצים תזמון כזה ששומר על cache affinity (כלומר שתהליך ירוץ על המעבד הראשון שהריץ אותו)'. הסיבה לכך היא שלכל מעבד במערכת מרובת ליבות יש מטמון (cache L1) פרטי ומהיר משלו. שמירה על זיקת מטמון מבטיחה שהתהליך ימשיך לרוץ על אותו מעבד, וכך הנתונים שהוא זקוק להם יימצאו כבר במטמון המקומי והמהיר של אותו מעבד. זה מוביל ל'זיכרון של התוכנית שלנו נראה מהיר', ובכך לשיפור בביצועים, מכיוון ש'אם כל פעם שהיינו קוראים מהזיכרון, המעבד באמת היה ניגש לזיכרון, הביצועים שלנו היו גרועים'."}, "_source_file": "0156__Concurrency__Multi-core_Processors__MC__Easy.json", "_topic_hint": "Multi-core Processors", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:29:11", "_subject": "Concurrency", "_context_lectures": [10, 12, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Multi-core Processors"], "difficulty_estimation": "Medium", "content": {"text": "בתזמון תהליכים במעבדים מרובי ליבות, מדוע שמירה על \"זיקת מטמון\" (cache affinity) נחשבת ליתרון משמעותי?", "code_snippet": null, "options": ["א. היא מפחיתה את הצורך בנעילות (locks) בין מעבדים שונים, מכיוון שכל תהליך משויך למעבד קבוע.", "ב. היא מבטיחה שנתונים שבהם התהליך השתמש בעבר יישארו במטמון הפרטי של המעבד, ובכך משפרת את ביצועי הגישה לזיכרון.", "ג. היא מאפשרת לכל תהליך לגשת לזיכרון הראשי (RAM) בקצב מהיר יותר, על ידי עקיפת מגבלות רוחב הפס של ה-BUS.", "ד. היא מאפשרת למערכת ההפעלה להריץ מספר תהליכים במקביל על ליבות שונות, ובכך להשיג מקביליות אמיתית."]}, "solution": {"correct_option": "ב", "explanation": "שמירה על זיקת מטמון (cache affinity) פירושה שתהליך ירוץ ככל הניתן על אותו מעבד שהריץ אותו בעבר. היתרון בכך נובע מהעובדה שבמערכות מרובות ליבות, לכל מעבד יש מטמון (cache) פרטי משלו. כאשר תהליך רץ על מעבד מסוים, הנתונים וההוראות שבהם הוא משתמש נטענים למטמון הפרטי של אותו מעבד. אם התהליך עובר למעבד אחר, הוא מאבד את הנתונים הללו מהמטמון הישן, ונדרש לטעון אותם מחדש למטמון של המעבד החדש. טעינה מחדש של נתונים מהזיכרון הראשי (RAM) היא פעולה יקרה ואיטית יחסית (כמה עשרות מחזורי שעון, ושימוש ב-BUS). לכן, שמירה על זיקת מטמון ממקסמת את הסיכוי שהנתונים הרלוונטיים לתהליך כבר יהיו זמינים במטמון המקומי של המעבד, ובכך משפרת משמעותית את ביצועי הגישה לזיכרון ומאיצה את ביצוע התהליך. אפשרות א' מתארת יתרון של Multi-queue multiprocessor scheduling, אשר באופן טבעי משיג cache affinity, אך זו אינה הסיבה הישירה לחשיבות ה-cache affinity עצמה. אפשרויות ג' ו-ד' אינן קשורות ישירות ליתרון הספציפי של cache affinity."}, "_source_file": "0157__Concurrency__Multi-core_Processors__MC__Medium.json", "_topic_hint": "Multi-core Processors", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:29:26", "_subject": "Concurrency", "_context_lectures": [10, 12, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Multi-core Processors"], "difficulty_estimation": "Medium", "content": {"text": "על פי חומר ההרצאה, מהו היתרון העיקרי של תזמון מעבדים מרובי תורים (Multi-queue Multiprocessor Scheduling) בסביבת מעבדים מרובי ליבות?", "code_snippet": null, "options": ["א. הוא מבטיח cache affinity טבעי, שכן כל ג'וב משויך למעבד ספציפי ורץ עליו באופן קבוע.", "ב. הוא מפחית את הצורך במנעולים (locks) באופן מוחלט בכל מצבי הוספת ג'ובים לתורים.", "ג. הוא משפר באופן משמעותי את ניצול רוחב הפס של ה-BUS בין המעבדים לזיכרון הראשי.", "ד. הוא מאפשר לג'וב יחיד לרוץ במקביל על מספר ליבות שונות בו-זמנית."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מציין במפורש את היתרונות של תזמון מעבדים מרובי תורים (Multi-queue multiprocessor scheduling). אחד היתרונות המודגשים ביותר הוא שיש 'cache affinity באופן טבעי: ברגע שג'וב מסוים מגיע, הוא מקבל תור, משויך למעבד ותמיד הוא יורץ על אותו המעבד'. זוהי תכונה קריטית לביצועים בסביבת מעבדים מרובי ליבות, כיוון שכל ליבה מצוידת ב-cache פרטי משלה (L1), ושמירה על ג'וב על אותה ליבה מונעת את הצורך בטעינה מחדש של נתונים מהזיכרון הראשי האיטי יותר. אפשרות ב' אינה נכונה לחלוטין מכיוון שהחומר מציין ש'מדי פעם כשמוסיפים באופן מקבילי ייתכן שיידרש מנעול'. אפשרות ג' אינה נתמכת בחומר ההרצאה כיתרון של תזמון זה. אפשרות ד' אינה נכונה, שכן תזמון מרובה תורים משייך ג'וב למעבד ספציפי, ולא מאפשר לג'וב יחיד לרוץ על מספר ליבות במקביל (אלא אם מדובר בחוטים שונים של אותו ג'וב)."}, "_source_file": "0158__Concurrency__Multi-core_Processors__MC__Medium.json", "_topic_hint": "Multi-core Processors", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:29:38", "_subject": "Concurrency", "_context_lectures": [10, 12, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Multi-core Processors"], "difficulty_estimation": "Medium", "content": {"text": "איזה מהיתרונות הבאים של תזמון מרובה תורים (Multi-queue multiprocessor scheduling) במערכות מרובות ליבות תורם ישירות לשיפור ביצועי המערכת על ידי ניצול יעיל של זיכרון המטמון (cache)?", "code_snippet": null, "options": ["א. שיפור ה-cache affinity על ידי הבטחה שתהליך ירוץ על אותו מעבד אליו שויך בתחילה, ובכך מקטין את הצורך בטעינת נתונים מחדש מזיכרון הראשי.", "ב. הפחתה משמעותית של הצורך במנגנוני נעילה (locks) בין מעבדים שונים, כיוון שכל מעבד מנהל תור עבודה משלו.", "ג. אפשרות למעבר מהיר ויעיל יותר של תהליכים בין מעבדים שונים כדי לאזן עומסים באופן דינמי.", "ד. הקטנת העלות של יצירת חוטים חדשים (kernel threads) ושל החלפת הקשר (context switch) ביניהם."]}, "solution": {"correct_option": "א", "explanation": "תזמון מרובה תורים (Multi-queue multiprocessor scheduling) מקצה לכל מעבד תור עבודה משלו. ברגע שתהליך משויך לתור של מעבד מסוים, הוא ירוץ באופן עקבי על אותו מעבד. עקביות זו מבטיחה שימור של \"cache affinity\", כלומר, הנתונים שהתהליך השתמש בהם בעבר נשארים במטמון הפרטי (L1 cache) של אותו מעבד. כתוצאה מכך, פחות נדרש לגשת לזיכרון הראשי (RAM) האיטי יותר, והתהליך יכול לגשת לנתונים שלו במהירות גבוהה יותר מהמטמון, מה שמשפר משמעותית את ביצועי המערכת. אפשרויות ב', ג' ו-ד' מתארות היבטים אחרים או שגויים: אפשרות ב' היא אכן יתרון של השיטה אך אינה קשורה ישירות לניצול המטמון. אפשרות ג' מתארת פעולה שמנוגדת ל-cache affinity ופוגעת בביצועים. אפשרות ד' מתייחסת לעלות של חוטים, שאינה קשורה ישירות לשיטת התזמון או ל-cache affinity."}, "_source_file": "0159__Concurrency__Multi-core_Processors__MC__Medium.json", "_topic_hint": "Multi-core Processors", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:29:51", "_subject": "Concurrency", "_context_lectures": [10, 12, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Multi-core Processors"], "difficulty_estimation": "Hard", "content": {"text": "בסביבת מעבדים מרובי ליבות (multi-core processors), מדיניות תזמון המבטיחה \"זיקת מטמון גבוהה\" (high cache affinity), כגון Multi-queue multiprocessor scheduling, תורמת באופן משמעותי לביצועי המערכת. בהתחשב בארכיטקטורת החומרה הטיפוסית המתוארת בחומר הקורס, איזה מההסברים הבאים מתאר בצורה המדויקת ביותר את היתרון התאורטי המרכזי של זיקת מטמון גבוהה על ביצועי המערכת?", "code_snippet": null, "options": ["א. היא מפחיתה את מספר הגישות לזיכרון הראשי (RAM) ומצמצמת את העומס על אפיק הנתונים (BUS) המשותף, ובכך משפרת את זמני התגובה של התהליכים ומונעת צווארי בקבוק.", "ב. היא מאפשרת למערכת ההפעלה להשתמש בפחות נעילות (locks) על תורי התזמון, מה שמפשט את הקוד של ה-scheduler ומקטין את תקורת המערכת.", "ג. היא מבטיחה שכל תהליך יקבל קוואנטת זמן ארוכה יותר לביצוע, מה שמוביל להפחתה במספר החלפות ההקשר (context switches) הכולל.", "ד. היא מאפשרת למעבדים לשתף ביניהם את תכולת המטמון (cache content) בצורה יעילה יותר, ובכך למנוע כפילויות מידע בין הליבות השונות."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. זיקת מטמון גבוהה פירושה שתהליך נוטה להמשיך לרוץ על אותה ליבה (מעבד) שהריצה אותו בעבר. כפי שמצוין בחומר הקורס (Lecture 15, chunk 22), לכל ליבה יש מטמון (cache) פרטי משלה. כאשר תהליך נשאר על אותה ליבה, הנתונים וההוראות שהוא זקוק להם נמצאים סביר להניח כבר במטמון הפרטי של הליבה (בזכות עקרונות ה-temporal וה-spatial locality). הדבר מפחית באופן דרמטי את הצורך לגשת לזיכרון הראשי (RAM), שהוא איטי משמעותית (עשרות מחזורי שעון, Lecture 12, chunk 31). פחות גישות ל-RAM מובילות בתורן לפחות עומס על אפיק הנתונים המשותף (BUS), שהוא רכיב חומרה המאפשר להעביר רק הודעה אחת בכל רגע נתון (Lecture 12, chunk 31). הפחתת העומס על ה-BUS מונעת צווארי בקבוק ומשפרת את הביצועים הכוללים של המערכת על ידי צמצום זמני ההמתנה לגישה לזיכרון.\nאפשרויות ב', ג' ו-ד' אינן נכונות:\nב. אמנם תזמון Multi-queue אכן מפחית את הצורך בנעילות על תורי התזמון (Lecture 15, chunk 29), אך זוהי תכונה של מדיניות התזמון הספציפית ולא היתרון התאורטי המרכזי של זיקת מטמון *עצמה* בהקשר של ארכיטקטורת החומרה.\nג. זיקת מטמון אינה קשורה ישירות לאורך קוואנטת הזמן או למספר החלפות ההקשר. היא משפרת את *איכות* הרצת התהליך על המעבד, לא את *משך* הרצתו הרציפה.\nד. חומר הקורס מציין מפורשות שלכל מעבד יש מטמון פרטי משלו (Lecture 15, chunk 22), וזיקת מטמון משמעותה להישאר על המטמון הפרטי הזה, לא לשתף תכולת מטמון בין ליבות."}, "_source_file": "0160__Concurrency__Multi-core_Processors__MC__Hard.json", "_topic_hint": "Multi-core Processors", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:30:12", "_subject": "Concurrency", "_context_lectures": [10, 12, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Multi-core Processors"], "difficulty_estimation": "Hard", "content": {"text": "במערכות הפעלה מודרניות המותאמות למעבדים מרובי ליבות, תזמון מסוג Multi-Queue Multiprocessor Scheduling (MQMS) נחשב לגישה עדיפה על פני תזמונים שבהם תהליכים (או חוטים) עשויים לנדוד בחופשיות בין ליבות. בהתבסס על ההבנה שכל ליבה במעבד מרובה ליבות כוללת מטמון פרטי משלה, איזו מהטענות הבאות מסבירה בצורה המקיפה ביותר את היתרון המשמעותי של MQMS בהקשר של שיפור ביצועי המערכת הכוללים, מעבר לשימור ה-cache affinity הישיר?", "code_snippet": null, "options": ["א. MQMS מפחית באופן דרמטי את הצורך במנגנוני נעילה מורכבים לשיתוף נתוני המתזמן בין ליבות, ובכך מונע עומסי תקשורת מיותרים על ה-BUS המשותף.", "ב. ה-cache affinity המשופר ב-MQMS מוביל לירידה משמעותית במספר הגישות הנדרשות לזיכרון הראשי (RAM), מה שמפחית את העומס על ה-BUS המשותף ומאפשר זרימת נתונים מהירה ויעילה יותר לכלל המעבדים.", "ג. MQMS מבטיח חלוקת עבודה אופטימלית ומאוזנת בין כל ליבות המעבד בכל עת, מה שממקסם את ניצולת המעבדים ומונע מצבי סרק.", "ד. MQMS מאפשר למערכת ההפעלה לנהל חוטים כחוטי ליבה (Kernel Threads) בעלות נמוכה יותר, כיוון שמעברי הקשר (context switches) הופכים לפחות תכופים ופחות יקרים."]}, "solution": {"correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. תזמון MQMS משפר באופן טבעי את ה-cache affinity מכיוון שתהליכים משויכים לליבה ספציפית ורצים עליה באופן עקבי. שימור ה-cache affinity פירושו שהנתונים שהתהליך צריך נמצאים במטמון הפרטי המהיר של הליבה (L1 cache), ולא נדרש לגשת לזיכרון הראשי (RAM) בתדירות גבוהה. כפי שהוזכר בחומר ההרצאה, גישה ל-RAM היא איטית ודורשת שימוש ב-BUS המשותף, אשר יכול להעביר רק הודעה אחת בכל רגע נתון. הפחתת הגישות ל-RAM מורידה את העומס על ה-BUS, מונעת צווארי בקבוק בתקשורת ומאפשרת לכלל הליבות לעבוד בצורה יעילה ומהירה יותר, ובכך משפרת את ביצועי המערכת הכוללים.\nא' אינה נכונה לחלוטין מכיוון שבעוד ש-MQMS מפחית את הצורך בנעילות על תורי המתזמן (אין תור משותף), הוא לא מבטל אותו לחלוטין (ייתכן שיידרש מנעול כשמוסיפים ג'ובים במקביל). בנוסף, ההשפעה העיקרית על ה-BUS מגיעה מגישות לנתונים ולא רק מנעילות המתזמן.\nג' אינה נכונה מכיוון ש-MQMS כשלעצמו אינו מבטיח חלוקת עבודה שווה אוטומטית; למעשה, הוא עלול לסבול מחוסר איזון עומסים אם לא מיושמים מנגנוני איזון עומסים נוספים.\nד' אינה נכונה מכיוון שחוטי ליבה (Kernel Threads) יקרים מטבעם בגלל קריאות מערכת ומעברי קשר דרך הליבה. MQMS משפר את הביצועים *למרות* עלות זו על ידי אופטימיזציה של שימוש במטמון, אך הוא אינו הופך את חוטי הליבה ל\"פחות יקרים\" או \"מאפשר\" אותם בעלות נמוכה יותר."}, "_source_file": "0161__Concurrency__Multi-core_Processors__MC__Hard.json", "_topic_hint": "Multi-core Processors", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:30:34", "_subject": "Concurrency", "_context_lectures": [10, 12, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Multi-core Processors"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על עקרונות תזמון במערכות מרובות ליבות (multi-core processors), ובפרט על תזמון מרובה תורים (Multi-queue multiprocessor scheduling), איזו מהטענות הבאות מתארת בצורה הטובה ביותר את היתרון המשולב של שיטה זו בהתמודדות עם אתגרי ביצועים במערכת כזו, תוך התחשבות במנגנוני חומרה כמו ה-cache וה-BUS?", "code_snippet": null, "options": ["א. תזמון מרובה תורים משפר באופן טבעי את זיקת המטמון (cache affinity) בכך שהוא משמר תהליכים על אותה ליבה. שיפור זה מפחית את הצורך בטעינת נתונים מהזיכרון הראשי (RAM) או ממטמונים אחרים, ובכך מקטין את העומס על ה-BUS ומזרז את ביצועי המערכת.", "ב. היתרון העיקרי של תזמון מרובה תורים הוא ביטול מוחלט של הצורך במנגנוני נעילה (locks) בין מעבדים שונים, מה שמפשט את הקוד ומקטין את תקורת המערכת.", "ג. תזמון מרובה תורים מאפשר למערכת ההפעלה להכיר את כל החוטים ולקבוע על איזה מעבד ירוץ כל חוט, מה שמוביל למקביליות אמיתית וניצול טוב יותר של ה-BUS.", "ד. תזמון מרובה תורים מבטיח שכל ג'וב ירוץ תמיד על אותה ליבה, ובכך משפר משמעותית את זיקת המטמון (cache affinity) ומקטין את זמן הגישה לנתונים."]}, "solution": {"correct_option": "א", "explanation": "האפשרות הנכונה היא א'. תזמון מרובה תורים (Multi-queue multiprocessor scheduling) משייך באופן טבעי ג'ובים למעבדים ספציפיים (כל מעבד מקבל תור משלו), מה שיוצר זיקת מטמון (cache affinity) מצוינת. כאשר תהליך נשאר על אותה ליבה, הנתונים הרלוונטיים לו נשארים במטמון הפרטי של הליבה (L1 cache), כפי שמתואר בחומר ההרצאה. גישה למטמון מהירה בהרבה מגישה לזיכרון הראשי (RAM). הזיכרון הראשי נגיש באמצעות ה-BUS, שהוא רכיב חומרה איטי שיכול להעביר רק הודעה אחת בכל רגע נתון. על ידי הקטנת הצורך בטעינת נתונים מה-RAM (בזכות זיקת המטמון המשופרת), תזמון מרובה תורים מפחית את העומס על ה-BUS ומצמצם את 'צוואר הבקבוק' שהוא מהווה, ובכך משפר משמעותית את ביצועי המערכת הכוללים. \n\nאפשרות ב' אינה נכונה מכיוון שלמרות שתזמון מרובה תורים מפחית את הצורך בנעילות עבור תזמון (כי לכל מעבד תור משלו), החומר מציין ש'מדי פעם כשמוסיפים באופן מקבילי ייתכן שיידרש מנעול', ולכן 'ביטול מוחלט' אינו מדויק, וזה לא היתרון המשולב העיקרי בהקשר של cache ו-BUS.\nאפשרות ג' אינה נכונה מכיוון שהיכולת של מערכת ההפעלה להכיר את כל החוטים ולנהל אותם על ליבות שונות היא מאפיין כללי של Kernel Threads (כפי שמתואר בחומר), ולא יתרון ייחודי של תזמון מרובה תורים בהקשר של cache ו-BUS. כמו כן, 'ניצול טוב יותר של ה-BUS' אינו מוסבר ואינו מתייחס להפחתת עומס עליו כתוצאה מזיקת מטמון.\nאפשרות ד' נכונה בחלקה - היא מתארת נכון את שיפור זיקת המטמון ואת קיצור זמן הגישה לנתונים - אך היא אינה מקיפה מספיק עבור שאלה ברמת קושי 'קשה', שדורשת הבנה של היתרון המערכתי הרחב יותר שנובע מכך, קרי: הפחתת העומס על ה-BUS, כפי שמפורט באפשרות א'."}, "_source_file": "0162__Concurrency__Multi-core_Processors__MC__Hard.json", "_topic_hint": "Multi-core Processors", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:30:51", "_subject": "Concurrency", "_context_lectures": [10, 12, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Locks"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר הקורס, מהי התכונה הבסיסית ביותר שצריכה להתקיים במנעול טוב?", "code_snippet": null, "options": ["א. מניעה הדדית (Mutual Exclusion)", "ב. חופש מקיפאון (Deadlock Freedom)", "ג. הוגנות (Starvation-freedom)", "ד. היכולת לתמוך בריבוי מעבדים"]}, "solution": {"correct_option": "א", "explanation": "חומר הקורס (Lecture 11, chunk 27) מגדיר שלמנעול טוב יש שלוש תכונות. הוא מציין במפורש כי 'מניעה הדדית - התכונה הבסיסית שצריכה להיות למנעול: בכל רגע נתון יש לכל היותר חוט אחד בקטע הקריטי'. תכונות חופש מקיפאון והוגנות הן גם תכונות חשובות של מנעול, אך הן אינן מוגדרות כ'בסיסית ביותר' כמו מניעה הדדית. האפשרות הרביעית אינה נכללת בין שלוש התכונות המוגדרות בחומר הקורס למנעול טוב."}, "_source_file": "0163__Concurrency__Locks__MC__Easy.json", "_topic_hint": "Locks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:31:01", "_subject": "Concurrency", "_context_lectures": [16, 11, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Locks"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, איזו תכונה נחשבת לתכונה הבסיסית וההכרחית ביותר של מנעול?", "code_snippet": null, "options": ["א. מניעה הדדית (Mutual Exclusion)", "ב. חופש מקיפאון (Deadlock Freedom)", "ג. הוגנות (Starvation-Freedom)", "ד. היכולת להשתמש במנגנון TestAndSet"]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה (Lecture 11, chunk 27), מניעה הדדית מוגדרת כ'התכונה הבסיסית שצריכה להיות למנעול: בכל רגע נתון יש לכל היותר חוט אחד בקטע הקריטי'. תכונות כמו חופש מקיפאון והוגנות הן תכונות רצויות למנעול טוב, אך מניעה הדדית היא התכונה הבסיסית וההכרחית ביותר. היכולת להשתמש במנגנון TestAndSet (כפי שמוזכר ב-Lecture 11, chunk 42) היא שיטת מימוש למנעול, ולא תכונה מהותית של המנעול עצמו."}, "_source_file": "0164__Concurrency__Locks__MC__Easy.json", "_topic_hint": "Locks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:31:12", "_subject": "Concurrency", "_context_lectures": [16, 11, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Locks"], "difficulty_estimation": "Easy", "content": {"text": "איזו תכונה נחשבת לדרישה הבסיסית ביותר ממנעול?", "code_snippet": null, "options": ["א. מניעה הדדית (Mutual Exclusion)", "ב. חופש מקיפאון (Deadlock Freedom)", "ג. הוגנות (Starvation-freedom)", "ד. מניעת invalidate ב-cache"]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה (הרצאה 11, קטע 27), מניעה הדדית מוגדרת כ-\"התכונה הבסיסית שצריכה להיות למנעול\". תכונה זו מבטיחה שבכל רגע נתון יהיה לכל היותר חוט אחד בקטע הקריטי. למרות שחופש מקיפאון והוגנות הן תכונות רצויות למנעול טוב, ההרצאה מציינת במפורש ש\"לא כולן חייבות להתקיים\", למעט מניעה הדדית שהיא הדרישה הבסיסית. מניעת invalidate ב-cache היא אופטימיזציה שרלוונטית לסוגים מסוימים של מנעולים (כמו מנעולי תור), ולא תכונה בסיסית של עצם הגדרת המנעול."}, "_source_file": "0165__Concurrency__Locks__MC__Easy.json", "_topic_hint": "Locks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:31:23", "_subject": "Concurrency", "_context_lectures": [16, 11, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Locks"], "difficulty_estimation": "Medium", "content": {"text": "איזו מהתכונות הבאות מתארת נכונה את מנעול ה-`TestAndSet` כפי שתואר בחומר הקורס?", "code_snippet": "while (TestAndSet(&flag, 1))\n  ; // spin-wait\n// critical section\nflag = 0;", "options": ["א. הוא מקיים מניעה הדדית ומניעת קיפאון, אך אינו מבטיח הוגנות מלאה.", "ב. הוא אינו מקיים מניעה הדדית, אך מבטיח מניעת קיפאון והוגנות מלאה.", "ג. הוא מקיים הוגנות מלאה, אך אינו מבטיח מניעה הדדית או מניעת קיפאון.", "ד. הוא מקיים מניעה הדדית, אך אינו מבטיח מניעת קיפאון או הוגנות מלאה."]}, "solution": {"correct_option": "א", "explanation": "המנעול מבוסס `TestAndSet` שתואר בחומר הקורס נחשב ל\"נכון\", מה שמרמז על כך שהוא מקיים מניעה הדדית (mutual exclusion) – בכל רגע נתון יש לכל היותר חוט אחד בקטע הקריטי. בנוסף, בחומר נאמר במפורש כי הוא \"מקיים deadlock freedom (מניעת קיפאון)\", כלומר אם חוטים מנסים לתפוס את המנעול, מישהו מצליח ולא נוצר מצב שכולם תקועים. עם זאת, מצוין כי \"אין בו הוגנות מלאה מבחינת תזמון - ייתכן שחוט יתפוס את המנעול מיד לאחר ששחרר אותו ולא ייתן לחוטים אחרים להשתמש בו\", כלומר הוא אינו מבטיח הוגנות (starvation-freedom). לכן, התכונות הנכונות הן מניעה הדדית ומניעת קיפאון, אך ללא הוגנות מלאה."}, "_source_file": "0166__Concurrency__Locks__MC__Medium.json", "_topic_hint": "Locks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:31:35", "_subject": "Concurrency", "_context_lectures": [16, 11, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Locks"], "difficulty_estimation": "Medium", "content": {"text": "על פי חומר ההרצאה, איזו מההצהרות הבאות לגבי תכונות של מנעולים (locks) היא הנכונה ביותר?", "code_snippet": null, "options": ["א. מנעול נחשב \"טוב\" רק אם הוא מקיים את כל שלוש התכונות: מניעה הדדית, deadlock freedom והוגנות.", "ב. מניעה הדדית (mutual exclusion) היא התכונה הבסיסית וההכרחית שצריכה להיות למנעול.", "ג. מנעול שמקיים deadlock freedom בהכרח מבטיח גם הוגנות (starvation-freedom) לכל החוטים.", "ד. מנעול שמקיים מניעה הדדית (mutual exclusion) בהכרח מקיים גם deadlock freedom."]}, "solution": {"correct_option": "ב", "explanation": "חומר ההרצאה מציין במפורש: \"מניעה הדדית - התכונה הבסיסית שצריכה להיות למנעול: בכל רגע נתון יש לכל היותר חוט אחד בקטע הקריטי.\" קביעה זו הופכת את המניעה ההדדית לדרישה יסודית וראשונית מכל מנעול.\n\nא. אפשרות א' שגויה, כיוון שחומר ההרצאה קובע: \"מנעול טוב הוא מנעול בעל 3 תכונות ולא כולן חייבות להתקיים\".\nג. אפשרות ג' שגויה, כפי שמודגם במנעול ה-TestAndSet. חומר ההרצאה מציין כי מנעול זה \"מקיים deadlock freedom\" אך \"אין בו הוגנות מלאה מבחינת תזמון - ייתכן שחוט יתפוס את המנעול מיד לאחר ששחרר אותו ולא ייתן לחוטים אחרים להשתמש בו\".\nד. אפשרות ד' שגויה. מניעה הדדית ו-deadlock freedom הן תכונות נפרדות. מנעול יכול לספק מניעה הדדית (לכל היותר חוט אחד בקטע הקריטי) אך עדיין להיכנס למצב של קיפאון (deadlock) אם, למשל, החוט המחזיק במנעול נתקע וממתין למשהו שלעולם לא יגיע, או במצב של שימוש במספר מנעולים בסדר לא עקבי. הדוגמה של המנעול לשני חוטים בהרצאה (Lecture 16, chunk 9) מראה כי מנעול יכול לקיים deadlock freedom מבלי לקיים מניעה הדדית, מה שמחזק את ההבנה שהן אינן תלויות זו בזו באופן חד-כיווני."}, "_source_file": "0167__Concurrency__Locks__MC__Medium.json", "_topic_hint": "Locks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:31:51", "_subject": "Concurrency", "_context_lectures": [16, 11, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Locks"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על מימוש מנעול ה-TestAndSet כפי שהוצג בחומר ההרצאה, ובהתחשב בשלוש התכונות של מנעול טוב (מניעה הדדית, מניעת קיפאון, והוגנות), איזו מהטענות הבאות נכונה?", "code_snippet": "while (TestAndSet(&flag, 1))\n  ; // spin-wait\n// critical section\nflag = 0;", "options": ["א. הוא מקיים מניעה הדדית ומניעת קיפאון (deadlock freedom), אך אינו מבטיח הוגנות מלאה (starvation-freedom).", "ב. הוא מקיים את כל שלוש התכונות: מניעה הדדית, מניעת קיפאון והוגנות מלאה.", "ג. הוא אינו מקיים מניעה הדדית, אך מבטיח מניעת קיפאון והוגנות מלאה.", "ד. הוא אינו מקיים לא מניעת קיפאון ולא הוגנות, אלא רק מניעה הדדית."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה (Lecture 11, chunk 42) מתאר את מנעול ה-TestAndSet. לגבי נכונותו, נאמר במפורש: \"מבחינת נכונות - המנעול הזה נכון. הוא מקיים deadlock freedom (מניעת קיפאון). אין בו הוגנות מלאה מבחינת תזמון - ייתכן שחוט יתפוס את המנעול מיד לאחר ששחרר אותו ולא ייתן לחוטים אחרים להשתמש בו.\"\n\nננתח את התכונות לפי ההרצאה:\n1.  **מניעה הדדית (Mutual Exclusion):** ההרצאה מציינת (Lecture 11, chunk 27) שמניעה הדדית היא \"התכונה הבסיסית שצריכה להיות למנעול\". מכיוון שהמנעול מוגדר כ\"נכון\", הוא בהכרח מקיים מניעה הדדית, שכן בלעדיה לא היה נחשב למנעול תקין בבסיסו.\n2.  **מניעת קיפאון (Deadlock Freedom):** ההרצאה מציינת במפורש שהמנעול \"מקיים deadlock freedom (מניעת קיפאון)\".\n3.  **הוגנות (Starvation-Freedom):** ההרצאה מציינת במפורש ש\"אין בו הוגנות מלאה מבחינת תזמון\" ומסבירה כי ייתכן שחוט יתפוס את המנעול מיד לאחר שחרורו, ובכך ימנע מחוטים אחרים להתקדם (starvation).\n\nלפיכך, הטענה הנכונה היא שהמנעול מקיים מניעה הדדית ומניעת קיפאון, אך אינו מבטיח הוגנות מלאה."}, "_source_file": "0169__Concurrency__Locks__MC__Hard.json", "_topic_hint": "Locks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:32:28", "_subject": "Concurrency", "_context_lectures": [16, 11, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Locks"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על ההגדרות והדוגמאות למנעולים שנדונו בחומר הקורס, איזו מבין הטענות הבאות אודות תכונות של מנעולים היא הנכונה ביותר?", "code_snippet": null, "options": ["א. מנעול שמבטיח מניעה הדדית (mutual exclusion) בהכרח ימנע מצב של קיפאון (deadlock freedom).", "ב. מנעול שאינו מקיים מניעה הדדית (mutual exclusion) אינו יכול לקיים את תכונת מניעת הקיפאון (deadlock freedom).", "ג. מנעול שמקיים הוגנות (starvation-freedom) בהכרח ימנע מצב של קיפאון (deadlock freedom).", "ד. מנעול שמקיים מניעת קיפאון (deadlock freedom) בהכרח יבטיח הוגנות (starvation-freedom)."]}, "solution": {"correct_option": "ג", "explanation": "התכונה deadlock freedom מבטיחה שאם חוטים מנסים לתפוס את המנעול, אז מישהו יצליח בסופו של דבר, כלומר לא יווצר מצב שכל החוטים תקועים בהמתנה למנעול. התכונה starvation-freedom (הוגנות) היא חזקה יותר, וקובעת שכל חוט שמנסה לתפוס את המנעול יצליח לעשות זאת בסופו של דבר. אם מנעול מקיים starvation-freedom, הרי שכל חוט שממתין למנעול יקבל אותו בסופו של דבר. מצב זה שולל בהכרח קיפאון (deadlock), שבו כל החוטים תקועים ואינם יכולים להתקדם. לכן, מנעול שמקיים הוגנות בהכרח מקיים גם מניעת קיפאון. \nנתבונן באפשרויות האחרות:\nא. טענה זו אינה נכונה. מנעול יכול לקיים מניעה הדדית אך עדיין לגרום לקיפאון במערכת רחבה יותר (לדוגמה, אם חוט תופס מנעול ונתקע תוך כדי המתנה למשאב אחר, ויוצר תלות מעגלית). בנוסף, ההגדרה של deadlock freedom מתייחסת ל'קוד של המנעול לבד', וגם שם, מנעול יכול לספק מניעה הדדית (רק אחד נכנס) אבל אם תהליך שקיבל אותו לא ישחרר אותו לעולם (למשל, קריסה), אז יגרם קיפאון לכל האחרים.\nב. טענה זו אינה נכונה. מנעול ה-`turn` שהוצג בחומר הקורס (Lecture 16, chunk 9) אינו מקיים מניעה הדדית (שני חוטים יכולים להיכנס לקטע הקריטי בו-זמנית), אך הוכח במפורש כי הוא מקיים deadlock freedom.\nד. טענה זו אינה נכונה. מנעול TestAndSet (Lecture 11, chunk 42) מקיים deadlock freedom, אך אינו מבטיח הוגנות מלאה (starvation-freedom), שכן חוט יכול לתפוס את המנעול שוב ושוב ולא לאפשר לחוטים אחרים להתקדם."}, "_source_file": "0170__Concurrency__Locks__MC__Hard.json", "_topic_hint": "Locks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:32:45", "_subject": "Concurrency", "_context_lectures": [16, 11, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Locks"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על ההגדרות והדוגמאות הנידונות בחומר הלימוד, במיוחד לאור תכונות מנעול ה-`TestAndSet`, איזה מהמשפטים הבאים נכון לגבי הקשר בין \"deadlock freedom\" לבין \"הוגנות (starvation-freedom)\"?", "code_snippet": null, "options": ["א. מנעול המבטיח \"הוגנות\" בהכרח מקיים גם \"deadlock freedom\".", "ב. מנעול המבטיח \"deadlock freedom\" בהכרח מקיים גם \"הוגנות\".", "ג. \"deadlock freedom\" ו\"הוגנות\" הן תכונות בלתי תלויות לחלוטין.", "ד. מנעול אינו יכול לקיים בו זמנית גם \"deadlock freedom\" וגם \"הוגנות\"."]}, "solution": {"correct_option": "א", "explanation": "ההגדרה של 'הוגנות' (starvation-freedom) בחומר הלימוד קובעת ש'כל חוט יצליח לתפוס את המנעול בסופו של דבר'. לעומת זאת, 'deadlock freedom' קובע ש'אם מנסים לתפוס את המנעול, אז מישהו מצליח'. אם כל חוט מצליח בסופו של דבר לתפוס את המנעול (הוגנות), אז בהכרח ניתן להסיק שלפחות חוט אחד מצליח (deadlock freedom). לכן, תכונת ה'הוגנות' חזקה יותר וגוררת בהכרח את תכונת ה-'deadlock freedom'. חומר הלימוד מחזק זאת בכך שהוא מציין שמנעול ה-`TestAndSet` 'מקיים deadlock freedom (מניעת קיפאון)' אך 'אין בו הוגנות מלאה מבחינת תזמון - ייתכן שחוט יתפוס את המנעול מיד לאחר ששחרר אותו ולא ייתן לחוטים אחרים להשתמש בו'. עובדה זו מפריכה את טענה ב', לפיה deadlock freedom גורר הוגנות. טענות ג' ו-ד' שגויות, שכן התכונות אינן בלתי תלויות (הוגנות חזקה יותר מ-deadlock freedom) ובהחלט ניתן לממש מנעולים המקיימים את שתיהן (כמו 'מנעולי תור' המוזכרים בשיעור)."}, "_source_file": "0171__Concurrency__Locks__MC__Hard.json", "_topic_hint": "Locks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:33:02", "_subject": "Concurrency", "_context_lectures": [16, 11, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Mutexes"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של מנעול (mutex) במערכת הפעלה?", "code_snippet": null, "options": ["א. לאפשר לשני חוטים או יותר להיכנס לקטע קריטי במקביל.", "ב. להבטיח מניעה הדדית (mutual exclusion) בקטע קריטי, כך שרק חוט אחד יבצע אותו בכל רגע נתון.", "ג. לספק מנגנון לשליחת אותות (signals) בין חוטים שאינם חולקים משאבים.", "ד. לפתור בעיות קיפאון (deadlock) באופן אוטומטי בכל מצב."]}, "solution": {"correct_option": "ב", "explanation": "מנעול (mutex) הוא אובייקט שנועד לסנכרן בין חוטים. מטרתו העיקרית היא להבטיח מניעה הדדית (mutual exclusion) בקטע קריטי, כלומר, שרק חוט אחד יוכל להחזיק במשאב או להיכנס לקטע קריטי מסוים בכל רגע נתון. כאשר חוט מנסה לנעול mutex שכבר תפוס, הוא נחסם וממתין עד שה-mutex ישוחרר על ידי החוט האחר, ורק אז יוכל לתפוס אותו בעצמו. מידע זה מופיע בבירור בחומר ההרצאה, לדוגמה ב-Lecture 11, chunk 12, שם מצוין כי 'מנעול - mutex הוא אובייקט חדש שנועד לסנכרן בין החוטים' וכי הוא מייצג 'את המצב שמישהו (חוט אחד בלבד) מחזיק את המשאב כרגע'."}, "_source_file": "0172__Concurrency__Mutexes__MC__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:33:14", "_subject": "Concurrency", "_context_lectures": [10, 11, 13, 14, 16]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Mutexes"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של שימוש במנעול (mutex) לצורך סנכרון גישה לקטע קריטי במערכת הפעלה?", "code_snippet": "mutex_t shared_resource_mutex;\n\nvoid access_critical_section() {\n    lock(&shared_resource_mutex);\n    // קטע קריטי: גישה למשאב משותף\n    // Critical Section: Access shared resource\n    unlock(&shared_resource_mutex);\n}", "options": ["א. לאפשר למספר חוטים להיכנס לקטע הקריטי במקביל, בתנאי שהם משתמשים במשאבים שונים.", "ב. להבטיח שרק חוט אחד בלבד יוכל לבצע את הקטע הקריטי בכל רגע נתון.", "ג. לזרז את ביצוע הקוד בתוך הקטע הקריטי על ידי פיצולו למשימות קטנות יותר.", "ד. למנוע לחלוטין מצבי רעב (starvation) של חוטים הממתינים להיכנס לקטע הקריטי."]}, "solution": {"correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. מטרתו העיקרית של מנעול (mutex), כפי שמוזכר בחומר ההרצאה, היא לסנכרן בין חוטים ולהבטיח מניעה הדדית (mutual exclusion) בקטעים קריטיים. מניעה הדדית פירושה שרק חוט אחד בלבד יכול להיכנס לקטע הקריטי בכל רגע נתון. כאשר חוט מנסה לבצע פעולת lock על מנעול שכבר תפוס, הוא נחסם (blocking) וממתין עד שהמנעול ישוחרר. זה מונע מצבי מרוץ (race conditions) ומבטיח עקביות בגישה למשאבים משותפים. האפשרויות האחרות אינן נכונות: מנעול אינו מאפשר למספר חוטים להיכנס בו זמנית (א'), אינו מאיץ את הביצוע (ג') אלא יוצר סריאליזציה, ואינו מבטיח מניעת רעב באופן מוחלט (ד') אלא בעיקר מניעת כניסה בו זמנית."}, "_source_file": "0173__Concurrency__Mutexes__MC__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:33:29", "_subject": "Concurrency", "_context_lectures": [10, 11, 13, 14, 16]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Mutexes"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של שימוש במנעול (mutex) בסנכרון בין חוטים?", "code_snippet": null, "options": ["א. לאפשר לחוטים מרובים לגשת למשאב משותף בו זמנית.", "ב. להבטיח שרק חוט אחד בלבד יחזיק במשאב משותף בכל רגע נתון.", "ג. לפתור בעיות קיפאון (deadlock) על ידי שינוי סדר לקיחת המשאבים.", "ד. לאותת לחוטים אחרים להתעורר כאשר משאב מתפנה."]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר ההרצאה (הרצאה 11, קטע 12), מנעול (mutex) הוא אובייקט שנועד לסנכרן בין חוטים. מצבו 'תפוס' מייצג שחוט אחד בלבד מחזיק במשאב כרגע. מטרתו העיקרית היא להבטיח מניעה הדדית (mutual exclusion), כלומר שרק חוט אחד יוכל להיות בקטע הקריטי ולהשתמש במשאב המוגן על ידי המנעול בכל רגע נתון. אפשרות א' הפוכה למטרה זו. אפשרות ג' מתארת אסטרטגיה ספציפית למניעת קיפאון (שבירת סימטריה), ולא את מטרת המנעול עצמו. אפשרות ד' מתארת פעולה של משתני תנאי (condition variables), אשר עובדים בשילוב עם מנעולים, אך אינה המטרה העיקרית של המנעול עצמו."}, "_source_file": "0174__Concurrency__Mutexes__MC__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:33:42", "_subject": "Concurrency", "_context_lectures": [10, 11, 13, 14, 16]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Mutexes"], "difficulty_estimation": "Medium", "content": {"text": "מה קורה למנעול (mutex) שחוט מחזיק בו, כאשר החוט קורא לפעולת `wait` על משתנה תנאי (condition variable)?", "code_snippet": "lock(&m1);\nwait(&cv1, &m1);\nunlock(&m1);\n\n// Atomic breakdown of wait:\n// unlock(&m1);\n// wait_for_signal(&cv1);\n// // after waking up:\n// lock(&m1);", "options": ["א. החוט ממשיך להחזיק במנעול בזמן שהוא ממתין לאות (signal).", "ב. החוט משחרר את המנעול, נחסם וממתין לאות, ולאחר מכן תופס מחדש את המנעול כשהוא מתעורר.", "ג. המנעול נהרס באופן אוטומטי כדי למנוע קיפאון (deadlock).", "ד. החוט משחרר את המנעול ומיד מנסה לתפוס אותו מחדש בלולאת המתנה פעילה (busy-wait)."]}, "solution": {"correct_option": "ב", "explanation": "כפי שמפורט בחומר ההרצאה, כאשר חוט קורא לפעולת `wait` על משתנה תנאי ומחזיק במנעול, הפעולה `wait` מבצעת באופן אטומי שחרור של המנעול, ולאחר מכן חוסמת את החוט עד שיקבל אות (signal) ממשתנה התנאי. רק לאחר שהחוט מתעורר ומקבל את האות, הוא תופס מחדש את המנעול ורק אז ממשיך בביצוע. פעולה זו חיונית כדי לאפשר לחוטים אחרים להיכנס לקטע הקריטי, לשנות את התנאי שעליו ממתינים, ולשלוח את האות, ובכך למנוע קיפאון. האפשרויות האחרות אינן מתארות את ההתנהגות הנכונה של `wait` כפי שהוצגה בחומר."}, "_source_file": "0175__Concurrency__Mutexes__MC__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:33:52", "_subject": "Concurrency", "_context_lectures": [10, 11, 13, 14, 16]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Mutexes"], "difficulty_estimation": "Medium", "content": {"text": "על פי חומר ההרצאה, מהי המטרה העיקרית של שימוש במנעול (mutex) בעת סנכרון בין חוטים בקטע קריטי?", "code_snippet": null, "options": ["א. להבטיח שרק חוט אחד בלבד יחזיק במשאב או יכנס לקטע הקריטי בכל רגע נתון.", "ב. למנוע את האפשרות של הרעבה (starvation) של חוטים הממתינים למשאב.", "ג. לאפשר למספר חוטים לרוץ במקביל בתוך הקטע הקריטי כדי לשפר ביצועים.", "ד. למנוע מצבי קיפאון (deadlock) באופן מוחלט בכל מצבי השימוש במנעול."]}, "solution": {"correct_option": "א", "explanation": "המטרה העיקרית של מנעול (mutex) היא להבטיח מניעה הדדית (mutual exclusion). על פי חומר ההרצאה (Lecture 11, chunk 12), מנעול הוא אובייקט שנועד לסנכרן בין חוטים, ובמצב 'תפוס' הוא מייצג ש'מישהו (חוט אחד בלבד) מחזיק את המשאב כרגע'. מניעה הדדית, כפי שהוגדרה ב-Lecture 16, chunk 8, פירושה ש'שני חוטים לא יכולים להיות בקטע הקריטי במקביל'. לכן, האפשרות הנכונה היא א'.\nאפשרות ב' שגויה, שכן חומר ההרצאה (Lecture 14, chunk 38) מציין כי 'עלולה להיות לנו הרעבה, אבל לא קיפאון', מה שמרמז כי גם פתרונות סנכרון מסוימים אינם מבטיחים חופש מהרעבה. אפשרות ג' שגויה לחלוטין, שכן היא סותרת את עקרון המניעה ההדדית - מנעול נועד למנוע הרצה מקבילית בקטע הקריטי. אפשרות ד' שגויה, מכיוון שאף שמנעול מסייע בסנכרון, שימוש לא נכון במספר מנעולים יכול דווקא להוביל למצבי קיפאון (deadlock), כפי שניתן להבין מהדיון על פילוסופים סועדים (Lecture 14, chunk 38), ולכן הוא אינו מונע קיפאון באופן מוחלט בכל מצבי השימוש."}, "_source_file": "0176__Concurrency__Mutexes__MC__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:34:08", "_subject": "Concurrency", "_context_lectures": [10, 11, 13, 14, 16]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Mutexes"], "difficulty_estimation": "Medium", "content": {"text": "מהי המטרה העיקרית של שימוש במנעול (mutex) במערכת הפעלה?", "code_snippet": null, "options": ["א. למנוע מצב של רעב (starvation) בחוטים הממתינים למשאב.", "ב. להבטיח שמניעה הדדית (mutual exclusion) תתקיים בקטע קריטי.", "ג. לאפשר לחוטים מרובים להיכנס לקטע קריטי בו-זמנית.", "ד. לסנכרן בין חוטים על ידי העברת הודעות ביניהם."]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר ההרצאה (Lecture 11, chunk 12), מנעול (mutex) הוא אובייקט שנועד לסנכרן בין חוטים. מטרתו המרכזית היא להבטיח שמניעה הדדית (mutual exclusion) תתקיים בקטע קריטי. מניעה הדדית פירושה, כפי שמוזכר גם ב-Lecture 16 (chunk 8), ש'שני חוטים לא יכולים להיות בקטע הקריטי במקביל', ובכך רק חוט אחד בלבד יוכל להחזיק במשאב בכל רגע נתון. זה מונע התנגשויות ובעיות עקביות בגישה למשאבים משותפים. אפשרות א' אינה נכונה מכיוון שמנעול אינו מבטיח מניעת רעב באופן מובנה. אפשרות ג' אינה נכונה מכיוון שהיא הפוכה למטרת המנעול, שנועד למנוע כניסה בו-זמנית. אפשרות ד' אינה נכונה מכיוון שמנעול לבדו אינו משמש ככלי להעברת הודעות ישירה בין חוטים, אלא לסנכרון גישה למשאבים."}, "_source_file": "0177__Concurrency__Mutexes__MC__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:34:23", "_subject": "Concurrency", "_context_lectures": [10, 11, 13, 14, 16]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Mutexes"], "difficulty_estimation": "Hard", "content": {"text": "בהתייחס לפעולת wait של משתנה תנאי, כפי שהוסברה בהקשר של מנעולים, ובהינתן הקוד הפנימי הבא המדגים את התנהגותה האטומי:\n```c\n// בתוך wait(&cv1, &m1):\n// באופן אטומי:\nunlock(&m1);\nwait_for_signal(&cv1);\n// לאחר התעוררות:\nlock(&m1);\n```\nמהי הסיבה המהותית ביותר לכך ששחרור המנעול (unlock(&m1)) מתבצע באופן אטומי *לפני* הכניסה למצב המתנה (wait_for_signal(&cv1))?", "code_snippet": "lock(&m1);\nwait(&cv1, &m1);\nunlock(&m1);\n\n-> Atomic:\nunlock(&m1);\nwait_for_signal(&cv1);\n// after waking up:\nlock(&m1);", "options": ["א. להבטיח שחוטים אחרים יוכלו להיכנס לקטע הקריטי, לגשת לנתונים המשותפים המוגנים על ידי m1, ואף לשלוח signal שיעיר את החוט הממתין, ובכך למנוע מצב של קיפאון (deadlock).", "ב. למנוע מצב שבו מספר חוטים יחזיקו את המנעול m1 בו-זמנית בזמן שהם ממתינים, ובכך לשמור על עקביות הנתונים.", "ג. לאפשר לחוט הממתין לסיים את עבודתו בקטע הקריטי מיד עם קבלת ה-signal, ללא צורך לרכוש מחדש את המנעול.", "ד. להבטיח מניעה הדדית (mutual exclusion) מלאה על המשאב המוגן על ידי m1 גם כאשר החוט נמצא במצב המתנה."]}, "solution": {"correct_option": "א", "explanation": "האופי האטומי של פעולת `wait` הוא קריטי למניעת קיפאון (deadlock) במערכות מקביליות המשתמשות במנעולים (mutexes) ומשתני תנאי (condition variables). כאשר חוט קורא ל-`wait(&cv, &m)`, הוא למעשה משחרר את המנעול `m` באופן אטומי *לפני* שהוא נכנס למצב המתנה עבור `cv`. כפי שהוסבר בחומר הלימוד, \"בנקודה הזו, הוא שחרר את המנעול וכרגע חוט A חסום עד שישלחו לו signal\". אם המנעול לא היה משוחרר, שום חוט אחר לא היה יכול להיכנס לקטע הקריטי המוגן על ידי `m`, לשנות את התנאי המבוקש (שעליו החוט ממתין), או לשלוח `signal` שיעיר את החוט הממתין. מצב זה היה מוביל לקיפאון, שכן החוט הממתין היה ממתין לתנאי שלא יכול להשתנות, והחוטים האחרים לא היו יכולים לגשת למנעול כדי לשנות את התנאי או לשלוח את ה-signal. רק לאחר שהחוט מתעורר מקריאת ה-`wait_for_signal`, הוא רוכש מחדש את המנעול (`lock(&m)`) באופן אוטומטי, ובכך מבטיח שהוא יכול להמשיך את פעולתו בקטע הקריטי תוך שמירה על מניעה הדדית. לכן, שחרור המנעול מאפשר לחוטים אחרים להתקדם ולשנות את המצב המערכתי, ובכך מונע קיפאון. אפשרות ב' אינה נכונה מכיוון שמנעול מטבעו מונע החזקה בו-זמנית על ידי מספר חוטים. אפשרות ג' אינה נכונה מכיוון שהחוט הממתין *כן* רוכש מחדש את המנעול לאחר ההתעוררות. אפשרות ד' אינה נכונה מכיוון שהמטרה של שחרור המנעול היא דווקא לאפשר לחוטים אחרים להיכנס לקטע הקריטי בזמן שהחוט ממתין, ובכך לא לשמור על מניעה הדדית *באותו רגע* עבור החוט הממתין."}, "_source_file": "0178__Concurrency__Mutexes__MC__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:34:43", "_subject": "Concurrency", "_context_lectures": [10, 11, 13, 14, 16]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Mutexes"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על התיאור בשיעור לגבי מנעול (mutex) פגום, כאשר חוט 0 וחוט 1 מנסים לנעול אותו (באמצעות פעולת ה-`lock`) במקביל, כפי שתואר, מהי התוצאה הישירה והבעייתית הנובעת מכך, ואיזו תכונה יסודית של מנעולים תקינים הוא מפר?", "code_snippet": null, "options": ["א. שני החוטים ייכנסו לקטע הקריטי בו זמנית, והמנעול מפר את תכונת ה\"מניעה ההדדית\" (Mutual Exclusion).", "ב. רק חוט אחד ייכנס לקטע הקריטי, בעוד שהחוט השני יסבול מ\"הרעבה\" (Starvation) ולא יוכל להיכנס לעולם.", "ג. המערכת תיכנס למצב של \"קיפאון\" (Deadlock) כיוון ששני החוטים ימתינו זה לזה באופן בלתי הפיך.", "ד. המנעול יבצע פעולת `unlock` אוטומטית לפני מעבר למצב המתנה (wait), ולאחר ההתעוררות יבצע `lock` מחדש."]}, "solution": {"correct_option": "א", "explanation": "ההסבר בשיעור 16 (chunk 8) מתאר מפורשות מצב שבו מנעול אינו מקיים מניעה הדדית. נאמר שם: \"מניעה הדדית פירושה: שני חוטים לא יכולים להיות בקטע הקריטי במקביל. אם זה לא מתקיים, זה אומר שייתכן ושני חוטים מחזיקים במנעול בו זמנית, כלומר שני חוטים נמצאים בקטע הקריטי במקביל.\" בהמשך התיאור, מודגם כיצד חוט 0 וחוט 1 קוראים ל-`lock` ו\"שני החוטים בו זמנית בקטע הקריטי ובו זמנית מחזיקים במנעול ולכן אין מניעה הדדית במנעול הזה.\" לכן, התוצאה הישירה היא כניסה בו-זמנית של שני החוטים לקטע הקריטי, מה שמפר את תכונת ה\"מניעה ההדדית\", שהיא תכונה יסודית של מנעולים תקינים (כפי שהוגדר בשיעור 11, chunk 12). אפשרויות ב' ו-ג' מתארות בעיות אחרות (הרעבה וקיפאון) שאינן הכשל המפורש והמיידי של מנעול זה. אפשרות ד' מתארת את מנגנון הפעולה של `wait` עם Mutex ו-Condition Variable (שיעור 13, chunk 38), ואינה רלוונטית לכשל במנעול עצמו כפי שתואר בשיעור 16."}, "_source_file": "0179__Concurrency__Mutexes__MC__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:35:13", "_subject": "Concurrency", "_context_lectures": [10, 11, 13, 14, 16]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Mutexes"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על החומר הנלמד, מדוע הפעולות של שחרור מנעול (unlock) והמתנה לאות (wait_for_signal) בתוך קריאת wait למשתנה תנאי חייבות להיות אטומיות?", "code_snippet": "void wait(condition_variable *cv1, mutex *m1) {\n    // -> Atomic:\n    unlock(m1);\n    wait_for_signal(cv1);\n    // after waking up:\n    lock(m1);\n}", "options": ["א. כדי למנוע מצב תחרות (race condition) שבו אות (signal) עלול להישלח ולאבד לפני שהחוט מצליח להיכנס למצב המתנה, מה שיוביל לקיפאון (deadlock) או הרעבה (starvation) של החוט.", "ב. כדי להבטיח שחוט אחר לא יוכל לתפוס את המנעול בין שחרורו לבין כניסת החוט למצב המתנה, ובכך למנוע הפרה של מניעה הדדית (mutual exclusion).", "ג. כדי להפחית את תקורה של החלפת הקשרים (context switches) בין חוטים הממתינים על אותו משתנה תנאי.", "ד. כדי להבטיח שהחוט המתעורר תמיד יחזיק את המנעול מחדש לפני שימשיך בביצוע הקטע הקריטי שלו."]}, "solution": {"correct_option": "א", "explanation": "הפעולות של שחרור המנעול והמתנה לאות חייבות להיות אטומיות כדי למנוע מצב תחרותי חמור המכונה 'אובדן אות' (lost wakeup). אם הפעולות לא היו אטומיות, ייתכן שחוט ישחרר את המנעול, ומיד לאחר מכן (לפני שהוא מספיק לקרוא ל-'wait_for_signal' ולהיחסם) יתבצע מיתוג הקשר לחוט אחר. החוט השני עשוי לתפוס את המנעול, לסיים את עבודתו בקטע הקריטי, ולשלוח אות ('signal') למשתנה התנאי. אם החוט הראשון עדיין לא נחסם, האות יישלח 'לריק' וילך לאיבוד. כאשר החוט הראשון ינסה לבסוף להיחסם על משתנה התנאי, הוא ימתין ללא הגבלת זמן לאות שכבר נשלח ולא יגיע שוב (אלא אם כן יישלח אות נוסף בעתיד), מה שעלול להוביל לקיפאון (deadlock) או הרעבה (starvation). האטומיות מבטיחה שברגע שהמנעול שוחרר, החוט נחסם מיד על משתנה התנאי, ואין חלון זמן שבו אות יכול ללכת לאיבוד."}, "_source_file": "0180__Concurrency__Mutexes__MC__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:35:30", "_subject": "Concurrency", "_context_lectures": [10, 11, 13, 14, 16]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Synchronization"], "difficulty_estimation": "Easy", "content": {"text": "לפי חומר ההרצאה, איזו בעיית סינכרון קלאסית מתוארת במצב שבו שני חוטים (threads) ניגשים למשתנה משותף (`next`) ומשנים אותו באופן שמוביל לדריסת מידע במערך (`arr`)?", "code_snippet": "Thread A\nmy_slot_A = next;\narr[my_slot_A] = value_A;\nnext = next+ 1;\n\nThread B\nmy_slot_B = next;\narr[my_slot_B] = value_B;\nnext = next+ 1;", "options": ["א. מצב מרוץ (Race Condition)", "ב. הרעבה (Starvation)", "ג. מבוי סתום (Deadlock)", "ד. איבוד אות (Lost Signal)"]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מתאר במפורש את המקרה שבו \"שני חוטים שרוצים לגשת למשאב משותף אבל מפריעים אחד לשני בקוד\", ונותן כדוגמה את הגישה למשתנה `next` ולמערך `arr`. הבעיה מתרחשת כאשר חוט A קורא את `next`, מתבצע context switch, חוט B גם קורא את אותו `next` (שעדיין לא עודכן על ידי A), ואז שניהם מנסים לכתוב לאותו מיקום או למיקומים שגויים, מה שמוביל לדריסת מידע. מצב זה, שבו התוצאה תלויה בסדר הלא צפוי של פעולות החוטים הניגשים למשאב משותף, נקרא \"מצב מרוץ\" (Race Condition). האפשרויות האחרות (הרעבה, מבוי סתום, איבוד אות) מתארות בעיות סינכרון אחרות, שחלקן אמנם מוזכרות בחומר ההרצאה, אך אינן מתאימות לתיאור הבעיה הספציפית והקלאסית של דריסת נתונים הנגרמת מגישה לא מתואמת למשתנה משותף כפי שהודגם."}, "_source_file": "0181__Concurrency__Synchronization__MC__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:35:40", "_subject": "Concurrency", "_context_lectures": [10, 11, 13, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Synchronization"], "difficulty_estimation": "Easy", "content": {"text": "בהתבסס על הדוגמה שבה חוט A וחוט B מנסים להוסיף ערכים למערך `arr` באמצעות המשתנה המשותף `next` ללא סנכרון, כפי שמתואר בקטע הקוד הבא, כאשר `next` ו-`arr` הם משאבים משותפים:\n\n```c\nmy_slot = next;\narr[my_slot] = value;\nnext = next + 1;\n```\n\nמהי הבעיה הקלאסית של סינכרון שעלולה להתרחש במצב זה?", "code_snippet": "my_slot_A = next;\narr[my_slot_A] = value_A;\nnext = next+ 1;", "options": ["א. רעב (Starvation), שבו חוט אחד לא מצליח להתקדם לעולם.", "ב. דריסת נתונים (Data Overwriting), שבה ערך שנכתב על ידי חוט אחד נמחק או נדרס על ידי חוט אחר.", "ג. חסימה (Blocking), שבה חוטים ממתינים לקלט/פלט ואינם יכולים לבצע עבודה אחרת במקביל.", "ד. אי-ניצול של Cache Affinity, המוביל לירידה בביצועים."]}, "solution": {"correct_option": "ב", "explanation": "חומר ההרצאה מתאר במפורש את הבעיה: \"חוט A... יכתוב את הערך שלו לאותו מספר 6 וידרוס את מה ש-B כתב לשם. זו בעיה קלאסית של סינכרון: שני חוטים שרוצים לגשת למשאב משותף אבל מפריעים אחד לשני בקוד.\" תיאור זה תואם באופן מדויק ל'דריסת נתונים' (Data Overwriting), שבה פעולת כתיבה של חוט אחד על משאב משותף מוחקת או משנה באופן בלתי רצוי את הנתונים שנכתבו על ידי חוט אחר, עקב חוסר סנכרון. האפשרויות האחרות אינן מתארות את הבעיה הספציפית והקלאסית שהודגמה בחומר המצורף בהקשר זה."}, "_source_file": "0182__Concurrency__Synchronization__MC__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:35:52", "_subject": "Concurrency", "_context_lectures": [10, 11, 13, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Synchronization"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, איזו בעיה קלאסית של סינכרון מתוארת כאשר שני חוטים (threads) ניגשים למשאב משותף (כמו המשתנה `next` בדוגמה) ומפריעים אחד לשני בקוד, מה שעלול להוביל לכתיבת נתונים שגויה?", "code_snippet": "Thread A\nmy_slot_A = next;\narr[my_slot_A] = value_A;\nnext = next+ 1;\n\nThread B\nmy_slot_B = next;\narr[my_slot_B] = value_B;\nnext = next+ 1;", "options": ["א. מצב מרוץ (Race Condition)", "ב. הרעבה (Starvation)", "ג. מבוי סתום (Deadlock)", "ד. זיקת מטמון (Cache Affinity)"]}, "solution": {"correct_option": "א", "explanation": "הבעיה המתוארת בחומר ההרצאה, שבה שני חוטים ניגשים למשאב משותף (`next` ו-`arr`) באופן לא מתואם ופעולותיהם משתלבות זו בזו באופן לא צפוי, נקראת 'מצב מרוץ' (Race Condition). מצב זה מוביל לכך שתוצאת הפעולה תלויה בסדר הספציפי שבו הפקודות מתבצעות, ועלולה לגרום לשגיאות כמו דריסת נתונים, כפי שמוסבר בדוגמה בה חוט A דורס את הערך שחוט B כתב. חומר ההרצאה מציין זאת במפורש כ\"בעיה קלאסית של סינכרון: שני חוטים שרוצים לגשת למשאב משותף אבל מפריעים אחד לשני בקוד\". הרעבה ומבוי סתום הן בעיות סינכרון אחרות אך אינן מתארות את המקרה הספציפי הזה של הפרעה בגישה לנתונים משותפים. זיקת מטמון קשורה לתזמון תהליכים וביצועים ולא לבעיית סינכרון של נתונים משותפים."}, "_source_file": "0183__Concurrency__Synchronization__MC__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:36:05", "_subject": "Concurrency", "_context_lectures": [10, 11, 13, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Synchronization"], "difficulty_estimation": "Medium", "content": {"text": "איזו בעיית סנכרון מתוארת בקטע הקוד הבא, וכיצד הפתרון המוצע בחומר ההרצאה מתמודד איתה?", "code_snippet": "Thread A (Blocked)\nlock(&m1);\n// wait for mmmBop\nif (!done)\n  wait(&cv1, &m1);\nbaDuBop();\nunlock(&m1);\n\nThread B\nmmmBop();\ndone = 1;\nsignal(&cv1);\nLost signal", "options": ["א. הבעיה היא \"Lost signal\" (איתות אבוד), מכיוון ש-signal() נקרא לפני ש-wait() נכנס למצב המתנה. הפתרון הוא לתפוס מנעול (lock) גם בצד של Thread B לפני הגישה למשתנה done והקריאה ל-signal().", "ב. הבעיה היא \"Race Condition\" (תנאי מירוץ) על המשתנה done. הפתרון הוא להשתמש ב-mutex יחיד המגן על כל הבלוק של Thread A ו-Thread B.", "ג. הבעיה היא \"Deadlock\" (מבוי סתום), מכיוון ש-Thread A נחסם ו-Thread B לא מצליח לשחרר אותו. הפתרון הוא להחליף את ה-condition variable ב-semaphore.", "ד. הבעיה היא \"Starvation\" (הרעבה), שבה Thread A לא מצליח להתקדם לעולם. הפתרון הוא להשתמש במנגנון lock-free."]}, "solution": {"correct_option": "א", "explanation": "הבעיה המתוארת בקטע הקוד היא בעיית \"Lost signal\" (איתות אבוד), כפי שמצוין במפורש בחומר ההרצאה (Lecture 13, chunk 41). היא מתרחשת כאשר חוט B קורא ל-`signal(&cv1)` ומסמן שאירוע התרחש, אך חוט A עדיין לא הספיק לקרוא ל-`wait(&cv1, &m1)` ולהיכנס למצב המתנה. כתוצאה מכך, האיתות \"אובד\" ואף חוט לא ממתין לו, וחוט A עלול להמתין ללא סוף למרות שהאירוע כבר התרחש. הפתרון, כפי שמוצג בחומר ההרצאה, הוא שימוש במנעול (mutex) גם בצד של חוט B, סביב הגישה למשתנה `done` והקריאה ל-`signal()`. זה מבטיח שחוטים A ו-B לא יוכלו להתערבב בצורה שתגרום לאובדן האיתות, מכיוון שחוט B יתפוס את המנעול לפני ה-signal, וחוט A יחזיק בו כשהוא קורא ל-wait, ובכך מובטח סדר פעולות נכון."}, "_source_file": "0184__Concurrency__Synchronization__MC__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:36:20", "_subject": "Concurrency", "_context_lectures": [10, 11, 13, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Synchronization"], "difficulty_estimation": "Medium", "content": {"text": "בהתבסס על בעיית ה-\"Lost Signal\" המתוארת בחומר ההרצאה (Lecture 13, chunk 41), איזו בעיה מרכזית היא מדגימה בשימוש במשתני תנאי (Condition Variables) ללא הגנה מתאימה, וכיצד היא נפתרת?", "code_snippet": "Thread A (Blocked)\nlock(&m1);\n// wait for mmmBop\nif (!done)\n  wait(&cv1, &m1);\nbaDuBop();\nunlock(&m1);\n\nThread B\nmmmBop();\ndone = 1;\nsignal(&cv1);\nLost signal", "options": ["א. הבעיה היא שחוט המאותת (signaling thread) עלול לשלוח את האות לפני שחוט הממתין (waiting thread) נכנס למצב המתנה, מה שגורם לאובדן האות. הפתרון הוא לתפוס מנעול (mutex) גם בצד של החוט המאותת וגם בצד של החוט הממתין.", "ב. הבעיה היא שחוט הממתין עלול להיכנס ללולאה אינסופית בבדיקת התנאי. הפתרון הוא להשתמש בפעולה signalAll במקום signal.", "ג. הבעיה היא שחוט המאותת עלול לשנות את התנאי אך לא לאותת על כך, מה שמוביל לקיפאון (deadlock). הפתרון הוא לוודא שכל שינוי בתנאי מלווה באיתות.", "ד. הבעיה היא שחוטים רבים מדי מנסים לגשת למשאב משותף בו-זמנית, מה שגורם לתחרות על המעבד. הפתרון הוא להגביל את מספר החוטים שיכולים לרוץ במקביל."]}, "solution": {"correct_option": "א", "explanation": "הבעיה המרכזית המודגמת ב-\"Lost Signal\" היא שחוט B (המאותת) יכול לשנות את המצב (done = 1) ולשלוח את האות (signal(&cv1)) לפני שחוט A (הממתין) הגיע לנקודה שבה הוא קורא ל-wait(&cv1, &m1). במצב כזה, האות נשלח אך אין חוט שממתין לו, ולכן הוא \"אובד\". כאשר חוט A יגיע לבסוף ל-wait, הוא ימתין לאות שלעולם לא יגיע, למרות שהתנאי כבר התקיים. הפתרון, כפי שמוצג בחומר ההרצאה, הוא להגן על הגישה למשתנה התנאי ולמשתנה המצב (done) באמצעות מנעול (mutex) משותף לשני החוטים. על ידי כך, חוט B לא יוכל לשנות את המצב ולאותת מבלי לתפוס את המנעול, וחוט A לא יוכל לבדוק את התנאי ולהיכנס למצב המתנה מבלי לתפוס את אותו מנעול. זה מבטיח שלא תהיה התערבות בין הפעולות ובכך מונע את אובדן האות."}, "_source_file": "0185__Concurrency__Synchronization__MC__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:36:37", "_subject": "Concurrency", "_context_lectures": [10, 11, 13, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Synchronization"], "difficulty_estimation": "Medium", "content": {"text": "בהתייחס לדוגמה משיעור 11, שבה שני חוטים (A ו-B) ניגשים למשתנים משותפים `next` ו-`arr`, ומתרחש מצב שבו חוט אחד דורס את הנתונים שנכתבו על ידי חוט אחר, איזו בעיה קלאסית של סינכרון מתוארת?", "code_snippet": "Thread A\nmy_slot_A = next;\narr[my_slot_A] = value_A;\nnext = next+ 1;\n\nThread B\nmy_slot_B = next;\narr[my_slot_B] = value_B;\nnext = next+ 1;", "options": ["א. מצב מרוץ (Race Condition)", "ב. רעב (Starvation)", "ג. אובדן אות (Lost Signal)", "ד. חוסר זיקה למטמון (Lack of Cache Affinity)"]}, "solution": {"correct_option": "א", "explanation": "הדוגמה מתארת מצב שבו מספר חוטים ניגשים למשאב משותף (במקרה זה, המשתנה `next` והמערך `arr`) בו-זמנית, ולפחות אחד מהם מבצע פעולת כתיבה. סדר הפעולות אינו ודאי, והתוצאה הסופית תלויה בסדר הביצוע הספציפי של הפקודות על ידי המעבד. במצב זה, חוט A קורא את `next`, מתרחש מיתוג הקשר, חוט B קורא גם הוא את `next` (שעדיין מכיל את הערך הישן), חוט B ממשיך וכותב ל-`arr` ומעדכן את `next`. כאשר חוט A ממשיך, הוא כותב למיקום שגוי (המיקום שקרא בתחילה) ודורס את הנתונים של חוט B. מצב זה, שבו התוצאה של הריצה תלויה בסדר הלא-דטרמיניסטי של הפעולות, מכונה 'מצב מרוץ' (Race Condition), והוא בעיה קלאסית של סינכרון כפי שמצוין במפורש בחומר הלימוד. אפשרויות ב' (רעב) וג' (אובדן אות) מתארות בעיות סינכרון ספציפיות אחרות המוזכרות בחומר, אך אינן מתאימות לתיאור הבעיה המרכזית בדוגמה זו. אפשרות ד' (חוסר זיקה למטמון) היא בעיה הקשורה לביצועים בתזמון מקבילי ואינה בעיית סינכרון של נתונים משותפים."}, "_source_file": "0186__Concurrency__Synchronization__MC__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:36:50", "_subject": "Concurrency", "_context_lectures": [10, 11, 13, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Synchronization"], "difficulty_estimation": "Hard", "content": {"text": "בהתייחס לבעיית \"אובדן אות\" (Lost Signal) עם משתני תנאי (Condition Variables), כפי שהוצגה בחומר הלימוד, התרחיש הבעייתי מתואר כך:\n```c\nThread A\nlock(&m1);\n// wait for mmmBop\nif (!done)\n  wait(&cv1, &m1);\nbaDuBop();\nunlock(&m1);\n\nThread B\nmmmBop();\ndone = 1;\nsignal(&cv1);\nLost signal\n```\nמהי ההשלכה המרכזית של מצב זה, וכיצד הפתרון המוצע בחומר הלימוד מונע אותה?", "code_snippet": "Thread A\nlock(&m1);\n// wait for mmmBop\nif (!done)\n  wait(&cv1, &m1);\nbaDuBop();\nunlock(&m1);\n\nThread B\nmmmBop();\ndone = 1;\nsignal(&cv1);\nLost signal", "options": ["א. ההשלכה המרכזית היא ש-Thread A ייכנס למצב של המתנה אינסופית, והפתרון הוא לוודא שגם Thread B יתפוס וישחרר את המנעול (lock) סביב עדכון משתנה התנאי והאיתות.", "ב. ההשלכה המרכזית היא \"הרעבה\" (starvation) של Thread A, והפתרון הוא שימוש במנגנון lock-free המאפשר התקדמות כוללת של המערכת.", "ג. ההשלכה המרכזית היא פגיעה ב-cache affinity עקב מיתוגי הקשר תכופים, והפתרון הוא יישום אלגוריתם תזמון המעדיף ריצת חוטים על אותו מעבד.", "ד. ההשלכה המרכזית היא כתיבת נתונים שגויה למשאב משותף (race condition), והפתרון הוא שימוש במנעול גלובלי יחיד לכל המשאבים המשותפים במערכת."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מתאר את בעיית ה-Lost Signal: כאשר Thread A בודק את `done` ומוצא אותו שקר, הוא מתכוון לקרוא ל-`wait`. אם מתבצע מיתוג הקשר (context switch) ל-Thread B לפני ש-Thread A הספיק לקרוא ל-`wait`, ו-Thread B מסיים את עבודתו (מגדיר `done = 1`) ומשגר אות (signal), האות אובד מכיוון שאף אחד לא ממתין לו. כאשר Thread A חוזר לרוץ, הוא קורא ל-`wait` ונכנס למצב של המתנה אינסופית, כיוון שהאות שכבר שוגר לא יגיע אליו. הפתרון לבעיה זו, כפי שמצוין בחומר הלימוד, הוא \"שימוש במנעול גם בצד השני\" – כלומר, גם Thread B חייב לתפוס את אותו המנעול (`m1`) לפני שהוא מעדכן את `done` ומשגר את ה-`signal`. פעולה זו מבטיחה שגישה למשתנה התנאי `done` וקריאות ל-`wait`/`signal` יהיו אטומיות, ומונעת את מיתוג הקשר בנקודה קריטית שיכולה לגרום לאובדן האות. לכן, אפשרות א' מתארת נכונה את ההשלכה המרכזית ואת הפתרון המוצע."}, "_source_file": "0187__Concurrency__Synchronization__MC__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:37:16", "_subject": "Concurrency", "_context_lectures": [10, 11, 13, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Synchronization"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על קטע הקוד הבא, המתאר תקשורת בין חוטים (Thread A ו-Thread B) באמצעות משתנה תנאי (cv1) ומנעול (m1), כאשר חוט A ממתין לאירוע שחוט B מסמן:\n\n```c\n// Thread A\nlock(&m1);\nif (!done) {\n  wait(&cv1, &m1);\n}\nbaDuBop();\nunlock(&m1);\n\n// Thread B\nmmmBop();\ndone = 1;\nsignal(&cv1);\n```\n\nנניח שחוט A מתחיל לרוץ, מבצע את `lock(&m1)` ובודק את `!done` (שערכו ההתחלתי הוא `true`). לפני שחוט A מספיק לקרוא לפונקציה `wait(&cv1, &m1)`, מתרחש מיתוג הקשר (context switch) לחוט B. חוט B רץ, מבצע את `mmmBop()`, משנה את `done = 1`, ושולח את הסיגנל (`signal(&cv1)`). לאחר מכן, חוט B מסיים (או מתרחש מיתוג קשר חזרה ל-A). כאשר חוט A חוזר לרוץ וממשיך מהנקודה בה עצר (לפני הקריאה ל-`wait`), איזו בעיה צפויה להתרחש?", "code_snippet": "// Thread A\nlock(&m1);\nif (!done) {\n  wait(&cv1, &m1);\n}\nbaDuBop();\nunlock(&m1);\n\n// Thread B\nmmmBop();\ndone = 1;\nsignal(&cv1);", "options": ["א. חוט A ייתקע בהמתנה אינסופית (starvation) מכיוון שהסיגנל מחוט B נשלח כאשר אף חוט לא המתין על cv1, ולכן הסיגנל אבד.", "ב. תתרחש שגיאת זמן ריצה כאשר חוט B ינסה לשלוח סיגנל ל-cv1 מבלי להחזיק במנעול m1.", "ג. חוט A יבצע את baDuBop() באופן מיידי מכיוון שהמשתנה done כבר קיבל את הערך 1 לפני הקריאה ל-wait.", "ד. תתרחש התנגשות (race condition) על המשתנה done שתגרום לערכו להיות בלתי צפוי."]}, "solution": {"correct_option": "א", "explanation": "הבעיה המתוארת היא בעיית \"אובדן סיגנל\" (lost signal), כפי שנדונה בחומר ההרצאה (Lecture 13, chunk 41). לפי תרחיש הריצה, חוט A בודק את `done` ומוצא אותו `false`. לפני שהוא מספיק להיכנס למצב המתנה על `cv1` באמצעות `wait()`, חוט B רץ, משנה את `done` ל-`1`, ושולח את הסיגנל. מכיוון שחוט A טרם קרא ל-`wait`, אף חוט אינו ממתין על `cv1` באותו רגע, ולכן הסיגנל \"אובד\" – אין לו למי להגיע. כאשר חוט A חוזר לרוץ ומגיע לבסוף לקריאה ל-`wait(&cv1, &m1)`, הוא נכנס למצב המתנה אינסופית, שכן הסיגנל שכבר נשלח לא יגיע אליו. אפשרות ב' אינה נכונה מכיוון ששליחת סיגנל אינה דורשת בהכרח שהחוט השולח יחזיק במנעול, אלא שהיא חלק מלוגיקת סינכרון כוללת. אפשרות ג' אינה נכונה מכיוון שחוט A כבר בדק את `done` וראה שהוא `false` לפני ש-B שינה אותו, ולכן הוא ייכנס ל-`wait`. אפשרות ד' אינה מתארת את הבעיה העיקרית; למרות ש-`done` הוא משתנה משותף, ערכו יהיה `1` באופן צפוי לאחר ש-B יסיים, אך חוט A לא יתעורר מההמתנה בגלל אובדן הסיגנל."}, "_source_file": "0188__Concurrency__Synchronization__MC__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:37:37", "_subject": "Concurrency", "_context_lectures": [10, 11, 13, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Synchronization"], "difficulty_estimation": "Hard", "content": {"text": "בהינתן בעיית ה\"איתות האבוד\" (Lost Signal) כפי שתוארה בחומר ההרצאה, שבה חוט A ממתין לאירוע וחוט B מאותת עליו, וללא שימוש נכון במנעולים עלול האיתות ללכת לאיבוד. הקוד הראשוני שהוצג, שבו האיתות עלול ללכת לאיבוד, היה כדלקמן:\n\n```c\n// Thread A\nlock(&m1);\nif (!done)\n  wait(&cv1, &m1);\nbaDuBop();\nunlock(&m1);\n\n// Thread B\nmmmBop();\ndone = 1;\nsignal(&cv1); // A signal might be lost here\n```\n\nהפתרון שהוצע כלל הוספת מנעול גם לחוט B, כך:\n\n```c\n// Thread A (unchanged)\nlock(&m1);\nif (!done)\n  wait(&cv1, &m1);\nbaDuBop();\nunlock(&m1);\n\n// Thread B (modified)\nlock(&m1); // Added\nmmmBop();\ndone = 1;\nsignal(&cv1);\nunlock(&m1); // Added\n```\n\nמהי הסיבה המדויקת והעיקרית להוספת המנעול (lock/unlock) בחוט B, כפי שהוצג בפתרון, למניעת בעיית ה\"איתות האבוד\"?", "code_snippet": null, "options": ["א. המנעול בחוט B מבטיח שאף חוט אחר לא יוכל להיכנס לקטע קריטי המוגן על ידי m1 בזמן שחוט B מעדכן את done ושולח את האיתות. זה מונע מצב שבו חוט A בודק את done, מוצא אותו כ-0, ואז לפני שהוא מספיק לקרוא ל-wait, חוט B משנה את done ל-1 ושולח signal, אשר אובד.", "ב. המנעול בחוט B נחוץ כדי להגן על המשתנה done מפני Race Condition, שכן done הוא משאב משותף, אך אינו קשור ישירות לאובדן האיתות.", "ג. המנעול בחוט B מונע מחוט A לקרוא ל-wait(&cv1, &m1) אם חוט B כבר סיים את mmmBop() ושלח את האיתות, ובכך מונע חסימה מיותרת של חוט A.", "ד. המנעול בחוט B מאפשר לחוט B להמשיך לרוץ במקביל לחוט A גם לאחר שליחת האיתות, מבלי שחוט A יחסום אותו."]}, "solution": {"correct_option": "א", "explanation": "הבעיה המרכזית ב\"איתות האבוד\" מתרחשת כאשר חוט A בודק את התנאי (`if (!done)`), מוצא אותו כ-`true` (כלומר `done` הוא `0`), אך לפני שהוא מספיק לקרוא לפונקציה `wait(&cv1, &m1)` (שגם משחררת את המנעול וגם חוסמת את החוט), מתרחש מיתוג הקשר (context switch) לחוט B. חוט B רץ, משנה את `done` ל-`1`, ושולח `signal(&cv1)`. מכיוון שחוט A עדיין לא קרא ל-`wait`, אין מי שממתין לאיתות זה, והאיתות הולך לאיבוד. כאשר חוט A יחזור לרוץ ויקרא ל-`wait`, הוא ייחסם ללא הגבלת זמן, למרות שהאירוע כבר התרחש.\n\nהוספת המנעול בחוט B (lock/unlock) מבטיחה שכל הרצף של עדכון `done` ושליחת `signal` יתבצע כפעולה אטומית, כלומר, לא ניתן יהיה לבצע מיתוג הקשר לחוט A (או לכל חוט אחר שמשתמש במנעול `m1`) בתוך רצף פעולות זה. בפרט, אם חוט A תפס את המנעול `m1` ובודק את `done`, חוט B לא יוכל לתפוס את `m1` ולהתקדם עד שחוט A ישחרר אותו (למשל, בעת קריאה ל-`wait` או יציאה מהקטע הקריטי). באופן דומה, אם חוט B תפס את `m1` ומתקדם לעדכון `done` ושליחת `signal`, חוט A לא יוכל לתפוס את `m1` ולבדוק את `done` או לקרוא ל-`wait`. בכך, המנעול מבטיח שחוט A לא יבדוק את `done` ויחליט להיכנס למצב המתנה, רק כדי שחוט B ישלים את פעולותיו וישלח איתות שייאבד לפני שחוט A נכנס למצב המתנה בפועל. כפי שצויין בהרצאה, \"עכשיו הם לא יכולים להתערבב\".\n\nאפשרויות ב', ג' ו-ד' אינן הסיבה העיקרית והמדויקת: \n*   **ב'** - הגנה על `done` מפני Race Condition היא חשובה, אך זוהי רק חלק מהתמונה. הבעיה העיקרית של ה\"איתות האבוד\" היא סנכרון התזמון בין `signal` ל-`wait`, ולא רק עקביות המשתנה `done` בפני עצמה.\n*   **ג'** - מניעת חסימה מיותרת של חוט A היא תוצאה רצויה של הפתרון, אך הסיבה העיקרית להוספת המנעול היא למנוע את אובדן האיתות מלכתחילה, מה שמוביל לחסימה מיותרת. המנעול פותר את שורש הבעיה ולא רק את הסימפטום.\n*   **ד'** - מנעולים (mutexes) משמשים למניעת ריצה מקבילית של קטעים קריטיים, כלומר להבטחת הדרה הדדית (mutual exclusion), ולא כדי לאפשר ריצה מקבילית. לכן, אפשרות זו שגויה לחלוטין."}, "_source_file": "0189__Concurrency__Synchronization__MC__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:38:02", "_subject": "Concurrency", "_context_lectures": [10, 11, 13, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Spinlocks"], "difficulty_estimation": "Easy", "content": {"text": "מהי תכונה נפוצה של מנעולי ספין (Spinlocks) פשוטים, כגון אלו המבוססים על CompareAndSwap (TAS)?", "code_snippet": "while (CompareAndSwap(&flag, 0, 1))\n  ; // spin-wait\n// critical section\nflag = 0;", "options": ["א. הם מונעים קיפאון (deadlock) אך אינם בהכרח הוגנים (fair).", "ב. הם תמיד מבטיחים הוגנות (fairness) בין חוטים.", "ג. הם רגישים למצב של קיפאון (deadlock).", "ד. הם משתמשים במערכת כרטיסים (ticket system) מובנית להבטחת סדר."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה (Lecture 11, chunk 45), מנעולי ספין המבוססים על פקודות מכונה כמו CompareAndSwap (TAS) מונעים מצבי קיפאון (deadlock), אך אינם מבטיחים בהכרח הוגנות (fairness) בין החוטים הממתינים. ההרצאה מציינת במפורש: 'שני המנעולים הללו דומים, שניהם מונעים deadlock אבל אינם בהכרח הוגנים'. מנעולים כמו Ticket Lock הוצגו כפתרון ספציפי להבטחת הוגנות, ולכן אינם מאפיינים מנעולי ספין פשוטים כמו TAS."}, "_source_file": "0190__Concurrency__Spinlocks__MC__Easy.json", "_topic_hint": "Spinlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:38:12", "_subject": "Concurrency", "_context_lectures": [16, 11, 13, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Spinlocks"], "difficulty_estimation": "Easy", "content": {"text": "מהי הדרך העיקרית שבה מנעול ספין (Spinlock) ממתין למשאב שיתפנה?", "code_snippet": "while (CompareAndSwap(&flag, 0, 1))\n  ; // spin-wait", "options": ["א. ביצוע \"המתנה פעילה\" (busy-waiting) בלולאה.", "ב. השעיית החוט והעברתו למצב חסימה.", "ג. שחרור המעבד לחוטים אחרים באופן מיידי.", "ד. שימוש בתור המתנה מבוסס אירועים."]}, "solution": {"correct_option": "א", "explanation": "מנעול ספין (Spinlock) מאופיין בכך שהוא ממתין למשאב שיתפנה על ידי ביצוע 'המתנה פעילה' (busy-waiting) בלולאה. במקום להשעות את החוט הממתין ולהעבירו למצב חסום, הוא ממשיך לבדוק שוב ושוב את מצב המנעול. דוגמת הקוד `while (CompareAndSwap(&flag, 0, 1)); // spin-wait` מדגימה בבירור התנהגות זו של 'spin-wait' (המתנה בסבסוב) על ידי לולאה שבודקת באופן רציף את המצב. אפשרויות אחרות, כמו השעיית חוטים (אפשרות ב'), מתאימות למנגנוני סנכרון אחרים כמו Mutex שאינם Spinlocks."}, "_source_file": "0191__Concurrency__Spinlocks__MC__Easy.json", "_topic_hint": "Spinlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:38:23", "_subject": "Concurrency", "_context_lectures": [16, 11, 13, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Spinlocks"], "difficulty_estimation": "Easy", "content": {"text": "מהי תכונה נפוצה של מנעולי ספין בסיסיים, כגון אלו המבוססים על פקודת CompareAndSwap (CAS)?", "code_snippet": "while (CompareAndSwap(&flag, 0, 1))\n  ; // spin-wait\n// critical section\nflag = 0;", "options": ["א. הם מונעים קיפאון (deadlock) אך אינם מבטיחים הוגנות (fairness).", "ב. הם תמיד מבטיחים הוגנות (fairness) אך אינם מונעים קיפאון (deadlock).", "ג. הם תמיד מונעים קיפאון (deadlock) ותמיד מבטיחים הוגנות (fairness).", "ד. הם אינם מונעים קיפאון (deadlock) וגם אינם מבטיחים הוגנות (fairness)."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה (Lecture 11, chunk 45), מנעולים המבוססים על פקודות כמו CompareAndSwap (CAS) דומים למנעולי TAS, ו\"שניהם מונעים deadlock אבל אינם בהכרח הוגנים.\" כלומר, מנעולים אלו מונעים מצב של קיפאון שבו חוטים חוסמים זה את זה ללא התקדמות, אך אינם מבטיחים שחוטים יקבלו גישה לקטע הקריטי בסדר מסוים או באופן שווה, מה שמהווה חוסר הוגנות פוטנציאלי."}, "_source_file": "0192__Concurrency__Spinlocks__MC__Easy.json", "_topic_hint": "Spinlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:38:33", "_subject": "Concurrency", "_context_lectures": [16, 11, 13, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Spinlocks"], "difficulty_estimation": "Medium", "content": {"text": "בהתבסס על קטע הקוד של המנעול `FlakyLock` שהוצג בהרצאה (Lecture 16, chunk 26), ובהתחשב בהגדרות של מניעה הדדית, מניעת קיפאון (deadlock freedom) והוגנות, איזו מהטענות הבאות נכונה לגבי המנעול?", "code_snippet": "typedef struct { int turn; int busy; } FlakyLock;\nvoid init(FlakyLock *lock) {\n    lock->busy = 0;\n}\nvoid lock(FlakyLock *lock, int me) {\n    do {\n        do {\n            lock->turn = me;\n        } while (lock->busy);\n        lock->busy = 1;\n    } while (lock->turn != me);\n}\nvoid unlock(FlakyLock *lock) {\n    lock->busy = 0;\n}", "options": ["א. המנעול מקיים מניעה הדדית, אך אינו מונע קיפאון ואינו הוגן.", "ב. המנעול אינו מקיים מניעה הדדית, אינו מונע קיפאון ואינו הוגן.", "ג. המנעול מונע קיפאון והוגן, אך אינו מקיים מניעה הדדית.", "ד. המנעול מקיים מניעה הדדית ומונע קיפאון, אך אינו הוגן."]}, "solution": {"correct_option": "א", "explanation": "המנעול `FlakyLock` מקיים מניעה הדדית, אך אינו מונע קיפאון ואינו הוגן:\n\n1.  **מניעה הדדית (Mutual Exclusion):** המנעול *כן* מקיים מניעה הדדית. ניתוח מפורט מראה שבכל רגע נתון, רק חוט אחד יכול להיכנס לקטע הקריטי. כאשר `lock->busy` הוא 0, מספר חוטים יכולים לבצע `lock->turn = me;` ולצאת מהלולאה הפנימית. אולם, רק אחד מהם יצליח בהמשך לקבוע `lock->busy = 1;` ולעבור את הבדיקה `lock->turn != me;` (כאשר `lock->turn` שווה ל-`me` שלו) כדי להיכנס לקטע הקריטי. כל עוד חוט נמצא בקטע הקריטי, `lock->busy` יהיה 1, וחוטים אחרים ימתינו בלולאה הפנימית `while (lock->busy);` או בלולאה החיצונית `while (lock->turn != me);`.\n\n2.  **מניעת קיפאון (Deadlock Freedom):** המנעול *אינו* מונע קיפאון. תרחיש לקיפאון: נניח ש-`lock->busy = 0`. חוט T1 מבצע `lock->turn = T1;`. מיד לאחר מכן, חוט T2 מבצע `lock->turn = T2;` (כך ש-`lock->turn` נשאר `T2`). שני החוטים יצאו מהלולאה הפנימית `do { ... } while (lock->busy);` כיוון ש-`lock->busy` היה 0. כעת, נניח שחוט T1 מצליח ראשון לקבוע `lock->busy = 1;`. חוט T1 ממשיך לבדיקה `while (lock->turn != T1);`. כיוון ש-`lock->turn` הוא `T2` (ולא `T1`), התנאי `lock->turn != T1` הוא אמת, וחוט T1 נתקע בלולאה החיצונית, מחזיק את `lock->busy=1`. במקביל, חוט T2, שגם הוא יצא מהלולאה הפנימית, נתקע כעת בלולאה הפנימית `while (lock->busy);` (שנמצאת בתוך הלולאה החיצונית) כיוון ש-`lock->busy` הוא 1. במצב זה, חוט T1 מחזיק את המשאב `lock->busy` ואינו יכול להתקדם, וחוט T2 אינו יכול להתקדם כי הוא מחכה ש-`lock->busy` יתאפס. זהו קיפאון, כיוון שאף אחד מהחוטים לא יכול להתקדם.\n\n3.  **הוגנות (Fairness):** המנעול *אינו* הוגן. משתנה ה-`turn` יכול להידרס שוב ושוב על ידי חוטים שונים המנסים לתפוס את המנעול, ואין מנגנון שמבטיח שחוטים יכנסו לקטע הקריטי בסדר הגעתם (כמו במנעול Ticket Lock שנדון בהרצאה), או שמבטיח שכל חוט יזכה להיכנס בסופו של דבר (מניעת הרעבה). חוט עלול להמתין לנצח אם ה-`turn` שלו לא יגיע לעולם או תמיד יידרס לפני שהוא מצליח לתפוס את המנעול."}, "_source_file": "0193__Concurrency__Spinlocks__MC__Medium.json", "_topic_hint": "Spinlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:39:24", "_subject": "Concurrency", "_context_lectures": [16, 11, 13, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Spinlocks"], "difficulty_estimation": "Medium", "content": {"text": "בהתבסס על מימוש המנעול `FlakyLock` הנתון, איזו מהטענות הבאות מתארת נכונה את תכונותיו ביחס למניעה הדדית, מניעת קיפאון והוגנות?", "code_snippet": "typedef struct { int turn; int busy; } FlakyLock;\nvoid init(FlakyLock *lock) {\n    lock->busy = 0;\n}\nvoid lock(FlakyLock *lock, int me) {\n    do {\n        do {\n            lock->turn = me;\n        } while (lock->busy);\n        lock->busy = 1;\n    } while (lock->turn != me);\n}\nvoid unlock(FlakyLock *lock) {\n    lock->busy = 0;\n}", "options": ["א. המנעול מקיים מניעה הדדית ומניעת קיפאון, אך אינו מבטיח הוגנות.", "ב. המנעול מקיים מניעה הדדית והוגנות, אך עלול לגרום לקיפאון.", "ג. המנעול אינו מקיים מניעה הדדית, אך מבטיח מניעת קיפאון והוגנות.", "ד. המנעול מקיים את כל שלוש התכונות: מניעה הדדית, מניעת קיפאון והוגנות."]}, "solution": {"correct_option": "א", "explanation": "הסבר מפורט:\n\n*   **מניעה הדדית (Mutual Exclusion):** המנעול מקיים מניעה הדדית. חוט יכול להיכנס לקטע הקריטי רק אם הוא מצליח להגדיר את `lock->busy = 1` וגם לוודא שערך `lock->turn` עדיין תואם את ה-`me` שלו. אם חוט אחר משנה את `lock->turn` לפני שהחוט הנוכחי מצליח לבדוק את התנאי `lock->turn != me`, החוט הנוכחי יחזור ללולאה החיצונית וינסה שוב. זה מבטיח שרק חוט אחד יכול להיכנס לקטע הקריטי בכל רגע נתון, שכן אם חוט אחד נמצא בקטע הקריטי, `lock->busy` יהיה 1, וימנע מחוטים אחרים להתקדם מעבר ללולאה הפנימית.\n\n*   **מניעת קיפאון (Deadlock Freedom):** המנעול מונע קיפאון. החוטים מבצעים \"ספין-וויט\" (busy-wait) על המנעול. אין תלות מעגלית שמונעת מכל החוטים להתקדם. ברגע שהמנעול משוחרר (על ידי קריאה ל-`unlock`), אחד מהחוטים הממתינים יצליח בסופו של דבר לתפוס אותו, גם אם יש תחרות קשה על משתנה `turn`. המצב המתואר ב-`Lecture 11 (chunk 34)` שבו חוט מחכה ל-`turn` של חוט אחר שאינו מעוניין להיכנס כלל, אינו מתרחש כאן, שכן חוט שמעוניין להיכנס ינסה באופן אקטיבי להגדיר את `turn` לעצמו.\n\n*   **הוגנות (Fairness):** המנעול אינו מבטיח הוגנות. אין מנגנון שמבטיח שחוטים יקבלו את המנעול לפי סדר הגעתם. חוט יכול להידחק שוב ושוב על ידי חוטים אחרים שמשנים את `lock->turn` שלו, לפני שהוא מספיק להשלים את תהליך התפיסה. זהו מאפיין נפוץ במנעולי ספין פשוטים כמו TAS, כפי שמצוין ב-`Lecture 11 (chunk 45)`: \"שני המנעולים הללו דומים, שניהם מונעים deadlock אבל אינם בהכרח הוגנים.\" מנעול ה-Ticket Lock מוזכר כדוגמה למנעול עם הוגנות, תכונה שאינה קיימת ב-`FlakyLock`."}, "_source_file": "0194__Concurrency__Spinlocks__MC__Medium.json", "_topic_hint": "Spinlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:39:44", "_subject": "Concurrency", "_context_lectures": [16, 11, 13, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Spinlocks"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על קוד המנעול FlakyLock הנתון, ובהתחשב בהגדרות של מניעה הדדית (Mutual Exclusion), מניעת קיפאון (Deadlock Freedom) ומהוגנות (Fairness) כפי שנלמדו בקורס:\n\n```c\ntypedef struct { int turn; int busy; } FlakyLock;\nvoid init(FlakyLock *lock) {\n    lock->busy = 0;\n}\nvoid lock(FlakyLock *lock, int me) {\n    do {\n        do {\n            lock->turn = me;\n        } while (lock->busy);\n        lock->busy = 1;\n    } while (lock->turn != me);\n}\nvoid unlock(FlakyLock *lock) {\n    lock->busy = 0;\n}\n```\n\nאילו מבין התכונות הבאות מקיים המנעול FlakyLock?", "code_snippet": null, "options": ["א. אף אחת מהתכונות (מניעה הדדית, מניעת קיפאון, מהוגנות) אינה מובטחת.", "ב. המנעול מקיים מניעה הדדית בלבד.", "ג. המנעול מקיים מניעה הדדית ומניעת קיפאון, אך לא מהוגנות.", "ד. המנעול מקיים את כל שלוש התכונות: מניעה הדדית, מניעת קיפאון ומהוגנות."]}, "solution": {"correct_option": "א", "explanation": "המנעול FlakyLock אינו מקיים אף אחת מהתכונות המבוקשות:\n\n1.  **מניעה הדדית (Mutual Exclusion):** המנעול אינו מבטיח מניעה הדדית. נניח שחוט T1 (עם `me=1`) קורא ל-`lock(lock, 1)`. הוא מבצע `lock->turn = 1;` ולאחר מכן `lock->busy = 1;`. כעת, לפני ש-T1 מספיק לבדוק את התנאי `lock->turn != me` בלולאה החיצונית, חוט T2 (עם `me=2`) קורא ל-`lock(lock, 2)`. T2 מבצע `lock->turn = 2;` (ובכך דורס את הערך ש-T1 כתב). כעת T2 יתחיל להמתין בלולאה הפנימית `while (lock->busy)` מכיוון ש-`lock->busy` הוא 1. T1, לעומת זאת, יגיע לבדיקה `while (lock->turn != 1)`. מכיוון ש-`lock->turn` הוא כעת 2 (לאחר ש-T2 דרס אותו), התנאי `2 != 1` הוא אמת, ו-T1 יכנס ללולאת המתנה אינסופית. במצב זה, אף חוט לא נכנס לקטע הקריטי, וגם אף חוט לא יכול להתקדם, מה שמצביע על כשל במנגנון המניעה ההדדית וקיפאון.\n\n2.  **מניעת קיפאון (Deadlock Freedom):** כפי שהוסבר לעיל, המנעול אינו מונע קיפאון. במצב שבו `lock->turn` נדרס על ידי חוט אחד בזמן שחוט אחר כבר קבע את `lock->busy = 1`, החוט שקבע את `busy` ייתקע בלולאה החיצונית `while (lock->turn != me)` מכיוון שערך ה-`turn` שלו כבר אינו תואם את ה-`me` שלו. במקביל, החוט שדרס את ה-`turn` ייתקע בלולאה הפנימית `while (lock->busy)` כי `busy` הוא 1. אף חוט לא יתקדם, ויתרחש קיפאון.\n\n3.  **מהוגנות (Fairness):** המנעול אינו מקיים מהוגנות. אין בו מנגנון תור מוגדר (כמו במנעול כרטיסים - Ticket Lock שהוצג בהרצאה) שיבטיח שחוטים יכנסו לקטע הקריטי לפי סדר בקשתם. קביעת `lock->turn = me` היא פעולה שחשופה לתחרות (race condition) ולדריסה, ואין שום ערובה שחוט יקבל את המנעול, גם אם הוא המתין זמן רב. חוט יכול להיות 'מורעב' (starved) מכיוון שחוטים אחרים דורסים שוב ושוב את ערך ה-`turn` שלו.\n\nלכן, אף אחת מהתכונות אינה מובטחת על ידי מנעול FlakyLock זה.", "code_snippet_explanation": null}, "_source_file": "0196__Concurrency__Spinlocks__MC__Hard.json", "_topic_hint": "Spinlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:40:26", "_subject": "Concurrency", "_context_lectures": [16, 11, 13, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Spinlocks"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על קוד ה-`FlakyLock` הנתון, אילו מהטענות הבאות נכונה לגבי תכונותיו של המנעול?", "code_snippet": "typedef struct { int turn; int busy; } FlakyLock;\nvoid init(FlakyLock *lock) {\n    lock->busy = 0;\n}\nvoid lock(FlakyLock *lock, int me) {\n    do {\n        do {\n            lock->turn = me;\n        } while (lock->busy);\n        lock->busy = 1;\n    } while (lock->turn != me);\n}\nvoid unlock(FlakyLock *lock) {\n    lock->busy = 0;\n}", "options": ["א. המנעול מקיים מניעה הדדית, אך אינו מונע קיפאון ואינו הוגן.", "ב. המנעול מקיים מניעה הדדית ומונע קיפאון, אך אינו הוגן.", "ג. המנעול אינו מקיים מניעה הדדית, אך מונע קיפאון והוא הוגן.", "ד. המנעול מקיים את כל שלוש התכונות: מניעה הדדית, מניעת קיפאון והוגנות."]}, "solution": {"correct_option": "א", "explanation": "הבה ננתח את תכונות ה-`FlakyLock` המוצג בקוד:\n\n**1. מניעה הדדית (Mutual Exclusion):**\nהמנעול **מקיים** מניעה הדדית. כאשר חוט (נניח חוט A) נכנס לקטע הקריטי, הוא מבטיח ש-`lock->busy` יהיה 1 לפני הכניסה. כל חוט אחר (נניח חוט B) שינסה להיכנס, יבצע קודם `lock->turn = B;` ולאחר מכן יגיע ללולאה הפנימית `while (lock->busy)`. מכיוון ש-`lock->busy` הוא 1 (נקבע על ידי חוט A), חוט B ימתין (spin) בלולאה זו ולא יוכל להמשיך עד שחוט A ישחרר את המנעול (יגדיר `lock->busy = 0`). לכן, רק חוט אחד יכול להימצא בקטע הקריטי בכל רגע נתון.\n\n**2. מניעת קיפאון (Deadlock Freedom):**\nהמנעול **אינו מונע** קיפאון. ניתן להדגים תרחיש קיפאון כזה:\nא. מצב התחלתי: `lock->busy = 0`.\nב. חוט A (עם מזהה `me=1`) קורא לפונקציה `lock` ומבצע `lock->turn = 1;`.\nג. חוט B (עם מזהה `me=2`) קורא לפונקציה `lock` ומבצע `lock->turn = 2;`. כעת `lock->turn` שווה 2.\nד. חוט A ממשיך בביצוע: הוא יוצא מהלולאה הפנימית `do { ... } while (lock->busy);` מכיוון ש-`lock->busy` הוא 0.\nה. חוט A מבצע `lock->busy = 1;`.\nו. חוט A ממשיך בביצוע: הוא נכנס ללולאה החיצונית `do { ... } while (lock->turn != me);`. התנאי `lock->turn != 1` (כלומר `2 != 1`) הוא אמיתי, ולכן חוט A מתחיל להמתין (spin) בלולאה זו.\nז. חוט B ממשיך בביצוע: הוא נכנס ללולאה הפנימית `do { ... } while (lock->busy);`. התנאי `lock->busy` (כלומר `1`) הוא אמיתי, ולכן חוט B מתחיל להמתין (spin) בלולאה זו.\nבשלב זה, חוט A ממתין ש-`lock->turn` יהפוך ל-1 (אך הוא 2), וחוט B ממתין ש-`lock->busy` יהפוך ל-0 (אך הוא 1). שני החוטים תקועים בלולאות המתנה אינסופיות, וזהו מצב קיפאון.\n\n**3. הוגנות (Fairness):**\nהמנעול **אינו הוגן**. מכיוון שקיים מצב של קיפאון, הוגנות אינה מושגת. גם ללא קיפאון, המנגנון של `lock->turn = me;` בתוך לולאה מאפשר לחוטים שונים 'לדרוס' זה את ערך ה-`turn` של זה שוב ושוב. אין מנגנון שמבטיח שחוטים יקבלו את המנעול לפי סדר בקשתם, בניגוד למנעולים כמו `Ticket Lock` המוזכרים בחומר ההרצאה, המבטיחים הוגנות על ידי מתן מספר תור לכל חוט.\n\nלסיכום, המנעול מקיים מניעה הדדית, אך סובל מקיפאון ואינו הוגן. לכן, אפשרות א' היא הנכונה."}, "_source_file": "0197__Concurrency__Spinlocks__MC__Hard.json", "_topic_hint": "Spinlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:40:55", "_subject": "Concurrency", "_context_lectures": [16, 11, 13, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Ticket Locks"], "difficulty_estimation": "Easy", "content": {"text": "מהו המאפיין העיקרי של מנעול מסוג Ticket Lock, המבדיל אותו ממנעולים פשוטים יותר כמו TestAndSet או CompareAndSwap?", "code_snippet": null, "options": ["א. הוא מבטיח מניעה הדדית (mutual exclusion) על ידי שימוש במשתנה דגל יחיד.", "ב. הוא מבטיח הוגנות (fairness) בכניסה לקטע הקריטי על ידי מנגנון תור מפורש.", "ג. הוא מונע קיפאון (deadlock) על ידי ביצוע פעולות אטומיות בלבד.", "ד. הוא מפחית את עומס התעבורה על ה-BUS על ידי שימוש במערך של דגלים."]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר ההרצאה, מנעול Ticket Lock הוצג כ'רעיון למנעול שיש בו הוגנות'. הוא משיג זאת על ידי כך שכל חוט שרוצה להיכנס לקטע הקריטי לוקח 'כרטיס' (מספר תור), ומשתנה נוסף ('turn') קובע מי החוט הבא בתור שרשאי להיכנס. מנגנון זה מבטיח סדר כניסה ומונע הרעבה, בניגוד למנעולים פשוטים יותר כמו TestAndSet או CompareAndSwap שאינם בהכרח הוגנים ועלולים לאפשר לחוט אחד לתפוס את המנעול שוב ושוב."}, "_source_file": "0199__Concurrency__Ticket_Locks__MC__Easy.json", "_topic_hint": "Ticket Locks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:41:41", "_subject": "Concurrency", "_context_lectures": [16, 11, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Ticket Locks"], "difficulty_estimation": "Easy", "content": {"text": "מהו היתרון המרכזי של מנגנון ה-Ticket Lock בהשוואה למנעולים פשוטים יותר שאינם מבטיחים סדר כניסה, כמו TestAndSet?", "code_snippet": null, "options": ["א. הוא מבטיח הוגנות בכך שחוטים נכנסים לקטע הקריטי לפי סדר בקשתם (First-Come, First-Served).", "ב. הוא מונע קיפאון (deadlock) באופן מוחלט בכל תרחיש אפשרי.", "ג. הוא מפחית משמעותית את העומס על ה-BUS על ידי מניעת פקודות invalidate מרובות.", "ד. הוא מבטיח מניעה הדדית (mutual exclusion) בין חוטים בקטע הקריטי."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מציין במפורש כי מנגנון ה-Ticket Lock הוצג כ'רעיון למנעול שיש בו הוגנות' (Lecture 11, chunk 45). המנגנון משיג זאת על ידי כך שכל חוט המעוניין להיכנס לקטע קריטי לוקח 'כרטיס' (מספר תור), והכניסה לקטע הקריטי מתאפשרת רק לחוט שהגיע תורו (כאשר מספר הכרטיס שלו תואם למשתנה ה-'turn' הגלובלי). בדרך זו, חוטים נכנסים לקטע הקריטי לפי הסדר בו ביקשו גישה, מה שמבטיח הוגנות (First-Come, First-Served). מנעולים פשוטים יותר כמו TestAndSet או CompareAndSwap אכן מבטיחים מניעה הדדית וחופש מקיפאון, אך אינם בהכרח הוגנים מבחינת תזמון, כפי שמוזכר בחומר הלימוד (Lecture 11, chunk 42, 45).", "explanation_reference": "Lecture 11, chunk 45; Lecture 11, chunk 42"}, "_source_file": "0200__Concurrency__Ticket_Locks__MC__Easy.json", "_topic_hint": "Ticket Locks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:41:57", "_subject": "Concurrency", "_context_lectures": [16, 11, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Ticket Locks"], "difficulty_estimation": "Easy", "content": {"text": "מהו המאפיין המרכזי המבטיח הוגנות במנעול מסוג Ticket Lock?", "code_snippet": "int ticket = 0; // next available ticket number\nint turn = 0;   // ticket number of the thread whose turn it is\n\nvoid acquire_lock() {\n    int my_ticket = atomic_fetch_and_add(&ticket, 1); // Atomically get a ticket and increment global ticket counter\n    while (my_ticket != turn) {\n        // spin-wait\n    }\n}\n\nvoid release_lock() {\n    atomic_add(&turn, 1); // Atomically increment turn to allow the next thread\n}", "options": ["א. שימוש בפקודת מכונה אטומית TestAndSet למניעת כניסה בו-זמנית לקטע הקריטי.", "ב. הקצאת מספר תור (כרטיס) לכל חוט המבקש להיכנס, והמתנה עד שמספר התור שלו יתאים למשתנה גלובלי המצביע על התור הנוכחי.", "ג. יישום אסטרטגיית Backoff אקספוננציאלית להפחתת עומס על ה-BUS בעת המתנה.", "ד. שמירת רשימת חוטים ממתינים במערך דגלים (flags) ועדכון הדגלים באופן אטומי."]}, "solution": {"correct_option": "ב", "explanation": "מנעול ה-Ticket Lock תוכנן במיוחד כדי לספק הוגנות (fairness). הוא עושה זאת על ידי כך שכל חוט שרוצה להיכנס לקטע קריטי מקבל מספר תור (כרטיס) ייחודי באמצעות פעולה אטומית (לדוגמה, `atomic_fetch_and_add`). החוטים ממתינים בלולאה (spin-wait) עד שהמספר שהוקצה להם (my_ticket) יהיה זהה למשתנה גלובלי `turn` המציין איזה כרטיס נמצא כעת בתור. כאשר חוט מסיים את הקטע הקריטי, הוא מקדם את משתנה ה-`turn` במספר אחד, ובכך מאפשר לחוט הבא בתור להיכנס. מנגנון זה מבטיח שחוטים ייכנסו לקטע הקריטי בסדר שבו ביקשו להיכנס, ובכך מונע הרעבה (starvation) ומבטיח הוגנות. אפשרויות א', ג' ו-ד' מתארות מנגנונים או מנעולים אחרים שאינם המאפיין המרכזי להוגנות של Ticket Lock."}, "_source_file": "0201__Concurrency__Ticket_Locks__MC__Easy.json", "_topic_hint": "Ticket Locks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:42:10", "_subject": "Concurrency", "_context_lectures": [16, 11, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Ticket Locks"], "difficulty_estimation": "Medium", "content": {"text": "מהו המנגנון העיקרי המבטיח הוגנות במנעול מסוג Ticket Lock?", "code_snippet": null, "options": ["א. כל חוט לוקח מספר כרטיס ייחודי וממתין שתורו יגיע לפי משתנה התור הכללי.", "ב. הוא משתמש בפקודת CompareAndSwap כדי לתפוס את המנעול באופן אטומי.", "ג. הוא מונע מכל החוטים לבצע invalidate במטמון בו-זמנית על ידי שימוש במערך דגלים.", "ד. הוא מבטיח שחוט ששחרר את המנעול לא יוכל לתפוס אותו שוב מיד."]}, "solution": {"correct_option": "א", "explanation": "מנעול ה-Ticket Lock תוכנן במיוחד כדי להבטיח הוגנות (fairness). הוא עושה זאת על ידי הקצאת מספר כרטיס (ticket) ייחודי לכל חוט המבקש להיכנס לקטע הקריטי. קיים גם משתנה גלובלי ('turn') המציין את תורו של מי להיכנס. חוטים ממתינים בלולאה (spin-wait) עד שמספר הכרטיס שלהם תואם למשתנה ה-'turn'. כאשר חוט מסיים את הקטע הקריטי, הוא מקדם את משתנה ה-'turn' ב-1, ובכך מאפשר לחוט הבא בתור להיכנס באופן מסודר. מנגנון זה יוצר תור מפורש ומונע הרעבה (starvation) מכיוון שכל חוט יקבל את תורו בסופו של דבר. אפשרות ב' מתארת מנגנון של מנעולי TAS/CAS, אפשרות ג' מתארת מנגנון של מנעול תור מסוג Anderson, ואילו אפשרות ד' מתארת תוצאה משנית של מנגנון הכרטיסים ולא את המנגנון העיקרי המבטיח הוגנות."}, "_source_file": "0202__Concurrency__Ticket_Locks__MC__Medium.json", "_topic_hint": "Ticket Locks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:42:22", "_subject": "Concurrency", "_context_lectures": [16, 11, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Ticket Locks"], "difficulty_estimation": "Medium", "content": {"text": "על פי חומר ההרצאה, מהו היתרון המרכזי שמנעול Ticket Lock מציע בהשוואה למנעולים פשוטים יותר שאינם מנעולי תור, כגון מנעול המבוסס על TestAndSet?", "code_snippet": null, "options": ["א. הוא מבטיח מניעה הדדית (Mutual Exclusion) בין חוטים בקטע הקריטי.", "ב. הוא מספק הוגנות (Fairness) ומונע הרעבה (Starvation Freedom) על ידי הקצאת תור.", "ג. הוא מפחית באופן משמעותי את עומס ה-BUS ואת ה-cache invalidations בזמן המתנה למנעול.", "ד. הוא מבטיח חופש מקיפאון (Deadlock Freedom) בכל מצב אפשרי של תזמון."]}, "solution": {"correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. חומר ההרצאה מציין במפורש: 'נראה רעיון למנעול שיש בו הוגנות: TICKET LOCK:'. מנעול ה-Ticket Lock תוכנן במיוחד כדי לפתור את בעיית ההוגנות והרעבה, אשר אינן מובטחות במנעולים פשוטים יותר כמו TestAndSet. הוא עושה זאת על ידי הקצאת מספר תור (ticket) לכל חוט המבקש את המנעול, ושמירה על משתנה 'turn' שקובע איזה חוט מורשה להיכנס לקטע הקריטי. חוטים ממתינים בלולאה עד שמספר התור שלהם תואם את ערך ה-'turn', ובכך מבטיחים כניסה מסודרת והוגנת לקטע הקריטי לפי סדר בקשתם. אפשרויות א' ו-ד' (מניעה הדדית וחופש מקיפאון) הן תכונות בסיסיות הנדרשות מכל מנעול נכון, וקיימות גם במנעולים כמו TestAndSet (כפי שצוין בחומר ההרצאה), ולכן אינן היתרון המרכזי המבדיל של Ticket Lock. אפשרות ג' (הפחתת עומס על ה-BUS) היא יתרון כללי יותר של 'מנעולי תור' אך לא מודגשת כמאפיין ייחודי של מנגנון ה-Ticket Lock הספציפי בחומר, אשר מתמקד בהוגנות."}, "_source_file": "0203__Concurrency__Ticket_Locks__MC__Medium.json", "_topic_hint": "Ticket Locks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:42:39", "_subject": "Concurrency", "_context_lectures": [16, 11, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Ticket Locks"], "difficulty_estimation": "Medium", "content": {"text": "מהו היתרון העיקרי של מנעול Ticket Lock בהשוואה למנעולים פשוטים יותר כמו TestAndSet (TAS) או CompareAndSwap (CAS)?", "code_snippet": null, "options": ["א. הוא מבטיח הוגנות (fairness) בכך שהוא מעניק גישה לקטע הקריטי לפי סדר בקשת הכניסה של החוטים.", "ב. הוא מונע קיפאון (deadlock) בצורה יעילה יותר ממנעולי TAS/CAS.", "ג. הוא מפחית את עומס ה-invalidate על ה-cache על ידי שימוש במספר משתני נעילה.", "ד. הוא מאפשר למספר חוטים להיכנס לקטע הקריטי בו-זמנית אם המנעול זמין."]}, "solution": {"correct_option": "א", "explanation": "מנעול Ticket Lock, בניגוד למנעולים פשוטים יותר כמו TestAndSet (TAS) או CompareAndSwap (CAS), תוכנן במיוחד כדי להבטיח הוגנות (fairness). החומר מציין במפורש: \"נראה רעיון למנעול שיש בו הוגנות: TICKET LOCK\". הוא עושה זאת על ידי הקצאת \"כרטיס\" (מספר תור) לכל חוט המבקש להיכנס לקטע הקריטי, ורק כאשר ה\"תור\" (turn) הכללי תואם את מספר הכרטיס של החוט, הוא מקבל גישה. מנעולי TAS/CAS, כפי שהחומר מציין, \"אינם בהכרח הוגנים\" וייתכן שחוט יתפוס את המנעול שוב ושוב מבלי לאפשר לחוטים אחרים גישה, מה שמוביל להרעבה. אפשרות ב' אינה נכונה מכיוון שגם מנעולי TAS/CAS מונעים קיפאון. אפשרות ג' מתארת יתרון כללי של \"מנעולי תור\" (queue locks) בהפחתת עומס על ה-cache, אך התיאור הספציפי של מנגנון ה-Ticket Lock בחומר מתמקד בהוגנות באמצעות מנגנון תור, ולא מפרט כיצד הוא משיג הפחתה בעומס ה-cache בדרך של ריבוי משתני נעילה לכל חוט כמו במנעול אנדרסון. אפשרות ד' אינה נכונה מכיוון שמנעול נועד להבטיח מניעה הדדית, כלומר שרק חוט אחד יוכל להיכנס לקטע הקריטי בכל רגע נתון."}, "_source_file": "0204__Concurrency__Ticket_Locks__MC__Medium.json", "_topic_hint": "Ticket Locks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:42:57", "_subject": "Concurrency", "_context_lectures": [16, 11, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Ticket Locks"], "difficulty_estimation": "Hard", "content": {"text": "מנעול ה-Ticket Lock, כפי שתואר בחומר ההרצאה, משתייך לקטגוריית \"מנעולי התור\" (queue locks) אשר נועדו, בין היתר, לצמצם את עומס תעבורת ה-BUS הנגרם כתוצאה מ-cache invalidations רבים בעת שחרור מנעול. בהתבסס על אופן פעולתו של ה-Ticket Lock, איזה היבט במימושו עלול להגביל את יעילותו בהשגת מטרה זו, בהשוואה למנעולי תור אחרים המיועדים ספציפית לבעיית ה-cache invalidation?", "code_snippet": null, "options": ["א. העובדה שחוטים הממתינים למנעול מבצעים spin-wait במקום לעבור למצב חסום, מה שמבזבז משאבי מעבד.", "ב. השימוש במשתנה `turn` יחיד ומשותף שכל החוטים הממתינים עליו מבצעים קריאות חוזרות ונשנות (spin-read), מה שגורם ל-cache invalidations נרחבים בכל פעם שערכו מתעדכן על ידי החוט המשחרר את המנעול.", "ג. הצורך בפעולה אטומית (כמו fetch-and-add) לצורך קבלת ה\"כרטיס\" (ticket), פעולה אשר עדיין מחייבת תקשורת ל-BUS ועלולה לגרום ל-cache invalidations מקומיים.", "ד. חוסר היכולת להבטיח מניעה הדדית (mutual exclusion) בתרחישי עומס גבוהים, המאפשר למספר חוטים להיכנס לקטע הקריטי בו-זמנית."]}, "solution": {"correct_option": "ב", "explanation": "ההסבר הנכון הוא ב'. מנעולי תור, ובכללם ה-Ticket Lock, נועדו לטפל בבעיית ההוגנות ובמקרים מסוימים גם בבעיות ביצועים הקשורות ל-cache invalidations. עם זאת, למרות ש-Ticket Lock מבטיח הוגנות על ידי מתן תור כרונולוגי לכל חוט המבקש להיכנס לקטע הקריטי, אופן ההמתנה שלו (spin-wait) מתבצע על משתנה `turn` יחיד ומשותף. כאשר החוט המסיים את הקטע הקריטי מעדכן את `turn` (מקדם אותו ב-1), השינוי במשתנה זה גורם ל-cache invalidation בכל הליבות האחרות שמחזיקות עותק שלו ב-cache שלהן, מכיוון שכל החוטים הממתינים קוראים באופן תדיר את `turn` כדי לבדוק האם הגיע תורם. מצב זה יוצר תעבורת BUS משמעותית של invalidations ו-cache misses, ובכך מגביל את יעילותו של ה-Ticket Lock בהפחתת עומס ה-BUS בהשוואה למנעולי תור מתוחכמים יותר (כמו מנעול אנדרסון המוזכר בהרצאה), שבהם כל חוט ממתין על משתנה או תא זיכרון ייעודי משלו, ובכך מצמצם את היקף ה-cache invalidations המשותפים."}, "_source_file": "0205__Concurrency__Ticket_Locks__MC__Hard.json", "_topic_hint": "Ticket Locks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:43:20", "_subject": "Concurrency", "_context_lectures": [16, 11, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Ticket Locks"], "difficulty_estimation": "Hard", "content": {"text": "מנעול Ticket Lock מוצג כפתרון לבעיית ההוגנות במנעולים קודמים. בהתבסס על מנגנון הפעולה המתואר למנעול Ticket Lock, איזו בעיית ביצועים פוטנציאלית עלולה להתעורר כאשר חוטים רבים ממתינים למנעול, ואינה מטופלת באופן מפורש במנגנון זה, בניגוד לפתרונות מתקדמים יותר בקטגוריית \"מנעולי תור\"?", "code_snippet": null, "options": ["א. חוסר מניעה הדדית (mutual exclusion) בין חוטים בקטע הקריטי.", "ב. מצב קיפאון (deadlock) שבו חוטים ממתינים זה לזה ללא יכולת להתקדם.", "ג. צריכת משאבי BUS גבוהה עקב אי-ולידציה חוזרת ונשנית של קווי מטמון משותפים על ידי חוטים הממתינים למשתנה התור (turn).", "ד. הרעבה (starvation) של חוטים מסוימים שאינם מצליחים לתפוס את המנעול לעולם."]}, "solution": {"correct_option": "ג", "explanation": "מנעול Ticket Lock, כפי שמתואר בחומר, פועל על בסיס משתנה יחיד ומשותף בשם `turn` (התור הנוכחי). כל החוטים הממתינים למנעול מבצעים לולאת המתנה (spin-wait) תוך כדי קריאה חוזרת ונשנית של ערך משתנה ה-`turn`. כאשר חוט משחרר את המנעול, הוא מקדם את ערך ה-`turn`. שינוי זה במשתנה המשותף גורם לאי-ולידציה (invalidation) של קווי המטמון (cache lines) אצל כל המעבדים שמחזיקים עותק של משתנה ה-`turn` במטמון המקומי שלהם. כתוצאה מכך, חוטים רבים ינסו לגשת ל-BUS על מנת לטעון מחדש את הערך המעודכן, מה שיוצר תעבורת BUS גבוהה ופוגע בביצועים, תופעה הידועה גם כ-cache contention או \"thundering herd\" במטמון. בעיה זו היא בדיוק מה שסוגים מתקדמים יותר של \"מנעולי תור\", כמו מנעול אנדרסון המוזכר בחומר, מנסים למנוע על ידי מתן משתנה ייעודי לכל חוט להמתין עליו, ובכך למנוע את ה-\"לינקי הזה על ה-cache\"."}, "_source_file": "0206__Concurrency__Ticket_Locks__MC__Hard.json", "_topic_hint": "Ticket Locks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:43:41", "_subject": "Concurrency", "_context_lectures": [16, 11, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Ticket Locks"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על מנגנון מנעול ה-Ticket Lock כפי שתואר בחומר ההרצאה, איזו מההצהרות הבאות מתארת בצורה הטובה ביותר את יתרונו המרכזי של מנגנון זה על פני מנעולי Spin Lock פשוטים יותר (כגון TestAndSet או CompareAndSwap) בהקשר של גישה למשאבים?", "code_snippet": null, "options": ["א. הוא מונע לחלוטין את בעיית \"סערת ה-Invalidate\" על ה-BUS על ידי פיצול משתנה המנעול למספר משתנים נפרדים.", "ב. הוא מבטיח מניעה הדדית (mutual exclusion) באופן אמין יותר באמצעות שימוש בפקודות אטומיות חזקות יותר.", "ג. הוא מבטיח חופש מרעב (starvation freedom) על ידי אכיפת סדר כניסה לקטע הקריטי המבוסס על סדר קבלת ה\"כרטיסים\" (tickets).", "ד. הוא מאפשר כניסה של מספר חוטים בו-זמנית לקטע הקריטי כל עוד הם אינם משנים את אותם נתונים."]}, "solution": {"correct_option": "ג", "explanation": "החומר המצורף מציין במפורש כי \"מנעול שיש בו הוגנות: TICKET LOCK\" ומתאר את מנגנונו: \"כל חוט שרוצה להחזיק במנעול - לוקח תור, ויש משתנה שאומר מי הבא בתור להיכנס לקטע הקריטי.\" תיאור זה, יחד עם ההגדרה של \"חופש מהרעבה\" כ\"לא יכול להיות שיעקפו אותי מספר אינסופי של פעמים\", מצביע על כך שיתרונו המרכזי והייחודי של מנעול ה-Ticket Lock על פני מנעולי Spin Lock פשוטים יותר (כמו TestAndSet או CompareAndSwap, אשר צוינו כ\"אינם בהכרח הוגנים\") הוא הבטחת הוגנות וחופש מרעב. סדר הכניסה לקטע הקריטי נקבע בצורה דטרמיניסטית על ידי סדר קבלת ה\"כרטיסים\", מה שמונע מחוט מסוים להיתקע בהמתנה אינסופית.\n\nא. הצהרה זו מתארת מנגנון שמטרתו לטפל בבעיות Invalidate על ה-BUS, כפי שמתואר עבור \"מנעולי תור\" באופן כללי, ובפרט עבור מנעול אנדרסון. למרות שמנעול Ticket Lock הוא סוג של \"מנעול תור\", התיאור הספציפי שלו בחומר ההרצאה מתמקד באכיפת סדר והוגנות, ולא בפתרון בעיות מטמון על ידי פיצול משתנה המנעול באופן שכל חוט מקבל תא מטמון ייעודי.\nב. מנעולי TestAndSet ו-CompareAndSwap גם הם מבטיחים מניעה הדדית באמצעות פקודות אטומיות. היתרון של ה-Ticket Lock אינו ב\"אמינות רבה יותר\" של המניעה ההדדית, אלא בהוספת תכונת ההוגנות.\nד. הצהרה זו שגויה מיסודה. מטרתו העיקרית של כל מנעול היא להבטיח מניעה הדדית, כלומר לאפשר רק לחוט אחד להיכנס לקטע הקריטי בכל רגע נתון."}, "_source_file": "0207__Concurrency__Ticket_Locks__MC__Hard.json", "_topic_hint": "Ticket Locks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:44:01", "_subject": "Concurrency", "_context_lectures": [16, 11, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["TAS and TTAS"], "difficulty_estimation": "Easy", "content": {"text": "מהו ההבדל המבני העיקרי בין מנעול TAS למנעול TTAS, כפי שתואר בחומר ההרצאה?", "code_snippet": "void lock()\n{\n    while (true) {\n        while (state) {}\n        if (!testAndSet(state, true))\n            return;\n    }\n}", "options": ["א. מנעול TTAS כולל לולאה פנימית שבודקת באופן תמידי את מצב המנעול לפני ניסיון לבצע את פעולת testAndSet.", "ב. מנעול TAS משתמש בפעולת testAndSet בעוד שמנעול TTAS משתמש בפעולת compareAndSwap.", "ג. מנעול TTAS מיושם באמצעות מערך תאים גדול, בניגוד למנעול TAS.", "ד. מנעול TAS מציג ביצועים טובים יותר באופן משמעותי ממנעול TTAS בסביבת ריבוי חוטים."]}, "solution": {"correct_option": "א", "explanation": "ההסבר המפורט בחומר ההרצאה מציין שמנעול TTAS (Test-and-Test-and-Set) דומה למנעול TAS (Test-and-Set), \"מלבד הלולאה הפנימית\". קוד ה-TTAS המוצג מראה בבירור את הלולאה הפנימית `while (state) {}` שתפקידה לבדוק את מצב המנעול (state) ורק כאשר הוא נראה פנוי (state הוא false), אז הוא מנסה לתפוס אותו באמצעות `testAndSet`. לולאה זו היא ההבדל המבני העיקרי בין שני המנעולים, והיא מאפשרת הפחתה משמעותית של תעבורת ה-BUS על ידי קריאה חוזרת ונשנית של מצב המנעול מהמטמון המקומי (cache), ובכך משפרת את הביצועים באופן דרמטי לעומת TAS. אפשרות ב' אינה נכונה מכיוון ששני המנעולים משתמשים ב-testAndSet. אפשרות ג' מתייחסת לבעיה או מאפיין של מנעול אחר או מנגנון מתקדם יותר ולא להבדל המבני הבסיסי בין TAS ו-TTAS עצמם. אפשרות ד' אינה נכונה מכיוון שמנעול TTAS מציג ביצועים טובים בהרבה ממנעול TAS בסביבת ריבוי חוטים."}, "_source_file": "0208__Concurrency__TAS_and_TTAS__MC__Easy.json", "_topic_hint": "TAS and TTAS", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:44:12", "_subject": "Concurrency", "_context_lectures": [12, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["TAS and TTAS"], "difficulty_estimation": "Easy", "content": {"text": "מהו המאפיין המבני העיקרי של מנעול TTAS (Test-and-Test-and-Set) שמבדיל אותו ממנעול TAS (Test-and-Set) ותורם לביצועיו העדיפים?", "code_snippet": "void lock()\n{\n    while (true) {\n        while (state) {}\n        if (!testAndSet(state, true))\n            return;\n    }\n}", "options": ["א. מנעול TTAS כולל לולאה פנימית שקוראת שוב ושוב את מצב המנעול לפני ניסיון לתפוס אותו באמצעות testAndSet.", "ב. מנעול TTAS משתמש במנגנון 'backoff' אקראי כדי למנוע התנגשויות בין חוטים.", "ג. מנעול TTAS מבצע את פעולת ה-testAndSet פחות פעמים ממנעול TAS.", "ד. מנעול TTAS דורש מערך גדול של תאים בזיכרון משותף כדי לנהל תור המתנה."]}, "solution": {"correct_option": "א", "explanation": "מנעול TTAS נבדל ממנעול TAS בכך שהוא כולל לולאה פנימית (`while (state) {}`) שקוראת שוב ושוב את מצב המנעול (state) ורק כאשר הוא נראה פנוי, הוא מנסה לתפוס אותו באמצעות הפעולה האטומה `testAndSet`. לולאה פנימית זו מפחיתה באופן משמעותי את מספר פעולות ה-`testAndSet` האטומיות המבוצעות על ידי חוטים ממתינים. פעולות אטומיות אלו כרוכות בתקורה גבוהה יותר (כמו תקשורת ב-BUS לצורך שמירה על קוהרנטיות מטמון במעבדים מרובי ליבות) בהשוואה לקריאה רגילה של משתנה, ולכן צמצומן משפר את הביצועים באופן ניכר, כפי שמוצג בגרפים של ביצועי TTAS לעומת TAS. האפשרויות האחרות אינן מתארות את ההבדל המבני העיקרי או שהן מתארות תוצאות או מאפיינים של מנגנוני נעילה אחרים/מורכבים יותר."}, "_source_file": "0209__Concurrency__TAS_and_TTAS__MC__Easy.json", "_topic_hint": "TAS and TTAS", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:44:24", "_subject": "Concurrency", "_context_lectures": [12, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["TAS and TTAS"], "difficulty_estimation": "Easy", "content": {"text": "בהתבסס על קטע הקוד של מנעול Test-and-Test-and-Set (TTAS) המצורף, מהו המאפיין המבני העיקרי שמבדיל אותו ממנעול Test-and-Set (TAS) פשוט?", "code_snippet": "void lock()\n{\n    while (true) {\n        while (state) {}\n        if (!testAndSet(state, true))\n            return;\n    }\n}", "options": ["א. מנעול TTAS כולל לולאה פנימית (`while (state) {}`) שבודקת את מצב המנעול ללא ניסיון לתפוס אותו, לפני קריאה ל-`testAndSet`.", "ב. מנעול TTAS משתמש בפונקציה אטומית שונה לחלוטין מ-`testAndSet` כדי לתפוס את המנעול.", "ג. מנעול TTAS אינו דורש לולאה חיצונית אינסופית, בניגוד ל-TAS.", "ד. מנעול TTAS מבצע את הפעולה `testAndSet` רק פעם אחת בכל ניסיון נעילה מוצלח."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מציין במפורש כי \"מנעול TTAS דומה ל-TAS, מלבד הלולאה הפנימית (שעלולה להיראות מיותרת)\". קטע הקוד של TTAS מדגים לולאה פנימית זו (`while (state) {}`). לולאה זו מאפשרת לחוטים הממתינים לבדוק באופן חוזר ונשנה את מצב המנעול (state) מבלי לבצע פעולת `testAndSet` יקרה ב-BUS המשותף בכל פעם. רק כאשר ה-state מצביע על כך שהמנעול פנוי, מתבצע ניסיון לתפוס אותו באמצעות `testAndSet`. בכך נמנע עומס מיותר על ה-BUS ומשתפרים הביצועים באופן משמעותי לעומת TAS."}, "_source_file": "0210__Concurrency__TAS_and_TTAS__MC__Easy.json", "_topic_hint": "TAS and TTAS", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:44:36", "_subject": "Concurrency", "_context_lectures": [12, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["TAS and TTAS"], "difficulty_estimation": "Medium", "content": {"text": "מדוע מנעול TTAS (Test-and-Test-and-Set) מציג ביצועים טובים באופן משמעותי ממנעול TAS (Test-and-Set) במערכת מרובת ליבות, למרות שהלולאה הפנימית שלו עשויה להיראות מיותרת?", "code_snippet": "void lock()\n{\n    while (true) {\n        while (state) {}\n        if (!testAndSet(state, true))\n            return;\n    }\n}", "options": ["א. מנעול TTAS מפחית באופן משמעותי את תעבורת ה-BUS על ידי קריאת מצב המנעול מזיכרון המטמון הפרטי של המעבד (cache) בלולאה הפנימית, ובכך נמנע משימוש בפעולת testAndSet שיוצרת תעבורת BUS רבה, אלא רק כאשר המנעול נראה פנוי.", "ב. מנעול TTAS מבטיח תור הוגן יותר בין החוטים הממתינים למנעול, מה שמפחית את זמן ההמתנה הכולל עבור כל חוט.", "ג. מנעול TTAS אינו משתמש בפעולת testAndSet כלל, אלא מסתמך על מנגנון נעילה אופטימיסטי אחר שאינו דורש סנכרון חומרה.", "ד. הלולאה הפנימית של TTAS מפחיתה את מספר הקריאות לפונקציית lock ובכך מקטינה את התקורה של קריאות לפונקציות."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. ההבדל המשמעותי בביצועים בין מנעול TAS למנעול TTAS נובע מהאופן שבו הם מתקשרים עם זיכרון המטמון (cache) המשותף במערכות מרובות ליבות. מנעול TAS מבצע פעולת `testAndSet` באופן חוזר ונשנה בלולאת ההמתנה שלו. פעולה זו היא פעולת כתיבה אטומית, וככזו, היא דורשת סנכרון דרך ה-BUS המשותף כדי לוודא עקביות בין זיכרונות המטמון של כל הליבות. כל ביצוע של `testAndSet` עלול לגרום לפסילת שורות מטמון אצל מעבדים אחרים ולייצר תעבורה רבה ב-BUS, מה שפוגע בביצועים ככל שיש יותר חוטים.\n\nלעומת זאת, מנעול TTAS, באמצעות הלולאה הפנימית `while (state) {}`, קורא את מצב המנעול מזיכרון המטמון הפרטי של המעבד. קריאה זו היא זולה יחסית ואינה יוצרת תעבורת BUS משמעותית אם הנתון כבר נמצא במטמון המקומי. רק כאשר הליבה רואה שמצב המנעול הוא 'פנוי' (כלומר `state` הוא false) בזיכרון המטמון שלה, היא מנסה לבצע את פעולת ה-`testAndSet` היקרה יותר. בכך, TTAS מפחית באופן דרמטי את כמות תעבורת ה-BUS ואת פסילות המטמון, מה שמוביל לשיפור ניכר בביצועים, במיוחד במערכות עם מספר רב של ליבות."}, "_source_file": "0211__Concurrency__TAS_and_TTAS__MC__Medium.json", "_topic_hint": "TAS and TTAS", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:44:54", "_subject": "Concurrency", "_context_lectures": [12, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["TAS and TTAS"], "difficulty_estimation": "Medium", "content": {"text": "מדוע מנעול Test-and-test-and-set (TTAS) מציג שיפור ביצועים משמעותי לעומת מנעול Test-and-set (TAS) במערכות מרובות ליבות, למרות שלכאורה שניהם מבצעים את אותה המטרה?", "code_snippet": "void lock()\n{\n    while (true) {\n        while (state) {} // The inner loop is key\n        if (!testAndSet(state, true))\n            return;\n    }\n}", "options": ["א. לולאת ה-`while (state) {}` הפנימית ב-TTAS מאפשרת לחוטים ממתינים לקרוא את מצב המנעול מזיכרון המטמון (cache) המקומי שלהם, ובכך מפחיתה באופן דרמטי את העומס על ה-BUS המשותף ואת תעבורת הודעות הקוהרנטיות בין המעבדים.", "ב. מנעול TTAS משתמש בפעולת `testAndSet` יעילה יותר מבחינה חישובית מנעול TAS, ולכן הוא מהיר יותר באופן מהותי.", "ג. TTAS מבטיח שכל חוט יקבל גישה למנעול תוך זמן קבוע מראש, מה שמונע רעב (starvation) ומשפר את הביצועים הכוללים.", "ד. TTAS אינו דורש גישה לזיכרון משותף כלל, בניגוד ל-TAS שתמיד ניגש לזיכרון הראשי."]}, "solution": {"correct_option": "א", "explanation": "ההבדל המשמעותי בביצועים בין TTAS ל-TAS נובע מהאופן שבו הם מתקשרים עם מערכת זיכרון המטמון (cache) במערכות מרובות ליבות. במנעול TAS, חוטים ממתינים מבצעים שוב ושוב את פעולת `testAndSet`. פעולה זו היא פעולת קריאה-שינוי-כתיבה (Read-Modify-Write) אטומית, הדורשת בלעדיות על שורת ה-cache המכילה את משתנה המצב של המנעול. כתוצאה מכך, בכל פעם שחוט מנסה לתפוס את המנעול, הוא גורם לפסילת (invalidation) שורת ה-cache בקרב מעבדים אחרים, מה שמוביל לתעבורה גבוהה על ה-BUS המשותף ולזמני המתנה ארוכים. לעומת זאת, במנעול TTAS, הלולאה הפנימית `while (state) {}` מאפשרת לחוטים ממתינים לבצע קריאות בלבד (reads) למשתנה המצב של המנעול. כאשר המנעול תפוס (`state` הוא true), חוטים רבים יכולים לקרוא את הערך הזה מזיכרון המטמון המקומי שלהם (לאחר הפעם הראשונה שבה הוא נטען), מבלי לגרום לפסילת קווי cache אצל מעבדים אחרים או לייצר תעבורה מיותרת על ה-BUS. רק כאשר `state` משתנה ל-false (המנעול משוחרר), שורות ה-cache של המעבדים האחרים נפסלות והם טוענים את הערך החדש. רק אז, כשנראה שהמנעול פנוי, החוטים מנסים לבצע את פעולת `testAndSet` האטומית, ובכך מפחיתים באופן דרמטי את העומס על ה-BUS ואת זמן ההמתנה הכולל."}, "_source_file": "0212__Concurrency__TAS_and_TTAS__MC__Medium.json", "_topic_hint": "TAS and TTAS", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:45:09", "_subject": "Concurrency", "_context_lectures": [12, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["TAS and TTAS"], "difficulty_estimation": "Medium", "content": {"text": "למרות הדמיון הפונקציונלי לכאורה בין מנעולי TAS ו-TTAS, קיימים פערי ביצועים משמעותיים ביניהם בסביבת ריבוי מעבדים (Multi-core). מהי הסיבה העיקרית לשיפור הביצועים המשמעותי של מנעול TTAS?", "code_snippet": "void lock()\n{\n    while (true) {\n        while (state) {}\n        if (!testAndSet(state, true))\n            return;\n    }\n}", "options": ["א. הלולאה הפנימית במנעול TTAS מאפשרת לחוטים ממתינים לבדוק את מצב המנעול מתוך זיכרון המטמון הפרטי שלהם (cache), ובכך מפחיתה באופן דרמטי את תעבורת ה-BUS ופגיעות בביצועים.", "ב. מנעול TAS מכיל שגיאה לוגית מובנית הגורמת לו לחסום חוטים ללא צורך, בעוד TTAS מתקן שגיאה זו.", "ג. מנעול TTAS משתמש באלגוריתם שונה לחלוטין שאינו מסתמך על פעולת testAndSet אטומית, ובכך הוא יעיל יותר.", "ד. מנעול TTAS מטמיע מנגנון תזמון (scheduler) פנימי המונע ממנועי הליבה לבצע פעולות מיותרות."]}, "solution": {"correct_option": "א", "explanation": "החומר המצטבר מציין במפורש כי הלולאה הפנימית `while (state) {}` במנעול TTAS, שלכאורה נראית מיותרת, היא הגורם המרכזי לשיפור הביצועים המשמעותי. בארכיטקטורת ריבוי ליבות, לכל מעבד יש זיכרון מטמון (cache) פרטי משלו. כאשר חוט ממתין למנעול שמוחזק על ידי חוט אחר, לולאה זו מאפשרת לו לבדוק שוב ושוב את מצב המשתנה `state` מתוך העותק המאוחסן בזיכרון המטמון המקומי שלו. זה מפחית באופן דרמטי את מספר הפעמים שהחוט צריך לגשת לזיכרון משותף (שמעורר תעבורת BUS ופגיעה בעקביות המטמון), בניגוד ל-TAS, שבו כל ניסיון לרכוש את המנעול באמצעות `testAndSet` כרוך בכתיבה לזיכרון משותף ולרוב גורם לפסילת מטמונים של מעבדים אחרים, גם כשהמנעול תפוס. רק כאשר המשתנה `state` משתחרר על ידי המחזיק הנוכחי של המנעול (מה שגורם לפסילת העותקים המאוחסנים במטמונים של מעבדים אחרים), החוטים הממתינים ממשיכים לנסות לבצע `testAndSet`."}, "_source_file": "0213__Concurrency__TAS_and_TTAS__MC__Medium.json", "_topic_hint": "TAS and TTAS", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:45:23", "_subject": "Concurrency", "_context_lectures": [12, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["TAS and TTAS"], "difficulty_estimation": "Hard", "content": {"text": "נתונים שני מנגנוני נעילה, Test-and-Set (TAS) ו-Test-and-Test-and-Set (TTAS), כפי שהוצגו בחומר הקורס. למרות ששניהם מיועדים להשגת הדדיות בלעדית, מנעול ה-TTAS מציג ביצועים עדיפים משמעותית על פני מנעול ה-TAS במערכות מרובות ליבות. מהו ההסבר העיקרי לפער ביצועים זה, בהתבסס על ארכיטקטורת המעבדים המודרנית?", "code_snippet": "void lock()\n{\n    while (true) {\n        while (state) {}\n        if (!testAndSet(state, true))\n            return;\n    }\n}", "options": ["א. TTAS מפחית באופן דרמטי את תעבורת ה-BUS על ידי כך שחוטים ממתינים בלולאה הפנימית (while(state) {}) וקוראים את משתנה המנעול מהמטמון הפרטי שלהם, במקום לבצע פעולות testAndSet אטומיות ועתירות תקשורת BUS באופן חוזר ונשנה כשהמנעול תפוס.", "ב. TTAS משתמש באלגוריתם חכם יותר לבחירת החוט הבא שייכנס לאזור הקריטי, בדומה למנגנון תור, מה שמבטיח הוגנות ומונע רעב.", "ג. מנגנון ה-TTAS מבצע אופטימיזציה של פעולות ה-I/O על ידי שימוש בזיכרון וירטואלי בצורה יעילה יותר, מה שמפחית את הצורך בגישות לדיסק הקשיח.", "ד. מנעול ה-TTAS מאפשר למספר חוטים להיכנס לאזור הקריטי בו-זמנית, כל עוד הם מבצעים פעולות קריאה בלבד, ובכך מגביר את המקביליות."]}, "solution": {"correct_option": "א", "explanation": "ההסבר המרכזי לפער הביצועים בין TAS ל-TTAS טמון באופן שבו הם מתקשרים עם ארכיטקטורת זיכרון המטמון במערכות מרובות ליבות. במנעול TAS, חוט מנסה לתפוס את המנעול שוב ושוב באמצעות הפעולה האטומית `testAndSet`. פעולה זו, הכוללת כתיבה, גורמת בדרך כלל לפרוטוקולי עקיבות מטמון (cache coherence protocols) להפיץ הודעות אי-תקפות (invalidation messages) ב-BUS לכל המעבדים שייתכן שיש להם עותק של המשתנה במטמון שלהם. תעבורת BUS גבוהה זו יוצרת צוואר בקבוק משמעותי ומורידה את הביצועים.\n\nלעומת זאת, מנעול ה-TTAS משלב לולאה פנימית (`while (state) {}`) לפני ניסיון ה-`testAndSet`. בלולאה זו, חוטים ממתינים על ידי קריאת ערך המנעול. אם המנעול תפוס, הם קוראים את המשתנה `state` שוב ושוב. מכיוון שזו פעולת קריאה בלבד, והמשתנה `state` נמצא במטמון הפרטי של המעבד (כל עוד המנעול לא שוחרר על ידי מעבד אחר), חוטים יכולים \"לסובב\" (spin) על עותק המטמון המקומי שלהם מבלי ליצור תעבורת BUS נוספת. רק כאשר המנעול משוחרר על ידי מעבד אחר, העותק במטמון המקומי של החוט הממתין הופך ללא תקף, והוא יצטרך לבצע קריאה מהזיכרון הראשי או ממטמון של מעבד אחר. רק אז הוא ינסה לבצע את פעולת ה-`testAndSet` האטומית. הפחתה דרמטית זו של תעבורת ה-BUS היא הסיבה העיקרית לביצועים העדיפים של TTAS, כפי שנדון בהרחבה בהקשר של ארכיטקטורת מעבדים מרובי ליבות וזיכרונות מטמון פרטיים."}, "_source_file": "0214__Concurrency__TAS_and_TTAS__MC__Hard.json", "_topic_hint": "TAS and TTAS", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:45:38", "_subject": "Concurrency", "_context_lectures": [12, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["TAS and TTAS"], "difficulty_estimation": "Hard", "content": {"text": "למרות שהמנעולים Test-and-Set (TAS) ו-Test-and-Test-and-Set (TTAS) נראים לכאורה מבחינה לוגית כמבצעים את אותה הפעולה, חומר הקורס מציין פער ביצועים משמעותי לטובת TTAS, בעיקר במערכות מרובות ליבות. בהתבסס על ההסבר שניתן בחומר לגבי ארכיטקטורת מעבד מרובה ליבות (cache פרטי ו-BUS משותף), מהי הסיבה העיקרית לפער ביצועים זה?\n\nלהלן מימוש פשטני של מנעול TTAS:\n", "code_snippet": "void lock()\n{\n    while (true) {\n        while (state) {} // הלולאה הפנימית\n        if (!testAndSet(state, true))\n            return;\n    }\n}", "options": ["א. לולאת ה-`while (state) {}` הפנימית ב-TTAS מאפשרת לחוטים \"להמתין בשקט\" על עותק ה-cache הפרטי שלהם של משתנה ה-`state`, ובכך מפחיתה באופן דרמטי את תעבורת ה-BUS ואת הודעות ה-invalidation הקשורות לניסיונות חוזרים ונשנים לבצע `testAndSet` על המנעול כשהוא תפוס.", "ב. מנגנון ה-`testAndSet` ב-TTAS מהיר יותר באופן אינהרנטי מאשר ב-TAS, מכיוון שהוא ממומש בחומרה בצורה אופטימלית יותר עבור מערכות מרובות מעבדים.", "ג. TTAS משתמש במשתנה `state` גדול יותר (בערך 128 בתים, כגודל שורת cache), מה שמאפשר גישה מהירה יותר לנתונים על ידי המעבדים ומפחית false sharing.", "ד. TTAS משתמש באלגוריתם תזמון חוטים מתקדם יותר המונע \"רעב\" (starvation) ומבטיח חלוקה שווה של זמן מעבד בין החוטים, מה שמוביל לביצועים טובים יותר."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר הקורס מסביר כי הפער המשמעותי בביצועים בין TAS ל-TTAS נובע מהאופן שבו הם מתקשרים עם ארכיטקטורת המעבד מרובה הליבות, ובפרט עם ה-cache הפרטי של כל מעבד וה-BUS המשותף. פעולת ה-`testAndSet` היא פעולה אטומית של קריאה-שינוי-כתיבה (Read-Modify-Write) הדורשת בלעדיות על שורת ה-cache הרלוונטית. כאשר חוט מבצע `testAndSet`, הוא שולח הודעות invalidation (פסילה) לכל שאר ה-caches המכילים עותק של המשתנה, מה שגורם לתעבורה רבה ב-BUS ולצורך בטעינה מחדש של שורת ה-cache.\n\nבמנעול TAS, כל איטרציה בלולאת ההמתנה מנסה לבצע `testAndSet`. כאשר המנעול תפוס, חוטים רבים מנסים שוב ושוב את הפעולה האטומית, מה שמוביל ל\"סערת\" הודעות invalidation על ה-BUS ולפגיעה קשה בביצועים.\n\nבמנעול TTAS, לעומת זאת, קיימת לולאה פנימית `while (state) {}`. לולאה זו מבצעת קריאה בלבד של משתנה ה-`state`. כל עוד ה-`state` הוא `true` (המנעול תפוס), החוט קורא את הערך מעותק ה-cache הפרטי שלו. רק כאשר חוט אחר משחרר את המנעול, הוא משנה את ערך ה-`state` ל-`false`, ופעולה זו גורמת להודעת invalidation שנשלחת לכל ה-caches האחרים. כאשר ה-cache המקומי של חוט ממתין מקבל את הודעת ה-invalidation, הוא מסמן את שורת ה-cache כלא תקפה. בגישה הבאה למשתנה `state` (באיטרציה הבאה של הלולאה הפנימית), הוא יטען את הערך המעודכן (כלומר `false`) מהזיכרון הראשי. רק אז, כשהלולאה הפנימית מסתיימת, החוט ינסה לבצע את פעולת ה-`testAndSet` היקרה. מנגנון זה מפחית באופן דרמטי את מספר הפעולות האטומית `testAndSet` המבוצעות על ה-BUS, ובכך מצמצם את תעבורת ה-BUS ואת הודעות ה-invalidation, מה שמוביל לשיפור ביצועים משמעותי."}, "_source_file": "0215__Concurrency__TAS_and_TTAS__MC__Hard.json", "_topic_hint": "TAS and TTAS", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:45:56", "_subject": "Concurrency", "_context_lectures": [12, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["TAS and TTAS"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על ארכיטקטורת מעבדים מרובי ליבות כפי שתוארה בחומר הלימוד, מדוע מנגנון הנעילה Test-and-Test-and-Set (TTAS) מציג ביצועים עדיפים באופן משמעותי על פני Test-and-Set (TAS), למרות ששניהם נועדו לבצע פעולה דומה?", "code_snippet": "void lock()\n{\n    while (true) {\n        while (state) {}\n        if (!testAndSet(state, true))\n            return;\n    }\n}", "options": ["א. הלולאה הפנימית של TTAS (while (state) {}) מאפשרת לחוטים הממתינים לבצע סבסוב (spin) על עותק מקומי של מצב המנעול מהמטמון הפרטי שלהם, ובכך מפחיתה באופן דרמטי את תעבורת האפיק (bus traffic) הנגרמת מניסיונות חוזרים ונשנים לבצע פעולת TestAndSet אטומית כאשר המנעול כבר תפוס.", "ב. TTAS משתמש באלגוריתם מתקדם יותר לניהול תורים, המבטיח שהחוטים יקבלו את המנעול בסדר הוגן יותר ובכך מונע רעב (starvation) ומקצר את זמן ההמתנה הכולל.", "ג. מנגנון ה-TestAndSet ב-TAS גורם להחלפות קשר (context switches) תכופות בין חוטים, מה שיוצר תקורה משמעותית, בעוד TTAS נמנע מכך על ידי שימוש בפעולות לא חוסמות.", "ד. הלולאה הפנימית ב-TTAS מבצעת קריאות חוזרות ונשנות לזיכרון הראשי (RAM) כדי לבדוק את מצב המנעול, מה שמבטיח עדכניות גבוהה יותר של הנתונים לעומת TAS שמסתמך על מטמון בלבד."]}, "solution": {"correct_option": "א", "explanation": "ההסבר לפער הביצועים המשמעותי בין מנעולי TAS ו-TTAS טמון באופן שבו הם מתייחסים לארכיטקטורת המעבדים מרובי הליבות ולזיכרון המטמון (cache) הפרטי של כל ליבה. במנגנון TAS, כל ניסיון לתפוס את המנעול כרוך בביצוע פעולת `testAndSet` אטומית. פעולה אטומית זו דורשת לרוב פרוטוקולי קוהרנטיות מטמון (cache coherence) המבטיחים שכל הליבות יראו את העדכון באופן עקבי. כאשר חוטים רבים מנסים לתפוס מנעול תפוס, כל אחד מהם מבצע `testAndSet`, מה שמוביל לשליחת הודעות ביטול מטמון (cache invalidation messages) רבות על האפיק המשותף (bus), יצירת עומס כבד והאטה משמעותית.\n\nלעומת זאת, מנגנון TTAS כולל לולאה פנימית (`while (state) {}`) לפני ניסיון ה-`testAndSet`. כאשר המנעול תפוס, חוטים ממתינים יכולים לבצע סבסוב בלולאה פנימית זו על ידי קריאת ערך המנעול מתוך העותק השמור במטמון הפרטי שלהם. רק כאשר ערך המנעול נראה פנוי במטמון המקומי, החוט מנסה לבצע את פעולת ה-`testAndSet` האטומית, אשר אכן מייצרת תעבורת אפיק. אך מכיוון שרוב זמן ההמתנה מתבצע על עותק מקומי במטמון, מספר הפעולות האטומיות והודעות ביטול המטמון על האפיק מצטמצם דרמטית, ובכך משפר את הביצועים באופן ניכר, כפי שתואר בחומר הלימוד כ'פתרון לתעלומה' על ידי התחשבות בארכיטקטורת ה-cache."}, "_source_file": "0216__Concurrency__TAS_and_TTAS__MC__Hard.json", "_topic_hint": "TAS and TTAS", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:46:17", "_subject": "Concurrency", "_context_lectures": [12, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Cache Coherence"], "difficulty_estimation": "Easy", "content": {"text": "מהי הבעיה העיקרית המתוארת בהקשר של מטמונים מקומיים במערכת מרובת מעבדים, כאשר מעבד אחד משנה ערך במטמון שלו?", "code_snippet": null, "options": ["א. חוסר עקביות (inconsistency) בנתונים בין המטמונים השונים לבין הזיכרון הראשי.", "ב. ירידה במהירות הגישה לזיכרון הראשי עבור כל המעבדים.", "ג. המעבד ששינה את הערך אינו יכול לקרוא אותו שוב מהמטמון שלו.", "ד. נוצרת בעיית עומס יתר על המטמון המקומי של המעבד ששינה את הנתון."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מתאר במפורש את הבעיה: כאשר מעבד משנה ערך במטמון המקומי שלו, הזיכרון הראשי אינו מתעדכן מיד. אם מעבד אחר ינסה לקרוא את אותו ערך, הוא יקבל ערך לא תקין (מיושן). מצב זה של עותקים שונים של אותו נתון שמחזיקים ערכים שונים (במטמונים ובזיכרון הראשי) הוא בעיית חוסר העקביות (Cache Coherence Problem). האפשרות ש'יהיה מאוד איטי' היא פתרון אפשרי לבעיה זו, לא הבעיה עצמה."}, "_source_file": "0217__Concurrency__Cache_Coherence__MC__Easy.json", "_topic_hint": "Cache Coherence", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:46:27", "_subject": "Concurrency", "_context_lectures": [16, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Cache Coherence"], "difficulty_estimation": "Easy", "content": {"text": "מהי הבעיה העיקרית הנוצרת כאשר למספר מעבדים יש מטמונים (caches) משלהם והם ניגשים לנתונים משותפים?", "code_snippet": null, "options": ["א. מעבדים שונים עשויים לקרוא ערכים לא מעודכנים של נתונים משותפים.", "ב. כל המעבדים חייבים לגשת ל-RAM בכל פעם שהם רוצים לקרוא נתונים.", "ג. קטעים קריטיים אינם ניתנים ליישום במצב זה.", "ד. יש צורך בסנכרון בין תהליכים שאינם חולקים זיכרון."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה (Lecture 15, chunk 23), הבעיה המרכזית הנוצרת היא שאם מעבד אחד קורא נתון לתוך המטמון שלו ומשנה את ערכו, והזיכרון הראשי עדיין לא מעודכן, מעבד אחר שינסה לקרוא את אותו נתון יקבל 'ערך לא תקין'. זוהי בעיית עקביות המטמונים (cache coherence), שבה יש להבטיח שכל המעבדים רואים את הגרסה העדכנית ביותר של נתונים משותפים."}, "_source_file": "0218__Concurrency__Cache_Coherence__MC__Easy.json", "_topic_hint": "Cache Coherence", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:46:35", "_subject": "Concurrency", "_context_lectures": [16, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Cache Coherence"], "difficulty_estimation": "Easy", "content": {"text": "מהי הבעיה העיקרית המתוארת בהקשר של עקביות מטמון (Cache Coherence) במערכת מרובת מעבדים, כאשר לכל מעבד יש מטמון משלו?", "code_snippet": null, "options": ["א. כאשר מעבד משנה ערך במטמון המקומי שלו, מעבדים אחרים עלולים לקרוא ערך לא מעודכן (שגוי) של אותו משתנה.", "ב. כל המעבדים ניגשים לזיכרון הראשי בו זמנית, מה שיוצר עומס רב ומאט את המערכת.", "ג. עקרון ה-spatial locality נפגע, מכיוון שמעבדים שונים ניגשים לכתובות זיכרון מרוחקות.", "ד. מתרחשים קיפאונות (deadlocks) תכופים עקב הצורך בסנכרון מתמיד בין המטמונים."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין מתאר בבירור את בעיית עקביות המטמון: \"אם יש לנו כמה מעבדים שכל אחד יש לו cache משל עצמו, ברגע שמעבד מספר 1 למשל קורא את עניין a מה-ram, הוא מסביר את זה למטמון שלו... אם הוא משנה את ערכו, זה משתנה במטמון המקומי והזיכרון הראשי עדיין לא מעודכן, אבל אם לא נעדכן חזרה את הזיכרון, אם מעבד אחר ירצה לקרוא את ערכו של a הוא יקבל ערך לא תקין.\" תשובה א' משקפת בדיוק מצב זה – מעבד אחד משנה נתון במטמון שלו, ומעבד אחר קורא את הגרסה הישנה (הלא מעודכנת) מהזיכרון הראשי או ממטמון אחר. שאר התשובות מתארות בעיות אחרות או פגיעה בעקרונות אחרים שאינם הבעיה הישירה של עקביות מטמון כפי שתוארה בחומר."}, "_source_file": "0219__Concurrency__Cache_Coherence__MC__Easy.json", "_topic_hint": "Cache Coherence", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:46:46", "_subject": "Concurrency", "_context_lectures": [16, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Cache Coherence"], "difficulty_estimation": "Medium", "content": {"text": "כאשר מספר מעבדים, שלכל אחד מהם מטמון (cache) משלו, ניגשים לזיכרון משותף, איזו בעיית סנכרון מרכזית עלולה להיווצר, כפי שתואר בחומר ההרצאה?", "code_snippet": null, "options": ["א. מעבד אחד משנה נתון במטמון המקומי שלו, וכל עוד הזיכרון הראשי אינו מתעדכן, מעבדים אחרים עלולים לקרוא ערך שגוי (מיושן) של אותו נתון.", "ב. חוסר יכולת למנוע מניעה הדדית (mutual exclusion) בין מעבדים הניגשים לאותו קטע קריטי.", "ג. פגיעה ב-cache affinity עקב העברת ג'ובים בין מעבדים, מה שמוביל לביצועים ירודים.", "ד. עומס יתר על ה-RAM כתוצאה מכך שכל מעבד ניגש אליו ישירות במקום להשתמש במטמון המקומי."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מציין במפורש כי 'אם הוא משנה את ערכו, זה משתנה במטמון המקומי והזיכרון הראשי עדיין לא מעודכן, אבל אם לא נעדכן חזרה את הזיכרון, אם מעבד אחר ירצה לקרוא את ערכו של a הוא יקבל ערך לא תקין.' תיאור זה מתאר את בעיית עקביות המטמונים (cache coherence), שבה מעבדים שונים עלולים להחזיק בגרסאות לא עקביות של אותו נתון משותף במטמונים המקומיים שלהם. אפשרויות ב', ג' ו-ד' אינן מתארות את בעיית עקביות המטמונים באופן ישיר כפי שהוצגה בחומר ההרצאה."}, "_source_file": "0220__Concurrency__Cache_Coherence__MC__Medium.json", "_topic_hint": "Cache Coherence", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:47:00", "_subject": "Concurrency", "_context_lectures": [16, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Cache Coherence"], "difficulty_estimation": "Medium", "content": {"text": "מהי הבעיה המרכזית הנובעת מקיומם של מטמונים (caches) נפרדים למעבדים מרובים במערכת, וכיצד היא באה לידי ביטוי?", "code_snippet": null, "options": ["א. הצורך בעדכון תכוף של הזיכרון הראשי (RAM) על כל שינוי, מה שגורם להאטה משמעותית בביצועים, או לחוסר עקביות בנתונים בין המעבדים.", "ב. חוסר היכולת לשמר \"זיקת מטמון\" (cache affinity) עבור תהליכים, מה שמוביל להחלפת ג'ובים תכופה בין מעבדים.", "ג. יצירת מצב קיפאון (deadlock) בין מעבדים המנסים לגשת לאותו קו מטמון (cache line) בו זמנית.", "ד. פגיעה בעיקרון ה\"מיקום הזמני\" (temporal locality) עקב חלוקת נתונים בין מטמונים שונים."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מתאר את בעיית עקביות המטמון (cache coherence) באופן מפורש. כאשר מעבד משנה ערך במטמון המקומי שלו, הזיכרון הראשי אינו מתעדכן באופן מיידי. אם מעבד אחר ינסה לקרוא את אותו הערך, הוא עלול לקבל ערך לא מעודכן, מה שיוביל לחוסר עקביות בנתונים. הפתרון לבעיה זו, עדכון תכוף של הזיכרון הראשי, גורם מצדו להאטה משמעותית בביצועים. זהו הדילמה המרכזית המתוארת: \"מצד אחד, אם לא נעדכן את הזיכרון, לא נהיה מתואמים עם שאר המעבדים. מצד שני, אם כן נעדכן את הזיכרון על כל שינוי, זה יהיה מאוד איטי.\" (Lecture 15, chunk 23).\nאפשרות ב' מתייחסת ל-cache affinity, שהוא מושג הקשור לתזמון תהליכים ולא לבעיית עקביות הנתונים במטמון עצמו. אפשרות ג' מתייחסת למצב קיפאון (deadlock), שהיא בעיית סנכרון כללית אך לא הבעיה הישירה של עקביות המטמון. אפשרות ד' מתייחסת לעיקרון ה-temporal locality, שהוא עיקרון המנוצל על ידי מטמונים ולא בעיה הנובעת מהם."}, "_source_file": "0221__Concurrency__Cache_Coherence__MC__Medium.json", "_topic_hint": "Cache Coherence", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:47:10", "_subject": "Concurrency", "_context_lectures": [16, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Cache Coherence"], "difficulty_estimation": "Medium", "content": {"text": "על פי חומר ההרצאה, מהי הבעיה המרכזית המתעוררת בהקשר של עקביות מטמון (Cache Coherence) במערכת מרובת מעבדים?", "code_snippet": null, "options": ["א. כאשר מעבד אחד משנה נתון במטמון המקומי שלו, מעבדים אחרים עלולים לקרוא ערך לא מעודכן של אותו נתון מהזיכרון הראשי או מהמטמונים שלהם.", "ב. קושי בשמירה על \"cache affinity\", כלומר תהליך אינו רץ באופן עקבי על אותו מעבד שהריץ אותו בעבר.", "ג. מניעה הדדית בין תהליכים אינה מובטחת, מה שמאפשר למספר תהליכים להיכנס לקטע קריטי בו זמנית.", "ד. כל עדכון לזיכרון הראשי מחייב עדכון מיידי של כל המטמונים האחרים, מה שמוביל בהכרח להאטה משמעותית בביצועים."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה (Lecture 15, chunk 23) מתאר במפורש כי כאשר מעבד אחד קורא נתון מהזיכרון הראשי למטמון המקומי שלו ומשנה אותו, הזיכרון הראשי (ומטמונים של מעבדים אחרים) עלולים להחזיק בערך לא מעודכן. אם מעבד אחר ינסה לאחר מכן לקרוא את אותו נתון, הוא יקבל ערך שגוי או מיושן ('ערך לא תקין'). זוהי הבעיה המרכזית של עקביות מטמון – הבטחת שכל המעבדים רואים את הגרסה העדכנית ביותר של הנתונים. אפשרות ב' מתארת בעיה של 'cache affinity' הקשורה לתזמון ג'ובים, אפשרות ג' מתארת בעיה של מניעה הדדית הקשורה למנגנוני סנכרון, ואפשרות ד' מתארת אתגר או תוצאה של ניסיון לפתור את בעיית העקביות, אך לא את הבעיה הבסיסית של חוסר עקביות הנתונים עצמה."}, "_source_file": "0222__Concurrency__Cache_Coherence__MC__Medium.json", "_topic_hint": "Cache Coherence", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:47:24", "_subject": "Concurrency", "_context_lectures": [16, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Cache Coherence"], "difficulty_estimation": "Hard", "content": {"text": "בהקשר של מערכות מרובות מעבדים עם מטמונים פרטיים לכל מעבד, בעיית קוהרנטיות המטמון (Cache Coherence) מציגה דילמה מהותית. איזו מהטענות הבאות מתארת בצורה הטובה ביותר את הדילמה המרכזית כפי שהוצגה בחומר הלימוד?", "code_snippet": null, "options": ["א. הצורך לשמור על temporal locality ו-spatial locality עבור כל מעבד מתנגש עם היכולת להקצות ג'ובים באופן אקראי בין מעבדים שונים, מה שפוגע ב-cache affinity.", "ב. מצד אחד, אי-עדכון מיידי של הזיכרון הראשי על ידי מעבד ששינה נתון מקומי במטמון שלו עלול להוביל לחוסר עקביות ולקריאת ערכים שגויים על ידי מעבדים אחרים; מצד שני, עדכון מיידי של הזיכרון הראשי על כל שינוי הוא איטי מאוד ופוגע בביצועים.", "ג. הבעיה העיקרית היא שמעבדים שונים עלולים להחזיק עותקים שונים של אותו נתון במטמונים שלהם, מה שמחייב מנגנוני נעילה מורכבים בזיכרון הראשי כדי למנוע deadlock.", "ד. מנגנוני קוהרנטיות מטמון דורשים תמיד שימוש בפעולות אטומיות כמו fetch_and_add על משתנה משותף, דבר המגביל את מדרגיות המערכת ומעלה את העומס על אפיק הזיכרון."]}, "solution": {"correct_option": "ב", "explanation": "האפשרות הנכונה מתארת במדויק את הדילמה המוצגת בחומר הלימוד (הרצאה 15, קטע 23): 'מצד אחד, אם לא נעדכן את הזיכרון, לא נהיה מתואמים עם שאר המעבדים. מצד שני, אם כן נעדכן את הזיכרון על כל שינוי, זה יהיה מאוד איטי.' דילמה זו מבליטה את המתח בין שמירה על עקביות נתונים מיידית בין כל המטמונים לבין שמירה על ביצועים גבוהים על ידי הימנעות מכתיבה תכופה לזיכרון הראשי.\n\nאפשרות א' מתייחסת ל-cache affinity (זיקה למטמון), שהיא מושג הקשור ליעילות ניצול המטמון על ידי תזמון תהליכים על אותם מעבדים, ולא לבעיית עקביות הנתונים בין מטמונים שונים (cache coherence). חומר הלימוד מתאר את ה-cache affinity בהקשר של תזמון ג'ובים (הרצאה 15, קטעים 27-28).\n\nאפשרות ג' מתארת חלק מהבעיה (עותקים שונים), אך הדילמה המרכזית שהוצגה אינה מתמקדת במנגנוני נעילה מורכבים בזיכרון הראשי כבעיה בפני עצמה, אלא במתח בין עדכון לביצועים.\n\nאפשרות ד' מתייחסת לשימוש בפעולות אטומיות, אשר הוזכרו בהקשר של מימוש מחסומים (barrier) (הרצאה 16, קטע 35) ולא כחלק מהדילמה המהותית של קוהרנטיות המטמון כפי שהוצגה."}, "_source_file": "0224__Concurrency__Cache_Coherence__MC__Hard.json", "_topic_hint": "Cache Coherence", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:47:51", "_subject": "Concurrency", "_context_lectures": [16, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Cache Coherence"], "difficulty_estimation": "Hard", "content": {"text": "במערכת מרובת מעבדים שבה לכל מעבד מטמון משלו, מתעוררת בעיה מהותית של קוהרנטיות מטמון. איזו מהטענות הבאות מתארת בצורה הטובה ביותר את הדילמה המרכזית שנוצרת כתוצאה מכך, ואת השפעותיה על תקינות הנתונים וביצועי המערכת?", "code_snippet": null, "options": ["א. הבעיה היא ששינוי נתונים במטמון מקומי של מעבד אחד מבלי לעדכן מיד את הזיכרון הראשי עלול להוביל לכך שמעבדים אחרים יקראו נתונים לא עדכניים; ניסיון לפתור זאת על ידי עדכון תמידי של הזיכרון הראשי גורם להאטה משמעותית בביצועים.", "ב. הבעיה העיקרית היא חוסר ב-cache affinity, הגורם לכך שתהליכים עוברים בין מעבדים שונים בתדירות גבוהה, ומבזבזים זמן רב על טעינת נתונים חדשים למטמון.", "ג. קוהרנטיות מטמון מתייחסת בעיקר למניעת מצבי קיפאון (deadlock) שעלולים להיווצר כאשר מספר מעבדים מנסים לגשת לאותו בלוק זיכרון במקביל, ודורשת מנגנוני נעילה מורכבים.", "ד. הבעיה היחידה בחוסר קוהרנטיות היא שמעבד אחד לא יוכל לדעת מתי מעבד אחר שינה ערך בזיכרון, ופתרונה דורש רק פרוטוקול פשוט של הודעות בין המטמונים המקומיים."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה (Lecture 15, chunk 23), הבעיה המרכזית בקוהרנטיות מטמון היא שאם מעבד אחד קורא נתון מה-RAM למטמון שלו ומשנה אותו, השינוי מתבצע במטמון המקומי שלו בלבד. אם הזיכרון הראשי אינו מעודכן באופן מיידי, מעבדים אחרים שיקראו את אותו נתון מהזיכרון הראשי יקבלו ערך לא תקין ולא עדכני. זוהי בעיית חוסר תיאום. הדילמה היא ש'אם לא נעדכן את הזיכרון, לא נהיה מתואמים עם שאר המעבדים', אך 'אם כן נעדכן את הזיכרון על כל שינוי, זה יהיה מאוד איטי'. תשובה א' מתארת במדויק דילמה זו של חוסר עקביות נתונים מול פגיעה בביצועים.\n\nתשובה ב' מתארת בעיה של 'cache affinity' (Lecture 15, chunks 27-28), שהיא קשורה לביצועים וליעילות ניצול המטמון על ידי תזמון תהליכים על אותו מעבד, אך אינה עוסקת ישירות בבעיית עקביות הנתונים בין מטמונים שונים, שהיא לב ליבה של קוהרנטיות מטמון.\n\nתשובה ג' מתייחסת ל'deadlock' ול'מנגנוני נעילה' (Lecture 16, chunk 8), שהם מושגים הקשורים לסנכרון ומניעת מצבי קיפאון כלליים בגישה למשאבים משותפים, אך אינם התיאור המדויק לבעיית קוהרנטיות המטמון כפי שהוצגה בחומר ההרצאה.\n\nתשובה ד' אינה נכונה מכיוון שהיא מפשטת יתר על המידה את הבעיה ומציעה פתרון פשוט, בעוד שהחומר מציין במפורש שעדכון הזיכרון הראשי על כל שינוי הוא 'מאוד איטי', מה שמעיד על כך שהפתרון אינו פשוט ואינו חסר עלות ביצועית."}, "_source_file": "0225__Concurrency__Cache_Coherence__MC__Hard.json", "_topic_hint": "Cache Coherence", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:48:05", "_subject": "Concurrency", "_context_lectures": [16, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Atomic Operations"], "difficulty_estimation": "Easy", "content": {"text": "מהי התכונה המרכזית של פעולה אטומית במערכות הפעלה?", "code_snippet": "int TestAndSet(int* old_ptr, int new) {\n  int old = *old_ptr;\n  *old_ptr = new;\n  return old;\n}", "options": ["א. היא תמיד מבוצעת מהר יותר מפעולה לא אטומית.", "ב. היא מבוצעת במלואה ללא אפשרות להפרעה מצד רכיבים אחרים של המערכת.", "ג. היא דורשת שימוש במנעולים (mutexes) כדי להבטיח את שלמותה.", "ד. היא יכולה להתבצע באופן חלקי אם המערכת נכנסת למצב עומס גבוה."]}, "solution": {"correct_option": "ב", "explanation": "החומר המצוין בשיעור 11 (chunk 38) מתאר פעולות אטומיות כ'פעולות חומרה שיש במעבד, שבבת אחת עושות כמה פעולות' ומציין כי פעולה כמו `__sync_fetch_and_add` 'מתבצע בפקודה אחת (במקום 3)'. בנוסף, בשיעור 11 (chunk 40), הפקודה `TestAndSet` מתוארת ככזו ש'עושה את קטע הקוד הזה באופן אטומי בבת אחת'. הגדרות אלו מדגישות כי פעולה אטומית היא יחידה בלתי ניתנת לחלוקה, המבוצעת במלואה ללא הפרעה חיצונית. לכן, אפשרות ב' ('היא מבוצעת במלואה ללא אפשרות להפרעה מצד רכיבים אחרים של המערכת') היא הנכונה ביותר. אפשרות א' אינה נכונה, שכן החומר (שיעור 11, chunk 40) מציין כי פעולות אטומיות אינן תמיד יעילות יותר. אפשרות ג' מתארת אמצעי להשגת אטומיות עבור קטעי קוד גדולים יותר (כפי שמוצג בשיעור 14, chunk 42), אך לא את התכונה המהותית של פעולה אטומית עצמה. אפשרות ד' סותרת ישירות את עקרון האטומיות."}, "_source_file": "0226__Concurrency__Atomic_Operations__MC__Easy.json", "_topic_hint": "Atomic Operations", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:48:20", "_subject": "Concurrency", "_context_lectures": [11, 13, 14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Atomic Operations"], "difficulty_estimation": "Easy", "content": {"text": "מהי ההגדרה הנכונה ביותר לפעולה אטומית (Atomic Operation) בהקשר של מערכות הפעלה?", "code_snippet": null, "options": ["א. פעולה שמתבצעת אך ורק על ידי המעבד הראשי (CPU) ולא על ידי מעבדי עזר.", "ב. פעולה או רצף פעולות שמבוצעות כיחידה אחת בלתי ניתנת לחלוקה, ללא אפשרות לחוטים אחרים להפריע לביצוען באמצע.", "ג. פעולה שתמיד דורשת שימוש במנגנוני נעילה מורכבים כמו סמפורים או מנעולים.", "ד. פעולה שמובטחת להיות מהירה יותר מכל פעולה מקבילה שאינה אטומית."]}, "solution": {"correct_option": "ב", "explanation": "ההרצאה מתארת מצב של 'atomicity violation' (הפרת אטומיות) כאשר רצף פעולות שאמור להתבצע 'בבת אחת' נקטע. היא גם מציינת ש'פעולות אטומיות' הן פעולות חומרה 'שבבת אחת עושות כמה פעולות'. לכן, ההגדרה הנכונה ביותר היא שפעולה אטומית מבוצעת כיחידה בלתי ניתנת לחלוקה, מה שמונע הפרעות מחוטים אחרים ומבטיח עקביות נתונים. אפשרויות א' ו-ג' אינן נכונות לגבי הגדרת אטומיות. אפשרות ד' שגויה, כפי שמצוין בהרצאה, לפעולות אטומיות יכולות להיות שיקולי יעילות שגורמים להן להיות פחות יעילות במקרים מסוימים מאשר פעולות לא אטומיות."}, "_source_file": "0227__Concurrency__Atomic_Operations__MC__Easy.json", "_topic_hint": "Atomic Operations", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:48:33", "_subject": "Concurrency", "_context_lectures": [11, 13, 14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Atomic Operations"], "difficulty_estimation": "Easy", "content": {"text": "מהו המאפיין העיקרי של פעולה אטומית ברמת החומרה, כפי שתואר בחומר הקורס?", "code_snippet": "int TestAndSet(int* old_ptr, int new) {\n  int old = *old_ptr;\n  *old_ptr = new;\n  return old;\n}", "options": ["א. זוהי רצף של מספר פקודות מכונה המבוצעות ללא הפרעה על ידי שימוש במנעול תוכנה.", "ב. זוהי פקודת חומרה יחידה המבצעת מספר פעולות באופן בלתי ניתן לחלוקה (אטומי).", "ג. היא תמיד דורשת שימוש במנגנון נעילה (כמו מנעול או סמפור) להבטחת אטומיות.", "ד. היא מיועדת רק לפעולות מתמטיות פשוטות כמו הגדלה או הקטנה של מונה."]}, "solution": {"correct_option": "ב", "explanation": "חומר הקורס (הרצאה 11, קטעים 38 ו-40) מגדיר פעולות אטומיות כ\"פעולות חומרה שיש במעבד, שבבת אחת עושות כמה פעולות\" וכי הן \"מתבצעות בפקודה אחת (במקום 3)\". דוגמת הפקודה TestAndSet מדגימה כיצד פקודת מכונה אחת מבצעת קריאה וכתיבה באופן אטומי, כלומר, מספר צעדים לוגיים מתבצעים כמקשה אחת. אפשרות א' מתארת קטע קריטי המוגן על ידי מנעול, שהוא מנגנון המשתמש בפעולות אטומיות, אך אינו ההגדרה של פעולה אטומית עצמה. אפשרות ג' אינה נכונה מכיוון שפעולה אטומית היא כזו מטבעה ברמת החומרה, ואינה דורשת מנגנון נעילה חיצוני כדי להיות אטומית. אפשרות ד' מגבילה מדי את השימוש בפעולות אטומיות; בעוד שהן משמשות להגדלה/הקטנה, הן יכולות לבצע גם פעולות מורכבות יותר כמו TestAndSet."}, "_source_file": "0228__Concurrency__Atomic_Operations__MC__Easy.json", "_topic_hint": "Atomic Operations", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:48:46", "_subject": "Concurrency", "_context_lectures": [11, 13, 14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Atomic Operations"], "difficulty_estimation": "Medium", "content": {"text": "מהי התכונה המהותית ביותר של פעולה אטומית (Atomic Operation) בהקשר של מערכת הפעלה מרובת תהליכים?", "code_snippet": null, "options": ["א. היא מבטיחה שכל הפעולות בתוך קטע הקוד האטומי יבוצעו על ידי חוט ביצוע יחיד ללא הפרעה של מעבר הקשר.", "ב. היא מבטיחה שפעולה מורכבת תיראה כפעולה בודדת ובלתי ניתנת לחלוקה מנקודת מבטם של חוטי ביצוע אחרים במערכת.", "ג. היא תמיד ממומשת ישירות על ידי פקודות חומרה מיוחדות, ואינה יכולה להיות מושגת באמצעות מנעולים תוכנתיים.", "ד. היא מבטיחה שהחוט המבצע אותה יקבל גישה בלעדית לכל משאבי המערכת למשך זמן ביצועה."]}, "solution": {"correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. פעולה אטומית היא פעולה שנראית כבלתי ניתנת לחלוקה מנקודת מבטם של חוטי ביצוע אחרים במערכת. משמעות הדבר היא שגם אם הפעולה מורכבת מכמה שלבים פנימיים, היא מבוצעת \"בבת אחת\" או \"בפקודה אחת\" (כפי שמתואר בהרצאה לגבי פעולות חומרה אטומיות כמו `__sync_fetch_and_add` ו-`TestAndSet`), כך שאין חוט אחר יכול לצפות במצב ביניים שלה. הפרת אטומיות (atomicity violation) מתרחשת כאשר פעולה כזו אינה מוגנת, וחוטים אחרים יכולים לראות מצבים חלקיים או לא עקביים. מנעולים (mutexes) משמשים כפתרון להבטחת אטומיות של קטעי קוד מורכבים.\n\nא' שגויה כי אמנם פעולות אטומיות רבות מבוצעות ללא מעבר הקשר עבור השלבים הפנימיים שלהן (במיוחד פעולות חומרה), אך ההגדרה העיקרית היא חוסר היכולת לצפות במצבי ביניים, ולא בהכרח היעדר מוחלט של מעבר הקשר בקטע קוד שלם המוגן במנעול (שם ייתכן מעבר קשר, אך הוא לא יאפשר לחוט אחר להיכנס לקטע הקריטי). ג' שגויה מכיוון שההרצאה מציינת במפורש שמנעולים (פתרון תוכנתי) הם דרך להבטיח אטומיות, בנוסף לפקודות חומרה. ד' שגויה לחלוטין – פעולה אטומית אינה דורשת גישה בלעדית לכל משאבי המערכת, אלא רק למשאבים הרלוונטיים שהיא משנה באופן אטומי."}, "_source_file": "0229__Concurrency__Atomic_Operations__MC__Medium.json", "_topic_hint": "Atomic Operations", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:49:05", "_subject": "Concurrency", "_context_lectures": [11, 13, 14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Atomic Operations"], "difficulty_estimation": "Medium", "content": {"text": "איזו מהטענות הבאות מתארת בצורה הטובה ביותר את המושג \"פעולה אטומית\" (Atomic Operation) בהקשר של מערכות הפעלה מקביליות?", "code_snippet": null, "options": ["א. פעולה המבוצעת על ידי רצף של פקודות, אשר מבחינת חוטים אחרים מתרחשת כיחידה אחת בלתי ניתנת להפרעה, ללא התערבות.", "ב. פעולה המבוצעת תמיד על ידי פקודת חומרה יחידה במעבד, ללא כל מורכבות לוגית פנימית.", "ג. פעולה שבה המהדר (compiler) מבטיח שכל הגישות למשתנים משותפים יבוצעו בסדר קבוע מראש.", "ד. פעולה שמטרתה העיקרית היא לשחרר באופן מיידי את כל המשאבים שתפס תהליך עם סיום ריצתו."]}, "solution": {"correct_option": "א", "explanation": "ההרצאה מתארת פעולות אטומיות כפעולות שנועדו למנוע 'atomicity violation' ולהבטיח שרצף של פעולות יתבצע 'בבת אחת'. זה כולל פעולות חומרה כמו `__sync_fetch_and_add` או `TestAndSet`, אשר למרות שעשויות לכלול מספר שלבים לוגיים (קריאה, שינוי, כתיבה), מבוצעות כיחידה אחת בלתי ניתנת להפרעה על ידי המעבד ('שבבת אחת עושות כמה פעולות', 'המימוש של הפקודה מתבצע באופן אטומי'). בנוסף, ההרצאה מציינת במפורש שניתן להפוך קטע קוד ל'אטומי' על ידי שימוש ב'מנעול' (mutex), אשר מבטיח שרצף של פקודות ייחשב כיחידה אחת מוגנת. אפשרות א' מקיפה את שני ההיבטים הללו בכך שהיא מתארת פעולה המבוצעת על ידי 'רצף של פקודות', אשר 'מבחינת חוטים אחרים מתרחשת כיחידה אחת בלתי ניתנת להפרעה, ללא התערבות', וזוהי בדיוק המהות של אטומיות."}, "_source_file": "0230__Concurrency__Atomic_Operations__MC__Medium.json", "_topic_hint": "Atomic Operations", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:49:26", "_subject": "Concurrency", "_context_lectures": [11, 13, 14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Atomic Operations"], "difficulty_estimation": "Medium", "content": {"text": "מהי ההגדרה הנכונה ביותר ל\"פעולה אטומית\" (Atomic Operation) בהקשר של מערכות הפעלה מרובות תהליכים (multithreaded/multiprocess)?", "code_snippet": null, "options": ["א. פעולה המבוצעת על ידי פקודת חומרה ייעודית בלבד, כגון __sync_fetch_and_add.", "ב. פעולה המובטחת להתבצע כולה ללא הפרעה או התערבות של תהליכים (threads) אחרים, כאילו הייתה פעולה יחידה.", "ג. פעולה שתמיד משתמשת במנגנון מנעולים (mutexes) כדי להבטיח גישה בלעדית למשאב.", "ד. פעולה שתמיד מחזירה ערך בוליאני המציין הצלחה או כישלון של הביצוע."]}, "solution": {"correct_option": "ב", "explanation": "פעולה אטומית היא פעולה שמובטחת להתבצע כיחידה שלמה ובלתי ניתנת לחלוקה (indivisible). המשמעות היא שמרגע שהפעולה מתחילה, היא מסתיימת לפני שכל תהליך או חוט אחר יכול לצפות או לשנות את הנתונים המעורבים בפעולה זו. זה מונע מצבי מרוץ (race conditions) ומבטיח עקביות נתונים, כפי שתואר במקרה של 'atomicity violation' בשיעור. המנגנונים להשגת אטומיות יכולים להיות פקודות חומרה ייעודיות (כמו TestAndSet או __sync_fetch_and_add) או באמצעות מנעולים (mutexes) המגינים על קטע קוד קריטי. לכן, תשובה א' ו-ג' אינן נכונות מכיוון שהן מתארות רק דרך אחת להשגת אטומיות, ולא את ההגדרה הכללית של הפעולה עצמה. תשובה ד' אינה רלוונטית להגדרת אטומיות."}, "_source_file": "0231__Concurrency__Atomic_Operations__MC__Medium.json", "_topic_hint": "Atomic Operations", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:49:41", "_subject": "Concurrency", "_context_lectures": [11, 13, 14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Atomic Operations"], "difficulty_estimation": "Hard", "content": {"text": "בהתייחס לפעולת החומרה TestAndSet כפי שהוצגה בחומר הלימוד, אשר מוגדרת באמצעות \"הגדרה סדרתית\" (sequential specification) אך מבוצעת באופן אטומי על ידי המעבד, מהי הטענה הנכונה ביותר לגבי תרומתה המהותית לפתרון בעיות אטומיות במערכות הפעלה?", "code_snippet": "int TestAndSet(int* old_ptr, int new) {\n  int old = *old_ptr;\n  *old_ptr = new;\n  return old;\n}", "options": ["א. היא מאפשרת לבצע רצף של פעולות קריאה וכתיבה על משתנה יחיד כפעולה בלתי ניתנת להפרעה (אטומית), ובכך מונעת מצב שבו חוט אחר מתערב בין הקריאה לכתיבה.", "ב. היא נועדה בעיקר להחליף מנגנוני נעילה מורכבים כמו mutexes במקרים של גישה למשאב משותף, ובכך מבטיחה יעילות ביצוע גבוהה יותר באופן גורף.", "ג. תפקידה העיקרי הוא לאפשר לחוטים להשהות את ביצועם באופן אטומי תוך שחרור מנעול קיים, בדומה לפעולת wait של Condition Variable, ובכך למנוע דדלוקים.", "ד. היא משמשת רק לביצוע פעולות חשבוניות אטומיות פשוטות כמו הגדלת מונה, והשימוש בה מומלץ רק כאשר יש צורך מובהק בסנכרון."]}, "solution": {"correct_option": "א", "explanation": "הסבר: פעולת ה-TestAndSet מוגדרת בחומר הלימוד כפקודת מכונה המבצעת באופן אטומי רצף של קריאת ערך ממשתנה, כתיבת ערך חדש לאותו משתנה, והחזרת הערך הישן. העובדה שהיא \"מבוצעת באופן אטומי בבת אחת\" (כפי שצוין בפירוש בחומר), למרות ה\"הגדרה הסדרתית\" שלה, היא המפתח. תרומתה המהותית היא שהיא מאפשרת לבצע את שתי הפעולות (קריאה וכתיבה) כטרנזקציה אחת בלתי ניתנת להפרעה, ובכך פותרת את בעיית ה-atomicity violation שבה חוט אחד עלול לקרוא ערך, חוט שני לשנות אותו, ורק אז החוט הראשון לכתוב ערך מיושן. זהו הבסיס למימוש מנעולים ומנגנוני סנכרון אחרים.\n\nאפשרויות שגויות:\nב. החומר מציין ש\"יש שיקולים שגורמים לפקודות הללו להיות פחות יעילות\" אם לא צריך סנכרון, ולכן הטענה ליעילות גורפת אינה נכונה. בנוסף, היא לא בהכרח \"מחליפה\" מנגנוני נעילה מורכבים אלא משמשת כפרימיטיב לבנייתם.\nג. תיאור זה מתייחס לפעולה האטומית של `wait(&cv1, &m1)` המשלבת שחרור מנעול והמתנה, כפי שהוסבר בחומר הלימוד. פעולת TestAndSet אינה כוללת שחרור מנעולים או \"ללכת לישון\".\nד. תיאור זה מתאים יותר לפעולות כמו `__sync_fetch_and_add` שהוצגו כדוגמה לפעולות אטומיות חשבוניות פשוטות. TestAndSet היא פקודה כללית יותר של קריאה-שינוי-כתיבה המשמשת לבניית מנעולים, ולא מוגבלת לפעולות חשבוניות בלבד. כמו כן, הטענה כי השימוש בה מומלץ רק כשיש צורך בסנכרון נכונה באופן כללי לפעולות אטומיות, אך לא מייחדת את TestAndSet רק לפעולות חשבוניות פשוטות."}, "_source_file": "0232__Concurrency__Atomic_Operations__MC__Hard.json", "_topic_hint": "Atomic Operations", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:50:02", "_subject": "Concurrency", "_context_lectures": [11, 13, 14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Atomic Operations"], "difficulty_estimation": "Hard", "content": {"text": "בהקשר של פעולות אטומיות במערכות הפעלה, פעולת ה-`wait` של משתנה תנאי (condition variable) מתוארת כפעולה שבה \"משחררים מנעול והולכים לישון (זה אטומי, בו זמנית)\". מהי הסיבה העיקרית לכך ששני שלבים אלו חייבים להתבצע באופן אטומי, ומדוע זה קריטי לתקינות המערכת?", "code_snippet": "-> Atomic:\nunlock(&m1);\nwait_for_signal(&cv1);\n// after waking up:\nlock(&m1);", "options": ["א. האטומיות מבטיחה ששחרור המנעול והכניסה למצב שינה יתרחשו כיחידה בלתי ניתנת להפרעה, ובכך מונעת מצב שבו חוט אחר יתפוס את המנעול, ישנה את מצב התנאי וישלח סיגנל (signal) לפני שהחוט הקורא ל-`wait` הספיק להירדם, מה שיוביל לאובדן הסיגנל ולקיפאון (deadlock) פוטנציאלי.", "ב. האטומיות של פעולת ה-`wait` נובעת מכך שהיא ממומשת באופן בלעדי באמצעות פקודת חומרה יחידה בדומה ל-`TestAndSet`, המשלבת את כל הפעולות הנדרשות לשחרור מנעול וכניסה למצב שינה.", "ג. האטומיות מבטיחה שרק חוט אחד יוכל לקרוא ל-`wait` על משתנה תנאי מסוים בכל רגע נתון, מה שמבטיח סדר קבוע וידוע מראש של המתנה בין החוטים.", "ד. האטומיות מיועדת למנוע מצב שבו המערכת קורסת באמצע פעולת ה-`wait`, ובכך מבטיחה שהמנעול תמיד ישוחרר ושהחוט לא ייתקע במצב ביניים בלתי עקבי."]}, "solution": {"correct_option": "א", "explanation": "האטומיות של פעולת ה-`wait` במשתני תנאי היא קריטית למניעת תזמון לא נכון (race condition) ואף קיפאון. ללא אטומיות זו, יכול להיווצר חלון זמן קצר בין שחרור המנעול לבין כניסת החוט למצב שינה. בחלון זמן זה, חוט אחר יכול לתפוס את המנעול, לשנות את התנאי שעליו ממתינים, ולשלוח סיגנל. אם הסיגנל נשלח לפני שהחוט הראשון הספיק להירדם, הסיגנל \"יאבד\", והחוט הראשון יירדם וימתין לסיגנל שלעולם לא יגיע, מה שיוביל לקיפאון. לכן, שחרור המנעול והכניסה למצב שינה חייבים להתבצע כיחידה אטומית אחת, כפי שמצוין בחומר ההרצאה: \"כשאנחנו קוראים ל-wait ומחכים למסר, אנחנו משחררים מנעול והולכים לישון (זה אטומי, בו זמנית).\" אפשרות ב' שגויה מכיוון שפעולת `wait` מורכבת מכדי להיות ממומשת כפקודת חומרה יחידה בלבד; היא משלבת פרימיטיבים חומרתיים עם לוגיקה של מתזמן מערכת ההפעלה. אפשרויות ג' ו-ד' אינן מתארות נכונה את מטרת האטומיות בהקשר זה."}, "_source_file": "0233__Concurrency__Atomic_Operations__MC__Hard.json", "_topic_hint": "Atomic Operations", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:50:19", "_subject": "Concurrency", "_context_lectures": [11, 13, 14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Atomic Operations"], "difficulty_estimation": "Hard", "content": {"text": "הבעיה של הפרת אטומיות (atomicity violation) מתרחשת כאשר רצף פעולות המיועד להתבצע כיחידה בלתי ניתנת לחלוקה מופרע. קיימות מספר גישות לפתרון בעיה זו. איזו מהטענות הבאות מתארת בצורה המדויקת ביותר את ההבדל העקרוני באופן שבו מנעול (mutex) ופקודת חומרה אטומית (כגון __sync_fetch_and_add) מבטיחים אטומיות?", "code_snippet": null, "options": ["א. מנעול מבטיח שקטע קוד שלם יתבצע באופן אטומי על ידי מניעת גישה מקבילית אליו, בעוד שפקודת חומרה אטומית מבצעת רצף ספציפי של פעולות כפקודת מעבד יחידה ובלתי ניתנת לחלוקה.", "ב. פקודות חומרה אטומיות הן תמיד יעילות יותר ממנעולים לצורך סנכרון, מכיוון שהן אינן דורשות מעבר למצב ליבה או החלפת הקשר.", "ג. מנעולים מיועדים להגן על מבני נתונים מורכבים בלבד, בעוד שפקודות חומרה אטומיות משמשות רק לפעולות אריתמטיות פשוטות על משתנים בודדים.", "ד. מנעולים ממומשים באופן בלעדי בתוכנה באמצעות אלגוריתמים מורכבים, ואילו פקודות חומרה אטומיות דורשות תמיד כתיבת קוד אסמבלי ישיר."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'.\n\nעל פי חומר ההרצאה (Lecture 14, chunk 42), מנעול (mutex) משמש לפתרון \"atomicity violation\" על ידי כך ש\"נתפוס את המנעול בקטע הקוד שהתכוונו שיהיה אטומי, ונתפוס את המנעול בכל קטע קוד אחר שעלול להפריע לנו. עכשיו זה יהיה אטומי\". כלומר, מנעול אוכף אטומיות על קטע קוד שלם על ידי הבטחת מניעת גישה הדדית (mutual exclusion), כך שרק חוט אחד יכול לבצע את הקטע בזמן נתון.\n\nלעומת זאת, פקודות חומרה אטומיות (כמו אלו המוזכרות ב-Lecture 11, chunk 38, כגון __sync_fetch_and_add, ו-TestAndSet ב-Lecture 11, chunk 40) מתוארות כ\"פעולות חומרה שיש במעבד, שבבת אחת עושות כמה פעולות\" או \"פקודת מכונה שמבצעת את הקוד הבא: ... המימוש של הפקודה מתבצע באופן אטומי\". הן מבצעות רצף פעולות קצר ויחיד כפקודת מעבד אינדיבידואלית, שאינה ניתנת להפרעה ברמת החומרה.\n\nאפשרויות ב', ג' ו-ד' שגויות:\n*   ב': חומר ההרצאה (Lecture 11, chunk 40) מציין כי \"יש שיקולים שגורמים לפקודות הללו להיות פחות יעילות. אם אנחנו לא צריכים סינכרון, אל לנו להשתמש בהן. פעולת הגדלת מונה פשוטה יכולה להיות יותר יעילה מאשר ביצוע פעולה אטומית.\" כלומר, פקודות חומרה אטומיות אינן *תמיד* יעילות יותר ממנעולים.\n*   ג': מנעולים מגינים על כל קטע קריטי, לא רק על מבני נתונים מורכבים, ופקודות חומרה אטומיות יכולות לשמש לבניית פרימיטיבי סנכרון מורכבים יותר (כמו מנעולים עצמם, באמצעות TestAndSet), ולא רק לפעולות אריתמטיות פשוטות.\n*   ד': מנעולים רבים ממומשים תוך שימוש בפקודות חומרה אטומיות (כמו TestAndSet) בתור אבני הבניין שלהם, ולכן אינם \"בלעדית בתוכנה\". בנוסף, פקודות כמו __sync_fetch_and_add ניתנות לשימוש ישירות מ-C/C++ ולא דורשות תמיד כתיבת קוד אסמבלי ישיר."}, "_source_file": "0234__Concurrency__Atomic_Operations__MC__Hard.json", "_topic_hint": "Atomic Operations", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:50:39", "_subject": "Concurrency", "_context_lectures": [11, 13, 14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Condition Variables"], "difficulty_estimation": "Easy", "content": {"text": "אילו מבין הפעולות הבאות קשורות לשימוש במשתני תנאי (Condition Variables) במערכת הפעלה, כפי שמוצג במימוש בלינוקס?", "code_snippet": "```c\n// wait:\npthread_cond_wait(pthread_cond_t *c, pthread_mutex_t *m);\n// signal:\npthread_cond_signal(pthread_cond_t *c);\n// broadcast:\npthread_cond_broadcast(pthread_cond_t *c);\n```", "options": ["א. wait, signal, broadcast", "ב. lock, unlock, try_lock", "ג. p, v, up", "ד. create, delete, execute"]}, "solution": {"correct_option": "א", "explanation": "הפעולות `wait`, `signal` ו-`broadcast` הן הפעולות הסטנדרטיות לטיפול במשתני תנאי (Condition Variables). על פי חומר ההרצאה, מימוש משתני התנאי בלינוקס משתמש בפונקציות `pthread_cond_wait`, `pthread_cond_signal` ו-`pthread_cond_broadcast`. פעולות אלו מאפשרות לחוטים להמתין לתנאי מסוים שיתקיים (`wait`) ולהודיע לחוט אחד (`signal`) או לכל החוטים הממתינים (`broadcast`) שהתנאי התקיים. האפשרויות האחרות מתייחסות לפעולות של מנעולים (mutexes) או סמפורים, שאינן הפעולות הישירות של משתני תנאי."}, "_source_file": "0235__Concurrency__Condition_Variables__MC__Easy.json", "_topic_hint": "Condition Variables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:50:51", "_subject": "Concurrency", "_context_lectures": [11, 14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Condition Variables"], "difficulty_estimation": "Easy", "content": {"text": "איזו בעיה מרכזית משתני תנאי (Condition Variables) נועדו לפתור במערכות הפעלה?", "code_snippet": null, "options": ["א. הבטחת גישה בלעדית (mutual exclusion) לקטעים קריטיים.", "ב. סנכרון פעולות בין חוטים, כך שחוט אחד ימתין לתנאי מסוים שיתקיים על ידי חוט אחר.", "ג. ניהול הקצאת זיכרון משותף בין תהליכים.", "ד. איתור ותיקון שגיאות זמן ריצה בקוד."]}, "solution": {"correct_option": "ב", "explanation": "החומר מציין במפורש שמשתני תנאי נועדו לפתור בעיות סנכרון כגון המקרה שבו \"חוט A רוצה לבצע את הפעולה שלו רק אחרי חוט B\". הפתרון כולל שימוש במשתנה משותף (דגל) שחוט A בודק וממתין שחוט B יסיים ויודיע לו בעזרת סיגנל. זוהי בדיוק המהות של סנכרון תהליכים על בסיס תנאי, כפי שמתואר ב-Lecture 14 (chunk 0). אפשרות א' מתארת את תפקידם של מנעולים (mutexes), ואילו אפשרויות ג' ו-ד' אינן קשורות למשתני תנאי."}, "_source_file": "0236__Concurrency__Condition_Variables__MC__Easy.json", "_topic_hint": "Condition Variables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:51:11", "_subject": "Concurrency", "_context_lectures": [11, 14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Condition Variables"], "difficulty_estimation": "Easy", "content": {"text": "מהו התפקיד העיקרי של משתנה תנאי (Condition Variable) בסנכרון בין תהליכונים (threads) במערכת הפעלה?", "code_snippet": null, "options": ["א. להגן על קטע קריטי מגישה בו-זמנית של מספר תהליכונים.", "ב. לאפשר לתהליכונים להמתין עד שתנאי מסוים יתקיים, ורק אז להמשיך בביצוע.", "ג. לספק מנגנון לספירה אטומית של משאבים משותפים.", "ד. לאפשר תקשורת ישירה בין תהליכונים באמצעות העברת הודעות."]}, "solution": {"correct_option": "ב", "explanation": "משתנה תנאי (Condition Variable) משמש בעיקר כדי לאפשר לתהליכונים להמתין באופן יעיל עד שיתקיים תנאי מסוים, שעלול להשתנות על ידי תהליכון אחר. לדוגמה, חוט A יכול להמתין באמצעות פעולת `wait` עד שחוט B יסיים פעולה מסוימת ויאותת לו (signal) שהתנאי התקיים. זהו מנגנון בסיסי לפתרון בעיות סנכרון כמו בעיית יצרן/צרכן, כפי שמתואר בחומר ההרצאה. אפשרות א' מתארת את תפקידו של מנעול (mutex), אפשרות ג' מתארת סמפור (semaphore), ואפשרות ד' מתארת מנגנון אחר לתקשורת."}, "_source_file": "0237__Concurrency__Condition_Variables__MC__Easy.json", "_topic_hint": "Condition Variables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:51:21", "_subject": "Concurrency", "_context_lectures": [11, 14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Condition Variables"], "difficulty_estimation": "Medium", "content": {"text": "בתרחיש בעיית יצרן/צרכן (Producer/Consumer) המתואר בחומר ההרצאה, מדוע נדרש שימוש בשני משתני תנאי (condition variables), כגון `empty` ו-`full`, במקום במשתנה תנאי בודד?", "code_snippet": "// דוגמה לשימוש במשתני תנאי בבעיית יצרן/צרכן (קטע קוד של צרכן):\n// if (count == 0)\n//     wait(&empty, &m1);\n// baDuBop(); // צורך פריט\n// --count;\n// signal(&full);\n// unlock(&m1);", "options": ["א. כדי למנוע קיפאון (deadlock) הנובע מערבוב הודעות המתנה, שבו יצרנים וצרכנים ממתינים על אותו משתנה תנאי למרות שהם מחכים לתנאים שונים (מקום פנוי לעומת פריטים זמינים).", "ב. כדי לאפשר ליצרנים וצרכנים להשתמש במנעולים נפרדים לכל משתנה תנאי, ובכך להגביר את מקביליות המערכת.", "ג. לאפשר לכל חוט (thread) של יצרן או צרכן להכריז על משתנה תנאי משלו, לניהול עצמאי של ההמתנה.", "ד. כדי לייעל את פעולת ה-broadcast ולאפשר שליחה סלקטיבית של אותות רק ליצרנים או רק לצרכנים."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר ההרצאה (שיעור 14, קטע 13) מסביר כי שימוש במשתנה תנאי יחיד בבעיית יצרן/צרכן עלול להוביל למצב של קיפאון (deadlock). קיפאון זה מתרחש כאשר צרכן חוסם (ממתין) כי אין מוצרים במחסן, ויצרן חסום (ממתין) כי אין מקום פנוי במחסן, למרות שייתכן שיש מקום פנוי או מוצרים זמינים אך ההודעות מעורבבות. הפתרון לבעיה זו הוא שימוש בשני משתני תנאי נפרדים: `empty` ו-`full`. הצרכנים ממתינים על `empty` כאשר המחסן ריק (count == 0), והיצרנים שולחים לו סיגנל בעת הוספת מוצר. לעומת זאת, היצרנים ממתינים על `full` כאשר המחסן מלא, והצרכנים שולחים לו סיגנל בעת צריכת מוצר (פינוי מקום). הפרדה זו מבטיחה שכל סוג של חוט ממתין לתנאי הרלוונטי לו בלבד, ומונעת קיפאון הנובע מערבוב הודעות המתנה."}, "_source_file": "0238__Concurrency__Condition_Variables__MC__Medium.json", "_topic_hint": "Condition Variables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:51:38", "_subject": "Concurrency", "_context_lectures": [11, 14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Condition Variables"], "difficulty_estimation": "Medium", "content": {"text": "מדוע בפתרון בעיית ה-Producer/Consumer (יצרן/צרכן) באמצעות condition variables (משתני תנאי) נהוג להשתמש בשני משתני תנאי נפרדים (לדוגמה, `empty` ו-`full`), ולא במשתנה תנאי יחיד?", "code_snippet": "/* Example pseudo-code for Producer/Consumer with two condition variables */\n\npthread_mutex_t buffer_mutex;\npthread_cond_t empty_cv; // Consumers wait on this when buffer is empty\npthread_cond_t full_cv;  // Producers wait on this when buffer is full\nint item_count = 0;     // Number of items currently in the buffer\nconst int BUFFER_SIZE = 10;\n\n// Producer thread logic:\nvoid producer() {\n    pthread_mutex_lock(&buffer_mutex);\n    while (item_count == BUFFER_SIZE) { // If buffer is full, wait for space\n        pthread_cond_wait(&full_cv, &buffer_mutex);\n    }\n    // Produce item and add to buffer\n    item_count++;\n    pthread_cond_signal(&empty_cv); // Signal consumers that buffer is not empty\n    pthread_mutex_unlock(&buffer_mutex);\n}\n\n// Consumer thread logic:\nvoid consumer() {\n    pthread_mutex_lock(&buffer_mutex);\n    while (item_count == 0) { // If buffer is empty, wait for items\n        pthread_cond_wait(&empty_cv, &buffer_mutex);\n    }\n    // Consume item from buffer\n    item_count--;\n    pthread_cond_signal(&full_cv); // Signal producers that buffer is not full\n    pthread_mutex_unlock(&buffer_mutex);\n}", "options": ["א. כדי למנוע מצב של קיפאון (deadlock) הנוצר כאשר יצרן וצרכן חוסמים זה את זה על אותו משתנה תנאי.", "ב. כדי לאפשר לחוטים להתחלף ביניהם באופן אקראי ולשפר את ביצועי המערכת על ידי מקביליות מוגברת.", "ג. מכיוון ש-condition variable יחיד יכול לטפל רק בסוג אחד של אירועים (למשל, רק \"מלא\" או רק \"ריק\"), ולא בשניהם יחד.", "ד. על מנת לאפשר לחוטים לגשת ישירות לערך המספרי הפנימי של משתנה התנאי ולשנות אותו באופן אטומי."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. החומר המצוין בשיעור 14 (chunk 13) מסביר כי שימוש במשתנה תנאי יחיד עבור בעיית היצרן/צרכן עלול להוביל למצב של קיפאון (deadlock). במצב כזה, צרכן יכול להיות חסום כי המחסן ריק, ויצרן יכול להיות חסום כי המחסן מלא, אך שניהם ממתינים על אותו משתנה תנאי. הפתרון לבעיה זו הוא שימוש בשני משתני תנאי נפרדים: אחד (`empty`) עליו ממתינים הצרכנים כאשר המחסן ריק ומופעל עליו סיגנל על ידי יצרנים שמוסיפים פריט; ואחד (`full`) עליו ממתינים היצרנים כאשר המחסן מלא ומופעל עליו סיגנל על ידי צרכנים שמוציאים פריט. הפרדה זו מבטיחה שההודעות (signals) וההמתנות (waits) יתאימו לתנאים הספציפיים (מחסן ריק או מלא) וימנעו קיפאון."}, "_source_file": "0239__Concurrency__Condition_Variables__MC__Medium.json", "_topic_hint": "Condition Variables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:51:55", "_subject": "Concurrency", "_context_lectures": [11, 14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Condition Variables"], "difficulty_estimation": "Medium", "content": {"text": "בבעיית היצרן-צרכן (Bounded Buffer), כאשר ישנם מספר יצרנים וצרכנים, מדוע הפתרון המומלץ כולל שימוש בשני משתני תנאי (Condition Variables) נפרדים, כגון `empty` ו-`full`, במקום משתנה תנאי יחיד?", "code_snippet": null, "options": ["א. כדי למנוע מצב של קיפאון (deadlock) בו גם יצרנים וגם צרכנים נחסמים באופן הדדי.", "ב. כדי לייעל את ביצועי המערכת על ידי הפחתת מספר הקריאות לפעולות `wait` ו-`signal`.", "ג. משתנה תנאי יחיד אינו יכול לתמוך בריבוי יצרנים וצרכנים בו-זמנית.", "ד. כדי לאפשר לצרכנים וליצרנים להשתמש במנעולים (mutexes) שונים ולא לחסום זה את זה."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין בשיעור 14 (chunk 13) מסביר במפורש כי בבעיית היצרן-צרכן, שימוש במשתנה תנאי יחיד עלול להוביל למצב של קיפאון (deadlock). מצב זה מתרחש כאשר צרכן חוסם (כי אין מוצרים במחסן) ויצרן חסום (כי אין מקום פנוי במחסן), או להפך, למרות שאולי יש מקום פנוי או שניתן לייצר. הפתרון לבעיה זו הוא שימוש בשני משתני תנאי נפרדים: אחד (`empty`) עבור הצרכנים שממתינים כאשר המחסן ריק, ואחד (`full`) עבור היצרנים שממתינים כאשר המחסן מלא. בדרך זו, הודעות היצרן (הוספת פריט) והצרכן (צריכת פריט) מטופלות בנפרד, ומונעות חסימה הדדית שמובילה לקיפאון."}, "_source_file": "0240__Concurrency__Condition_Variables__MC__Medium.json", "_topic_hint": "Condition Variables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:52:07", "_subject": "Concurrency", "_context_lectures": [11, 14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Condition Variables"], "difficulty_estimation": "Hard", "content": {"text": "בהקשר של פתרון בעיית היצרן-צרכן (Producer-Consumer) תוך שימוש במשתני תנאי (Condition Variables) לסנכרון גישה למאגר חסום (Bounded Buffer), ובהתבסס על הבעיות והפתרונות הנדונים בחומר הקורס, מהי הגישה המומלצת למנוע מצבי קיפאון (Deadlock) הנובעים מערבוב הודעות סנכרון?", "code_snippet": null, "options": ["א. יש להשתמש במשתנה תנאי יחיד עבור כל ההודעות הקשורות למאגר, כאשר הן היצרנים והן הצרכנים ממתינים עליו ומודיעים זה לזה דרכו.", "ב. יש להשתמש בשני משתני תנאי נפרדים: אחד (empty) עליו ממתינים הצרכנים כאשר המאגר ריק, ואליו שולחים היצרנים סיגנל בעת הוספת מוצר; ואחד (full) עליו ממתינים היצרנים כאשר המאגר מלא, ואליו שולחים הצרכנים סיגנל בעת צריכת מוצר.", "ג. יש להסתפק בשימוש במנעול (mutex) בודד המגן על הגישה למאגר, שכן הוא מספק בלעדיות (mutual exclusion) ובכך מונע את כל בעיות הסנכרון, כולל קיפאון.", "ד. יש להחליף את השימוש במשתני תנאי בסמפורים (Semaphores) עם פעולות wait ו-post, מכיוון שהם מספקים פונקציונליות רחבה יותר ואינם סובלים מבעיות קיפאון בבעיית היצרן-צרכן."]}, "solution": {"correct_option": "ב", "explanation": "החומר המצורף מציין במפורש כי שימוש במשתנה תנאי יחיד עבור שני סוגי הודעות (כשהמאגר ריק וכשהמאגר מלא) בבעיית היצרן-צרכן עלול להוביל למצב של קיפאון (Deadlock). דוגמה לכך היא מצב שבו צרכן חסום כי אין מוצרים ויצרן חסום כי אין מקום פנוי, למרות שבפועל עשוי להיות מקום פנוי או מוצרים זמינים. הפתרון המומלץ, על פי החומר, הוא \"שימוש בשני condition variables\" ו-\"לא נערבב בין הודעות, כל הודעה היא בפני עצמה.\" הוסבר כי יש להשתמש במשתנה תנאי `empty` עבור צרכנים הממתינים על מאגר ריק (ויצרנים שולחים לו סיגנל), ובמשתנה תנאי `full` עבור יצרנים הממתינים על מאגר מלא (וצרכנים שולחים לו סיגנל). לכן, אפשרות ב' מתארת במדויק את הפתרון לבעיה זו כפי שהוצג בהרצאה. אפשרות א' מתארת את הגורם לקיפאון. אפשרות ג' אינה נכונה, מכיוון שמנעול לבדו מספק בלעדיות אך אינו מאפשר לחוטים לחכות לתנאי מסוים. אפשרות ד' אינה נכונה, שכן סמפורים ומשתני תנאי הם מנגנוני סנכרון שונים, והחומר מציג את המימוש הספציפי של משתני תנאי בלינוקס באמצעות `pthread_cond_wait` ו-`pthread_cond_signal`, ומבהיר את הצורך בפתרון הספציפי הזה עם שני משתני תנאי כדי למנוע קיפאון בבעיה זו."}, "_source_file": "0241__Concurrency__Condition_Variables__MC__Hard.json", "_topic_hint": "Condition Variables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:52:30", "_subject": "Concurrency", "_context_lectures": [11, 14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Producer-Consumer"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, מהו התפקיד המרכזי של היצרנים (producers) בבעיית ה-producer/consumer?", "code_snippet": "Producer:\n```c\nlock(&m1);\nmmmBop();\nwhile (count < MAX)\n    wait(&full, &m1);\n++count; // Represents adding an item\nsignal(&empty);\nunlock(&m1);\n```", "options": ["א. להוציא איברים מהמחסן המשותף.", "ב. להוסיף איברים חדשים למחסן המשותף.", "ג. להמתין כשהמחסן אינו ריק.", "ד. לשלוח סיגנל לצרכנים כאשר המחסן מלא."]}, "solution": {"correct_option": "ב", "explanation": "חומר ההרצאה מציין במפורש כי 'היצרנים מייצרים איברים חדשים שנכנסים לתור'. תפקידם העיקרי הוא לייצר ולהוסיף נתונים למחסן המשותף (התור או ה-bounded buffer), כפי שמודגם גם בקטע הקוד בביטוי `++count;` המייצג הוספת פריט. שאר האפשרויות מתארות תפקידים של הצרכנים, המתנה במצבים שונים, או פעולות שגויות."}, "_source_file": "0244__Concurrency__Producer-Consumer__MC__Easy.json", "_topic_hint": "Producer-Consumer", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:53:23", "_subject": "Concurrency", "_context_lectures": [14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Producer-Consumer"], "difficulty_estimation": "Easy", "content": {"text": "מתי חוט צרכן (Consumer) נכנס למצב המתנה (wait) בפתרון הנכון לבעיית היצרן-צרכן (Producer-Consumer) עם באפר חסום?", "code_snippet": "Consumer:\n```c\nlock(&m1);\nwhile (count == 0)\n    wait(&empty, &m1);\nbaDuBop();\n--count;\nsignal(&full);\nunlock(&m1);\n```", "options": ["א. כאשר המחסן (buffer) מלא לחלוטין.", "ב. כאשר המחסן (buffer) ריק לחלוטין.", "ג. כאשר חוט יצרן (Producer) אחר תפוס בביצוע פעולה.", "ד. כאשר חוט צרכן (Consumer) אחר מחזיק את המנעול (lock)."]}, "solution": {"correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. חוט צרכן ממתין כאשר המחסן (buffer) ריק לחלוטין (count == 0), כלומר אין פריטים לצרוך. מנגנון זה מונע מצרכנים לנסות לגשת לנתונים שאינם קיימים. חוט הצרכן ימתין על משתנה תנאי (condition variable) ייעודי (כמו `empty` בדוגמת הקוד), ויתעורר רק כאשר חוט יצרן יוסיף פריט למחסן וישלח סיגנל. דוגמת הקוד המצורפת מדגימה זאת במפורש בשורה `while (count == 0) wait(&empty, &m1);`."}, "_source_file": "0245__Concurrency__Producer-Consumer__MC__Easy.json", "_topic_hint": "Producer-Consumer", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:53:34", "_subject": "Concurrency", "_context_lectures": [14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Producer-Consumer"], "difficulty_estimation": "Easy", "content": {"text": "מהו התפקיד העיקרי של ה'יצרן' (Producer) בדפוס התכנות יצרן-צרכן (Producer-Consumer)?", "code_snippet": "Producer:\n```c\nlock(&m1);\nmmmBop();\n++count; // Represents adding an item\nsignal(&cv1);\nunlock(&m1);\n```", "options": ["א. להמתין שהמחסן המשותף יתרוקן לפני הוספת פריטים.", "ב. לייצר ולהוסיף פריטים חדשים למחסן המשותף.", "ג. לצרוך פריטים מהמחסן המשותף כשהוא אינו ריק.", "ד. לאותת לצרכנים כשהמחסן המשותף מלא."]}, "solution": {"correct_option": "ב", "explanation": "התפקיד העיקרי של ה'יצרן' (Producer) בדפוס יצרן-צרכן הוא לייצר פריטים חדשים ולהוסיף אותם למבנה נתונים משותף (כמו תור או באפר), אשר ממנו ה'צרכנים' (Consumers) יצרכו אותם. קטע הקוד המצורף מדגים זאת על ידי הגדלת המונה (count), המייצג הוספת פריט למחסן, כפי שמתואר בחומר ההרצאה: \"היצרנים מייצרים איברים חדשים שנכנסים לתור\"."}, "_source_file": "0246__Concurrency__Producer-Consumer__MC__Easy.json", "_topic_hint": "Producer-Consumer", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:53:43", "_subject": "Concurrency", "_context_lectures": [14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Producer-Consumer"], "difficulty_estimation": "Medium", "content": {"text": "מהי הבעיה העיקרית שיכולה להתעורר במימוש בעיית היצרן-צרכן (Producer-Consumer) עם משתנה תנאי יחיד (condition variable) עבור שני סוגי התהליכים (יצרנים וצרכנים), כפי שנדון בחומר ההרצאה?", "code_snippet": "Producer:\n```c\nlock(&m1);\nmmmBop();\nwhile (count < MAX)\n    wait(&cv1, &m1);\n++count;\nsignal(&cv1);\nunlock(&m1);\n```\n\nConsumer:\n```c\nlock(&m1);\nwhile (count == 0)\n    wait(&cv1, &m1);\nbaDuBop();\n--count;\nsignal(&cv1);\nunlock(&m1);\n```", "options": ["א. מצב של קיפאון (deadlock) עלול להתרחש כאשר אות (signal) שמיועד להעיר תהליך מסוג מסוים מעיר בטעות תהליך מסוג אחר, מה שמוביל לחסימה הדדית.", "ב. ביצועי המערכת יורדים משמעותית עקב ריבוי החלפות הקשר (context switches) בין היצרנים לצרכנים, ללא קשר לזמינות המאגר.", "ג. נתונים במאגר המשותף עלולים להיפגם (data corruption) כתוצאה מכניסת מספר תהליכים לאזור קריטי בו-זמנית, מכיוון שמשתנה התנאי אינו מבטיח הדדיות.", "ד. תהליכים מסוימים עלולים להיכנס למצב של הרעבה (starvation) ולא לקבל לעולם הזדמנות לבצע את פעולתם, גם כשהמאגר פנוי או מכיל פריטים."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. במימוש בעיית היצרן-צרכן עם משתנה תנאי יחיד (כמו `cv1` בקוד לדוגמה), קיימת בעיה מהותית של חוסר ספציפיות באותות (signals). כפי שמתואר בחומר ההרצאה: 'כאשר עושים signal ל-cv1, ייתכן ואנחנו רוצים להעיר צרכן אבל במקום זאת בטעות יצרן שמחכה לסיגנל יתעורר.' מצב זה יכול להוביל לקיפאון (deadlock). לדוגמה, יצרן ממלא את המאגר ושולח סיגנל, אך במקום להעיר צרכן שיפנה מקום, הוא מעיר יצרן אחר שמנסה להוסיף למאגר מלא ומיד נחסם. במקביל, אם צרכנים ממתינים על מאגר ריק, הם יישארו חסומים והמערכת כולה עלולה להיתקע. דוגמה זו מודגשת בחומר ההרצאה כ'מקרה של קיפאון, יש צרכן שחוסם (כי אין מוצרים במחסן) ויצרן חסום (כי אין מקום פנוי במחסן) למרות שיש מקום פנוי במחסן'. השימוש בשני משתני תנאי נפרדים (`empty` ו-`full`), כפי שמוצג בפתרון המתקדם יותר בחומר, מאפשר שליטה מדויקת יותר על איזה סוג תהליך יתעורר, ובכך מונע את הקיפאון הנובע מחוסר ספציפיות זו."}, "_source_file": "0247__Concurrency__Producer-Consumer__MC__Medium.json", "_topic_hint": "Producer-Consumer", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:53:59", "_subject": "Concurrency", "_context_lectures": [14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Producer-Consumer"], "difficulty_estimation": "Medium", "content": {"text": "בבעיית היצרן-צרכן (Bounded Buffer), שימוש במשתנה תנאי (condition variable) יחיד עבור יצרנים וצרכנים (למשל, `cv1`) עלול להוביל לקיפאון (deadlock). מהי הסיבה העיקרית לכך?", "code_snippet": "Producer:\n```c\nlock(&m1);\nmmmBop();\nwhile (count < MAX)\n    wait(&cv1, &m1);\n++count;\nsignal(&cv1);\nunlock(&m1);\n```\n\nConsumer:\n```c\nlock(&m1);\nwhile (count == 0)\n    wait(&cv1, &m1);\nbaDuBop();\n--count;\nsignal(&cv1);\nunlock(&m1);\n```", "options": ["א. כאשר צרכן מסיים לצרוך פריט ושולח סיגנל, ייתכן שיצרן יתעורר בטעות במקום יצרן אחר, למרות שהמחסן עדיין מלא.", "ב. כאשר יצרן מסיים לייצר פריט ושולח סיגנל, ייתכן שיצרן יתעורר בטעות במקום צרכן, מה שמונע צריכה של הפריט שנוצר.", "ג. כאשר צרכן מסיים לצרוך פריט ושולח סיגנל, ייתכן שצרכן אחר יתעורר בטעות במקום יצרן, למרות שהמחסן התפנה ויש מקום לייצור נוסף.", "ד. כאשר יצרן מסיים לייצר פריט ושולח סיגנל, ייתכן שצרכן יתעורר בטעות במקום יצרן, למרות שהמחסן אינו מלא."]}, "solution": {"correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. במימוש בעיית היצרן-צרכן עם משתנה תנאי יחיד (`cv1`), כאשר יצרן מסיים לייצר פריט, הוא שולח סיגנל (`signal(&cv1)`) כדי להודיע שיש פריט חדש לצריכה. המטרה היא להעיר צרכן שייתכן שממתין. עם זאת, מכיוון שגם יצרנים וגם צרכנים ממתינים על אותו משתנה תנאי (`cv1`), מערכת ההפעלה אינה מבחינה בין סוגי החוטים. לכן, ייתכן שחוט יצרן אחר (שממתין כי המחסן היה מלא בעבר, או מסיבה אחרת) יתעורר במקום צרכן. אם יצרן מתעורר אך אינו יכול להמשיך (למשל, כי המחסן שוב מלא), ואין צרכן שמתעורר כדי לרוקן את המחסן, ייווצר מצב של קיפאון שבו יצרנים חסומים כי המחסן מלא וצרכנים חסומים כי אין פריטים, אך אף אחד לא מתקדם. מצב זה מתואר במפורש בחומר ההרצאה: \"כאשר עושים signal ל-cv1, ייתכן ואנחנו רוצים להעיר צרכן אבל במקום זאת בטעות יצרן שמחכה לסיגנל יתעורר.\""}, "_source_file": "0248__Concurrency__Producer-Consumer__MC__Medium.json", "_topic_hint": "Producer-Consumer", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:54:22", "_subject": "Concurrency", "_context_lectures": [14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Producer-Consumer"], "difficulty_estimation": "Medium", "content": {"text": "בפתרון בעיית היצרן-צרכן (bounded buffer) באמצעות משתני תנאי (condition variables), מדוע שימוש במשתנה תנאי יחיד (לדוגמה, `cv1`) עלול להוביל למצב של קיפאון (deadlock)?", "code_snippet": "Producer:\n```c\nlock(&m1);\nmmmBop();\nwhile (count < MAX)\n    wait(&cv1, &m1);\n++count;\nsignal(&cv1);\nunlock(&m1);\n```\n\nConsumer:\n```c\nlock(&m1);\nwhile (count == 0)\n    wait(&cv1, &m1);\nbaDuBop();\n--count;\nsignal(&cv1);\nunlock(&m1);\n```", "options": ["א. מכיוון ש-`signal(&cv1)` מעיר חוט באופן אקראי, וייתכן שיצרן ינסה להעיר צרכן, אך במקום זאת יתעורר יצרן אחר שכבר חסום (או להיפך), מה שמונע התקדמות.", "ב. מכיוון ש-`wait()` עם משתנה תנאי יחיד אינו משחרר את המנעול, ובכך חוסם גישה של חוטים אחרים.", "ג. מכיוון שהמונה `count` אינו מעודכן באופן אטומי כאשר משתמשים במשתנה תנאי יחיד, מה שגורם לחוסר עקביות בנתונים.", "ד. מכיוון שקריאות ל-`signal()` אינן נשמרות בתור, ולכן אם אין חוטים ממתינים, הסיגנל אובד."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. כפי שמוסבר בחומר ההרצאה (Lecture 14, chunk 11), כאשר משתמשים במשתנה תנאי יחיד (`cv1`) לניהול הן של מצב \"מאגר ריק\" והן של מצב \"מאגר מלא\", קריאה ל-`signal(&cv1)` מעירה חוט אחד מתוך כלל החוטים הממתינים על `cv1`. הבעיה היא שהמערכת אינה מבחינה האם החוט שהתעורר הוא יצרן או צרכן. לדוגמה, אם צרכן מסיים לצרוך פריט ומשחרר מקום במאגר, הוא אמור להעיר יצרן. אך אם במקרה ישנם רק צרכנים הממתינים על `cv1` (כי המאגר היה ריק), הסיגנל עלול להעיר צרכן אחר שעדיין אינו יכול להתקדם (כי המאגר עדיין ריק או כבר רוקן), בעוד שהיצרנים ממתינים על `cv1` למקרה שהמאגר יהיה מלא. במצב כזה, יצרנים יכולים להיות חסומים (כי הם חושבים שהמאגר מלא ואין מקום) וצרכנים יכולים להיות חסומים (כי הם חושבים שהמאגר ריק ואין פריטים), מה שמוביל לקיפאון כפי שמודגם ב-Lecture 14, chunk 12: \"Deadlock\". הפתרון הנכון הוא להשתמש בשני משתני תנאי נפרדים: `full` עבור יצרנים ו-`empty` עבור צרכנים, כפי שמוצג ב-Lecture 14, chunk 14."}, "_source_file": "0249__Concurrency__Producer-Consumer__MC__Medium.json", "_topic_hint": "Producer-Consumer", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:54:37", "_subject": "Concurrency", "_context_lectures": [14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Producer-Consumer"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על מימוש בעיית היצרן-צרכן עם משתנה תנאי יחיד (cv1) כפי שמוצג, ובהתחשב בתרחיש הקיפאון המתואר בהרצאה (1: consumer -> count==0 -> wait, 2: consumer -> count==0 -> wait, 3: producer -> produces, signal -> consumer 1, 4: producer -> count==MAX -> wait, 5: consumer -> consumes item, signal -> consumer 2, 1 & 2 -> count==0, wait Deadlock), מהי הסיבה העיקרית לקיפאון במצב זה?", "code_snippet": "Producer:\n```c\nlock(&m1);\nmmmBop();\nwhile (count < MAX)\n    wait(&cv1, &m1);\n++count;\nsignal(&cv1);\nunlock(&m1);\n```\n\nConsumer:\n```c\nlock(&m1);\nwhile (count == 0)\n    wait(&cv1, &m1);\nbaDuBop();\n--count;\nsignal(&cv1);\nunlock(&m1);\n```", "options": ["א. שליחת סיגנל (signal) למשתנה התנאי cv1 אינה מבחינה בין יצרנים לצרכנים הממתינים, מה שעלול להעיר חוט שאינו יכול להמשיך (לדוגמה, יצרן מתעורר כשהמחסן מלא, או צרכן מתעורר כשהמחסן ריק), ובכך למנוע התקדמות של חוטים אחרים.", "ב. המנעול (m1) אינו משוחרר לפני ביצוע פעולת ה-wait, מה שמוביל לכך שחוטים אחרים אינם יכולים להיכנס לאזור הקריטי.", "ג. מספר הפריטים במחסן (count) אינו מוגן כראוי על ידי המנעול, מה שמאפשר תנאי מרוץ (race conditions) ומספרים שגויים.", "ד. אין מספיק חוטי יצרן או צרכן פעילים כדי למנוע מצב של קיפאון, ונדרשת אסטרטגיה של ניהול תורים מורכבת יותר."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. הבעיה המרכזית בשימוש במשתנה תנאי יחיד (cv1) עבור יצרנים וצרכנים היא שפעולת ה-signal(&cv1) אינה ספציפית. כאשר יצרן מוסיף פריט ושולח סיגנל, הוא עלול להעיר יצרן אחר הממתין על cv1 (במחשבה שהמחסן מלא), במקום צרכן. באופן דומה, כאשר צרכן צורך פריט ושולח סיגנל, הוא עלול להעיר צרכן אחר הממתין על cv1 (במחשבה שהמחסן ריק), במקום יצרן. בתרחיש הקיפאון המתואר בהרצאה, יצרנים עלולים לחכות שמקום יתפנה (כי count הגיע ל-MAX), וצרכנים עלולים לחכות לפריטים (כי count הגיע ל-0). אם סיגנל מעיר את הסוג הלא נכון של חוט (למשל, יצרן מעיר יצרן אחר כשהמחסן מלא), הוא לא פותר את החסימה, וכל החוטים יכולים להישאר במצב המתנה אינסופי. כפי שמוזכר בהרצאה: \"כאשר עושים signal ל-cv1, ייתכן ואנחנו רוצים להעיר צרכן אבל במקום זאת בטעות יצרן שמחכה לסיגנל יתעורר.\" הפתרון הנכון, כפי שמוצג בהרצאה, הוא שימוש בשני משתני תנאי נפרדים: empty עבור צרכנים הממתינים לפריטים (ושיצרנים שולחים להם סיגנל), ו-full עבור יצרנים הממתינים למקום פנוי (ושרכנים שולחים להם סיגנל)."}, "_source_file": "0250__Concurrency__Producer-Consumer__MC__Hard.json", "_topic_hint": "Producer-Consumer", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:54:53", "_subject": "Concurrency", "_context_lectures": [14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Producer-Consumer"], "difficulty_estimation": "Hard", "content": {"text": "בהינתן מימוש בעיית היצרן-צרכן הבא, המשתמש במשתנה תנאי יחיד (`cv1`) עבור שתי הפעולות של יצרנים וצרכנים:\n\nאיזו מהטענות הבאות מתארת בצורה הטובה ביותר את הבעיה העיקרית של מימוש זה, שעלולה להוביל למצב קיפאון (deadlock)?", "code_snippet": "Producer:\n```c\nlock(&m1);\nmmmBop();\nwhile (count < MAX)\n    wait(&cv1, &m1);\n++count;\nsignal(&cv1);\nunlock(&m1);\n```\n\nConsumer:\n```c\nlock(&m1);\nwhile (count == 0)\n    wait(&cv1, &m1);\nbaDuBop();\n--count;\nsignal(&cv1);\nunlock(&m1);\n```", "options": ["א. שימוש במשתנה תנאי יחיד (`cv1`) עבור יצרנים וצרכנים כאחד עלול לגרום לכך שפעולת `signal` תעיר חוט מהסוג הלא נכון (לדוגמה, יצרן יתעורר במקום צרכן), ובכך למנוע התקדמות של המערכת ולהוביל לקיפאון.", "ב. הפעולה `mmmBop()` או `baDuBop()` אינה מוגנת באמצעות מנעול, מה שעלול לגרום לתנאי מרוץ (race condition) בגישה למשאבים משותפים.", "ג. לולאת `while` בבדיקת התנאים (לדוגמה, `while (count == 0)`) אינה נחוצה, ודי בבדיקת `if` יחידה, מה שמוביל לבדיקות מיותרות ולפגיעה בביצועים.", "ד. המשתנה `MAX` אינו מוגדר כ-`volatile`, ועלול לגרום לקומפיילר לבצע אופטימיזציות שגויות המשפיעות על נכונות בדיקת גודל המאגר."]}, "solution": {"correct_option": "א", "explanation": "הבעיה המרכזית במימוש המוצג, כפי שמתואר בחומר ההרצאה (Lecture 14, chunk 11), היא השימוש במשתנה תנאי יחיד (`cv1`) הן עבור יצרנים והן עבור צרכנים. כאשר מתבצעת פעולת `signal(&cv1)`, המערכת מעירה חוט אקראי מבין כל החוטים הממתינים על משתנה תנאי זה. הבעיה היא שייתכן וחוט מהסוג הלא נכון יתעורר – לדוגמה, יצרן הממתין על `cv1` עלול להתעורר כאשר צרכן מסיים לצרוך פריט ומשחרר מקום, אף על פי שהכוונה הייתה להעיר יצרן שחיכה למקום פנוי. או לחלופין, צרכן עלול להתעורר כאשר יצרן מוסיף פריט, אך במקום זאת יצרן אחר יתעורר בטעות. מצב זה, של העוררות שגויה, עלול להוביל לכך שחוטים נשארים במצב המתנה אף על פי שהתנאי עבורם התקיים, או שחוטים מתעוררים ללא סיבה רלוונטית, ובכך ליצור מצב קיפאון (deadlock) בו המערכת כולה נתקעת, כפי שמוצג בדוגמת הדדלוק בחומר ההרצאה.\n\nאפשרויות ב', ג' ו-ד' אינן מתארות את הבעיה העיקרית הספציפית לשימוש במשתנה תנאי יחיד: אפשרות ב' אינה נכונה מכיוון שהפעולות `mmmBop()` ו-`baDuBop()` נמצאות בתוך בלוק נעול (`lock(&m1)`), כך שהן מוגנות. אפשרות ג' אינה נכונה מכיוון שלולאת `while` הכרחית בשימוש עם `wait` של משתני תנאי, שכן חוטים עלולים להתעורר באופן שגוי (spurious wakeups) או שהתנאי לא יהיה תקף עוד כאשר החוט יתעורר. אפשרות ד' מתייחסת לפרט מימוש שאינו קשור לבעיה הספציפית של משתנה התנאי היחיד ולא נדונה בחומר ההרצאה."}, "_source_file": "0251__Concurrency__Producer-Consumer__MC__Hard.json", "_topic_hint": "Producer-Consumer", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:55:16", "_subject": "Concurrency", "_context_lectures": [14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Producer-Consumer"], "difficulty_estimation": "Hard", "content": {"text": "בהתייחס לבעיית היצרן-צרכן (Producer-Consumer) עם מאגר חסום (Bounded Buffer), נתבונן במימוש הבא המשתמש במשתנה תנאי יחיד (cv1):\n\n```c\n// קוד היצרן (Producer)\nlock(&m1);\nmmmBop(); // פעולת ייצור\nwhile (count < MAX)\n    wait(&cv1, &m1);\n++count;\nsignal(&cv1);\nunlock(&m1);\n\n// קוד הצרכן (Consumer)\nlock(&m1);\nwhile (count == 0)\n    wait(&cv1, &m1);\nbaDuBop(); // פעולת צריכה\n--count;\nsignal(&cv1);\nunlock(&m1);\n```\n\nמדוע מימוש זה עלול להוביל לקיפאון (deadlock) או לחוסר יעילות, וכיצד השימוש בשני משתני תנאי נפרדים (empty ו-full) פותר בעיה זו, כפי שמוצע בחומר ההרצאה?", "code_snippet": "// קוד היצרן (Producer)\nlock(&m1);\nmmmBop(); // פעולת ייצור\nwhile (count < MAX)\n    wait(&cv1, &m1);\n++count;\nsignal(&cv1);\nunlock(&m1);\n\n// קוד הצרכן (Consumer)\nlock(&m1);\nwhile (count == 0)\n    wait(&cv1, &m1);\nbaDuBop(); // פעולת צריכה\n--count;\nsignal(&cv1);\nunlock(&m1);", "options": ["א. המימוש עם cv1 עלול לגרום לקיפאון מכיוון ש-signal(&cv1) עלול להעיר יצרן כאשר המאגר מלא וצרכן נחוץ, או להעיר צרכן כאשר המאגר ריק ויצרן נחוץ. empty ו-full פותרים זאת על ידי הבטחה שרק חוטים מהסוג הנכון (יצרנים או צרכנים) יתעוררו כאשר התנאי המתאים מתקיים.", "ב. המימוש עם cv1 אינו מבטיח שהמונה (count) יישאר בטווח חוקי (0 עד MAX), מה שמוביל לגישה לא חוקית לזיכרון. empty ו-full פותרים זאת על ידי אכיפת גבולות המאגר באופן מפורש.", "ג. המימוש עם cv1 גורם לקיפאון כי הוא אינו משתמש במנעול (mutex) כדי להגן על הגישה למונה (count), ובכך מאפשר מצבי מרוץ (race conditions). empty ו-full פועלים רק בשילוב עם מנעול, ולכן פותרים את בעיית ה-race conditions.", "ד. המימוש עם cv1 אינו מאפשר ליותר מיצרן או צרכן יחיד לפעול בו-זמנית, מה שפוגע במקביליות. empty ו-full מאפשרים למספר יצרנים וצרכנים לפעול במקביל ללא בעיות."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר ההרצאה מציין במפורש כי במימוש עם משתנה תנאי יחיד (כמו cv1), \"כאשר עושים signal ל-cv1, ייתכן ואנחנו רוצים להעיר צרכן אבל במקום זאת בטעות יצרן שמחכה לסיגנל יתעורר\" (Lecture 14, chunk 11). מצב זה עלול להוביל לקיפאון או לחוסר יעילות, שכן חוט מסוג לא רלוונטי מתעורר ומיד נחסם שוב (לדוגמה, יצרן מתעורר כשהמאגר עדיין מלא, או צרכן מתעורר כשהמאגר עדיין ריק), בעוד שהחוט הנחוץ (יצרן כשיש מקום פנוי, או צרכן כשיש פריט) נשאר רדום. הפתרון עם שני משתני תנאי נפרדים, empty ו-full, פותר בעיה זו על ידי יצירת ערוצי איתות ייעודיים: יצרנים ממתינים על full ומאותתים ל-empty, וצרכנים ממתינים על empty ומאותתים ל-full. בכך, מובטח ש-signal יופנה תמיד לחוטים מהסוג הנכון שבאמת יכולים להתקדם, כפי שמתואר ב-Lecture 14, chunk 14.\n\nאפשרויות ב', ג' ו-ד' שגויות: ב' שגויה מכיוון ששני המימושים משתמשים בלולאות while ו-wait כדי לאכוף את גבולות המאגר. ג' שגויה כי שני המימושים משתמשים במנעול (lock/unlock(&m1)) כדי להגן על הגישה למונה ולמנוע מצבי מרוץ. ד' שגויה כי השימוש במנעול יחיד מונע מיותר מחוט אחד להיות בתוך האזור הקריטי בכל רגע נתון, והבעיה אינה קשורה למקביליות בתוך האזור הקריטי אלא לתזמון נכון של התעוררות חוטים."}, "_source_file": "0252__Concurrency__Producer-Consumer__MC__Hard.json", "_topic_hint": "Producer-Consumer", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:55:42", "_subject": "Concurrency", "_context_lectures": [14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Semaphores"], "difficulty_estimation": "Easy", "content": {"text": "מהו הערך ההתחלתי שצריך להגדיר לסמפור בינארי על מנת שישמש כמנגנון למניעה הדדית (mutual exclusion)?", "code_snippet": "sem_t semlock;\nsem_init(&semlock, 0, init_value);", "options": ["א. 0", "ב. 1", "ג. כל מספר חיובי", "ד. תלוי במספר התהליכים המשתמשים בסמפור"]}, "solution": {"correct_option": "ב", "explanation": "החומר המצורף מציין במפורש כי סמפור בינארי, המשמש כמנעול למניעה הדדית, צריך להיות מאותחל לערך 1. כפי שצויין: \"התשובה: 1. קודם כל, ה-semaphore הזה נקרא binary semaphore - סמפור בינארי – זה מנעול והערך שלו יכול להיות רק 1 או 0. אנחנו נותנים את הסמפור להיות 1.\" ערך 1 מסמן שהמנעול פנוי, וחוט שקורא ל-wait יקטין אותו ל-0 וייכנס לקטע הקריטי, וחוטים אחרים ימתינו. לאחר מכן, ה-post יחזיר את הערך ל-1 וישחרר את המנעול."}, "_source_file": "0253__Concurrency__Semaphores__MC__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:55:50", "_subject": "Concurrency", "_context_lectures": [10, 14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Semaphores"], "difficulty_estimation": "Easy", "content": {"text": "מהו הערך ההתחלתי הנכון שיש להגדיר לסמפור בינארי (binary semaphore) על מנת שישמש כמנעול רגיל (mutual exclusion) לקטע קריטי?", "code_snippet": "init(&semlock, ?);\n// ...\nwait(&semlock);\n// critical section\npost(&semlock);", "options": ["א. 0", "ב. 1", "ג. -1", "ד. כל ערך חיובי גדול מ-0"]}, "solution": {"correct_option": "ב", "explanation": "סמפור בינארי (binary semaphore) משמש כמנעול רגיל (mutual exclusion) והערך שלו יכול להיות רק 1 או 0. על מנת שהמנעול יהיה פנוי בתחילה ויאפשר לחוט הראשון להיכנס לקטע הקריטי, יש לאתחל את הסמפור לערך 1. כאשר חוט קורא לפעולת wait, ערך הסמפור קטן ב-1 (הופך ל-0), והחוט נכנס לקטע הקריטי. כל חוט שינסה להיכנס לאחר מכן ימתין, מכיוון שערך הסמפור הוא 0. לאחר שהחוט מסיים את הקטע הקריטי, הוא קורא לפעולת post, אשר מעלה את ערך הסמפור ב-1 (הופך ל-1) ומאפשר לחוטים ממתינים להיכנס."}, "_source_file": "0254__Concurrency__Semaphores__MC__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:55:57", "_subject": "Concurrency", "_context_lectures": [10, 14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Semaphores"], "difficulty_estimation": "Easy", "content": {"text": "מה מציין סמפור בינארי שערכו 1?", "code_snippet": null, "options": ["א. המנעול פנוי וניתן להיכנס לקטע הקריטי.", "ב. המנעול תפוס ולא ניתן להיכנס לקטע הקריטי.", "ג. ישנם שני חוטים הממתינים להיכנס לקטע הקריטי.", "ד. הסמפור משמש לויסות כמות החוטים ולא למניעה הדדית."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, סמפור בינארי שערכו 1 מייצג שהמנעול פנוי. כאשר המנעול פנוי, חוט יכול לבצע פעולת wait, להקטין את ערך הסמפור ל-0, ולהיכנס לקטע הקריטי. כאשר ערך הסמפור הוא 0, המנעול תפוס."}, "_source_file": "0255__Concurrency__Semaphores__MC__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:56:04", "_subject": "Concurrency", "_context_lectures": [10, 14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Semaphores"], "difficulty_estimation": "Medium", "content": {"text": "על פי חומר ההרצאה, איזה שימוש בסמפורים, שאינו נובע בהכרח מסיבות סנכרון של קטע קריטי (mutual exclusion), מתואר כאפשרות לניהול משאבים?", "code_snippet": "sem_t throttle_sem;\nsem_init(&throttle_sem, 0, MAX_THREADS_ALLOWED);\n// ...\nsem_wait(&throttle_sem);\n// קטע קוד המשתמש במשאבים מוגבלים (למשל, מקצה זיכרון רב)\nsem_post(&throttle_sem);\n// ...", "options": ["א. הגבלת מספר החוטים שיכולים לבצע קטע קוד מסוים בו-זמנית, למשל עקב מגבלות זיכרון.", "ב. הבטחת גישה בלעדית למשאב משותף יחיד על מנת למנוע תנאי מרוץ (race conditions).", "ג. איתור ופתרון באגים לא דטרמיניסטיים בקוד מקבילי על ידי הוספת פקודות סנכרון.", "ד. יצירת עותקים נפרדים של סמפורים עבור תהליכים שונים לאחר קריאה ל-fork()."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מתאר שימוש בסמפורים ל'THREAD THROTTLING' (הגבלת חוטים). מודגש כי שימוש זה אינו בהכרח לצורך סנכרון קטע קריטי, אלא למשל, להגבלת מספר החוטים המקצים זיכרון רב במקביל, כדי למנוע חריגה ממשאבי הזיכרון הזמינים. הסמפור מאותחל למספר המקסימלי של חוטים מותרים, וכל חוט מבצע `wait` לפני הכניסה לקטע הקוד ו-`post` ביציאה ממנו.\n\nאפשרות ב' מתארת שימוש בסמפור בינארי למניעה הדדית (mutual exclusion), שזו אכן פונקציה חשובה של סמפורים, אך השאלה מבקשת שימוש שאינו נובע בהכרח מסיבות סנכרון של קטע קריטי.\n\nאפשרות ג' מתייחסת לכך שפעולות סנכרון (כמו הדפסות) יכולות לשנות את התנהגות הקוד המקבילי, אך אינה מתארת שימוש ישיר בסמפורים ככלי לאיתור באגים.\n\nאפשרות ד' שגויה, שכן חומר ההרצאה מציין במפורש כי לאחר קריאה ל-`fork()`, הסמפור אינו משוכפל אלא נשאר אותו סמפור בזיכרון משותף, וניתן להשתמש בו לסנכרון בין תהליכים."}, "_source_file": "0256__Concurrency__Semaphores__MC__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:56:19", "_subject": "Concurrency", "_context_lectures": [10, 14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Semaphores"], "difficulty_estimation": "Medium", "content": {"text": "בשימוש בסמפורים לצורך הגבלת כמות החוטים הרצים במקביל בקטע קוד מסוים (Thread Throttling), מסיבות של משאבי מערכת מוגבלים (לדוגמה, זיכרון), כיצד יש לאתחל את הסמפור ומהי מטרת פעולות ה-`sem_wait` וה-`sem_post` בהקשר זה?", "code_snippet": "sem_t throttle_sem;\nsem_init(&throttle_sem, 0, max_concurrent_threads);\n// ...\n// Before entering resource-intensive section\nsem_wait(&throttle_sem);\n// ... resource-intensive code ...\n// After exiting resource-intensive section\nsem_post(&throttle_sem);", "options": ["א. יש לאתחל את הסמפור לערך המייצג את מספר החוטים המקסימלי המותרים במקביל. פעולת `sem_wait` מקטינה את ערך הסמפור ו'תופסת' מקום לחוט להיכנס לקטע הקוד, ופעולת `sem_post` מגדילה את ערך הסמפור ומשחררת 'מקום' לחוט אחר.", "ב. יש לאתחל את הסמפור ל-1, בדומה לסמפור בינארי. פעולת `sem_wait` מבטיחה מניעה הדדית בקטע הקוד, ופעולת `sem_post` משחררת את המנעול.", "ג. יש לאתחל את הסמפור ל-0. פעולת `sem_wait` ממתינה עד שחוט אחר יבצע `sem_post` כדי לאפשר המשך, ופעולת `sem_post` מאפשרת לחוט הבא להיכנס מיד.", "ד. אין צורך לאתחל את הסמפור לערך ספציפי, מכיוון שמערכת ההפעלה מטפלת בכך אוטומטית. `sem_wait` ו-`sem_post` משמשות רק לסנכרון לוגי ואינן קשורות להגבלת משאבים פיזיים."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין בשיעור קובע במפורש כי בשימוש בסמפורים להגבלת כמות החוטים בקטע קוד מסוים (Thread Throttling) מסיבות של משאבי מערכת מוגבלים (כגון זיכרון), יש לאתחל את הסמפור ל'כמות המקסימלית שאנחנו רוצים להחזיק במקביל'. כל חוט לפני כניסתו לקטע הקוד מבצע `sem_wait` (מקטין את ערך הסמפור ותופס 'מקום'), וכשהוא מסיים, הוא מבצע `sem_post` (מגדיל את ערך הסמפור ומשחרר 'מקום'). כך, מספר החוטים המקסימלי המורשים בקטע הקוד נשמר על פי ערך האתחול של הסמפור. אפשרות ב' מתארת שימוש בסמפור בינארי למניעה הדדית, אפשרות ג' מתארת אתחול שגוי ופעולות שגויות בהקשר זה, ואפשרות ד' שגויה לחלוטין לגבי הצורך באתחול וייעוד הסמפורים."}, "_source_file": "0257__Concurrency__Semaphores__MC__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:56:35", "_subject": "Concurrency", "_context_lectures": [10, 14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Semaphores"], "difficulty_estimation": "Medium", "content": {"text": "מהו הערך ההתחלתי (init_value) המתאים לסמפור (sem_t) בשני התרחישים הבאים, בהתאמה?\n1. כאשר הוא משמש כמנעול בינארי (binary semaphore) להבטחת מניעה הדדית (mutual exclusion) לקטע קריטי.\n2. כאשר הוא משמש להגבלת מספר החוטים המקסימלי שיכולים להיכנס לקטע קוד מסוים (thread throttling) עקב מגבלות משאבים.", "code_snippet": "```c\n#include <semaphore.h>\nsem_t s;\nsem_init(&s, 0, init_value);\n// ...\nsem_wait(&s);\n// קטע קוד רלוונטי\nsem_post(&s);\n```", "options": ["א. (1) 1, (2) מספר החוטים המקסימלי המותר.", "ב. (1) 0, (2) 1.", "ג. (1) 1, (2) 0.", "ד. (1) מספר החוטים המקסימלי המותר, (2) 1."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה:\n1.  כאשר סמפור משמש כמנעול בינארי (binary semaphore) להבטחת מניעה הדדית (mutual exclusion), ערכו ההתחלתי צריך להיות 1. ערך זה מאפשר לחוט אחד לתפוס את המנעול (פעולת wait) ולהיכנס לקטע הקריטי, תוך הקטנת ערך הסמפור ל-0. כל חוט נוסף שינסה להיכנס ימתין עד שהחוט הנוכחי ישחרר את המנעול (פעולת post) ויעלה את ערך הסמפור חזרה ל-1.\n2.  כאשר סמפור משמש להגבלת כמות החוטים המורשים להיכנס לקטע קוד מסוים (thread throttling) עקב מגבלות משאבים, ערכו ההתחלתי צריך להיות שווה למספר החוטים המקסימלי שאנחנו רוצים לאפשר שירוצו במקביל. כל חוט מבצע פעולת wait לפני הכניסה לקטע הקוד ופעולת post לאחר היציאה ממנו, ובכך הסמפור מווסת את הגישה כך שלא יעלה על הכמות המקסימלית שהוגדרה."}, "_source_file": "0258__Concurrency__Semaphores__MC__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:56:49", "_subject": "Concurrency", "_context_lectures": [10, 14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Semaphores"], "difficulty_estimation": "Hard", "content": {"text": "בהתחשב בשימושים השונים של סמפורים כפי שתוארו בחומר הלימוד, מהי ההשפעה המיידית הנכונה ביותר של אתחול סמפור עם ערך התחלתי של 0 (כפי שמוצג בדוגמת הקוד)?", "code_snippet": "sem_t s;\nsem_init(&s, 0, 0); // init_value = 0\n// ... later in code ...\nsem_wait(&s);\n// critical or throttled section\nsem_post(&s);", "options": ["א. אם הסמפור נועד לספק מניעה הדדית (mutual exclusion), אתחול ל-0 יבטיח שחוט אחד בלבד יוכל להיכנס לקטע הקריטי באופן מיידי.", "ב. כאשר הסמפור משמש להגבלת כמות חוטים במקטע קוד (thread throttling), אתחול ל-0 יאפשר לכל החוטים להיכנס מיד ללא הגבלה.", "ג. אתחול סמפור ל-0, בין אם הוא משמש למניעה הדדית או להגבלת כמות חוטים, יגרום לכך שכל חוט שינסה לבצע פעולת sem_wait ימתין עד שיתבצע sem_post.", "ד. אתחול ל-0 מיועד למקרים בהם יש צורך לאפשר לחוטים לצאת מקטע קוד מסוים אך לא להיכנס אליו."]}, "solution": {"correct_option": "ג", "explanation": "החומר מתאר שני שימושים עיקריים לסמפורים: מניעה הדדית (כמו מנעול בינארי) והגבלת כמות חוטים (thread throttling).\n1.  **סמפור בינארי למניעה הדדית:** החומר מציין שאם סמפור בינארי משמש כמנעול, הוא מאותחל לערך 1. לאחר פעולת `sem_wait`, ערכו יורד ל-0, וכל חוט נוסף שינסה לבצע `sem_wait` ימתין כי הערך הוא 0. מכאן, אם הסמפור מאותחל מלכתחילה ל-0, משמעות הדבר היא שהמנעול \"תפוס\" וכל חוט שיבצע `sem_wait` ימתין מיד.\n2.  **סמפור להגבלת כמות חוטים:** החומר מסביר שיש לאתחל את הסמפור \"לכמות המקסימלית שאנחנו רוצים להחזיק במקביל\". אם כמות מקסימלית זו היא 0, הרי שאין מקומות פנויים, וכל חוט שינסה לבצע `sem_wait` כדי \"לקחת את המשאב הזה\" ימתין עד שמשאב כזה יהיה זמין (כלומר, עד שיתבצע `sem_post` שיעלה את ערך הסמפור).\n\nלכן, בשני המקרים, אתחול סמפור ל-0 גורם לכך שפעולת `sem_wait` תחסום את החוט המבצע אותה עד שיתבצע `sem_post` שיעלה את ערך הסמפור מעל 0.\n\n*   א. שגויה, אתחול ל-0 לא מאפשר כניסה מיידית; דווקא אתחול ל-1 מאפשר זאת, כפי שמתואר בחומר עבור סמפור בינארי.\n*   ב. שגויה, אתחול ל-0 מגביל את הכניסה ל-0 חוטים, כלומר חוסם את כולם, בניגוד ל\"ללא הגבלה\".\n*   ד. שגויה, סמפורים שולטים בכניסה (באמצעות `sem_wait`) וביציאה/שחרור משאב (באמצעות `sem_post`), ולא רק ביציאה ללא כניסה."}, "_source_file": "0259__Concurrency__Semaphores__MC__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:57:10", "_subject": "Concurrency", "_context_lectures": [10, 14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Semaphores"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על השימוש בסמפורים לצורך \"ויסות חוטים\" (Thread Throttling), כפי שתואר בחומר הלימוד, מהו הערך ההתחלתי המתאים לסמפור ומהי מטרתו העיקרית במקרה זה?", "code_snippet": "sem_t s;\nsem_init(&s, 0, init_value);\n...\nsem_wait(&s);\n// קטע קוד המשתמש במשאבים מוגבלים\nsem_post(&s);\n...", "options": ["א. הערך ההתחלתי צריך להיות 1, ומטרתו העיקרית היא להבטיח מניעה הדדית (mutual exclusion) לקטע הקוד המוגבל במשאבים.", "ב. הערך ההתחלתי צריך להיות כמספר החוטים המקסימלי המותרים במקביל, ומטרתו העיקרית היא להגביל את כמות החוטים המבצעים קטע קוד מסוים (למשל, עקב מגבלות זיכרון), ולא בהכרח לצורך סנכרון קטע קריטי.", "ג. הערך ההתחלתי צריך להיות 0, ומטרתו העיקרית היא לאותת לחוטים אחרים כאשר המשאבים מתפנים, ובכך למנוע מצב של הרעבה (starvation).", "ד. הערך ההתחלתי יכול להיות כל מספר חיובי גדול מ-1, ומטרתו העיקרית היא למנוע קיפאון (deadlock) בין חוטים המתחרים על משאבים."]}, "solution": {"correct_option": "ב", "explanation": "בחומר הלימוד, הוסבר כי שימוש נוסף לסמפורים הוא 'ויסות חוטים' (Thread Throttling). במקרה זה, מטרת הסמפור אינה בהכרח סנכרון קטע קריטי (מניעה הדדית), אלא הגבלת כמות החוטים שיכולים לבצע קטע קוד מסוים בו-זמנית, למשל עקב מגבלות על משאבים כמו זיכרון. לשם כך, מאתחלים את הסמפור לכמות המקסימלית של החוטים שאנו רוצים לאפשר שיפעלו במקביל. כל חוט מבצע `sem_wait()` לפני הכניסה לקטע הקוד המוגבל במשאבים ו-`sem_post()` לאחר מכן. פעולה זו מבטיחה שלא יעלה מספר החוטים המוגדר על ידי הערך ההתחלתי, ובכך מוגבל העומס על המשאבים. אפשרות א' מתארת שימוש בסמפור בינארי למניעה הדדית, שאינו המטרה העיקרית ב-Thread Throttling. אפשרות ג' אינה נכונה מכיוון שערך התחלתי של 0 יחסום את כל החוטים בתחילה. אפשרות ד' אינה מדויקת לגבי הערך ההתחלתי הספציפי והמטרה העיקרית בתיאור זה היא הגבלת משאבים ולא מניעת קיפאון כללית."}, "_source_file": "0260__Concurrency__Semaphores__MC__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:57:23", "_subject": "Concurrency", "_context_lectures": [10, 14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Semaphores"], "difficulty_estimation": "Hard", "content": {"text": "מערכת הפעלה משתמשת בסמפורים בשני תרחישים שונים: \n1. הבטחת מניעה הדדית (mutual exclusion) עבור קטע קריטי.\n2. הגבלת מספר התהליכים (throttling) שיכולים להקצות משאב יקר (לדוגמה, זיכרון) באופן סימולטני למקסימום K תהליכים.\n\nאיזו קביעה נכונה לגבי הערך ההתחלתי של הסמפור בכל אחד מהתרחישים הללו ומהות השימוש בו?", "code_snippet": null, "options": ["א. עבור מניעה הדדית, הערך ההתחלתי הוא 1, והסמפור מייצג זמינות מנעול. עבור הגבלת משאבים, הערך ההתחלתי הוא K, והסמפור מייצג את מספר ה\"היתרים\" הנותרים לשימוש במשאב.", "ב. עבור מניעה הדדית, הערך ההתחלתי הוא 0, והסמפור מייצג את מספר התהליכים הממתינים. עבור הגבלת משאבים, הערך ההתחלתי הוא K, והסמפור מייצג את מספר התהליכים שכבר משתמשים במשאב.", "ג. בשני המקרים, הערך ההתחלתי הוא 1, אך עבור מניעה הדדית הוא מבטיח שרק תהליך אחד יכנס, ועבור הגבלת משאבים הוא מבטיח שרק תהליך אחד יקצה זיכרון.", "ד. עבור מניעה הדדית, הערך ההתחלתי הוא K, והסמפור מייצג את מספר הקטעים הקריטיים הזמינים. עבור הגבלת משאבים, הערך ההתחלתי הוא 1, והסמפור מייצג האם המשאב פנוי או תפוס."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'.\n\nעבור מניעה הדדית (mutual exclusion), הסמפור משמש כמנעול בינארי. לפי חומר ההרצאה (Lecture 14, chunk 21), \"אנחנו נותנים את הסמפור להיות 1\" כערך התחלתי. ערך 1 מסמל שהמנעול פנוי, וערך 0 מסמל שהוא תפוס. כל תהליך שמבקש להיכנס לקטע קריטי מבצע `sem_wait()`, שמקטינה את ערך הסמפור. אם הסמפור היה 1, הוא הופך ל-0 והתהליך נכנס. אם היה 0, התהליך ממתין. בסיום הקטע הקריטי, התהליך מבצע `sem_post()`, שמגדילה את ערך הסמפור ומסמנת שהמנעול שוחרר.\n\nעבור הגבלת מספר תהליכים (thread throttling) לצורך ניהול משאבים, הסמפור משמש כמונה המייצג את מספר המקומות הפנויים (או ההיתרים) לשימוש במשאב. לפי חומר ההרצאה (Lecture 14, chunk 34), \"נאתחל את הסמפור שלנו לכמות המקסימלית שאנחנו רוצים להחזיק במקביל\". כלומר, אם K הוא המספר המקסימלי של תהליכים שיכולים להשתמש במשאב בו זמנית, הערך ההתחלתי של הסמפור יהיה K. כל תהליך לפני שימוש במשאב מבצע `sem_wait()`, שמקטינה את המונה (תופס \"היתר\" אחד), ולאחר סיום השימוש מבצע `sem_post()`, שמגדילה את המונה (משחרר \"היתר\").\n\nהאפשרויות האחרות אינן נכונות:\nב. הערך ההתחלתי למניעה הדדית הוא 1, לא 0. כמו כן, הסמפור במקרה של הגבלת משאבים מייצג את היתרים זמינים, לא את מספר התהליכים שכבר משתמשים.\nג. הערך ההתחלתי להגבלת משאבים הוא K, לאו דווקא 1, אלא אם כן K=1.\nד. הערכים ההתחלתיים וההסברים הפוכים ולא מדויקים ביחס לשימושם הנכון."}, "_source_file": "0261__Concurrency__Semaphores__MC__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:57:39", "_subject": "Concurrency", "_context_lectures": [10, 14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Deadlocks"], "difficulty_estimation": "Easy", "content": {"text": "מהי המתנה מעגלית (circular wait) בהקשר של קיפאון (deadlock)?", "code_snippet": "/*\n//Thread 1::\nlock(&L1);\nlock(&L2);\n\n//Thread 2::\nlock(&L2);\nlock(&L1);\n*/", "options": ["א. מצב בו חוטים שונים תופסים משאבים בסדר הפוך, כך שכל חוט ממתין למשאב שמוחזק על ידי חוט אחר במעגל.", "ב. מצב בו חוט אחד מנסה לתפוס את אותו מנעול פעמיים ברצף.", "ג. מצב בו חוטים מחכים למשאבים שאינם זמינים כלל במערכת.", "ד. מצב בו כל החוטים במערכת תקועים כתוצאה מכשל חומרה."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, המתנה מעגלית (circular wait) היא אחד מארבעת התנאים ההכרחיים לקיומו של קיפאון (deadlock). מצב זה מתאר מצב בו חוטים שונים תופסים משאבים (כמו מנעולים) בסדר הפוך. הדוגמה שניתנה בהרצאה ממחישה זאת: חוט 1 תופס את L1 ואז מנסה לתפוס את L2, בעוד שחוט 2 תופס את L2 ואז מנסה לתפוס את L1. במקרה זה, כל חוט ממתין למשאב שמוחזק על ידי חוט אחר במעגל, ונוצר קיפאון מכיוון שאף חוט לא יכול להתקדם ולשחרר את המשאבים שברשותו. שאר האפשרויות אינן תואמות את ההגדרה של המתנה מעגלית כפי שהוצגה בחומר."}, "_source_file": "0262__Concurrency__Deadlocks__MC__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:57:50", "_subject": "Concurrency", "_context_lectures": [16, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Deadlocks"], "difficulty_estimation": "Easy", "content": {"text": "איזה מהתיאורים הבאים מתאר בצורה הטובה ביותר את התנאי 'המתנה מעגלית' (circular wait), שהוא אחד מארבעת התנאים ההכרחיים לקיומו של קיפאון (deadlock)?", "code_snippet": "//Thread 1::\nlock(&L1);\nlock(&L2);\n\n//Thread 2::\nlock(&L2);\nlock(&L1);", "options": ["א. מצב שבו חוטים שונים תופסים משאבים (מנעולים) בסדר הפוך, וכל חוט ממתין למשאב שמוחזק על ידי חוט אחר במעגל.", "ב. מצב שבו חוט יחיד תופס את כל המשאבים הדרושים לו, אך אינו משחרר אותם לעולם.", "ג. מצב שבו המשאבים הדרושים לחוטים אינם זמינים כלל במערכת, ולכן אין אפשרות להתקדם.", "ד. מצב שבו מנעול בודד אינו מקיים את תכונת ה-deadlock freedom, ובכך גורם לקיפאון בשימוש בו."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א. לפי חומר ההרצאה (שיעור 15, קטע 5), 'המתנה מעגלית' (circular wait) מתוארת כמצב בו 'חוטים שונים תופסים משאבים בסדר הפוך'. הדוגמה בקוד המצורף ממחישה זאת היטב: חוט 1 תופס את L1 ואז רוצה את L2, בעוד חוט 2 תופס את L2 ואז רוצה את L1. מצב זה יוצר מעגל המתנה שבו כל חוט ממתין למשאב שמוחזק על ידי החוט הבא במעגל, מה שמונע מכל החוטים להתקדם.\n\nאפשרויות אחרות אינן נכונות:\nב. תיאור זה מתאר יותר מצב של הרעבה (starvation) או חוסר שחרור משאבים, ולא את התנאי הספציפי של 'המתנה מעגלית' או את תנאי הקיפאון כפי שהוגדרו.\nג. תיאור זה סותר את ההגדרה של קיפאון, לפיה 'כל המשאבים הדרושים זמינים להם' (שיעור 15, קטע 0), אך המערכת עדיין תקועה. בקיפאון, המשאבים קיימים אך אינם ניתנים לשימוש עקב סדר התפיסה שלהם.\nד. תיאור זה מתייחס למקרה של מנעול בודד שאינו מקיים deadlock freedom, כפי שנדון בשיעור 16 (קטע 28), אך אינו מתאר את התנאי 'המתנה מעגלית' שמתייחס בדרך כלל לאינטראקציה בין מספר מנעולים."}, "_source_file": "0263__Concurrency__Deadlocks__MC__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:58:01", "_subject": "Concurrency", "_context_lectures": [16, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Deadlocks"], "difficulty_estimation": "Easy", "content": {"text": "לפי חומר הקורס, כמה תנאים חייבים להתקיים כדי שיתרחש קיפאון (deadlock), וכמה תנאים מספיק למנוע כדי למנוע קיפאון?", "code_snippet": null, "options": ["א. כל ארבעת התנאים חייבים להתקיים; מספיק למנוע תנאי אחד.", "ב. כל ארבעת התנאים חייבים להתקיים; יש למנוע את כל ארבעת התנאים.", "ג. מספיק שתנאי אחד יתקיים; מספיק למנוע תנאי אחד.", "ד. מספיק שתנאי אחד יתקיים; יש למנוע את כל ארבעת התנאים."]}, "solution": {"correct_option": "א", "explanation": "חומר הקורס מציין במפורש: \"בשביל שיקרה קיפאון, אז כל ארבעת התנאים להתקיים.\" וגם \"בשביל למנוע קיפאון, מספיק למנוע תנאי אחד מבין הארבעה\". לכן, כדי שיתרחש קיפאון, כל ארבעת התנאים חייבים להתקיים. וכדי למנוע קיפאון, מספיק למנוע קיום של תנאי אחד מתוך הארבעה."}, "_source_file": "0264__Concurrency__Deadlocks__MC__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:58:10", "_subject": "Concurrency", "_context_lectures": [16, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Deadlocks"], "difficulty_estimation": "Medium", "content": {"text": "מהי הטענה הנכונה ביותר לגבי תכונת \"deadlock freedom\" של מנעולים, כפי שהוצגה בחומר הלימוד?", "code_snippet": null, "options": ["א. מנעול המקיים \"deadlock freedom\" מבטיח שלא יכול לקרות קיפאון בשימוש בו לבדו, אך תכונה זו אינה מבטיחה היעדר קיפאון כאשר משתמשים במספר מנעולים יחד.", "ב. \"deadlock freedom\" היא תנאי מוקדם הכרחי לקיומו של קיפאון, המתאר מצב של המתנה מעגלית בין חוטים שונים.", "ג. אם כל מנעול בנפרד במערכת מקיים \"deadlock freedom\", אזי המערכת כולה מובטחת להיות חופשית מקיפאון.", "ד. תכונת \"deadlock freedom\" מבטיחה שכל החוטים במערכת יתקדמו תמיד, ללא קשר לסדר תפיסת המשאבים."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר הלימוד מציין במפורש כי \"מנעול שכן מקיים זאת [deadlock freedom], מבטיח שלא יכול להיות deadlock בשימוש בו, אבל זה נכון רק עבור שימוש במנעול יחיד\". בנוסף, מודגש כי \"ל-deadlock אין תכונת הרכבה. כלומר אם ניקח שני מנעולים שבשניהם אין deadlocks ונשתמש בשניהם, זה לא מבטיח שלא יהיו לנו deadlocks\" (שיעור 15, קטע 0). \nאפשרות ב' שגויה מכיוון שהיא מתארת את תנאי \"circular wait\" (המתנה מעגלית), שהוא אחד מארבעת התנאים ההכרחיים לקיום קיפאון, ולא את תכונת \"deadlock freedom\" עצמה. \nאפשרות ג' שגויה מכיוון שהיא סותרת את העיקרון שלחופש מקיפאון \"אין תכונת הרכבה\" (no composition property).\nאפשרות ד' שגויה מכיוון ש\"deadlock freedom\" מתייחסת למנעול בודד ואינה מבטיחה התקדמות ללא קשר לסדר תפיסת המשאבים כאשר מדובר במספר מנעולים; סדר תפיסת המשאבים הוא קריטי ויכול להוביל לקיפאון (כפי שמוצג בדוגמת ה-circular wait)."}, "_source_file": "0265__Concurrency__Deadlocks__MC__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:58:27", "_subject": "Concurrency", "_context_lectures": [16, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Deadlocks"], "difficulty_estimation": "Medium", "content": {"text": "בהינתן קטע הקוד הבא, איזה מושג או תופעה הקטע מדגים בצורה הטובה ביותר בהקשר של קיפאון (deadlock)?", "code_snippet": "//Thread 1::\nlock(&L1);\nlock(&L2);\n\n//Thread 2::\nlock(&L2);\nlock(&L1);", "options": ["א. המתנה מעגלית (circular wait)", "ב. חוסר תכונת הרכבה של מנעולים (lack of composition property for locks)", "ג. אי-קיום \"deadlock freedom\" במנעול יחיד", "ד. באג כללי של מקביליות (general concurrency bug)"]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א. המתנה מעגלית (circular wait). קטע הקוד מדגים מצב קלאסי של המתנה מעגלית, שבו חוט 1 תופס את המנעול L1 ומנסה לתפוס את L2, בעוד חוט 2 תופס את המנעול L2 ומנסה לתפוס את L1. כפי שמתואר בחומר ההרצאה, 'המתנה מעגלית' היא מצב בו חוטים שונים תופסים משאבים בסדר הפוך, וזהו תנאי הכרחי לקיומו של קיפאון. במצב כזה, כל חוט מחכה למנעול שהחוט השני מחזיק בו, וכתוצאה מכך אף אחד מהם לא יכול להתקדם. האפשרויות האחרות אינן מתארות באופן מדויק את התופעה הספציפית המודגמת בקוד: חוסר תכונת הרכבה הוא מאפיין כללי יותר של מנעולים, אי-קיום deadlock freedom מתייחס למנעול יחיד בעוד כאן מדובר בשני מנעולים, ובאג כללי של מקביליות הוא תיאור כללי מדי."}, "_source_file": "0266__Concurrency__Deadlocks__MC__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:58:42", "_subject": "Concurrency", "_context_lectures": [16, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Deadlocks"], "difficulty_estimation": "Medium", "content": {"text": "בהתבסס על חומר ההרצאה והקוד המצורף, איזה מהתיאורים הבאים מתאר בצורה הטובה ביותר את תנאי ה-\"המתנה מעגלית\" (circular wait), שהוא אחד מארבעת התנאים ההכרחיים לקיומו של קיפאון (deadlock)?", "code_snippet": "//Thread 1::\nlock(&L1);\nlock(&L2);\n\n//Thread 2::\nlock(&L2);\nlock(&L1);", "options": ["א. מצב שבו חוטים שונים תופסים משאבים (מנעולים) בסדר הפוך, כך שכל חוט ממתין למשאב שמוחזק על ידי חוט אחר במעגל סגור.", "ב. מצב שבו חוט אחד תופס את כל המשאבים הנדרשים ומונע מכל החוטים האחרים להתקדם.", "ג. מצב שבו מספר חוטים מנסים לתפוס את אותו מנעול בו-זמנית, ורק אחד מהם מצליח בעוד האחרים נחסמים.", "ד. מצב שבו המערכת כולה לא יכולה להתקדם מכיוון שאין מספיק משאבים זמינים לכל החוטים הדרושים להם."]}, "solution": {"correct_option": "א", "explanation": "תנאי ה-\"המתנה מעגלית\" (circular wait) מתואר בחומר ההרצאה כ\"מצב בו חוטים שונים תופסים משאבים בסדר הפוך\". הדוגמה בקוד המצורף ממחישה זאת היטב: חוט 1 תופס את L1 ואז מנסה לתפוס את L2, בעוד שחוט 2 תופס את L2 ואז מנסה לתפוס את L1. אם כל אחד מהחוטים יתפוס את המנעול הראשון שלו וינסה לתפוס את השני, ייווצר מצב שבו חוט 1 ממתין ל-L2 שמוחזק על ידי חוט 2, וחוט 2 ממתין ל-L1 שמוחזק על ידי חוט 1. מצב זה יוצר מעגל המתנה שמונע משני החוטים להתקדם ומוביל לקיפאון. האפשרויות האחרות מתארות היבטים שונים של סנכרון או תוצאות של קיפאון, אך אינן מתארות באופן מדויק את תנאי ה\"המתנה מעגלית\" עצמו כפי שהוגדר בחומר."}, "_source_file": "0267__Concurrency__Deadlocks__MC__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:58:55", "_subject": "Concurrency", "_context_lectures": [16, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Deadlocks"], "difficulty_estimation": "Hard", "content": {"text": "לפי חומר ההרצאה, \"ל-deadlock אין תכונת הרכבה\". מה המשמעות העמוקה ביותר של קביעה זו בהקשר של תכנון מערכות מקביליות המשתמשות במספר מנעולים?", "code_snippet": "// דוגמה למצב של המתנה מעגלית בין שני מנעולים:\n//Thread 1::\nlock(&L1);\nlock(&L2);\n\n//Thread 2::\nlock(&L2);\nlock(&L1);", "options": ["א. גם אם כל מנעול בפני עצמו מתוכנן באופן שמבטיח deadlock freedom (כלומר, אינו גורם לקיפאון בשימוש יחיד בו), השילוב של שני מנעולים כאלה או יותר בקוד משותף עלול עדיין להוביל לקיפאון מערכתי, לדוגמה באמצעות המתנה מעגלית (circular wait) בין חוטים התופסים את המנעולים בסדר שונה.", "ב. מנעול יכול לקיים deadlock freedom רק אם הוא לא מקיים mutual exclusion, מה שמגביל מאוד את השימוש במנעולים למניעת קיפאון.", "ג. כדי למנוע קיפאון במערכת מרובת מנעולים, מספיק לוודא שכל מנעול בודד מקיים deadlock freedom, ואין צורך להתחשב באינטראקציה ביניהם.", "ד. העובדה של-deadlock אין תכונת הרכבה משמעותה שקיפאון יכול להתרחש רק כאשר ישנו מנעול אחד בלבד במערכת שאינו מקיים deadlock freedom."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר ההרצאה מציין במפורש כי \"ל-deadlock אין תכונת הרכבה. כלומר אם ניקח שני מנעולים שבשניהם אין deadlocks ונשתמש בשניהם, זה לא מבטיח שלא יהיו לנו deadlocks. כל מנעול בפני עצמו יגרום שבשימוש שלו ספציפית לא יהיו deadlocks, אבל השילוב שלהם כן יכול לגרום ל-deadlock\". המשמעות היא שבעוד שמנעול בודד עשוי להיות מתוכנן כך שהוא לא ייכנס לקיפאון בעצמו (deadlock freedom), הדרך שבה חוטים שונים רוכשים ומשחררים מספר מנעולים במערכת יכולה ליצור תנאים לקיפאון מערכתי. התנאי הקלאסי לכך הוא המתנה מעגלית (circular wait), כפי שהודגם בדוגמת הקוד, בה חוטים תופסים משאבים (מנעולים) בסדר הפוך וכל אחד מחכה למשאב שהשני מחזיק. לכן, הבטחת deadlock freedom למנעולים בודדים אינה מספיקה למניעת קיפאון במערכת מורכבת."}, "_source_file": "0268__Concurrency__Deadlocks__MC__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:59:13", "_subject": "Concurrency", "_context_lectures": [16, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Deadlocks"], "difficulty_estimation": "Hard", "content": {"text": "בהינתן מערכת המשתמשת במספר מנעולים (locks), כאשר כל מנעול בנפרד הוכח כ\"חופשי מקיפאון\" (deadlock freedom) ואינו יכול לגרום לקיפאון בשימוש עצמאי. מדוע עדיין ייתכן מצב של קיפאון (deadlock) במערכת הכוללת?", "code_snippet": "//Thread 1::\nlock(&L1);\nlock(&L2);\n\n//Thread 2::\nlock(&L2);\nlock(&L1);", "options": ["א. תכונת ה\"חופשי מקיפאון\" אינה תכונה הרכבתית, ולכן שילוב של מנעולים בודדים, גם אם כל אחד מהם \"חופשי מקיפאון\", אינו מבטיח שהמערכת כולה תהיה חופשית מקיפאון.", "ב. קיפאון במערכת כזו יכול להתרחש רק אם אחד המנעולים, למרות ההוכחה, אינו באמת \"חופשי מקיפאון\" בפועל.", "ג. קיפאון נגרם תמיד כתוצאה מכשל חומרה המונע שחרור מנעולים, ולא קשור לאופן השימוש בהם על ידי תוכנה.", "ד. מצב כזה של קיפאון בלתי אפשרי, שכן אם כל רכיב בודד חופשי מקיפאון, גם המערכת כולה חייבת להיות חופשית מקיפאון באופן מוחלט."]}, "solution": {"correct_option": "א", "explanation": "ההסבר הנכון מתבסס על העיקרון של- \"אין תכונת הרכבה\" (no composition property) עבור deadlocks, כפי שמופיע בחומר הלימוד. נאמר במפורש: \"ל-deadlock אין תכונת הרכבה. כלומר אם ניקח שני מנעולים שבשניהם אין deadlocks ונשתמש בשניהם, זה לא מבטיח שלא יהיו לנו deadlocks. כל מנעול בפני עצמו יגרום שבשימוש שלו ספציפית לא יהיו deadlocks, אבל השילוב שלהם כן יכול לגרום ל-deadlock.\" המשמעות היא שאף על פי שמנעול בודד עשוי להיות מתוכנן כך שלא ייווצר בו deadlock בשימוש עצמאי (כלומר, הוא מקיים deadlock freedom), הדרך שבה מנעולים שונים משולבים ונתפסים על ידי חוטים שונים (למשל, בסדר הפוך כפי שמתרחש בתנאי \"המתנה מעגלית\" - circular wait, כפי שמודגם בדוגמת הקוד) יכולה ליצור מצב של קיפאון במערכת הכוללת. לכן, האפשרות ששילוב מנעולים \"חופשיים מקיפאון\" יוביל לקיפאון היא נכונה ומצביעה על היעדר תכונת ההרכבה."}, "_source_file": "0269__Concurrency__Deadlocks__MC__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:59:27", "_subject": "Concurrency", "_context_lectures": [16, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Deadlocks"], "difficulty_estimation": "Hard", "content": {"text": "מדוע עקרונות תכנות נכון, כגון אנקפסולציה ושימוש ב\"קופסא שחורה\" עבור אובייקטים, נחשבים למאתגרים או לא עובדים היטב עם מניעה או איתור של קיפאונות (deadlocks) במערכות מקביליות?", "code_snippet": null, "options": ["א. עקרונות אלו מטשטשים את סדר תפיסת המנעולים הפנימי בתוך קריאות לפעולות של אובייקטים, ובכך מקשים על זיהוי המתנה מעגלית.", "ב. אנקפסולציה מפחיתה את מספר המנעולים הכולל במערכת, מה שדווקא מקטין את הסבירות לקיפאון.", "ג. \"קופסא שחורה\" מונעת מחוטים אחרים לגשת למשאבים משותפים, ובכך תורמת באופן ישיר למניעת תנאי 'החזקה והמתנה'.", "ד. עקרונות אלו מביאים ליצירת קוד פשוט מדי, מה שמקשה על המהדר לזהות דפוסי גישה למשאבים."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. כפי שמצוין בחומר ההרצאה, עקרונות תכנות מונחה עצמים כמו אנקפסולציה והתייחסות לפעולות כאובייקטים כ'קופסא שחורה' (black box) אומרים שאנו לא אמורים לדעת את פרטי המימוש הפנימיים. אך אם פעולה של אובייקט תופסת מנעול, ובנוסף קוראת לפעולות אחרות שגם הן תופסות מנעולים, אנו מאבדים את השליטה והראות לגבי סדר תפיסת המנעולים הכולל במערכת. חוסר היכולת לדעת \"מי תופס את המנעול, מתי ובאיזה סדר\" מקשה מאוד על זיהוי ומניעה של תנאי המתנה מעגלית (circular wait), שהוא תנאי הכרחי לקיומו של קיפאון. לכן, עקרונות אלו, למרות שהם טובים לארגון קוד, יוצרים אתגר משמעותי בהבנה ובשליטה על התנהגות מנעולים במערכת מקבילית."}, "_source_file": "0270__Concurrency__Deadlocks__MC__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:59:40", "_subject": "Concurrency", "_context_lectures": [16, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Race Conditions"], "difficulty_estimation": "Easy", "content": {"text": "מהו המאפיין העיקרי של \"מצב מרוץ\" (Race Condition) במערכת הפעלה, כפי שמתואר בחומר הלימוד?", "code_snippet": null, "options": ["א. מצב שבו מספר חוטים מנסים לגשת ולשנות משאב משותף בו-זמנית, כאשר סדר הגישה אינו מוגדר ועלול להוביל לתוצאות בלתי צפויות או שגויות.", "ב. מצב שבו חוט אחד תופס משאב משותף ומונע מכל החוטים האחרים לגשת אליו באופן קבוע, ובכך גורם להרעבה.", "ג. מצב שבו שני חוטים או יותר ממתינים זה לזה למשאבים שכל אחד מהם מחזיק, וכתוצאה מכך אף חוט לא יכול להתקדם בביצוע.", "ד. מצב שבו מערכת ההפעלה קובעת מראש את סדר הריצה המדויק של כל החוטים, כדי להבטיח עקביות בגישה למשאבים."]}, "solution": {"correct_option": "א", "explanation": "הסבר: מצב מרוץ (Race Condition) מתרחש כאשר מספר חוטים (threads) ניגשים למשאב משותף (כמו זיכרון או קובץ) בו-זמנית, וסדר הפעולות שלהם אינו מוגדר או ניתן לחיזוי. כפי שמתואר בשיעור 11 (chunk 1 ו-9), גישה בו-זמנית זו עלולה להוביל ל\"התנגשות\" או \"בעיית סנכרון\" ולתוצאות שגויות או לא עקביות, מכיוון ש\"אין שליטה מתי החוטים יפעלו, זה תלוי במתזמן/במערכת ההפעלה\" (שיעור 11, chunk 1). המטרה היא למנוע מצבים אלו בקטעים קריטיים.\nאופציה ב' מתארת תופעה של הרעבה (starvation), שבה חוט אחד נמנע באופן מתמשך מגישה למשאב, אך אינה ההגדרה הישירה של מצב מרוץ. אופציה ג' מתארת קיפאון (deadlock), שבו חוטים ממתינים זה לזה במעגל ואינם יכולים להתקדם. אופציה ד' אינה נכונה, שכן אחד הגורמים למצב מרוץ הוא דווקא חוסר היכולת של מערכת ההפעלה לקבוע מראש את סדר הריצה המדויק, מה שמוביל לאי-ודאות (שיעור 10, chunk 29)."}, "_source_file": "0271__Concurrency__Race_Conditions__MC__Easy.json", "_topic_hint": "Race Conditions", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:59:54", "_subject": "Concurrency", "_context_lectures": [16, 10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Race Conditions"], "difficulty_estimation": "Easy", "content": {"text": "מהו מצב מרוץ (Race Condition) במערכת הפעלה, כפי שתואר בחומר הלימוד?", "code_snippet": null, "options": ["א. מצב שבו שני חוטים או יותר ניגשים למשאב משותף בו-זמנית, ולפחות אחד מהם משנה אותו, כאשר סדר הגישה אינו מוגדר ועלול להוביל לתוצאות שגויות או בלתי צפויות.", "ב. מצב שבו חוט יחיד מנסה לגשת לכתובת זיכרון לא חוקית, מה שגורם לקריסת התוכנית.", "ג. מצב שבו שני חוטים או יותר ממתינים זה לזה באופן הדדי, ואינם יכולים להתקדם (deadlock).", "ד. מצב שבו תזמון המעבד אינו יעיל, ומונע מחוט ספציפי לקבל זמן מעבד מספק."]}, "solution": {"correct_option": "א", "explanation": "מצב מרוץ (Race Condition) מתרחש כאשר מספר חוטים ניגשים למשאב משותף בו-זמנית, ולפחות אחד מהם מבצע שינוי במשאב. כפי שמתואר בחומר הלימוד (הרצאה 11, קטע 1), 'חוטים ייגשו למשאבים בו זמנית ותהיה בעיית סנכרון עקב כך'. הבעיה נובעת מכך שסדר הריצה של החוטים אינו מוגדר מראש ותלוי במתזמן (הרצאה 10, קטע 29: 'כל הפלטים היו אפשריים, כתלות במזלנו שלנו'), מה שעלול להוביל לתוצאות שגויות או בלתי צפויות. המטרה היא למנוע מצב זה בקטעים קריטיים (הרצאה 11, קטע 9)."}, "_source_file": "0272__Concurrency__Race_Conditions__MC__Easy.json", "_topic_hint": "Race Conditions", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:00:06", "_subject": "Concurrency", "_context_lectures": [16, 10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Race Conditions"], "difficulty_estimation": "Easy", "content": {"text": "מהו מצב מרוץ (Race Condition) בתכנות מקבילי, כפי שתואר בחומר ההרצאה?", "code_snippet": null, "options": ["א. מצב שבו שני חוטים או יותר מנסים לגשת למשאב משותף בו זמנית, וסדר הגישה משפיע על התוצאה הסופית באופן בלתי צפוי.", "ב. מצב שבו חוטים מרובים ננעלים ואינם יכולים להתקדם, מכיוון שכל אחד מהם ממתין למשאב שמוחזק על ידי חוט אחר.", "ג. מצב שבו חוט אחד מונע מחוטים אחרים לגשת למשאב משותף באופן קבוע, מה שמוביל לכך שהם לעולם לא יצליחו לבצע את פעולתם.", "ד. מצב שבו המערכת כולה קורסת עקב עומס יתר של חוטים מרובים המבצעים פעולות לא חוקיות."]}, "solution": {"correct_option": "א", "explanation": "הסבר: מצב מרוץ (Race Condition) מתרחש כאשר מספר חוטים (או תהליכים) ניגשים בו זמנית למשאב משותף (כמו משתנה גלובלי, קובץ, או אזור זיכרון), וסדר הפעולות שבהן החוטים ניגשים למשאב משפיע על התוצאה הסופית. מכיוון שמתזמן מערכת ההפעלה קובע את סדר הריצה של החוטים באופן שאינו ניתן לחיזוי מראש, התוצאה של הגישה למשאב המשותף עלולה להיות שונה בין הרצות שונות של התוכנית. חומר ההרצאה מתאר זאת כ'בעיית סנכרון עקב כך' כאשר 'החוטים ייגשו למשאבים בו זמנית' וכן כ'קטעים מסוימים שניגשים למשאב משותף, ולוודא שהם רצים בצורה נכונה בלי סיכון להגיע למצב ריצה/מרוץ'. אפשרות ב' מתארת קיפאון (Deadlock). אפשרות ג' מתארת הרעבה (Starvation). אפשרות ד' מתארת כשל מערכת כללי שאינו בהכרח מצב מרוץ."}, "_source_file": "0273__Concurrency__Race_Conditions__MC__Easy.json", "_topic_hint": "Race Conditions", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:00:19", "_subject": "Concurrency", "_context_lectures": [16, 10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Race Conditions"], "difficulty_estimation": "Medium", "content": {"text": "מהו הגורם העיקרי למצב מרוץ (Race Condition) במערכת הפעלה מרובת חוטים, כפי שמתואר בחומר ההרצאה?", "code_snippet": null, "options": ["א. חוטים מרובים ניגשים למשאב משותף בו-זמנית, ללא מנגנון סנכרון מתאים, מה שמוביל לתוצאות בלתי צפויות.", "ב. חוט אחד מנסה לגשת למשאב שאינו קיים במערכת, וגורם לשגיאת זמן ריצה.", "ג. חוטים מרובים מנסים לתפוס מנעול על משאב שאינו קריטי, ובכך מבזבזים משאבי מעבד.", "ד. המתזמן של מערכת ההפעלה מקצה זמן מעבד רב מדי לחוט יחיד, ומונע מחוטים אחרים לרוץ."]}, "solution": {"correct_option": "א", "explanation": "מצב מרוץ (Race Condition) מתרחש כאשר מספר חוטים ניגשים למשאב משותף בו-זמנית, ולפחות אחד מהם משנה אותו, ללא מנגנון סנכרון מתאים שיבטיח סדר פעולות מוגדר. חומר ההרצאה מדגיש כי 'ייתכן שהחוטים ייגשו למשאבים בו זמנית ותהיה בעיית סנכרון עקב כך' (הרצאה 11, קטע 1). כמו כן, הוא מתאר את המטרה לוודא ש'קטעים קריטיים... רצים בצורה נכונה בלי סיכון להגיע למצב ריצה/מרוץ' (הרצאה 11, קטע 9). דוגמת הצומת ללא רמזורים, המובילה ל'התנגשות', ממחישה את התוצאות הבלתי צפויות של גישה לא מסונכרנת למשאב משותף. אפשרות א' מתארת במדויק מצב זה."}, "_source_file": "0274__Concurrency__Race_Conditions__MC__Medium.json", "_topic_hint": "Race Conditions", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:00:32", "_subject": "Concurrency", "_context_lectures": [16, 10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Race Conditions"], "difficulty_estimation": "Medium", "content": {"text": "על פי חומר ההרצאה, מהו הגורם המרכזי המוביל למצב מרוץ (Race Condition) במערכת מרובת חוטים?", "code_snippet": null, "options": ["א. גישה בלתי מבוקרת ובו-זמנית של מספר חוטים למשאב משותף, כאשר סדר הגישה הבלתי צפוי משפיע על נכונות התוצאה הסופית.", "ב. מצב שבו חוט אחד תופס משאב חיוני ואינו משחרר אותו, ובכך מונע מחוטים אחרים להתקדם באופן אינסופי.", "ג. מצב שבו שני חוטים או יותר ממתינים זה לזה למשאבים שונים, וכל אחד מהם מחזיק במשאב שהאחר זקוק לו, מה שמוביל לחסימה הדדית.", "ד. תזמון לא יעיל של חוטים על ידי המתזמן של מערכת ההפעלה, הגורם לעיכובים בביצוע משימות."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מתאר מצב מרוץ (Race Condition) כנובע מ\"חוטים ייגשו למשאבים בו זמנית ותהיה בעיית סנכרון עקב כך\" (הרצאה 11, קטע 1). הוא מדגיש שיש לוודא ש\"קטעים מסוימים שניגשים למשאב משותף\" (קטעים קריטיים) \"רצים בצורה נכונה בלי סיכון להגיע למצב ריצה/מרוץ\" (הרצאה 11, קטע 9). אנלוגיית הצומת ללא רמזורים, המובילה ל\"התנגשות\", ממחישה את הבעיה של גישה בלתי מבוקרת למשאב משותף. העובדה ש\"לנו אין שליטה מתי מכוניות מגיעות (מתי החוטים יפעלו, זה תלוי במתזמן/במערכת ההפעלה)\" (הרצאה 11, קטע 1) מצביעה על כך שסדר הגישה הוא בלתי צפוי. לכן, אפשרות א' מתארת במדויק את הגורמים למצב מרוץ: גישה בו-זמנית ובלתי מבוקרת למשאב משותף, כאשר סדר הגישה הבלתי צפוי משפיע על נכונות התוצאה.\nאפשרויות ב' ו-ג' מתארות בעיות סנכרון אחרות: ב' מתארת הרעבה (starvation), וג' מתארת מבוי סתום (deadlock), שניהם מוזכרים בחומר ההרצאה כבעיות נפרדות ממצב מרוץ. אפשרות ד' מתייחסת ליעילות התזמון של המתזמן, שאינה ההגדרה הישירה של מצב מרוץ."}, "_source_file": "0275__Concurrency__Race_Conditions__MC__Medium.json", "_topic_hint": "Race Conditions", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:00:48", "_subject": "Concurrency", "_context_lectures": [16, 10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Race Conditions"], "difficulty_estimation": "Medium", "content": {"text": "מהו הגורם העיקרי למצב מרוץ (Race Condition) בתוכנית מרובת חוטים?", "code_snippet": null, "options": ["א. גישת מספר חוטים למשאב משותף בו-זמנית ללא סנכרון מתאים.", "ב. חוט יחיד המבצע חישובים מורכבים.", "ג. מתזמן מערכת ההפעלה המריץ תמיד את החוטים בסדר קבוע וצפוי.", "ד. חוטים הניגשים אך ורק למשתנים פרטיים מקומיים."]}, "solution": {"correct_option": "א", "explanation": "הסבר: מצב מרוץ (Race Condition) מתרחש כאשר מספר חוטים (או תהליכים) ניגשים למשאב משותף (כמו משתנה גלובלי, קובץ, או התקן חומרה) בו-זמנית, ולפחות אחד מהם משנה את המשאב. כתוצאה מכך, התוצאה הסופית של הפעולות תלויה בסדר הלא-צפוי שבו החוטים מריצים את הקוד שלהם, מה שמוביל לחוסר עקביות או לשגיאות. החומר המצוין בשיעור 11 (chunk 1) מתאר זאת: \"אנחנו כותבים קוד עם חוטים מרובים... והקוד הזה לפעמים עלול להתנגש אחד עם השני. ייתכן שהחוטים ייגשו למשאבים בו זמנית ותהיה בעיית סנכרון עקב כך.\" אפשרות א' מתארת בדיוק מצב זה. אפשרויות ב' ו-ד' אינן קשורות למשאבים משותפים או לריבוי חוטים, ואילו אפשרות ג' מתארת מצב שבו לא היו מתרחשים מצבי מרוץ, שכן הסדר הקבוע היה מאפשר שליטה ובקרה, אך בפועל סדר ריצת החוטים אינו קבוע וצפוי (כמוסבר בשיעור 10 chunk 29)."}, "_source_file": "0276__Concurrency__Race_Conditions__MC__Medium.json", "_topic_hint": "Race Conditions", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:01:00", "_subject": "Concurrency", "_context_lectures": [16, 10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Race Conditions"], "difficulty_estimation": "Hard", "content": {"text": "איזו מההגדרות הבאות מתארת בצורה המדויקת ביותר מצב מרוץ (Race Condition) בהקשר של מערכות הפעלה, כפי שנדון בחומר הלימוד?", "code_snippet": null, "options": ["א. מצב שבו חוטים מרובים ניגשים למשאב משותף בקטע קריטי לא מוגן, וסדר הריצה הלא-דטרמיניסטי של החוטים קובע את התוצאה הסופית, מה שעלול להוביל לתוצאות שגויות או בלתי צפויות.", "ב. מצב שבו חוט יחיד נכנס ללולאה אינסופית ומעכב את כל החוטים האחרים מלהתקדם בקטע קריטי.", "ג. מצב שבו שני חוטים או יותר ממתינים זה לזה באופן הדדי (תלות מעגלית), ואינם יכולים להתקדם בביצוע הקוד שלהם.", "ד. מצב שבו מנגנון המניעה ההדדית נכשל, ומאפשר לחוט אחד בלבד לגשת למשאב המשותף, אך אינו מבטיח הוגנות."]}, "solution": {"correct_option": "א", "explanation": "מצב מרוץ (Race Condition) מתרחש כאשר מספר חוטים ניגשים למשאב משותף (כמו צומת בכביש בדוגמה מחומר הלימוד) בתוך קטע קריטי שאינו מוגן כראוי. חומר הלימוד מציין כי המטרה היא \"לוודא שהם רצים בצורה נכונה בלי סיכון להגיע למצב ריצה/מרוץ\" בקטעים קריטיים שניגשים למשאב משותף (Lecture 11, chunk 9). כמו כן, הוא מדגיש כי \"ייתכן שהחוטים ייגשו למשאבים בו זמנית ותהיה בעיית סנכרון עקב כך\" (Lecture 11, chunk 1). המאפיין המרכזי שמוביל למצב זה הוא חוסר השליטה בסדר הריצה של החוטים, ש\"תלוי במתזמן/במערכת ההפעלה\" (Lecture 11, chunk 1), וכי \"איזה יתומן מתי, מי יקבל page fault וכו'\" הוא לא דטרמיניסטי (Lecture 10, chunk 29). כתוצאה מכך, הפלט או מצב המערכת הסופי יכולים להיות שונים ובלתי צפויים, או שגויים, כתלות ב\"מזלנו שלנו\" ובסדר הריצה הספציפי (Lecture 10, chunk 29).\n\nאפשרויות אחרות אינן מתארות מצב מרוץ:\nב. מתאר מצב של לולאה אינסופית או הרעבה (starvation) מטיפוס מסוים, ולא את ההגדרה של מצב מרוץ.\nג. מתאר מצב של קיפאון (deadlock), שבו חוטים ממתינים זה לזה בתלות מעגלית ואינם יכולים להתקדם (Lecture 11, chunk 28).\nד. אפשרות זו סותרת את עצמה חלקית. כישלון מנגנון מניעה הדדית אכן יכול להוביל למצב מרוץ בכך שהוא מאפשר לחוטים רבים לגשת למשאב. אולם, הטענה שאז הוא \"מאפשר לחוט אחד בלבד לגשת למשאב המשותף\" שגויה, שכן זוהי דווקא המטרה של מניעה הדדית מוצלחת, ובמקרה של כישלון, יותר מחוט אחד יכול לגשת. החלק העוסק ב\"אינו מבטיח הוגנות\" מתייחס להרעבה (starvation), שהיא בעיה נפרדת ממצב מרוץ, גם אם שתיהן בעיות סנכרון."}, "_source_file": "0277__Concurrency__Race_Conditions__MC__Hard.json", "_topic_hint": "Race Conditions", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:01:22", "_subject": "Concurrency", "_context_lectures": [16, 10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Race Conditions"], "difficulty_estimation": "Hard", "content": {"text": "בהקשר של מערכות הפעלה מרובות חוטים, מהו המאפיין המהותי ביותר המגדיר מצב מרוץ (Race Condition) בקטע קריטי?", "code_snippet": null, "options": ["א. תוצאת הפעולות על המשאב המשותף תלויה בסדר הלא-דטרמיניסטי שבו חוטים שונים ניגשים אליו ומבצעים עליו שינויים.", "ב. חוטים מרובים נכנסים למצב של קיפאון (Deadlock) ואינם יכולים להמשיך את פעולתם.", "ג. יותר מחוט אחד רץ בתוך הקטע הקריטי בו-זמנית, מה שמונע מניעה הדדית.", "ד. ביצועי המערכת נפגעים באופן משמעותי עקב ריבוי החלפות הקשר (Context Switches) בין החוטים."]}, "solution": {"correct_option": "א", "explanation": "מצב מרוץ (Race Condition) מתרחש כאשר מספר חוטים ניגשים למשאב משותף (כמו משתנה גלובלי או קובץ) ומשנים אותו, והתוצאה הסופית של הפעולות הללו תלויה בסדר הספציפי והבלתי צפוי (לא-דטרמיניסטי) שבו החוטים מבצעים את פעולותיהם. כפי שצוין בחומר ההרצאה (Lecture 10, chunk 29 ו-Lecture 11, chunk 1), סדר הריצה של חוטים נקבע על ידי המתזמן של מערכת ההפעלה ואינו ניתן לשליטה מדויקת, מה שיכול להוביל לפלטים שונים \"כתלות במזלנו שלנו\". זוהי ההגדרה המהותית של מצב מרוץ – התוצאה אינה עקבית ואינה ניתנת לחיזוי.\n\nאפשרות ב' אינה נכונה מכיוון שקיפאון (Deadlock) הוא מצב שבו שני חוטים או יותר חסומים וממתינים זה לזה למשאב שלעולם לא ישוחרר. בעוד שקיפאון הוא בעיה חמורה שיכולה לנבוע מבעיות סנכרון, הוא אינו ההגדרה של מצב מרוץ עצמו, אלא תוצאה אפשרית של תכנון לקוי של מנגנוני סנכרון. מצב מרוץ יכול להתקיים גם ללא קיפאון.\n\nאפשרות ג' אינה נכונה מכיוון שהאפשרות ש\"יותר מחוט אחד רץ בתוך הקטע הקריטי בו-זמנית\" מתארת הפרה של תנאי \"מניעה הדדית\" (Mutual Exclusion). מניעה הדדית היא דרישה קריטית למניעת מצבי מרוץ (Lecture 16, chunk 8). כאשר אין מניעה הדדית, חוטים יכולים לגשת למשאב משותף בו-זמנית, וזהו התנאי המקדים שמאפשר למצב מרוץ להתרחש. עם זאת, מצב המרוץ עצמו מוגדר על ידי התוצאה הבלתי צפויה הנובעת מהגישה הבו-זמנית למשאב המשותף (כפי שמתואר באפשרות א'), ולא רק על ידי העובדה שהגישה הבו-זמנית התרחשה. כלומר, הפרת מניעה הדדית היא *הגורם* המאפשר למצב מרוץ להתממש, אך לא *ההגדרה המהותית* של מצב המרוץ כהתנהגות המערכתית שבה התוצאה משתנה בהתאם לסדר הריצה.\n\nאפשרות ד' אינה נכונה מכיוון שפגיעה בביצועי המערכת עקב ריבוי החלפות קשר היא תופעה שיכולה להתרחש במערכות מרובות חוטים, אך אינה קשורה ישירות להגדרה של מצב מרוץ. מצב מרוץ מתייחס לנכונות הלוגית של הפלט, בעוד שהחלפות קשר משפיעות על היעילות והביצועים."}, "_source_file": "0278__Concurrency__Race_Conditions__MC__Hard.json", "_topic_hint": "Race Conditions", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:01:45", "_subject": "Concurrency", "_context_lectures": [16, 10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Race Conditions"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על התיאור של מנגנון נעילה (lock) שאינו מקיים מניעה הדדית (mutual exclusion), כפי שהוצג בחומר ההרצאה (למשל, כאשר שני חוטים יכולים להיכנס לקטע קריטי בו-זמנית), ובהתחשב בקטע קריטי הניגש למשאב משותף, איזו מההשלכות הבאות היא התוצאה הישירה והמיידית ביותר של כשל זה?", "code_snippet": null, "options": ["א. מצב מרוץ (Race Condition) בו התנהגות התוכנית הופכת לבלתי צפויה ותלויה בסדר הריצה של החוטים.", "ב. רעב (Starvation) של חוטים, כאשר חוט מסוים לעולם אינו מצליח להיכנס לקטע הקריטי.", "ג. קיפאון (Deadlock) של התוכנית, כאשר שני חוטים או יותר ממתינים זה לזה ואינם יכולים להמשיך.", "ד. שימוש מופרז במעבד (CPU Overutilization) עקב לולאות המתנה פעילות (busy waiting)."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר ההרצאה מציין כי מצב ריצה/מרוץ (Race Condition) מתרחש כאשר חוטים מרובים ניגשים למשאבים משותפים בו-זמנית, מה שעלול להוביל לבעיות סנכרון ולהתנהגות בלתי צפויה של התוכנית (הרצאה 11, פיסקה 1 ו-9). כשל של מנגנון נעילה לספק מניעה הדדית (הרצאה 16, פיסקה 8) פירושו ששני חוטים או יותר יכולים להיכנס לקטע קריטי המטפל במשאב משותף במקביל. גישה בו-זמנית זו היא ההגדרה המדויקת של מצב מרוץ, שבו התוצאה תלויה בסדר הלא-דטרמיניסטי של פעולות החוטים, כפי שמוסבר גם בהקשר של סדר הריצה הבלתי צפוי של חוטים (הרצאה 10, פיסקה 29). לכן, ההשלכה המיידית והחמורה ביותר של כשל במניעה הדדית היא יצירת מצב מרוץ. אפשרויות ב', ג' ו-ד' מתארות בעיות אחרות בתחום המקביליות: רעב (starvation) קשור לכשל בהוגנות, קיפאון (deadlock) קשור למצב שבו חוטים חוסמים זה את זה בהמתנה למשאבים, ושימוש מופרז במעבד קשור למימוש ספציפי של מנגנוני המתנה (busy waiting), אף אחת מהן אינה ההשלכה הישירה של כשל במניעה הדדית המאפשר גישה סימולטנית לקטע קריטי."}, "_source_file": "0279__Concurrency__Race_Conditions__MC__Hard.json", "_topic_hint": "Race Conditions", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:02:06", "_subject": "Concurrency", "_context_lectures": [16, 10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Starvation"], "difficulty_estimation": "Easy", "content": {"text": "מהי ההגדרה הנכונה ביותר ל\"הרעבה\" (Starvation) במערכת הפעלה?", "code_snippet": null, "options": ["א. מצב שבו חוט אחד או יותר חסומים ואינם יכולים להתקדם, בעוד שחוטים אחרים במערכת ממשיכים לבצע את פעולותיהם.", "ב. מצב שבו כל החוטים במערכת חסומים ואינם יכולים להתקדם, באופן שמונע מכל פעולה נוספת להתבצע.", "ג. מצב שבו חוט תופס משאב קריטי ומחזיק בו ללא הגבלה, ובכך מונע מחוטים אחרים לגשת אליו אי-פעם.", "ד. מצב שבו חוטים מתחרים על משאב, אך עקב תזמון לא יעיל, אף חוט אינו מקבל זמן מעבד מספק."]}, "solution": {"correct_option": "א", "explanation": "ההגדרה של הרעבה כפי שנלמדה בחומר השיעור היא: 'תהליך מורעב (כפי שלמדנו בקורס) הוא תהליך (חוט) שחסום בזמן שחוטים אחרים מתקדמים'. אפשרות א' מתארת בדיוק מצב זה. אפשרות ב' מתארת קיפאון (Deadlock), שבו כל החוטים חסומים ואינם מתקדמים. אפשרות ג' מתארת באג בקוד שבו משאב מוחזק לנצח, ולא הרעבה. אפשרות ד' כללית מדי ואינה תואמת במדויק את ההגדרה הספציפית של הרעבה כחסימת חוט בעוד שאחרים מתקדמים."}, "_source_file": "0280__Concurrency__Starvation__MC__Easy.json", "_topic_hint": "Starvation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:02:19", "_subject": "Concurrency", "_context_lectures": [16, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Starvation"], "difficulty_estimation": "Easy", "content": {"text": "מהי ההגדרה הנכונה ביותר למצב של \"הרעבה\" (Starvation) במערכת הפעלה, כפי שנלמד בקורס?", "code_snippet": "int turn;\nvoid lock(int i) {\n    turn = 1-i;\n    while (turn != i);\n}\nvoid unlock(int i) {\n    turn = 1-i;\n}", "options": ["א. חוט אחד (או יותר) חסום באופן תמידי מלקבל גישה למשאב, בעוד חוטים אחרים כן מצליחים להתקדם ולגשת למשאב.", "ב. כל החוטים במערכת חסומים ואינם יכולים לבצע עבודה כלשהי.", "ג. חוט תפס משאב קריטי ומחזיק בו ללא שחרור, מה שמונע מכל החוטים האחרים להתקדם.", "ד. חוט אחד חסום, אך אף חוט אחר אינו מתקדם בפועל באותה מערכת."]}, "solution": {"correct_option": "א", "explanation": "על פי החומר הנלמד, הרעבה (Starvation) מתרחשת כאשר חוט אחד חסום באופן תמידי מלקבל גישה למשאב, בעוד חוטים אחרים ממשיכים להתקדם ולגשת למשאב באופן תקין. זהו מצב שבו החוט המורעב לעולם אינו מקבל את המשאב, למרות שהוא משוחרר ונתפס על ידי אחרים. הקוד המצורף מדגים מנגנון נעילה פשוט בו חוט 0 יכול להיות מורעב באופן תמידי אם חוט 1 תמיד מצליח לתפוס את המשאב. האפשרויות האחרות אינן מתארות הרעבה: אפשרות ב' ו-ד' מתארות קיפאון (Deadlock) או מצב דומה שבו אף חוט אינו מתקדם. אפשרות ג' מתארת באג בקוד שבו חוט מחזיק במשאב לנצח, ולא מצב של הרעבה כפי שהוגדר בשיעור, שבו המשאב משוחרר ונתפס מחדש על ידי חוטים אחרים."}, "_source_file": "0281__Concurrency__Starvation__MC__Easy.json", "_topic_hint": "Starvation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:02:33", "_subject": "Concurrency", "_context_lectures": [16, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Starvation"], "difficulty_estimation": "Easy", "content": {"text": "מהי ההגדרה הנכונה ביותר למצב \"הרעבה\" (Starvation) במערכת הפעלה, כפי שנלמד בקורס?", "code_snippet": null, "options": ["א. חוט אחד חסום ואינו יכול להתקדם, בעוד שחוטים אחרים במערכת ממשיכים להתקדם ולבצע פעולות.", "ב. כל החוטים במערכת חסומים ואינם יכולים להתקדם, וממתינים זה לזה למשאבים.", "ג. חוט תפס משאב קריטי ומחזיק בו ללא הגבלה, ובכך מונע מכל שאר החוטים לגשת אליו.", "ד. חוטים רבים מתחרים על גישה למשאב, והמערכת אינה מצליחה להקצות את המשאב לאף אחד מהם."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי ההגדרה שנלמדה בקורס (Lecture 16, chunk 0), תהליך (חוט) מורעב הוא תהליך שחסום בזמן שחוטים אחרים מתקדמים. מצב זה שונה מקיפאון (Deadlock), שבו כל החוטים חסומים ואינם מתקדמים כלל (Lecture 16, chunk 1). כמו כן, אם חוט תופס משאב ומחזיק בו לנצח, זו אינה הרעבה אלא באג בקוד, שכן בהרעבה, המשאב משתחרר אך לעולם אינו מגיע לחוט המורעב (Lecture 16, chunk 11)."}, "_source_file": "0282__Concurrency__Starvation__MC__Easy.json", "_topic_hint": "Starvation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:02:44", "_subject": "Concurrency", "_context_lectures": [16, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Starvation"], "difficulty_estimation": "Medium", "content": {"text": "איזו מהטענות הבאות מתארת נכונה את הקשר בין הרעבה (Starvation) לקיפאון (Deadlock) במערכת הפעלה?", "code_snippet": null, "options": ["א. אם במערכת מתרחשת הרעבה, אזי בהכרח מתרחש גם קיפאון.", "ב. אם במערכת מתרחש קיפאון, אזי בהכרח מתרחשת גם הרעבה.", "ג. הרעבה מתרחשת כאשר חוט אחד חסום בזמן שחוטים אחרים מתקדמים, בעוד שבקיפאון כל החוטים חסומים.", "ד. הרעבה היא מקרה פרטי של קיפאון שבו רק חלק מהתהליכים חסומים."]}, "solution": {"correct_option": "ג", "explanation": "הטענה הנכונה היא ג', בהתאם להגדרות ולתיאורים שניתנו בחומר הקורס. הרעבה (Starvation) מוגדרת כמצב שבו תהליך (או חוט) מסוים חסום ואינו מצליח להתקדם, בזמן שחוטים אחרים במערכת ממשיכים לפעול ולהתקדם. כפי שצוין בשיעור 16, 'אם יש הרעבה וחוט מסוים חסום, זה לא אומר שכולם חסומים (שזה קיפאון), זה אומר למעשה בדיוק את ההפך כי כל שאר החוטים מתקדמים'. לעומת זאת, קיפאון (Deadlock) הוא מצב חמור יותר שבו קבוצה של חוטים חסומה, ואף אחד מהם אינו יכול להתקדם, מכיוון שכל אחד מהם ממתין למשאב שמוחזק על ידי חוט אחר בקבוצה. לכן, בקיפאון כל החוטים המעורבים חסומים ו'אף חוט לא מתקדם', מה שאומר שלא מתקיימת הרעבה במצב כזה, כי הרעבה דורשת שחוטים אחרים יתקדמו. לכן, טענות א' ו-ב' אינן נכונות, וטענה ד' שגויה מכיוון שהרעבה וקיפאון הם מצבים מובחנים במהותם ולא מקרה פרטי זה של זה."}, "_source_file": "0283__Concurrency__Starvation__MC__Medium.json", "_topic_hint": "Starvation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:02:57", "_subject": "Concurrency", "_context_lectures": [16, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Starvation"], "difficulty_estimation": "Medium", "content": {"text": "מהי ההבחנה הנכונה בין הרעבה (Starvation) לקיפאון (Deadlock) במערכת הפעלה?", "code_snippet": null, "options": ["א. אם יש הרעבה במערכת, בהכרח יש גם קיפאון.", "ב. אם יש קיפאון במערכת, בהכרח יש גם הרעבה.", "ג. הרעבה מתרחשת כאשר חוט אחד חסום ואינו מתקדם, בזמן שחוטים אחרים ממשיכים להתקדם, בעוד קיפאון הוא מצב שבו כל החוטים המעורבים חסומים ואינם יכולים להתקדם.", "ד. הרעבה וקיפאון הם מונחים שונים המתארים את אותו סוג של בעיית סנכרון."]}, "solution": {"correct_option": "ג", "explanation": "על פי חומר ההרצאה, הרעבה מוגדרת כמצב שבו 'תהליך (חוט) שחסום בזמן שחוטים אחרים מתקדמים'. לעומת זאת, קיפאון הוא מצב שבו 'אף חוט לא מתקדם', כלומר כולם חסומים. הטענות בחומר ההרצאה מבהירות כי אם יש הרעבה, לא בהכרח יש קיפאון (כי לא כולם חסומים), ואם יש קיפאון, לא בהכרח יש הרעבה (כי בקיפאון כולם חסומים, ולא רק אחד בזמן שאחרים מתקדמים). לכן, אפשרות ג' מתארת נכונה את ההבחנה בין שני המצבים."}, "_source_file": "0284__Concurrency__Starvation__MC__Medium.json", "_topic_hint": "Starvation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:03:06", "_subject": "Concurrency", "_context_lectures": [16, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Starvation"], "difficulty_estimation": "Medium", "content": {"text": "איזו מהטענות הבאות מתארת נכונה דרך למנוע הרעבה (starvation) במערכת הפעלה?", "code_snippet": null, "options": ["א. שימוש במנעולים הוגנים (fair locks) או קביעת סדר גישה למשאבים.", "ב. הבטחה שכל החוטים יחסמו בו-זמנית כדי למנוע מחוט אחד להתקדם.", "ג. הגדלת מספר המעבדים במערכת כדי לאפשר ליותר חוטים לרוץ במקביל.", "ד. מתן עדיפות קבועה לחוט מסוים כדי להבטיח את התקדמותו על פני אחרים."]}, "solution": {"correct_option": "א", "explanation": "ההרעבה מתרחשת כאשר חוט מסוים נחסם באופן תמידי בזמן שחוטים אחרים מתקדמים. חומר ההרצאה מציין במפורש כי ניתן למנוע הרעבה על ידי שימוש ב'מנעולים הוגנים' (fair locks), אשר מבטיחים שכל חוט שממתין למשאב יקבל אותו בסופו של דבר. כמו כן, מוזכרת האפשרות 'לקבוע סדר מסוים ביניהם' (בין החוטים) כדרך למנוע הרעבה, למשל בבעיית הפילוסופים הסועדים ובפתרונות לבעיית ה-Reader-Writer lock. לכן, שימוש במנגנוני הוגנות או קביעת סדר גישה למשאבים הם פתרונות ישירים למניעת הרעבה.\n\nאפשרויות אחרות אינן נכונות: \nב. הבטחה שכל החוטים יחסמו בו-זמנית מתארת מצב של קיפאון (deadlock), אשר בחומר ההרצאה מצוין במפורש שאינו הרעבה, שכן בהרעבה חוטים אחרים דווקא מתקדמים.\nג. הגדלת מספר המעבדים עשויה לשפר ביצועים כלליים ולצמצם עומס, אך אינה מבטיחה מניעת הרעבה, שהיא בעיה של הוגנות בגישה למשאבים ולאו דווקא חוסר במשאבי עיבוד.\nד. מתן עדיפות קבועה לחוט מסוים תבטיח את התקדמותו, אך עלולה לגרום להרעבה של חוטים אחרים שייאלצו להמתין לו ללא הגבלה, ואינה פתרון כולל למניעת הרעבה במערכת."}, "_source_file": "0285__Concurrency__Starvation__MC__Medium.json", "_topic_hint": "Starvation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:03:20", "_subject": "Concurrency", "_context_lectures": [16, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Starvation"], "difficulty_estimation": "Hard", "content": {"text": "איזו מהטענות הבאות לגבי הרעבה (starvation) ומניעתה היא הנכונה ביותר בהתבסס על חומר ההרצאה?", "code_snippet": null, "options": ["א. שימוש במנגנוני סנכרון הוגנים (fair synchronization mechanisms) יכול למנוע הרעבה, כפי שניתן לראות בפתרונות לבעיית הפילוסופים הסועדים או בבעיית הקוראים והכותבים.", "ב. הרעבה מתרחשת כאשר חוט תופס משאב ומחזיק בו באופן קבוע, ובכך מונע מחוטים אחרים להתקדם.", "ג. קיפאון (deadlock) הוא מצב בו חוטים רבים חסומים, ותמיד גורר אחריו מצב של הרעבה עבור חלק מהחוטים.", "ד. פתרונות שמונעים קיפאון בבעיית הפילוסופים הסועדים בהכרח מונעים גם הרעבה."]}, "solution": {"correct_option": "א", "explanation": "האפשרות הנכונה היא א'. חומר ההרצאה מציין במפורש כי בבעיית הפילוסופים הסועדים, \"אם נשתמש במנעולים הוגנים הכל יהיה סדר\" וכי \"אפילו מנעול אחד גלובאלי הוגן ימנע הרעבה\". בנוסף, בפתרון לבעיית הקוראים והכותבים, מוזכר \"שימוש במנעול הוגן\" כאחת הדרכים למנוע הרעבה.\nאפשרות ב' שגויה מכיוון שההרצאה מבהירה כי \"אם חוט תפס את המשאב ומחזיק בו לנצח, זו לא הרעבה, זה באג בקוד. בשביל הרעבה צריך שיהיה מישהו שתמיד תופס ומשחרר את המשאב.\"\nאפשרות ג' שגויה מכיוון שההרצאה קובעת: \"אם יש קיפאון, אף חוט לא מתקדם, לכן לא מתקיימת הרעבה, כי בקיפאון כולם חסומים (ולא רק חוט אחד בזמן שכל השאר מתקדמים).\" כלומר, קיפאון אינו גורר הרעבה.\nאפשרות ד' שגויה מכיוון שההרצאה מציינת במפורש כי הפתרונות לבעיית הפילוסופים הסועדים \"מנעו קיפאון אך לא דיברנו על מניעת הרעבה. אבל אפשר למנוע הרעבה.\" כלומר, מניעת קיפאון אינה מבטיחה מניעת הרעבה."}, "_source_file": "0286__Concurrency__Starvation__MC__Hard.json", "_topic_hint": "Starvation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:03:39", "_subject": "Concurrency", "_context_lectures": [16, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Starvation"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על חומר הקורס, ובפרט על ההבחנה בין הרעבה (starvation) לקיפאון (deadlock) ולבאגים בקוד, איזה מהתרחישים הבאים מתאר בצורה המדויקת ביותר מצב של הרעבה, כפי שעלול לקרות במערכת המשתמשת במנעולים לא הוגנים (כדוגמת הקוד המצורף)?", "code_snippet": "int turn;\nvoid lock(int i) {\n    turn = 1-i;\n    while (turn != i);\n}\nvoid unlock(int i) {\n    turn = 1-i;\n}", "options": ["א. חוט אחד (למשל, חוט 1) מצליח לרכוש ולשחרר את המשאב באופן חוזר ונשנה, בעוד שחוט אחר (למשל, חוט 0) נשאר חסום באופן עקבי ואינו מצליח לרכוש את המשאב כלל.", "ב. שני חוטים (חוט 0 וחוט 1) מנסים לרכוש את המשאב בו-זמנית, אך נכנסים למצב שבו כל אחד מהם ממתין לזה השני, ואף אחד מהם אינו מתקדם.", "ג. חוט אחד (למשל, חוט 1) רוכש את המשאב ונכשל בשחרורו עקב באג בקוד, ובכך מונע מכל החוטים האחרים לגשת למשאב.", "ד. חוט 0 משנה את ערך המשתנה turn ל-1, ומיד לאחר מכן חוט 1 משנה את turn ל-0, מה שיוצר לולאה אינסופית שבה שני החוטים משנים את turn ללא הרף אך אף אחד אינו נכנס לקטע הקריטי."]}, "solution": {"correct_option": "א", "explanation": "אפשרות א' מתארת במדויק את הגדרת ההרעבה כפי שהוצגה בחומר הקורס: 'תהליך (חוט) שחסום בזמן שחוטים אחרים מתקדמים'. כמו כן, ההסבר מדגיש את הנקודה ש'בשביל הרעבה צריך שיהיה מישהו שתמיד תופס ומשחרר את המשאב' – כלומר, חוט אחד (חוט 1 בדוגמה) מצליח להתקדם שוב ושוב, בעוד חוט אחר (חוט 0) נחסם באופן עקבי. זהו בדיוק התרחיש שתואר בהקשר של מנעולים לא הוגנים, למשל בבעיית ה-Reader-Writer lock שבה קוראים רבים יכולים להרעיב כותב, או בתזמון מסוים עם קוד מנעול דומה לזה שהוצג, שבו חוט אחד יכול להתקדם תמיד על חשבון השני."}, "_source_file": "0287__Concurrency__Starvation__MC__Hard.json", "_topic_hint": "Starvation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:04:06", "_subject": "Concurrency", "_context_lectures": [16, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Starvation"], "difficulty_estimation": "Hard", "content": {"text": "איזו מהטענות הבאות מתארת בצורה המדויקת ביותר מצב של הרעבה (starvation), כפי שהוגדר בחומר הקורס, ומבחינה אותו מבאג בקוד או קיפאון?", "code_snippet": null, "options": ["א. חוט אחד חסום באופן קבוע מלהתקדם בקטע קריטי, מכיוון שחוט אחר תפס את המשאב הדרוש ומחזיק בו ללא שחרור.", "ב. כל החוטים במערכת חסומים בו-זמנית, כאשר כל אחד ממתין למשאב שמוחזק על ידי חוט חסום אחר.", "ג. חוט מסוים אינו מצליח לקבל גישה למשאב משותף, למרות שחוטים אחרים תמיד תופסים ומשחררים את המשאב הזה, ובכך ממשיכים להתקדם.", "ד. חוט אינו מסוגל להתבצע כלל עקב הגדרת עדיפות נמוכה, בעוד חוטים בעלי עדיפות גבוהה יותר ממשיכים לרוץ על המעבד."]}, "solution": {"correct_option": "ג", "explanation": "על פי חומר הקורס, הרעבה מתרחשת כאשר \"תהליך מורעב (כפי שלמדנו בקורס) הוא תהליך (חוט) שחסום בזמן שחוטים אחרים מתקדמים\". כמו כן, ההגדרה מדגישה כי \"בשביל הרעבה צריך שיהיה מישהו שתמיד תופס ומשחרר את המשאב\", בניגוד למצב בו חוט תופס את המשאב ומחזיק בו לנצח, שמוגדר כ\"באג בקוד\". תשובה ג' מתארת בדיוק מצב זה: חוט חסום מגישה למשאב, בעוד שחוטים אחרים כן מצליחים לתפוס ולשחרר את המשאב, ובכך מתקדמים.\n\nהסבר מדוע שאר התשובות אינן נכונות:\n- תשובה א' מתארת מצב של באג בקוד, שבו חוט תופס משאב ואינו משחרר אותו לעולם, ולא הרעבה כהגדרתה בקורס.\n- תשובה ב' מתארת מצב של קיפאון (deadlock), שבו כל החוטים חסומים ואיש אינו מתקדם. הרעבה, לעומת זאת, דורשת שחוטים אחרים יתקדמו בזמן שהחוט המורעב חסום.\n- תשובה ד' מתארת סוג של הרעבה שיכולה לנבוע מתזמון לא הוגן על המעבד, אך ההגדרה הספציפית בחומר הקורס התמקדה בחסימה מגישה למשאב שמשוחרר ונתפס באופן חוזר על ידי חוטים אחרים, ומבדילה זאת במפורש ממצב של החזקה קבועה של משאב. לכן, תשובה ג' מדויקת יותר להגדרה שניתנה."}, "_source_file": "0288__Concurrency__Starvation__MC__Hard.json", "_topic_hint": "Starvation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:04:22", "_subject": "Concurrency", "_context_lectures": [16, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["File System Structure"], "difficulty_estimation": "Easy", "content": {"text": "מהי מטרתו העיקרית של ה-inode במערכת קבצים, כפי שתואר בחומר השיעור?", "code_snippet": null, "options": ["א. לאחסן את הנתונים בפועל של הקובץ.", "ב. לשמור את כל המידע על הקובץ (metadata).", "ג. לתאם את הגישה לדיסק עבור פעולות קריאה וכתיבה.", "ד. לנהל רשימה של מקומות פנויים בדיסק."]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר השיעור, \"נשמור איזור מסוים בדיסק שיכיל את ה-metadata, כלומר את כל המידע על הקבצים, ונקרא לאזור הזה inode.\" ה-inode מכיל פרטים כמו סוג הקובץ, בעלים, הרשאות, גודל, ובלוקי נתונים (הפניות אליהם), שכולם מהווים metadata על הקובץ. אפשרות א' שגויה מכיוון שה-inode אינו מכיל את נתוני הקובץ בפועל, אלא מצביע על בלוקי הנתונים. אפשרויות ג' וד' מתארות תפקידים אחרים של מערכת הקבצים שאינם מטרתו העיקרית של ה-inode עצמו."}, "_source_file": "0289__File_Systems__File_System_Structure__MC__Easy.json", "_topic_hint": "File System Structure", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:04:32", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["File System Structure"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, מהו התפקיד העיקרי של ה-inode במבנה מערכת קבצים?", "code_snippet": null, "options": ["א. לאחסן את התוכן הממשי של קובץ או תיקייה.", "ב. לאחסן מטא-דאטה (metadata) אודות קובץ או תיקייה, הכולל מידע כגון סוג, בעלים, הרשאות ורשימת בלוקי הנתונים.", "ג. לנהל רשימה של כל הבלוקים הפנויים בדיסק לצורך הקצאה עתידית.", "ד. לשמש כבופר זמני לנתונים הנקראים מהדיסק לפני שהם נמסרים ליישום."]}, "solution": {"correct_option": "ב", "explanation": "חומר ההרצאה מציין במפורש כי 'נשמור איזור מסוים בדיסק שיכיל את ה-metadata, כלומר את כל המידע על הקבצים, ונקרא לאזור הזה inode.' הרשימה שמופיעה בחומר ההרצאה תחת 'Inode' כוללת פריטים כמו Type (file / directory), UID (owner), rwx (permissions), Data blocks, ועוד, המהווים כולם מטא-דאטה. לכן, התפקיד העיקרי של ה-inode הוא לאחסן מידע זה. אפשרות א' שגויה מכיוון שבלוקי הנתונים (data blocks) הם אלו המאחסנים את התוכן הממשי. אפשרויות ג' ו-ד' מתארות תפקידים של רכיבים אחרים במערכת קבצים (כגון מנהל שטח פנוי או מנגנון מטמון), ולא את התפקיד הישיר של ה-inode עצמו."}, "_source_file": "0290__File_Systems__File_System_Structure__MC__Easy.json", "_topic_hint": "File System Structure", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:04:42", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["File System Structure"], "difficulty_estimation": "Easy", "content": {"text": "מהו התפקיד העיקרי של ה-inode במערכת קבצים, כפי שתואר בחומר הלימוד?", "code_snippet": null, "options": ["א. לאחסן את הנתונים (תוכן) בפועל של הקובץ או התיקייה.", "ב. לאחסן את המידע על הקובץ או התיקייה (metadata), כגון סוג, הרשאות ומיקומי בלוקי הנתונים.", "ג. לרשום את כל הבלוקים הפנויים הקיימים בדיסק הקשיח.", "ד. לשמש כ-cache מהיר עבור פעולות קריאה חוזרות ונשנות."]}, "solution": {"correct_option": "ב", "explanation": "בחומר הלימוד מצוין במפורש כי ה-inode הוא אזור בדיסק המכיל את ה-metadata, כלומר את כל המידע על הקבצים. מידע זה כולל פרטים כמו סוג הקובץ/תיקייה, בעלים (UID), הרשאות (rwx), גודל, ובלוקי הנתונים המשויכים לקובץ. ה-inode אינו מכיל את תוכן הקובץ עצמו, אלא את המידע המאפשר למערכת הקבצים למצוא ולארגן את התוכן."}, "_source_file": "0291__File_Systems__File_System_Structure__MC__Easy.json", "_topic_hint": "File System Structure", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:04:49", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["File System Structure"], "difficulty_estimation": "Easy", "content": {"text": "מהו תפקידו העיקרי של ה-inode במערכת קבצים?", "code_snippet": null, "options": ["א. לאחסן מטא-דאטה אודות קובץ או תיקייה, כגון סוג, הרשאות ומיקומי בלוקי הנתונים שלו.", "ב. לאחסן את שם הקובץ ואת תוכן הקובץ עצמו.", "ג. לשמור רשימה מקושרת של כל הקבצים הקיימים במערכת הקבצים.", "ד. לשמש כ-cache מהיר לגישה לנתונים הנפוצים ביותר."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, inode הוא אזור מסוים בדיסק שמכיל את ה-metadata, כלומר את כל המידע על הקבצים. המידע המפורט שנשמר ב-inode כולל: סוג (קובץ/תיקייה), UID, הרשאות (rwx), גודל, בלוקי נתונים (Data blocks), זמני גישה/יצירה וספירת קישורים. לכן, תפקידו העיקרי הוא לאחסן מטא-דאטה קריטי אודות קבצים ותיקיות, כולל הפניות למיקומי הנתונים הפיזיים שלהם בדיסק. אפשרויות ב', ג' ו-ד' אינן מתארות נכונה את תפקידו או תוכנו של ה-inode על פי החומר."}, "_source_file": "0292__File_Systems__File_System_Structure__MC__Easy.json", "_topic_hint": "File System Structure", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:05:00", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["File System Structure"], "difficulty_estimation": "Medium", "content": {"text": "לפי חומר ההרצאה, מהי המטרה העיקרית של Inode במערכת קבצים ומהי אחת ההשלכות של אופן השימוש בו בפעולות בסיסיות כמו פתיחת קובץ?", "code_snippet": null, "options": ["א. Inode מאחסן את תוכן הקובץ עצמו, והשימוש בו מוביל לגישה אחת בלבד לדיסק לפתיחת קובץ.", "ב. Inode מכיל את המטא-דאטה (metadata) של הקובץ, כגון סוג, הרשאות ובלוקי נתונים, והגישה אליו כרוכה במספר רב של גישות לדיסק בפעולת פתיחת קובץ.", "ג. Inode משמש לניהול רשימת המקומות הפנויים בדיסק, והוא תמיד נטען לזיכרון הראשי כדי למנוע גישות לדיסק.", "ד. Inode הוא מבנה נתונים זמני שנוצר בזיכרון הראשי בלבד בעת ריצת התוכנית, ואינו נשמר בדיסק."]}, "solution": {"correct_option": "ב", "explanation": "חומר ההרצאה מציין במפורש כי Inode הוא אזור בדיסק המכיל את המטא-דאטה (metadata) של הקבצים, כלומר את כל המידע עליהם, ולא את תוכן הקובץ עצמו. המטא-דאטה כוללת פרטים כמו סוג הקובץ, UID, הרשאות (rwx), גודל בבתים, בלוקי נתונים, זמנים ומספר קישורים. בנוסף, ההרצאה מדגישה כי פעולות בסיסיות כמו פתיחת קובץ (/foo/bar) דורשות מספר רב של גישות לדיסק (למשל, 5 גישות רק כדי לפתוח קובץ, ללא קריאה), מכיוון שיש צורך לחצות את נתיב הקובץ על ידי קריאת Inodes ובלוקי נתונים שונים מהדיסק."}, "_source_file": "0293__File_Systems__File_System_Structure__MC__Medium.json", "_topic_hint": "File System Structure", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:05:13", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["File System Structure"], "difficulty_estimation": "Medium", "content": {"text": "על פי עקרונות מימוש מערכות קבצים, מהו התפקיד המרכזי של מבנה הנתונים inode בתהליך איתור וגישה לתוכן של קובץ?", "code_snippet": null, "options": ["א. ה-inode מאחסן את התוכן המלא של הקובץ, ובכך מייתר את הצורך בגישה לבלוקי נתונים נפרדים.", "ב. ה-inode מכיל את שם הקובץ ואת הנתיב המלא שלו במערכת הקבצים, מה שמאפשר למערכת למצוא אותו במהירות.", "ג. ה-inode מכיל את המטא-דאטה של הקובץ, כגון סוג, הרשאות, גודל, ורשימה של בלוקי הנתונים הפיזיים המרכיבים את הקובץ.", "ד. ה-inode משמש בעיקר לרישום בלוקים פנויים בדיסק ואינו מכיל מידע ספציפי לקובץ בודד."]}, "solution": {"correct_option": "ג", "explanation": "התשובה הנכונה היא ג'. ה-inode הוא מבנה נתונים חיוני במערכות קבצים (כמו ה-vsfs שהוצגה כדוגמה לימודית) אשר מוקצה לכל קובץ או תיקייה. תפקידו העיקרי הוא לאחסן את כל המטא-דאטה (מידע על המידע) אודות הקובץ, כפי שצוין בחומר ההרצאה: \"נשמור איזור מסוים בדיסק שיכיל את ה-metadata, כלומר את כל המידע על הקבצים, ונקרא לאזור הזה inode\". מידע זה כולל את סוג הקובץ (קובץ רגיל או תיקייה), זכויות גישה (rwx), מזהה הבעלים (UID), גודל הקובץ בבתים, זמני גישה ויצירה, וחשוב מכל, רשימה של בלוקי הנתונים הפיזיים בדיסק שבהם מאוחסן תוכן הקובץ בפועל. באמצעות רשימת בלוקי הנתונים, מערכת הקבצים יכולה לאתר ולקרוא את תוכן הקובץ. אפשרויות א', ב' ו-ד' אינן נכונות מכיוון שה-inode אינו מכיל את תוכן הקובץ עצמו (אלא הפניות לבלוקים), אינו מאחסן את שם הקובץ או הנתיב המלא (אלו נשמרים בתיקיות), ואינו משמש לניהול בלוקים פנויים."}, "_source_file": "0294__File_Systems__File_System_Structure__MC__Medium.json", "_topic_hint": "File System Structure", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:05:25", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["File System Structure"], "difficulty_estimation": "Medium", "content": {"text": "מהי הסיבה המרכזית לכך שמערכת קבצים מאחסנת מטא-נתונים (כדוגמת Inodes) ישירות על גבי הדיסק, ומהי השלכה ביצועית ישירה של גישה זו על פעולות קבצים בסיסיות?", "code_snippet": null, "options": ["א. הבטחת עמידות הנתונים (persistence) במקרה של כיבוי המערכת, וכתוצאה מכך נדרשות גישות מרובות לדיסק רק לצורך פתיחת קובץ.", "ב. שיפור מהירות הקריאה על ידי שמירת Inodes בזיכרון המטמון (cache), והפחתת הצורך בגישות לדיסק עבור פעולות כתיבה.", "ג. מתן אפשרות לניתוק והעברת הדיסק בין מערכות שונות, וייעול ניהול המקום הפנוי על הדיסק.", "ד. הפחתת השימוש בזיכרון הראשי של המערכת, ופישוט הממשק של מערכת הקבצים למשתמש."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מציין במפורש כי \"אנחנו צריכים לקחת בחשבון שבכל רגע נתון המחשב עלול להיכבות והנתונים שלנו צריכים להישאר שם כשנדליק מחדש את המחשב.\" זוהי הסיבה המרכזית לאחסון נתוני מערכת הקבצים, כולל מטא-נתונים כמו Inodes, ישירות על גבי הדיסק - כדי להבטיח את עמידותם (persistence) מעבר למחזורי הפעלה. ההשלכה הביצועית הישירה של גישה זו מוזכרת גם היא בבירור: \"5 reads just to open a file!\" המתארת כיצד פתיחת קובץ פשוט (לדוגמה, /foo/bar) דורשת מספר רב של גישות לדיסק רק כדי לאתר את ה-Inode הרצוי, לפני שבכלל מתבצעת קריאת התוכן עצמו. לכן, אפשרות א' נכונה."}, "_source_file": "0295__File_Systems__File_System_Structure__MC__Medium.json", "_topic_hint": "File System Structure", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:05:39", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["File System Structure"], "difficulty_estimation": "Medium", "content": {"text": "מהו התפקיד העיקרי של ה-inode במערכת קבצים, כפי שתואר בחומר הלימוד?", "code_snippet": null, "options": ["א. לאחסן את התוכן בפועל של הקובץ (כלומר, את הנתונים).", "ב. לשמש כמבנה נתונים על הדיסק המכיל את כל המטא-דאטה של הקובץ, כגון הרשאות, גודל ומצביעים לבלוקי הנתונים.", "ג. לתעד את רשימת הקבצים הפנויים במערכת הקבצים.", "ד. לשמש כ-cache בזיכרון עבור גישות מהירות לנתוני קבצים שבהם נעשה שימוש תכוף."]}, "solution": {"correct_option": "ב", "explanation": "החומר מציין במפורש כי ה-inode הוא \"איזור מסוים בדיסק שיכיל את ה-metadata, כלומר את כל המידע על הקבצים\". הוא מכיל פרטים כמו סוג הקובץ, בעלים, הרשאות (rwx), גודל, זמני גישה ויצירה, וחשוב מכך, מצביעים לבלוקי הנתונים של הקובץ. תפקידו הוא לאפשר למערכת הקבצים לאתר ולנהל את המידע אודות קובץ מסוים, בניגוד לתוכן הקובץ עצמו (אשר מאוחסן בבלוקי הנתונים שאליהם ה-inode מפנה). אפשרויות א, ג ו-ד אינן מתארות את תפקידו המוגדר של ה-inode בחומר הלימוד."}, "_source_file": "0296__File_Systems__File_System_Structure__MC__Medium.json", "_topic_hint": "File System Structure", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:05:50", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["File System Structure"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על מבנה מערכת קבצים טיפוסית דוגמת vsfs, ומתוך הבנה שנתונים חייבים לשרוד כיבוי מערכת, איזה מההיגדים הבאים מסביר בצורה הטובה ביותר את העלות הגבוהה במונחי גישות לדיסק עבור פעולה כמו פתיחת קובץ בנתיב עמוק (לדוגמה, /foo/bar), גם ללא קריאת תוכן הקובץ עצמו?", "code_snippet": null, "options": ["א. הצורך לחפש באופן סדרתי בתוך בלוקי הנתונים של כל ספרייה בנתיב את מספר ה-inode של הספריה הבאה או הקובץ הסופי, תוך כדי קריאת ה-inode המתאים לכל אחת מהן, וזאת מכיוון שכל המידע חייב להיות מאוחסן באופן עמיד בדיסק.", "ב. מערכת הקבצים נדרשת לטעון את כל ה-bitmaps של הקבצים הפנויים בנתיב כדי לוודא שהקובץ אינו פגום, פעולה הדורשת גישות דיסק רבות.", "ג. כל פעולת open דורשת כתיבה לדיסק לצורך עדכון זמני גישה (access times) ב-inode, וכל כתיבה כזו גוררת קריאה מקדימה של ה-inode המלא.", "ד. מערכות קבצים מודרניות כמו LFS מתעדפות אופטימיזציה של כתיבות על חשבון קריאות, ולכן פעולות קריאה מורכבות יותר כמו פתיחת קובץ סובלות מעלות גבוהה יותר בגישות לדיסק."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. ההסבר טמון במבנה ההיררכי של מערכת הקבצים והדרישה לעמידות הנתונים (persistence). כאשר אנו פותחים קובץ בנתיב עמוק כגון /foo/bar, מערכת הקבצים נדרשת לבצע מעבר על כל רכיבי הנתיב החל משורש מערכת הקבצים (inode 2). כל שלב במעבר זה דורש גישות לדיסק: קריאת בלוק הנתונים של הספריה הנוכחית כדי למצוא את מספר ה-inode של רכיב הנתיב הבא, ולאחר מכן קריאת ה-inode של רכיב הנתיב הבא עצמו. תהליך זה חוזר על עצמו עבור כל רכיב בנתיב. עבור /foo/bar, זה אומר: קריאת inode של השורש, קריאת בלוק הנתונים של השורש כדי למצוא את ה-inode של 'foo', קריאת ה-inode של 'foo', קריאת בלוק הנתונים של 'foo' כדי למצוא את ה-inode של 'bar', וקריאת ה-inode של 'bar'. סה\"כ 5 גישות לדיסק, כפי שמצוין בחומר הלימוד, וזאת רק כדי לאתר את הקובץ ולא לקרוא את תוכנו. דרישת העמידות (persistence) היא קריטית, שכן כל המידע הזה חייב להיות מאוחסן על הדיסק כדי לשרוד כיבוי מערכת, ולכן לא ניתן להסתמך רק על זיכרון נדיף (RAM)."}, "_source_file": "0297__File_Systems__File_System_Structure__MC__Hard.json", "_topic_hint": "File System Structure", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:06:06", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["File System Structure"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על מודל מערכת הקבצים vsfs שהוצג, הכולל אחסון inodes ונתוני ספריות על הדיסק הקשיח לצורך עמידות (persistence), ובהתחשב בדוגמה של 5 גישות דיסק לפתיחת קובץ בודד (/foo/bar), מהי ההשלכה הארכיטקטונית המרכזית על ביצועי המערכת הנובעת באופן ישיר מאופן ניהול המטא-דאטה?", "code_snippet": null, "options": ["א. הצורך בביצוע פעולות קריאה/כתיבה מרובות ולא רציפות (scattered I/O) לדיסק עבור גישה למטא-דאטה (כמו inodes ותוכן ספריות), דבר המגביל את ביצועי פתיחת וגישת קבצים.", "ב. הקושי בשמירה על עקביות הנתונים (data consistency) בין עותקי המטא-דאטה בזיכרון ה-cache לבין אלו שעל הדיסק, במיוחד לאחר קריסות מערכת.", "ג. הגודל המוגבל של ה-inodes, המונע אחסון מידע רב מדי על קבצים גדולים במיוחד ודורש מבני נתונים מורכבים נוספים.", "ד. העלות הגבוהה של הקצאת בלוקים חדשים לנתוני קבצים, הדורשת עדכון מתמיד של מפות בלוקים פנויים (free block bitmaps) על הדיסק, מה שמאט פעולות כתיבה."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. החומר המצוין מדגיש כי במערכת קבצים כמו vsfs, המטא-דאטה (כגון inodes ותוכן ספריות) מאוחסן על הדיסק הקשיח על מנת להבטיח עמידות נתונים במקרה של כיבוי המערכת. דוגמת פתיחת הקובץ /foo/bar ממחישה שפעולה זו דורשת 5 גישות לדיסק רק כדי לאתר את ה-inode של הקובץ המבוקש. כל גישה לדיסק היא פעולה יקרה מבחינת זמן, ובמיוחד כאשר הגישות אינן רציפות (scattered I/O) והן מפוזרות על פני אזורים שונים בדיסק (עבור inodes ובלוקי נתונים של ספריות שונות). אתגר ארכיטקטוני מרכזי זה, של ביצועי גישה איטיים כתוצאה מריבוי גישות דיסק למטא-דאטה, הוא תוצאה ישירה של אופן הארגון והאחסון של המטא-דאטה על הדיסק. אפשרויות ב', ג' ו-ד' מתארות בעיות קיימות או פוטנציאליות במערכות קבצים, אך הן אינן ההשלכה הארכיטקטונית המרכזית המודגשת באופן ישיר על ידי הדוגמה הספציפית של 5 גישות הדיסק לפתיחת קובץ, המתמקדת בעלות ביצועי הגישה למטא-דאטה."}, "_source_file": "0298__File_Systems__File_System_Structure__MC__Hard.json", "_topic_hint": "File System Structure", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:06:21", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["File System Structure"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על העקרונות של מימוש מערכת קבצים כפי שתוארו בחומר הלימוד, ובפרט על הדרישה לשמר נתונים באופן קבוע גם לאחר כיבוי המחשב, מהי ההשלכה המהותית ביותר של מבנה מערכת הקבצים על ביצועי פעולת פתיחת קובץ (ללא קריאת תוכן) כמו `/foo/bar`?", "code_snippet": null, "options": ["א. ריבוי גישות לדיסק (Disk I/O) כתוצאה ממעבר על נתיב הקובץ וקריאת מטא-נתונים (inodes) ובלוקי נתונים של ספריות.", "ב. הצורך לטעון את כל תוכן הקובץ לזיכרון הראשי לפני שניתן לגשת אליו, מה שיוצר עומס כבד על ה-RAM.", "ג. קושי בשמירת עקביות הנתונים במקרה של קריסות מערכת, מכיוון שאין מבנה זיכרון וירטואלי ייעודי למערכת הקבצים.", "ד. הגבלת גודל הקובץ המקסימלי בשל מבנה ה-inode הפשוט שאינו תומך בהפניות עקיפות רבות."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. החומר המצוין בשיעור 20, בפרט בדוגמת פתיחת הקובץ `/foo/bar`, מדגיש כי פעולה זו דורשת 5 גישות לדיסק *רק לצורך הפתיחה*, עוד לפני קריאת תוכן הקובץ. הסיבה לכך נובעת מהצורך של מערכת הקבצים לעבור על נתיב הקובץ (pathname) ולטעון את המטא-נתונים (inodes) ובלוקי הנתונים של הספריות המרכיבות את הנתיב, כפי שמתואר: 'Begin at root: well-known, usually inode 2', 'Read block that contains inode 2', 'Look inside it – read data block to find inode number of foo', 'Read inode of foo to find data block of foo', 'Read data blocks of foo to find inode of bar', 'Read inode of bar'. דרישה זו נובעת מכך שכל המידע על מבנה מערכת הקבצים, כולל נתוני ה-metadata והקשר בין שמות לקבצים בתוך ספריות, חייב להישמר על הדיסק באופן קבוע ('הנתונים שלנו צריכים להישאר שם כשנדליק מחדש את המחשב') ואינו יכול להישמר באופן מלא בזיכרון הראשי בלבד. אפשרויות ב', ג' ו-ד' אינן נכונות: אפשרות ב' אינה נכונה מכיוון שהטקסט מציין במפורש שזוהי פעולת פתיחה בלבד ולא קריאת תוכן. אפשרות ג' אומנם נוגעת בסוגיית עקביות וזיכרון, אך אינה מתייחסת ישירות להשלכה הביצועית של פתיחת קובץ כתוצאה ממבנה מערכת הקבצים. אפשרות ד' אינה נכונה מכיוון שהחומר הנתון אינו מספק מידע על מגבלות גודל קובץ או על מבנה ספציפי של inode המגביל הפניות עקיפות."}, "_source_file": "0299__File_Systems__File_System_Structure__MC__Hard.json", "_topic_hint": "File System Structure", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:06:40", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["File System Structure"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על מודל מערכת הקבצים `vsfs` שהוצג, אשר מדגיש את הצורך באחסון פרסיסטנטי של מטא-דאטה ונתונים בדיסק, מהי הסיבה העיקרית לכך שפעולת 'פתיחת קובץ' (open) של נתיב היררכי כמו `/foo/bar` דורשת מספר גישות לדיסק, ואיזו בעיה ביצועית מרכזית נובעת מכך?", "code_snippet": null, "options": ["א. הצורך לטייל במבנה ההיררכי של הספריות, כאשר כל שלב דורש קריאת בלוק נתונים של ספרייה כדי למצוא את מספר ה-inode הבא, ולאחר מכן קריאת בלוק ה-inode עצמו. בעיה ביצועית מרכזית היא העלות הגבוהה של גישות מרובות לדיסק.", "ב. הגודל המוגבל של הזיכרון הפנימי של מערכת ההפעלה, אשר מונע שמירה של כל ה-inodes בזיכרון הראשי ודורש טעינה שלהם מהדיסק בכל פעם. הבעיה המרכזית היא בזבוז זיכרון.", "ג. הצורך לבדוק הרשאות גישה לכל קובץ וספרייה בנתיב, כאשר בדיקה זו מחייבת קריאת בלוק ה-inode של כל רכיב. הבעיה המרכזית היא עומס חישובי על המעבד.", "ד. מערכת הקבצים מפצלת בכוונה את הנתונים והמטא-דאטה לבלוקים נפרדים על הדיסק, מה שמבטיח עמידות נתונים גבוהה יותר אך דורש גישות נפרדות לכל חלק. הבעיה המרכזית היא סיבוכיות יתרה במימוש."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. החומר המצוין בשיעור מפרט במדויק את תהליך פתיחת הקובץ `/foo/bar`:\n1. מתחילים בשורש (inode 2).\n2. קוראים את הבלוק שמכיל את inode 2.\n3. קוראים את בלוק הנתונים של ספריית השורש כדי למצוא את מספר ה-inode של `foo`.\n4. קוראים את ה-inode של `foo` כדי למצוא את בלוק הנתונים של `foo`.\n5. קוראים את בלוק הנתונים של `foo` כדי למצוא את ה-inode של `bar`.\n6. קוראים את ה-inode של `bar`.\nכל שלב כזה, כפי שהוזכר בחומר, דורש גישה לדיסק (סה\"כ 5 גישות רק לפתיחת הקובץ, עוד לפני קריאה). הסיבה המרכזית היא הצורך לטייל במבנה ההיררכי, כאשר כל רכיב בנתיב (ספרייה או קובץ) דורש קריאה של המטא-דאטה שלו (inode) ושל נתוניו (בלוק נתונים של ספרייה) כדי לאתר את הרכיב הבא. בעיה ביצועית מרכזית הנובעת מכך היא העלות הגבוהה והאיטיות של גישות דיסק מרובות וסדרתיות.\n\nאפשרויות אחרות אינן נכונות:\nב. למרות שה-cache יכול לסייע, הבעיה המבנית של ריבוי גישות לדיסק נשארת. החומר מציין שפעולות קריאה משתפרות בזכות ה-cache, אך הדוגמה של 5 גישות לפתיחת קובץ מדגישה את העלות המבנית הבסיסית. הבעיה אינה בזבוז זיכרון אלא גישות איטיות לדיסק.\nג. בדיקת הרשאות היא אכן חלק מתהליך ודורשת קריאת ה-inode, אך הסיבה העיקרית לריבוי הגישות היא איתור מיקום הרכיבים בנתיב ההיררכי, ולא רק בדיקת ההרשאות. העומס החישובי על המעבד זניח יחסית לזמן ההמתנה לגישות דיסק.\nד. הפרדה בין נתונים למטא-דאטה אכן קיימת, אך היא אינה הסיבה הישירה ל-5 הגישות הספציפיות לפתיחת קובץ. הסיבה היא תהליך הטיול בנתיב ההיררכי. עמידות נתונים וסיבוכיות מימוש אינן הבעיה הביצועית המרכזית המתוארת בהקשר זה."}, "_source_file": "0300__File_Systems__File_System_Structure__MC__Hard.json", "_topic_hint": "File System Structure", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:06:57", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Inodes"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, אילו סוגי מידע מאוחסנים בדרך כלל ב-inode עבור קובץ?", "code_snippet": null, "options": ["א. התוכן הממשי של הקובץ (הנתונים).", "ב. שם הקובץ המלא ונתיבו במערכת הקבצים.", "ג. מטא-נתונים על הקובץ, כגון סוגו, גודלו, הרשאות הגישה שלו ומיקומי בלוקי הנתונים שלו.", "ד. כל מבנה ה-imap עבור כל הקבצים במערכת."]}, "solution": {"correct_option": "ג", "explanation": "החומר המצוין בהרצאה קובע במפורש כי inode מכיל \"סוג, גודל, הרשאות גישה, איפה המידע שלו נמצא ועוד..\". מידע זה מתאר את המאפיינים של הקובץ ואת מיקומו הפיזי בדיסק, אך לא את תוכן הקובץ עצמו (שנמצא בבלוקי נתונים אליהם ה-inode מפנה), ולא את שמו (שנמצא במבני ספריות). אפשרות ד' שגויה מכיוון ש-imap הוא מבנה נפרד המצביע על הגרסאות העדכניות של ה-inodes, ולא חלק מ-inode יחיד."}, "_source_file": "0301__File_Systems__Inodes__MC__Easy.json", "_topic_hint": "Inodes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:07:04", "_subject": "File Systems", "_context_lectures": [20, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Inodes"], "difficulty_estimation": "Easy", "content": {"text": "איזה מן הפרטים הבאים אינו נשמר בדרך כלל בתוך ה-inode עצמו, אלא במבנה נתונים אחר במערכת הקבצים?", "code_snippet": null, "options": ["א. גודל הקובץ", "ב. הרשאות הגישה לקובץ", "ג. סוג הקובץ", "ד. שם הקובץ"]}, "solution": {"correct_option": "ד", "explanation": "ה-inode מכיל מטא-נתונים חיוניים על הקובץ, כגון סוג הקובץ, גודלו, הרשאות הגישה אליו, ומיקום בלוקי הנתונים שלו בדיסק, כפי שצוין בחומר ההרצאה: \"inode: סוג, גודל, הרשאות גישה, איפה המידע שלו נמצא ועוד..\". לעומת זאת, שם הקובץ אינו נשמר בתוך ה-inode עצמו. שמות קבצים נשמרים בדרך כלל בתוך רשומות ספרייה (directory entries), אשר מקשרות את השם למספר ה-inode המתאים."}, "_source_file": "0302__File_Systems__Inodes__MC__Easy.json", "_topic_hint": "Inodes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:07:14", "_subject": "File Systems", "_context_lectures": [20, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Inodes"], "difficulty_estimation": "Easy", "content": {"text": "איזה סוג מידע עיקרי מאוחסן ב-inode עבור קובץ במערכת קבצים?", "code_snippet": null, "options": ["א. סוג הקובץ, גודלו, הרשאות גישה ומספרי הבלוקים המכילים את תוכן הקובץ.", "ב. שם הקובץ המלא ונתיבו במערכת הקבצים.", "ג. הגרסה העדכנית ביותר של ה-imap עבור ה-inode.", "ד. מידע על בלוק ה-Super Block ומיקום ה-inode bitmap."]}, "solution": {"correct_option": "א", "explanation": "לפי חומר ההרצאה, inode מכיל פרטים על הקובץ כגון סוג הקובץ, גודלו, הרשאות גישה וכן את מספרי הבלוקים בדיסק שבהם נמצא התוכן של הקובץ ('איפה המידע שלו נמצא'). אפשרויות ב', ג' ו-ד' מתארות מידע המאוחסן במקומות אחרים במערכת הקבצים (כמו בערכי תיקיות עבור שמות קבצים, ב-imap עבור מיפויים של inodes, או ב-Super Block עבור מידע כללי על מערכת הקבצים), ולא ב-inode עצמו."}, "_source_file": "0303__File_Systems__Inodes__MC__Easy.json", "_topic_hint": "Inodes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:07:26", "_subject": "File Systems", "_context_lectures": [20, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Inodes"], "difficulty_estimation": "Easy", "content": {"text": "איזה מהפרטים הבאים **אינו** נשמר ישירות בתוך inode?", "code_snippet": null, "options": ["א. גודל הקובץ", "ב. הרשאות הגישה לקובץ", "ג. שם הקובץ", "ד. מספרי הבלוקים המכילים את תוכן הקובץ"]}, "solution": {"correct_option": "ג", "explanation": "על פי חומר ההרצאה, inode מכיל פרטים כגון סוג הקובץ, גודלו, הרשאות הגישה שלו, וכן את מספרי הבלוקים בדיסק המכילים את תוכן הקובץ ('איפה המידע שלו נמצא'). שם הקובץ אינו נזכר כפרט הנשמר בתוך ה-inode בחומר ההרצאה, ולכן הוא התשובה הנכונה לשאלה מה אינו נשמר ישירות ב-inode."}, "_source_file": "0304__File_Systems__Inodes__MC__Easy.json", "_topic_hint": "Inodes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:07:35", "_subject": "File Systems", "_context_lectures": [20, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Inodes"], "difficulty_estimation": "Medium", "content": {"text": "על פי חומר ההרצאה, אילו פרטים נשמרים ב-inode עבור קובץ נתון במערכת קבצים?", "code_snippet": null, "options": ["א. הנתונים הבינאריים בפועל של תוכן הקובץ.", "ב. מטה-דאטה אודות הקובץ, כגון סוג, גודל, הרשאות גישה, וכן הפניות לבלוקים המכילים את תוכן הקובץ.", "ג. מפת סיביות (bitmap) המציינת אם ה-inode פנוי או תפוס לשימוש.", "ד. מספר הגרסה העדכני של ה-inode כפי שמתועד במבנה ה-imap."]}, "solution": {"correct_option": "ב", "explanation": "חומר ההרצאה מציין במפורש כי inode מכיל 'סוג, גודל, הרשאות גישה, איפה המידע שלו נמצא ועוד..', ובנוסף 'מכיל את מספרי הבלוקים בהם נמצא התוכן של אותו קובץ'. זהו תיאור מדויק של מטה-דאטה הכולל הפניות לבלוקי הנתונים של הקובץ.\nא. שגויה, ה-inode מכיל הפניות לבלוקי הנתונים, לא את הנתונים עצמם של הקובץ.\nג. שגויה, מפת סיביות (inode bitmap) היא מבנה נפרד המשמש למעקב אחר זמינות Inodes, ולא חלק מה-inode עצמו.\nד. שגויה, ה-imap הוא המבנה שמצביע על הגרסה העדכנית של ה-inode, ולא ה-inode עצמו שומר את מספר הגרסה שלו לצרכי מעקב ב-imap."}, "_source_file": "0305__File_Systems__Inodes__MC__Medium.json", "_topic_hint": "Inodes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:07:45", "_subject": "File Systems", "_context_lectures": [20, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Inodes"], "difficulty_estimation": "Medium", "content": {"text": "מהו אחד התפקידים המרכזיים של inode במערכת קבצים, כפי שתואר בחומר ההרצאה, וכיצד הוא מסייע באיתור תוכן קובץ?", "code_snippet": null, "options": ["א. inode מכיל את מספרי הבלוקים בדיסק שבהם מאוחסן תוכן הקובץ, גם אם הם אינם רציפים.", "ב. inode מכיל את ה-hash value של שם הקובץ, המשמש לחיפוש מהיר של הקובץ בטבלת ה-directory.", "ג. inode שומר את הגרסה העדכנית ביותר של הקובץ בזיכרון הראשי (RAM) לצורך גישה מהירה.", "ד. inode מציין את המיקום של ה-superblock, המכיל מידע כללי על מערכת הקבצים."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מציין במפורש כי 'ב-inode יש כל מיני פרטים על הקובץ, ובין השאר, מכיל את מספרי הבלוקים בהם נמצא התוכן של אותו קובץ (הבלוקים שמכילים את התוכן של הקובץ לא חייבים להיות רציפים בדיסק)'. זהו התפקיד המרכזי של ה-inode בקשר למיקום נתוני הקובץ. אפשרויות ב', ג' ו-ד' אינן נתמכות על ידי חומר ההרצאה; inode אינו מכיל ערכי hash של שמות קבצים, אינו שומר את הקובץ כולו ב-RAM (אלא ה-imap מצביע על הגרסה העדכנית של ה-inode עצמו, שבתורו מכיל מצביעים לנתונים), ואינו מצביע על ה-superblock."}, "_source_file": "0306__File_Systems__Inodes__MC__Medium.json", "_topic_hint": "Inodes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:07:56", "_subject": "File Systems", "_context_lectures": [20, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Inodes"], "difficulty_estimation": "Medium", "content": {"text": "על פי חומר ההרצאה, מהו התפקיד המרכזי של ה-imap (inode map) במערכת קבצים?", "code_snippet": null, "options": ["א. הוא מכיל את מספרי הבלוקים הפיזיים המרכיבים את תוכן הקובץ, ובכך מאפשר גישה מהירה לנתוני הקובץ.", "ב. הוא משמש כלי לרישום הגרסה העדכנית ביותר של כל inode, ומאפשר למערכת לאתר את המיקום המעודכן ביותר של ה-inode הרצוי.", "ג. הוא מאחסן את המידע על סוג הקובץ, גודלו והרשאות הגישה שלו, ומתעדכן בכל שינוי בפרטים אלו.", "ד. הוא אחראי על הקצאת בלוקים פנויים בדיסק כאשר נוצר קובץ חדש או כאשר קובץ קיים גדל."]}, "solution": {"correct_option": "ב", "explanation": "חומר ההרצאה מציין במפורש כי \"ה-imap מצביע על הגרסה העדכנית של inode k\" וכן \"עכשיו אם נרצה למצוא inode מסוים, נצטרך להסתכל ב-imap העדכני (המיפוי העדכני) והוא יגיד לנו איפה הגרסה הכי עדכנית של אותו inode ומשם נוכל להגיע לנתון הרצוי.\". מכאן שהתפקיד המרכזי של ה-imap הוא למפות ולשמור את המיקום של הגרסה העדכנית ביותר של כל inode, ובכך לאפשר איתור יעיל של המידע המעודכן על קובץ. אפשרויות א' ו-ג' מתארות מידע הנשמר בתוך ה-inode עצמו (מספרי בלוקים, סוג, גודל, הרשאות), ואילו אפשרות ד' מתארת תפקיד הקשור לניהול בלוקים פנויים, שאינו התפקיד העיקרי של ה-imap כפי שתואר בחומר."}, "_source_file": "0307__File_Systems__Inodes__MC__Medium.json", "_topic_hint": "Inodes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:08:07", "_subject": "File Systems", "_context_lectures": [20, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Inodes"], "difficulty_estimation": "Medium", "content": {"text": "על פי חומר ההרצאה, מהו התפקיד העיקרי של inode במערכת קבצים?", "code_snippet": null, "options": ["א. לאחסן את התוכן הממשי של הקובץ (כלומר, את הנתונים עצמם).", "ב. לתאר את המאפיינים (מטא-דאטה) של הקובץ ולציין את מספרי הבלוקים בהם נמצא תוכן הקובץ.", "ג. לשמור רשימה של כל ה-inodes הפנויים במערכת הקבצים.", "ד. למפות את הגרסאות העדכניות ביותר של כל ה-inodes במערכת."]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר ההרצאה (Lecture 20, chunk 5), inode מכיל את הפרטים על קובץ כגון 'סוג, גודל, הרשאות גישה' וכן 'איפה המידע שלו נמצא' ו'מכיל את מספרי הבלוקים בהם נמצא התוכן של אותו קובץ'. לכן, התפקיד העיקרי של inode הוא לתאר את המאפיינים (מטא-דאטה) של הקובץ ולציין היכן נמצאים בלוקי הנתונים שלו, מה שהופך את אפשרות ב' לנכונה.\nאפשרות א' שגויה מכיוון שה-inode מצביע על מיקום הנתונים אך אינו מכיל את הנתונים עצמם. הנתונים מאוחסנים בבלוקי נתונים נפרדים.\nאפשרות ג' מתארת את תפקידו של ה-inode bitmap, שמשמש למעקב אחר inodes פנויים (Lecture 20, chunk 28).\nאפשרות ד' מתארת את תפקידו של ה-IMAP (Inode Map), שאחראי למפות את הגרסאות העדכניות ביותר של ה-inodes (Lecture 22, chunk 1, 2)."}, "_source_file": "0308__File_Systems__Inodes__MC__Medium.json", "_topic_hint": "Inodes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:08:18", "_subject": "File Systems", "_context_lectures": [20, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Inodes"], "difficulty_estimation": "Hard", "content": {"text": "במערכת קבצים המשתמשת במבנה סגמנטים (segments) וב-imap (inode map) לניהול גרסאות, כיצד קובעת המערכת האם בלוק נתונים (data block) מסוים, שנמצא בתוך סגמנט, אכן מייצג את הגרסה העדכנית והתקפה ביותר של נתוני קובץ המשויכים ל-inode מסוים?", "code_snippet": null, "options": ["א. המערכת פונה ל-imap כדי לאתר את הגרסה העדכנית ביותר של ה-inode הרלוונטי. לאחר מכן, היא בודקת האם בלוק הנתונים שנמצא בסגמנט תואם לאחד מבלוקי הנתונים שמצוינים בגרסת ה-inode העדכנית שאותרה.", "ב. כל בלוק נתונים מכיל מספר גרסה פנימי, אשר מושווה מול מספר הגרסה האחרונה של ה-inode השמור ב-Super Block.", "ג. בלוק סיכום הסגמנט (segment summary block) מכיל רשימה של כל בלוקי הנתונים התקפים בתוכו, כולל חותמת זמן המעידה על תקיפותם.", "ד. ה-inode עצמו מכיל מצביע לבלוק הנתונים העדכני ביותר, והמערכת בודקת אם המצביע הזה תואם למיקום הבלוק בסגמנט."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין בפרק 22, פיסקה 15, מסביר כיצד מתבצעת בדיקת תקיפות זו: \"אם בסגמנט כלשהו אנחנו יודעים שיש דאטה של inode x, נלך ל-imap ונסתכל על הגרסה הכי עדכנית של inode x ונבדוק אם המיקום שנשמר ב-imap לזה למיקום שבסגמנט שאנחנו עכשיו מסתכלים עליו, אם כן, אז הדאטה הזה תקף\". ה-imap משמש כמנגנון המרכזי למציאת הגרסה העדכנית ביותר של כל inode. ברגע שאותרה גרסת ה-inode העדכנית דרך ה-imap, המערכת יכולה לגשת לפרטי ה-inode (כפי שמצוין בפרק 20, פיסקה 5: \"מכיל את מספרי הבלוקים בהם נמצא התוכן של אותו קובץ\") ולבדוק האם בלוק הנתונים שנמצא בסגמנט אכן תואם לאחד מהבלוקים שמצוינים בגרסת ה-inode העדכנית. אפשרות א' מתארת תהליך זה בצורה המדויקת ביותר.\nאפשרות ב' שגויה מכיוון שהחומר אינו מציין כי בלוקי נתונים מכילים מספרי גרסה פנימיים או ש-Super Block מאחסן גרסאות Inode. ה-Super Block מכיל נתונים כלליים על מערכת הקבצים, כולל מספר ה-inodes, אך לא גרסאות ספציפיות.\nאפשרות ג' שגויה מכיוון שבלוק סיכום הסגמנט מתאר את תוכנו של הסגמנט, אך אינו קובע את תקיפות הנתונים באופן מוחלט. התקיפות נקבעת על ידי השוואה למידע העדכני ב-imap.\nאפשרות ד' שגויה מכיוון שאף על פי שה-inode אכן מכיל מצביעים לבלוקי הנתונים שלו, אפשרות זו מתעלמת מהתפקיד המכריע של ה-imap במציאת ה-inode ה*עדכני* ביותר. ללא ה-imap, המערכת עלולה לבדוק inode מיושן, שאינו מייצג את מצב הקובץ העדכני."}, "_source_file": "0309__File_Systems__Inodes__MC__Hard.json", "_topic_hint": "Inodes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:08:55", "_subject": "File Systems", "_context_lectures": [20, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Inodes"], "difficulty_estimation": "Hard", "content": {"text": "במערכת קבצים המשתמשת ב-inodes ובמנגנון IMAP (Inode Map) לניהול גרסאות, מהו המנגנון העיקרי המאפשר למערכת ההפעלה לאתר את הגרסה העדכנית ביותר של inode עבור קובץ נתון, לאחר שבוצעו בו שינויים שגרמו לכתיבת גרסה חדשה של ה-inode למיקום פיזי אחר בדיסק?", "code_snippet": null, "options": ["א. המערכת עושה שימוש ב-IMAP, אשר מכיל מצביעים לגרסאות העדכניות ביותר של כל inode, ודרכו מאתרת את הבלוק הפיזי המכיל את ה-inode המעודכן.", "ב. המערכת סורקת את ה-Inode Bitmap כדי למצוא את ה-inode המסומן כפעיל והעדכני ביותר, ומשם ניגשת לנתוניו.", "ג. המערכת קוראת את ה-Super Block כדי לגלות את מיקומו של ה-inode האחרון שנכתב עבור הקובץ, מכיוון שה-Super Block מתעדכן בכל שינוי.", "ד. המערכת עוברת על כל הסגמנטים בדיסק ובודקת את ה-Segment Summary Block של כל סגמנט כדי לזהות את ה-inode הרלוונטי והעדכני ביותר באמצעות השוואה למידע שנשמר בזיכרון."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה, ה-IMAP (Inode Map) הוא המנגנון שזוכר את הגרסה האחרונה והעדכנית ביותר של כל inode. כאשר מחפשים inode מסוים, המערכת מסתכלת ב-IMAP העדכני, והוא זה שמספק את המיקום הפיזי של הגרסה העדכנית ביותר של אותו inode בדיסק. משם, ניתן לגשת לנתונים הרצויים, כולל מספרי הבלוקים של תוכן הקובץ המצויים בתוך ה-inode עצמו. אפשרויות ב' ו-ג' אינן נכונות: ה-Inode Bitmap משמש למעקב אחר inodes פנויים/תפוסים ולא למיקום גרסאות עדכניות, וה-Super Block מכיל מידע כללי על מערכת הקבצים ומיקומי Bitmaps, אך לא מצביעים לגרסאות ספציפיות של inodes. אפשרות ד' מתארת תהליך של אימות בלוקים בתוך סגמנטים (כדי לבדוק אם הם עדיין רלוונטיים), אך לא את המנגנון העיקרי לאיתור הגרסה העדכנית ביותר של inode מלכתחילה; ה-IMAP הוא המקור הראשוני למיקום זה."}, "_source_file": "0310__File_Systems__Inodes__MC__Hard.json", "_topic_hint": "Inodes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:09:11", "_subject": "File Systems", "_context_lectures": [20, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Inodes"], "difficulty_estimation": "Hard", "content": {"text": "בהתייחס למבנה מערכת קבצים לוגית (Log-Structured File System) כפי שתואר, ובהינתן שבלוקי נתונים של קובץ אינם בהכרח רציפים ומיקומי Inode יכולים להתעדכן, מהי התרומה המרכזית של מנגנון ה-`imap` לאבטחת נכונות הנתונים וגישה יעילה אליהם?", "code_snippet": null, "options": ["א. ה-`imap` שומר את המיקום הפיזי העדכני ביותר של כל inode, ובכך מאפשר גישה מהירה לגרסה התקפה ביותר של ה-inode ואימות תקינותם של בלוקי נתונים בסגמנטים שונים.", "ב. ה-`imap` אחראי להקצאת בלוקי נתונים רציפים עבור כל קובץ, ובכך משפר משמעותית את ביצועי הקריאה והכתיבה.", "ג. ה-`imap` מחליף את הצורך ב-inode bitmap על ידי מעקב ישיר אחר ה-inodes הפנויים והתפוסים במערכת.", "ד. ה-`imap` הוא חלק בלתי נפרד מה-Super Block ומספק מידע כללי על מערכת הקבצים, כגון גודל הדיסק ומספר ה-inodes הכולל."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. מנגנון ה-`imap` נועד לשמור את המיפוי העדכני ביותר של כל inode למיקומו הפיזי בדיסק (Lecture 22, chunk 1: \"ה-imap מצביע על הגרסה העדכנית של inode k\"). זה מאפשר למערכת לגשת במהירות לגרסה התקפה והמעודכנת ביותר של ה-inode, גם כאשר מיקומו משתנה (Lecture 22, chunk 2: \"הוא יגיד לנו איפה הגרסה הכי עדכנית של אותו inode\"). בנוסף, ה-`imap` משמש לאימות תקינותם של בלוקי נתונים ו-inodes בתוך סגמנטים. המערכת בודקת האם המיקום שנשמר ב-`imap` תואם למיקום של הנתונים בסגמנט הנבדק; אם כן, הנתונים תקפים, אחרת הם אינם רלוונטיים (Lecture 22, chunk 15). תשובה ב' שגויה מכיוון שבלוקי נתונים של קובץ אינם חייבים להיות רציפים (Lecture 20, chunk 5: \"הבלוקים שמכילים את התוכן של הקובץ לא חייבים להיות רציפים בדיסק\"). תשובה ג' שגויה מכיוון שה-`imap` עוקב אחר מיקומי inodes ולא מחליף את ה-inode bitmap המשמש למעקב אחר זמינותם (Lecture 20, chunk 28). תשובה ד' שגויה מכיוון שה-`Super Block` מכיל מידע כללי על מערכת הקבצים ומיקומי ה-bitmaps, אך ה-`imap` הוא מנגנון נפרד לעדכון ומעקב אחר מיקומי inodes (Lecture 20, chunk 28; Lecture 22, chunk 1)."}, "_source_file": "0311__File_Systems__Inodes__MC__Hard.json", "_topic_hint": "Inodes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:09:25", "_subject": "File Systems", "_context_lectures": [20, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Inodes"], "difficulty_estimation": "Hard", "content": {"text": "בהינתן שמערכת קבצים מסתמכת על מבנה ה-`imap` (inode map) כדי לעקוב אחר הגרסאות העדכניות ביותר של inodes, וכן שבלוקי הנתונים של קובץ אינם בהכרח רציפים בדיסק, איזו הצהרה מתארת בצורה הטובה ביותר כיצד המערכת מאתרת ומבטיחה גישה לגרסה התקפה והעדכנית ביותר של נתוני קובץ ספציפי?", "code_snippet": null, "options": ["א. המערכת ניגשת תחילה ל-`imap` כדי לקבל את המיקום הפיזי של הגרסה העדכנית ביותר של ה-inode המבוקש. ה-inode הזה, בתורו, מכיל את מספרי הבלוקים המרכיבים את נתוני הקובץ, אשר יכולים להיות מפוזרים בדיסק.", "ב. ה-Super Block מכיל טבלה גלובלית המצביעה ישירות על כל בלוק נתונים של קובץ, ומבטיחה גישה לגרסה העדכנית ביותר על ידי עדכון מתמיד של מצביעים אלה.", "ג. המערכת סורקת באופן רציף את כל הסגמנטים בדיסק, משווה את חותמות הזמן של בלוקי הנתונים עם אלו של ה-inode bitmap כדי לוודא שהם תואמים לגרסה האחרונה.", "ד. כל בלוק נתונים מכיל מטא-דאטה משלו הכולל מצביע לבלוק הנתונים הבא של אותו קובץ ומספר גרסה, וכך נוצרת רשימה מקושרת של נתוני הקובץ התקפים."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה, ה-`imap` (inode map) הוא המנגנון המרכזי למציאת הגרסה העדכנית ביותר של כל `inode`. כאשר אנו רוצים למצוא `inode` מסוים, אנו מסתכלים ב-`imap` העדכני, והוא מורה לנו על המיקום של הגרסה העדכנית ביותר של אותו `inode`. ה-`inode` עצמו, כפי שתואר, מכיל את כל הפרטים על הקובץ, ובכלל זה את מספרי הבלוקים שבהם מאוחסנים נתוני הקובץ. חשוב לציין שבלוקים אלה אינם חייבים להיות רציפים בדיסק, וה-`inode` מספק את המיפוי הדרוש כדי לאסוף אותם. אפשרות ב' שגויה מכיוון שה-Super Block מכיל מידע כללי על מערכת הקבצים אך אינו עוקב אחר בלוקי נתונים ספציפיים של קבצים בפירוט כזה. אפשרות ג' שגויה מכיוון שסריקה רציפה של כל הסגמנטים אינה יעילה, וה-inode bitmap משמש לניהול בלוקי `inode` פנויים/תפוסים, לא לאימות גרסאות נתונים. אפשרות ד' מתארת שיטת הקצאה מסוימת שאינה בהכרח זו המתוארת, והיא אינה עונה על שאלת איתור גרסת ה-`inode` העדכנית באמצעות ה-`imap`."}, "_source_file": "0312__File_Systems__Inodes__MC__Hard.json", "_topic_hint": "Inodes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:09:44", "_subject": "File Systems", "_context_lectures": [20, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Data Blocks and Bitmaps"], "difficulty_estimation": "Easy", "content": {"text": "מה תפקידו העיקרי של 'מפת סיביות לנתונים' (Data Bitmap) במערכת קבצים?", "code_snippet": null, "options": ["א. לסמן אילו בלוקים של נתונים תפוסים ואילו פנויים.", "ב. לסמן אילו inodes תפוסים ואילו פנויים.", "ג. לרשום את שמות הקבצים והתיקיות במערכת.", "ד. לשמור את התוכן בפועל של קבצי המערכת."]}, "solution": {"correct_option": "א", "explanation": "מפת סיביות לנתונים (Data Bitmap) משמשת במערכת קבצים כדי לעקוב אחר מצב בלוקי הנתונים. כל ביט במפה מייצג בלוק נתונים אחד, כאשר ערך '1' מציין שהבלוק תפוס וערך '0' מציין שהבלוק פנוי. זה מאפשר למערכת הקבצים למצוא במהירות בלוקים פנויים לכתיבת נתונים חדשים או לדעת אילו בלוקים נמצאים בשימוש, כפי שמתואר בחומר ההרצאה (Lecture 20, chunk 27): 'בלוק שני ל-data bitmap- (d), כלוק שאומר אותו דבר, רק עבור הבלוקים של ה-data, אילה בלוקים של data פנויים ואילה לא. הרעיון של bitmap: אם למשל יש לנו 56 בלוקים של data, אז נשמור מספר בינארי בגודל 56, שבו בכל מקום שבלוק תפוס יהיה 1 ובכל מקום שבלוק פנוי יהיה 0'. אפשרויות ב', ג' ו-ד' מתארות פונקציות של רכיבים אחרים במערכת הקבצים או תיאור שגוי של תפקיד ה-Data Bitmap."}, "_source_file": "0313__File_Systems__Data_Blocks_and_Bitmaps__MC__Easy.json", "_topic_hint": "Data Blocks and Bitmaps", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:09:53", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Data Blocks and Bitmaps"], "difficulty_estimation": "Easy", "content": {"text": "מהו התפקיד העיקרי של ה-Data Bitmap במערכת קבצים, כפי שתואר בחומר ההרצאה?", "code_snippet": null, "options": ["א. לסמן אילו בלוקי נתונים (data blocks) פנויים ואילו תפוסים.", "ב. לאחסן את רשימת השמות של כל הקבצים במערכת.", "ג. לשמור מידע על הרשאות גישה לכל קובץ.", "ד. לתעד את המיקום הפיזי של Inodes על הדיסק."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה (Lecture 20, chunk 27), ה-Data Bitmap הוא \"בלוק שאומר... אילה בלוקים של data פנויים ואילה לא\". הוא משתמש בייצוג בינארי שבו '1' מסמן בלוק תפוס ו-'0' מסמן בלוק פנוי, מה שמאפשר למערכת הקבצים למצוא מקום פנוי במהירות. אפשרויות ב', ג' ו-ד' אינן מתארות את תפקידו של ה-Data Bitmap: אפשרות ב' מתייחסת לשמות קבצים (שנמצאים בספריות), אפשרות ג' מתייחסת להרשאות (שנשמרות ב-inodes), ואפשרות ד' מתייחסת ל-inodes, בעוד שהשאלה עוסקת ב-Data Bitmap."}, "_source_file": "0314__File_Systems__Data_Blocks_and_Bitmaps__MC__Easy.json", "_topic_hint": "Data Blocks and Bitmaps", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:10:03", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Data Blocks and Bitmaps"], "difficulty_estimation": "Easy", "content": {"text": "מהו תפקידו העיקרי של ה-Data Bitmap במערכת קבצים?", "code_snippet": null, "options": ["א. לסמן אילו בלוקי נתונים (data blocks) פנויים ואילו תפוסים.", "ב. לאחסן את התוכן בפועל של קבצים.", "ג. לרשום את מספר הלינקים (links) לכל קובץ.", "ד. למצוא את המיקום הפיזי של inodes על הדיסק."]}, "solution": {"correct_option": "א", "explanation": "לפי חומר ההרצאה (Lecture 20, chunk 27), ה-Data Bitmap הוא בלוק שמטרתו לסמן אילו בלוקים של נתונים (data blocks) פנויים ואילו תפוסים. הוא עושה זאת באמצעות מספר בינארי שבו 1 מסמן בלוק תפוס ו-0 מסמן בלוק פנוי, ובכך מאפשר למצוא מקום פנוי במהירות. אפשרות ב' מתארת את תפקידם של בלוקי הנתונים עצמם. אפשרות ג' קשורה ל-inodes ולא ל-Data Bitmap. אפשרות ד' קשורה למיקום ה-inodes או ל-inode bitmap, ולא ל-Data Bitmap."}, "_source_file": "0315__File_Systems__Data_Blocks_and_Bitmaps__MC__Easy.json", "_topic_hint": "Data Blocks and Bitmaps", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:10:13", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Data Blocks and Bitmaps"], "difficulty_estimation": "Easy", "content": {"text": "לפי חומר ההרצאה, מהו התפקיד העיקרי של ה-\"data bitmap\" במערכת קבצים?", "code_snippet": null, "options": ["א. לסמן אילו בלוקים של נתונים (data blocks) פנויים ואילו תפוסים.", "ב. לאחסן את התוכן בפועל של קבצים על הדיסק.", "ג. לרשום את רשימת ה-inodes הפנויים והתפוסים במערכת.", "ד. לשמש כמצביע למיקום הפיזי של קובץ על הדיסק."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה (Lecture 20, chunk 27) מתאר במפורש את ה-data bitmap כבלוק ש\"אומר... רק עבור הבלוקים של ה-data, אילה בלוקים של data פנויים ואילה לא\". הוא מציין כי \"בכל מקום שבלוק תפוס יהיה 1 ובכל מקום שבלוק פנוי יהיה 0\". לכן, תפקידו העיקרי הוא לסמן את מצב הפנוי/תפוס של בלוקי הנתונים."}, "_source_file": "0316__File_Systems__Data_Blocks_and_Bitmaps__MC__Easy.json", "_topic_hint": "Data Blocks and Bitmaps", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:10:22", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Data Blocks and Bitmaps"], "difficulty_estimation": "Medium", "content": {"text": "מערכת קבצים מעדכנת קובץ, מה שכולל הקצאת בלוק נתונים חדש. נניח שהמערכת קורסת *לאחר* שבלוק הנתונים החדש נכתב ו-`data bitmap` עודכן כדי לסמן את הבלוק כתפוס, אך *לפני* שה-`inode` עודכן להצביע לבלוק החדש הזה. מהי התוצאה הסבירה ביותר של קריסה זו?", "code_snippet": null, "options": ["א. בלוק הנתונים החדש יסומן כתפוס ב-`data bitmap`, אך אף `inode` לא יצביע אליו, מה שיוביל לליג' זיכרון (disk space leak).", "ב. ה-`inode` יצביע לבלוק שעדיין מסומן כפנוי ב-`data bitmap`, מה שיאפשר לבלוק להידרס על ידי קובץ אחר.", "ג. ה-`data bitmap` וה-`inode` יישארו במצבם הקודם לפני ההקצאה, כאילו הפעולה לא התרחשה כלל.", "ד. מערכת הקבצים תזהה אוטומטית את חוסר העקביות ותשחרר את בלוק הנתונים עם אתחול מחדש מבלי לאבד נתונים."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה (Lecture 21, chunk 12, סעיף iii), אם המערכת קורסת לאחר שבלוק הנתונים עודכן ו-`data bitmap` עודכן (כלומר, הבלוק סומן כתפוס), אך ה-`inode` טרם עודכן להצביע על הבלוק החדש, הבעיה שתיווצר היא 'ליג' זיכרון'. המשמעות היא שישנו בלוק נתונים שמסומן כתפוס ב-`data bitmap`, אך אין אף `inode` שמצביע אליו, ובכך הוא הופך לבלוק בלתי נגיש שתופס מקום מיותר בדיסק."}, "_source_file": "0317__File_Systems__Data_Blocks_and_Bitmaps__MC__Medium.json", "_topic_hint": "Data Blocks and Bitmaps", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:10:35", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Data Blocks and Bitmaps"], "difficulty_estimation": "Medium", "content": {"text": "במהלך פעולת כתיבה לקובץ, מערכת הקבצים מקצה בלוק נתונים חדש (data block) ומעדכנת את ה-inode כך שיצביע עליו. אם קריסה מתרחשת לאחר ששני עדכונים אלו בוצעו אך לפני ש-data bitmap עודכן לסמן את הבלוק כתפוס, מהו המצב הלא תקין שעלול להיווצר?", "code_snippet": null, "options": ["א. ה-data bitmap יסמן את בלוק הנתונים כפנוי, למרות שה-inode מצביע אליו, ועלול להיווצר מצב שבו בלוק זה יוקצה מחדש לקובץ אחר.", "ב. יתרחש \"זליגת זיכרון\" (memory leak), כאשר בלוק הנתונים מסומן כתפוס ב-data bitmap אך אף inode אינו מצביע עליו.", "ג. הקובץ יכיל נתונים חלקיים או שגויים, אך מערכת הקבצים תזהה את הבלוקים כפנויים ותוכל לשחזר אותם בקלות.", "ד. ה-inode עצמו יסומן כפנוי ב-inode bitmap, מה שיאפשר הקצאה חוזרת של ה-inode לקובץ אחר ויגרום לאובדן הקובץ המקורי."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. לפי חומר ההרצאה (Lecture 21, chunk 12, סעיף ii), אם קריסה מתרחשת לאחר שבלוק הנתונים החדש עודכן ולאחר שה-inode עודכן להצביע עליו, אך לפני שה-data bitmap עודכן לסמן את הבלוק כתפוס, הבעיה שנוצרת היא שה-data bitmap עדיין מצביע על הבלוק כפנוי. מצב זה עלול להוביל לכך שבלוק זה יוקצה מאוחר יותר לקובץ אחר, בעוד שה-inode המקורי עדיין מצביע עליו, מה שיוצר חוסר עקביות חמור במערכת הקבצים ומצב לא תקין. אפשרות ב' מתארת מצב הפוך, שבו ה-data bitmap עודכן אך ה-inode לא (סעיף iii בחומר ההרצאה)."}, "_source_file": "0318__File_Systems__Data_Blocks_and_Bitmaps__MC__Medium.json", "_topic_hint": "Data Blocks and Bitmaps", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:10:50", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Data Blocks and Bitmaps"], "difficulty_estimation": "Medium", "content": {"text": "במערכת קבצים המשתמשת ב-data bitmap וב-inodes, מהי הסכנה העיקרית אם המערכת קורסת לאחר שבלוק נתונים חדש וגם ה-data bitmap עודכנו (כך שהבלוק מסומן כתפוס), אך לפני שה-inode עודכן להצביע על בלוק הנתונים החדש?", "code_snippet": null, "options": ["א. ה-inode יצביע לבלוק נתונים שאינו מסומן כתפוס ב-data bitmap, מה שיכול להוביל לשימוש כפול בבלוק.", "ב. הבלוק החדש יסומן כתפוס ב-data bitmap ויכיל נתונים, אך אף inode לא יצביע אליו, מה שיוביל ל\"דליפת זיכרון\" (memory leak) בבלוקי הנתונים.", "ג. ה-data bitmap ימשיך לסמן את הבלוק כפנוי, למרות שהוא מכיל נתונים, מה שיגרום לאיבוד נתונים בעת הקצאת הבלוק מחדש.", "ד. הקובץ ימשיך להכיל את הנתונים המקוריים בלבד, והבלוק החדש לא יהיה נגיש כלל, אך לא תיווצר אי-עקביות במערכת הקבצים."]}, "solution": {"correct_option": "ב", "explanation": "השאלה מתארת מצב שבו מתבצעת כתיבה לקובץ, והמערכת קורסת לאחר שבלוק הנתונים החדש נכתב לדיסק וה-data bitmap עודכן כדי לסמן את הבלוק כתפוס, אך לפני שה-inode של הקובץ עודכן להצביע על בלוק זה. במצב כזה, כפי שמוזכר בחומר ההרצאה (Lecture 21, chunk 12, סעיף iii), הבעיה שנוצרת היא \"דליפת זיכרון\" (memory leak). הבלוק מסומן כתפוס ב-data bitmap ולכן לא יוקצה מחדש לקובץ אחר, אך מכיוון שאף inode אינו מצביע אליו, הוא למעשה בלתי נגיש ולא ניתן לשימוש על ידי אף קובץ. זוהי אי-עקביות במערכת הקבצים.\n\nאפשרויות אחרות אינן נכונות:\nאפשרות א' מתארת תרחיש אחר לגמרי שבו ה-data bitmap לא עודכן, בעוד שהשאלה מציינת שהוא כן עודכן (Lecture 21, chunk 12, סעיף ii).\nאפשרות ג' שגויה מכיוון שהשאלה מציינת שה-data bitmap *עודכן* וסימן את הבלוק כתפוס.\nאפשרות ד' שגויה כיוון שאכן נוצרת אי-עקביות משמעותית בצורת \"דליפת זיכרון\" של בלוק נתונים."}, "_source_file": "0319__File_Systems__Data_Blocks_and_Bitmaps__MC__Medium.json", "_topic_hint": "Data Blocks and Bitmaps", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:11:03", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Data Blocks and Bitmaps"], "difficulty_estimation": "Medium", "content": {"text": "במערכת קבצים המשתמשת במנגנון bitmap לניהול בלוקי נתונים (data blocks), איזו בעיה עלולה להתרחש אם המערכת קורסת לאחר שבלוק נתונים וביט המפה שלו (data bitmap) עודכנו בהצלחה, אך לפני שה-inode המתאים עודכן להצביע לבלוק זה?", "code_snippet": null, "options": ["א. ה-inode bitmap יסמן בטעות inode כתפוס, למרות שאין לו בלוקי נתונים משויכים.", "ב. בלוק הנתונים יישאר מסומן כפנוי ב-data bitmap, למרות שהוא מכיל נתונים.", "ג. ייווצר \"ליג' זיכרון\" (memory leak) – בלוק נתונים יהיה מסומן כתפוס ב-data bitmap אך אף inode לא יצביע אליו.", "ד. המערכת תתקן אוטומטית את חוסר העקביות בעת העלייה מחדש, מכיוון שה-inode bitmap עדיין תקין."]}, "solution": {"correct_option": "ג", "explanation": "על פי חומר ההרצאה, ב-Lecture 21 (chunk 12), תחת סעיף (iii) נכתב: \"נניח וקרסנו לאחר עדכון ה-data block וה-data bitmap – הבעיה שתהיה כאן היא ליג' זיכרון. כלומר יש בלוק דאטה עם נתונים, שמעודכן שהוא תפוס, אך אף אחד לא מצביע אליו.\" מצב זה מתאר בדיוק את הבעיה המוצגת באפשרות ג'. אפשרות א' מתארת בעיה הקשורה ל-inode bitmap ולא לתרחיש הספציפי. אפשרות ב' מתארת תרחיש קריסה אחר (סעיף ii בחומר ההרצאה), שבו ה-data bitmap עדיין מסמן את הבלוק כפנוי. אפשרות ד' אינה נכונה מכיוון שחומר ההרצאה מתאר את הבעיה ולא פתרון אוטומטי מיידי."}, "_source_file": "0320__File_Systems__Data_Blocks_and_Bitmaps__MC__Medium.json", "_topic_hint": "Data Blocks and Bitmaps", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:11:17", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Data Blocks and Bitmaps"], "difficulty_estimation": "Hard", "content": {"text": "בעת הוספת בלוק נתונים חדש לקובץ קיים, מערכת הקבצים מבצעת סדרת פעולות כתיבה לדיסק. בהתבסס על המידע אודות סדר פעולות אלו והשלכות קריסה, איזו בעיה ספציפית תתרחש אם מערכת הקבצים קורסת *מיד לאחר* עדכון ה-data bitmap לסימון בלוק חדש כתפוס, אך *לפני* עדכון ה-inode של הקובץ כדי שיצביע על הבלוק החדש?", "code_snippet": "// Simplified pseudo-code illustrating key write operations for adding a new data block\n// This sequence is derived from the lecture material (Lecture 20, chunk 31)\n\n// Assume 'new_block_id' is a free data block found using the data bitmap\n// Assume 'current_inode' is the in-memory representation of the file's inode\n\n// 1. Mark the chosen data block as busy in the data bitmap on disk.\n//    (This corresponds to \"Write updated data bitmap\" in the lecture)\ndisk_write(DATA_BITMAP_BLOCK_ADDRESS, new_block_id, BUSY_STATE);\n\n// --- CRASH POINT: If the system crashes here ---\n// The data bitmap on disk marks 'new_block_id' as busy.\n// However, 'current_inode' (and its on-disk version) does NOT yet point to 'new_block_id'.\n// This leads to the \"memory leak\" scenario.\n\n// 2. Update the file's inode to point to the newly allocated data block on disk.\n//    (This corresponds to \"Write updated inode with new block location\")\ncurrent_inode.data_pointers[next_available_slot] = new_block_id;\ndisk_write(INODE_TABLE_BLOCK_ADDRESS, current_inode.id, current_inode);\n\n// 3. Write the actual data content to the new data block on disk.\n//    (This corresponds to \"Write the actual block itself\")\ndisk_write(DATA_BLOCK_ADDRESS(new_block_id), new_data_content);", "options": ["א. בלוק הנתונים החדש יסומן כפנוי ב-data bitmap, למרות שה-inode כבר מצביע עליו, מה שיוביל לשימוש חוזר בבלוק על ידי קובץ אחר ואיבוד נתונים.", "ב. ה-data bitmap יסמן את הבלוק כתפוס, אך אף inode לא יצביע אליו, מה שיוביל ל\"דליפת זיכרון\" (memory leak) של בלוק הנתונים – בלוק תפוס אך בלתי נגיש.", "ג. ה-inode של הקובץ יצביע על בלוק נתונים שטרם נכתב בפועל על הדיסק, מה שיוביל לשגיאות קריאה עתידיות מהקובץ.", "ד. מערכת הקבצים תיכנס למצב שבו לא ניתן יהיה לאתר את הקובץ כלל, מכיוון שה-inode שלו יהיה במצב לא עקבי ולא ישקף את גודלו האמיתי."]}, "solution": {"correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. לפי חומר ההרצאה (Lecture 21, chunk 12, תרחיש iii), אם מתרחשת קריסה לאחר עדכון ה-data bitmap לסימון בלוק כתפוס, אך לפני שעדכון ה-inode מתרחש (כדי שיצביע על הבלוק החדש), אנו נותרים במצב שבו ה-data bitmap מסמן את הבלוק כתפוס, אך אף inode במערכת אינו מצביע עליו. מצב זה מתואר כ\"דליפת זיכרון\" (memory leak), שכן הבלוק תפוס ולא ניתן לשימוש חוזר, אך הוא גם בלתי נגיש לחלוטין מכיוון שאין דרך להגיע אליו דרך היררכיית הקבצים. חומר ההרצאה מציין שזו אחת הסיבות מדוע \"שתי הפעולות הראשונות שלנו לא יכולות להיות כתיבה ל-data bitmap ועדכון ה-inode\" (Lecture 21, chunk 12, נקודה ראשונה).\n\nלגבי האפשרויות האחרות:\nא. תרחיש זה מתאר קריסה לאחר עדכון ה-inode וה-data block, כאשר ה-data bitmap עדיין מסמן את הבלוק כפנוי (Lecture 21, chunk 12, תרחיש ii). זהו מצב הפוך לזה המתואר בשאלה.\nג. בעיה זו עלולה להתרחש אם ה-inode עודכן להצביע על בלוק, אך התוכן של הבלוק עצמו טרם נכתב או לא נכתב כראוי. השאלה מתמקדת בקריסה *לפני* עדכון ה-inode, לא *אחרי* כתיבת ה-inode אך *לפני* כתיבת הדאטה.\nד. זוהי מסקנה כללית מדי. הבעיה הספציפית והחמורה יותר המתוארת במצב זה היא \"דליפת זיכרון\" של בלוק הנתונים, ולא אי-איתור כללי של הקובץ (שכן ה-inode הקיים עדיין קיים, רק לא מכיל את הבלוק החדש)."}, "_source_file": "0321__File_Systems__Data_Blocks_and_Bitmaps__MC__Hard.json", "_topic_hint": "Data Blocks and Bitmaps", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:11:49", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Data Blocks and Bitmaps"], "difficulty_estimation": "Hard", "content": {"text": "נניח שבמערכת קבצים, במהלך פעולת כתיבה לקובץ, המערכת קרסה לאחר שבלוק הנתונים (data block) ובלוק מפת הסיביות של הנתונים (data bitmap) עודכנו בהצלחה, אך העדכון של ה-inode המצביע לבלוק החדש לא הושלם. איזו מהבעיות הבאות עלולה להיווצר כתוצאה ממצב זה?", "code_snippet": null, "options": ["א. ה-data bitmap יסמן את הבלוק כפנוי, למרות שהוא מכיל נתונים, ובלוק זה עלול להיכתב על ידי קובץ אחר.", "ב. ה-inode יצביע לבלוק נתונים שאינו קיים או שאינו מכיל את הנתונים המיועדים.", "ג. הבלוק החדש יהיה מסומן כתפוס ב-data bitmap ויכיל נתונים, אך אף inode לא יצביע אליו, מה שיוביל ל\"ליג' זיכרון\".", "ד. מערכת הקבצים תיכנס למצב שבו לא ניתן יהיה לגשת לשאר בלוקי הנתונים של הקובץ המקורי."]}, "solution": {"correct_option": "ג", "explanation": "לפי חומר ההרצאה, בסעיף (iii) נניח וקרסנו לאחר עדכון ה-data block וה-data bitmap, הבעיה שתהיה היא 'ליג' זיכרון'. כלומר, יש בלוק דאטה עם נתונים, שמעודכן שהוא תפוס ב-data bitmap, אך אף אחד לא מצביע אליו מה-inode. זהו בדיוק המצב המתואר באפשרות ג'.\nאפשרות א' מתארת תרחיש קריסה אחר, בו ה-data bitmap לא עודכן (עדיין מסמן פנוי) למרות שה-inode ובלוק הנתונים כן עודכנו. זהו מצב הבעיה המתואר בסעיף (ii).\nאפשרות ב' מתארת מצב שבו ה-data bitmap וה-inode עודכנו, אך בלוק הנתונים עצמו לא נכתב, מה שמוביל ל-inode שמצביע לבלוק תפוס אך עם תוכן שגוי או חסר. זהו מצב הבעיה המתואר בסעיף (i) כ'אסור לנו להתחיל בשתי הפעולות הללו'.\nאפשרות ד' היא כללית מדי ואינה מתארת באופן ספציפי את ההשלכה הישירה של סדר הפעולות והקריסה הנתונים."}, "_source_file": "0322__File_Systems__Data_Blocks_and_Bitmaps__MC__Hard.json", "_topic_hint": "Data Blocks and Bitmaps", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:12:03", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Data Blocks and Bitmaps"], "difficulty_estimation": "Hard", "content": {"text": "בעת הוספת בלוק נתונים חדש לקובץ קיים, מערכת הקבצים נדרשת לעדכן שלושה רכיבים עיקריים: ה-inode של הקובץ, בלוק הנתונים עצמו, וה-data bitmap. בהתבסס על החומר הנלמד, איזו בעיית עקביות חמורה עלולה להיווצר במערכת הקבצים אם המערכת קורסת *לאחר* שבלוק הנתונים נכתב וגם ה-inode עודכן להצביע אליו, אך *לפני* שה-data bitmap עודכן לסמן את הבלוק כתפוס?", "code_snippet": null, "options": ["א. בלוק הנתונים ייחשב כ\"דליפת זיכרון\" (memory leak), כלומר הוא מסומן כתפוס ב-data bitmap אך אין אליו מצביע מ-inode כלשהו.", "ב. ה-data bitmap יסמן את בלוק הנתונים כפנוי, למרות שה-inode מצביע אליו, מה שמאפשר לבלוק להינתן לקובץ אחר ויוביל לשחיתות נתונים.", "ג. ה-inode של הקובץ יכיל מצביע שגוי לבלוק נתונים שאינו קיים, מה שיגרום לשגיאות קריאה עתידיות עבור הקובץ.", "ד. ה-inode bitmap יסמן את ה-inode כפנוי, למרות שהוא בשימוש, מה שעלול לגרום להקצאת ה-inode לקובץ חדש."]}, "solution": {"correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. על פי חומר ההרצאה (Lecture 21, chunk 12, סעיף ii), אם המערכת קורסת לאחר עדכון ה-inode וה-data block, אך לפני עדכון ה-data bitmap, נוצר מצב שבו ה-data bitmap עדיין מסמן את הבלוק כפנוי. במקביל, ה-inode של הקובץ כבר מצביע לבלוק זה. בעיה זו עלולה להוביל לכך שמערכת הקבצים תקצה את הבלוק הפנוי לכאורה לקובץ אחר, מה שייצור שחיתות נתונים חמורה שכן שני קבצים יצביעו לאותו בלוק פיזי, או שקובץ אחד יצביע לבלוק שהתוכן שלו \"נדרס\" על ידי קובץ אחר. \nאפשרות א' מתארת בעיית \"דליפת זיכרון\" (memory leak), הנוצרת כאשר המערכת קורסת לאחר עדכון ה-data block וה-data bitmap, אך לפני עדכון ה-inode (Lecture 21, chunk 12, סעיף iii). במקרה זה, הבלוק מסומן כתפוס ב-data bitmap אך אף inode אינו מצביע אליו. אפשרויות ג' ו-ד' מתארות בעיות שאינן תואמות את תרחיש הקריסה הספציפי המתואר בשאלה, או מתייחסות לרכיבים אחרים (inode bitmap) באופן שאינו קשור ישירות לבעיה המרכזית של הקצאת בלוק נתונים חדש במצב זה."}, "_source_file": "0323__File_Systems__Data_Blocks_and_Bitmaps__MC__Hard.json", "_topic_hint": "Data Blocks and Bitmaps", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:12:28", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Data Blocks and Bitmaps"], "difficulty_estimation": "Hard", "content": {"text": "במהלך פעולת כתיבה לקובץ המצריכה הקצאת בלוק נתונים חדש, איזה סדר פעולות בין עדכון ה-data bitmap לעדכון ה-inode נחשב בטוח יותר למניעת חוסר עקביות חמור במקרה של קריסת מערכת, על פי חומר ההרצאה?", "code_snippet": "/*\n// Pseudocode for crucial steps in allocating a new data block and updating inode\n// Assume 'new_block_addr' is the address of the newly allocated block\n// Assume 'inode_ptr' is a pointer to the relevant inode\n\n// Sequence 1: Update Data Bitmap THEN Inode (Option א)\nvoid sequence_A(int new_block_addr, Inode* inode_ptr) {\n    // 1. Mark block as taken in data bitmap\n    update_data_bitmap(new_block_addr, TAKEN); \n    // CRASH HERE: Block is marked taken, but no inode points to it.\n    // (Memory leak, recoverable by fsck - less severe inconsistency)\n\n    // 2. Update inode to point to the new block\n    inode_ptr->data_block_pointers[...]= new_block_addr;\n    write_inode_to_disk(inode_ptr);\n    // CRASH HERE: Block is marked taken, inode points to it, but data might be old/garbage.\n    // (Inconsistent, but less severe than data corruption)\n}\n\n// Sequence 2: Update Inode THEN Data Bitmap (Option ב)\nvoid sequence_B(int new_block_addr, Inode* inode_ptr) {\n    // 1. Update inode to point to the new block\n    inode_ptr->data_block_pointers[...]= new_block_addr;\n    write_inode_to_disk(inode_ptr);\n    // CRASH HERE: Inode points to block, but data bitmap marks it FREE.\n    // (SEVERE: Another process might allocate it, leading to data corruption for original file)\n\n    // 2. Mark block as taken in data bitmap\n    update_data_bitmap(new_block_addr, TAKEN); \n}\n*/", "options": ["א. עדכון ה-data bitmap לפני עדכון ה-inode.", "ב. עדכון ה-inode לפני עדכון ה-data bitmap.", "ג. אין חשיבות לסדר העדכונים, כל עוד שניהם מתרחשים באותה טרנזקציה אטומית.", "ד. עדכון בלוק הנתונים (data block) בפועל חייב להתרחש לפני כל עדכון של מטה-הנתונים (inode או data bitmap)."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מציג שני תרחישי קריסה אפשריים ומשמעויותיהם:\n\n1.  **קריסה לאחר עדכון ה-inode וה-data block, כאשר ה-data bitmap עדיין מסמן שהבלוק פנוי (Lecture 21, chunk 12, סעיף ii):** במצב זה, ה-inode מצביע לבלוק נתונים, אך ה-data bitmap עדיין מסמן את הבלוק כפנוי. זוהי בעיה חמורה מאוד, שכן בלוק זה עלול להיות מוקצה מחדש לקובץ אחר, מה שיוביל לשחיתות נתונים (data corruption) בקובץ המקורי. ההרצאה מציינת: \"ה-data bitmap עדיין מסמן שהבלוק הזה פנוי ומישהו אחר יכול להשתמש בו בהמשך וקורה מצב שבו inode שלנו מצביע לבלוק שלא מסומן כתפוס ב-bitmap, וזו בעיה במערכת הקבצים.\"\n\n2.  **קריסה לאחר עדכון ה-data block וה-data bitmap, כאשר ה-inode עדיין אינו מצביע אליו (Lecture 21, chunk 12, סעיף iii):** במצב זה, ה-data bitmap מסמן את הבלוק כתפוס, אך ה-inode עדיין אינו מצביע אליו. זוהי בעיית \"דליפת זיכרון\" (memory leak), מכיוון שהבלוק מסומן כתפוס אך אינו נגיש לקבצים. בעיה זו פחות חמורה, והחומר מציין ש-\"fsck\" יכול לשחזר אותה על ידי בדיקה אם כל בלוק שמסומן כתפוס, יש inode שמצביע אליו. אם לא, הוא מסומן כפנוי.\n\nכדי למנוע את המצב החמור ביותר של שחיתות נתונים (תרחיש 1), עדיף לעדכן קודם את ה-data bitmap (לסמן את הבלוק כתפוס) ורק לאחר מכן לעדכן את ה-inode שיצביע אליו. סדר פעולות זה (א') ממזער את הסיכון לשחיתות נתונים במקרה של קריסה, גם אם הוא עלול להוביל ל\"דליפת זיכרון\" זמנית שניתנת לשחזור. סדר זה גם תואם את רצף הפעולות הכללי המתואר בהרצאה (Lecture 20, chunk 31) עבור כתיבה לקובץ: \"Write updated data bitmap\" לפני \"Write updated inode\"."}, "_source_file": "0324__File_Systems__Data_Blocks_and_Bitmaps__MC__Hard.json", "_topic_hint": "Data Blocks and Bitmaps", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:13:07", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Superblock"], "difficulty_estimation": "Easy", "content": {"text": "מהו התפקיד העיקרי של ה-Super Block במערכת קבצים?", "code_snippet": null, "options": ["א. הוא מכיל מידע חיוני על מבנה מערכת הקבצים, כגון סוג מערכת הקבצים, גודל הדיסק, מספר בלוקי נתונים ומיקום מפות הסיביות (bitmaps).", "ב. הוא מאחסן את התוכן של קבצים ותיקיות בתוך מערכת הקבצים.", "ג. הוא מכיל את קוד האתחול הראשוני של מערכת ההפעלה.", "ד. הוא משמש לתיעוד היסטוריית הטרנזקציות ב-journal לצורך שחזור."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. לפי חומר ההרצאה (הרצאה 20, קטע 28), ה-Super Block הוא בלוק המכיל נתונים חיוניים על הכונן ומערכת הקבצים כולה. מידע זה כולל את סוג מערכת הקבצים (כדי לדעת איזה קוד להריץ), גודל הדיסק, מספר בלוקי הנתונים (data blocks), מספר ה-inodes, ומיקומם של מפות הסיביות (bitmaps) עבור בלוקים ו-inodes. בלעדי מידע זה, מערכת ההפעלה לא תוכל להבין ולנהל את מבנה הקבצים על הדיסק.\n\nאפשרויות אחרות שגויות:\n*   ב' שגויה: תוכן הקבצים מאוחסן בבלוקי נתונים (data blocks), לא ב-Super Block.\n*   ג' שגויה: קוד האתחול הראשוני של מערכת ההפעלה נמצא בדרך כלל ב\"בלוק אתחול\" (boot block), שלעיתים קרובות קודם ל-Super Block, אך אינו ה-Super Block עצמו.\n*   ד' שגויה: בעוד שה-Super Block ב-journaling file systems יכול להכיל מצביעים או מידע הקשור ל-journal לצורך שחזור (כפי שמוזכר בהרצאה 21, קטע 33), תפקידו העיקרי והכללי, כפי שהוגדר בהרצאה 20, הוא לספק מידע מבני כללי על מערכת הקבצים כולה, ולא רק על ה-journal. התפקיד המתואר באפשרות א' הוא רחב יותר ומהווה את ההגדרה הבסיסית של ה-Super Block."}, "_source_file": "0325__File_Systems__Superblock__MC__Easy.json", "_topic_hint": "Superblock", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:13:19", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Superblock"], "difficulty_estimation": "Easy", "content": {"text": "מהו התפקיד העיקרי של ה-Super Block במערכת קבצים?", "code_snippet": null, "options": ["א. לאחסן נתונים חיוניים אודות מבנה מערכת הקבצים והכונן, כגון סוג מערכת הקבצים, גודל הדיסק, מספר בלוקי נתונים ומיקום ה-bitmaps.", "ב. לשמור רשימה מקושרת של כל הבלוקים הפנויים בדיסק כדי לשפר גישה אקראית.", "ג. לתעד טרנזקציות שהושלמו כדי לאפשר שחזור מהיר לאחר קריסה.", "ד. למפות דפים ל-chunks ב-SSD כדי לייעל שינויים בדפים בודדים."]}, "solution": {"correct_option": "א", "explanation": "ה-Super Block הוא בלוק קריטי במערכת הקבצים המכיל מידע מהותי על הכונן ומבנה מערכת הקבצים כולה. על פי חומר ההרצאה (Lecture 20, chunk 28), הוא 'בלוק אחד שמכיל נתונים על הכונן שלנו ועל מערכת הקבצים. יהיה כתוב בו אילו מערכת קבצים מישנן כדי לדעת איזה קוד להריץ על הדיסק, יהיה כתוב מה הגודל של הדיסק, כמה data block, inodes יש לו, איפה ה-bitmaps וכו'.'. אפשרויות ב', ג' ו-ד' מתארות תפקידים אחרים או פרטים ספציפיים שאינם התפקיד העיקרי והכללי של ה-Super Block במערכת קבצים."}, "_source_file": "0326__File_Systems__Superblock__MC__Easy.json", "_topic_hint": "Superblock", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:13:31", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Superblock"], "difficulty_estimation": "Easy", "content": {"text": "מהו התפקיד העיקרי של ה-Super Block במערכת קבצים?", "code_snippet": null, "options": ["א. הוא מכיל נתונים על הכונן ומערכת הקבצים, כגון סוג מערכת הקבצים, גודל הדיסק, כמות בלוקי נתונים ו-inodes, ומיקום ה-bitmaps.", "ב. הוא שומר את קוד האתחול (boot code) המאפשר למערכת ההפעלה לעלות.", "ג. הוא מתעד את היסטוריית כל הטרנזקציות שבוצעו על מערכת הקבצים לצורך שחזור.", "ד. הוא מאחסן את תוכן הנתונים של כל הקבצים הקטנים במערכת."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה (Lecture 20, chunk 28), ה-Super Block הוא בלוק אחד המכיל נתונים על הכונן ועל מערכת הקבצים. נתונים אלו כוללים את סוג מערכת הקבצים, גודל הדיסק, כמה בלוקי נתונים (data blocks) ו-inodes קיימים, וכן את מיקום ה-bitmaps. לכן, תשובה א' מתארת במדויק את תפקידו העיקרי של ה-Super Block. תשובה ב' מתארת את ה-boot block, שהוא בלוק נפרד שיכול להופיע לפני ה-Super Block. תשובה ג' מתייחסת יותר לתפקיד ה-Journal Superblock בהקשר של שחזור טרנזקציות, ולא לתפקידו הכללי של ה-Super Block כמתאר את מערכת הקבצים. תשובה ד' אינה נכונה, שכן ה-Super Block מאחסן מטא-דאטה על מערכת הקבצים ולא את תוכן הקבצים עצמם."}, "_source_file": "0327__File_Systems__Superblock__MC__Easy.json", "_topic_hint": "Superblock", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:13:40", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Superblock"], "difficulty_estimation": "Easy", "content": {"text": "מהו התפקיד העיקרי של ה-Superblock במערכת קבצים?", "code_snippet": null, "options": ["א. הוא מכיל נתונים על הכונן ומערכת הקבצים, כגון סוג מערכת הקבצים, גודל הדיסק, מספר בלוקי נתונים ו-inodes, ומיקומי ה-bitmaps.", "ב. הוא משמש לאחסון תוכן הקבצים בפועל.", "ג. הוא מכיל רשימה מקושרת של כל הבלוקים הפנויים בדיסק.", "ד. הוא אחראי לניהול גישה למשאבים משותפים בין תהליכים."]}, "solution": {"correct_option": "א", "explanation": "ה-Superblock הוא בלוק מיוחד המכיל מידע קריטי על מבנה מערכת הקבצים כולה. על פי חומר ההרצאה (Lecture 20, chunk 28), הוא מכיל נתונים כמו סוג מערכת הקבצים, גודל הדיסק, מספר בלוקי הנתונים (data blocks), מספר ה-inodes ומיקומם של ה-bitmaps. מידע זה חיוני למערכת ההפעלה כדי להבין כיצד לארגן ולגשת לנתונים על הדיסק."}, "_source_file": "0328__File_Systems__Superblock__MC__Easy.json", "_topic_hint": "Superblock", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:13:50", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Superblock"], "difficulty_estimation": "Medium", "content": {"text": "מהו התפקיד המרכזי של ה-Super Block במערכת קבצים?", "code_snippet": null, "options": ["א. לאחסן את הנתונים בפועל של קבצים ותיקיות.", "ב. לנהל את המיפוי בין בלוקים לוגיים לפיזיים עבור זיכרון SSD.", "ג. להכיל מידע בסיסי אודות מבנה מערכת הקבצים, גודלה, ומיקום מבני הנתונים החשובים שלה.", "ד. לשמור רשימה מקושרת של כל ה-inodes במערכת."]}, "solution": {"correct_option": "ג", "explanation": "ה-Super Block הוא בלוק חיוני המכיל מידע מטא-נתונים קריטי על מערכת הקבצים והכונן. כפי שמצוין בחומר ההרצאה, הוא מכיל נתונים כמו סוג מערכת הקבצים (כדי לדעת איזה קוד להריץ), גודל הדיסק, מספר בלוקי הנתונים (data blocks), מספר ה-inodes, ומיקום מפות הסיביות (bitmaps) לניהול בלוקים פנויים ו-inodes פנויים. במערכות קבצים עם Journal, הוא גם מכיל מצביעים חיוניים לשחזור טרנזקציות. לכן, תפקידו המרכזי הוא להכיל מידע בסיסי אודות מבנה מערכת הקבצים, גודלה, ומיקום מבני הנתונים החשובים שלה."}, "_source_file": "0329__File_Systems__Superblock__MC__Medium.json", "_topic_hint": "Superblock", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:14:04", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Superblock"], "difficulty_estimation": "Medium", "content": {"text": "מהי מטרתו העיקרית של ה-Superblock במערכת קבצים?", "code_snippet": null, "options": ["א. לאחסן את הנתונים בפועל של כל הקבצים במערכת.", "ב. להכיל מידע מטה-דאטה אודות מערכת הקבצים, כגון סוגה, גודלה ומיקום מבנים קריטיים אחרים.", "ג. לנהל את תהליך האתחול של מערכת ההפעלה בעת הדלקת המחשב.", "ד. לשמש כיומן רישום של כל הטרנזקציות במערכת הקבצים לצורך שחזור."]}, "solution": {"correct_option": "ב", "explanation": "החומר המצורף מציין כי ה-Superblock הוא בלוק המכיל 'נתונים על הכונן שלנו ועל מערכת הקבצים. יהיה כתוב בו אילו מערכת קבצים מישנן כדי לדעת איזה קוד להריץ על הדיסק, יהיה כתוב מה הגודל של הדיסק, כמה data block, inodes יש לו, איפה ה-bitmaps וכו'.' כלומר, הוא מאחסן מידע מטה-דאטה חיוני על מבנה מערכת הקבצים. אפשרות א' אינה נכונה, שכן נתוני הקבצים עצמם נשמרים בבלוקי נתונים (data blocks). אפשרות ג' אינה נכונה, מכיוון שתהליך האתחול מנוהל על ידי בלוק ה-boot, שלעיתים קודם ל-Superblock. אפשרות ד' אינה נכונה, שכן ה-Superblock אינו יומן הרישום עצמו (Journal), אלא יכול להכיל מצביעים לטרנזקציות ביומן הרישום לצורך שחזור, כחלק ממידע המטה-דאטה שלו."}, "_source_file": "0330__File_Systems__Superblock__MC__Medium.json", "_topic_hint": "Superblock", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:14:15", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Superblock"], "difficulty_estimation": "Medium", "content": {"text": "לפי חומר ההרצאה, מהו התפקיד העיקרי של ה-Superblock במערכת קבצים?", "code_snippet": null, "options": ["א. הוא מכיל מידע קריטי על הכונן ומערכת הקבצים, כגון סוג מערכת הקבצים, גודל הדיסק, מספר בלוקי נתונים ו-inodes, ומיקומי ה-bitmaps.", "ב. הוא משמש לאחסון תוכן הקבצים עצמם ומבנה התיקיות.", "ג. הוא אחראי על ניהול הרשאות גישה למשתמשים שונים במערכת.", "ד. הוא מכיל את הקוד האתחולי (boot code) שמערכת ההפעלה טוענת בעת הפעלת המחשב."]}, "solution": {"correct_option": "א", "explanation": "הסופרבלוק הוא בלוק מיוחד המכיל מידע מהותי על הכונן הפיזי ומערכת הקבצים כולה. חומר ההרצאה מציין במפורש שהוא \"בלוק אחד שמכיל נתונים על הכונן שלנו ועל מערכת הקבצים\", וכן ש\"יהיה כתוב בו אילו מערכת קבצים מישנן כדי לדעת איזה קוד להריץ על הדיסק, יהיה כתוב מה הגודל של הדיסק, כמה data block, inodes יש לו, איפה ה-bitmaps וכו'\". הוא משמש כנקודת כניסה למערכת הקבצים ומאפשר למערכת ההפעלה להבין את המבנה הכללי שלה. תשובות אחרות אינן נכונות מכיוון שהסופרבלוק אינו מאחסן את תוכן הקבצים (אלו בלוקי הנתונים), אינו מנהל הרשאות גישה באופן ישיר (אלו בדרך כלל חלק מנתוני ה-inode), ואינו מכיל את קוד האתחול (שנמצא בבלוק אתחול נפרד, אם קיים, לפני הסופרבלוק)."}, "_source_file": "0331__File_Systems__Superblock__MC__Medium.json", "_topic_hint": "Superblock", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:14:25", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Superblock"], "difficulty_estimation": "Medium", "content": {"text": "מהי המטרה העיקרית של ה-Superblock במערכת קבצים?", "code_snippet": null, "options": ["א. לאחסן את כל תוכן הקבצים (data blocks) המאוחסנים בכונן.", "ב. להכיל מידע קריטי על מערכת הקבצים והכונן, כגון סוג מערכת הקבצים, גודל הדיסק, מספר בלוקי נתונים ו-inodes, ומיקום ה-bitmaps.", "ג. לשמש כאינדקס לכל ה-inodes במערכת, ובכך לאפשר גישה מהירה לכל קובץ.", "ד. להכיל את קוד האתחול (boot code) שמערכת ההפעלה טוענת בעת הפעלת המחשב."]}, "solution": {"correct_option": "ב", "explanation": "ה-Superblock הוא בלוק קריטי המכיל מידע מטא-נתונים על מערכת הקבצים והכונן. כפי שצוין בחומר ההרצאה (Lecture 20, chunk 28), הוא כולל פרטים כמו סוג מערכת הקבצים (כדי לדעת איזה קוד להריץ), גודל הדיסק, כמה בלוקי נתונים (data blocks) ו-inodes קיימים, וכן היכן ממוקמים ה-bitmaps (לדוגמה, bitmap עבור inodes). מידע זה חיוני למערכת ההפעלה כדי להבין את מבנה מערכת הקבצים ולגשת לנתונים. אפשרות א' שגויה מכיוון שה-Superblock מאחסן מטא-נתונים, לא את תוכן הקבצים עצמם. אפשרות ג' שגויה מכיוון שה-Superblock מציין את מיקום ה-bitmaps אך אינו משמש כאינדקס ישיר לכל ה-inodes. אפשרות ד' שגויה מכיוון שקוד האתחול (boot code) נמצא בדרך כלל בבלוק ה-boot, אשר לפעמים ממוקם לפני ה-Superblock, אך אינו חלק מה-Superblock עצמו."}, "_source_file": "0332__File_Systems__Superblock__MC__Medium.json", "_topic_hint": "Superblock", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:14:38", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Superblock"], "difficulty_estimation": "Hard", "content": {"text": "במערכת קבצים המשלבת מנגנון Journaling, מהו התפקיד המהותי והדינמי ביותר של ה-superblock, כפי שמתואר בהקשר של התאוששות לאחר קריסת מערכת?", "code_snippet": null, "options": ["א. הוא מאחסן מצביע המורה על הטרנזקציה הבאה ביומן שיש להתחיל ממנה בתהליך השחזור, ובכך מאפשר למערכת לחדש פעילות בצורה יעילה מבלי לבצע מחדש פעולות שהושלמו.", "ב. הוא כולל מידע סטטי על גודל הדיסק, מספר בלוקי הנתונים וה-inodes, ומיקומי ה-bitmaps, המשמשים לניהול המבנה הכללי של מערכת הקבצים.", "ג. הוא מכיל את הקוד האתחולי (boot code) שאחראי על טעינת מערכת ההפעלה לזיכרון בעת הדלקת המחשב.", "ד. הוא מנהל את טבלאות המיפוי של דפים ל-chunks בזיכרון ה-SSD, תוך מתן עדיפות לנתונים עדכניים באזור זמני (log table)."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. לפי חומר ההרצאה (Lecture 21, chunk 33), ה-superblock משמש לאחסון מצביע המציין את הטרנזקציה הבאה ביומן (Journal) שיש לטפל בה. עדכון מצביע זה לאחר סיום טרנזקציה מאפשר למערכת להתאושש ביעילות מקריסה: במקום להתחיל את תהליך השחזור מההתחלה, המערכת קוראת את ה-superblock ויודעת בדיוק מאיפה להמשיך, מה שחוסך זמן ומשאבים. אפשרות ב' מתארת תפקיד נכון של ה-superblock (Lecture 20, chunk 28) – שמירת מידע סטטי על מבנה מערכת הקבצים – אך אינה התפקיד הדינמי המהותי בהקשר של שחזור. אפשרות ג' מתארת את תפקידו של בלוק האתחול (boot block), שלפעמים קודם ל-superblock (Lecture 20, chunk 28), ולא את תפקיד ה-superblock עצמו. אפשרות ד' מתייחסת למנגנון מיפוי פנימי של SSD (Lecture 22, chunk 54), שאינו קשור ישירות לתפקיד ה-superblock במערכת הקבצים."}, "_source_file": "0333__File_Systems__Superblock__MC__Hard.json", "_topic_hint": "Superblock", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:14:54", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Superblock"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על חומר ההרצאה, מהי ההשלכה המיידית והחמורה ביותר של כשל בקריאת ה-Superblock של מערכת קבצים בעת אתחול המערכת?", "code_snippet": null, "options": ["א. מערכת הקבצים לא תוכל לנהל ביעילות את המיפויים הלוגיים-פיזיים של ה-SSD, מה שיוביל לירידה בביצועים.", "ב. מערכת ההפעלה לא תוכל לזהות את סוג מערכת הקבצים המותקנת ולא תדע כיצד לפרש או לגשת לנתונים בכונן.", "ג. תהליך השחזור של יומן הרישום (journal) יצטרך לסרוק את כל הטרנזקציות מההתחלה, במקום להתחיל מנקודה ידועה.", "ד. לא תהיה למערכת היכולת לזהות קבצים גדולים הדורשים בלוקים מפוזרים, מה שיגרום לשגיאות גישה."]}, "solution": {"correct_option": "ב", "explanation": "ה-Superblock הוא הבלוק המרכזי המכיל מטא-נתונים חיוניים על מערכת הקבצים כולה. לפי חומר ההרצאה (Lecture 20, chunk 28), ב-Superblock \"יהיה כתוב בו אילו מערכת קבצים מישנן כדי לדעת איזה קוד להריץ על הדיסק\". משמעות הדבר היא שללא יכולת לקרוא את ה-Superblock, מערכת ההפעלה לא תוכל לזהות את סוג מערכת הקבצים (למשל, ext4, NTFS וכו'). ללא ידע זה, מערכת ההפעלה אינה יודעת כיצד לפרש את מבנה הדיסק, היכן נמצאים ה-inodes, בלוקי הנתונים, ה-bitmaps, או כיצד לגשת למידע כלשהו בכונן. זוהי ההשלכה המיידית והבסיסית ביותר, שכן היא מונעת כל פעולה נוספת עם מערכת הקבצים, כולל ניהול קבצים או ביצוע שחזור יומן.\n\nא. ניהול מיפויים לוגיים-פיזיים של SSD הוא נושא ספציפי ל-SSD (Lecture 22) ואינו תפקיד ישיר של ה-Superblock במערכת קבצים כללית, אלא רמה נמוכה יותר של ניהול אחסון.\nג. בעיית שחזור יומן (journal) היא אכן השלכה של Superblock פגום (Lecture 21, chunk 33, \"הוא יקרא את ה-superblock וידע מאיפה להתחיל\"), אך היא משנית לזיהוי סוג מערכת הקבצים. אם מערכת ההפעלה אינה יודעת כלל באיזו מערכת קבצים מדובר, היא לא תגיע לשלב ניסיון שחזור היומן הספציפי למערכת קבצים זו.\nד. זיהוי קבצים גדולים וניהול בלוקים מפוזרים קשור ל-inodes ולמבני נתונים אחרים שמערכת הקבצים משתמשת בהם, אך Superblock עצמו רק מצביע על מיקומם של מבנים אלו ולא מנהל ישירות את המיפויים עבור קובץ ספציפי. חוסר יכולת לקרוא את ה-Superblock מונע קודם כל את הגישה לכלל מבני הנתונים הללו."}, "_source_file": "0334__File_Systems__Superblock__MC__Hard.json", "_topic_hint": "Superblock", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:15:17", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Superblock"], "difficulty_estimation": "Hard", "content": {"text": "בהתחשב בתפקידו המרכזי של ה-Superblock במערכת קבצים, איזו מבין ההשלכות הבאות היא הקריטית והמיידית ביותר במקרה של שחיתות ב-Superblock, המונעת מהמערכת לתפקד באופן תקין עם הכונן?", "code_snippet": null, "options": ["א. מערכת ההפעלה לא תוכל לזהות את סוג מערכת הקבצים, ובכך תמנע ממנה לטעון את הקוד המתאים לטיפול בכונן.", "ב. לא ניתן יהיה לבצע הקצאה או שחרור של בלוקי נתונים או Inodes, מכיוון שמיקומי ה-bitmaps לא יהיו ידועים.", "ג. תהליך שחזור יומן (Journaling recovery) ייפגע, מה שיוביל לחוסר עקביות או אובדן נתונים לאחר קריסה.", "ד. הגישה האקראית לבלוקים ספציפיים של קבצים תהפוך לבלתי יעילה באופן משמעותי, בדומה למבנה רשימה מקושרת."]}, "solution": {"correct_option": "א", "explanation": "ה-Superblock מכיל נתונים חיוניים על הכונן ומערכת הקבצים, כולל איזה סוג מערכת קבצים מיושן כדי לדעת 'איזה קוד להריץ על הדיסק'. אם מידע זה נפגם, מערכת ההפעלה לא תוכל לזהות נכונה את סוג מערכת הקבצים. זוהי השלכה קריטית ומיידית, שכן ללא זיהוי נכון, המערכת אינה יכולה לטעון את הדרייברים או הקוד המתאימים כדי לפרש ולתפעל את מבנה הדיסק כלל. אופציות ב' ו-ג' הן אכן השלכות אפשריות של Superblock פגום, אך הן תלויות ביכולת הראשונית של המערכת לזהות ולגשת למערכת הקבצים, יכולת שנפגעת קודם כל אם סוג מערכת הקבצים אינו ידוע. אופציה ד' מתארת בעיית ביצועים בגישה לבלוקים בודדים של קבצים, שאינה קשורה ישירות לתפקיד ה-Superblock בניהול המטא-נתונים הכלליים של מערכת הקבצים."}, "_source_file": "0335__File_Systems__Superblock__MC__Hard.json", "_topic_hint": "Superblock", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:15:31", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Superblock"], "difficulty_estimation": "Hard", "content": {"text": "בהתחשב בתפקידו הכפול של ה-Superblock להחזיק נתונים סטטיים על מערכת הקבצים (כגון גודל דיסק ומספר inodes) וכן נתונים דינמיים (כמו המצביע הראשון ב-Journal), איזו מהטענות הבאות מדגישה באופן הטוב ביותר את ההשלכה הקריטית של הנתונים הדינמיים ב-Superblock על אמינות מערכת הקבצים?", "code_snippet": null, "options": ["א. הנתונים הדינמיים מאפשרים למערכת הקבצים לזהות את סוגה ולהפעיל את קוד הטיפול המתאים בזמן האתחול.", "ב. הם חיוניים לקביעת נקודת ההתחלה לשחזור פעולות לאחר קריסת מערכת, ובכך מבטיחים את עקביות הנתונים.", "ג. הנתונים הדינמיים משפרים את ביצועי הגישה האקראית לבלוקים על ידי צמצום הצורך בסריקה מלאה של טבלאות מיפוי.", "ד. הם מסייעים בניהול הקצאת inodes על ידי מתן גישה מהירה ל-inode bitmap, ובכך מקלים על יצירת קבצים חדשים."]}, "solution": {"correct_option": "ב", "explanation": "החומר המצורף מציין כי ה-Superblock מכיל נתונים סטטיים כמו סוג מערכת הקבצים, גודל הדיסק ומיקום ה-bitmaps, אך גם נתונים דינמיים, כגון 'הראשון של ה-superblock יהיה ל- Tx2' ביומן. ההסבר מדגיש את חשיבותו של מצביע זה בתהליך השחזור: 'אם המחשב יקרוס ויעלה שוב, הוא לא יצטרך להתחיל מההתחלה ולעדכן את הכל, הוא יוכל להתחיל ישר מ-3. כלומר, הוא יקרא את ה-superblock וידע מאיפה להתחיל.' טענה ב' מתארת במדויק תפקיד קריטי זה של הנתונים הדינמיים ב-Superblock – קביעת נקודת ההתחלה לשחזור פעולות לאחר קריסה, מה שמבטיח את עקביות הנתונים. יתר האפשרויות מתייחסות לנתונים סטטיים ב-Superblock (א'), להשלכות ביצועים כלליות שאינן קשורות ישירות לנתונים הדינמיים ב-Superblock (ג'), או למידע סטטי על מיקום מפות סיביות (ד')."}, "_source_file": "0336__File_Systems__Superblock__MC__Hard.json", "_topic_hint": "Superblock", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:15:44", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Directory Structure"], "difficulty_estimation": "Easy", "content": {"text": "איזה פרט מידע, הנשמר ב-inode, מאפשר למערכת הקבצים להבחין בין קובץ רגיל לבין תיקייה (directory)?", "code_snippet": null, "options": ["א. ה-UID (מזהה הבעלים)", "ב. ה-Type (סוג הקובץ)", "ג. ה-Size (גודל הקובץ בבתים)", "ד. ה-Links count (מספר הקישורים לקובץ)"]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר ההרצאה, ה-inode מכיל מטא-דאטה על קבצים, ואחד מהפרטים המפורטים הוא 'Type (file / directory)'. פרט מידע זה מציין במפורש האם הרשומה היא קובץ רגיל או תיקייה, ובכך מאפשר למערכת הקבצים להבחין ביניהם. שאר הפרטים כמו UID, Size או Links count אינם משמשים ישירות למטרה זו."}, "_source_file": "0337__File_Systems__Directory_Structure__MC__Easy.json", "_topic_hint": "Directory Structure", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:15:51", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Directory Structure"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, איזה שדה ב-inode מאפשר למערכת הקבצים להבחין אם ה-inode מייצג קובץ רגיל או תיקייה?", "code_snippet": null, "options": ["א. ה-UID (מזהה הבעלים).", "ב. שדה ה\"סוג\" (Type).", "ג. מספר בלוקי הנתונים.", "ד. ספירת הקישורים (Links count)."]}, "solution": {"correct_option": "ב", "explanation": "חומר ההרצאה מציין בפירוש שבין המידע הנשמר ב-inode קיים שדה \"Type\" המגדיר האם ה-inode הוא מסוג \"file\" (קובץ) או \"directory\" (תיקייה). שדה זה הוא המנגנון הישיר המאפשר למערכת הקבצים להבחין בין השניים. שאר האפשרויות מתארות מידע אחר ב-inode שאינו משמש להבחנה בין קובץ לתיקייה."}, "_source_file": "0338__File_Systems__Directory_Structure__MC__Easy.json", "_topic_hint": "Directory Structure", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:16:00", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Directory Structure"], "difficulty_estimation": "Easy", "content": {"text": "לפי חומר ההרצאה, איזה סוג מידע נשמר ב-inode ומציין האם רשומת מערכת הקבצים היא קובץ רגיל או תיקיה?", "code_snippet": null, "options": ["א. Type (file / directory)", "ב. UID (owner)", "ג. Size (in bytes)", "ד. Data blocks"]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מפרט את המידע הנשמר ב-inode, וכולל במפורש את השדה 'Type (file / directory)'. שדה זה הוא הקובע האם ה-inode מייצג קובץ רגיל או תיקיה, ובכך מאפשר למערכת הקבצים לדעת את טבעה של הרשומה. שאר האפשרויות הן אכן תכונות של inode אך אינן מציינות את סוג הרשומה (קובץ לעומת תיקיה)."}, "_source_file": "0339__File_Systems__Directory_Structure__MC__Easy.json", "_topic_hint": "Directory Structure", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:16:08", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Directory Structure"], "difficulty_estimation": "Easy", "content": {"text": "מהו התפקיד העיקרי של ה-inode במערכת קבצים, כפי שתואר בחומר הלימוד?", "code_snippet": null, "options": ["א. לאחסן את התוכן בפועל (data) של קבצים ותיקיות.", "ב. להכיל את המטא-דאטה (metadata) של קבצים ותיקיות.", "ג. לשמור מפת סיביות (bitmap) המציינת אילו בלוקים בדיסק תפוסים.", "ד. לנהל רשימה מקושרת של בלוקים עבור קבצים גדולים."]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר הלימוד (שיעור 20, קטע 4), ה-inode הוא \"איזור מסוים בדיסק שיכיל את ה-metadata, כלומר את כל המידע על הקבצים\". כמו כן, רשימת התכולה של ה-inode כוללת 'Type (file / directory)', מה שמצביע על כך שהוא מאחסן מטא-דאטה עבור שני הסוגים – קבצים ותיקיות. אפשרות א' אינה נכונה מכיוון שהתוכן בפועל נשמר בבלוקי נתונים (Data Blocks) ולא ב-inode עצמו. אפשרות ג' מתארת את תפקידו של ה-Data Bitmap או ה-inode Bmap, ולא את ה-inode עצמו. אפשרות ד' מתארת שיטת הקצאת בלוקים (רשימה מקושרת) שבה ה-inode אכן מכיל מצביע לבלוק הראשון, אך תפקידו העיקרי והכללי יותר של ה-inode הוא להכיל את כלל המטא-דאטה, ולא רק לנהל רשימות מקושרות."}, "_source_file": "0340__File_Systems__Directory_Structure__MC__Easy.json", "_topic_hint": "Directory Structure", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:16:19", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Directory Structure"], "difficulty_estimation": "Medium", "content": {"text": "מהי מטרת השדה \"Links count\" (מספר קישורים) בתוך ה-inode?", "code_snippet": null, "options": ["א. לספור את סך כל הבלוקים של הנתונים שהוקצו לקובץ על הדיסק.", "ב. לציין כמה שמות (נתיבים) שונים קיימים במערכת הקבצים שמצביעים על ה-inode הזה.", "ג. לאחסן את זהות הבעלים של הקובץ (UID).", "ד. לתעד את מועד הגישה האחרון לקובץ או התיקייה."]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר ההרצאה, ה-inode מכיל מטא-דאטה אודות קובץ או תיקייה. אחד מהשדות הללו הוא \"Links count (# paths)\", שתפקידו הוא לספור את מספר הנתיבים השונים במערכת הקבצים המצביעים על אותו ה-inode. כלומר, הוא מציין כמה שמות קבצים או תיקיות שונות (קישורים קשיחים) מפנות לנתונים ולמטא-דאטה המיוצגים על ידי ה-inode הספציפי. כאשר ה-links count מגיע לאפס, ה-inode והנתונים המשויכים אליו נמחקים פיזית מהדיסק."}, "_source_file": "0341__File_Systems__Directory_Structure__MC__Medium.json", "_topic_hint": "Directory Structure", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:16:30", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Directory Structure"], "difficulty_estimation": "Medium", "content": {"text": "מהו אחד ממרכיבי המטא-דאטה החיוניים הנשמרים ב-inode, המאפשר למערכת הקבצים להבחין בין קובץ רגיל לבין ספרייה?", "code_snippet": null, "options": ["א. מספר הקישורים (Links count)", "ב. סוג האובייקט (Type)", "ג. גודל הקובץ בבתים (Size)", "ד. מפת סיביות של נתונים (Data Bmap)"]}, "solution": {"correct_option": "ב", "explanation": "ה-inode הוא מבנה נתונים בדיסק המכיל את כל המטא-דאטה אודות קובץ או ספרייה. על פי חומר ההרצאה, אחד מהשדות המפורטים כחלק ממרכיבי ה-inode הוא \"Type (file / directory)\". שדה זה הוא המאפיין הישיר והברור ביותר המאפשר למערכת הקבצים להבחין האם ה-inode מתאר קובץ רגיל (file) או ספרייה (directory). שדות אחרים כמו \"Links count\" מציינים כמה קישורים (נתיבים) קיימים לאובייקט, אך אינם מגדירים את סוגו באופן בלעדי (גם לקבצים וגם לספריות יכולים להיות קישורים). \"Size\" מתאר את גודל התוכן, ו\"Data Bmap\" היא מפת סיביות כללית המנהלת הקצאת בלוקים, ולא חלק ישיר ממטא-דאטה של inode ספציפי המגדיר את סוגו."}, "_source_file": "0342__File_Systems__Directory_Structure__MC__Medium.json", "_topic_hint": "Directory Structure", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:16:41", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Directory Structure"], "difficulty_estimation": "Medium", "content": {"text": "על פי חומר ההרצאה, איזה רכיב בתוך ה-inode מאפשר למערכת הקבצים להבחין בין קובץ רגיל לבין ספרייה (directory)?", "code_snippet": null, "options": ["א. השדה `Type` (סוג) המאוחסן ב-inode.", "ב. רשימת `Data blocks` (בלוקי נתונים) שאליהם ה-inode מצביע.", "ג. ה-`Links count` (מספר קישורים) של ה-inode.", "ד. ה-`Size` (גודל) של הקובץ המופיע ב-inode."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מציין במפורש כי בין המידע הנשמר ב-inode נכלל השדה `Type` (סוג), אשר מוגדר כ-`(file / directory)`. שדה זה הוא המנגנון המיועד והעיקרי שבאמצעותו מערכת הקבצים מבחינה בין קובץ רגיל לבין ספרייה. בעוד ששדות אחרים כמו `Data blocks`, `Links count` או `Size` עשויים להיות שונים בין קבצים וספריות, השדה `Type` הוא המזהה המפורש לסוג האובייקט."}, "_source_file": "0343__File_Systems__Directory_Structure__MC__Medium.json", "_topic_hint": "Directory Structure", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:16:53", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Directory Structure"], "difficulty_estimation": "Medium", "content": {"text": "איזה שדה ב-inode מאפשר למערכת הקבצים להבחין בין קובץ רגיל לבין ספרייה (directory)?", "code_snippet": null, "options": ["א. שדה ה-'Type'", "ב. שדה ה-'Size'", "ג. שדה ה-'Data blocks'", "ד. שדה ה-'Links count'"]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, ה-inode מכיל metadata אודות קבצים וספריות. אחד מהשדות המפורטים ב-inode הוא 'Type (file / directory)', המציין במפורש האם ה-inode מתאר קובץ רגיל או ספרייה. שדות אחרים כמו 'Size' מתארים את גודל הקובץ/ספרייה, 'Data blocks' מצביע לבלוקי הנתונים בפועל, ו-'Links count' מציין את מספר הנתיבים המצביעים ל-inode, אך אף אחד מהם לא מגדיר את סוג הישות (קובץ או ספרייה) כמו שדה ה-'Type'."}, "_source_file": "0344__File_Systems__Directory_Structure__MC__Medium.json", "_topic_hint": "Directory Structure", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:17:02", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Directory Structure"], "difficulty_estimation": "Hard", "content": {"text": "בעת יצירת קישור קשיח (hard link) לקובץ קיים, מתבצעות שתי פעולות עיקריות במערכת הקבצים:\n1. עדכון רשומת התיקייה (directory entry) בתיקיית האב כדי לכלול את הקישור החדש.\n2. הגדלת מונה הקישורים (Links count) ב-inode של הקובץ המקורי.\nבהתבסס על עקרונות עקביות מערכת הקבצים שנדונו בחומר הלימוד, מה תהיה התוצאה אם מערכת הקבצים תקרוס לאחר שבוצעה רק הפעולה השנייה (הגדלת מונה הקישורים ב-inode), אך לפני שבוצעה הפעולה הראשונה (עדכון רשומת התיקייה)?", "code_snippet": null, "options": ["א. הקובץ המקורי ייחשב כבעל קישור נוסף, אך לא תהיה דרך אמיתית לגשת אליו דרך הקישור החדש, מה שיוביל למצב של 'דליפת' קישור (link leak) ב-inode.", "ב. הקובץ המקורי יימחק באופן מיידי מכיוון שמערכת הקבצים לא תמצא רשומה מתאימה בתיקייה עבור הקישור החדש.", "ג. מערכת הקבצים תתקן אוטומטית את המצב בעת האתחול מחדש, מכיוון שזוהי פעולה פשוטה שאינה דורשת שיחזור מורכב.", "ד. הקובץ המקורי יהפוך לבלתי נגיש לחלוטין, ותהיה גישה אליו רק דרך הקישור החדש שאינו קיים בפועל."]}, "solution": {"correct_option": "א", "explanation": "בחומר הלימוד נדון מקרה שבו מערכת הקבצים קורסת לאחר עדכון ה-data bitmap בלבד, לפני שבלוק הנתונים החדש מקושר ל-inode כלשהו. במקרה כזה, הבלוק מסומן כתפוס אך אינו בשימוש, מה שמוביל ל'דליפה' (leak) של זיכרון - בלוק מבוזבז שמסומן כתפוס אך איש אינו משתמש בו. באופן דומה, כאשר מונה הקישורים (Links count) ב-inode גדל אך רשומת התיקייה המתאימה טרם נוצרה, ה-inode מציין שיש לו קישור נוסף שאינו קיים בפועל. מצב זה יוצר אי-עקביות במערכת הקבצים, שבה ה-metadata (מונה הקישורים) אינו משקף נכונה את המצב הפיזי או הלוגי של הקבצים בתיקיות. חומר הלימוד מציין במפורש כי במצב קריסה כזה, 'כשנעלה את המחשב מחדש, לא נדע שקרסנו באמצע הפעולה, אין לנו דרך לדעת זאת, והגענו למצב לא תקין של מערכת הקבצים שלנו'. לכן, מערכת הקבצים לא תתקן זאת אוטומטית בעת אתחול מחדש. הקובץ עדיין נגיש דרך הקישורים הקודמים שלו, אך ה-inode שלו מדווח על מספר קישורים שגוי, מהווה 'דליפת' קישור (link leak) ב-inode."}, "_source_file": "0345__File_Systems__Directory_Structure__MC__Hard.json", "_topic_hint": "Directory Structure", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:17:18", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Directory Structure"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על מבנה ה-inode כפי שתואר ועל עקרונות עקביות מערכת הקבצים לאחר קריסה, איזו מהטענות הבאות מתארת את בעיית העקביות החמורה ביותר שעלולה להיווצר במערכת קבצים המשתמשת ב-inodes, בעת יצירת קישור קשיח (hard link) לקובץ קיים, אם סדר הפעולות אינו מתוכנן בקפידה?", "code_snippet": null, "options": ["א. אם ספירת הקישורים ב-inode של הקובץ מעודכנת לעלות לפני שרשומת התיקייה החדשה נכתבת לדיסק, ומתרחשת קריסה, אז הקובץ יופיע עם ספירת קישורים גבוהה מדי, מה שיוביל לבזבוז משאבים בכך שה-inode לא ישוחרר גם אם כל הקישורים האחרים יוסרו.", "ב. אם רשומת התיקייה החדשה נכתבת לדיסק לפני שספירת הקישורים ב-inode של הקובץ מעודכנת לעלות, ומתרחשת קריסה, אז הקישור החדש בתיקייה יצביע ל-inode עם ספירת קישורים נמוכה מדי. אם כל הקישורים המקוריים יוסרו, ה-inode עלול להימחק ולהיות מוקצה מחדש בזמן שהקישור החדש עדיין קיים, מה שיוביל לקישור תלוי (dangling pointer) ולשחיתות נתונים פוטנציאלית.", "ג. יצירת קישור קשיח אינה דורשת עדכון של ה-inode עצמו, אלא רק הוספת רשומה בתיקיית האב, ולכן אין בעיות עקביות הנוגעות לספירת קישורים ב-inode.", "ד. ה-inode מכיל רק מצביעים לבלוקי נתונים ואינו קשור ישירות לספירת קישורים, ולכן עדכון ספירת הקישורים אינו מהווה פעולה קריטית לשמירת עקביות ה-inode במקרה של קריסה."]}, "solution": {"correct_option": "ב", "explanation": "ה-inode מכיל את ספירת הקישורים (Links count), כפי שצוין בחומר ההרצאה. בעת יצירת קישור קשיח, נדרשות לפחות שתי פעולות עיקריות: עדכון ספירת הקישורים ב-inode של הקובץ, וכתיבת רשומה חדשה בבלוק הנתונים של תיקיית האב המצביעה על ה-inode של הקובץ.\n\nאפשרות א' מתארת מצב שבו ספירת הקישורים ב-inode גבוהה מדי. זהו מצב של 'ליג' משאבים', בדומה לתרחיש של עדכון ה-data bitmap לפני עדכון ה-inode כפי שתואר בהרצאה (Lecture 21, chunk 8), שבו בלוק מסומן כתפוס אך לא בשימוש. מצב זה מוביל לבזבוז מקום אך בדרך כלל אינו מוביל לשחיתות נתונים חמורה.\n\nאפשרות ב' מתארת את הבעיה החמורה יותר: אם רשומת התיקייה נכתבת לפני שספירת הקישורים ב-inode מעודכנת, ומתרחשת קריסה, הרי שרשומה חוקית בתיקייה מצביעה על inode שאינו 'מודע' לקיומה. אם כל הקישורים המקוריים לקובץ נמחקים, ספירת הקישורים ב-inode תגיע לאפס (שכן היא לא הוגדלה עבור הקישור החדש), וה-inode עלול להימחק ולהיות מוקצה מחדש. במצב זה, הקישור החדש בתיקייה יצביע ל-inode שאינו שייך לקובץ המקורי, מה שיוצר 'קישור תלוי' (dangling pointer) ועלול להוביל לשחיתות נתונים חמורה או לקריסת המערכת בגישה לנתונים שגויים.\n\nאפשרויות ג' ו-ד' שגויות, שכן חומר ההרצאה מציין במפורש ש-inode מכיל 'Links count (# paths)', ולכן עדכון זה הוא קריטי לשמירת העקביות של מערכת הקבצים."}, "_source_file": "0346__File_Systems__Directory_Structure__MC__Hard.json", "_topic_hint": "Directory Structure", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:17:47", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Directory Structure"], "difficulty_estimation": "Hard", "content": {"text": "מהי ההבחנה המהותית בין `inode` המייצג קובץ לבין `inode` המייצג תיקייה, בהתייחס לתוכן בלוקי הנתונים (`Data blocks`) שלהם, על פי המודל המתואר בחומר השיעור?", "code_snippet": null, "options": ["א. בלוקי הנתונים של קובץ מכילים את התוכן הבינארי של הקובץ, בעוד שבלוקי הנתונים של תיקייה מכילים רשימה של שמות קבצים ומספרי `inode` מתאימים.", "ב. קובץ משתמש בבלוקי נתונים רציפים בלבד, בעוד שתיקייה תמיד משתמשת בבלוקי נתונים המקושרים בשיטת \"רשימה מקושרת\".", "ג. ל-`inode` של קובץ יש שדה `Size` המציין את גודל הקובץ בבתים, אך ל-`inode` של תיקייה אין שדה כזה.", "ד. `inode` של קובץ מצביע ישירות לבלוקי הנתונים, בעוד ש-`inode` של תיקייה מצביע ל-`inode Bmap` כדי למצוא את הבלוקים של הפריטים שבתוכה."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר השיעור, לכל `inode` יש שדה `Type` המציין אם הוא קובץ או תיקייה, ושדה `Data blocks` המצביע לבלוקים המכילים את הנתונים. כאשר `inode` מייצג קובץ, בלוקי הנתונים מכילים את התוכן הגולמי (בינארי) של הקובץ. לעומת זאת, כאשר `inode` מייצג תיקייה, תפקידה הוא לארגן קבצים ותיקיות אחרות. לכן, בלוקי הנתונים שלה חייבים להכיל רשימה של שמות קבצים ותיקיות יחד עם מספרי ה-`inode` המתאימים להם, ובכך לאפשר למערכת הקבצים לאתר את הפריטים בתוך התיקייה.\n\nאפשרויות ב', ג' ו-ד' שגויות:\nב. חומר השיעור מציין במפורש ששיטת הקצאת \"רשימה מקושרת\" פותרת בעיות פרגמנטציה חיצונית ומאפשרת לקבצים להתפזר על פני הדיסק (\"קובץ יכול להתפזר על פני הדיסק ולא חייב להיות רציף\"), כלומר קבצים אינם חייבים להשתמש בבלוקים רציפים בלבד.\nג. שדה `Size` מופיע כמאפיין כללי של `inode` ברשימת תכונות ה-`inode`, ללא הבחנה בין קובץ לתיקייה. לכן, גם לתיקייה יהיה שדה `Size` המציין את גודל רשימת התוכן שלה.\nד. ה-`inode Bmap` משמש למעקב אחר `inode`ים תפוסים/פנויים, ולא כמצביע לבלוקי נתונים של פריטים בתוך תיקייה. `inode` מצביע ישירות לבלוקי הנתונים שלו (או דרך מנגנון עקיף כמו רשימה מקושרת), לא ל-`inode Bmap`."}, "_source_file": "0347__File_Systems__Directory_Structure__MC__Hard.json", "_topic_hint": "Directory Structure", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:18:09", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Directory Structure"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על מבנה ה-inode המתואר בחומר, הכולל את שדות ה-\"Type (file / directory)\" ו-\"Links count (# paths)\", איזו מהטענות הבאות מתארת בצורה הטובה ביותר כיצד שדות אלו תורמים לניהול עקבי ואמין של מבנה התיקיות במערכת הקבצים?", "code_snippet": null, "options": ["א. שדה \"Links count\" מבטיח ש-inode ובלוקי הנתונים המשויכים אליו יימחקו רק כאשר כל ההפניות אליו ממבנה התיקיות יוסרו, ובכך מונע איבוד נתונים ומאפשר מימוש קישורים קשיחים. שדה \"Type\" מאפשר למערכת הקבצים להבחין בין קבצים רגילים לתיקיות.", "ב. שדה \"Links count\" משמש בעיקר למניעת פרגמנטציה חיצונית בתיקיות על ידי מעקב אחר בלוקים רציפים, בעוד שדה \"Type\" קובע את סדר הגישה לבלוקים.", "ג. שדה \"Type\" אוכף הרשאות קריאה/כתיבה/הפעלה רק עבור פעולות על תיקיות, ולא עבור קבצים רגילים, בעוד שדה \"Links count\" מציין את מספר הבלוקים של הנתונים בתיקייה.", "ד. ה-inode מאחסן את הנתיב המלא לכל קובץ ותיקייה, ובכך מייעל את פעולות החיפוש ומבטל את הצורך בטיול היררכי, כאשר \"Links count\" מציין את עומק ההיררכיה."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'.\n\n**הסבר לאפשרות א' (נכונה):**\n*   **שדה \"Links count (# paths)\"**: על פי חומר ההרצאה, שדה זה ב-inode עוקב אחר מספר הנתיבים (paths) המצביעים ל-inode. כלומר, הוא סופר כמה כניסות בתיקיות שונות מפנות לאותו קובץ או תיקייה. עובדה זו חיונית לניהול קישורים קשיחים (hard links), שבהם מספר שמות קבצים יכולים להפנות לאותו inode. המערכת תמחק את ה-inode ואת בלוקי הנתונים שלו רק כאשר מונה הקישורים יגיע לאפס, כלומר, כאשר אין עוד הפניות אליו ממבנה התיקיות. זה מונע מחיקה מוקדמת של נתונים ומבטיח שלמות.\n*   **שדה \"Type (file / directory)\"**: חומר ההרצאה מציין ששדה זה הוא חלק מה-metadata ב-inode. הוא מאפשר למערכת הקבצים להבחין האם ה-inode מייצג קובץ רגיל או תיקייה. הבחנה זו הכרחית מכיוון שתיקייה היא סוג מיוחד של קובץ שבלוקי הנתונים שלו מכילים רשימה של שמות קבצים ומספרי inodes מתאימים, בעוד שקובץ רגיל מכיל נתוני משתמש. ההבחנה מאפשרת למערכת הקבצים לבצע פעולות מתאימות לכל סוג.\n\n**הסבר לאפשרויות שגויות:**\n*   **אפשרות ב'**: שדה \"Links count\" אינו קשור למניעת פרגמנטציה חיצונית; שיטות הקצאת בלוקים (כמו רשימה מקושרת המוזכרת בחומר) מטפלות בכך. שדה \"Type\" אינו קובע את סדר הגישה לבלוקים.\n*   **אפשרות ג'**: הרשאות קריאה/כתיבה/הפעלה (rwx) הן שדה נפרד ב-inode, ואינן נאכפות רק על ידי שדה \"Type\". שדה \"Links count\" מציין את מספר הנתיבים ל-inode, לא את מספר בלוקי הנתונים בתיקייה.\n*   **אפשרות ד'**: ה-inode אינו מאחסן את הנתיב המלא לקובץ או לתיקייה. מערכות קבצים היררכיות דורשות בדרך כלל טריוורסל (מעבר) דרך תיקיות כדי למצוא קובץ. שדה \"Links count\" מציין את מספר ההפניות ל-inode, לא את עומק ההיררכיה."}, "_source_file": "0348__File_Systems__Directory_Structure__MC__Hard.json", "_topic_hint": "Directory Structure", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:18:29", "_subject": "File Systems", "_context_lectures": [20, 21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Crash Consistency"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של **Crash Consistency** במערכות קבצים?", "code_snippet": null, "options": ["א. למנוע אובדן נתונים של משתמשים כתוצאה מקריסה.", "ב. להבטיח שמערכת הקבצים תישאר במצב תקין ועקבי לאחר קריסה.", "ג. לשפר את ביצועי הקריאה והכתיבה על ידי איחוד בלוקים.", "ד. לאפשר כתיבה של מספר בלוקים בו זמנית באופן אטומי."]}, "solution": {"correct_option": "ב", "explanation": "החומר המלמד מגדיר את Crash Consistency כהתמודדות עם קריסות \"בלי להשאיר את מערכת הקבצים שלנו במצב לא תקין\". המטרה המפורשת היא \"לקחת את מערכת הקבצים ולהעביר אותה ממצב תקין אחד למצב תקין אחר באופן אטומי\" וכי \"מעניינת אותנו אך ורק התקינות של מערכת הקבצים\". לכן, האפשרות הנכונה היא ב'. אפשרות א' שגויה מכיוון שהחומר מציין ש\"אם משתמש איבד את הנתונים זה לא מעניין אותנו\" בהקשר זה. אפשרויות ג' וד' אינן מתארות את מטרת Crash Consistency כפי שהוצגה בחומר."}, "_source_file": "0349__File_Systems__Crash_Consistency__MC__Easy.json", "_topic_hint": "Crash Consistency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:18:38", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Crash Consistency"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של מושג ה-Crash Consistency במערכות קבצים?", "code_snippet": null, "options": ["א. להבטיח שמערכת הקבצים תעבור ממצב תקין אחד למצב תקין אחר באופן אטומי, ולמנוע מצב לא תקין לאחר קריסה.", "ב. למנוע לחלוטין אובדן נתונים של המשתמשים כתוצאה מקריסה.", "ג. לשפר את מהירות הגישה לנתונים על ידי אופטימיזציה של מיקום ה-inodes.", "ד. להפחית את השימוש בזיכרון הראשי על ידי העברת בלוקים \"קרים\" לדיסק."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין בשיעור מבהיר כי המטרה העיקרית של Crash Consistency היא 'לקחת את מערכת הקבצים ולהעביר אותה ממצב תקין אחד למצב תקין אחר באופן אטומי', וכן 'איך אנחנו מתמודדים עם קריסות בלי להשאיר את מערכת הקבצים שלנו במצב לא תקין'. לכן, אפשרות א' מתארת במדויק מטרה זו. אפשרות ב' אינה נכונה, שכן החומר מציין במפורש ש'לא מעניין אותנו אם אבדו נתונים, מעניינת אותנו אך ורק התקינות של מערכת הקבצים'. אפשרויות ג' ו-ד' מתארות מטרות או היבטים אחרים במערכות קבצים (כמו ביצועים או ניהול בלוקים), שאינם המטרה המרכזית של Crash Consistency."}, "_source_file": "0350__File_Systems__Crash_Consistency__MC__Easy.json", "_topic_hint": "Crash Consistency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:18:50", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Crash Consistency"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של התמודדות עם בעיית Crash Consistency במערכות קבצים?", "code_snippet": null, "options": ["א. להבטיח שמערכת הקבצים תישאר במצב תקין (consistent) גם לאחר קריסה בלתי צפויה.", "ב. למנוע אובדן נתונים של המשתמש בכל מצב, גם אם הנתונים לא נכתבו פיזית לדיסק.", "ג. לשפר את ביצועי הגישה האקראית לקבצים גדולים.", "ד. להפעיל תוכנית File System Checker (fsck) באופן יזום בכל פעם שמבוצעת פעולת כתיבה."]}, "solution": {"correct_option": "א", "explanation": "ההרצאה מגדירה במפורש את בעיית Crash Consistency כדרך להתמודד עם קריסות \"בלי להשאיר את מערכת הקבצים שלנו במצב לא תקין\" (הרצאה 21, קטע 4). המטרה היא \"לקחת את מערכת הקבצים ולהעביר אותה ממצב תקין אחד למצב תקין אחר באופן אטומי\" (הרצאה 21, קטע 13). לכן, המטרה העיקרית היא להבטיח את תקינות ועקביות מערכת הקבצים לאחר קריסה.\nאפשרויות אחרות אינן נכונות מכיוון:\nב. ההרצאה מציינת במפורש כי מניעת אובדן נתוני משתמש אינה המטרה העיקרית של Crash Consistency: \"אם משתמש איבד את הנתונים זה לא מעניין אותנו, אנחנו לא יכולים למנוע שהם יאבדו אם הנתונים לא נכתבו\" (הרצאה 21, קטע 13).\nג. שיפור ביצועי גישה אקראית נדון בהקשר של מבני נתונים של מערכת קבצים (הרצאה 20, קטע 13), ולא כמטרה של Crash Consistency.\nד. בעוד ש-File System Checker (fsck) הוא פתרון לבעיית Crash Consistency, הוא אינו המטרה עצמה. בנוסף, fsck מופעל בדרך כלל לאחר קריסה, בזמן עליית המחשב, ולא באופן יזום בכל פעולת כתיבה (הרצאה 21, קטע 15)."}, "_source_file": "0351__File_Systems__Crash_Consistency__MC__Easy.json", "_topic_hint": "Crash Consistency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:19:02", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Crash Consistency"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של התמודדות עם בעיית ה-Crash Consistency במערכות קבצים?", "code_snippet": null, "options": ["א. למנוע מצב של אובדן נתונים למשתמשים במקרה של קריסה.", "ב. להבטיח שמערכת הקבצים תישאר במצב תקין ועקבי לאחר קריסה.", "ג. לשפר את ביצועי הגישה האקראית לבלוקים בדיסק על ידי שימוש ברשימות מקושרות.", "ד. לסווג בלוקים כ\"חמים\" או \"קרים\" כדי לייעל את פעולת ה-cleaner."]}, "solution": {"correct_option": "ב", "explanation": "חומר ההרצאה מגדיר את בעיית ה-Crash Consistency כשאלה של \"איך אנחנו מתמודדים עם קריסות בלי להשאיר את מערכת הקבצים שלנו במצב לא תקין\". ההרצאה מדגישה במפורש כי \"לא מעניין אותנו אם אבדו נתונים, מעניינת אותנו אך ורק התקינות של מערכת הקבצים\". המטרה היא להעביר את מערכת הקבצים \"ממצב תקין אחד למצב תקין אחר באופן אטומי\". לכן, המטרה העיקרית היא שמירה על תקינות ועקביות מערכת הקבצים עצמה, ולא מניעת אובדן נתוני משתמשים. תשובה א' שגויה מכיוון שהיא מתמקדת במניעת אובדן נתונים, דבר שההרצאה מציינת שאינו המטרה העיקרית. תשובות ג' ו-ד' מתייחסות לנושאים אחרים שנדונו בהרצאות אחרות ואינן קשורות ישירות ל-Crash Consistency."}, "_source_file": "0352__File_Systems__Crash_Consistency__MC__Easy.json", "_topic_hint": "Crash Consistency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:19:13", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Crash Consistency"], "difficulty_estimation": "Medium", "content": {"text": "מהי הגישה המרכזית של כלי ה-`fsck` (File System Checker) להתמודדות עם בעיות של Crash Consistency, ומהי מגבלה משמעותית של גישה זו?", "code_snippet": null, "options": ["א. הגישה היא למנוע כתיבות לא אטומיות על ידי ריצה ברקע, אך מגבלתה היא פגיעה בביצועים.", "ב. הגישה היא לתקן בעיות לאחר שהתרחשו על ידי סריקת הדיסק, אך מגבלתה היא שאינה יכולה לגלות בעיות שבהן מערכת הקבצים נראית תקינה מבחינה מבנית למרות שנתונים בפועל הם \"זבל\".", "ג. הגישה היא להבטיח אטומיות של כל פעולת כתיבה באמצעות חלוקה לסגמנטים \"חמים\" ו\"קרים\", אך מגבלתה היא מורכבות היישום.", "ד. הגישה היא למנוע אובדן נתונים בכל מצב של קריסה, אך מגבלתה היא שהיא מצריכה שמירת עותקים רבים של הנתונים."]}, "solution": {"correct_option": "ב", "explanation": "הגישה המרכזית של כלי ה-`fsck` היא לתת לבעיות לקרות ולאחר מכן לתקן אותן על ידי סריקת הדיסק ובדיקת מצבו לאחר קריסה, כפי שמתואר בחומר ההרצאה: \"הגישה: ניתן לבעיות לקרות ונתקן אותן אחר-כך\". מגבלה משמעותית של גישה זו היא ש-`fsck` אינו יכול לגלות ולתקן כל בעיה. לדוגמה, אם inode מצביע לבלוק נתונים המסומן כתפוס ב-bitmap, אך בפועל הבלוק מכיל נתונים לא רלוונטיים (\"זבל\") ומבחינה מבנית מערכת הקבצים נראית תקינה, ה-`fsck` לא יזהה זאת כבעיה. הציטוט מההרצאה תומך בכך: \"אבל אם מערכת הקבצים שלנו נראית תקינה ויש בעיה, הוא לא יוכל לתקן אותה. למשל: נניח ויש לנו inode שמצביע ל-דאטה כלשהו, בלי data block שנכתב לשם, וב-bitmap הדאטה הזה מסומן כתפוס. כלומר מצב מערכת הקבצים נראה תקין, אף לא כתבנו את הדאטה לדאטה בלוק בפועל. יש שם זבל. את המצב הזה הכלי הנ\"ל לא יכול לגלות.\" לכן, אפשרות ב' היא הנכונה ביותר."}, "_source_file": "0353__File_Systems__Crash_Consistency__MC__Medium.json", "_topic_hint": "Crash Consistency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:19:26", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Crash Consistency"], "difficulty_estimation": "Medium", "content": {"text": "מהי אחת המגבלות המרכזיות של כלי ה-File System Checker (fsck) בהתמודדות עם בעיות Crash Consistency, כפי שתוארה בחומר ההרצאה?", "code_snippet": null, "options": ["א. הוא אינו יכול לזהות מצב שבו inode מצביע לבלוק נתונים (data block) שמסומן כתפוס ב-bitmap, אך בפועל מכיל \"זבל\" ולא את הנתונים המצופים.", "ב. הוא אינו יכול לתקן בעיות הנובעות מקריסה שהתרחשה לפני הכתיבה הראשונה של נתונים לקובץ.", "ג. הוא דורש הפעלה ידנית על ידי המשתמש ואינו רץ אוטומטית בעת עליית המערכת לאחר קריסה.", "ד. הוא גורם לפגיעה משמעותית בביצועים בזמן ריצה, בדומה ל-cleaner המטפל ב\"סגמנטים קרים\", ועל כן אינו מופעל לעיתים קרובות."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר ההרצאה מציין במפורש מגבלה זו של כלי ה-fsck: \"אם מערכת הקבצים שלנו נראית תקינה ויש בעיה, הוא לא יוכל לתקן אותה. למשל: נניח ויש לנו inode שמצביע ל-דאטה כלשהו, בלי data block שנכתב לשם, וב-bitmap הדאטה הזה מסומן כתפוס. כלומר מצב מערכת הקבצים נראה תקין, אף לא כתבנו את הדאטה לדאטה בלוק בפועל. יש שם זבל. את המצב הזה הכלי הנ\"ל לא יכול לגלות.\" (הרצאה 21, קטע 15). מגבלה זו נובעת מכך שהכלי בודק עקביות מבנית (metadata consistency) אך אינו יכול לאמת את תוכן הנתונים בפועל. אפשרויות ב', ג' ו-ד' אינן מתוארות כמגבלות של fsck בחומר ההרצאה, או שהן סותרות מידע הקיים בו."}, "_source_file": "0354__File_Systems__Crash_Consistency__MC__Medium.json", "_topic_hint": "Crash Consistency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:19:40", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Crash Consistency"], "difficulty_estimation": "Medium", "content": {"text": "מהי הגישה העיקרית של כלי ה-`fsck` (File System Checker) להתמודדות עם בעיות Crash Consistency במערכת קבצים, ומהי מגבלה ידועה של גישה זו?", "code_snippet": null, "options": ["א. הגישה היא למנוע קריסות לחלוטין באמצעות כתיבות אטומיות מרובות-בלוקים, אך המגבלה היא שזה דורש חומרה מיוחדת.", "ב. הגישה היא לאפשר לבעיות לקרות ולאחר מכן לתקן אותן באמצעות סריקת הדיסק בעת עליית המחשב, אך המגבלה היא שהוא אינו יכול לגלות ולתקן מצבים בהם ה-inode מצביע לנתונים מזובלים אך ה-bitmap מסמן את הבלוק כתפוס.", "ג. הגישה היא לבצע את כל פעולות הכתיבה בסדר קבוע מראש כדי להבטיח עקביות, אך המגבלה היא שאין סדר כזה שיכול למנוע את כל הבעיות.", "ד. הגישה היא לסווג בלוקים ל\"חמים\" ו\"קרים\" ולטפל בהם באופן שונה כדי למזער נזקים מקריסה, אך המגבלה היא שזה פוגע בביצועים."]}, "solution": {"correct_option": "ב", "explanation": "כפי שמתואר בחומר ההרצאה (Lecture 21, chunk 15), הגישה של ה-File System Checker (fsck) להתמודדות עם Crash Consistency היא \"לתת לבעיות לקרות ונתקן אותן אחר-כך\". כלי זה רץ בעת עליית המחשב לאחר קריסה, סורק את הדיסק ומנסה לתקן חוסר עקביות. עם זאת, קיימת מגבלה ידועה לגישה זו: הוא אינו יכול לגלות או לתקן את כל סוגי חוסר העקביות. לדוגמה, אם inode מצביע לבלוק נתונים שלא נכתב בפועל (כלומר מכיל \"זבל\"), אך במקביל ה-bitmap מסמן את הבלוק הזה כתפוס, מערכת הקבצים נראית תקינה מבחינת מבנה המטא-דאטה, ולכן ה-fsck לא יזהה את הבעיה ולא יוכל לתקן אותה. אפשרויות א, ג, ו-ד מתארות גישות שגויות או מושגים אחרים שאינם מתארים נכונה את פעולת ה-fsck או את מגבלותיו כפי שתוארו בחומר."}, "_source_file": "0356__File_Systems__Crash_Consistency__MC__Medium.json", "_topic_hint": "Crash Consistency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:20:05", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Crash Consistency"], "difficulty_estimation": "Hard", "content": {"text": "בהתייחס לבעיית ה-Crash Consistency במערכות קבצים, ובהתבסס על תיאור פעולת הוספת 4KB לקובץ קיים (append) והמגבלות של כלי ה-File System Checker (fsck) כפי שהוצגו בחומר ההרצאה, איזה מהתרחישים הבאים של קריסה (crash) יוביל למצב של חוסר עקביות במערכת הקבצים שלא יזוהה על ידי fsck, כאשר נראה כי המטא-דאטה תקין אך תוכן הנתונים בפועל אינו תקין?", "code_snippet": null, "options": ["א. קריסה מתרחשת לאחר שבלוק הנתונים החדש הוקצה וסומן ב-bitmap כתפוס, ולאחר שה-inode עודכן להצביע לבלוק החדש, אך לפני שהנתונים בפועל נכתבו לבלוק זה.", "ב. קריסה מתרחשת לאחר שהנתונים נכתבו לבלוק הנתונים החדש, אך לפני שבלוק זה סומן ב-bitmap כתפוס וגם לפני שה-inode עודכן להצביע אליו.", "ג. קריסה מתרחשת לאחר שה-inode עודכן להצביע לבלוק הנתונים החדש, אך לפני שבלוק הנתונים החדש הוקצה וסומן ב-bitmap כתפוס, ולפני שהנתונים נכתבו אליו.", "ד. קריסה מתרחשת בדיוק במהלך כתיבת הנתונים לבלוק החדש, באופן חלקי, כאשר כל המטא-דאטה (bitmap ו-inode) כבר עודכן."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר ההרצאה מציין במפורש כי כלי ה-File System Checker (fsck) אינו יכול לגלות את כל סוגי חוסר העקביות. דוגמה ספציפית לכך היא מצב בו \"inode מצביע ל-דאטה כלשהו, בלי data block שנכתב לשם, וב-bitmap הדאטה הזה מסומן כתפוס. כלומר מצב מערכת הקבצים נראה תקין, אף לא כתבנו את הדאטה לדאטה בלוק בפועל. יש שם זבל. את המצב הזה הכלי הנ\"ל לא יכול לגלות.\" (הרצאה 21, קטע 15). תרחיש זה מתרחש כאשר הקריסה מתרחשת לאחר שכל עדכוני המטא-דאטה הנדרשים (הקצאת בלוק חדש וסימונו ב-bitmap, ועדכון ה-inode להצביע אליו) הושלמו בהצלחה, אך לפני שפעולת הכתיבה של הנתונים בפועל לבלוק זה בוצעה במלואה. במצב כזה, מערכת הקבצים נראית עקבית מבחינת המטא-דאטה שלה, אך הבלוק שאליו מצביע ה-inode מכיל 'זבל' (נתונים לא תקינים או ישנים), ו-fsck לא יבחין בכך כיוון שהוא אינו בודק את תוכן הנתונים עצמם אלא רק את עקביות המטא-דאטה."}, "_source_file": "0357__File_Systems__Crash_Consistency__MC__Hard.json", "_topic_hint": "Crash Consistency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:20:24", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Crash Consistency"], "difficulty_estimation": "Hard", "content": {"text": "על פי חומר ההרצאה, כלי ה-`fsck` מתקשה לזהות ולתקן סוג מסוים של חוסר עקביות במערכת קבצים. איזו מבין הסיטואציות הבאות מתארת מצב כזה, שבו מערכת הקבצים נראית תקינה מבחינת המבנה שלה, אך בפועל קיימת בעיה עמוקה יותר?", "code_snippet": null, "options": ["א. ה-inode מצביע לבלוק נתונים המסומן כתפוס ב-bitmap, אך התוכן בפועל של בלוק הנתונים הוא \"זבל\" מכיוון שהנתונים המיועדים מעולם לא נכתבו אליו.", "ב. ה-inode מצביע לבלוק נתונים המסומן כפנוי ב-bitmap.", "ג. ה-bitmap מסמן בלוק נתונים כתפוס, אך אין אף inode במערכת הקבצים המצביע לבלוק זה.", "ד. מספר inodes שונים במערכת הקבצים מצביעים לאותו בלוק נתונים ייחודי."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה (Lecture 21, chunk 15), כלי ה-`fsck` מתקשה לגלות ולתקן בעיות כאשר מערכת הקבצים \"נראית תקינה\" מבחינת מבנה המטא-דאטה שלה, אך בפועל מכילה נתונים שגויים או \"זבל\". הדוגמה הספציפית שניתנה היא מצב שבו \"inode מצביע ל-דאטה כלשהו, בלי data block שנכתב לשם, וב-bitmap הדאטה הזה מסומן כתפוס. כלומר מצב מערכת הקבצים נראה תקין, אף לא כתבנו את הדאטה לדאטה בלוק בפועל. יש שם זבל. את המצב הזה הכלי הנ\"ל לא יכול לגלות.\"אפשרות א' מתארת בדיוק מצב זה: ה-inode וה-bitmap עקביים (הבלוק מסומן כתפוס וה-inode מצביע אליו), ולכן מבחינת `fsck` המערכת נראית תקינה. עם זאת, התוכן בפועל של בלוק הנתונים אינו הנתונים המיועדים, אלא \"זבל\", מכיוון שהכתיבה בפועל של הנתונים לבלוק לא הושלמה. `fsck` בודק עקביות של מבני נתונים (מטא-דאטה) ולא את תקינות תוכן הנתונים עצמם.\nאפשרויות ב', ג' ו-ד' מתארות כולן מצבי חוסר עקביות במטא-דאטה (למשל, inode מצביע לבלוק פנוי, בלוק מסומן כתפוס אך לא בשימוש, או בלוק משותף באופן לא חוקי), שמצבים אלו `fsck` מיועד לזהות ולרוב אף לתקן."}, "_source_file": "0358__File_Systems__Crash_Consistency__MC__Hard.json", "_topic_hint": "Crash Consistency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:20:41", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Crash Consistency"], "difficulty_estimation": "Hard", "content": {"text": "מערכת קבצים נתקלת בקריסה בלתי צפויה במהלך פעולת כתיבה. לאחר האתחול מחדש, כלי ה-`fsck` (File System Checker) מופעל. בהתבסס על החומר הנלמד, איזה מבין המצבים הבאים, המעידים על חוסר עקביות פנימי, כלי ה-`fsck` *לא יוכל* לגלות או לתקן באופן אמין?", "code_snippet": null, "options": ["א. Inode שמצביע לבלוק נתונים שסומן ב-bitmap כתפוס, אך בפועל הבלוק מכיל נתונים שגויים (\"זבל\") כיוון שהכתיבה אליו לא הושלמה.", "ב. Inode שמצביע לבלוק נתונים שאינו מסומן ב-bitmap כתפוס, מה שמעיד על בלוק דאטה תפוס אך לא מקושר.", "ג. בלוק נתונים שסומן ב-bitmap כתפוס, אך בפועל אין אף Inode שמצביע אליו (בלוק \"אבוד\").", "ד. Inode שמסומן ב-inode bitmap כתפוס, אך בפועל אינו מצביע לאף בלוק נתונים (Inode ריק אך מסומן כתפוס)."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין בשיעור 21, קטע 15, מתאר במפורש את המגבלה הזו של כלי ה-`fsck`. נאמר שם: \"אבל אם מערכת הקבצים שלנו נראית תקינה ויש בעיה, הוא לא יוכל לתקן אותה. למשל: נניח ויש לנו inode שמצביע ל-דאטה כלשהו, בלי data block שנכתב לשם, וב-bitmap הדאטה הזה מסומן כתפוס. כלומר מצב מערכת הקבצים נראה תקין, אף לא כתבנו את הדאטה לדאטה בלוק בפועל. יש שם זבל. את המצב הזה הכלי הנ\"ל לא יכול לגלות.\" מצב זה מתאים בדיוק לאפשרות א'. במצב זה, מבחינה מבנית, ה-inode מצביע לבלוק, וה-bitmap מציין שהבלוק תפוס – הכל נראה תקין מבחינת המטא-דאטה, אך תוכן הבלוק עצמו פגום. כלי ה-`fsck` בודק בעיקר עקביות מבנית של מטא-דאטה ולא את תקינות התוכן של הנתונים בתוך הבלוקים. האפשרויות האחרות (ב, ג, ד) מתארות מצבים של חוסר עקביות במטא-דאטה (כגון בלוק תפוס אך לא מקושר, או Inode שמצביע לבלוק לא מסומן), שאותם כלי ה-`fsck` נועד לזהות ולתקן."}, "_source_file": "0359__File_Systems__Crash_Consistency__MC__Hard.json", "_topic_hint": "Crash Consistency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:20:58", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Crash Consistency"], "difficulty_estimation": "Hard", "content": {"text": "בעיית ה-Crash Consistency במערכות קבצים נובעת מהצורך לבצע מספר כתיבות לדיסק (למשל, בעת הוספת נתונים לקובץ קיים) באופן אטומי, למרות שקריסות יכולות להתרחש בכל עת. אחד הפתרונות להתמודדות עם בעיה זו הוא שימוש בכלי ה-`fsck` (File System Checker). בהקשר למגבלותיו של `fsck`, איזה מהמצבים הבאים מהווה דוגמה לבעיה ש-`fsck` *אינו יכול* לזהות או לתקן, כפי שנדון בחומר הלימוד?", "code_snippet": null, "options": ["א. Inode המצביע לבלוק נתונים, כאשר ה-Bitmap מסמן את הבלוק כתפוס, אך תוכן בלוק הנתונים בפועל מכיל \"זבל\" (נתונים לא תקינים) כתוצאה מכתיבה שלא הושלמה.", "ב. Inode המצביע לבלוק נתונים שאינו קיים או שמסומן כפנוי ב-Bitmap, מה שמעיד על מצביע \"תלוי\" (dangling pointer).", "ג. בלוק נתונים המסומן כתפוס ב-Bitmap, אך אין אף Inode המצביע עליו, מה שמוביל לאובדן שטח דיסק (lost block).", "ד. חוסר התאמה בין גודל הקובץ המצוין ב-Inode לבין מספר בלוקי הנתונים בפועל שה-Inode מצביע עליהם."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר הלימוד מציין במפורש כי `fsck` אינו יכול לגלות מצב שבו \"יש לנו inode שמצביע ל-דאטה כלשהו, בלי data block שנכתב לשם, וב-bitmap הדאטה הזה מסומן כתפוס. כלומר מצב מערכת הקבצים נראה תקין, אף לא כתבנו את הדאטה לדאטה בלוק בפועל. יש שם זבל. את המצב הזה הכלי הנ\"ל לא יכול לגלות.\" הסיבה לכך היא שמבחינת מטא-הנתונים של מערכת הקבצים (ה-inode וה-bitmap), הכל נראה תקין ועקבי, למרות שתוכן הנתונים בפועל אינו נכון. `fsck` בודק בעיקר את עקביות המבנה והמטא-נתונים, ולא את \"איכות\" התוכן של בלוקי הנתונים בפועל. שאר האפשרויות (ב, ג, ד) מתארות חוסר עקביות במטא-נתונים או במבנה מערכת הקבצים, ש-`fsck` מתוכנן לזהות ולתקן (למשל, מצביעים תלויים, בלוקים אבודים, או אי-התאמות בגודל קובץ מול בלוקים בפועל)."}, "_source_file": "0360__File_Systems__Crash_Consistency__MC__Hard.json", "_topic_hint": "Crash Consistency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:21:14", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Journaling"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, מה מאפיין נקודת \"checkpoint\" בהקשר של כתיבת טרנזקציה ל-journal?", "code_snippet": null, "options": ["א. זוהי נקודת הזמן שבה ידוע בוודאות שהטרנזקציה נכתבה במלואה ל-journal ואושרה על ידי הדיסק.", "ב. זוהי הנקודה שבה ה-Txe (Transaction End) נכתב ל-journal, מה שמסמן את סיום הטרנזקציה.", "ג. זוהי הנקודה שבה ה-metadata של הטרנזקציה נכתב למיקומו הסופי במערכת הקבצים.", "ד. זוהי הנקודה שבה ה-journal superblock מתעדכן לשחרור מקום שהתפנה ב-journal."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה (Lecture 21, chunk 26), נקודת \"checkpoint\" מוגדרת כנקודת הזמן שבה אנחנו יודעים בוודאות שהטרנזקציה שלנו נכתבה במלואה ל-journal ואושרה על ידי הדיסק באמצעות פעולת סנכרון (fsync). ברגע שהנתונים נכתבו פיזית לדיסק ב-journal, זוהי נקודת ה-checkpoint, המאפשרת למערכת לדעת שאם תקרוס, הטרנזקציה שמורה במלואה ב-journal וניתן יהיה לשחזר אותה.\nאפשרות ב' מתארת את שלב ה-Journal commit (כתיבת Txe), שמסמן את הפיכת הטרנזקציה ל'מחויבת' (committed), אך ה-checkpoint עצמו (לפי Chunk 26) מתייחס לכתיבת כל הטרנזקציה ל-journal ואישורה.\nאפשרות ג' מתארת שלב מאוחר יותר בפרוטוקול הסופי (גם הוא נקרא \"Checkpoint\" ב-Chunk 38), שבו ה-metadata נכתב למיקומו הקבוע, אך זו לא ההגדרה הבסיסית של נקודת הביטחון ב-journal עצמו כפי שהוצגה בתחילה.\nאפשרות ד' מתארת את שלב שחרור המקום ב-journal, שהוא שלב שמתרחש לאחר השלמת הטרנזקציה והעברתה מה-journal."}, "_source_file": "0361__File_Systems__Journaling__MC__Easy.json", "_topic_hint": "Journaling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:21:29", "_subject": "File Systems", "_context_lectures": [21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Journaling"], "difficulty_estimation": "Easy", "content": {"text": "מהם הביטים המיוחדים המסמנים את תחילתה וסיומה של טרנזקציה ב-journal?", "code_snippet": null, "options": ["א. Txb ו-Txe", "ב. Checkpoint ו-Free", "ג. Metadata ו-Data", "ד. Journal Superblock ו-Pointer"]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה (Chunk 24), Txb (Transaction Begin) הם ביטים מיוחדים המציינים את תחילתה של טרנזקציה חדשה ב-journal. Txe (Transaction End) הם ביטים מיוחדים המסמנים את סיום הטרנזקציה. מבנה זה מוצג גם בתרשים: | Txb | metadata | Data | Txe |. שאר האפשרויות אינן נכונות: Checkpoint ו-Free מתארים שלבים בפרוטוקול או נקודות זמן, Metadata ו-Data הם תוכן הטרנזקציה, ו-Journal Superblock ו-Pointer הם מבנים לניהול ה-journal כולו, לא סימונים לטרנזקציה בודדת."}, "_source_file": "0362__File_Systems__Journaling__MC__Easy.json", "_topic_hint": "Journaling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:21:36", "_subject": "File Systems", "_context_lectures": [21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Journaling"], "difficulty_estimation": "Easy", "content": {"text": "מהם הסימונים המשמשים לציון תחילתה וסיומה של טרנזקציה ביומן (Journal) במערכת קבצים?", "code_snippet": null, "options": ["א. Txb ו-Txe", "ב. Checkpoint ו-Commit", "ג. Metadata ו-Data", "ד. Journal Superblock ו-Free"]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה (Lecture 21, chunk 24), 'Txb' (Transaction Begin) הוא סט של ביטים מיוחדים המציינים את תחילתו של note חדש ביומן, ואילו 'Txe' (Transaction End) הוא סט של ביטים המציינים את סיום הטרנזקציה. סימונים אלו תוחמים את הנתונים והמטא-דאטה השייכים לטרנזקציה ספציפית ב-journal. האפשרויות האחרות מתארות מושגים שונים: Checkpoint ו-Commit הם שלבים בתהליך הטיפול בטרנזקציה, Metadata ו-Data הם תוכן הטרנזקציה, ו-Journal Superblock ו-Free הם מנגנונים לניהול היומן."}, "_source_file": "0363__File_Systems__Journaling__MC__Easy.json", "_topic_hint": "Journaling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:21:45", "_subject": "File Systems", "_context_lectures": [21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Journaling"], "difficulty_estimation": "Easy", "content": {"text": "בהקשר של מערכות קבצים מבוססות יומן (Journaling), מהי ההגדרה הנכונה ל'נקודת ביקורת' (checkpoint)?", "code_snippet": null, "options": ["א. הנקודה שבה ה-Txb נכתב לדיסק, המסמן את תחילת הטרנזקציה.", "ב. הנקודה שבה כל הטרנזקציה (כולל נתונים ומטא-דאטה) נכתבה ליומן והדיסק אישר את הכתיבה הפיזית.", "ג. הנקודה שבה המטא-דאטה נכתב למיקומו הסופי במערכת הקבצים.", "ד. הנקודה שבה ה-journal superblock מתעדכן כדי לשחרר מקום ביומן."]}, "solution": {"correct_option": "ב", "explanation": "לפי חומר ההרצאה (chunk 26), 'נקודת ביקורת' (checkpoint) מוגדרת כנקודת הזמן שבה אנחנו יודעים בוודאות שהטרנזקציה שלנו נמצאת באופן מלא ב-journal, לאחר שקראנו ל-fsync וקיבלנו אישור מהדיסק שהנתונים נכתבו פיזית. אופציה ב' מתארת זאת במדויק. אופציה א' מתייחסת רק לתחילת הטרנזקציה (Txb), אופציה ג' מתארת שלב מאוחר יותר של כתיבת מטא-דאטה למיקום הסופי (שלב ה-Checkpoint ב-final protocol, אך לא הגדרת ה-checkpoint כפי שהוצגה בהקשר זה), ואופציה ד' מתייחסת לניהול מקום ביומן באמצעות ה-journal superblock, שהינו תהליך שונה."}, "_source_file": "0364__File_Systems__Journaling__MC__Easy.json", "_topic_hint": "Journaling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:21:53", "_subject": "File Systems", "_context_lectures": [21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Journaling"], "difficulty_estimation": "Medium", "content": {"text": "על פי פרוטוקול 'metadata journaling' (או 'ordered journaling') כפי שתואר בחומר ההרצאה, מהו הסדר הנכון של הפעולות?", "code_snippet": null, "options": ["א. כתיבת הדאטה למיקומו הסופי בדיסק ← כתיבת תוכן הטרנזקציה (TxB ו-metadata) ליומן ← כתיבת בלוק ה-commit של הטרנזקציה (Txe) ליומן ← כתיבת ה-metadata למיקומיו הסופיים.", "ב. כתיבת תוכן הטרנזקציה (TxB ו-metadata) ליומן ← כתיבת הדאטה למיקומו הסופי בדיסק ← כתיבת בלוק ה-commit של הטרנזקציה (Txe) ליומן ← כתיבת ה-metadata למיקומיו הסופיים.", "ג. כתיבת הדאטה למיקומו הסופי בדיסק ← כתיבת בלוק ה-commit של הטרנזקציה (Txe) ליומן ← כתיבת תוכן הטרנזקציה (TxB ו-metadata) ליומן ← כתיבת ה-metadata למיקומיו הסופיים.", "ד. כתיבת ה-metadata למיקומיו הסופיים ← כתיבת הדאטה למיקומו הסופי בדיסק ← כתיבת תוכן הטרנזקציה (TxB ו-metadata) ליומן ← כתיבת בלוק ה-commit של הטרנזקציה (Txe) ליומן."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, ובפרט פרוטוקול ה-'Final protocol' ב-chunk 38, הסדר הנכון של הפעולות ב-'metadata journaling' הוא כדלקמן:\n1.  **Data write**: כתיבת הדאטה למיקום הסופי בדיסק והמתנה לסיום הכתיבה.\n2.  **Journal write**: כתיבת תוכן הטרנזקציה (TxB ו-metadata) ליומן והמתנה לסיום הכתיבה.\n3.  **Journal commit**: כתיבת בלוק ה-commit של הטרנזקציה (Txe) ליומן והמתנה לסיום הכתיבה, מה שמסמן שהטרנזקציה בוצעה בהצלחה ביומן.\n4.  **Checkpoint**: כתיבת ה-metadata למיקומיו הסופיים.\n\nאפשרות א' משקפת במדויק סדר פעולות זה, המבטיח עקביות ושחזור נתונים במקרה של קריסה."}, "_source_file": "0365__File_Systems__Journaling__MC__Medium.json", "_topic_hint": "Journaling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:22:06", "_subject": "File Systems", "_context_lectures": [21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Journaling"], "difficulty_estimation": "Medium", "content": {"text": "מהי המטרה העיקרית של ה-`journal superblock` במערכת קבצים מבוססת יומן (journaling) כפי שתוארה בחומר הלימוד?", "code_snippet": null, "options": ["א. לנהל את המקום הפנוי ביומן ולאפשר שימוש מחזורי ביומן על ידי מעקב אחר הטרנזקציות הפעילות או הממתינות לביצוע.", "ב. לסנכרן את כתיבת הנתונים (data) לדיסק הראשי לפני כתיבת המטא-דאטה (metadata) ליומן.", "ג. לסמן את נקודת ה-checkpoint, המבטיחה שכל הטרנזקציה נכתבה ליומן וניתן להתחיל לכתוב לדיסק הראשי.", "ד. להגדיר את תחילתה וסיומה של טרנזקציה בודדת ביומן באמצעות סמנים מיוחדים (Txb ו-Txe)."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר הלימוד (Lecture 21, chunk 31), ה-journal הוא סופי ולכן יש צורך במנגנון לניהול המקום בו. ה-`journal superblock` מתואר כמבנה קטן שנוסף ליומן, המכיל מצביעים (כמו מצביע להתחלה) שמטרתם לעקוב אחר הטרנזקציות שטרם בוצעו בהצלחה או שנכתבו לדיסק, ובכך לאפשר שימוש מחזורי ביומן על ידי מחיקת טרנזקציות שהושלמו. לכן, מטרתו העיקרית היא לנהל את המקום ביומן ולאפשר את ניצולו מחדש באופן מחזורי. אפשרות ב' מתארת את סדר הפעולות בכתיבה ליומן, לא את תפקיד ה-superblock. אפשרות ג' מתארת את מושג ה-checkpoint, שהוא נקודת זמן, לא מבנה ה-superblock. אפשרות ד' מתארת את תפקידם של Txb ו-Txe, לא את תפקיד ה-superblock."}, "_source_file": "0366__File_Systems__Journaling__MC__Medium.json", "_topic_hint": "Journaling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:22:19", "_subject": "File Systems", "_context_lectures": [21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Journaling"], "difficulty_estimation": "Medium", "content": {"text": "איזה מבין התיאורים הבאים מתאר נכונה את סדר הפעולות הנדרש בעת ביצוע טרנזקציה במערכת קבצים מבוססת Journaling מסוג Metadata Journaling (ordered journaling), בהתאם לחומר הנלמד?", "code_snippet": null, "options": ["א. יש לכתוב קודם את הנתונים (Data) למיקומם הסופי בדיסק, לאחר מכן לכתוב את המטא-דאטה (Metadata) ליומן, ורק לבסוף לכתוב את בלוק ה-Txe ליומן.", "ב. יש לכתוב קודם את המטא-דאטה (Metadata) ליומן, לאחר מכן את בלוק ה-Txe ליומן, ורק לבסוף לכתוב את הנתונים (Data) למיקומם הסופי בדיסק.", "ג. יש לכתוב קודם את בלוק ה-Txe ליומן, לאחר מכן את הנתונים (Data) למיקומם הסופי בדיסק, ורק לבסוף לכתוב את המטא-דאטה (Metadata) ליומן.", "ד. כל הנתונים (Data), המטא-דאטה (Metadata) ובלוק ה-Txe נכתבים בו זמנית (concurrently) לדיסק וליומן, ללא סדר קבוע."]}, "solution": {"correct_option": "א", "explanation": "החומר הנלמד מתאר במפורש את הפרוטוקול הסופי (Final protocol) עבור Metadata Journaling (הידוע גם כ-ordered journaling). לפי פרוטוקול זה, סדר הפעולות הקריטיות לשמירה על עקביות הוא: ראשית, כתיבת הנתונים (Data) למיקומם הסופי בדיסק ורק לאחר מכן המתנה לסיום פעולה זו. שנית, כתיבת תוכן הטרנזקציה (בלוק TxB והמטא-דאטה) ליומן והמתנה לסיום פעולה זו. שלישית, כתיבת בלוק ה-commit (Txe) ליומן והמתנה לסיום הכתיבה, מה שמסמן את הטרנזקציה כ-committed. אפשרות א' משקפת סדר זה: כתיבת Data, לאחר מכן Metadata ליומן, ולבסוף Txe ליומן. ציטוט מהחומר: \"נשים לב שכשאנחנו עושים זאת אנחנו חייבים קודם כל לכתוב לדיסק את הדאטה ובו זמנית לכתוב את ה-metadata ליומן, ונתונים שהכל נכתב ורק אחר כך לכתוב את ה-Txe.\"."}, "_source_file": "0367__File_Systems__Journaling__MC__Medium.json", "_topic_hint": "Journaling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:22:36", "_subject": "File Systems", "_context_lectures": [21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Journaling"], "difficulty_estimation": "Medium", "content": {"text": "לפי פרוטוקול ה-journaling הסופי, הידוע גם כ-ordered journaling, המתואר בחומר ההרצאה, מהי הפעולה העיקרית המבוצעת בשלב ה-\"Checkpoint\"?", "code_snippet": null, "options": ["א. כתיבת הנתונים (data) למיקומם הסופי בדיסק, והמתנה לסיומה.", "ב. כתיבת חסימת ההתחייבות של הטרנזקציה (Txe) ל-journal.", "ג. כתיבת המטא-דאטה (metadata) למיקומיו הסופיים בדיסק.", "ד. סימון הטרנזקציה כפנויה לשימוש עתידי ב-journal superblock."]}, "solution": {"correct_option": "ג", "explanation": "החומר המצורף (Lecture 21, chunk 38) מפרט את פרוטוקול ה-journaling הסופי, הידוע כ-ordered journaling. שלב 4 בפרוטוקול זה הוא \"Checkpoint\", ותפקידו המוגדר הוא \"Write metadata to final locations\" (כתיבת המטא-דאטה למיקומיה הסופיים). אפשרות א' מתארת את שלב 1 (Data write), אפשרות ב' מתארת את שלב 3 (Journal commit), ואפשרות ד' מתארת את שלב 5 (Free). לכן, האפשרות הנכונה היא ג'."}, "_source_file": "0368__File_Systems__Journaling__MC__Medium.json", "_topic_hint": "Journaling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:22:49", "_subject": "File Systems", "_context_lectures": [21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Journaling"], "difficulty_estimation": "Hard", "content": {"text": "במערכת קבצים המשתמשת ב-metadata journaling (הידועה גם כ-ordered journaling), פרוטוקול הכתיבה הסופי קובע כי יש לכתוב את הנתונים למיקומם הסופי בדיסק ולאמת את השלמת הכתיבה, ורק לאחר מכן לכתוב את בלוק ה-commit (Txe) ליומן. בהתבסס על פרוטוקול זה, מדוע סדר פעולות זה חיוני לשמירה על עקביות הנתונים במקרה של קריסה?", "code_snippet": "/* פרוטוקול הכתיבה הסופי (מתוך חומר ההרצאה): */\n/* Final protocol: */\n1. Data write\n  * Write data to final location, wait for completion\n2. Journal write\n  * Write transaction contents (TxB and metadata), wait for completion\n3. Journal commit\n  * Write transaction commit block (Txe)\n  * Wait for write to complete → transaction is **committed**\n4. Checkpoint\n  * Write metadata to final locations\n5. Free\n  * Later, mark transaction as free in journal superblock", "options": ["א. כדי למנוע מצב שבו ה-Txe נכתב ליומן ומצביע על טרנזקציה שהושלמה, בעוד שהנתונים עצמם טרם נכתבו במלואם למיקומם הסופי בדיסק, מה שיוביל לשחזור שגוי של נתונים ישנים או חלקיים לאחר קריסה.", "ב. מכיוון שה-journal superblock דורש שה-Txe ייכתב רק לאחר שכל הנתונים והמטא-דאטה נמחקו מהיומן, כדי לפנות מקום לטרנזקציות חדשות.", "ג. כדי להבטיח שהיומן לא יתמלא יתר על המידה, על ידי הקפדה על כך שרק המטא-דאטה תישמר ביומן, והנתונים יישמרו ישירות בדיסק ללא תיעוד ביומן.", "ד. משום שבלוק ה-Txe מכיל מצביע למיקום הפיזי של הנתונים בדיסק, ולכן יש לוודא שהנתונים קיימים לפני שהמצביע נכתב."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. בחומר ההרצאה (chunk 38) מצוין במפורש: \"נשים לב שכשאנחנו עושים זאת אנחנו חייבים קודם כל לכתוב לדיסק את הדאטה ובו זמנית לכתוב את ה-metadata ליומן, ונתונים שהכל נכתב ורק אחר כך לכתוב את ה-Txe.\" פרוטוקול זה, המכונה metadata journaling או ordered journaling, מבטיח שעקביות הנתונים תישמר. אם בלוק ה-Txe (המסמן את סיום הטרנזקציה והתחייבותה) ייכתב ליומן לפני שהנתונים עצמם נכתבו בהצלחה למיקומם הסופי בדיסק, אזי במקרה של קריסה, מערכת ההפעלה תאמין שהטרנזקציה הושלמה בהצלחה (כפי שהיומן מציין), אך בפועל הנתונים בדיסק יהיו חסרים, לא מעודכנים או פגומים. מצב זה יוביל לשחזור שגוי של מערכת הקבצים. לכן, הכרחי לוודא את שלמות כתיבת הנתונים לפני התחייבות הטרנזקציה ביומן. אפשרות ב' שגויה מכיוון ש-Txe מסמן התחייבות (commit) ולא מחיקה או פינוי מקום ביומן, פעולה המבוצעת מאוחר יותר על ידי ה-journal superblock. אפשרות ג' מתארת את מאפיין כללי של metadata journaling אך אינה מסבירה את חשיבות הסדר הספציפי בין כתיבת הנתונים לכתיבת ה-Txe לצורך עקביות. אפשרות ד' שגויה שכן חומר ההרצאה אינו מציין כי בלוק ה-Txe מכיל מצביע למיקום הפיזי של הנתונים; תפקידו הוא לסמן את סיום הטרנזקציה."}, "_source_file": "0369__File_Systems__Journaling__MC__Hard.json", "_topic_hint": "Journaling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:23:12", "_subject": "File Systems", "_context_lectures": [21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Journaling"], "difficulty_estimation": "Hard", "content": {"text": "במערכת קבצים המשתמשת ב-`metadata journaling` (המכונה גם `ordered journaling`), מהו המצב הצפוי של המערכת לאחר קריסה המתרחשת *לאחר* שבלוק הנתונים נכתב בהצלחה למיקומו הסופי על הדיסק, אך *לפני* שמטא-הנתונים של הטרנזקציה (כולל `TxB` ו-`metadata` של הטרנזקציה) נכתבו במלואם ליומן וסונכרנו?", "code_snippet": null, "options": ["א. מטא-הנתונים של מערכת הקבצים יהיו לא עקביים עם בלוק הנתונים, וידרשו סריקה מלאה (לדוגמה, `fsck`) כדי לשחזר את הנתונים היתומים.", "ב. מערכת הקבצים תתאושש למצב עקבי, אך בלוק הנתונים החדש יאבד (יהפוך לבלוק יתום) מכיוון שהטרנזקציה לא תועדה ביומן.", "ג. היומן יופעל מחדש (replayed), ומכיוון שבלוק הנתונים כבר נכתב, הטרנזקציה תושלם בהצלחה.", "ד. המערכת תזהה טרנזקציה לא שלמה ביומן ותחזיר את בלוק הנתונים למצבו הקודם."]}, "solution": {"correct_option": "ב", "explanation": "השאלה מתייחסת לפרוטוקול הספציפי של `metadata journaling` (או `ordered journaling`), כפי שתואר בחומר ההרצאה:\n1. Data write: Write data to final location, wait for completion\n2. Journal write: Write transaction contents (TxB and metadata), wait for completion\n\nהמצב המתואר בשאלה הוא קריסה המתרחשת *לאחר* שלב 1 (כתיבת הנתונים למיקומם הסופי בדיסק והמתנה לסיום הכתיבה) אך *לפני* שלב 2 (כתיבת ה-`TxB` ומטא-הנתונים של הטרנזקציה ליומן וסנכרונם).\n\nבמקרה כזה:\n- בלוק הנתונים החדש אכן נכתב פיזית לדיסק במיקומו הסופי.\n- אך מכיוון ששלב 2 לא הושלם, הטרנזקציה לא התחילה להירשם ביומן (אין `TxB` או מטא-נתונים ביומן שמתארים את השינוי). מטא-הנתונים של מערכת הקבצים הראשית (לדוגמה, ה-inode המצביע על הנתונים) עדיין משקפים את המצב הקודם (לפני הניסיון לכתוב את הנתונים החדשים).\n\nכתוצאה מכך, בעת התאוששות מקריסה, מערכת הקבצים תסרוק את היומן ולא תמצא שום תיעוד לטרנזקציה זו. לכן, היא תתאושש למצב עקבי שבו מטא-הנתונים שלה תקינים ושלמים (הם פשוט משקפים את המצב הישן). עם זאת, בלוק הנתונים החדש שנכתב לדיסק אינו מקושר עוד לשום מטא-נתונים, ולכן הוא הופך לבלוק 'יתום' (orphaned block) שאבד למערכת הקבצים. זוהי תכונה מהותית של `ordered journaling` – הוא מבטיח עקביות של מטא-נתונים על חשבון אובדן פוטנציאלי של נתונים במקרה קריסה מסוים זה.\n\nלכן, אפשרות ב' היא הנכונה ביותר."}, "_source_file": "0370__File_Systems__Journaling__MC__Hard.json", "_topic_hint": "Journaling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:23:36", "_subject": "File Systems", "_context_lectures": [21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Journaling"], "difficulty_estimation": "Hard", "content": {"text": "במערכת קבצים המשתמשת ב-metadata journaling (הידועה גם כ-ordered journaling), פרוטוקול הכתיבה קובע כי כתיבת הנתונים עצמם למיקומם הסופי בדיסק מתרחשת לפני כתיבת ה-metadata המתאר אותם ליומן. בהתחשב בפרוטוקול זה, מהי ההשלכה הסבירה ביותר במקרה של קריסת מערכת שהתרחשה *לאחר* השלמת כתיבת הנתונים לדיסק אך *לפני* שהטרנזקציה סומנה כ-committed ביומן (כלומר, לפני כתיבת ה-Txe)?", "code_snippet": null, "options": ["א. הנתונים החדשים יימצאו בדיסק אך לא יהיו מקושרים או נגישים באמצעות ה-metadata של מערכת הקבצים, שכן עדכון ה-metadata הרלוונטי לא בוצע במלואו דרך היומן ולכן לא ישוחזר.", "ב. מערכת הקבצים תשוחזר למצב עקבי לחלוטין כאילו הטרנזקציה מעולם לא החלה, ללא כל אובדן נתונים או חוסר עקביות.", "ג. ה-metadata ביומן יצביע על הנתונים החדשים שהושלמו, ומערכת הקבצים תתאושש ותשלים את העדכון באופן אוטומטי.", "ד. הנתונים הישנים בדיסק יימחקו באופן אוטומטי, והמקום יסומן כפנוי, מה שיגרום לאובדן נתונים אך ישמור על עקביות ה-metadata."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. בפרוטוקול metadata journaling (או ordered journaling), שלב כתיבת הנתונים (Data write) למיקומם הסופי בדיסק מתבצע ראשון וממתין להשלמה. לאחר מכן נכתב ה-metadata הרלוונטי ליומן (Journal write). עם זאת, הטרנזקציה נחשבת 'מבוצעת' (committed) רק לאחר כתיבת ה-Txe ליומן (Journal commit). אם המערכת קורסת לאחר שהנתונים נכתבו לדיסק אך לפני כתיבת ה-Txe, הנתונים החדשים אמנם קיימים פיזית בדיסק. אך מכיוון שה-Txe לא נכתב, היומן לא יזהה את הטרנזקציה כשלמה. בעת התאוששות המערכת מקריסה, היומן יסרוק את הטרנזקציות ויפעיל מחדש רק טרנזקציות שסומנו כ'מבוצעות' במלואן (עם Txe). במקרה זה, עדכון ה-metadata ביומן לא יופעל, ומבני ה-metadata הראשיים של מערכת הקבצים (כמו טבלאות inodes או מפות סיביות) יישארו במצבם הקודם. התוצאה היא שהנתונים החדשים שהיו אמורים להיות מקושרים באמצעות ה-metadata נשארים בדיסק אך אינם נגישים או מקושרים על ידי מערכת הקבצים, ונוצר מצב של חוסר עקביות.\n\nאפשרויות אחרות אינן נכונות: \nב. המערכת לא תשוחזר כאילו הטרנזקציה מעולם לא החלה, שכן הנתונים החדשים כבר נכתבו לדיסק. \nג. ה-metadata ביומן לא יאפשר התאוששות אוטומטית כי חסר ה-Txe המעיד על השלמת הטרנזקציה. \nד. הבעיה המרכזית אינה מחיקת נתונים ישנים או סימון מקום כפנוי, אלא חוסר הגישה לנתונים החדשים שנכתבו."}, "_source_file": "0371__File_Systems__Journaling__MC__Hard.json", "_topic_hint": "Journaling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:24:01", "_subject": "File Systems", "_context_lectures": [21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Journaling"], "difficulty_estimation": "Hard", "content": {"text": "בהתייחס לפרוטוקול הסופי של Journaling מסוג \"Metadata Journaling\" (או \"Ordered Journaling\"), המתואר בחומר ההרצאה, ובהנחה ששלב \"Journal commit\" (כתיבת Txe ליומן) הושלם בהצלחה, מהי המטרה העיקרית של שלב ה-\"Checkpoint\" (שלב 4: \"Write metadata to final locations\")?", "code_snippet": null, "options": ["א. להבטיח שהנתונים (data) עצמם נכתבו באופן עמיד למיקומם הסופי בדיסק.", "ב. לסמן את הטרנזקציה ביומן כפעולה שבוצעה בהצלחה וניתן לפנות את מקומה.", "ג. ליישם את שינויי המטא-דאטה מתוך היומן למיקומם הקבוע במבני מערכת הקבצים העיקריים.", "ד. להבטיח את עמידות הטרנזקציה כולה ביומן, כך שניתן יהיה לשחזר אותה לאחר קריסה."]}, "solution": {"correct_option": "ג", "explanation": "חומר ההרצאה מתאר את הפרוטוקול הסופי של Metadata Journaling (chunk 38). שלבים 1 עד 3 מבטיחים את כתיבת הנתונים למיקומם הסופי ואת רישום הטרנזקציה כולה (כולל Txb, metadata ו-Txe) ביומן, וכי הטרנזקציה \"committed\" (ממומשת/מחויבת) ביומן. שלב ה-\"Checkpoint\" (שלב 4) מוגדר במפורש כ-\"Write metadata to final locations\" (כתיבת מטא-דאטה למיקומם הסופי). לאחר שהטרנזקציה כבר ממומשת ביומן (committed), מטרת שלב זה היא ליישם בפועל את שינויי המטא-דאטה, שתועדו ביומן, אל המבנים הקבועים של מערכת הקבצים מחוץ ליומן. לכן, תשובה ג' מתארת במדויק מטרה זו.\n\nתשובה א' שגויה, כיוון שכתיבת הנתונים הסופית מתבצעת בשלב 1 (\"Data write\").\nתשובה ב' שגויה, כיוון שסימון הטרנזקציה כפנויה ביומן מתבצע בשלב 5 (\"Free\"), שהוא שלב מאוחר יותר.\nתשובה ד' שגויה, כיוון שעמידות הטרנזקציה ביומן ויכולת השחזור שלה לאחר קריסה מושגות עם השלמת שלב 3 (\"Journal commit\"), אשר מסמן את הטרנזקציה כ-\"committed\" ביומן."}, "_source_file": "0372__File_Systems__Journaling__MC__Hard.json", "_topic_hint": "Journaling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:24:18", "_subject": "File Systems", "_context_lectures": [21]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Log-structured File System"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, מהי הבעיה העיקרית שמערכת קבצים מסוג Log-structured File System (LFS) נועדה לפתור?", "code_snippet": null, "options": ["א. שיפור ביצועי קריאה על ידי שמירת נתונים בזיכרון מטמון.", "ב. הפחתת פרגמנטציה חיצונית של קבצים גדולים.", "ג. אופטימיזציה של פעולות כתיבה לדיסק.", "ד. ניהול יעיל של הקצאת זיכרון עבור מטא-דאטה."]}, "solution": {"correct_option": "ג", "explanation": "חומר ההרצאה מציין במפורש כי 'פעולות הכתיבה הן הבעיה העיקרית שלנו' מכיוון שפעולות קריאה רבות נשארות בזיכרון המטמון (cache) (כגון inodes, bitmaps ונתונים). לכן, הרעיון המרכזי מאחורי LFS הוא 'לשפר את הכתיבות'."}, "_source_file": "0373__File_Systems__Log-structured_File_System__MC__Easy.json", "_topic_hint": "Log-structured File System", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:24:26", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Log-structured File System"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, מהי הבעיה העיקרית שמערכת הקבצים LFS (Log-structured File System) נועדה לפתור?", "code_snippet": null, "options": ["א. שיפור ביצועי קריאה מהדיסק על ידי שימוש ב-cache.", "ב. שיפור ביצועי כתיבה לדיסק, מכיוון שפעולות קריאה מטופלות היטב על ידי cache.", "ג. הפחתת פרגמנטציה חיצונית בדיסק על ידי הקצאת בלוקים רציפים.", "ד. הבטחת עמידות נתונים במקרה של קריסת מערכת באופן אוטומטי."]}, "solution": {"correct_option": "ב", "explanation": "חומר ההרצאה מציין במפורש כי 'רוב הפעולות שאנחנו מבצעים את הכתיבות על הדיסק הן פעולות כתיבה. כי כשאנחנו קוראים נתונים, אזי יש לנו cache ה-inodes, bitmaps, data הרבה פעמים נשארים כבר בזיכרון. זה הופך את פעולות הקריאה להרבה יותר קלות ולכן פעולות הכתיבה הן הבעיה העיקרית שלנו'. מכאן, המטרה העיקרית של LFS היא לשפר את ביצועי הכתיבה לדיסק."}, "_source_file": "0374__File_Systems__Log-structured_File_System__MC__Easy.json", "_topic_hint": "Log-structured File System", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:24:34", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Log-structured File System"], "difficulty_estimation": "Easy", "content": {"text": "לפי חומר ההרצאה, מהי הבעיה העיקרית שמערכת קבצים מסוג Log-structured File System (LFS) נועדה לפתור?", "code_snippet": null, "options": ["א. שיפור ביצועי פעולות כתיבה לדיסק.", "ב. מניעת פרגמנטציה חיצונית של קבצים.", "ג. שיפור מהירות גישה סדרתית לקבצים גדולים.", "ד. הקטנת צריכת הזיכרון הראשי (RAM) על ידי מערכת הקבצים."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מציין במפורש כי LFS פותחה על רקע העובדה ש'רוב הפעולות שאנחנו מבצעים את הכתיבות על הדיסק הן פעולות כתיבה' וכי 'פעולות הכתיבה הן הבעיה העיקרית שלנו'. ההסבר לכך הוא שפעולות קריאה משופרות באופן משמעותי בזכות שמירת נתונים (כמו inodes, bitmaps ו-data) בזיכרון המטמון. לכן, המטרה המרכזית של LFS היא לשפר את ביצועי פעולות הכתיבה לדיסק."}, "_source_file": "0375__File_Systems__Log-structured_File_System__MC__Easy.json", "_topic_hint": "Log-structured File System", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:24:45", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Log-structured File System"], "difficulty_estimation": "Easy", "content": {"text": "לפי חומר ההרצאה, מהי הבעיה העיקרית שמערכת קבצים מסוג LFS (Log-structured File System) מנסה לפתור?", "code_snippet": null, "options": ["א. שיפור ביצועי פעולות קריאה מהדיסק.", "ב. הקטנת פרגמנטציה חיצונית של קבצים.", "ג. שיפור ביצועי פעולות כתיבה לדיסק.", "ד. ניהול יעיל של זיכרון מטמון (cache) עבור מטא-דאטה."]}, "solution": {"correct_option": "ג", "explanation": "חומר ההרצאה מציין במפורש: \"רוב הפעולות שאנחנו מבצעים את הכתיבות על הדיסק הן פעולות כתיבה... פעולות הקריאה להרבה יותר קלות ולכן פעולות הכתיבה הן הבעיה העיקרית שלנו.\" מכאן עולה כי LFS תוכננה במטרה לשפר את ביצועי פעולות הכתיבה, שהוגדרו כבעיה המרכזית."}, "_source_file": "0376__File_Systems__Log-structured_File_System__MC__Easy.json", "_topic_hint": "Log-structured File System", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:24:52", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Log-structured File System"], "difficulty_estimation": "Medium", "content": {"text": "מהי הבעיה העיקרית שמערכת הקבצים מסוג LFS (Log-structured File System) מנסה לפתור, כפי שמתואר בחומר הלימוד?", "code_snippet": null, "options": ["א. שיפור ביצועי פעולות כתיבה לדיסק.", "ב. הפחתת פרגמנטציה חיצונית של קבצים.", "ג. אופטימיזציה של פעולות קריאה מהדיסק באמצעות מטמון.", "ד. הבטחת עמידות נתונים במקרה של כיבוי פתאומי של המחשב."]}, "solution": {"correct_option": "א", "explanation": "חומר הלימוד מציג את LFS כגישה שונה למערכת קבצים, ומציין במפורש כי \"רוב הפעולות שאנחנו מבצעים את הכתיבות על הדיסק הן פעולות כתיבה\" וכי \"פעולות הכתיבה הן הבעיה העיקרית שלנו\". לכן, מערכת LFS תוכננה במיוחד כדי להתמודד עם בעיה זו ולשפר את ביצועי הכתיבה לדיסק. פעולות קריאה, לעומת זאת, נחשבות קלות יותר לניהול בזכות מנגנוני מטמון קיימים."}, "_source_file": "0377__File_Systems__Log-structured_File_System__MC__Medium.json", "_topic_hint": "Log-structured File System", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:25:01", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Log-structured File System"], "difficulty_estimation": "Medium", "content": {"text": "על פי חומר ההרצאה, מהי הבעיה העיקרית שמערכת קבצים מסוג LFS (Log-structured File System) באה לפתור?", "code_snippet": null, "options": ["א. שיפור ביצועי פעולות הכתיבה לדיסק, שכן פעולות הקריאה משתפרות באופן טבעי על ידי שימוש במטמון.", "ב. מניעת פרגמנטציה חיצונית של קבצים על ידי הקצאת בלוקים רציפים בלבד לכל קובץ.", "ג. הבטחת עמידות נתונים במקרה של קריסת מערכת, על ידי ביצוע כתיבות אטומיות.", "ד. ייעול תהליך איסוף הזבל (garbage collection) על ידי פינוי בלוקים בודדים שאינם בשימוש."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מציין במפורש כי \"רוב הפעולות שאנחנו מבצעים את הכתיבות על הדיסק הן פעולות כתיבה. כי כשאנחנו קוראים נתונים, אזי יש לנו cache ה-inodes, bitmaps, data הרבה פעמים נשארים כבר בזיכרון. זה הופך את פעולות הקריאה להרבה יותר קלות ולכן פעולות הכתיבה הן הבעיה העיקרית שלנו.\" מכאן, המטרה המרכזית של LFS היא לשפר את ביצועי הכתיבה לדיסק. אפשרות ב' אינה נכונה, שכן LFS כותבת באופן סדרתי ללוג ואינה מחייבת בלוקים רציפים לקובץ. אפשרות ג' היא דרישה כללית ממערכות קבצים אך אינה הבעיה העיקרית ש-LFS באה לפתור באופן ספציפי כפי שמוזכר בחומר. אפשרות ד' שגויה לחלוטין, מכיוון שההרצאה מציינת במפורש ש\"אנחנו לא רוצים לפנות בלוקים בודדים... נרצה לפנות את כל הסגמנט\" בתהליך איסוף הזבל."}, "_source_file": "0378__File_Systems__Log-structured_File_System__MC__Medium.json", "_topic_hint": "Log-structured File System", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:25:14", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Log-structured File System"], "difficulty_estimation": "Medium", "content": {"text": "על פי חומר ההרצאה, מהי הבעיה העיקרית שמערכות קבצים מבוססות יומן (LFS - Log-structured File System) מנסות לפתור?", "code_snippet": null, "options": ["א. ביצועים ירודים של פעולות קריאה מהדיסק עקב היעדר מנגנוני מטמון (cache) יעילים.", "ב. פרגמנטציה חיצונית של נתונים על הדיסק המאטה את הגישה לקבצים.", "ג. חוסר היעילות של פעולות כתיבה לדיסק, לאור העובדה שפעולות קריאה רבות משרתות מהזיכרון המטמון.", "ד. הקושי בניהול גרסאות קבצים ישנות ופינוי שטח דיסק מיותר."]}, "solution": {"correct_option": "ג", "explanation": "חומר ההרצאה מציין במפורש כי מערכת קבצים מסוג LFS נועדה להתמודד עם הבעיה ש'פעולות הכתיבה הן הבעיה העיקרית שלנו'. ההסבר לכך הוא ש'כשאנחנו קוראים נתונים, אזי יש לנו cache ה-inodes, bitmaps, data הרבה פעמים נשארים כבר בזיכרון. זה הופך את פעולות הקריאה להרבה יותר קלות'. לכן, LFS מתמקדת בשיפור יעילות הכתיבה לדיסק, תוך התחשבות בכך שפעולות קריאה כבר מואצות על ידי זיכרון המטמון. אפשרות א' אינה נכונה מכיוון שפעולות קריאה דווקא יעילות יחסית בזכות המטמון. אפשרות ב' אינה הבעיה העיקרית הספציפית ש-LFS מתייחסת אליה בהקשר זה. אפשרות ד' מתארת מנגנון (garbage collection) המשמש ב-LFS, אך אינה הבעיה העיקרית שלשמה פותחה המערכת, אלא פתרון לבעיה משנית הנוצרת כתוצאה משיטת הכתיבה."}, "_source_file": "0379__File_Systems__Log-structured_File_System__MC__Medium.json", "_topic_hint": "Log-structured File System", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:25:26", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Log-structured File System"], "difficulty_estimation": "Medium", "content": {"text": "מהי הבעיה העיקרית שמערכת הקבצים LFS (Log-structured File System) מנסה לפתור, על פי חומר ההרצאה?", "code_snippet": null, "options": ["א. שיפור ביצועי פעולות הכתיבה לדיסק, שכן פעולות הקריאה לרוב מטופלות ביעילות על ידי זיכרון מטמון.", "ב. מניעת פרגמנטציה חיצונית בדיסק.", "ג. הבטחת עקביות הנתונים במקרה של קריסת מערכת.", "ד. שיפור מהירות הגישה הסדרתית לקבצים גדולים."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מציין במפורש כי 'רוב הפעולות שאנחנו מבצעים את הכתיבות על הדיסק הן פעולות כתיבה', וכי 'פעולות הכתיבה הן הבעיה העיקרית שלנו'. ההרצאה מסבירה שפעולות קריאה רבות מטופלות ביעילות על ידי זיכרון מטמון (cache) המכיל inodes, bitmaps ונתונים, ולכן 'זה הופך את פעולות הקריאה להרבה יותר קלות'. לפיכך, המטרה העיקרית של LFS היא לשפר את ביצועי הכתיבה לדיסק."}, "_source_file": "0380__File_Systems__Log-structured_File_System__MC__Medium.json", "_topic_hint": "Log-structured File System", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:25:35", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Log-structured File System"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על עקרונות מערכת הקבצים הלוג-מבנית (LFS) ודגשיה על שיפור פעולות כתיבה באמצעות כתיבת סגמנטים שלמים, איזו מההשלכות הבאות נכונה לגבי תהליך איסוף הזבל (Garbage Collection) כאשר סגמנט מכיל תערובת של נתונים עדכניים ומיושנים?", "code_snippet": null, "options": ["א. ה-LFS נדרשת לבצע איחוי דיסק תכוף (defragmentation) כדי להבטיח רציפות סגמנטים, מה שמגדיל את זמן השהיה בקריאה.", "ב. בלוקי נתונים תקפים בתוך סגמנטים \"מלוכלכים\" (dirty segments) חלקית חייבים להיות מועתקים לסגמנטים חדשים לפני שניתן יהיה לשחרר את הסגמנט המקורי, מה שמוביל להגברת כתיבות (write amplification).", "ג. ה-inodes מאוחסנים תמיד במיקומים קבועים בדיסק, מה שהופך את עדכוניהם לאיטיים מאוד.", "ד. מערכת הקבצים מבטלת לחלוטין פיצול חיצוני (external fragmentation), אך מציגה פיצול פנימי משמעותי בתוך בלוקי הנתונים עצמם."]}, "solution": {"correct_option": "ב", "explanation": "מערכת הקבצים הלוג-מבנית (LFS) מתוכננת לשפר את ביצועי הכתיבה על ידי כתיבת סגמנטים שלמים באופן סדרתי. תהליך איסוף הזבל (garbage collection) ב-LFS פועל כדי לפנות סגמנטים מיותרים, אך הוא שואף לפנות סגמנטים שלמים ולא בלוקים בודדים. כפי שמצוין בחומר הלימוד, 'לא בטוח שיש סגמנט שכולו ירוקון, ייתכן ויהיה בו בלוק שישאר תקף ולא זבל שכתבנו אותו'. משמעות הדבר היא שאם סגמנט מכיל גם בלוקים תקפים וגם בלוקים מיושנים (זבל), לא ניתן לפנות את הסגמנט כולו ישירות. במקרה כזה, על ה-LFS להעתיק את הבלוקים התקפים שנותרו בסגמנט ה'מלוכלך' לסגמנט חדש וריק לפני שניתן יהיה לשחרר את הסגמנט המקורי. פעולה זו של העתקת נתונים תקפים היא תוספת של פעולות כתיבה, הידועה כ'הגברת כתיבות' (write amplification), והיא מהווה אתגר מהותי במימוש LFS."}, "_source_file": "0381__File_Systems__Log-structured_File_System__MC__Hard.json", "_topic_hint": "Log-structured File System", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:25:48", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Log-structured File System"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על עקרונות מערכת הקבצים Log-structured File System (LFS), אשר שמה דגש על אופטימיזציה של פעולות כתיבה על ידי כתיבת סגמנטים שלמים, איזה אתגר מהותי עומד בפני מנגנון איסוף הזבל (garbage collection) שלה, כפי שתואר בחומר הלימוד?", "code_snippet": null, "options": ["א. האתגר העיקרי הוא שסגמנטים מכילים לעיתים קרובות תערובת של בלוקי נתונים תקפים (מעודכנים) ולא תקפים (ישנים), מה שמקשה על פינוי סגמנט שלם מבלי להעתיק נתונים תקפים, ובכך עלול להפחית את יעילות תהליך איסוף הזבל.", "ב. LFS סובלת מפרגמנטציה חיצונית חמורה עקב הקצאת בלוקי נתונים לא רציפה, בדומה לשיטות הקצאה מבוססות רשימה מקושרת, מה שמדרדר באופן משמעותי את ביצועי הקריאה הסדרתית.", "ג. תהליך איסוף הזבל ב-LFS נדרש לעיתים קרובות לגשת ל-inodes ובלוקי נתונים בודדים המפוזרים על פני סגמנטים רבים כדי לקבוע את תוקפם, מה שמוביל לגישות דיסק אקראיות רבות וקטנות.", "ד. שמירה במטמון של inodes, bitmaps ונתונים בזיכרון מקלה על פעולות קריאה, אך איסוף הזבל של LFS מתקשה לנצל מטמון זה ביעילות לזיהוי סגמנטים מיושנים, ומאלץ אותו לקרוא מטא-דאטה ישירות מהדיסק."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מציין במפורש כי \"אבל לא בטוח שיש סגמנט שכולו ירוקון, ייתכן ויהיה בו בלוק שישאר תקף ולא זבל שכתבנו אותו\". יחד עם העיקרון הבסיסי של LFS ש\"אנחנו לא רוצים לפנות בלוקים בודדים... נרצה לפנות את כל הסגמנט\", נובע מכך שהאתגר המהותי עבור מנגנון איסוף הזבל הוא לנהל סגמנטים המכילים גם בלוקים תקפים וגם בלוקים לא תקפים. במצב כזה, על מנת לפנות את הסגמנט כולו, יש צורך להעתיק את הבלוקים התקפים לסגמנט חדש לפני שניתן לפנות את הסגמנט המקורי, מה שמפחית את יעילות הפינוי. אפשרות ב' מתארת בעיית פרגמנטציה כללית ולא אתגר ספציפי של איסוף הזבל ב-LFS, ואילו אפשרות ג' סותרת את העיקרון של LFS לא לפנות בלוקים בודדים אלא סגמנטים שלמים. אפשרות ד' מתארת את יתרון המטמון לקריאות אך לא אתגר ספציפי של איסוף הזבל ב-LFS כפי שתואר."}, "_source_file": "0382__File_Systems__Log-structured_File_System__MC__Hard.json", "_topic_hint": "Log-structured File System", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:26:02", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Log-structured File System"], "difficulty_estimation": "Hard", "content": {"text": "במערכת קבצים מסוג LFS (Log-structured File System), מהו האתגר העיקרי העומד בפני תהליך ה-\"Garbage Collection\" (איסוף זבל) כאשר הוא מנסה לפנות שטח דיסק, בהתחשב בעקרון העיצוב הבסיסי של המערכת?", "code_snippet": null, "options": ["א. הצורך לאתר ולסמן בלוקים בודדים שאינם תקפים (זבל) בתוך סגמנט, מבלי להזיז בלוקים תקפים שנותרו באותו סגמנט.", "ב. הקושי לפנות סגמנט שלם כאשר הוא מכיל תערובת של בלוקים תקפים ובלוקים שאינם תקפים, מבלי לפגוע בנתונים התקפים.", "ג. ביצועי קריאה ירודים הנגרמים מפיזור נתונים ברחבי הדיסק כתוצאה מכתיבה סדרתית לסגמנטים.", "ד. הצורך לתחזק רשימה מקושרת של כל ה-inodes התקפים בדיסק כדי לאפשר גישה מהירה לנתונים."]}, "solution": {"correct_option": "ב", "explanation": "החומר המצוין בשיעור מדגיש כי הרעיון הבסיסי של LFS הוא לכתוב סגמנטים שלמים ולפנות סגמנטים שלמים, ולא בלוקים בודדים. האתגר העיקרי בתהליך ה-Garbage Collection הוא שסגמנטים רבים אינם מכילים רק בלוקים 'זבל' (גרסאות ישנות או נתונים שנמחקו), אלא גם בלוקים תקפים שעדיין בשימוש. לכן, הקושי הוא לפנות סגמנט שלם כאשר הוא מכיל תערובת כזו, מכיוון שאי אפשר פשוט למחוק את כל הסגמנט מבלי לאבד נתונים תקפים. יש צורך להעתיק את הבלוקים התקפים לסגמנט חדש לפני שניתן יהיה לפנות את הסגמנט הישן כולו, מה שמוסיף מורכבות ועלויות לתהליך איסוף הזבל. אפשרות א' שגויה מכיוון שהיא מתמקדת בפינוי בלוקים בודדים, בניגוד לעקרון של LFS. אפשרויות ג' ו-ד' אינן מתארות את האתגר הספציפי של ה-Garbage Collection ב-LFS."}, "_source_file": "0383__File_Systems__Log-structured_File_System__MC__Hard.json", "_topic_hint": "Log-structured File System", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:26:14", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Log-structured File System"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על עקרונות מערכת הקבצים הלוגית (LFS) כפי שהוצגו, מהו האתגר המהותי ביותר בפעולת איסוף הזבל (garbage collection) של LFS כאשר מנסים לפנות שטח דיסק?", "code_snippet": null, "options": ["א. האתגר העיקרי הוא שאיסוף הזבל שואף לפנות סגמנטים שלמים ולא בלוקים בודדים, אך ייתכן שסגמנט מכיל בלוקים תקפים שאינם \"זבל\", מה שמסבך את תהליך הפינוי היעיל.", "ב. LFS אינה מסוגלת לזהות ביעילות אילו גרסאות של קבצים ו-inodes הן העדכניות ביותר, מה שעלול להוביל לשמירת נתונים מיושנים ולבזבוז שטח.", "ג. תהליך איסוף הזבל דורש גישה סדרתית לכל בלוק ובלוק בדיסק, מה שגורם לביצועים גרועים במיוחד במערכות עם קבצים מפוזרים.", "ד. LFS מתעדפת כתיבה על פני קריאה, ולכן פעולת איסוף הזבל המבצעת קריאות רבות כדי לזהות זבל, מפריעה באופן משמעותי לפעולות המערכת השוטפות."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה, הרעיון הבסיסי של LFS הוא לכתוב סגמנטים שלמים. תהליך איסוף הזבל (garbage collection) ב-LFS שואף לפנות סגמנטים שלמים ולא בלוקים בודדים. עם זאת, האתגר טמון בכך ש\"לא בטוח שיש סגמנט שכולו ירוקון, ייתכן ויהיה בו בלוק שישאר תקף ולא זבל שכתבנו אותו.\" מצב זה מסבך את פינוי השטח, שכן יש צורך להעביר את הבלוקים התקפים לסגמנטים אחרים לפני שניתן יהיה לפנות את הסגמנט המקורי במלואו.\n\nאפשרויות ב', ג' ו-ד' אינן נכונות: \nב. חומר ההרצאה מציין שתהליך איסוף הזבל \"דואג שישארו לנו רק הגרסאות הכי עדכניות של כל קובץ, של כל inode וכו' והוא זורק את הגרסאות הישנות\", מה שמצביע על יכולת לזהות גרסאות עדכניות.\nג. חומר ההרצאה לא מתאר את האתגר המהותי של איסוף הזבל ב-LFS כדרישה לגישה סדרתית לכל בלוק ובלוק בדיסק, אלא מתמקד בבעיה של סגמנטים מעורבים.\nד. למרות ש-LFS אכן מתעדפת כתיבה, חומר ההרצאה לא מתאר את ההפרעה לפעולות המערכת כתוצאה מריבוי קריאות של איסוף הזבל כאתגר המהותי ביותר, אלא את המורכבות של פינוי סגמנטים חלקיים."}, "_source_file": "0384__File_Systems__Log-structured_File_System__MC__Hard.json", "_topic_hint": "Log-structured File System", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:26:28", "_subject": "File Systems", "_context_lectures": [20, 21, 22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Inode Map"], "difficulty_estimation": "Easy", "content": {"text": "מהו המאפיין הנכון ביותר לגבי מבנה ה-imap (Inode Map) במערכת הקבצים, על פי חומר ההרצאה?", "code_snippet": null, "options": ["א. ה-imap הוא מפה לוגית אחת המחולקת לחלקים פיזיים, כאשר רק החלקים הרלוונטיים מתעדכנים ונכתבים לדיסק בעת שינוי.", "ב. לכל קבוצת inodes יש imap נפרד ועצמאי משלה, ללא קשר למפות אחרות.", "ג. ה-imap הוא בלוק נתונים יחיד וקבוע בגודלו, אשר אינו מתחלק לחלקים.", "ד. ה-imap נשמר בזיכרון בלבד ואינו נכתב לעולם לדיסק, אלא משוחזר בכל אתחול מחדש."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מציין במפורש לגבי ה-imap: \"מדובר על imap אחד שמחולק לחלקים\" וכי \"אנחנו מפרקים אותו לחלקים וכותבים את החלק הרלוונטי המעודכן.\" תיאור זה תואם לאפשרות א', המציינת מפה לוגית אחת המחולקת לחלקים פיזיים שמתעדכנים באופן סלקטיבי.\n\nאפשרות ב' שגויה מכיוון שההרצאה מדגישה \"מדובר על imap אחד\", ולא על מספר imaps נפרדים.\n\nאפשרות ג' שגויה כיוון שההרצאה מציינת \"ה-imap יכול להיות בכל מיני גדלים... אז אנחנו מפרקים אותו לחלקים\", מה שסותר את הרעיון של בלוק נתונים יחיד וקבוע שאינו מתחלק.\n\nאפשרות ד' שגויה משום שלמרות שה-imap נשמר בזיכרון בזמן ריצה (\"בזמן ריצה יש לנו תמיד את ה-imap בזיכרון\"), ההרצאה גם מציינת שהוא נכתב לדיסק מדי פעם באמצעות ה-CR, ומשמש לשחזור בעת אתחול מחדש (\"מדי פעם גם כותבים אל ה-cr את הנתון המעודכן. אם נסגור את המחשב ונדליק אותו מחדש, אין בעיה, נקרא את ה-cr, הוא יצביע לכל החלקים של ה-imap, נקרא גם אותם וכך נוכל לשחזר את ה-imap ולעבוד כרגיל.\")."}, "_source_file": "0385__File_Systems__Inode_Map__MC__Easy.json", "_topic_hint": "Inode Map", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:26:40", "_subject": "File Systems", "_context_lectures": [22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Inode Map"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של ה-Inode Map (imap) במערכת הקבצים, כפי שתואר בחומר ההרצאה?", "code_snippet": null, "options": ["א. לשמור את הגרסה העדכנית ביותר של כל inode.", "ב. לתעד את כל הגרסאות ההיסטוריות של כל inode לצורך שחזור.", "ג. למפות בלוקים פיזיים בדיסק לבלוקים לוגיים בקובץ.", "ד. לאחסן את הנתונים בפועל של הקבצים."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, ה-imap (Inode Map) מצביע על הגרסה העדכנית של inode מסוים (למשל, \"ה-imap מצביע על הגרסה העדכנית של inode k\"). כמו כן, נכתב כי הוא \"יגיד לנו איפה הגרסה הכי עדכנית של אותו inode\". תפקידו העיקרי הוא לספק גישה מהירה למיקום הפיזי של הגרסה האחרונה של כל inode. אפשרויות ב', ג' ו-ד' אינן מתארות נכונה את תפקידו המרכזי של ה-imap כפי שהוצג בחומר ההרצאה."}, "_source_file": "0386__File_Systems__Inode_Map__MC__Easy.json", "_topic_hint": "Inode Map", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:26:49", "_subject": "File Systems", "_context_lectures": [22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Inode Map"], "difficulty_estimation": "Easy", "content": {"text": "מהו תפקידו העיקרי של ה-CR (checkpoint region) במערכת הקבצים, בהקשר ל-imap?", "code_snippet": null, "options": ["א. הוא מצביע לגרסה העדכנית ביותר של ה-imap (או לחלקיו).", "ב. הוא מכיל את הנתונים בפועל של כל קבצי ה-inode.", "ג. הוא מתעדכן לעיתים קרובות מאוד כדי להבטיח עקביות מיידית של ה-imap.", "ד. הוא משמש כמטמון זמני לערכי imap הנמצאים בשימוש פעיל."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין בבירור כי ה-CR (checkpoint region) הוא מצביע קבוע במערכת הקבצים שתפקידו להצביע לגרסה העדכנית ביותר של ה-imap. אם ה-imap מחולק לחלקים, ה-CR יכיל מצביעים לגרסה העדכנית של כל חלק. זה מאפשר למערכת לשחזר את ה-imap המעודכן גם לאחר אתחול המחשב על ידי קריאת ה-CR. האפשרויות האחרות אינן נכונות: ה-CR אינו מכיל את נתוני ה-inodes עצמם (ב'), הוא מתעדכן לעיתים רחוקות ולא לעיתים קרובות כדי למנוע פגיעה בביצועים (ג'), ואינו מטמון זמני אלא מנגנון הצבעה קבוע (ד')."}, "_source_file": "0387__File_Systems__Inode_Map__MC__Easy.json", "_topic_hint": "Inode Map", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:26:57", "_subject": "File Systems", "_context_lectures": [22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Inode Map"], "difficulty_estimation": "Easy", "content": {"text": "מהו התפקיד העיקרי של ה-imap (Inode Map) במערכת הקבצים כפי שתואר בחומר ההרצאה?", "code_snippet": null, "options": ["א. להצביע לגרסה העדכנית ביותר של כל inode.", "ב. לאחסן את הנתונים בפועל של הקבצים.", "ג. לשמש כ-Checkpoint Region (CR) קבוע במיקום מוגדר.", "ד. לתעדכן בכל פעולת קריאה מהדיסק על מנת לשפר ביצועים."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, ה-imap (Inode Map) הוא המיפוי העדכני שאומר לנו היכן נמצאת הגרסה הכי עדכנית של כל inode. לדוגמה, 'ה-imap מצביע על הגרסה העדכנית של inode k' וכן 'הוא יגיד לנו איפה הגרסה הכי עדכנית של אותו inode'. אפשרויות ב', ג' ו-ד' אינן נכונות: ה-imap אינו מאחסן את נתוני הקבצים ישירות, הוא אינו ה-CR אלא ה-CR מצביע אליו, והוא אינו מתעדכן בכל קריאה אלא כאשר סגמנטים מתעדכנים וה-CR עצמו מתעדכן לעיתים רחוקות."}, "_source_file": "0388__File_Systems__Inode_Map__MC__Easy.json", "_topic_hint": "Inode Map", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:27:06", "_subject": "File Systems", "_context_lectures": [22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Inode Map"], "difficulty_estimation": "Medium", "content": {"text": "מהו המאפיין העיקרי של ה-Inode Map (imap) במערכת קבצים המתוארת, וכיצד הוא מאותר לאחר אתחול המערכת?", "code_snippet": null, "options": ["א. ה-imap הוא מבנה יחיד וקבוע במיקומו הפיזי בדיסק, וה-CR (Checkpoint Region) מצביע אליו ישירות.", "ב. ה-imap מורכב מחלקים הכתובים לדיסק במיקומים משתנים יחד עם עדכוני סגמנטים. ה-CR, הממוקם בנקודה קבועה, מכיל מצביעים לגרסאות העדכניות של כל חלקי ה-imap.", "ג. ה-imap נשמר כולו בזיכרון הפעיל בלבד ואינו נכתב לדיסק כלל, ולכן נבנה מחדש מאפס בכל אתחול.", "ד. ה-imap הוא מבנה היררכי קבוע המכיל הפניות לכל ה-inodes במערכת, ורק ה-CR מתעדכן כדי לשקף שינויים בגרסאות ה-inodes."]}, "solution": {"correct_option": "ב", "explanation": "החומר המצורף מציין כי ה-imap מחולק לחלקים ('מדובר על imap אחד שמחולק לחלקים'). חלקים אלו נכתבים לדיסק יחד עם הסגמנטים המעודכנים ('כל סגמנט שאנחנו מעדכנים – כותבים את החלק/החלקים הרלוונטיים שהתעדכנו ב-imap'), מה שמרמז על מיקומים פיזיים משתנים ('כי הוא גם כל הזמן מתעדכן ומשתנה'). כדי לאתר את ה-imap לאחר אתחול, משתמשים ב-CR (Checkpoint Region) שנמצא במיקום קבוע ('ה-cr לא זז, הוא כל הזמן במיקום קבוע') ומכיל מצביעים לגרסאות העדכניות של כל חלקי ה-imap ('ה-CR ... יצביע לגרסה העדכנית ביותר של ה-imap. אם יש כמה חלקים ל-imap אז יהיו בו מצביעים לגרסה העדכנית של כל חלק'). לכן, אפשרות ב' היא הנכונה ביותר."}, "_source_file": "0389__File_Systems__Inode_Map__MC__Medium.json", "_topic_hint": "Inode Map", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:27:20", "_subject": "File Systems", "_context_lectures": [22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Inode Map"], "difficulty_estimation": "Medium", "content": {"text": "כיצד מערכת הקבצים מבטיחה את היכולת לאתר את הגרסה העדכנית ביותר של מפת ה-inodes (imap), גם לאחר הפעלה מחדש של המערכת, בהתחשב בכך שה-imap עצמו משתנה ומתעדכן?", "code_snippet": null, "options": ["א. ה-imap נשמר במיקום קבוע בדיסק ולכן קל לאתר אותו תמיד.", "ב. קיים רכיב בשם Checkpoint Region (CR) במיקום קבוע, המצביע לגרסאות העדכניות של חלקי ה-imap.", "ג. המערכת סורקת את כל הדיסק בכל הפעלה מחדש כדי לאתר את חלקי ה-imap.", "ד. ה-imap תמיד נשמר בשלמותו בזיכרון הראשי, ורק הוא משוחזר לאחר הפעלה מחדש."]}, "solution": {"correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. החומר הלימודי מציין במפורש כי ה-imap עצמו משתנה ומתעדכן באופן תדיר, והוא אף מחולק לחלקים. כדי לאתר את הגרסה העדכנית ביותר של חלקי ה-imap, המערכת משתמשת ברכיב בשם Checkpoint Region (CR). ה-CR ממוקם במיקום קבוע בדיסק (\"ה-cr לא זז, הוא כל הזמן במיקום קבוע\") ותפקידו להצביע לגרסאות העדכניות של כל חלקי ה-imap. במקרה של הפעלה מחדש של המערכת, ה-CR נקרא ראשון, ודרכו ניתן לשחזר את כל חלקי ה-imap לזיכרון (\"נקרא את ה-cr, הוא יצביע לכל החלקים של ה-imap, נקרא גם אותם וכך נוכל לשחזר את ה-imap ולעבוד כרגיל\"). אפשרויות א', ג' ו-ד' אינן נכונות: א' שגויה מכיוון שה-imap אינו במיקום קבוע, אלא ה-CR הוא זה שבמיקום קבוע. ג' שגויה מכיוון שסריקת כל הדיסק אינה יעילה ואינה המנגנון המתואר בחומר. ד' שגויה מכיוון שה-imap אכן נשמר בזיכרון בזמן ריצה, אך לאחר הפעלה מחדש הוא משוחזר מהדיסק באמצעות ה-CR והחלקים אליהם הוא מצביע, ולא רק \"משוחזר\" מזיכרון שנשמר."}, "_source_file": "0390__File_Systems__Inode_Map__MC__Medium.json", "_topic_hint": "Inode Map", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:27:33", "_subject": "File Systems", "_context_lectures": [22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Inode Map"], "difficulty_estimation": "Medium", "content": {"text": "בהקשר של מערכת קבצים LFS, מהו התפקיד העיקרי של ה-Checkpoint Region (CR) ביחס למפת ה-Inodes (imap) לאחר הפעלה מחדש של המערכת?", "code_snippet": null, "options": ["א. ה-CR מאחסן את כל הנתונים של ה-imap באופן קבוע, ללא צורך בעדכונים תכופים.", "ב. ה-CR מצביע למיקומה של הגרסה העדכנית ביותר של ה-imap (או לחלקיו), ובכך מאפשר שחזור לאחר קריסה.", "ג. ה-CR אחראי לוודא שכל חלקי ה-imap נכתבים באופן סינכרוני לדיסק בכל עדכון.", "ד. ה-CR משמש כמאגר גיבוי עבור גרסאות קודמות של ה-imap למקרה של שחזור היסטורי."]}, "solution": {"correct_option": "ב", "explanation": "ההסבר הנכון הוא 'ב'. על פי חומר ההרצאה, ה-Checkpoint Region (CR) הוא מצביע קבוע במיקום ידוע שמטרתו להצביע לגרסה העדכנית ביותר של מפת ה-Inodes (imap). אם ה-imap מחולק לחלקים, ה-CR יכיל מצביעים לגרסאות העדכניות של כל חלק. כאשר המערכת מופעלת מחדש לאחר כיבוי או קריסה, היא קוראת את ה-CR, וזה מאפשר לה לאתר ולשחזר את ה-imap העדכני מתוך הדיסק כדי להמשיך לפעול כרגיל. חומר ההרצאה מציין במפורש: \"אם נסגור את המחשב ונדליק אותו מחדש, אין בעיה, נקרא את ה-cr, הוא יצביע לכל החלקים של ה-imap, נקרא גם אותם וכך נוכל לשחזר את ה-imap ולעבוד כרגיל.\""}, "_source_file": "0391__File_Systems__Inode_Map__MC__Medium.json", "_topic_hint": "Inode Map", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:27:45", "_subject": "File Systems", "_context_lectures": [22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Inode Map"], "difficulty_estimation": "Medium", "content": {"text": "מדוע מפת ה-inodes (imap) במערכת קבצים מסוג LFS מחולקת לחלקים, וכיצד המערכת מאתרת את הגרסאות העדכניות של חלקי ה-imap לאחר אתחול המחשב?", "code_snippet": null, "options": ["א. ה-imap מחולק לחלקים על מנת לאפשר כתיבה מקבילית של inodes שונים, והמערכת מאתרת אותם על ידי שמירת העותק השלם שלהם בזיכרון ה-RAM בלבד.", "ב. ה-imap מחולק לחלקים בגלל גודלו המשתנה ותלותו במספר ה-inodes במערכת, וה-Checkpoint Region (CR) מכיל מצביעים לגרסאות העדכניות של כל חלק של ה-imap.", "ג. ה-imap מחולק לחלקים כדי למנוע שגיאות קריאה וכתיבה במקרה של קריסת דיסק, והוא תמיד נשמר במיקום לוגי קבוע בדיסק.", "ד. ה-imap מחולק לחלקים כדי לייעל את תהליך הקצאת הבלוקים לנתונים, והמערכת בונה אותו מחדש באמצעות סריקת כל בלוקי הנתונים הקיימים."]}, "solution": {"correct_option": "ב", "explanation": "החומר המצוין בשיעור מסביר כי ה-imap יכול להיות בגדלים שונים, התלויים בכמות ה-inodes במערכת, ולכן הוא מפורק לחלקים. כמו כן, כדי לאתר את הגרסאות העדכניות של חלקי ה-imap לאחר אתחול המחשב (או בכל עת), קיים ה-Checkpoint Region (CR) – מצביע קבוע שמכיל מצביעים לגרסאות העדכניות של כל חלק ב-imap. כאשר המחשב נדלק מחדש, המערכת קוראת את ה-CR, ודרכו היא מאתרת את כל חלקי ה-imap העדכניים ומשחזרת אותו לעבודה תקינה. לכן, תשובה ב' היא הנכונה ביותר."}, "_source_file": "0392__File_Systems__Inode_Map__MC__Medium.json", "_topic_hint": "Inode Map", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:28:00", "_subject": "File Systems", "_context_lectures": [22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Inode Map"], "difficulty_estimation": "Hard", "content": {"text": "מערכת קבצים מסוג LFS מאופיינת בכך שמפת ה-inodes (imap) מחולקת לחלקים ומיקומם הפיזי על הדיסק משתנה עם עדכונים. אזור ה-Checkpoint Region (CR) נשמר במיקום קבוע ומתעדכן לעיתים רחוקות (למשל, כל 30 דקות). בהתחשב בכך, מהו העיקרון המרכזי המאפשר למערכת לשחזר גרסה עקבית של ה-imap לאחר קריסה והפעלה מחדש?", "code_snippet": null, "options": ["א. ה-CR מכיל רשימה של מצביעים לגרסאות העדכניות ביותר של *כל אחד מחלקי ה-imap*, כפי שהיו ידועות בעת כתיבת ה-CR האחרונה, ובכך משמש כנקודת כניסה יחידה לשחזור המפה.", "ב. ה-CR מצביע תמיד על קובץ יומן (log) נפרד המכיל את כל השינויים שבוצעו ב-imap מאז כתיבת ה-CR הקודם, ומערכת הקבצים משחזרת את ה-imap על ידי יישום שינויים אלו.", "ג. כל חלק של ה-imap מכיל מצביע ל-CR, ומאפשר ל-CR \"לסרוק\" את הדיסק ולאתר את כל חלקי ה-imap הפזורים.", "ד. ה-CR מאחסן עותק מלא ואטומי של ה-imap כולו, ובכל פעם שמתעדכן ה-imap בזיכרון, נכתב עותק מלא וחדש ל-CR."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. ה-CR (Checkpoint Region) נשמר במיקום קבוע, מה שמאפשר לאתרו בקלות לאחר אתחול המערכת. תפקידו הוא להכיל מצביעים למיקומים הפיזיים של כל חלקי ה-imap על הדיסק. כאשר המערכת כותבת CR חדש (למרות שזה קורה לעיתים רחוקות), היא מעדכנת אותו עם המצביעים לגרסאות ה'עדכניות ביותר' של חלקי ה-imap כפי שהיו בזיכרון באותו רגע. לאחר קריסה והפעלה מחדש, המערכת קוראת את ה-CR האחרון שנכתב. המצביעים שבתוכו מאפשרים לה לאתר את כל חלקי ה-imap שהיו עקביים בנקודת הזמן שבה נכתב ה-CR, ובכך לשחזר את מבנה ה-imap כולו לגרסה עקבית (אף אם לא בהכרח לגרסה האחרונה ממש לפני הקריסה, עקב העדכון התכוף של חלקי ה-imap והעדכון הנדיר של ה-CR עצמו). \n\nאפשרויות ב', ג' ו-ד' שגויות על פי חומר ההרצאה:\nב. חומר ההרצאה אינו מזכיר קובץ יומן נפרד לשינויי imap המשמש לשחזור לאחר קריסה. השחזור מתבצע ישירות דרך המצביעים ב-CR.\nג. הקשר הוא הפוך: ה-CR מצביע על חלקי ה-imap, ולא חלקי ה-imap מצביעים על ה-CR. כמו כן, סריקת הדיסק לאיתור חלקי imap היא שיטה לא יעילה ואינה מתוארת.\nד. ה-imap מפוצל לחלקים ואינו נכתב כעותק מלא ואטומי ב-CR. בנוסף, ה-CR מתעדכן לעיתים רחוקות, ולא בכל שינוי ב-imap, כדי למנוע פגיעה בביצועים."}, "_source_file": "0393__File_Systems__Inode_Map__MC__Hard.json", "_topic_hint": "Inode Map", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:28:36", "_subject": "File Systems", "_context_lectures": [22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Inode Map"], "difficulty_estimation": "Hard", "content": {"text": "במערכת קבצים LFS, ה-Inode Map (imap) מחולק לחלקים, וכל חלק יכול להתעדכן באופן עצמאי על הדיסק. ה-Checkpoint Region (CR) משמש לאיתור הגרסה העדכנית של ה-imap. בהתחשב בכך שה-CR מתעדכן לעיתים רחוקות יחסית (לדוגמה, כל 30 דקות), איזו מהטענות הבאות מתארת בצורה המדויקת ביותר כיצד המערכת מבטיחה שחזור עקבי של ה-imap המלא לאחר קריסה?", "code_snippet": null, "options": ["א. ה-CR, על אף עדכונו התקופתי, מכיל מצביעים ישירים לגרסאות העדכניות ביותר של *כל* חלקי ה-imap שנכתבו לדיסק *עד לנקודת זמן העדכון האחרונה שלו*, ובכך מאפשר שחזור קונסיסטנטי של ה-imap בזיכרון.", "ב. המערכת משחזרת את ה-imap על ידי סריקת כל הסגמנטים האחרונים על הדיסק, זיהוי חלקי ה-imap החדשים ביותר, ואיסופם ליצירת ה-imap השלם, תוך התעלמות מה-CR שאינו יכול להבטיח עדכניות.", "ג. ה-CR מצביע רק לבלוק הראשי של ה-imap, אשר בתורו מכיל מצביעים לחלקי ה-imap האחרים. מנגנון זה מחייב שרשרת קריאות ואינו מבטיח עקביות של כל החלקים במקרה של קריסה.", "ד. בזמן קריסה, המערכת מאבדת את היכולת לשחזר את חלקי ה-imap שלא נכללו בעדכון האחרון של ה-CR, ונדרש תהליך תיקון מורכב לשחזור הנתונים החסרים."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין בשיעור מסביר כי ה-CR (Checkpoint Region) הוא מצביע קבוע במיקומו הפיזי על הדיסק, אשר תפקידו להצביע לגרסה העדכנית ביותר של ה-imap. מכיוון שה-imap יכול להיות מחולק לחלקים, ה-CR מכיל מצביעים לגרסה העדכנית של *כל* חלק ב-imap. למרות שה-CR עצמו מתעדכן לעיתים רחוקות יחסית (כדי למנוע פגיעה בביצועים), כאשר הוא נכתב, הוא מכיל את ה\"נתון המעודכן\" – כלומר, את המצביעים לגרסאות האחרונות של חלקי ה-imap כפי שהיו בזיכרון המערכת בעת כתיבת ה-CR. לכן, לאחר קריסה ואתחול מחדש, המערכת קוראת את ה-CR, ומשתמשת במצביעים שבו כדי לאתר ולקרוא את כל חלקי ה-imap העדכניים ביותר *שנרשמו לדיסק עד לנקודת הזמן שבה ה-CR עצמו עודכן לאחרונה*. זה מאפשר שחזור עקבי של ה-imap בזיכרון המערכת, כפי שצוין: \"אם נסגור את המחשב ונדליק אותו מחדש, אין בעיה, נקרא את ה-cr, הוא יצביע לכל החלקים של ה-imap, נקרא גם אותם וכך נוכל לשחזר את ה-imap ולעבוד כרגיל.\"\n\nאפשרות ב' שגויה מכיוון שהיא מתארת סריקה יקרה של הדיסק, בעוד תפקיד ה-CR הוא בדיוק לספק נקודת כניסה ישירה ויעילה ל-imap.\nאפשרות ג' שגויה מכיוון שהחומר מציין במפורש שה-CR מכיל מצביעים ל\"כל חלק\", ולא רק לחלק ראשי שמוביל לשרשרת.\nאפשרות ד' שגויה, שכן הטקסט מציין \"אין בעיה\" בשחזור ה-imap באמצעות ה-CR, מה שמעיד על עקביות ושלמות מספקת לצורך פעולה רגילה, גם אם לא כל שינוי שבוצע *אחרי* עדכון ה-CR האחרון נכלל."}, "_source_file": "0394__File_Systems__Inode_Map__MC__Hard.json", "_topic_hint": "Inode Map", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:29:04", "_subject": "File Systems", "_context_lectures": [22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Inode Map"], "difficulty_estimation": "Hard", "content": {"text": "בהתחשב במבנה מערכת הקבצים (LFS) שבה ה-Checkpoint Region (CR) מצביע על הגרסאות העדכניות של חלקי ה-inode map (imap), ובהינתן שה-CR מתעדכן לעיתים רחוקות (לדוגמה, כל 30 דקות) בעוד שחלקי ה-imap מתעדכנים בתדירות גבוהה יותר עם כל שינוי ב-inodes הרלוונטיים, איזו מהטענות הבאות מתארת בצורה הטובה ביותר את ההשלכה של מנגנון זה על התאוששות המערכת לאחר כשל?", "code_snippet": null, "options": ["א. אם חלק מ-imap נכתב לדיסק עם עדכונים חדשים, אך ה-CR לא עודכן להצביע על מיקום חדש זה לפני כשל, המערכת תשחזר את ה-imap מגרסתו הישנה יותר כפי שמצביע ה-CR, ובכך תאבד את עדכוני ה-inode האחרונים שלא נכללו ב-CR.", "ב. המערכת תסרוק את כל הסגמנטים בדיסק כדי לאתר את הגרסה העדכנית ביותר של כל חלק imap, ללא תלות במה שמצביע ה-CR, ובכך תבטיח שהיא תמיד תתאושש למצב העדכני ביותר.", "ג. ה-CR מכיל מצביעים לכל הגרסאות ההיסטוריות של חלקי ה-imap, מה שמאפשר למערכת לשחזר תמיד את המצב העדכני ביותר של כל inode, גם אם הכשל התרחש לפני עדכון ה-CR.", "ד. חלקי ה-imap נכתבים תמיד יחד עם ה-CR במיקום קבוע על הדיסק, מה שמבטיח עקביות מלאה בין ה-CR לבין הגרסאות העדכניות של ה-imap בכל עת."]}, "solution": {"correct_option": "א", "explanation": "ההסבר הנכון הוא א'. על פי חומר ההרצאה, ה-CR (Checkpoint Region) משמש כנקודת התייחסות קבועה המצביעה על הגרסה העדכנית ביותר של חלקי ה-imap. עם זאת, ה-CR מתעדכן לעיתים רחוקות (למשל, כל 30 דקות) כדי למנוע פגיעה בביצועים כתוצאה מכתיבה תכופה. חלקי ה-imap עצמם מתעדכנים בתדירות גבוהה יותר, עם כל שינוי ב-inodes הרלוונטיים, ונכתבים לדיסק. במקרה של כשל מערכת לפני שה-CR הספיק להתעדכן ולהצביע על גרסאות חדשות של חלקי imap שנכתבו לדיסק, המערכת, בעת התאוששות, תקרא את ה-CR. ה-CR יפנה אותה לגרסאות ה-imap שהיו עדכניות *בזמן עדכון ה-CR האחרון*. משמעות הדבר היא שכל עדכוני imap ו-inode שבוצעו ונכתבו לדיסק *אחרי* עדכון ה-CR האחרון ו*לפני* הכשל, יאבדו, והמערכת תחזור למצב שהיה תקף בנקודת הבדיקה האחרונה (ה-CR). זהו פשרה בין ביצועים (אי-עדכון תכוף של ה-CR) לבין עקביות ואיבוד נתונים פוטנציאלי במקרה של כשל.\nאפשרות ב' שגויה מכיוון שהיא מתארת סריקה מלאה של הדיסק, בעוד שתפקיד ה-CR הוא בדיוק לספק נקודת כניסה מהירה לשחזור ה-imap מבלי לסרוק את כל הדיסק.\nאפשרות ג' שגויה מכיוון שה-CR מצביע על הגרסה ה\"עדכנית ביותר\" של כל חלק imap, ולא על כל הגרסאות ההיסטוריות.\nאפשרות ד' שגויה מכיוון שה-CR נמצא במיקום קבוע ומתעדכן לעיתים רחוקות, בעוד שחלקי ה-imap משתנים ומופיעים בסגמנטים שונים. הם אינם נכתבים יחד באופן אטומי ולא חייבים להיות באותו מיקום."}, "_source_file": "0395__File_Systems__Inode_Map__MC__Hard.json", "_topic_hint": "Inode Map", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:29:22", "_subject": "File Systems", "_context_lectures": [22]}, {"id": 1, "type": "MultipleChoice", "subject": "File Systems", "topic": ["Inode Map"], "difficulty_estimation": "Hard", "content": {"text": "בהתחשב במנגנון ה-Checkpoint Region (CR) ובחלוקת ה-inode map (imap) לחלקים, מהי ההשלכה הסבירה ביותר של קריסת מערכת המתרחשת לאחר שחלק מעודכן של ה-imap נכתב בהצלחה לדיסק, אך לפני שה-CR עצמו עודכן להצביע לגרסה החדשה של אותו חלק?", "code_snippet": null, "options": ["א. המערכת תשחזר גרסה לא עדכנית של חלק ה-imap, מה שעלול להוביל לחוסר עקביות בנתונים או לאובדנם.", "ב. המערכת לא תצליח לעלות כלל (boot failure) מכיוון שה-CR יצביע לחלק imap פגום.", "ג. המערכת תבנה מחדש באופן אוטומטי את חלק ה-imap הנכון מתוך בלוקי סיכום הסגמנטים (segment summary blocks).", "ד. ה-imap נשמר תמיד בעקביות מלאה על הדיסק יחד עם ה-CR, ולכן תרחיש כזה אינו אפשרי."]}, "solution": {"correct_option": "א", "explanation": "ההסבר הנכון הוא א'. על פי חומר ההרצאה, ה-Checkpoint Region (CR) מצביע לגרסאות העדכניות ביותר של חלקי ה-imap. עם זאת, ה-CR עצמו נכתב לדיסק לעיתים רחוקות (למשל, כל 30 דקות) כדי למנוע פגיעה בביצועים. אם חלק מה-imap מתעדכן ונכתב לדיסק, אך המערכת קורסת לפני שה-CR הספיק להתעדכן ולהצביע לגרסה החדשה של אותו חלק, ה-CR יישאר עם המצביע לגרסה הישנה. בעת אתחול מחדש, המערכת תקרא את ה-CR, אשר יוביל אותה לגרסה המיושנת של חלק ה-imap. כתוצאה מכך, ה-imap שייבנה בזיכרון יהיה לא עדכני, וזה עלול לגרום לחוסר עקביות בנתונים או לאובדן נתונים שהיו אמורים להיות משויכים לגרסה החדשה יותר של ה-inode. אפשרויות ב', ג' ו-ד' אינן נכונות מכיוון שה-CR יצביע לגרסה תקינה אך מיושנת (לא פגומה), חומר ההרצאה אינו מתאר מנגנון שחזור אוטומטי של imap מבלוקי סיכום במקרה כזה, והוא מדגיש שה-CR אינו מתעדכן באופן מיידי עם כל עדכון imap."}, "_source_file": "0396__File_Systems__Inode_Map__MC__Hard.json", "_topic_hint": "Inode Map", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:29:36", "_subject": "File Systems", "_context_lectures": [22]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["I/O Devices"], "difficulty_estimation": "Easy", "content": {"text": "לשם איזו מטרה משמש רגיסטר מסוג 'command' בממשק של רכיב חומרה?", "code_snippet": null, "options": ["א. לקרוא את המצב הנוכחי של הרכיב (כגון עסוק/פנוי).", "ב. להעביר נתונים שהרכיב יכול להשתמש בהם עבור הפעולה המבוקשת.", "ג. להורות לרכיב את הפעולה שאנו רוצים שיבצע (כגון כתיבה או קריאה).", "ד. למפות זיכרון וירטואלי לרכיב החומרה כדי לאפשר גישה ישירה."]}, "solution": {"correct_option": "ג", "explanation": "על פי חומר ההרצאה, ממשק רכיב חומרה בנוי מרגיסטרים מסוגים שונים. רגיסטר מסוג 'command' משמש כדי 'לכתוב אליו, אומרים לרכיב את הפעולה שאנחנו רוצים לבצע. למשל לכתוב / לקרוא'.\nאפשרות א' מתארת רגיסטר מסוג 'status'.\nאפשרות ב' מתארת רגיסטר מסוג 'data'.\nאפשרות ד' מתארת את מנגנון ה-memory mapped I/O, שהוא שיטה לגישה לרכיבי חומרה אך אינו סוג של רגיסטר בפני עצמו."}, "_source_file": "0397__Disks__I-O_Devices__MC__Easy.json", "_topic_hint": "I/O Devices", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:29:43", "_subject": "Disks", "_context_lectures": [17, 18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["I/O Devices"], "difficulty_estimation": "Easy", "content": {"text": "מערכת ההפעלה/המעבד מתקשרת עם רכיבי חומרה, כגון דיסק און קי, על מנת לקרוא את מצבם ולפקד עליהם לבצע פעולות. מהו המנגנון הבסיסי שבאמצעותו מתבצעת תקשורת ישירה זו עם הרכיב?", "code_snippet": null, "options": ["א. באמצעות רישומים (Registers) מסוג status, command ו-data.", "ב. על ידי מיפוי זיכרון (memory mapped I/O) של כל רכיבי החומרה לזיכרון וירטואלי.", "ג. דרך מנהל התקן (Driver) ייעודי המגדיר ממשק אחיד לתקשורת.", "ד. באמצעות שליחת פקודות מכונה מיוחדות (special machine instructions) בלבד, ללא שימוש ברישומים."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מציין במפורש כי \"ממשק הרכיב בנוי מרגיסטרים. בדרך כלל יש 3 סוגים: status, command, data\". רישומים אלו מהווים את המנגנון הבסיסי והישיר שבאמצעותו מערכת ההפעלה/המעבד יכולה לקרוא את מצב הרכיב (status), לכתוב אליו פקודות לביצוע פעולות (command), ולהעביר נתונים (data) עבור הפעולות הללו. אפשרות ב' מתארת שיטת גישה לרישומים, אך לא את הרישומים עצמם כמנגנון התקשורת. אפשרות ג' מתארת שכבת הפשטה גבוהה יותר (דרייבר) שמשתמשת במנגנון הרישומים. אפשרות ד' אינה נכונה שכן התקשורת מתבצעת דרך רישומים."}, "_source_file": "0398__Disks__I-O_Devices__MC__Easy.json", "_topic_hint": "I/O Devices", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:29:57", "_subject": "Disks", "_context_lectures": [17, 18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["I/O Devices"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של מנהל התקן (דרייבר) במערכת הפעלה?", "code_snippet": null, "options": ["א. לאפשר למערכת ההפעלה לגשת ישירות לזיכרון הפיזי של ההתקן.", "ב. לספק אבסטרקציה וממשק אחיד לתקשורת בין מערכת ההפעלה לרכיבי חומרה ספציפיים.", "ג. לבצע אופטימיזציה של מהירות הדיסק באמצעות חלוקת נתונים על פני מספר דיסקים.", "ד. למפות דפי זיכרון וירטואליים לרכיבי חומרה כדי לאפשר גישה במצב משתמש."]}, "solution": {"correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. על פי חומר ההרצאה (chunk 21), מערכת ההפעלה אינה יכולה לדעת לתקשר עם כל רכיב חומרה בעולם בנפרד. לשם כך קיים מנגנון הדרייבר, שהוא 'אבסטרקציה לתקשורת בין רכיבים'. הדרייבר מספק 'ממשק אחיד' למערכת ההפעלה, והוא עצמו קוד שנכתב כדי לתקשר עם רכיב חומרה מסוים באופן ספציפי, ובכך מתווך בין מערכת ההפעלה לחומרה. אפשרות א' אינה מדויקת מכיוון שהדרייבר מספק ממשק ולא בהכרח גישה ישירה לזיכרון הפיזי של ההתקן למערכת ההפעלה. אפשרות ג' מתארת את מנגנון ה-RAID (chunk 27) ואינה קשורה לדרייברים. אפשרות ד' מתארת את מנגנון ה-memory mapped I/O (chunk 17), שהוא מנגנון שונה לתקשורת עם חומרה."}, "_source_file": "0399__Disks__I-O_Devices__MC__Easy.json", "_topic_hint": "I/O Devices", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:30:09", "_subject": "Disks", "_context_lectures": [17, 18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["I/O Devices"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של מנהל התקן (דרייבר) במערכת הפעלה?", "code_snippet": null, "options": ["א. לספק שכבת הפשטה המאפשרת למערכת ההפעלה לתקשר עם רכיבי חומרה ספציפיים.", "ב. לנהל את תזמון התהליכים הרצים במעבד.", "ג. להמיר כתובות לוגיות לכתובות פיזיות בזיכרון.", "ד. לאפשר גישה ישירה ולא מוגבלת של תוכניות משתמש לרגיסטרים של החומרה."]}, "solution": {"correct_option": "א", "explanation": "המטרה העיקרית של מנהל התקן (דרייבר) היא לספק שכבת הפשטה (abstraction layer) בין מערכת ההפעלה לבין רכיב חומרה ספציפי. כפי שמצוין בחומר ההרצאה, \"במקום שמערכת ההפעלה תכיר כל רכיב חומרה שקיים בעולם, היא פשוט מגדירה ממשק אחיד (שהדרייבר לה המימוש שלו)\". הדרייבר הוא הקוד שיודע לתקשר עם רכיב החומרה הספציפי ומאפשר למערכת ההפעלה לגשת אליו באמצעות ממשק אחיד, מבלי לדעת את הפרטים הפנימיים של אופן הפעולה של החומרה. אפשרויות ב' ו-ג' מתארות פונקציות אחרות של מערכת ההפעלה (תזמון תהליכים וניהול זיכרון, בהתאמה), ואפשרות ד' אינה נכונה מכיוון שדרייברים מספקים גישה מבוקרת, ולא תמיד ישירה ובלתי מוגבלת, ולרוב מטרתם העיקרית היא תיווך עבור מערכת ההפעלה."}, "_source_file": "0400__Disks__I-O_Devices__MC__Easy.json", "_topic_hint": "I/O Devices", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:30:22", "_subject": "Disks", "_context_lectures": [17, 18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["I/O Devices"], "difficulty_estimation": "Medium", "content": {"text": "מהי אחת המטרות העיקריות של גישת ה-Memory-Mapped I/O במערכות הפעלה, וכיצד היא מתייחסת לגישה לרכיבי חומרה כגון רגיסטרים של דיסק קשיח?", "code_snippet": "/* Pseudo-code for Memory-Mapped I/O interaction */\n/* Imagine 'device_memory_ptr' is a pointer to a memory region\n   that has been mapped to a hardware device's registers. */\n\n// Accessing device status register\nint status_reg_value = device_memory_ptr[STATUS_REGISTER_OFFSET];\n\n// Writing to device command register\ndevice_memory_ptr[COMMAND_REGISTER_OFFSET] = SOME_COMMAND_VALUE;\n\n// Transferring data to device data register\ndevice_memory_ptr[DATA_REGISTER_OFFSET] = DATA_TO_WRITE;\n\n// No special I/O instructions are used; it's just memory access.", "options": ["א. היא מאפשרת למשתמש ולמערכת ההפעלה לגשת ישירות לרכיבי חומרה דרך מרחב כתובות הזיכרון הווירטואלי, אך מונעת מיפוי ישיר של רגיסטרים שעלולים לגרום נזק, כמו רגיסטרי שליטה של דיסק קשיח.", "ב. היא דורשת שימוש בפקודות מכונה מיוחדות ובמעבר ל-kernel mode כדי לתקשר עם חומרה, ומאפשרת מיפוי ישיר של כל רגיסטר חומרה ללא הגבלה.", "ג. היא מפשטת את התקשורת עם רכיבי חומרה על ידי שימוש בממשק אחיד הממומש על ידי דרייברים, ובכך מבטלת את הצורך בגישה ישירה לזיכרון הווירטואלי.", "ד. היא משמשת בעיקר לשיפור מהירות הקריאה/כתיבה לדיסקים מרובים במקביל (כמו ב-RAID), ולא קשורה לדרך הגישה לרגיסטרים של התקנים בודדים."]}, "solution": {"correct_option": "א", "explanation": "גישת ה-Memory-Mapped I/O מאפשרת למשתמש ולמערכת ההפעלה לגשת לרכיבי חומרה באמצעות מיפוי חלקים ממרחב הזיכרון הווירטואלי ישירות לחומרה (Lecture 17, chunk 17). הגישה הזו מייתרת את הצורך בפקודות מיוחדות או במעבר למצב ליבה (kernel mode), ומאפשרת אינטראקציה עם החומרה כאילו היא מערך בזיכרון. עם זאת, מערכת ההפעלה אוכפת הגבלות אבטחה ומונעת מיפוי ישיר של רגיסטרים שעלולים לגרום נזק למערכת, כגון רגיסטרי שליטה של דיסק קשיח, אך כן מאפשרת מיפוי נתונים בתוכו (Lecture 17, chunk 20).\n\nאפשרויות אחרות שגויות מכיוון:\n- **ב:** גישת ה-Memory-Mapped I/O אינה דורשת פקודות מיוחדות או מעבר ל-kernel mode, והיא אינה מאפשרת מיפוי בלתי מוגבל של כל רגיסטר חומרה (Lecture 17, chunk 17, 20).\n- **ג:** תיאור זה מתייחס למנגנון הדרייברים (מנהלי התקן), שמספק ממשק אחיד לתקשורת עם חומרה ספציפית, ולא ל-Memory-Mapped I/O. בנוסף, Memory-Mapped I/O מתבססת דווקא על גישה לזיכרון הווירטואלי (Lecture 17, chunk 21).\n- **ד:** תיאור זה מתייחס למערכי RAID, שמטרתם לשפר ביצועים ואמינות באמצעות מספר דיסקים (Lecture 18, chunk 27), ואינו קשור ישירות לדרך הגישה לרגיסטרים של התקני קלט/פלט בודדים באמצעות Memory-Mapped I/O."}, "_source_file": "0401__Disks__I-O_Devices__MC__Medium.json", "_topic_hint": "I/O Devices", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:30:38", "_subject": "Disks", "_context_lectures": [17, 18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["I/O Devices"], "difficulty_estimation": "Medium", "content": {"text": "בהתייחס לאופן שבו מערכת הפעלה מתקשרת עם התקני קלט/פלט מגוונים, מהו התפקיד המרכזי של מנהל התקן (Device Driver)?", "code_snippet": null, "options": ["א. לאפשר גישה ישירה של תהליכים במרחב המשתמש (user space) לרגיסטרי ה-Status, Command, ו-Data של ההתקן.", "ב. לספק למערכת ההפעלה ממשק אחיד לתקשורת עם סוגים רבים של חומרה, ובכך לפטור אותה מהצורך להכיר את הפרטים הספציפיים של כל רכיב.", "ג. לבצע מיפוי זיכרון (memory-mapped I/O) של כל רכיבי החומרה לתוך מרחב הכתובות של הקרנל, כדי לייעל את מהירות התקשורת.", "ד. לנהל את הזיכרון הווירטואלי של ההתקנים ולבצע הקצאת דפים (paging) עבורם, ללא מעורבות של מערכת ההפעלה."]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר ההרצאה (chunk 21), התפקיד העיקרי של מנהל ההתקן (דרייבר) הוא לשמש כאבסטרקציה לתקשורת בין מערכת ההפעלה לרכיבי החומרה. במקום שמערכת ההפעלה תצטרך להכיר את הפרטים הספציפיים של כל רכיב חומרה קיים, היא מגדירה ממשק אחיד, ואת המימוש לממשק זה מספק הדרייבר. כך, מערכת ההפעלה קוראת לפונקציה בדרייבר, והדרייבר הוא זה שיודע לתקשר עם הרכיב הספציפי ולהחזיר את התשובה. אפשרות ב' מתארת תפקיד זה במדויק. אפשרויות א' ו-ד' שגויות מכיוון שהדרייבר אינו חושף גישה ישירה לרגיסטרים למרחב המשתמש, ואינו מנהל את הזיכרון הווירטואלי של ההתקנים ללא מעורבות מערכת ההפעלה. אפשרות ג' מתארת מנגנון (memory-mapped I/O) שהדרייבר עשוי להשתמש בו, אך זה אינו התפקיד המרכזי והייחודי של הדרייבר כפי שהוגדר בחומר ההרצאה, אלא אמצעי למימוש."}, "_source_file": "0402__Disks__I-O_Devices__MC__Medium.json", "_topic_hint": "I/O Devices", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:30:53", "_subject": "Disks", "_context_lectures": [17, 18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["I/O Devices"], "difficulty_estimation": "Medium", "content": {"text": "איזו מהאפשרויות הבאות מתארת נכונה יתרון מרכזי של שימוש ב-Memory-Mapped I/O לתקשורת עם התקני חומרה, בהשוואה לגישה ישירה לרגיסטרים של ההתקן באמצעות פקודות מיוחדות?", "code_snippet": "/*\n * דוגמה לגישה להתקן דרך Memory-Mapped I/O\n * נניח ש-device_ptr הוא מצביע לאזור זיכרון הממופה להתקן חומרה (למשל, בקר מסך)\n */\n\n#define COMMAND_REGISTER_OFFSET 0x00\n#define STATUS_REGISTER_OFFSET  0x04\n#define DATA_BUFFER_OFFSET      0x1000\n\n#define START_OPERATION_CMD     0x01\n#define DEVICE_READY_BIT        0x01\n\nvolatile unsigned int *device_registers = (volatile unsigned int *)0xF0000000; // כתובת בסיס ממופה\n\n// כתיבה לרגיסטר פקודה (לדוגמה, פקודת \"התחל פעולה\")\ndevice_registers[COMMAND_REGISTER_OFFSET / sizeof(unsigned int)] = START_OPERATION_CMD;\n\n// קריאה מרגיסטר סטטוס (לדוגמה, בדיקת אם ההתקן פנוי)\nif (device_registers[STATUS_REGISTER_OFFSET / sizeof(unsigned int)] & DEVICE_READY_BIT) {\n    // ההתקן פנוי\n}\n\n// כתיבת נתונים דרך אזור נתונים ממופה\nvolatile unsigned char *data_buffer = (volatile unsigned char *)(0xF0000000 + DATA_BUFFER_OFFSET);\n\ndata_buffer[0] = 'H';\ndata_buffer[1] = 'e';\ndata_buffer[2] = 'l';\n// ... ועוד\n\n/*\n * בדוגמה זו, הגישה להתקן מתבצעת באמצעות פעולות זיכרון רגילות\n * (קריאה/כתיבה למצביעים), ללא צורך בפקודות קלט/פלט מיוחדות או מעבר ל-kernel mode\n * עבור כל פעולה, במידה והזיכרון ממופה למרחב כתובות של התהליך.\n */", "options": ["א. Memory-Mapped I/O מאפשר גישה לרכיבי החומרה הן למשתמש והן למערכת ההפעלה ללא צורך במעבר ל-kernel mode, תוך שימוש במנגנון הזיכרון הווירטואלי הקיים.", "ב. Memory-Mapped I/O דורש שימוש בפקודות מכונה מיוחדות לכל פעולת קריאה וכתיבה, מה שמבטיח אבטחה גבוהה יותר.", "ג. Memory-Mapped I/O מוגבל לגישה לרגיסטרים מסוג \"status\" בלבד, ואינו מאפשר שליטה בפעולות \"command\" או העברת נתונים \"data\".", "ד. Memory-Mapped I/O מפשט את תהליך התקנת הדרייברים בכך שהוא מבטל את הצורך בקוד ספציפי לכל התקן."]}, "solution": {"correct_option": "א", "explanation": "אפשרות א' נכונה. על פי חומר ההרצאה, Memory-Mapped I/O מאפשר גישה לרכיבי חומרה הן למשתמש והן למערכת ההפעלה ללא צורך בפקודות מיוחדות או במעבר ל-kernel mode. זה מתאפשר על ידי שימוש במנגנון הזיכרון הווירטואלי הקיים, הממפה דפי זיכרון לחומרה, ובכך מאפשר גישה אליה כאילו הייתה מערך בזיכרון (למשל, גישה לפיקסלים במסך). אפשרויות ב', ג' ו-ד' שגויות: ב' שגויה כיוון ש-Memory-Mapped I/O דווקא מבטל את הצורך בפקודות מכונה מיוחדות או קריאות מערכת. ג' שגויה מכיוון ש-Memory-Mapped I/O אינו מוגבל לגישה לרגיסטרי סטטוס בלבד, אלא יכול לשמש לכל סוגי האינטראקציה (קריאה וכתיבה לנתונים, פקודות וסטטוס) עם החומרה הממופה. ד' שגויה כיוון ש-Memory-Mapped I/O הוא מנגנון גישה לחומרה, אך אינו מבטל את הצורך בדרייברים, שהם קוד ספציפי שמיישם את הממשק האחיד לתקשורת עם החומרה."}, "_source_file": "0403__Disks__I-O_Devices__MC__Medium.json", "_topic_hint": "I/O Devices", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:31:16", "_subject": "Disks", "_context_lectures": [17, 18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["I/O Devices"], "difficulty_estimation": "Medium", "content": {"text": "כיצד מערכת הפעלה מתקשרת באופן טיפוסי עם התקן קלט/פלט (I/O) כמו דיסק קשיח, בהתבסס על המנגנונים המתוארים בחומר הלימוד?", "code_snippet": null, "options": ["א. על ידי מיפוי ישיר של כל רגיסטרי ההתקן לזיכרון וירטואלי של המשתמש דרך memory-mapped I/O, מה שמאפשר גישה ישירה מה-user mode.", "ב. באמצעות שימוש בדרייבר (מנהל התקן) ייעודי, אשר מתרגם את בקשות מערכת ההפעלה לפעולות קריאה וכתיבה לרגיסטרי ה-status, command ו-data של ההתקן.", "ג. המעבד שולח פקודות מכונה מיוחדות (special machine instructions) ישירות להתקן, עוקף את הצורך בדרייברים או במנגנוני זיכרון וירטואלי.", "ד. מערכת ההפעלה טוענת את הקושחה (firmware) הפנימית של ההתקן לזיכרון הראשי ומתקשרת איתה ישירות, ללא כל שכבת תיווך נוספת."]}, "solution": {"correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. חומר הלימוד מציין כי מנגנון הדרייבר (מנהל ההתקן) הוא אבסטרקציה לתקשורת בין רכיבים, המאפשר למערכת ההפעלה לדבר עם מגוון רחב של התקני חומרה מבלי להכיר את הפרטים הספציפיים של כל אחד מהם. מערכת ההפעלה מגדירה ממשק אחיד, והדרייבר הוא המימוש שלו עבור התקן מסוים. הדרייבר הוא הקוד שיודע לתקשר עם רכיב החומרה הספציפי על ידי כתיבה וקריאה לרגיסטרים שלו – רגיסטר status לקריאת מצב, רגיסטר command לביצוע פעולות, ורגיסטר data להעברת נתונים. לכן, מערכת ההפעלה קוראת לפונקציה בדרייבר, והדרייבר מבצע את האינטראקציה ברמה הנמוכה עם רגיסטרי הדיסק. אפשרות א' שגויה מכיוון שחומר הלימוד מציין במפורש ש\"לא נוכל לגשת לרגיסטרים של ההארד דיסק. מערכת ההפעלה לא תיתן לנו\" באמצעות memory-mapped I/O, אלא רק לנתונים בתוכו (למשל קובץ). אפשרויות ג' ו-ד' מתארות מנגנונים שאינם תואמים את התפקיד המרכזי של הדרייברים כשכבת תיווך הכרחית בין מערכת ההפעלה לחומרה, כפי שהוסבר בחומר הלימוד על מנת להתמודד עם ריבוי סוגי החומרות."}, "_source_file": "0404__Disks__I-O_Devices__MC__Medium.json", "_topic_hint": "I/O Devices", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:31:33", "_subject": "Disks", "_context_lectures": [17, 18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["I/O Devices"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על חומר ההרצאה, מהו המנגנון העיקרי שבאמצעותו מערכת ההפעלה מתקשרת עם רגיסטרי פיקוד (command registers) של התקן חומרה מורכב כמו דיסק קשיח, וכיצד מנגנון זה משתלב עם גישת משתמשים?", "code_snippet": null, "options": ["א. מערכת ההפעלה ממפה ישירות את רגיסטרי הפיקוד למרחב הכתובות של המשתמש באמצעות Memory-mapped I/O, מה שמאפשר לתוכניות משתמש לשלוט ישירות בפעולות ההתקן.", "ב. דרייברים (מנהלי התקן) ייעודיים, הנטענים לתוך מערכת ההפעלה, הם האחראים לתקשר עם רגיסטרי הפיקוד של ההתקן. גישת משתמשים לרגיסטרים אלו מוגבלת ואפשרית רק בעקיפין דרך קריאות מערכת לדרייבר.", "ג. התקני חומרה מודרניים מנהלים את רגיסטרי הפיקוד שלהם באופן אוטונומי לחלוטין, ומערכת ההפעלה רק מספקת נתונים דרך רגיסטרי ה-data, ללא צורך בפקודות פיקוד מפורשות.", "ד. המעבד שולח פקודות מכונה מיוחדות (special machine instructions) ישירות לרגיסטרי הפיקוד, כאשר פקודות אלו זמינות לתוכניות משתמש במצב user mode כדי לאפשר שליטה ישירה ויעילה."]}, "solution": {"correct_option": "ב", "explanation": "האפשרות הנכונה היא ב'. על פי חומר ההרצאה (chunk 21), דרייברים הם המנגנון המופשט המאפשר למערכת ההפעלה לתקשר עם רכיבי חומרה ספציפיים. הדרייבר הוא קוד שיודע לתקשר עם רכיב החומרה (כמו דיסק קשיח) ועם הרגיסטרים שלו (כולל רגיסטרי פיקוד, כפי שמוזכר ב-chunk 2). הדרייברים נטענים לתוך מערכת ההפעלה ומבצעים את התקשורת ברמה נמוכה. גישת משתמשים לרגיסטרים רגישים אלו נמנעת על ידי מערכת ההפעלה כדי למנוע נזק (chunk 20: \"לא נוכל לגשת לרגיסטרים של ההארד דיסק. מערכת ההפעלה לא תיתן לנו.\"), ולכן גישה אפשרית רק בעקיפין דרך קריאות מערכת המועברות לדרייבר.\n\nא. לא נכונה. למרות ש-Memory-mapped I/O מאפשר גישה ישירה לחומרה (chunk 17), חומר ההרצאה מציין במפורש שמערכת ההפעלה לא תאפשר למפות רגיסטרים של התקנים רגישים כמו דיסק קשיח למרחב המשתמש, כדי למנוע נזק (chunk 20).\nג. לא נכונה. חומר ההרצאה מפרט בבירור את קיומם של רגיסטרי command (פיקוד) שאליהם מערכת ההפעלה כותבת כדי לבצע פעולות (chunk 2). התקני חומרה אינם מנהלים את רגיסטרי הפיקוד באופן אוטונומי לחלוטין.\nד. לא נכונה. חומר ההרצאה מציין ש-Memory-mapped I/O מאפשר גישה \"ללא צורך בשימוש בפקודות מיוחדות והמעבר ל-kernel mode\" (chunk 17), מה שמרמז שפקודות כאלה קיימות אך אינן הדרך הסטנדרטית או המועדפת לגישת משתמשים להתקנים מורכבים, ובטח שלא לרגיסטרים רגישים במצב user mode. הדרייברים הם המתווכים במקרים אלו."}, "_source_file": "0405__Disks__I-O_Devices__MC__Hard.json", "_topic_hint": "I/O Devices", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:31:55", "_subject": "Disks", "_context_lectures": [17, 18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["I/O Devices"], "difficulty_estimation": "Hard", "content": {"text": "מנגנון Memory Mapped I/O מאפשר למערכת ההפעלה ולמשתמש לגשת לרכיבי חומרה על ידי מיפוי זיכרון וירטואלי לכתובות חומרה, ללא צורך בפקודות מיוחדות או מעבר למצב ליבה. עם זאת, חומר ההרצאה מציין שמערכת ההפעלה לא תאפשר למפות רגיסטרים של התקנים קריטיים (כמו דיסק קשיח) שעלולים לגרום נזק. איזו מהטענות הבאות מסבירה בצורה הטובה ביותר את ההבחנה הזו ואת תפקיד מערכת ההפעלה?", "code_snippet": null, "options": ["א. מערכת ההפעלה מגינה על תקינות המערכת על ידי מניעת גישה ישירה של תהליכי משתמש לרג'יסטרי Command ו-Status קריטיים, גם באמצעות Memory Mapped I/O, ומתווכת גישה אליהם דרך דרייברים במצב ליבה כדי להבטיח פעולה בטוחה ומבוקרת.", "ב. Memory Mapped I/O מיועדת אך ורק לגישה לנתונים (כמו קבצים) ולא לרג'יסטרי בקרה של חומרה, ולכן גישה לרג'יסטרים אלו תמיד דורשת קריאות מערכת במצב ליבה ולא יכולה להתבצע דרך מיפוי זיכרון כלל.", "ג. המגבלה נובעת מחוסר יכולת טכנית למפות רג'יסטרים מסוג Command או Status לזיכרון וירטואלי, שכן הם אינם נחשבים ל\"זיכרון\" במובן המסורתי ואינם ניתנים למיפוי.", "ד. גישה לרג'יסטרים קריטיים של התקני I/O דרך Memory Mapped I/O אפשרית רק במערכות הפעלה מודרניות התומכות ב-RAID, המפשטות את ממשק החומרה ומאפשרות גישה בטוחה יותר."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. מנגנון Memory Mapped I/O (chunk 17) אכן מאפשר מיפוי זיכרון וירטואלי לכתובות חומרה ומקל על גישה לרכיבים אלו, לעיתים קרובות גם מתהליכי משתמש ללא מעבר למצב ליבה. עם זאת, חומר ההרצאה (chunk 20) מדגיש שמערכת ההפעלה אינה מאפשרת גישה ישירה לרגיסטרים \"שעלולים לגרום נזק\", כגון רגיסטרי Command ו-Status של דיסק קשיח (chunk 2). הסיבה לכך היא הגנה על תקינות המערכת. מתן גישה ישירה למשתמשים לרג'יסטרים אלו עלול לאפשר להם לבצע פעולות הרסניות או לערער את יציבות המערכת. במקום זאת, מערכת ההפעלה מתווכת גישה לרגיסטרים קריטיים אלו דרך דרייברים (chunk 21) הפועלים במצב ליבה. הדרייברים הם קוד מהימן שנכתב במיוחד עבור החומרה, והם מבטיחים שהפעולות יבוצעו בצורה בטוחה ומבוקרת, תוך שמירה על עקרונות האבטחה וההגנה של מערכת ההפעלה. אפשרות ב' אינה נכונה מכיוון ש-MMIO יכול למפות רגיסטרי חומרה באופן כללי, אך מערכת ההפעלה מגבילה זאת מטעמי ביטחון. אפשרות ג' אינה נכונה מכיוון שהמגבלה היא מדיניותית ולא טכנית. אפשרות ד' אינה נכונה מכיוון ש-RAID קשור לביצועי דיסקים ואמינות, ולא ישירות לבקרת גישה לרג'יסטרי I/O קריטיים באמצעות MMIO."}, "_source_file": "0406__Disks__I-O_Devices__MC__Hard.json", "_topic_hint": "I/O Devices", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:32:13", "_subject": "Disks", "_context_lectures": [17, 18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["I/O Devices"], "difficulty_estimation": "Hard", "content": {"text": "מערכת הפעלה מודרנית משתמשת במנגנון דרייברים (מנהלי התקן) כדי לתקשר עם התקני חומרה מורכבים כמו דיסקים, במקום לחשוף ישירות את רגיסטרי השליטה (command, status) שלהם למרחב המשתמש באמצעות מיפוי זיכרון (memory-mapped I/O). איזו מהסיבות הבאות היא הסיבה העיקרית לכך?", "code_snippet": null, "options": ["א. חשיפת רגיסטרי שליטה של דיסקים למרחב המשתמש באמצעות מיפוי זיכרון עלולה לאפשר למשתמשים לבצע פעולות שעלולות לשבש את פעולת הדיסק או את שלמות הנתונים, מה שמחייב את מערכת ההפעלה לתווך דרך דרייבר הפועל במצב ליבה.", "ב. מנגנון מיפוי הזיכרון (memory-mapped I/O) מיועד אך ורק לרכיבי חומרה פשוטים כמו זיכרון וידאו ואינו תומך כלל בתקשורת עם רגיסטרים של התקני אחסון מורכבים.", "ג. שימוש בדרייברים מאפשר למערכת ההפעלה להשיג מהירות גישה גבוהה יותר לדיסק מאשר באמצעות מיפוי זיכרון, מכיוון שדרייברים מותאמים אישית לחומרה הספציפית.", "ד. מנגנון הדרייברים נחוץ רק כאשר התקן החומרה אינו תומך כלל במיפוי זיכרון, ורוב הדיסקים המודרניים אינם תומכים ביכולת זו."]}, "solution": {"correct_option": "א", "explanation": "ההסבר הנכון מתבסס על העיקרון שמערכת ההפעלה פועלת כמתווכת ומגנה על משאבי המערכת. לפי חומר ההרצאה (chunk 20), \"לא נוכל לגשת לרגיסטרים של ההארד דיסק. מערכת ההפעלה לא תיתן לנו. אבל היא כן תיתן לנו למפות את הנתונים שבתוכו (למשל קובץ). כלומר היא לא תיתן לנו למפות רק דברים שאנחנו לא יכולים להזיק בהם.\" רגיסטרי שליטה (command, status) של דיסק הם רכיבים קריטיים שגישה ישירה ובלתי מבוקרת אליהם ממרחב המשתמש עלולה להוביל לשחיתות נתונים, לקריסת המערכת או לניצול לרעה. לכן, למרות שמנגנון מיפוי הזיכרון (memory-mapped I/O) מאפשר גישה ישירה לחומרה ואף עשוי לחסוך מעבר למצב ליבה במקרים מסוימים (כמו גישה לפיקסלים בזיכרון וידאו), מערכת ההפעלה אוכפת הגנה על רכיבים רגישים אלו. היא עושה זאת באמצעות דרייברים, שהם קוד הפועל במצב ליבה (kernel mode) ומבצע את התקשורת בפועל עם רגיסטרי החומרה באופן מבוקר ובטוח, ומספק ממשק אחיד ומוגן ליישומים. אפשרויות ב, ג ו-ד אינן נכונות שכן מיפוי זיכרון אינו מוגבל בהכרח לרכיבים פשוטים, דרייברים אינם בהכרח מהירים יותר מגישה ישירה במונחי ביצועים טהורים של איתור כתובת, ורוב ההתקנים המודרניים תומכים בדרך כלל במיפוי זיכרון ברמה מסוימת, אך השאלה היא על בקרת הגישה."}, "_source_file": "0407__Disks__I-O_Devices__MC__Hard.json", "_topic_hint": "I/O Devices", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:32:31", "_subject": "Disks", "_context_lectures": [17, 18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["I/O Devices"], "difficulty_estimation": "Hard", "content": {"text": "בהתחשב במנגנונים של **Memory-Mapped I/O** ו**דרייברים (מנהלי התקן)** כפי שתוארו בחומר הקורס, ובהינתן שמערכת ההפעלה אינה מאפשרת ליישום במרחב המשתמש (user space) למפות לזיכרון רגיסטרים של פקודה (command registers) או מצב (status registers) של התקן חומרה ישירות, כדי למנוע נזק למערכת, איזו מהאפשרויות הבאות מתארת בצורה הטובה ביותר את הדרך שבה יישום במרחב המשתמש יכול להפעיל פעולת כתיבה (למשל, \"התחל הקלטה\") על התקן חומרה מותאם אישית?", "code_snippet": null, "options": ["א. על ידי גישה ישירה ל-**Command Register** של ההתקן באמצעות **Memory-Mapped I/O**, שכן ה-OS ממפה את כל רגיסטרי ההתקן למרחב הכתובות של היישום.", "ב. באמצעות כתיבה ישירה ל-**Data Register** של ההתקן דרך **Memory-Mapped I/O**, שכן פעולות כתיבה תמיד מתבצעות דרך רגיסטר הנתונים בלבד.", "ג. באמצעות קריאת מערכת (system call) שמערכת ההפעלה מספקת, אשר בתורה משתמשת בדרייבר המתאים כדי לכתוב ל-**Command Register** של ההתקן.", "ד. על ידי טעינת קוד דרייבר חדש ישירות ממרחב המשתמש לתוך זיכרון הליבה (kernel memory) וביצוע הפקודה באופן עצמאי."]}, "solution": {"correct_option": "ג", "explanation": "חומר הקורס מציין כי Memory-Mapped I/O מאפשר גישה לרכיבי חומרה, אך מערכת ההפעלה אינה מאפשרת למפות רגיסטרים שעלולים להזיק (כמו Command/Status registers) למרחב המשתמש, כדי למנוע נזק. לכן, אפשרות א' שגויה. אפשרות ב' שגויה מכיוון ש-Data Register משמש להעברת נתונים עבור פעולה מסוימת, אך לא להפעלת הפקודה עצמה; הפקודה מוגדרת ברגיסטר הפקודה (Command Register). אפשרות ד' שגויה, שכן טעינת דרייבר היא פעולה מבוקרת של מערכת ההפעלה, ולא משהו שיישום משתמש מבצע ישירות לתוך זיכרון הליבה באופן אד-הוק. הדרך הנכונה היא שאפליקציית משתמש תבצע קריאת מערכת (system call) למערכת ההפעלה. מערכת ההפעלה, בתורה, תשתמש בדרייבר המתאים (שכבר טעון במערכת ופועל במצב ליבה) כדי לתקשר עם רגיסטרי הפקודה של ההתקן ולבצע את הפעולה המבוקשת בצורה בטוחה ומבוקרת. הדרייבר הוא האבסטרקציה שמאפשרת למערכת ההפעלה לתקשר עם רכיבי חומרה ספציפיים."}, "_source_file": "0408__Disks__I-O_Devices__MC__Hard.json", "_topic_hint": "I/O Devices", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:32:49", "_subject": "Disks", "_context_lectures": [17, 18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Device Model"], "difficulty_estimation": "Easy", "content": {"text": "מהו המאפיין העיקרי של מודל ההתקן (Device Model) שמערכת RAID מציגה למערכת ההפעלה?", "code_snippet": null, "options": ["א. היא מציגה דיסק לוגי יחיד, גם אם בפועל קיימים מספר דיסקים פיזיים.", "ב. היא דורשת ממערכת ההפעלה לנהל באופן ישיר את פיצול הנתונים בין הדיסקים הפיזיים.", "ג. היא חושפת למערכת ההפעלה את הגישה הישירה לכל פלטה ומסלול פיזי בדיסק.", "ד. היא ממפה כל דיסק פיזי לאזור זיכרון נפרד באמצעות Memory-Mapped I/O."]}, "solution": {"correct_option": "א", "explanation": "מערכת RAID (Redundant Array of Independent Disks) נועדה לפשט את הגישה לדיסקים מרובים עבור מערכת ההפעלה והיישומים. כפי שמצוין בחומר ההרצאה, מערכת RAID נחשבת ל'דיסק מדומה' או 'דיסק לוגי'. מערכת ההפעלה רואה דיסק לוגי אחד בלבד, ואינה יודעת על קיומם של מספר דיסקים פיזיים מאחורי הקלעים. מנגנון ה-RAID (חומרה או קוד) הוא זה שמטפל באופן שקוף בפיצול, שכפול וניהול הנתונים על פני הדיסקים הפיזיים."}, "_source_file": "0409__Disks__Device_Model__MC__Easy.json", "_topic_hint": "Device Model", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:32:58", "_subject": "Disks", "_context_lectures": [17, 18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Device Model"], "difficulty_estimation": "Easy", "content": {"text": "מהי התכונה העיקרית של מערך RAID (Redundant Array of Independent Disks) מנקודת מבטה של מערכת ההפעלה?", "code_snippet": null, "options": ["א. מערכת ההפעלה רואה אותו כדיסק לוגי יחיד, למרות שהוא מורכב ממספר דיסקים פיזיים.", "ב. מערכת ההפעלה רואה ומנהלת כל דיסק פיזי בנפרד בתוך המערך.", "ג. מערכת ההפעלה נדרשת להשתמש בפקודות מיוחדות כדי לפצל ולשכפל נתונים על פני הדיסקים במערך.", "ד. RAID הוא מנגנון המשמש למיפוי זיכרון (memory-mapped I/O) עבור התקני אחסון."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, RAID נחשב ל'דיסק מדומה' או 'דיסק לוגי'. מערכת ההפעלה 'לא תדע שמדובר בדיסק מדומה' ומבחינתה 'יש הארד דיסק אחד'. המנגנון של RAID 'שקוף לחלוטין עבור מערכת ההפעלה', והוא מטפל בפיצול וניהול הנתונים על פני הדיסקים הפיזיים באופן אוטומטי. לכן, מערכת ההפעלה רואה את מערך ה-RAID כדיסק לוגי יחיד."}, "_source_file": "0410__Disks__Device_Model__MC__Easy.json", "_topic_hint": "Device Model", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:33:09", "_subject": "Disks", "_context_lectures": [17, 18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Device Model"], "difficulty_estimation": "Easy", "content": {"text": "מהו המאפיין העיקרי של מערכת RAID מנקודת מבטה של מערכת ההפעלה?", "code_snippet": null, "options": ["א. מערכת ההפעלה רואה את כל הדיסקים הפיזיים בנפרד ומנהלת כל אחד מהם באופן עצמאי.", "ב. מערכת ההפעלה רואה דיסק לוגי אחד בלבד, מבלי לדעת על קיומם של מספר דיסקים פיזיים.", "ג. מערכת ההפעלה נדרשת להשתמש בפקודות מיוחדות וקריאות מערכת כדי לתקשר עם מנגנון ה-RAID.", "ד. מנגנון ה-RAID מנוהל בלעדית על ידי התוכנה שרצה, ללא כל מעורבות של מערכת ההפעלה."]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר ההרצאה, מערכת RAID (Redundant Array of Independent Disks) נחשבת ל'דיסק מדומה' או 'דיסק לוגי'. הן התוכנית והן מערכת ההפעלה רואות דיסק אחד בלבד, ואינן מודעות לכך שמאחורי הקלעים קיימים מספר דיסקים פיזיים. מנגנון ה-RAID (רכיב חומרה או קוד) מטפל בפיצול ובניהול הנתונים באופן שקוף לחלוטין למערכת ההפעלה ולתוכנה. לכן, התשובה הנכונה היא שמערכת ההפעלה רואה דיסק לוגי אחד בלבד."}, "_source_file": "0411__Disks__Device_Model__MC__Easy.json", "_topic_hint": "Device Model", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:33:19", "_subject": "Disks", "_context_lectures": [17, 18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Device Model"], "difficulty_estimation": "Easy", "content": {"text": "לפי חומר ההרצאה, כיצד מערכת הפעלה תופסת מערך אחסון המוגדר כ-RAID?", "code_snippet": null, "options": ["א. כמספר דיסקים פיזיים נפרדים, כאשר היא אחראית לפיצול הנתונים ביניהם.", "ב. כדיסק לוגי יחיד, כאשר רכיב חומרה או תוכנה ייעודי מטפל במיפוי לדיסקים הפיזיים.", "ג. כמערך זיכרון וירטואלי הממופה ישירות ל-RAM, ללא מעורבות דיסקים פיזיים.", "ד. כיחידת אחסון בעלת מהירות קבועה של סיבובים לדקה (RPM), ללא קשר למספר הדיסקים."]}, "solution": {"correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. חומר ההרצאה מציין שמערכת RAID (Redundant Array of Independent Disks) נחשבת ל\"דיסק מדומה\" או \"דיסק לוגי\" עבור מערכת ההפעלה והתוכניות. מערכת ההפעלה רואה דיסק אחד בלבד (מבחינתה יש הארד דיסק אחד), בעוד שמאחורי הקלעים, רכיב חומרה או קוד מיוחד מנהל את הדיסקים הפיזיים בפועל ומבצע את פיצול ו/או שכפול הנתונים באופן שקוף לחלוטין למערכת ההפעלה. לכן, מערכת ההפעלה תופסת את מערך ה-RAID כדיסק לוגי יחיד."}, "_source_file": "0412__Disks__Device_Model__MC__Easy.json", "_topic_hint": "Device Model", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:33:29", "_subject": "Disks", "_context_lectures": [17, 18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Device Model"], "difficulty_estimation": "Medium", "content": {"text": "לפי מודל ההתקן של דיסק קשיח, מהו 'צילינדר' (cylinder)?", "code_snippet": null, "options": ["א. סט של סקטורים זהים על פני משטח אחד של פלטה.", "ב. אותה טבעת (track) על פני כל המשטחים של הפלטות בדיסק.", "ג. המוט המרכזי המחובר למנוע ומסובב את הפלטות.", "ד. צד אחד של פלטה מגנטית שעליו נשמרים נתונים."]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר ההרצאה (Lecture 17, chunk 25), 'סט של עיגולים (tracks) זהים על פני צלחות שונות נקראים צילינדר (cylinder)'. צילינדר מייצג את כל ה-tracks הנמצאים באותו רדיוס על כל משטחי הפלטות בדיסק. אפשרות א' אינה נכונה מכיוון שסקטור הוא יחידת אחסון קטנה יותר בתוך track, וצילינדר מתייחס ל-tracks על פני מספר משטחים. אפשרות ג' מתארת את ה-spindle (מוט הסיבוב). אפשרות ד' מתארת surface (משטח) של פלטה."}, "_source_file": "0413__Disks__Device_Model__MC__Medium.json", "_topic_hint": "Device Model", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:33:41", "_subject": "Disks", "_context_lectures": [17, 18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Device Model"], "difficulty_estimation": "Medium", "content": {"text": "על פי חומר ההרצאה, מהו המודל הלוגי של יחידת אחסון (דיסק) שמערכת הפעלה רואה כאשר היא עובדת עם מערכת RAID?", "code_snippet": null, "options": ["א. מערכת ההפעלה רואה דיסק לוגי יחיד המורכב מבלוקים/סקטורים, כאשר מנגנון ה-RAID מטפל בשקיפות בפיצול ובמיפוי לדיסקים הפיזיים המרובים.", "ב. מערכת ההפעלה מודעת לכל הדיסקים הפיזיים המחוברים ומנהלת בעצמה את פיצול הנתונים ביניהם לצורך ביצועים וגיבוי.", "ג. מערכת ההפעלה מתייחסת לכל פלטה ומשטח (platter and surface) של הדיסקים הפיזיים כיחידות אחסון נפרדות, ומבצעת מיפוי באמצעות צילינדרים.", "ד. מערכת ההפעלה משתמשת ב-Memory Mapped I/O כדי לגשת ישירות לבקר הדיסק, ומכאן מנהלת את סיבוב ה-spindle וקריאת ה-RPM."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מתאר את מערכת RAID (Redundant Array of Independent Disks) כדיסק מדומה או לוגי. מנגנון ה-RAID שקוף לחלוטין למערכת ההפעלה ולתוכניות. מבחינת מערכת ההפעלה, היא רואה דיסק לוגי אחד בלבד, המחולק לבלוקים/סקטורים, ואינה מודעת למספר הדיסקים הפיזיים שמאחוריו. מנגנון ה-RAID הוא זה שמנהל את פיצול הנתונים, הכפלתם ומיפויים לדיסקים הפיזיים בפועל, וכל זאת באופן שקוף לחלוטין למערכת ההפעלה."}, "_source_file": "0414__Disks__Device_Model__MC__Medium.json", "_topic_hint": "Device Model", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:33:53", "_subject": "Disks", "_context_lectures": [17, 18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Device Model"], "difficulty_estimation": "Medium", "content": {"text": "על פי החומר הנלמד, מהי הגישה שבה מערכת RAID מציגה את מערך הדיסקים הפיזיים למערכת ההפעלה?", "code_snippet": null, "options": ["א. היא מציגה דיסק לוגי יחיד, תוך הסתרת הדיסקים הפיזיים הבסיסיים באופן שקוף לחלוטין.", "ב. היא דורשת ממערכת ההפעלה לנהל באופן מפורש כל דיסק פיזי בנפרד.", "ג. היא ממפה כל דיסק פיזי לאזור זיכרון ייעודי באמצעות מנגנון memory mapped I/O.", "ד. היא חושפת את הרכיבים הפיזיים של הדיסקים, כגון פלטות ומסלולים, ישירות למערכת ההפעלה."]}, "solution": {"correct_option": "א", "explanation": "החומר המציין כי מערכת RAID (Redundant Array of Independent Disks) נחשבת ל\"דיסק מדומה\" או \"דיסק לוגי\". ההסבר מפרט שמבחינת מערכת ההפעלה והתוכניות, נראה דיסק אחד, ומנגנון ה-RAID מתפעל את הנתונים על פני הדיסקים הפיזיים השונים באופן שקוף לחלוטין. מערכת ההפעלה \"בטוחה שהיא שולחת אליו רק סקטור אחד\" ואינה מודעת לכמות הדיסקים הפיזיים שמאחורי הקלעים. לכן, התשובה הנכונה היא שהיא מציגה דיסק לוגי יחיד, תוך הסתרת הדיסקים הפיזיים הבסיסיים באופן שקוף."}, "_source_file": "0415__Disks__Device_Model__MC__Medium.json", "_topic_hint": "Device Model", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:34:02", "_subject": "Disks", "_context_lectures": [17, 18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Device Model"], "difficulty_estimation": "Medium", "content": {"text": "כיצד מערכת RAID (Redundant Array of Independent Disks) מציגה את עצמה למערכת ההפעלה, על פי עקרונות המודל ההתקני?", "code_snippet": null, "options": ["א. כדיסק קשיח לוגי יחיד, תוך ניהול שקוף של מספר דיסקים פיזיים מתחת לפני השטח.", "ב. כמספר דיסקים פיזיים נפרדים, המחייב את מערכת ההפעלה לנהל את פיצול הנתונים והעמידות.", "ג. כהתקן I/O הממופה לזיכרון, המאפשר גישה ישירה לסקטורים פיזיים ללא צורך במעבר ל-kernel mode.", "ד. כמנגנון תוכנה בלבד הפועל במרחב המשתמש, המטפל בעצמו בעמידות ובביצועים של הדיסקים."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין בשיעור 18 (chunk 25 ו-26) מסביר שמערכת RAID נחשבת \"דיסק מדומה\" או \"דיסק לוגי\". מבחינת מערכת ההפעלה והתוכניות, היא רואה דיסק קשיח אחד, למרות שבפועל מדובר במספר דיסקים פיזיים. מנגנון ה-RAID (בין אם ממומש בחומרה ובין אם בקוד) הוא שקוף לחלוטין עבור מערכת ההפעלה, והוא מפצל את הנתונים, מכפל קבצים ומטפל בעמידות ובביצועים מאחורי הקלעים. לכן, הגישה הנכונה היא שהמערכת מוצגת כדיסק לוגי יחיד, המנהל באופן שקוף את המורכבות הפיזית."}, "_source_file": "0416__Disks__Device_Model__MC__Medium.json", "_topic_hint": "Device Model", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:34:11", "_subject": "Disks", "_context_lectures": [17, 18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Device Model"], "difficulty_estimation": "Hard", "content": {"text": "מערכת RAID נועדה לנהל מספר דיסקים פיזיים באופן שקוף למערכת ההפעלה. בהקשר זה, מהו העיקרון המרכזי המאפשר למערכת ההפעלה \"לראות\" דיסק לוגי אחד בלבד, וכיצד הוא דומה למנגנון אחר במערכת ההפעלה?", "code_snippet": null, "options": ["א. מנגנון ה-RAID מבצע מיפוי של בלוקים לוגיים לבלוקים פיזיים על פני הדיסקים השונים, בדומה לאופן שבו זיכרון וירטואלי ממפה כתובות לוגיות לכתובות פיזיות.", "ב. מערכת ההפעלה משתמשת בפקודות I/O מיוחדות כדי לתקשר ישירות עם בקר ה-RAID, המטפל בפיצול הנתונים, בדומה למנגנון Memory Mapped I/O.", "ג. ה-RAID מבצע קריאות סדרתיות בלבד כדי למקסם את קצב ההעברה, מה שמאפשר למערכת ההפעלה להתייחס אליו כאל דיסק מהיר יחיד, בדומה לאופן פעולת Spindle בתוך דיסק פיזי.", "ד. רכיב החומרה של ה-RAID מסובב את כל הפלטות בבת אחת (RPM) ומוסתר לחלוטין ממערכת ההפעלה, בדומה לאופן שבו ה-OS אינה מודעת למהירות הסיבוב של דיסק בודד."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. הלקטורה מדגישה כי מערכת RAID יוצרת דיסק לוגי מדומה שמוצג למערכת ההפעלה כדיסק יחיד, למרות שמאחוריו ישנם מספר דיסקים פיזיים. השקיפות הזו מושגת באמצעות מנגנון מיפוי, שבו בקשות לבלוקים לוגיים מהדיסק המדומה מתורגמות לבלוקים פיזיים על פני הדיסקים האמיתיים המרכיבים את מערך ה-RAID. הלקטורה מציינת במפורש דמיון למנגנון הזיכרון הווירטואלי: \"בדומה לזיכרון וירטואלי, נצפה בדיסק מדומה, דיסק לוגי\" וכן \"כאשר אנחנו ניגשים לבלוק 2, יש מיפוי (כמו זיכרון וירטואלי) של הדיסק פיזי\".\n\nתשובה ב' שגויה מכיוון שהלקטורה מציינת כי RAID שקוף לחלוטין למערכת ההפעלה, כלומר, אין צורך בפקודות I/O מיוחדות. מערכת ההפעלה \"בטוחה שהיא שולחת אליו רק סקטור אחד\". מנגנון Memory Mapped I/O מאפשר גישה ישירה לחומרה ללא פקודות מיוחדות, אך זהו מנגנון שונה המאפשר גישה ישירה לאזורי חומרה ספציפיים, ולא מנגנון המטפל בשקיפות של מספר דיסקים כאחד.\n\nתשובה ג' שגויה מכיוון ש-RAID אינו מוגבל לקריאות סדרתיות בלבד; הוא נועד לשפר ביצועים עבור מגוון דפוסי גישה, כולל גישה אקראית, כפי שמצוין בדוגמאות לבדיקת ביצועים. ההתייחסות ל-Spindle אינה רלוונטית למנגנון השקיפות של RAID.\n\nתשובה ד' שגויה. בעוד ש-RAID אכן מוסתר ממערכת ההפעלה, מנגנון השקיפות אינו קשור לסיבוב הפלטות (RPM). ה-RPM הוא מאפיין פיזי של כל דיסק בודד, ואינו חלק מהאופן שבו RAID מאחד מספר דיסקים לוגית. RAID מנהל את הגישה לדיסקים הפיזיים, אך לא את פעולת הסיבוב הפנימית שלהם."}, "_source_file": "0417__Disks__Device_Model__MC__Hard.json", "_topic_hint": "Device Model", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:34:29", "_subject": "Disks", "_context_lectures": [17, 18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Device Model"], "difficulty_estimation": "Hard", "content": {"text": "איזו מהטענות הבאות מתארת בצורה המדויקת ביותר את האופן שבו מודל ההתקן (Device Model) של דיסק קשיח, כפי שהוא נתפס על ידי מערכת ההפעלה, משתנה מהותית כאשר מיושמת מערכת RAID, בהתבסס על עקרון השקיפות?", "code_snippet": null, "options": ["א. מערכת ההפעלה ממשיכה לתפוס דיסק לוגי יחיד ורציף, מבלי להיות מודעת לפיצול והכפלת הנתונים על פני מספר דיסקים פיזיים, כאשר מנגנון ה-RAID מטפל במיפוי בשקיפות מלאה.", "ב. מערכת ההפעלה מקבלת גישה ישירה לכל אחד מהדיסקים הפיזיים המרכיבים את מערך ה-RAID, ומנהלת באופן עצמאי את חלוקת הנתונים ביניהם.", "ג. מודל ההתקן משתנה כך שמערכת ההפעלה נדרשת ליישם אלגוריתמים מיוחדים לגישה לסקטורים, על מנת לנצל את יתרונות הביצועים של ה-RAID.", "ד. RAID משנה את המבנה הפיזי של הסקטורים והטרקים בדיסק הבודד, מה שמשפיע ישירות על אופן הגישה של מערכת ההפעלה לרכיבים אלו."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. החומר המצוין בשיעור 18 (chunks 25 ו-26) מדגיש כי מערכת RAID יוצרת 'דיסק מדומה' או 'דיסק לוגי' אחד, אשר 'שקוף לחלוטין עבור מערכת ההפעלה'. מערכת ההפעלה 'לא תדע שמדובר בדיסק מדומה' ותמשיך לתפוס 'הארד דיסק אחד'. מנגנון ה-RAID (רכיב חומרה/קוד) הוא זה שמפצל את הנתונים, מכפיל אותם (לצורך גיבוי), ומבצע את ה'מיפוי (כמו זיכרון וירטואלי) של הדיסק פיזי' לבלוקים הלוגיים, כל זאת באופן שקוף לחלוטין. לכן, מודל ההתקן נתפס על ידי מערכת ההפעלה כדיסק יחיד, למרות המורכבות הפיזית שמאחורי הקלעים. אפשרויות ב', ג' ו-ד' שגויות מכיוון שהן סותרות את עקרון השקיפות של RAID למערכת ההפעלה או מתארות שינויים שאינם מתרחשים ברמת מודל ההתקן כפי שהיא נתפסת על ידי מערכת ההפעלה."}, "_source_file": "0418__Disks__Device_Model__MC__Hard.json", "_topic_hint": "Device Model", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:34:45", "_subject": "Disks", "_context_lectures": [17, 18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Device Model"], "difficulty_estimation": "Hard", "content": {"text": "בהקשר למודל הדיסק שמערכת ההפעלה רואה, ובפרט למנגנון RAID (Redundant Array of Independent Disks) המתואר בחומר, איזו קביעה מתארת נכונה את האופן שבו מערכת ההפעלה תתפוס ותפעל מול מערך RAID?", "code_snippet": null, "options": ["א. מערכת ההפעלה רואה את מערך ה-RAID כדיסק פיזי יחיד עם גאומטריה מורכבת הכוללת מספר צילינדרים, ראשי קריאה/כתיבה ופלטות, ומשתמשת במידע זה לאופטימיזציה של גישות.", "ב. מערכת ההפעלה מתייחסת ל-RAID כאל דיסק לוגי המורכב מרצף ליניארי של בלוקים/סקטורים, ושולחת בקשות קריאה/כתיבה לבלוקים אלו מבלי להיות מודעת למיפוי הפיזי שמתבצע על ידי רכיב ה-RAID.", "ג. מערכת ההפעלה נדרשת לנהל טבלאות מיפוי משלה כדי לפצל בקשות לדיסקים הפיזיים המרכיבים את מערך ה-RAID, בדומה לאופן שבו היא מנהלת זיכרון וירטואלי.", "ד. מערכת ההפעלה תמיד תבצע אופטימיזציות גישה לדיסק, כגון מיון בקשות לפי צילינדר, תוך התחשבות בכך שמדובר במערך דיסקים פיזיים נפרדים."]}, "solution": {"correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. חומר ההרצאה מציין במפורש כי מערכת RAID 'שקוף לחלוטין עבור מערכת ההפעלה' (Lecture 18, chunk 26) וכי 'מערכת ההפעלה והתוכנית שלנו רואות משהו בלו בלוקים/סקטורים' (Lecture 18, chunk 26). כמו כן, נאמר ש'הארד דיסק הזה הוא לוגי והוא לא באמת קיים' וכי 'כאשר אנחנו ניגשים לבלוק 2, יש מיפוי (כמו זיכרון וירטואלי) של הדיסק פיזי' (Lecture 18, chunk 26). כלומר, מערכת ההפעלה רואה רק דיסק לוגי יחיד, המורכב מרצף ליניארי של בלוקים או סקטורים, ואינה מודעת כלל למבנה הפיזי המורכב או למספר הדיסקים הפיזיים שמאחורי הקלעים. רכיב ה-RAID (חומרה או קוד) הוא זה שמבצע את המיפוי והפיצול בפועל. לכן, אפשרויות א', ג' ו-ד' שגויות, שכן הן מניחות שמערכת ההפעלה מודעת למבנה הפיזי של הדיסקים המרכיבים את המערך או נדרשת לנהל את הפיצול בעצמה."}, "_source_file": "0419__Disks__Device_Model__MC__Hard.json", "_topic_hint": "Device Model", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:35:04", "_subject": "Disks", "_context_lectures": [17, 18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Device Model"], "difficulty_estimation": "Hard", "content": {"text": "מערכת הפעלה מריצה תוכנית המבצעת סדרת קריאות סדרתיות לסקטורים עוקבים (לדוגמה, סקטור 0, 1, 2, 3...) על דיסק לוגי יחיד. דיסק לוגי זה ממומש בפועל באמצעות מערך RAID המפצל את הנתונים (stripping) על פני מספר דיסקים פיזיים, באופן שקוף לחלוטין למערכת ההפעלה. בהתחשב בכך, איזו מהטענות הבאות מתארת בצורה הטובה ביותר את תבנית הגישה לדיסקים הפיזיים ואת תפיסת מערכת ההפעלה?", "code_snippet": null, "options": ["א. מערכת ההפעלה תתפוס את הגישה כסדרתית לחלוטין, ומנגנון ה-RAID יתרגם זאת לגישה סדרתית על דיסק פיזי יחיד בכל פעם, תוך ניצול מיטבי של מהירות הסיבוב (RPM) של אותו דיסק.", "ב. למרות שהקריאות לדיסק הלוגי הן סדרתיות, מנגנון ה-RAID יפצל אותן לגישות אקראיות על פני מספר דיסקים פיזיים, מה שעשוי להפחית את הביצועים הכוללים אך יגביר את עמידות הנתונים. מערכת ההפעלה עדיין תדווח על ביצועים סדרתיים.", "ג. מערכת ההפעלה רואה את הדיסק כסדרתי ואינה מודעת לפיצול. בפועל, מנגנון ה-RAID יבצע קריאות מקבילות למספר דיסקים פיזיים שונים עבור סקטורים לוגיים עוקבים, ובכך ישפר את קצב ההעברה הכולל בהשוואה לדיסק פיזי יחיד, למרות שהגישה לכל דיסק פיזי בנפרד עשויה להיות אקראית למדי.", "ד. הגישה הסדרתית לדיסק הלוגי תתורגם באופן ישיר לגישה סדרתית ורציפה על דיסק פיזי יחיד, שכן מנגנון ה-RAID נועד לאחד את הדיסקים הפיזיים ליחידה אחת המבצעת פעולות כאילו הייתה דיסק בודד וענק. מערכת ההפעלה תבחין בשיפור בביצועים אך לא תבין את המנגנון."]}, "solution": {"correct_option": "ג", "explanation": "התשובה הנכונה היא ג'. ההסבר לכך מתבסס על עקרונות ה-RAID כפי שתוארו בחומר הקורס, ובמיוחד על המודל השקוף למערכת ההפעלה ועל פיצול הנתונים (stripping) לשיפור ביצועים.\n\n1.  **תפיסת מערכת ההפעלה:** חומר הקורס מציין במפורש כי \"raid שקוף לחלוטין עבור מערכת ההפעלה, כי היא בטוחה שהיא שולחת אליו רק סקטור אחד\" וכי \"מערכת ההפעלה והתוכנית שלנו רואות משהו בלו בלוקים/סקטורים... מבחינתנו יש הארד דיסק אחד\". לכן, מערכת ההפעלה תמיד תתפוס את הגישה לדיסק הלוגי כסדרתית, כפי שהיא מבקשת, ואינה מודעת לכך שמדובר במערך דיסקים פיזיים או לפיצול הנתונים. זה תואם את הרישא של אפשרות ג' ופוסל חלקים מאפשרות ב' ו-ד' לגבי מודעות מערכת ההפעלה.\n\n2.  **פעולת מנגנון ה-RAID:** כאשר מערכת ההפעלה מבקשת קריאות סדרתיות לסקטורים לוגיים עוקבים, ומנגנון ה-RAID מבצע \"פיצול נתונים\" (stripping), הוא מפזר את הסקטורים הלוגיים העוקבים על פני דיסקים פיזיים שונים. לדוגמה, סקטור 0 לדיסק פיזי 1, סקטור 1 לדיסק פיזי 2, וכן הלאה. פיצול זה מאפשר למנגנון ה-RAID לבצע קריאות וכתיבות מקבילות למספר דיסקים פיזיים בו-זמנית (\"הוא יפצל את הנתונים... ויביא לנו את הביצועים באופן שקוף\"). פעולה מקבילה זו משפרת באופן מהותי את קצב ההעברה הכולל (throughput) בהשוואה לדיסק פיזי יחיד, כיוון שהיא מאפשרת לבצע מספר פעולות I/O במקביל. זה תואם את החלק השני של אפשרות ג' לגבי קריאות מקבילות ושיפור קצב ההעברה.\n\n3.  **תבנית הגישה לדיסקים הפיזיים:** למרות שהקריאה הלוגית היא סדרתית, הגישה לכל דיסק פיזי בנפרד אינה בהכרח סדרתית במובן הפיזי (כלומר, קריאה מטראקים סמוכים). אם למשל ישנם N דיסקים, דיסק פיזי אחד יקבל את סקטור 0, ואז את סקטור N, ואז את סקטור 2N וכו'. גישה זו, שבה ראש הדיסק קופץ בין מיקומים שונים בדיסק כדי לקרוא את הסקטורים המוקצים לו, עשויה להיחשב \"אקראית למדי\" מהפרספקטיבה של אופטימיזציית תנועת ראש הדיסק הבודד. לכן, אפשרות ג' מדגישה נכון את השיפור בביצועים הכוללים ואת טבעה של הגישה לכל דיסק פיזי בנפרד.\n\nאפשרות א' שגויה כיוון ש-RAID עם פיצול נתונים אינו מתרגם קריאה סדרתית לדיסק לוגי לקריאה סדרתית על דיסק פיזי יחיד; הוא מפזר אותה. אפשרות ב' שגויה בחלקה - הפיצול נועד בדרך כלל לשפר ביצועים (ב-RAID 0), לא להפחית אותם, והוא לא בהכרח מגביר עמידות נתונים (תלוי ברמת ה-RAID, והשאלה מתמקדת בפיצול בלבד). אפשרות ד' שגויה כיוון שהיא טוענת שהגישה תהיה סדרתית ורציפה על דיסק פיזי יחיד, מה שמנוגד לעיקרון הפיצול של נתונים על פני מספר דיסקים."}, "_source_file": "0420__Disks__Device_Model__MC__Hard.json", "_topic_hint": "Device Model", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:35:33", "_subject": "Disks", "_context_lectures": [17, 18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Hard Disk Performance"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, מהי אחת הדרכים העיקריות בהן מנגנון RAID-0 משפר את ביצועי הדיסק?", "code_snippet": null, "options": ["א. הוא משפר את הביצועים באופן משמעותי על ידי ניצול מקבילי של מספר דיסקים.", "ב. הוא מבטיח אמינות נתונים גבוהה יותר על ידי יצירת עותקים זהים של הנתונים.", "ג. הוא מאפשר פעולות כתיבה אטומיות על פני מספר סקטורים בו-זמנית.", "ד. הוא משפר ביצועים רק בקריאות סדרתיות, אך אינו משפיע על קריאות אקראיות."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מציין במפורש כי \"הביצועים שלו (של RAID-0) מעולים. ברגע שאנחנו משתמשים בכל הדיסקים, אנחנו יכולים להשתמש בהם לרוב במקביל, ולשפר את הביצועים באופן משמעותי.\" וכן \"כלומר, ה-raid-0 משפר לנו משמעותית את הביצועים (כפול N למעשה).\".\nאפשרות ב' שגויה מכיוון ש-RAID-0 אינו מספק אמינות או יתירות נתונים; למעשה, הוא מגדיל את הסיכון לאובדן נתונים אם אחד הדיסקים נכשל, כפי שמשתמע מהעובדה שאין בו זוגיות (parity).\nאפשרות ג' שגויה מכיוון שהבטחת אטומיות על פני מספר סקטורים אינה קשורה ל-RAID-0 ואינה מובטחת על ידי החומרה עבור פעולות על יותר מסקטור אחד.\nאפשרות ד' שגויה מכיוון שחומר ההרצאה מציין במפורש ש-RAID-0 משפר ביצועים הן בקריאות סדרתיות (N*S mb/sec) והן בקריאות אקראיות (N*S mb/sec)."}, "_source_file": "0421__Disks__Hard_Disk_Performance__MC__Easy.json", "_topic_hint": "Hard Disk Performance", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:35:44", "_subject": "Disks", "_context_lectures": [17, 18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Hard Disk Performance"], "difficulty_estimation": "Easy", "content": {"text": "איזו טענה נכונה לגבי ביצועי דיסקים קשיחים (hard disks) על פי חומר ההרצאה?", "code_snippet": null, "options": ["א. דיסקים קשיחים הם תמיד מהירים מאוד, במיוחד כאשר הם פועלים במהירותם האופטימלית.", "ב. גם כאשר דיסק קשיח פועל במהירותו האופטימלית, הוא עדיין נחשב לאיטי יחסית.", "ג. מנגנון RAID-0 אינו משפר את ביצועי הקריאה הסדרתית (sequential read) של דיסקים קשיחים.", "ד. החומרה של הדיסק מבטיחה שבעת ביצוע פעולה על מספר סקטורים בבת אחת, או שהכל נכתב או ששום דבר לא נכתב."]}, "solution": {"correct_option": "ב", "explanation": "חומר ההרצאה מציין במפורש: 'עם כל השיפורים הללו, הדיסק עדיין איטי. גם דיסק שהמהירות האופטימלית שלו היא 125MB/sec, זה עדיין איטי, ונדיר גם שנגיע לזה.' לכן, גם במהירותו האופטימלית, דיסק קשיח נחשב לאיטי. אפשרות א' שגויה כיוון שהיא סותרת זאת. אפשרות ג' שגויה כיוון שההרצאה מציינת כי RAID-0 משפר ביצועים באופן משמעותי, לרבות קריאה סדרתית (הביצועים יכולים להגיע ל-N*S mb/sec). אפשרות ד' שגויה כיוון שההרצאה קובעת כי 'החומרה שלנו לא מבטיחה לנו שום דבר' לגבי פעולות על מספר סקטורים, וייתכן שאחד ייכתב והשני ייכשל, בניגוד להבטחה על סקטור בודד."}, "_source_file": "0422__Disks__Hard_Disk_Performance__MC__Easy.json", "_topic_hint": "Hard Disk Performance", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:35:56", "_subject": "Disks", "_context_lectures": [17, 18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Hard Disk Performance"], "difficulty_estimation": "Easy", "content": {"text": "מהי אחת מהמאפיינים המרכזיים של ביצועי דיסק קשיח, כפי שתוארו בחומר ההרצאה?", "code_snippet": null, "options": ["א. דיסקים קשיחים תמיד מגיעים למהירותם האופטימלית בקלות.", "ב. דיסקים קשיחים נחשבים מהירים יותר מזיכרון הראשי (RAM).", "ג. דיסקים קשיחים נחשבים איטיים, וקשה להגיע למהירותם האופטימלית בפועל.", "ד. מהירות הקריאה והכתיבה של דיסקים קשיחים זהה לחלוטין לקריאה וכתיבה אקראית."]}, "solution": {"correct_option": "ג", "explanation": "חומר ההרצאה מציין במפורש כי 'הדיסק עדיין איטי. גם דיסק שהמהירות האופטימלית שלו היא 125MB/sec, זה עדיין איטי, ונדיר גם שנגיע לזה.' משמעות הדבר היא שדיסקים קשיחים נחשבים איטיים יחסית, וגם כשיש להם מהירות אופטימלית תיאורטית, בפועל קשה להגיע אליה. לכן, תשובה ג' היא הנכונה. תשובה א' שגויה כי נדיר להגיע למהירות האופטימלית. תשובה ב' שגויה משום שהטקסט מציין שהדיסק 'עדיין איטי', מה שמרמז על איטיות יחסית למרכיבים אחרים כמו זיכרון ראשי. תשובה ד' אינה נכונה, שכן מהירות קריאה סדרתית (S) ומהירות קריאה אקראית (R) אינן זהות, ולרוב S > R."}, "_source_file": "0423__Disks__Hard_Disk_Performance__MC__Easy.json", "_topic_hint": "Hard Disk Performance", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:36:05", "_subject": "Disks", "_context_lectures": [17, 18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Hard Disk Performance"], "difficulty_estimation": "Easy", "content": {"text": "איזו מהטענות הבאות מתארת נכונה את היתרון העיקרי של RAID-0 בהקשר לביצועי דיסק קשיח?", "code_snippet": null, "options": ["א. RAID-0 מבטיח אמינות גבוהה במקרה של כשל דיסק בודד.", "ב. RAID-0 משפר משמעותית את מהירות הקריאה והכתיבה על ידי פיצול נתונים בין דיסקים מרובים.", "ג. RAID-0 מאפשר פעולות אטומיות על מספר סקטורים בו-זמנית, מה שאינו מובטח בחומרה הרגילה.", "ד. RAID-0 מקטין את עומס העבודה על הדיסק המהיר ביותר במערכת על ידי שימוש בדיסק זוגיות."]}, "solution": {"correct_option": "ב", "explanation": "RAID-0, כפי שמתואר בחומר ההרצאה, הוא מנגנון שמטרתו העיקרית היא לשפר ביצועים. הוא עושה זאת על ידי פיצול המידע (stripping) על פני מספר דיסקים, ובכך מאפשר לבצע פעולות קריאה וכתיבה במקביל על כל הדיסקים. כתוצאה מכך, הביצועים משתפרים משמעותית, ואף יכולים להגיע לפי N (מספר הדיסקים) מקצב העברת הנתונים של דיסק בודד, הן בקריאה סדרתית והן בקריאה אקראית (N*S mb/sec), כפי שמצוין בפירוש בחומר."}, "_source_file": "0424__Disks__Hard_Disk_Performance__MC__Easy.json", "_topic_hint": "Hard Disk Performance", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:36:15", "_subject": "Disks", "_context_lectures": [17, 18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Hard Disk Performance"], "difficulty_estimation": "Medium", "content": {"text": "בהתבסס על חומר ההרצאה, מהו היתרון העיקרי של מערך RAID 0 בהשוואה לדיסק קשיח בודד, בהקשר של ביצועים?", "code_snippet": null, "options": ["א. הוא משפר משמעותית את מהירות הקריאה והכתיבה על ידי חלוקת הנתונים בין מספר דיסקים וביצוע פעולות I/O במקביל, עד פי N, כאשר N הוא מספר הדיסקים.", "ב. הוא מספק עמידות גבוהה בפני תקלות דיסק בודד באמצעות שמירת נתונים כפולים או נתוני זוגיות (parity) על דיסקים שונים.", "ג. הוא מאפשר גישה מהירה יותר לנתונים על ידי אופטימיזציה של זמן החיפוש (seek time) באמצעות אלגוריתמים מתקדמים של תזמון ראשים.", "ד. הוא מפחית את העומס על יחידת העיבוד המרכזית (CPU) על ידי ביצוע פעולות ניהול דיסק באופן עצמאי באמצעות בקר חומרה ייעודי."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מציין במפורש כי RAID 0 נועד לשפר ביצועים באופן משמעותי. הוא עושה זאת על ידי חלוקת המידע בין כל הדיסקים במערך וביצוע פעולות במקביל, מה שמוביל לשיפור של 'כפול N למעשה' במהירות הקריאה והכתיבה (כאשר N הוא מספר הדיסקים). לכן, אופציה א' מתארת בצורה מדויקת את היתרון העיקרי של RAID 0 בביצועים.\nאופציה ב' שגויה מכיוון שההרצאה מציינת במפורש ש-RAID 0 'רק מחלקים את המידע לשם ביצועים' ואין בו מנגנון זוגיות או יתירות לאמינות (בניגוד ל-RAID-ים אחרים).\nאופציות ג' ו-ד' מתארות מנגנוני אופטימיזציה שאינם היתרון העיקרי והמפורש של RAID 0 כפי שתואר בחומר ההרצאה, אשר מתמקד בחלוקה מקבילית של הנתונים."}, "_source_file": "0425__Disks__Hard_Disk_Performance__MC__Medium.json", "_topic_hint": "Hard Disk Performance", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:36:27", "_subject": "Disks", "_context_lectures": [17, 18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Hard Disk Performance"], "difficulty_estimation": "Medium", "content": {"text": "איזו טענה מתארת בצורה הטובה ביותר את המאפיינים העיקריים של RAID 0 בהקשר של ביצועי מערכת אחסון דיסקים קשיחים?", "code_snippet": null, "options": ["א. הוא משפר משמעותית את מהירות הקריאה והכתיבה על ידי פיצול נתונים בין דיסקים מרובים וביצוע פעולות במקביל, אך אינו מספק הגנה מפני כשל דיסק.", "ב. הוא מבטיח יתירות נתונים מלאה המאפשרת המשך פעולה במקרה של כשל דיסק יחיד, תוך שיפור זניח בביצועים.", "ג. הוא מאפשר אחסון נתונים על דיסק אחד בלבד ומנצל דיסקים נוספים לגיבוי בלעדי.", "ד. הוא משפר את ביצועי הקריאה הסדרתית בלבד, ואינו משפיע על ביצועי קריאה אקראית או כתיבה."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'.\nRAID 0, כפי שמתואר בחומר ההרצאה, הוא מנגנון שמטרתו העיקרית היא שיפור ביצועים. הוא עושה זאת על ידי פיצול המידע (striping) בין מספר דיסקים, מה שמאפשר לבצע פעולות קריאה וכתיבה במקביל על פני כל הדיסקים. הדבר מוביל לשיפור משמעותי בביצועים, למשל, N*S mb/sec עבור קריאה סדרתית ו-N*R mb/sec עבור קריאה אקראית, כאשר N הוא מספר הדיסקים. עם זאת, RAID 0 אינו כולל מנגנוני זוגיות (parity) או יתירות נתונים, ולכן הוא אינו מספק הגנה מפני כשל דיסק יחיד; כשל כזה יגרום לאובדן נתונים.\nאפשרויות ב', ג' ו-ד' שגויות:\n*   אפשרות ב' שגויה מכיוון ש-RAID 0 אינו מספק יתירות נתונים ואינו מגן מפני כשל דיסק, וכן הביצועים שלו משופרים משמעותית ולא באופן זניח.\n*   אפשרות ג' שגויה מכיוון ש-RAID 0 משתמש במספר דיסקים לאחסון הנתונים בפיצול, ולא בדיסק אחד בלבד עם גיבוי נפרד.\n*   אפשרות ד' שגויה מכיוון ש-RAID 0 משפר הן את ביצועי הקריאה הסדרתית והן את ביצועי הקריאה האקראית (ואף הכתיבה), ולא רק את הקריאה הסדרתית."}, "_source_file": "0426__Disks__Hard_Disk_Performance__MC__Medium.json", "_topic_hint": "Hard Disk Performance", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:36:41", "_subject": "Disks", "_context_lectures": [17, 18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Hard Disk Performance"], "difficulty_estimation": "Medium", "content": {"text": "לפי חומר הקורס, מהו היתרון המרכזי של שימוש במערך RAID-0 בהקשר של ביצועי דיסק קשיח?", "code_snippet": null, "options": ["א. הוא משפר את אמינות הדיסק על ידי שמירת עותקים זהים של נתונים במספר דיסקים.", "ב. הוא מגדיל באופן משמעותי את מהירויות הקריאה והכתיבה על ידי פיצול נתונים בין מספר דיסקים.", "ג. הוא מבטיח אטומיות עבור פעולות כתיבה או קריאה המשתרעות על פני מספר סקטורים.", "ד. הוא מפחית את צריכת החשמל הכוללת של מערכת הדיסקים."]}, "solution": {"correct_option": "ב", "explanation": "מערך RAID-0 (המכונה גם Striping) מתוכנן במיוחד לשיפור ביצועי קריאה וכתיבה. על ידי פיצול הנתונים (striping) על פני מספר דיסקים, המערכת יכולה לבצע פעולות קריאה וכתיבה במקביל על פני כל הדיסקים. כפי שצוין בחומר הקורס, ביצועים אלו יכולים להגיע ל-N*S MB/sec, כאשר N הוא מספר הדיסקים ו-S היא מהירות הקריאה הסדרתית של דיסק בודד, ובכך לשפר משמעותית את מהירות העבודה (כפול N למעשה). אפשרות א' אינה נכונה מכיוון ש-RAID-0 אינו מספק יתרונות אמינות או יתירות (אין בו מנגנון זוגיות או שיקוף). אפשרות ג' אינה נכונה מכיוון שחומרת הדיסק מבטיחה אטומיות רק לפעולות על סקטור בודד, ו-RAID-0 אינו משנה הבטחה זו עבור מספר סקטורים. אפשרות ד' אינה נכונה מכיוון שהפחתת צריכת חשמל אינה יתרון מרכזי או מוזכר של RAID-0 בחומר הלימוד."}, "_source_file": "0427__Disks__Hard_Disk_Performance__MC__Medium.json", "_topic_hint": "Hard Disk Performance", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:36:53", "_subject": "Disks", "_context_lectures": [17, 18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Hard Disk Performance"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על חומר ההרצאה, איזו טענה הבאה מתארת בצורה המדויקת ביותר את שיפור הביצועים של מערך RAID-0 (Striping) המורכב מ-N דיסקים, בהשוואה לביצועי דיסק בודד?", "code_snippet": null, "options": ["א. הן קריאה סדרתית והן קריאה אקראית משיגות שיפור ביצועים ליניארי ביחס למספר הדיסקים (N), כאשר מהירות הקריאה האפקטיבית עבור שני סוגי הגישה יכולה להגיע ל- N*S מגה-בתים לשנייה, כאשר S מייצג את מהירות הקריאה הסדרתית של דיסק בודד.", "ב. קריאה סדרתית משתפרת ל- N*S מגה-בתים לשנייה, אך קריאה אקראית משתפרת ל- N*R מגה-בתים לשנייה, כאשר R מייצג את מהירות הקריאה האקראית של דיסק בודד.", "ג. RAID-0 משמש בעיקר לשיפור אמינות הדיסקים על ידי חלוקת הנתונים, ואינו מספק שיפור משמעותי בביצועים מעבר לדיסק בודד, במיוחד בגלל היעדר יתירות.", "ד. שיפור הביצועים ב-RAID-0 מתבטא בעיקר בקריאות סדרתיות, בעוד שביצועי קריאות אקראיות נשארים דומים לאלו של דיסק בודד, מכיוון שהגישה לסקטורים מפוזרים אינה ניתנת לניצול מקבילי יעיל."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מציין במפורש כי מערך RAID-0 משפר את הביצועים באופן משמעותי על ידי ניצול מקבילי של כל הדיסקים. עבור קריאה סדרתית, נאמר כי הביצועים מגיעים ל- N*S מגה-בתים לשנייה. באופן קריטי, ההרצאה מציינת גם כי 'כנ\"ל גם לגבי קריאה אקראית' וכי 'מדובר על N*S mb/sec' גם עבור קריאות אקראיות (כאשר N הוא מספר הדיסקים ו-S היא מהירות הקריאה הסדרתית של דיסק בודד).\n\n- **א. נכון** – אפשרות זו משקפת במדויק את התיאור בחומר ההרצאה לפיו 'הן קריאה סדרתית והן קריאה אקראית' משיגות ביצועים של N*S מגה-בתים לשנייה.\n- **ב. לא נכון** – למרות שבאופן כללי RAID-0 משפר קריאה אקראית ב-N*R, חומר ההרצאה הספציפי קובע במפורש 'N*S mb/sec' גם עבור קריאות אקראיות, מה שהופך טענה זו ללא מדויקת בהקשר של החומר הנתון.\n- **ג. לא נכון** – חומר ההרצאה מציין בבירור ש-RAID-0 משמש 'לשם ביצועים' וכי 'הביצועים שלו מעולים', וכי 'אין יתירות' (Parity) במערך זה, מה שאומר שהוא אינו משפר אמינות אלא פוגע בה.\n- **ד. לא נכון** – חומר ההרצאה מציין במפורש שגם קריאות אקראיות משתפרות משמעותית ('כנ\"ל גם לגבי קריאה אקראית') ומגיעות לביצועים של N*S מגה-בתים לשנייה, ולא נשארות דומות לדיסק בודד."}, "_source_file": "0429__Disks__Hard_Disk_Performance__MC__Hard.json", "_topic_hint": "Hard Disk Performance", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:37:24", "_subject": "Disks", "_context_lectures": [17, 18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Hard Disk Performance"], "difficulty_estimation": "Hard", "content": {"text": "בהתחשב באתגרי הביצועים המובנים של דיסקים קשיחים בודדים (כגון מהירות תפוקה נמוכה יחסית), כיצד מערך RAID-0 משפר באופן יסודי את ביצועי הקריאה והכתיבה?", "code_snippet": null, "options": ["א. RAID-0 משפר את הביצועים על ידי חלוקת הנתונים לרצועות (striping) על פני מספר דיסקים וביצוע פעולות קריאה/כתיבה במקביל על כל הדיסקים, מה שמגדיל את רוחב הפס הכולל באופן ליניארי למספר הדיסקים (N).", "ב. RAID-0 מתמקד בשיפור האמינות על ידי שכפול נתונים על פני דיסקים מרובים, ובכך מבטיח המשכיות פעולה וזמינות גבוהה יותר גם במקרה של כשל חומרה.", "ג. היתרון הביצועי המרכזי של RAID-0 נובע משימוש בדיסק ייעודי לאחסון מידע זוגיות (parity), אשר מאפשר שחזור מהיר של נתונים פגומים ומפחית את עומס העבודה על הדיסקים הפעילים.", "ד. RAID-0 משפר ביצועים על ידי הבטחת אטומיות מלאה עבור פעולות קריאה וכתיבה המשתרעות על פני מספר סקטורים, ובכך מייעל את הטיפול בשגיאות ומפחית את הצורך בסנכרון."]}, "solution": {"correct_option": "א", "explanation": "הסבר: מערך RAID-0 (Striping) משפר באופן משמעותי את ביצועי הדיסק על ידי חלוקת הנתונים לרצועות קטנות הנכתבות ונלכדות במקביל על פני מספר דיסקים פיזיים. כפי שמצוין בחומר ההרצאה, 'ברגע שאנחנו משתמשים בכל הדיסקים, אנחנו יכולים להשתמש בהם לרוב במקביל, ולשפר את הביצועים באופן משמעותי'. הדבר מאפשר להגדיל את רוחב הפס הכולל של המערכת באופן פרופורציונלי למספר הדיסקים (N), ומכאן ההצהרה 'ה-raid-0 משפר לנו משמעותית את הביצועים (כפול N למעשה)'. אפשרות ב' אינה נכונה מכיוון ש-RAID-0 אינו מספק אמינות נתונים או יתירות; הוא נועד לביצועים בלבד ('פה רק מחלקים את המידע לשם ביצועים'). אפשרות ג' מתארת רמות RAID אחרות המשתמשות בזוגיות (parity) להגברת אמינות, תכונה שאינה קיימת ב-RAID-0. אפשרות ד' שגויה, שכן חומר ההרצאה מציין שהחומרה מבטיחה אטומיות רק עבור פעולות על סקטור בודד, ולא על פני מספר סקטורים בו-זמנית, ו-RAID-0 אינו פותר בעיה זו."}, "_source_file": "0430__Disks__Hard_Disk_Performance__MC__Hard.json", "_topic_hint": "Hard Disk Performance", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:37:44", "_subject": "Disks", "_context_lectures": [17, 18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Hard Disk Performance"], "difficulty_estimation": "Hard", "content": {"text": "על פי חומר ההרצאה, מהי ההצהרה הנכונה ביותר לגבי שיפורי הביצועים של מערך RAID-0 (Striping) המורכב מ-N דיסקים, בהשוואה לדיסק בודד? נניח ש-S היא מהירות הקריאה הסדרתית של דיסק בודד, ו-R היא מהירות הקריאה האקראית של דיסק בודד (כאשר S > R).", "code_snippet": null, "options": ["א. קריאה סדרתית משתפרת למהירות של N*S MB/sec, אך קריאה אקראית משתפרת לכל היותר ל-N*R MB/sec.", "ב. גם קריאה סדרתית וגם קריאה אקראית משתפרות באופן משמעותי, כאשר הביצועים הכוללים מגיעים ל-N*S MB/sec עבור שני סוגי הקריאות.", "ג. הביצועים של RAID-0 משתפרים בעיקר עבור קריאות אקראיות, בעוד שקריאות סדרתיות אינן מרוויחות באופן ליניארי מתוספת דיסקים.", "ד. RAID-0 מספק שיפור אמינות משמעותי על ידי חלוקת נתונים, ולכן שיפורי הביצועים הם משניים ולא ליניאריים."]}, "solution": {"correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. חומר ההרצאה מציין במפורש כי ב-RAID-0, כאשר יש N דיסקים, הביצועים משתפרים פי N. עבור קריאה סדרתית, נאמר שניתן להגיע ל-N*S MB/sec. עבור קריאה אקראית, נאמר במפורש: \"כנ\"ל גם לגבי קריאה אקראית... מדובר על N*S mb/sec\", מה שמעיד על כך שגם קריאות אקראיות מגיעות לאותה מהירות תיאורטית של N*S MB/sec, על אף שהמהירות הבסיסית של קריאה אקראית מדיסק בודד (R) נמוכה יותר ממהירות קריאה סדרתית (S). ההרצאה מדגישה ש-RAID-0 משפר משמעותית את הביצועים \"כפול N למעשה\" על ידי ניצול מקבילי של כל הדיסקים. אפשרויות א', ג' ו-ד' אינן תואמות במדויק את הניסוח והמספרים שהוצגו בחומר ההרצאה לגבי ביצועי RAID-0. במיוחד, אפשרות א' שגויה משום שההרצאה מציינת N*S MB/sec גם עבור קריאה אקראית, ולא N*R MB/sec."}, "_source_file": "0431__Disks__Hard_Disk_Performance__MC__Hard.json", "_topic_hint": "Hard Disk Performance", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:38:05", "_subject": "Disks", "_context_lectures": [17, 18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Hard Disk Performance"], "difficulty_estimation": "Hard", "content": {"text": "בהינתן מערך RAID 0 המורכב מ-N דיסקים, ובהינתן שמהירות קריאה סדרתית מדיסק בודד היא S MB/sec ומהירות קריאה אקראית היא R MB/sec, כאשר ידוע ש-S > R. איזו מהטענות הבאות מתארת נכונה את ביצועי הקריאה של מערך ה-RAID 0?", "code_snippet": null, "options": ["א. ביצועי קריאה סדרתית הם N*S MB/sec, ואילו ביצועי קריאה אקראית הם N*R MB/sec.", "ב. גם ביצועי קריאה סדרתית וגם ביצועי קריאה אקראית הם N*S MB/sec.", "ג. ביצועי קריאה סדרתית הם N*R MB/sec, ואילו ביצועי קריאה אקראית הם N*S MB/sec.", "ד. ביצועי קריאה סדרתית ואקראית כאחד אינם משתפרים משמעותית ב-RAID 0 מכיוון שאין מנגנון זוגיות (parity) לשיפור ביצועים."]}, "solution": {"correct_option": "ב", "explanation": "החומר המצורף קובע במפורש כי עבור קריאה סדרתית במערך RAID 0 עם N דיסקים, הביצועים הם N*S MB/sec. באופן דומה, החומר מציין במפורש כי גם עבור קריאה אקראית, הביצועים של מערך ה-RAID 0 הם N*S MB/sec, למרות שמהירות קריאה אקראית מדיסק בודד (R) נמוכה בדרך כלל ממהירות קריאה סדרתית (S). הטקסט מדגיש כי ב-RAID 0 \"מנצלים את כל הדיסקים ומשפרים את הביצועים באופן משמעותי\" פי N, ומציין את N*S MB/sec לשני סוגי הקריאות. לכן, אפשרות ב' היא הנכונה ביותר לפי החומר."}, "_source_file": "0432__Disks__Hard_Disk_Performance__MC__Hard.json", "_topic_hint": "Hard Disk Performance", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:38:21", "_subject": "Disks", "_context_lectures": [17, 18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Sequential vs Random Access"], "difficulty_estimation": "Easy", "content": {"text": "מדוע גישה סדרתית (sequential access) לדיסק קשיח היא לרוב מהירה יותר מגישה אקראית (random access)?", "code_snippet": null, "options": ["א. גישה סדרתית מפחיתה באופן משמעותי את זמני החיפוש (seek time) ואת זמני ההמתנה לסיבוב (rotational latency).", "ב. גישה סדרתית מאפשרת דחיסת נתונים טובה יותר על הדיסק, ובכך מקצרת את זמן ההעברה.", "ג. גישה סדרתית דורשת פחות משאבי מעבד לצורך ניהול בקשות ה-I/O.", "ד. גישה סדרתית מאפשרת לדיסק לבצע קריאות וכתיבות במקביל באופן טבעי יותר."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, זמן פעולת I/O מורכב בעיקר מזמן חיפוש (seek time) וזמן המתנה לסיבוב (rotational latency), בעוד שזמן העברת המידע עצמו זניח יחסית ($T_{I/O} = T_{seek} + T_{rotation} + T_{transfer}$). גישה סדרתית לנתונים ממוקמים ברצף על הדיסק מפחיתה את הצורך בתנועה רבה של ראש הקריאה/כתיבה (seek) וממזערת את זמן ההמתנה למיקום הנכון על הפלטה (rotation). חומר ההרצאה אף מציין במפורש כי מהירות קריאה סדרתית (S) גבוהה יותר ממהירות קריאה אקראית (R), כלומר S > R. לכן, הפחתת זמני ה-seek וה-rotation היא הסיבה העיקרית ליתרון בביצועים של גישה סדרתית."}, "_source_file": "0433__Disks__Sequential_vs_Random_Access__MC__Easy.json", "_topic_hint": "Sequential vs Random Access", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:38:34", "_subject": "Disks", "_context_lectures": [17, 18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Sequential vs Random Access"], "difficulty_estimation": "Easy", "content": {"text": "מהי הטענה הנכונה ביותר לגבי ביצועי קריאה סדרתית (Sequential Read) לעומת קריאה אקראית (Random Read) בדיסק קשיח בודד?", "code_snippet": null, "options": ["א. קריאה סדרתית מהירה יותר מקריאה אקראית, בעיקר בשל צמצום זמני ה-seek וה-rotation.", "ב. קריאה אקראית מהירה יותר מקריאה סדרתית, מכיוון שהדיסק יכול לגשת לנתונים בכל סדר.", "ג. אין הבדל משמעותי בביצועים בין קריאה סדרתית לאקראית בדיסק קשיח, מכיוון שזמן ה-transfer הוא זניח.", "ד. קריאה סדרתית איטית יותר מקריאה אקראית, עקב הצורך לעבד את הנתונים לפי סדר קפדני."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה (הרצאה 18, קטע 34), מצוין במפורש שקצב קריאה סדרתית (S) גבוה יותר מקצב קריאה אקראית (R) בדיסק בודד (S>R). הסיבה העיקרית לכך, כפי שמפורט בהרצאה 17, קטע 38, היא שזמן ה-I/O הכולל ($T_{I/O}$) נשלט על ידי זמני ה-seek וה-rotation. בגישה סדרתית, ראש הקריאה/כתיבה נע באופן מינימלי וההמתנה לסיבוב הדיסק מצטמצמת משמעותית, מה שמפחית את התקורה של זמנים אלו בהשוואה לגישה אקראית, בה הראש צריך למקם את עצמו מחדש לעיתים קרובות ולחכות לסקטורים שונים."}, "_source_file": "0434__Disks__Sequential_vs_Random_Access__MC__Easy.json", "_topic_hint": "Sequential vs Random Access", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:38:46", "_subject": "Disks", "_context_lectures": [17, 18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Sequential vs Random Access"], "difficulty_estimation": "Easy", "content": {"text": "למה דיסק קשיח עשוי לבחור לטפל בבקשות קריאה/כתיבה בסדר שונה מהסדר שבו התקבלו, לדוגמה לטפל בסקטור 8 לפני סקטורים 10, 11, 12 למרות שסקטור 8 התבקש אחרון?", "code_snippet": null, "options": ["א. כדי לשמור על פעולה סדרתית ככל הניתן ובכך לשפר יעילות.", "ב. כדי למנוע הרעבה (starvation) של בקשות מרוחקות.", "ג. מכיוון שהדיסק אינו יודע את משך הזמן של כל פעולה מראש.", "ד. על מנת להבטיח עקביות נתונים במקרה של כיבוי מערכת פתאומי."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין בשיעור 18 (chunk 13) מסביר כי ההארד דיסק יודע לעבור על בקשות קריאה וכתיבה ולטפל בהן בסדר שהוא בוחר, במטרה לשמור על פעולה סדרתית ככל הניתן. הדוגמה המובאת היא טיפול בסקטור 8 לפני סקטורים 10, 11, 12, למרות סדר קבלתם, \"כדי לשמור על פעולה סדרתית\". גישה סדרתית יעילה יותר מגישה אקראית בדיסקים מכניים, כפי שגם מרומז בכך שמהירות קריאה סדרתית (S) גבוהה ממהירות קריאה אקראית (R) ב-raid-0 (שיעור 18 chunk 34). אפשרות ב' אינה הסיבה העיקרית לשינוי סדר זה בדוגמה הנתונה. אפשרות ג' אינה נכונה, שכן החומר מציין שהדיסק 'יודע בדיוק כמה זמן כל פעולה תיקח'. אפשרות ד' מתארת סיכון או אתגר בגישות מסוימות, ולא את הסיבה לביצוע סדר פעולות סדרתי."}, "_source_file": "0435__Disks__Sequential_vs_Random_Access__MC__Easy.json", "_topic_hint": "Sequential vs Random Access", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:39:03", "_subject": "Disks", "_context_lectures": [17, 18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Sequential vs Random Access"], "difficulty_estimation": "Easy", "content": {"text": "מדוע גישה סדרתית (Sequential Access) לדיסק קשיח יעילה יותר באופן כללי מגישה אקראית (Random Access)?", "code_snippet": null, "options": ["א. היא מפחיתה באופן משמעותי את זמן ה-seek ואת זמן ההמתנה לסיבוב (rotational latency).", "ב. היא מאפשרת לדיסק לטפל בבקשות בכל סדר שיבחר.", "ג. היא מקטינה את נפח האחסון הכולל של הדיסק.", "ד. היא דורשת פחות צריכת חשמל מהדיסק."]}, "solution": {"correct_option": "א", "explanation": "הגישה הסדרתית לדיסק קשיח יעילה יותר מגישה אקראית מכיוון שהיא מפחיתה באופן דרמטי את הצורך בתנועה פיזית של ראש הקריאה/כתיבה (seek time) ואת זמן ההמתנה לסיבוב (rotational latency). חומר ההרצאה מציין כי $T_{I/O} = T_{seek} + T_{rotation} + T_{transfer}$ וכי $T_{seek}$ ו-$T_{rotation}$ הם הגורמים המשמעותיים ביותר בזמן הגישה לדיסק. בגישה סדרתית, ראש הדיסק נע ברצף על פני סקטורים סמוכים, מה שממזער את ההשהיות הללו. בגישה אקראית, לעומת זאת, הראש נאלץ לנוע למקומות שונים בדיסק עבור כל בקשה, מה שמוביל לזמני seek ו-rotation ארוכים יותר ולביצועים נמוכים יותר (כפי שמצוין כי מהירות קריאה סדרתית, S, גדולה ממהירות קריאה אקראית, R, כלומר S > R)."}, "_source_file": "0436__Disks__Sequential_vs_Random_Access__MC__Easy.json", "_topic_hint": "Sequential vs Random Access", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:39:15", "_subject": "Disks", "_context_lectures": [17, 18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Sequential vs Random Access"], "difficulty_estimation": "Medium", "content": {"text": "מהו הגורם העיקרי להבדל בביצועים בין גישה סדרתית (Sequential Access) לגישה אקראית (Random Access) לדיסק קשיח?", "code_snippet": null, "options": ["א. גישה סדרתית מפחיתה באופן משמעותי את הצורך בתנועת ראש הקריאה/כתיבה (seek time) וזמן ההמתנה לסיבוב הדיסק (rotational latency), שהם המרכיבים הדומיננטיים בזמן ה-I/O.", "ב. בגישה סדרתית, הדיסק יכול להעביר יותר מידע בכל פעולת העברה (transfer time), מה שמגדיל את קצב ה-I/O.", "ג. בגישה אקראית, מערכת ההפעלה אינה יכולה ליישם אלגוריתמי תזמון יעילים כמו Shortest Seek Time First (SSTF) ולכן הביצועים יורדים.", "ד. גישה סדרתית מאפשרת ניצול מקבילי של מספר דיסקים במערכי RAID, בעוד שגישה אקראית אינה מאפשרת זאת."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין בשיעור מבהיר כי זמן ה-I/O לדיסק מורכב בעיקר מזמן תנועת ראש הקריאה/כתיבה (seek time) וזמן ההמתנה לסיבוב הדיסק (rotational latency), כאשר זמן העברת המידע (transfer time) נחשב זניח. גישה סדרתית מאפשרת לקרוא או לכתוב בלוקים רציפים של נתונים תוך מזעור תנועות הראש וזמני ההמתנה לסיבוב, ובכך מפחיתה באופן דרמטי את המרכיבים הדומיננטיים בזמן ה-I/O. לעומת זאת, גישה אקראית דורשת תנועות ראש תכופות וזמני המתנה ארוכים יותר עבור כל פעולת קריאה/כתיבה, מה שמפחית את הביצועים הכוללים. לכן, הפחתת זמני ה-seek וה-rotation היא הסיבה העיקרית לביצועים העדיפים של גישה סדרתית."}, "_source_file": "0437__Disks__Sequential_vs_Random_Access__MC__Medium.json", "_topic_hint": "Sequential vs Random Access", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:39:31", "_subject": "Disks", "_context_lectures": [17, 18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Sequential vs Random Access"], "difficulty_estimation": "Medium", "content": {"text": "מהי הסיבה העיקרית לכך שביצועי קריאה/כתיבה סדרתית (sequential access) לדיסק קשיח עדיפים באופן משמעותי על פני ביצועי קריאה/כתיבה אקראית (random access) על דיסק בודד?", "code_snippet": null, "options": ["א. בגישה סדרתית, זמני ה-seek וה-rotation, שהם המרכיבים הדומיננטיים בזמן ה-I/O, ממוזערים באופן טבעי מכיוון שראש הקריאה/כתיבה זז פחות.", "ב. הדיסק הקשיח תמיד מטפל בבקשות בסדר הגעתן כאשר מדובר בגישה סדרתית, מה שמבטיח יעילות.", "ג. מערכת ההפעלה מיישמת אלגוריתמי תזמון מורכבים (כגון SSTF) רק עבור בקשות סדרתיות, ובכך משפרת את מהירותן.", "ד. גישה סדרתית מאפשרת פיצול מידע בין מספר דיסקים במקביל (כמו ב-RAID-0), מה שמכפיל את קצב העברת הנתונים גם לקריאות אקראיות."]}, "solution": {"correct_option": "א", "explanation": "ההסבר הנכון מתבסס על ההבנה שזמן ה-I/O לסקטור יחיד מורכב בעיקר מזמן ה-seek (תזוזת ראש הקריאה/כתיבה למיקום הנכון) ומזמן ה-rotation (המתנה לסיבוב הפלטה מתחת לראש). חומר ההרצאה מציין כי $T_{I/O} = T_{seek} + T_{rotation} + T_{transfer}$ וכי $T_{transfer}$ זניח. בגישה סדרתית, לאחר פעולה ראשונית של seek ו-rotation, ראש הקריאה/כתיבה נשאר במיקום קרוב וממשיך לקרוא/לכתוב סקטורים סמוכים. בכך, עלויות ה-seek וה-rotation מתחלקות על פני בלוק גדול של נתונים וזמני ההמתנה מצטמצמים באופן דרמטי. לעומת זאת, בגישה אקראית, כל בקשה לסקטור חדש עשויה לדרוש seek ו-rotation משמעותיים, מה שהופך אותה לאיטית בהרבה. חומר ההרצאה גם מציין במפורש כי S>R (כאשר S הוא קצב סדרתי ו-R הוא קצב אקראי) עבור דיסק בודד, מה שמדגיש את יתרון המהירות של גישה סדרתית."}, "_source_file": "0438__Disks__Sequential_vs_Random_Access__MC__Medium.json", "_topic_hint": "Sequential vs Random Access", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:39:47", "_subject": "Disks", "_context_lectures": [17, 18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Sequential vs Random Access"], "difficulty_estimation": "Medium", "content": {"text": "מדוע גישה סדרתית לדיסק קשיח (Hard Disk) נחשבת בדרך כלל ליעילה ומהירה יותר מגישה אקראית?", "code_snippet": null, "options": ["א. גישה סדרתית מפחיתה באופן משמעותי את הצורך בתנועת ראש הקריאה/כתיבה (seek time) ואת זמן ההמתנה לסיבוב הדיסק (rotational latency).", "ב. גישה סדרתית מאפשרת העברת מידע בקצבים גבוהים יותר באופן מהותי (transfer rate) מאשר גישה אקראית.", "ג. דיסקים קשיחים מתוכננים כך שרק גישה סדרתית יכולה לנצל מספר דיסקים במקביל (כמו ב-RAID 0), בעוד שגישה אקראית מוגבלת לדיסק יחיד.", "ד. במערכות הפעלה מודרניות, רק בקשות גישה סדרתיות נכנסות לתור עיבוד של מנגנון הדיסק, בעוד בקשות אקראיות מטופלות מיידית ללא אופטימיזציה."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מציין כי זמן ה-I/O לקריאת סקטור יחיד מורכב בעיקר מ-T_seek (זמן תנועת ראש) ו-T_rotation (זמן המתנה לסיבוב הדיסק), בעוד ש-T_transfer (זמן העברת המידע) הוא זניח (Lecture 17, chunk 38). גישה סדרתית מטבעה מפחיתה את הצורך בתנועות ראש ארוכות ואת זמן ההמתנה לסיבוב, שכן הנתונים הדרושים נמצאים בדרך כלל בסקטורים סמוכים. מנגנון הדיסק עצמו מנסה להפוך בקשות אקראיות לסדרתיות ככל הניתן כדי לשמור על פעולה סדרתית (Lecture 18, chunk 13), ואלגוריתמים כמו SSTF במערכת ההפעלה פועלים על עיקרון של טיפול בסקטורים הקרובים ביותר כדי למזער את זמני ה-seek (Lecture 18, chunk 16). כמו כן, מצוין במפורש כי קצב קריאה סדרתית (S) גבוה מקצב קריאה אקראית (R), כלומר S > R (Lecture 18, chunk 34). לכן, הפחתת זמני ה-seek וה-rotation היא הסיבה העיקרית ליעילותה של גישה סדרתית."}, "_source_file": "0439__Disks__Sequential_vs_Random_Access__MC__Medium.json", "_topic_hint": "Sequential vs Random Access", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:40:05", "_subject": "Disks", "_context_lectures": [17, 18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Sequential vs Random Access"], "difficulty_estimation": "Medium", "content": {"text": "מדוע גישה סדרתית (sequential access) לדיסק קשיח מהירה יותר באופן משמעותי מגישה אקראית (random access)?", "code_snippet": null, "options": ["א. גישה סדרתית ממזערת את הצורך בתנועת ראש הקריאה/כתיבה (seek time) ואת זמן ההמתנה לסיבוב הדיסק (rotation latency), שהם המרכיבים הדומיננטיים בזמן ה-I/O הכולל.", "ב. הדיסק הקשיח מתוכנן לאחסן נתונים סדרתית בלבד, וגישה אקראית דורשת המרה פנימית לגישה סדרתית.", "ג. גישה סדרתית מאפשרת העברת מידע בכמויות קטנות יותר אך בתדירות גבוהה יותר, מה שמשפר את הביצועים.", "ד. זמן העברת המידע (T_transfer) בגישה סדרתית ארוך יותר, ולכן קצב הנתונים הכולל גבוה יותר."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מציין כי זמן ה-I/O הכולל לסקטור מורכב מזמן ה-seek (תנועת ראש הקריאה/כתיבה), זמן ה-rotation (המתנה לסיבוב הדיסק) וזמן ה-transfer (העברת המידע). החומר מדגיש כי זמן ה-transfer הוא זניח, וכי המרכיבים הדומיננטיים בזמן ה-I/O הם ה-seek וה-rotation. בגישה אקראית, ראש הקריאה/כתיבה נדרש לנוע בין מיקומים שונים בדיסק, מה שגורם לזמני seek ו-rotation גבוהים. לעומת זאת, בגישה סדרתית, לאחר ה-seek וה-rotation הראשוניים, הנתונים הבאים ממוקמים בסמוך ויכולים להיקרא ברצף עם מינימום או ללא תנועת ראש נוספת ומינימום המתנה לסיבוב. לכן, גישה סדרתית ממזערת את זמני ה-seek וה-rotation, ובכך מביאה לביצועים מהירים יותר, כפי שהחומר מציין במפורש: 'אנחנו יודעים ש-S>R' (כאשר S הוא קצב קריאה סדרתית ו-R הוא קצב קריאה אקראית)."}, "_source_file": "0440__Disks__Sequential_vs_Random_Access__MC__Medium.json", "_topic_hint": "Sequential vs Random Access", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:40:18", "_subject": "Disks", "_context_lectures": [17, 18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Sequential vs Random Access"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על אופן פעולת בקר הדיסק והגורמים הדומיננטיים בזמן גישת I/O, איזו מהטענות הבאות מתארת בצורה הטובה ביותר את ההשפעה של מנגנון תזמון הבקשות הפנימי של הדיסק על ההבדל בביצועים בין גישה סדרתית לגישה אקראית?", "code_snippet": null, "options": ["א. מנגנון התזמון הפנימי של הדיסק שואף להפוך בקשות אקראיות לכאלו המטופלות באופן סדרתי ככל הניתן, על מנת למזער את זמני ה-seek וה-rotation, ובכך מצמצם את הפער בביצועים מול גישה סדרתית אמיתית, אך אינו מבטל אותו.", "ב. מנגנון התזמון הפנימי מבטל לחלוטין את היתרון של גישה סדרתית, מכיוון שהוא מסוגל לארגן מחדש כל סט של בקשות אקראיות לרצף אופטימלי, ובכך להשיג ביצועים זהים.", "ג. מנגנון התזמון הפנימי רלוונטי רק לבקשות כתיבה, שכן בקשות קריאה חייבות להתבצע בסדר שהן הגיעו מהמערכת ההפעלה כדי למנוע בעיות עקביות.", "ד. מנגנון התזמון הפנימי מגדיל למעשה את זמני ה-seek וה-rotation עבור בקשות אקראיות, מכיוון שהוא מוסיף תקורה של חישוב ותכנון, ובכך מרחיב את הפער מול גישה סדרתית."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. החומר המצוין בפירוש קובע כי \"הדיסק לא בהכרח יטפל בהם בסדר הזה. הוא יודע לעבור בקשות (גם קריאה וגם כתיבה) ולטפל בהם בסדר שהוא רוצה. במצב אידיאלי, ההארד דיסק יטפל קודם ב-8 (למרות שהגיעה אחרונה) ואז ב-10,11,12 כדי לשמור על פעולה סדרתית\". מנגנון זה נועד למזער את הגורמים הדומיננטיים בזמן ה-I/O, שהם זמני ה-T_seek ו-T_rotation, ובכך לשפר את הביצועים של גישה אקראית על ידי הפיכתה לסדרתית יותר. עם זאת, הוא אינו יכול לבטל לחלוטין את היתרון הטבעי של גישה סדרתית אמיתית, שבה הבקשות כבר מגיעות בסדר מיטבי. לכן, הפער בביצועים מצטמצם אך אינו נעלם. אפשרות ב' שגויה מכיוון שהמנגנון אינו מבטל לחלוטין את הפער. אפשרות ג' שגויה כי המנגנון פועל גם עבור קריאות וגם עבור כתיבות. אפשרות ד' שגויה כי מטרת המנגנון היא לצמצם ולא להגדיל את זמני ה-seek וה-rotation."}, "_source_file": "0441__Disks__Sequential_vs_Random_Access__MC__Hard.json", "_topic_hint": "Sequential vs Random Access", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:40:34", "_subject": "Disks", "_context_lectures": [17, 18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Sequential vs Random Access"], "difficulty_estimation": "Hard", "content": {"text": "מדוע ביצועי קריאה סדרתית (Sequential Read) מדיסק קשיח גבוהים משמעותית מביצועי קריאה אקראית (Random Read), וכיצד בקר הדיסק מנסה לצמצם את הפער הזה?", "code_snippet": null, "options": ["א. ביצועי קריאה סדרתית גבוהים יותר מכיוון שבגישה סדרתית זמני ה-seek וה-rotation נמוכים או ניתנים לחיזוי, בעוד שבגישה אקראית הם מהווים את הרכיב הדומיננטי בזמן ה-I/O. בקר הדיסק מנסה לצמצם את הפער על ידי שינוי סדר הבקשות האקראיות כך שיהיו קרובות יותר פיזית זו לזו, ובכך להפחית את תנועת ראש הקריאה/כתיבה.", "ב. ביצועי קריאה סדרתית גבוהים יותר מכיוון שרק בגישה סדרתית ניתן לנצל את מנגנוני ה-caching הפנימיים של הדיסק. בקר הדיסק מנסה לצמצם את הפער על ידי העברת בלוקים גדולים יותר של נתונים בכל פעולת העברה (transfer), ללא קשר למיקום הפיזי שלהם.", "ג. ביצועי קריאה סדרתית גבוהים יותר מכיוון שהם דורשים פחות משאבי מעבד במערכת ההפעלה. בקר הדיסק אינו יכול להשפיע על פער זה, שכן הוא כפוף באופן מוחלט לסדר הבקשות הנשלחות אליו ממערכת ההפעלה.", "ד. ביצועי קריאה אקראית זהים לביצועי קריאה סדרתית בדיסקים מודרניים, מכיוון שזמן ה-transfer הוא הרכיב הדומיננטי ב-T_I/O, וזמני ה-seek וה-rotation זניחים. בקר הדיסק מבצע אופטימיזציה על ידי פיזור בקשות על פני מספר דיסקים (כמו ב-RAID-0) גם עבור גישה אקראית."]}, "solution": {"correct_option": "א", "explanation": "ההסבר הנכון הוא א. כפי שנלמד, זמן ה-I/O לסקטור בודד ($T_{I/O}$) מורכב מ-$T_{seek}$ (זמן תזוזת ראש הקריאה/כתיבה), $T_{rotation}$ (זמן ההמתנה לסיבוב הפלטה), ו-$T_{transfer}$ (זמן העברת הנתונים). הנתונים מלמדים שזמן ה-$T_{transfer}$ זניח, וכי זמני ה-$T_{seek}$ וה-$T_{rotation}$ הם הרכיבים הדומיננטיים ב-$T_{I/O}$. בגישה סדרתית, זמנים אלו מצטמצמים משמעותית או הופכים קבועים עבור רצף נתונים גדול, ולכן ביצועי הקריאה הסדרתית (S) גבוהים מביצועי הקריאה האקראית (R), כלומר S > R. בקר הדיסק מודע לכך ויכול לתזמן מחדש בקשות I/O (כפי שצוין בשיעור: \"הדיסק לא בהכרח יטפל בהם בסדר הזה. הוא יודע לעבור בקשות... ולטפל בהם בסדר שהוא רוצה\"), על מנת לטפל קודם בבקשות קרובות פיזית, ובכך להפחית את תנועת הראש ולדמות פעולה סדרתית יותר, מה שמצמצם את זמני ה-$T_{seek}$ וה-$T_{rotation}$ ומגדיל את הביצועים הכוללים. אפשרויות ב, ג ו-ד אינן נכונות: ב אינה מתארת את הסיבה העיקרית לפער ואינה מדויקת לגבי אופן הפעולה; ג שגויה לגבי יכולת בקר הדיסק לתזמן בקשות, שכן הוא אכן יכול לשנות את סדרן; ו-ד שגויה מהיסוד לגבי מרכיבי זמן ה-I/O ואינה משקפת את ההבדל המהותי בין S ל-R."}, "_source_file": "0442__Disks__Sequential_vs_Random_Access__MC__Hard.json", "_topic_hint": "Sequential vs Random Access", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:40:57", "_subject": "Disks", "_context_lectures": [17, 18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Sequential vs Random Access"], "difficulty_estimation": "Hard", "content": {"text": "בהתחשב ביכולתו של בקר הדיסק לבצע אופטימיזציה של בקשות קלט/פלט על ידי שינוי סדר הטיפול בהן (לדוגמה, טיפול בסקטור קרוב יותר לפני סקטורים רחוקים שהתקבלו מוקדם יותר), מדוע גישה סדרתית לנתונים (קריאה/כתיבה של בלוקים רציפים) עדיין מהירה באופן מהותי ומשמעותי מגישה אקראית לנתונים (קריאה/כתיבה של בלוקים מפוזרים)?", "code_snippet": null, "options": ["א. גישה סדרתית אמיתית ממזערת את מספר פעולות ה-seek ואת זמן ההמתנה לסיבוב (rotation latency), שהם הרכיבים הדומיננטיים בזמן הגישה לדיסק, בניגוד לגישה אקראית שבה כל בקשה דורשת לרוב seek ו-rotation חדשים.", "ב. בקר הדיסק אינו יכול לשנות את סדר בקשות הכתיבה כלל, מה שמונע אופטימיזציה עבור גישה אקראית בכותבים.", "ג. מהירות העברת הנתונים (T_transfer) גבוהה משמעותית בגישה סדרתית מאשר בגישה אקראית, ורכיב זה הוא הדומיננטי בזמן ה-I/O.", "ד. גישה סדרתית מנצלת באופן בלעדי את זיכרון המטמון (cache) של הדיסק, בעוד שגישה אקראית עוקפת אותו תמיד."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. זמן הגישה הכולל לדיסק (T_I/O) מורכב משלושה רכיבים עיקריים: זמן חיפוש (T_seek), זמן המתנה לסיבוב (T_rotation) וזמן העברת הנתונים (T_transfer). על פי חומר ההרצאה, זמן העברת הנתונים נחשב זניח יחסית לשני הרכיבים האחרים, כאשר T_seek ו-T_rotation הם הדומיננטיים. גישה סדרתית לנתונים מתייחסת לקריאה או כתיבה של בלוקים סמוכים פיזית על הדיסק. במצב כזה, לאחר פעולת חיפוש וסיבוב ראשונית, ראש הקריאה/כתיבה יכול להמשיך לקרוא או לכתוב בלוקים עוקבים במינימום (או ללא) צורך בפעולות T_seek ו-T_rotation נוספות עבור כל בלוק. לעומת זאת, גישה אקראית, שבה הנתונים מפוזרים על פני הדיסק, דורשת בדרך כלל ביצוע פעולות T_seek ו-T_rotation משמעותיות עבור כל בלוק או קבוצת בלוקים קטנה. אף שבקר הדיסק יכול לבצע אופטימיזציה ולשנות את סדר הטיפול בבקשות על מנת למזער את תנועת הראש (כפי שתואר בהרצאה לגבי טיפול בסקטור 8 לפני 10,11,12), הוא אינו יכול לבטל את הצורך בפעולות אלו לחלוטין כאשר הנתונים מפוזרים באופן מהותי. לכן, גישה סדרתית תמיד תהיה מהירה יותר באופן מהותי עקב צמצום דרמטי ברכיבי ה-T_seek ו-T_rotation הדומיננטיים. תשובה ב' שגויה מכיוון שההרצאה מציינת במפורש שהדיסק יכול לשנות את סדר בקשות (קריאה וכתיבה) ולטפל בהן בסדר שהוא רוצה. תשובה ג' שגויה מכיוון שההרצאה מציינת שזמן ה-T_transfer זניח. תשובה ד' אינה נתמכת בחומר ההרצאה שסופק."}, "_source_file": "0443__Disks__Sequential_vs_Random_Access__MC__Hard.json", "_topic_hint": "Sequential vs Random Access", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:41:16", "_subject": "Disks", "_context_lectures": [17, 18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Sequential vs Random Access"], "difficulty_estimation": "Hard", "content": {"text": "מערכת ההפעלה שולחת בקשות קריאה וכתיבה לדיסק הקשיח. לעיתים קרובות, בקשות אלו מגיעות בסדר לוגי אקראי. עם זאת, בקר הדיסק מצויד במנגנונים המאפשרים לו לשנות את סדר הביצוע של בקשות אלו (כמו בדוגמה של טיפול בסקטור 8 לפני 10, 11, 12). בהתבסס על עקרונות פעולת הדיסק כפי שתוארו בחומר הקורס, איזו מההצהרות הבאות מתארת בצורה המדויקת ביותר את ההשפעה של יכולת זו על ביצועי הדיסק הכוללים בתרחיש של עומס עבודה אקראי?", "code_snippet": null, "options": ["א. יכולת שינוי הסדר מאפשרת לבקר הדיסק למזער את זמני ה-seek וה-rotation על ידי קיבוץ בקשות קרובות פיזית, ובכך להפוך דפוס גישה אקראי לוגי לדפוס גישה סדרתי יותר מבחינה פיזית, מה שמשפר משמעותית את קצב התפוקה (throughput) הכולל.", "ב. שינוי סדר הבקשות נועד בעיקר למנוע בעיות עקביות נתונים במקרה של כשל מערכת פתאומי, ואינו משפיע באופן מהותי על זמני ה-seek או ה-rotation.", "ג. יכולת זו למעשה מבטלת את ההבדל בביצועים בין גישה סדרתית לגישה אקראית, שכן היא מאפשרת לבקר הדיסק לטפל בכל בקשה באותה יעילות, ללא קשר למיקומה הפיזי.", "ד. היתרון העיקרי של שינוי סדר הבקשות מתממש רק במערכי RAID-0, שם הוא מאפשר ניצול מקבילי של כל הדיסקים לשיפור הביצועים, אך בדיסק בודד השפעתו זניחה."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר הקורס מציין במפורש כי בקר הדיסק יכול לשנות את סדר הטיפול בבקשות קלט/פלט (קריאה וכתיבה), גם אם הן הגיעו בסדר אקראי לוגית. המטרה היא לטפל בהן בסדר אופטימלי מבחינה פיזית, כגון טיפול בסקטור 8 לפני סקטורים 10, 11, 12, על מנת 'לשמור על פעולה סדרתית' ככל הניתן. פעולה זו מפחיתה באופן דרמטי את הצורך בתנועה רחבה של ראש הקריאה/כתיבה (זמן ה-seek) ואת זמן ההמתנה לסיבוב הדיסק (זמן ה-rotation), שהם הרכיבים הדומיננטיים בזמן הגישה הכולל לדיסק ($T_{I/O} = T_{seek} + T_{rotation} + T_{transfer}$). על ידי מזעור רכיבים אלו, בקר הדיסק ממיר למעשה דפוס גישה אקראי לוגי לדפוס גישה סדרתי יותר מבחינה פיזית, מה שמשפר משמעותית את קצב התפוקה הכולל (throughput) של הדיסק.\n\nאפשרויות אחרות אינן נכונות: \nב. שינוי הסדר אכן טומן בחובו סיכון לבעיות עקביות במקרה של כשל (כפי שצוין בחומר הקורס: 'הסיכון העיקרי בגישה הזו הוא שאם תובטח לנו סדר ולכן עלולה להיות בעיית עקביות, ועלול להיות אובדן מידע במקרה של מחשב שנכבה'), אך זו אינה המטרה או ההשפעה העיקרית של מנגנון זה על הביצועים. המטרה המרכזית היא אופטימיזציה של ביצועים.\nג. יכולת זו מפחיתה את ההבדל, אך אינה מבטלת אותו לחלוטין. גישה סדרתית אמיתית עדיין תהיה מהירה יותר מגישה אקראית שעברה אופטימיזציה, מכיוון שגם לאחר אופטימיזציה עדיין יהיו זמני seek ו-rotation מסוימים, וקצב העברת הנתונים הפיזי של דיסק בודד (S) עדיין גבוה יותר מקצב הגישה האקראית (R).\nד. חומר הקורס מציין שמנגנון זה קיים 'בתוך ההארד דיסק שלנו', כלומר הוא מובנה בבקר הדיסק עצמו ורלוונטי לכל דיסק, לא רק למערכי RAID-0. השפעתו על ביצועי דיסק בודד משמעותית ביותר."}, "_source_file": "0444__Disks__Sequential_vs_Random_Access__MC__Hard.json", "_topic_hint": "Sequential vs Random Access", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:41:44", "_subject": "Disks", "_context_lectures": [17, 18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Disk Scheduling"], "difficulty_estimation": "Easy", "content": {"text": "איזה מבין אלגוריתמי תזמון הדיסקים הבאים מבוצע בדרך כלל בתוך הדיסק עצמו (בקר הדיסק), ולא על ידי מערכת ההפעלה, בשל חוסר מודעותה של מערכת ההפעלה למבנה הפיזי של הדיסק?", "code_snippet": null, "options": ["א. First Come, First Served (FCFS)", "ב. Shortest Positioning Time First (SPTF)", "ג. אלגוריתם המשלב בקשות עוקבות (sequential requests)", "ד. אלגוריתם אופטימלי (Optimal Algorithm)"]}, "solution": {"correct_option": "ב", "explanation": "החומר מציין במפורש כי אלגוריתם Shortest Positioning Time First (SPTF) מבוצע בתוך הדיסק עצמו. הסיבה לכך היא שמערכת ההפעלה אינה מודעת למבנה הפיזי המדויק של הדיסק (כמו מיקום הראש הקורא/כותב, זמני חיפוש וסיבוב), ולכן אינה יכולה לחשב באופן יעיל איזה בקשה תיקח את הזמן הקצר ביותר. הדיסק, לעומת זאת, יודע בדיוק כמה זמן תיקח כל פעולה ויכול לתזמן את הבקשות בצורה אופטימלית יותר עבורו. FCFS הוא אלגוריתם פשוט שניתן לבצע הן על ידי מערכת ההפעלה והן על ידי הדיסק, אך לא מסיבת חוסר מודעות למבנה הפיזי. שילוב בקשות עוקבות הוא אופטימיזציה שמערכת ההפעלה מבצעת לפני שליחתן לדיסק. אלגוריתם אופטימלי אינו ישים בפועל מכיוון שלא ניתן לדעת את הבקשות שיגיעו בעתיד."}, "_source_file": "0445__Disks__Disk_Scheduling__MC__Easy.json", "_topic_hint": "Disk Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:41:58", "_subject": "Disks", "_context_lectures": [18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Disk Scheduling"], "difficulty_estimation": "Easy", "content": {"text": "מהו המאפיין העיקרי של אלגוריתם תזמון הדיסק First Come, First Served (FCFS)?", "code_snippet": null, "options": ["א. מטפל בבקשות לפי סדר הגעתן למערכת ההפעלה.", "ב. בוחר תמיד את הבקשה שדורשת את זמן המיקום הקצר ביותר.", "ג. משלב בקשות סמוכות לקריאה אחת רציפה.", "ד. מבוצע אך ורק בתוך הדיסק עצמו, ללא מעורבות מערכת ההפעלה."]}, "solution": {"correct_option": "א", "explanation": "אלגוריתם FCFS (First Come, First Served) הוא שיטת תזמון דיסק פשוטה וישירה. המאפיין העיקרי שלו, כפי שמוצג בחומר ההרצאה, הוא טיפול בבקשות בדיוק לפי הסדר שבו הגיעו למערכת. גישה זו אינה מתחשבת במיקום הפיזי של הנתונים על הדיסק או בזמן הנדרש לביצוע הבקשה, אלא רק בסדר כרונולוגי של קבלת הבקשות. אפשרויות ב', ג' ו-ד' מתארות מאפיינים של אלגוריתמים אחרים או אופטימיזציות שונות בתזמון דיסק."}, "_source_file": "0446__Disks__Disk_Scheduling__MC__Easy.json", "_topic_hint": "Disk Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:42:09", "_subject": "Disks", "_context_lectures": [18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Disk Scheduling"], "difficulty_estimation": "Easy", "content": {"text": "איזה מבין התיאורים הבאים מתאר בצורה הטובה ביותר את אלגוריתם תזמון הדיסק First Come, First Served (FCFS)?", "code_snippet": null, "options": ["א. הדיסק מטפל בבקשות לפי הזמן הקצר ביותר למיקום ראש הקריאה/כתיבה.", "ב. מערכת ההפעלה מטפלת בבקשות לפי סדר הגעתן.", "ג. מערכת ההפעלה מאחדת בקשות לסקטורים סמוכים לבקשה אחת.", "ד. הדיסק מבצע תזמון אופטימלי על ידי חיזוי בקשות עתידיות."]}, "solution": {"correct_option": "ב", "explanation": "אלגוריתם First Come, First Served (FCFS) מטפל בבקשות לדיסק לפי הסדר שבו הן מתקבלות (First Come) ומוגשות (First Served). החומר מציין במפורש: \"First come, First served (FCFS): נטפל בבקשות לפי הסדר.\" אפשרות א' מתארת את Shortest Positioning Time First (SPTF), שבו מטפלים בבקשה שלוקח הכי פחות זמן לטפל בה. אפשרות ג' מתארת אופטימיזציה של איחוד בקשות סמוכות, שאינה אלגוריתם תזמון בפני עצמו אלא טכניקה לשיפור יעילות. אפשרות ד' מתארת תזמון אופטימלי שאינו אפשרי בפועל מכיוון שאי אפשר לדעת מה יגיע בעתיד."}, "_source_file": "0447__Disks__Disk_Scheduling__MC__Easy.json", "_topic_hint": "Disk Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:42:18", "_subject": "Disks", "_context_lectures": [18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Disk Scheduling"], "difficulty_estimation": "Easy", "content": {"text": "מדוע אלגוריתם SPTF (Shortest Positioning Time First) מיושם בדרך כלל בתוך בקר הדיסק ולא על ידי מערכת ההפעלה?", "code_snippet": null, "options": ["א. מכיוון שמערכת ההפעלה אינה מודעת למבנה הפיזי של הדיסק ולזמני הגישה המדויקים.", "ב. מכיוון שאלגוריתם SPTF מונע לחלוטין תופעות של הרעבה (starvation) ולכן עדיף להשאירו לטיפול הדיסק.", "ג. מכיוון שמערכת ההפעלה מתעדפת בקשות קריאה על פני בקשות כתיבה, מה שעלול לשבש את יעילות SPTF.", "ד. מכיוון שהדיסק אינו מסוגל לקבל מספר בקשות במקביל ממערכת ההפעלה, ולכן עליו לתזמן אותן בעצמו."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. החומר המצוין בשיעור קובע במפורש כי אלגוריתם SPTF מבוצע בתוך הדיסק משום ש\"מערכת ההפעלה לא מודעת למבנה של הדיסק, לכן יכול לקרוא מצב בו מערכת ההפעלה תעשה תזמון שגוי\". הדיסק, לעומת זאת, \"יודע בדיוק כמה זמן כל פעולה תיקח ולכן הוא יכול לחשב\" את זמן המיקום הקצר ביותר. אפשרות ב' אינה הסיבה העיקרית להטמעת SPTF בתוך הדיסק, אלא תוצאה של אופן ביצועו (טיפול בסט של בקשות). אפשרויות ג' ו-ד' אינן נתמכות ישירות על ידי החומר כהסבר להטמעת SPTF בתוך הדיסק."}, "_source_file": "0448__Disks__Disk_Scheduling__MC__Easy.json", "_topic_hint": "Disk Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:42:30", "_subject": "Disks", "_context_lectures": [18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Disk Scheduling"], "difficulty_estimation": "Medium", "content": {"text": "איזו מהטענות הבאות נכונה לגבי אלגוריתם תזמון הדיסק Shortest Positioning Time First (SPTF) כפי שמתואר בחומר השיעור?", "code_snippet": null, "options": ["א. הוא מיושם ביעילות על ידי מערכת ההפעלה מכיוון שהיא מודעת למבנה הפיזי המדויק של הדיסק.", "ב. הוא מטפל בבקשות לפי סדר הגעתן, בדומה ל-FCFS, אך עם עדיפות לבקשות סדרתיות.", "ג. הוא מיושם בתוך בקר הדיסק עצמו (ולא במערכת ההפעלה) ומונע הרעבה על ידי טיפול בסט בקשות מסוים.", "ד. הוא מבטיח טיפול יעיל בבקשות, אך עלול לגרום להרעבה (starvation) של בקשות רחוקות אם יגיעו כל הזמן בקשות קרובות."]}, "solution": {"correct_option": "ג", "explanation": "חומר השיעור מציין במפורש כי אלגוריתם SPTF 'לא כ\"כ אפשרי בתוך OS אלא במערכת ההפעלה' מכיוון 'שמערכת ההפעלה לא מודעת למבנה של הדיסק', ולכן 'האלגוריתם הזה מבוצע בתוך הדיסק'. בנוסף, הוא מבטיח טיפול נכון וחכם בבקשות ו'לא ייתכן הרעבה (אם כל הזמן יגיעו בקשות קרובות למיקום של הראש קורא/כותב באותה עת, בקשות רחוקות יותר לא יטופלו) כי הדיסק מטפל תמיד בסט של בקשות מסויים ואין לו מעבר לבאות'. לכן, אפשרות ג' מתארת באופן מדויק את מאפייני SPTF כפי שהם מיושמים בדיסק, כולל מניעת הרעבה."}, "_source_file": "0449__Disks__Disk_Scheduling__MC__Medium.json", "_topic_hint": "Disk Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:42:41", "_subject": "Disks", "_context_lectures": [18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Disk Scheduling"], "difficulty_estimation": "Medium", "content": {"text": "לפי חומר ההרצאה, מדוע אלגוריתם SPTF (Shortest Positioning Time First) מיושם בדרך כלל בתוך בקר הדיסק (הדיסק עצמו) ולא על ידי מערכת ההפעלה?", "code_snippet": null, "options": ["א. מערכת ההפעלה אינה מודעת למבנה הפיזי המדויק של הדיסק ולכן אינה יכולה לחשב באופן אופטימלי את זמן הטיפול בכל בקשה.", "ב. אלגוריתם SPTF מבטיח שלא תתרחש תופעת הרעבה, תכונה שרק בקר הדיסק יכול להבטיח.", "ג. מערכת ההפעלה מעדיפה לשלוח בקשות לדיסק ברצף (FCFS) כדי למנוע עומס על בקר הדיסק.", "ד. הדיסק, בניגוד למערכת ההפעלה, אינו יודע מה יגיע בעתיד, ולכן חייב לבצע תזמון מקומי."]}, "solution": {"correct_option": "א", "explanation": "אלגוריתם SPTF (Shortest Positioning Time First) מיושם בתוך בקר הדיסק משום שמערכת ההפעלה אינה בעלת המידע הנדרש לגבי המבנה הפיזי הפנימי של הדיסק. חומר ההרצאה מציין במפורש כי \"מערכת ההפעלה לא מודעת למבנה של הדיסק, לכן יכול לקרוא מצב בו מערכת ההפעלה תעשה תזמון שגוי\". לעומת זאת, הדיסק עצמו (בקר הדיסק) יודע בדיוק כמה זמן כל פעולה תיקח, מה שמאפשר לו לחשב באופן אופטימלי איזו בקשה תדרוש את זמן הטיפול הקצר ביותר. לכן, יישום ה-SPTF בדיסק מבטיח תזמון נכון וחכם יותר. אפשרות ב' אינה הסיבה העיקרית למיקום האלגוריתם, אלא תכונה נלווית לדרך היישום שלו. אפשרות ג' אינה קשורה לסיבת מיקום ה-SPTF. אפשרות ד' שגויה, שכן הדיסק אמנם לא יודע מה יגיע בעתיד, אך הוא יודע לחשב את זמני הפעולה הנוכחיים, בניגוד למערכת ההפעלה."}, "_source_file": "0450__Disks__Disk_Scheduling__MC__Medium.json", "_topic_hint": "Disk Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:42:53", "_subject": "Disks", "_context_lectures": [18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Disk Scheduling"], "difficulty_estimation": "Medium", "content": {"text": "מדוע אלגוריתם תזמון הדיסק Shortest Positioning Time First (SPTF) מיושם בדרך כלל בתוך בקר הדיסק ולא במערכת ההפעלה, ומהי תכונה חשובה הנובעת מדרך יישום זו?", "code_snippet": null, "options": ["א. הוא מיושם בבקר הדיסק מכיוון שמערכת ההפעלה אינה מודעת לפרטי המבנה הפיזי של הדיסק, ותכונתו החשובה היא שהוא מונע הרעבה (starvation) על ידי טיפול בסט בקשות שלם לפני המעבר לבקשות נוספות.", "ב. הוא מיושם במערכת ההפעלה כדי לאפשר איחוד בקשות קריאה/כתיבה סמוכות, אך חסרונו הוא שהוא עלול לגרום להרעבה של בקשות רחוקות.", "ג. הוא מיושם בבקר הדיסק כדי למזער את זמן ה-rotation, אך הוא אינו מבטיח מניעת הרעבה במקרים של עומס גבוה.", "ד. הוא מיושם במערכת ההפעלה מכיוון שהיא יכולה לחשב באופן אופטימלי את זמן הטיפול המדויק בכל בקשה, ובכך מבטיח את הביצועים הטובים ביותר לכל הבקשות."]}, "solution": {"correct_option": "א", "explanation": "אלגוריתם SPTF מיושם בבקר הדיסק (ולא במערכת ההפעלה) מכיוון שמערכת ההפעלה אינה מודעת לפרטי המבנה הפיזי של הדיסק ולזמנים המדויקים שכל פעולה תיקח, בעוד שבקר הדיסק יודע בדיוק נתונים אלו. כפי שמצוין בחומר ההרצאה, הדיסק מטפל תמיד ב\"סט של בקשות מסוים\" ורק לאחר מכן עובר לבאות. מנגנון זה מונע הרעבה (starvation), שכן בקשות שנקלטו באותו סט יטופלו כולן, גם אם יגיעו בקשות חדשות שקרובות יותר לראש הקורא/כותב."}, "_source_file": "0451__Disks__Disk_Scheduling__MC__Medium.json", "_topic_hint": "Disk Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:43:08", "_subject": "Disks", "_context_lectures": [18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Disk Scheduling"], "difficulty_estimation": "Medium", "content": {"text": "מדוע אלגוריתם תזמון הדיסק Shortest Positioning Time First (SPTF) מיושם בדרך כלל בתוך בקר הדיסק ולא ישירות על ידי מערכת ההפעלה?", "code_snippet": null, "options": ["א. מערכת ההפעלה אינה מודעת למבנה הפיזי של הדיסק ולכן אינה יכולה לחשב במדויק את זמן המיקום הקצר ביותר.", "ב. אלגוריתם SPTF מבטיח שכל הבקשות יטופלו ללא הרעבה, תכונה שלא ניתן להבטיח על ידי מערכת ההפעלה.", "ג. בקר הדיסק יכול לבצע פעולות תזמון מהר יותר ממערכת ההפעלה, מה שמוביל לשיפור ביצועים משמעותי.", "ד. מערכת ההפעלה מעדיפה תמיד לאחד בקשות סדרתיות לפני שליחתן לדיסק, מה שמתנגש עם עקרונות SPTF."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין מציין במפורש כי 'מערכת ההפעלה לא מודעת למבנה של הדיסק, לכן יכול לקרוא מצב בו מערכת ההפעלה תעשה תזמון שגוי. לכן האלגוריתם הזה מבוצע בתוך הדיסק.' (Lecture 18, chunk 15). ידע זה על המבנה הפיזי של הדיסק (כמו מיקום ראש הקריאה/כתיבה הנוכחי) חיוני לחישוב מדויק של זמן המיקום הקצר ביותר (seek time + rotation latency) ולכן האלגוריתם מיושם בצורה יעילה יותר בתוך בקר הדיסק עצמו. האפשרויות האחרות אינן הסיבה העיקרית המפורטת בחומר."}, "_source_file": "0452__Disks__Disk_Scheduling__MC__Medium.json", "_topic_hint": "Disk Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:43:19", "_subject": "Disks", "_context_lectures": [18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Disk Scheduling"], "difficulty_estimation": "Hard", "content": {"text": "מדוע אלגוריתם תזמון הדיסק Shortest Positioning Time First (SPTF), כשהוא מיושם בתוך הדיסק עצמו, מצליח למנוע הרעבה (starvation) של בקשות, בניגוד ליישום פוטנציאלי שלו במערכת ההפעלה?", "code_snippet": null, "options": ["א. הדיסק מעבד תמיד קבוצה מוגדרת מראש של בקשות לפני שהוא עובר לקבוצה הבאה, ובכך מבטיח שכל בקשה בקבוצה תטופל בסופו של דבר.", "ב. הדיסק מודע למבנה הפיזי המלא שלו ויכול לחשב במדויק את זמני ה-seek וה-rotation לכל בקשה, ובכך למנוע מצב של בקשות רחוקות שאינן מטופלות.", "ג. מערכת ההפעלה שולחת לדיסק רק בקשות קרובות זו לזו מבחינה לוגית, מה שמפשט את עבודת הדיסק ומונע הרעבה.", "ד. SPTF בדיסק מתעדף קריאות על פני כתיבות, ובכך מבטיח שכל בקשות הקריאה יטופלו במהירות ובאופן הוגן."]}, "solution": {"correct_option": "א", "explanation": "ההסבר המופיע בחומר ההרצאה מציין במפורש כי אלגוריתם SPTF המבוצע בתוך הדיסק עצמו מונע הרעבה (starvation) מכיוון \"הדיסק מטפל תמיד בסט של בקשות מסויים ואין לו מעבר לבאות\". המשמעות היא שהדיסק מקבל קבוצה מסוימת של בקשות, מתזמן ומבצע אותן כולן לפני שהוא מקבל קבוצה חדשה של בקשות. בכך, גם אם כל הזמן יגיעו בקשות חדשות שקרובות יותר לראש הקורא/כותב, הן לא יפריעו לבקשות שכבר נמצאות ב\"סט\" הנוכחי, ובכך מובטח שכל הבקשות בסט הנוכחי יטופלו. אופציה ב' מתארת יתרון של הדיסק (מודעות למבנה וזמנים), אך זהו התנאי ליכולת ליישם SPTF, לא הסיבה הספציפית למניעת הרעבה במודל של הדיסק. אופציות ג' ו-ד' אינן נתמכות בחומר ההרצאה כהסבר למניעת הרעבה ב-SPTF של הדיסק."}, "_source_file": "0453__Disks__Disk_Scheduling__MC__Hard.json", "_topic_hint": "Disk Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:43:32", "_subject": "Disks", "_context_lectures": [18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Disk Scheduling"], "difficulty_estimation": "Hard", "content": {"text": "מדוע אלגוריתם תזמון הדיסק Shortest Positioning Time First (SPTF) מבוצע לרוב בתוך בקר הדיסק ולא במערכת ההפעלה, וכיצד מנגנון זה מונע רעב (starvation) של בקשות?", "code_snippet": null, "options": ["א. מערכת ההפעלה אינה מודעת למבנה הפיזי המדויק של הדיסק (מיקום ראש קריאה/כתיבה, מבנה סקטורים/טראקים), מידע חיוני לחישוב זמן המיקום הקצר ביותר. בקר הדיסק, על ידי טיפול ב\"סט\" קבוע של בקשות, מבטיח שכל בקשה בסט תטופל בסופו של דבר, ובכך מונע רעב.", "ב. מערכת ההפעלה מסוגלת לבצע SPTF, אך הדבר פחות יעיל בשל עומס החלפת ההקשרים. רעב נמנע מכיוון שמערכת ההפעלה מתעדפת בקשות ישנות לאחר זמן קצוב מראש.", "ג. SPTF דורש ידע בזמן אמת על בקשות עתידיות, ידע שקיים רק בבקר הדיסק. רעב אינו אפשרי ב-SPTF מעצם הגדרתו, כיוון שהוא תמיד בוחר את הבקשה הקצרה ביותר, מה שמבטיח שכל הבקשות יטופלו בסופו של דבר.", "ד. לבקר הדיסק יש כוח עיבוד ייעודי רב יותר לתזמון, מה שמאפשר חישובי SPTF מהירים יותר. רעב נמנע מכיוון שהדיסק מטפל מיד בכל בקשה שמגיעה כאשר ראש הקריאה/כתיבה כבר נמצא במיקומה."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה, אלגוריתם SPTF מבוצע בתוך בקר הדיסק ולא על ידי מערכת ההפעלה מכיוון ש'מערכת ההפעלה לא מודעת למבנה של הדיסק, לכן יכול לקרוא מצב בו מערכת ההפעלה תעשה תזמון שגוי'. כדי לבצע SPTF בצורה יעילה, יש צורך בידע מדויק על מיקום ראש הקריאה/כתיבה ועל מבנה הדיסק הפיזי, ידע שקיים רק בבקר הדיסק. בנוסף, חומר ההרצאה מסביר כיצד נמנע רעב: 'לא ייתכן הרעבה... כי הדיסק מטפל תמיד בסט של בקשות מסויים ואין לו מעבר לבאות'. כלומר, בקר הדיסק אוסף קבוצה (סט) של בקשות, מטפל בכולן בסט זה לפי עקרון SPTF, ורק לאחר מכן עובר לסט הבא. מנגנון זה מבטיח שכל הבקשות בסט הנוכחי יטופלו בסופו של דבר, ובכך מונע מצב שבו בקשות רחוקות יותר 'יורעבו' על ידי בקשות קרובות חדשות שמגיעות ללא הרף."}, "_source_file": "0454__Disks__Disk_Scheduling__MC__Hard.json", "_topic_hint": "Disk Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:43:48", "_subject": "Disks", "_context_lectures": [18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Disk Scheduling"], "difficulty_estimation": "Hard", "content": {"text": "מדוע אלגוריתם תזמון הדיסק \"Shortest Positioning Time First\" (SPTF) מיושם בדרך כלל בתוך בקר הדיסק עצמו ולא על ידי מערכת ההפעלה?", "code_snippet": null, "options": ["א. מערכת ההפעלה אינה מודעת למבנה הפיזי המדויק של הדיסק (כגון מיקום סקטורים, מסלולים, ו-track skew) ולכן אינה יכולה לחשב במדויק את זמן המיקום הקצר ביותר.", "ב. יישום SPTF במערכת ההפעלה עלול לגרום להרעבה (starvation) של בקשות מרוחקות, בעוד שבקר הדיסק מבטיח טיפול בכל הבקשות בסט נתון.", "ג. בקר הדיסק מסוגל לבצע פעולות איחוד בקשות (merging requests) ו-caching בצורה יעילה יותר ממערכת ההפעלה, מה שמשפר את ביצועי SPTF.", "ד. אלגוריתם SPTF דורש גישה ישירה לזמני ה-seek וה-rotation, מידע שאינו זמין למערכת ההפעלה אלא רק לחומרת הדיסק."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין מדגיש כי אלגוריתם SPTF (Shortest Positioning Time First) מבוצע בתוך בקר הדיסק ולא על ידי מערכת ההפעלה. הסיבה לכך היא שמערכת ההפעלה אינה מודעת למבנה הפיזי הפנימי המדויק של הדיסק, כפי שצוין בפירוש: \"מערכת ההפעלה לא מודעת למבנה של הדיסק, לכן יכול לקרוא מצב בו מערכת ההפעלה תעשה תזמון שגוי\". לעומת זאת, הדיסק עצמו \"יודע בדיוק כמה זמן כל פעולה תיקח ולכן הוא יכול לחשב\" את זמן המיקום הקצר ביותר באופן אופטימלי. ידע זה כולל פרטים קריטיים כמו track skew ומבנה ה-zones, שמשפיעים על חישוב זמן הגישה בפועל. ללא ידע זה, מערכת ההפעלה לא יכולה ליישם את SPTF ביעילות או במדויק. אפשרות ב' מתארת יתרון של אופן יישום ה-SPTF בדיסק (מניעת הרעבה על ידי טיפול בסט בקשות), אך לא את הסיבה העיקרית מדוע מערכת ההפעלה אינה מיישמת אותו. אפשרות ג' אינה הסיבה העיקרית ליישום SPTF בדיסק, שכן גם מערכת ההפעלה יכולה לבצע איחוד ו-caching. אפשרות ד' נכונה חלקית אך פחות מקיפה מאפשרות א', שכן \"המבנה הפיזי המדויק\" כולל בתוכו את היכולת לחשב את זמני ה-seek וה-rotation בהקשר של סידור נתונים מורכב בדיסק."}, "_source_file": "0455__Disks__Disk_Scheduling__MC__Hard.json", "_topic_hint": "Disk Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:44:05", "_subject": "Disks", "_context_lectures": [18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["Disk Scheduling"], "difficulty_estimation": "Hard", "content": {"text": "איזו טענה מתארת בצורה הנכונה ביותר את אלגוריתם תזמון הדיסק SPTF (Shortest Positioning Time First) ואת השלכותיו, על פי חומר ההרצאה?", "code_snippet": null, "options": ["א. אלגוריתם SPTF מבוצע בדרך כלל בתוך בקר הדיסק ולא במערכת ההפעלה, מכיוון שמערכת ההפעלה אינה מודעת למבנה הפיזי של הדיסק ועלולה לבצע תזמון שגוי. בקר הדיסק מטפל בסט בקשות נתון, מה שמונע הרעבה של בקשות מרוחקות.", "ב. מערכת ההפעלה יכולה ליישם SPTF ביעילות על ידי שימוש במידע שמתקבל מהדיסק, אך הדבר עלול להוביל להרעבה של בקשות רחוקות אם לא מיושמים מנגנונים נוספים.", "ג. SPTF מיועד בעיקר לטיפול בבקשות סדרתיות (sequential requests) במערכת ההפעלה, בעוד שאלגוריתם FCFS מבוצע בתוך הדיסק כדי למנוע הרעבה.", "ד. SPTF הוא אלגוריתם תזמון ברמת מערכת ההפעלה המתמקד בהפחתת זמן ה-seek בלבד, ואינו לוקח בחשבון את זמן ה-rotation, מה שעלול לגרום לתזמון אופטימלי פחות."]}, "solution": {"correct_option": "א", "explanation": "האפשרות הנכונה היא א'. חומר ההרצאה מציין במפורש שאלגוריתם SPTF מבוצע בתוך בקר הדיסק (\"לכן האלגוריתם הזה מבוצע בתוך הדיסק\") ולא במערכת ההפעלה, מכיוון שלמערכת ההפעלה אין מודעות למבנה הפיזי של הדיסק (\"מערכת ההפעלה לא מודעת למבנה של הדיסק\") ולכן עלולה לבצע תזמון שגוי. בנוסף, ההרצאה מסבירה שהרעבה של בקשות מרוחקות נמנעת ביישום זה של SPTF בתוך הדיסק, מכיוון שהדיסק מטפל תמיד ב\"סט של בקשות מסויים ואין לו מעבר לבאות\" (מנגנון המונע הרעבה). \nאפשרות ב' שגויה משום שהיא טוענת שמערכת ההפעלה יכולה ליישם SPTF ביעילות, בניגוד לחומר ההרצאה. כמו כן, היא מתארת הרעבה כבעיה אפשרית, בעוד שההרצאה מציינת שהיא נמנעת באופן ספציפי ביישום הדיסקאי. \nאפשרות ג' שגויה מכיוון ש-SPTF אינו מיועד ספציפית לבקשות סדרתיות ברמת מערכת ההפעלה, ואין אזכור ש-FCFS מבוצע בתוך הדיסק כדי למנוע הרעבה. \nאפשרות ד' שגויה משום שהיא מציגה את SPTF כאלגוריתם ברמת מערכת ההפעלה, בעוד שההרצאה מבהירה שהוא מבוצע בתוך הדיסק. כמו כן, היא טוענת שאינו לוקח בחשבון את זמן ה-rotation, בעוד שהקונספט של \"Shortest Positioning Time First\" בדרך כלל מתייחס לזמן המיקום הכולל, הכולל גם seek וגם rotation, והדיסק עצמו \"יודע בדיוק כמה זמן כל פעולה תיקח\"."}, "_source_file": "0456__Disks__Disk_Scheduling__MC__Hard.json", "_topic_hint": "Disk Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:44:20", "_subject": "Disks", "_context_lectures": [18]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, איזו רמת RAID נחשבת לעדיפה באופן מוחלט על RAID-4?", "code_snippet": null, "options": ["א. RAID-0", "ב. RAID-1", "ג. RAID-5", "ד. JBOD"]}, "solution": {"correct_option": "ג", "explanation": "חומר ההרצאה מציין במפורש כי 'RAID-5 is strictly better than RAID-4' וכי 'אין סיבה להשתמש ב-raid-4'. קביעות אלו מבהירות ש-RAID-5 עדיף על RAID-4."}, "_source_file": "0457__Disks__RAID__MC__Easy.json", "_topic_hint": "RAID", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:44:27", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID"], "difficulty_estimation": "Easy", "content": {"text": "מהו אחד המאפיינים המרכזיים של אופן הפעולה של מערכת RAID?", "code_snippet": null, "options": ["א. היא מחייבת את מערכת ההפעלה לנהל באופן ישיר את פיצול הנתונים בין הדיסקים הפיזיים.", "ב. היא מציגה דיסק לוגי יחיד למערכת ההפעלה וליישומים, באופן שקוף לחלוטין.", "ג. מטרתה העיקרית היא תמיד לשפר את ביצועי הקריאה בלבד.", "ד. היא דורשת שימוש בתוכניות ייעודיות שתוכננו במיוחד עבורה."]}, "solution": {"correct_option": "ב", "explanation": "החומר המצוין בשיעור מדגיש כי מערכת RAID פועלת באופן שקוף לחלוטין למערכת ההפעלה וליישומים. היא מציגה 'דיסק מדומה' או 'דיסק לוגי' יחיד, ובדומה לזיכרון וירטואלי, התוכניות עובדות כאילו זהו הארד דיסק רגיל אחד. מערכת ההפעלה אינה יודעת שמדובר בדיסק מדומה, ומנגנון ה-RAID הוא זה שמפצל ומנהל את הנתונים בין הדיסקים הפיזיים באופן אוטומטי. לכן, אפשרות ב' היא הנכונה ביותר."}, "_source_file": "0458__Disks__RAID__MC__Easy.json", "_topic_hint": "RAID", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:44:37", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID"], "difficulty_estimation": "Easy", "content": {"text": "בהתבסס על חומר ההרצאה, מהי הטענה הנכונה ביותר לגבי RAID-4 ו-RAID-5?", "code_snippet": null, "options": ["א. RAID-5 עדיף באופן מובהק על RAID-4, ואין סיבה להשתמש ב-RAID-4.", "ב. RAID-4 מציע ביצועי כתיבה טובים יותר מ-RAID-5.", "ג. RAID-5 מתאים רק לביצועים ללא אמינות, בניגוד ל-RAID-4.", "ד. RAID-4 ו-RAID-5 זהים לחלוטין בכל מאפייניהם."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מציין במפורש כי \"RAID-5 is strictly better than RAID-4\" וכן \"אין סיבה להשתמש ב-raid-4\". לכן, הטענה ש-RAID-5 עדיף באופן מובהק על RAID-4 היא הנכונה. אפשרויות ב', ג' ו-ד' אינן נתמכות על ידי חומר ההרצאה או סותרות אותו ישירות."}, "_source_file": "0459__Disks__RAID__MC__Easy.json", "_topic_hint": "RAID", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:44:46", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה המרכזית של מנגנון ה-RAID בהקשר של הצגתו למערכת ההפעלה והיישומים?", "code_snippet": null, "options": ["א. להפוך כל דיסק פיזי לזמין באופן נפרד לכל יישום.", "ב. להציג קבוצת דיסקים פיזיים כדיסק לוגי יחיד ושקוף למערכת ההפעלה.", "ג. לשפר את ביצועי הקריאה והכתיבה על ידי ביצוע פעולות במקביל על דיסקים בודדים בלבד.", "ד. לאפשר גיבוי נתונים ידני על ידי המשתמש בין דיסקים שונים."]}, "solution": {"correct_option": "ב", "explanation": "החומר המצוין בשיעור קובע כי 'השימוש העיקרי של raid הוא בדומה לזיכרון וירטואלי, שזה יהיה שקוף לחלוטין. אנחנו משתמשים בו כאילו זה הארד דיסק רגיל.' וכן 'מערכת raid: Raid(redundant array of independent disks): נחשב דיסק מדומה. בדומה לזיכרון וירטואלי, נצפה בדיסק מדומה, דיסק לוגי. כשהתוכנית עובדת היא תכתוב את כל הנתונים שלה למקום אחד (רכיב חומרה- הארד דיסק לוגי), וגם מערכת ההפעלה לא תדע שמדובר בדיסק מדומה. מבחינתנו יש הארד דיסק אחד.' מכאן שהמטרה המרכזית היא להציג למערכת ההפעלה וליישומים דיסק לוגי יחיד ושקוף, המאגד בתוכו מספר דיסקים פיזיים, מבלי שהם יצטרכו לדעת על הפיצול או הניהול הפנימי של הנתונים."}, "_source_file": "0460__Disks__RAID__MC__Easy.json", "_topic_hint": "RAID", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:44:55", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID"], "difficulty_estimation": "Medium", "content": {"text": "מהי התכונה המרכזית המבדילה מערכת RAID ממערכת JBOD (Just a Bunch Of Disks) בהיבט של ניהול נתונים עבור מערכת ההפעלה והיישומים?", "code_snippet": null, "options": ["א. מערכת RAID תמיד מספקת ביצועים טובים יותר ממערכת JBOD.", "ב. מערכת RAID מבטיחה תמיד גיבוי מלא של הנתונים במקרה של כשל דיסק יחיד.", "ג. מערכת RAID מציגה את אוסף הדיסקים הפיזיים כדיסק לוגי יחיד ושקוף למערכת ההפעלה וליישומים.", "ד. מערכת RAID דורשת חומרת בקר ייעודית, בעוד JBOD היא פתרון תוכנה בלבד."]}, "solution": {"correct_option": "ג", "explanation": "חומר ההרצאה מדגיש כי מנגנון ה-RAID בא לנהל את הדיסקים הפיזיים באופן שקוף לחלוטין למערכת ההפעלה וליישומים. הוא מציג את אוסף הדיסקים כדיסק מדומה, דיסק לוגי יחיד, כך ש\"מבחינתנו יש הארד דיסק אחד\" ו\"התוכנית שלנו יכולה להמשיך לעבוד רגיל ולשמור איך שהיא רוצה\". לעומת זאת, בגישת JBOD, \"התוכנית שלנו תנהל קבצים בכמה מקומות שונים\", מה שמסורבל ומצריך תוכניות מיוחדות. לכן, התכונה המרכזית המבדילה היא השקיפות והצגת דיסק לוגי יחיד. אפשרות א' אינה נכונה מכיוון שלא כל רמות ה-RAID תמיד משפרות ביצועים (למשל, כתיבה ב-RAID-1). אפשרות ב' אינה נכונה מכיוון ש-RAID-0, לדוגמה, אינו מספק אמינות או גיבוי. אפשרות ד' אינה נכונה מכיוון שמנגנון ה-RAID יכול להיות מיושם גם בתוכנה וגם בחומרה, כפי שמצוין בחומר."}, "_source_file": "0461__Disks__RAID__MC__Medium.json", "_topic_hint": "RAID", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:45:08", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID"], "difficulty_estimation": "Medium", "content": {"text": "איזו מהטענות הבאות לגבי מערכות RAID נכונה על פי חומר ההרצאה?", "code_snippet": null, "options": ["א. RAID-0 משפר ביצועים ואמינות גם יחד על ידי פיצול נתונים בין דיסקים.", "ב. אין סיבה ממשית להשתמש ב-RAID-4, שכן RAID-5 עדיף ממנו באופן מובהק.", "ג. מערכת RAID דורשת ממערכת ההפעלה לנהל את פיצול הנתונים והכפלתם באופן מפורש.", "ד. JBOD מספק מנגנון שקוף וקל לניהול דיסקים מרובים, ומשמש כאלטרנטיבה מודרנית ל-RAID."]}, "solution": {"correct_option": "ב", "explanation": "חומר ההרצאה מציין במפורש כי \"RAID-5 is strictly better than RAID-4\" וכי \"אין סיבה להשתמש ב-raid-4\". לכן, טענה ב' נכונה. טענה א' אינה נכונה מכיוון ש-RAID-0 משפר ביצועים אך אינו מספק אמינות, ואף מגדיל את הסיכון לאובדן נתונים במקרה של כשל דיסק בודד. טענה ג' אינה נכונה מכיוון שמנגנון ה-RAID נועד להיות שקוף לחלוטין למערכת ההפעלה וליישומים, ונתפס כדיסק לוגי יחיד, בדומה לזיכרון וירטואלי. טענה ד' אינה נכונה, שכן JBOD אינו מנגנון שקוף וקל לניהול; הוא דורש מהיישומים לנהל את פיצול המידע באופן ידני, בניגוד למנגנון ה-RAID שבא לפתור בעיה זו."}, "_source_file": "0462__Disks__RAID__MC__Medium.json", "_topic_hint": "RAID", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:45:24", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID"], "difficulty_estimation": "Medium", "content": {"text": "על פי חומר ההרצאה, איזו מהטענות הבאות לגבי RAID-4 ו-RAID-5 היא הנכונה ביותר?", "code_snippet": null, "options": ["א. RAID-5 מציע ביצועי כתיבה מהירים יותר באופן מובהק מ-RAID-4.", "ב. RAID-4 ו-RAID-5 מספקים את אותה רמת אמינות וביצועים בדיוק, ולכן אין יתרון לאחד על פני השני.", "ג. RAID-5 עדיף באופן מובהק על RAID-4, ולכן אין סיבה להשתמש ב-RAID-4.", "ד. RAID-4 מציע יתרון בביצועי קריאה על פני RAID-5."]}, "solution": {"correct_option": "ג", "explanation": "חומר ההרצאה קובע במפורש כי \"RAID-5 is strictly better than RAID-4\" וכן \"אין סיבה להשתמש ב-raid-4\". קביעות אלו מצביעות על עדיפות מובהקת של RAID-5 על פני RAID-4, כפי שמנוסח באפשרות ג'. שאר האפשרויות אינן נכונות: אפשרויות א' ו-ד' סותרות את טבלת הביצועים שבחומר ההרצאה, שבה מוצגים ערכים זהים ל-Read Latency (D) ול-Write Latency (2D) עבור שני הסוגים. אפשרות ב' סותרת ישירות את הקביעה המפורשת בחומר ההרצאה כי ל-RAID-5 יש עדיפות מובהקת ואין סיבה להשתמש ב-RAID-4, למרות שהטבלה מציגה אמינות (Reliability) זהה (1) עבור שניהם."}, "_source_file": "0463__Disks__RAID__MC__Medium.json", "_topic_hint": "RAID", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:45:44", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID"], "difficulty_estimation": "Medium", "content": {"text": "איזה מהתיאורים הבאים מייצג בצורה הנכונה ביותר את מטרתו העיקרית של מנגנון RAID מנקודת מבטה של מערכת ההפעלה והיישומים?", "code_snippet": null, "options": ["א. RAID מאפשר למערכת ההפעלה לנהל כל דיסק פיזי בנפרד, מה שמספק גמישות מירבית בבחירת אלגוריתמי אחסון.", "ב. RAID יוצר אשליה של דיסק לוגי יחיד, כאשר הוא מטפל בפיצול הנתונים, שכפולם וניהולם על פני מספר דיסקים פיזיים באופן שקוף לחלוטין.", "ג. RAID דורש מהיישומים לפצל את הנתונים באופן ידני בין הדיסקים הפיזיים השונים כדי להשיג שיפור בביצועים.", "ד. RAID נועד בעיקר לניהול גיבויים ידניים של קבצים חשובים על פני מספר דיסקים, ללא קשר לביצועים."]}, "solution": {"correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. מנגנון RAID נועד ליצור אשליה של דיסק לוגי יחיד (דיסק מדומה) עבור מערכת ההפעלה והיישומים. כפי שמצוין בחומר ההרצאה, \"השימוש העיקרי של raid הוא בדומה לזיכרון וירטואלי, שזה יהיה שקוף לחלוטין.\" וכן, \"מבחינתנו יש הארד דיסק אחד.\" מנגנון ה-RAID, בין אם בחומרה או בתוכנה, הוא זה שמנהל באופן שקוף את פיצול הנתונים (כמו ב-striping ב-RAID-0) ואת שכפולם (לצורך אמינות, כפי שנדון ברמות RAID אחרות), על פני הדיסקים הפיזיים המרובים. זאת בניגוד לגישות כמו JBOD, שבהן התוכנית נדרשת לנהל את הנתונים על פני דיסקים שונים באופן מפורש, מה שנחשב למסורבל."}, "_source_file": "0464__Disks__RAID__MC__Medium.json", "_topic_hint": "RAID", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:45:58", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס אך ורק על חומר ההרצאה, איזו מהטענות הבאות לגבי השוואה בין RAID-4 ל-RAID-5 היא הנכונה ביותר?", "code_snippet": null, "options": ["א. RAID-4 מציע יתרון מובהק בביצועי קריאה סדרתיים על פני RAID-5, אך חסר באמינות.", "ב. למרות שלוחות הזמנים לקריאה וכתיבה (latency) המצוינים עבור RAID-4 ו-RAID-5 זהים, אין סיבה מוצדקת להשתמש ב-RAID-4.", "ג. RAID-5 עדיף רק בתרחישים של ביצועי קריאה אקראיים ואמינות, בעוד RAID-4 עדיף ל-I/O סדרתי.", "ד. RAID-4 ו-RAID-5 נחשבים לפתרונות מקבילים לחלוטין, והבחירה ביניהם תלויה בהעדפות אישיות בלבד."]}, "solution": {"correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. חומר ההרצאה מציין במפורש כי \"RAID-5 is strictly better than RAID-4\" וכי \"אין סיבה להשתמש ב-raid-4\". יתרה מכך, הטבלה המצורפת בחומר ההרצאה מראה כי עבור RAID-4 ו-RAID-5, זמן השהיה לקריאה (Read Latency) הוא D וזמן השהיה לכתיבה (Write Latency) הוא 2D, כלומר הם זהים. למרות הדמיון בנתוני ה-latency בטבלה, ההצהרה המפורשת על כך ש-RAID-5 עדיף באופן מובהק ושאין סיבה להשתמש ב-RAID-4, מדגישה את הבחירה ב-RAID-5 כאשר נדרשת אמינות וקיבולת, או I/O סדרתי. לכן, האפשרות היחידה הנכונה היא שאין סיבה מוצדקת להשתמש ב-RAID-4 על פני RAID-5. אפשרויות א', ג' ו-ד' סותרות את ההצהרות המפורשות בחומר ההרצאה."}, "_source_file": "0465__Disks__RAID__MC__Hard.json", "_topic_hint": "RAID", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:46:15", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על חומר ההרצאה, אשר מציין מפורשות כי \"RAID-5 עדיף באופן מוחלט על RAID-4\" וכי \"אין סיבה להשתמש ב-RAID-4\", ובהתחשב בטבלת הביצועים המצורפת עבורם, מהי המסקנה העיקרית הנגזרת מהצהרות אלו עבור מנהל מערכת הבוחר בין רמות RAID אלו?", "code_snippet": null, "options": ["א. למרות של-RAID-4 ול-RAID-5 ביצועי השהיה (latency) זהים לפי הטבלה, ההמלצה החד-משמעית היא לבחור ב-RAID-5 בכל מקרה המצריך גם אמינות וגם קיבולת.", "ב. ההצהרה ש-RAID-5 עדיף באופן מוחלט על RAID-4 מעידה על כך של-RAID-5 יש בהכרח ביצועי כתיבה טובים יותר, אף אם זה לא משתקף בטבלת השהיות.", "ג. מכיוון של-RAID-4 ול-RAID-5 יש אותם ביצועי השהיה (D לקריאה, 2D לכתיבה), הבחירה ביניהם תלויה בעיקר בעלות היישום, ולא בביצועים או אמינות.", "ד. RAID-4 מועדף על RAID-5 במצבים בהם נדרשת אמינות גבוהה יותר על פני ביצועים, מכיוון שהוא פשוט יותר ליישום."]}, "solution": {"correct_option": "א", "explanation": "החומר מצהיר במפורש ש-RAID-5 \"עדיף באופן מוחלט על RAID-4\" וכי \"אין סיבה להשתמש ב-RAID-4\". בנוסף, הוא ממליץ על RAID-5 עבור תרחישים הדורשים \"Capacity and reliability\" ו-\"Sequential I/O and maximize capacity\". למרות שטבלת הביצועים מציגה את אותם ערכי השהיה (latency) עבור RAID-4 ו-RAID-5 (D לקריאה ו-2D לכתיבה), ההצהרה על עדיפותו המוחלטת של RAID-5 והיעדר הסיבה להשתמש ב-RAID-4, יחד עם ההמלצות הספציפיות, מכוונת את מנהל המערכת לבחור ב-RAID-5 כאשר דרישות המערכת כוללות אמינות וקיבולת. אפשרות ב' שגויה מכיוון שהטבלה מציגה ביצועי כתיבה זהים. אפשרויות ג' ו-ד' שגויות מכיוון שהן סותרות ישירות את ההצהרות החד-משמעיות של חומר ההרצאה לגבי עדיפותו של RAID-5 וחוסר התועלת ב-RAID-4."}, "_source_file": "0466__Disks__RAID__MC__Hard.json", "_topic_hint": "RAID", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:46:34", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על חומר ההרצאה הנתון, אילו מההיגדים הבאים נכון לגבי RAID-4 ו-RAID-5?", "code_snippet": null, "options": ["א. למרות ש-RAID-4 ו-RAID-5 מציגים זמן אחזור קריאה וכתיבה זהים בטבלה, RAID-5 נחשב עדיף באופן מוחלט ואין סיבה להשתמש ב-RAID-4.", "ב. RAID-4 מציע יתרון באמינות על פני RAID-5, כיוון שהוא תומך בגיבוי של יותר מדיסקים במקרה של כשל.", "ג. RAID-5 מיועד בעיקר לשיפור ביצועי קריאה רנדומלית, בעוד RAID-4 מתמקד ביעילות אחסון נתונים סדרתיים.", "ד. זמן אחזור הכתיבה (Write Latency) ב-RAID-4 עדיף על זה של RAID-5, מה שהופך אותו לבחירה טובה יותר ליישומים עתירי כתיבה."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מציין במפורש כי 'RAID-5 is strictly better than RAID-4' וכי 'אין סיבה להשתמש ב-raid-4'. למרות שטבלת ההשוואה מציגה עבור שניהם זמן אחזור קריאה (Read Latency) של D וזמן אחזור כתיבה (Write Latency) של 2D, והם תומכים שניהם בכשל של דיסק אחד (1), ההצהרה המפורשת על עדיפותו המוחלטת של RAID-5 ואי הצורך ב-RAID-4 גוברת. לכן, ההיגד באפשרות א' הוא הנכון ביותר על פי חומר ההרצאה. אפשרויות ב' ו-ד' שגויות על פי הטבלה המציגה ערכים זהים לאמינות (1 דיסק כשל) ולזמני כתיבה. אפשרות ג' שגויה כיוון שהחומר לא מייחס ל-RAID-4 התמחות ב-I/O סדרתי, ואף מציין ש-RAID-5 מומלץ גם עבור Sequential I/O וגם עבור Capacity and reliability."}, "_source_file": "0467__Disks__RAID__MC__Hard.json", "_topic_hint": "RAID", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:46:50", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על חומר ההרצאה, בהינתן שהמטרה היא להשיג איזון אופטימלי בין אמינות לקיבולת תוך תמיכה בפעולות קריאה וכתיבה סדרתיות, איזו מהטענות הבאות משקפת בצורה הטובה ביותר את ההמלצות לשימוש במערכי RAID?", "code_snippet": null, "options": ["א. יש לבחור ב-RAID-5, מכיוון שהוא עדיף באופן מוחלט על RAID-4 עבור מטרות אלו, ומספק אמינות (תמיכה בכשל דיסק אחד) יחד עם ניצול קיבולת יעיל, ובנוסף מומלץ עבור I/O סדרתי.", "ב. עדיף להשתמש ב-RAAD-4, כיוון שהוא מציע ביצועים דומים ל-RAID-5 בפעולות קריאה וכתיבה סדרתיות, ופשוט יותר למימוש.", "ג. RAID-0 יהווה את הבחירה הטובה ביותר לשיפור ביצועים של קריאות וכתיבות סדרתיות, אך ללא יכולת התאוששות מכשל דיסק, ולכן יש לשקול אותו רק אם אמינות אינה דרישה קריטית.", "ד. RAID-1 הוא האפשרות המומלצת ביותר, שכן הוא מספק את רמת האמינות הגבוהה ביותר על ידי שכפול מלא של הנתונים, מה שהופך אותו לאידיאלי לכל מטרה הדורשת אמינות וקיבולת."]}, "solution": {"correct_option": "א", "explanation": "השאלה מתמקדת במציאת האיזון האופטימלי בין אמינות לקיבולת, תוך תמיכה ב-I/O סדרתי. חומר ההרצאה מציין במפורש כי RAID-5 מומלץ עבור 'Capacity and reliability' וכן עבור 'Sequential I/O and maximize capacity'. בנוסף, נכתב כי 'RAID-5 is strictly better than RAID-4' ו'אין סיבה להשתמש ב-raid-4'.\n\nא. זו התשובה הנכונה. היא משלבת את כל ההיבטים הרלוונטיים: RAID-5 עדיף מ-RAID-4, הוא מספק אמינות (תמיכה בכשל של דיסק אחד, כפי שמוצג בטבלה), מציע ניצול קיבולת יעיל (N-1 דיסקים לנתונים מתוך N דיסקים סה\"כ, טוב יותר מ-RAID-1 מבחינת קיבולת עבור יתירות), ומומלץ ספציפית עבור I/O סדרתי.\n\nב. טענה זו שגויה מכיוון שחומר ההרצאה קובע במפורש ש-RAID-5 עדיף באופן מוחלט על RAID-4, ואין סיבה להשתמש ב-RAID-4. כמו כן, הטענה על פשטות מימוש אינה מופיעה בחומר.\n\nג. RAID-0 אכן משפר ביצועים (במיוחד עבור I/O סדרתי) אך הוא אינו מספק אמינות כלל ('no reliability'). השאלה דורשת איזון בין אמינות לקיבולת, ולכן RAID-0 אינו הבחירה המתאימה.\n\nד. RAID-1 מספק אמינות גבוהה באמצעות שכפול מלא, אך הוא אינו האפשרות המומלצת ביותר ל'קיבולת מקסימלית', מכיוון שהוא משתמש בחצי מהקיבולת הכוללת לשכפול (N/2), בעוד ש-RAID-5 מנצל את הקיבולת בצורה יעילה יותר עבור יתירות (N-1). חומר ההרצאה ממליץ על RAID-5 עבור 'Capacity and reliability' ו-'maximize capacity', מה שמעיד על עדיפותו בתרחיש זה."}, "_source_file": "0468__Disks__RAID__MC__Hard.json", "_topic_hint": "RAID", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:47:13", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID-0 Striping"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של טכניקת ה-striping ב-RAID-0?", "code_snippet": null, "options": ["א. שיפור ביצועים על ידי פיצול נתונים לרוחב דיסקים מרובים.", "ב. הבטחת עמידות בפני תקלות על ידי שכפול נתונים.", "ג. הגדלת נפח האחסון הכולל של המערכת.", "ד. הקטנת צריכת החשמל של מערך הדיסקים."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מציין במפורש כי RAID-0 משתמש בטכניקת ה-striping שנועדה 'לשפר את הביצועים'. הרעיון מאחורי פיזור הנתונים (סקטורים) לסירוגין בין הדיסקים הוא לאפשר ניצול מקבילי שלהם בזמן פעולות קריאה סדרתיות, מה שמוביל ל'הגברת הביצועים בכמעט פי 2'. כמו כן, צוין במפורש כי RAID-0 מיועד ל-'Performance and no reliability', מה שמדגיש את מטרתו העיקרית בשיפור הביצועים."}, "_source_file": "0469__Disks__RAID-0_Striping__MC__Easy.json", "_topic_hint": "RAID-0 Striping", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:47:22", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID-0 Striping"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של טכניקת ה-striping המשמשת ב-RAID-0?", "code_snippet": null, "options": ["א. לשפר את ביצועי הקריאה והכתיבה על ידי פיצול נתונים בין דיסקים שונים.", "ב. לספק יתירות נתונים ואמינות גבוהה במקרה של כשל דיסק.", "ג. לשכפל את כל הנתונים על פני מספר דיסקים כדי למנוע אובדן מידע.", "ד. לאחד מספר דיסקים פיזיים לדיסק לוגי יחיד מבלי לשפר ביצועים."]}, "solution": {"correct_option": "א", "explanation": "RAID-0, המכונה גם Striping, מיועד בראש ובראשונה לשפר את ביצועי ה-I/O (קריאה וכתיבה) של המערכת. הוא עושה זאת על ידי פיצול סקטורים או בלוקים של נתונים (בהתאם ל-chunk size) וחלוקתם לסירוגין בין מספר דיסקים פיזיים. גישה זו מאפשרת לבצע פעולות קריאה וכתיבה מקבילות על דיסקים שונים, ובכך להגביר את קצב העברת הנתונים באופן משמעותי, לעיתים קרובות כמעט פי שניים עבור פעולות סדרתיות. המטרה העיקרית היא הגברת ביצועים, ולא אמינות או יתירות נתונים."}, "_source_file": "0470__Disks__RAID-0_Striping__MC__Easy.json", "_topic_hint": "RAID-0 Striping", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:47:31", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID-0 Striping"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של טכניקת Striping ב-RAID-0?", "code_snippet": null, "options": ["א. שיפור ביצועי קריאה וכתיבה על ידי פיזור נתונים לסירוגין בין דיסקים שונים.", "ב. הבטחת יתירות נתונים ושרידות במקרה של כשל דיסק בודד.", "ג. הקטנת שטח האחסון הנדרש עבור הנתונים במערכת.", "ד. יצירת דיסק לוגי יחיד שקוף למערכת ההפעלה המדמה דיסק פיזי גדול יותר."]}, "solution": {"correct_option": "א", "explanation": "לפי חומר ההרצאה, RAID-0 משתמש בטכניקת Striping שמטרתה העיקרית היא שיפור ביצועים. טכניקה זו מחלקת את הסקטורים (או בלוקים) של הנתונים לסירוגין בין מספר דיסקים פיזיים. רעיון זה מאפשר ניצול מקבילי של הדיסקים לפעולות קריאה וכתיבה סדרתיות, ובכך מגביר את הביצועים באופן משמעותי, כפי שצוין בשיעור: 'זה גורם להגברת הביצועים בכמעט פי 2'. האפשרויות האחרות אינן המטרה העיקרית של ה-striping ב-RAID-0; לדוגמה, יתירות (אמינות) מתוארת כמאפיין שאינו קיים ב-RAID-0 ('no reliability'), והקטנת שטח האחסון אינה מטרה של RAID-0. יצירת דיסק לוגי שקוף היא מאפיין כללי של RAID, אך לא המטרה הספציפית של טכניקת ה-striping עצמה."}, "_source_file": "0471__Disks__RAID-0_Striping__MC__Easy.json", "_topic_hint": "RAID-0 Striping", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:47:42", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID-0 Striping"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של שימוש ב-RAID-0, וכיצד הוא משיג אותה על פי החומר הנלמד?", "code_snippet": null, "options": ["א. לשפר ביצועים על ידי פיצול נתונים (סקטורים/בלוקים) לסירוגין בין מספר דיסקים.", "ב. לספק יתירות ואמינות נתונים על ידי שכפול נתונים בין דיסקים שונים.", "ג. להגדיל את נפח האחסון הכולל של המערכת ללא שיפור ביצועים משמעותי.", "ד. לאפשר גישה אקראית מהירה יותר לנתונים באמצעות שמירת אינדקסים מרוכזים."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, RAID-0 (המכונה גם striping) נועד בראש ובראשונה 'לשפר את הביצועים'. הוא משיג זאת על ידי פיצול הנתונים – 'נחלק את הסקטורים השונים בין הדיסקים לסירוגין, פעם לדיסק אחד, פעם לדיסק אחר'. פיזור זה מאפשר ניצול מקבילי של הדיסקים בפעולות סדרתיות, מה שמוביל ל'הגברת הביצועים בכמעט פי 2'. האפשרויות האחרות אינן מתארות נכונה את מטרתו או מנגנונו של RAID-0 כפי שהוצג בחומר – RAID-0 אינו מספק יתירות (אמינות) ואף נאמר עליו 'no reliability', והמטרה העיקרית היא שיפור ביצועים ולא רק הגדלת נפח אחסון."}, "_source_file": "0472__Disks__RAID-0_Striping__MC__Easy.json", "_topic_hint": "RAID-0 Striping", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:47:50", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID-0 Striping"], "difficulty_estimation": "Medium", "content": {"text": "מהי הסיבה העיקרית לשיפור הביצועים במערך RAID-0 (striping) עבור פעולות קריאה/כתיבה סדרתיות?", "code_snippet": null, "options": ["א. פיזור סקטורים לסירוגין בין דיסקים פיזיים מאפשר ניצול מקבילי של הדיסקים.", "ב. שכפול נתונים על פני מספר דיסקים מפחית את זמן האחזור בקריאה.", "ג. שימוש בזיכרון מטמון (cache) גדול יותר עבור נתוני הדיסק.", "ד. פישוט מבנה מערכת הקבצים על ידי איחוד דיסקים לוגיים."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מציין במפורש כי טכניקת ה-striping ב-RAID-0 נועדה לשפר ביצועים על ידי חלוקת סקטורים לסירוגין בין דיסקים פיזיים. הרעיון הוא שרוב פעולות הדיסק הן סדרתיות, וכאשר יש צורך לקרוא מספר סקטורים ברצף, ניתן לנצל את הדיסקים במקביל, מה שגורם להגברת הביצועים. אפשרות ב' מתארת mirroring (RAID-1), שאינו המנגנון של RAID-0. אפשרויות ג' ו-ד' אינן הסיבה העיקרית והספציפית לשיפור הביצועים ב-RAID-0 כפי שתואר בחומר, אשר מתמקד בניצול מקבילי של הדיסקים."}, "_source_file": "0474__Disks__RAID-0_Striping__MC__Medium.json", "_topic_hint": "RAID-0 Striping", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:48:14", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID-0 Striping"], "difficulty_estimation": "Medium", "content": {"text": "מהו העיקרון המרכזי שבאמצעותו טכניקת ה-striping ב-RAID-0 משפרת את ביצועי קריאת/כתיבת נתונים?", "code_snippet": null, "options": ["א. שמירת עותקים זהים של כל סקטור נתונים על לפחות שני דיסקים פיזיים, מה שמאפשר קריאה מדיסק חלופי במקרה של תקלה.", "ב. פיצול רצף הנתונים לסקטורים (או גושים) קטנים ופיזורם לסירוגין בין מספר דיסקים פיזיים, כך שניתן לבצע פעולות I/O במקביל.", "ג. הקצאת דיסק ייעודי לאחסון נתוני יתירות (parity) המאפשרים שחזור מידע במקרה של כשל באחד מדיסקי הנתונים.", "ד. יצירת דיסק לוגי גדול יותר על ידי איחוד נפח האחסון של מספר דיסקים פיזיים, ללא שינוי באופן גישת מערכת ההפעלה לנתונים."]}, "solution": {"correct_option": "ב", "explanation": "RAID-0 משתמש בטכניקת ה-striping כדי לשפר ביצועים. בטכניקה זו, הנתונים מחולקים לסקטורים או גושים (chunks) קטנים ומפוזרים לסירוגין על פני מספר דיסקים פיזיים. כאשר מתבצעת פעולת קריאה או כתיבה סדרתית, ניתן לגשת בו-זמנית לסקטורים/גושים שונים מדיסקים שונים. לדוגמה, אם יש שני דיסקים, סקטור 0 נכתב לדיסק הראשון, סקטור 1 לדיסק השני, סקטור 2 שוב לראשון וכן הלאה. גישה מקבילית זו לדיסקים מרובים מאפשרת להגביר באופן משמעותי את קצב העברת הנתונים (throughput) ובכך לשפר את הביצועים, כפי שמצוין בחומר ההרצאה: \"אם עכשיו מישהו ירצה לקרוא שני סקטורים, נוכל לנצל אותם במקביל. זה גורם להגברת הביצועים בכמעט פי 2\"."}, "_source_file": "0475__Disks__RAID-0_Striping__MC__Medium.json", "_topic_hint": "RAID-0 Striping", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:48:27", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID-0 Striping"], "difficulty_estimation": "Medium", "content": {"text": "מהי הטכניקה העיקרית בה משתמש RAID-0 לשיפור ביצועים, וכיצד היא פועלת?", "code_snippet": null, "options": ["א. היא משכפלת נתונים על פני מספר דיסקים כדי להבטיח זמינות נתונים גבוהה, ובכך מאיצה קריאות.", "ב. היא מפצלת סקטורים (בלוקי נתונים) לסירוגין בין דיסקים פיזיים מרובים, ומאפשרת גישה מקבילית ועיבוד בו-זמני לפעולות סדרתיות.", "ג. היא משתמשת בדיסק ייעודי לשמירת נתוני זוגיות (parity) כדי לשחזר נתונים שאבדו, מה שמשפר בעקיפין את הביצועים.", "ד. היא שומרת נתונים בזיכרון מטמון מהיר בנפרד ממערך הדיסקים, ובכך מקצרת את זמני הגישה."]}, "solution": {"correct_option": "ב", "explanation": "RAID-0 משתמש בטכניקת ה-striping, אשר נועדה לשפר ביצועים. בטכניקה זו, סקטורים (או בלוקי נתונים בגודל chunk size) מחולקים לסירוגין בין מספר דיסקים פיזיים. הרעיון הוא שרוב פעולות הקלט/פלט הן סדרתיות, ולכן פיזור הנתונים מאפשר למערכת לנצל את הדיסקים במקביל. כאשר נדרשת קריאה או כתיבה של נתונים סדרתיים, חלקים שונים מהם יכולים להיקרא או להיכתב במקביל על ידי דיסקים שונים, מה שמגביר את הביצועים באופן משמעותי (עד פי 2, לפי החומר). אפשרות א' מתארת mirroring (RAID-1), אפשרות ג' מתארת שימוש ב-parity (כמו ב-RAID-4/5), ואפשרות ד' מתארת מנגנון cache כללי שאינו ייחודי ל-RAID-0."}, "_source_file": "0476__Disks__RAID-0_Striping__MC__Medium.json", "_topic_hint": "RAID-0 Striping", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:48:37", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID-0 Striping"], "difficulty_estimation": "Hard", "content": {"text": "מערכת RAID-0 מתוכננת בעיקר לשיפור ביצועים באמצעות טכניקת Striping. בהתחשב בכך שהיא מציגה למערכת ההפעלה דיסק לוגי יחיד ושקוף, ובהינתן שרוב פעולות הדיסק הן סדרתיות, איזו מההשלכות הבאות היא הנכונה ביותר לגבי אמינות הנתונים במערכת RAID-0?", "code_snippet": null, "options": ["א. כשל של דיסק פיזי אחד במערך יגרום לירידה בביצועים אך לא לאובדן מידע, מכיוון שהנתונים משוכפלים באופן אוטומטי.", "ב. אובדן של דיסק פיזי אחד מתוך המערך יוביל לאובדן מוחלט של כלל הנתונים המאוחסנים במערך RAID-0.", "ג. RAID-0 מבטיחה אמינות נתונים גבוהה על ידי פיזור הנתונים בין דיסקים רבים, כך שכשל בדיסק בודד אינו משפיע על זמינותם.", "ד. אמינות הנתונים ב-RAID-0 זהה לזו של דיסק פיזי בודד באותו נפח, שכן היא אינה כוללת מנגנוני גיבוי או שחזור."]}, "solution": {"correct_option": "ב", "explanation": "החומר המצוין בשיעור קובע במפורש כי RAID-0 מיועדת ל-\"Performance and no reliability\". טכניקת ה-Striping ב-RAID-0 מפזרת את הנתונים (סקטורים או בלוקים) לסירוגין בין הדיסקים הפיזיים המרכיבים את המערך. משמעות הדבר היא שכל קובץ או מערך נתונים מחולק לחלקים, וחלקים אלו מאוחסנים על דיסקים שונים. כתוצאה מכך, אם דיסק פיזי אחד נכשל, חלקים חיוניים מכלל הנתונים המאוחסנים במערך הופכים לבלתי נגישים או פגומים, מה שמוביל לאובדן מוחלט של הנתונים במערך כולו. RAID-0 אינה כוללת כל מנגנון יתירות (redundancy) או שיכפול (mirroring) לגיבוי נתונים."}, "_source_file": "0477__Disks__RAID-0_Striping__MC__Hard.json", "_topic_hint": "RAID-0 Striping", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:48:55", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID-0 Striping"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על עקרונות ה-Striping ב-RAID-0, איזו קביעה לגבי אמינות הנתונים (Data Reliability) במערכת היא הנכונה ביותר?", "code_snippet": null, "options": ["א. RAID-0 משפר את אמינות הנתונים על ידי פיזורם בין דיסקים מרובים, ומאפשר שחזור במקרה של כשל בדיסק בודד.", "ב. כשל בדיסק פיזי בודד במערך RAID-0 יוביל לאובדן פוטנציאלי של כלל הנתונים המאוחסנים במערך.", "ג. RAID-0 אינו משפיע כלל על אמינות הנתונים, שכן מטרתו היחידה היא שיפור ביצועי קריאה וכתיבה.", "ד. אמינות הנתונים ב-RAID-0 תלויה בגודל ה-chunk size; ככל שה-chunk גדול יותר, כך האמינות גבוהה יותר."]}, "solution": {"correct_option": "ב", "explanation": "החומר המצוין בשיעור קובע במפורש כי RAID-0 מיועד לביצועים (Performance) אך ללא אמינות (no reliability). טכניקת ה-Striping ב-RAID-0 מפצלת את הנתונים לסירוגין בין דיסקים פיזיים שונים ללא יצירת עותקים מיותרים או מידע שחזור (parity). כתוצאה מכך, אם דיסק פיזי בודד במערך כזה כושל, חלקים מהנתונים של כל הקבצים (או רבים מהם) הופכים לבלתי נגישים, מה שמוביל לאובדן מוחלט של כלל הנתונים המאוחסנים במערך הווירטואלי. זוהי ההשלכה המרכזית של היעדר אמינות ב-RAID-0."}, "_source_file": "0478__Disks__RAID-0_Striping__MC__Hard.json", "_topic_hint": "RAID-0 Striping", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:49:11", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID-0 Striping"], "difficulty_estimation": "Hard", "content": {"text": "בהתחשב בכך שמערך RAID-0 נועד לשפר ביצועים באמצעות פיזור נתונים (striping) לסירוגין בין מספר דיסקים פיזיים, כיצד תופסת מערכת ההפעלה את המערך הזה, ומה ההשלכות המרכזיות על שלמות הנתונים במקרה של כשל באחד הדיסקים הפיזיים?", "code_snippet": null, "options": ["א. מערכת ההפעלה רואה דיסק לוגי יחיד, אך כשל של דיסק פיזי אחד במערך יגרום לאובדן כל הנתונים במערך RAID-0, מכיוון שאין יתירות.", "ב. מערכת ההפעלה מודעת לפיצול הנתונים ומנהלת את הגישה לדיסקים הפיזיים בנפרד, ובמקרה של כשל דיסק, הנתונים הנותרים על הדיסקים התקינים נשמרים.", "ג. מערך RAID-0 מספק גיבוי נתונים חלקי על ידי שכפול סקטורים חיוניים, ומערכת ההפעלה מנצלת זאת לשיפור ביצועי קריאה בלבד.", "ד. מערכת ההפעלה מטפלת במערך RAID-0 כקבוצה של דיסקים נפרדים, כאשר כל דיסק מכיל בלוקים רציפים של נתונים בגודל קבוע (chunk size) לפני המעבר לדיסק הבא, ובכך משפרת את זמן הגישה לנתונים סדרתיים."]}, "solution": {"correct_option": "א", "explanation": "לפי חומר ההרצאה, RAID-0 הוא שקוף לחלוטין למערכת ההפעלה ולתוכניות, והן תופסות אותו כ'הארד דיסק רגיל' או 'דיסק לוגי יחיד'. מנגנון ה-RAID הוא זה שמפצל את הנתונים באופן שקוף לדיסקים הפיזיים. כמו כן, ההרצאה מציינת במפורש כי RAID-0 מיועד ל'Performance and no reliability'. מכיוון שהנתונים מפוזרים לסירוגין על פני הדיסקים הפיזיים, כשל של דיסק אחד בלבד במערך RAID-0 יגרום לאובדן חלקי של כל קובץ או נתון במערך, ולמעשה הופך את כל הנתונים במערך לבלתי שמישים. לכן, אין יתירות (redundancy) או יכולת שחזור במקרה של כשל דיסק ב-RAID-0."}, "_source_file": "0479__Disks__RAID-0_Striping__MC__Hard.json", "_topic_hint": "RAID-0 Striping", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:49:23", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID-0 Striping"], "difficulty_estimation": "Hard", "content": {"text": "מערכת RAID-0 מתוכננת בעיקר לשיפור ביצועים. בהתבסס על מנגנון ה-striping והאופן שבו RAID מתממשק עם מערכת ההפעלה, איזו מהטענות הבאות מתארת בצורה המדויקת ביותר את מאפייניה המהותיים של RAID-0?", "code_snippet": null, "options": ["א. RAID-0 משיגה שיפור ביצועים משמעותי על ידי פיזור נתונים לסירוגין בין דיסקים פיזיים, מה שמאפשר קריאה וכתיבה מקבילית, אך היא אינה מספקת יתירות או הגנה מפני כשל דיסק, והיא שקופה לחלוטין למערכת ההפעלה וליישומים.", "ב. RAID-0 משתמשת בשיכפול נתונים (mirroring) בין דיסקים כדי להבטיח זמינות גבוהה וגם לשפר ביצועים בקריאה, אך היא דורשת מנהל התקן מיוחד במערכת ההפעלה כדי לנהל את הכפילויות.", "ג. RAID-0 נועדה להגדיל את נפח האחסון הזמין על ידי איחוד דיסקים קטנים לדיסק לוגי גדול יותר, כאשר היתרונות בביצועים הם שוליים ומתבטאים בעיקר בפעולות כתיבה טוריות.", "ד. RAID-0 מבטיחה שלמות נתונים ועמידות בפני כשל דיסק באמצעות שימוש במידע זוגיות (parity), תוך שיפור ביצועי כתיבה על ידי פיזור המידע, אך אינה שקופה למערכת ההפעלה ודורשת התאמה מיוחדת של מערכת הקבצים."]}, "solution": {"correct_option": "א", "explanation": "תשובה א' נכונה מכיוון שהיא משלבת את כל המאפיינים המרכזיים של RAID-0 כפי שתוארו בחומר ההרצאה:\n1.  **שיפור ביצועים על ידי striping**: חומר ההרצאה מציין ש-RAID-0 משתמשת בטכניקת ה-striping כדי 'לשפר את הביצועים' ו'נחלק את הסקטורים השונים בין הדיסקים לסירוגין', מה שמאפשר 'לנצל אותם במקביל' ו'גורם להגברת הביצועים בכמעט פי 2'.\n2.  **חוסר יתירות/הגנה מפני כשל**: טבלת ההשוואה מציינת במפורש 'Performance and no reliability -> RAID-0'. בנוסף, למרות ש-RAID באופן כללי יכול לספק גיבויים, RAID-0 ספציפית אינו מספק זאת.\n3.  **שקיפות למערכת ההפעלה**: ההרצאה מדגישה ש-RAID 'יהיה שקוף לחלוטין' ו'גם מערכת ההפעלה לא תדע שמדובר בדיסק מדומה. מבחינתנו יש הארד דיסק אחד'.\n\nתשובה ב' שגויה כי היא מתארת mirroring (שיכפול נתונים), שהוא מאפיין של RAID-1, לא RAID-0, וגם לא נכון לגבי דרישת מנהל התקן מיוחד.\nתשובה ג' שגויה כי המטרה העיקרית של RAID-0 היא שיפור ביצועים ולא רק הגדלת נפח, והיא אינה מתארת נכונה את יתרונות הביצועים.\nתשובה ד' שגויה כי היא מתארת שימוש במידע זוגיות (parity) להגנה על נתונים, שהוא מאפיין של RAID-4 או RAID-5, לא RAID-0, וגם טועה לגבי השקיפות."}, "_source_file": "0480__Disks__RAID-0_Striping__MC__Hard.json", "_topic_hint": "RAID-0 Striping", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:49:41", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID-1 Mirroring"], "difficulty_estimation": "Easy", "content": {"text": "מהי הגישה העיקרית של RAID-1 (mirroring) לניהול נתונים בין דיסקים, כפי שתוארה בחומר ההרצאה?", "code_snippet": null, "options": ["א. שכפול כל בלוק נתונים על פני מספר דיסקים.", "ב. פיצול נתונים (striping) לסירוגין בין דיסקים שונים לשיפור ביצועים.", "ג. שימוש בדיסק אחד לנתונים ובדיסק אחר לשמירת מידע תיקון (parity).", "ד. איחוד מספר דיסקים לדיסק וירטואלי אחד ללא כל שכפול נתונים."]}, "solution": {"correct_option": "א", "explanation": "RAID-1, המכונה גם 'mirroring', מבוסס על שכפול נתונים במטרה להגביר את אמינות המערכת. על פי חומר ההרצאה, ב-RAID-1 \"נשכפל את הנתונים בין כולם (כל בלוק יהיה משוכפל בין כל הדיסקים)\". גישה זו מבטיחה שאם דיסק אחד כושל, הנתונים עדיין זמינים מהדיסק המשוכפל. אפשרות ב' מתארת את RAID-0 (striping), אפשרות ג' מתארת מנגנון המשתמש ב-parity (כמו RAID-4 או RAID-5), ואפשרות ד' אינה כוללת את מנגנון השכפול המרכזי של RAID-1."}, "_source_file": "0481__Disks__RAID-1_Mirroring__MC__Easy.json", "_topic_hint": "RAID-1 Mirroring", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:49:49", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID-1 Mirroring"], "difficulty_estimation": "Easy", "content": {"text": "מהו המאפיין העיקרי של RAID-1 (mirroring) כפי שתואר בחומר הקורס?", "code_snippet": null, "options": ["א. הנתונים משוכפלים בין כל הדיסקים, כך שכל בלוק נתונים קיים במספר עותקים.", "ב. הנתונים מחולקים לסירוגין (striping) בין הדיסקים ללא כפילות.", "ג. הנתונים נשמרים על דיסק אחד בלבד, וגיבויים נשמרים באופן ידני על דיסקים אחרים.", "ד. נתוני Parity מחושבים ומפוזרים יחד עם הנתונים על פני מספר דיסקים."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר הקורס, RAID-1 נקרא 'mirroring' (שיקוף). המאפיין המרכזי שלו הוא ש'בהינתן כמה דיסקים, נשכפל את הנתונים בין כולם (כל בלוק יהיה משוכפל בין כל הדיסקים)'. כלומר, כל בלוק נתונים קיים במספר עותקים על פני דיסקים שונים. אפשרות ב' מתארת את טכניקת ה-striping המאפיינת את RAID-0. אפשרות ג' מתארת גישה ידנית ללא מנגנון RAID מובנה. אפשרות ד' מתארת מנגנוני RAID מתקדמים יותר כמו RAID-5 המשתמשים ב-parity."}, "_source_file": "0482__Disks__RAID-1_Mirroring__MC__Easy.json", "_topic_hint": "RAID-1 Mirroring", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:49:59", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID-1 Mirroring"], "difficulty_estimation": "Easy", "content": {"text": "מהו המאפיין המרכזי של RAID-1, המכונה גם mirroring, על פי חומר ההרצאה?", "code_snippet": null, "options": ["א. שכפול מלא של כל הנתונים בין מספר דיסקים פיזיים, על מנת להבטיח יתירות ואמינות גבוהה.", "ב. פיצול נתונים לבלוקים קטנים וחלוקתם לסירוגין (striping) בין דיסקים שונים לצורך שיפור ביצועי קריאה וכתיבה.", "ג. שמירת נתוני זוגיות (parity) מבוזרים על פני כל הדיסקים, המאפשרים שחזור נתונים במקרה של כשל בדיסק אחד.", "ד. איחוד מספר דיסקים פיזיים לדיסק לוגי יחיד שקוף למערכת ההפעלה, ללא כל שכפול או פיצול פנימי."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, RAID-1 נקרא \"mirroring\" והוא מתאר מצב שבו \"נשכפל את הנתונים בין כולם (כל בלוק יהיה משוכפל בין כל הדיסקים)\". המטרה העיקרית של שכפול זה היא יתירות, כך ש\"אם דיסק אחד יתקלקל, נוכל להביא את הנתונים מדיסק אחר\", מה שמבטיח אמינות גבוהה. אפשרות ב' מתארת את RAID-0 (striping), אפשרות ג' מתארת את RAID-5 (parity מבוזר), ואילו אפשרות ד' מתארת איחוד דיסקים ללא מנגנון ספציפי של RAID-1."}, "_source_file": "0483__Disks__RAID-1_Mirroring__MC__Easy.json", "_topic_hint": "RAID-1 Mirroring", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:50:08", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID-1 Mirroring"], "difficulty_estimation": "Easy", "content": {"text": "מהו המאפיין העיקרי של RAID-1 (mirroring) כפי שתואר בחומר הקורס?", "code_snippet": null, "options": ["א. פיצול נתונים (striping) לסירוגין בין דיסקים שונים כדי לשפר ביצועים.", "ב. שכפול מלא של נתונים בין דיסקים שונים כדי להגביר אמינות ועמידות לכשלים.", "ג. שמירת נתונים בפורמט דחוס על דיסק יחיד.", "ד. איחוד מספר דיסקים פיזיים לדיסק וירטואלי יחיד ללא כל שכפול או פיצול נתונים."]}, "solution": {"correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. חומר הקורס מתאר את RAID-1 כ-mirroring, שבו 'נשכפל את הנתונים בין כולם (כל בלוק יהיה משוכפל בין כל הדיסקים)'. המטרה העיקרית של שכפול זה היא להבטיח אמינות ועמידות בפני כשלים, כפי שצוין: 'אם דיסק אחד יתקלקל, נוכל להביא את הנתונים מדיסק אחר'. אפשרות א' מתארת RAID-0 (striping), אפשרות ג' ו-ד' אינן מתארות את העקרונות של RAID-1 כפי שתוארו."}, "_source_file": "0484__Disks__RAID-1_Mirroring__MC__Easy.json", "_topic_hint": "RAID-1 Mirroring", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:50:16", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID-1 Mirroring"], "difficulty_estimation": "Medium", "content": {"text": "מהי ההצהרה הנכונה ביותר לגבי RAID-1 (mirroring) על פי חומר ההרצאה?", "code_snippet": null, "options": ["א. מטרתו העיקרית היא שיפור ביצועי קריאה וכתיבה על ידי פיצול נתונים (striping) לסירוגין בין דיסקים.", "ב. הוא מבטיח אמינות נתונים גבוהה על ידי שיכפול כל בלוק נתונים על פני מספר דיסקים פיזיים, והוא שקוף למערכת ההפעלה.", "ג. הוא מקטין את שטח האחסון הכולל הזמין על ידי שימוש במידע זוגיות (parity) במקום שיכפול מלא של נתונים.", "ד. הוא מאפשר למערכת ההפעלה לנהל באופן ישיר את חלוקת הנתונים בין הדיסקים הפיזיים השונים המרכיבים את המערך."]}, "solution": {"correct_option": "ב", "explanation": "RAID-1, המכונה mirroring, נועד בראש ובראשונה להבטיח אמינות נתונים גבוהה (fault tolerance) על ידי שיכפול מלא של כל בלוק נתונים על פני מספר דיסקים פיזיים, כפי שמצוין בחומר ההרצאה: 'נשכפל את הנתונים בין כולם (כל בלוק יהיה משוכפל בין כל הדיסקים)' ו-'אם דיסק אחד יתקלקל, נוכל להביא את הנתונים מדיסק אחר'. בנוסף, מנגנון ה-RAID פועל באופן שקוף למערכת ההפעלה ולתוכניות, כך שמבחינתן מדובר בדיסק לוגי אחד: 'השימוש העיקרי של raid הוא בדומה לזיכרון וירטואלי, שזה יהיה שקוף לחלוטין'. אפשרויות אחרות מתארות מאפיינים של RAID-0 (שיפור ביצועים באמצעות striping), RAID-5 (שימוש ב-parity) או הבנה שגויה של שקיפות ה-RAID למערכת ההפעלה."}, "_source_file": "0485__Disks__RAID-1_Mirroring__MC__Medium.json", "_topic_hint": "RAID-1 Mirroring", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:50:27", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID-1 Mirroring"], "difficulty_estimation": "Medium", "content": {"text": "על פי חומר הקורס, מהי המטרה העיקרית של RAID-1 (mirroring)?", "code_snippet": null, "options": ["א. לשפר באופן דרמטי את מהירות הקריאה והכתיבה על ידי פיצול סקטורים לסירוגין בין דיסקים.", "ב. להבטיח זמינות נתונים ושרידות מפני כשל של דיסק יחיד, באמצעות שכפול מלא של כל הנתונים על פני מספר דיסקים.", "ג. לייעל את ניצול שטח האחסון הכולל על ידי מניעת שכפול נתונים.", "ד. לאפשר שחזור נתונים באמצעות שמירת נתוני זוגיות (parity) בנפרד מהנתונים המקוריים."]}, "solution": {"correct_option": "ב", "explanation": "חומר הקורס מגדיר את RAID-1 (mirroring) כשיטה שבה 'נשכפל את הנתונים בין כולם (כל בלוק יהיה משוכפל בין כל הדיסקים)'. בנוסף, צוין כי 'אם דיסק אחד יתקלקל, נוכל להביא את הנתונים מדיסק אחר', מה שמדגיש את מטרת היתירות והשרידות. אפשרות א' מתארת את RAID-0 (striping) שמטרתו העיקרית היא שיפור ביצועים. אפשרות ג' אינה נכונה מכיוון ש-RAID-1 משכפל נתונים ולכן אינו מייעל את ניצול שטח האחסון. אפשרות ד' מתארת מנגנוני RAID מבוססי parity כגון RAID-5, ולא RAID-1."}, "_source_file": "0486__Disks__RAID-1_Mirroring__MC__Medium.json", "_topic_hint": "RAID-1 Mirroring", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:50:42", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID-1 Mirroring"], "difficulty_estimation": "Medium", "content": {"text": "במערך RAID-1 (mirroring), מהו המאפיין המרכזי של אופן אחסון הנתונים, ומהי המטרה העיקרית המושגת בזכות מאפיין זה?", "code_snippet": null, "options": ["א. הנתונים מחולקים לבלוקים ומופצים לסירוגין בין דיסקים שונים כדי להגביר את מהירות הקריאה והכתיבה.", "ב. כל בלוק נתונים משוכפל באופן מלא על פני דיסקים מרובים, ובכך מבטיח זמינות נתונים ואמינות גבוהה במקרה של כשל דיסק.", "ג. נתונים נכתבים לדיסק אחד ומידע parity נשמר על דיסק נפרד, המאפשר שחזור נתונים במקרה של כשל דיסק במינימום שטח אחסון.", "ד. מערך הדיסקים מוצג כדיסק לוגי יחיד, כאשר הנתונים מאוחסנים באופן רציף ללא כל שכפול או פיזור ספציפי, בדומה ל-JBOD."]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר ההרצאה, RAID-1 נקרא 'mirroring' ובו 'כל בלוק יהיה משוכפל בין כל הדיסקים'. המטרה העיקרית של שכפול זה היא אמינות וזמינות נתונים, שכן 'אם דיסק אחד יתקלקל, נוכל להביא את הנתונים מדיסק אחר'. אפשרות ב' מתארת במדויק הן את מנגנון השכפול והן את התועלת העיקרית של אמינות וזמינות נתונים במקרה של כשל דיסק, כפי שמצוין בחומר הלימוד. אפשרויות א' ו-ג' מתארות מאפיינים של רמות RAID אחרות (RAID-0 ו-RAID-4/5 בהתאמה), ואפשרות ד' מתארת גישה שאינה RAID כלל או RAID-0 בסיסי ללא יתרונות יתירות."}, "_source_file": "0487__Disks__RAID-1_Mirroring__MC__Medium.json", "_topic_hint": "RAID-1 Mirroring", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:50:53", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID-1 Mirroring"], "difficulty_estimation": "Medium", "content": {"text": "על פי חומר ההרצאה, מהו המאפיין המרכזי של RAID-1 (mirroring) ומהי מטרתו העיקרית?", "code_snippet": null, "options": ["א. פיצול נתונים (striping) לסירוגין בין דיסקים שונים לצורך שיפור ביצועים, ללא שכפול נתונים.", "ב. שכפול מלא של כל בלוק נתונים על פני מספר דיסקים, במטרה להבטיח שרידות נתונים במקרה של כשל בדיסק.", "ג. יצירת דיסק וירטואלי המאחד מספר דיסקים פיזיים, כאשר כל דיסק מכיל נתונים ייחודיים ללא גיבוי או שכפול.", "ד. שמירת נתוני זוגיות (parity) על דיסק נפרד לצורך שחזור נתונים במקרה של כשל באחד הדיסקים."]}, "solution": {"correct_option": "ב", "explanation": "RAID-1, המכונה mirroring, מאופיין בשכפול מלא של כל בלוק נתונים על פני מספר דיסקים. כפי שצוין בחומר ההרצאה, 'בהינתן כמה דיסקים, נשכפל את הנתונים בין כולם (כל בלוק יהיה משוכפל בין כל הדיסקים)'. מטרתו העיקרית היא להבטיח אמינות וזמינות נתונים: 'אם דיסק אחד יתקלקל, נוכל להביא את הנתונים מדיסק אחר'.\nאפשרות א' מתארת את RAID-0 (striping), שמטרתו העיקרית היא שיפור ביצועים. אפשרות ג' מתארת גישה פשוטה של איגוד דיסקים (כמו JBOD) ללא מנגנוני RAID לאמינות או ביצועים. אפשרות ד' מתארת RAID-4 או RAID-5, המשתמשים ב-parity לצורך שחזור נתונים."}, "_source_file": "0488__Disks__RAID-1_Mirroring__MC__Medium.json", "_topic_hint": "RAID-1 Mirroring", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:51:06", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID-1 Mirroring"], "difficulty_estimation": "Hard", "content": {"text": "בהינתן מערך RAID-1 הכולל 4 דיסקים פיזיים (D0, D1, D2, D3) ב-\"mirroring level 2\" כפי שתואר בשיעור (כלומר, כל נתון משוכפל על פני שני דיסקים ונעשה striping ביניהם, כפי שמודגם בטבלה), מהו המספר המרבי של דיסקים פיזיים שיכולים להיכשל מבלי לגרום לאובדן נתונים?", "code_snippet": null, "options": ["א. 1 דיסק.", "ב. 2 דיסקים, בתנאי שכל אחד מהם שייך לזוג שיקוף שונה.", "ג. 2 דיסקים, ללא תלות בזוג השיקוף אליו הם שייכים.", "ד. 3 דיסקים."]}, "solution": {"correct_option": "ב", "explanation": "החומר המצוי בשיעור מתאר תצורת RAID-1 עם 4 דיסקים פיזיים ב-\"mirroring level 2\" ככזו שבה כל נתון משוכפל על פני שני דיסקים, ומתבצע striping בין זוגות השיקוף. הטבלה המצורפת מדגימה תצורה של RAID 0+1 (striping across mirrors), כאשר דיסקים (D0, D1) מהווים זוג שיקוף אחד עבור בלוקים מסוימים (לדוגמה: 0, 2, 4, 6), ודיסקים (D2, D3) מהווים זוג שיקוף שני עבור בלוקים אחרים (לדוגמה: 1, 3, 5, 7). במערך כזה:\n*   כישלון של דיסק בודד (לדוגמה D0) לא יגרום לאובדן נתונים, שכן הנתונים משוכפלים על הדיסק המקביל (D1).\n*   כישלון של שני דיסקים מאותו זוג שיקוף (לדוגמה D0 ו-D1) יגרום לאובדן נתונים, שכן לא נשאר עותק זמין של הנתונים המאוחסנים בזוג זה.\n*   כישלון של שני דיסקים, כאשר כל אחד מהם שייך לזוג שיקוף אחר (לדוגמה D0 ו-D2), לא יגרום לאובדן נתונים. במקרה זה, הנתונים של D0 יהיו זמינים ב-D1, והנתונים של D2 יהיו זמינים ב-D3.\nלכן, המספר המרבי של דיסקים שיכולים להיכשל מבלי לגרום לאובדן נתונים הוא 2, בתנאי שהם אינם שייכים לאותו זוג שיקוף."}, "_source_file": "0489__Disks__RAID-1_Mirroring__MC__Hard.json", "_topic_hint": "RAID-1 Mirroring", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:51:29", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID-1 Mirroring"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על תצורת RAID-1 ברמת שיקוף 2 (mirroring level 2) המתוארת בחומר הלימוד, הכוללת 4 דיסקים פיזיים שבהם כל נתון משוכפל על פני שני דיסקים ומתבצע striping ביניהם (כדוגמת הטבלה המצורפת), איזו מהטענות הבאות נכונה ביותר לגבי מאפייני המערכת?", "code_snippet": null, "options": ["א. המערכת מספקת אמינות גבוהה יותר וביצועי קריאה משופרים בהשוואה למערך RAID-0 המשתמש באותה כמות דיסקים, אך נפח האחסון הזמין שלה קטן משמעותית.", "ב. ביצועי הכתיבה במערך זה זהים לביצועי כתיבה במערך RAID-0 עם אותה כמות דיסקים, תוך שמירה על עמידות גבוהה יותר בפני כשל דיסק בודד.", "ג. המערכת אינה מסוגלת להתמודד עם כשל של יותר מדיסק פיזי אחד, שכן כל בלוק משוכפל פעמיים בלבד.", "ד. נפח האחסון הזמין במערכת זו שווה לסכום נפחי כל הדיסקים הפיזיים, בזכות פיזור הנתונים בטכניקת striping."]}, "solution": {"correct_option": "א", "explanation": "התצורה המתוארת בחומר הלימוד (RAID-1 ברמת שיקוף 2 עם 4 דיסקים, כאשר כל נתון משוכפל על פני שני דיסקים ומתבצע striping ביניהם) היא למעשה RAID-10. במערך זה, זוגות דיסקים משמשים לשיקוף (mirroring) ואז הנתונים מפולחים (striped) בין זוגות השיקוף.\nא. **נכונה.** מערך RAID-10 משלב את היתרונות של RAID-1 (אמינות גבוהה יותר בזכות שיקוף, המאפשר שחזור נתונים במקרה של כשל דיסק כפי שצוין בחומר הלימוד) ואת היתרונות של RAID-0 (ביצועי קריאה משופרים בזכות striping המאפשר קריאה מקבילית). עם זאת, מכיוון שכל הנתונים משוכפלים, נפח האחסון הזמין הוא כמחצית מסך נפח הדיסקים הפיזיים, ולכן הוא קטן משמעותית בהשוואה ל-RAID-0 שבו כל הנפח זמין.\nב. **שגויה.** ביצועי כתיבה במערך RAID-1 (ובכלל ב-RAID-10) אינם זהים לאלו של RAID-0. ב-RAID-10, כל פעולת כתיבה צריכה להתבצע על שני דיסקים (הדיסק המקורי והדיסק המשוכפל), מה שלרוב מפחית את ביצועי הכתיבה בהשוואה ל-RAID-0 שבו כל בלוק נכתב לדיסק אחד בלבד.\nג. **שגויה.** תצורת RAID-10 (כפי שתוארה) מסוגלת להתמודד עם כשל של יותר מדיסק פיזי אחד. לדוגמה, אם דיסק 0 ודיסק 2 נכשלים בו-זמנית, הנתונים עדיין זמינים מדיסקים 1 ו-3 בהתאמה, משום שהם אינם חלק מאותו זוג משוקף. המגבלה היא שכשל של שני דיסקים מאותו זוג משוקף (לדוגמה, דיסק 0 ודיסק 1) יגרום לאובדן נתונים.\nד. **שגויה.** טענה זו מתארת את נפח האחסון של מערך RAID-0, שבו אין שיקוף נתונים ולכן כל נפח הדיסקים זמין. במערך RAID-1 (וב-RAID-10), הנתונים משוכפלים, ולכן נפח האחסון הזמין הוא רק חלק מסך נפח הדיסקים הפיזיים (במקרה זה, מחצית)."}, "_source_file": "0490__Disks__RAID-1_Mirroring__MC__Hard.json", "_topic_hint": "RAID-1 Mirroring", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:51:56", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID-1 Mirroring"], "difficulty_estimation": "Hard", "content": {"text": "מערכת הפעלה עושה שימוש במערך RAID-1 הכולל 4 דיסקים פיזיים, כפי שתואר בחומר הקורס (כלומר, mirroring level 2 עם striping). איזה מההיגדים הבאים מתאר בצורה הנכונה ביותר את ההתנהגות הצפויה של המערכת במקרה של כשל בדיסק פיזי אחד, ואת השפעתה על זמינות הנתונים וביצועי הקריאה?", "code_snippet": "/* Pseudo-code for a simplified RAID-10 read operation */\nDiskBlock read_raid10_block(LogicalBlockAddress lba) {\n    // Determine which RAID-1 pair and which physical disk within the pair\n    // to read from based on LBA and current system state (e.g., disk health, load)\n\n    RAID1Pair *pair = get_raid1_pair_for_lba(lba);\n    PhysicalDisk *disk_to_read_from = null;\n\n    if (pair->disk1->is_healthy() && pair->disk2->is_healthy()) {\n        // Both disks healthy, choose one (e.g., based on load, or read from both for performance)\n        disk_to_read_from = choose_disk_from_pair(pair->disk1, pair->disk2);\n    } else if (pair->disk1->is_healthy()) {\n        disk_to_read_from = pair->disk1;\n    } else if (pair->disk2->is_healthy()) {\n        disk_to_read_from = pair->disk2;\n    } else {\n        // Both disks in pair failed - data loss\n        return ERROR_DATA_UNAVAILABLE; // Critical failure\n    }\n\n    if (disk_to_read_from != null) {\n        return disk_to_read_from->read_block(lba_on_physical_disk);\n    }\n    return ERROR_DATA_UNAVAILABLE; // Should not be reached with single disk failure if logic is correct\n}", "options": ["א. המערכת תמשיך לתפקד ללא אובדן נתונים, שכן כל בלוק נתונים משוכפל. ביצועי הקריאה עשויים להיפגע קלות עבור הנתונים שהיו על הדיסק הכושל, שכן הם ייקראו כעת מדיסק בודד במקום משניים.", "ב. כשל של דיסק בודד יוביל לאובדן נתונים חלקי באופן בלתי נמנע, עקב מבנה ה-striping המפזר את הנתונים על פני כל הדיסקים ללא כפילות מלאה בכל מקום.", "ג. המערכת תמשיך לתפקד ללא אובדן נתונים, אך ביצועי הכתיבה יפגעו משמעותית עקב הצורך לשחזר את הדיסק הכושל במקביל לפעולות כתיבה רגילות.", "ד. כשל של דיסק בודד יגרום לקריסת המערכת ולאובדן זמינות הנתונים, שכן ה-striping במקרה זה אינו מספק עמידות לכשל."]}, "solution": {"correct_option": "א", "explanation": "חומר הקורס מתאר מצב שבו 'כשיש לנו יותר משני דיסקים, אנחנו קוראים לזה raid-01 / raid-10 (אבל בקורס כשנגיד raid-1 נכוון לזה)', ומציג טבלה הממחישה מערך RAID-10 (striping מעל זוגות דיסקים ב-mirroring). במקרה של RAID-10, כל בלוק נתונים משוכפל על פני שני דיסקים (mirroring level 2). לכן, כשל של דיסק פיזי בודד אינו מוביל לאובדן נתונים, שכן הנתונים קיימים במדויק על הדיסק המקביל בזוג המראה שלו.\n\nלגבי ביצועים: במצב תקין, מערכי RAID-10 יכולים לשפר ביצועי קריאה על ידי פיצול בקשות קריאה בין הדיסקים המראה, או על ידי בחירה בדיסק הפחות עמוס מבין השניים. כאשר דיסק אחד כושל, היכולת הזו של פיצול קריאות עבור אותם בלוקים ספציפיים שהיו על הדיסק הכושל אובדת, והקריאות יבוצעו מעתה רק מהדיסק הבודד שנותר בזוג המראה. הדבר עלול לגרום לפגיעה קלה בביצועי הקריאה עבור הנתונים הספציפיים הללו, למרות שהמערכת כולה נשארת זמינה וללא אובדן נתונים.\n\n*   א. זו התשובה הנכונה. היא מתארת במדויק את העמידות לכשל (ללא אובדן נתונים) ואת ההשפעה הניואנסית על ביצועי הקריאה במצב של כשל בדיסק בודד במערך RAID-10.\n*   ב. שגויה. RAID-10 מספק כפילות מלאה לכל בלוק, ולכן כשל של דיסק בודד אינו גורם לאובדן נתונים חלקי.\n*   ג. שגויה. אמנם ביצועי הכתיבה עשויים להיפגע במהלך תהליך שחזור הדיסק, אך השאלה מתמקדת בהשפעה על זמינות הנתונים וביצועי הקריאה, וההסבר אינו מדויק לגבי ההשפעה על ביצועי קריאה רגילים לאחר כשל.\n*   ד. שגויה. RAID-10 נועד לספק עמידות לכשל ואינו קורס כתוצאה מכשל של דיסק בודד. תיאור זה מתאים יותר למערך RAID-0."}, "_source_file": "0491__Disks__RAID-1_Mirroring__MC__Hard.json", "_topic_hint": "RAID-1 Mirroring", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:52:32", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Disks", "topic": ["RAID-1 Mirroring"], "difficulty_estimation": "Hard", "content": {"text": "בהתייחס ל-RAID-1 ברמת \"mirroring level 2\" הכוללת ארבעה דיסקים פיזיים, כפי שתואר בחומר הלימוד (עם שיכפול נתון על פני שני דיסקים ו-striping ביניהם), איזו מהטענות הבאות נכונה ביותר לגבי תכונותיה של תצורה זו?", "code_snippet": null, "options": ["א. היא משפרת באופן ניכר את ביצועי הכתיבה בהשוואה ל-RAID-0, אך אינה תורמת לאמינות המערכת.", "ב. היא מאפשרת המשך פעולה תקינה של המערכת במקרה של כשל בדיסק פיזי בודד, וגם עשויה לשפר את ביצועי הקריאה על ידי פיזור נתונים.", "ג. היא מבטיחה שכל נתון ישוכפל על פני כל ארבעת הדיסקים הפיזיים, וכתוצאה מכך מכפילה את שטח האחסון הזמין.", "ד. היא מיועדת בעיקר להגדלת נפח האחסון הזמין למשתמש, בדומה ל-JBOD, ללא שיקולי ביצועים או אמינות מיוחדים."]}, "solution": {"correct_option": "ב", "explanation": "חומר הלימוד מציין כי במערכת RAID-1 ברמת \"mirroring level 2\" הכוללת ארבעה דיסקים פיזיים, \"נשכפל כל נתון רק על פני שני דיסקים ונעשה striping ביניהם\". תצורה זו, הידועה גם כ-RAID-01 או RAID-10 (אשר בקורס זה נכללת תחת המונח RAID-1), נועדה לשלב את היתרונות של שיקוף ואת היתרונות של פיזור נתונים (striping).\n\n*   **אמינות:** שיקוף הנתונים על פני שני דיסקים מבטיח עמידות בפני כשל של דיסק בודד. אם דיסק אחד נכשל, הנתונים עדיין זמינים מהדיסק המשוכפל לו, מה שמאפשר המשך פעולה תקינה.\n*   **ביצועים:** ה-striping (פיזור נתונים לסירוגין בין הדיסקים או בין קבוצות דיסקים משוקפות) מאפשר קריאה מקבילה של נתונים, מה שיכול לשפר באופן ניכר את ביצועי הקריאה, כפי שמתואר עבור RAID-0.\n\nלכן, האפשרות הנכונה היא ב', המשלבת את שני היתרונות הללו:\n\n*   אפשרות א' שגויה מכיוון ש-RAID-1 אינו משפר ביצועי כתיבה (לרוב אף מאט אותם בשל הצורך לכתוב את הנתונים פעמיים), והוא בהחלט תורם לאמינות.\n*   אפשרות ג' שגויה מכיוון ש-\"mirroring level 2\" משמעו שיכפול על פני שני דיסקים בלבד, לא ארבעה, ושיקוף מקטין את שטח האחסון הזמין (במקרה זה, לחצי).\n*   אפשרות ד' שגויה מכיוון ש-RAID-1 מיועד לאמינות ו/או ביצועים, ולא רק להגדלת נפח כמו JBOD, שאף מתואר בחומר כגישה מסורבלת ש-RAID בא לנהל באופן שקוף."}, "_source_file": "0492__Disks__RAID-1_Mirroring__MC__Hard.json", "_topic_hint": "RAID-1 Mirroring", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:52:56", "_subject": "Disks", "_context_lectures": [18, 19]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Processes and Scheduling"], "difficulty_estimation": "Medium", "content": {"text": "בהתבסס על אלגוריתם תזמון \"Lottery scheduling\" כפי שתואר, אילו תהליכים נחשבים כשירים לזכות ב\"כרטיס\" (ticket) ולהיבחר לריצה על המעבד?", "code_snippet": null, "options": ["א. רק תהליכים הנמצאים במצב Ready.", "ב. כל התהליכים הקיימים במערכת, ללא קשר למצבם הנוכחי.", "ג. תהליכים הנמצאים במצב Running או Ready.", "ד. תהליכים הנמצאים במצב Blocked בלבד, שכן הם ממתינים למשאבים חיצוניים."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, המתזמן (Scheduler) הוא הלוגיקה שמחליטה איזה תהליך ירוץ בכל רגע נתון. כאשר מערכת ההפעלה בוחרת את התהליך הבא להרצה, היא עושה זאת אך ורק מתוך רשימת התהליכים הנמצאים במצב Ready. תהליכים במצב Running כבר רצים על המעבד, ואילו תהליכים במצב Blocked ממתינים לאירוע חיצוני (כמו סיום קלט/פלט) ואין טעם להריץ אותם; חומר ההרצאה מציין במפורש כי \"מערכת ההפעלה בכלל לא מסתכלת על תהליכים שהם Blocked\". לכן, כל אלגוריתם תזמון, כולל Lottery scheduling, יבחר את התהליך הבא לריצה רק מבין התהליכים המוכנים (Ready) במערכת."}, "_source_file": "0493__Virtualization__Processes_and_Scheduling__MC__Medium.json", "_topic_hint": "Processes and Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:53:09", "_subject": "Virtualization", "_context_lectures": [2, 3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Processes and Scheduling"], "difficulty_estimation": "Medium", "content": {"text": "לפי מחזור החיים של תהליך, לאיזה מצב יעבור תהליך הנמצא כרגע במצב \"Running\" כאשר מערכת ההפעלה מחליטה להפסיק את ריצתו (לדוגמה, עקב פסיקת שעון) ולהריץ תהליך אחר במקומו?", "code_snippet": null, "options": ["א. Blocked, מכיוון שהוא ממתין לתורו לריצה.", "ב. Ready, מכיוון שהוא מוכן לרוץ אך אינו רץ כרגע על המעבד.", "ג. Terminated, מכיוון שזמן הריצה שלו פג.", "ד. Running שוב, לאחר שהמתזמן יבחר אותו מחדש באופן מיידי."]}, "solution": {"correct_option": "ב", "explanation": "החומר המצורף מסביר כי כאשר מערכת ההפעלה מחליטה להפסיק תהליך שרץ (לדוגמה, עקב פסיקת שעון) ולהריץ תהליך אחר במקומו, פעולה זו נקראת 'Descheduled'. לאחר פעולה זו, התהליך עובר למצב 'Ready'. מצב 'Ready' מתאר תהליך שמוכן לרוץ אך אינו רץ כרגע על המעבד, והוא ממתין להיבחר על ידי המתזמן מתוך רשימת התהליכים המוכנים להרצה. מצב 'Blocked' (אפשרות א') שמור לתהליכים הממתינים לאירוע חיצוני (כגון קלט/פלט) ולא לתור מעבד. מצב 'Terminated' (אפשרות ג') מציין סיום הרצה מלא של התהליך. אפשרות ד' אינה נכונה מכיוון שהשאלה מציינת שהמתזמן החליט להריץ תהליך אחר במקומו."}, "_source_file": "0494__Virtualization__Processes_and_Scheduling__MC__Medium.json", "_topic_hint": "Processes and Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:53:21", "_subject": "Virtualization", "_context_lectures": [2, 3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Processes and Scheduling"], "difficulty_estimation": "Medium", "content": {"text": "איזו מהטענות הבאות מתארת נכונה את עקרון הפעולה של מתזמן ה-Lottery Scheduling, כפי שתואר בחומר הקורס?", "code_snippet": null, "options": ["א. המתזמן בוחר תהליך באופן אקראי על בסיס כמות \"כרטיסי הגרלה\" שברשותו, כאשר כמות גדולה יותר של כרטיסים מעניקה הסתברות גבוהה יותר להיבחר לריצה.", "ב. המתזמן מקצה זמן מעבד באופן שווה בין כל התהליכים הפעילים במערכת, ללא קשר לעדיפות או כרטיסים.", "ג. המתזמן תמיד נותן עדיפות לתהליכים בעלי זמן הריצה הקצר ביותר, על מנת למקסם את קצב השלמת הג'ובים.", "ד. המתזמן בוחר תהליך לריצה רק לאחר שהוא יוצא ממצב Blocked, ואינו מתחשב בתהליכים במצב Ready."]}, "solution": {"correct_option": "א", "explanation": "המתזמן Lottery Scheduling פועל על ידי הקצאת \"כרטיסי הגרלה\" לתהליכים השונים. כפי שמתואר בחומר הקורס (Lecture 3, chunk 28), המתזמן בוחר תהליך לריצה באופן אקראי מבין התהליכים הקיימים במערכת, כאשר ההסתברות של תהליך להיבחר פרופורציונלית למספר הכרטיסים שברשותו. לדוגמה, אם לתהליך A יש 150 כרטיסים ולתהליך B יש 50 כרטיסים מתוך סך הכל 200 כרטיסים, אז A יזכה ב-75% מזמן המעבד ו-B ב-25%. לכן, אפשרות א' מתארת נכונה את עקרון הפעולה.\nאפשרויות ב', ג' ו-ד' אינן מתארות נכונה את Lottery Scheduling. אפשרות ב' סותרת את העיקרון של הקצאה פרופורציונלית (ולא שווה). אפשרות ג' מתארת אלגוריתם תזמון אחר (כמו Shortest Job First), שאינו Lottery Scheduling. אפשרות ד' שגויה מיסודה, שכן מתזמן בוחר תהליכים מתוך רשימת ה-Ready, ולא מתוך ה-Blocked, כפי שמוסבר בתיאור מחזור החיים של תהליך (Lecture 2, chunk 34, 35)."}, "_source_file": "0495__Virtualization__Processes_and_Scheduling__MC__Medium.json", "_topic_hint": "Processes and Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:53:36", "_subject": "Virtualization", "_context_lectures": [2, 3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Processes and Scheduling"], "difficulty_estimation": "Hard", "content": {"text": "במערכת הפעלה המשתמשת באלגוריתם תזמון Lottery scheduling, קיימים שני תהליכים: P1 עם 150 כרטיסים ו-P2 עם 50 כרטיסים. שניהם נמצאים במצב Ready. לאחר זמן מה, P1 מבצע פעולת קלט/פלט ארוכה (כגון קריאה מקובץ) ונכנס למצב Blocked. בהנחה ש-P2 נשאר במצב Ready, ואין תהליכים אחרים במערכת, מהו אחוז זמן המעבד ש-P2 צפוי לקבל לאחר ש-P1 נכנס למצב Blocked?", "code_snippet": null, "options": ["א. 100%", "ב. 25%", "ג. 75%", "ד. 50%"]}, "solution": {"correct_option": "א", "explanation": "אלגוריתם Lottery scheduling מחלק את זמן המעבד באופן פרופורציונלי למספר ה'כרטיסים' (Tickets) של כל תהליך מתוך סך כל הכרטיסים של התהליכים הנמצאים במצב Ready. בתחילה, היו 200 כרטיסים בסך הכל (150 ל-P1 ו-50 ל-P2), ולכן P2 היה צפוי לקבל 25% מזמן המעבד (50/200).\nאך כאשר תהליך P1 נכנס למצב Blocked (עקב פעולת קלט/פלט, למשל), מערכת ההפעלה מפסיקה להתייחס אליו לצורך תזמון. כפי שצויין בחומר ההרצאה: \"מערכת ההפעלה בכלל לא מסתכלת על תהליכים שהם Blocked\" (Lecture 2, chunk 35). המשמעות היא שתהליך P1 אינו נכלל עוד ברשימת התהליכים הפוטנציאליים להרצה. מכיוון ש-P2 הוא התהליך היחיד שנותר במצב Ready (והנחנו שאין תהליכים אחרים במערכת), הוא יהיה התהליך היחיד שהמתזמן יכול לבחור. לכן, P2 יקבל 100% מזמן המעבד עד ש-P1 יחזור למצב Ready (או שתהליכים אחרים ייכנסו למצב Ready)."}, "_source_file": "0497__Virtualization__Processes_and_Scheduling__MC__Hard.json", "_topic_hint": "Processes and Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:54:09", "_subject": "Virtualization", "_context_lectures": [2, 3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Processes and Scheduling"], "difficulty_estimation": "Hard", "content": {"text": "בהינתן מערכת הפעלה המשתמשת במתזמן Lottery scheduling, ושני תהליכים P1 ו-P2 קיימים במערכת במצב Ready עם 150 ו-50 כרטיסים בהתאמה. אם תהליך P1 נכנס למצב Blocked (למשל, עקב בקשת קלט/פלט), כיצד הדבר צפוי להשפיע על שיעור זמן המעבד שתהליך P2 יקבל בפועל?", "code_snippet": null, "options": ["א. P2 יקבל 100% מזמן המעבד הפנוי, שכן כרטיסי P1 לא ייכללו בהגרלה כל עוד הוא במצב Blocked.", "ב. P2 ימשיך לקבל 25% מזמן המעבד, כאשר 75% מזמן המעבד יבוזבז עקב בחירה אקראית בתהליך P1 שאינו יכול לרוץ.", "ג. P2 יקבל אחוז גבוה יותר מ-25% אך פחות מ-100%, מכיוון שחלק מכרטיסי P1 עדיין ישפיעו על ההגרלה באופן חלקי.", "ד. חלוקת זמן המעבד לא תשתנה, שכן Lottery scheduling מבטיח חלוקה פרופורציונלית קבועה ללא תלות במצב התהליך."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א. על פי חומר ההרצאה, תהליך במצב Blocked \"ממתין למשהו... ואין טעם להריץ תהליך כזה. מערכת ההפעלה בכלל לא מסתכלת על תהליכים שהם Blocked\". המשמעות היא שכאשר מתזמן ה-Lottery scheduling בוחר את התהליך הבא להרצה, הוא עושה זאת מתוך רשימת התהליכים הנמצאים במצב Ready. ברגע ש-P1 נכנס למצב Blocked, הוא אינו נחשב עוד כמועמד לריצה, וכרטיסיו אינם נכללים בהגרלה. מכיוון ש-P2 נשאר התהליך היחיד במצב Ready עם כרטיסים פעילים (50 כרטיסים), הוא למעשה זוכה ב-100% מההגרלות המתבצעות, ולכן יקבל 100% מזמן המעבד הפנוי. אפשרויות ב', ג' ו-ד' אינן נכונות משום שהן מתעלמות מהעובדה שתהליכים חסומים אינם מועמדים לריצה, או מניחות בזבוז משאבים או חלוקה קבועה שאינה תואמת את מנגנון התזמון בפועל."}, "_source_file": "0498__Virtualization__Processes_and_Scheduling__MC__Hard.json", "_topic_hint": "Processes and Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:54:27", "_subject": "Virtualization", "_context_lectures": [2, 3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Paging and TLB"], "difficulty_estimation": "Medium", "content": {"text": "בעת מעבר הקשר (Context Switch) בין תהליכים שונים, ה-TLB עלול להכיל מיפויים שאינם רלוונטיים לתהליך החדש. מהו הפתרון שהוצג בחומר הלימוד להתמודדות עם בעיה זו, וכיצד הוא פועל?", "code_snippet": null, "options": ["א. ניקוי מוחלט של כל רשומות ה-TLB (TLB Flush) בכל מעבר קשר כדי להבטיח עקביות.", "ב. הוספת מזהה מרחב כתובות (ASID - Address Space ID) לכל רשומה ב-TLB, המציין לאיזה תהליך הרשומה שייכת ומאפשר שימוש ברשומות מתהליכים שונים במקביל.", "ג. שימוש בביט 'תקף' (Valid Bit) בכל רשומת TLB, אשר מתאפס עבור רשומות שאינן שייכות לתהליך הנוכחי.", "ד. בדיקת ה-Page Table עבור כל גישה לזיכרון וירטואלי לאחר מעבר קשר, עד שה-TLB מתמלא מחדש באופן אוטומטי."]}, "solution": {"correct_option": "ב", "explanation": "החומר מציין במפורש כי הפתרון לבעיית עדכון ה-TLB בעת מעבר קשר הוא הוספת מזהה מרחב כתובות (ASID - Address Space ID) לכל רשומה ב-TLB. מזהה זה מאפשר למערכת להבחין בין רשומות השייכות לתהליכים שונים, ובכך למנוע מצב שבו יש צורך לנקות את כל ה-TLB (TLB Flush) או להסתמך על מיפויים שגויים. במקום זאת, ה-TLB יכול להכיל במקביל מיפויים של מספר תהליכים, וה-MMU משתמש ב-ASID כדי לוודא שנעשה שימוש רק במיפויים הרלוונטיים לתהליך הפועל כעת. אפשרות א' (ניקוי TLB) היא פתרון אפשרי אך פחות יעיל מהשימוש ב-ASID. אפשרויות ג' ו-ד' אינן מתארות את הפתרון שהוצג בחומר הלימוד."}, "_source_file": "0499__Virtualization__Paging_and_TLB__MC__Medium.json", "_topic_hint": "Paging and TLB", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:54:41", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Paging and TLB"], "difficulty_estimation": "Medium", "content": {"text": "מהי הבעיה העיקרית המתעוררת ב-TLB במהלך החלפת הקשר (context switch), וכיצד היא נפתרת בדרך כלל על פי חומר ההרצאה?", "code_snippet": null, "options": ["א. ה-TLB מכיל מיפויים של התהליך הקודם שאינם רלוונטיים לתהליך החדש, והפתרון הוא הוספת מזהה ASID (Address Space ID) לכל רשומה ב-TLB.", "ב. ה-TLB אינו מסוגל לטפל בגישות זיכרון מקבילות מתהליכים שונים, ולכן יש לרוקן אותו לחלוטין בכל החלפת קשר.", "ג. ה-TLB הופך לפגיע להתקפות אבטחה כאשר תהליכים שונים חולקים אותו, והפתרון הוא הפרדת ה-TLB לתהליכים שונים.", "ד. ה-TLB עלול להכיל מיפויים שגויים עקב שינויים בטבלאות הדפים, והפתרון הוא אימות מחדש של כל רשומה ב-TLB בכל גישה."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, הבעיה העיקרית בהחלפת קשר (context switch) היא שרשומות ה-TLB אינן מעודכנות או רלוונטיות לתהליך החדש, מכיוון שהן שייכות לתהליך הקודם. הפתרון המצוין בחומר הוא הוספת מזהה ASID (Address Space ID) לכל רשומה ב-TLB. מזהה זה מציין לאיזה תהליך שייכת הרשומה, ובכך מאפשר ל-TLB להבחין בין רשומות של תהליכים שונים ולא לרוקן את ה-TLB כולו, מה שמשפר את הביצועים."}, "_source_file": "0500__Virtualization__Paging_and_TLB__MC__Medium.json", "_topic_hint": "Paging and TLB", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:54:53", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Paging and TLB"], "difficulty_estimation": "Medium", "content": {"text": "מהו התהליך הנכון ביותר המתאר את אופן הפעולה של ה-MMU כאשר מתרחש TLB Miss במהלך תרגום כתובת וירטואלית לכתובת פיזית?", "code_snippet": null, "options": ["א. ה-MMU פונה לטבלת הדפים (Page Table) כדי למצוא את המיפוי הנדרש, ולאחר מכן מעדכן את ה-TLB במיפוי שנמצא.", "ב. ה-MMU מזהה שהמיפוי חסר ב-TLB, ולכן מחזיר שגיאת \"Page Fault\" למערכת ההפעלה באופן מיידי.", "ג. ה-MMU בודק תחילה את ה-TLB, ואם המיפוי אינו נמצא, הוא ממשיך ישירות לזיכרון הפיזי עם הכתובת הוירטואלית.", "ד. ה-MMU מנסה לבנות מחדש את המיפוי ב-TLB על בסיס נתונים קודמים שנשמרו בו, מבלי לגשת לטבלת הדפים."]}, "solution": {"correct_option": "א", "explanation": "ההסבר הנכון הוא א'. על פי חומר ההרצאה, כאשר מתרחש TLB Miss (כלומר, המיפוי בין הכתובת הוירטואלית לכתובת הפיזית אינו נמצא ב-TLB), ה-MMU אינו מחזיר שגיאה מיד. במקום זאת, הוא מבצע את \"התהליך הארוך\" הכולל חיפוש המיפוי בטבלת הדפים (Page Table). לאחר שהמיפוי נמצא בטבלת הדפים, הוא משמש לתרגום הכתובת, ובנוסף, ה-TLB מתעדכן עם המיפוי החדש שנמצא, כדי שגישות עתידיות לאותו מיפוי יהיו מהירות יותר (TLB Hit)."}, "_source_file": "0501__Virtualization__Paging_and_TLB__MC__Medium.json", "_topic_hint": "Paging and TLB", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:55:05", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Paging and TLB"], "difficulty_estimation": "Hard", "content": {"text": "בהתחשב במנגנון ה-ASID (Address Space ID) ב-TLB, איזו מההשלכות הבאות היא הנכונה ביותר לגבי אופן פעולת ה-TLB והיתרון המרכזי שהוא מספק בעת מעבר הקשר (context switch)?", "code_snippet": null, "options": ["א. ה-TLB לא דורש יותר ניקוי מוחלט (flush) בכל מעבר הקשר, מכיוון שרשומות של תהליכים שונים יכולות לדור בכפיפה אחת ולהיות מזוהות לפי ה-ASID שלהן.", "ב. בכל מעבר הקשר, ה-TLB חייב עדיין לעבור ניקוי חלקי, שבו נמחקות רק הרשומות השייכות לתהליך הקודם, כדי למנוע התנגשויות.", "ג. מנגנון ה-ASID מבטיח שכל רשומות ה-TLB תמיד יהיו תקפות עבור כל תהליך, ובכך מייתר את הצורך בבדיקת ה-ASID במהלך תרגום כתובת.", "ד. הוספת ה-ASID לרשומות ה-TLB מייקרת את תהליך חיפוש המיפוי, כיוון שיש צורך בהשוואה נוספת, ובכך מאטה את תרגום הכתובות באופן כללי."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין בשיעור קובע כי הוספת ASID (address space id) לכל רשומה ב-TLB נועדה לפתור את הבעיה שה-TLB לא יהיה מעודכן עבור התהליך הנוכחי לאחר מעבר הקשר. ה-ASID מציין לאיזה תהליך הרשומה שייכת, ובכך מאפשר להבדיל בין רשומות של תהליכים שונים. המשמעות המרכזית של פתרון זה היא שאין צורך לנקות את כל ה-TLB במעבר הקשר, מכיוון שרשומות של תהליכים אחרים יכולות להישאר ב-TLB ולהיות תקפות עבור התהליכים שלהן. זה משפר את ביצועי המערכת על ידי הפחתת מספר ה-TLB misses כאשר חוזרים לתהליך שכבר היה פעיל בעבר. לכן, אפשרות א' היא הנכונה ביותר."}, "_source_file": "0502__Virtualization__Paging_and_TLB__MC__Hard.json", "_topic_hint": "Paging and TLB", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:55:21", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Paging and TLB"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על עקרונות ה-TLB כפי שתוארו בחומר הלימוד, מהי הטענה הנכונה ביותר לגבי תפקידו של מזהה ASID (Address Space ID) והשפעת היעדרותו בעת מעבר הקשר (Context Switch)?", "code_snippet": null, "options": ["א. ASID מאפשר ל-TLB להכיל מיפויים של מספר תהליכים במקביל, ובכך מונע את הצורך לנקות (flush) את כל רשומות ה-TLB בעת מעבר הקשר. בהיעדרו, כל מעבר קשר ידרוש ניקוי מלא של ה-TLB כדי למנוע גישה שגויה.", "ב. ASID מסייע בזיהוי דפים ששונו (dirty pages) על ידי תהליך ספציפי, ובהיעדרו, מערכת ההפעלה תתקשה לדעת אילו דפים יש לכתוב חזרה לדיסק.", "ג. ASID משפר את קצב הפגיעות (hit rate) ב-TLB על ידי ניבוי הגישות הבאות לזיכרון, ובהיעדרו, ה-TLB יפעל כמעין מטמון LRU פשוט.", "ד. ASID מבטיח את תקינות ה-`valid bit` ברשומת ה-PTE לאחר פספוס ב-TLB, ובהיעדרו, ה-MMU עלול לתרגם כתובות וירטואליות לא תקינות."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר הלימוד מציין במפורש: \"אם נעשה עכשיו context switch, הבעיה תהיה ש-tlb לא יהיה מעודכן עבור התהליך הנוכחי. הפתרון לכך: נוסיף לכל רשומה ב-tlb מזהה נוסף שנקרא ASID (address space id) שיציין לאיזה תהליך הרשומה הזו ששייכת וכך ניתן להבדיל בין רשומות של תהליכים שונים.\" משמעות הדבר היא ש-ASID מאפשר להבחין בין רשומות של תהליכים שונים ב-TLB, ובכך למנוע את הצורך לנקות את ה-TLB כולו בכל מעבר קשר. בהיעדרו, כדי למנוע מתהליך אחד לגשת למיפויים ששייכים בטעות לתהליך אחר (מה שעלול לגרום לשגיאות או פרצות אבטחה), יש צורך לנקות את ה-TLB לחלוטין בכל פעם שמתרחש מעבר קשר.\n\nאפשרויות ב', ג' ו-ד' אינן נכונות: \n- אפשרות ב' שגויה מכיוון שביט ה-`Dirty` הוא זה שמציין אם דף שונה, לא ASID.\n- אפשרות ג' שגויה מכיוון שתפקידו העיקרי של ASID אינו ניבוי גישות עתידיות לזיכרון אלא זיהוי תהליכים. שיפור בקצב הפגיעות הוא תוצאה עקיפה של הימנעות מניקוי TLB, לא מניבוי.\n- אפשרות ד' שגויה מכיוון שביט ה-`valid bit` הוא חלק מה-PTE וקשור לתקינות המיפוי עצמו, בעוד ש-ASID קשור לזיהוי התהליך לו שייך המיפוי ב-TLB."}, "_source_file": "0503__Virtualization__Paging_and_TLB__MC__Hard.json", "_topic_hint": "Paging and TLB", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:55:39", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Paging and TLB"], "difficulty_estimation": "Hard", "content": {"text": "תהליך מבצע גישה לכתובת וירטואלית מסוימת. ה-MMU בודק תחילה את ה-TLB ומגלה שהמיפוי אינו קיים (TLB miss). כתוצאה מכך, ה-MMU ממשיך לבצע חיפוש בטבלת הדפים כדי למצוא את רשומת טבלת הדפים (PTE) המתאימה. איזה מהמצבים הבאים, שנמצא ב-PTE שהתגלה, יגרום ל-MMU להוציא **trap** למערכת ההפעלה *לפני* השלמת התרגום לכתובת פיזית וגישה לזיכרון?", "code_snippet": null, "options": ["א. ביט ה-`valid` ברשומת ה-PTE הוא 0.", "ב. ביט ה-`dirty` ברשומת ה-PTE הוא 1.", "ג. ביט ה-`reference` ברשומת ה-PTE הוא 1.", "ד. ביט ה-`protection` ברשומת ה-PTE מאפשר את סוג הגישה שהתהליך מנסה לבצע."]}, "solution": {"correct_option": "א", "explanation": "לאחר TLB miss, ה-MMU ניגש לטבלת הדפים כדי לאחזר את ה-PTE. בשלב זה, ה-MMU בודק את תקינות המיפוי וההרשאות. אם ביט ה-`valid` ב-PTE הוא 0, פירוש הדבר שהדף אינו תקף או אינו בשימוש על ידי התהליך. במקרה זה, ה-MMU יוציא מיד **trap** למערכת ההפעלה, כפי שמצוין בחומר ההרצאה: \"אם ביט זה הוא 0 אז המיפוי הזה לא תקף... אם תהליך מנסה לגשת לדף כזה, כשה-mmu רואה שהביט הוא 0 הוא מוציא שגיאה למערכת ההפעלה (trap)\".\n\nאפשרויות ב' ו-ג' (ביטי ה-`dirty` וה-`reference`) הם ביטי סטטוס המציינים אם הדף השתנה או נגיש לאחרונה, ואינם גורמים ל-trap מיידי. אפשרות ד' מציינת כי ביט ה-`protection` מאפשר את הגישה המבוקשת, ולכן לא תתרחש שגיאה או trap בגין הפרת הרשאה."}, "_source_file": "0504__Virtualization__Paging_and_TLB__MC__Hard.json", "_topic_hint": "Paging and TLB", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:55:53", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Virtual Memory and Page Tables"], "difficulty_estimation": "Medium", "content": {"text": "על פי חומר ההרצאה, איזו בעיה מרכזית בארגון טבלאות דפים רגילות (Single-level Page Tables) נפתרת על ידי שימוש בטבלאות דפים היררכיות (Multi-Level Page Tables)?", "code_snippet": null, "options": ["א. האצת תהליך התרגום מכתובת וירטואלית לפיזית על ידי ה-MMU.", "ב. הפחתת בעיית הפיצול הפנימי (Internal Fragmentation) בזיכרון הפיזי.", "ג. הקטנת גודל הזיכרון הנדרש לאחסון טבלאות הדפים עצמן, במיוחד עבור מרחבי כתובות גדולים ודלילים.", "ד. מתן אפשרות לתהליכים שונים לשתף מסגרות זיכרון פיזיות."]}, "solution": {"correct_option": "ג", "explanation": "החומר מציין במפורש כי אחת הבעיות המרכזיות בטבלאות דפים היא שגודלן יכול להיות \"מאוד איטי\" (Lecture 7, chunk 11) וכי \"בתור התחלה, נטפל בבעיה הראשונה\" שהיא גודל טבלת הדפים. הפתרון המוצע לבעיה זו, לאחר שנדחה הפתרון של הגדלת דפים (עקב פרגמנטציה פנימית), הוא שימוש ב\"Multi-Level Page table – טבלת דפים היררכית\" (Lecture 7, chunk 16). מטרתה היא למנוע הקצאת זיכרון עבור דפים וירטואליים שאינם בשימוש, ובכך להקטין את טביעת הרגל של טבלת הדפים בזיכרון הפיזי. לכן, האפשרות הנכונה היא ג."}, "_source_file": "0505__Virtualization__Virtual_Memory_and_Page_Tables__MC__Medium.json", "_topic_hint": "Virtual Memory and Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:56:04", "_subject": "Virtualization", "_context_lectures": [6, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Virtual Memory and Page Tables"], "difficulty_estimation": "Medium", "content": {"text": "בעת תרגום כתובת וירטואלית לכתובת פיזית על ידי ה-MMU, לאילו שני רכיבים עיקריים מחולקת הכתובת הוירטואלית, ומה קובע את מספר הביטים של רכיב ה'היסט'?", "code_snippet": null, "options": ["א. מספר דף וירטואלי (VPN) והיסט (Offset); מספר הביטים של ההיסט נקבע לפי לוג 2 של גודל הדף.", "ב. מספר מסגרת פיזית (PFN) והיסט (Offset); מספר הביטים של ההיסט נקבע לפי לוג 2 של גודל הזיכרון הפיזי.", "ג. מספר דף וירטואלי (VPN) ומספר מסגרת פיזית (PFN); מספר הביטים של ה-VPN נקבע לפי גודל טבלת הדפים.", "ד. כתובת בסיס ותזוזה; מספר הביטים של התזוזה נקבע לפי גודל מרחב הכתובות הכולל."]}, "solution": {"correct_option": "א", "explanation": "החומר המצטט מציין במפורש: 'כאשר יהיה ניגש לכתובת וירטואלית אנחנו מתרגמים את זה לשני חלקים: 1. לאיזה מספר דף הוא ניגש. 2. לאיזה היסט מתחילת הדף הזה.' זה תואם את הרכיבים 'מספר דף וירטואלי (VPN)' ו'היסט (Offset)'. לגבי קביעת מספר הביטים של ההיסט, החומר קובע: 'ההיסט תלוי בגודל הדף – מספר הביטים לייצוג ההיסט הוא לוג 2 של גודל הדף.'. לכן, אפשרות א' היא הנכונה. אפשרויות ב' ו-ג' שגויות מכיוון שמספר מסגרת פיזית (PFN) הוא התוצאה של התרגום (היעד הפיזי) ולא רכיב שאליו מחולקת הכתובת הוירטואלית עצמה לצורך התרגום. אפשרות ד' משתמשת בטרמינולוגיה שאינה מפורטת בחומר ואינה מתארת נכונה את קביעת גודל הביטים של ההיסט בהקשר של דפדוף."}, "_source_file": "0506__Virtualization__Virtual_Memory_and_Page_Tables__MC__Medium.json", "_topic_hint": "Virtual Memory and Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:56:18", "_subject": "Virtualization", "_context_lectures": [6, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Virtual Memory and Page Tables"], "difficulty_estimation": "Medium", "content": {"text": "במערכת הפעלה המשתמשת בזיכרון וירטואלי עם טבלת דפים ברמה אחת (single-level page table), מהי התוצאה העיקרית של בחירת גודל דף (page size) קטן מאוד?", "code_snippet": null, "options": ["א. הגדלה משמעותית של בעיית הפרגמנטציה הפנימית.", "ב. הקטנת מספר הגישות הפיזיות לזיכרון עבור כל גישה לכתובת וירטואלית.", "ג. הגדלה ניכרת של גודל טבלת הדפים הנדרשת עבור כל תהליך.", "ד. הפחתת כמות הביטים המשמשים לזיהוי מספר הדף הוירטואלי (VPN)."]}, "solution": {"correct_option": "ג", "explanation": "החומר המצוין בשיעור 7 (chunk 11) מסביר כי 'כל דף יותר גדול, אז יהיו פחות דפים ולכן גודל טבלת הדפים קטן'. מכאן נובע שאם נבחר גודל דף קטן מאוד, יהיו יותר דפים וירטואליים במרחב הכתובות. מכיוון שלכל דף וירטואלי יש רשומה בטבלת הדפים (PTE), מספר גדול יותר של דפים יגרום לטבלת דפים גדולה יותר באופן משמעותי, כפי שמוזכר גם כבעיה בפני עצמה ('גודל טבלת הדפים יכול להיות מאוד גדול').\nאפשרות א' שגויה מכיוון שדפים קטנים דווקא מקטינים את בעיית הפרגמנטציה הפנימית, בעוד שדפים גדולים מגדילים אותה (שיעור 7, chunk 11).\nאפשרות ב' שגויה מכיוון שמספר הגישות הפיזיות לזיכרון עבור גישה וירטואלית נשאר בדרך כלל שתיים (גישה לטבלת הדפים וגישה לנתונים עצמם), ואינו מושפע ישירות מגודל הדף (שיעור 7, chunk 11).\nאפשרות ד' שגויה מכיוון שאם גודל הדף קטן, מספר הביטים הנדרשים להיסט (offset) קטן, ולכן מספר הביטים הנותרים עבור זיהוי הדף הוירטואלי (VPN) גדל (בהנחה שגודל הכתובת הוירטואלית קבוע). הגדלת מספר הביטים ל-VPN פירושה שיש יותר דפים וירטואליים."}, "_source_file": "0507__Virtualization__Virtual_Memory_and_Page_Tables__MC__Medium.json", "_topic_hint": "Virtual Memory and Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:56:34", "_subject": "Virtualization", "_context_lectures": [6, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Memory Management and Paging"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על תיאור אלגוריתם \"free list\" בחומר הלימוד, אשר מחלק את הזיכרון לבלוקים שווים בגודלם ומנהל אותם ברשימה מקושרת, מהו האתגר המרכזי שאלגוריתם זה יתקשה להתמודד איתו ביעילות, בהשוואה לשיטות מתקדמות יותר כמו \"segmentation\" או \"Buddy Allocation\", במערכת הפעלה המנהלת תהליכים בעלי צרכי זיכרון דינמיים ומשתנים?", "code_snippet": null, "options": ["א. קושי בניהול והקצאת זיכרון עבור רכיבים כמו ערימה (heap) או מחסנית (stack) הדורשים יכולת גדילה והתכווצות דינמית בגדלים משתנים.", "ב. בזבוז זיכרון משמעותי עקב פרגמנטציה פנימית (internal fragmentation) כאשר בקשות קטנות מבלוק בגודל קבוע.", "ג. חוסר יכולת לאחד בלוקי זיכרון פנויים סמוכים (coalescing) כדי ליצור בלוקים גדולים יותר, מה שמוביל לפרגמנטציה חיצונית (external fragmentation).", "ד. עלות תקורה גבוהה הכרוכה בניהול הרשימה המקושרת של הבלוקים הפנויים, הפוגעת בביצועי המערכת."]}, "solution": {"correct_option": "א", "explanation": "אלגוריתם ה-\"free list\" המתואר בחומר הלימוד מחלק את הזיכרון לבלוקים בגודל קבוע וזהה. תכונה זו, למרות פשטותה ויעילותה עבור הקצאות בגודל קבוע, מהווה מגבלה מהותית כאשר יש צורך לנהל רכיבי זיכרון כמו ערימה (heap) או מחסנית (stack), אשר גודלם משתנה באופן דינמי ובלתי צפוי במהלך ריצת התהליך. חומר הלימוד מציין במפורש כי בשיטת \"segmentation\", ה-bounds של סגמנטים כמו מחסנית וערימה \"יגדלו וישתנו תוך כדי ריצה ככל שמקצים זיכרון\", מה שמדגיש את הצורך ביכולת גמישות בגודל. אלגוריתם \"Buddy Allocation\" גם הוא נועד להתמודד עם בקשות בגדלים משתנים. לעומת זאת, אלגוריתם \"free list\" בגרסתו זו, המקצה \"איבר מהרשימה\" (בלוק יחיד בגודל קבוע), אינו מספק פתרון טבעי ויעיל לניהול זיכרון בעל דרישות גודל גמישות כאלה. אפשרות ב' (פרגמנטציה פנימית) נכונה באופן כללי עבור בלוקים בגודל קבוע, אך לא מהווה את האתגר המרכזי הייחודי בהשוואה לשיטות מתקדמות המטפלות בגדלים משתנים. אפשרות ג' (coalescing ופרגמנטציה חיצונית) רלוונטית יותר לאלגוריתמים המנהלים בלוקים בגדלים משתנים (כמו Buddy Allocation המיועד לפתור בעיות coalesce), ואילו ב-free list עם בלוקים שווים בגודלם, בעיית האיחוד שונה. אפשרות ד' (עלות תקורה גבוהה) נשללת על ידי חומר הלימוד הקובע כי free list \"מאוד יעיל וזה מאוד פשוט\"."}, "_source_file": "0508__Virtualization__Memory_Management_and_Paging__MC__Hard.json", "_topic_hint": "Memory Management and Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:57:01", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Memory Management and Paging"], "difficulty_estimation": "Hard", "content": {"text": "בהתחשב באופי הכאוטי של הקצאת ושחרור זיכרון בערימה (heap), שבו תהליכים מבקשים ומשחררים זיכרון בגדלים ובסדר לא קבועים, איזה אלגוריתם לניהול זיכרון מתמודד באופן יעיל ביותר עם בעיית איחוד (coalesce) של אזורי זיכרון פנויים סמוכים, ומהו המנגנון העיקרי המאפשר זאת?", "code_snippet": null, "options": ["א. Free List: מנהל רשימה מקושרת של בלוקים בגודל שווה, אך אינו תומך במנגנון מובנה לאיחוד יעיל של בלוקים סמוכים בגדלים משתנים.", "ב. Segmentation: מקצה בסיס וגבולות (base & bounds) לכל סגמנט לוגי (כמו ערימה ומחסנית), אך אינו עוסק ישירות באיחוד בלוקים פיזיים פנויים.", "ג. Buddy Allocation: מפצל את הזיכרון לבלוקים בגדלים שהם חזקות של 2, ומאפשר איחוד מהיר ויעיל של \"בלוקים אחים\" (buddies) באמצעות שינוי ביט יחיד בכתובתם.", "ד. Slab Allocation: מקצה מקטעי זיכרון בגודל קבוע מראש עבור אובייקטים נפוצים, אך אינו מיועד לטיפול כללי באיחוד זיכרון פנוי בגדלים שונים."]}, "solution": {"correct_option": "ג", "explanation": "החומר המצורף מציין במפורש כי \"Buddy Allocation - בא לפתור את הבעיה של coalesce (איחוד שטחי זיכרון בודדים ופנויים)\". המנגנון העיקרי המתואר הוא ש\"הכתובת של שני שכנים נבדלת בביט אחד, ואז קל לייצר מבנה נתונים שמתאר מתי שני שכנים פנויים. ברגע שהמשתמש מפנה את הבלוק הזה... רק נחליף ביט אחד ונבדוק את הבלוק של השכן שלו- אם שניהם פנויים, נאחד אותם\". זהו המנגנון המדויק לאיחוד יעיל של בלוקים סמוכים בזיכרון דינמי.\n\nא. Free List מתואר כאלגוריתם פשוט ויעיל לבלוקים בגודל שווה, אך אינו כולל מנגנון ייעודי לאיחוד בלוקים פנויים בגדלים משתנים כפי ש-Buddy Allocation עושה.\nב. Segmentation עוסק בניהול סגמנטים לוגיים (כמו ערימה ומחסנית) באופן עצמאי באמצעות בסיס וגבולות ייחודיים לכל סגמנט. מטרתו היא לפתור בעיות של בזבוז זיכרון ואי רציפות לוגית, אך אינו מטפל ישירות באיחוד בלוקים פיזיים פנויים לאחר שחרורם.\nד. Slab Allocation משמש להקצאת זיכרון עבור אובייקטים בגודל קבוע מראש וממוקד ביעילות בהקצאה חוזרת של אובייקטים נפוצים, אך אינו מספק פתרון כללי לבעיית איחוד זיכרון פנוי בגדלים שונים בערימה כאוטית."}, "_source_file": "0509__Virtualization__Memory_Management_and_Paging__MC__Hard.json", "_topic_hint": "Memory Management and Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:57:20", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Memory Management and Paging"], "difficulty_estimation": "Hard", "content": {"text": "אלגוריתם Buddy Allocation מתמקד בניהול יעיל של זיכרון פיזי על ידי פיצול ואיחוד בלוקים בגדלים של חזקות של 2, במטרה לטפל בבעיית ה-coalesce ולמזער פרגמנטציה חיצונית. לעומת זאת, שיטת הסגמנטציה (Segmentation), המרחיבה את הרעיון של Base&Bounds, נועדה לפתור אתגר מהותי אחר בניהול זיכרון עבור תהליכים. איזה אתגר עיקרי פותרת הסגמנטציה בגישה זו?", "code_snippet": null, "options": ["א. הקצאת זיכרון לתהליכים שונים באזורים סמוכים בזיכרון הפיזי כדי לשפר את ביצועי ה-cache.", "ב. מתן אפשרות לכל רכיב לוגי בתהליך (כגון מחסנית או ערימה) לגדול באופן דינמי ועצמאי, תוך מיפוי לאזורים לא סמוכים בזיכרון הפיזי.", "ג. מניעת בזבוז זיכרון פנימי (internal fragmentation) על ידי חלוקת הזיכרון לבלוקים קטנים ככל הניתן.", "ד. ייעול תהליך שחרור הזיכרון על ידי איחוד מיידי של בלוקים פנויים עם שכניהם."]}, "solution": {"correct_option": "ב", "explanation": "החומר המצורף מתאר את הסגמנטציה כהרחבה של Base&Bounds, שבה לכל תהליך יש מספר זוגות של Base&Bounds. כל זוג כזה מיועד לסגמנט לוגי אחר של התהליך (כמו מחסנית או ערימה), ואלה יכולים להיות ממוקמים באזורים לא סמוכים בזיכרון הפיזי ('הם לא צריכים להיות סמוכים'). היתרון המרכזי שמתואר הוא היכולת של כל סגמנט כזה לגדול ולהשתנות באופן דינמי ועצמאי תוך כדי ריצה ('ה-bounds והמחסנית והערימה יגדלו וישתנו תוך כדי ריצה ככל שמקצים זיכרון'), ללא צורך בזיכרון רציף לכל התהליך. אפשרות ב' מתארת בדיוק את היתרון הזה. אפשרות א' שגויה מכיוון שהסגמנטציה מאפשרת מיקום לא סמוך, בניגוד לטענה. אפשרות ג' אינה הבעיה העיקרית שהסגמנטציה פותרת באופן ישיר על ידי הרחבת Base&Bounds, ואף באלגוריתמים כמו Buddy Allocation עדיין יכולה להיות פרגמנטציה פנימית. אפשרות ד' מתארת את היתרון המרכזי של Buddy Allocation ('בא לפתור את הבעיה של coalesce') ולא של סגמנטציה."}, "_source_file": "0510__Virtualization__Memory_Management_and_Paging__MC__Hard.json", "_topic_hint": "Memory Management and Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 18:57:41", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Context Switching and Processes"], "difficulty_estimation": "Easy", "content": {"text": "איזה מהבאים נשמר כחלק ממצב תהליך (process context) במהלך פעולת context switch?", "code_snippet": null, "options": ["א. מצב המעבד (כגון רגיסטרים), מיקומי זיכרון וקבצים פתוחים.", "ב. רק ה-ID של התהליך וזמן הריצה הכולל שלו.", "ג. רק הכתובת הפיזית של ה-PCB בזיכרון הראשי.", "ד. רק תוכן המטמון (cache) של המעבד."]}, "solution": {"correct_option": "א", "explanation": "המנגנון של context switch (החלפה בין תהליכים) נועד לאפשר למערכת ההפעלה להשהות תהליך אחד ולטעון תהליך אחר, תוך שמירה על היכולת לחדש את התהליך שהופסק מאותה נקודה. לשם כך, מערכת ההפעלה שומרת את כל המידע הנדרש עבור הריצה של התהליך המושעה. על פי החומר, מידע זה כולל את מצב המעבד (כגון ערכי הרגיסטרים), מיקומי הזיכרון שהתהליך מחזיק ומשתמש בהם, ואת הקבצים הפתוחים של התהליך. מידע זה נשמר ב-PCB (Process Control Block) של התהליך. לכן, אפשרות א' היא הנכונה ביותר."}, "_source_file": "0511__Virtualization__Context_Switching_and_Processes__MC__Easy.json", "_topic_hint": "Context Switching and Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:57:52", "_subject": "Virtualization", "_context_lectures": [2, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Context Switching and Processes"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של מנגנון ה-Context Switch (החלפת הקשר) במערכת הפעלה?", "code_snippet": null, "options": ["א. לאפשר למספר תהליכים לשתף את המעבד וליצור אשליה של הרצה מקבילית.", "ב. לאפשר לתהליך במצב משתמש (user mode) לבצע פעולות מורשות (privileged operations) באופן ישיר.", "ג. לסיים תהליך רץ באופן קבוע ולשחרר את כל המשאבים שלו.", "ד. להגביר את מהירות הביצוע של תהליך יחיד על ידי הקצאת כל משאבי המערכת אליו."]}, "solution": {"correct_option": "א", "explanation": "מנגנון ה-Context Switch (החלפת הקשר) מאפשר למערכת ההפעלה לעצור תהליך אחד שרץ על המעבד, לשמור את מצבו, ולטעון תהליך אחר במקומו. כפי שמצוין בחומר ההרצאה (chunk 16), אם המנגנון יהיה איטי, \"תיעלם האשליה של המקביליות\". מכאן נובע שהמטרה העיקרית של מנגנון זה היא ליצור ולשמר את האשליה שתהליכים רבים רצים במקביל על מעבד בודד, וזאת על ידי שיתוף יעיל של המעבד ביניהם. אפשרויות ב', ג' ו-ד' אינן נכונות: אפשרות ב' מתארת מנגנון של system call המאפשר מעבר ל-kernel mode עבור פעולות מורשות, ולא ביצוע ישיר מ-user mode (chunk 24). אפשרות ג' מתארת סיום תהליך, בעוד ש-context switch משעה ושומר את מצבו של התהליך כדי שיוכל להמשיך מאוחר יותר (chunk 16). אפשרות ד' שגויה מכיוון שהחלפת הקשר מטבעה מוסיפה תקורה ואינה מיועדת להגביר את מהירות הביצוע של תהליך יחיד, אלא לנהל שיתוף משאבי מעבד בין תהליכים שונים."}, "_source_file": "0512__Virtualization__Context_Switching_and_Processes__MC__Easy.json", "_topic_hint": "Context Switching and Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:58:06", "_subject": "Virtualization", "_context_lectures": [2, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Context Switching and Processes"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של מנגנון ה-Context Switch (החלפת הקשר) במערכת הפעלה?", "code_snippet": null, "options": ["א. לאפשר למספר תהליכים לחלוק את המעבד וליצור אשליה של מקביליות.", "ב. להעביר את השליטה במעבד ממצב משתמש למצב ליבה לצורך ביצוע פעולות מורשות.", "ג. לשמור את כל תוכן הזיכרון של תהליך שהוקפא על הדיסק הקשיח.", "ד. לעדכן את רגיסטרי ה-Base וה-Bounds במעבד כדי לאפשר גישה לזיכרון וירטואלי."]}, "solution": {"correct_option": "א", "explanation": "מנגנון ה-Context Switch (החלפת הקשר) מתואר בחומר כדרך שבה מערכת ההפעלה מוציאה תהליך אחד מהמעבד וטוענת תהליך חדש במקומו (Lecture 2, chunk 16). מטרתו העיקרית היא לאפשר למספר תהליכים לרוץ על מעבד יחיד על ידי החלפה מהירה ביניהם, ובכך ליצור אשליה של מקביליות (Lecture 2, chunk 16: 'כי אז תיעלם האשליה של המקביליות'). אפשרות ב' מתארת מעבר מצב (mode switch) אשר יכול להיות חלק מאירוע שגורם ל-context switch (לדוגמה, system call או פסיקת שעון, Lecture 2, chunks 24 ו-32), אך אינה המטרה העיקרית של ה-context switch עצמו. אפשרות ג' אינה מדויקת; ה-context switch שומר את מצב התהליך (כולל רגיסטרים, מיקומי זיכרון, קבצים פתוחים - Lecture 2, chunk 20) ולא בהכרח את כל תוכן הזיכרון על הדיסק. אפשרות ד' היא פעולה ספציפית שמתרחשת במהלך context switch הקשורה לניהול זיכרון (עדכון רגיסטרי Base&Bounds, Lecture 6, chunk 15), אך זו אינה המטרה הכוללת והעיקרית של המנגנון כולו."}, "_source_file": "0513__Virtualization__Context_Switching_and_Processes__MC__Easy.json", "_topic_hint": "Context Switching and Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 18:58:23", "_subject": "Virtualization", "_context_lectures": [2, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Signals and System Calls"], "difficulty_estimation": "Medium", "content": {"text": "מהו המאפיין המבדיל המרכזי בין \"פסיקה\" (interrupt) לבין \"סיגנל\" (signal) בהקשר של יכולת תהליך משתמש להתערב בטיפול בהם?", "code_snippet": "int main(int argc, char *argv[])\n{\n    struct sigaction act;\n    sigemptyset(&act.sa_mask);\n    act.sa_handler = signal_handler;\n    act.sa_flags = 0;\n    \n    sigaction(SIGCHLD, &act, NULL);\n    if (fork()) {\n        while (1);\n    }\n}", "options": ["א. תהליך משתמש יכול להגדיר פונקציית טיפול (signal handler) עבור סיגנל, ואף לבחור להתעלם ממנו, בעוד שפסיקות מטופלות באופן בלעדי על ידי מערכת ההפעלה ותהליכי משתמש אינם יכולים להשפיע עליהן או לבטל אותן.", "ב. פסיקות וסיגנלים שניהם אירועים שה-kernel מטפל בהם בלבד, ההבדל היחיד הוא שסיגנלים יכולים לשמש לתקשורת בין תהליכים.", "ג. תהליכי משתמש יכולים לבטל פסיקות, אך רק מערכת ההפעלה יכולה להגדיר דרך טיפול בסיגנלים.", "ד. סיגנלים תמיד גורמים להפסקת ריצת התהליך, בעוד פסיקות יכולות להיות מטופלות ברקע מבלי להשפיע על ריצת התהליך."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין מדגיש כי בעוד ש\"פסיקות\" (interrupts) הן אירועים ברמת מערכת ההפעלה המטופלים באופן בלעדי על ידי קוד ה-kernel, ותהליכי משתמש אינם יכולים להשפיע עליהן או לבטל אותן (\"אבל לא יכולים להשפיע על פסיקה ובטח שלא לבטל אותה\"), \"סיגנלים\" הם אירועים ברמת התהליך. עבור סיגנלים, תהליכי משתמש יכולים להתערב בטיפול בהם על ידי הגדרת פונקציית טיפול (signal handler) מותאמת אישית, כפי שניתן לראות בדוגמת הקוד עם `sigaction` ו-`signal_handler`. כמו כן, תהליכים יכולים לבחור להתעלם מסיגנלים מסוימים, למשל על ידי שימוש ב-`SIG_IGN` עבור `SIGCHLD`, מה שמונע יצירת תהליכי זומבי ומדגים שליטה של תהליך המשתמש על אופן הטיפול בסיגנל. לכן, תשובה א' נכונה ומדויקת בהתאם לחומר."}, "_source_file": "0514__Virtualization__Signals_and_System_Calls__MC__Medium.json", "_topic_hint": "Signals and System Calls", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:58:37", "_subject": "Virtualization", "_context_lectures": [9, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Signals and System Calls"], "difficulty_estimation": "Medium", "content": {"text": "בהקשר של מערכות הפעלה, מהו ההבדל המהותי ביותר בין 'פסיקה' (Interrupt) לבין 'סיגנל' (Signal) מבחינת יכולת ההתערבות והשליטה של תהליך משתמש?", "code_snippet": "// signal2.c\nvoid signal_handler(int signal) {\n    if (signal == SIGCHLD) {\n        int rc = wait(NULL);\n        printf(\"child terminated %d (pid:%d)\\n\", rc, getpid());\n    }\n}\n\nint main(int argc, char *argv[])\n{\n    struct sigaction act;\n    sigemptyset(&act.sa_mask);\n    act.sa_handler = signal_handler;\n    act.sa_flags = 0;\n    \n    sigaction(SIGCHLD, &act, NULL);\n    if (fork()) {\n        while (1);\n    }\n}", "options": ["א. פסיקות מטופלות באופן בלעדי על ידי ליבת מערכת ההפעלה, בעוד שתהליכי משתמש יכולים להגדיר דרך טיפול משלהם בסיגנלים או להתעלם מהם.", "ב. סיגנלים משמשים אך ורק לתקשורת בין תהליכים (IPC), בעוד שפסיקות מטפלות באירועי חומרה בלבד.", "ג. תהליכי משתמש יכולים לבטל פסיקות חומרה, אך אינם יכולים למנוע קבלת סיגנלים ממערכת ההפעלה.", "ד. פסיקות וסיגנלים שניהם אירועים פנימיים לתהליך, ותהליכי משתמש יכולים לשלוט באופן מלא בטיפול בשניהם."]}, "solution": {"correct_option": "א", "explanation": "ההבדל המהותי ביותר המוצג בחומר ההרצאה הוא שפסיקות (Interrupts) הן אירועי חומרה המטופלים באופן בלעדי על ידי ליבת מערכת ההפעלה (kernel). חומר ההרצאה מציין שתהליכי משתמש 'לא יכולים להשפיע על פסיקה ובטח שלא לבטל אותה. רק מערכת ההפעלה יכולה לבטל פסיקות'. לעומת זאת, סיגנלים הם אירועים המיועדים לתהליכים, וחומר ההרצאה קובע כי 'אנחנו יכולים להשפיע על הטבלה הזו' (טבלת האירועים של הסיגנלים של התהליך) וכי 'תהליכי משתמש כן יכולים להתערב'. הדבר מתבטא ביכולת להגדיר פונקציית טיפול (handler) באמצעות פונקציות כמו `sigaction` (כפי שמודגם בקוד המצורף), וכן ביכולת להתעלם מסיגנלים (לדוגמה, `SIG_IGN` עבור `SIGCHLD` מונע יצירת זומבים). לכן, תשובה א' משקפת נאמנה את ההבדל הזה."}, "_source_file": "0515__Virtualization__Signals_and_System_Calls__MC__Medium.json", "_topic_hint": "Signals and System Calls", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:58:55", "_subject": "Virtualization", "_context_lectures": [9, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Signals and System Calls"], "difficulty_estimation": "Medium", "content": {"text": "מהו ההבדל המהותי ביותר בין \"סיגנלים\" (signals) ל\"פסיקות\" (interrupts) בהקשר של יכולת תהליך משתמש להתערב בטיפול בהם?", "code_snippet": "// signal2.c\nvoid signal_handler(int signal) {\n    if (signal == SIGCHLD) {\n        int rc = wait(NULL);\n        printf(\"child terminated %d (pid:%d)\\n\", rc, getpid());\n    }\n}\n\nint main(int argc, char *argv[])\n{\n    struct sigaction act;\n    sigemptyset(&act.sa_mask);\n    act.sa_handler = signal_handler;\n    act.sa_flags = 0;\n    \n    sigaction(SIGCHLD, &act, NULL);\n    if (fork()) {\n        while (1);\n    }\n}", "options": ["א. פסיקות הן אירועים פנימיים למערכת ההפעלה שאינם ניתנים לשינוי או ביטול על ידי תהליכי משתמש, בעוד שסיגנלים הם אירועים שבהם תהליכי משתמש יכולים להתערב, למשל על ידי הגדרת פונקציית טיפול או התעלמות מהם.", "ב. סיגנלים הם תמיד תוצאה של פעולת משתמש (כמו לחיצה על Ctrl+C), בעוד שפסיקות הן תמיד אירועים חומרתיים בלבד.", "ג. פסיקות משמשות בעיקר לתקשורת בין תהליכים, ואילו סיגנלים מצביעים על שגיאות חמורות במערכת.", "ד. תהליכי משתמש יכולים לבטל פסיקות בצורה יזומה, אך אינם יכולים להשפיע על אופן הטיפול בסיגנלים."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר הלימוד, פסיקות (interrupts) הן אירועים פנימיים למערכת ההפעלה, ותהליכי משתמש אינם יכולים להשפיע עליהן או לבטל אותן. המעבד מטפל בהן באמצעות טבלת כתובות של ה-kernel. לעומת זאת, סיגנלים (signals) הם אירועים המיועדים לתהליכים, ולכל תהליך יש טבלת אירועים משלו. תהליכי משתמש *כן* יכולים להתערב באופן הטיפול בסיגנלים אלו; לדוגמה, הם יכולים להגדיר פונקציית טיפול (signal handler) עבור סיגנל מסוים, כפי שמוצג בדוגמת הקוד עבור SIGCHLD, או לבחור להתעלם מסיגנל (למשל, SIG_IGN עבור SIGCHLD כדי למנוע זומבים). רק מערכת ההפעלה יכולה לבטל פסיקות, בעוד שסיגנלים נתונים לשליטת תהליך המשתמש במידה מסוימת."}, "_source_file": "0516__Virtualization__Signals_and_System_Calls__MC__Medium.json", "_topic_hint": "Signals and System Calls", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:59:12", "_subject": "Virtualization", "_context_lectures": [9, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Threads and Locks"], "difficulty_estimation": "Medium", "content": {"text": "איזו בעיה מרכזית עלולה להתעורר במנגנון נעילה מבוסס משתנה תור (turn), כפי שמוצג להלן, כאשר חוט (Thread) שהגיע תורו אינו מעוניין להיכנס לקטע הקריטי?", "code_snippet": "Thread A\nwhile (turn != A)\n  ; // busy-wait\n// critical section\nturn = B;\n\nThread B\nwhile (turn != B)\n  ; // busy-wait\n// critical section\nturn = A;", "options": ["א. שני חוטים עלולים להיכנס לקטע הקריטי בו-זמנית, ובכך להפר את עקרון ההדרה ההדדית (mutual exclusion).", "ב. נוצר מצב של קיפאון (deadlock), שבו חוט אחד ממתין לתורו ללא סוף, בעוד שהחוט השני אינו מעוניין להיכנס לקטע הקריטי ואינו משנה את התור.", "ג. מנגנון זה גורם לבזבוז משאבי CPU משמעותי עקב לולאת המתנה פעילה (busy-waiting) מתמדת.", "ד. חוטים עלולים לסבול מרעב (starvation), כאשר חוט אחד תמיד מצליח לתפוס את המנעול לפני האחר."]}, "solution": {"correct_option": "ב", "explanation": "החומר המצורף (Lecture 11, chunk 34) מתאר את הבעיה באופן מפורש: \"נחשוב על ריצה שבה יש מנעול וכרגע התור הוא של חוט A אבל חוט A מבצע דברים אחרים כרגע ולא קטע קריטי. ... אחרת חוט B ייכנס ללולאה אינסופית ויחכה. שוב קורה לנו deadlock - חוט B מחכה לתורו אבל אף פעם לא יגיע תורו.\"\nלכן, אם חוט אחד אינו זקוק לקטע הקריטי כשתורו מגיע, הוא לא ישחרר את התור לחוט השני, מה שיוביל לכך שהחוט השני ימתין ללא סוף בלולאת busy-wait, וייווצר מצב של קיפאון (deadlock)."}, "_source_file": "0517__Concurrency__Threads_and_Locks__MC__Medium.json", "_topic_hint": "Threads and Locks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:59:24", "_subject": "Concurrency", "_context_lectures": [10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Threads and Locks"], "difficulty_estimation": "Medium", "content": {"text": "מנגנון מנעול פשוט המשתמש במשתנה `turn` בכדי לאכוף גישה בלעדית לקטע קריטי, כפי שמוצג בקוד הבא:\n\n```c\n// Thread A\nwhile (turn != A)\n  ; // busy-wait\n// critical section\nturn = B;\n\n// Thread B\nwhile (turn != B)\n  ; // busy-wait\n// critical section\nturn = A;\n```\n\nעלול להיתקל בבעיה חמורה כאשר חוט (לדוגמה, חוט A) אינו זקוק לקטע הקריטי בזמן שתורו להיכנס. איזו מהבעיות הבאות מתארת נכונה את הכשל העיקרי של מנגנון זה במצב כזה, על פי חומר ההרצאה?", "code_snippet": "// Thread A\nwhile (turn != A)\n  ; // busy-wait\n// critical section\nturn = B;\n\n// Thread B\nwhile (turn != B)\n  ; // busy-wait\n// critical section\nturn = A;", "options": ["א. חוט B ייכנס ללולאת המתנה אינסופית (busy-wait) ולא יוכל להיכנס לקטע הקריטי לעולם, מה שיגרום למצב של קיפאון (deadlock).", "ב. שני החוטים עלולים להיכנס לקטע הקריטי בו-זמנית עקב חוסר אטומיות בפעולות הבדיקה וההשמה.", "ג. חוט B יבזבז משאבי מעבד בהמתנה פעילה אך בסופו של דבר יוכל להיכנס לקטע הקריטי לאחר שחוט A יסיים את פעולותיו האחרות.", "ד. מנגנון זה דורש שחוטים יבצעו `join` זה לזה כדי להבטיח סנכרון תקין."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מסביר כי מנגנון המנעול המבוסס על משתנה `turn` נכשל במצב שבו חוט A, שאליו שייך התור כרגע (`turn == A`), מבצע דברים אחרים ואינו נכנס לקטע הקריטי. במקרה כזה, חוט B, הממתין לתורו (`while (turn != B)`), ייכנס ללולאה אינסופית של המתנה פעילה (`busy-wait`) ולא יוכל להמשיך, מכיוון שחוט A לעולם לא ישנה את ערך `turn` ל-B. מצב זה מתואר במפורש כ\"deadlock\" בחומר ההרצאה (Lecture 11, chunk 34), שבו חוט B מחכה לתורו אך הוא לעולם לא יגיע."}, "_source_file": "0518__Concurrency__Threads_and_Locks__MC__Medium.json", "_topic_hint": "Threads and Locks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:59:39", "_subject": "Concurrency", "_context_lectures": [10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Threads and Locks"], "difficulty_estimation": "Medium", "content": {"text": "בהתבסס על קטע הקוד הבא, המציג ניסיון לסינכרון בין שני חוטים באמצעות משתנה `turn`, מדוע מנגנון זה אינו יעיל ועלול לגרום לבעיית חסימה (deadlock) או המתנת שווא אינסופית?", "code_snippet": "Thread A\nwhile (turn != A)\n  ; // busy-wait\n// critical section\nturn = B;\n\nThread B\nwhile (turn != B)\n  ; // busy-wait\n// critical section\nturn = A;", "options": ["א. אם החוט שהתור שלו (לדוגמה, חוט A כאשר `turn == A`) עסוק בביצוע פעולות אחרות ואינו מעוניין להיכנס לקטע הקריטי באופן מיידי, החוט השני (חוט B) ייכנס ללולאת המתנה אינסופית ולא יוכל להתקדם.", "ב. קיימת בעיית תחרות (race condition) בין בדיקת ערך המשתנה `turn` לבין עדכונו, מה שעלול לאפשר לשני חוטים להיכנס לקטע הקריטי בו-זמנית.", "ג. המנגנון אינו מבטיח סדר כניסה הוגן (fairness) בין החוטים, וחוט אחד עלול להישאר מורעב (starved) לנצח גם אם החוט השני מסיים את הקטע הקריטי שלו.", "ד. המשתנה `turn` אינו מוגדר כ-`volatile`, ולכן המהדר עלול לבצע אופטימיזציות שימנעו את עדכונו הנכון בין החוטים."]}, "solution": {"correct_option": "א", "explanation": "ההסבר הנכון הוא שהמנגנון המוצג סובל מבעיה של חסימה הדדית (deadlock) או המתנת שווא (busy-wait) שאינה נגמרת. כפי שמתואר בחומר ההרצאה (Lecture 11, chunk 34), אם התור שייך לחוט מסוים (לדוגמה, חוט A) אך חוט A מבצע פעולות אחרות ואינו מעוניין להיכנס לקטע הקריטי כרגע, חוט B ימשיך להמתין בלולאה אינסופית (`while (turn != B)`). חוט B לעולם לא יקבל את תורו מכיוון שחוט A לא ישנה את ערך המשתנה `turn` ל-B, שכן הוא אינו נכנס לקטע הקריטי כלל. מנגנון מנעול תקין צריך לאפשר לחוט אחר לתפוס את המנעול אם החוט הנוכחי אינו זקוק לו, אחרת נוצר מצב של deadlock."}, "_source_file": "0519__Concurrency__Threads_and_Locks__MC__Medium.json", "_topic_hint": "Threads and Locks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 18:59:55", "_subject": "Concurrency", "_context_lectures": [10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Threads and Locks"], "difficulty_estimation": "Hard", "content": {"text": "נתונה שיטת הסינכרון הבאה בין שני חוטים (A ו-B) לקטע קריטי:", "code_snippet": "int turn = A; // A or B\n\n// Thread A\nwhile (turn != A)\n  ; // busy-wait\n// critical section\nturn = B;\n\n// Thread B\nwhile (turn != B)\n  ; // busy-wait\n// critical section\nturn = A;", "options": ["א. הוא עלול לגרום למצב של קיפאון (deadlock), שבו חוט B ממתין באופן אינסופי לקבל את התור, בעוד שחוט A, שאליו שייך התור, אינו נכנס לקטע הקריטי ולכן אינו משחרר אותו.", "ב. המנגנון אינו מבטיח הדרה הדדית (mutual exclusion), מכיוון ששני החוטים עלולים לזהות את המשתנה `turn` כמתאים להם בו-זמנית.", "ג. חוט A עלול לסבול מרעב (starvation) מכיוון שאם חוט B ירצה להיכנס לקטע הקריטי פעמים רבות ברצף, הוא ימנע מ-A את הגישה.", "ד. המנגנון סובל מבעיית יעילות חמורה עקב המתנה פעילה (busy-waiting), אך הוא עדיין מבטיח נכונות (correctness) בהדרה הדדית ובהתקדמות."]}, "solution": {"correct_option": "א", "explanation": "הסבר: מנגנון זה, המבוסס על משתנה 'תור' (`turn`), סובל מבעיית התקדמות (progress) חמורה. לפי חומר ההרצאה (Lecture 11, chunk 34), אם התור שייך לחוט A (כלומר `turn == A`), אך חוט A מבצע משימות אחרות ואינו מעוניין להיכנס לקטע הקריטי באותו רגע, חוט B ייכנס ללולאת המתנה פעילה (busy-wait) אינסופית. חוט B ימתין ש-`turn` יהפוך ל-B, אך זה לעולם לא יקרה מכיוון שחוט A לא נכנס לקטע הקריטי ולכן לא ישנה את ערך `turn`. מצב זה מתואר בהרצאה כקיפאון (deadlock), שבו חוט B חסום לצמיתות ואינו יכול להתקדם. המנגנון אמנם מבטיח הדרה הדדית (mutual exclusion) – רק חוט אחד יכול להיות בקטע הקריטי בכל רגע נתון – אך הוא נכשל בהבטחת התקדמות במקרה הספציפי המתואר."}, "_source_file": "0520__Concurrency__Threads_and_Locks__MC__Hard.json", "_topic_hint": "Threads and Locks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 19:00:15", "_subject": "Concurrency", "_context_lectures": [10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Threads and Locks"], "difficulty_estimation": "Hard", "content": {"text": "נתון קטע הקוד הבא המנסה לממש מנגנון נעילה (lock) עבור שני חוטים (Thread A ו-Thread B) המשתפים משתנה `turn` (המאותחל ל-A):\n\n```c\n// Initial state: turn = A\n\nThread A\nwhile (turn != A)\n  ; // busy-wait\n// critical section\nturn = B;\n\nThread B\nwhile (turn != B)\n  ; // busy-wait\n// critical section\nturn = A;\n```\n\nבהתבסס על חומר ההרצאה, מהי הבעיה העיקרית במנגנון נעילה זה, במיוחד במקרה שבו חוט A אינו מעוניין להיכנס לקטע הקריטי כשתורו?", "code_snippet": "// Initial state: turn = A\n\nThread A\nwhile (turn != A)\n  ; // busy-wait\n// critical section\nturn = B;\n\nThread B\nwhile (turn != B)\n  ; // busy-wait\n// critical section\nturn = A;", "options": ["א. המנגנון אינו מבטיח הדדיות (mutual exclusion), מכיוון ששני חוטים עלולים להיכנס לקטע הקריטי בו-זמנית במקרים מסוימים.", "ב. המנגנון עלול להוביל למצב של קיפאון (deadlock) או \"רעב\" (starvation) ממושך, כאשר חוט אחד מחכה לתורו ללא הגבלה משום שהחוט השני, שלו התור, אינו מעוניין להיכנס לקטע הקריטי.", "ג. המנגנון מבזבז משאבי מעבד יקרים באמצעות לולאת המתנה פעילה (busy-waiting), אך אינו סובל מבעיות לוגיות של סנכרון מעבר לכך.", "ד. המנגנון דורש יחסי אב-ילד בין החוטים כדי לפעול כראוי, דבר שאינו מובטח בקוד המוצג."]}, "solution": {"correct_option": "ב", "explanation": "הקוד המוצג מממש מנגנון נעילה המבוסס על משתנה `turn` המבטיח תור קפדני בין חוטים. הבעיה העיקרית, כפי שמתוארת בחומר ההרצאה (Lecture 11, chunk 34), מתרחשת כאשר חוט אחד (לדוגמה, חוט A) אינו מעוניין או אינו צריך להיכנס לקטע הקריטי כאשר התור שלו. במצב כזה, חוט A לא ישנה את ערך המשתנה `turn` ל-B, ולכן חוט B יישאר בלולאת המתנה פעילה (busy-wait) לנצח, מחכה לתורו שלעולם לא יגיע. מצב זה הוא למעשה קיפאון (deadlock), שכן חוט B חסום ואינו יכול להתקדם, והחוט A אינו מבצע את הפעולה שתשחרר את חוט B. חומר ההרצאה מציין במפורש: \"חוט B ייכנס ללולאה אינסופית ויחכה. שוב קורה לנו deadlock - חוט B מחכה לתורו אבל אף פעם לא יגיע תורו.\" אפשרות א' אינה נכונה מכיוון שהמנגנון מנסה לאכוף הדדיות באמצעות תור קפדני. אפשרות ג' נכונה חלקית בכך שהוא משתמש ב-busy-waiting, אך היא מחמיצה את הבעיה הלוגית החמורה יותר של קיפאון. אפשרות ד' אינה רלוונטית כלל לנושא מנגנוני נעילה או לבעיה הספציפית בקוד."}, "_source_file": "0521__Concurrency__Threads_and_Locks__MC__Hard.json", "_topic_hint": "Threads and Locks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 19:00:31", "_subject": "Concurrency", "_context_lectures": [10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Threads and Locks"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על מנגנון המנעול מבוסס ה\"תור\" (turn) המוצג בחומר הלימוד, אשר נועד לסנכרן גישה לקטע קריטי בין שני חוטים (A ו-B), מדוע מנגנון זה עלול להוביל למצב של קיפאון (deadlock) בתרחיש מסוים?", "code_snippet": "Thread A\nwhile (turn != A)\n  ; // busy-wait\n// critical section\nturn = B;\n\nThread B\nwhile (turn != B)\n  ; // busy-wait\n// critical section\nturn = A;", "options": ["א. חוט שמגיע תורו (לדוגמה, turn == A) אך אינו מעוניין להיכנס לקטע הקריטי באותו רגע, ימשיך לבצע פעולות אחרות ולא ישחרר את ה\"תור\". כתוצאה מכך, החוט השני (B) ימתין בלולאה אינסופית (busy-wait) ולא יוכל להיכנס לקטע הקריטי, מה שיוביל לקיפאון.", "ב. הבעיה נובעת מכך ששני החוטים מנסים לשנות את ערך המשתנה turn בו-זמנית, מה שגורם למצב מרוץ (race condition) ועלול להוביל לכך שאף חוט לא יצליח לתפוס את המנעול.", "ג. מנגנון זה אינו מבטיח הגינות (fairness), וחוט אחד עלול להישאר מורעב (starvation) ולא לקבל את תורו לעולם, גם אם החוט השני מסיים את הקטע הקריטי ומשחרר את המנעול.", "ד. הקוד אינו מטפל במקרה שבו חוט אחד מסיים את פעולתו לפני שהחוט השני מספיק להיכנס לקטע הקריטי, ומשאיר את המשתנה turn במצב לא עקבי."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. מנגנון ה\"תור\" המוצג סובל מבעיית קיפאון (deadlock) בתרחיש שבו תורו של חוט מסוים (לדוגמה, חוט A) הגיע (כלומר, turn == A), אך חוט A אינו מעוניין באותו רגע להיכנס לקטע הקריטי ומבצע פעולות אחרות. במצב כזה, חוט A לא ייכנס ללולאת ה-busy-wait שלו, ולכן גם לא יגיע לשורה turn = B שתשחרר את ה\"תור\" לחוט השני. חוט B, לעומת זאת, ימצא את עצמו בלולאת while (turn != B) אינסופית, ממתין לתורו שלעולם לא יגיע. חוט A לא יאפשר ל-B להתקדם, ו-B ימתין ל-A, מה שיוצר קיפאון קלאסי. כפי שצויין בחומר הלימוד, \"חוט B מחכה לתורו אבל אף פעם לא יגיע תורו\"."}, "_source_file": "0522__Concurrency__Threads_and_Locks__MC__Hard.json", "_topic_hint": "Threads and Locks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 19:00:48", "_subject": "Concurrency", "_context_lectures": [10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Deadlocks and Synchronization"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על חומר ההרצאה, מדוע עקרונות תכנות נכון כמו אנקפסולציה ותכנות מונחה עצמים (המתייחס לפעולות כ'קופסה שחורה') מקשים על מניעת קיפאון במערכות מקביליות, במיוחד בהתחשב בכך של-deadlock אין תכונת הרכבה?", "code_snippet": null, "options": ["א. אנקפסולציה מונעת מהמתכנת לדעת באילו מנעולים פעולות פנימיות משתמשות ובאיזה סדר, מה שפוגע ביכולת לאכוף סדר עקבי לרכישת מנעולים (ובכך למנוע המתנה מעגלית). בנוסף, העובדה שמנעולים בודדים עשויים להיות חופשיים מקיפאון אינה מבטיחה שילובם יהיה חופשי מקיפאון, כיוון של-deadlock אין תכונת הרכבה.", "ב. עקרונות אלו גורמים למערכת להגיע למצב של הרעבה (starvation) במקום קיפאון, שכן חוטים נאלצים להמתין ללא הגבלת זמן למשאבים, אך המערכת כולה עדיין מתקדמת.", "ג. תכנות מונחה עצמים מחייב כל חוט לתפוס את כל המשאבים הדרושים לו בבת אחת (hold and wait), מה שמגביר את הסיכוי לקיפאון במקום למנוע אותו על ידי שחרור משאבים באופן יזום.", "ד. אנקפסולציה מקשה על איתור וניפוי שגיאות של קיפאונות לאחר שהם כבר התרחשו, אך אינה הגורם הישיר לקיומם או לקושי במניעתם מלכתחילה."]}, "solution": {"correct_option": "א", "explanation": "ההרצאה מסבירה כי עקרונות תכנות נכון כגון אנקפסולציה ותכנות מונחה עצמים, הרואים פעולות כ'קופסה שחורה', אינם עובדים טוב עם מנעולים וקיפאון. הסיבה היא שאין לנו שליטה או ידיעה איזה מנעול נתפס, מתי ובאיזה סדר כאשר קוראים לפעולות של אובייקט. חוסר שליטה זה מונע את היכולת לאכוף סדר אחיד לרכישת מנעולים, ובכך מקשה למנוע את תנאי ה'המתנה מעגלית' (circular wait), שהוא אחד מארבעת התנאים ההכרחיים לקיפאון. בנוסף, ההרצאה מציינת במפורש של-deadlock אין 'תכונת הרכבה' (composition property), כלומר, גם אם ניקח שני מנעולים שבשניהם אין deadlocks בנפרד, שילובם אינו מבטיח שלא ייווצרו deadlocks. שילוב שני ההיבטים הללו – חוסר השליטה בסדר רכישת מנעולים בתוך קוד אנקפסולציה והעדר תכונת ההרכבה – הופך את מניעת הקיפאון למורכבת במיוחד. אפשרות ב' שגויה מכיוון שהרעבה (starvation) מוגדרת במצגת כמצב שבו המערכת כולה מתקדמת, בניגוד לקיפאון. אפשרות ג' שגויה מכיוון שאנקפסולציה אינה מחייבת 'hold and wait', אלא דווקא מונעת שליטה על אופן רכישת המשאבים. אפשרות ד' נכונה חלקית בכך שאנקפסולציה מקשה על איתור באגים, אך ההרצאה מדגישה שהיא משפיעה ישירות גם על *מניעת* הקיפאון מלכתחילה עקב חוסר השליטה."}, "_source_file": "0523__Concurrency__Deadlocks_and_Synchronization__MC__Hard.json", "_topic_hint": "Deadlocks and Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 19:01:07", "_subject": "Concurrency", "_context_lectures": [15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Deadlocks and Synchronization"], "difficulty_estimation": "Hard", "content": {"text": "עקרונות תכנות נכון, כגון אנקפסולציה ושימוש ב'קופסאות שחורות' (black boxes) עבור פעולות של אובייקטים, נחשבים חיוניים לפיתוח תוכנה מודרנית. עם זאת, חומר השיעור מציין כי עקרונות אלו 'לא עובדים טוב עם העניין של סנכרון, מקביליות וקיפאון'. איזו מהטענות הבאות מסבירה בצורה הטובה ביותר מדוע אנקפסולציה עלולה להקשות על מניעה או זיהוי של קיפאונות במערכות מקביליות, על פי חומר השיעור?", "code_snippet": "//Thread 1::\nlock(&L1);\nlock(&L2);\n\n//Thread 2::\nlock(&L2);\nlock(&L1);", "options": ["א. אנקפסולציה מפחיתה את הצורך במנעולים על ידי ריכוז משאבים בתוך אובייקטים, ובכך מצמצמת את הסיכוי לקיפאון.", "ב. כאשר אובייקט חושף רק ממשק (API) ופעולותיו הפנימיות תופסות מנעולים וקוראות לפעולות אחרות, הסדר והתלות בין תפיסות המנעולים נסתרים מהקוד הקורא, מה שמונע שליטה על סדר זה ועלול להוביל לקיפאון.", "ג. אנקפסולציה מחייבת שכל המנעולים יהיו גלובליים ולא פרטיים לאובייקטים, ובכך יוצרת נקודות חולשה שקל יותר לתקוף אותן באמצעות קיפאונות.", "ד. חלוקה לאובייקטים קטנים, עיקרון הנגזר מאנקפסולציה, מבטיחה שכל אובייקט יטפל במנעול יחיד בלבד, ובכך מונעת את התנאי של המתנה מעגלית."]}, "solution": {"correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. חומר השיעור מציין במפורש כי 'אם אנחנו קוראים לפעולה של אובייקט, כתכנות מונחה עצמים אנחנו רואים את הפעולה כקופסא שחורה. אבל אם הפעולה הזו תופסת מנעול והיא קוראת לפעולות נוספות, עלול להיגרם מצב של קיפאון כי אין לנו שליטה מי תופס את המנעול, מתי ובאיזה סדר'. עקרון האנקפסולציה, שמטרתו להסתיר את פרטי המימוש הפנימיים של אובייקט, הופך לחיסרון בהקשר של מקביליות וקיפאונות. כאשר פעולה מוסתרת תופסת מנעולים בסדר מסוים, וייתכן שגם קוראת לפעולות נוספות שגם הן תופסות מנעולים, הקוד הקורא לפעולה זו אינו מודע לסדר תפיסת המנעולים הפנימי. חוסר שליטה וידע זה מקשה על מניעת תנאים לקיפאון כמו המתנה מעגלית (כפי שמודגם בקוד המצורף), שכן לא ניתן להבטיח סדר עקבי של תפיסת מנעולים על פני קריאות שונות לאובייקטים או בתוך קריאות מקוננות."}, "_source_file": "0524__Concurrency__Deadlocks_and_Synchronization__MC__Hard.json", "_topic_hint": "Deadlocks and Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 19:01:27", "_subject": "Concurrency", "_context_lectures": [15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Deadlocks and Synchronization"], "difficulty_estimation": "Hard", "content": {"text": "בהתחשב בארבעת התנאים לקיומו של קיפאון, ובהתייחס לעקרונות תכנות נכון כגון אנקפסולציה ושימוש ב'קופסאות שחורות', איזה מהבאים מתאר בצורה הטובה ביותר את האתגר הייחודי במניעת 'המתנה מעגלית' (circular wait) במערכות מקביליות מורכבות?", "code_snippet": null, "options": ["א. אנקפסולציה מקשה על קביעת סדר רכישת מנעולים גלובלי ועקבי, שכן פעולות פנימיות של אובייקטים עשויות לתפוס מנעולים בסדר לא ידוע וליצור תרחישי המתנה מעגלית בלתי צפויים.", "ב. עקרונות תכנות נכון מחייבים שכל מנעול ישוחרר מיד לאחר השימוש בו, ובכך מונעים המתנה מעגלית על ידי הבטחת זמינות מיידית של משאבים לכל חוט.", "ג. השימוש בקופסאות שחורות מבטיח שכל מנעול נרכש ומשוחרר בתוך גבולות האובייקט בלבד, ובכך מונע מצב של חוטים התופסים משאבים בסדר הפוך.", "ד. המתנה מעגלית היא תופעה הנובעת אך ורק מתזמון בלתי צפוי של חוטים על ידי מערכת ההפעלה, ואינה מושפעת באופן מהותי מעקרונות האנקפסולציה או ארכיטקטורת הקוד."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר ההרצאה מציין כי \"כל העניין של סנכרון, מקביליות וקיפאון- לא עובד טוב עם העקרונות של תכנות נכון (אנקפסולציה, קופסא שחורה וכו'..).\" בפרט, כאשר קוראים לפעולה של אובייקט כ\"קופסא שחורה\", אין לנו שליטה או ידע \"מי תופס את המנעול, מתי ובאיזה סדר\". תנאי ה\"המתנה מעגלית\" מתאר מצב שבו \"חוטים שונים תופסים משאבים בסדר הפוך\". מכיוון שאנקפסולציה מסתירה את סדר רכישת המנעולים בתוך אובייקטים, קשה מאוד לאכוף סדר רכישה גלובלי ועקבי על פני כל המערכת, ובכך למנוע המתנה מעגלית. אפשרות ב' אינה נכונה מכיוון ששחרור מיידי של מנעולים קשור יותר למניעת תנאי \"החזק והמתן\" (Hold and Wait) או לשיפור ביצועים, אך אינו מטפל ישירות בבעיה של סדר רכישה הפוך הנגרם מחוסר שקיפות של אנקפסולציה. אפשרות ג' אינה נכונה; ההרצאה מציינת שההפך הוא הנכון – אנקפסולציה (קופסאות שחורות) דווקא מקשה על שליטה בסדר רכישת המנעולים, ולא מונעת מצב של סדר הפוך. אפשרות ד' אינה נכונה, שכן ההרצאה מדגישה כי \"האופן בו הקוד נכתב ורץ, הוא זה שגרם ל-deadlock\", ומצביעה על הקשר בין עקרונות תכנות (כמו אנקפסולציה) לבין קשיי סנכרון וקיפאון. קיפאון אינו נובע *רק* מתזמון בלתי צפוי, אלא גם מאופן תכנון וארכיטקטורת הקוד."}, "_source_file": "0525__Concurrency__Deadlocks_and_Synchronization__MC__Hard.json", "_topic_hint": "Deadlocks and Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 19:01:46", "_subject": "Concurrency", "_context_lectures": [15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Semaphores and Producer-Consumer"], "difficulty_estimation": "Medium", "content": {"text": "בבעיית היצרן-צרכן (bounded buffer) הממומשת באמצעות סמפורים, מהם ערכי האתחול הנכונים עבור הסמפורים `full` ו-`empty`, בהינתן ש-`MAX` הוא גודל הבאפר המקסימלי?", "code_snippet": null, "options": ["א. הסמפור full מאותחל ל-0, והסמפור empty מאותחל ל-MAX.", "ב. הסמפור full מאותחל ל-MAX, והסמפור empty מאותחל ל-0.", "ג. הסמפור full מאותחל ל-1, והסמפור empty מאותחל ל-MAX.", "ד. הסמפור full מאותחל ל-MAX, והסמפור empty מאותחל ל-1."]}, "solution": {"correct_option": "א", "explanation": "ההסבר מהחומר המצורף מציין במפורש: 'הסמפור full מייצג כמה מדפים מלאים, ובתור התחלה אף מדף לא מלא ולכן הוא מאותחל ל-0.' וכן: 'הסמפור empty לעומת זאת מייצג כמה מדפים פנויים יש לנו... ולכן בתור התחלה יש לנו MAX מדפים פנויים'. מכאן שהאפשרות הנכונה היא ש-full מאותחל ל-0 ו-empty מאותחל ל-MAX."}, "_source_file": "0526__Concurrency__Semaphores_and_Producer-Consumer__MC__Medium.json", "_topic_hint": "Semaphores and Producer-Consumer", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 19:01:57", "_subject": "Concurrency", "_context_lectures": [14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Semaphores and Producer-Consumer"], "difficulty_estimation": "Medium", "content": {"text": "בבעיית היצרן/צרכן (bounded buffer) הממומשת באמצעות סמפורים, מהם הערכים ההתחלתיים הנכונים עבור הסמפורים `empty` ו-`full` בהתאמה, בהינתן שהבאפר בגודל `MAX`?", "code_snippet": "init(&empty, MAX);\ninit(&full, 0);", "options": ["א. empty = MAX, full = 0", "ב. empty = 0, full = MAX", "ג. empty = 1, full = MAX", "ד. empty = MAX, full = 1"]}, "solution": {"correct_option": "א", "explanation": "לפי חומר ההרצאה, במימוש בעיית היצרן/צרכן באמצעות סמפורים, הסמפור `empty` מייצג את מספר המדפים הפנויים בבאפר. בתחילה, כל המדפים בבאפר פנויים, ולכן ערכו ההתחלתי הוא `MAX` (גודל הבאפר המקסימלי). הסמפור `full` מייצג את מספר המדפים המלאים בבאפר. בתחילה, הבאפר ריק לחלוטין, ולכן ערכו ההתחלתי הוא `0`. הקטע קוד שסופק בהרצאה מדגים זאת במפורש: `init(&empty, MAX); init(&full, 0);`"}, "_source_file": "0527__Concurrency__Semaphores_and_Producer-Consumer__MC__Medium.json", "_topic_hint": "Semaphores and Producer-Consumer", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 19:02:05", "_subject": "Concurrency", "_context_lectures": [14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Semaphores and Producer-Consumer"], "difficulty_estimation": "Medium", "content": {"text": "בבעיית היצרן/צרכן (Producer/Consumer) הממומשת באמצעות סמפורים עבור באפר חסום בגודל MAX, מהם הערכים ההתחלתיים הנכונים עבור הסמפורים `empty` ו-`full`?", "code_snippet": "init(&empty, MAX);\ninit(&full, 0);\nint fill = 0;\nint use = 0;\nint buff[MAX];", "options": ["א. הסמפור `empty` מאותחל ל-`MAX`, והסמפור `full` מאותחל ל-`0`.", "ב. הסמפור `empty` מאותחל ל-`0`, והסמפור `full` מאותחל ל-`MAX`.", "ג. גם הסמפור `empty` וגם הסמפור `full` מאותחלים ל-`1`.", "ד. גם הסמפור `empty` וגם הסמפור `full` מאותחלים ל-`MAX`."]}, "solution": {"correct_option": "א", "explanation": "האפשרות הנכונה היא א'. בבעיית היצרן/צרכן עם באפר חסום, אנו משתמשים בשני סמפורים עיקריים: `empty` ו-`full`. הסמפור `empty` מייצג את מספר המדפים הפנויים (או המקומות הריקים) בבאפר. בתחילת הדרך, כל המדפים בבאפר פנויים, ולכן הוא מאותחל לגודל המקסימלי של הבאפר (`MAX`). הסמפור `full` לעומת זאת, מייצג את מספר המדפים המלאים (או האיברים שנמצאים בבאפר). בתחילת הדרך, הבאפר ריק מאיברים, ולכן הוא מאותחל ל-0. מידע זה מצוי במפורש בחומר ההרצאה, לדוגמה ב-Lecture 14 (chunk 25)."}, "_source_file": "0528__Concurrency__Semaphores_and_Producer-Consumer__MC__Medium.json", "_topic_hint": "Semaphores and Producer-Consumer", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 19:02:15", "_subject": "Concurrency", "_context_lectures": [14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Semaphores and Producer-Consumer"], "difficulty_estimation": "Hard", "content": {"text": "בבעיית היצרן-צרכן (Bounded Buffer), הממומשת באמצעות סמפורים full ו-empty כפי שתואר בהרצאה, הסמפור full מאותחל ל-0 והסמפור empty מאותחל לערך MAX (גודל הבאפר). מהי הסיבה התיאורטית העיקרית מאחורי אתחול סמפורים אלו בערכים ספציפיים אלה?", "code_snippet": "init(&empty, MAX);\ninit(&full, 0);\nint fill = 0;\nint use = 0;\nint buff[MAX];", "options": ["א. להבטיח שצרכנים ימתינו אם הבאפר ריק, ושייצרנים יוכלו להוסיף פריטים כל עוד יש מקום פנוי בבאפר, עד לקיבולתו המלאה.", "ב. למנוע מצב תחרות (race condition) על גישה למערך הבאפר עצמו, ובכך להבטיח עקביות נתונים.", "ג. לוודא שמספר החוטים הפעילים בו-זמנית בקטע הקוד הקריטי של הוספה או הוצאה מוגבל למספר קבוע מראש.", "ד. לסנכרן בין מספר יצרנים למספר צרכנים כך שכל מוצר שנוצר יצרך על ידי צרכן אחד בלבד, ללא התערבות."]}, "solution": {"correct_option": "א", "explanation": "ההרצאה מציינת כי הסמפור 'full' מייצג את מספר המדפים המלאים בבאפר, ולכן מאותחל ל-0 כיוון שבתחילה הבאפר ריק. אתחול זה מבטיח שכל צרכן שינסה לצרוך פריט כאשר הבאפר ריק יבצע 'sem_wait(&full)' וייחסם עד שיצרן יוסיף פריט. לעומת זאת, הסמפור 'empty' מייצג את מספר המדפים הפנויים, ולכן מאותחל ל-'MAX' (גודל הבאפר) כיוון שבתחילה כל המדפים פנויים. אתחול זה מאפשר ליצרנים להוסיף פריטים ללא חסימה עד שהבאפר יתמלא, כלומר עד ש-'empty' יגיע ל-0. אפשרות א' מתארת במדויק את התנהגות זו, שהיא התפקיד התיאורטי העיקרי של אתחול הסמפורים בערכים אלו בבעיית היצרן-צרכן עם באפר חסום. אפשרות ב' אינה נכונה מכיוון שסמפורים אלו אינם מיועדים למנוע מצבי תחרות על גישה למערך עצמו (שדורש מנגנון כמו mutex), אלא לנהל את מצב המלאי. אפשרות ג' מתארת שימוש אחר בסמפורים ('thread throttling') שגם הוזכר בהרצאה, אך אינו הסיבה העיקרית לאתחול הספציפי של 'full' ו-'empty' בבעיה זו. אפשרות ד' מתארת מטרה כללית של סנכרון, אך אינה הסיבה הספציפית לאתחול בערכים אלו, אלא תוצאה של המנגנון כולו."}, "_source_file": "0529__Concurrency__Semaphores_and_Producer-Consumer__MC__Hard.json", "_topic_hint": "Semaphores and Producer-Consumer", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 19:02:38", "_subject": "Concurrency", "_context_lectures": [14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Semaphores and Producer-Consumer"], "difficulty_estimation": "Hard", "content": {"text": "בבעיית היצרן/צרכן (bounded buffer) הממומשת באמצעות סמפורים, כפי שתואר בחומר ההרצאה, נהוג לאתחל את הסמפור 'empty' לערך המייצג את גודל הבאפר המקסימלי (MAX), ואת הסמפור 'full' ל-0. מה תהיה ההשלכה המיידית העיקרית אם הסמפור 'empty' יאותחל בטעות ל-0 במקום לערכו הנכון MAX, כאשר מנסים להפעיל את המערכת?", "code_snippet": "init(&empty, 0); // Incorrect initialization\ninit(&full, 0);\nint fill = 0;\nint use = 0;\nint buff[MAX];\n\n// ... Producer thread logic would then include:\n// sem_wait(&empty);", "options": ["א. כל הצרכנים יחסמו מיד בניסיון לצרוך פריט, מכיוון שהסמפור 'full' יהיה גם הוא 0.", "ב. כל היצרנים יחסמו מיד בניסיון להוסיף פריט לבאפר, גם אם הבאפר ריק לחלוטין.", "ג. יתאפשר ליצרנים להוסיף פריטים ללא הגבלה, מה שיוביל לגלישת באפר (buffer overflow).", "ד. לא תהיה כל השפעה מיידית, שכן הסמפור 'empty' רלוונטי רק לאחר שהבאפר מתמלא."]}, "solution": {"correct_option": "ב", "explanation": "הסמפור 'empty' מייצג את מספר המדפים הפנויים בבאפר. תפקידו הוא לוודא שליצרנים יש מקום פנוי להניח בו פריטים לפני שהם מוסיפים אותם. יצרן מבצע פעולת `sem_wait(&empty)` לפני הוספת פריט. אם הסמפור 'empty' מאותחל ל-0 במקום ל-MAX, הרי שכל יצרן שינסה להוסיף פריט לבאפר יבצע `sem_wait` על ערך 0. פעולה זו תגרום לו להיחסם מיד, מכיוון שהסמפור לא יכול לרדת מתחת ל-0 והחוט ימתין עד שערך הסמפור יהפוך לחיובי. מצב זה יתרחש גם אם הבאפר ריק לחלוטין פיזית, מכיוון שערכו של הסמפור שגוי. לכן, כל היצרנים יחסמו מיד ולא יוכלו להוסיף פריטים."}, "_source_file": "0530__Concurrency__Semaphores_and_Producer-Consumer__MC__Hard.json", "_topic_hint": "Semaphores and Producer-Consumer", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 19:02:50", "_subject": "Concurrency", "_context_lectures": [14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Semaphores and Producer-Consumer"], "difficulty_estimation": "Hard", "content": {"text": "בבעיית היצרן-צרכן (bounded buffer) עם מספר יצרנים וצרכנים המשתמשים בסמפורים `empty` ו-`full` לסנכרון, מהי התוצאה הסבירה והקריטית ביותר אם הסמפור `empty` יאותחל ל-0 והסמפור `full` יאותחל לערך המקסימלי (MAX) של הבאפר?", "code_snippet": "```c\n// Initialization as per lecture material:\n// sem_t empty, full;\n// sem_init(&empty, 0, MAX); // MAX empty slots initially\n// sem_init(&full, 0, 0);    // 0 full slots initially\n\n// Producer's logic (simplified):\n// sem_wait(&empty); // Decrement empty count (wait for free slot)\n// // Add item to buffer\n// sem_post(&full);  // Increment full count (signal item added)\n\n// Consumer's logic (simplified):\n// sem_wait(&full);  // Decrement full count (wait for item)\n// // Remove item from buffer\n// sem_post(&empty); // Increment empty count (signal slot freed)\n```", "options": ["א. יצרנים יחסמו מיד (לא יוכלו להוסיף פריטים), בעוד שצרכנים ינסו לגשת לבאפר ריק.", "ב. צרכנים יחסמו מיד (לא יוכלו לצרוך פריטים), בעוד שיצרנים ימלאו את הבאפר ללא הגבלה.", "ג. גם יצרנים וגם צרכנים יכנסו למצב קיפאון (deadlock) באופן מיידי.", "ד. המערכת תתפקד נכון בתחילה אך תסבול מתנאי מרוץ (race conditions) כאשר הבאפר יתמלא או יתרוקן."]}, "solution": {"correct_option": "א", "explanation": "הסמפור `empty` מייצג את מספר המקומות הפנויים בבאפר, ובתחילת העבודה, כאשר הבאפר ריק, הוא מאותחל ל-MAX (מספר המקומות הכולל). הסמפור `full` מייצג את מספר המקומות המלאים בבאפר, ובתחילה הוא מאותחל ל-0. \n\nאם `empty` יאותחל ל-0 במקום ל-MAX, כל יצרן שינסה להוסיף פריט לבאפר (באמצעות `sem_wait(&empty)`) יחסם מיד, מכיוון שערך הסמפור הוא 0, מה שמעיד לכאורה שאין מקומות פנויים. \n\nאם `full` יאותחל ל-MAX במקום ל-0, כל צרכן שינסה לצרוך פריט (באמצעות `sem_wait(&full)`) יצליח מיד, מכיוון שערך הסמפור הוא MAX, מה שמעיד לכאורה שהבאפר מלא. כתוצאה מכך, הצרכנים ינסו לגשת למקומות בבאפר שאינם מכילים פריטים תקפים (כי הבאפר ריק בפועל), מה שיוביל לשגיאות לוגיות, קריסה או התנהגות בלתי צפויה. \n\nלכן, התוצאה הקריטית ביותר היא יצרנים שיחסמו מיד וצרכנים שינסו לגשת לבאפר ריק."}, "_source_file": "0531__Concurrency__Semaphores_and_Producer-Consumer__MC__Hard.json", "_topic_hint": "Semaphores and Producer-Consumer", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 19:03:08", "_subject": "Concurrency", "_context_lectures": [14]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Race Conditions and Mutexes"], "difficulty_estimation": "Medium", "content": {"text": "בחומר ההרצאה נדון מנגנון נעילה מסוים שנמצא כלא מקיים את תכונת ה'מניעה ההדדית'. איזו מההשלכות הבאות היא התוצאה הישירה של כשל זה?", "code_snippet": null, "options": ["א. חוטים עלולים להיתקע במצב של קיפאון (deadlock), שבו כל אחד ממתין לאחר.", "ב. חוט אחד עלול להיכנס לקטע הקריטי שוב ושוב, ובכך למנוע מחוטים אחרים להיכנס (starvation).", "ג. שני חוטים או יותר יכולים להיכנס לקטע הקריטי בו-זמנית.", "ד. המנגנון דורש שימוש בלולאות המתנה פעילות (busy-waiting) הצורכות משאבי מעבד רבים."]}, "solution": {"correct_option": "ג", "explanation": "ההסבר בחומר ההרצאה מציין במפורש כי 'מניעה הדדית פירושה: שני חוטים לא יכולים להיות בקטע הקריטי במקביל.' ומוסיף כי אם תכונה זו אינה מתקיימת, 'זה אומר שייתכן ושני חוטים מחזיקים במנעול בו זמנית, כלומר שני חוטים נמצאים בקטע הקריטי במקביל.' לכן, הכשל במניעה הדדית מוביל ישירות לכך שחוטים מרובים יכולים להיכנס לקטע הקריטי בו-זמנית, מה שעלול לגרום לתנאי מרוץ ולשגיאות בנתונים. אפשרויות א', ב' ו-ד' מתארות בעיות אחרות במנגנוני סנכרון (קיפאון, הרעבה, בזבוז משאבים בהמתנה פעילה, בהתאמה), אך אינן ההשלכה הישירה של כשל במניעה הדדית כפי שהוגדר בחומר ההרצאה."}, "_source_file": "0532__Concurrency__Race_Conditions_and_Mutexes__MC__Medium.json", "_topic_hint": "Race Conditions and Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 19:03:25", "_subject": "Concurrency", "_context_lectures": [16, 11, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Race Conditions and Mutexes"], "difficulty_estimation": "Medium", "content": {"text": "בהתבסס על מנגנון ה-`Exponential Backoff Lock` המתואר בחומר ההרצאה, מהי המטרה העיקרית של השימוש בפונקציות `sleep` ובהכפלת משתנה ה-`delay` בתוך לולאת ה-`lock`?", "code_snippet": "void lock()\n{\n  int delay = MIN_DELAY;\n  while (1) {\n    while (state) {}\n    if (!getAndSet(state, true))\n      return;\n    sleep(random() % delay);\n    if (delay < MAX_DELAY)\n      delay = 2 * delay;\n  }\n}", "options": ["א. להבטיח מניעה הדדית (mutual exclusion) מלאה על המשאב המשותף.", "ב. למנוע מצב של קיפאון (deadlock) בין חוטים הממתינים למנעול.", "ג. להפחית את התחרות (contention) על המנעול כאשר מספר חוטים מנסים לתפוס אותו בו-זמנית.", "ד. להבטיח הוגנות (fairness) בכך שכל חוט יקבל את המנעול בפרק זמן סופי."]}, "solution": {"correct_option": "ג", "explanation": "חומר ההרצאה (Lecture 13, chunk 8) מתאר את מנגנון ה-`Exponential Backoff Lock` ומציין במפורש: \"כך נמנע את התחרות ולא כולם יקפצו על המנעול בבת אחת.\" מטרת השימוש ב-`sleep` והכפלת ה-`delay` היא למנוע מחוטים רבים לנסות לתפוס את המנעול מיד לאחר שחרורו, ובכך להפחית את התחרות (contention) על המנעול. מניעה הדדית היא תכונה בסיסית של מנעול תקין אך אינה המטרה העיקרית של מנגנון ה-backoff עצמו (אלא איך לשפר את ביצועי המנעול תחת עומס). מניעת קיפאון והבטחת הוגנות הן תכונות נפרדות שאינן המטרה המפורשת של מנגנון זה."}, "_source_file": "0533__Concurrency__Race_Conditions_and_Mutexes__MC__Medium.json", "_topic_hint": "Race Conditions and Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 19:03:41", "_subject": "Concurrency", "_context_lectures": [16, 11, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Race Conditions and Mutexes"], "difficulty_estimation": "Medium", "content": {"text": "על פי חומר ההרצאה, מנעול שבו שני חוטים (thread 0 ו-thread 1) יכולים להיכנס לקטע קריטי בו-זמנית, כפי שתואר בדוגמה שבה מנגנון ה-'turn' מוגדר כך ששני החוטים יוצאים מיד מלולאת ה-`while` ונכנסים לקטע הקריטי, אינו מקיים איזו תכונה חיונית של מנעולים?", "code_snippet": null, "options": ["א. מניעה הדדית (Mutual Exclusion)", "ב. חופש מקיפאון (Deadlock Freedom)", "ג. הוגנות (Fairness)", "ד. מניעת תחרות (Contention Avoidance)"]}, "solution": {"correct_option": "א", "explanation": "ההסבר בחומר ההרצאה (Lecture 16, chunk 8) קובע במפורש: \"מניעה הדדית פירושה: שני חוטים לא יכולים להיות בקטע הקריטי במקביל. אם זה לא מתקיים, זה אומר שייתכן ושני חוטים מחזיקים במנעול בו זמנית, כלומר שני חוטים נמצאים בקטע הקריטי במקביל.\" הדוגמה המתוארת, שבה חוט 0 וחוט 1 נכנסים לקטע הקריטי בו-זמנית עקב כשל במנגנון ה-`turn` של המנעול, מראה בדיוק מצב שבו תנאי המניעה ההדדית מופר. לכן, המנעול אינו מקיים מניעה הדדית. חופש מקיפאון (deadlock freedom) והוגנות (fairness) הן תכונות חשובות אחרות של מנעולים, אך הכשל הספציפי המתואר בדוגמה זו מתייחס ישירות להפרת המניעה ההדדית, שהיא תנאי בסיסי למניעת תנאי מרוץ (race conditions). מניעת תחרות היא אסטרטגיה לשיפור ביצועים (כמו במנעול עם Exponential Backoff), ולא תכונה בסיסית של נכונות המנעול כמו מניעה הדדית."}, "_source_file": "0534__Concurrency__Race_Conditions_and_Mutexes__MC__Medium.json", "_topic_hint": "Race Conditions and Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 19:04:02", "_subject": "Concurrency", "_context_lectures": [16, 11, 13]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Condition Variables and Locks"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על הדיון אודות מימושי מנעולים פשוטים בתוכנה, ובהתחשב במגבלות של משאבים (כגון מספר המשתנים הזמינים), איזו מהטענות הבאות מתארת בצורה הטובה ביותר את הקושי המהותי במימוש מנעול תקין עבור מספר שרירותי של חוטים (N>2) ללא פקודות חומרה מיוחדות, בכל הנוגע למניעה הדדית (Mutual Exclusion) וחופש מקיפאון (Deadlock Freedom)?", "code_snippet": null, "options": ["א. מימוש מנעול תקין עבור N חוטים ללא פקודות חומרה מיוחדות דורש לפחות N משתנים, ובמקרים בהם משתמשים בפחות מכך, לא ניתן לקיים בו-זמנית גם מניעה הדדית וגם חופש מקיפאון, כך שאחד מהם בוודאות לא יתקיים.", "ב. חופש מקיפאון הוא תמיד בר השגה במימושי מנעולים פשוטים בתוכנה, אך מניעה הדדית עלולה להיפגע אם לא משתמשים בפקודות חומרה אטומיות.", "ג. מניעה הדדית ומהוגנות (Fairness) הן תכונות הסותרות זו את זו במימושי מנעולים ללא פקודות חומרה מיוחדות, בעוד שחופש מקיפאון תמיד מובטח.", "ד. מנעולים מבוססי תוכנה תמיד סובלים מבעיית Livelock במקום Deadlock, ולכן הדיון בחופש מקיפאון אינו רלוונטי עבורם."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. החומר המועבר בשיעור מציין במפורש כי 'לא ניתן לממש מנעול לכל מספר של חוטים עם רק שני משתנים בלבד. בשביל לממש מנעול ל-100 חוטים, נדרשים 100 משתנים. אלא אם כן משתמשים בפקודות חומרה מיוחדות מה שלא קורה כאן. אז לא יכול להיות שהמנעול הזה תקין. לא ייתכן שהוא גם מקיים מניעה הדדית וגם deadlock freedom, במצב הזה אחד מהם לא יכול להתקיים בוודאות.' קביעה זו מדגישה את המגבלה המהותית במימוש מנעולים בתוכנה בלבד ללא מספיק משאבים (משתנים) או פקודות חומרה מיוחדות, בכך שלא ניתן להבטיח בו-זמנית את שתי התכונות הקריטיות: מניעה הדדית וחופש מקיפאון."}, "_source_file": "0535__Concurrency__Condition_Variables_and_Locks__MC__Hard.json", "_topic_hint": "Condition Variables and Locks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 19:04:18", "_subject": "Concurrency", "_context_lectures": [16, 11, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Condition Variables and Locks"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על עקרונות תכנון מנעולים תוכנתיים במערכות הפעלה, ובפרט על מגבלות מימוש מנעולים ללא שימוש בפקודות חומרה אטומיות מיוחדות (כגון test_and_set או compare_and_swap), איזו מהטענות הבאות מתארת נכונה את היכולת לממש מנעול כללי (עבור N חוטים שרירותי) המשתמש במספר קבוע ומוגבל של משתנים (למשל, שניים בלבד)?", "code_snippet": null, "options": ["א. מנעול כזה יכול לקיים בו-זמנית מניעה הדדית (Mutual Exclusion), חופש מקיפאון (Deadlock Freedom) והוגנות (Fairness), אם כי מימושו מורכב.", "ב. מנעול כזה יכול לקיים מניעה הדדית והוגנות, אך אינו יכול להבטיח חופש מקיפאון.", "ג. מנעול כזה אינו יכול לקיים בו-זמנית מניעה הדדית וחופש מקיפאון; אחד משני התנאים הללו בוודאות לא יתקיים במימוש כזה.", "ד. מנעול כזה יכול לקיים חופש מקיפאון והוגנות, אך אינו יכול להבטיח מניעה הדדית."]}, "solution": {"correct_option": "ג", "explanation": "החומר המצוין בשיעור 16 (קטע 27) קובע במפורש: \"לא ניתן לממש מנעול לכל מספר של חוטים עם רק שני משתנים בלבד. בשביל לממש מנעול ל-100 חוטים, נדרשים 100 משתנים. אלא אם כן משתמשים בפקודות חומרה מיוחדות מה שלא קורה כאן. אז לא יכול להיות שהמנעול הזה תקין. לא ייתכן שהוא גם מקיים מניעה הדדית וגם deadlock freedom, במצב הזה אחד מהם לא יכול להתקיים בוודאות.\" משפט זה מדגיש מגבלה יסודית בתכנון מנעולים תוכנתיים כלליים (עבור N חוטים) ללא תמיכת חומרה אטומית, המשתמשים במספר קבוע ומוגבל של משתנים. במצב כזה, לא ניתן להבטיח בו-זמנית גם מניעה הדדית (שרק חוט אחד ייכנס לקטע הקריטי) וגם חופש מקיפאון (שחוטים המעוניינים להיכנס לקטע הקריטי אכן יצליחו בסופו של דבר). לכן, בהכרח אחד מהתנאים הללו ייפגע, וזה תואם לאפשרות ג'."}, "_source_file": "0536__Concurrency__Condition_Variables_and_Locks__MC__Hard.json", "_topic_hint": "Condition Variables and Locks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 19:04:37", "_subject": "Concurrency", "_context_lectures": [16, 11, 15]}]