[{"id": 1, "type": "MultipleChoice", "topic": ["Processes", "Process States"], "content": {"text": "מה קורה למצב התהליך (Process State) כאשר הוא מבצע קריאת מערכת הממתינה לפעולת קלט/פלט (I/O), כגון קריאה מדיסק או המתנה לקלט מהמקלדת?", "code_snippet": null, "options": ["א. התהליך עובר למצב Ready כדי שיוכל להמשיך לרוץ מיד.", "ב. התהליך נשאר במצב Running ומבצע Busy Waiting עד שהמידע מגיע.", "ג. התהליך עובר למצב Blocked (או Waiting) עד לסיום פעולת הקלט/פלט.", "ד. התהליך מסיים את ריצתו (Terminated) ומערכת ההפעלה מוחקת אותו."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "כאשר תהליך מבצע פעולת I/O, הוא אינו יכול להמשיך בביצוע פקודות עד שהמידע יהיה זמין. כדי לא לבזבז זמן מעבד יקר, מערכת ההפעלה מעבירה אותו למצב Blocked (חסום) ומקצה את המעבד לתהליך אחר שנמצא במצב Ready. רק לאחר סיום פעולת ה-I/O, התהליך יחזור למצב Ready."}, "difficulty_estimation": "Easy", "_source_file": "0001__Processes__MultipleChoice__Easy.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:02:44", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "Process States"], "content": {"text": "כאשר תהליך מבצע קריאת מערכת הממתינה לקלט מהמשתמש (כמו קריאה מהמקלדת), לאיזה מצב (State) הוא יעבור בדרך כלל?", "code_snippet": null, "options": ["א. Running", "ב. Ready", "ג. Blocked / Waiting", "ד. Terminated"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "כאשר תהליך נדרש להמתין לאירוע חיצוני (כמו קלט/פלט), הוא אינו יכול להמשיך בביצוע הפקודות שלו על המעבד. לכן, מערכת ההפעלה מעבירה אותו למצב Blocked (חום/המתנה) ומשחררת את המעבד לטובת תהליכים אחרים. רק לאחר שהקלט יתקבל, התהליך יחזור למצב Ready."}, "difficulty_estimation": "Easy", "_source_file": "0002__Processes__MultipleChoice__Easy.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:02:52", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Processes"], "content": {"text": "כאשר תהליך מבצע קריאת מערכת לביצוע פעולת קלט/פלט (I/O) וממתין לסיומה, לאיזה מצב (State) הוא יעבור?", "code_snippet": null, "options": ["א. Ready (מוכן)", "ב. Blocked / Waiting (חסום / ממתין)", "ג. Running (רץ)", "ד. Terminated (סיים)"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "כאשר תהליך מבצע פעולה הדורשת המתנה לאירוע חיצוני (כמו קלט/פלט), הוא אינו יכול לנצל את המעבד ולכן עובר למצב Blocked (חסום). לאחר סיום הפעולה והגעת הנתונים, הוא יעבור למצב Ready כדי להמתין לתורו לרוץ שוב על המעבד."}, "difficulty_estimation": "Easy", "_source_file": "0003__Processes__MultipleChoice__Easy.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:03:07", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Processes"], "content": {"text": "מה קורה למצב התהליך (Process State) כאשר הוא מבצע קריאת מערכת חוסמת (Blocking I/O), כמו קריאה מקובץ מהדיסק שטרם נטען?", "code_snippet": null, "options": ["א. התהליך עובר למצב Ready ומחכה בתור למעבד.", "ב. התהליך נשאר במצב Running ומבצע Busy Waiting עד שהנתונים מגיעים.", "ג. התהליך עובר למצב Blocked (או Waiting) עד לסיום פעולת ה-I/O.", "ד. התהליך עובר למצב Terminated ומערכת ההפעלה סוגרת אותו עקב שגיאה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "כאשר תהליך מבצע פעולת I/O חוסמת, הוא אינו יכול להמשיך בביצוע הקוד שלו עד שהנתונים מוכנים. כדי לא לבזבז זמן מעבד יקר, מערכת ההפעלה מעבירה את התהליך למצב Blocked ומוציאה אותו מהמעבד. רק כאשר פעולת ה-I/O מסתיימת, התהליך יועבר חזרה למצב Ready."}, "difficulty_estimation": "Easy", "_source_file": "0004__Processes__MultipleChoice__Easy.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:03:25", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Processes", "System Calls"], "content": {"text": "מה קורה לתהליך אב הקורא למערכת הקריאה wait() כאשר תהליך הבן שלו עדיין פעיל?", "code_snippet": null, "options": ["א. תהליך האב ממשיך בביצוע הקוד שלו כרגיל ובמקביל לבן.", "ב. תהליך האב עובר למצב 'חסום' (Blocked/Waiting) עד אשר אחד מצאצאיו יסיים את ריצתו.", "ג. תהליך האב נמחק מהטבלה של מערכת ההפעלה.", "ד. תהליך הבן הופך להיות תהליך יתום (Orphan)."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "מערכת הקריאה wait() נועדה לסנכרון בין תהליכים. כאשר תהליך אב קורא לה, הוא מושהה על ידי מערכת ההפעלה (עובר למצב Blocked) עד שאחד מתהליכי הבן שלו מסיים את ריצתו (מבצע exit), ורק אז האב חוזר למצב Ready."}, "difficulty_estimation": "Easy", "_source_file": "0005__Processes__MultipleChoice__Easy.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:09:11", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "System Calls"], "content": {"text": "מה יהיה הפלט של הקוד הבא, בהנחה שכל קריאות המערכת מצליחות?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 10;\n    if (fork() == 0) {\n        x += 5;\n        printf(\"%d \", x);\n    } else {\n        wait(NULL);\n        x -= 5;\n        printf(\"%d \", x);\n    }\n    return 0;\n}", "options": ["א. 15 5", "ב. 15 15", "ג. 5 5", "ד. 5 15", "ה. הפלט אינו דטרמיניסטי ותלוי בתזמון המעבד."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א. 15 5", "explanation": "לאחר הקריאה ל-fork, נוצר תהליך בן המקבל עותק נפרד של מרחב הכתובות. בתהליך הבן, fork מחזירה 0, לכן הוא נכנס לבלוק ה-if, מעדכן את ה-x המקומי שלו ל-15 ומדפיס אותו. בתהליך האב, fork מחזירה את ה-PID של הבן (ערך חיובי), ולכן הוא עובר לבלוק ה-else. האב מבצע wait(NULL) ולכן ממתין לסיום הבן לפני שהוא ממשיך בביצוע. לאחר שהבן מסיים, האב מפחית 5 מה-x שלו (שנשאר בערך 10 במקור כי הזיכרון נפרד) ומדפיס 5. לכן הפלט יהיה 15 ולאחר מכן 5."}, "difficulty_estimation": "Medium", "_source_file": "0005__Processes__MultipleChoice__Medium.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:03:40", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "System Calls"], "content": {"text": "מהו הערך המוחזר מהקריאה למערכת fork() בתהליך האב (parent process), בהנחה שהפעולה הצליחה?", "code_snippet": null, "options": ["א. 0", "ב. ה-PID (מזהה התהליך) של תהליך הבן שנוצר", "ג. ה-PID של תהליך האב עצמו", "ד. ערך בוליאני true (1)", "ה. הקריאה אינה מחזירה ערך בתהליך האב"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "לאחר קריאה מוצלחת ל-fork(), המערכת מחזירה את ה-PID של הבן החדש לתהליך האב, ומחזירה 0 לתהליך הבן. ערך שלילי מוחזר רק במקרה של שגיאה."}, "difficulty_estimation": "Easy", "_source_file": "0006__Processes__MultipleChoice__Easy.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:09:20", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Processes", "System Calls"], "content": {"text": "מה קורה כאשר תהליך קורא לקריאת המערכת fork() במערכת הפעלה מסוג Unix/Linux?", "code_snippet": null, "options": ["א. נוצר תהליך חדש (תהליך בן) שהוא עותק כמעט זהה של תהליך האב.", "ב. התהליך הנוכחי נעצר ומתחלף בקוד של תוכנית חדשה לגמרי.", "ג. נוצר חוט (Thread) חדש בתוך אותו מרחב כתובות של התהליך הקיים.", "ד. המערכת מבצעת מעבר למצב המתנה (Waiting) עד לסיום כל תהליכי הרקע."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "קריאת המערכת fork() יוצרת תהליך חדש על ידי שכפול התהליך הקורא. התהליך החדש (הבן) מקבל עותק של מרחב הכתובות, משתנים וקובצי הקלט/פלט של האב, אך הוא פועל כתהליך נפרד עם מזהה תהליך (PID) ייחודי."}, "difficulty_estimation": "Easy", "_source_file": "0007__Processes__MultipleChoice__Easy.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:09:28", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "Process States"], "content": {"text": "מהו המצב (State) של תהליך שממתין לסיום פעולת קלט/פלט (I/O) לפני שיוכל להמשיך בריצתו?", "code_snippet": null, "options": ["א. Running (ריצה)", "ב. Ready (מוכן)", "ג. Blocked/Waiting (חסום/ממתין)", "ד. Terminated (סיום)", "ה. Zombie (זומבי)"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "כאשר תהליך מבצע קריאת מערכת לקלט/פלט, הוא אינו יכול להמשיך בביצועו עד שהנתונים מוכנים או הפעולה הושלמה. לכן, מערכת ההפעלה מעבירה אותו למצב חסום (Blocked) ומוציאה אותו מתור הריצה כדי לאפשר לתהליכים אחרים להשתמש במעבד. רק לאחר קבלת פסיקה מהחומרה שהפעולה הסתיימה, התהליך יעבור למצב Ready ויוכל להיבחר שוב על ידי ה-Scheduler."}, "difficulty_estimation": "Easy", "_source_file": "0008__Processes__MultipleChoice__Easy.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:09:39", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "System Calls"], "content": {"text": "כמה פעמים תודפס המחרוזת \"Hello\" כתוצאה מהרצת הקוד הבא? הנח שכל הקריאות ל-fork מצליחות.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    if (fork() == 0) {\n        fork();\n        printf(\"Hello\\n\");\n    } else {\n        wait(NULL);\n    }\n    return 0;\n}", "options": ["1", "2", "3", "4", "0"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "2", "explanation": "התהליך המקורי (האב) מבצע fork. תהליך האב מקבל ערך חיובי (PID של הבן) ונכנס לבלוק ה-else, שם הוא מבצע wait וממתין לסיום בנו. תהליך הבן מקבל 0 ונכנס לבלוק ה-if. בתוך ה-if, תהליך הבן מבצע fork נוסף, מה שיוצר תהליך נכד. גם הבן וגם הנכד ממשיכים לשורת ה-printf ומדפיסים \"Hello\". סה\"כ ההדפסה מתבצעת פעמיים."}, "difficulty_estimation": "Medium", "_source_file": "0009__Processes__MultipleChoice__Medium.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:09:47", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "System Calls", "Memory Management"], "content": {"text": "נתון קטע הקוד הבא בשפת C. מהו הפלט הצפוי של התוכנית בהנחה שכל קריאות המערכת מצליחות?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 10;\n    if (fork() == 0) {\n        x += 5;\n        printf(\"%d \", x);\n    } else {\n        wait(NULL);\n        x -= 3;\n        printf(\"%d \", x);\n    }\n    return 0;\n}", "options": ["א. 15 12", "ב. 15 7", "ג. 7 15", "ד. 12 15", "ה. הפלט אינו קבוע ותלוי בתזמון המעבד."]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ב. 15 7", "explanation": "לאחר קריאת המערכת fork, נוצר תהליך בן המקבל עותק נפרד של מרחב הכתובות של האב, כולל המשתנה x. בתהליך הבן (שבו fork מחזיר 0), הערך של x הופך ל-15 והוא מודפס. בתהליך האב, נעשה שימוש ב-wait(NULL) שממתין לסיום הבן. לאחר מכן האב מחסיר 3 מהערך המקורי של x (שהיה 10 במרחב הכתובות שלו) ומדפיס 7. מכיוון שהאב מחכה לבן, הפלט תמיד יהיה 15 ולאחר מכן 7."}, "difficulty_estimation": "Medium", "_source_file": "0010__Processes__MultipleChoice__Medium.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:09:57", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Processes", "System Calls"], "content": {"text": "נתון קטע הקוד הבא בשפת C. נניח שכל קריאות המערכת מצליחות. מה נכון לומר לגבי ה-PID (Process Identifier) ומרחב הכתובות (Address Space) של התהליך המריץ את התוכנית \"ls\", בהשוואה לתהליך הבן שנוצר על ידי קריאת ה-fork המופיעה בקוד?", "code_snippet": "pid_t pid = fork();\nif (pid == 0) {\n    char *args[] = {\"ls\", \"-l\", NULL};\n    execvp(args[0], args);\n    exit(0);\n} else {\n    wait(NULL);\n}", "options": ["א. ה-PID משתנה ומרחב הכתובות משתנה.", "ב. ה-PID נשאר זהה ומרחב הכתובות נשאר זהה.", "ג. ה-PID משתנה אך מרחב הכתובות נשאר זהה.", "ד. ה-PID נשאר זהה אך מרחב הכתובות מוחלף בתוכנית החדשה.", "ה. לא ניתן לדעת, הדבר תלוי במתזמן (Scheduler)."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ד. ה-PID נשאר זהה אך מרחב הכתובות מוחלף בתוכנית החדשה.", "explanation": "הקריאה למשפחת פונקציות exec (כמו execvp) מחליפה את מרחב הכתובות של התהליך הנוכחי (קוד, נתונים, מחסנית) בתוכנית חדשה. עם זאת, התהליך עצמו נשאר אותו תהליך במערכת ההפעלה, ולכן הוא שומר על ה-PID המקורי שלו שניתן לו בעת ה-fork."}, "difficulty_estimation": "Medium", "_source_file": "0011__Processes__MultipleChoice__Medium.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:10:11", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "System Calls"], "content": {"text": "נתון קטע הקוד הבא בשפת C. מה יהיה הפלט הצפוי של התוכנית בהנחה שכל קריאות המערכת מצליחות?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    if (fork() == 0) {\n        execlp(\"/bin/echo\", \"echo\", \"Hello\", NULL);\n        printf(\"World\\n\");\n    } else {\n        wait(NULL);\n        printf(\"Goodbye\\n\");\n    }\n    return 0;\n}", "options": ["א. Hello ולאחר מכן World ולאחר מכן Goodbye", "ב. Hello ולאחר מכן Goodbye", "ג. World ולאחר מכן Goodbye", "ד. Goodbye ולאחר מכן Hello", "ה. Hello בלבד"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ב. Hello ולאחר מכן Goodbye", "explanation": "קריאת המערכת execlp מחליפה את דמות התהליך (Process Image) בתוכנית חדשה. לכן, הקוד שמופיע לאחר הקריאה ל-execlp בתהליך הבן לא יבוצע לעולם (אלא אם הקריאה נכשלה). תהליך האב ממתין לסיום הבן בעזרת wait ולכן ידפיס Goodbye רק לאחר שהבן סיים להדפיס Hello."}, "difficulty_estimation": "Medium", "_source_file": "0012__Processes__MultipleChoice__Medium.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:10:32", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "System Calls", "Fork"], "content": {"text": "מה יהיה הפלט של הקוד הבא (בהנחה שכל קריאות המערכת מצליחות והפלט מודפס למסך באופן מיידי)?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 10;\n    if (fork() == 0) {\n        x += 5;\n        if (fork() == 0) {\n            printf(\"%d \", x);\n        } else {\n            wait(NULL);\n            printf(\"%d \", x);\n        }\n    } else {\n        wait(NULL);\n        printf(\"%d \", x);\n    }\n    return 0;\n}", "options": ["א. 10 15 15", "ב. 15 15 10", "ג. 15 20 10", "ד. 15 10 10", "ה. 15 15 15"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב. 15 15 10", "explanation": "התהליך הראשי מתחיל עם x=10. הוא מבצע fork. בתהליך הבן, x הופך ל-15. הבן מבצע fork נוסף ליצירת נכד. הנכד יורש את x=15 ומדפיס אותו. הבן מחכה לנכד (wait) ואז מדפיס את ה-x שלו (שהוא 15). לבסוף, תהליך האב המקורי, שחיכה לסיום הבן, מדפיס את ה-x שלו. מכיוון ש-fork יוצר העתק נפרד של מרחב הכתובות, השינויים בבן ובנכד לא השפיעו על ה-x של האב, ולכן הוא מדפיס 10."}, "difficulty_estimation": "Medium", "_source_file": "0013__Processes__MultipleChoice__Medium.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:10:47", "_subject": "Virtualization"}, {"id": 101, "type": "MultipleChoice", "topic": ["Processes", "System Calls", "Memory Management"], "content": {"text": "לפניך קטע קוד בשפת C המשתמש בקריאת המערכת fork. מה יהיה הפלט של התוכנית (בהנחה שכל הקריאות ל-fork ו-wait מצליחות)?", "code_snippet": "int main() {\n    int x = 10;\n    if (fork() == 0) {\n        x += 5;\n        if (fork() == 0) {\n            x += 5;\n            printf(\"%d\", x);\n        } else {\n            wait(NULL);\n        }\n    } else {\n        wait(NULL);\n        x -= 5;\n        printf(\"%d\", x);\n    }\n    return 0;\n}", "options": ["א. 205", "ב. 2015", "ג. 1510", "ד. 2010", "ה. 155"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "א. 205", "explanation": "לאחר ביצוע fork, נוצר עותק של התהליך עם מרחב כתובות נפרד (Copy-on-Write). בתהליך הבן הראשון, x הופך ל-15. לאחר מכן הוא מבצע fork נוסף, ובתהליך הנכד x הופך ל-20 ומודפס. בתהליך האב המקורי, x נשאר 10 (כי הוא לא מושפע מהשינויים בבנים), ולאחר ה-wait הוא מופחת ב-5 ומודפס הערך 5. כיוון שהאב והבן ממתינים לסיום הצאצאים שלהם, ההדפסה של ה-20 תתבצע לפני ה-5."}, "difficulty_estimation": "Medium", "_source_file": "0014__Processes__MultipleChoice__Medium.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:10:58", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "System Calls", "Memory Management"], "content": {"text": "מה יהיה הפלט של תוכנית ה-C הבאה? הניחו שכל קריאות המערכת מצליחות.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint x = 10;\n\nint main() {\n    pid_t pid = fork();\n    if (pid == 0) {\n        x += 5;\n        return 0;\n    } else {\n        wait(NULL);\n        x -= 2;\n        printf(\"%d\", x);\n    }\n    return 0;\n}", "options": ["א. 8", "ב. 13", "ג. 10", "ד. 15", "ה. אף אחת מהתשובות אינה נכונה"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "א. 8", "explanation": "קריאת המערכת fork יוצרת תהליך חדש עם מרחב כתובות נפרד (Copy-on-Write). למרות שהתהליך הבן משנה את ערכו של x (מעלה ל-15), השינוי מתבצע על העתק מקומי בזיכרון של הבן ואינו משפיע על המשתנה x בתהליך האב. תהליך האב ממתין לסיום הבן באמצעות wait, ולאחר מכן מבצע x -= 2 על הערך המקורי שנותר אצלו (10). לכן הפלט יהיה 8."}, "difficulty_estimation": "Medium", "_source_file": "0015__Processes__MultipleChoice__Medium.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:11:21", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "System Calls", "Memory Management"], "content": {"text": "מה יהיה הפלט של הקוד הבא (בהנחה שכל קריאות המערכת מצליחות)?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 10;\n    if (fork() == 0) {\n        x += 5;\n        printf(\"%d \", x);\n    } else {\n        wait(NULL);\n        x -= 3;\n        printf(\"%d \", x);\n    }\n    return 0;\n}", "options": ["א. 15 12", "ב. 15 7", "ג. 7 15", "ד. 12 15", "ה. התוצאה אינה דטרמיניסטית ותלויה במתזמן."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב. 15 7", "explanation": "לאחר הקריאה ל-fork, נוצרים שני תהליכים נפרדים עם מרחבי כתובות נפרדים. שינוי משתנה בתהליך הבן אינו משפיע על המשתנה בתהליך האב. תהליך הבן מעדכן את x ל-15 ומדפיס. תהליך האב מחכה לסיום הבן באמצעות wait, ולכן הבן תמיד ידפיס ראשון. לאחר מכן האב מעדכן את ה-x המקומי שלו (שערכו נותר 10) ל-7 ומדפיס."}, "difficulty_estimation": "Medium", "_source_file": "0016__Processes__MultipleChoice__Medium.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:11:30", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "fork", "wait", "Copy-on-Write"], "content": {"text": "נתון קוד ה-C הבא. בהנחה שכל הקריאות ל-fork() מצליחות ושהמערכת מדפיסה את הפלט למסך, מהם הערכים שיודפסו על ידי כל התהליכים שנוצרו (בסדר כלשהו)?", "code_snippet": "int main() {\n    int x = 0;\n    for (int i = 0; i < 3; i++) {\n        if (fork() == 0) {\n            x++;\n        } else {\n            x--;\n            wait(NULL);\n            break;\n        }\n    }\n    printf(\"%d \", x);\n    return 0;\n}", "options": ["-1 0 1 3", "0 1 2 3", "-1 -1 -1 3", "-1 0 1 2", "אף אחת מהתשובות אינה נכונה"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "-1 0 1 3", "explanation": "הקוד מבצע לולאה שבה בכל שלב נוצר תהליך ילד חדש. האב (התהליך שקיבל ערך חיובי מ-fork) מחסיר 1 מהמשתנה המקומי x שלו, ממתין לסיום הילד שלו (wait), ויוצא מהלולאה (break). הילד (שקיבל 0 מ-fork) מוסיף 1 ל-x שלו וממשיך לאיטרציה הבאה של הלולאה.\n1. תהליך מקורי P0 (עם x=0): ב-i=0 יוצר את P1. ב-P0 ה-x הופך ל-1-, הוא עוצר ומדפיס 1-.\n2. תהליך P1 (הילד של P0, התחיל עם x=1): ב-i=1 יוצר את P2. ב-P1 ה-x הופך ל-0 (פחות 1), הוא עוצר ומדפיס 0.\n3. תהליך P2 (הילד של P1, התחיל עם x=2): ב-i=2 יוצר את P3. ב-P2 ה-x הופך ל-1 (פחות 1), הוא עוצר ומדפיס 1.\n4. תהליך P3 (הילד של P2, התחיל עם x=3): מסיים את הלולאה (i=3) ומדפיס 3.\nהערכים המודפסים הם 1-, 0, 1, 3. בשל ה-wait, הסדר יהיה הפוך (3, 1, 0, 1-) אך השאלה ביקשה את הערכים בסדר כלשהו."}, "difficulty_estimation": "Hard", "_source_file": "0017__Processes__MultipleChoice__Hard.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:11:57", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "fork", "waitpid", "Memory Management"], "content": {"text": "בהנחה שכל הקריאות למערכת (fork, waitpid) מצליחות, מה יהיה הפלט של קוד ה-C הבא?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    int x = 10;\n    pid_t pid = fork();\n    if (pid == 0) {\n        x += 5;\n        pid_t pid2 = fork();\n        if (pid2 == 0) {\n            x += 5;\n            exit(x);\n        }\n        int status;\n        waitpid(pid2, &status, 0);\n        if (WIFEXITED(status)) {\n            x += WEXITSTATUS(status);\n        }\n        printf(\"%d\", x);\n    } else {\n        wait(NULL);\n    }\n    return 0;\n}", "options": ["א. 15", "ב. 20", "ג. 30", "ד. 35", "ה. 40"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "הסבר: 1. האב המקורי יוצר תהליך בן (C1). לכל אחד מהם מרחב זיכרון נפרד. 2. בתוך C1, המשתנה x מעודכן ל-15. 3. C1 יוצר תהליך נכד (G1). ל-G1 עותק נפרד של הזיכרון שבו x הוא 15. 4. G1 מעדכן את x ל-20 ומסיים עם exit(20). 5. C1 ממתין ל-G1 ובעזרת המאקרו WEXITSTATUS שולף את קוד החזרה (20). 6. C1 מוסיף את הערך שחזר (20) ל-x המקומי שלו (15), ולכן x ב-C1 הופך ל-35. 7. C1 מדפיס את הערך 35. האב המקורי רק מבצע wait ולכן לא מדפיס דבר."}, "difficulty_estimation": "Hard", "_source_file": "0018__Processes__MultipleChoice__Hard.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:12:18", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "fork", "exec", "Process Image"], "content": {"text": "נתון קוד ה-C הבא. בהנחה שכל הקריאות למערכת מצליחות וכל הקבצים קיימים, מה יהיה הפלט של התוכנית?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    printf(\"1\\n\");\n    if (fork() == 0) {\n        printf(\"2\\n\");\n        execlp(\"/bin/echo\", \"echo\", \"3\", NULL);\n        printf(\"4\\n\");\n    } else {\n        wait(NULL);\n        printf(\"5\\n\");\n    }\n    return 0;\n}", "options": ["1, 2, 3, 4, 5", "1, 2, 3, 5", "1, 2, 4, 5", "1, 3, 2, 5", "הקוד יגרום לשגיאת זמן ריצה (Runtime Error)"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "1, 2, 3, 5", "explanation": "התהליך הראשי מתחיל ומדפיס '1'. לאחר מכן מתבצע fork. בתהליך הבן, מודפס '2' ואז מתבצעת הקריאה ל-execlp. פקודה זו מחליפה את תמונת הזיכרון של התהליך הנוכחי בתוכנית החדשה (echo). לכן, הקוד שמופיע לאחר ה-exec (הדפסת '4') לעולם לא יתבצע אם ה-exec הצליח. התוכנית echo מדפיסה '3' ומסתיימת. תהליך האב ממתין לסיום הבן באמצעות wait, ורק לאחר מכן מדפיס '5'. לכן הפלט יהיה 1, 2, 3, 5."}, "difficulty_estimation": "Hard", "_source_file": "0019__Processes__MultipleChoice__Hard.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:12:41", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Processes", "fork", "wait", "Zombie Processes", "Orphan Processes"], "content": {"text": "נתון קטע הקוד הבא בשפת C המורץ על מערכת Linux. נניח שכל הקריאות ל-fork מצליחות, ה-PID של התהליך המקורי הוא 100, וה-PID של תהליך ה-init במערכת הוא 1. מה יודפס על ידי ה-Grandchild (הנכד), ומה יהיה מצבו של תהליך הבן (Child 1) ברגע שה-Grandchild מדפיס את הפלט?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    pid_t pid = fork();\n    if (pid == 0) { // Child 1\n        if (fork() == 0) { // Grandchild\n            sleep(2);\n            printf(\"%d\", getppid());\n            exit(0);\n        }\n        exit(0);\n    }\n    wait(NULL);\n    sleep(5);\n    return 0;\n}", "options": ["א. יודפס 100, ותהליך Child 1 יהיה במצב Zombie.", "ב. יודפס 1, ותהליך Child 1 יהיה במצב Zombie.", "ג. יודפס 1, ותהליך Child 1 לא יהיה קיים במערכת (נוקה).", "ד. יודפס 100, ותהליך Child 1 לא יהיה קיים במערכת (נוקה).", "ה. יודפס ה-PID של ה-Grandchild, ו-Child 1 יהיה במצב Running."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "כאשר Child 1 מבצע exit, הוא הופך ל-Zombie. התהליך המקורי (Parent) קורא ל-wait(NULL), פעולה זו 'אוספת' את הסטטוס של Child 1 ומנקה אותו מטבלת התהליכים (Reaping), לכן הוא אינו קיים יותר במערכת. ה-Grandchild הופך ליתום (Orphan) כיוון שאביו (Child 1) סיים את ריצתו. במערכות Linux, תהליך יתום מאומץ על ידי תהליך ה-init (או subreaper), שכתובתו היא 1. לכן, getppid() יחזיר 1."}, "difficulty_estimation": "Hard", "_source_file": "0020__Processes__MultipleChoice__Hard.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:12:58", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "fork", "Zombie Processes", "Orphan Processes"], "content": {"text": "נתון קטע הקוד הבא בשפת C. נניח שכל הקריאות ל-fork מצליחות, ושהמערכת משתמשת בתהליך ה-init (PID 1) כמאמץ ברירת מחדל לתהליכים יתומים. מה יהיה מצב התהליכים במערכת כעבור 5 שניות מתחילת ריצת התוכנית?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/types.h>\n#include <stdlib.h>\n\nint main() {\n    pid_t pid = fork();\n    if (pid == 0) {\n        // Child process\n        if (fork() > 0) {\n            // Child creates a Grandchild and exits immediately\n            _exit(0);\n        }\n        // Grandchild process continues\n        sleep(100);\n    } else {\n        // Parent process\n        // Parent does not call wait() yet\n        sleep(100);\n    }\n    return 0;\n}", "options": ["א. התהליך הנכד (Grandchild) יהיה במצב Zombie והתהליך הבן (Child) יהיה במצב Running.", "ב. התהליך הבן (Child) יהיה במצב Zombie והתהליך הנכד (Grandchild) יאומץ על ידי ה-init (או reaper process).", "ג. התהליך הבן (Child) ינוקה מהמערכת באופן מיידי כי הוא קרא ל-_exit, והנכד ימשיך לרוץ תחת האב המקורי.", "ד. כל התהליכים יסיימו את ריצתם כיוון שהבן (שהוא ההורה של הנכד) סיים את ריצתו."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "לאחר ה-fork הראשון נוצר תהליך הבן. הבן מבצע fork נוסף ויוצר את הנכד, ואז קורא מיד ל-_exit ומסיים. מכיוון שהאב המקורי עדיין רץ (ב-sleep) ולא קרא ל-wait(), הבן הופך ל-Zombie (תהליך שסיים אך רשומתו נשארת בטבלת התהליכים). הנכד הופך ליתום (Orphan) כי אביו (הבן) מת, ולכן הוא מאומץ על ידי ה-init process."}, "difficulty_estimation": "Hard", "_source_file": "0021__Processes__MultipleChoice__Hard.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:13:14", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "fork", "Address Space", "wait"], "content": {"text": "נתון קטע הקוד הבא בשפת C. מה יהיה סכום כל המספרים שיודפסו למסך (Standard Output) בהנחה שכל הקריאות ל-fork ו-wait מצליחות ואין בעיות זיכרון?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 2;\n    if (fork() == 0) {\n        x = x * 2;\n        if (fork() == 0) {\n            x = x + 1;\n            printf(\"%d\\n\", x);\n        } else {\n            wait(NULL);\n            x = x - 1;\n            printf(\"%d\\n\", x);\n        }\n    } else {\n        wait(NULL);\n        x = x + 2;\n        printf(\"%d\\n\", x);\n    }\n    return 0;\n}", "options": ["12", "10", "14", "9", "התוצאה אינה דטרמיניסטית ותלויה בסדר התזמון של המעבד"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "12", "explanation": "במערכת הפעלה, פקודת fork יוצרת תהליך בן עם מרחב כתובות נפרד המהווה העתק של תהליך האב. ננתח את זרימת התוכנית: 1. תהליך האב המקורי (P) מתחיל עם x=2. 2. P יוצר את C1. בתוך C1, המשתנה x מוכפל ב-2 (x=4). 3. C1 יוצר את GC (הנכד). בתוך GC, המשתנה x (שהועתק מ-C1 כ-4) גדל ב-1 (x=5) ומודפס המספר 5. 4. C1 ממתין לסיום GC, ואז מחסיר 1 מה-x שלו (4-1=3) ומדפיס 3. 5. P ממתין לסיום C1, ואז מוסיף 2 ל-x שלו (2+2=4) ומדפיס 4. סכום כל ההדפסות: 5+3+4=12. כיוון שמרחבי הכתובות מופרדים (Copy-on-Write), השינויים ב-x בכל תהליך אינם משפיעים על האחרים."}, "difficulty_estimation": "Hard", "_source_file": "0022__Processes__MultipleChoice__Hard.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:13:46", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "Fork", "Memory Space", "Wait"], "content": {"text": "מה יהיה הפלט של הקוד הבא בשפת C, בהנחה שכל הקריאות למערכת מצליחות ושסדר ההדפסה נקבע על פי ה-wait (כלומר, תהליך אב תמיד ידפיס אחרי שתהליך הבן שלו סיים)?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int val = 5;\n    if (fork() == 0) {\n        val += 10;\n        if (fork() == 0) {\n            val *= 2;\n            printf(\"%d \", val);\n        } else {\n            wait(NULL);\n            val -= 5;\n            printf(\"%d \", val);\n        }\n    } else {\n        wait(NULL);\n        val += 1;\n        printf(\"%d \", val);\n    }\n    return 0;\n}", "options": ["א. 30 10 6", "ב. 30 25 6", "ג. 15 10 6", "ד. 30 10 16", "ה. אף אחת מהתשובות אינה נכונה."]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "בתהליך המקורי (P1) המשתנה val שווה 5. לאחר ה-fork הראשון, נוצר תהליך בן (P2) שמקבל עותק של val עם הערך 5. P2 מעדכן את val שלו ל-15 (5+10). לאחר מכן P2 מבצע fork נוסף ויוצר את P3. P3 מקבל עותק של val מ-P2, כלומר 15, מכפיל ב-2 ומדפיס 30. P2 ממתין ל-P3, לאחר מכן מחסיר 5 מה-val שלו (שהיה 15) ומדפיס 10. לבסוף, P1 שהמתין ל-P2, מעדכן את ה-val המקורי שלו (5) ב-1 ומדפיס 6. כיוון שכל תהליך פועל במרחב כתובות נפרד, השינויים במשתנה val אינם משותפים בין התהליכים."}, "difficulty_estimation": "Hard", "_source_file": "0023__Processes__MultipleChoice__Hard.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:14:03", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Processes", "System Calls", "File Descriptors"], "content": {"text": "נתון קטע הקוד הבא המבוצע במערכת הפעלה Unix. נניח שכל קריאות המערכת מצליחות והקובץ test.txt נפתח כקובץ ריק (גודל 0). מה יהיה תוכן הקובץ בסיום ריצת התוכנית?", "code_snippet": "#include <fcntl.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    int fd = open(\"test.txt\", O_RDWR | O_CREAT | O_TRUNC, 0644);\n    write(fd, \"OS\", 2);\n    if (fork() == 0) {\n        write(fd, \"IS\", 2);\n        exit(0);\n    } else {\n        wait(NULL);\n        write(fd, \"FUN\", 3);\n    }\n    close(fd);\n    return 0;\n}", "options": ["א. OSISFUN", "ב. OSIS", "ג. OSFUN", "ד. OS"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "לאחר ביצוע קריאת המערכת fork(), תהליך הבן מקבל עותק של טבלת מתארי הקבצים (File Descriptor Table) של האב. עם זאת, מתארי הקבצים בשני התהליכים מצביעים לאותה כניסה בטבלת הקבצים הפתוחים של מערכת ההפעלה (System-wide Open File Table). כניסה זו מנהלת את ה-File Offset עבור הקובץ הפתוח. כיוון שהאופסט משותף, כאשר הבן כותב את המחרוזת 'IS', הוא מקדם את האופסט מ-2 ל-4. כיוון שהאב ממתין לסיום הבן (בעזרת wait), הוא יבצע את הכתיבה של 'FUN' רק לאחר מכן, והיא תתחיל מהאופסט המעודכן (4). לכן התוצאה היא OSISFUN."}, "difficulty_estimation": "Hard", "_source_file": "0024__Processes__MultipleChoice__Hard.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:14:38", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Processes"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בקריאות מערכת מסוג fork. כמה פעמים תודפס המחרוזת \"Hello\" במהלך הרצה תקינה של התוכנית? הסבירו את תשובתכם על ידי מעקב אחר יצירת התהליכים.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n\nint main() {\n    fork();\n    if (fork() == 0) {\n        fork();\n    }\n    printf(\"Hello\\n\");\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "המחרוזת \"Hello\" תודפס 6 פעמים. \nמעקב אחר יצירת התהליכים:\n1. התוכנית מתחילה עם תהליך אב יחיד (P1).\n2. לאחר ה-fork() הראשון, נוצר תהליך בן (P2). כעת ישנם 2 תהליכים במערכת.\n3. שני התהליכים (P1 ו-P2) מגיעים לשורת ה-if ומבצעים fork() נוסף. נוצרים שני תהליכים חדשים: P3 (הבן של P1) ו-P4 (הבן של P2). כעת ישנם 4 תהליכים במערכת.\n4. תנאי ה-if בודק האם הערך המוחזר מפעולת ה-fork הוא 0. תנאי זה מתקיים אך ורק עבור תהליכי הבן שזה עתה נוצרו (P3 ו-P4).\n5. בתוך בלוק ה-if, התהליכים P3 ו-P4 מבצעים fork() נוסף, מה שיוצר שני תהליכים חדשים נוספים (P5 ו-P6). כעת ישנם סה\"כ 6 תהליכים במערכת.\n6. כל 6 התהליכים הקיימים (P1, P2, P3, P4, P5, P6) ממשיכים בביצוע הקוד ומגיעים לשורת ה-printf. לכן, המחרוזת תודפס 6 פעמים."}, "difficulty_estimation": "Easy", "_source_file": "0025__Processes__Open__Easy.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:14:55", "_subject": "Virtualization"}, {"id": 8, "type": "Open", "topic": ["Processes", "fork"], "content": {"text": "כמה תהליכים נוצרים בסך הכל (כולל תהליך האב המקורי) במהלך הרצת הקוד הבא? יש לפרט את שלבי ההיווצרות של התהליכים.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/types.h>\n\nint main() {\n    fork();\n    pid_t pid = fork();\n    if (pid > 0) {\n        fork();\n    }\n    printf(\"Process\\n\");\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "להלן שלבי היווצרות התהליכים:\n1. בתחילה קיים תהליך אחד (נסמנו P1).\n2. לאחר פקודת ה-fork() הראשונה, נוצר תהליך בן (P2). כעת יש במערכת 2 תהליכים.\n3. לאחר פקודת ה-fork() השנייה, כל אחד משני התהליכים הקיימים (P1 ו-P2) מתפצל פעם נוספת. נוצרים שני תהליכים חדשים (P3 ו-P4). כעת יש במערכת 4 תהליכים.\n4. המשתנה pid מכיל את ערך ההחזר של ה-fork השני. בתהליכי האב של הפיצול השני (P1 ו-P2) הערך יהיה גדול מ-0 (ה-PID של הבן), ובתהליכי הבן החדשים (P3 ו-P4) הערך יהיה 0.\n5. פקודת ה-if מתבצעת רק עבור תהליכים בהם pid > 0, כלומר רק P1 ו-P2 מבצעים את ה-fork() השלישי.\n6. ה-fork השלישי יוצר עוד שני תהליכים (P5 ו-P6).\n7. לסיכום: 1 (התחלתי) + 1 (ב-fork הראשון) + 2 (ב-fork השני) + 2 (ב-fork השלישי בתוך ה-if) = 6 תהליכים סך הכל."}, "difficulty_estimation": "Easy", "_source_file": "0026__Processes__Open__Easy.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:15:08", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Processes", "fork"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בקריאת המערכת fork(). כמה תהליכים בסך הכל (כולל תהליך האב המקורי) ייווצרו במהלך ריצת התוכנית? הניחו שכל הקריאות ל-fork() מצליחות. יש להסביר את שלבי ההיווצרות.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n\nint main() {\n    fork();\n    if (fork() == 0) {\n        fork();\n    }\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "במהלך ריצת התוכנית ייווצרו בסך הכל 6 תהליכים (כולל האב המקורי). להלן הפירוט:\n1. התוכנית מתחילה עם תהליך אחד (P1).\n2. הקריאה הראשונה ל-fork() יוצרת תהליך בן (P2). כעת ישנם 2 תהליכים.\n3. לאחר מכן, שני התהליכים (P1 ו-P2) מגיעים לשורת ה-if ומבצעים fork() נוסף. \n   - P1 יוצר את P3 (עבור P3 הערך המוחזר הוא 0, עבור P1 הערך הוא ה-PID של P3).\n   - P2 יוצר את P4 (עבור P4 הערך המוחזר הוא 0, עבור P2 הערך הוא ה-PID של P4).\n   כעת ישנם 4 תהליכים.\n4. תנאי ה-if בודק האם הערך המוחזר מ-fork הוא 0. תנאי זה מתקיים רק עבור תהליכי הבן החדשים שנוצרו בשלב הקודם (P3 ו-P4).\n5. בתוך בלוק ה-if, שני התהליכים הללו (P3 ו-P4) קוראים ל-fork() פעם שלישית:\n   - P3 יוצר את P5.\n   - P4 יוצר את P6.\n6. סך כל התהליכים במערכת: P1, P2, P3, P4, P5, P6 (סה\"כ 6)."}, "difficulty_estimation": "Easy", "_source_file": "0027__Processes__Open__Easy.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:15:23", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Processes", "Memory Management", "Fork"], "content": {"text": "נתון קוד ה-C הבא המשתמש בקריאת המערכת fork. מה יהיה הפלט של התוכנית (הניחו שכל קריאות המערכת מצליחות)? הסבירו האם השינוי במשתנה x בתהליך הבן משפיע על ערכו בתהליך האב.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 10;\n    pid_t pid = fork();\n\n    if (pid == 0) {\n        // תהליך הבן\n        x = x + 5;\n        printf(\"Child: x = %d\\n\", x);\n    } else {\n        // תהליך האב\n        wait(NULL);\n        x = x - 5;\n        printf(\"Parent: x = %d\\n\", x);\n    }\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפלט של התוכנית יהיה:\nChild: x = 15\nParent: x = 5\n\nהסבר: קריאת המערכת fork יוצרת תהליך חדש (בן) המהווה העתק של תהליך האב. למרות שהבן יורש את ערכי המשתנים של האב ברגע הפיצול, לכל תהליך יש מרחב כתובות (Address Space) נפרד ומבודד בזיכרון. לכן, כל שינוי שמבצע תהליך הבן במשתנה x מתבצע בזיכרון הפרטי שלו ואינו משפיע על ערכו של x במרחב הזיכרון של תהליך האב. תהליך האב ממתין לסיום הבן באמצעות wait, ולאחר מכן מדפיס את ערכו של x המקורי (10) פחות 5."}, "difficulty_estimation": "Easy", "_source_file": "0028__Processes__Open__Easy.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:15:41", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Processes", "fork"], "content": {"text": "לפניך קטע קוד בשפת C המשתמש בקריאת המערכת fork(). הנח שכל הקריאות ל-fork() מצליחות ושאין שגיאות בזמן הריצה.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n\nint main() {\n    fork();\n    if (fork() == 0) {\n        fork();\n    }\n    printf(\"Done\\n\");\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "כמה תהליכים סך הכל ייווצרו במהלך ריצת התוכנית (כולל התהליך הראשי)?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "כמה פעמים תודפס המחרוזת \"Done\" למסך? נמק את תשובתך.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: סך הכל ייווצרו 6 תהליכים.\nניתוח שלבי היצירה:\n1. ה-fork() הראשון מפצל את התהליך המקורי (P) לשני תהליכים: P ו-C1.\n2. ה-fork() השני מתבצע על ידי שני התהליכים הקיימים (P ו-C1). P יוצר את C2, ו-C1 יוצר את C3. כעת ישנם 4 תהליכים במערכת.\n3. התנאי (fork() == 0) מתקיים רק עבור הילדים שנוצרו ב-fork השני (C2 ו-C3). לכן רק הם נכנסים לתוך בלוק ה-if.\n4. בתוך ה-if, התהליך C2 מבצע fork() ויוצר את C4. התהליך C3 מבצע fork() ויוצר את C5.\n5. סך התהליכים: P, C1, C2, C3, C4, C5 - סה\"כ 6 תהליכים.\n\n1.2: המחרוזת תודפס 6 פעמים.\nהסבר: כל תהליך שנוצר במהלך ריצת התוכנית ממשיך בביצוע הקוד עד סוף פונקציית ה-main. מכיוון שפקודת ה-printf נמצאת מחוץ לבלוק ה-if (אחריו), כל אחד מ-6 התהליכים שנוצרו יגיע לשורה זו וידפיס את המחרוזת פעם אחת."}, "difficulty_estimation": "Easy", "_source_file": "0029__Processes__Open__Easy.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:16:00", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Processes", "fork"], "content": {"text": "כמה תהליכים ייווצרו בסך הכל (כולל התהליך הראשי) כתוצאה מהרצת הקוד הבא? פרטו את החישוב והסבירו בקצרה כיצד הגעתם לתוצאה.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n\nint main() {\n    fork();\n    fork();\n    fork();\n    printf(\"Hello\\n\");\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "בכל קריאה לפקודת fork(), כל תהליך קיים במערכת שמריץ את השורה הזו מתפצל לשני תהליכים: תהליך האב המקורי ותהליך בן חדש. שני התהליכים ממשיכים את הריצה מאותה נקודה בקוד. \nהחישוב הוא כדלקמן:\n1. התחלה: תהליך 1 (הראשי).\n2. לאחר ה-fork הראשון: התהליך הראשי יוצר בן, סה\"כ 2 תהליכים.\n3. לאחר ה-fork השני: כל אחד מ-2 התהליכים הקיימים יוצר בן, סה\"כ 4 תהליכים.\n4. לאחר ה-fork השלישי: כל אחד מ-4 התהליכים הקיימים יוצר בן, סה\"כ 8 תהליכים.\nבאופן כללי, עבור n קריאות עוקבות ל-fork(), מספר התהליכים הכולל יהיה 2 בחזקת n. במקרה זה 2^3 = 8."}, "difficulty_estimation": "Easy", "_source_file": "0030__Processes__Open__Easy.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:16:09", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Processes", "fork"], "content": {"text": "כמה תהליכים נוצרים בסך הכל (כולל תהליך האב המקורי) במהלך ריצת הקוד הבא? הסבירו את תשובתכם.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n\nint main() {\n    fork();\n    fork();\n    fork();\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כל קריאה לפקודת fork() יוצרת תהליך בן חדש שהוא העתק של התהליך הקורא. \n1. בתחילה קיים תהליך אחד (האב).\n2. לאחר ה-fork הראשון, ישנם 2 תהליכים (האב והבן הראשון).\n3. לאחר ה-fork השני, כל אחד מ-2 התהליכים הקיימים מבצע fork, ולכן נוצרים 2 תהליכים נוספים, סה\"כ 4 תהליכים.\n4. לאחר ה-fork השלישי, כל אחד מ-4 התהליכים הקיימים מבצע fork, ולכן נוצרים 4 תהליכים נוספים, סה\"כ 8 תהליכים.\nבאופן כללי, עבור n קריאות עוקבות ל-fork, מספר התהליכים יהיה 2 בחזקת n."}, "difficulty_estimation": "Easy", "_source_file": "0031__Processes__Open__Easy.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:16:17", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Processes"], "content": {"text": "נתון קטע הקוד הבא בשפת C. בהנחה שכל הקריאות למערכת מצליחות, כמה תהליכים סה\"כ ירוצו במהלך ביצוע התוכנית (כולל תהליך האב המקורי)? יש לפרט את שלבי היצירה של התהליכים.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n\nint main() {\n    fork();\n    if (fork() == 0) {\n        fork();\n    }\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "שלבי יצירת התהליכים הם כדלקמן:\n1. בתחילה קיים תהליך אחד (נסמנו P1).\n2. לאחר ביצוע ה-fork() הראשון בשורה 5, נוצר תהליך בן (P2). כעת ישנם 2 תהליכים במערכת.\n3. בשורה 6, שני התהליכים (P1 ו-P2) מבצעים את הקריאה fork() בתוך תנאי ה-if:\n   - P1 יוצר תהליך בן חדש (P3). עבור P3 הפונקציה מחזירה 0, ולכן הוא נכנס לבלוק ה-if.\n   - P2 יוצר תהליך בן חדש (P4). עבור P4 הפונקציה מחזירה 0, ולכן הוא נכנס לבלוק ה-if.\n   - עבור P1 ו-P2, הפונקציה מחזירה ערך שונה מ-0 (ה-PID של הבנים שלהם), ולכן הם אינם נכנסים לבלוק ה-if.\n4. בתוך בלוק ה-if (שורה 7), התהליכים P3 ו-P4 מבצעים fork() נוסף:\n   - P3 יוצר תהליך בן חדש (P5).\n   - P4 יוצר תהליך בן חדש (P6).\n5. לסיכום, התהליכים שהורצו הם: P1 (המקורי), P2 (נוצר ב-fork הראשון), P3 ו-P4 (נוצרו ב-fork השני), P5 ו-P6 (נוצרו ב-fork השלישי).\nסה\"כ: 6 תהליכים."}, "difficulty_estimation": "Easy", "_source_file": "0032__Processes__Open__Easy.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:16:39", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Processes", "fork", "Memory Isolation"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בקריאה למערכת fork. הניחו שכל הקריאות למערכת מצליחות ושאין תהליכי זומבי הממתינים במערכת.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/types.h>\n\nint main() {\n    int x = 5;\n    if (fork() == 0) {\n        x += 10;\n        if (fork() == 0) {\n            x += 10;\n        }\n    } else {\n        x -= 5;\n        fork();\n    }\n    printf(\"%d\\n\", x);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "כמה תהליכים נוצרו סך הכל במהלך ריצת התוכנית (כולל התהליך הראשי)? הציגו את עץ התהליכים שנוצר.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "מהם הערכים השונים שיודפסו למסך? הסבירו עבור כל ערך איזה תהליך מדפיס אותו וכיצד הגיע לערך זה.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "האם שינוי הערך של x בתהליך אחד משפיע על הערך של x בתהליך אחר? הסבירו מדוע, תוך התייחסות למנגנון ניהול הזיכרון של תהליכים במערכת ההפעלה.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: סך הכל נוצרו 4 תהליכים. התהליך הראשי (P0) יוצר תהליך בן (P1). P1 יוצר תהליך נכד (P2). לאחר מכן, התהליך הראשי (P0) יוצר תהליך בן נוסף (P3). עץ התהליכים: P0 הוא השורש, בניו הם P1 ו-P3, ו-P2 הוא הבן של P1.\n\n1.2: הערכים שיודפסו הם 25, 15, 0, 0 (הסדר עשוי להשתנות בהתאם לתזמון):\n- תהליך P2 (הנכד): נכנס לבלוק ה-if הראשון של אביו (x=15) ולבלוק ה-if השני שלו עצמו (x=25) ומדפיס 25.\n- תהליך P1 (הבן הראשון): נכנס לבלוק ה-if הראשון (x=15), מסיים את ה-if הפנימי ומדפיס 15.\n- תהליך P0 (האב): נכנס לבלוק ה-else, מעדכן ל-x=0, מבצע fork ומדפיס 0.\n- תהליך P3 (הבן השני): נוצר בתוך ה-else של P0, יורש את הערך x=0 ומדפיס 0.\n\n1.3: לא, שינוי הערך אינו משפיע. לכל תהליך יש מרחב כתובות וירטואלי נפרד (Address Space). בעת ביצוע fork, מערכת ההפעלה יוצרת העתק של מרחב הכתובות עבור הבן. למרות שהתהליכים משתמשים באותה כתובת וירטואלית עבור x, הן ממופות למסגרות שונות בזיכרון הפיזי (או משוכפלות בעת כתיבה במנגנון Copy-on-Write), ולכן השינויים מבודדים."}, "difficulty_estimation": "Medium", "_source_file": "0033__Processes__Open__Medium.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:17:00", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Processes", "fork", "Memory Isolation"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בקריאת המערכת fork. הניחו שכל הקריאות ל-fork מצליחות ושהפלט מודפס למסך באופן מיידי. הניחו כי פקודת ה-wait(NULL) גורמת לתהליך האב להמתין לסיום ביצועו של תהליך הבן הישיר שלו.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 10;\n    if (fork() == 0) {\n        x += 5;\n        if (fork() == 0) {\n            x += 5;\n            printf(\"%d\\n\", x);\n        } else {\n            wait(NULL);\n            x -= 2;\n            printf(\"%d\\n\", x);\n        }\n    } else {\n        wait(NULL);\n        x -= 5;\n        printf(\"%d\\n\", x);\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "כמה תהליכים נוצרו בסך הכל במהלך ריצת התוכנית (כולל התהליך הראשי)?", "code_snippet": null, "options": null}, {"id": "7.2", "text": "מה יהיו הערכים שיודפסו למסך ובאיזה סדר? נמקו את תשובתכם.", "code_snippet": null, "options": null}, {"id": "7.3", "text": "האם שינוי המשתנה x בתהליך הבן משפיע על ערכו של x בתהליך האב? הסבירו מדוע על סמך מנגנוני ניהול זיכרון בסיסיים של תהליכים.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1: נוצרו 3 תהליכים בסך הכל. התהליך הראשי (P1) קרא ל-fork ויצר את P2. תהליך P2 קרא ל-fork פנימי ויצר את P3.\n\n7.2: הערכים שיודפסו הם 20, לאחר מכן 13, ולבסוף 5. \nהסבר: \n- תהליך P3 (הנכד) מקבל x=15 מ-P2, מוסיף 5 ומדפיס 20.\n- תהליך P2 (הבן) ממתין ל-P3, לאחר מכן מחסיר 2 מה-x שלו (שהיה 15) ומדפיס 13.\n- תהליך P1 (האב) ממתין ל-P2, לאחר מכן מחסיר 5 מה-x שלו (שהיה 10) ומדפיס 5.\nהסדר מובטח בזכות קריאות ה-wait.\n\n7.3: לא, השינוי אינו משפיע. בעת ביצוע fork, מערכת ההפעלה יוצרת העתק של מרחב הכתובות של האב עבור הבן. למרות שבתחילה הנתונים זהים, לכל תהליך יש זיכרון וירטואלי נפרד. בזכות מנגנון Copy-on-Write, ברגע שתהליך מנסה לשנות משתנה, נוצר עותק פיזי נפרד עבורו, ולכן שינויים בתהליך אחד אינם נראים בתהליך אחר."}, "difficulty_estimation": "Medium", "_source_file": "0034__Processes__Open__Medium.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:17:15", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Processes", "Process Creation", "fork"], "content": {"text": "לפניכם קוד בשפת C המשתמש בקריאות המערכת fork ו-wait. הניחו שכל קריאות המערכת מצליחות ושהתהליכים מתזמנים בצורה כזו שכל תהליך אב ממתין לסיום ילדיו לפני הדפסה.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 10;\n    pid_t pid1, pid2;\n\n    pid1 = fork();\n    if (pid1 == 0) {\n        x += 5;\n        pid2 = fork();\n        if (pid2 == 0) {\n            x += 5;\n            printf(\"C2: x=%d\\n\", x);\n        } else {\n            wait(NULL);\n            printf(\"C1: x=%d\\n\", x);\n        }\n    } else {\n        wait(NULL);\n        printf(\"P: x=%d\\n\", x);\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "כמה תהליכים נוצרו בסך הכל במהלך ריצת התוכנית, כולל התהליך הראשי?", "code_snippet": null, "options": null}, {"id": "7.2", "text": "מה יהיה הפלט של התוכנית? יש לכתוב את השורות לפי סדר הדפסתן.", "code_snippet": null, "options": null}, {"id": "7.3", "text": "הסבירו מדוע השינויים במשתנה x בתהליכי הבנים אינם משתקפים בערכו של x בתהליך האב (P).", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1: נוצרו 3 תהליכים בסך הכל. התהליך הראשי (P) מבצע fork ויוצר את C1. התהליך C1 מבצע fork נוסף ויוצר את C2.\n\n7.2: הפלט יהיה:\nC2: x=20\nC1: x=15\nP: x=10\nהסבר: C2 יורש מ-C1 את x=15 ומוסיף 5. C1 מוסיף 5 ל-10 המקורי. האב P נשאר עם 10. בגלל קריאות ה-wait, הסדר מובטח מהנכד לסבא.\n\n7.3: כאשר מתבצע fork, נוצר עותק של מרחב הכתובות של תהליך האב עבור הבן. למרות שהם חולקים קוד, לכל תהליך יש מחסנית (stack) וסגמנט נתונים (data segment) נפרדים משלו. מנגנון Copy-on-Write מוודא שברגע שתהליך מנסה לשנות משתנה, נוצר עותק פיזי נפרד בזיכרון, ולכן שינוי ב-x בתהליך אחד לא ישפיע על האחרים."}, "difficulty_estimation": "Medium", "_source_file": "0035__Processes__Open__Medium.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:17:26", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Processes", "fork", "Process Lifecycle"], "content": {"text": "נתון קוד בשפת C המשתמש בקריאת המערכת fork. הניחו שכל הקריאות ל-fork מצליחות.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 10;\n    if (fork() == 0) {\n        x += 5;\n        if (fork() == 0) {\n            x += 5;\n            printf(\"C2: x = %d\\n\", x);\n        } else {\n            wait(NULL);\n            printf(\"C1: x = %d\\n\", x);\n        }\n    } else {\n        wait(NULL);\n        x -= 5;\n        printf(\"P: x = %d\\n\", x);\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "כמה תהליכים נוצרים סה\"כ במהלך ריצת התוכנית (כולל התהליך הראשי)? תארו את עץ התהליכים שנוצר.", "code_snippet": null, "options": null}, {"id": "7.2", "text": "מה יהיה הפלט של התוכנית? הסבירו מדוע השינויים במשתנה x בכל תהליך אינם משפיעים על ערכו בתהליכים האחרים.", "code_snippet": null, "options": null}, {"id": "7.3", "text": "הגדירו מהו תהליך \"זומבי\" (Zombie Process). האם במהלך ריצת קוד זה (כפי שהוא כתוב) אחד התהליכים הופך לזומבי לפרק זמן מסוים? הסבירו.", "code_snippet": null, "options": null}, {"id": "7.4", "text": "מה יקרה אם נסיר את כל קריאות ה-wait מהקוד? התייחסו בפרט למושג \"תהליך יתום\" (Orphan Process).", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1: נוצרים 3 תהליכים בסך הכל. התהליך הראשי (P) קורא ל-fork ויוצר את תהליך הבן הראשון (C1). תהליך C1 קורא ל-fork ויוצר את תהליך הנכד (C2). המבנה הוא שרשרת: P -> C1 -> C2.\n\n7.2: הפלט יהיה:\nC2: x = 20\nC1: x = 15\nP: x = 5\nהסבר: כאשר מתבצע fork, נוצר עותק של מרחב הכתובות של תהליך האב עבור הבן. למרות שבתחילה הם חולקים דפים פיזיים (Copy-on-Write), לוגית לכל תהליך יש משתנה x משלו בכתובת וירטואלית זהה אך בזיכרון פיזי נפרד. לכן, שינוי של x ב-C2 לא משפיע על C1, ושינוי ב-C1 לא משפיע על P.\n\n7.3: תהליך זומבי הוא תהליך שסיים את ביצועו (קרא ל-exit) אך עדיין קיימת עבורו רשומה בטבלת התהליכים של מערכת ההפעלה, כיוון שהאב טרם קרא ל-wait כדי לאסוף את סטטוס הסיום שלו. בקוד זה, C2 יהיה זומבי מרגע סיומו ועד ש-C1 יסיים את ה-wait, וכנ\"ל לגבי C1 מול P.\n\n7.4: ללא wait, תהליכי הבנים עלולים להפוך ליתומים אם האב יסיים לפניהם. תהליך יתום הוא תהליך שאביו הסתיים, ובמצב זה מערכת ההפעלה מאמצת אותו (בדרך כלל ע\"י תהליך ה-init/systemd ש-PID שלו הוא 1) כדי להבטיח שמישהו יבצע עליו wait בסיום."}, "difficulty_estimation": "Medium", "_source_file": "0036__Processes__Open__Medium.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:17:40", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Processes", "System Calls", "fork"], "content": {"text": "לפניכם קוד בשפת C המשתמש בקריאות המערכת fork ו-wait. הניחו שכל קריאות המערכת מצליחות.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    for (int i = 0; i < 3; i++) {\n        pid_t pid = fork();\n        if (pid == 0) {\n            printf(\"Child %d\\n\", i);\n            if (i % 2 == 0) {\n                fork();\n            }\n            _exit(0);\n        }\n    }\n    while(wait(NULL) > 0);\n    printf(\"Parent done\\n\");\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "כמה תהליכים בסך הכל ייווצרו במהלך ריצת התוכנית (כולל התהליך הראשי)? הסבירו את החישוב.", "code_snippet": null, "options": null}, {"id": "7.2", "text": "מה יקרה אם נחליף את הקריאה ל-`_exit(0)` בפקודת `break`? כיצד זה ישפיע על מספר התהליכים הנוצרים?", "code_snippet": null, "options": null}, {"id": "7.3", "text": "הסבירו בקצרה את ההבדל בין `exit()` לבין `_exit()`. מדוע בקוד זה נעשה שימוש ב-`_exit()` בתוך תהליך הבן?", "code_snippet": null, "options": null}, {"id": "7.4", "text": "אם נסיר את שורת הקוד `while(wait(NULL) > 0);`, מה עלול לקרות לתהליכי הבן בסיום ריצתם כל עוד התהליך האב עדיין רץ? הגדירו את המושג המתאים.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1: סך הכל ייווצרו 6 תהליכים. פירוט: התהליך הראשי (1) מריץ לולאה 3 פעמים. באיטרציה i=0 הוא יוצר בן (C1), והבן יוצר נכד (C1_1) כי 0 זוגי. באיטרציה i=1 הוא יוצר בן (C2), והוא לא יוצר נכד כי 1 אינו זוגי. באיטרציה i=2 הוא יוצר בן (C3), והוא יוצר נכד (C3_1) כי 2 זוגי. סה\"כ: 1 (אב) + 3 (בנים) + 2 (נכדים) = 6.\n\n7.2: אם נחליף ב-break, תהליכי הבנים והנכדים לא יסיימו את ריצתם מיד אלא יצאו מהלולאה וימשיכו לשורת ה-wait. במקרה זה, מספר התהליכים שייווצרו לא ישתנה (עדיין 6), מכיוון שכל תהליך שנוצר יוצא מהלולאה ולא ממשיך לאיטרציות הבאות של האב.\n\n7.3: הפונקציה exit() היא פונקציית ספרייה המבצעת ניקוי (cleanup) הכולל ריקון חוצצים (buffers) של stdio לפני סיום התהליך, בעוד _exit() היא קריאת מערכת שמסיימת את התהליך מיד ללא ניקוי חוצצים. בבנים משתמשים לעיתים ב-_exit כדי למנוע מצב שבו חוצצים שהועתקו מהאב ירוקנו פעמיים (גם ע\"י הבן וגם ע\"י האב), מה שעלול להוביל לכפילות בפלט.\n\n7.4: ללא ה-wait, תהליכי הבן יהפכו לתהליכי 'זומבי' (Zombie Processes). זהו מצב שבו התהליך סיים את ביצועו אך עדיין קיימת רשומה עבורו בטבלת התהליכים של מערכת ההפעלה, כדי לאפשר לאב לקרוא את קוד היציאה שלו."}, "difficulty_estimation": "Medium", "_source_file": "0037__Processes__Open__Medium.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:17:57", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Processes", "System Calls", "Memory Management"], "content": {"text": "נתון קוד בשפת C המשתמש בקריאות המערכת fork ו-wait. הנח שכל קריאות המערכת מצליחות ומתבצעות ללא שגיאות. ענו על הסעיפים הבאים בהסתמך על הקוד.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 10;\n    if (fork() == 0) {\n        x += 5;\n        if (fork() == 0) {\n            x += 5;\n            printf(\"%d\\n\", x);\n        } else {\n            wait(NULL);\n            x -= 2;\n            printf(\"%d\\n\", x);\n        }\n    } else {\n        wait(NULL);\n        printf(\"%d\\n\", x);\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "כמה תהליכים נוצרו בסך הכל במהלך הרצת התוכנית (כולל תהליך האב המקורי)?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "מה יהיה הפלט של התוכנית? יש לציין את הערכים המודפסים לפי סדר הדפסתם ולהסביר את החישוב עבור כל אחד.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "האם המשתנה x משותף בין התהליכים השונים? הסבירו כיצד מנגנון ה-Copy-on-Write (CoW) בא לידי ביטוי במקרה זה.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: נוצרו 3 תהליכים בסך הכל. תהליך האב המקורי (P1), תהליך הבן הראשון (P2) שנוצר ב-fork הראשון, ותהליך הנכד (P3) שנוצר ב-fork השני בתוך הבלוק של הבן.\n\n1.2: הפלט יהיה:\n20\n13\n10\nהסבר: \n- P3 (הנכד): יורש x=15 מ-P2, מוסיף 5 ומדפיס 20.\n- P2 (הבן): מחכה ל-P3 שיסיים, לאחר מכן מחסיר 2 מה-x שלו (שהיה 15) ומדפיס 13.\n- P1 (האב): מחכה ל-P2 שיסיים, מדפיס את ה-x שלו שנשאר 10 ללא שינוי.\nהסדר מובטח עקב קריאות ה-wait.\n\n1.3: לא, המשתנה אינו משותף. כל תהליך מקבל מרחב כתובות וירטואלי נפרד. מנגנון Copy-on-Write גורם לכך שכל עוד התהליכים רק קוראים מהזיכרון, הם חולקים את אותם דפים פיזיים. ברגע שתהליך מבצע כתיבה (כמו x += 5), מערכת ההפעלה יוצרת עותק פיזי נפרד של הדף עבור אותו תהליך, כך שהשינוי אינו משפיע על תהליך האב או תהליכים מקבילים אחרים."}, "difficulty_estimation": "Medium", "_source_file": "0038__Processes__Open__Medium.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:18:11", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Processes", "Fork", "Address Space"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בקריאת המערכת fork(). הניחו כי כל הקריאות למערכת מצליחות וכי הפלט נכתב למסך באופן מיידי (ללא buffering).", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 10;\n    pid_t pid1 = fork();\n\n    if (pid1 == 0) {\n        x += 5;\n        pid_t pid2 = fork();\n        if (pid2 == 0) {\n            x *= 2;\n            printf(\"A: x=%d\\n\", x);\n        } else {\n            wait(NULL);\n            x -= 2;\n            printf(\"B: x=%d\\n\", x);\n        }\n    } else {\n        wait(NULL);\n        x += 1;\n        printf(\"C: x=%d\\n\", x);\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "כמה תהליכים נוצרו בסך הכל במהלך ריצת התוכנית (כולל התהליך הראשי)? ציירו את עץ התהליכים.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "מה יהיה הפלט של התוכנית? האם סדר ההדפסות מובטח? הסבירו.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "האם שינוי המשתנה x בתהליך אחד משפיע על ערכו בתהליך אחר? הסבירו מדוע על סמך מנגנון הזיכרון של תהליכים.", "code_snippet": null, "options": null}, {"id": "1.4", "text": "מה יקרה אם נסיר את כל קריאות ה-wait(NULL) מהקוד? האם ערכי ה-x המודפסים ישתנו? האם סדר ההדפסה ישתנה?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: נוצרו 3 תהליכים בסך הכל. התהליך הראשי (P1) יוצר בן (P2), והבן (P2) יוצר נכד (P3). עץ התהליכים הוא ליניארי: P1 -> P2 -> P3.\n\n1.2: הפלט יהיה:\nA: x=30\nB: x=13\nC: x=11\nסדר ההדפסות מובטח בגלל קריאות ה-wait. תהליך P2 מחכה ל-P3 (לכן A לפני B), ותהליך P1 מחכה ל-P2 (לכן B לפני C).\n\n1.3: לא. בעת ביצוע fork, התהליך הבן מקבל העתק של מרחב הכתובות של האב (Copy-on-Write). לכן, לכל תהליך יש עותק פרטי משלו של המשתנה x בזיכרון שלו, ושינויים בו אינם משפיעים על תהליכים אחרים.\n\n1.4: ערכי ה-x המודפסים לא ישתנו, כי המרחבים עדיין מופרדים. עם זאת, סדר ההדפסה לא יהיה מובטח יותר ויהיה תלוי במתזמן (Scheduler), שכן התהליכים ירוצו במקביל ללא סנכרון."}, "difficulty_estimation": "Medium", "_source_file": "0039__Processes__Open__Medium.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:18:27", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Processes", "Fork", "Address Space"], "content": {"text": "נתונה תוכנית בשפת C המשתמשת בקריאת המערכת fork. הניחו כי כל הקריאות למערכת מצליחות וכי התהליכים מסתיימים כסדרם (אין תהליכי זומבי או יתומים במהלך הריצה שימנעו את ההדפסות).", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 10;\n    pid_t p1 = fork();\n    if (p1 == 0) {\n        x += 5;\n        pid_t p2 = fork();\n        if (p2 == 0) {\n            x += 5;\n            printf(\"Child-Child: x = %d\\n\", x);\n        } else {\n            wait(NULL);\n            printf(\"Child: x = %d\\n\", x);\n        }\n    } else {\n        wait(NULL);\n        x -= 5;\n        printf(\"Parent: x = %d\\n\", x);\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "מה יהיה פלט התוכנית? יש להסביר את סדר ההדפסות ואת הערך של x בכל הדפסה.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "כמה תהליכים נוצרו בסך הכל במהלך ריצת התוכנית (כולל התהליך הראשי)?", "code_snippet": null, "options": null}, {"id": "1.3", "text": "האם שינוי הערך של x בתהליך הבן משפיע על ערכו של x בתהליך האב? הסבר מדוע בהתבסס על ניהול הזיכרון של תהליכים.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: פלט התוכנית יהיה:\nChild-Child: x = 20\nChild: x = 15\nParent: x = 5\nהסבר: התהליך הראשי (P1) מפצל את P2. ב-P2 המשתנה x הופך ל-15. P2 מפצל את P3. ב-P3 המשתנה x הופך ל-20 ומודפס. בגלל פקודות ה-wait, P3 מסיים ומדפיס ראשון, אחריו P2 מדפיס (x=15) ואז P1 מבצע x-=5 (מתוך ה-10 המקורי שלו) ומדפיס (x=5).\n\n1.2: נוצרו 3 תהליכים בסך הכל: התהליך המקורי (P1), הבן שלו (P2), והנכד (P3 - הבן של P2).\n\n1.3: לא, השינוי אינו משפיע. בעת ביצוע fork(), מערכת ההפעלה יוצרת עותק של מרחב הכתובות (Address Space) של תהליך האב עבור תהליך הבן. למרות שהם משתמשים באותן כתובות וירטואליות, הן ממופות למסגרות פיזיות שונות בזיכרון (או משתמשות במנגנון Copy-on-Write שיוצר עותק פיזי רק בעת כתיבה). לכן, לכל תהליך יש עותק פרטי משלו של המשתנה x."}, "difficulty_estimation": "Medium", "_source_file": "0040__Processes__Open__Medium.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:18:46", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Processes", "Fork", "Short-circuit evaluation", "Process Tree", "Synchronization"], "content": {"text": "נתון קוד ה-C הבא המשתמש בקריאות מערכת לניהול תהליכים. הניחו שכל הקריאות ל-fork מצליחות, שהמערכת אינה מוגבלת במשאבים, ושאין אופטימיזציות קומפילציה המשנות את לוגיקת הקריאות. ענו על הסעיפים הבאים תוך פירוט מלא של עץ התהליכים והלוגיקה.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <sys/types.h>\n\nint main() {\n    pid_t pid;\n    if (fork() == 0) {\n        // Child block\n        if (fork() || fork()) {\n            fork();\n        }\n    } else {\n        // Parent block\n        wait(NULL);\n        printf(\"Parent Done\\n\");\n    }\n    printf(\"Process %d exiting\\n\", getpid());\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "כמה תהליכים נוצרים בסך הכל במהלך הרצת התוכנית (כולל התהליך המקורי)? פרטו את שלבי היצירה.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "כמה פעמים תודפס המחרוזת 'Process %d exiting' (כאשר %d הוא ה-PID) וכמה פעמים תודפס המחרוזת 'Parent Done'?", "code_snippet": null, "options": null}, {"id": "10.3", "text": "האם מובטח שההדפסה 'Parent Done' תהיה האחרונה שתופיע על המסך? נמקו את תשובתכם על בסיס מנגנון ה-wait.", "code_snippet": null, "options": null}], "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: ניתוח עץ התהליכים:\n- התהליך המקורי (P0) מבצע fork ראשון. נוצר P1 (הבן של P0).\n- P0 נכנס לבלוק ה-else ומבצע wait.\n- P1 נכנס לבלוק ה-if הראשון ומבצע fork (השני בתוכנית). נוצר P2 (הבן של P1).\n- בתוך ה-if הפנימי (fork() || fork()):\n  א. עבור P1: ה-fork מחזיר ערך חיובי (ה-PID של P2), ולכן בשל short-circuit evaluation של אופרטור ה-OR (||), ה-fork השני בביטוי לא מתבצע. P1 נכנס לתוך ה-if ומבצע fork נוסף (יצירת P4).\n  ב. עבור P2: ה-fork מחזיר 0, ולכן הוא חייב לבצע את החלק השני של ה-OR. הוא מבצע fork (השלישי בתוכנית) ויוצר את P3. עבור P2, תוצאת ה-OR היא אמת (0 || PID_P3), ולכן הוא נכנס לתוך ה-if ומבצע fork נוסף (יצירת P5).\n  ג. עבור P3: הוא נוצר מה-fork השני בביטוי ה-OR. הוא מקבל 0. תוצאת ה-OR עבורו היא (0 || 0) כלומר שקר, ולכן הוא לא נכנס לתוך ה-if.\nסך התהליכים: P0, P1, P2, P3, P4, P5 - סה\"כ 6 תהליכים.\n\n10.2: \n- המחרוזת 'Process %d exiting' מודפסת על ידי כל תהליך שמסיים את הריצה שלו מחוץ למבנה ה-if/else. מכיוון שיש 6 תהליכים וכולם מגיעים לשורה זו, היא תודפס 6 פעמים.\n- המחרוזת 'Parent Done' מודפסת רק בבלוק ה-else של ה-fork הראשון. רק תהליך P0 (האב המקורי) נכנס לבלוק זה, ולכן היא תודפס פעם אחת בלבד.\n\n10.3: \nלא, זה לא מובטח. הקריאה wait(NULL) ב-P0 גורמת לו להמתין לסיום של *אחד* מילדיו הישירים. ל-P0 יש רק ילד ישיר אחד והוא P1. ברגע ש-P1 מסיים (exit), P0 משתחרר מה-wait וממשיך להדפסה. עם זאת, P1 עצמו לא קורא ל-wait עבור הילדים שלו (P2, P4). לכן, ייתכן ש-P1 יסיים את ריצתו והדפסתו בזמן שילדיו (ונכדיו P3, P5) עדיין רצים. במצב כזה, P0 ידפיס 'Parent Done' ו-'Process P0 exiting' בזמן שתהליכים אחרים עדיין פעילים ברקע (תהליכים אלו יהפכו ליתומים - orphans)."}, "difficulty_estimation": "Hard", "_source_file": "0041__Processes__Open__Hard.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:19:18", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Processes", "Fork", "Process Tree"], "content": {"text": "נתון הקוד הבא בשפת C. הניחו כי כל קריאות המערכת מצליחות, וכי הפלט מודפס לטרמינל ללא השהיות (buffering) משמעותיות שמשנות את סדר הלוגיקה (פרט לסדר הסטנדרטי של תזמון תהליכים).", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    int i;\n    for (i = 0; i < 3; i++) {\n        if (fork() == 0) {\n            if (i % 2 == 0) {\n                fork();\n                printf(\"A\\n\");\n            } else {\n                printf(\"B\\n\");\n                exit(0);\n            }\n        }\n    }\n    while(wait(NULL) > 0);\n    printf(\"C\\n\");\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "כמה פעמים יודפס התו 'A' במהלך ריצת התוכנית? פרטו את החישוב.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "כמה פעמים יודפס התו 'B' במהלך ריצת התוכנית? פרטו את החישוב.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "כמה פעמים יודפס התו 'C' במהלך ריצת התוכנית? פרטו את החישוב.", "code_snippet": null, "options": null}, {"id": "10.4", "text": "מהו מספר התהליכים הכולל שנוצרו במערכת (כולל תהליך האב המקורי)?", "code_snippet": null, "options": null}], "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ננתח את הלולאה לפי איטרציות:\n1. איטרציה i=0:\n- תהליך האב (P) יוצר בן (C1).\n- C1 נכנס לתנאי (i%2 == 0), מבצע fork נוסף ויוצר את C1a.\n- גם C1 וגם C1a מדפיסים 'A' וממשיכים לאיטרציה הבאה (i=1).\n- סה\"כ הדפסות 'A': 2.\n- תהליכים פעילים שממשיכים ל-i=1: P, C1, C1a.\n\n2. איטרציה i=1:\n- כל אחד מהתהליכים הפעילים (P, C1, C1a) מבצע fork.\n- נוצרים 3 בנים חדשים. עבורם i=1, לכן i%2 != 0.\n- כל אחד מ-3 הבנים הללו מדפיס 'B' ומבצע exit(0).\n- סה\"כ הדפסות 'B': 3.\n- תהליכים פעילים שממשיכים ל-i=2: P, C1, C1a.\n\n3. איטרציה i=2:\n- כל אחד מהתהליכים הפעילים (P, C1, C1a) מבצע fork.\n- נוצרים 3 בנים חדשים (C2, C3, C4). עבורם i=2, לכן i%2 == 0.\n- כל אחד מהם (C2, C3, C4) מבצע fork נוסף (יוצרים את C2a, C3a, C4a).\n- כל ה-6 הללו (הבנים והנכדים של איטרציה זו) מדפיסים 'A'.\n- סה\"כ הדפסות 'A' באיטרציה זו: 6.\n- תהליכים פעילים שמסיימים את הלולאה: P, C1, C1a, C2, C2a, C3, C3a, C4, C4a (סה\"כ 9 תהליכים).\n\n4. סיום (הדפסת 'C'):\n- כל תהליך שמסיים את הלולאה ומגיע לשורת ה-wait מדפיס 'C' פעם אחת לאחר שכל בניו הסתיימו.\n- ישנם 9 תהליכים כאלו.\n\nסיכום:\n- כמות 'A': 2 (מאיטרציה 0) + 6 (מאיטרציה 2) = 8.\n- כמות 'B': 3 (מאיטרציה 1).\n- כמות 'C': 9.\n- סה\"כ תהליכים: תהליך מקורי (1) + בנים מאיטרציה 0 (2) + בנים מאיטרציה 1 (3) + בנים מאיטרציה 2 (6) = 12."}, "difficulty_estimation": "Hard", "_source_file": "0042__Processes__Open__Hard.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:19:41", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Processes", "Fork", "Wait", "Process Tree"], "content": {"text": "נתון הקוד הבא בשפת C. הנח שכל הקריאות למערכת מצליחות, שההדפסות מתבצעות ללא buffering (כלומר יוצאות מיד למסך), ושאין השהיות חיצוניות. ענה על הסעיפים הבאים:\n1. כמה פעמים תודפס האות 'A' וכמה פעמים תודפס האות 'B' על המסך?\n2. תאר את עץ התהליכים שנוצר. עבור כל תהליך, ציין אילו אותיות הוא מדפיס ובאיזה שלב.\n3. האם ייתכן מצב שבו האות 'B' מודפסת לפני כל מופע כלשהו של האות 'A'? נמק את תשובתך על סמך מנגנון הסנכרון בקוד.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int i, status;\n    pid_t pid;\n    for (i = 0; i < 2; i++) {\n        pid = fork();\n        if (pid == 0) {\n            // Child process\n            if (i == 0) {\n                fork();\n            }\n            printf(\"A\");\n        } else {\n            // Parent process\n            waitpid(pid, &status, 0);\n            printf(\"B\");\n        }\n    }\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ניתוח הריצה:\n1. איטרציה i=0:\n- תהליך האב המקורי (P1) מבצע fork ויוצר את P2. \n- P1 נכנס ל-else ומחכה ל-P2 (באמצעות waitpid).\n- P2 (הבן) נכנס ל-if (pid == 0). כיוון ש-i=0, הוא מבצע fork נוסף ויוצר את P3.\n- P2 מדפיס 'A'.\n- P3 (הנכד) נוצר בתוך הבלוק של i=0 ומדפיס 'A'.\n\n2. איטרציה i=1:\n- P2 ו-P3 ממשיכים לאיטרציה הבאה. \n- P2 מבצע fork ויוצר את P4. P2 מחכה ל-P4 ומדפיס 'B'.\n- P4 (הנין) מדפיס 'A' (הוא לא עושה fork כי i=1) ומסיים.\n- P3 מבצע fork ויוצר את P5. P3 מחכה ל-P5 ומדפיס 'B'.\n- P5 (הנין) מדפיס 'A' ומסיים.\n- לאחר ש-P2 מסיים את i=1 ויוצא, P1 (שחיכה לו) מדפיס 'B' וממשיך ל-i=1.\n- P1 (ב-i=1) מבצע fork ויוצר את P6. P1 מחכה ל-P6 ומדפיס 'B'.\n- P6 מדפיס 'A' ומסיים.\n\nסיכום הדפסות:\n- האות 'A' מודפסת ע\"י: P2(i=0), P3(i=0), P4(i=1), P5(i=1), P6(i=1). סה\"כ 5 פעמים.\n- האות 'B' מודפסת ע\"י: P2(i=1), P3(i=1), P1(i=0), P1(i=1). סה\"כ 4 פעמים.\n\nתשובה לסעיף 3:\nלא, לא ייתכן ש-'B' תודפס לפני כל 'A'. בקוד קיים שימוש ב-waitpid המאלץ את האב לחכות לסיום הילד שלו לפני הדפסת 'B'. לדוגמה, P2 ו-P3 מדפיסים 'A' מיד בתחילת הריצה (i=0) עוד לפני שהם יכולים להגיע לשלב ההדפסה של 'B' או לפני ש-P1 יכול להשתחרר מה-wait שלו. כיוון ש-P2 חייב להדפיס 'A' ב-i=0 לפני שהוא בכלל מגיע ל-i=1 או מסיים, ו-P1 מחכה ל-P2, ה-'A' של P2 תמיד תופיע לפני ה-'B' של P1."}, "difficulty_estimation": "Hard", "_source_file": "0043__Processes__Open__Hard.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:20:21", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Processes", "Fork", "Wait", "Process Hierarchy"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בקריאות המערכת fork ו-wait. עליכם לנתח את פעולת התוכנית ולענות על הסעיפים הבאים. הניחו כי כל הקריאות ל-fork מצליחות וכי אין בעיות זיכרון או משאבים. יש לפרט ולנמק את כל שלבי החישוב.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int val = 5;\n    for (int i = 0; i < 2; i++) {\n        if (fork() == 0) {\n            val += 2;\n            if (fork() > 0) {\n                val *= 2;\n                wait(NULL);\n            }\n        } else {\n            wait(NULL);\n            val -= 1;\n        }\n    }\n    printf(\"%d\\n\", val);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "כמה תהליכים סה\"כ (כולל תהליך האב המקורי) ייווצרו במהלך הרצת התוכנית? הציגו את עץ התהליכים (ניתן להשתמש בשמות כמו P0, P1 וכו' כדי לסמן את התהליכים).", "code_snippet": null, "options": null}, {"id": "10.2", "text": "מהם הערכים שיודפסו למסך? יש לציין איזה ערך הודפס על ידי כל תהליך שזיהיתם בסעיף הקודם (לדוגמה: 'תהליך P0 הדפיס X').", "code_snippet": null, "options": null}], "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ניתוח עץ התהליכים:\n1. התחלה: תהליך P0 עם val=5.\n2. איטרציה i=0:\n   - P0 מבצע fork ויוצר את P1. P0 נכנס ל-else, מחכה ל-P1 ומבצע val -= 1 (val=4).\n   - P1 (בן) מבצע val += 2 (val=7). אז P1 מבצע fork נוסף ויוצר את P2. \n   - ב-P1 (אב של P2), התנאי fork()>0 מתקיים: val *= 2 (val=14), מחכה ל-P2.\n   - ב-P2 (בן של P1), התנאי fork()>0 לא מתקיים. P2 ממשיך עם val=7.\nכעת יש 3 תהליכים (P0, P1, P2) שממשיכים לאיטרציה i=1.\n\n3. איטרציה i=1:\n   - כל אחד מ-3 התהליכים משכפל את המבנה של האיטרציה הקודמת:\n   - P0 (val=4) יוצר את P3. P3 יוצר את P4. P0 מחכה ל-P3 ומבצע val -= 1 (val=3).\n   - P3 (בן של P0) מבצע val=4+2=6, יוצר את P4, הופך ל-val=12 ומחכה ל-P4. P4 נשאר val=6.\n   - P1 (val=14) יוצר את P5. P5 יוצר את P6. P1 מחכה ל-P5 ומבצע val -= 1 (val=13).\n   - P5 (בן של P1) מבצע val=14+2=16, יוצר את P6, הופך ל-val=32 ומחכה ל-P6. P6 נשאר val=16.\n   - P2 (val=7) יוצר את P7. P7 יוצר את P8. P2 מחכה ל-P7 ומבצע val -= 1 (val=6).\n   - P7 (בן של P2) מבצע val=7+2=9, יוצר את P8, הופך ל-val=18 ומחכה ל-P8. P8 נשאר val=9.\n\nסיכום:\n10.1: סה\"כ נוצרו 9 תהליכים.\n10.2: הערכים המודפסים הם:\n- P0 מדפיס 3\n- P1 מדפיס 13\n- P2 מדפיס 6\n- P3 מדפיס 12\n- P4 מדפיס 6\n- P5 מדפיס 32\n- P6 מדפיס 16\n- P7 מדפיס 18\n- P8 מדפיס 9"}, "difficulty_estimation": "Hard", "_source_file": "0044__Processes__Open__Hard.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:21:00", "_subject": "Virtualization"}, {"id": 101, "type": "Open", "topic": ["Processes", "Pipes", "Fork", "IPC"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בקריאות מערכת לניהול תהליכים ותקשורת ביניהם. הניחו כי כל קריאות המערכת (fork, pipe, write, read, wait) מצליחות ומתבצעות ללא שגיאות. ענו על הסעיפים הבאים תוך פירוט הנימוקים.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int fd[2];\n    pipe(fd);\n    pid_t p1 = fork();\n\n    if (p1 == 0) {\n        // Child 1 (C1)\n        close(fd[0]);\n        pid_t g1 = fork();\n        if (g1 == 0) {\n            // Grandchild (G)\n            int val = 15;\n            write(fd[1], &val, sizeof(val));\n            printf(\"G\");\n            return 0;\n        }\n        wait(NULL);\n        int val = 25;\n        write(fd[1], &val, sizeof(val));\n        printf(\"C1\");\n        close(fd[1]);\n        return 0;\n    } else {\n        // Parent (P)\n        pid_t p2 = fork();\n        if (p2 == 0) {\n            // Child 2 (C2)\n            close(fd[1]);\n            int res, sum = 0;\n            while(read(fd[0], &res, sizeof(res)) > 0) {\n                sum += res;\n            }\n            printf(\"%d\", sum);\n            close(fd[0]);\n            return 0;\n        }\n        close(fd[0]);\n        close(fd[1]);\n        wait(NULL);\n        wait(NULL);\n        printf(\"P\");\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "101.1", "text": "מה יהיה הפלט המדויק של התוכנית? הסבירו את סדר ההדפסה ואת החישוב שהוביל לתוצאה.", "code_snippet": null, "options": null}, {"id": "101.2", "text": "כמה תהליכים נוצרו בסך הכל במהלך הרצת התוכנית (כולל תהליך האב המקורי)?", "code_snippet": null, "options": null}, {"id": "101.3", "text": "מה יקרה לפלט התוכנית אם נסיר את השורה (close(fd[1] בתהליך האב (השורה שנמצאת תחת הבלוק של ה-Parent)? נמקו.", "code_snippet": null, "options": null}], "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "101.1: הפלט יהיה GC140P. הסבר: תהליך C1 יוצר את G. תהליך G כותב 15 לצינור, מדפיס G ומסתיים. C1 ממתין ל-G (באמצעות wait), ואז כותב 25 לצינור, מדפיס C1 ומסתיים. תהליך C2 קורא מהצינור בלולאה. הוא יקרא את 15 ואז את 25. הלולאה תסתיים רק כאשר כל קצוות הכתיבה של הצינור ייסגרו. קצוות הכתיבה נמצאים אצל G (נסגר בסיום), C1 (נסגר במפורש ובסיום), והאב P. כיוון ש-P סוגר את fd[1] מיד לאחר ה-fork השני, ברגע ש-C1 מסתיים, אין יותר כותבים פתוחים ו-read יחזיר 0. לכן C2 ידפיס את הסכום 40. האב P ממתין לשני ילדיו ומדפיס P בסוף.\n\n101.2: נוצרו 4 תהליכים: האב המקורי (P), הבן הראשון (C1), הנכד (G), והבן השני (C2).\n\n101.3: אם האב לא יסגור את fd[1], התוכנית תיתקע (Deadlock/Hang). תהליך C2 יישאר חסום בקריאת ה-read בתוך הלולאה, כיוון שקיים עדיין קצה כתיבה פתוח (אצל האב P), ולכן מערכת ההפעלה לא תשלח סיגנל EOF (ערך חזרה 0 מ-read). כתוצאה מכך C2 לא ידפיס את הסכום ולא יסתיים, והאב P ימתין לו לנצח ב-wait."}, "difficulty_estimation": "Hard", "_source_file": "0045__Processes__Open__Hard.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:21:22", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Processes", "System Calls", "Memory Isolation"], "content": {"text": "לפניכם קוד בשפת C המשתמש בקריאות המערכת fork ו-waitpid. עליכם לנתח את פעולת הקוד ולענות על הסעיפים הבאים. הניחו שכל קריאות המערכת מצליחות ושאין השהיות חיצוניות מלבד אלו המשתמעות מהקוד. יש לפרט ולנמק את שלבי החישוב.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    int x = 10;\n    for (int i = 0; i < 2; i++) {\n        pid_t pid = fork();\n        if (pid == 0) {\n            x -= 2;\n            if (fork() == 0) {\n                x += 5;\n                printf(\"A: %d\\n\", x);\n                exit(0);\n            }\n            x++;\n            printf(\"B: %d\\n\", x);\n            exit(0);\n        } else {\n            waitpid(pid, NULL, 0);\n            x /= 2;\n        }\n    }\n    printf(\"C: %d\\n\", x);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "כמה תהליכים נוצרו בסך הכל במהלך הרצת התוכנית (כולל תהליך האב המקורי)?", "code_snippet": null, "options": null}, {"id": "10.2", "text": "מהו הפלט של התוכנית? במידה וסדר ההדפסה אינו דטרמיניסטי, ציינו אילו שורות יכולות להתחלף ביניהן והסבירו מדוע.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "כיצד היה משתנה ערכו של x המודפס בשורה המתחילה באות C, לו היינו מחליפים את השורה x /= 2; בשורה x = x - i;?", "code_snippet": null, "options": null}], "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ניתוח הקוד:\n1. סעיף 10.1: האב מבצע לולאה בת 2 איטרציות. בכל איטרציה הוא קורא ל-fork (יצירת ילד) ומחכה לו שיסתיים. כל ילד בתורו קורא ל-fork נוסף (יצירת נכד). \nאיטרציה i=0: אב -> ילד 1 -> נכד 1 (סה\"כ 3 תהליכים עד כה).\nאיטרציה i=1: אב -> ילד 2 -> נכד 2 (עוד 2 תהליכים).\nסה\"כ נוצרו 5 תהליכים.\n\n2. סעיף 10.2: \n- איטרציה i=0: האב מתחיל עם x=10. הילד יורש x=10, מחסיר 2 (x=8). הנכד יורש מהילד x=8, מוסיף 5 ומדפיס A: 13. הילד מוסיף 1 ומדפיס B: 9. האב מחכה לילד ומבצע x=10/2=5.\n- איטרציה i=1: האב כעת עם x=5. הילד השני יורש x=5, מחסיר 2 (x=3). הנכד השני יורש x=3, מוסיף 5 ומדפיס A: 8. הילד השני מוסיף 1 ומדפיס B: 4. האב מחכה לילד ומבצע x=5/2=2 (חלוקת שלמים).\n- סיום: האב מדפיס C: 2.\nסדר ההדפסה: בתוך כל איטרציה, הסדר בין A ל-B אינו דטרמיניסטי כי הילד והנכד רצים במקביל ואין wait ביניהם. אך כל איטרציה חייבת להסתיים לפני שהבאה מתחילה בגלל ה-waitpid של האב. לכן A:13 ו-B:9 יופיעו לפני A:8 ו-B:4.\n\n3. סעיף 10.3: \n- ב-i=0: האב יבצע x = 10 - 0 = 10.\n- ב-i=1: האב יבצע x = 10 - 1 = 9.\nלכן הפלט בשורה C יהיה 9."}, "difficulty_estimation": "Hard", "_source_file": "0046__Processes__Open__Hard.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:21:51", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Processes", "Fork", "Wait", "Orphan Processes"], "content": {"text": "נתון קטע הקוד הבא בשפת C. הנח שכל קריאות המערכת מצליחות, שהתהליכים רצים על מעבד יחיד, ושהפלט של הפונקציה printf נכתב ל-stdout בצורה אטומית (כלומר, לא ייתכן ערבוב תווים בתוך מחרוזת אחת מהדפסות שונות). ענה על הסעיפים הבאים:", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    for (int i = 0; i < 2; i++) {\n        pid_t pid = fork();\n        if (pid == 0) {\n            printf(\"C%d \", i);\n            if (i == 0) {\n                if (fork() == 0) {\n                    printf(\"G \");\n                    return 0;\n                }\n                printf(\"G \");\n            }\n            return 0;\n        } else {\n            printf(\"P%d \", i);\n            wait(NULL);\n        }\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "כמה תהליכים נוצרו סך הכל במהלך ריצת התוכנית (כולל התהליך המקורי)? פרטו אילו תהליכים נוצרו ובאיזה שלב.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "שרטטו את עץ התהליכים (Process Tree) שנוצר במהלך הריצה.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "האם ייתכן שיתקבל הפלט הבא: 'P0 C0 G P1 C1 G '? נמקו את תשובתכם תוך התייחסות למנגנון ה-wait ולתהליכים יתומים (orphans).", "code_snippet": null, "options": null}], "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. נוצרו סה\"כ 4 תהליכים: התהליך המקורי (P), הבן הראשון (C0) שנוצר ב-i=0, הבן השני (C1) שנוצר ב-i=1, והנכד (G) שנוצר על ידי C0.\n2. עץ התהליכים: P הוא השורש. ל-P יש שני בנים ישירים: C0 ו-C1. ל-C0 יש בן אחד: G. חשוב לציין ש-C1 נוצר רק לאחר ש-C0 הסתיים, כיוון ש-P מבצע wait(NULL) בכל איטרציה ומחכה לסיום הבן הנוכחי לפני המעבר לאיטרציה הבאה.\n3. כן, הפלט ייתכן. הסבר: באיטרציה i=0, האב P יוצר את C0 ומחכה לו. C0 מדפיס 'C0', יוצר את G, ומדפיס 'G'. ברגע ש-C0 מסיים (return 0), האב P משתחרר מה-wait וממשיך לאיטרציה i=1. ב-i=1, האב מדפיס 'P1' ויוצר את C1 שמדפיס 'C1'. התהליך G הוא נכד של P ובן של C0. מכיוון ש-C0 לא ביצע wait(NULL) עבור G, התהליך G הופך ליתום (Orphan) וממשיך לרוץ במקביל לאב P. לכן, ה-'G' השני (שהודפס על ידי הנכד) יכול להופיע בכל שלב לאחר ה-fork בתוך C0, ובפרט בסוף הפלט לאחר ש-P ו-C1 כבר סיימו את פעולתם."}, "difficulty_estimation": "Hard", "_source_file": "0047__Processes__Open__Hard.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:22:29", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Processes", "Signals", "Fork"], "content": {"text": "לפניכם קוד בשפת C המשתמש בקריאות מערכת לניהול תהליכים וסיגנלים. הניחו שכל הקריאות למערכת מצליחות, שאין עומס חריג על המערכת, וכי פקודת sleep אכן גורמת לתהליך להמתין כנדרש. שימו לב כי סיגנלים עשויים לקטוע קריאות מערכת חוסמות (כמו sleep).", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <signal.h>\n\nint g_var = 1;\n\nvoid signal_handler(int sig) {\n    if (sig == SIGUSR1) g_var += 3;\n    else if (sig == SIGCHLD) g_var *= 2;\n}\n\nint main() {\n    signal(SIGUSR1, signal_handler);\n    signal(SIGCHLD, signal_handler);\n\n    pid_t p = fork();\n    if (p == 0) { // Child process\n        g_var += 5;\n        if (fork() == 0) { // Grandchild process\n            g_var += 10;\n            kill(getppid(), SIGUSR1);\n            exit(0);\n        }\n        wait(NULL);\n        printf(\"C: %d\\n\", g_var);\n        exit(0);\n    }\n\n    sleep(5);\n    printf(\"P: %d\\n\", g_var);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "מה יהיה הפלט של התוכנית? יש לכתוב את השורות בסדר הופעתן.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "הסבירו בפירוט את השתלשלות האירועים: מדוע כל ערך הודפס כפי שהודפס? התייחסו למרחבי הכתובות, לטיפול בסיגנלים ולסנכרון בין התהליכים.", "code_snippet": null, "options": null}], "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסבר השלבים:\n1. תהליך האב מתחיל עם g_var = 1 ורושם מטפלים לסיגנלים SIGUSR1 ו-SIGCHLD.\n2. האב מבצע fork. נוצר בן (C) עם עותק נפרד של g_var = 1.\n3. הבן מעדכן את g_var שלו ל-6 (1+5).\n4. הבן מבצע fork. נוצר נכד (GC) עם עותק נפרד של g_var = 6.\n5. הנכד מעדכן את g_var שלו ל-16 (6+10) ושולח סיגנל SIGUSR1 לאביו (הבן) באמצעות kill(getppid(), ...).\n6. הבן מקבל את הסיגנל SIGUSR1. המטפל שלו רץ ומעדכן את g_var של הבן ל-9 (6+3).\n7. הנכד מסיים (exit). סיום הנכד שולח סיגנל SIGCHLD לאביו (הבן).\n8. הבן מקבל SIGCHLD. המטפל שלו רץ ומכפיל את g_var שלו: 9 * 2 = 18.\n9. הבן משלים את ה-wait, מדפיס 'C: 18' ומסיים.\n10. סיום הבן שולח סיגנל SIGCHLD לאב.\n11. האב, שהיה ב-sleep, מתעורר עקב קבלת הסיגנל. המטפל של האב רץ ומכפיל את g_var שלו: 1 * 2 = 2.\n12. האב ממשיך להדפסה ומדפיס 'P: 2'.\n\nהפלט הצפוי:\nC: 18\nP: 2"}, "difficulty_estimation": "Hard", "_source_file": "0048__Processes__Open__Hard.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:23:25", "_subject": "Virtualization"}, {"id": 5, "type": "CodeAnalysis", "topic": ["Processes", "System Calls"], "content": {"text": "נתונה התוכנית הבאה. כמה פעמים תודפס המחרוזת \"Hello\"?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n\nint main() {\n    if (fork() == 0) {\n        fork();\n        printf(\"Hello\\n\");\n    }\n    return 0;\n}", "options": ["א. 1", "ב. 2", "ג. 3", "ד. 4"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "התהליך הראשי (האב) מבצע fork() ראשון. תהליך האב מקבל מהקריאה את ה-PID של הבן (ערך חיובי), ולכן התנאי fork() == 0 אינו מתקיים עבורו והוא מדלג על הבלוק. תהליך הבן מקבל מהקריאה את הערך 0, ולכן הוא נכנס לתוך בלוק ה-if. בתוך הבלוק, תהליך הבן מבצע fork() נוסף, מה שיוצר תהליך חדש (נכד). בשלב זה, גם הבן וגם הנכד נמצאים בתוך הבלוק וממשיכים לביצוע פקודת ה-printf. לכן, המחרוזת תודפס פעמיים (פעם אחת על ידי הבן ופעם אחת על ידי הנכד)."}, "difficulty_estimation": "Easy", "_source_file": "0049__Processes__CodeAnalysis__Easy.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:23:43", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Processes", "System Calls"], "content": {"text": "נתונה התוכנית הבאה. כמה פעמים תודפס המחרוזת \"Hello\" למסך? הניחו שכל קריאות המערכת מצליחות.", "code_snippet": "int main() {\n    for (int i = 0; i < 2; i++) {\n        fork();\n    }\n    printf(\"Hello\\n\");\n    return 0;\n}", "options": ["א. 2", "ב. 3", "ג. 4", "ד. 6", "ה. 8"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "בכל איטרציה של הלולאה, כל תהליך קיים מבצע fork() ובכך מכפיל את מספר התהליכים. בתחילה יש תהליך אחד (התהליך הראשי). לאחר האיטרציה הראשונה (i=0) ישנם 2 תהליכים. לאחר האיטרציה השנייה (i=1), כל אחד משני התהליכים הקיימים מבצע fork(), ולכן נוצרים 2 תהליכים נוספים, מה שמביא אותנו ל-4 תהליכים בסך הכל. כל אחד מארבעת התהליכים הללו ממשיך לשורת ה-printf ומדפיס את המחרוזת פעם אחת."}, "difficulty_estimation": "Easy", "_source_file": "0050__Processes__CodeAnalysis__Easy.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:23:52", "_subject": "Virtualization"}, {"id": 5, "type": "CodeAnalysis", "topic": ["Processes", "System Calls"], "content": {"text": "נתונה התוכנית הבאה. מה יהיה הפלט של התוכנית? (הנח שכל קריאות המערכת מצליחות, ואין חשיבות לסדר ההדפסה בין התהליכים השונים).", "code_snippet": "int main() {\n    int x = 10;\n    if (fork() == 0) {\n        x += 5;\n    } else {\n        x -= 5;\n    }\n    printf(\"%d \", x);\n    return 0;\n}", "options": ["א. 15 5", "ב. 15", "ג. 5", "ד. 10 10", "ה. 15 10"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "קריאת המערכת fork() יוצרת תהליך בן חדש המהווה העתק של תהליך האב. בתהליך הבן, הערך המוחזר מ-fork() הוא 0, ולכן הוא נכנס לבלוק ה-if ומעדכן את x ל-15. בתהליך האב, הערך המוחזר הוא ה-PID של הבן (גדול מ-0), ולכן הוא נכנס לבלוק ה-else ומעדכן את x ל-5. כיוון שלכל תהליך מרחב זיכרון נפרד, כל אחד מהם מדפיס את הערך המקומי שלו, ומתקבלים שני המספרים 15 ו-5."}, "difficulty_estimation": "Easy", "_source_file": "0051__Processes__CodeAnalysis__Easy.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:24:03", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Processes", "System Calls"], "content": {"text": "נתונה התוכנית הבאה. כמה פעמים תודפס המחרוזת \"OS\" למסך? הניחו שכל קריאות המערכת מצליחות וכי הפלט מרוקן (flushed) מיד לאחר ההדפסה.", "code_snippet": "int main() {\n    for (int i = 0; i < 2; i++) {\n        fork();\n    }\n    printf(\"OS\\n\");\n    return 0;\n}", "options": ["א. 2", "ב. 3", "ג. 4", "ד. 6", "ה. 8"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התוכנית מבצעת לולאה בת שתי איטרציות. בתחילה קיים תהליך אחד. באיטרציה הראשונה (i=0), התהליך מבצע fork ונוצר תהליך בן, כך שישנם 2 תהליכים. באיטרציה השנייה (i=1), כל אחד משני התהליכים הקיימים מבצע fork בעצמו, מה שיוצר שני תהליכים חדשים נוספים. סה\"כ בסיום הלולאה קיימים 4 תהליכים (2^2). כל אחד מארבעת התהליכים הללו ממשיך לשורת ההדפסה ומדפיס \"OS\" פעם אחת, ולכן המחרוזת תודפס 4 פעמים."}, "difficulty_estimation": "Easy", "_source_file": "0052__Processes__CodeAnalysis__Easy.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:24:16", "_subject": "Virtualization"}, {"id": 5, "type": "CodeAnalysis", "topic": ["Processes", "System Calls"], "content": {"text": "כמה פעמים תודפס המילה 'Hello' במהלך הרצת הקוד הבא? הניחו שכל הקריאות למערכת מצליחות.", "code_snippet": "int main() {\n    fork();\n    if (fork() == 0) {\n        fork();\n    }\n    printf(\"Hello\\n\");\n    return 0;\n}", "options": ["א. 3", "ב. 4", "ג. 6", "ד. 8", "ה. 5"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "לאחר ה-fork הראשון ישנם 2 תהליכים. בשורה השנייה, כל אחד מהם מבצע fork נוסף, מה שיוצר 2 תהליכים נוספים (סה\"כ 4 תהליכים בשלב זה). מתוך הארבעה, רק 2 התהליכים שהם 'בנים' של ה-fork השני (אלו שקיבלו את הערך 0) נכנסים לתוך בלוק ה-if ומבצעים fork שלישי. ה-fork השלישי יוצר 2 תהליכים נוספים. לסיכום: 4 תהליכים קיימים לפני ה-if, ועוד 2 נוצרים בתוכו, סה\"כ 6 תהליכים שכל אחד מהם מגיע לשורת ההדפסה."}, "difficulty_estimation": "Easy", "_source_file": "0053__Processes__CodeAnalysis__Easy.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:24:26", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Processes", "System Calls"], "content": {"text": "נתונה התוכנית הבאה בשפת C. כמה פעמים תודפס המילה 'OS' במהלך ריצת התוכנית?\nהניחו כי כל קריאות המערכת מצליחות, וכי כל הדפסה מתבצעת מיד ללא חוצץ (buffer).", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n\nint main() {\n    for (int i = 0; i < 2; i++) {\n        fork();\n        printf(\"OS\\n\");\n    }\n    return 0;\n}", "options": ["א. 2", "ב. 4", "ג. 6", "ד. 8", "ה. 16"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "באיטרציה הראשונה של הלולאה (i=0), מתבצעת קריאת fork אחת שיוצרת תהליך בן. בשלב זה ישנם 2 תהליכים (האב המקורי והבן החדש), וכל אחד מהם מדפיס את המילה 'OS' פעם אחת (סה\"כ 2 הדפסות). באיטרציה השנייה (i=1), כל אחד משני התהליכים הקיימים מבצע fork בעצמו, מה שיוצר 2 תהליכים נוספים (סה\"כ 4 תהליכים רצים כעת). כל ארבעת התהליכים הללו מבצעים את פקודת ההדפסה של האיטרציה השנייה (סה\"כ 4 הדפסות נוספות). לכן, סך כל הפעמים שהמילה תודפס הוא 2 + 4 = 6."}, "difficulty_estimation": "Easy", "_source_file": "0054__Processes__CodeAnalysis__Easy.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:24:52", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Processes", "System Calls"], "content": {"text": "נתונה התוכנית הבאה. כמה פעמים יודפס התו 'X' למסך? הניחו שכל קריאות המערכת מצליחות ותהליכים אינם נכשלים.", "code_snippet": "int main() {\n    if (fork() == 0) {\n        fork();\n        printf(\"X\\n\");\n    }\n    return 0;\n}", "options": ["א. 1", "ב. 2", "ג. 3", "ד. 4", "ה. 0"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "התהליך הראשי (האב) מבצע fork. תהליך האב מקבל ערך הגדול מ-0 ולכן אינו נכנס לבלוק ה-if. תהליך הבן מקבל את הערך 0 ונכנס לבלוק ה-if. בתוך הבלוק, תהליך הבן מבצע fork נוסף, מה שיוצר תהליך חדש (הנכד של התהליך המקורי). כעת, גם תהליך הבן וגם תהליך הנכד נמצאים בתוך הבלוק וממשיכים לשורת ההדפסה. לכן, התו 'X' יודפס פעמיים בסך הכל."}, "difficulty_estimation": "Easy", "_source_file": "0055__Processes__CodeAnalysis__Easy.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:25:05", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Processes", "System Calls"], "content": {"text": "נתונה התוכנית הבאה. כמה פעמים יודפס המחרוזת \"OS\" במהלך הרצת התוכנית? הניחו שכל קריאות המערכת מצליחות.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n\nint main() {\n    fork();\n    if (fork() == 0) {\n        fork();\n    }\n    printf(\"OS\\n\");\n    return 0;\n}", "options": ["א. 2", "ב. 4", "ג. 5", "ד. 6", "ה. 8"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "נבצע מעקב אחר יצירת התהליכים:\n1. התהליך המקורי (P1) מבצע את ה-fork הראשון. נוצר תהליך בן (P2). כעת יש 2 תהליכים.\n2. שני התהליכים (P1, P2) מגיעים לשורת ה-if ומבצעים fork נוסף:\n   - P1 יוצר את P3. ב-P1 ה-fork מחזיר PID חיובי (דילוג על ה-if). ב-P3 ה-fork מחזיר 0 (כניסה ל-if).\n   - P2 יוצר את P4. ב-P2 ה-fork מחזיר PID חיובי (דילוג על ה-if). ב-P4 ה-fork מחזיר 0 (כניסה ל-if).\n3. התהליכים שנכנסו ל-if (הם P3 ו-P4) מבצעים fork שלישי:\n   - P3 יוצר את P5.\n   - P4 יוצר את P6.\n4. כל התהליכים שנוצרו ולא הסתיימו מגיעים לשורת ההדפסה. התהליכים הם: P1, P2, P3, P4, P5, P6. סה\"כ 6 תהליכים, ולכן המחרוזת תודפס 6 פעמים."}, "difficulty_estimation": "Easy", "_source_file": "0056__Processes__CodeAnalysis__Easy.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:25:25", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Processes", "System Calls"], "content": {"text": "נתונה התוכנית הבאה בשפת C. מה יהיה הפלט של התוכנית? הניחו שכל קריאות המערכת מצליחות, וכי הפלט מודפס ברצף ללא רווחים או ירידות שורה.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 0;\n    for (int i = 0; i < 3; i++) {\n        if (fork() == 0) {\n            x++;\n        } else {\n            x--;\n            wait(NULL);\n            break;\n        }\n    }\n    printf(\"%d\", x);\n    return 0;\n}", "options": ["א. 3210", "ב. 310-1", "ג. -1013", "ד. 0", "ה. אף אחת מהתשובות אינה נכונה"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "נעקוב אחר יצירת התהליכים: התהליך הראשי (P0) מתחיל עם x=0. באיטרציה הראשונה (i=0) הוא יוצר בן (P1). P0 מבצע x-- (הופך ל-1-) ומחכה ל-P1. P1 מבצע x++ (הופך ל-1) וממשיך לאיטרציה הבאה. באיטרציה i=1, P1 יוצר בן (P2). P1 מבצע x-- (הופך ל-0) ומחכה ל-P2. P2 מבצע x++ (הופך ל-2) וממשיך לאיטרציה הבאה. באיטרציה i=2, P2 יוצר בן (P3). P2 מבצע x-- (הופך ל-1) ומחכה ל-P3. P3 מבצע x++ (הופך ל-3) ומסיים את הלולאה. P3 הוא הראשון שמגיע להדפסה ומדפיס 3. לאחר מכן P2 מסיים את ה-wait ומדפיס 1. לאחר מכן P1 מסיים את ה-wait ומדפיס 0. לבסוף P0 מסיים את ה-wait ומדפיס 1-. לכן הפלט הוא 310-1."}, "difficulty_estimation": "Medium", "_source_file": "0057__Processes__CodeAnalysis__Medium.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:25:42", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Processes", "System Calls", "Address Space"], "content": {"text": "נתונה התוכנית הבאה בשפת C. הניחו כי כל קריאות המערכת מצליחות, וכי הפונקציה wait(NULL) גורמת לתהליך האב להמתין עד לסיום ביצועו של תהליך בן אחד. מה יהיה הפלט המדויק של התוכנית?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint counter = 0;\n\nint main() {\n    for (int i = 0; i < 2; i++) {\n        if (fork() == 0) {\n            counter++;\n            printf(\"%d\", counter);\n        } else {\n            wait(NULL);\n            counter--;\n            printf(\"%d\", counter);\n        }\n    }\n    return 0;\n}", "options": ["א. 120-10-2", "ב. 1100-1-2", "ג. 120-1-20", "ד. 1210-1-2", "ה. אף אחת מהתשובות אינה נכונה"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "נעקוב אחר ביצוע התהליכים: 1. תהליך האב המקורי (P1) עם counter=0 ו-i=0 מבצע fork. P1 נכנס ל-wait. 2. הבן (P2) עם i=0 מקדם את counter ל-1 ומדפיס '1'. 3. P2 ממשיך ל-i=1 ומבצע fork. P2 נכנס ל-wait. 4. הבן של P2 (נקרא לו P3) עם i=1 מקדם את ה-counter שלו (שהיה 1) ל-2 ומדפיס '2'. P3 מסיים. 5. P2 משתחרר מה-wait, מקטין את ה-counter שלו ל-0 ומדפיס '0'. P2 מסיים. 6. P1 משתחרר מה-wait (של P2), מקטין את ה-counter שלו ל-1- ומדפיס '1-'. 7. P1 ממשיך ל-i=1 ומבצע fork. P1 נכנס ל-wait. 8. הבן החדש (P4) עם i=1 מקדם את ה-counter שלו (שהיה 1-) ל-0 ומדפיס '0'. P4 מסיים. 9. P1 משתחרר מה-wait, מקטין את ה-counter ל-2- ומדפיס '2-'. סה\"כ הפלט: 120-10-2."}, "difficulty_estimation": "Medium", "_source_file": "0058__Processes__CodeAnalysis__Medium.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:25:58", "_subject": "Virtualization"}, {"id": 7, "type": "CodeAnalysis", "topic": ["Processes", "System Calls", "Memory Management"], "content": {"text": "נתונה התוכנית הבאה בשפת C. הניחו שכל קריאות המערכת מצליחות, שהתהליכים רצים לפי סדר הקריאה ל-wait, ושהפלט מודפס למסך ללא השהיה (buffering). מה יהיה הפלט של התוכנית?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint x = 10;\n\nint main() {\n    for (int i = 0; i < 2; i++) {\n        if (fork() == 0) {\n            x += 5;\n            printf(\"%d \", x);\n            return 0;\n        } else {\n            wait(NULL);\n            x += 2;\n        }\n    }\n    printf(\"%d\", x);\n    return 0;\n}", "options": ["א. 15 15 10", "ב. 15 17 14", "ג. 15 22 24", "ד. 15 17 12", "ה. אף אחת מהתשובות אינה נכונה"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "באיטרציה הראשונה (i=0), האב יוצר בן. הבן מקבל עותק של x=10, מבצע x += 5 ומדפיס 15. האב ממתין לסיום הבן (wait) ואז מבצע x += 2, כך שערך x אצלו הופך ל-12. באיטרציה השנייה (i=1), האב יוצר בן נוסף. הבן השני יורש את ערך ה-x הנוכחי של האב (12), מבצע x += 5 ומדפיס 17. האב שוב ממתין ואז מבצע x += 2, כך שערך x אצלו הופך ל-14. בסיום הלולאה, האב מדפיס את ערך ה-x שלו (14). מכיוון שכל תהליך מקבל עותק נפרד של הזיכרון (Copy-on-Write), השינויים של הבנים לא משפיעים על האב ולהיפך, מלבד הירושה ברגע ה-fork. לכן הפלט הכולל הוא 15 17 14."}, "difficulty_estimation": "Medium", "_source_file": "0059__Processes__CodeAnalysis__Medium.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:26:24", "_subject": "Virtualization"}, {"id": 7, "type": "CodeAnalysis", "topic": ["Processes"], "content": {"text": "נתונה התוכנית הבאה בשפת C. הניחו שכל קריאות המערכת מצליחות, ושלא פועלים במערכת תהליכים נוספים פרט לאלו שנוצרים בקוד. תזכורת: כל הדפסה לפלט הסטנדרטי מתבצעת מיד, ללא חוצץ (buffer) הדפסה. איזה מהפלטים הבאים אינו אפשרי?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    if (fork() == 0) {\n        fork();\n        printf(\"1\");\n    } else {\n        wait(NULL);\n        printf(\"2\");\n    }\n    return 0;\n}", "options": ["א. 112", "ב. 121", "ג. 211", "ד. כל הפלטים המוצגים אפשריים"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התהליך הראשי (האב) מבצע fork ויוצר את תהליך הבן (C1). לאחר מכן האב קורא ל-wait, מה שאומר שהוא ימתין עד ש-C1 יסיים את ריצתו לפני שידפיס '2'. תהליך C1 בעצמו מבצע fork ויוצר תהליך נכד (G1). גם C1 וגם G1 מדפיסים '1'. כיוון ש-C1 חייב להדפיס '1' לפני שהוא מסיים את ריצתו, והאב מדפיס '2' רק לאחר סיום C1, הרי שלפחות תו '1' אחד חייב להופיע לפני התו '2' בפלט. לכן הפלט '211' אינו אפשרי (הנכד G1 יכול להדפיס '1' אחרי ה-'2' של האב אם C1 סיים לפניו, אך הבן C1 עצמו חייב להדפיס '1' לפני ה-'2')."}, "difficulty_estimation": "Medium", "_source_file": "0060__Processes__CodeAnalysis__Medium.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:26:59", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Processes", "System Calls"], "content": {"text": "נתון קטע הקוד הבא בשפת C. הניחו כי כל קריאות המערכת מצליחות, וכי הפלט מודפס ישירות למסך ללא שימוש ב-buffer פנימי. מה יהיו הערכים המודפסים על המסך בסיום ריצת התוכנית (הסדר אינו מחייב)?", "code_snippet": "int main() {\n    int x = 0;\n    for (int i = 0; i < 2; i++) {\n        if (fork() == 0) {\n            x += 2;\n        } else {\n            x += 1;\n            wait(NULL);\n        }\n    }\n    printf(\"%d \", x);\n    return 0;\n}", "options": ["א. 2 3 3 4", "ב. 1 2 3 4", "ג. 2 2 4 4", "ד. 0 1 2 3", "ה. אף אחת מהתשובות אינה נכונה"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "נעקוב אחר פיצול התהליכים וערך המשתנה x (הנמצא במרחב הכתובות הנפרד של כל תהליך):\n1. התהליך המקורי (P0) מתחיל עם x=0.\n2. איטרציה ראשונה (i=0): P0 מבצע fork. נוצר בן P1. בבן (P1) התנאי מתקיים ו-x גדל ל-2. באב (P0) התנאי לא מתקיים, x גדל ל-1 והוא ממתין לבנו.\n3. איטרציה שנייה (i=1):\n   - תהליך P1 (שבו x=2) מבצע fork ויוצר את P3. ב-P3 (הבן החדש) x=2+2=4. ב-P1 (האב של P3) x=2+1=3.\n   - לאחר ש-P1 מסיים, P0 ממשיך לאיטרציה השנייה שלו. P0 (שבו x=1) מבצע fork ויוצר את P2. ב-P2 (הבן החדש) x=1+2=3. ב-P0 (האב) x=1+1=2.\n4. בסיום, כל ארבעת התהליכים שנוצרו (P0, P1, P2, P3) מדפיסים את ערך ה-x שלהם: 2, 3, 3, 4."}, "difficulty_estimation": "Medium", "_source_file": "0061__Processes__CodeAnalysis__Medium.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:27:20", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Processes", "System Calls", "Memory Management"], "content": {"text": "נתונה התוכנית הבאה בשפת C. מה יהיה הפלט של התוכנית? הניחו שכל קריאות המערכת מצליחות ושהפלט מודפס מיד ללא חוצץ (buffering).", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint x = 5;\n\nint main() {\n    for (int i = 0; i < 2; i++) {\n        if (fork() == 0) {\n            x += 10;\n            printf(\"%d\", x);\n            return 0;\n        } else {\n            wait(NULL);\n            x -= 2;\n            printf(\"%d\", x);\n        }\n    }\n    return 0;\n}", "options": ["א. 153131", "ב. 1513131", "ג. 155133", "ד. 15151313", "ה. 151331"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "בכל איטרציה של הלולאה, תהליך האב יוצר תהליך בן ומחכה לסיומו בעזרת wait. כיוון שכל תהליך מקבל מרחב כתובות נפרד, השינויים במשתנה הגלובלי x בתוך הבן אינם משפיעים על האב, אך הבן יורש את הערך הנוכחי של x מהאב ברגע ה-fork. באיטרציה הראשונה (i=0): הבן מקבל x=5, מוסיף 10 ומדפיס 15. האב מחכה, מעדכן את ה-x שלו ל-3 (5-2) ומדפיס 3. באיטרציה השנייה (i=1): האב (שה-x שלו הוא 3) יוצר בן חדש. הבן יורש x=3, מוסיף 10 ומדפיס 13. האב מחכה, מעדכן את ה-x שלו ל-1 (3-2) ומדפיס 1. התוצאה המצטברת היא 153131."}, "difficulty_estimation": "Medium", "_source_file": "0062__Processes__CodeAnalysis__Medium.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:27:33", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Processes", "System Calls", "Fork"], "content": {"text": "נתונה התוכנית הבאה בשפת C. הניחו כי כל קריאות המערכת מצליחות, וכי הפלט מודפס מיד למסך (ללא buffering). מה יהיה הפלט של התוכנית?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    int x = 5;\n    for (int i = 0; i < 2; i++) {\n        if (fork() == 0) {\n            x += 10;\n            printf(\"%d\", x);\n            exit(0);\n        } else {\n            x += 2;\n            wait(NULL);\n        }\n    }\n    printf(\"%d\", x);\n    return 0;\n}", "options": ["א. 15159", "ב. 15179", "ג. 152535", "ד. 151719", "ה. 15177"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "בתחילת התוכנית x=5. באיטרציה הראשונה (i=0), מתבצע fork. הבן הראשון מקבל עותק של x=5, מעדכן אותו ל-15 (x += 10), מדפיס '15' ומסיים (exit). האב באותו זמן מעדכן את ה-x שלו ל-7 (x += 2) ומחכה לסיום הבן. באיטרציה השנייה (i=1), האב (שבו x=7) מבצע fork נוסף. הבן השני מקבל עותק של x=7, מעדכן אותו ל-17 (x += 10), מדפיס '17' ומסיים. האב מעדכן את ה-x שלו ל-9 (x += 2) ומחכה לסיום הבן. בסיום הלולאה, האב מדפיס את הערך הסופי של x שלו, שהוא 9. לכן הפלט המצטבר הוא 15179."}, "difficulty_estimation": "Medium", "_source_file": "0063__Processes__CodeAnalysis__Medium.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:27:45", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Processes", "System Calls", "Memory Management"], "content": {"text": "נתונה התוכנית הבאה בשפת C. מה יהיה הפלט של התוכנית? הניחו שכל קריאות המערכת מצליחות, שההדפסות מתבצעות מיד ללא חוצץ (buffer), ושתהליך אב תמיד ממתין לסיום ילדיו לפני שהוא ממשיך בביצוע.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint val = 5;\n\nint main() {\n    pid_t pid;\n    pid = fork();\n    if (pid == 0) {\n        val += 15;\n        if (fork() == 0) {\n            val += 20;\n            printf(\"%d\", val);\n        } else {\n            wait(NULL);\n            printf(\"%d\", val);\n        }\n    } else {\n        wait(NULL);\n        val += 10;\n        printf(\"%d\", val);\n    }\n    return 0;\n}", "options": ["א. 402015", "ב. 404015", "ג. 402025", "ד. 404025", "ה. 204015"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "לאחר ה-fork הראשון, נוצר תהליך בן (C1) בו המשתנה הגלובלי val הוא 5. C1 מעדכן את val ל-20. לאחר מכן C1 מבצע fork נוסף ויוצר נכד (G1). ב-G1 המשתנה val מתחיל ב-20, מעודכן ל-40 ומודפס. כיוון שלכל תהליך מרחב זיכרון נפרד (Copy on Write), השינוי בנכד לא משפיע על C1. לכן, לאחר ה-wait ב-C1, הוא מדפיס את הערך שלו שהוא 20. תהליך האב המקורי המתין לסיום C1, ולאחר מכן הוסיף 10 לערך המקורי שלו (5) והדפיס 15. התוצאה המשורשרת היא 402015."}, "difficulty_estimation": "Medium", "_source_file": "0064__Processes__CodeAnalysis__Medium.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:27:56", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Processes", "fork", "wait", "Memory Isolation", "Concurrency"], "content": {"text": "נתונה התוכנית הבאה בשפת C. הניחו שכל קריאות המערכת מצליחות, ושאין תהליכים נוספים במערכת מלבד אלו שנוצרים על ידי התוכנית. הניחו כי המערכת אינה משתמשת בחוצצים (buffers) עבור הפלט.", "code_snippet": "1  #include <stdio.h>\n2  #include <unistd.h>\n3  #include <sys/wait.h>\n4  #include <stdlib.h>\n5\n6  int main() {\n7    int x = 1;\n8    pid_t p;\n9    for (int i = 0; i < 2; i++) {\n10     p = fork();\n11     if (p == 0) {\n12       x += 2;\n13       if (i == 1) {\n14         if (fork() == 0) {\n15           x *= 2;\n16           printf(\"C: %d\\n\", x);\n17           exit(0);\n18         }\n19         wait(NULL);\n20       }\n21       printf(\"B: %d\\n\", x);\n22       exit(0);\n23     } else {\n24       x += 1;\n25     }\n26   }\n27   while(wait(NULL) > 0);\n28   printf(\"A: %d\\n\", x);\n29   return 0;\n30 }", "options": null}, "sub_questions": [{"id": "10.1", "text": "כמה תהליכים נוצרו סה\"כ במהלך ריצת התוכנית (כולל התהליך הראשי)? הסבירו את תשובתכם בעזרת תיאור עץ התהליכים.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "ציינו את כל שורות הפלט של התוכנית. האם סדר ההדפסה של השורות קבוע? אם כן - מהו? אם לא - אילו אילוצים קיימים על סדר ההדפסה?", "code_snippet": null, "options": null}, {"id": "10.3", "text": "נניח שמוחקים את שורה 27 מהקוד (לולאת ה-wait). האם במצב זה ייתכן שהשורה \"A: 3\" תודפס לפני השורה \"B: 4\"? נמקו.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: נוצרו 4 תהליכים סה\"כ. התהליך הראשי (P0) מתחיל עם x=1. באיטרציה i=0 הוא יוצר את P1. באיטרציה i=1 הוא יוצר את P2. תהליך P2, כיוון שהוא בבן של האיטרציה השנייה (i=1), יוצר את P3 (נכד של P0).\n\n10.2: שורות הפלט הן: \"B: 3\", \"C: 8\", \"B: 4\", \"A: 3\".\nהסבר הערכים:\n- P1 (נוצר ב-i=0): יורש x=1, מבצע x+=2 ומדפיס \"B: 3\".\n- P0 (אחרי i=0): מבצע x+=1, כעת x=2.\n- P2 (נוצר ב-i=1): יורש x=2, מבצע x+=2, כעת x=4. כיוון ש-i=1, יוצר את P3.\n- P3 (נוצר בתוך P2): יורש x=4, מבצע x*=2, מדפיס \"C: 8\".\n- P2 מחכה ל-P3 (שורה 19) ואז מדפיס \"B: 4\".\n- P0 (אחרי i=1): מבצע x+=1, כעת x=3. מחכה לכל בניו (שורה 27) ומדפיס \"A: 3\".\nאילוצי סדר: \"C: 8\" חייב להופיע לפני \"B: 4\" בגלל ה-wait בשורה 19. \"A: 3\" חייב להופיע אחרון בגלל ה-wait בשורה 27. \"B: 3\" יכול להופיע בכל מקום לפני \"A: 3\".\n\n10.3: כן. אם נסיר את שורה 27, התהליך הראשי (P0) לא יחכה לסיום בניו (P1, P2). לאחר סיום הלולאה הוא יגיע מיד לשורה 28. ייתכן מצב שבו P0 יסיים את הריצה וידפיס \"A: 3\" בזמן ש-P2 עדיין ממתין ל-P3 או טרם הגיע לשורת ההדפסה שלו (מרוץ תהליכים)."}, "difficulty_estimation": "Hard", "_source_file": "0065__Processes__CodeAnalysis__Hard.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:28:19", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Processes", "Fork", "System Calls", "Concurrency"], "content": {"text": "נתונה התוכנית הבאה בשפת C. הריצו את התוכנית, והתהליך שנוצר קיבל את מזהה התהליך (PID) שמספרו 100. \nיש להניח שכל קריאות המערכת שיכולות להצליח הצליחו, לא נוצרים תהליכים בקטעי קוד אחרים במערכת, וכל תהליך חדש מקבל מזהה הגדול ב-1 מהתהליך שנוצר לפניו.\nתזכורת: כל הדפסה לפלט הסטנדרטי מתבצעת מיד (ללא buffer).", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    pid_t root = getpid(); \n    if (fork() || fork()) {\n        if (!fork()) {\n            printf(\"A %d %d\\n\", getpid(), getppid());\n            exit(0);\n        }\n    } else {\n        if (fork() && fork()) {\n            printf(\"B %d %d\\n\", getpid(), getppid());\n        }\n    }\n\n    while(wait(NULL) > 0);\n\n    if (getpid() == root) {\n        printf(\"Root Done: %d\\n\", getpid());\n    }\n\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "כמה תהליכים נוצרו בתוכנית בסך הכל (כולל התהליך הראשי)? הציגו את עץ התהליכים שנוצר.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "כתבו את כל שורות הפלט האפשריות של התוכנית (סדר השורות עשוי להשתנות, אך יש לציין את תוכן השורות במדויק).", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. ניתוח יצירת התהליכים:\n- תהליך 100 מבצע fork() ראשון (שורה 8). נוצר תהליך 101. עבור 100 הביטוי fork() הוא אמת (101), לכן בגלל אופרטור ה-|| הוא מדלג על ה-fork השני ונכנס לבלוק ה-if.\n- תהליך 101 קיבל 0 מה-fork הראשון, לכן הוא מבצע את ה-fork() השני בביטוי ה-||. נוצר תהליך 102. עבור 101 הביטוי השני הוא אמת (102), לכן הוא נכנס לבלוק ה-if. תהליך 102 קיבל 0 ב-fork השני, לכן הביטוי (0 || 0) הוא שקר והוא נכנס לבלוק ה-else.\n- בתוך ה-if (תהליכים 100 ו-101): שניהם מבצעים if(!fork()). תהליך 100 יוצר את 103. תהליך 103 מדפיס 'A 103 100' ויוצא. תהליך 101 יוצר את 104. תהליך 104 מדפיס 'A 104 101' ויוצא.\n- בתוך ה-else (תהליך 102): מבצע fork() && fork(). תהליך 102 יוצר את 105. תהליך 105 מקבל 0 ומפסיק את ה-AND. תהליך 102 מקבל 105 וממשיך ל-fork() השני, בו הוא יוצר את 106. תהליך 102 מקבל 106 (אמת) ומדפיס 'B 102 101'. תהליך 106 מקבל 0 ולא מדפיס.\n- סה\"כ נוצרו 7 תהליכים (100, 101, 102, 103, 104, 105, 106).\n\n2. פלט התוכנית:\nהשורות הבאות יודפסו (הסדר בין השלוש הראשונות עשוי להשתנות, האחרונה תמיד בסוף):\nA 103 100\nA 104 101\nB 102 101\nRoot Done: 100"}, "difficulty_estimation": "Hard", "_source_file": "0066__Processes__CodeAnalysis__Hard.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:28:46", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Processes", "System Calls", "Memory Management", "Concurrency"], "content": {"text": "נתונה התוכנית הבאה בשפת C. הניחו שכל קריאות המערכת מצליחות, שתהליכים אינם נוצרים מחוץ לקוד המוצג, ושתזמון התהליכים (Scheduling) אינו ידוע מראש. הנחה נוספת: הפונקציה fflush(stdout) מבטיחה שהפלט נשלח למסך באופן מיידי.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    int x = 10;\n    for (int i = 0; i < 2; i++) {\n        pid_t pid = fork();\n        if (pid == 0) {\n            x += 5;\n            if (i == 0) {\n                if (fork() == 0) {\n                    x += 10;\n                }\n                x *= 2;\n            }\n            printf(\"%d:%d \", i, x);\n            fflush(stdout);\n            exit(0);\n        } else {\n            x -= 2;\n            waitpid(pid, NULL, 0);\n        }\n    }\n    printf(\"Done:%d\\n\", x);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "כמה תהליכים נוצרו במהלך ריצת התוכנית (כולל התהליך המקורי)? ציירו את עץ התהליכים.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "האם ייתכן שהפלט \"0:50\" יופיע לאחר הפלט \"1:13\"? נמקו את תשובתכם על סמך מנגנון ה-wait בתוכנית.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "מהו הפלט המלא (או הפלטים האפשריים) של התוכנית? יש לפרט את החישוב עבור כל תהליך.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. נוצרו 4 תהליכים בסך הכל: התהליך הראשי (P1), הבן שלו מהאיטרציה הראשונה (P2), הנכד (P3 - הבן של P2), והבן של הראשי מהאיטרציה השנייה (P4).\n\n2. כן, ייתכן שהפלט '0:50' יופיע אחרי '1:13'. הסיבה היא שהתהליך הראשי (P1) מבצע waitpid(pid) רק עבור הבנים הישירים שלו (P2 ו-P4). P1 מחכה ש-P2 יסתיים לפני שהוא ממשיך לאיטרציה הבאה (i=1), אבל P2 עצמו לא מחכה לבן שלו (P3). לכן, ברגע ש-P2 מסיים ומדפיס, P1 יכול להמשיך, ליצור את P4 ולהדפיס '1:13', בזמן ש-P3 עדיין רץ או ממתין לתורו להדפיס.\n\n3. פירוט החישובים:\n- P1 (הראשי): מתחיל עם x=10. ב-i=0 מבצע x-=2 (x=8) ומחכה ל-P2. ב-i=1 מבצע x-=2 (x=6) ומחכה ל-P4. בסוף מדפיס 'Done:6'.\n- P2 (בן של P1, i=0): יורש x=10. מבצע x+=5 (x=15). יוצר את P3. מבצע x*=2 (x=30). מדפיס '0:30' ויוצא.\n- P3 (בן של P2): יורש x=15. מבצע x+=10 (x=25). מבצע x*=2 (x=50). מדפיס '0:50' ויוצא.\n- P4 (בן של P1, i=1): יורש x=8. מבצע x+=5 (x=13). מדפיס '1:13' ויוצא.\n\nסדר ההדפסות: '0:30' חייב להופיע לפני '1:13' (כי P1 מחכה ל-P2). '0:50' יכול להופיע בכל מקום לפני 'Done:6'. 'Done:6' תמיד אחרון.\nפלטים אפשריים לדוגמה: \n- 0:30 0:50 1:13 Done:6\n- 0:50 0:30 1:13 Done:6\n- 0:30 1:13 0:50 Done:6"}, "difficulty_estimation": "Hard", "_source_file": "0067__Processes__CodeAnalysis__Hard.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:29:22", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Processes", "System Calls", "Fork", "Exec", "Concurrency"], "content": {"text": "נתונה התוכנית הבאה בשפת C. הניחו שכל קריאות המערכת מצליחות, שקריאת ה-exec מוצאת את הפקודה echo, ושכל הדפסה מתבצעת באופן מיידי ללא חוצץ (buffer). כמו כן, הניחו כי המערכת אינה יוצרת תהליכים נוספים פרט לאלו המצוינים בקוד.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    printf(\"A\");\n    fflush(stdout);\n    if (fork() && fork()) {\n        fork();\n    } else {\n        if (fork() == 0) {\n            execlp(\"echo\", \"echo\", \"B\", NULL);\n            printf(\"D\");\n            fflush(stdout);\n        }\n    }\n    printf(\"C\");\n    fflush(stdout);\n    while(wait(NULL) > 0);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "כמה תהליכים נוצרו סה\"כ במהלך ריצת התוכנית (כולל התהליך הראשי)? הסבירו בעזרת פירוט שלבי הריצה או עץ תהליכים.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "האם הפלט \"ACCCBCB\" הוא פלט אפשרי עבור ריצה של תוכנית זו? נמקו.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "האם התו 'D' יודפס אי פעם? הסבירו מדוע.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. ניתוח תהליכים: \n- P0 (הראשי) מדפיס A.\n- P0 מבצע fork() ראשון ויוצר את P1. עבור P0 התוצאה אמת, לכן הוא ממשיך ל-fork() השני ויוצר את P2. התנאי (fork && fork) אמת עבור P0 ולכן הוא נכנס לבלוק ה-if ומבצע fork() שלישי ליצירת P3. גם P0 וגם P3 מדפיסים C.\n- P1 (נוצר ב-fork הראשון): עבורו ה-fork הראשון מחזיר 0. בשל אופרטור ה-&& מתבצע short-circuit ו-P1 עובר לבלוק ה-else. שם הוא מבצע fork() ויוצר את P4. P4 מבצע exec ומדפיס B. P1 ממשיך ומדפיס C.\n- P2 (נוצר ב-fork השני): עבורו ה-fork השני מחזיר 0. התנאי (אמת && 0) הוא שקר, לכן P2 עובר לבלוק ה-else. שם הוא מבצע fork() ויוצר את P5. P5 מבצע exec ומדפיס B. P2 ממשיך ומדפיס C.\nסה\"כ תהליכים: P0, P1, P2, P3, P4, P5 - סה\"כ 6 תהליכים.\n\n2. ניתוח פלט: \n- 'A' מודפס פעם אחת (P0).\n- 'C' מודפס 4 פעמים על ידי התהליכים P0, P3, P1, P2.\n- 'B' מודפס פעמיים על ידי התהליכים P4, P5 (באמצעות echo).\nהפלט \"ACCCBCB\" מכיל פעם אחת A, ארבע פעמים C ופעמיים B. כיוון שאין סדר מחייב בין התהליכים השונים (פרט לכך ש-A מודפס ראשון), פלט זה אפשרי.\n\n3. הדפסת 'D':\n- התו 'D' לא יודפס לעולם. התהליכים P4 ו-P5, שהם היחידים שמגיעים לשורה זו, מבצעים קריאת execlp לפני ההדפסה. קריאת exec מחליפה את מרחב הכתובות והקוד של התהליך בקוד של התוכנית echo, ולכן הפקודה printf(\"D\") שמופיעה אחרי ה-exec לא תתבצע לעולם (אלא אם ה-exec נכשל, אך הנחנו שהצליח)."}, "difficulty_estimation": "Hard", "_source_file": "0068__Processes__CodeAnalysis__Hard.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:30:04", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Processes", "System Calls", "fork", "exec", "Wait"], "content": {"text": "נתונה התוכנית הבאה בשפת C. הניחו כי המזהה (PID) של התהליך המריץ את הפונקציה main הוא 100. כל קריאת מערכת שמצליחה מחזירה ערך תקין (לפי התיעוד), ותהליכים חדשים מקבלים מזהה הגדול ב-1 מהמזהה האחרון שהוקצה במערכת. הניחו כי לא נוצרים תהליכים אחרים במערכת בזמן הריצה, וכי הפונקציה printf מדפיסה ישירות למסך ללא שימוש ב-buffer (כאילו בוצע fflush).", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    pid_t pid;\n    printf(\"P%d\\n\", getpid());\n    if (fork() == 0) {\n        if (fork() || fork()) {\n            printf(\"T%d\\n\", getpid());\n        }\n        exit(0);\n    }\n    pid = fork();\n    if (pid == 0) {\n        execlp(\"ls\", \"ls\", NULL);\n        printf(\"E%d\\n\", getpid());\n        exit(1);\n    }\n    waitpid(pid, NULL, 0);\n    printf(\"D%d\\n\", getpid());\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "כמה תהליכים נוצרו בסך הכל במהלך ריצת התוכנית (כולל התהליך הראשי)? פרטו את ה-PID של כל אחד מהם ואת הקשר ביניהם (מי האבא של מי).", "code_snippet": null, "options": null}, {"id": "10.2", "text": "האם ייתכן מצב בו המחרוזת 'D100' תודפס לפני המחרוזת 'T101'? נמקו את תשובתכם.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "נניח כי הקריאה ל-execlp נכשלה (למשל, הקובץ ls לא נמצא). מה יהיו כל ההדפסות של התוכנית במקרה זה? (אין צורך לציין את סדר ההדפסות, אלא רק אילו מחרוזות יופיעו).", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. נוצרו 5 תהליכים בסך הכל:\n- תהליך 100: התהליך הראשי.\n- תהליך 101: נוצר על ידי 100 בשורה 9.\n- תהליך 102: נוצר על ידי 101 בשורה 10 (ב-fork הראשון).\n- תהליך 103: נוצר על ידי 102 בשורה 10 (ב-fork השני, מכיוון שה-fork הראשון החזיר 0 ל-102).\n- תהליך 104: נוצר על ידי 100 בשורה 15.\n\n2. כן, ייתכן. תהליך 100 מבצע waitpid עבור תהליך 104 בלבד. הוא אינו ממתין לסיום של תהליך 101 או צאצאיו (102, 103). לכן, אם תהליך 104 יסיים את פעולתו (ה-ls יסתיים) ותהליך 100 ימשיך להדפסה בשורה 22 לפני שתהליך 101 יספיק להגיע להדפסה בשורה 11, 'D100' יודפס לפני 'T101'.\n\n3. אם execlp נכשל, התהליך (104) לא מוחלף וממשיך לשורה הבאה בקוד. ההדפסות שיופיעו הן:\n- P100 (מהתהליך הראשי בתחילת הריצה).\n- T101 (מתהליך 101, שעובר את תנאי ה-OR בגלל short-circuit).\n- T102 (מתהליך 102, שמבצע את ה-fork השני בתנאי ה-OR).\n- E104 (מתהליך 104, המדפיס הודעת שגיאה לאחר כישלון ה-exec).\n- D100 (מתהליך 100, לאחר שסיים להמתין ל-104)."}, "difficulty_estimation": "Hard", "_source_file": "0069__Processes__CodeAnalysis__Hard.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:30:46", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Processes", "System Calls", "Fork Logic", "Process Tree"], "content": {"text": "נתונה התוכנית הבאה בשפת C. הניחו כי כל קריאות המערכת מצליחות, וכי מזהה התהליך (PID) של התהליך המריץ את main הוא 1000. כל תהליך חדש שנוצר במערכת מקבל PID הגדול ב-1 מה-PID האחרון שניתן. הניחו כי אין תהליכים אחרים שנוצרים במערכת בזמן הריצה. ענו על הסעיפים הבאים.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    int x = 5;\n    pid_t p1, p2;\n\n    p1 = fork();\n    if (p1 > 0) {\n        // Parent block\n        x += 2;\n        if (fork() == 0) {\n            x *= 2;\n            printf(\"Node A: x=%d, PID=%d, PPID=%d\\n\", x, getpid(), getppid());\n            exit(0);\n        }\n        wait(NULL);\n    } else if (p1 == 0) {\n        // Child block\n        x -= 2;\n        p2 = fork();\n        if (p2 > 0) {\n            wait(NULL);\n            x += 10;\n        } else {\n            x += 5;\n            printf(\"Node B: x=%d, PID=%d, PPID=%d\\n\", x, getpid(), getppid());\n            exit(0);\n        }\n        printf(\"Node C: x=%d, PID=%d, PPID=%d\\n\", x, getpid(), getppid());\n        exit(0);\n    }\n\n    wait(NULL);\n    printf(\"Node D: x=%d, PID=%d\\n\", x, getpid());\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "101.1", "text": "ציירו את עץ התהליכים שנוצר במהלך ריצת התוכנית. עבור כל תהליך בעץ ציינו את ה-PID שלו ואת ה-PPID שלו.", "code_snippet": null, "options": null}, {"id": "101.2", "text": "מהו הפלט המלא של התוכנית? במידה וישנם מספר פלטים אפשריים בשל חוסר דטרמיניזם בתזמון, ציינו את כולם או הסבירו את סדר ההדפסה.", "code_snippet": null, "options": null}, {"id": "101.3", "text": "כמה פעמים תודפס המילה \"Node\" בסך הכל?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ניתוח זרימת התוכנית:\n1. תהליך 1000 (P1000) מבצע fork ראשון. נוצר תהליך 1001.\n2. P1000 (הורה): x הופך ל-7. הוא מבצע fork נוסף ויוצר את 1002. \n   - תהליך 1002 (בן של 1000): x הופך ל-14 (7*2). מדפיס 'Node A: x=14, PID=1002, PPID=1000' ויוצא.\n   - P1000 מחכה ל-1002, ואז מחכה ל-1001 (בסוף), ומדפיס 'Node D: x=7, PID=1000'.\n3. תהליך 1001 (בן של 1000): x הופך ל-3. הוא מבצע fork ויוצר את 1003.\n   - תהליך 1003 (בן של 1001): x הופך ל-8 (3+5). מדפיס 'Node B: x=8, PID=1003, PPID=1001' ויוצא.\n   - תהליך 1001 מחכה ל-1003, מעדכן את x ל-13 (3+10), מדפיס 'Node C: x=13, PID=1001, PPID=1000' ויוצא.\n\nסדר הדפסה אפשרי:\nהסדר בין Node A לבין Node B/C תלוי במתזמן, אך Node D תמיד יהיה אחרון עבור P1000. Node C חייב לבוא אחרי Node B. Node A חייב לבוא לפני Node D.\nפלט לדוגמה:\nNode B: x=8, PID=1003, PPID=1001\nNode C: x=13, PID=1001, PPID=1000\nNode A: x=14, PID=1002, PPID=1000\nNode D: x=7, PID=1000\n\nסה\"כ הדפסות של Node: 4 פעמים."}, "difficulty_estimation": "Hard", "_source_file": "0070__Processes__CodeAnalysis__Hard.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:31:06", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Processes", "System Calls", "Buffering", "Fork"], "content": {"text": "נתונה התוכנית הבאה בשפת C. הניחו שכל קריאות המערכת מצליחות, ושכל תהליך שנוצר מסיים את ריצתו כראוי.\nתזכורת: פונקציית printf משתמשת בחוצץ (buffer) עבור הפלט הסטנדרטי. במידה ואין תו ירידת שורה (\\n), החוצץ מועבר בשלמותו לתהליכי בנים בעת ביצוע fork ומתרוקן רק בסיום התהליך או בעת קריאה ל-fflush.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    printf(\"Start\");\n    if (fork() || fork()) {\n        if (!fork()) {\n            printf(\"1\");\n            exit(0);\n        }\n    } else {\n        printf(\"2\");\n    }\n    while(wait(NULL) > 0);\n    printf(\"End\");\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "כמה תהליכים סה\"כ נוצרו במהלך ריצת התוכנית (כולל התהליך הראשי)?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "רשמו פלט אפשרי אחד של התוכנית והסבירו כיצד מנגנון ה-buffering משפיע על הופעת המילה \"Start\" בפלט.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "כיצד ישתנה מספר הפעמים שהמילה \"Start\" מופיעה בפלט אם נוסיף n\\ לאחר המילה \"Start\" בשורה 7?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: נוצרו 5 תהליכים סה\"כ. תהליך האב P0 יוצר את P1 ב-fork הראשון. P0 נכנס ל-if (בגלל short-circuit). P1 ממשיך ל-fork השני ויוצר את P2. P1 נכנס ל-if ו-P2 נכנס ל-else. בתוך ה-if, תהליך P0 יוצר את P3 ותהליך P1 יוצר את P4.\n\n1.2: פלט אפשרי: Start1Start1Start2EndStartEndStartEnd (הסדר בין התהליכים יכול להשתנות). הסבר: המילה Start נכנסת ל-buffer של P0. כיוון שאין n\\, היא לא מודפסת מיד. כל תהליך שנוצר ב-fork יורש את תוכן ה-buffer. לכן, כל אחד מ-5 התהליכים מחזיק ב-Start ב-buffer שלו ומדפיס אותו בסיום או בתוספת לפלט אחר. P3 ו-P4 מדפיסים Start1, תהליך P2 מדפיס Start2End, ותהליכים P0 ו-P1 מדפיסים StartEnd.\n\n1.3: אם נוסיף n\\, ה-buffer יתרוקן מיד בשורה 7. לכן המילה Start תודפס פעם אחת בלבד על ידי P0 לפני ה-fork הראשון, והבנים יירשו buffer ריק. המילה Start תופיע פעם אחת בלבד בכל הפלט."}, "difficulty_estimation": "Hard", "_source_file": "0071__Processes__CodeAnalysis__Hard.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:31:33", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Processes", "System Calls", "fork", "Short-circuit Evaluation"], "content": {"text": "נתונה התוכנית הבאה בשפת C. הניחו שכל קריאות המערכת מצליחות, אין תהליכים נוספים במערכת שמשפיעים על הריצה, וכל הדפסה מתבצעת באופן מיידי ללא חוצץ (buffer).", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 0;\n    if (fork() || fork()) {\n        x++;\n        if (!fork()) {\n            x += 2;\n        }\n    } else {\n        x--;\n    }\n    while(wait(NULL) > 0);\n    printf(\"%d \", x);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "כמה תהליכים נוצרו בסך הכל במהלך ריצת התוכנית (כולל התהליך הראשי)? הציגו את עץ התהליכים.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "מהם כל הערכים האפשריים שיוצגו כפלט של התוכנית? הסבירו אילו תהליכים מדפיסים אילו ערכים.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "נניח ונחליף את האופרטור || בשורה 6 באופרטור &&. כמה תהליכים ייווצרו כעת במערכת (כולל התהליך הראשי)?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. סך הכל נוצרו 5 תהליכים:\n- תהליך אב (P1) מבצע fork ראשון. הוא מקבל ערך חיובי ולכן בגלל short-circuit של || הוא לא מבצע את ה-fork השני ונכנס לבלוק ה-if.\n- הבן הראשון (P2) מקבל 0 מה-fork הראשון, ולכן חייב לבצע את ה-fork השני. הוא יוצר את P3.\n- P2 מקבל ערך חיובי מה-fork השני ונכנס לבלוק ה-if.\n- P3 מקבל 0 מה-fork השני ונכנס לבלוק ה-else.\n- בתוך בלוק ה-if, תהליכים P1 ו-P2 מבצעים fork נוסף (P4 ו-P5 בהתאמה). סך הכל 5 תהליכים.\n\n2. הערכים המודפסים הם 1, 1, 3, 3, 1-:\n- P1 ו-P2: מקדמים את x ל-1. ב-fork הפנימי האבא (P1/P2) מקבל PID ולכן ה-if הפנימי לא מתקיים עבורו. הם מדפיסים 1.\n- P4 ו-P5 (הבנים של ה-fork הפנימי): יורשים x=1, נכנסים ל-if הפנימי ומבצעים x += 2. הם מדפיסים 3.\n- P3: נכנס ל-else ומבצע x--. הוא מדפיס 1-.\n\n3. אם נחליף ל-&&, ייווצרו 4 תהליכים:\n- P1 מבצע fork ראשון (P2). P1 ממשיך ל-fork שני (P3). P2 נכשל בתנאי (קיבל 0) ועובר ל-else.\n- P1 מצליח בשני ה-forks ונכנס ל-if. P3 נכשל בתנאי (קיבל 0 ב-fork השני) ועובר ל-else.\n- בתוך ה-if, רק P1 מבצע fork נוסף (P4).\n- סך הכל: P1, P2, P3, P4."}, "difficulty_estimation": "Hard", "_source_file": "0072__Processes__CodeAnalysis__Hard.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:31:51", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Threads", "Memory Management"], "content": {"text": "איזה מהמשאבים הבאים משותף (shared) לכל החוטים (threads) השייכים לאותו תהליך?", "code_snippet": null, "options": ["א. המחסנית (Stack)", "ב. משתנים גלובליים ומרחב הכתובות (Global Variables / Address Space)", "ג. אוגרי המעבד (CPU Registers)", "ד. מונה התוכנית (Program Counter)"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "חוטים בתוך אותו תהליך חולקים את אותו מרחב כתובות, הכולל את קטע הנתונים (משתנים גלובליים) והערימה (Heap). לעומת זאת, לכל חוט יש מחסנית (Stack), אוגרים ומונה תוכנית (PC) משלו, המהווים את ההקשר (Context) הייחודי שלו."}, "difficulty_estimation": "Easy", "_source_file": "0073__Threads__MultipleChoice__Easy.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:31:58", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Threads", "Memory Management"], "content": {"text": "איזה מבין המשאבים הבאים משותף לכל החוטים (threads) השייכים לאותו תהליך?", "code_snippet": null, "options": ["א. מחסנית (Stack)", "ב. מונה התוכנית (Program Counter)", "ג. משתנים גלובליים ומרחב הכתובות", "ד. קובץ האוגרים (Register set)"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "חוטים באותו תהליך חולקים את מרחב הכתובות של התהליך, הכולל את קטע הקוד (Code segment) ואת קטע הנתונים (Data segment) שבו נמצאים המשתנים הגלובליים. לעומת זאת, לכל חוט יש הקשר הרצה (execution context) ייחודי הכולל מחסנית משלו, מונה תוכנית משלו וסט אוגרים משלו."}, "difficulty_estimation": "Easy", "_source_file": "0074__Threads__MultipleChoice__Easy.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:32:09", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Threads", "Memory Management"], "content": {"text": "איזה מהמשאבים הבאים משותף (Shared) לכל החוטים (threads) השייכים לאותו תהליך?", "code_snippet": null, "options": ["א. המחסנית (Stack)", "ב. אוגרי המעבד (Registers)", "ג. מונה הפקודות (Program Counter)", "ד. מרחב הכתובות הגלובלי והערימה (Heap)", "ה. אף אחת מהתשובות אינה נכונה"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "חוטים (threads) בתוך אותו תהליך חולקים את מרחב הכתובות של התהליך, הכולל את קטע הקוד, המשתנים הגלובליים והערימה (Heap). לעומת זאת, לכל חוט יש משאבים פרטיים משלו ההכרחיים לניהול זרימת הריצה העצמאית שלו: מחסנית (Stack) עבור משתנים לוקאליים וקריאות לפונקציות, אוגרים (Registers) ומונה פקודות (PC)."}, "difficulty_estimation": "Easy", "_source_file": "0075__Threads__MultipleChoice__Easy.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:32:18", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Threads", "Memory Management"], "content": {"text": "איזה מהמשאבים הבאים משותף (Shared) בדרך כלל בין חוטים (threads) שונים השייכים לאותו תהליך?", "code_snippet": null, "options": ["א. מחסנית (Stack)", "ב. אוגרי המעבד (Registers)", "ג. מרחב הכתובות (Address Space) ומשתנים גלובליים", "ד. מונה הפקודות (Program Counter)", "ה. אף אחת מהתשובות אינה נכונה"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "חוטים השייכים לאותו תהליך חולקים את מרחב הכתובות של התהליך, הכולל את קטע הקוד (Code), המשתנים הגלובליים (Data) והערימה (Heap). לעומת זאת, לכל חוט יש הקשר ריצה (Execution Context) נפרד הכולל מחסנית משלו, אוגרים משלו ומונה פקודות (PC) משלו כדי לאפשר הרצה עצמאית."}, "difficulty_estimation": "Easy", "_source_file": "0076__Threads__MultipleChoice__Easy.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:32:26", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Threads", "Memory Management"], "content": {"text": "מה מהבאים משותף לכל החוטים (threads) השייכים לאותו תהליך?", "code_snippet": null, "options": ["א. המחסנית (Stack)", "ב. אוגרי המעבד (Registers)", "ג. מונה הפקודות (Program Counter)", "ד. מרחב הכתובות ומשתנים גלובליים", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "חוטים באותו תהליך חולקים את מרחב הכתובות, קוד, נתונים (משתנים גלובליים) ומשאבי מערכת כמו קבצים פתוחים. לעומת זאת, לכל חוט יש הקשר ריצה פרטי הכולל מחסנית, אוגרים ומונה פקודות (PC) משלו."}, "difficulty_estimation": "Easy", "_source_file": "0077__Threads__MultipleChoice__Easy.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:32:34", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Threads", "Memory Management"], "content": {"text": "בהינתן קוד C המשתמש בספריית pthreads, איזה מהמשתנים הבאים משותף (shared) ונגיש גם לחוט החישוב הראשי (main thread) וגם לחוט החדש שנוצר?", "code_snippet": "int x = 10;\n\nvoid* my_func(void* arg) {\n    int y = 20;\n    x++;\n    return NULL;\n}\n\nint main() {\n    pthread_t tid;\n    pthread_create(&tid, NULL, my_func, NULL);\n    // ... code ...\n    return 0;\n}", "options": ["א. המשתנה x בלבד", "ב. המשתנה y בלבד", "ג. גם x וגם y", "ד. אף אחד מהמשתנים אינו משותף"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "המשתנה x הוא משתנה גלובלי, ולכן הוא נמצא במקטע הנתונים (Data Segment) המשותף לכל החוטים (threads) באותו תהליך. לעומת זאת, המשתנה y הוא משתנה מקומי המוגדר בתוך פונקציית החוט, ולכן הוא מוקצה על המחסנית (Stack) הפרטית של החוט ואינו משותף לחוטים אחרים."}, "difficulty_estimation": "Easy", "_source_file": "0078__Threads__MultipleChoice__Easy.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:32:47", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Threads", "Memory Management"], "content": {"text": "כאשר מספר חוטים (threads) רצים בתוך אותו תהליך (process), מה מהבאים משותף לכל החוטים?", "code_snippet": null, "options": ["א. המחסנית (Stack) הפרטית של כל חוט.", "ב. ערימת הזיכרון (Heap) והמשתנים הגלובליים.", "ג. אוגרי המעבד (Registers).", "ד. מונה התוכנית (Program Counter)."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "בתוך תהליך, כל החוטים חולקים את אותו מרחב כתובות, הכולל את ה-Heap והמשתנים הגלובליים. לעומת זאת, לכל חוט יש Stack, Registers ו-Program Counter משלו כדי לאפשר הרצה עצמאית של קוד."}, "difficulty_estimation": "Easy", "_source_file": "0079__Threads__MultipleChoice__Easy.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:32:53", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Threads", "Memory Management"], "content": {"text": "איזה מהמשאבים הבאים **אינו** משותף בין חוטי חישוב (threads) השייכים לאותו תהליך?", "code_snippet": null, "options": ["א. משתנים גלובליים (Global variables)", "ב. זיכרון הערימה (Heap memory)", "ג. קוד התוכנית (Code segment)", "ד. המחסנית (Stack)", "ה. כל התשובות האחרות משותפות בין חוטי החישוב"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "לכל חוט חישוב (thread) יש מחסנית (Stack) פרטית משלו וסט רגיסטרים משלו (כולל Program Counter), זאת על מנת לאפשר לכל חוט לנהל את זרימת הפונקציות והמשתנים המקומיים שלו באופן עצמאי. לעומת זאת, חוטי חישוב באותו תהליך חולקים את מרחב הכתובות הכולל את קטע הקוד, הנתונים הגלובליים והערימה."}, "difficulty_estimation": "Easy", "_source_file": "0080__Threads__MultipleChoice__Easy.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:33:00", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Threads", "Concurrency", "Race Conditions"], "content": {"text": "נתונה התוכנית הבאה בשפת C המשתמשת בספריית pthreads. התוכנית יוצרת 10 חוטים (threads), כאשר כל חוט מבצע לולאה המקדמת משתנה גלובלי משותף counter ב-1, כמיליון פעמים. בסיום ריצת כל החוטים, התוכנית מדפיסה את ערכו של counter. מה ניתן לומר על פלט התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint counter = 0;\n\nvoid* thread_func(void* arg) {\n    for (int i = 0; i < 1000000; i++) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[10];\n    for (int i = 0; i < 10; i++) {\n        pthread_create(&threads[i], NULL, thread_func, NULL);\n    }\n    for (int i = 0; i < 10; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    printf(\"%d\\n\", counter);\n    return 0;\n}", "options": ["א. התוכנית תמיד תדפיס 10,000,000.", "ב. התוכנית תדפיס ערך קטן מ-10,000,000 או שווה לו, בשל היעדר סנכרון (Race Condition).", "ג. התוכנית תגרום לשגיאת הרצה (Segmentation Fault) כיוון שחוטים שונים ניגשים לאותו זיכרון בו-זמנית.", "ד. התוכנית תמיד תדפיס 1,000,000 כי המשתנה counter הוא מקומי לכל חוט (Thread Local Storage).", "ה. התוכנית לא תתקמפל כי לא ניתן להשתמש במשתנה גלובלי משותף בתוך פונקציית חוט ללא מילת המפתח volatile."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הפעולה ++counter ברמת שפת C אינה פעולה אטומית (Atomic Operation). ברמת האסמבלי, היא מורכבת בדרך כלל משלוש פקודות: קריאת הערך מהזיכרון לרגיסטר, הוספת 1 לרגיסטר, וכתיבת הערך חזרה לזיכרון. ללא שימוש במנגנוני סנכרון כמו Mutex, ייתכן מצב שבו שני חוטים קוראים את אותו הערך לפני שאחד מהם הספיק לעדכן אותו (Context Switch ביניהם), מה שמוביל לאובדן עדכונים ולערך סופי נמוך מהצפוי (Race Condition). תיאורטית הערך יכול להיות 10,000,000 אם לא התרחש שום מירוץ, אך במערכת מרובת ליבות זה כמעט בלתי אפשרי."}, "difficulty_estimation": "Medium", "_source_file": "0081__Threads__MultipleChoice__Medium.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:33:15", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Threads", "Concurrency", "Memory Layout"], "content": {"text": "נתון הקוד הבא בשפת C, המריץ שני חוטים (threads) המבצעים את אותה הפונקציה. בהנחה שהמערכת מריצה את החוטים במקביל על מעבד מרובה ליבות וללא סנכרון חיצוני, איזו מהטענות הבאות היא הנכונה ביותר לגבי תוצאת ההרצה?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint shared_var = 0;\n\nvoid* increment_task(void* arg) {\n    static int func_static = 0;\n    for (int i = 0; i < 100; i++) {\n        shared_var++;\n        func_static++;\n    }\n    return (void*)(long)func_static;\n}\n\nint main() {\n    pthread_t t1, t2;\n    void *res1, *res2;\n    pthread_create(&t1, NULL, increment_task, NULL);\n    pthread_create(&t2, NULL, increment_task, NULL);\n    pthread_join(t1, &res1);\n    pthread_join(t2, &res2);\n    printf(\"%d, %ld, %ld\\n\", shared_var, (long)res1, (long)res2);\n    return 0;\n}", "options": ["א. הערך של shared_var יהיה בדיוק 200, וערכי ההחזר res1 ו-res2 יהיו 100 ו-200 (בסדר כלשהו).", "ב. הערך של shared_var עשוי להיות קטן מ-200 עקב Race Condition, אך המשתנה func_static הוא מקומי לכל חוט ולכן ערכי ההחזר יהיו תמיד 100.", "ג. המשתנה func_static משותף לשני החוטים, ולכן גם shared_var וגם ערכי ההחזר res1 ו-res2 עשויים להיות מושפעים מ-Race Condition.", "ד. הקוד יגרום לשגיאת הרצה (Runtime Error) כיוון ששני חוטים מנסים לגשת למשתנה static בו-זמנית.", "ה. המשתנה func_static מאותחל מחדש ל-0 בכל פעם שחוט חדש מתחיל את הפונקציה, לכן התוצאה הסופית של shared_var תהיה 200."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "במשתני static המוגדרים בתוך פונקציה, בדומה למשתנים גלובליים, קיים רק עותק אחד בזיכרון המשותף לכל החוטים באותו תהליך (הם מאוחסנים ב-Data Segment). מכיוון ששני החוטים מקדמים את shared_var ואת func_static ללא מנגנון סנכרון (כמו Mutex), שניהם חשופים לבעיית מרוץ (Race Condition). לכן, לא ניתן להבטיח ש-shared_var יגיע ל-200, וערכי ההחזר (שמייצגים את מצב func_static ברגע סיום החוט) אינם מובטחים להיות 100 או 200."}, "difficulty_estimation": "Medium", "_source_file": "0082__Threads__MultipleChoice__Medium.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:33:32", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Threads", "Concurrency", "Race Conditions"], "content": {"text": "בקטע הקוד הבא ב-C, מתכנת מנסה ליצור 5 חוטים (threads) שכל אחד מהם ידפיס את המספר הסידורי שבו הוא נוצר (0 עד 4). מה ניתן לומר על פלט התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nvoid* thread_func(void* arg) {\n    int id = *(int*)arg;\n    printf(\"%d \", id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[5];\n    for (int i = 0; i < 5; i++) {\n        pthread_create(&threads[i], NULL, thread_func, &i);\n    }\n    for (int i = 0; i < 5; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    return 0;\n}", "options": ["א. התוכנית תמיד תדפיס את המספרים 0, 1, 2, 3, 4 לפי הסדר.", "ב. התוכנית תדפיס את המספרים 0, 1, 2, 3, 4 בסדר כלשהו (פרמוטציה), וכל מספר יופיע בדיוק פעם אחת.", "ג. ייתכן שחלק מהערכים יודפסו מספר פעמים וערכים אחרים לא יודפסו כלל, שכן כל החוטים ניגשים לאותה כתובת זיכרון של המשתנה i.", "ד. התוכנית תמיד תדפיס '5 5 5 5 5' כיוון שהלולאה ב-main מסתיימת תמיד לפני שהחוטים מתחילים לרוץ.", "ה. תתרחש שגיאת הידור (Compilation Error) כי לא ניתן להעביר מצביע למשתנה מקומי i לפונקציית החוט."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הבעיה בקוד היא העברת הכתובת של המשתנה הלוקאלי i (באמצעות i&) לכל החוטים. כל החוטים מקבלים מצביע לאותו מיקום בזיכרון. כיוון שה-main thread ממשיך לקדם את i בלולאה בזמן שהחוטים נוצרים ומתחילים את ריצתם, נוצר Race Condition: עד שחוט מסוים ניגש לזיכרון כדי לקרוא את הערך של id, הערך של i כבר עשוי להשתנות על ידי ה-main thread. לכן, ייתכן שחוטים שונים יקראו את אותו הערך (למשל, כולם יקראו 5 אם הלולאה הסתיימה מהר), וערכים מסוימים לא יודפסו כלל."}, "difficulty_estimation": "Medium", "_source_file": "0083__Threads__MultipleChoice__Medium.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:33:47", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Threads", "Concurrency", "Memory Management"], "content": {"text": "נתונה תוכנית C המשתמשת בספריית pthreads ליצירת 5 חוטים (threads). המטרה היא שכל חוט ידפיס את המספר הסידורי שלו (0 עד 4). מה מהבאים מתאר נכונה את התנהגות התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nvoid* thread_func(void* arg) {\n    int val = *((int*)arg);\n    printf(\"%d \", val);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[5];\n    for (int i = 0; i < 5; i++) {\n        pthread_create(&threads[i], NULL, thread_func, &i);\n    }\n    for (int i = 0; i < 5; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    return 0;\n}", "options": ["א. התוכנית תמיד תדפיס את המספרים 0 עד 4 בסדר עולה (0 1 2 3 4).", "ב. התוכנית תמיד תדפיס את המספרים 0 עד 4, אך הסדר עשוי להשתנות בהתאם לתזמון.", "ג. התוכנית עלולה להדפיס מספרים שאינם בטווח 0-5 עקב גישה לזיכרון שאינו מאותחל.", "ד. התוכנית עלולה להדפיס את אותו מספר מספר פעמים (למשל 5 5 5 5 5), כיוון שכל החוטים ניגשים לאותה כתובת זיכרון שערכה משתנה בחוט הראשי.", "ה. התוכנית לא תתקמפל כי לא ניתן להעביר מצביע למשתנה מקומי (i) כארגומנט לחוט."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "הבעיה בתוכנית היא Race Condition על המשתנה i. הפונקציה pthread_create מקבלת מצביע לכתובת הזיכרון של i. כיוון שהחוט הראשי ממשיך לרוץ ולעדכן את i בלולאה, וכל החוטים שנוצרו ניגשים לאותה כתובת זיכרון, ייתכן שעד שחוט מסוים יתחיל לרוץ ויבצע את ה-dereference למצביע, הערך של i כבר השתנה ע\"י החוט הראשי (למשל ל-5 בסיום הלולאה). לכן, ייתכן שיוצגו ערכים כפולים או ערכים שאינם תואמים את הציפייה המקורית."}, "difficulty_estimation": "Medium", "_source_file": "0084__Threads__MultipleChoice__Medium.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:34:04", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Threads", "Concurrency", "Memory Management"], "content": {"text": "נתון קוד ה-C הבא המשתמש בספריית pthreads. מה מהבאים מתאר נכונה את הפלט הצפוי של התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nvoid* thread_func(void* arg) {\n    int* id = (int*)arg;\n    printf(\"%d \", *id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[5];\n    for (int i = 0; i < 5; i++) {\n        pthread_create(&threads[i], NULL, thread_func, &i);\n    }\n    for (int i = 0; i < 5; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    return 0;\n}", "options": ["א. התוכנית תמיד תדפיס את המספרים 0 עד 4 בסדר עולה (0 1 2 3 4).", "ב. התוכנית תמיד תדפיס את המספרים 0 עד 4 בסדר כלשהו.", "ג. התוכנית תמיד תדפיס את המספר 5 חמש פעמים.", "ד. התוכנית עלולה להדפיס מספרים בטווח 0-5, כאשר ייתכן שמספר מסוים יודפס יותר מפעם אחת.", "ה. תתרחש שגיאת הידור (Compilation Error) כי לא ניתן להעביר כתובת של משתנה מקומי לפונקציית החוט."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "הבעיה בקוד היא שכל החוטים (threads) מקבלים מצביע לאותו מיקום בזיכרון - המשתנה המקומי i שנמצא על המחסנית של פונקציית main. כיוון שהחוטים רצים במקביל ללולאת היצירה, ייתכן שערכו של i ישתנה על ידי ה-main thread לפני שחוט מסוים יספיק לקרוא אותו ולהדפיסו. בסיום הלולאה הראשונה i מגיע לערך 5. לכן, הפלט תלוי בתזמון (Race Condition): ייתכן שחלק מהחוטים ידפיסו ערכים ישנים של i, חלק ידפיסו את הערך הנוכחי, וחלק ידפיסו 5 אם הם ירוצו רק לאחר שהלולאה הסתיימה."}, "difficulty_estimation": "Medium", "_source_file": "0085__Threads__MultipleChoice__Medium.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:34:22", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Threads", "Concurrency", "Pthreads", "Race Conditions"], "content": {"text": "לפניך קוד בשפת C המשתמש בספריית pthreads ליצירת 5 חוטים (threads). מה מהבאים מתאר נכונה את ההתנהגות הצפויה של התוכנית בעת הרצתה?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nvoid* thread_func(void* arg) {\n    int val = *(int*)arg;\n    printf(\"%d \", val);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[5];\n    for (int i = 0; i < 5; i++) {\n        pthread_create(&threads[i], NULL, thread_func, &i);\n    }\n    for (int i = 0; i < 5; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    return 0;\n}", "options": ["א. התוכנית תדפיס תמיד את המספרים 0 1 2 3 4 בסדר זה בדיוק.", "ב. התוכנית תדפיס תמיד את המספרים 0 עד 4, אך בסדר שאינו ידוע מראש (פרמוטציה של המספרים).", "ג. ייתכן שחלק מהמספרים יודפסו יותר מפעם אחת, חלק לא יודפסו כלל, וייתכן אף שהמספר 5 יודפס.", "ד. התוכנית תגרום לשגיאת גישה לזיכרון (Segmentation Fault) כיוון שהמשתנה i הוא מקומי לפונקציית main.", "ה. התוכנית לא תעבור קומפילציה כיוון שלא ניתן להעביר את הכתובת של i כארגומנט מסוג void*."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הבעיה בקוד היא מרוץ תהליכים (Race Condition) על המשתנה i. כל חמשת החוטים מקבלים את אותה הכתובת בזיכרון (הכתובת של המשתנה i ב-stack של main). מכיוון שחוט ה-main ממשיך לקדם את i בלולאה בזמן שהחוטים החדשים נוצרים ומתחילים לרוץ, ייתכן שחוט מסוים יקרא את הערך של i רק אחרי שהוא כבר קודם מספר פעמים על ידי ה-main. לכן, ייתכן ששני חוטים יקראו את אותו ערך, או שחוט יקרא את הערך 5 (תנאי העצירה של הלולאה) לפני שהתוכנית תסתיים. הפלט אינו דטרמיניסטי ותלוי בתזמון המעבד."}, "difficulty_estimation": "Medium", "_source_file": "0086__Threads__MultipleChoice__Medium.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:34:35", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Threads", "Concurrency", "Race Condition"], "content": {"text": "נתון הקוד הבא הכתוב בשפת C ומשתמש בספריית pthreads. מה מהבאים מתאר נכונה את התנהגות התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint global_sum = 0;\n\nvoid* thread_func(void* arg) {\n    int val = *(int*)arg;\n    for (int i = 0; i < 1000; i++) {\n        global_sum += val;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[2];\n    for (int i = 1; i <= 2; i++) {\n        pthread_create(&threads[i-1], NULL, thread_func, &i);\n    }\n    for (int i = 0; i < 2; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    printf(\"%d\\n\", global_sum);\n    return 0;\n}", "options": ["א. התוכנית תמיד תדפיס 3000, מכיוון שהלולאה הראשונה רצה עבור i=1 ו-i=2.", "ב. התוכנית תדפיס ערך שבין 1000 ל-3000, אך הערך יהיה תמיד כפולה של 1000.", "ג. הפלט עשוי להיות שונה מ-3000 גם בשל Race Condition על global_sum וגם בשל העברת מצביע למשתנה הלוקאלי i שערכו משתנה ב-main.", "ד. התוכנית תגרום לשגיאת סגמנטציה (Segmentation Fault) כיוון שחוטי המשנה מנסים לגשת לזיכרון של המחסנית של חוט ה-main.", "ה. התוכנית תדפיס תמיד 3000, שכן pthread_join מבצע סנכרון (Memory Barrier) שמבטיח את תקינות הערך של global_sum."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התשובה הנכונה היא ג'. ישנן שתי בעיות סנכרון עיקריות בקוד: 1. Race Condition על המשתנה הגלובלי: הפעולה global_sum += val אינה אטומית. כאשר שני חוטים מנסים לעדכן את המשתנה בו-זמנית, עדכונים עלולים ללכת לאיבוד. 2. Argument Race: הכתובת של המשתנה i מועברת לחוטים. כיוון ש-i משתנה בלולאה ב-main בזמן שהחוטים נוצרים, ייתכן שחוט יקרא את הערך של i מהזיכרון רק לאחר ש-main כבר קידם אותו (למשל ל-2 או ל-3), ולכן val בתוך החוט לא יהיה בהכרח הערך המיועד (1 או 2)."}, "difficulty_estimation": "Medium", "_source_file": "0087__Threads__MultipleChoice__Medium.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:34:56", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Threads", "Concurrency", "Race Conditions"], "content": {"text": "לפניכם קוד בשפת C המשתמש בספריית pthreads. מה ניתן לומר על הפלט של התוכנית בהנחה שהקומפילציה והרצת התהליכונים הצליחו?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nvoid* task(void* arg) {\n    int* val = (int*)arg;\n    for (int i = 0; i < 100; i++) {\n        (*val)++;\n    }\n    return NULL;\n}\n\nint main() {\n    int shared_val = 0;\n    pthread_t threads[10];\n    for (int i = 0; i < 10; i++) {\n        pthread_create(&threads[i], NULL, task, &shared_val);\n    }\n    for (int i = 0; i < 10; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    printf(\"%d\", shared_val);\n    return 0;\n}", "options": ["א. הפלט יהיה תמיד 1000.", "ב. הפלט עשוי להיות קטן מ-1000 עקב מרוץ תהליכונים (Race Condition).", "ג. התוכנית תגרום לשגיאת פילוח (Segmentation Fault) בשל גישה מקבילית של תהליכונים שונים לאותו משתנה מקומי.", "ד. הפלט יהיה תמיד 100, כיוון שכל תהליכון מבצע בדיוק 100 איטרציות ודורס את תוצאות קודמיו.", "ה. הקוד לא יעבור קומפילציה כיוון שהפונקציה pthread_create דורשת העברת משתנה גלובלי בלבד כארגומנט."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הפעולה ++(*val) אינה אטומית. היא מורכבת משלושה שלבים ברמת המכונה: טעינת הערך מהזיכרון לרגיסטר, קידום הערך ברגיסטר, וכתיבת הערך המעודכן חזרה לזיכרון. כאשר מספר תהליכונים ניגשים לאותו משתנה ללא סנכרון (כמו Mutex), תהליכון אחד עלול לקרוא ערך 'ישן' בזמן שתהליכון אחר מעדכן אותו, ובכך לגרום לאובדן עדכונים (Race Condition). לכן, התוצאה הסופית עשויה להיות נמוכה מ-1000. שימוש בכתובת של משתנה מקומי מתוך main הוא תקין במקרה זה כי main ממתינה לסיום התהליכונים בעזרת pthread_join לפני שהיא מסיימת את ריצתה ומפנה את המחסנית."}, "difficulty_estimation": "Medium", "_source_file": "0088__Threads__MultipleChoice__Medium.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:35:19", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Threads", "Race Conditions", "Pthreads", "Memory Management"], "content": {"text": "נתון קוד ה-C הבא המשתמש בספריית pthreads. מה ניתן לומר על פלט התוכנית בסיום ריצתה?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint global_val = 0;\n\nvoid* thread_func(void* arg) {\n    int thread_id = *(int*)arg;\n    global_val += thread_id;\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[3];\n    for (int i = 1; i <= 3; i++) {\n        pthread_create(&threads[i-1], NULL, thread_func, &i);\n    }\n    for (int i = 0; i < 3; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    printf(\"%d\\n\", global_val);\n    return 0;\n}", "options": ["א. הפלט יהיה תמיד 6 (הסכום של 1, 2 ו-3).", "ב. הפלט יהיה תמיד 12 (הערך 4 כפול 3 שרשורים).", "ג. הפלט אינו דטרמיניסטי; הוא עשוי להשתנות בין הרצות שונות עקב גישה לאותה כתובת זיכרון ותחרות על משתנה גלובלי.", "ד. התוכנית תגרום לשגיאת זמן ריצה (Runtime Error) כיוון שלא ניתן לגשת למשתנה מקומי של main מתוך שרשור.", "ה. הפלט יהיה תמיד 0 כיוון שהשינויים בשרשורים מתבצעים על עותק מקומי של global_val."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התשובה הנכונה היא ג'. קיימות כאן שתי בעיות קריטיות: 1. ה-Main thread מעביר לכל השרשורים מצביע (&i) לאותו מיקום בזיכרון שבו נמצא משתנה הלולאה. כיוון שהלולאה ממשיכה לרוץ במקביל להיווצרות השרשורים, עד שהשרשור יבצע dereference למצביע, הערך של i עשוי להשתנות (למשל ל-4). 2. קיימת תחרות (Race Condition) על המשתנה הגלובלי global_val; פעולת ה-increment (+=) אינה אטומית ברמת ה-CPU, וללא שימוש ב-Mutex, עדכונים של שרשורים שונים עלולים 'לדרוס' זה את זה."}, "difficulty_estimation": "Hard", "_source_file": "0089__Threads__MultipleChoice__Hard.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:35:34", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Threads", "Processes", "Synchronization", "fork"], "content": {"text": "נתון תהליך המריץ שני חוטים (Threads) של POSIX. חוט א' נועל Mutex גלובלי ומתחיל בביצוע חישוב ארוך. בזמן שחוט א' מחזיק בנעילה, חוט ב' מבצע קריאה למערכת (system call) מסוג fork(). איזו מהטענות הבאות מתארת נכונה את מצב התהליך הבן שנוצר?", "code_snippet": null, "options": ["א. בתהליך הבן ייווצרו שני חוטים המקבילים לחוטים בתהליך האב, וחוט א' בבן ימשיך להחזיק ב-Mutex.", "ב. בתהליך הבן יהיה קיים רק חוט אחד (העתק של חוט ב'), וה-Mutex יופיע במצב 'נעול' ללא חוט שיכול לשחרר אותו.", "ג. מערכת ההפעלה מזהה שה-Mutex נעול על ידי חוט שלא הועתק לבן, ולכן היא משחררת את ה-Mutex באופן אוטומטי בתהליך הבן.", "ד. הקריאה ל-fork() תחסום את חוט ב' עד שחוט א' ישחרר את ה-Mutex, כדי למנוע חוסר עקביות בזיכרון.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "לפי תקן POSIX, כאשר תהליך מרובה חוטים מבצע fork(), רק החוט שקרא ל-fork() מועתק לתהליך הבן. שאר החוטים אינם קיימים בבן. עם זאת, מרחב הכתובות מועתק כפי שהוא (במנגנון Copy-on-Write), כולל מצבם של אובייקטי סנכרון בזיכרון. לכן, אם Mutex היה נעול באב על ידי חוט שלא הועתק לבן, הוא יישאר נעול בבן לנצח (מצב של Deadlock פוטנציאלי), שכן החוט האחראי לשחרורו אינו קיים בבן."}, "difficulty_estimation": "Hard", "_source_file": "0090__Threads__MultipleChoice__Hard.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:35:58", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Threads", "Processes", "fork", "Synchronization"], "content": {"text": "נתון תהליך המכיל שלושה חוטים (threads) הפועלים במקביל במרחב המשתמש (POSIX threads). חוט א' נועל Mutex גלובלי ומתחיל בביצוע חישוב ארוך. לפני שחוט א' מספיק לשחרר את הנעילה, חוט ב' מבצע קריאה למערכת מסוג fork(). איזה מההיגדים הבאים מתאר בצורה המדויקת ביותר את מצב התהליך הבן (Child Process) שנוצר מיד לאחר הקריאה?", "code_snippet": null, "options": ["א. בתהליך הבן ייווצרו שלושה חוטים המקבילים לאלו שבמקור, וחוט א' בבן ימשיך להחזיק ב-Mutex.", "ב. בתהליך הבן ייווצר רק חוט אחד (העתק של חוט ב'), וה-Mutex יהיה במצב נעול (locked) מבלי שיהיה חוט קיים שיוכל לשחררו.", "ג. בתהליך הבן ייווצר רק חוט אחד (העתק של חוט ב'), ומערכת ההפעלה תזהה שהחוט שנעל את ה-Mutex אינו קיים ותשחרר את הנעילה אוטומטית.", "ד. הקריאה ל-fork() תיחסם על ידי מערכת ההפעלה עד שכל ה-Mutexes במרחב הכתובות ישוחררו על ידי החוטים המחזיקים בהם.", "ה. בתהליך הבן ייווצר רק חוט אחד (העתק של חוט ב'), וכל ה-Mutexes בזיכרון של הבן יאותחלו למצב פתוח (unlocked) כברירת מחדל."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "לפי תקן POSIX, כאשר תהליך מרובה חוטים קורא ל-fork(), רק החוט שביצע את הקריאה מועתק לתהליך הבן. שאר החוטים אינם קיימים בבן. עם זאת, מרחב הכתובות מועתק במלואו, כולל המצב של משתנים גלובליים ואובייקטי סנכרון (כמו Mutexes). מכיוון שה-Mutex הועתק כשהוא במצב 'נעול' והחוט שאמור לשחרר אותו (חוט א') לא הועתק לבן, ה-Mutex יישאר נעול לצמיתות בתוך התהליך הבן. מצב זה נחשב למסוכן ועלול להוביל ל-Deadlock בתהליך הבן."}, "difficulty_estimation": "Hard", "_source_file": "0091__Threads__MultipleChoice__Hard.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:36:13", "_subject": "Virtualization"}, {"id": 101, "type": "MultipleChoice", "topic": ["Threads", "Memory Management", "Pthreads", "Stack vs Heap"], "content": {"text": "שקלו את קטע הקוד הבא הכתוב בשפת C והמשתמש בספריית pthreads. נניח שהקריאה ל-pthread_create מצליחה והמערכת היא מערכת Linux סטנדרטית. מהי הקביעה המדויקת ביותר לגבי הרצת התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n\nvoid* task(void* arg) {\n    int* p = (int*)arg;\n    sleep(1);\n    printf(\"%d\\n\", *p);\n    return NULL;\n}\n\nvoid start_work() {\n    pthread_t t;\n    int local_val = 42;\n    pthread_create(&t, NULL, task, &local_val);\n    // No pthread_join here\n}\n\nint main() {\n    start_work();\n    sleep(2);\n    return 0;\n}", "options": ["א. יודפס תמיד הערך 42, מכיוון שחוטים חולקים את אותו מרחב כתובות והזיכרון נשאר תקף כל עוד התהליך רץ.", "ב. תתרחש בהכרח שגיאת Segmentation Fault מיד עם הניסיון לגשת למשתנה p, כיוון שלכל חוט יש מחסנית נפרדת וגישה למחסנית של חוט אחר חסומה על ידי ה-MMU.", "ג. התנהגות התוכנית אינה מוגדרת (Undefined Behavior). ייתכן שיודפס 42, ייתכן שיודפס ערך זבל, וייתכן שתתרחש שגיאת זיכרון.", "ד. התוכנית לא תעבור קומפילציה כיוון שלא ניתן להעביר כתובת של משתנה מקומי (Local Variable) כארגומנט לפונקציית החוט.", "ה. התוכנית תסתיים מיד לאחר הקריאה ל-start_work מבלי להדפיס דבר, כיוון שסיום הפונקציה שיוצרת את החוט גורר את סיום החוט עצמו."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הסבר: למרות שכל החוטים בתהליך חולקים את אותו מרחב כתובות וירטואלי, לכל חוט יש מחסנית (Stack) פרטית משלו. המשתנה local_val מוקצה על המחסנית של החוט הראשי בזמן ביצוע הפונקציה start_work. ברגע שפונקציה זו מסתיימת, מסגרת המחסנית (Stack Frame) שלה משתחררת וניתן להשתמש בה לקריאות עתידיות. החוט החדש מנסה לגשת לכתובת הזיכרון הזו (Dangling Pointer) לאחר שהפונקציה שיצרה אותו כבר חזרה. כיוון שהתהליך עדיין רץ (בגלל ה-sleep ב-main), הגישה לזיכרון לא תמיד תגרום ל-Segfault (כי הדף בזיכרון עדיין שייך לתהליך), אך התוכן בכתובת זו עלול להשתנות או להיות לא תקף, מה שמוביל להתנהגות לא מוגדרת."}, "difficulty_estimation": "Hard", "_source_file": "0092__Threads__MultipleChoice__Hard.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:36:31", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Threads", "Process Management", "fork", "Synchronization"], "content": {"text": "נתון תהליך מרובה חוטים (Multi-threaded process) המשתמש ב-Mutex גלובלי לצורך סנכרון. אחד מהחוטים (שאינו חוט ה-Main) מבצע קריאה לפונקציה fork() כפי שמתואר בקוד מטה. נניח כי בזמן הקריאה ל-fork(), חוט אחר בתהליך האב (שאינו החוט הקורא ל-fork) מחזיק במנעול ה-lock. מה יקרה בנקודה המסומנת ב-Line X בתוך תהליך הבן?", "code_snippet": "void* thread_func(void* arg) {\n    if (fork() == 0) {\n        // Child process\n        pthread_mutex_lock(&lock); // Line X\n        printf(\"Child acquired lock\\n\");\n        pthread_mutex_unlock(&lock);\n        exit(0);\n    }\n    return NULL;\n}", "options": ["א. תהליך הבן יצליח לתפוס את המנעול מכיוון שכל המנעולים משתחררים אוטומטית בעת fork().", "ב. תהליך הבן יכיל את כל החוטים שהיו באב, ולכן החוט שהחזיק במנעול באב ישחרר אותו גם בבן.", "ג. תהליך הבן ייתקע בקיפאון (Deadlock) ב-Line X, שכן המנעול מועתק במצב 'תפוס' אך החוט שאמור לשחרר אותו אינו קיים בבן.", "ד. תהליך הבן יקרוס (Segmentation Fault) בגישה למנעול שנתפס על ידי חוט שכבר לא קיים.", "ה. מערכת ההפעלה תזהה את המצב ותעביר את הבעלות על המנעול לחוט היחיד שקיים בבן."]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "לפי תקן POSIX, כאשר תהליך מרובה חוטים מבצע fork(), רק החוט שקרא ל-fork() משוכפל בתהליך הבן. שאר החוטים של האב אינם קיימים בבן. עם זאת, מצב הזיכרון (כולל מצב ה-Mutexes) מועתק כפי שהוא (Copy-on-Write). אם חוט אחר באב החזיק במנעול בזמן ה-fork, המנעול יופיע כתפוס בזיכרון של הבן. מכיוון שהחוט שהחזיק במנעול לא קיים בבן כדי לשחרר אותו, כל ניסיון של החוט היחיד בבן לתפוס את המנעול יוביל ל-Deadlock."}, "difficulty_estimation": "Hard", "_source_file": "0093__Threads__MultipleChoice__Hard.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:36:56", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Threads", "Concurrency", "Race Conditions"], "content": {"text": "נתון קטע הקוד הבא בשפת C המשתמש בספריית pthreads. מה מהבאים מתאר נכונה את התנהגות התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n\nvoid* thread_func(void* arg) {\n    int id = *(int*)arg;\n    printf(\"%d \", id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[5];\n    for (int i = 0; i < 5; i++) {\n        pthread_create(&threads[i], NULL, thread_func, &i);\n    }\n    for (int i = 0; i < 5; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    return 0;\n}", "options": ["א. התוכנית תדפיס תמיד את המספרים 0 עד 4 בסדר כלשהו, כאשר כל מספר מופיע בדיוק פעם אחת.", "ב. ייתכן מצב בו יודפס המספר 5, או שמספר מסוים בטווח 0-4 יודפס יותר מפעם אחת.", "ג. השימוש ב-pthread_join מבטיח שכל thread יסיים את ריצתו לפני שהלולאה הבאה של ה-main תתחיל, ולכן הפלט יהיה 0 1 2 3 4.", "ד. התוכנית תגרום לשגיאת זמן ריצה (Runtime Error) כיוון שכל ה-threads מנסים לגשת לאותו זיכרון במקביל."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הבעיה בקוד היא Race Condition על המשתנה i. כל ה-threads מקבלים את אותה הכתובת בזיכרון (&i). בזמן ש-thread מסוים מתעורר וניגש לכתובת הזו כדי לקרוא את הערך (dereference), ה-main thread עשוי כבר לקדם את i בתוך הלולאה. יתרה מכך, i מגיע לערך 5 כדי לצאת מהלולאה הראשונה, ולכן ייתכן שחלק מה-threads (או כולם) יקראו את הערך 5 מהכתובת המשותפת לפני שהם מספיקים להדפיס."}, "difficulty_estimation": "Hard", "_source_file": "0094__Threads__MultipleChoice__Hard.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:37:14", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Threads", "Memory Visibility", "Optimization", "Pthreads"], "content": {"text": "במערכת המשתמשת ב-POSIX Threads (Pthreads), נתון הקוד הבא בשפת C. מהי הטענה המדויקת ביותר לגבי התנהגות התוכנית בעת הרצה על מעבד מרובה ליבות (Multi-core) עם רמת אופטימיזציה גבוהה (למשל O3-)?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nvoid* thread_func(void* arg) {\n    int* p = (int*)arg;\n    while (*p == 0); // Wait for flag to change\n    printf(\"Value changed!\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t t1;\n    int flag = 0;\n    pthread_create(&t1, NULL, thread_func, &flag);\n    \n    // Simulate some work\n    for (volatile int i = 0; i < 1000000; i++);\n    \n    flag = 1;\n    pthread_join(t1, NULL);\n    return 0;\n}", "options": ["א. התוכנית תקינה לחלוטין ותדפיס תמיד את ההודעה, שכן חוטים חולקים את אותו מרחב כתובות והשינוי ב-flag ייראה מיד לחוט t1.", "ב. התוכנית עלולה להיכנס ללולאה אינסופית בגלל אופטימיזציות קומפיילר, שכן ללא סנכרון או שימוש ב-volatile, החוט t1 עשוי לטעון את הערך של flag לרגיסטר פעם אחת בלבד ולא לבדוק שוב את הזיכרון.", "ג. תתרחש שגיאת Segmentation Fault כיוון שחוט t1 מנסה לגשת למחסנית (Stack) של החוט הראשי, דבר שאינו מותר במודל של Kernel-level threads.", "ד. הקריאה ל-pthread_join תגרום ל-Deadlock כיוון שהיא חוסמת את החוט הראשי מלערוך את המשתנה flag.", "ה. התוכנית לא תתקמפל כיוון שלא ניתן להעביר כתובת של משתנה מקומי (flag) כארגומנט לפונקציה pthread_create."]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "במרחב כתובות משותף, חוטים אכן יכולים לגשת לאותם משתנים (כולל משתנים על מחסנית של חוט אחר כל עוד הוא חי). עם זאת, ללא מנגנוני סנכרון (כמו Mutex) או הגדרת המשתנה כ-volatile, הקומפיילר עשוי להניח שערכו של flag אינו משתנה בתוך הלולאה בחוט t1 (כי אין שום קריאה לפונקציה או כתיבה למשתנה בתוך הלולאה). לכן, הקומפיילר עשוי לבצע אופטימיזציה שבה הערך נטען לרגיסטר פעם אחת בלבד לפני הלולאה. במצב כזה, השינוי שביצע החוט הראשי בזיכרון לא יורגש בתוך הלולאה והחוט ייתקע בלולאה אינסופית."}, "difficulty_estimation": "Hard", "_source_file": "0095__Threads__MultipleChoice__Hard.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:37:47", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Threads", "Process Management", "POSIX"], "content": {"text": "נתון קוד C המשתמש בספריית Pthreads. תהליך מסוים יוצר שני תהליכונים (Threads) בנוסף לתהליכון הראשי (Main thread). אחד מהתהליכונים החדשים שנוצרו מבצע קריאה למערכת (System Call) מסוג fork(). איזה מההיגדים הבאים מתאר נכונה את מצב התהליך הבן שנוצר מיד לאחר הקריאה?", "code_snippet": "void* thread_func(void* arg) {\n    pid_t pid = fork();\n    if (pid == 0) {\n        // מה קיים כאן בתוך התהליך הבן?\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, thread_func, NULL);\n    pthread_create(&t2, NULL, some_other_func, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    return 0;\n}", "options": ["א. התהליך הבן יכיל העתק של כל התהליכונים שהיו קיימים בתהליך האב (סה\"כ 3 תהליכונים).", "ב. התהליך הבן יכיל רק תהליכון אחד, שהוא העתק של התהליכון שביצע את הקריאה ל-fork.", "ג. התהליך הבן יכיל רק את התהליכון הראשי (Main thread), וכל שאר התהליכונים יופסקו.", "ד. הפעולה אינה מוגדרת (Undefined behavior) ותלויה במימוש הספציפי של ה-Scheduler של מערכת ההפעלה."]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "לפי תקן POSIX, כאשר תהליך מרובה תהליכונים קורא ל-fork, התהליך הבן שנוצר הוא העתק של תהליך האב מבחינת מרחב הכתובות (Address Space), אך הוא מכיל רק תהליכון אחד בלבד - התהליכון שביצע את הקריאה ל-fork. שאר התהליכונים שהיו קיימים באב אינם נוצרים בבן. זוהי נקודה קריטית כי אם התהליכונים האחרים החזיקו במנעולים (Mutexes) ברגע הקריאה, המנעולים יופיעו כתפוסים בבן אך התהליכון שאמור לשחרר אותם לא קיים שם, מה שעלול להוביל ל-Deadlock."}, "difficulty_estimation": "Hard", "_source_file": "0096__Threads__MultipleChoice__Hard.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:38:08", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Threads", "User-level threads", "Kernel-level threads"], "content": {"text": "במערכת הפעלה מסוימת, תהליך מכיל שלושה חוטים (threads). אחד החוטים מבצע קריאת מערכת חוסמת (blocking system call) לקלט מהמקלדת, כפי שמתואר בקטע הקוד הבא. הסבירו מה יקרה לשני החוטים האחרים באותו תהליך בשני המקרים המפורטים מטה:", "code_snippet": "void* thread_work(void* arg) {\n    char buffer[1024];\n    // הקריאה הבאה חוסמת את החוט עד לקבלת קלט\n    read(STDIN_FILENO, buffer, sizeof(buffer));\n    printf(\"Input received!\\n\");\n    return NULL;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "החוטים ממומשים כחוטים ברמת המשתמש (User-level threads) במודל Many-to-One.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "החוטים ממומשים כחוטים ברמת הגרעין (Kernel-level threads) במודל One-to-One.", "code_snippet": null, "options": null}], "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1. במודל Many-to-One (User-level threads), מערכת ההפעלה (הגרעין) אינה מודעת לקיומם של החוטים ורואה רק תהליך אחד. כאשר חוט אחד מבצע קריאת מערכת חוסמת, הגרעין מעביר את כל התהליך למצב 'ממתין' (Waiting/Blocked). כתוצאה מכך, כל שאר החוטים בתהליך ייחסמו ולא יוכלו להמשיך בביצועם עד שהקריאה תסתיים.\n\n10.2. במודל One-to-One (Kernel-level threads), כל חוט משתמש ממופה לחוט נפרד בתוך הגרעין. במקרה זה, הגרעין מנהל את התזמון של כל חוט בנפרד. לכן, אם חוט אחד נחסם בגלל קריאת מערכת, הגרעין יכול להמשיך לתזמן ולהריץ את שני החוטים האחרים של אותו תהליך ללא הפרעה."}, "difficulty_estimation": "Easy", "_source_file": "0097__Threads__Open__Easy.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:38:19", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Threads", "Concurrency", "Race Conditions"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בספריית pthreads. התוכנית יוצרת שני חוטים (threads) המריצים את הפונקציה `increment` שמקדמת משתנה גלובלי משותף.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint counter = 0;\n\nvoid* increment(void* arg) {\n    for (int i = 0; i < 100; i++) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, increment, NULL);\n    pthread_create(&t2, NULL, increment, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"%d\\n\", counter);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "מהו הערך המקסימלי האפשרי שיודפס על ידי התוכנית? נמקו בקצרה.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "האם ייתכן שהתוכנית תדפיס ערך הנמוך מ-200? אם כן, הסבירו באיזה מצב זה עלול לקרות. אם לא, הסבירו מדוע.", "code_snippet": null, "options": null}], "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1. הערך המקסימלי הוא 200. כל אחד משני החוטים מבצע 100 איטרציות שבהן הוא מקדם את המשתנה הגלובלי counter. במקרה שבו אין חפיפה בין הפעולות (למשל ריצה סדרתית מלאה של חוט אחד ואז השני), כל הקידומים יישמרו.\n10.2. כן, ייתכן ערך נמוך מ-200 בשל מצב מרוץ (Race Condition). הפעולה ++counter אינה אטומית (היא מורכבת מקריאת הערך מהזיכרון, הוספת 1 ברגיסטר, וכתיבה חזרה לזיכרון). אם שני חוטים קוראים את הערך בו-זמנית (למשל 50), שניהם יקדמו אותו ל-51 ויכתבו את אותה התוצאה לזיכרון, מה שיוביל לאובדן של אחד הקידומים."}, "difficulty_estimation": "Easy", "_source_file": "0098__Threads__Open__Easy.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:38:32", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Threads"], "content": {"text": "נתון קטע הקוד הבא בשפת C המשתמש בספריית pthreads. מה יהיה הפלט של התוכנית? הסבר את תשובתך תוך התייחסות למרחב הכתובות המשותף בין חוטים (threads).", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint global_var = 10;\n\nvoid* thread_func(void* arg) {\n    global_var += 5;\n    return NULL;\n}\n\nint main() {\n    pthread_t tid;\n    pthread_create(&tid, NULL, thread_func, NULL);\n    pthread_join(tid, NULL);\n    printf(\"%d\\n\", global_var);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפלט יהיה 15. חוטים (threads) ששייכים לאותו תהליך חולקים את אותו מרחב כתובות, ובפרט את מקטע הנתונים (Data Segment) שבו נמצאים משתנים גלובליים. לכן, כאשר ה-thread שנוצר מעדכן את המשתנה global_var, השינוי משתקף גם ב-thread הראשי (main). הפעולה pthread_join מבטיחה שה-thread הראשי ימתין לסיום ביצוע ה-thread החדש לפני שידפיס את הערך."}, "difficulty_estimation": "Easy", "_source_file": "0099__Threads__Open__Easy.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:38:47", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Threads", "Concurrency", "Memory Management"], "content": {"text": "לפניך קטע קוד בשפת C המשתמש בספריית pthreads. התוכנית מגדירה משתנה גלובלי ומבצעת פעולות עדכון מתוך שני חוטים שונים.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint counter = 0;\n\nvoid* increment_task(void* arg) {\n    for (int i = 0; i < 100; i++) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n\n    pthread_create(&t1, NULL, increment_task, NULL);\n    pthread_create(&t2, NULL, increment_task, NULL);\n\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n\n    printf(\"%d\\n\", counter);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "בהנחה שהריצה מתבצעת באופן תקין וללא הפרעות של מרוץ תהליכים (race conditions), מה יהיה הפלט המודפס למסך?", "code_snippet": null, "options": null}, {"id": "7.2", "text": "הסבר מדוע חוטים (threads) מסוגלים לעדכן את המשתנה counter בצורה כזו, וכיצד התנהגות זו הייתה משתנה אילו היינו משתמשים בתהליכים (processes) ע\"י fork במקום חוטים?", "code_snippet": null, "options": null}], "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1. הפלט יהיה 200. כל אחד משני החוטים מבצע 100 איטרציות של קידום המשתנה counter ב-1.\n7.2. חוטים (threads) השייכים לאותו תהליך חולקים את אותו מרחב כתובות (Address Space), ולכן משתנים גלובליים (הנמצאים במקטע הנתונים) הם משותפים לכולם. אילו היינו משתמשים ב-fork, היה נוצר תהליך בן עם עותק נפרד של מרחב הכתובות (Copy-on-write). במקרה כזה, קידום המשתנה בתהליך הבן לא היה משפיע על המשתנה בתהליך האב, והאב היה מדפיס 0."}, "difficulty_estimation": "Easy", "_source_file": "0100__Threads__Open__Easy.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:39:01", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Threads", "Concurrency", "Memory Management"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בספריית pthreads. מה יהיה הפלט המודפס למסך בסיום ריצת התוכנית? הסבירו את תשובתכם תוך התייחסות לאופן שבו חוטים (threads) חולקים זיכרון.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint shared_val = 100;\n\nvoid* thread_work(void* arg) {\n    shared_val += 50;\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n\n    pthread_create(&t1, NULL, thread_work, NULL);\n    pthread_join(t1, NULL);\n\n    pthread_create(&t2, NULL, thread_work, NULL);\n    pthread_join(t2, NULL);\n\n    printf(\"%d\\n\", shared_val);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפלט יהיה 200. ההסבר לכך טמון בעובדה שחוטים (Threads) השייכים לאותו תהליך חולקים את אותו מרחב כתובות (Address Space), ובפרט את מקטע הנתונים הגלובליים. המשתנה shared_val הוא גלובלי, ולכן כל שינוי שמבצע חוט אחד נראה באופן מיידי לחוטים האחרים. בתוכנית זו: 1. הערך ההתחלתי הוא 100. 2. החוט הראשון (t1) מוסיף 50, והערך הופך ל-150. 3. הפונקציה pthread_join מבטיחה שהחוט הראשון יסיים לפני שהחוט השני יתחיל. 4. החוט השני (t2) מוסיף 50 נוספים לערך הקיים (150), ולכן התוצאה הסופית היא 200."}, "difficulty_estimation": "Easy", "_source_file": "0101__Threads__Open__Easy.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:39:12", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Threads"], "content": {"text": "לפניך קטע קוד בשפת C המשתמש בספריית pthreads. מהן האפשרויות השונות לפלט התוכנית? הסבר/י מדוע ייתכנו מספר אפשרויות והאם קיימת הבטחה לגבי סדר ההדפסה של האותיות A ו-B.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nvoid* thread_func(void* arg) {\n    printf(\"B\");\n    return NULL;\n}\n\nint main() {\n    pthread_t t;\n    pthread_create(&t, NULL, thread_func, NULL);\n    printf(\"A\");\n    pthread_join(t, NULL);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפלט של התוכנית יכול להיות 'AB' או 'BA'. הסיבה לכך היא שברגע שמתבצעת הקריאה ל-pthread_create, נוצר חוט (thread) חדש שמתחיל לרוץ במקביל לחוט הראשי. התזמון (scheduling) של החוטים על ידי מערכת ההפעלה אינו דטרמיניסטי, ולכן אין לדעת מי יבצע את פקודת ה-printf שלו קודם: החוט הראשי שממשיך מיד לאחר הקריאה ל-create, או החוט החדש שנוצר. פקודת ה-pthread_join מבטיחה שהחוט הראשי ימתין לסיום החוט החדש לפני שהתוכנית כולה תסתיים, אך מכיוון שהיא ממוקמת אחרי ה-printf של ה-main, היא אינה משפיעה על סדר ההדפסה היחסי בין A ל-B."}, "difficulty_estimation": "Easy", "_source_file": "0102__Threads__Open__Easy.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:39:27", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Threads", "Shared Memory", "Pthreads"], "content": {"text": "נתון קטע הקוד הבא בשפת C המשתמש בספריית pthreads. הניחו כי כל הקריאות למערכת (system calls) מצליחות וכי התזמון מתבצע כך שהחוט החדש מסיים את ריצתו לפני שהחוט הראשי ממשיך לאחר ה-join. מה יהיה הפלט של התוכנית? הסבירו בקצרה מדוע.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint x = 10;\n\nvoid* thread_func(void* arg) {\n    x += 5;\n    printf(\"Thread: x = %d\\n\", x);\n    return NULL;\n}\n\nint main() {\n    pthread_t tid;\n    pthread_create(&tid, NULL, thread_func, NULL);\n    pthread_join(tid, NULL);\n    x += 2;\n    printf(\"Main: x = %d\\n\", x);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפלט הצפוי הוא:\nThread: x = 15\nMain: x = 17\nהסבר: חוטים (threads) בתוך אותו תהליך חולקים את אותו מרחב כתובות, ולכן המשתנה הגלובלי x משותף לחוט הראשי ולחוט שנוצר. החוט הראשי קורא ל-pthread_join, מה שגורם לו להמתין עד שהחוט החדש יסיים את ביצועו. בתוך thread_func, הערך של x עולה מ-10 ל-15 ומודפס. לאחר סיום החוט, החוט הראשי ממשיך, מוסיף 2 לערך המעודכן (15+2=17) ומדפיס את התוצאה."}, "difficulty_estimation": "Easy", "_source_file": "0103__Threads__Open__Easy.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:39:38", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Threads", "Concurrency", "Race Conditions"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בספריית pthreads. התוכנית יוצרת שני חוטים (threads) שכל אחד מהם מעלה את הערך של משתנה גלובלי משותף counter בתוך לולאה 10,000 פעמים.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0;\n\nvoid* increment(void* arg) {\n    for (int i = 0; i < 10000; i++) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, increment, NULL);\n    pthread_create(&t2, NULL, increment, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"Final counter: %d\\n\", counter);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "מהי התוצאה המקסימלית האפשרית של המשתנה counter בסיום ריצת התוכנית?", "code_snippet": null, "options": null}, {"id": "7.2", "text": "האם מובטח שהפלט של התוכנית יהיה תמיד התוצאה המקסימלית? הסבירו מדוע, והשתמשו במושג \"מרוץ תהליכים\" (Race Condition) בהסברכם.", "code_snippet": null, "options": null}], "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1. התוצאה המקסימלית היא 20,000 (כל אחד משני החוטים מבצע 10,000 פעולות הגדלה).\n7.2. לא, לא מובטח שהפלט יהיה 20,000. הסיבה לכך היא קיום של מרוץ תהליכים (Race Condition). הפעולה ++counter אינה פעולה אטומית (Atomic) ברמת המעבד; היא מורכבת משלושה שלבים: קריאת הערך מהזיכרון לרגיסטר, הוספת 1 ברגיסטר, וכתיבת הערך חזרה לזיכרון. אם מתבצע context switch בין חוטים באמצע שלבים אלו, חוט אחד עלול לקרוא ערך ישן ולדרוס עדכון של חוט אחר, מה שיוביל לכך שחלק מההגדלות יאבדו והתוצאה הסופית תהיה קטנה מ-20,000."}, "difficulty_estimation": "Easy", "_source_file": "0104__Threads__Open__Easy.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:39:57", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Threads", "Concurrency", "Race Conditions", "Memory Layout"], "content": {"text": "לפניכם קוד בשפת C המשתמש בחוטים (Threads). הניחו שהקוד רץ על מערכת מרובת ליבות וכי אין מנגנוני סנכרון נוספים מעבר למה שמופיע בקוד.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0;\n\nvoid* worker(void* arg) {\n    int* local_ptr = (int*)arg;\n    for (int i = 0; i < 100; i++) {\n        counter++;\n        (*local_ptr)++;\n    }\n    return NULL;\n}\n\nint main() {\n    int shared_val = 0;\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, worker, &shared_val);\n    pthread_create(&t2, NULL, worker, &shared_val);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"counter: %d, shared_val: %d\\n\", counter, shared_val);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "מהם הערכים המינימליים והמקסימליים האפשריים שיוצגו עבור counter ו-shared_val בסיום התוכנית? הסבירו בקצרה מדוע.", "code_snippet": null, "options": null}, {"id": "7.2", "text": "הסבירו את ההבדל במיקום בזיכרון בין counter ל-shared_val. האם הבדל זה משנה את רגישות המשתנה shared_val למצבי מרוץ (Race Conditions)?", "code_snippet": null, "options": null}, {"id": "7.3", "text": "כיצד שימוש ב-pthread_mutex_t יכול לפתור את הבעיה? הציגו את השינוי הנדרש בקוד ה-worker בלבד (הניחו כי המיוטקס כבר אותחל גלובלית בשם lock).", "code_snippet": null, "options": null}], "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1. המקסימום עבור שניהם הוא 200 (במקרה של ריצה סדרתית או תזמון מושלם). המינימום הוא 2 (במקרה של Race Condition שבו כל חוט קורא את הערך 0, מקדם ל-1 וכותב, ואז התהליך חוזר על עצמו כך שכל חוט דורס את עבודת השני פרט לפעם אחת). הערכים נובעים מכך שפעולת הקידום אינה אטומית (Load, Increment, Store).\n\n7.2. המשתנה counter הוא גלובלי ולכן נמצא ב-Data Segment. המשתנה shared_val הוכרז ב-main ולכן נמצא על המחסנית (Stack) של חוט ה-main. למרות זאת, כיוון שכתובתו הועברה כארגומנט לחוטים האחרים, לכולם יש גישה לאותו מרחב זיכרון. לכן, shared_val חשוף ל-Race Condition בדיוק כמו counter.\n\n7.3. יש לנעול את המיוטקס לפני הגישה למשתנים המשותפים ולשחרר אחרי:\nvoid* worker(void* arg) {\n    int* local_ptr = (int*)arg;\n    for (int i = 0; i < 100; i++) {\n        pthread_mutex_lock(&lock);\n        counter++;\n        (*local_ptr)++;\n        pthread_mutex_unlock(&lock);\n    }\n    return NULL;\n}"}, "difficulty_estimation": "Medium", "_source_file": "0105__Threads__Open__Medium.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:40:14", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Threads", "Concurrency", "Memory Layout", "Process vs Thread"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בספריית pthreads. הניחו כי כל הקריאות למערכת מצליחות וכי התוכנית רצה על מערכת עם מעבד מרובה ליבות.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint global_var = 0;\n\nvoid* thread_func(void* arg) {\n    int local_var = 0;\n    for (int i = 0; i < 1000; i++) {\n        global_var++;\n        local_var++;\n    }\n    printf(\"%d \", local_var);\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, thread_func, NULL);\n    pthread_create(&t2, NULL, thread_func, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"%d\\n\", global_var);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "מה יהיו הערכים שיודפסו עבור המשתנה local_var על ידי שני החוטים? נמקו.", "code_snippet": null, "options": null}, {"id": "7.2", "text": "מהו טווח הערכים האפשרי שיודפס עבור המשתנה global_var בפקודת ה-printf האחרונה ב-main? הסבירו מדוע.", "code_snippet": null, "options": null}, {"id": "7.3", "text": "נניח ונחליף את יצירת החוטים (pthread_create) ביצירת תהליכים על ידי fork, ואת ה-pthread_join בפקודת wait. כיצד ישתנה הפלט עבור global_var בסוף הריצה של תהליך האב?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1: כל חוט ידפיס 1000. הסבר: המשתנה local_var הוא משתנה מקומי המוקצה על המחסנית (stack). לכל חוט (Thread) יש מחסנית נפרדת משלו, ולכן כל חוט מעדכן עותק פרטי שלו שאינו מושפע מהחוט השני.\n\n7.2: טווח הערכים הוא [1000, 2000]. הסבר: המשתנה global_var נמצא במקטע הנתונים המשותף לכל החוטים באותו תהליך. מכיוון שאין סנכרון (כמו Mutex) על הגישה למשתנה, נוצר מצב מרוץ (Race Condition). בפעולת הקידום (global_var++), חוט אחד עלול לקרוא את הערך, ובזמן שהוא מחשב את התוצאה, החוט השני יקרא את אותו ערך ישן, מה שיגרום לעדכון של אחד מהם 'להידרס'. המינימום הוא 1000 (במקרה שחוט אחד תמיד דורס את השני) והמקסימום הוא 2000 (במקרה שלא היו התנגשויות כלל).\n\n7.3: הפלט עבור global_var בתהליך האב יהיה 0. הסבר: כאשר משתמשים ב-fork, נוצר תהליך חדש עם מרחב כתובות נפרד. למרות שבתחילה הזיכרון מועתק (או משתמש ב-Copy-on-Write), שינויים שמבצע תהליך הבן על משתנה גלובלי אינם משפיעים על המשתנה בזיכרון של תהליך האב. מכיוון שתהליך האב עצמו לא שינה את global_var ב-main, הערך יישאר 0."}, "difficulty_estimation": "Medium", "_source_file": "0106__Threads__Open__Medium.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:40:30", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Threads", "User-level threads", "Kernel-level threads", "Concurrency", "Race Conditions"], "content": {"text": "השאלה הבאה עוסקת בניהול חוטים (threads) במערכות הפעלה ובבעיות סנכרון הנובעות מריצה מקבילית.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "10.1", "text": "נניח תהליך המשתמש בחוטים ברמת המשתמש (User-level threads) במודל Many-to-One. אחד החוטים מבצע קריאת מערכת חוסמת (blocking system call) לקלט מהמקלדת. הסבירו מה יקרה לשאר החוטים באותו תהליך ומדוע. האם המצב היה שונה אילו המערכת הייתה משתמשת בחוטים ברמת הגרעין (Kernel-level threads) במודל One-to-One?", "code_snippet": null, "options": null}, {"id": "10.2", "text": "נתון קטע הקוד הבא המורץ על ידי שני חוטים (Thread A ו-Thread B) החולקים את אותו מרחב כתובות. המשתנה counter הוא גלובלי ומאותחל ל-0. מהו הערך המינימלי האפשרי של counter לאחר ששני החוטים מסיימים את ריצתם? הסבירו בקצרה כיצד ניתן להגיע לערך זה.", "code_snippet": "void* increment(void* arg) {\n    for (int i = 0; i < 100; i++) {\n        int temp = counter;\n        counter = temp + 1;\n    }\n    return NULL;\n}", "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: במודל Many-to-One (חוטים ברמת המשתמש), הגרעין אינו מכיר את החוטים הבודדים ומתייחס לכל התהליך כיחידת תזמון אחת. לכן, כאשר חוט אחד מבצע קריאת מערכת חוסמת, כל התהליך נכנס למצב 'חסום' (Blocked), וכל שאר החוטים בתהליך לא יוכלו לרוץ עד שהקריאה תסתיים. במודל One-to-One (חוטים ברמת הגרעין), כל חוט ממופה לישות תזמון עצמאית בגרעין, ולכן חסימה של חוט אחד אינה מונעת מהגרעין להמשיך לתזמן חוטים אחרים של אותו תהליך.\n\n10.2: הערך המינימלי הוא 2. הסבר: מצב זה קורה עקב Race Condition. נניח שחוט א' קורא את counter=0 לתוך temp ומופסק מיד. חוט ב' רץ 99 פעמים ומסיים (counter=99). כעת חוט א' חוזר, מבצע counter = 0 + 1 ומעדכן את counter ל-1. כעת חוט ב' מתחיל את האיטרציה ה-100 שלו, קורא counter=1 לתוך ה-temp שלו ומופסק. חוט א' ממשיך ורץ את כל 99 האיטרציות הנותרות שלו ומסיים (נניח שעדכן את counter ל-100). לבסוף, חוט ב' חוזר לביצוע האיטרציה האחרונה שלו, מבצע counter = 1 + 1 ודורס את הערך ל-2."}, "difficulty_estimation": "Medium", "_source_file": "0107__Threads__Open__Medium.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:40:52", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Threads", "Concurrency", "User-level vs Kernel-level Threads"], "content": {"text": "נניח מערכת הפעלה התומכת בשני מודלים שונים לניהול חוטים (Threads): מודל Many-to-One (חוטים ברמת המשתמש) ומודל One-to-One (חוטים ברמת הליבה). תהליך מסוים יוצר 4 חוטים. חוט מספר 1 מבצע קריאת מערכת חוסמת (Blocking System Call) לקריאת נתונים מהדיסק, בעוד ששאר החוטים (2, 3, ו-4) מבצעים חישובים מתמטיים.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint counter = 0;\n\nvoid* worker(void* arg) {\n    for (int i = 0; i < 1000000; i++) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, worker, NULL);\n    pthread_create(&t2, NULL, worker, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"Final counter: %d\\n\", counter);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "תאר מה יקרה לחוטים 2, 3 ו-4 בזמן שחוט 1 ממתין לדיסק בכל אחד מהמודלים (Many-to-One ו-One-to-One).", "code_snippet": null, "options": null}, {"id": "7.2", "text": "התייחס לקוד ה-C המצורף. מהי הבעיה הלוגית בקוד זה, ומה יהיה הפלט הצפוי של התוכנית (האם תמיד יודפס 2,000,000)? הסבר מדוע.", "code_snippet": null, "options": null}], "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1: במודל Many-to-One, כל החוטים של התהליך ממופים לישות תזמון אחת בליבה. לכן, כאשר חוט 1 מבצע קריאה חוסמת, הליבה חוסמת את התהליך כולו, וחוטים 2, 3 ו-4 לא יוכלו לרוץ עד שהקריאה תסתיים. במודל One-to-One, כל חוט ממופה לישות תזמון נפרדת בליבה. לכן, רק חוט 1 ייחסם, וחוטים 2, 3 ו-4 יוכלו להמשיך לרוץ במקביל על מעבדים אחרים או בתורות תזמון נפרדים.\n\n7.2: הבעיה בקוד היא מרוץ תהליכים (Race Condition) על המשתנה הגלובלי counter. הפעולה ++counter אינה אטומית (היא מורכבת מקריאה, הוספה וכתיבה). מאחר ששני החוטים ניגשים ומשנים את אותו משתנה ללא סנכרון (למשל ללא Mutex), ייתכן שחוט אחד יקרא ערך ישן לפני שהשני הספיק לעדכן אותו. לכן, הפלט כמעט תמיד יהיה קטן מ-2,000,000, והוא אינו דטרמיניסטי."}, "difficulty_estimation": "Medium", "_source_file": "0108__Threads__Open__Medium.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:41:05", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Threads", "User-level Threads", "Kernel-level Threads", "Blocking I/O"], "content": {"text": "שקלו מערכת המריצה תהליך עם שלושה חוטים (Threads) המבצעים את הפעולות המתוארות בקוד הבא. נניח שחוט 2 מבצע קריאה חוסמת (blocking read) מקובץ גדול הנמצא על הדיסק.", "code_snippet": "void* thread_1_work(void* arg) { \n    while(1) { /* Compute intensive math */ } \n}\n\nvoid* thread_2_work(void* arg) { \n    int fd = open(\"large_file.dat\", O_RDONLY);\n    read(fd, buffer, 1000000); // Blocking I/O call\n    close(fd);\n}\n\nvoid* thread_3_work(void* arg) { \n    printf(\"Status: Working...\\n\"); \n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "במידה והספרייה לניהול חוטים ממומשת במודל Many-to-One (User-level threads), האם חוט 1 יוכל להמשיך בחישוביו בזמן שחוט 2 ממתין לנתונים מהדיסק? נמקו.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "במידה והמערכת משתמשת במודל One-to-One (Kernel-level threads), מה יהיה מצבם של חוט 1 וחוט 3 בזמן שחוט 2 חסום?", "code_snippet": null, "options": null}, {"id": "10.3", "text": "ציינו יתרון אחד של מודל Many-to-One על פני מודל One-to-One, למרות המגבלה שהוצגה בסעיפים הקודמים.", "code_snippet": null, "options": null}], "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: לא, חוט 1 לא יוכל להמשיך לרוץ. במודל Many-to-One, מערכת ההפעלה אינה מודעת לקיום החוטים בתוך התהליך ורואה רק ישות תזמון אחת. כאשר חוט 2 מבצע קריאה חוסמת, הוא מבצע קריאת מערכת (system call) שגורמת לכל התהליך להיכנס למצב Waiting עד לסיום פעולת ה-I/O.\n\n10.2: במודל One-to-One, כל חוט משתמש בישות תזמון נפרדת של הקרנל. לכן, כאשר חוט 2 נחסם על פעולת I/O, רק הוא עובר למצב Waiting. חוט 1 יכול להמשיך לרוץ על המעבד (מצב Running) וחוט 3 יכול להיות מתוזמן להדפסה (מצב Ready/Running).\n\n10.3: יתרון מרכזי של Many-to-One הוא היעילות בניהול החוטים. יצירת חוט, החלפת הקשר (context switch) בין חוטים וסנכרון ביניהם מתבצעים במרחב המשתמש (User-space) ללא צורך במעבר למצב קרנל (trap/kernel mode), מה שהופך את הפעולות הללו למהירות משמעותית בהשוואה לניהול חוטים על ידי הקרנל."}, "difficulty_estimation": "Medium", "_source_file": "0109__Threads__Open__Medium.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:41:17", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Threads", "Concurrency", "Memory Management"], "content": {"text": "לפניך קוד בשפת C המשתמש בספריית pthreads. מטרת התוכנית היא ליצור 5 חוטים (threads), כאשר כל חוט מקבל את המזהה שלו (מספר בין 0 ל-4) ומדפיס אותו.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#define NUM_THREADS 5\n\nvoid* thread_func(void* arg) {\n    int id = *((int*)arg);\n    printf(\"Thread ID: %d\\n\", id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    for (int i = 0; i < NUM_THREADS; i++) {\n        pthread_create(&threads[i], NULL, thread_func, &i);\n    }\n    for (int i = 0; i < NUM_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "הסבר מדוע הקוד לעיל אינו תקין ועלול להדפיס פלט שאינו מכיל את כל המספרים 0 עד 4 (למשל, הדפסה של המספר 5 מספר פעמים).", "code_snippet": null, "options": null}, {"id": "7.2", "text": "הצע שתי דרכים שונות לתיקון הבעיה: אחת המשתמשת בהקצאה דינמית (malloc) ואחת המשתמשת בהעברת ערך ישירות דרך המצביע (Casting), מבלי להשתמש במנגנוני סנכרון כמו Mutex.", "code_snippet": null, "options": null}], "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1: הבעיה היא Race Condition על המשתנה i. כל החוטים מקבלים מצביע לאותה כתובת זיכרון (&i) הנמצאת במחסנית (stack) של פונקציית ה-main. מכיוון שהחוטים רצים במקביל ללולאת ה-for ב-main, ייתכן שעד שחוט מסוים ניגש לזיכרון כדי לקרוא את הערך, הלולאה כבר התקדמה והערך של i השתנה (או אפילו הגיע ל-5, התנאי לעצירת הלולאה).\n\n7.2: דרך א': הקצאה דינמית - בתוך הלולאה נקצה זיכרון עם malloc עבור כל מספר, נשמור בו את i ונעביר את המצביע ל-malloc. החוט יבצע free בסיום. דרך ב': העברת ערך ב-Casting - נמיר את הערך של i לטיפוס void* ונשלח אותו כארגומנט (למשל pthread_create(..., (void*)(long)i)). בתוך החוט נבצע המרה הפוכה מ-void* חזרה ל-int. בצורה זו כל חוט מקבל עותק של הערך בתוך ה-argument pointer עצמו ולא מצביע לכתובת משותפת."}, "difficulty_estimation": "Medium", "_source_file": "0110__Threads__Open__Medium.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:41:35", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Threads", "Concurrency", "Memory Management"], "content": {"text": "סטודנט כתב תוכנית ב-C המשתמשת בחוטים (threads) כדי להדפיס את המזהה של כל חוט. הקוד נראה כך:", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nvoid* print_id(void* arg) {\n    int id = *((int*)arg);\n    printf(\"My ID is: %d\\n\", id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[4];\n    for (int i = 0; i < 4; i++) {\n        pthread_create(&threads[i], NULL, print_id, &i);\n    }\n    for (int i = 0; i < 4; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "הסטודנט הריץ את התוכנית וקיבל את הפלט הבא: \nMy ID is: 1\nMy ID is: 2\nMy ID is: 4\nMy ID is: 4\nהסבירו מדוע התוכנית לא הדפיסה את המספרים 0 עד 3 בסדר כלשהו, ומהי הבעיה בגישה לזיכרון בקוד זה.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "הציעו שתי דרכים שונות לתיקון הבעיה (שינוי הקוד כך שכל חוט ידפיס בוודאות מזהה ייחודי מ-0 עד 3), והסבירו את היתרון/חיסרון של כל אחת.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "אם נזיז את הקריאה ל-pthread_join אל תוך הלולאה הראשונה (מיד לאחר ה-pthread_create), האם הבעיה תיפתר? מה תהיה ההשפעה על זמן הריצה הכולל של התוכנית?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: הבעיה היא race condition על המשתנה i. הסטודנט מעביר לכל חוט מצביע לאותו מיקום בזיכרון (הכתובת של i במחסנית של main). בזמן שהחוטים נוצרים ומתחילים לרוץ, הלולאה ב-main ממשיכה להתקדם ולשנות את הערך של i. לכן, חוט עשוי לקרוא את הערך של i לאחר שהוא כבר גדל. בדוגמה, חוטים מסוימים קראו את אותו ערך, וערך 0 לא נקרא בכלל כי הלולאה התקדמה לפני שהחוט הראשון הספיק לקרוא מהזיכרון.\n\n10.2: דרך א: העברת הערך עצמו על ידי casting. במקום &i, נעביר (void*)(long)i. בחוט נבצע casting חזרה ל-int. יתרון: אין צורך בניהול זיכרון נוסף. חיסרון: מסתמך על כך שגודל מצביע גדול או שווה לגודל int.\nדרך ב: הקצאת מערך של מזהים או הקצאה דינמית (malloc) לכל חוט בנפרד. יתרון: בטוח וגנרי לכל סוג מידע. חיסרון: דורש ניהול זיכרון (שחרור).\n\n10.3: כן, הבעיה תיפתר כי ה-main thread ימתין לסיום כל חוט לפני שיקדם את i באיטרציה הבאה. עם זאת, התוכנית תהפוך לסדרתית לחלוטין (Sequential) ולא יהיה כל ניצול של מקביליות, מה שיבטל את המטרה של שימוש בחוטים."}, "difficulty_estimation": "Medium", "_source_file": "0111__Threads__Open__Medium.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:41:49", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Threads", "User-level threads", "Kernel-level threads", "Concurrency"], "content": {"text": "סטודנט פיתח דפדפן אינטרנט פשוט המשתמש בספריית חוטים (threads) ברמת המשתמש (User-level threads) במימוש של Many-to-One (כלומר, כל חוטי המשתמש ממופים לחוט ליבה יחיד).", "code_snippet": null, "options": null}, "sub_questions": [{"id": "7.1", "text": "מה יקרה כאשר אחד החוטים בדפדפן מבצע קריאת מערכת חוסמת (Blocking system call), כמו למשל קריאת נתונים מהרשת? הסבירו את ההשפעה על שאר החוטים בתהליך.", "code_snippet": null, "options": null}, {"id": "7.2", "text": "כיצד המעבר למודל של חוטי ליבה (Kernel-level threads) במודל One-to-One עשוי לשפר את ביצועי הדפדפן במקרה של פעולות קלט/פלט (I/O)?", "code_snippet": null, "options": null}, {"id": "7.3", "text": "נתון קטע הקוד הבא המשתמש ב-POSIX Threads. מה יהיה הפלט של התוכנית? הסבירו בקצרה את הקשר למרחב הכתובות של חוטים.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint global_val = 20;\n\nvoid* increment_func(void* arg) {\n    global_val += 10;\n    return NULL;\n}\n\nint main() {\n    pthread_t t1;\n    pthread_create(&t1, NULL, increment_func, NULL);\n    pthread_join(t1, NULL);\n    printf(\"Final value: %d\\n\", global_val);\n    return 0;\n}", "options": null}], "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1: במודל Many-to-One, מערכת ההפעלה רואה רק את תהליך הליבה היחיד. כאשר חוט משתמש מבצע קריאת מערכת חוסמת, הליבה מעבירה את כל התהליך למצב המתנה (Waiting/Blocked). כתוצאה מכך, כל שאר החוטים באותו תהליך ייחסמו ולא יוכלו לרוץ, גם אם הם מוכנים לביצוע פעולות חישוב.\n\n7.2: במודל One-to-One, כל חוט משתמש ממופה לחוט ליבה נפרד. אם חוט אחד מבצע קריאת מערכת חוסמת, הליבה חוסמת רק את חוט הליבה הספציפי הזה. המתזמן (Scheduler) של מערכת ההפעלה יכול להמשיך להריץ חוטים אחרים של אותו תהליך על מעבדים פנויים, מה שמאפשר מקביליות אמיתית ושיפור ביצועים.\n\n7.3: הפלט יהיה: Final value: 30. הסיבה היא שחוטים (Threads) בתוך אותו תהליך חולקים את אותו מרחב כתובות, ובפרט הם חולקים את סגמנט הנתונים (Data segment) שבו נמצאים משתנים גלובליים. לכן, השינוי שביצע חוט t1 במשתנה global_val נראה מיד לחוט הראשי (main thread) לאחר סיום הריצה (pthread_join)."}, "difficulty_estimation": "Medium", "_source_file": "0112__Threads__Open__Medium.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:42:02", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Threads", "Synchronization", "Condition Variables", "Deadlock"], "content": {"text": "במערכת הפעלה נתונה, ממומש מנגנון לניהול משאבים משותפים (Tokens). המנגנון מאפשר לתהליכונים לבקש מספר מסוים של אסימונים ולשחרר אותם בסיום השימוש. להלן קוד ה-C המממש את המנגנון באמצעות Pthreads:", "code_snippet": "#include <pthread.h>\n\nint available_tokens = 5;\npthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER;\npthread_cond_t c = PTHREAD_COND_INITIALIZER;\n\nvoid request_tokens(int n) {\n    pthread_mutex_lock(&m);\n    while (available_tokens < n) {\n        pthread_cond_wait(&c, &m);\n    }\n    available_tokens -= n;\n    pthread_mutex_unlock(&m);\n}\n\nvoid release_tokens(int n) {\n    pthread_mutex_lock(&m);\n    available_tokens += n;\n    pthread_cond_signal(&c);\n    pthread_mutex_unlock(&m);\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "הסבר מדוע השימוש ב-pthread_cond_signal בפונקציה release_tokens עלול להוביל למצב של Deadlock או הרעבה (Starvation) במערכת בה פועלים מספר תהליכונים המבקשים כמויות שונות של אסימונים. הדגם באמצעות תרחיש ספציפי.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "נניח שבתור למשתנה התנאי c ממתינים התהליכונים הבאים (לפי סדר הגעתם): T1 (מבקש 6 אסימונים), T2 (מבקש 2 אסימונים). כרגע available_tokens = 1. תהליכון T3 קורא ל-release_tokens(2). תאר את השתלשלות האירועים אם המימוש של pthread_cond_signal מעיר את התהליכון הראשון בתור (FIFO).", "code_snippet": null, "options": null}, {"id": "10.3", "text": "הצע שינוי מינימלי לקוד (שורת קוד אחת) שיפתור את הבעיה שהוצגה בסעיף 10.1, והסבר מדוע פתרון זה יעיל אך עלול להיות יקר מבחינת ביצועים.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: הבעיה נובעת מכך ש-pthread_cond_signal מעיר תהליכון אחד בלבד מהתור. אם התהליכון שהתעורר דורש יותר אסימונים ממה שיש כרגע ב-available_tokens, הוא יחזור לישון בתוך ה-while. הבעיה היא שהאות (signal) 'אבד' - ייתכן שישנם תהליכונים אחרים בתור שדרישתם קטנה יותר ויכלו להמשיך בריצה עם כמות האסימונים הנוכחית, אך הם לא התעוררו. אם כל התהליכונים שמשחררים אסימונים מסתמכים על signal בודד, המערכת עלולה להיתקע (Deadlock) למרות שיש מספיק משאבים.\n\n10.2: תרחיש: 1. available_tokens = 1. תהליכונים T1(6) ו-T2(2) ישנים בתור c. \n2. T3 משחרר 2 אסימונים: available_tokens מעודכן ל-3.\n3. T3 מבצע signal. לפי FIFO, התהליכון T1 מתעורר.\n4. T1 בודק את התנאי: 3 < 6, לכן הוא מבצע שוב wait וחוזר לישון.\n5. המשתנה available_tokens נשאר 3, אך T2 (שצריך רק 2) נשאר לישון כי אף אחד לא העיר אותו. המערכת במצב של Deadlock אם אין תהליכונים נוספים שיבצעו release.\n\n10.3: הפתרון הוא החלפת pthread_cond_signal(&c) ב-pthread_cond_broadcast(&c). פעולה זו תעיר את כל התהליכונים הממתינים. כל אחד מהם יבדוק את התנאי שלו בתורו (תחת הגנת המוטקס). מי שדרישתו נענית ימשיך, ומי שלא יחזור לישון. זה פותר את הבעיה כי מובטח שכל מי שיכול להתקדם יתעורר. החיסרון (Performance Overhead) הוא 'בעיית העדר' (Thundering Herd) - התעוררות המונית של תהליכונים שרובם יחזרו לישון מיד, מה שגורם להקשרים מיותרים (Context Switches) ותחרות על המוטקס."}, "difficulty_estimation": "Hard", "_source_file": "0113__Threads__Open__Hard.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:42:24", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Threads", "Process Management", "Synchronization"], "content": {"text": "לפניך קטע קוד בשפת C המשתמש בספריית pthreads. התוכנית מבצעת יצירת חוט (thread) ולאחר מכן מבצעת fork(). הנח כי כל הקריאות למערכת מצליחות וכי התזמון מתבצע בדיוק כפי שמתואר בהערות (ה-sleep מבטיח סדר פעולות מסוים).", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\npthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;\nint shared_data = 0;\n\nvoid* thread_work(void* arg) {\n    pthread_mutex_lock(&lock);\n    shared_data++;\n    sleep(5); // מחזיק את המנעול לזמן ממושך\n    pthread_mutex_unlock(&lock);\n    return NULL;\n}\n\nint main() {\n    pthread_t t1;\n    pthread_create(&t1, NULL, thread_work, NULL);\n    \n    sleep(1); // מבטיח ש-t1 יספיק לנעול את המוטקס\n\n    if (fork() == 0) {\n        // תהליך הבן\n        printf(\"Child process started...\\n\");\n        pthread_mutex_lock(&lock);\n        printf(\"Child: shared_data = %d\\n\", shared_data);\n        pthread_mutex_unlock(&lock);\n        return 0;\n    }\n\n    wait(NULL);\n    pthread_join(t1, NULL);\n    printf(\"Parent finished.\\n\");\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "האם תהליך הבן יצליח להדפיס את השורה \"Child: shared_data = 1\"? נמק את תשובתך תוך התייחסות למצב החוטים והמנעולים לאחר פעולת ה-fork().", "code_snippet": null, "options": null}, {"id": "10.2", "text": "כיצד ניתן להשתמש בפונקציה pthread_atfork() כדי לפתור את הבעיה שנוצרה? הסבר מה תפקיד כל אחד משלושת ה-handlers (prepare, parent, child).", "code_snippet": null, "options": null}, {"id": "10.3", "text": "נניח והמערכת הייתה משתמשת במודל Many-to-One (User-Level Threads) עבור ספריית ה-pthreads. כיצד הקריאה ל-sleep(5) בתוך thread_work הייתה משפיעה על ביצוע ה-fork() ב-main? הסבר.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: לא, תהליך הבן ייכנס למצב של Deadlock. כאשר מתבצע fork() בתהליך מרובה חוטים, רק החוט שקרא ל-fork() משוכפל לתהליך הבן. עם זאת, כל מצב הזיכרון (כולל המוטקסים) מועתק כפי שהוא. מכיוון שחוט t1 נעל את המוטקס לפני ה-fork, המוטקס בבן מועתק כשהוא במצב 'נעול'. מאחר וחוט t1 לא קיים בתהליך הבן, אין מי שישחרר את המנעול, והקריאה ל-pthread_mutex_lock בבן תחסום לעד.\n\n10.2: הפונקציה pthread_atfork(prepare, parent, child) מאפשרת לרשום פונקציות טיפול שיופעלו סביב ה-fork:\n- prepare: מופעלת בתהליך האב לפני ה-fork. שם ננעל את כל המוטקסים הרלוונטיים.\n- parent: מופעלת בתהליך האב לאחר ה-fork. שם נשחרר את המוטקסים.\n- child: מופעלת בתהליך הבן לאחר ה-fork. שם נשחרר את המוטקסים בתוך הכתובת של הבן (כך שהם יהיו פתוחים לשימוש בבן).\n\n10.3: במודל Many-to-One, כל החוטים של תהליך מסוים ממופים לחוט קרנל יחיד. אם חוט משתמש מבצע קריאת מערכת חוסמת (כמו sleep), הקרנל חוסם את כל תהליך המשתמש. לכן, thread_work יגרום לכל תהליך האב להיחסם ל-5 שניות, וה-main לא יגיע לקריאה ל-fork עד ש-t1 יסיים את ה-sleep וישחרר את המנעול. במקרה כזה, הבעיה מהסעיף הראשון לא תתרחש כי המנעול יהיה משוחרר בזמן ה-fork."}, "difficulty_estimation": "Hard", "_source_file": "0114__Threads__Open__Hard.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:42:49", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Threads", "Synchronization", "Read-Write Locks", "Starvation"], "content": {"text": "לפניך מימוש חלקי בשפת C למנגנון Read-Write Lock המשתמש ב-Mutex וב-Condition Variable. המטרה היא לאפשר למספר קוראים (Readers) לגשת למשאב בו-זמנית, אך לאפשר לכותב (Writer) אחד בלבד גישה בלעדית.\nענה על הסעיפים הבאים תוך פירוט והסבר.", "code_snippet": "typedef struct {\n    int readers;\n    int writer_active;\n    pthread_mutex_t lock;\n    pthread_cond_t cond;\n} rwlock_t;\n\nvoid read_lock(rwlock_t *rw) {\n    pthread_mutex_lock(&rw->lock);\n    while (rw->writer_active)\n        pthread_cond_wait(&rw->cond, &rw->lock);\n    rw->readers++;\n    pthread_mutex_unlock(&rw->lock);\n}\n\nvoid read_unlock(rwlock_t *rw) {\n    pthread_mutex_lock(&rw->lock);\n    rw->readers--;\n    if (rw->readers == 0)\n        pthread_cond_broadcast(&rw->cond);\n    pthread_mutex_unlock(&rw->lock);\n}\n\nvoid write_lock(rwlock_t *rw) {\n    pthread_mutex_lock(&rw->lock);\n    while (rw->writer_active || rw->readers > 0)\n        pthread_cond_wait(&rw->cond, &rw->lock);\n    rw->writer_active = 1;\n    pthread_mutex_unlock(&rw->lock);\n}\n\nvoid write_unlock(rwlock_t *rw) {\n    pthread_mutex_lock(&rw->lock);\n    rw->writer_active = 0;\n    pthread_cond_broadcast(&rw->cond);\n    pthread_mutex_unlock(&rw->lock);\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "האם המימוש הנתון סובל מבעיית הרעבה (Starvation)? אם כן, איזה סוג תהליכונים (קוראים או כותבים) עלול לסבול מהרעבה ובאילו תנאים?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "מדוע נעשה שימוש בלולאת while סביב הקריאה ל-pthread_cond_wait ולא בפקודת if? הסבר מה עלול לקרות אם נחליף את ה-while ב-if.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "נניח שהמערכת פועלת במודל תהליכונים Many-to-One (כלומר, כל תהליכוני המשתמש ממופים לתהליכון קרנל יחיד). תהליכון קורא מחזיק ב-lock ומבצע קריאת מערכת חוסמת (Blocking I/O) כגון read() מדיסק. כיצד הדבר ישפיע על תהליכון כותב הממתין ב-write_lock?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: כן, המימוש סובל מהרעבת כותבים (Writer Starvation). ב-read_lock, קורא חדש נחסם רק אם יש כותב פעיל (writer_active). אם יש קוראים פעילים וכותב ממתין ב-write_lock, קוראים חדשים שיגיעו יצליחו להעלות את rw->readers ולהיכנס למשאב, כי writer_active עדיין 0. אם זרם הקוראים הוא רציף, מספר הקוראים לעולם לא ירד ל-0, והכותב ימתין לנצח.\n\n1.2: השימוש ב-while הכרחי בגלל שתי סיבות: א. Spurious Wakeups - תהליכון עלול להתעורר מה-Condition Variable גם ללא שליחת סיגנל מפורש. ב. Mesa Semantics - ברגע שתהליכון מתעורר ומנסה לנעול את המוטקס מחדש, תהליכון אחר עלול 'להשתחל' ולשנות את התנאי (למשל, כותב אחר תפס את המשאב). לכן, יש לבדוק את התנאי שוב מיד עם החזרה מההמתנה.\n\n1.3: במודל Many-to-One, הקרנל אינו מודע לקיום תהליכוני המשתמש ורואה רק את תהליך ה-LWP היחיד. כאשר תהליכון משתמש מבצע קריאת מערכת חוסמת, כל התהליך (על כל תהליכוניו) נחסם ע\"י הקרנל. לכן, הכותב הממתין לא יוכל לקבל זמן מעבד אפילו אם הקורא סיים את פעולת ה-I/O, עד שהקרנל לא יחזיר את התהליך כולו למצב Ready."}, "difficulty_estimation": "Hard", "_source_file": "0115__Threads__Open__Hard.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:43:16", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Threads", "Process Management", "Synchronization", "Deadlock"], "content": {"text": "במערכות הפעלה מודרניות, השילוב בין יצירת תהליכים (fork) לבין שימוש בחוטים (threads) עשוי להוביל למצבים מורכבים ובעייתיים. לפניכם קוד C המדגים סיטואציה כזו. הניחו כי כל הקריאות למערכת מצליחות וכי התזמון מתבצע בדיוק כפי שמתואר בהערות (sleep).", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\npthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;\n\nvoid* thread_A(void* arg) {\n    pthread_mutex_lock(&lock);\n    printf(\"Thread A: Locked mutex, performing long task...\\n\");\n    sleep(10); \n    pthread_mutex_unlock(&lock);\n    return NULL;\n}\n\nvoid* thread_B(void* arg) {\n    sleep(1); // הבטחה שחוט א' יתפוס את המנעול קודם\n    printf(\"Thread B: Forking now...\\n\");\n    pid_t pid = fork();\n    \n    if (pid == 0) {\n        // תהליך הבן\n        printf(\"Child process: Attempting to lock mutex...\\n\");\n        pthread_mutex_lock(&lock);\n        printf(\"Child process: Success! Locked!\\n\");\n        pthread_mutex_unlock(&lock);\n    } else {\n        // תהליך האב\n        wait(NULL);\n        printf(\"Parent process: Child finished.\\n\");\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, thread_A, NULL);\n    pthread_create(&t2, NULL, thread_B, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "האם תהליך הבן יצליח להדפיס את השורה \"Child process: Success! Locked!\"? נמקו את תשובתכם תוך התייחסות למה שקורה לחוטים (Threads) ולמבני הנתונים בזיכרון בזמן ביצוע fork().", "code_snippet": null, "options": null}, {"id": "10.2", "text": "כיצד מנגנון ה-Copy-on-Write (COW) משפיע על מצב המנעול (mutex) בזיכרון של תהליך הבן ברגע ה-fork?", "code_snippet": null, "options": null}, {"id": "10.3", "text": "הציעו פתרון המשתמש בפונקציה pthread_atfork. הסבירו מה תפקידן של שלוש פונקציות ה-callback (prepare, parent, child) וכיצד הן מונעות את הבעיה שהתגלתה בסעיף 10.1.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: לא, תהליך הבן ייכנס למצב של Deadlock (קיפאון). כאשר מתבצע fork() בתהליך מרובה חוטים, רק החוט שקרא ל-fork() משוכפל בתהליך הבן. כל שאר החוטים (במקרה זה Thread A) אינם קיימים בבן. מכיוון ש-Thread A החזיק במנעול בזמן ה-fork, המנעול מועתק לבן כשהוא במצב 'תפוס' (Locked). מכיוון ש-Thread A לא קיים בבן כדי לשחרר את המנעול, החוט היחיד בבן ימתין לנצח.\n\n10.2: מנגנון ה-COW מבטיח שכל מרחב הכתובות, כולל מצב המנעול בזיכרון, יועתק לוגית לבן. בזיכרון הפיזי, עד שלא יבוצע שינוי, הבן והאב חולקים את אותם דפים. לכן, ביט ה-lock בתוך מבנה הנתונים של ה-mutex יועתק כשהוא דלוק (1). העובדה שמדובר בעותק נפרד (בסופו של דבר) לא עוזרת כאן, כי המצב הפנימי של האובייקט מעיד על כך שהוא תפוס על ידי ישות שאינה קיימת בבן.\n\n10.3: הפונקציה pthread_atfork מאפשרת לרשום פונקציות שירוצו בנקודות זמן קריטיות סביב ה-fork:\n1. prepare: רצה באב לפני ה-fork. עליה לנעול את המנעול (pthread_mutex_lock) כדי להבטיח מצב עקבי.\n2. parent: רצה באב אחרי ה-fork. עליה לשחרר את המנעול (pthread_mutex_unlock).\n3. child: רצה בבן אחרי ה-fork. עליה לשחרר את המנעול או לאתחל אותו מחדש. \nבצורה זו, מובטח שבזמן השכפול המנעול מוחזק ע\"י החוט המבצע, ולכן בבן הוא 'ישתחרר' בצורה מסודרת ע\"י פונקציית ה-child."}, "difficulty_estimation": "Hard", "_source_file": "0116__Threads__Open__Hard.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:43:37", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Threads", "Synchronization", "Process Management", "Deadlock"], "content": {"text": "נתון קטע הקוד הבא בשפת C המשתמש בספריית pthreads ובפקודת המערכת fork. הנח כי התוכנית רצה על מערכת Linux מודרנית וכי כל הקריאות למערכת (pthread_create, fork) מצליחות. ענה על הסעיפים הבאים תוך פירוט ונימוק מלא.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\npthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;\nint counter = 100;\n\nvoid* thread_work(void* arg) {\n    pthread_mutex_lock(&lock);\n    counter += 50;\n    sleep(20); // Hold the lock for a long time\n    pthread_mutex_unlock(&lock);\n    return NULL;\n}\n\nint main() {\n    pthread_t t1;\n    pthread_create(&t1, NULL, thread_work, NULL);\n    \n    sleep(2); // Ensure thread_work starts and acquires the lock\n    \n    pid_t pid = fork();\n    if (pid == 0) {\n        // Child process\n        printf(\"Child: Attempting to lock...\\n\");\n        pthread_mutex_lock(&lock);\n        counter += 10;\n        printf(\"Child counter: %d\\n\", counter);\n        pthread_mutex_unlock(&lock);\n    } else {\n        // Parent process\n        wait(NULL);\n        printf(\"Parent counter: %d\\n\", counter);\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "כמה תהליכים וכמה חוטים (threads) סה\"כ יהיו קיימים במערכת מיד לאחר ביצוע שורת ה-fork? פרט כמה בכל תהליך.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "האם תהליך הבן יצליח להדפיס את השורה \"Child counter: ...\"? הסבר את המנגנון הגורם לכך/מונע זאת.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "נניח שהורדנו את השורה (pthread_mutex_lock(&lock)) ואת ה-unlock מתהליך הבן. מה יהיה הפלט של תהליך האב ומה יהיה הפלט של תהליך הבן? התייחס למנגנון ה-Copy-on-Write.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: לאחר ה-fork יהיו 2 תהליכים. בתהליך האב יהיו 2 חוטים (החוט הראשי והחוט t1 שנוצר). בתהליך הבן יהיה חוט אחד בלבד. זאת מכיוון שעל פי תקן POSIX, כאשר תהליך מרובה חוטים מבצע fork, רק החוט שקרא ל-fork משוכפל לתהליך הבן. שאר החוטים אינם קיימים בבן.\n\n1.2: לא, תהליך הבן לא ידפיס את השורה. הוא ייכנס למצב של Deadlock. הסיבה היא שה-mutex משוכפל כחלק ממרחב הזיכרון של התהליך. מכיוון שבאב החוט t1 החזיק בנעילה בזמן ה-fork, ה-mutex משוכפל לבן כשהוא במצב 'נעול'. אולם, החוט שהחזיק בנעילה (t1) לא קיים בתהליך הבן, ולכן אין אף חוט שיכול לשחרר את הנעילה. החוט היחיד בבן ימתין לנצח ב-pthread_mutex_lock.\n\n1.3: אם נסיר את הנעילה בבן, הבן ידפיס: 'Child counter: 160' (הוא יורש את ה-counter מהאב אחרי ש-t1 כבר הוסיף 50, ואז מוסיף 10 משלו). האב ידפיס: 'Parent counter: 150'. למרות שהמשתנה גלובלי, fork יוצר מרחב כתובות נפרד. בתחילה שני התהליכים מצביעים לאותם דפים פיזיים (Copy-on-Write), אך ברגע שהבן מבצע כתיבה (counter += 10), נוצר עותק פרטי של הדף עבורו, ולכן השינוי בבן לא משפיע על האב."}, "difficulty_estimation": "Hard", "_source_file": "0117__Threads__Open__Hard.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:43:55", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Threads", "Synchronization", "Mutex", "Condition Variables"], "content": {"text": "לפניכם קוד בשפת C המשתמש בספריית pthreads לניהול סנכרון בין תהליכונים. במערכת קיימים שני סוגי תהליכונים: 'Increasers' המעלים מונה משותף, ו-'Checkers' הממתינים שהמונה יגיע לערך סף N ואז מפחיתים ממנו. הנח כי כל הקריאות לפונקציות pthreads מצליחות ושאין בעיות זיכרון.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#define N 5\nint counter = 0;\npthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;\npthread_cond_t cond = PTHREAD_COND_INITIALIZER;\n\nvoid* increaser(void* arg) {\n    for(int i = 0; i < 1000; i++) {\n        pthread_mutex_lock(&lock);\n        counter++;\n        if (counter >= N) {\n            pthread_cond_broadcast(&cond);\n        }\n        pthread_mutex_unlock(&lock);\n    }\n    return NULL;\n}\n\nvoid* checker(void* arg) {\n    pthread_mutex_lock(&lock);\n    while (counter < N) {\n        pthread_cond_wait(&cond, &lock);\n    }\n    counter -= N;\n    pthread_mutex_unlock(&lock);\n    return NULL;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "מה יהיה הערך הסופי של המשתנה הגלובלי `counter` אם נריץ 10 תהליכוני `increaser` ו-2 תהליכוני `checker`, בהנחה שכל התהליכונים סיימו את ביצועם? פרטו את החישוב.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "מדוע נעשה שימוש בלולאת `while` בשורה `while (counter < N)` בתוך פונקציית ה-`checker`? תארו תרחיש ספציפי (interleaving) שבו החלפת ה-`while` ב-`if` תוביל למצב שבו `counter` יהיה שלילי.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "נניח שהחלפנו את `pthread_cond_broadcast` ב-`pthread_cond_signal`. האם ייתכן מצב שבו תהליכון `checker` ימתין לנצח (Deadlock/Starvation) למרות שהתנאי `counter >= N` התקיים בשלב כלשהו? הסבירו.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: כל תהליכון increaser מבצע 1000 הגדלות. ישנם 10 תהליכונים כאלו, לכן סה\"כ יתבצעו 10,000 הגדלות (10 * 1000). כל תהליכון checker מבצע הפחתה אחת של הערך N (שהוא 5). ישנם 2 תהליכונים כאלו, לכן סה\"כ יופחתו 10 (2 * 5). הערך הסופי יהיה: 10,000 - 10 = 9,990.\n\n1.2: השימוש ב-while הכרחי בגלל Mesa Semantics. תרחיש שבו if יכשל: נניח ש-counter=4. שני תהליכוני checker (נקרא להם C1 ו-C2) נכנסים להמתנה ב-cond_wait. תהליכון increaser מעלה את המונה ל-5 וקורא ל-broadcast. שני ה-checkers מתעוררים ומנסים להשיג את ה-mutex. C1 משיג את ה-mutex ראשון, בודק את התנאי (שכבר נבדק לפני ה-wait), מפחית 5 מהמונה (counter=0) ומשחרר את ה-mutex. כעת C2 משיג את ה-mutex. אם היה נעשה שימוש ב-if, הוא היה ממשיך ישר להפחתה ומחסיר 5 מ-0, מה שמוביל ל-counter=-5. שימוש ב-while מכריח את C2 לבדוק שוב את התנאי, לגלות שהוא שוב קטן מ-N ולחזור להמתין.\n\n1.3: כן. במצב שבו יש מספר checkers הממתינים, signal מעיר רק תהליכון אחד. אם התהליכון שהתעורר לא מצליח לסיים את עבודתו (למשל, אם התנאי השתנה שוב לפני שהשיג את ה-lock) או אם ישנם מספר checkers שצריכים להתעורר כדי לצרוך את המשאבים שהצטברו (למשל counter=10), שימוש ב-signal עלול להשאיר checkers אחרים ישנים לנצח למרות שהמשאב זמין. עם זאת, בקוד הספציפי הזה, הבעיה העיקרית ב-signal היא אובדן הודעות (Lost Wakeups) אם ה-signal נשלח כשאין אף אחד שממתין, אך כאן ה-broadcast מבטיח שכל מי שצריך להתעורר יתעורר."}, "difficulty_estimation": "Hard", "_source_file": "0118__Threads__Open__Hard.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:44:21", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Threads", "Process Management", "Synchronization", "Deadlock"], "content": {"text": "נתון קוד בשפת C המשתמש בספריית pthreads. התוכנית מדגימה אינטראקציה בין חוטים (threads) לבין יצירת תהליך חדש באמצעות fork. עליכם לנתח את התנהגות המערכת ולענות על השאלות הבאות. הניחו כי כל הקריאות למערכת מצליחות וכי התזמון מתבצע בדיוק כפי שמתואר ב-sleep.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint counter = 0;\npthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;\n\nvoid* thread_func(void* arg) {\n    pthread_mutex_lock(&lock);\n    counter++;\n    sleep(10); // מדמה עבודה ממושכת תחת נעילה\n    pthread_mutex_unlock(&lock);\n    return NULL;\n}\n\nint main() {\n    pthread_t t1;\n    pthread_create(&t1, NULL, thread_func, NULL);\n    sleep(1); // מבטיח שהחוט t1 התחיל ונעל את המוטקס\n\n    int pid = fork();\n    if (pid == 0) {\n        // תהליך הבן\n        printf(\"Child: Attempting to lock...\\n\");\n        pthread_mutex_lock(&lock);\n        printf(\"Child: Counter is %d\\n\", counter);\n        pthread_mutex_unlock(&lock);\n        return 0;\n    } else {\n        // תהליך האב\n        wait(NULL);\n        printf(\"Parent: Finished\\n\");\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "האם תהליך הבן ידפיס את השורה \"Child: Counter is 1\"? נמקו את תשובתכם תוך התייחסות למצב ה-Mutex ולמבנה התהליך בבן.", "code_snippet": null, "options": null}, {"id": "7.2", "text": "מה יקרה לתהליך האב במקרה זה? האם הוא יגיע להדפסה \"Parent: Finished\"?", "code_snippet": null, "options": null}, {"id": "7.3", "text": "כיצד שימוש בפונקציה pthread_atfork יכול לפתור את הבעיה? הסבירו את תפקיד שלושת ה-callbacks שהיא מקבלת.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1: לא, תהליך הבן לא ידפיס את השורה. ב-POSIX, כאשר תהליך המכיל מספר חוטים מבצע fork, רק החוט שקרא ל-fork משוכפל לתהליך הבן. החוט thread_func שביצע את הנעילה אינו קיים בבן. עם זאת, ה-fork מעתיק את כל מרחב הכתובות כפי שהוא, כולל את מצב ה-Mutex. מכיוון שהמוטקס היה נעול באב ברגע ה-fork, הוא מועתק כשהוא במצב 'נעול' לבן. כיוון שהחוט היחיד שיכול לשחרר את הנעילה (thread_func) לא קיים בבן, הבן ייכנס למצב של Deadlock בניסיון לנעול את המוטקס.\n\n7.2: תהליך האב לא יסיים את ריצתו. האב קורא ל-wait(NULL) וממתין לסיום תהליך הבן. מכיוון שתהליך הבן תקוע ב-Deadlock ולעולם לא יסתיים, האב יישאר במצב המתנה (Blocked) לנצח.\n\n7.3: הפונקציה pthread_atfork מאפשרת לרשום handlers שירוצו בנקודות זמן קריטיות סביב ה-fork: \n1. prepare: רץ באב לפני ה-fork. שם ננעל את כל המוטקסים כדי להבטיח מצב עקבי.\n2. parent: רץ באב מיד אחרי ה-fork. שם נשחרר את המוטקסים.\n3. child: רץ בבן מיד אחרי ה-fork. שם נשחרר (re-initialize/unlock) את המוטקסים כדי שהבן יתחיל עם מוטקסים פתוחים ויוכל להשתמש בהם."}, "difficulty_estimation": "Hard", "_source_file": "0119__Threads__Open__Hard.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:44:44", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Threads", "Synchronization", "Race Conditions", "Pthreads"], "content": {"text": "לפניכם מימוש בשפת C של מנגנון 'מחסום' (Barrier) המיועד לשימוש על ידי N תהליכונים (Threads). המטרה היא שכל תהליכון ימתין בנקודת המחסום עד שכל ה-N תהליכונים יגיעו אליה, ורק אז כולם ימשיכו בביצוע. המתכנת מעוניין שהמחסום יהיה 'רב-פעמי' (Reusable), כלומר שניתן יהיה להשתמש בו בלולאה.", "code_snippet": "int count = 0;\npthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER;\npthread_cond_t cv = PTHREAD_COND_INITIALIZER;\n\nvoid barrier_wait(int N) {\n    pthread_mutex_lock(&m);\n    count++;\n    if (count == N) {\n        count = 0;\n        pthread_cond_broadcast(&cv);\n    } else {\n        pthread_cond_wait(&cv, &m);\n    }\n    pthread_mutex_unlock(&m);\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "נניח שהתהליכונים מריצים את הפונקציה הבאה: \nvoid* worker(void* arg) {\n    for(int i=0; i<100; i++) {\n        // Do some work\n        barrier_wait(N);\n    }\n    return NULL;\n}\nהסבירו מדוע המימוש הנתון של barrier_wait אינו תקין עבור שימוש חוזר (reusable barrier) ועלול לגרום לקיפאון (Deadlock) או להתנהגות לא צפויה.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "כיצד תופעת ה-Spurious Wakeup משפיעה על הקוד הנתון? הציעו תיקון לקוד הקיים (ברמת הלוגיקה) שפותר גם את בעיית ה-Spurious Wakeup וגם את בעיית השימוש החוזר.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "6.1: הבעיה המרכזית במימוש היא ה-Race Condition שנוצר בין איטרציות שונות של הלולאה. כאשר התהליכון ה-N מגיע, הוא מאפס את count ל-0 ומבצע broadcast. תהליכון 'מהיר' עשוי להתעורר, לסיים את barrier_wait, לבצע את העבודה של האיטרציה הבאה ולקרוא שוב ל-barrier_wait לפני שתהליכון 'איטי' מהאיטרציה הקודמת בכלל הצליח להתעורר או לצאת מהפונקציה. התהליכון המהיר יקדם את count ל-1, בעוד שתהליכונים אחרים עדיין שייכים ל'סיבוב' הקודם. במצב קיצוני, תהליכון מהיר יכול להשלים סיבוב שלם ולגרום ל-broadcast נוסף בזמן שתהליכונים מהסיבוב הקודם עדיין מחכים, מה שיגרום לערבוב של תהליכונים מאיטרציות שונות וסיכוי גבוה לקיפאון (Deadlock) כי ה-count לא ישקף נכונה את מספר המחכים לסיבוב הנוכחי.\n\n6.2: Spurious Wakeup היא תופעה בה תהליכון מתעורר מ-pthread_cond_wait ללא קבלת סיגנל. בקוד הנתון, אם תהליכון מתעורר בטעות לפני ש-count == N, הוא ימשיך לביצוע (Phase 2) למרות ששאר התהליכונים טרם הגיעו. הפתרון המקובל הוא עטיפת ה-wait בלולאת while. \nכדי לפתור את שתי הבעיות (כולל ה-reusable barrier), ניתן להשתמש בטכניקה של 'דורות' (Generations) או Sense-Reversing Barrier. בשיטה זו, מחזיקים משתנה נוסף המייצג את הדור הנוכחי. תהליכון מחכה עד שהדור משתנה: \nvoid barrier_wait(int N) {\n    pthread_mutex_lock(&m);\n    int my_gen = generation;\n    count++;\n    if (count == N) {\n        count = 0;\n        generation++;\n        pthread_cond_broadcast(&cv);\n    } else {\n        while (my_gen == generation)\n            pthread_cond_wait(&cv, &m);\n    }\n    pthread_mutex_unlock(&m);\n}\nכך, גם אם תהליכון מהיר נכנס שוב, הוא יגדיל את count עבור הדור הבא, בעוד שהתהליכונים האיטיים מחכים לשינוי ב-generation."}, "difficulty_estimation": "Hard", "_source_file": "0120__Threads__Open__Hard.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:45:03", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Concurrency", "Race Condition"], "content": {"text": "לפניכם קוד בשפת C המשתמש בספריית pthreads. נניח שכל הקריאות למערכת מצליחות והתוכנית רצה על מערכת עם מעבד מרובה ליבות. מה ניתן לומר על הפלט של התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint count = 0;\n\nvoid* task(void* arg) {\n    for (int i = 0; i < 1000; i++) {\n        count++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, task, NULL);\n    pthread_create(&t2, NULL, task, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"%d\", count);\n    return 0;\n}", "options": ["הפלט יהיה תמיד 1000.", "הפלט יהיה תמיד 2000.", "הפלט יהיה בטווח [2, 2000] ולא ניתן לחיזוי מראש.", "התוכנית לא תעבור קומפילציה כי count הוא משתנה גלובלי."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "הפלט יהיה בטווח [2, 2000] ולא ניתן לחיזוי מראש.", "explanation": "הקוד מדגים מצב מרוץ (Race Condition). הפעולה ++count אינה פעולה אטומית (Atomic Operation) ברמת שפת המכונה; היא מורכבת משלושה שלבים: קריאת הערך מהזיכרון לרגיסטר, הוספת 1, וכתיבת הערך חזרה לזיכרון. מכיוון ששני החוטים (Threads) ניגשים לאותו משתנה גלובלי ומשנים אותו ללא מנגנון סנכרון (כמו Mutex), חוט אחד עלול לקרוא ערך ישן בזמן שהחוט השני מעדכן אותו, ובכך 'לדרוס' את העדכון של החוט השני. לכן, התוצאה הסופית אינה דטרמיניסטית ויכולה להיות כל ערך בין 2 ל-2000 (במקרים קיצוניים של תזמון)."}, "difficulty_estimation": "Easy", "_source_file": "0121__Threads__CodeAnalysis__Easy.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:45:20", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Threads", "Pthreads", "Shared Memory"], "content": {"text": "לפניך קטע קוד בשפת C המשתמש בספריית pthreads. מה יהיה הפלט של התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint shared_val = 5;\n\nvoid* thread_func(void* arg) {\n    int val = *((int*)arg);\n    shared_val += val;\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    int a = 10, b = 20;\n\n    pthread_create(&t1, NULL, thread_func, &a);\n    pthread_join(t1, NULL);\n\n    pthread_create(&t2, NULL, thread_func, &b);\n    pthread_join(t2, NULL);\n\n    printf(\"%d\", shared_val);\n    return 0;\n}", "options": ["5", "15", "25", "35"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "35", "explanation": "התוכנית מתחילה עם משתנה גלובלי shared_val שערכו 5. בשלב הראשון נוצר חוט t1 שמקבל את הערך 10 ומוסיף אותו ל-shared_val. מכיוון שמתבצע pthread_join מיד לאחר מכן, תהליך ה-main עוצר ומחכה ש-t1 יסיים. לאחר ש-t1 מסיים, ערכו של shared_val הוא 15. רק אז נוצר חוט t2 שמקבל את הערך 20 ומוסיף אותו ל-shared_val. שוב מתבצע join ולכן ה-main מחכה ל-t2. בסיום, shared_val שווה ל-35 והוא מודפס למסך. מכיוון שהצטרפות החוטים (join) נעשית באופן סדרתי, אין כאן מצב מרוץ (Race Condition) והתוצאה דטרמיניסטית."}, "difficulty_estimation": "Easy", "_source_file": "0122__Threads__CodeAnalysis__Easy.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:45:35", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Pthreads"], "content": {"text": "מה יהיה הפלט של התוכנית הבאה המשתמשת בספריית pthreads? הניחו כי כל הקריאות לספרייה מצליחות.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint counter = 5;\n\nvoid* task(void* arg) {\n    counter += 10;\n    return NULL;\n}\n\nint main() {\n    pthread_t t1;\n    pthread_create(&t1, NULL, task, NULL);\n    pthread_join(t1, NULL);\n    printf(\"%d\", counter);\n    return 0;\n}", "options": ["5", "10", "15", "ערך לא ידוע עקב Race Condition"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "15", "explanation": "התוכנית יוצרת חוט (Thread) חדש שמבצע את הפונקציה task. פונקציה זו מוסיפה 10 למשתנה הגלובלי counter, שערכו ההתחלתי הוא 5. מכיוון שהתהליך הראשי קורא ל-pthread_join, הוא ממתין לסיום הביצוע של חוט t1 לפני שהוא ממשיך לשורת ההדפסה. לכן, מובטח כי הפעולה בחוט תסתיים לפני ה-printf, והתוצאה תהיה 15. אין כאן Race Condition על אף הגישה למשתנה משותף, כיוון שה-join מסנכרן את סדר הפעולות."}, "difficulty_estimation": "Easy", "_source_file": "0123__Threads__CodeAnalysis__Easy.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:45:45", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Shared Memory"], "content": {"text": "נתון קטע הקוד הבא בשפת C המשתמש בספריית pthreads. מה יהיה הפלט של התוכנית בהנחה שכל הקריאות למערכת מצליחות?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint x = 10;\n\nvoid* thread_func(void* arg) {\n    x += 5;\n    return NULL;\n}\n\nint main() {\n    pthread_t t;\n    pthread_create(&t, NULL, thread_func, NULL);\n    pthread_join(t, NULL);\n    printf(\"%d\", x);\n    return 0;\n}", "options": ["5", "10", "15", "0"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "15", "explanation": "התוכנית מגדירה משתנה גלובלי x המאותחל ל-10. חוטים (threads) באותו תהליך חולקים את אותו מרחב כתובות, ולכן לחוט החדש שנוצר יש גישה ישירה למשתנה x. הפונקציה thread_func מוסיפה 5 לערך של x. הפונקציה pthread_join גורמת לחוט הראשי (main) להמתין עד שהחוט החדש יסיים את פעולתו לפני שהוא ממשיך לשורת ההדפסה. לכן, בזמן הקריאה ל-printf, הערך של x כבר עודכן ל-15."}, "difficulty_estimation": "Easy", "_source_file": "0124__Threads__CodeAnalysis__Easy.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:46:05", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בספריית pthreads. מה יהיה הפלט של התוכנית בהנחה שכל קריאות המערכת מצליחות?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint x = 10;\n\nvoid* my_thread(void* arg) {\n    x = x * 2;\n    return NULL;\n}\n\nint main() {\n    pthread_t t;\n    pthread_create(&t, NULL, my_thread, NULL);\n    pthread_join(t, NULL);\n    printf(\"%d\", x);\n    return 0;\n}", "options": ["10", "20", "0", "הפלט אינו קבוע"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "20", "explanation": "התוכנית מגדירה משתנה גלובלי x המשותף לכל החוטים בתהליך. חוט חדש נוצר ומבצע הכפלה של x ב-2. הפונקציה pthread_join גורמת לחוט הראשי (main) להמתין עד לסיום ביצועו של החוט החדש. לכן, ההדפסה תתבצע רק לאחר ש-x עודכן ל-20."}, "difficulty_estimation": "Easy", "_source_file": "0125__Threads__CodeAnalysis__Easy.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:46:16", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Shared Memory"], "content": {"text": "מה יהיה הפלט של התוכנית הבאה המשתמשת בחוטים (threads)? הניחו שכל הקריאות למערכת מצליחות.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint counter = 10;\n\nvoid* func(void* arg) {\n    counter += 5;\n    return NULL;\n}\n\nint main() {\n    pthread_t t1;\n    pthread_create(&t1, NULL, func, NULL);\n    pthread_join(t1, NULL);\n    printf(\"%d\", counter);\n    return 0;\n}", "options": ["5", "10", "15", "הפלט אינו קבוע"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "15", "explanation": "התוכנית מגדירה משתנה גלובלי בשם counter עם ערך התחלתי 10. בתוך ה-main נוצר חוט (thread) חדש המריץ את הפונקציה func, אשר מוסיפה 5 למשתנה הגלובלי. מכיוון שהתהליך הראשי קורא ל-pthread_join, הוא ממתין עד לסיום ביצוע החוט t1 לפני שהוא ממשיך לשורת ההדפסה. לכן, מובטח שהשינוי למשתנה counter יתבצע לפני ההדפסה, והתוצאה תהיה 15."}, "difficulty_estimation": "Easy", "_source_file": "0126__Threads__CodeAnalysis__Easy.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:46:26", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Concurrency", "Race Conditions"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בספריית pthreads. מהם הערכים האפשריים שיכולים להיות מודפסים ע\"י פקודת ה-printf בסיום ריצת התוכנית?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0;\n\nvoid* thread_func(void* arg) {\n    int temp = counter;\n    counter = temp + 1;\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, thread_func, NULL);\n    pthread_create(&t2, NULL, thread_func, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"%d\", counter);\n    return 0;\n}", "options": ["0", "1", "2", "1 או 2"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "1 או 2", "explanation": "הקוד יוצר שני חוטים (threads) הניגשים לאותו משתנה גלובלי (counter) ללא שימוש במנגנוני סנכרון כמו Mutex. במצב שבו החוטים רצים אחד אחרי השני באופן מלא, הערך הסופי יהיה 2. אולם, ייתכן מצב של Race Condition שבו שני החוטים קוראים את הערך ההתחלתי 0 לתוך המשתנה המקומי temp, שניהם מחשבים temp + 1 = 1, ושניהם כותבים את הערך 1 חזרה למשתנה הגלובלי. במקרה כזה, אחת מההגדלות תאבד והפלט יהיה 1."}, "difficulty_estimation": "Easy", "_source_file": "0127__Threads__CodeAnalysis__Easy.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:46:49", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Threads", "Shared Memory"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בספריית pthreads. מה יהיה הפלט של התוכנית בהנחה שכל קריאות המערכת מצליחות?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint global_var = 20;\n\nvoid* thread_routine(void* arg) {\n    global_var += 30;\n    return NULL;\n}\n\nint main() {\n    pthread_t tid;\n    if (pthread_create(&tid, NULL, thread_routine, NULL) != 0) {\n        return 1;\n    }\n    pthread_join(tid, NULL);\n    printf(\"%d\", global_var);\n    return 0;\n}", "options": ["20", "30", "50", "הפלט אינו דטרמיניסטי"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "50", "explanation": "בניגוד לתהליכים הנוצרים על ידי fork, חוטים (threads) בתוך אותו תהליך חולקים את אותו מרחב כתובות, ובפרט את המשתנים הגלובליים. החוט שנוצר ב-pthread_create ניגש למשתנה global_var ומעדכן אותו ל-50 (20+30). מכיוון שהחוט הראשי קורא ל-pthread_join, הוא ממתין לסיום ביצוע החוט השני לפני שהוא ממשיך להדפסה, ולכן יודפס הערך המעודכן 50."}, "difficulty_estimation": "Easy", "_source_file": "0128__Threads__CodeAnalysis__Easy.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:47:04", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Concurrency", "Memory Sharing", "Pthreads"], "content": {"text": "לפניך קטע קוד בשפת C המשתמש בספריית pthreads. מה מהבאים מתאר נכונה את הפלטים האפשריים של התוכנית? הניחו כי כל הקריאות למערכת מצליחות.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n\nvoid* print_val(void* arg) {\n    int val = *((int*)arg);\n    printf(\"%d\", val);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[3];\n    for (int i = 0; i < 3; i++) {\n        pthread_create(&threads[i], NULL, print_val, &i);\n    }\n    for (int i = 0; i < 3; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    return 0;\n}", "options": ["א. הפלט תמיד יהיה 012 (בסדר כלשהו).", "ב. הפלט תמיד יהיה 333.", "ג. ייתכנו פלטים כמו 123, 333, או 023.", "ד. התוכנית תדפיס תמיד 000 כיוון שזה הערך ההתחלתי של i."]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הבעיה המרכזית בקוד היא שכל שלושת החוטים (threads) מקבלים כארגומנט את הכתובת של אותו משתנה מקומי i (כלומר &i). כיוון שהחוטים רצים במקביל ללולאת ה-main, הערך בכתובת זו עשוי להשתנות על ידי לולאת ה-for בטרם החוט הספיק לקרוא אותו. בסיום הלולאה הראשונה, ערכו של i הוא 3. לכן, כל חוט עשוי לקרוא כל ערך ש-i קיבל במהלך הריצה (0, 1, 2) או את הערך הסופי (3), תלוי בתזמון (scheduling) של החוטים ביחס ללולאה ב-main. לכן פלטים המכילים 3 או חזרות על מספרים הם אפשריים בהחלט."}, "difficulty_estimation": "Medium", "_source_file": "0129__Threads__CodeAnalysis__Medium.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:47:17", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Race Conditions", "Concurrency"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בספריית pthreads. בתוכנית זו, שני חוטים ניגשים למשתנה גלובלי משותף x ומעדכנים אותו ללא שימוש במנגנוני סנכרון (כגון Mutex). מהו הערך המינימלי האפשרי שיודפס על המסך בסיום ריצת התוכנית? הניחו שפעולת העדכון x = x + y מורכבת משלושה שלבים: קריאת הערך של x מהזיכרון לאוגר, הוספת y לאוגר, וכתיבת הערך מהאוגר חזרה לזיכרון.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint x = 10;\n\nvoid* thread_func(void* arg) {\n    int y = *(int*)arg;\n    x = x + y;\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    int val1 = 5, val2 = 10;\n    pthread_create(&t1, NULL, thread_func, &val1);\n    pthread_create(&t2, NULL, thread_func, &val2);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"%d\\n\", x);\n    return 0;\n}", "options": ["א. 10", "ב. 15", "ג. 20", "ד. 25"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הערך ההתחלתי של x הוא 10. חוט t1 אמור להוסיף 5 (סך הכל 15) וחוט t2 אמור להוסיף 10 (סך הכל 20). ללא סנכרון, תיתכן תחרות (Race Condition). הערך המינימלי מתקבל בתרחיש הבא: 1. חוט t1 קורא את הערך x=10 לתוך אוגר מקומי. 2. מתבצעת החלפת הקשר (Context Switch) וחוט t2 רץ במלואו: הוא קורא 10, מוסיף 10 וכותב 20 ל-x. 3. חוט t1 ממשיך מהנקודה שעצר: באוגר שלו עדיין שמור הערך 10, הוא מוסיף לו 5 וכותב את התוצאה 15 לתוך x. פעולה זו דורסת את העדכון של חוט t2. לכן, הערך המינימלי האפשרי הוא 15."}, "difficulty_estimation": "Medium", "_source_file": "0130__Threads__CodeAnalysis__Medium.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:47:49", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Pthreads", "Race Conditions", "Memory Sharing"], "content": {"text": "לפניכם קוד בשפת C המשתמש בספריית pthreads. התוכנית יוצרת שלושה חוטים (threads), כאשר כל חוט אמור להדפיס את אינדקס הלולאה שבו הוא נוצר. מה ניתן לומר על הפלט של התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nvoid* print_id(void* arg) {\n    int id = *(int*)arg;\n    printf(\"%d \", id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[3];\n    for (int i = 0; i < 3; i++) {\n        pthread_create(&threads[i], NULL, print_id, &i);\n    }\n    for (int i = 0; i < 3; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    return 0;\n}", "options": ["א. הפלט יהיה תמיד 0 1 2 בסדר כלשהו.", "ב. הפלט יהיה תמיד 0 1 2 בסדר עולה.", "ג. ייתכן שהפלט יכיל ערכים כפולים (למשל 1 1 2) או את הערך 3.", "ד. הקוד לא יתקמפל עקב ניסיון להעביר מצביע למשתנה מקומי.", "ה. הפלט יהיה תמיד 3 3 3."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הבעיה בקוד נובעת מכך שכל החוטים מקבלים כארגומנט את אותה הכתובת בזיכרון - הכתובת של המשתנה i שנמצא במחסנית של פונקציית ה-main. מכיוון שהחוטים רצים במקביל לחוט הראשי שמקדם את i, נוצר מצב של מרוץ (Race Condition). עד שחוט מסוים מספיק לבצע את ה-dereference למצביע שקיבל, ערכו של i ב-main כבר עשוי להשתנות. במקרה קיצון, אם ה-main מסיים את הלולאה לפני שמי מהחוטים התחיל לפעול, כולם עשויים להדפיס 3 (הערך שבו i עוצר את הלולאה). לכן, ייתכנו כפילויות וערכים מחוץ לטווח המקורי 0-2."}, "difficulty_estimation": "Medium", "_source_file": "0131__Threads__CodeAnalysis__Medium.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:48:15", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Pthreads", "Concurrency", "Race Conditions"], "content": {"text": "לפניך קטע קוד בשפת C המשתמש בספריית pthreads. מה ניתן לומר על הפלט של התוכנית בהרצה טיפוסית במערכת מרובת ליבות?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n\nvoid* thread_func(void* arg) {\n    int id = *(int*)arg;\n    printf(\"%d \", id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[4];\n    for (int i = 0; i < 4; i++) {\n        pthread_create(&threads[i], NULL, thread_func, &i);\n    }\n    for (int i = 0; i < 4; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    return 0;\n}", "options": ["א. הפלט יהיה תמיד 0 1 2 3 (בסדר כלשהו).", "ב. הפלט יהיה תמיד 4 4 4 4.", "ג. הפלט עשוי להכיל ספרות בין 0 ל-4, כאשר ייתכן שספרה מסוימת תודפס יותר מפעם אחת וספרה אחרת לא תודפס כלל.", "ד. התוכנית תגרום לשגיאת סגמנטציה (Segmentation Fault) כיוון שכל החוטים ניגשים לאותו משתנה i."]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הבעיה המרכזית בקוד היא העברת הכתובת של משתנה הלולאה i לכל החוטים. כיוון שכל החוטים חולקים את אותו מרחב כתובות, כל חוט מקבל מצביע לאותו מיקום בזיכרון (המחסנית של main). בזמן שחוט אחד נוצר ומתחיל את ריצתו, הלולאה ב-main ממשיכה לרוץ ומעדכנת את הערך של i. כתוצאה מכך, עד שחוט מסוים ניגש לזיכרון כדי לקרוא את הערך של id, הערך של i עשוי להשתנות. ייתכן שחוט יקרא את הערך 1, 2, 3 או אפילו 4 (אם הלולאה הסתיימה לפני שהחוט ניגש לזיכרון). לכן, הפלט אינו צפוי ויכול לכלול חזרות על מספרים."}, "difficulty_estimation": "Medium", "_source_file": "0132__Threads__CodeAnalysis__Medium.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:48:30", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Pthreads", "Concurrency"], "content": {"text": "לפניך קטע קוד בשפת C המשתמש בספריית pthreads. בהנחה שכל הקריאות למערכת מצליחות, וכי פעולת הקידום (count++) מתבצעת באופן אטומי (כלומר, אין איבוד עדכונים עקב Race Condition), מה יהיה הפלט של התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint count = 0;\n\nvoid* increment(void* arg) {\n    int limit = *(int*)arg;\n    for (int i = 0; i < limit; i++) {\n        count++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2, t3;\n    int val1 = 10, val2 = 20, val3 = 30;\n\n    pthread_create(&t1, NULL, increment, &val1);\n    pthread_join(t1, NULL);\n\n    pthread_create(&t2, NULL, increment, &val2);\n    pthread_create(&t3, NULL, increment, &val3);\n\n    pthread_join(t2, NULL);\n    pthread_join(t3, NULL);\n\n    printf(\"%d\", count);\n    return 0;\n}", "options": ["א. 30", "ב. 50", "ג. 60", "ד. 10", "ה. התוצאה אינה קבועה"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התוכנית מתחילה בביצוע ה-main. החוט הראשון (t1) נוצר עם הערך 10. פקודת ה-pthread_join(t1) גורמת לתהליך הראשי להמתין עד ש-t1 יסיים. בשלב זה count שווה ל-10. לאחר מכן, נוצרים שני חוטים נוספים (t2 ו-t3) כמעט במקביל. t2 מבצע 20 איטרציות ו-t3 מבצע 30 איטרציות. מכיוון שצוין בשאלה שיש להניח שאין Race Condition (פעולות אטומיות), הערך הסופי של count יהיה סכום כל ההוספות שבוצעו על ידי כל החוטים: 10 (מ-t1) + 20 (מ-t2) + 30 (מ-t3) = 60."}, "difficulty_estimation": "Medium", "_source_file": "0133__Threads__CodeAnalysis__Medium.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:48:46", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Pthreads", "Race Conditions", "Shared Memory"], "content": {"text": "לפניך קטע קוד בשפת C המשתמש בספריית pthreads. התוכנית יוצרת שלושה חוטים (threads), כאשר כל אחד מהם אמור להדפיס את המספר שקיבל כארגומנט ולעדכן מונה גלובלי. מה ניתן לומר על פלט התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint counter = 0;\n\nvoid* task(void* arg) {\n    int id = *(int*)arg;\n    printf(\"%d\", id);\n    counter++;\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[3];\n    for (int i = 0; i < 3; i++) {\n        pthread_create(&threads[i], NULL, task, &i);\n    }\n    for (int i = 0; i < 3; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    printf(\" C%d\", counter);\n    return 0;\n}", "options": ["א. הפלט תמיד יהיה הצירוף '012 C3' בסדר כלשהו של הספרות.", "ב. הפלט יהיה תמיד '333 C3'.", "ג. ייתכן שהפלט יכיל את הספרה 3, וייתכן שספרות מסוימות יופיעו יותר מפעם אחת (למשל '133 C2').", "ד. התוכנית תמיד תדפיס '012 C0' כי המונה לא מתעדכן בחוט הראשי.", "ה. תתרחש שגיאת סגמנטציה כיוון שהגישה לכתובת של i אינה מותרת מהחוטים."]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הקוד מדגים שתי בעיות סנכרון נפוצות: 1. העברת מצביע למשתנה מקומי (i) שערכו משתנה בחוט אחר. כל החוטים מקבלים את אותה כתובת בזיכרון. כיוון שהחוט הראשי ממשיך לרוץ ולקדם את i, בזמן שהחוטים החדשים ניגשים לכתובת זו, הערך בה עשוי להיות כל אחד מערכי הלולאה או ערך הסיום (3). לכן ייתכנו כפילויות או הופעה של הספרה 3. 2. קיימת תחרות (Race Condition) על המשתנה הגלובלי counter. הפעולה ++ אינה אטומית, ולכן אם שני חוטים ינסו לעדכן אותו בו-זמנית, ייתכן שעדכון אחד ידרס והערך הסופי יהיה קטן מ-3."}, "difficulty_estimation": "Medium", "_source_file": "0134__Threads__CodeAnalysis__Medium.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:49:10", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Race Conditions", "Concurrency", "Pthreads"], "content": {"text": "לפניך קטע קוד בשפת C המשתמש בספריית pthreads. התוכנית יוצרת שני חוטים (threads) המבצעים כל אחד 100 איטרציות של קידום משתנה גלובלי משותף `counter`. מהו הערך המינימלי האפשרי שיודפס על ידי הפקודה `printf` בסיום ריצת התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint counter = 0;\n\nvoid* func(void* arg) {\n    for (int i = 0; i < 100; i++) {\n        int temp = counter;\n        counter = temp + 1;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, func, NULL);\n    pthread_create(&t2, NULL, func, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"%d\\n\", counter);\n    return 0;\n}", "options": ["א. 1", "ב. 2", "ג. 100", "ד. 200"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הפעולה counter = temp + 1 אינה אטומית, ולכן נוצר מרוץ תהליכים (Race Condition). הערך המינימלי האפשרי עבור שני חוטים המבצעים N קידומים כל אחד הוא 2. \nתרחיש לדוגמה המביא לערך 2: \n1. חוט א' קורא את הערך 0 לתוך temp ונרדם.\n2. חוט ב' רץ 99 איטרציות מלאות, ומעדכן את counter ל-99.\n3. חוט א' מתעורר, מחשב 0+1 וכותב ל-counter את הערך 1 (בכך הוא דורס את ה-99 של חוט ב').\n4. חוט ב' מתחיל את האיטרציה ה-100 שלו, קורא את הערך 1 לתוך temp ונרדם.\n5. חוט א' מתעורר ומבצע את כל 99 האיטרציות הנותרות שלו עד הסוף. הערך ב-counter יהיה כעת 100.\n6. חוט ב' מתעורר מהאיטרציה האחרונה שלו, מחשב 1+1 וכותב ל-counter את הערך 2 (בכך הוא דורס את ה-100 של חוט א')."}, "difficulty_estimation": "Medium", "_source_file": "0135__Threads__CodeAnalysis__Medium.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:49:26", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Concurrency", "Race Conditions", "Synchronization"], "content": {"text": "נתון קטע הקוד הבא בשפת C המשתמש בספריית pthreads. מה מהבאים נכון לגבי הפלט המודפס למסך? הניחו שכל הקריאות ל-pthread_create מצליחות ושהתהליכון הראשי (main) ממתין לסיום כל החוטים לפני ההדפסה.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint total = 0;\n\nvoid* task(void* arg) {\n    int val = *(int*)arg;\n    total += val;\n    return NULL;\n}\n\nint main() {\n    pthread_t t[2];\n    int i;\n    for (i = 1; i <= 2; i++) {\n        pthread_create(&t[i-1], NULL, task, &i);\n    }\n    for (int j = 0; j < 2; j++) {\n        pthread_join(t[j], NULL);\n    }\n    printf(\"%d\", total);\n    return 0;\n}", "options": ["א. הפלט יהיה תמיד 3", "ב. הפלט יהיה תמיד 6", "ג. הפלט יכול להיות כל מספר שלם בין 1 ל-6", "ד. הפלט יהיה תמיד 0", "ה. לא ניתן לדעת, התוכנית תמיד תסתיים בשגיאת סגמנטציה (Segmentation Fault)"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הפלט אינו קבוע עקב שתי בעיות סנכרון מרכזיות: 1. העברת משתנה לפי כתובת (Pass by Reference): החוטים מקבלים את הכתובת של משתנה הלולאה i. מכיוון שהם רצים במקביל ללולאה, הערך בכתובת זו עשוי להשתנות לפני שהם קוראים אותו. הערכים האפשריים שחוט יכול לקרוא הם 1, 2, או 3 (הערך של i לאחר סיום הלולאה). 2. מרוץ תהליכונים (Race Condition): הפעולה total += val אינה אטומית (היא מורכבת מקריאה, הוספה וכתיבה). חוט אחד יכול לקרוא את הערך הישן של total, ובזמן שהוא מחשב את הסכום, חוט אחר יעדכן את total, כך שהעדכון של החוט הראשון ידרוס את השני. השילוב של שתי הבעיות מאפשר לקבל כל ערך שלם בטווח 1 עד 6. לדוגמה: אם שני החוטים קראו את הערך i=1 ושניהם קראו total=0, שניהם יכתבו 1 לתוך total והפלט יהיה 1. אם שניהם קראו i=3 ורצו בזה אחר זה, הפלט יהיה 6."}, "difficulty_estimation": "Medium", "_source_file": "0136__Threads__CodeAnalysis__Medium.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:49:56", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Race Conditions", "Pthreads", "Memory Management"], "content": {"text": "לפניכם קוד בשפת C המשתמש בספריית pthreads. הניחו כי כל קריאות המערכת מצליחות, כי התוכנית רצה על מערכת עם מעבד יחיד (Single Core), וכי ה-Scheduler יכול להחליף בין חוטים בכל רגע (Preemptive).", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n\nint global_counter = 0;\n\nvoid* thread_func(void* arg) {\n    int* id_ptr = (int*)arg;\n    int my_id = *id_ptr;\n    int temp = global_counter;\n    usleep(10); // Force potential context switch\n    global_counter = temp + my_id;\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[3];\n    int i;\n    for (i = 0; i < 3; i++) {\n        pthread_create(&threads[i], NULL, thread_func, &i);\n    }\n    for (int j = 0; j < 3; j++) {\n        pthread_join(threads[j], NULL);\n    }\n    printf(\"%d\\n\", global_counter);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "מהו הטווח (מינימום ומקסימום) של הערכים האפשריים שיודפסו על ידי התוכנית? נמקו והדגימו תרחיש קצר עבור כל קצה.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "נניח שנוסיף מנעול (Mutex) סביב הקטע הקריטי בתוך thread_func (שורות 10-12). האם הפלט יהיה בהכרח 3 (0+1+2)? הסבירו.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "הציעו דרך לתקן את הקריאה ל-pthread_create ואת הגישה בתוך thread_func כך שכל חוט יקבל בוודאות את ערך ה-i המקורי שלו (0, 1, או 2) ללא שימוש בהקצאת זיכרון דינמי (malloc).", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. מקסימום: 9. המשתנה i ב-main משותף לכל החוטים דרך הכתובת שלו. עד שהחוטים מספיקים לקרוא את הערך בשורה 9, הלולאה ב-main עשויה להסתיים וערכו של i יהיה 3. אם כל חוט קרא 3 וביצע את העדכון באופן סדרתי (ללא דריסת ערכים), נקבל 3+3+3=9. מינימום: 0. ייתכן שחוט אחד קרא i=0 ושמר temp=0. בזמן שהוא ב-usleep, חוטים אחרים רצו ועדכנו את global_counter לערך כלשהו (למשל 6). כשהחוט הראשון מתעורר, הוא מבצע 0+0 וכותב 0 לתוך global_counter, ובכך דורס את העדכונים האחרים.\n2. לא. המנעול יפתור את ה-Race Condition על global_counter (העדכונים יהיו אטומיים), אך הוא לא פותר את הבעיה שכל החוטים ניגשים לאותה כתובת זיכרון (&i). עדיין ייתכן שכל החוטים יקראו את הערך 3 מהכתובת המשותפת, ולכן הפלט יהיה 9 (אך לא תהיה דריסת זיכרון באמצע).\n3. ניתן להעביר את הערך של i ישירות כארגומנט (Casting) במקום את הכתובת שלו. ב-main: pthread_create(&threads[i], NULL, thread_func, (void*)(long)i); ובפונקציית החוט: int my_id = (int)(long)arg;"}, "difficulty_estimation": "Hard", "_source_file": "0137__Threads__CodeAnalysis__Hard.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:50:24", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Concurrency", "Synchronization", "Race Conditions", "Pthreads"], "content": {"text": "לפניך קוד בשפת C המשתמש בספריית Pthreads. הנח כי כל הקריאות למערכת מצליחות וכי התוכנית רצה על מערכת מרובת ליבות. ענה על הסעיפים הבאים:", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint counter = 0;\n\nvoid* thread_func(void* arg) {\n    int val = *((int*)arg);\n    for (int i = 0; i < 100; i++) {\n        counter++;\n    }\n    printf(\"%d \", val);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[5];\n    for (int i = 0; i < 5; i++) {\n        pthread_create(&threads[i], NULL, thread_func, &i);\n    }\n    for (int i = 0; i < 5; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    printf(\"\\nCounter: %d\\n\", counter);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "זהה שתי בעיות סנכרון/לוגיקה בקוד לעיל הקשורות לעבודה עם חוטים.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "מהו הטווח האפשרי של הערך המודפס עבור המשתנה counter? הסבר בקצרה את הגבול התחתון.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "האם ייתכן שהפלט של התוכנית יכלול את הספרה 5? אם כן, הסבר באילו תנאים. אם לא, הסבר מדוע.", "code_snippet": null, "options": null}], "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. הבעיות הן: א) Race Condition על המשתנה הגלובלי counter כיוון שפעולת ה-increment אינה אטומית. ב) Data Race על המשתנה i - כל החוטים מקבלים מצביע לאותה כתובת זיכרון שערכה משתנה על ידי ה-main thread בזמן שהם מנסים לקרוא ממנה.\n2. הטווח הוא [100, 500]. הגבול התחתון הוא 100: זה קורה למשל אם חוט אחד קורא את הערך 0, מושהה, ובינתיים שאר החוטים מסיימים את עבודתם ומעדכנים את counter ל-400. כאשר החוט הראשון חוזר לפעול, הוא מחזיק בערך המקומי שקרא (0), מקדם אותו וכותב חזרה לזיכרון, ובכך דורס את כל העדכונים הקודמים.\n3. כן, ייתכן שהערך 5 יודפס. הלולאה ב-main רצה מ-0 עד 4. בסיום האיטרציה האחרונה, i מקודם ל-5 והתנאי i < 5 נכשל. אם חוט שנוצר באיטרציה כלשהי ניגש לכתובת arg (שהיא הכתובת של i) רק לאחר שה-main thread סיים את הלולאה, הוא יקרא את הערך 5 וידפיס אותו."}, "difficulty_estimation": "Hard", "_source_file": "0138__Threads__CodeAnalysis__Hard.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:50:45", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Threads", "Concurrency", "Race Conditions", "Pthreads"], "content": {"text": "לפניכם קוד הכתוב בשפת C המשתמש בספריית pthreads. נניח כי כל הקריאות למערכת מצליחות, וכי התוכנית רצה על מערכת המאפשרת פרה-אמפציה (preemption) בכל עת.\n\n1. מהו הטווח האפשרי (מינימום ומקסימום) של הערך המודפס עבור המשתנה counter בסוף התוכנית? הסבירו.\n2. מהן הספרות האפשריות שיכולות להיות מודפסות על ידי פקודת ה-printf בתוך הפונקציה worker? האם הספרה '3' יכולה להופיע? הסבירו.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint counter = 0;\n\nvoid* worker(void* arg) {\n    int val = *(int*)arg;\n    int local = counter;\n    local++;\n    counter = local;\n    printf(\"%d\", val);\n    return NULL;\n}\n\nint main() {\n    pthread_t t[3];\n    for (int i = 0; i < 3; i++) {\n        pthread_create(&t[i], NULL, worker, &i);\n    }\n    for (int i = 0; i < 3; i++) {\n        pthread_join(t[i], NULL);\n    }\n    printf(\" Final: %d\\n\", counter);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. טווח הערכים של counter: המינימום הוא 1 והמקסימום הוא 3. המקסימום (3) מתקבל אם החוטים רצים באופן סדרתי או ללא התערבות בקריאה/כתיבה של counter. המינימום (1) מתקבל במצב של Race Condition: כל שלושת החוטים קוראים את הערך ההתחלתי (0) לתוך המשתנה המקומי local, מקדמים אותו ל-1, ואז כותבים כולם 1 חזרה ל-counter.\n\n2. הספרות האפשריות ב-worker: הספרות הן 0, 1, 2, וגם 3. הסיבה לכך היא שהכתובת של i מועברת לכל החוטים (&i). מכיוון ש-i הוא משתנה מקומי ב-main שמשתנה בלולאה, קיים מרוץ (Race Condition) על ערכו. אם חוט מסוים ניגש לכתובת הזיכרון של i רק לאחר שהלולאה ב-main התקדמה או הסתיימה, הוא יראה את הערך המעודכן. מכיוון שהלולאה רצה עד ש-i שווה ל-3, ייתכן שחוט יקרא את הערך 3 מהכתובת לפני ש-main יצא מהלולאה או בזמן ההמתנה ב-join."}, "difficulty_estimation": "Hard", "_source_file": "0139__Threads__CodeAnalysis__Hard.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:51:02", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Concurrency", "Race Conditions", "Memory Management"], "content": {"text": "עיינו בקוד ה-C הבא המשתמש ב-POSIX Threads. התוכנית רצה על מערכת מרובת ליבות. הניחו שכל קריאות המערכת מצליחות ושספריית הסטנדרט מוגדרת ללא Buffering (כלומר printf מדפיס מיד).", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint g = 0;\n\nvoid* task(void* arg) {\n    int val = *(int*)arg;\n    g = g + 1;\n    printf(\"%d \", val);\n    return NULL;\n}\n\nint main() {\n    pthread_t t[3];\n    for (int i = 0; i < 3; i++) {\n        pthread_create(&t[i], NULL, task, &i);\n    }\n    for (int i = 0; i < 3; i++) {\n        pthread_join(t[i], NULL);\n    }\n    printf(\"! %d\", g);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "מהם הערכים האפשריים שיכולים להיות מודפסים עבור המשתנה val על ידי כל אחד מהחוטים? הסבירו האם הערך 3 יכול להופיע בפלט.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "מהו הטווח האפשרי של ערכים עבור המשתנה g בהדפסה האחרונה (אחרי הסימן '!')? נמקו.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "כיצד ניתן לשנות את שורת הקריאה ל-pthread_create ואת השורה הראשונה בפונקציה task כך שכל חוט ידפיס בוודאות ערך ייחודי (0, 1, 2) ללא שימוש במנגנוני סנכרון (כגון Mutex)?", "code_snippet": null, "options": null}], "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. הערכים האפשריים עבור val הם {0, 1, 2, 3}. הסיבה לכך היא שכל החוטים מקבלים את הכתובת של אותו משתנה מקומי i מהמחסנית של main. כיוון שאין סנכרון, חוט עשוי לקרוא את הערך של i רק לאחר שהחוט הראשי כבר קידם אותו בלולאה. הערך 3 אפשרי בהחלט: אם חוט מסוים מתחיל לבצע את הפונקציה task רק לאחר שהלולאה הראשונה ב-main הסתיימה, הוא יקרא את הערך הנוכחי של i בכתובת שקיבל, שהוא 3 (ערך היציאה מהלולאה).\n\n2. הטווח עבור g הוא [1, 3]. הפעולה g = g + 1 אינה אטומית (מורכבת מקריאה, הוספה וכתיבה). במערכת מרובת ליבות, ייתכן שכל שלושת החוטים יקראו את הערך 0 בו-זמנית, יוסיפו 1 ויכתבו כולם 1 חזרה לזיכרון (Race Condition). במקרה האופטימלי שבו אין התנגשות, כל חוט יקדם את g בתורו והתוצאה תהיה 3.\n\n3. כדי להבטיח שכל חוט יקבל עותק ייחודי של הערך i ללא תלות בשינויים העתידיים של המשתנה ב-main, ניתן להעביר את הערך עצמו באמצעות Casting לטיפוס void* (בהנחה שגודל מצביע מאפשר זאת): \nב-main: pthread_create(&t[i], NULL, task, (void*)(long)i);\nב-task: int val = (int)(long)arg;"}, "difficulty_estimation": "Hard", "_source_file": "0140__Threads__CodeAnalysis__Hard.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:51:27", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Concurrency", "Race Conditions", "Pthreads"], "content": {"text": "לפניך קטע קוד ב-C המשתמש בספריית pthreads. מטרת התוכנית היא ליצור 5 חוטים (threads), כך שכל חוט ידפיס מזהה ייחודי (0 עד 4) שהועבר לו בזמן היצירה. הנח כי כל הקריאות ל-pthread_create ו-pthread_join מצליחות.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#define NUM_THREADS 5\n\nvoid* thread_func(void* arg) {\n    int id = *((int*)arg);\n    printf(\"%d \", id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    for (int i = 0; i < NUM_THREADS; i++) {\n        pthread_create(&threads[i], NULL, thread_func, &i);\n    }\n    for (int i = 0; i < NUM_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "האם הפלט של התוכנית יהיה בהכרח פרמוטציה של המספרים {0, 1, 2, 3, 4}? הסבירו מדוע.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "האם ייתכן מצב בו אחד החוטים ידפיס את הערך 5? נמקו.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "הציעו שינוי מינימלי לקוד (שורות בודדות) שיבטיח שכל חוט ידפיס מזהה ייחודי בין 0 ל-NUM_THREADS-1.", "code_snippet": null, "options": null}], "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. לא, הפלט לא יהיה בהכרח פרמוטציה של 0-4. הבעיה היא שכל החוטים מקבלים את הכתובת של אותו משתנה מקומי i. מכיוון שהחוטים רצים במקביל ללולאת ה-main, ייתכן שערך המשתנה i ישתנה ב-main לפני שחוט מסוים יספיק לקרוא אותו ב-thread_func. זהו Race Condition על המשתנה i.\n2. כן, ייתכן בהחלט. אם לולאת היצירה (הלולאה הראשונה) מסתיימת לפני שאחד החוטים ניגש לזיכרון של i, הערך של i יהיה 5 (תנאי העצירה של הלולאה), וזה מה שהחוט ידפיס.\n3. ישנן שתי דרכים נפוצות לתיקון: א. הקצאת מערך של מזהים (למשל int ids[NUM_THREADS]) והעברת הכתובת של המקום ה-i במערך לכל חוט. ב. העברת הערך של i ישירות על ידי Casting ל-(void*) ב-pthread_create וביצוע Casting חזרה ל-int בתוך ה-thread_func (עובד כי גודל void* בדרך כלל גדול או שווה ל-int)."}, "difficulty_estimation": "Hard", "_source_file": "0141__Threads__CodeAnalysis__Hard.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:51:41", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Threads", "Concurrency", "Race Conditions"], "content": {"text": "נתון קטע הקוד הבא בשפת C. שני חוטים (Threads) נוצרים ומריצים את הפונקציה worker במקביל על מעבד יחיד. המשתנה x הוא גלובלי ומאותחל ל-0. מהו הערך המקסימלי והערך המינימלי האפשריים של x עם סיום ריצת התוכנית? הסבירו את תשובתכם ותארו את סדר הפעולות (interleaving) המוביל לערכים אלו.", "code_snippet": "int x = 0;\n\nvoid* worker(void* arg) {\n    for (int i = 0; i < 100; i++) {\n        int temp = x;\n        temp = temp + 1;\n        x = temp;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, worker, NULL);\n    pthread_create(&t2, NULL, worker, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"%d\", x);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ערך מקסימלי: 200. מתקבל כאשר שני החוטים רצים באופן סדרתי (אחד אחרי השני), כך שכל פעולת קידום מתבצעת על הערך המעודכן ביותר.\nערך מינימלי: 2. תרחיש המביא לתוצאה זו:\n1. חוט א' קורא x=0 עבור האיטרציה הראשונה שלו (i=0) ונעצר.\n2. חוט ב' רץ 99 איטרציות מלאות (i=0 עד i=98), ומעדכן את x ל-99.\n3. חוט א' ממשיך וכותב x=1 (הערך שקרא 0 פלוס 1).\n4. חוט ב' קורא את הערך x=1 עבור האיטרציה האחרונה שלו (i=99) ונעצר.\n5. חוט א' רץ ומסיים את כל 99 האיטרציות הנותרות שלו (מ-i=1 עד i=99), ומעדכן את x ל-100.\n6. חוט ב' ממשיך את האיטרציה האחרונה שלו, מחשב 1+1 וכותב x=2."}, "difficulty_estimation": "Hard", "_source_file": "0142__Threads__CodeAnalysis__Hard.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:52:20", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Threads", "Concurrency", "Race Conditions", "Synchronization", "Pthreads"], "content": {"text": "לפניכם קוד בשפת C המשתמש בחוטים (Threads). הניחו כי כל קריאות המערכת מצליחות וכי התוכנית רצה על מערכת מרובת ליבות המאפשרת הרצה מקבילית אמיתית.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint total = 0;\npthread_mutex_t mtx = PTHREAD_MUTEX_INITIALIZER;\n\nvoid* worker(void* arg) {\n    int id = *(int*)arg;\n    for (int i = 0; i < 100; i++) {\n        if (id % 2 == 0) {\n            total++;\n        } else {\n            pthread_mutex_lock(&mtx);\n            total++;\n            pthread_mutex_unlock(&mtx);\n        }\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[4];\n    for (int i = 0; i < 4; i++) {\n        pthread_create(&threads[i], NULL, worker, &i);\n    }\n    for (int i = 0; i < 4; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    printf(\"%d\\n\", total);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "101.1", "text": "מהו הערך המקסימלי האפשרי שהתוכנית יכולה להדפיס? הסבירו בקצרה.", "code_snippet": null, "options": null}, {"id": "101.2", "text": "האם פלט התוכנית דטרמיניסטי (כלומר, האם תמיד יודפס אותו ערך)? אם לא, ציינו את שתי הסיבות המרכזיות לכך שערכו של total עשוי להשתנות בין הרצות שונות.", "code_snippet": null, "options": null}, {"id": "101.3", "text": "נניח ושינינו את שורת יצירת החוט ל-pthread_create(&threads[i], NULL, worker, (void*)(long)i); ואת קריאת ה-id ל-int id = (int)(long)arg;. האם כעת הפלט יהיה דטרמיניסטי ושווה ל-400? נמקו.", "code_snippet": null, "options": null}], "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. הערך המקסימלי הוא 400. ישנם 4 חוטים וכל אחד מבצע 100 איטרציות של קידום המשתנה total. בתרחיש אידיאלי ללא איבוד עדכונים, הסכום יגיע ל-400.\n2. הפלט אינו דטרמיניסטי משתי סיבות עיקריות:\nא) מרוץ תהליכים על המשתנה i: כל החוטים מקבלים את הכתובת של i בזיכרון של פונקציית main. עד שחוט מתחיל לרוץ וקורא את הערך מהכתובת, הערך של i עשוי להשתנות על ידי הלולאה ב-main (למשל, כל החוטים עשויים לקרוא את הערך 4).\nב) מרוץ תהליכים על total: בתוך פונקציית worker, אם ה-id שנקרא הוא זוגי, הגישה ל-total מתבצעת ללא הגנת Mutex. מכיוון שמספר חוטים יכולים לגשת למשתנה בו-זמנית, עדכונים עלולים ללכת לאיבוד (Lost Update).\n3. לא. למרות שתיקון זה מבטיח שכל חוט יקבל ID ייחודי (0, 1, 2, 3), חוטים 0 ו-2 עדיין יזהו את עצמם כזוגיים (id % 2 == 0) וינסו לקדם את total ללא שימוש במנעול. כתוצאה מכך, עדיין קיים מרוץ תהליכים בין חוט 0 לחוט 2 (ובין שניהם לחוטים האי-זוגיים שמשתמשים במנעול אך לא מונעים מהזוגיים לגשת), ולכן הפלט עדיין לא יהיה דטרמיניסטי ועלול להיות נמוך מ-400."}, "difficulty_estimation": "Hard", "_source_file": "0143__Threads__CodeAnalysis__Hard.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:52:41", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Concurrency", "Race Conditions", "Synchronization"], "content": {"text": "לפניכם תוכנית בשפת C המשתמשת בספריית pthreads. המשתנה g הוא משתנה גלובלי המשותף לכל החוטים ומאותחל ל-0. הניחו כי המערכת משתמשת במעבד יחיד וכי אלגוריתם התזמון הוא Preemptive (ניתן להחליף בין חוטים בכל נקודת זמן, כולל באמצע פעולות אריתמטיות של קריאה וכתיבה לזיכרון). מהו הערך המינימלי והערך המקסימלי האפשריים של המשתנה g עם סיום ריצת התוכנית? נמקו את תשובתכם בעזרת תרחיש הרצה (interleaving) מתאים.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint g = 0;\n\nvoid* child_func(void* arg) {\n    int temp = g;\n    g = temp + 1;\n    return NULL;\n}\n\nvoid* parent_func(void* arg) {\n    pthread_t tid;\n    int temp = g;\n    g = temp + 1;\n    pthread_create(&tid, NULL, child_func, NULL);\n    pthread_join(tid, NULL);\n    temp = g;\n    g = temp + 1;\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, parent_func, NULL);\n    pthread_create(&t2, NULL, parent_func, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"%d\\n\", g);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ערך מקסימלי: 6. זהו המקרה שבו כל הפעולות מתבצעות באופן סדרתי ללא הפרעה. כל חוט אב (parent_func) מבצע 3 קידומים של g: אחד ישירות לפני יצירת הבן, אחד על ידי הבן (child_func), ואחד ישירות לאחר ה-join. כיוון שיש שני חוטי אב, מתבצעים 6 קידומים סה\"כ.\n\nערך מינימלי: 3. כדי להגיע למינימום, ננסה לגרום לאובדן עדכונים (lost updates). נניח שחוט אב T1 קורא g=0. אז חוט T2 רץ את כל המסלול שלו (3 קידומים) ומביא את g ל-3. כעת T1 חוזר ומבצע את הכתיבה שלו: g = 0 + 1 = 1. בשלב זה איבדנו את כל העדכונים של T2 והערך הוא 1. כעת T1 יוצר את חוט הבן שלו (C1). כיוון ש-C1 נוצר לאחר ש-T1 כבר כתב 1, C1 יקרא לפחות 1 ויעדכן ל-2. לאחר מכן T1 יבצע join ויקרא את הערך שכתב הבן (2) ויעדכן ל-3. \nלא ניתן להגיע לערך נמוך מ-3 (כמו 2) מכיוון שכל חוט אב מחולק לשני מקטעי קוד שביניהם יש נקודת סנכרון (join). הקידום האחרון של חוט אב תמיד יתבסס על הערך שנכתב על ידי הבן שלו, והבן תמיד יקרא ערך שנכתב לפחות על ידי הקידום הראשון של האב שלו."}, "difficulty_estimation": "Hard", "_source_file": "0144__Threads__CodeAnalysis__Hard.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:53:50", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Race Condition"], "content": {"text": "מהו מצב מרוץ (Race Condition) בהקשר של סנכרון בין תהליכים או חוטים (threads)?", "code_snippet": null, "options": ["א. מצב שבו שני תהליכים מנסים לגשת לאותו קובץ בדיסק בו-זמנית.", "ב. מצב שבו התוצאה הסופית של התוכנית תלויה בתזמון היחסי של ביצוע הפעולות על משאב משותף.", "ג. מצב שבו תהליך אחד נתקע בלולאה אינסופית ומונע מתהליכים אחרים להשתמש במעבד.", "ד. מצב שבו שני תהליכים מחכים זה לזה לצורך קבלת משאב ואינם יכולים להמשיך בביצועם.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. מצב מרוץ (Race Condition) מוגדר כמצב שבו מספר תהליכים או חוטים ניגשים ומשנים נתונים משותפים בו-זמנית, כך שהתוצאה הסופית של החישוב תלויה בסדר הגישה (התזמון) של הישויות השונות למשאב."}, "difficulty_estimation": "Easy", "_source_file": "0145__Synchronization__MultipleChoice__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:53:57", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Critical Section"], "content": {"text": "מהו 'קטע קריטי' (Critical Section) בהקשר של סנכרון בין תהליכים או חוטים (threads)?", "code_snippet": null, "options": ["א. קטע קוד שחייב להתבצע בזמן הקצר ביותר האפשרי כדי לא לעכב את המערכת.", "ב. קטע קוד שבו מתבצעת גישה למשאב משותף, ושאסור ליותר מתהליך אחד לבצעו בו-זמנית.", "ג. קטע קוד שרק למערכת ההפעלה (Kernel) מותר להריץ.", "ד. קטע קוד שבו מתרחשת פסיקת שעון לצורך החלפת הקשר (Context Switch).", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "קטע קריטי הוא חלק בתוכנית שבו מתבצעת גישה למשאבים משותפים (כמו משתנים גלובליים, קבצים או חומרה). כדי למנוע מצבי מרוץ (Race Conditions), יש להבטיח 'מניעה הדדית' (Mutual Exclusion), כלומר שרק תהליך/חוט אחד ישהה בקטע הקריטי שלו בכל רגע נתון."}, "difficulty_estimation": "Easy", "_source_file": "0146__Synchronization__MultipleChoice__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:54:06", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Synchronization", "Concurrency"], "content": {"text": "מהו 'מצב מרוץ' (Race Condition) בהקשר של סנכרון תהליכים?", "code_snippet": null, "options": ["א. מצב שבו שני תהליכים או יותר ניגשים למשאב משותף והתוצאה הסופית תלויה בתזמון הביצוע של הפקודות.", "ב. מצב שבו תהליך אחד ממתין למשאב שמוחזק על ידי תהליך אחר, שממתין למשאב של הראשון.", "ג. מצב שבו תהליך בעל עדיפות נמוכה אינו מצליח לקבל זמן מעבד בגלל תהליכים בעלי עדיפות גבוהה.", "ד. מצב שבו המעבד מבצע החלפת הקשר (context switch) בתדירות גבוהה מדי.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "א'. מצב מרוץ מתרחש כאשר מספר חוטים או תהליכים מבצעים מניפולציה על נתונים משותפים במקביל, והתוצאה הסופית של החישוב תלויה בסדר שבו הגישות בוצעו בפועל. כדי למנוע זאת, יש להשתמש במנגנוני סנכרון כמו Mutex."}, "difficulty_estimation": "Easy", "_source_file": "0147__Synchronization__MultipleChoice__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:54:18", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Synchronization", "Concurrency"], "content": {"text": "מהו \"קטע קריטי\" (Critical Section) בהקשר של סנכרון בין תהליכים או חוטים (threads)?", "code_snippet": null, "options": ["א. חלק בקוד שבו מתבצעת גישה למשאבים משותפים ועלול להיווצר בו Race Condition.", "ב. קטע קוד במערכת ההפעלה שאחראי על ביצוע החלפת הקשר (Context Switch).", "ג. קוד שחייב לרוץ במצב פריבילגי (Kernel Mode) בלבד.", "ד. פונקציה שמבצעת הקצאת זיכרון דינמי עבור תהליך חדש.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "א'. קטע קריטי הוא קטע קוד שבו מתבצעת גישה למשאב משותף (כגון משתנה גלובלי, קובץ או מבנה נתונים). כדי למנוע מצב של מרוץ (Race Condition), עלינו להבטיח שרק תהליך אחד נמצא בקטע הקריטי שלו בו-זמנית (Mutual Exclusion)."}, "difficulty_estimation": "Easy", "_source_file": "0148__Synchronization__MultipleChoice__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:54:25", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Synchronization", "Mutex"], "content": {"text": "מהי המטרה העיקרית של שימוש ב-mutex (מנעול הדדי) במערכת הפעלה?", "code_snippet": null, "options": ["א. לאפשר תקשורת אמינה בין תהליכים שונים.", "ב. למנוע מצב של רעב (starvation) של תהליכים.", "ג. להבטיח שרק תהליך אחד יבצע קטע קוד קריטי בכל רגע נתון.", "ד. לסנכרן את עבודת המעבד עם התקני קלט/פלט.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "ג'. המטרה העיקרית של mutex (מנעול הדדי) היא להגן על קטעים קריטיים של קוד (critical sections) המשתמשים במשאבים משותפים. בכך, הוא מבטיח שרק תהליך או חוט חישוב אחד יוכל לגשת למשאב המשותף ולשנות אותו בכל רגע נתון, ובכך למנוע תנאי מרוץ (race conditions) ולהבטיח עקביות נתונים."}, "difficulty_estimation": "Easy", "_source_file": "0149__Synchronization__MultipleChoice__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:43:51", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Concurrency"], "content": {"text": "מהו 'קטע קריטי' (Critical Section) בהקשר של סנכרון בין תהליכים או חוטים (threads)?", "code_snippet": null, "options": ["א. קטע קוד שחייב להתבצע על ידי המעבד במהירות המרבית ללא השהיות.", "ב. קטע קוד שבו מתבצעת גישה למשאב משותף ושרק חוט/תהליך אחד יכול לבצע בו זמנית.", "ג. קטע קוד המכיל רק פקודות מערכת (System Calls) המיועדות לניהול זיכרון.", "ד. קטע קוד שבו המעבד מבצע פעולות קלט/פלט (I/O) בלבד.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. קטע קריטי הוא חלק בתוכנית שבו ניגשים למשאב משותף (כגון משתנה גלובלי). כדי למנוע מצבי מרוץ (Race Conditions), יש להשתמש במנגנוני סנכרון כדי להבטיח שרק תהליך/חוט אחד ישהה בקטע זה בכל זמן נתון (Mutual Exclusion)."}, "difficulty_estimation": "Easy", "_source_file": "0150__Synchronization__MultipleChoice__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:54:35", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Mutex"], "content": {"text": "מהי מטרתו העיקרית של מנעול (mutex) בסנכרון תהליכים?", "code_snippet": null, "options": ["א. למנוע מצב של קיפאון (deadlock).", "ב. להבטיח גישה בלעדית למשאב משותף (mutual exclusion).", "ג. לאפשר לתהליכים להחליף נתונים ביניהם.", "ד. לוודא שכל התהליכים ירוצו באותו סדר.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. מנעול (mutex) משמש בעיקר להבטחת גישה בלעדית לקטע קריטי (critical section) או למשאב משותף, כדי למנוע תנאי מרוץ (race conditions) ולהבטיח עקביות נתונים. בעוד שהוא יכול להיות חלק מפתרון למניעת קיפאון, זו אינה מטרתו העיקרית בפני עצמה."}, "difficulty_estimation": "Easy", "_source_file": "0151__Synchronization__MultipleChoice__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:43:58", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Critical Section"], "content": {"text": "מהו \"קטע קריטי\" (Critical Section) בהקשר של סנכרון בין תהליכים או חוטים (threads)?", "code_snippet": null, "options": ["א. קטע קוד שזמן הריצה שלו ארוך במיוחד ועלול לעכב את המערכת.", "ב. קטע קוד שבו מתבצעת גישה למשאב משותף ונדרש להבטיח שרק חוט אחד יבצע אותו בכל רגע נתון.", "ג. קטע קוד בתוך ליבת מערכת ההפעלה (kernel) שלא ניתן להפסיק את ריצתו על ידי פסיקה.", "ד. פונקציה שניתן לקרוא לה רק מתוך תהליך יחיד במהלך כל חיי התוכנית.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. קטע קריטי הוא קטע בתוכנית שבו מתבצעת גישה למשאבים משותפים (כגון משתנים גלובליים, מבני נתונים או קבצים). כדי למנוע מצבי מרוץ (race conditions), יש להשתמש במנגנוני סנכרון שיבטיחו מניעה הדדית (mutual exclusion), כך שרק חוט אחד יוכל לשהות בקטע הקריטי בכל זמן נתון."}, "difficulty_estimation": "Easy", "_source_file": "0152__Synchronization__MultipleChoice__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:54:46", "_subject": "Concurrency"}, {"id": 3, "type": "MultipleChoice", "topic": ["Synchronization", "Race Conditions", "Threads"], "content": {"text": "נתונה תוכנית C++ המשתמשת בחוטים (threads) לשם עדכון משתנה גלובלי משותף:\n```cpp\n#include <iostream>\n#include <thread>\n#include <vector>\n\nvolatile int shared_counter = 0; // משתנה משותף\n\nvoid increment_function() {\n    for (int i = 0; i < 100000; ++i) {\n        shared_counter++;\n    }\n}\n\nint main() {\n    std::vector<std::thread> threads;\n    for (int i = 0; i < 2; ++i) {\n        threads.emplace_back(increment_function);\n    }\n\n    for (std::thread& t : threads) {\n        t.join();\n    }\n\n    std::cout << \"Final counter value: \" << shared_counter << std::endl;\n    return 0;\n}\n```\nכאשר מריצים את הקוד לעיל, מהי הטענה הנכונה לגבי ערכו הסופי של `shared_counter`?", "code_snippet": null, "options": ["א. הערך הסופי תמיד יהיה 200000.", "ב. הערך הסופי תמיד יהיה 0.", "ג. הערך הסופי תמיד יהיה קטן מ-200000.", "ד. הערך הסופי אינו מובטח, והוא יכול להיות קטן מ-200000 עקב תנאי מירוץ (race condition).", "ה. הערך הסופי אינו מובטח, והוא יכול להיות גדול מ-200000 עקב תנאי מירוץ (race condition)."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "הקוד מכיל תנאי מירוץ (race condition) על המשתנה המשותף `shared_counter`. פעולת ה-`++` אינה אטומית, אלא מורכבת מכמה שלבים (קריאת הערך הנוכחי, הגדלת הערך, וכתיבת הערך החדש). כאשר שני חוטים מנסים לעדכן את המונה במקביל ללא מנגנון סנכרון (כמו mutex), ייתכן שחוט אחד יקרא את הערך, חוט אחר יקרא את אותו הערך ויעדכן אותו, ואז החוט הראשון יכתוב את הערך המיושן שלו, ובכך 'ידרוס' את העדכון של החוט השני. כתוצאה מכך, חלק מהעדכונים עלולים ללכת לאיבוד, והערך הסופי יהיה קטן מ-200000. הערך אינו מובטח ומשתנה בין הרצות שונות. הוא לא יכול להיות גדול מ-200000, שכן כל פעולה רק אמורה להגדיל את המונה באחד."}, "difficulty_estimation": "Medium", "_source_file": "0153__Synchronization__MultipleChoice__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:44:14", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Synchronization", "Race Condition", "Shared Memory"], "content": {"text": "נתון קטע הקוד הבא המורץ על ידי N חוטים (threads) במקביל. כל חוט מבצע את הפונקציה `thread_func` פעם אחת. המשתנה `counter` הוא גלובלי ומשותף לכל החוטים. מה תהיה התוצאה הסופית של `counter` לאחר שכל N החוטים סיימו את פעולתם?", "code_snippet": "int counter = 0; // משתנה גלובלי\n\nvoid *thread_func(void *arg) {\n    int temp = counter;\n    temp = temp + 1;\n    counter = temp;\n    return NULL;\n}", "options": ["א. בדיוק N", "ב. בדיוק 0", "ג. ערך כלשהו בין 0 ל-N-1 (כולל)", "ד. ערך כלשהו בין 1 ל-N (כולל), אך לרוב פחות מ-N", "ה. לא ניתן לדעת בוודאות, יכול להיות כל ערך שלם חיובי."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "הפעולה `counter++` אינה אטומית. היא מורכבת מקריאה של `counter` (לתוך `temp`), הגדלה של `temp`, וכתיבה בחזרה של `temp` ל-`counter`. כאשר מספר חוטים מבצעים פעולה זו במקביל ללא מנגנון סנכרון (כגון mutex), עלול להיווצר מצב מרוץ (race condition). לדוגמה, חוט אחד קורא את `counter` (נניח 0), אך לפני שהוא מספיק לכתוב בחזרה את הערך המוגדל (1), חוט אחר קורא גם הוא את אותו ערך ישן של `counter` (0). שני החוטים מגדילים את הערך באופן עצמאי ל-1 וכותבים בחזרה, ובכך 'אובדת' אחת ההגדלות – ה-`counter` יעמוד על 1 במקום 2. לכן, התוצאה הסופית של `counter` תהיה לרוב קטנה מ-`N`. במקרה הטוב ביותר (כאשר אין מצב מרוץ כלל, או כאשר N=1), הערך יהיה `N`. במקרה הגרוע ביותר, כאשר N גדול, ובהינתן מצבי מרוץ רבים, הערך יהיה נמוך משמעותית מ-`N`, אך לא יכול להיות פחות מ-1 (אם N גדול או שווה ל-1). לכן, הטווח הנכון הוא בין 1 ל-`N` (כולל), אך בפועל (במערכת מרובת חוטים) לרוב יהיה פחות מ-`N`."}, "difficulty_estimation": "Medium", "_source_file": "0154__Synchronization__MultipleChoice__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:44:29", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Race Conditions", "Mutexes"], "content": {"text": "נתונה פיסת הקוד הבאה:\nאם מספר חוטים (threads) שונים קוראים לפונקציה `increment_shared_counter()` במקביל, איזו מהטענות הבאות נכונה לגבי הערך הסופי של `shared_counter` לאחר שכל החוטים סיימו את ביצועם?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint shared_counter = 0; // משתנה גלובלי משותף\n\nvoid increment_shared_counter() {\n    shared_counter++;\n}", "options": ["א. הערך הסופי של `shared_counter` תמיד יהיה נכון, מכיוון שפעולת הקידום `++` היא אטומית במעבדים מודרניים.", "ב. הערך הסופי של `shared_counter` תמיד יהיה שגוי עקב Race Condition.", "ג. הערך הסופי של `shared_counter` עלול להיות שגוי עקב Race Condition, ונדרש מנגנון סנכרון (לדוגמה, Mutex) כדי להבטיח נכונות.", "ד. המערכת תמיד תקרוס (crash) עקב Race Condition.", "ה. Race Condition אינו רלוונטי במקרה זה מכיוון שאין כתיבה למשתנה מצד מספר חוטים."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "פעולת הקידום `shared_counter++` אינה פעולה אטומית. היא מורכבת משלוש פעולות בסיסיות: קריאת הערך של `shared_counter` מהזיכרון, הגדלת הערך, וכתיבת הערך החדש בחזרה לזיכרון. כאשר מספר חוטים מבצעים פעולה זו במקביל ללא סנכרון, ייתכן שחוט אחד יקרא את הערך, חוט אחר יקרא את אותו ערך לפני שהחוט הראשון הספיק לכתוב את הערך המעודכן, וכתוצאה מכך עדכונים מסוימים עלולים ללכת לאיבוד. מצב זה נקרא Race Condition. כדי למנוע זאת ולהבטיח שהערך הסופי יהיה נכון, יש להגן על הקטע הקריטי (הכולל את פעולת הקידום) באמצעות מנגנון סנכרון כמו Mutex."}, "difficulty_estimation": "Medium", "_source_file": "0155__Synchronization__MultipleChoice__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:44:46", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Mutexes", "Threads"], "content": {"text": "בתוכנית C הכוללת מספר תהליכונים (threads) המעדכנים משתנה משותף `counter`, נעשה שימוש ב-`pthread_mutex_t` בשם `lock` כדי להגן על הקטע הקריטי. איזו מהטענות הבאות נכונה לגבי השימוש ב-`lock`?", "code_snippet": null, "options": ["א. אם תהליכון רוכש את ה-`lock` ולאחר מכן מנסה לרכוש אותו שוב (לפני שחרורו), התוכנית תיכנס ככל הנראה למצב של קיפאון (deadlock).", "ב. תהליכון יכול לשחרר בהצלחה `lock` שנרכש על ידי תהליכון אחר.", "ג. אם תהליכון רוכש את ה-`lock` וקורא ל-`pthread_exit()` מבלי לשחררו, ה-`lock` ישוחרר אוטומטית על ידי המערכת.", "ד. השימוש ב-`pthread_mutex_lock` וב-`pthread_mutex_unlock` מבטיח שהתהליכונים יבצעו את עדכוני `counter` תמיד באותו סדר."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "נכון. עבור mutex רגיל (PTHREAD_MUTEX_NORMAL, שהוא ברירת המחדל), תהליכון המנסה לרכוש mutex שכבר נמצא בבעלותו ייחסם וייכנס למצב של קיפאון (self-deadlock). mutexים רקורסיביים (PTHREAD_MUTEX_RECURSIVE) מאפשרים זאת, אך אינם ברירת המחדל.\n\nלא נכון לגבי ב': ניסיון לשחרר mutex שלא נרכש על ידי התהליכון הקורא הוא התנהגות בלתי מוגדרת (undefined behavior) ובדרך כלל יגרום לשגיאה או קריסה.\n\nלא נכון לגבי ג': אם תהליכון יוצא תוך כדי החזקת mutex, ה-mutex נשאר נעול. זהו מקור נפוץ לבעיות כאשר תהליכונים אחרים ימתינו ל-mutex זה לנצח. mutexים רובסטיים (robust mutexes) מטפלים בתרחיש זה אך אינם ברירת המחדל.\n\nלא נכון לגבי ד': mutexים מבטיחים בלעדיות לקטע קריטי, ובכך מונעים תנאי מרוץ (race conditions) ומבטיחים את נכונות הערך הסופי. עם זאת, הם אינם מבטיחים סדר מסוים שבו תהליכונים יבצעו את הפעולות בתוך הקטע הקריטי."}, "difficulty_estimation": "Medium", "_source_file": "0156__Synchronization__MultipleChoice__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:45:06", "_subject": "Concurrency"}, {"id": 10, "type": "MultipleChoice", "topic": ["Synchronization", "Race Conditions", "Threads"], "content": {"text": "נתון קוד C הבא המשתמש במשתנה גלובלי `counter` ובשני תהליכונים (threads) המנסים להגדיל אותו. המשתנה `counter` מאותחל ל-0. כל אחד משני התהליכונים מגדיל את `counter` 1000 פעמים. מהו הערך הסופי האפשרי של `counter` לאחר ששני התהליכונים סיימו את פעולתם?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0;\n\nvoid* increment_thread(void* arg) {\n    for (int i = 0; i < 1000; i++) {\n        counter++;\n    }\n    return NULL;\n}\n\n// ההנחה היא שפונקציית main יוצרת שני תהליכונים הקוראים ל-increment_thread,\n// ממתינה להם, ואז מדפיסה את counter.", "options": ["א. 2000 בלבד", "ב. כל ערך בין 1 ל-2000 כולל", "ג. כל ערך בין 1000 ל-2000 כולל", "ד. כל ערך בין 1001 ל-2000 כולל", "ה. 0 בלבד"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הבעיה המתוארת היא תנאי מרוץ (Race Condition). הפעולה `counter++` אינה אטומית. היא מורכבת בדרך כלל משלושה שלבים: טעינת הערך של `counter` לתוך אוגר, הגדלת הערך באוגר, ושמירת הערך החדש מהאוגר חזרה ל-`counter`. כאשר שני תהליכונים מבצעים פעולה זו במקביל ללא מנגנוני סנכרון, ייתכנו תרחישי ביצוע שונים.\n\nהערך המקסימלי האפשרי הוא 2000. זה יקרה אם אחד התהליכונים מסיים את כל 1000 ההגדלות שלו לפני שהשני מתחיל, או אם פעולות ה-`load-increment-store` של כל תהליכון מתבצעות באופן כזה שאין איבוד עדכונים.\n\nהערך המינימלי האפשרי הוא 1. תרחיש לדוגמה:\n1. תהליכון A טוען את `counter` (שהוא 0) לאוגר שלו (R_A=0).\n2. תהליכון B טוען את `counter` (שהוא 0) לאוגר שלו (R_B=0).\n3. תהליכון A מגדיל את הערך באוגר שלו ל-1 (R_A=1).\n4. תהליכון B מגדיל את הערך באוגר שלו ל-1 (R_B=1).\n5. תהליכון A שומר את הערך (1) מן האוגר שלו ל-`counter`. כעת `counter` שווה ל-1.\n6. תהליכון B שומר את הערך (1) מן האוגר שלו ל-`counter`. כעת `counter` נשאר שווה ל-1.\nבמקרה זה, שתי פעולות `counter++` גרמו להגדלה אחת בלבד של `counter`. תרחיש קיצוני נוסף לערך מינימלי הוא אם תהליכון A טוען את 0, ואז תהליכון B מבצע את כל 1000 ההגדרות שלו (מעלה את `counter` ל-1000), ואז תהליכון A שומר את הערך 1 (שאותו חישב קודם לכן) חזרה ל-`counter`, הרי ש-`counter` יסיים ב-1.\n\nלכן, הערך הסופי של `counter` יכול להיות כל מספר שלם בין 1 ל-2000, כולל."}, "difficulty_estimation": "Medium", "_source_file": "0157__Synchronization__MultipleChoice__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:45:43", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Synchronization", "Mutexes", "POSIX Threads"], "content": {"text": "חוט ביצוע (thread) מנסה לרכוש מנעול (mutex) מסוג PTHREAD_MUTEX_NORMAL (הגדרת ברירת מחדל של POSIX mutex) שכבר נרכש על ידו, מבלי לשחרר אותו קודם. מהי התוצאה הסבירה ביותר של הניסיון השני לרכישת המנעול?", "code_snippet": null, "options": ["א. החוט ירכוש את המנעול שוב בהצלחה וימשיך בביצוע.", "ב. החוט ייתקע (deadlock) בניסיון הרכישה השני.", "ג. קריאת ה-`pthread_mutex_lock` השנייה תחזיר שגיאה.", "ד. המערכת תבצע החלפת הקשר לחוט אחר ותיתן לו הזדמנות לרכוש את המנעול."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "מנעול מסוג PTHREAD_MUTEX_NORMAL (התנהגות ברירת המחדל של POSIX mutex) אינו מאפשר רכישה חוזרת על ידי אותו חוט שכבר מחזיק בו. אם חוט מנסה לרכוש מנעול כזה פעם שנייה מבלי לשחרר אותו קודם, הוא ייחסם בניסיון הרכישה השני, מה שיוביל ל-deadlock עצמי (self-deadlock). זוהי התנהגות מוגדרת בתקן POSIX כדי למנוע טעויות תכנות נפוצות. מנעולים רקורסיביים (PTHREAD_MUTEX_RECURSIVE) מאפשרים רכישה חוזרת, אך זה לא המקרה כאן."}, "difficulty_estimation": "Medium", "_source_file": "0158__Synchronization__MultipleChoice__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:45:55", "_subject": "Concurrency"}, {"id": 10, "type": "MultipleChoice", "topic": ["Synchronization", "Mutexes", "Deadlock"], "content": {"text": "איזו מהטענות הבאות מתארת נכונה התנהגות של mutex סטנדרטי (non-recursive) בסביבת ריבוי חוטים?", "code_snippet": null, "options": ["א. חוט יכול לנעול mutex פעמיים ברצף (ללא שחרור ביניהם) בהצלחה.", "ב. אם חוט מנסה לנעול mutex שכבר נעול על ידו, הפעולה תגרום ל-deadlock (קיפאון).", "ג. mutex יכול לשמש להגנה על מספר משאבים שונים בו זמנית, כל עוד הם בתוך אותו critical section.", "ד. שחרור mutex שלא ננעל על ידי החוט הנוכחי, או שכבר שוחרר, הוא פעולה חוקית ובטוחה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "mutex סטנדרטי (non-recursive) מיועד להיות נעול רק פעם אחת על ידי חוט מסוים. אם חוט מנסה לנעול mutex שכבר נעול על ידו, הוא ימתין לשחרורו. מכיוון שהחוט עצמו הוא זה שמחזיק את המנעול, הוא לעולם לא ישחרר אותו בזמן שהוא ממתין לנעילה, מה שמוביל ל-deadlock. זוהי תכונה בסיסית של mutexים למניעת נעילה חוזרת (re-entrancy) אלא אם כן הם מוגדרים במפורש כ-recursive mutex. אפשרות א' שגויה מכיוון שזו בדיוק הסיבה ל-deadlock. אפשרות ג' נכונה מבחינת שימוש ב-mutex, אך היא אינה מתארת את 'התנהגות ה-mutex' אלא את אופן יישומו. אפשרות ד' שגויה, שכן ניסיון לשחרר mutex שלא ננעל על ידי החוט הקורא או שכבר שוחרר, מוביל בדרך כלל לשגיאה או התנהגות בלתי מוגדרת."}, "difficulty_estimation": "Medium", "_source_file": "0159__Synchronization__MultipleChoice__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:46:08", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Race Condition", "Mutex"], "content": {"text": "נתונה פיסת קוד המשתמשת בשני תהליכונים (threads) המעדכנים משתנה גלובלי משותף `counter`. כל תהליכון מבצע לולאה של 100,000 איטרציות, ובכל איטרציה מגדיל את `counter` באחד. איזו מהטענות הבאות נכונה לגבי קוד זה?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0; // משתנה גלובלי משותף\n\nvoid* increment(void* arg) {\n    for (int i = 0; i < 100000; i++) {\n        counter++; // פעולה לא אטומית\n    }\n    return NULL;\n}\n\n// פונקציית main (לא מוצגת במלואה) תיצור ותריץ שני תהליכונים שיקראו ל-increment.", "options": ["א. קוד זה יבטיח שהערך הסופי של counter יהיה תמיד 200,000.", "ב. קוד זה עלול לסבול מבעיית Race Condition, וניתן לפתור אותה באמצעות שימוש ב-mutex.", "ג. קוד זה עלול לסבול מבעיית Deadlock, וניתן לפתור אותה באמצעות שימוש בסמפור.", "ד. קוד זה בטוח לשימוש (thread-safe) מכיוון שפעולת ההגדלה counter++ היא אטומית."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הטענה הנכונה היא ב'. פעולת ההגדלה `counter++` אינה אטומית; היא מורכבת מקריאה של הערך הנוכחי של `counter`, הגדלתו באחד, וכתיבת הערך החדש בחזרה לזיכרון. כאשר שני תהליכונים מנסים לבצע פעולה זו במקביל ללא מנגנון סנכרון, ייתכן שתהליכון אחד יקרא את הערך, ותהליכון שני יקרא גם הוא את אותו ערך לפני שהתהליכון הראשון הספיק לכתוב את הערך המעודכן. כתוצאה מכך, אחד העדכונים יאבד, והערך הסופי של `counter` יהיה קטן מ-200,000. מצב זה נקרא Race Condition. הפתרון הנפוץ לבעיה זו הוא הגנה על הקטע הקריטי (critical section) באמצעות mutex, שיבטיח שרק תהליכון אחד יוכל לבצע את פעולת ההגדלה בכל רגע נתון. אין כאן בעיית Deadlock מכיוון שאין תלות מעגלית במשאבים."}, "difficulty_estimation": "Medium", "_source_file": "0160__Synchronization__MultipleChoice__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:46:19", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Deadlock", "Semaphores", "Producer-Consumer"], "content": {"text": "נתונה המחלקה הבאה ב-C המממשת חוצץ מעגלי (bounded buffer) באמצעות סמפורים:\n\n```c\n#include <semaphore.h>\n#include <stdio.h>\n\n#define BUFFER_SIZE 5\n\nint buffer[BUFFER_SIZE];\nint in = 0;\n// int out = 0; // Not directly used in produce, omitted for brevity\n\nsem_t mutex;    // Ensures mutual exclusion for buffer access\nsem_t full;     // Counts number of occupied slots\nsem_t empty;    // Counts number of empty slots\n\nvoid init_semaphores() {\n    sem_init(&mutex, 0, 1);\n    sem_init(&full, 0, 0);\n    sem_init(&empty, 0, BUFFER_SIZE);\n}\n\nvoid produce(int item) {\n    // סדר פעולות שגוי שעלול לגרום לבעיה\n    sem_wait(&mutex);   // 1. תפיסת המנעול ראשונה\n    sem_wait(&empty);   // 2. המתנה למקום פנוי (תוך החזקת המנעול)\n\n    // קטע קריטי: הוספת פריט לחוצץ\n    buffer[in] = item;\n    in = (in + 1) % BUFFER_SIZE;\n\n    sem_post(&full);    // 3. איתות שמקום התמלא\n    sem_post(&mutex);   // 4. שחרור המנעול\n}\n\n// void consume() { ... } // Omitted for brevity\n// int main() { ... } // Omitted for brevity\n```\n\nאיזו בעיה עלולה להיווצר כתוצאה מהמימוש הנתון של הפונקציה `produce`?", "code_snippet": null, "options": ["א. תנאי מרוץ (race condition) בגישה לחוצץ.", "ב. קיפאון (deadlock) כאשר החוצץ מלא.", "ג. הרעבה (starvation) של תהליכי הצרכן.", "ד. בזבוז משאבים עקב busy-waiting.", "ה. אף אחת מהתשובות האחרות אינה נכונה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הבעיה במימוש הפונקציה `produce` נובעת מסדר פעולות ה-`sem_wait`. תהליך יצרן תופס תחילה את ה-`mutex` באמצעות `sem_wait(&mutex)`. לאחר מכן, הוא מנסה להמתין למקום פנוי בחוצץ באמצעות `sem_wait(&empty)`. אם החוצץ מלא (כלומר `empty` שווה ל-0), תהליך היצרן ייחסם בהמתנה ל-`empty` – אך הוא עדיין מחזיק ב-`mutex`.\n\nתהליך צרכן, על מנת לפנות מקום בחוצץ, צריך לגשת לאזור הקריטי, ולשם כך עליו לתפוס את ה-`mutex`. אולם, ה-`mutex` כבר מוחזק על ידי היצרן החסום. מצב זה מוביל לקיפאון (deadlock): היצרן חסום בהמתנה למקום פנוי (שיכול להשתחרר רק על ידי צרכן), והצרכן חסום בהמתנה ל-`mutex` (המוחזק על ידי היצרן החסום). הפתרון הנכון הוא להמתין למקום פנוי (`sem_wait(&empty)`) *לפני* תפיסת ה-`mutex` (`sem_wait(&mutex)`), כך שה-`mutex` לא יוחזק בזמן המתנה למקום בחוצץ. "}, "difficulty_estimation": "Hard", "_source_file": "0161__Synchronization__MultipleChoice__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:46:38", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Reader-Writer Lock", "Starvation", "Concurrency"], "content": {"text": "נתונה מימוש חלקי של מנגנון נעילת קוראים-כותבים (Reader-Writer Lock) ב-C/C++ באמצעות mutex-ים של pthreads. המטרה היא לאפשר לקוראים מרובים לגשת למשאב במקביל, אך לאפשר רק לכותב אחד לגשת למשאב בכל רגע, ולמנוע גישת קוראים בזמן כתיבה.\n\n```c\n#include <pthread.h>\n#include <semaphore.h>\n\n// Global variables\nint readers_count = 0;\npthread_mutex_t mutex_readers; // Protects readers_count\npthread_mutex_t resource_lock; // Protects the shared resource for writers\n\nvoid init() {\n    pthread_mutex_init(&mutex_readers, NULL);\n    pthread_mutex_init(&resource_lock, NULL);\n}\n\nvoid reader_acquire() {\n    pthread_mutex_lock(&mutex_readers);\n    readers_count++;\n    if (readers_count == 1) {\n        pthread_mutex_lock(&resource_lock); // First reader locks resource for writers\n    }\n    pthread_mutex_unlock(&mutex_readers);\n}\n\nvoid reader_release() {\n    pthread_mutex_lock(&mutex_readers);\n    readers_count--;\n    if (readers_count == 0) {\n        pthread_mutex_unlock(&resource_lock); // Last reader unlocks resource for writers\n    }\n    pthread_mutex_unlock(&mutex_readers);\n}\n\nvoid writer_acquire() {\n    pthread_mutex_lock(&resource_lock); // Writer locks the resource\n}\n\nvoid writer_release() {\n    pthread_mutex_unlock(&resource_lock); // Writer unlocks the resource\n}\n```\n\nבהתבסס על הקוד לעיל, איזו מהטענות הבאות נכונה לגבי המימוש?", "code_snippet": null, "options": ["א. המימוש נכון ומבטיח שאין תנאי מרוץ (race conditions) ואין רעב (starvation) עבור אף סוג של תהליכים (קוראים או כותבים).", "ב. המימוש עלול לגרום לתנאי מרוץ כאשר מספר קוראים מנסים להיכנס בו זמנית.", "ג. המימוש עלול לגרום לרעב של כותבים (writer starvation) אם יש זרם קבוע של קוראים.", "ד. המימוש עלול לגרום לרעב של קוראים (reader starvation) אם יש זרם קבוע של כותבים.", "ה. המימוש עלול לגרום למבוי סתום (deadlock) במצבים מסוימים."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג. המימוש עלול לגרום לרעב של כותבים (writer starvation) אם יש זרם קבוע של קוראים.", "explanation": "הסבר: המימוש הנתון הוא סוג של מנגנון קוראים-כותבים המעדיף קוראים. כאשר קורא ראשון מגיע, הוא נועל את המשאב (resource_lock), וחוסם כותבים. קוראים נוספים יכולים להיכנס בחופשיות. הבעיה המרכזית מתרחשת כאשר יש זרם מתמשך של קוראים: כל עוד יש לפחות קורא אחד פעיל, resource_lock נשאר תפוס על ידי קבוצת הקוראים, והכותבים הממתינים על writer_acquire לעולם לא יוכלו לתפוס את המנעול, וכתוצאה מכך יסבלו מרעב (starvation). אין תנאי מרוץ על readers_count מכיוון שהוא מוגן על ידי mutex_readers. אין מבוי סתום מכיוון שאין תלות מעגלית במנעולים, והמנעולים נתפסים ומשוחררים בסדר לינארי פשוט שאינו יוצר מעגל המתנה."}, "difficulty_estimation": "Hard", "_source_file": "0162__Synchronization__MultipleChoice__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:46:59", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Condition Variables", "Starvation", "Concurrency"], "content": {"text": "נתונה תבנית קוד C/C++ לניהול מאגר משאבים משותף. כל תהליך יכול לבקש כמות משתנה של משאבים מהמאגר. אם אין מספיק משאבים זמינים, התהליך ממתין על משתנה התנאי `cond`. כאשר תהליך משחרר משאבים למאגר, הוא צריך להודיע לתהליכים הממתינים.\n\nאיזו קריאה לפונקציית הודעה (notification) יש לבצע בתוך `release_items` כדי למנוע קיפאון (starvation) או חוסר יעילות משמעותי במערכת, בהתחשב בכך שייתכנו תהליכים רבים הממתינים למספרים שונים של משאבים?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For usleep\n\nconst int MAX_ITEMS = 10;\nint available_items = MAX_ITEMS;\npthread_mutex_t mtx = PTHREAD_MUTEX_INITIALIZER;\npthread_cond_t cond = PTHREAD_COND_INITIALIZER;\n\nvoid acquire_items(int num_to_acquire, int thread_id) {\n    pthread_mutex_lock(&mtx);\n    // printf(\"Thread %d requesting %d items. Available: %d\\n\", thread_id, num_to_acquire, available_items);\n    while (available_items < num_to_acquire) {\n        pthread_cond_wait(&cond, &mtx);\n    }\n    available_items -= num_to_acquire;\n    // printf(\"Thread %d acquired %d items. Available: %d\\n\", thread_id, num_to_acquire, available_items);\n    pthread_mutex_unlock(&mtx);\n    // Simulate work outside critical section\n    usleep(100000); // 100 ms\n}\n\nvoid release_items(int num_to_release, int thread_id) {\n    pthread_mutex_lock(&mtx);\n    available_items += num_to_release;\n    // printf(\"Thread %d released %d items. Available: %d\\n\", thread_id, num_to_release, available_items);\n    // איזו קריאה יש לבצע כאן כדי להודיע לתהליכים ממתינים?\n    // א. pthread_cond_signal(&cond);\n    // ב. pthread_cond_broadcast(&cond);\n    // ג. אין צורך בקריאה כלשהי.\n    // ד. כל התשובות האחרות אינן נכונות.\n    pthread_mutex_unlock(&mtx);\n}", "options": ["א. pthread_cond_signal(&cond);", "ב. pthread_cond_broadcast(&cond);", "ג. אין צורך בקריאה כלשהי.", "ד. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "במקרה זה, יש להשתמש ב-`pthread_cond_broadcast(&cond);`. הסיבה לכך היא שתהליכים שונים עשויים להמתין לכמויות שונות של משאבים. כאשר משאבים משוחררים, ייתכן שיותר מתהליך אחד יוכל כעת להמשיך, או שהתהליך היחיד שהתעורר על ידי `pthread_cond_signal` לא יוכל להמשיך (כי עדיין אין מספיק משאבים עבורו, בעוד שתהליך אחר שזקוק לפחות משאבים כן היה יכול). שימוש ב-`pthread_cond_signal` במצב כזה עלול להוביל לקיפאון (starvation) של תהליכים שיכולים היו להמשיך, או לחוסר יעילות משמעותי עקב התעוררויות שווא (spurious wakeups) שאינן מקדמות את המערכת. `pthread_cond_broadcast` מבטיח שכל התהליכים הממתינים יבדקו מחדש את תנאיהם, ומאפשר לכל התהליכים שיכולים להמשיך לעשות זאת, ובכך מונע קיפאון ומבטיח יעילות רבה יותר."}, "difficulty_estimation": "Hard", "_source_file": "0163__Synchronization__MultipleChoice__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:47:29", "_subject": "Concurrency"}, {"id": 10, "type": "MultipleChoice", "topic": ["Synchronization", "Peterson's Algorithm", "Memory Barriers", "Concurrency"], "content": {"text": "נניח מימוש של אלגוריתם פיטרסון (Peterson's Algorithm) עבור שני תהליכים (P0 ו-P1) במערכת מודרנית שבה המעבד או הקומפיילר עשויים לבצע אופטימיזציות של Reordering (שינוי סדר פעולות) לפעולות קריאה וכתיבה לזיכרון. הקוד עבור P0 מוצג להלן. מהי הסכנה העיקרית בהרצת קוד זה ללא שימוש ב-Memory Barriers (מחסומי זיכרון) או במשתנים אטומיים?", "code_snippet": "flag[0] = true;\nturn = 1;\nwhile (flag[1] && turn == 1);\n// Critical Section\nflag[0] = false;", "options": ["א. לא קיימת סכנה, האלגוריתם הוכח מתמטית ולכן יעבוד תמיד ללא קשר לארכיטקטורת החומרה.", "ב. ייתכן מצב שבו שני התהליכים יכנסו לקטע הקריטי בו-זמנית (פגיעה ב-Mutual Exclusion).", "ג. המערכת תיכנס ל-Deadlock ודאי בכל פעם ששני התהליכים ינסו להיכנס לקטע הקריטי יחד.", "ד. התהליכים יסבלו מהרעבה (Starvation) כיוון ש-turn לעולם לא יתעדכן בזמן, אך ה-Mutual Exclusion יישמר."]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "בארכיטקטורות מחשב מודרניות, המעבד או הקומפיילר עשויים לשנות את סדר פעולות הכתיבה והקריאה (Out-of-order execution) כדי לשפר ביצועים. ללא Memory Barriers, ייתכן שהכתיבה ל-flag[0] תתבצע בפועל (או תיראה לשאר הליבות) רק אחרי הקריאה של flag[1] בתוך הלולאה. במצב כזה, שני התהליכים עלולים לראות ש-flag של הצד השני הוא false בו-זמנית, ושניהם ייכנסו לקטע הקריטי יחד, מה שמפר את עקרון ה-Mutual Exclusion."}, "difficulty_estimation": "Hard", "_source_file": "0164__Synchronization__MultipleChoice__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:55:22", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Deadlock", "Condition Variables", "Concurrency", "Multithreading"], "content": {"text": "נתונה תוכנית C++ המממשת מחסום (barrier) ל-`NUM_THREADS` תהליכונים, המיועד לשימוש חוזר במספר סבבים. התהליכונים מבצעים עבודה, מגיעים למחסום, ממתינים שכל שאר התהליכונים יגיעו, ואז ממשיכים. המחסום מוגדר כדלקמן: \n\nמה יקרה כאשר התוכנית תרוץ עם `NUM_THREADS = 3`?", "code_snippet": "#include <iostream>\n#include <vector>\n#include <thread>\n#include <mutex>\n#include <condition_variable>\n#include <chrono>\n\nconst int NUM_THREADS = 3;\nstd::mutex mtx;\nstd::condition_variable cv;\nint arrived_count = 0;\n\nvoid barrier_function() {\n    std::unique_lock<std::mutex> lock(mtx);\n    arrived_count++;\n\n    if (arrived_count == NUM_THREADS) {\n        cv.notify_one(); // נקודת הכשל הפוטנציאלית\n        arrived_count = 0; // איפוס לסבב הבא\n    } else {\n        cv.wait(lock);\n    }\n}\n\nvoid worker_thread() {\n    std::this_thread::sleep_for(std::chrono::milliseconds(10));\n    barrier_function(); // סבב ראשון\n    std::this_thread::sleep_for(std::chrono::milliseconds(10));\n    barrier_function(); // סבב שני\n}\n\nint main() {\n    std::vector<std::thread> threads;\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        threads.emplace_back(worker_thread);\n    }\n    for (auto& t : threads) {\n        t.join();\n    }\n    // This line will likely not be reached due to deadlock\n    // std::cout << \"Main finished.\" << std::endl;\n    return 0;\n}", "options": ["א. התוכנית תרוץ בהצלחה ותסיים את פעולתה כרגיל.", "ב. יתרחש מצב של מרוץ (race condition) אך התוכנית תמיד תסיים בהצלחה.", "ג. יתרחש קיפאון (deadlock) של חלק מהתהליכונים בסבב השני של המחסום.", "ד. יתרחש קיפאון (deadlock) של כל התהליכונים כבר בסבב הראשון של המחסום.", "ה. התוכנית תקרוס עקב גישה לא חוקית לזיכרון."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התשובה הנכונה היא ג'.\nהבעיה טמונה בשימוש ב-`cv.notify_one()` במקום `cv.notify_all()` כאשר `arrived_count == NUM_THREADS` במחסום רב-פעמי.\n\nבסבב הראשון של המחסום:\n1. שלושת התהליכונים (T1, T2, T3) קוראים ל-`barrier_function()`.\n2. `arrived_count` יגיע ל-3. אחד התהליכונים (נניח T3) יגיע ראשון לשלב זה ויקרא ל-`cv.notify_one()`.\n3. `arrived_count` יתאפס ל-0.\n4. `cv.notify_one()` יעיר רק תהליכון אחד מבין שני התהליכונים האחרים שממתינים (T1 או T2). נניח ש-T1 מתעורר.\n5. כעת, T1 ו-T3 ממשיכים לאחר המחסום (T3 כי הוא קרא ל-`notify_one` ולא נכנס ל-`wait`, ו-T1 כי הוא התעורר). T2 נשאר במצב המתנה (waiting) מהסבב הראשון.\n\nבסבב השני של המחסום:\n1. T1 ו-T3 קוראים שוב ל-`barrier_function()`.\n2. `arrived_count` יגיע ל-1 (מ-T1) ואז ל-2 (מ-T3).\n3. T1 ו-T3 ייכנסו למצב המתנה (calling `cv.wait(lock)`), מכיוון ש-`arrived_count` לא יגיע ל-`NUM_THREADS` (שהוא 3). הם ימתינו לתהליכון השלישי.\n4. T2 עדיין ממתין מהסבב הראשון ולעולם לא יתעורר, מכיוון שהאות `notify_one` כבר נשלח בסבב הראשון והוא לא נבחר להתעורר, ואין מי שיעיר אותו שוב. לכן, `arrived_count` לעולם לא יגיע ל-3 בסבב השני.\n5. התוצאה היא ש-T1 ו-T3 ימתינו ללא הגבלת זמן (deadlock), מכיוון שהם ממתינים לתהליכון השלישי (שכבר נמצא בקיפאון מהסבב הראשון), ו-T2 עצמו בקיפאון. זהו קיפאון של חלק מהתהליכונים (T1, T2, T3 כולם בסופו של דבר) שנובע מהשימוש השגוי ב-`notify_one` במקום `notify_all` במחסום רב-פעמי."}, "difficulty_estimation": "Hard", "_source_file": "0165__Synchronization__MultipleChoice__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:47:58", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Concurrency", "Barrier"], "content": {"text": "נתון קטע קוד ב-C המממש מחסום (barrier) עבור מספר קבוע של תהליכים (NUM_THREADS). המחסום מיועד לאפשר לכל התהליכים להגיע לנקודה מסוימת לפני שכולם ממשיכים יחד. איזו מן הטענות הבאות מתארת נכונה בעיה פוטנציאלית בקוד וכיצד ניתן לפתור אותה באופן נכון?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\n#define NUM_THREADS 3 // Small number for easier analysis\n\npthread_mutex_t barrier_mutex = PTHREAD_MUTEX_INITIALIZER;\npthread_cond_t barrier_cond = PTHREAD_COND_INITIALIZER;\nint threads_arrived = 0; // Number of threads that have arrived at the barrier\n\nvoid *worker_thread(void *arg) {\n    long id = (long)arg;\n    printf(\"Thread %ld: Started, doing some work...\\n\", id);\n    sleep(1); // Simulate some work\n\n    pthread_mutex_lock(&barrier_mutex);\n    threads_arrived++;\n    printf(\"Thread %ld: Arrived at barrier. threads_arrived = %d\\n\", id, threads_arrived);\n\n    if (threads_arrived < NUM_THREADS) {\n        pthread_cond_wait(&barrier_cond, &barrier_mutex);\n    } else {\n        printf(\"Thread %ld: Last one, broadcasting!\\n\", id);\n        threads_arrived = 0; // Reset for next use\n        pthread_cond_broadcast(&barrier_cond);\n    }\n    pthread_mutex_unlock(&barrier_mutex);\n\n    printf(\"Thread %ld: Passed barrier, continuing...\\n\", id);\n    // Simulate more work after barrier\n    sleep(1);\n    printf(\"Thread %ld: Finished.\\n\", id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    for (long i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, worker_thread, (void *)i);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"All threads finished.\\n\");\n    return 0;\n}", "options": ["א. הקוד עלול לגרום למצב קיפאון (deadlock) מכיוון ש-pthread_cond_broadcast מעיר רק חלק מהתהליכים, ואילו אחרים נשארים בהמתנה. הפתרון הנכון הוא להשתמש ב-pthread_cond_signal במקום pthread_cond_broadcast.", "ב. הקוד עלול לגרום למצב קיפאון (deadlock). כאשר התהליך האחרון מגיע ומאפס את threads_arrived ל-0 לפני שכל התהליכים שהיו בהמתנה הספיקו להתעורר ולעבור את תנאי ה-if, תהליכים שהתעוררו מאוחר יבדקו threads_arrived < NUM_THREADS (שיהיה 0 < NUM_THREADS) ויכנסו שוב להמתנה בלתי מוגבלת. הפתרון הנכון הוא להשתמש במונה דורות (generation counter) או בשני משתני תנאי כדי למנוע מתהליכים להתעורר ולבדוק תנאי של מחזור עתידי.", "ג. הקוד סובל מבעיית תנאי מירוץ (race condition) בגישה למשתנה threads_arrived מכיוון שהוא אינו מוגן על ידי מנעול. הפתרון הוא לעטוף את כל הגישות ל-threads_arrived בקריאות pthread_mutex_lock ו-pthread_mutex_unlock.", "ד. הקוד אינו מכיל בעיות סנכרון והוא יפעל כראוי בכל התרחישים, שכן pthread_cond_broadcast מבטיח שכל התהליכים יתעוררו."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הבעיה בקוד היא מצב קיפאון (deadlock) פוטנציאלי במחסום. כאשר התהליך האחרון מגיע למחסום, הוא מאפס את threads_arrived ל-0 וקורא ל-pthread_cond_broadcast. pthread_cond_broadcast מעיר את כל התהליכים שממתינים על barrier_cond. תהליכים אלו, לאחר שהתעוררו ותפסו מחדש את המנעול barrier_mutex, בודקים שוב את התנאי `if (threads_arrived < NUM_THREADS)`. מכיוון ש-`threads_arrived` אופס כבר ל-0 על ידי התהליך האחרון, התנאי `0 < NUM_THREADS` יהיה תמיד נכון עבור תהליכים אלו, והם יכנסו שוב ל-`pthread_cond_wait` וימתינו באופן בלתי מוגבל. הם לעולם לא יתעוררו שוב מכיוון שאין תהליכים נוספים שיגיעו למחסום ויקראו ל-`pthread_cond_broadcast` עבור מחזור זה. הפתרון הנפוץ לבעיה זו במחסומים מחזוריים (או במחסומים עם פוטנציאל לשימוש חוזר) הוא שימוש ב\"מונה דורות\" (generation counter) או בשני משתני תנאי. מונה הדורות מבטיח שגם אם תהליך מתעורר מאוחר, הוא לא יבלבל את מחזור המחסום הנוכחי עם מחזור עתידי, אלא ימתין רק אם מונה הדורות שלו אינו תואם למונה הדורות הנוכחי של המחסום."}, "difficulty_estimation": "Hard", "_source_file": "0166__Synchronization__MultipleChoice__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:48:42", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Concurrency", "Condition Variables", "Race Conditions"], "content": {"text": "נתון קטע קוד C++ המייצג חלק ממימוש צרכן בתבנית מפיק-צרכן באמצעות `std::mutex` ו-`std::condition_variable`. הצֶרְכָן ממתין לפריטים בחוצץ משותף. איזו בעיה פוטנציאלית חמורה קיימת במימוש זה של פונקציית הצרכן?", "code_snippet": "#include <mutex>\n#include <condition_variable>\n#include <queue>\n\nstd::mutex mtx;\nstd::condition_variable cv;\nstd::queue<int> buffer; // Assume this is shared and populated by a producer\n\nvoid consumer_func() {\n    std::unique_lock<std::mutex> lock(mtx);\n    if (buffer.empty()) {\n        cv.wait(lock);\n    }\n    // Assume after this point, the consumer attempts to process an item.\n}", "options": ["א. הקוד עלול לגרום ל-deadlock אם הצרכן מתעורר לפני שיש פריטים בחוצץ.", "ב. הקוד סובל מבעיה של \"התעוררות אבודה\" (missed wakeup), שבה הצרכן עלול להמתין ללא הגבלת זמן למרות שיש פריטים בחוצץ.", "ג. הקוד עלול לגרום ל-starvation של המפיק, מכיוון שהצרכן לא משחרר את המנעול בזמן.", "ד. הקוד עלול לגרום ל-race condition על המשתנה `buffer.empty()`, מכיוון שהוא לא מוגן כראוי.", "ה. אין בעיה פוטנציאלית חמורה בקוד, והוא נכון מבחינה לוגית עבור תרחיש בסיסי."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. הבעיה העיקרית כאן היא \"התעוררות אבודה\" (missed wakeup). אם התנאי `buffer.empty()` מתקיים, הצרכן נכנס לבלוק ה-`if`. בין הבדיקה `buffer.empty()` לבין הקריאה ל-`cv.wait(lock)`, ייתכן שהמפיק יוסיף פריט לחוצץ ויקרא ל-`cv.notify_one()`. במקרה כזה, ה-`notify_one` \"נאבד\" מכיוון שהצרכן עדיין לא נכנס למצב המתנה. לאחר מכן, הצרכן יקרא ל-`cv.wait(lock)` וייכנס למצב המתנה, אך לא יקבל את ההתראה שכבר נשלחה, ועלול להמתין ללא הגבלת זמן למרות שיש פריט בחוצץ. הפתרון הנכון הוא לבדוק את התנאי בלולאת `while` (כלומר, `while (buffer.empty()) { cv.wait(lock); }`) או להשתמש בגרסת ה-`wait` שמקבלת פרדיקט (למשל, `cv.wait(lock, []{ return !buffer.empty(); });`), כדי להתמודד גם עם \"התעוררויות שווא\" (spurious wakeups) וגם עם בעיית ה-\"התעוררות אבודה\".\n\nניתוח תשובות אחרות:\nא. deadlock: לא סביר שזה יגרום ל-deadlock באופן ישיר מהקוד הזה. ה-`cv.wait` משחרר את המנעול באופן אטומי לפני הכניסה למצב המתנה, כך שתהליכים אחרים (כמו המפיק) יכולים לתפוס את המנעול. הבעיה כאן היא לא חסימה הדדית.\nג. starvation של המפיק: הצרכן משחרר את המנעול לפני ה-`wait`, כך שהמפיק יכול לתפוס את המנעול ולהוסיף פריטים. הבעיה היא יותר שהצרכן לא יתעורר, לא שהמפיק לא יוכל לייצר.\nד. race condition על `buffer.empty()`: הבדיקה `buffer.empty()` מתבצעת בתוך קטע קריטי (לאחר תפיסת המנעול `lock(mtx)`), כך שאין race condition על הבדיקה עצמה. ה-race condition הוא על ה-timing של ה-`notify_one` ביחס ל-`wait`."}, "difficulty_estimation": "Hard", "_source_file": "0167__Synchronization__MultipleChoice__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:49:09", "_subject": "Concurrency"}, {"id": 10, "type": "MultipleChoice", "topic": ["Synchronization", "Condition Variables", "Race Conditions", "Lost Wakeup"], "content": {"text": "נתון הקוד הבא המממש סנכרון פשוט בין שני תהליכונים (Threads). תהליכון א' ממתין שמשתנה גלובלי בשם ready יהפוך ל-1, ותהליכון ב' מעדכן את ערכו. המשתנים m (מסוג pthread_mutex_t) ו-c (מסוג pthread_cond_t) אותחלו כראוי. איזה מהמשפטים הבאים מתאר בצורה המדויקת ביותר את הבעיה הפוטנציאלית בקוד?", "code_snippet": "// Global variables\nint ready = 0;\npthread_mutex_t m;\npthread_cond_t c;\n\n// Thread A:\npthread_mutex_lock(&m);\nwhile (ready == 0) {\n    pthread_cond_wait(&c, &m);\n}\npthread_mutex_unlock(&m);\n\n// Thread B:\nready = 1;\npthread_cond_signal(&c);", "options": ["א. הקוד תקין לחלוטין; ביצוע pthread_cond_signal ללא נעילת המנעול הוא מותר ותקין תמיד.", "ב. תיתכן בעיית 'Lost Wakeup': תהליכון א' עלול לבדוק את התנאי, למצוא שהוא 0, אך לפני שיקרא ל-wait, תהליכון ב' יעדכן את המשתנה וישלח סיגנל שייאבד.", "ג. הקוד יגרום בהכרח ל-Deadlock כיוון שתהליכון ב' לא משחרר מנעול שלא נעל.", "ד. תהליכון א' עלול להיכנס ללולאה אינסופית בגלל Spurious Wakeup גם אם ready שונה ל-1.", "ה. תהליכון ב' יקרוס (Segmentation Fault) בזמן הקריאה ל-pthread_cond_signal כי המנעול m אינו מוחזק על ידו."]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הבעיה היא היעדר סנכרון על המשתנה המשותף ready בתהליכון ב'. תרחיש אפשרי: תהליכון א' נועל את המנעול, בודק את ready ורואה שהוא 0. לפני ש-א' קורא ל-pthread_cond_wait (שמשחרר את המנעול אטומית), מתבצע context switch. תהליכון ב' מעדכן את ready ל-1 ושולח סיגנל. כיוון שאין אף תהליכון שממתין כרגע על c, הסיגנל הולך לאיבוד. כש-א' חוזר לפעול, הוא קורא ל-wait ונרדם לנצח, למרות ש-ready כבר 1. לכן חובה לעדכן את המשתנה ולשלוח את הסיגנל תחת הגנת המנעול."}, "difficulty_estimation": "Hard", "_source_file": "0168__Synchronization__MultipleChoice__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:55:43", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Semaphores", "Threads"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בשני חוטים (threads) לעדכון משתנה גלובלי משותף בשם counter. הסמפור s מאותחל לערך 1.", "code_snippet": "int counter = 0;\nsem_t s;\n\nvoid* increment(void* arg) {\n    for (int i = 0; i < 50; i++) {\n        sem_wait(&s);\n        counter++;\n        sem_post(&s);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    sem_init(&s, 0, 1);\n    pthread_create(&t1, NULL, increment, NULL);\n    pthread_create(&t2, NULL, increment, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"%d\", counter);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "מהו הערך שיודפס בסיום ריצת התוכנית? הסבירו בקצרה מדוע.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "נניח שמתכנת בטעות הסיר את השורה sem_post(&s); מתוך הלולאה. כיצד תשתנה התנהגות התוכנית?", "code_snippet": null, "options": null}], "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: הערך שיודפס הוא 100. כל אחד משני החוטים מבצע 50 איטרציות של הגדלת המשתנה counter. מכיוון שהגישה למשתנה המשותף מוגנת על ידי סמפור בינארי (המשמש כ-Mutex), לא יתרחשו מצבי מרוץ (Race Conditions) וכל העדכונים יישמרו.\n\n10.2: התוכנית תיכנס למצב של קיפאון (Deadlock/Hang). החוט הראשון שיצליח להיכנס לקטע הקריטי יבצע sem_wait ויוריד את ערך הסמפור ל-0. מכיוון שאין sem_post, ערך הסמפור לא יחזור ל-1 לעולם. לכן, באיטרציה השנייה שלו (או כאשר החוט השני ינסה להיכנס), הוא ייחסם ב-sem_wait לנצח."}, "difficulty_estimation": "Easy", "_source_file": "0169__Synchronization__Open__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:55:58", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Race Condition", "Mutex", "Threads"], "content": {"text": "נתונה תוכנית C בה מספר חוטים (threads) ניגשים במקביל למשתנה גלובלי משותף ומגדילים אותו. קטע הקוד הבא מציג את הפונקציה אותה מריץ כל חוט:", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint shared_counter = 0; // משתנה גלובלי משותף\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < 100000; ++i) {\n        shared_counter++; // גישה למשתנה המשותף\n    }\n    return NULL;\n}\n\n// פונקציית main לא הוצגה במלואה, אך היא יוצרת מספר חוטים המריצים את increment_counter", "options": null}, "sub_questions": [{"id": "10.1", "text": "הסבירו מדוע קטע הקוד הנ\"ל עלול להוביל לתוצאה שגויה כאשר מספר חוטים מריצים אותו במקביל. מהו הבעיה המרכזית כאן?", "code_snippet": null, "options": null}, {"id": "10.2", "text": "הציעו פתרון לבעיה באמצעות מנעול (mutex) בסביבת pthreads. כתבו את קטע הקוד המתוקן.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: הבעיה המרכזית היא תנאי מרוץ (Race Condition). הפעולה `shared_counter++` אינה פעולה אטומית. למעשה, היא מתורגמת למספר הוראות מכונה:\n1. קריאת הערך של `shared_counter` מהזיכרון לתוך רגיסטר.\n2. הגדלת הערך ברגיסטר באחד.\n3. כתיבת הערך המעודכן מהרגיסטר בחזרה לזיכרון.\n\nכאשר מספר חוטים מריצים את הפעולות הללו במקביל, ייתכן שחוט אחד יקרא את הערך של `shared_counter`, לפני שחוט אחר הספיק לכתוב את ערכו המעודכן בחזרה. לדוגמה, אם `shared_counter` הוא 10, חוט A קורא 10, חוט B קורא 10. שניהם מגדילים ל-11 ברגיסטר שלהם. חוט A כותב 11, ומיד אחריו חוט B כותב 11. במקרה כזה, למרות שבוצעו שתי פעולות הגדלה, המונה יגדל רק באחד במקום בשניים, מה שיוביל לתוצאה שגויה (פחותה מהצפוי).\n\n10.2: כדי לפתור את בעיית תנאי המרוץ, יש להגן על הגישה למשתנה המשותף `shared_counter` באמצעות מנעול (mutex). מנעול מבטיח שרק חוט אחד יוכל להיכנס לקטע קריטי (Critical Section) מסוים בכל רגע נתון.\nיש לאתחל את המנעול, לנעול אותו לפני הגישה למשתנה המשותף, ולשחרר אותו לאחר מכן.\n\nקוד מתוקן:\n```c\n#include <stdio.h>\n#include <pthread.h>\n\nint shared_counter = 0; // משתנה גלובלי משותף\npthread_mutex_t counter_mutex; // הכרזת על מנעול\n\nvoid* increment_counter_safe(void* arg) {\n    for (int i = 0; i < 100000; ++i) {\n        pthread_mutex_lock(&counter_mutex); // נעל את המנעול\n        shared_counter++;                   // גישה בטוחה למשתנה המשותף\n        pthread_mutex_unlock(&counter_mutex); // שחרר את המנעול\n    }\n    return NULL;\n}\n\n// פונקציית main (לצורך הדגמה, לא חלק מהשאלה המקורית)\n/*\nint main() {\n    pthread_t threads[5];\n    pthread_mutex_init(&counter_mutex, NULL); // אתחול המנעול\n\n    for (int i = 0; i < 5; ++i) {\n        pthread_create(&threads[i], NULL, increment_counter_safe, NULL);\n    }\n\n    for (int i = 0; i < 5; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", shared_counter); // אמור להיות 500000\n    pthread_mutex_destroy(&counter_mutex); // שחרור המנעול\n    return 0;\n}\n*/\n```"}, "difficulty_estimation": "Easy", "_source_file": "0170__Synchronization__Open__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:49:24", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Synchronization", "Mutex", "Race Condition"], "content": {"text": "נתונים שני חוטים (Threads) המריצים את הפונקציה `increment_counter` במקביל. המשתנה `counter` הוא משתנה גלובלי המאותחל ל-0. הנח כי אין אופטימיזציות של הקומפיילר וכי הפעולות מבוצעות בדיוק כפי שהן כתובות.", "code_snippet": "int counter = 0;\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < 100; i++) {\n        int temp = counter;\n        temp = temp + 1;\n        counter = temp;\n    }\n    return NULL;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "מהו השם של התופעה שעלולה לגרום לכך שהערך הסופי של המשתנה `counter` יהיה נמוך מ-200?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "הציעו פתרון המשתמש ב-Mutex (מנעול) על מנת להבטיח שהערך הסופי של `counter` יהיה תמיד 200. יש לכתוב את קטע הקוד הרלוונטי.", "code_snippet": null, "options": null}], "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: התופעה נקראת 'מרוץ תהליכים' (Race Condition). היא מתרחשת כאשר מספר חוטים ניגשים למשאב משותף (במקרה זה המשתנה counter) ומבצעים עליו פעולות של קריאה וכתיבה ללא סנכרון, כך שהתוצאה הסופית תלויה בסדר התזמון של החוטים.\n\n1.2: כדי לפתור זאת, יש להשתמש ב-Mutex שיבטיח שרק חוט אחד נמצא ב'קטע הקריטי' (Critical Section) בכל זמן נתון. \nקוד מוצע:\n\npthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < 100; i++) {\n        pthread_mutex_lock(&lock);\n        int temp = counter;\n        temp = temp + 1;\n        counter = temp;\n        pthread_mutex_unlock(&lock);\n    }\n    return NULL;\n}"}, "difficulty_estimation": "Easy", "_source_file": "0171__Synchronization__Open__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:56:17", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Race Condition", "Mutex"], "content": {"text": "נתון קטע קוד ב-C המציג פונקציה `increment_counter` המופעלת על ידי מספר תהליכונים במקביל. הפונקציה מגדילה מונה גלובלי משותף.", "code_snippet": "int global_counter = 0;\n\nvoid increment_counter() {\n    int temp = global_counter;\n    // Simulate some work\n    // usleep(1000);\n    global_counter = temp + 1;\n}"}, "sub_questions": [{"id": "10.1", "text": "הסבר מדוע קטע הקוד הזה עלול לגרום לבעיית מירוץ (Race Condition) כאשר מספר תהליכונים מפעילים את `increment_counter` במקביל.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "הצג קטע קוד מתוקן המשתמש במנעול (mutex) כדי למנוע את בעיית המירוץ ולהבטיח שהמונה הגלובלי יתעדכן בצורה נכונה. כלול את ההכרזה, האתחול והשחרור של המנעול.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: בעיית מירוץ (Race Condition) מתרחשת כאשר מספר תהליכונים ניגשים למשאב משותף (במקרה זה, `global_counter`) ומנסים לשנות אותו בו-זמנית, והתוצאה הסופית תלויה בסדר הלא-דטרמיניסטי שבו התהליכונים מבצעים את פעולותיהם. בקטע הקוד הנתון, פעולת ההגדלה (`global_counter = temp + 1;`) אינה אטומית. אם שני תהליכונים קוראים את `global_counter` (למשל, שניהם קוראים 0) כמעט באותו זמן, ואז שניהם מגדילים את הערך שקראו ל-1 וכותבים בחזרה, במקום שהמונה יהיה 2, הוא יהיה רק 1. זאת מכיוון שכל אחד מהם עבד על עותק משלו של הערך הישן, וכתב אותו בחזרה מבלי להתחשב בשינויים של תהליכונים אחרים. הוספת `usleep` מדמה עיכוב ומגדילה את הסיכוי לבעיה זו.\n\n10.2: כדי למנוע את בעיית המירוץ, יש להגן על הקטע הקריטי (Critical Section) שבו המשתנה המשותף `global_counter` נקרא ונכתב. נשתמש במנעול (mutex) כדי להבטיח שרק תהליכון אחד יוכל להיכנס לקטע קריטי זה בכל רגע נתון.\n```c\n#include <pthread.h>\n#include <stdio.h>\n// #include <unistd.h> // For usleep, if needed for testing\n\nint global_counter = 0;\npthread_mutex_t counter_mutex; // Declare a mutex\n\nvoid increment_counter() {\n    pthread_mutex_lock(&counter_mutex); // Acquire the lock\n    // Critical Section\n    int temp = global_counter;\n    // Simulate some work (should be minimal in critical section if performance is key)\n    // usleep(1000);\n    global_counter = temp + 1;\n    // End Critical Section\n    pthread_mutex_unlock(&counter_mutex); // Release the lock\n}\n\n// Example of how mutex would be initialized and destroyed in main:\n// int main() {\n//     pthread_mutex_init(&counter_mutex, NULL); // Initialize the mutex\n//     // ... create and join threads that call increment_counter()...\n//     pthread_mutex_destroy(&counter_mutex); // Destroy the mutex\n//     return 0;\n// }\n```\nהסבר:\n1.  **הכרזה ואתחול המנעול**: `pthread_mutex_t counter_mutex;` מכריז על משתנה מנעול. `pthread_mutex_init(&counter_mutex, NULL);` מאתחל אותו לפני השימוש (לרוב בפונקציית `main` או בפונקציית אתחול מערכת). יש לזכור גם לשחרר את המשאבים של המנעול באמצעות `pthread_mutex_destroy()` בסיום השימוש כדי למנוע דליפות זיכרון.\n2.  **נעילה (Lock)**: `pthread_mutex_lock(&counter_mutex);` מבוצעת לפני הכניסה לקטע הקריטי. אם המנעול כבר תפוס על ידי תהליכון אחר, התהליכון הנוכחי ייחסם (יעבור למצב המתנה) עד שהמנעול ישוחרר. זה מבטיח בלעדיות הדדית (mutual exclusion) לקטע הקריטי.\n3.  **שחרור (Unlock)**: `pthread_mutex_unlock(&counter_mutex);` מבוצעת לאחר היציאה מהקטע הקריטי, ומשחררת את המנעול, ובכך מאפשרת לתהליכונים אחרים שחסומים להיכנס לקטע הקריטי."}, "difficulty_estimation": "Easy", "_source_file": "0172__Synchronization__Open__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:49:44", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Race Condition", "Mutex", "Threads"], "content": {"text": "נתון קטע הקוד הבא בשפת C המשתמש בספריית pthreads. הקוד יוצר שני תהליכונים (threads) שכל אחד מהם מגדיל משתנה גלובלי משותף `counter` 100,000 פעמים.\n\nמהו הערך הסופי ה *צפוי* של המונה `counter` לאחר ששני התהליכונים יסיימו את ריצתם? האם ערך זה מובטח תמיד? אם לא, הסבר מדוע וכיצד ניתן לתקן את הבעיה כדי להבטיח שהמונה יגיע לערך הצפוי בכל הרצה, תוך שימוש במנגנון סנכרון מתאים.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0;\n\nvoid *increment(void *arg) {\n    for (int i = 0; i < 100000; i++) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n    pthread_create(&tid1, NULL, increment, NULL);\n    pthread_create(&tid2, NULL, increment, NULL);\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n    printf(\"Final counter: %d\\n\", counter);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הערך הסופי הצפוי של המונה `counter` הוא 200,000 (100,000 מכל תהליכון).\n\nערך זה אינו מובטח תמיד. הבעיה היא תנאי מרוץ (race condition). הפעולה `counter++` אינה פעולה אטומית. היא מורכבת משלוש פעולות בסיסיות: קריאת ערך המונה לתוך רגיסטר, הגדלת הרגיסטר באחד, וכתיבת הערך המעודכן חזרה לזיכרון. כאשר שני תהליכונים מנסים לבצע פעולה זו במקביל, ייתכן תזמון שבו תהליכון אחד קורא את ערך המונה, ואז מופסק לפני שהוא מספיק לכתוב את הערך המעודכן. בזמן זה, התהליכון השני קורא את אותו ערך ישן, מגדיל אותו וכותב אותו בחזרה. התוצאה היא שעדכון אחד אובד, ולכן הערך הסופי יהיה נמוך מ-200,000.\n\nכדי לתקן את הבעיה ולהבטיח שהמונה יגיע לערך הנכון, יש להגן על הגישה למשתנה `counter` באמצעות מנגנון סנכרון, כגון mutex. ה-mutex מבטיח שרק תהליכון אחד יוכל להיכנס לקטע הקריטי (הקוד שמשנה את המונה) בכל רגע נתון. הנה קטע הקוד המתוקן:\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0;\npthread_mutex_t mutex; // Declare a mutex\n\nvoid *increment(void *arg) {\n    for (int i = 0; i < 100000; i++) {\n        pthread_mutex_lock(&mutex);   // Lock the mutex before accessing counter\n        counter++;\n        pthread_mutex_unlock(&mutex); // Unlock the mutex after accessing counter\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n    pthread_mutex_init(&mutex, NULL); // Initialize the mutex\n\n    pthread_create(&tid1, NULL, increment, NULL);\n    pthread_create(&tid2, NULL, increment, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    printf(\"Final counter: %d\\n\", counter);\n\n    pthread_mutex_destroy(&mutex); // Destroy the mutex\n    return 0;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0173__Synchronization__Open__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:49:58", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization"], "content": {"text": "נתון קטע הקוד הבא בשפת C, המבוצע על ידי מספר חוטים במקביל. קטע הקוד מנסה לעדכן משתנה גלובלי משותף בשם `shared_counter`.\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n\nint shared_counter = 0; // משתנה גלובלי משותף\n\nvoid *increment_counter(void *arg) {\n    for (int i = 0; i < 100000; i++) {\n        shared_counter++;\n    }\n    return NULL;\n}\n```\n\n1. הסבר מדוע קטע קוד זה עלול להוביל לתוצאה שגויה (כלומר, לא 200000 אם שני חוטים מריצים אותו). ציין את שם הבעיה הספציפית.\n2. הצע פתרון לבעיה זו באמצעות מנגנון סנכרון מתאים (לדוגמה, מוטקס) וכתוב את קטע הקוד המתוקן עבור הפונקציה `increment_counter`.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint shared_counter = 0; // משתנה גלובלי משותף\n\nvoid *increment_counter(void *arg) {\n    for (int i = 0; i < 100000; i++) {\n        shared_counter++;\n    }\n    return NULL;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "**חלק 1: הסבר הבעיה**\nהבעיה בקטע הקוד הנתון היא 'תנאי מירוץ' (Race Condition). כאשר מספר חוטים מנסים לעדכן את המשתנה `shared_counter` במקביל ללא סנכרון, הפעולה `shared_counter++` אינה אטומית. היא מורכבת משלוש פעולות ברמה נמוכה יותר:\n1.  קריאת הערך הנוכחי של `shared_counter` מהזיכרון.\n2.  הגדלת הערך ב-1.\n3.  כתיבת הערך החדש בחזרה לזיכרון.\nאם שני חוטים קוראים את אותו ערך של `shared_counter` לפני שאחד מהם מספיק לכתוב את הערך המוגדל בחזרה, שני החוטים יגדילו את אותו ערך ורק ההגדלה של אחד מהם תשרוד, מה שיוביל לאובדן עדכונים ולתוצאה סופית שגויה (נמוכה מהצפוי).\n\n**חלק 2: פתרון באמצעות מוטקס**\nכדי לפתור את בעיית תנאי המירוץ, יש להגן על הקטע הקריטי (הפעולה `shared_counter++`) באמצעות מנגנון סנכרון, כגון מוטקס (mutex). מוטקס מבטיח שבכל רגע נתון רק חוט אחד יוכל להיכנס לקטע הקריטי ולעדכן את המשתנה המשותף. יש לאתחל את המוטקס לפני יצירת החוטים ולשחרר אותו בסיום.\n\nלהלן קטע הקוד המתוקן עבור הפונקציה `increment_counter`:\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n\nint shared_counter = 0; // משתנה גלובלי משותף\npthread_mutex_t counter_mutex; // מוטקס להגנה על המונה\n\nvoid *increment_counter_safe(void *arg) {\n    for (int i = 0; i < 100000; i++) {\n        pthread_mutex_lock(&counter_mutex); // נעל את המוטקס לפני כניסה לקטע הקריטי\n        shared_counter++;\n        pthread_mutex_unlock(&counter_mutex); // שחרר את המוטקס לאחר היציאה מהקטע הקריטי\n    }\n    return NULL;\n}\n\n// הערה: בקוד הראשי (main), יש לאתחל ולשחרר את המוטקס:\n// int main() {\n//     pthread_mutex_init(&counter_mutex, NULL);\n//     // קוד ליצירת חוטים והפעלת increment_counter_safe\n//     // לדוגמה:\n//     // pthread_t tid1, tid2;\n//     // pthread_create(&tid1, NULL, increment_counter_safe, NULL);\n//     // pthread_create(&tid2, NULL, increment_counter_safe, NULL);\n//     // pthread_join(tid1, NULL);\n//     // pthread_join(tid2, NULL);\n//     // printf(\"Final counter value: %d\\n\", shared_counter); // אמור להיות 200000\n//     pthread_mutex_destroy(&counter_mutex);\n//     return 0;\n// }\n```", "difficulty_estimation": "Easy"}, "_source_file": "0174__Synchronization__Open__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:50:20", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Race Condition", "Mutex"], "content": {"text": "נתון קטע הקוד הבא ב-C שבו שני תהליכונים (threads) מנסים לעדכן משתנה גלובלי משותף. המשתנה `counter` מאותחל ל-0. כל תהליכון מבצע לולאה שבה הוא מגדיל את `counter` 1000 פעמים.\n\n1. מהי התוצאה הצפויה של `counter` בסיום ריצת שני התהליכונים?\n2. האם התוצאה מובטחת? הסבר מדוע או מדוע לא.\n3. כיצד ניתן לתקן את הקוד כדי להבטיח את התוצאה הנכונה באמצעות mutex? יש לכלול את קטע הקוד המתוקן.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0; // Shared global variable\n\nvoid *increment(void *arg) {\n    for (int i = 0; i < 1000; i++) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_create(&tid1, NULL, increment, NULL);\n    pthread_create(&tid2, NULL, increment, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. התוצאה הצפויה של `counter` בסיום ריצת שני התהליכונים היא 2000. כל תהליכון מגדיל את המונה 1000 פעמים, כך ששני תהליכונים יחד אמורים להגדיל אותו 2000 פעמים.\n\n2. התוצאה אינה מובטחת. זוהי דוגמה למצב מרוץ (Race Condition). פעולת `counter++` אינה אטומית, אלא מורכבת משלושה שלבים:\n   א. קריאת הערך הנוכחי של `counter`.\n   ב. הגדלת הערך שנקרא ב-1.\n   ג. כתיבת הערך החדש בחזרה ל-`counter`.\n   כאשר שני תהליכונים מנסים לבצע פעולה זו במקביל, ייתכן ששניהם יקראו את אותו ערך של `counter`, יגדילו אותו בנפרד, ולאחר מכן יכתבו את הערך המוגדל בחזרה. במצב כזה, אחת ההגדלות 'תאבד', והערך הסופי יהיה קטן מ-2000.\n\n3. כדי לתקן את הקוד ולהבטיח את התוצאה הנכונה, יש להשתמש ב-mutex (מנעול הדדי) כדי להגן על הקטע הקריטי (critical section) שבו המשתנה המשותף `counter` משתנה. ה-mutex יבטיח שרק תהליכון אחד יוכל לגשת לקטע הקריטי בכל רגע נתון. הנה הקוד המתוקן:\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0; // Shared global variable\npthread_mutex_t mutex; // Mutex for synchronization\n\nvoid *increment(void *arg) {\n    for (int i = 0; i < 1000; i++) {\n        pthread_mutex_lock(&mutex); // Lock mutex before accessing critical section\n        counter++;\n        pthread_mutex_unlock(&mutex); // Unlock mutex after accessing critical section\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&mutex, NULL); // Initialize the mutex\n\n    pthread_create(&tid1, NULL, increment, NULL);\n    pthread_create(&tid2, NULL, increment, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    pthread_mutex_destroy(&mutex); // Destroy the mutex\n\n    return 0;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0175__Synchronization__Open__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:50:32", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Race Conditions", "Mutexes"], "content": {"text": "נתון קטע קוד בשפת C שבו מספר תהליכונים (threads) מנסים לעדכן משתנה גלובלי משותף (counter) ללא מנגנוני סנכרון. ענה על השאלות הבאות:", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0;\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < 100000; i++) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tids[2];\n\n    pthread_create(&tids[0], NULL, increment_counter, NULL);\n    pthread_create(&tids[1], NULL, increment_counter, NULL);\n\n    pthread_join(tids[0], NULL);\n    pthread_join(tids[1], NULL);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}"}, "sub_questions": [{"id": "10.1", "text": "מהי הבעיה בקטע הקוד הנתון? הסבר מדוע היא מתרחשת.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "מהו הערך הסופי הצפוי של `counter` אם הקוד היה רץ כהלכה? מהי הפלט הטיפוסי בפועל, ומדוע הוא עשוי להשתנות?", "code_snippet": null, "options": null}, {"id": "10.3", "text": "שנה את קטע הקוד הנתון כך שיסנכרן נכונה את הגישה למשתנה `counter` באמצעות mutexים של POSIX, ויבטיח את הערך הסופי הנכון. הצג את הקוד המתוקן.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: הבעיה בקטע הקוד היא תנאי מרוץ (Race Condition). מספר תהליכונים ניגשים למשתנה המשותף `counter` ומנסים לעדכן אותו בו זמנית. הפעולה `counter++` אינה אטומית; היא מורכבת מכמה פעולות מכונה: קריאת הערך הנוכחי של `counter` מהזיכרון, הגדלתו באחד, וכתיבת הערך החדש בחזרה לזיכרון. כאשר מספר תהליכונים מבצעים פעולות אלו במקביל, ייתכן שתהליכון אחד יקרא את הערך, יבוצע מיתוג הקשר (context switch) לתהליכון אחר שיקרא ויעדכן את אותו ערך, ואז התהליכון הראשון ימשיך ויכתוב את הערך הישן + 1 בחזרה, ובכך ידרוס את העדכון של התהליכון השני. זה מוביל לאיבוד עדכונים.\n\n10.2: הערך הסופי הצפוי של `counter` אם הקוד היה רץ כהלכה הוא 200,000. כל אחד משני התהליכונים מבצע 100,000 הגדלות, ולכן סך ההגדלות אמור להיות 2 * 100,000. הפלט הטיפוסי בפועל יהיה ערך נמוך מ-200,000, למשל 120,000, 150,000, או כל ערך אחר בטווח שבין 0 ל-200,000 (כולל). הערך עשוי להשתנות בין הרצות שונות ואף על אותה מכונה, מכיוון שתזמון התהליכונים אינו דטרמיניסטי, ומספר העדכונים שאבדו תלוי בסדר ובזמני המיתוגים בין התהליכונים.\n\n10.3: כדי לסנכרן נכונה את הגישה למשתנה `counter`, יש להשתמש ב-mutex. ה-mutex מבטיח שרק תהליכון אחד יוכל להיכנס לקטע הקריטי (הגדלת המונה) בכל רגע נתון. יש לאתחל את ה-mutex לפני יצירת התהליכונים ולשחרר אותו בסיום. הנה הקוד המתוקן:\n```c\n#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0;\npthread_mutex_t mutex; // Declare a mutex\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < 100000; i++) {\n        pthread_mutex_lock(&mutex); // Acquire the mutex\n        counter++;\n        pthread_mutex_unlock(&mutex); // Release the mutex\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tids[2];\n\n    pthread_mutex_init(&mutex, NULL); // Initialize the mutex\n\n    pthread_create(&tids[0], NULL, increment_counter, NULL);\n    pthread_create(&tids[1], NULL, increment_counter, NULL);\n\n    pthread_join(tids[0], NULL);\n    pthread_join(tids[1], NULL);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    pthread_mutex_destroy(&mutex); // Destroy the mutex\n\n    return 0;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0176__Synchronization__Open__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:50:54", "_subject": "Concurrency"}, {"id": 7, "type": "Open", "topic": ["Synchronization", "Race Conditions", "Semaphores", "Mutexes"], "content": {"text": "נתונים שני חוטים, `incrementer` ו-`decrementer`, אשר ניגשים למשתנה גלובלי משותף `counter`. החוט `incrementer` מגדיל את `counter` ב-`N` פעמים, והחוט `decrementer` מקטין את `counter` ב-`N` פעמים.\nהציגו את קוד המקור עבור שני החוטים ואת פונקציית `main` המפעילה אותם (ללא סנכרון). הסבירו מדוע קיים מצב מרוץ (race condition) בקוד זה ומה יכול להיות הערך הסופי השגוי של `counter`.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\n#define N 1000000\n\nint counter = 0;\n\nvoid* incrementer(void* arg) {\n    for (int i = 0; i < N; i++) {\n        counter++;\n    }\n    return NULL;\n}\n\nvoid* decrementer(void* arg) {\n    for (int i = 0; i < N; i++) {\n        counter--;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_create(&tid1, NULL, incrementer, NULL);\n    pthread_create(&tid2, NULL, decrementer, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "עדכנו את הקוד שהוצג בסעיף הקודם באמצעות סמפורים (semaphores) או mutexים כך שהערך הסופי של `counter` יהיה תמיד 0. הציגו את הקוד המעודכן והסבירו את השינויים.", "code_snippet": null, "options": null}], "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסבר למצב מרוץ (Race Condition):\nפעולות הגידול (`counter++`) וההקטנה (`counter--`) אינן אטומיות. כל אחת מהן מורכבת בדרך כלל ממספר הוראות מעבד:\n1. טעינת הערך הנוכחי של `counter` מזיכרון לתוך רגיסטר.\n2. ביצוע פעולת הגידול/הקטנה על הרגיסטר.\n3. שמירת הערך המעודכן מהרגיסטר בחזרה לזיכרון ב-`counter`.\n\nמצב מרוץ מתרחש כאשר שני החוטים מנסים לבצע פעולות אלו בו-זמנית, והגישה לזיכרון משתלבת ביניהן באופן לא צפוי. לדוגמה, אם `counter` שווה 0:\n* חוט `incrementer` טוען את `0` לרגיסטר שלו.\n* מתבצע מיתוג הקשר (context switch) לחוט `decrementer`.\n* חוט `decrementer` טוען גם הוא את `0` לרגיסטר שלו.\n* חוט `decrementer` מקטין את הרגיסטר שלו ל`-1` ושומר את `-1` בחזרה ל-`counter`. כעת `counter` שווה `-1`.\n* מתבצע מיתוג הקשר בחזרה לחוט `incrementer`.\n* חוט `incrementer` מגדיל את הרגיסטר שלו ל-`1` (זוכרים, הוא התחיל מ-`0`!).\n* חוט `incrementer` שומר את `1` בחזרה ל-`counter`. כעת `counter` שווה `1`.\n\nבמקרה זה, למרות שבוצעו פעולת גידול אחת ופעולת הקטנה אחת, הערך הסופי אינו `0` אלא `1`. באופן דומה, הערך הסופי יכול להיות `-1`. מכיוון שזה קורה `N` פעמים, הערך הסופי של `counter` יכול להיות כל מספר בין `-N` ל-`N` (כולל), ולא בהכרח `0`.\n\nפתרון באמצעות סמפור (Sub-question 7.1):\nכדי למנוע את מצב המרוץ ולהבטיח ש-`counter` יהיה `0` בסיום, יש להגן על האזור הקריטי (הפעולות `counter++` ו-`counter--`) באמצעות מנגנון סנכרון כמו סמפור בינארי (המשמש כמו mutex). הסמפור יבטיח שרק חוט אחד יוכל לגשת לאזור הקריטי בכל רגע נתון.\n\nקוד מעודכן:\n```c\n#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h> // נדרש עבור סמפורים\n\n#define N 1000000\n\nint counter = 0;\nsem_t mutex; // הכרזת סמפור\n\nvoid* incrementer(void* arg) {\n    for (int i = 0; i < N; i++) {\n        sem_wait(&mutex); // נכנס לאזור הקריטי\n        counter++;\n        sem_post(&mutex); // יוצא מהאזור הקריטי\n    }\n    return NULL;\n}\n\nvoid* decrementer(void* arg) {\n    for (int i = 0; i < N; i++) {\n        sem_wait(&mutex); // נכנס לאזור הקריטי\n        counter--;\n        sem_post(&mutex); // יוצא מהאזור הקריטי\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n    sem_init(&mutex, 0, 1); // אתחול סמפור בינארי לערך 1 (פתוח)\n\n    pthread_create(&tid1, NULL, incrementer, NULL);\n    pthread_create(&tid2, NULL, decrementer, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    sem_destroy(&mutex); // שחרור משאבי הסמפור\n    return 0;\n}\n```\n\nהסבר השינויים:\n1. **הכרזת סמפור:** הוספנו משתנה מסוג `sem_t` בשם `mutex` גלובלי.\n2. **אתחול סמפור:** בפונקציית `main`, קראנו ל-`sem_init(&mutex, 0, 1)` כדי לאתחל את הסמפור. הפרמטר `0` מציין שהסמפור ישמש בין חוטים באותו תהליך, והפרמטר `1` מאתחל אותו כסמפור בינארי (mutex) זמין.\n3. **כניסה לאזור קריטי:** לפני כל גישה ל-`counter` (בתוך הלולאות של `incrementer` ו-`decrementer`), קראנו ל-`sem_wait(&mutex)`. קריאה זו חוסמת את החוט אם הסמפור אינו זמין, ומאפשרת לו להמשיך רק כאשר הסמפור הופך זמין (ואז מקטינה את ערכו).\n4. **יציאה מאזור קריטי:** לאחר סיום הפעולה על `counter`, קראנו ל-`sem_post(&mutex)`. קריאה זו משחררת את הסמפור ומאפשרת לחוט אחר (אם יש כזה שממתין) להיכנס לאזור הקריטי.\n5. **שחרור משאבי סמפור:** בסיום `main`, קראנו ל-`sem_destroy(&mutex)` כדי לשחרר את המשאבים שהוקצו לסמפור.\n\nשינויים אלו מבטיחים בלעדיות הדדית (mutual exclusion) על הגישה למשתנה `counter`, ובכך מונעים את מצב המרוץ ומבטיחים שהערך הסופי של `counter` יהיה תמיד `0`."}, "difficulty_estimation": "Medium", "_source_file": "0177__Synchronization__Open__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:51:18", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Synchronization", "Race Conditions", "Mutexes"], "content": {"text": "נתונה תוכנית C המשתמשת במספר חוטים (threads) כדי להגדיל מונה גלובלי משותף. קטע הקוד הבא מציג את פונקציית החוט (thread function) ואת המונה הגלובלי. ענו על השאלות הבאות:", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <stdlib.h> // For exit\n\nint shared_counter = 0;\n\nvoid* thread_func(void* arg) {\n    int i;\n    for (i = 0; i < 100000; i++) {\n        shared_counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[5];\n    int i;\n\n    for (i = 0; i < 5; i++) {\n        pthread_create(&threads[i], NULL, thread_func, NULL);\n    }\n\n    for (i = 0; i < 5; i++) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", shared_counter);\n\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "א. מהי הבעיה העיקרית בקוד זה בהקשר של סנכרון? הסבירו מדוע הבעיה מתרחשת וכיצד היא יכולה להשפיע על הפלט הסופי של המונה.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "ב. כתבו מחדש את פונקציית ה-`thread_func` ואת קטע הקוד ב-`main` שנדרש לאתחול ולשחרור משאבים, כך שהמונה המשותף יעודכן באופן בטוח ונכון באמצעות מנעול הדדי (mutex). הציגו את הקוד המתוקן במלואו.", "code_snippet": null, "options": null}], "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. הבעיה העיקרית בקוד זה היא תנאי מירוץ (race condition). מספר חוטים מנסים לגשת ולשנות את המשתנה הגלובלי `shared_counter` בו-זמנית ללא מנגנון סנכרון מתאים. פעולת הגידול `shared_counter++` אינה פעולה אטומית. היא מורכבת בדרך כלל משלוש פעולות בסיסיות:\n1.  קריאת הערך הנוכחי של `shared_counter` לתוך אוגר.\n2.  הגדלת הערך באוגר באחד.\n3.  כתיבת הערך החדש מהאוגר בחזרה ל-`shared_counter`.\n\nאם שני חוטים (או יותר) מבצעים פעולות אלה במקביל, ייתכן ששניהם יקראו את אותו ערך ישן של `shared_counter`, יגדילו אותו באחד, ויכתבו בחזרה את אותו ערך (מוגדל באחד) - במקום שכל אחד מהם יגדיל אותו בנפרד. לדוגמה, אם `shared_counter` הוא 10, חוט A קורא 10, חוט B קורא 10. חוט A מגדיל ל-11 וכותב 11. חוט B מגדיל ל-11 וכותב 11. התוצאה הסופית היא 11 במקום 12. כתוצאה מכך, הערך הסופי של `shared_counter` יהיה בדרך כלל נמוך מהערך הצפוי (5 חוטים * 100,000 איטרציות = 500,000).\n\nב. כדי לפתור את בעיית תנאי המירוץ, נשתמש במנעול הדדי (mutex) כדי להגן על הקטע הקריטי, שהוא פעולת הגידול של `shared_counter`. יש לאתחל את המוטקס לפני יצירת החוטים ולשחרר אותו לאחר סיום עבודתם.\n\n**הקוד המתוקן:**\n```c\n#include <stdio.h>\n#include <pthread.h>\n#include <stdlib.h> // For exit\n\nint shared_counter = 0;\npthread_mutex_t counter_mutex; // הצהרה על המוטקס\n\nvoid* thread_func(void* arg) {\n    int i;\n    for (i = 0; i < 100000; i++) {\n        pthread_mutex_lock(&counter_mutex);   // נעילת המוטקס לפני כניסה לקטע הקריטי\n        shared_counter++;                     // הקטע הקריטי\n        pthread_mutex_unlock(&counter_mutex); // שחרור המוטקס לאחר היציאה מהקטע הקריטי\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[5];\n    int i;\n\n    pthread_mutex_init(&counter_mutex, NULL); // אתחול המוטקס\n\n    for (i = 0; i < 5; i++) {\n        pthread_create(&threads[i], NULL, thread_func, NULL);\n    }\n\n    for (i = 0; i < 5; i++) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", shared_counter); // הפלט הצפוי כעת הוא 500000\n\n    pthread_mutex_destroy(&counter_mutex); // שחרור המוטקס\n\n    return 0;\n}\n```\n\n**הסבר:**\nהשימוש ב-`pthread_mutex_lock` וב-`pthread_mutex_unlock` מבטיח שרק חוט אחד יכול להיכנס לקטע הקריטי (שבו `shared_counter` מוגדל) בכל רגע נתון. כאשר חוט אחד נכנס לקטע הקריטי ונועל את המוטקס, כל חוט אחר שינסה להיכנס יחסם (ימתין) עד שהחוט הראשון ישחרר את המוטקס. זה מונע את תנאי המירוץ ומבטיח שפעולת הגידול של המונה תתבצע באופן אטומי מבחינה לוגית, מה שמוביל לערך סופי נכון של `shared_counter`."}, "difficulty_estimation": "Medium", "_source_file": "0178__Synchronization__Open__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:51:38", "_subject": "Concurrency"}, {"id": 7, "type": "Open", "topic": ["Synchronization", "Race Conditions", "Mutexes", "Semaphores"], "content": {"text": "נתון קטע קוד המשתמש בשני חוטים (threads) המבצעים פעולות על משאבים משותפים. כל חוט מטרתו להגדיל מונה גלובלי (shared_counter) ולרשום את ה-ID שלו במערך לוג (log_of_updates) במיקום המתאים לערך המונה *לפני* ההגדלה.\n\nקראו את הקוד בעיון וענו על השאלות הבאות:", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h>\n\n#define NUM_ITERATIONS 50000\n#define NUM_THREADS 2\n#define LOG_ARRAY_SIZE (NUM_ITERATIONS * NUM_THREADS)\n\nint shared_counter = 0;\nint log_of_updates[LOG_ARRAY_SIZE]; // To log which thread updated at which logical step\n\n// Thread IDs for demonstration (0 or 1)\nint thread_ids[NUM_THREADS] = {0, 1};\n\nvoid* thread_routine(void* arg) {\n    int thread_id = *(int*)arg;\n    for (int i = 0; i < NUM_ITERATIONS; ++i) {\n        // Critical section operations\n        int current_index = shared_counter; // Read shared_counter\n        shared_counter++;                   // Increment shared_counter\n        if (current_index < LOG_ARRAY_SIZE) {\n            log_of_updates[current_index] = thread_id; // Write to log_of_updates\n        }\n    }\n    return NULL;\n}\n\n/*\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    printf(\"Starting threads...\n\");\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_routine, &thread_ids[i]);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final shared_counter: %d (Expected: %d)\n\", shared_counter, NUM_ITERATIONS * NUM_THREADS);\n\n    printf(\"First 10 log entries: \");\n    for (int i = 0; i < 10 && i < LOG_ARRAY_SIZE; ++i) {\n        printf(\"%d \", log_of_updates[i]);\n    }\n    printf(\"\\n\");\n    \n    printf(\"Last 10 log entries: \");\n    for (int i = LOG_ARRAY_SIZE - 10; i < LOG_ARRAY_SIZE; ++i) {\n        if (i >= 0) printf(\"%d \", log_of_updates[i]);\n    }\n    printf(\"\\n\");\n\n    return 0;\n}\n*/", "options": null}, "sub_questions": [{"id": "7.1", "text": "הסבירו מדוע קטע הקוד הזה עלול להוביל לתוצאות שגויות. תארו דוגמה קונקרטית לתרחיש ריצה (interleaving) שיגרום לבעיה בערך הסופי של shared_counter ו/או בתוכן המערך log_of_updates.", "code_snippet": null, "options": null}, {"id": "7.2", "text": "כתבו גרסה מתוקנת של הפונקציה `thread_routine` המשתמשת ב-mutex (מנעול) כדי למנוע את הבעיות שתוארו בסעיף הקודם. ציינו היכן יש להצהיר ולאתחל את המנעול.", "code_snippet": null, "options": null}, {"id": "7.3", "text": "כתבו גרסה מתוקנת נוספת של הפונקציה `thread_routine` המשתמשת בסמפור (semaphore) בינארי (או mutex כפי שמומש לעיתים באמצעות סמפור) כדי לפתור את אותן הבעיות. ציינו היכן יש להצהיר ולאתחל את הסמפור.", "code_snippet": null, "options": null}], "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1. **הסבר הבעיה:**\nקטע הקוד סובל מ-Race Condition (מצב מרוץ) עקב גישה לא מסונכרנת למשתנים הגלובליים המשותפים `shared_counter` ו-`log_of_updates` על ידי מספר חוטים במקביל. הפעולות `int current_index = shared_counter; shared_counter++; log_of_updates[current_index] = thread_id;` אינן אטומיות. כלומר, מערכת ההפעלה יכולה להחליף הקשר (context switch) בין חוטים בכל נקודה בביצוע של שלוש הפעולות הללו.\n\n**דוגמה לתרחיש ריצה שיגרום לבעיה:**\nנניח ש-`shared_counter` שווה ל-5 בתחילת האיטרציה.\n1.  **חוט 0 מתוזמן:**\n    *   קורא: `current_index = shared_counter;` (כלומר `current_index = 5;`) \n    *   **החלפת הקשר** לחוט 1.\n2.  **חוט 1 מתוזמן:**\n    *   קורא: `current_index = shared_counter;` (כלומר `current_index = 5;` - שימו לב ש-`shared_counter` עדיין 5)\n    *   מגדיל: `shared_counter++;` (כלומר `shared_counter` הופך ל-6)\n    *   כותב ללוג: `log_of_updates[5] = 1;`\n    *   **החלפת הקשר** לחוט 0.\n3.  **חוט 0 ממשיך:**\n    *   מגדיל: `shared_counter++;` (כלומר `shared_counter` הופך ל-6. **זו טעות!** המונה היה אמור להיות 7 אם שני החוטים היו מבצעים את ההגדלה באופן אטומי)\n    *   כותב ללוג: `log_of_updates[5] = 0;` (**זו טעות!** חוט 0 דרס את הערך שחוט 1 כתב במיקום 5, ובפועל חוט 1 לא \"נרשם\" בלוג כלל במיקום זה, למרות שביצע פעולה). \n\n**השלכות:**\n*   **ערך סופי שגוי של `shared_counter`**: המונה הסופי יהיה נמוך מהצפוי (לדוגמה, במקום 100,000 עבור 2 חוטים ו-50,000 איטרציות לכל אחד, הוא יהיה פחות מכך). במקרה הדוגמה לעיל, במקום 7 הוא 6. אובדן עדכונים.\n*   **תוכן שגוי במערך `log_of_updates`**: חלק מהעדכונים יידרסו על ידי חוטים אחרים, ועלולות להיות כניסות חסרות או שגויות. במקרה הדוגמה לעיל, `log_of_updates[5]` אמור היה להכיל שני עדכונים (אחד מ-0 ואחד מ-1) אך מכיל רק את האחרון שנדרס.\n\n7.2. **פתרון באמצעות Mutex:**\nכדי למנוע את מצב המרוץ, יש להגן על ה-Critical Section (האזור הקריטי) באמצעות Mutex. ה-Critical Section במקרה זה כולל את הקריאה ל-`shared_counter`, ההגדלה שלו, והכתיבה ל-`log_of_updates`.\n\n**הצהרה ואיפוס המנעול:**\nיש להצהיר על משתנה Mutex גלובלי ולאתחל אותו פעם אחת לפני יצירת החוטים (לרוב בפונקציית `main`).\n```c\npthread_mutex_t counter_mutex; // הצהרה גלובלית\n\n// בתוך פונקציית main, לפני יצירת החוטים:\npthread_mutex_init(&counter_mutex, NULL);\n```\n\n**גרסה מתוקנת של `thread_routine`:**\n```c\nvoid* thread_routine_mutex(void* arg) {\n    int thread_id = *(int*)arg;\n    for (int i = 0; i < NUM_ITERATIONS; ++i) {\n        pthread_mutex_lock(&counter_mutex); // נעל את המנעול לפני הכניסה לאזור הקריטי\n\n        // Critical section operations\n        int current_index = shared_counter;\n        shared_counter++;\n        if (current_index < LOG_ARRAY_SIZE) {\n            log_of_updates[current_index] = thread_id;\n        }\n\n        pthread_mutex_unlock(&counter_mutex); // שחרר את המנעול לאחר היציאה מהאזור הקריטי\n    }\n    return NULL;\n}\n```\n\n7.3. **פתרון באמצעות Semaphore בינארי:**\nניתן להשתמש בסמפור בינארי באופן דומה ל-Mutex כדי להגן על אזור קריטי. סמפור בינארי מאותחל לערך 1, וכל קריאה ל-`sem_wait` מקטינה אותו ב-1 (וחוסמת אם הוא 0), וכל קריאה ל-`sem_post` מגדילה אותו ב-1.\n\n**הצהרה ואיפוס הסמפור:**\nיש להצהיר על משתנה Semaphore גלובלי ולאתחל אותו פעם אחת לפני יצירת החוטים (לרוב בפונקציית `main`).\n```c\nsem_t counter_sem; // הצהרה גלובלית\n\n// בתוך פונקציית main, לפני יצירת החוטים:\n// sem_init(sem, pshared, value)\n// pshared = 0: הסמפור משותף לחוטים בתוך אותו תהליך.\n// value = 1: ערך אתחול 1 הופך אותו לסמפור בינארי (כמו mutex).\nsem_init(&counter_sem, 0, 1);\n```\n\n**גרסה מתוקנת של `thread_routine`:**\n```c\nvoid* thread_routine_semaphore(void* arg) {\n    int thread_id = *(int*)arg;\n    for (int i = 0; i < NUM_ITERATIONS; ++i) {\n        sem_wait(&counter_sem); // המתן (acquire) לסמפור לפני הכניסה לאזור הקריטי\n\n        // Critical section operations\n        int current_index = shared_counter;\n        shared_counter++;\n        if (current_index < LOG_ARRAY_SIZE) {\n            log_of_updates[current_index] = thread_id;\n        }\n\n        sem_post(&counter_sem); // שחרר (release) את הסמפור לאחר היציאה מהאזור הקריטי\n    }\n    return NULL;\n}\n```"}, "difficulty_estimation": "Medium", "_source_file": "0179__Synchronization__Open__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:52:07", "_subject": "Concurrency"}, {"id": 7, "type": "Open", "topic": ["Synchronization", "Reader-Writer Problem", "Pthreads"], "content": {"text": "נתונה מערכת המכילה משאב משותף (לדוגמה, מבנה נתונים) אליו ניגשים מספר תהליכונים (threads) משני סוגים: כותבים (Writers) וקוראים (Readers). תהליכונים כותבים משנים את המשאב, ותהליכונים קוראים קוראים אותו בלבד. יש לממש מנגנון סנכרון עבור גישה למשאב המשותף כך שיעמוד בדרישות הבאות:\n1. רק תהליכון כותב אחד יכול לגשת למשאב המשותף בכל רגע נתון.\n2. מספר תהליכונים קוראים יכולים לגשת למשאב המשותף בו זמנית.\n3. אף תהליכון כותב לא יכול לגשת למשאב כאשר תהליכון קורא כלשהו ניגש אליו, ולהיפך (אין גישה בו זמנית של קוראים וכותבים).\n4. לתהליכונים כותבים יש עדיפות: אם תהליכון כותב ממתין לגישה למשאב, אף תהליכון קורא חדש לא יוכל להתחיל לקרוא עד שהכותב יסיים את פעולתו וישחרר את המשאב.\n\nיש להציג את קטעי הקוד הרלוונטיים עבור תהליכון כותב ותהליכון קורא, תוך שימוש במנגנוני סנכרון של POSIX (mutexes ו-condition variables), ולהסביר את פעולת המנגנון.", "code_snippet": null, "options": null}, "sub_questions": null, "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון בעיית קוראים-כותבים עם עדיפות לכותבים באמצעות mutexes ו-condition variables של POSIX:\n\nמשתנים גלובליים לתיאום:\n```c\npthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;\npthread_cond_t reader_cond = PTHREAD_COND_INITIALIZER;\npthread_cond_t writer_cond = PTHREAD_COND_INITIALIZER;\n\nint readers_reading = 0;   // מספר הקוראים הפעילים כרגע\nint writers_writing = 0;   // 1 אם כותב פעיל, 0 אחרת\nint writers_waiting = 0;   // מספר הכותבים הממתינים לגישה\n```\n\nפונקציות כניסה ויציאה עבור תהליכון כותב:\n```c\nvoid writer_entry() {\n    pthread_mutex_lock(&mutex);\n    writers_waiting++;\n    while (readers_reading > 0 || writers_writing > 0) {\n        pthread_cond_wait(&writer_cond, &mutex);\n    }\n    writers_waiting--;\n    writers_writing = 1;\n    pthread_mutex_unlock(&mutex);\n}\n\nvoid writer_exit() {\n    pthread_mutex_lock(&mutex);\n    writers_writing = 0;\n    if (writers_waiting > 0) {\n        pthread_cond_signal(&writer_cond); // מעיר כותב ממתין אחד\n    } else {\n        pthread_cond_broadcast(&reader_cond); // מעיר את כל הקוראים הממתינים\n    }\n    pthread_mutex_unlock(&mutex);\n}\n```\n\nפונקציות כניסה ויציאה עבור תהליכון קורא:\n```c\nvoid reader_entry() {\n    pthread_mutex_lock(&mutex);\n    while (writers_writing > 0 || writers_waiting > 0) {\n        pthread_cond_wait(&reader_cond, &mutex);\n    }\n    readers_reading++;\n    pthread_mutex_unlock(&mutex);\n}\n\nvoid reader_exit() {\n    pthread_mutex_lock(&mutex);\n    readers_reading--;\n    if (readers_reading == 0 && writers_waiting > 0) {\n        pthread_cond_signal(&writer_cond); // אם אין יותר קוראים וכותבים ממתינים, מעיר כותב אחד\n    }\n    pthread_mutex_unlock(&mutex);\n}\n```\n\nהסבר:\n*   **`mutex`**: מגן על הגישה למשתנים המשותפים (`readers_reading`, `writers_writing`, `writers_waiting`) כדי למנוע תנאי מירוץ.\n*   **`readers_reading`**: מונה את מספר הקוראים שנמצאים כרגע בקטע הקריטי. כאשר ערכו אפס, אין קוראים פעילים.\n*   **`writers_writing`**: דגל (0 או 1) המציין אם כותב כלשהו נמצא כרגע בקטע הקריטי. רק כותב אחד יכול להיות פעיל בכל רגע.\n*   **`writers_waiting`**: מונה את מספר הכותבים שממתינים להיכנס לקטע הקריטי. משמש ליישום עדיפות לכותבים.\n\n**היגיון עדיפות לכותבים:**\n1.  **כניסת כותב (`writer_entry`)**: כותב מעלה את `writers_waiting` וממתין אם יש קוראים פעילים (`readers_reading > 0`) או כותב אחר פעיל (`writers_writing > 0`). לאחר מכן, הוא מוריד את `writers_waiting` ומסמן את עצמו ככותב פעיל.\n2.  **כניסת קורא (`reader_entry`)**: קורא ממתין אם יש כותב פעיל (`writers_writing > 0`) או אם יש כותבים ממתינים (`writers_waiting > 0`). תנאי `writers_waiting > 0` הוא המפתח לעדיפות לכותבים – קוראים חדשים לא יורשו להיכנס אם יש כותב שממתין. אם אין כותבים פעילים או ממתינים, הקורא מעלה את `readers_reading` ונכנס לקטע הקריטי.\n3.  **יציאת כותב (`writer_exit`)**: כותב מסיים ומאפס את `writers_writing`. אם יש כותבים ממתינים (`writers_waiting > 0`), הוא מעיר רק אחד מהם באמצעות `pthread_cond_signal(&writer_cond)` כדי לאפשר לכותב הבא להיכנס (שכן רק כותב אחד יכול להיות פעיל). רק אם אין כותבים ממתינים, הוא מעיר את כל הקוראים הממתינים באמצעות `pthread_cond_broadcast(&reader_cond)`.\n4.  **יציאת קורא (`reader_exit`)**: קורא מסיים ומוריד את `readers_reading`. אם הוא היה הקורא האחרון (`readers_reading == 0`) ויש כותבים ממתינים (`writers_waiting > 0`), הוא מעיר כותב אחד באמצעות `pthread_cond_signal(&writer_cond)` כדי לאפשר לכותב להיכנס כעת כשהמשאב פנוי מקוראים."}, "difficulty_estimation": "Medium", "_source_file": "0180__Synchronization__Open__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:52:32", "_subject": "Concurrency"}, {"id": 7, "type": "Open", "topic": ["Synchronization", "Race Condition", "Mutex", "Threads"], "content": {"text": "נתון קטע הקוד הבא המדמה גישה למשתנה גלובלי משותף `balance` על ידי מספר חוטים. חוטים מסוג `deposit_thread` מגדילים את `balance` וחוטים מסוג `withdraw_thread` מקטינים אותו. כל חוט מבצע את הפעולה מספר רב של פעמים. בתום ריצת התוכנית, מצפים שהערך הסופי של `balance` יהיה 0.\n\n1. מהי הבעיה המרכזית בקוד זה בהקשר של מערכות הפעלה מקביליות? הסבר מדוע היא מתרחשת וכיצד היא יכולה להוביל לתוצאה שגויה.\n2. הצע פתרון לבעיה זו באמצעות סמפורים או מנעולים (mutexes) ב-C. הצג את קטע הקוד המתוקן עבור הפונקציות `deposit_thread` ו-`withdraw_thread` ואת האתחול והסיום הנדרשים בפונקציית `main`.\n3. הסבר כיצד הפתרון שלך מונע את הבעיה ומבטיח נכונות.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n\nint balance = 0; // Shared global variable\n\nvoid* deposit_thread(void* arg) {\n    int i;\n    for (i = 0; i < 100000; i++) {\n        balance++;\n    }\n    return NULL;\n}\n\nvoid* withdraw_thread(void* arg) {\n    int i;\n    for (i = 0; i < 100000; i++) {\n        balance--;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2, tid3, tid4;\n\n    pthread_create(&tid1, NULL, deposit_thread, NULL);\n    pthread_create(&tid2, NULL, deposit_thread, NULL);\n    pthread_create(&tid3, NULL, withdraw_thread, NULL);\n    pthread_create(&tid4, NULL, withdraw_thread, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n    pthread_join(tid3, NULL);\n    pthread_join(tid4, NULL);\n\n    printf(\"Final balance: %d\\n\", balance);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "### הסבר לבעיה (שאלה 1):\nהבעיה המרכזית בקוד היא תנאי מרוץ (Race Condition) בגישה למשתנה הגלובלי המשותף `balance`. הפעולות `balance++` ו-`balance--` אינן אטומיות. הן מורכבות ממספר פעולות מכונה ברמה נמוכה יותר (לדוגמה, עבור `balance++`:\n1. קריאת הערך של `balance` מהזיכרון לתוך רגיסטר.\n2. הגדלת הערך ברגיסטר.\n3. כתיבת הערך המעודכן מהרגיסטר בחזרה לזיכרון).\nכאשר מספר חוטים מנסים לבצע פעולות אלו בו-זמנית, ייתכן שחוט אחד יקרא את הערך של `balance`, יבוצע מיתוג הקשר (context switch) לחוט אחר שישנה את `balance`, וכאשר החוט הראשון יחזור לרוץ הוא יכתוב בחזרה ערך שגוי (מבוסס על הערך הישן שקרא לפני שהחוט השני שינה אותו). כתוצאה מכך, חלק מהעדכונים עלולים 'לאבד' (lost updates) והערך הסופי של `balance` יהיה שגוי ולא צפוי, ובדרך כלל לא יהיה 0 כפי שמצופה (שני חוטי הפקדה ושני חוטי משיכה, כל אחד 100,000 פעמים, אמורים לבטל זה את זה).\n\n### קוד מתוקן באמצעות מנעול (mutex) (שאלה 2):\n```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n\npthread_mutex_t balance_mutex; // Mutex for synchronization\nint balance = 0; // Shared global variable\n\nvoid* deposit_thread_sync(void* arg) {\n    int i;\n    for (i = 0; i < 100000; i++) {\n        pthread_mutex_lock(&balance_mutex); // Acquire lock\n        balance++;\n        pthread_mutex_unlock(&balance_mutex); // Release lock\n    }\n    return NULL;\n}\n\nvoid* withdraw_thread_sync(void* arg) {\n    int i;\n    for (i = 0; i < 100000; i++) {\n        pthread_mutex_lock(&balance_mutex); // Acquire lock\n        balance--;\n        pthread_mutex_unlock(&balance_mutex); // Release lock\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2, tid3, tid4;\n\n    pthread_mutex_init(&balance_mutex, NULL); // Initialize mutex\n\n    pthread_create(&tid1, NULL, deposit_thread_sync, NULL);\n    pthread_create(&tid2, NULL, deposit_thread_sync, NULL);\n    pthread_create(&tid3, NULL, withdraw_thread_sync, NULL);\n    pthread_create(&tid4, NULL, withdraw_thread_sync, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n    pthread_join(tid3, NULL);\n    pthread_join(tid4, NULL);\n\n    printf(\"Final balance with sync: %d\\n\", balance);\n\n    pthread_mutex_destroy(&balance_mutex); // Destroy mutex\n    return 0;\n}\n```\n\n### הסבר לפתרון (שאלה 3):\nהפתרון המוצע הוא שימוש במנעול (mutex). מנעול הוא פרימיטיב סנכרון המבטיח הדרה הדדית (mutual exclusion), כלומר, רק חוט אחד יכול להחזיק במנעול בכל רגע נתון. לפני כל גישה למשתנה המשותף `balance` (בין אם לצורך הגדלה או הקטנה), החוט קורא לפונקציה `pthread_mutex_lock(&balance_mutex)` כדי לנעול את המנעול. אם המנעול כבר נעול על ידי חוט אחר, החוט הנוכחי נחסם וממתין עד שהמנעול ישוחרר. לאחר סיום הפעולה על `balance` (הקטע הקריטי), החוט קורא לפונקציה `pthread_mutex_unlock(&balance_mutex)` כדי לשחרר את המנעול, ובכך מאפשר לחוטים אחרים שחסומים לנסות לרכוש אותו. \n\nבצורה זו, פעולות `balance++` ו-`balance--` הופכות לאטומיות מבחינה לוגית: מרגע שחוט נעל את המנעול ועד ששחרר אותו, אף חוט אחר לא יוכל להיכנס לקטע הקריטי ולשנות את `balance`. זה מונע תנאי מרוץ ומבטיח שכל עדכון ל-`balance` יתבצע באופן מלא וללא הפרעה מחוטים אחרים, ובכך מבטיח שהחישוב הסופי של `balance` יהיה נכון (במקרה זה, 0)."}, "difficulty_estimation": "Medium", "_source_file": "0181__Synchronization__Open__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:53:00", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Semaphores", "Concurrency"], "content": {"text": "במערכת הפעלה נתונה, ישנו משאב משותף הנגיש לשני סוגי תהליכים: קוראים (Readers) וכותבים (Writers). עליכם לממש פתרון סנכרון בשפת C באמצעות סמפורים בלבד המקיים את התנאים הבאים:\n1. מספר הקוראים שיכולים לגשת למשאב בו-זמנית מוגבל לכל היותר ל-5.\n2. כותב יכול לגשת למשאב רק אם אין בו קוראים כלל.\n3. בזמן שכותב ניגש למשאב, אף קורא או כותב אחר לא יכול לגשת אליו (בלעדיות).\n4. מניעת הרעבה של כותבים: ברגע שכותב ממתין בתור, קוראים חדשים לא יורשו להיכנס למשאב עד שהכותב יסיים.", "code_snippet": "sem_t mutex;          // Protects read_count\nsem_t resource;       // Controls access to the resource\nsem_t read_limit;     // Limits number of concurrent readers\nsem_t service_queue;  // Prevents writer starvation\nint read_count = 0;\n\n// Initialize semaphores and implement reader() and writer()", "options": null}, "sub_questions": null, "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון עושה שימוש בארבעה סמפורים:\n1. הסמפור service_queue (אותחל ל-1) משמש כ'שומר סף'. גם קוראים וגם כותבים חייבים לעבור דרכו. אם כותב ממתין עליו, קוראים חדשים ייחסמו, מה שמונע הרעבת כותבים.\n2. הסמפור read_limit (אותחל ל-5) מבטיח שלא יותר מ-5 קוראים ישהו במשאב בו-זמנית.\n3. הסמפור resource (אותחל ל-1) מבטיח בלעדיות לכותב. הקורא הראשון שנכנס נועל אותו, והקורא האחרון שיוצא משחרר אותו.\n4. הסמפור mutex (אותחל ל-1) מגן על המשתנה המשותף read_count.\n\nמימוש ה-Writer:\nsem_wait(&service_queue);\nsem_wait(&resource);\n// Writing...\nsem_post(&resource);\nsem_post(&service_queue);\n\nמימוש ה-Reader:\nsem_wait(&service_queue);\nsem_wait(&read_limit);\nsem_wait(&mutex);\nread_count++;\nif (read_count == 1) sem_wait(&resource);\nsem_post(&mutex);\nsem_post(&service_queue);\n\n// Reading...\n\nsem_wait(&mutex);\nread_count--;\nif (read_count == 0) sem_post(&resource);\nsem_post(&mutex);\nsem_post(&read_limit);"}, "difficulty_estimation": "Medium", "_source_file": "0182__Synchronization__Open__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:56:53", "_subject": "Concurrency"}, {"id": 7, "type": "Open", "topic": ["Synchronization"], "content": {"text": "נתון קטע קוד בשפת C המדמה מצב בו מספר תהליכונים (threads) ניגשים למשתנה גלובלי משותף (מונה) ומבצעים עליו פעולת הגדלה. קטע הקוד הנוכחי אינו משתמש במנגנוני סנכרון כלשהם.\n\nא. הסבר/י מדוע קטע קוד זה עלול לייצר תוצאות לא צפויות או שגויות. תאר/י את הבעיה הספציפית העלולה להתרחש.\nב. הצע/י פתרון לקטע הקוד באמצעות שימוש במנעול (mutex) כדי להבטיח שהמונה יוגדל באופן עקבי ונכון. הצג/י את קטע הקוד המתוקן.\nג. הצע/י פתרון נוסף לקטע הקוד באמצעות שימוש בסמפור בינארי (binary semaphore) כדי להבטיח את עקביות המונה. הצג/י את קטע הקוד המתוקן.\nד. השווה/י בקצרה בין שני הפתרונות שהצעת בסעיפים ב' ו-ג' בהקשר של בעיה זו.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\n#define NUM_THREADS 5\n#define ITERATIONS_PER_THREAD 100000\n\nlong long global_counter = 0;\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < ITERATIONS_PER_THREAD; ++i) {\n        global_counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, increment_counter, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final global_counter value: %lld\\n\", global_counter);\n    printf(\"Expected value: %lld\\n\", (long long)NUM_THREADS * ITERATIONS_PER_THREAD);\n\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. הבעיה בקטע הקוד היא תנאי מרוץ (race condition). פעולת ההגדלה של המונה (`global_counter++`) אינה פעולה אטומית (atomic operation). היא מורכבת למעשה משלוש פעולות ברמת המעבד:\n1. קריאת הערך הנוכחי של `global_counter` לתוך רגיסטר.\n2. הגדלת הערך ברגיסטר.\n3. כתיבת הערך המעודכן מהרגיסטר בחזרה ל`global_counter`.\nכאשר מספר תהליכונים מבצעים פעולה זו במקביל ללא סנכרון, ייתכן שתהליכון אחד יקרא את הערך, ותהליכון אחר יספיק לקרוא את אותו הערך, להגדיל אותו ולכתוב אותו בחזרה, לפני שהתהליכון הראשון יכתוב את הערך המוגדל שלו. כתוצאה מכך, חלק מההגדלות \"יאבדו\", והערך הסופי של `global_counter` יהיה נמוך מהצפוי.\n\nב. פתרון באמצעות מנעול (mutex):\nהמנעול מבטיח שרק תהליכון אחד יוכל להיכנס לקטע הקריטי (critical section) בו מתבצעת פעולת ההגדלה של המונה בכל רגע נתון. תהליכונים אחרים שינסו להיכנס יחסמו עד שהתהליכון המחזיק במנעול ישחרר אותו.\nהשינויים כוללים:\n1. הצהרה על משתנה `pthread_mutex_t`.\n2. אתחול המנעול באמצעות `pthread_mutex_init` לפני יצירת התהליכונים.\n3. קריאה ל`pthread_mutex_lock` לפני הכניסה לקטע הקריטי.\n4. קריאה ל`pthread_mutex_unlock` לאחר היציאה מהקטע הקריטי.\n5. השמדת המנעול באמצעות `pthread_mutex_destroy` בסיום.\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n\n#define NUM_THREADS 5\n#define ITERATIONS_PER_THREAD 100000\n\nlong long global_counter = 0;\npthread_mutex_t counter_mutex; // Mutex declaration\n\nvoid* increment_counter_mutex(void* arg) {\n    for (int i = 0; i < ITERATIONS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&counter_mutex);   // Acquire mutex\n        global_counter++;\n        pthread_mutex_unlock(&counter_mutex); // Release mutex\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    pthread_mutex_init(&counter_mutex, NULL); // Initialize mutex\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, increment_counter_mutex, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final global_counter value (with mutex): %lld\\n\", global_counter);\n    printf(\"Expected value: %lld\\n\", (long long)NUM_THREADS * ITERATIONS_PER_THREAD);\n\n    pthread_mutex_destroy(&counter_mutex); // Destroy mutex\n\n    return 0;\n}\n```\n\nג. פתרון באמצעות סמפור בינארי:\nסמפור בינארי יכול לשמש למטרות הדדית (mutual exclusion) בדומה למנעול. סמפור המאותחל ל-1 מאפשר רק לתהליכון אחד לבצע `sem_wait` בהצלחה, בעוד שאחרים יחסמו. `sem_post` משחרר את הסמפור ומאפשר לתהליכון אחר להיכנס.\nהשינויים כוללים:\n1. הצהרה על משתנה `sem_t`.\n2. אתחול הסמפור לערך 1 באמצעות `sem_init` לפני יצירת התהליכונים. הפרמטר השני 0 מציין שהסמפור משותף רק לתהליכונים בתוך אותו תהליך.\n3. קריאה ל`sem_wait` לפני הכניסה לקטע הקריטי (פעולת P).\n4. קריאה ל`sem_post` לאחר היציאה מהקטע הקריטי (פעולת V).\n5. השמדת הסמפור באמצעות `sem_destroy` בסיום.\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h> // For sem_t\n\n#define NUM_THREADS 5\n#define ITERATIONS_PER_THREAD 100000\n\nlong long global_counter = 0;\nsem_t counter_semaphore; // Semaphore declaration\n\nvoid* increment_counter_semaphore(void* arg) {\n    for (int i = 0; i < ITERATIONS_PER_THREAD; ++i) {\n        sem_wait(&counter_semaphore);   // Acquire semaphore (P operation)\n        global_counter++;\n        sem_post(&counter_semaphore); // Release semaphore (V operation)\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    // Initialize semaphore to 1 (binary semaphore)\n    sem_init(&counter_semaphore, 0, 1);\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, increment_counter_semaphore, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final global_counter value (with semaphore): %lld\\n\", global_counter);\n    printf(\"Expected value: %lld\\n\", (long long)NUM_THREADS * ITERATIONS_PER_THREAD);\n\n    sem_destroy(&counter_semaphore); // Destroy semaphore\n\n    return 0;\n}\n```\n\nד. השוואה בין מנעול לסמפור בינארי:\nעבור בעיה ספציפית זו של הדדית (mutual exclusion) עבור קטע קריטי בודד, הן מנעול והן סמפור בינארי מספקים פתרון נכון ויעיל. בפועל, ברוב מערכות ההפעלה המודרניות, מנעולים ממוטבים במיוחד למטרה זו ונוטים להיות קלים ויעילים יותר לשימוש עבור הדדית בלבד.\n**מנעול (Mutex):**\n*   מיועד ספציפית להדדית.\n*   לרוב, רק התהליכון שרכש את המנעול יכול לשחרר אותו (בעל \"בעלות\").\n*   מנגנוני זיהוי שגיאות מובנים (לדוגמה, ניסיון לשחרר מנעול שלא נרכש).\n*   יכול לתמוך בפרוטוקולי עדיפויות (priority inheritance) למניעת priority inversion.\n**סמפור בינארי (Binary Semaphore):**\n*   כלי כללי יותר, שיכול לשמש גם להדדית וגם לסנכרון מורכב יותר (למשל, סמפורי ספירה לתבנית מפיק-צרכן).\n*   כל תהליכון יכול לבצע `sem_post` גם אם לא הוא ביצע `sem_wait` (אין \"בעלות\"). זה יכול להיות יתרון במצבים מסוימים, אך גם מקור לשגיאות.\n*   במקרה של הדדית פשוטה, מנעול עשוי להיות קצת יותר יעיל או בטוח לשימוש עקב הייעוד הספציפי שלו והתכונות הנוספות שהוזכרו."}, "difficulty_estimation": "Medium", "_source_file": "0183__Synchronization__Open__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:53:26", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Semaphores", "Deadlocks"], "content": {"text": "נתונים שלושה חוטים (Threads) המבצעים לולאה אינסופית. המטרה היא להשתמש בסמפורים כדי לסנכרן ביניהם כך שהפלט יהיה תמיד ברצף ABCABC... (כלומר, A תמיד מודפס לפני B, ו-B תמיד לפני C). לפניכם קטעי הקוד של החוטים:", "code_snippet": "// Thread A\nwhile(1) {\n    sem_wait(&s1);\n    printf(\"A\");\n    sem_post(&s2);\n}\n\n// Thread B\nwhile(1) {\n    sem_wait(&s2);\n    printf(\"B\");\n    sem_post(&s3);\n}\n\n// Thread C\nwhile(1) {\n    sem_wait(&s3);\n    printf(\"C\");\n    sem_post(&s1);\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "מהם ערכי האתחול הנדרשים עבור הסמפורים s1, s2, s3 כדי להבטיח שההדפסה הראשונה תהיה 'A' והסדר יישמר לאורך זמן?", "code_snippet": null, "options": null}, {"id": "10.2", "text": "מה יקרה אם נאתחל את כל הסמפורים לערך 0? הסבירו בקצרה.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "נניח ואתחלנו את s1=1, s2=1, s3=1. האם הסדר ABC מובטח? אם לא, תנו דוגמה לפלט אפשרי אחר.", "code_snippet": null, "options": null}], "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1. ערכי האתחול הנדרשים הם s1=1, s2=0, s3=0. אתחול s1 ל-1 מאפשר לחוט A להתחיל מיד. מכיוון ש-s2 ו-s3 הם 0, חוטים B ו-C ייחסמו ב-wait עד שחוט A יבצע post ל-s2, וחוט B יבצע post ל-s3 בהתאמה.\n\n10.2. אם כל הסמפורים יאותחלו ל-0, יתרחש מצב של Deadlock (קיפאון). כל אחד משלושת החוטים ינסה לבצע sem_wait על סמפור שערכו 0 וייחסם, ולא יהיה אף חוט שיבצע sem_post כדי לשחרר אותם.\n\n10.3. לא, הסדר אינו מובטח. אם כל הסמפורים מאותחלים ל-1, כל אחד מהחוטים יכול לעבור את ה-wait הראשון שלו ללא תלות באחרים. במצב כזה קיימת תחרות (Race Condition) על סדר ההדפסה שתלוי בתזמון של מערכת ההפעלה. פלט אפשרי אחר יכול להיות למשל BACBAC או CBA..."}, "difficulty_estimation": "Medium", "_source_file": "0184__Synchronization__Open__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:57:08", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Synchronization", "Threads", "Concurrency", "Mutexes", "Condition Variables"], "content": {"text": "נתונה מערכת המורכבת מ-N חוטי עבודה (worker threads) וחוט מתאם יחיד (coordinator thread). המערכת מעבדת משימות בקבוצות (batches). כל קבוצה מכילה סך הכל N * M משימות, כאשר כל חוט עבודה אחראי על עיבוד M משימות מתוך הקבוצה.\nלאחר שכל חוט עבודה סיים לעבד את M המשימות שלו עבור קבוצה מסוימת, הוא חייב להמתין שכל שאר N-1 חוטי העבודה יסיימו גם הם את משימותיהם עבור אותה קבוצה. רק לאחר שכל N חוטי העבודה סיימו את משימותיהם בקבוצה הנוכחית, הם יכולים להתקדם לקבוצה הבאה.\nחוט המתאם אחראי על אתחול קבוצות חדשות. הוא ממתין שכל N חוטי העבודה יסיימו קבוצה אחת לפני שהוא מסמן להם להתחיל את הקבוצה הבאה. התהליך חוזר על עצמו עבור B קבוצות סך הכל.\nממשו את מבנה הנתונים ואת הלוגיקה הנדרשת עבור חוטי העבודה וחוט המתאם, תוך שימוש ב-mutexes ו-condition variables, על מנת להבטיח סנכרון נכון, למנוע תקלות (race conditions, deadlocks) ולאפשר שימוש חוזר במנגנון הסנכרון עבור קבוצות עבודה עוקבות. יש לשים דגש על יעילות ומינימום 'המתנה ערה' (busy-waiting).", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h> // For usleep, to simulate work\n\n// Structure for the synchronization mechanism\ntypedef struct {\n  pthread_mutex_t mutex;\n  pthread_cond_t cv_workers_ready_to_start_batch;          // Coordinator signals workers to start. Workers wait.\n  pthread_cond_t cv_coordinator_notified_of_batch_completion; // Last worker signals coordinator. Coordinator waits.\n  int N;                                // Total number of worker threads\n  int workers_finished_current_batch;   // Counter for workers completing tasks in the *current* batch\n  int current_batch_num;                // The batch number currently being processed by workers (or waiting to be started)\n  int total_batches;                    // Total batches to process for the entire system\n} BatchCoordinator;\n\n// Arguments for worker threads\ntypedef struct {\n  int id;\n  int M; // Number of tasks per worker per batch\n  BatchCoordinator* coordinator;\n} WorkerArgs;\n\n// Function to initialize the BatchCoordinator\nvoid init_batch_coordinator(BatchCoordinator* bc, int N_workers, int total_batches_system) {\n  pthread_mutex_init(&bc->mutex, NULL);\n  pthread_cond_init(&bc->cv_workers_ready_to_start_batch, NULL);\n  pthread_cond_init(&bc->cv_coordinator_notified_of_batch_completion, NULL);\n  bc->N = N_workers;\n  bc->workers_finished_current_batch = 0;\n  bc->current_batch_num = 0; // Initialize to 0, so workers can start batch 0 immediately\n  bc->total_batches = total_batches_system;\n}\n\n// Function to destroy the BatchCoordinator\nvoid destroy_batch_coordinator(BatchCoordinator* bc) {\n  pthread_mutex_destroy(&bc->mutex);\n  pthread_cond_destroy(&bc->cv_workers_ready_to_start_batch);\n  pthread_cond_destroy(&bc->cv_coordinator_notified_of_batch_completion);\n}\n\n// Worker thread function\nvoid* worker_thread_func(void* arg) {\n    WorkerArgs* args = (WorkerArgs*)arg;\n    BatchCoordinator* bc = args->coordinator;\n    int worker_id = args->id;\n    int M = args->M;\n\n    for (int b = 0; b < bc->total_batches; ++b) {\n        // --- Phase 1: Worker waits for coordinator to allow starting batch 'b' ---\n        pthread_mutex_lock(&bc->mutex);\n        while (bc->current_batch_num < b) {\n            pthread_cond_wait(&bc->cv_workers_ready_to_start_batch, &bc->mutex);\n        }\n        pthread_mutex_unlock(&bc->mutex);\n\n        // --- Phase 2: Process M tasks ---\n        // Simulate work (e.g., sleep for a short random time)\n        usleep(rand() % 100000);\n\n        // --- Phase 3: Worker signals completion and (implicitly) waits for others ---\n        pthread_mutex_lock(&bc->mutex);\n        bc->workers_finished_current_batch++;\n\n        if (bc->workers_finished_current_batch == bc->N) {\n            // Last worker to finish. Signal coordinator.\n            pthread_cond_signal(&bc->cv_coordinator_notified_of_batch_completion);\n        }\n        pthread_mutex_unlock(&bc->mutex);\n    }\n    return NULL;\n}\n\n// Coordinator thread function\nvoid* coordinator_thread_func(void* arg) {\n    BatchCoordinator* bc = (BatchCoordinator*)arg;\n\n    for (int b = 0; b < bc->total_batches; ++b) {\n        // Phase 1: Coordinator ensures workers are ready for batch 'b' and signals them.\n        pthread_mutex_lock(&bc->mutex);\n        bc->current_batch_num = b; // Allow workers to start batch 'b'\n        pthread_cond_broadcast(&bc->cv_workers_ready_to_start_batch); // Wake up all workers for batch 'b'\n        pthread_mutex_unlock(&bc->mutex);\n\n        // Simulate coordinator doing some preparatory work for the batch if any\n        usleep(rand() % 50000);\n\n        // Phase 2: Coordinator waits for all workers to finish batch 'b'.\n        pthread_mutex_lock(&bc->mutex);\n        while (bc->workers_finished_current_batch < bc->N) {\n            pthread_cond_wait(&bc->cv_coordinator_notified_of_batch_completion, &bc->mutex);\n        }\n        // All workers finished batch 'b'. Reset counter for the next batch.\n        bc->workers_finished_current_batch = 0;\n        pthread_mutex_unlock(&bc->mutex);\n\n        // Simulate coordinator doing some work between batches\n        usleep(rand() % 50000);\n    }\n    return NULL;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הבעיה דורשת סנכרון דו-שלבי ושימוש חוזר: ראשית, חוטי העבודה צריכים להמתין זה לזה בסיום כל קבוצת משימות. שנית, חוט המתאם צריך לסנכרן את התחלת הקבוצות הבאות עם חוטי העבודה, ולהמתין לסיום הקבוצה הנוכחית לפני שהוא מאפשר את התחלת הבאה.\nלשם כך, נשתמש במבנה `BatchCoordinator` שיכיל:\n1.  `pthread_mutex_t mutex`: מנעול להגנה על משתנים משותפים.\n2.  `pthread_cond_t cv_workers_ready_to_start_batch`: משתנה תנאי שחוטי העבודה ממתינים עליו כדי לקבל אישור מחוט המתאם להתחיל קבוצת משימות חדשה. חוט המתאם מאותת עליו (broadcast).\n3.  `pthread_cond_t cv_coordinator_notified_of_batch_completion`: משתנה תנאי שחוט המתאם ממתין עליו כדי לקבל אישור מחוט העבודה האחרון שסיים את משימותיו בקבוצה הנוכחית. חוט העבודה האחרון מאותת עליו (signal).\n4.  `int N`: מספר חוטי העבודה הכולל.\n5.  `int workers_finished_current_batch`: מונה שסופר כמה חוטי עבודה סיימו את משימותיהם בקבוצה הנוכחית.\n6.  `int current_batch_num`: מספר הקבוצה הנוכחית שמותר לחוטי העבודה לעבד. משמש כ'שער' (turnstile) שמונע מחוטים להתקדם לקבוצה הבאה לפני שהמתאם אישר זאת.\n7.  `int total_batches`: המספר הכולל של קבוצות לעיבוד.\n\n**לוגיקת חוט העבודה (`worker_thread_func`):**\nכל חוט עבודה עובר בלולאה על כל הקבוצות (`b` מ-0 עד `total_batches-1`).\n*   **שלב 1 (המתנה לאישור מהמתאם):** החוט נועל את המוטקס ובודק אם `current_batch_num` שווה למספר הקבוצה הנוכחי `b`. אם `current_batch_num` נמוך מ-`b`, החוט ממתין על `cv_workers_ready_to_start_batch`. כאשר `current_batch_num` מגיע ל-`b` (כלומר, המתאם אישר להתחיל את קבוצה `b`), החוט משתחרר מההמתנה וממשיך.\n*   **שלב 2 (עיבוד משימות):** החוט מבצע את `M` המשימות המוטלות עליו עבור הקבוצה הנוכחית.\n*   **שלב 3 (איתות סיום):** החוט נועל את המוטקס, מגדיל את `workers_finished_current_batch` באחד. אם הוא החוט האחרון שמסיים (כלומר, `workers_finished_current_batch` שווה ל-`N`), הוא מאותת לחוט המתאם באמצעות `cv_coordinator_notified_of_batch_completion`. לאחר מכן הוא משחרר את המוטקס. החוטים אינם ממתינים זה לזה באופן מפורש בשלב זה, אלא ימתינו באופן טבעי לאישור המתאם לקבוצה הבאה בתחילת האיטרציה הבאה של הלולאה.\n\n**לוגיקת חוט המתאם (`coordinator_thread_func`):**\nחוט המתאם גם הוא עובר בלולאה על כל הקבוצות.\n*   **שלב 1 (איתות לחוטים להתחיל):** המתאם נועל את המוטקס, מעדכן את `current_batch_num` למספר הקבוצה הנוכחי `b` (כדי לאפשר לחוטי העבודה להתחיל לעבד אותה), ומשדר איתות (`pthread_cond_broadcast`) על `cv_workers_ready_to_start_batch` כדי להעיר את כל חוטי העבודה הממתינים. לאחר מכן הוא משחרר את המוטקס.\n*   **שלב 2 (המתנה לסיום הקבוצה):** המתאם נועל שוב את המוטקס וממתין על `cv_coordinator_notified_of_batch_completion` עד ש-`workers_finished_current_batch` יגיע ל-`N` (כלומר, כל חוטי העבודה סיימו את הקבוצה). ברגע שכל החוטים סיימו, המתאם מאפס את `workers_finished_current_batch` ל-0 לקראת הקבוצה הבאה, ומשחרר את המוטקס.\n\n**אתחול וסיום:**\n*   פונקציית `init_batch_coordinator` מאתחלת את כל אובייקטי הסנכרון וקובעת את `current_batch_num` ל-0, כך שחוטי העבודה יכולים להתחיל את קבוצה 0 ללא המתנה ראשונית.\n*   פונקציית `destroy_batch_coordinator` משחררת את המשאבים.\n\nפתרון זה מבטיח סנכרון נכון, מונע מצבי מירוץ וקיפאון, ומאפשר שימוש חוזר במנגנון הסנכרון ביעילות (ללא busy-waiting)."}, "difficulty_estimation": "Hard", "_source_file": "0185__Synchronization__Open__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:54:14", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Atomics", "Barriers", "Concurrency"], "content": {"text": "מחסום (Barrier) הוא אובייקט סנכרון המבטיח שכל N החוטים המשתתפים הגיעו לנקודה מסוימת לפני שמישהו מהם ממשיך בביצוע. מימוש נאיבי של מחסום המבוסס על מונה (Counter) ו-Mutex בלבד עלול להיכשל או לגרום לביצועים ירודים כאשר המחסום נמצא בשימוש חוזר (Reusable Barrier) בתוך לולאה. בשאלה זו נבחן את טכניקת ה-Sense Reversal המאפשרת מימוש יעיל ובטוח לשימוש חוזר ללא צורך ב-Locking כבד.", "code_snippet": "#include <stdatomic.h>\n\ntypedef struct {\n    atomic_int count;\n    atomic_int sense;\n    int N;\n} Barrier;\n\nvoid init(Barrier* b, int N) {\n    atomic_init(&b->count, N);\n    atomic_init(&b->sense, 0);\n    b->N = N;\n}\n\nvoid wait(Barrier* b) {\n    // Implementation required\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "הסבירו מדוע מימוש מחסום המבוסס על קידום מונה ובדיקת `if (count == N)` (ללא מנגנון נוסף) אינו בטיחותי לשימוש בתוך לולאה. תארו תרחיש (Race Condition) שבו חוט עלול להתקדם לשלב הבא באופן שגוי.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "השלימו את הקוד עבור הפונקציה `wait` המשתמשת בטכניקת ה-Sense Reversal. עליכם להשתמש בפעולות אטומיות בלבד (`atomic_load`, `atomic_store`, `atomic_fetch_sub`) ולהבטיח שהמחסום ניתן לשימוש חוזר אינסופי ללא אתחול חיצוני.", "code_snippet": "void wait(Barrier* b) {\n    // השלימו כאן\n}", "options": null}], "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: במימוש נאיבי, החוט האחרון שמעלה את המונה ל-N משחרר את שאר החוטים. אם החוטים רצים בלולאה, חוט מהיר במיוחד עשוי לסיים את האיטרציה הנוכחית, להיכנס לאיטרציה הבאה ולהתחיל לשנות את המונה (למשל לאפס אותו או להעלות אותו שוב) לפני שחוטים איטיים יותר הספיקו אפילו לקרוא שהמונה הגיע ל-N. מצב זה יגרום לחוטים האיטיים להיתקע לנצח או לחוט המהיר 'לפרוץ' את המחסום בטרם עת.\n\n10.2: בטכניקת Sense Reversal, אנו משתמשים במשתנה 'sense' גלובלי ובמשתנה מקומי לכל חוט. חוט שנכנס למחסום מחשב מה צריך להיות ה-sense הבא (היפוך של הנוכחי). החוטים ממתינים עד שה-sense הגלובלי ישתנה לערך המבוקש. החוט האחרון שמגיע הוא זה שאחראי לאפס את המונה עבור הסבב הבא ולשנות את ה-sense הגלובלי, ובכך הוא משחרר את כולם.\n\nקוד המימוש:\nvoid wait(Barrier* b) {\n    static _Thread_local int local_sense = 0;\n    local_sense = !local_sense; // היפוך ה-sense המקומי לכל חוט\n    \n    if (atomic_fetch_sub(&b->count, 1) == 1) {\n        // החוט האחרון שהגיע\n        atomic_store(&b->count, b->N); // הכנה לסבב הבא\n        atomic_store(&b->sense, local_sense); // שחרור כל החוטים ע\"י שינוי ה-sense הגלובלי\n    } else {\n        // חוטים שאינם האחרונים מחכים לשינוי ה-sense\n        while (atomic_load(&b->sense) != local_sense) {\n            // Spinning\n        }\n    }\n}"}, "difficulty_estimation": "Hard", "_source_file": "0186__Synchronization__Open__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:57:43", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Synchronization", "Concurrency", "Threads", "Mutexes", "Condition Variables"], "content": {"text": "ממשו אובייקט סנכרון בשם `QuotaGate` אשר מאפשר למכסה קבועה של חוטים, `N`, להיכנס לקטע קריטי. לאחר ש-`N` חוטים נכנסו לקטע הקריטי, כל חוט נוסף שינסה להיכנס יחסם. השער נפתח מחדש (כלומר, מאפשר ל-`N` חוטים חדשים להיכנס) רק לאחר שכל `N` החוטים שהיו בקטע הקריטי יצאו ממנו. יש לממש את האובייקט כך שיהיה ניתן לשימוש חוזר אינסופי.\n\nהשלימו את המימוש של הפונקציות `enter` ו-`exit_quota_gate` עבור מבנה הנתונים `QuotaGate` הנתון, תוך שימוש ב-`pthread_mutex_t` וב-`pthread_cond_t`. עליכם להגדיר את השדות הנדרשים בתוך מבנה `QuotaGate` ולממש גם את פונקציות ה-`init_quota_gate` ו-`destroy_quota_gate`.", "code_snippet": "```c\n#include <pthread.h>\n#include <stdlib.h>\n\n// You need to define the struct QuotaGate and implement its functions.\ntypedef struct {\n    // Define your fields here\n} QuotaGate;\n\n// Initializes the QuotaGate with a given quota N\nvoid init_quota_gate(QuotaGate *gate, int N);\n\n// Destroys the QuotaGate resources\nvoid destroy_quota_gate(QuotaGate *gate);\n\n// Thread calls this to enter the critical section\nvoid enter(QuotaGate *gate);\n\n// Thread calls this to exit the critical section\nvoid exit_quota_gate(QuotaGate *gate);\n```", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון משתמש בשני מונים ובמשתנה תנאי (condition variable) אחד בנוסף למוטקס אחד:\n1.  `N`: המכסה המקסימלית של חוטים המורשים להיכנס לקטע הקריטי בכל מחזור.\n2.  `current_entries`: מונה כמה חוטים כבר נכנסו לקטע הקריטי במחזור הנוכחי. כאשר מונה זה מגיע ל-`N`, חוטים נוספים יחסמו בכניסה.\n3.  `threads_waiting_to_exit`: מונה כמה חוטים מתוך ה-`N` שנכנסו עדיין נמצאים בקטע הקריטי (כלומר, טרם קראו ל-`exit_quota_gate`). כאשר מונה זה מגיע ל-0, זה מצביע על כך שכל החוטים מהמחזור הנוכחי יצאו, וניתן לאפס את השער למחזור הבא.\n4.  `mutex`: מנעול להגנה על המונים ועל גישה למשתנה התנאי.\n5.  `can_enter`: משתנה תנאי עבור חוטים הממתינים להיכנס לקטע הקריטי. חוטים אלו יקבלו איתות כאשר מחזור חדש מתחיל.\n\n**פונקציית `init_quota_gate`**: מאתחלת את המונים ומשתני הסנכרון.\n\n**פונקציית `destroy_quota_gate`**: משחררת את משאבי הסנכרון.\n\n**פונקציית `enter`**:\n*   החוט נועל את המוטקס.\n*   הוא בודק אם `current_entries` שווה ל-`N`. אם כן, זה אומר שמכסת החוטים למחזור הנוכחי כבר נכנסה, ולכן הוא ממתין על `can_enter`.\n*   כאשר החוט מתעורר (כי מחזור חדש התחיל), הוא מגדיל את `current_entries` (כדי לסמן שנכנס חוט נוסף למחזור החדש) ואת `threads_waiting_to_exit` (כדי לסמן שהוא נמצא כעת בתוך הקטע הקריטי).\n*   החוט משחרר את המוטקס.\n\n**פונקציית `exit_quota_gate`**:\n*   החוט נועל את המוטקס.\n*   הוא מקטין את `threads_waiting_to_exit` (כדי לסמן שיצא מהקטע הקריטי).\n*   אם `threads_waiting_to_exit` הגיע ל-0, זה אומר שכל `N` החוטים מהמחזור הקודם יצאו. במקרה זה:\n    *   מאפסים את `current_entries` ל-0, מה שמאפשר לחוטים חדשים להיכנס במחזור הבא.\n    *   שולחים איתות `broadcast` לכל החוטים הממתינים על `can_enter`, כדי לעורר אותם ולאפשר להם להתחיל להיכנס למחזור הבא.\n*   החוט משחרר את המוטקס.\n\nהפתרון מבטיח שאך ורק `N` חוטים ייכנסו בכל מחזור, ושהמחזור הבא יתחיל רק לאחר שכל `N` החוטים הקודמים יצאו. השימוש ב-`pthread_cond_broadcast` מבטיח שכל החוטים הממתינים בכניסה יתעוררו כאשר השער נפתח מחדש, ויכולים להתחרות על הכניסה.\n\n```c\n#include <pthread.h>\n#include <stdlib.h>\n\ntypedef struct {\n    int N;                      // The quota (max threads allowed in critical section per cycle)\n    int current_entries;        // Number of threads that have entered in the current cycle\n    int threads_waiting_to_exit; // Number of threads that are currently inside the critical section from the current cycle\n    pthread_mutex_t mutex;\n    pthread_cond_t can_enter;   // Condition variable for threads waiting to enter\n} QuotaGate;\n\nvoid init_quota_gate(QuotaGate *gate, int N) {\n    gate->N = N;\n    gate->current_entries = 0;\n    gate->threads_waiting_to_exit = 0;\n    pthread_mutex_init(&gate->mutex, NULL);\n    pthread_cond_init(&gate->can_enter, NULL);\n}\n\nvoid destroy_quota_gate(QuotaGate *gate) {\n    pthread_mutex_destroy(&gate->mutex);\n    pthread_cond_destroy(&gate->can_enter);\n}\n\nvoid enter(QuotaGate *gate) {\n    pthread_mutex_lock(&gate->mutex);\n\n    // Wait if N threads have already entered in the current cycle.\n    // This means the current batch is full, and we must wait for it to complete.\n    while (gate->current_entries == gate->N) {\n        pthread_cond_wait(&gate->can_enter, &gate->mutex);\n    }\n\n    gate->current_entries++;\n    gate->threads_waiting_to_exit++; // Increment this when a thread enters, to track how many are still inside\n\n    pthread_mutex_unlock(&gate->mutex);\n}\n\nvoid exit_quota_gate(QuotaGate *gate) {\n    pthread_mutex_lock(&gate->mutex);\n\n    gate->threads_waiting_to_exit--;\n\n    // If this is the last thread from the current cycle to exit,\n    // reset the gate for the next cycle and notify waiting threads.\n    if (gate->threads_waiting_to_exit == 0) {\n        gate->current_entries = 0; // Reset entry count for the next cycle\n        pthread_cond_broadcast(&gate->can_enter); // Wake up all threads waiting to enter\n    }\n\n    pthread_mutex_unlock(&gate->mutex);\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0187__Synchronization__Open__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:54:48", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Threads", "Concurrency", "Mutexes", "Condition Variables", "Barriers"], "content": {"text": "מערכת מרובת חוטים צריכה לעבד פריטים בקבוצות. קיים משאב משותף שיש לאפס (reset) לאחר כל K פריטים שמעובדים. הפעולה `reset_resource()` חייבת להתבצע בדיוק פעם אחת לאחר ש-K פריטים עובדו, וכל החוטים שהשתתפו בעיבוד קבוצה זו חייבים להמתין שהאיפוס יסתיים לפני שימשיכו לעבוד על הקבוצה הבאה. יש לממש את אובייקט הסנכרון `BatchProcessor` ואת הפונקציות `init`, `destroy`, ו-`process_item` תוך שימוש במנעולים (mutexes) ומשתני תנאי (condition variables) בלבד. אין לשנות את חתימת הפונקציה `reset_resource` או להוסיף לה פרמטרים. יש להקפיד על סנכרון נכון, מניעת מצבי מירוץ (race conditions) ומבוי סתום (deadlocks), ולהבטיח קריאה יחידה ל-`reset_resource` בכל K קריאות ל-`process_item`.", "code_snippet": "/* Include headers like <pthread.h> for mutexes and condition variables */\n\n// Function to be called by the system, simulates resource reset\nvoid reset_resource() {\n    // This function simulates work and should be called exactly once\n    // every K calls to process_item.\n    // In a real scenario, this might involve re-initializing a data structure,\n    // resetting a hardware component, etc.\n}\n\ntypedef struct {\n    // TODO: Add fields here\n} BatchProcessor;\n\nvoid init(BatchProcessor *bp, int K) {\n    // TODO: Implement\n}\n\nvoid destroy(BatchProcessor *bp) {\n    // TODO: Implement\n}\n\nvoid process_item(BatchProcessor *bp) {\n    // TODO: Implement\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון משתמש במנגנון מחסום מחזורי (Cyclic Barrier) כדי לסנכרן את החוטים. אובייקט `BatchProcessor` מכיל את השדות הבאים:\n- `K`: גודל הקבוצה הנדרש.\n- `count`: מונה כמה חוטים כבר נכנסו לקריאה ל-`process_item` עבור הקבוצה הנוכחית.\n- `generation`: מונה את מספר הקבוצה הנוכחית. משתנה זה חיוני כדי להבחין בין חוטים הממתינים מקבוצות שונות במקרה של שימוש חוזר באובייקט הסנכרון.\n- `mutex`: מנעול להגנה על המונים (`count`, `generation`) מפני מצבי מירוץ.\n- `cond`: משתנה תנאי המשמש להמתנה ושחרור חוטים.\n\n**מימוש קוד:**\n```c\n#include <pthread.h>\n\n// Function to be called by the system, simulates resource reset\nvoid reset_resource() {\n    // This function simulates work and should be called exactly once\n    // every K calls to process_item.\n    // In a real scenario, this might involve re-initializing a data structure,\n    // resetting a hardware component, etc.\n}\n\ntypedef struct {\n    int K;                  // Batch size\n    int count;              // Number of threads currently in the batch\n    int generation;         // Counter for batch cycles\n    pthread_mutex_t mutex;\n    pthread_cond_t cond;\n} BatchProcessor;\n\nvoid init(BatchProcessor *bp, int K) {\n    bp->K = K;\n    bp->count = 0;\n    bp->generation = 0;\n    pthread_mutex_init(&bp->mutex, NULL);\n    pthread_cond_init(&bp->cond, NULL);\n}\n\nvoid destroy(BatchProcessor *bp) {\n    pthread_mutex_destroy(&bp->mutex);\n    pthread_cond_destroy(&bp->cond);\n}\n\nvoid process_item(BatchProcessor *bp) {\n    pthread_mutex_lock(&bp->mutex);\n\n    int my_generation = bp->generation; \n\n    bp->count++;\n\n    if (bp->count == bp->K) { // This is the K-th thread in the batch\n        reset_resource();\n        bp->count = 0;          // Reset count for next batch\n        bp->generation++;       // Advance generation, signaling batch completion\n        pthread_cond_broadcast(&bp->cond); // Wake up all waiting threads\n    } else { \n        // Not the last thread, wait until the generation advances\n        // (meaning current batch is done and reset by the K-th thread)\n        while (bp->generation == my_generation) {\n            pthread_cond_wait(&bp->cond, &bp->mutex);\n        }\n    }\n\n    pthread_mutex_unlock(&bp->mutex);\n}\n```\n\n**הסבר מפורט:**\n\n**פונקציית `init`:**\nמאתחלת את השדות `K`, `count` (ל-0, משום שאף חוט עדיין לא נכנס לקבוצה הראשונה), `generation` (ל-0, קבוצה ראשונה), ומאתחלת את המנעול ומשתנה התנאי של `pthread`. אתחול נכון של אובייקטי הסנכרון הוא קריטי.\n\n**פונקציית `destroy`:**\nמשחררת את המשאבים של המנעול ומשתנה התנאי. חשוב לבצע זאת כדי למנוע דליפות זיכרון ומשאבי מערכת.\n\n**פונקציית `process_item`:**\n1.  **כניסה לאזור קריטי:** החוט נועל את ה-`mutex` באמצעות `pthread_mutex_lock(&bp->mutex)`. זה מבטיח שרק חוט אחד יוכל לשנות את המונים (`count`, `generation`) בכל רגע נתון, ובכך מונע מצבי מירוץ.\n2.  **שמירת דור (Generation):** החוט שומר את ערך ה-`generation` הנוכחי לתוך משתנה מקומי (`my_generation`). זהו מנגנון חיוני במחסומים מחזוריים. הוא מאפשר לחוטים לדעת לאיזה מחזור (קבוצה) הם שייכים. חוטים מקבוצה קודמת שהתעוררו (אך עדיין לא יצאו מהלולאה) או חוטים מקבוצה עתידית לא יושפעו בטעות מה-`broadcast` הנוכחי, ויוכלו להמתין לדור הנכון שלהם.\n3.  **קידום מונה הקבוצה:** החוט מקדם את המונה `count` (`bp->count++`), המייצג את מספר החוטים שנכנסו לקבוצה הנוכחית.\n4.  **זיהוי החוט האחרון בקבוצה:**\n    *   **`if (bp->count == bp->K)`:** אם ה-`count` שווה ל-`K`, החוט הנוכחי הוא האחרון בקבוצה. זהו החוט שאחראי לבצע את פעולות הסיום של הקבוצה:\n        *   **`reset_resource()`:** קריאה לפונקציית איפוס המשאב. מכיוון שרק החוט ה-K-י מגיע לכאן, מובטח שהפעולה תתבצע בדיוק פעם אחת עבור כל קבוצה של K פריטים.\n        *   **`bp->count = 0;`:** איפוס המונה `count` ל-0, כדי להתחיל לספור את החוטים עבור הקבוצה הבאה.\n        *   **`bp->generation++;`:** קידום מונה ה-`generation`. פעולה זו היא הסימן לכל החוטים הממתינים שהקבוצה הנוכחית הסתיימה, ושהמשאב אופס.\n        *   **`pthread_cond_broadcast(&bp->cond);`:** שידור לכל החוטים הממתינים על משתנה התנאי. כל החוטים שהמתינו (כלומר, הגיעו לפני החוט ה-K-י) יתעוררו ויבדקו את תנאי ההמתנה שלהם.\n5.  **המתנת חוטים שאינם אחרונים:**\n    *   **`else { while (bp->generation == my_generation) { pthread_cond_wait(&bp->cond, &bp->mutex); } }`:** אם החוט אינו החוט ה-K-י, הוא נכנס ללולאת המתנה. הוא ממתין על משתנה התנאי (`pthread_cond_wait`) כל עוד ה-`generation` הנוכחי של האובייקט (`bp->generation`) שווה ל-`my_generation` (הדור שהחוט הזה ראה כשנכנס). תנאי זה מבטיח שהחוט ימתין עד שהחוט ה-K-י יבצע את האיפוס ויקדם את ה-`generation`. כשה-`generation` של האובייקט מתקדם, החוט יודע שהקבוצה שלו הסתיימה ושהמשאב אופס, והוא יכול להמשיך.\n6.  **יציאה מאזור קריטי:** החוט משחרר את ה-`mutex` באמצעות `pthread_mutex_unlock(&bp->mutex)`. כעת הוא יכול להמשיך בעבודתו, בידיעה שהמשאב מוכן לקבוצה הבאה של פריטים."}, "difficulty_estimation": "Hard", "_source_file": "0188__Synchronization__Open__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:55:27", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Semaphores", "Mutexes", "Concurrency", "Starvation"], "content": {"text": "עליכם לממש מנגנון סנכרון עבור משאב משותף המוגבל ל-M משתמשים בו-זמנית. החוטים במערכת מחולקים לשני סוגים: A ו-B. המגבלות הן:\n1. סך כל החוטים (A ו-B יחד) המשתמשים במשאב לא יעלה על M.\n2. מספר החוטים מסוג A המשתמשים במשאב לא יעלה על K (כאשר K < M).\n3. מניעת הרעבה: אם יש חוטים מסוג B הממתינים בתור לכניסה, חוט חדש מסוג A יוכל להיכנס למשאב רק אם נמצאים בו כרגע פחות מ-K-1 חוטים מסוג A (כלומר, עליו להשאיר מקום פוטנציאלי לחוט מסוג B).\n\nעליכם להשתמש בטכניקת 'העברת המקל' (Pass the Baton) על מנת להבטיח את קיום התנאים ומניעת הרעבה, תוך שימוש בסמפורים ומוטקסים בלבד.", "code_snippet": "typedef struct {\n    int M, K;\n    int inA, inB;\n    int waitA, waitB;\n    sem_t lock;\n    sem_t semA;\n    sem_t semB;\n} ResourceControl;\n\nvoid init(ResourceControl *rc, int M, int K);\nvoid enter_A(ResourceControl *rc);\nvoid leave_A(ResourceControl *rc);\nvoid enter_B(ResourceControl *rc);\nvoid leave_B(ResourceControl *rc);", "options": null}, "sub_questions": [{"id": "10.1", "text": "ממשו את פונקציית האתחול init.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "ממשו את הפונקציות enter_A, leave_A, enter_B, leave_B. יש להשתמש בפונקציית עזר release_next המיישמת את לוגיקת העברת המקל.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון משתמש בטכניקת Pass the Baton. הרעיון המרכזי הוא שחוט שנכנס או יוצא בודק אם יש חוטים אחרים שיכולים להיכנס. אם כן, הוא משחרר את הסמפור שלהם מבלי לשחרר את ה-mutex (החוט המשוחרר 'יורש' את ה-mutex). רק אם אין אף חוט שיכול להיכנס, ה-mutex משוחרר.\n\n10.1:\nvoid init(ResourceControl *rc, int M, int K) {\n    rc->M = M; rc->K = K;\n    rc->inA = 0; rc->inB = 0;\n    rc->waitA = 0; rc->waitB = 0;\n    sem_init(&rc->lock, 0, 1);\n    sem_init(&rc->semA, 0, 0);\n    sem_init(&rc->semB, 0, 0);\n}\n\n10.2:\nvoid release_next(ResourceControl *rc) {\n    if (rc->waitB > 0 && (rc->inA + rc->inB < rc->M)) {\n        rc->waitB--; rc->inB++;\n        sem_post(&rc->semB);\n    } else if (rc->waitA > 0 && (rc->inA + rc->inB < rc->M) && (rc->inA < rc->K) && !(rc->waitB > 0 && rc->inA == rc->K - 1)) {\n        rc->waitA--; rc->inA++;\n        sem_post(&rc->semA);\n    } else {\n        sem_post(&rc->lock);\n    }\n}\n\nvoid enter_A(ResourceControl *rc) {\n    sem_wait(&rc->lock);\n    if ((rc->inA + rc->inB < rc->M) && (rc->inA < rc->K) && !(rc->waitB > 0 && rc->inA == rc->K - 1)) {\n        rc->inA++;\n        release_next(rc);\n    } else {\n        rc->waitA++;\n        sem_post(&rc->lock);\n        sem_wait(&rc->semA);\n        release_next(rc);\n    }\n}\n\nvoid leave_A(ResourceControl *rc) {\n    sem_wait(&rc->lock);\n    rc->inA--;\n    release_next(rc);\n}\n\nvoid enter_B(ResourceControl *rc) {\n    sem_wait(&rc->lock);\n    if (rc->inA + rc->inB < rc->M) {\n        rc->inB++;\n        release_next(rc);\n    } else {\n        rc->waitB++;\n        sem_post(&rc->lock);\n        sem_wait(&rc->semB);\n        release_next(rc);\n    }\n}\n\nvoid leave_B(ResourceControl *rc) {\n    sem_wait(&rc->lock);\n    rc->inB--;\n    release_next(rc);\n}"}, "difficulty_estimation": "Hard", "_source_file": "0189__Synchronization__Open__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:58:21", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Threads", "Concurrency", "Barriers", "Mutexes", "Condition Variables"], "content": {"text": "במערכות מרובות חוטים, לעיתים קרובות נדרש לסנכרן תהליכים במספר נקודות שונות במהלך ביצועם. נתונים N חוטים, ומטרתנו לממש מחסום דו-שלבי (Two-Phase Barrier) שניתן לשימוש חוזר. המחסום יסנכרן את N החוטים בשני שלבים עוקבים, כך שכל N החוטים חייבים להשלים שלב אחד לפני שמישהו מהם יוכל להתחיל את השלב הבא, וכן לפני שמישהו מהם יוכל להתחיל את השלב הראשון של המחזור הבא.\n\nיש לממש את מבנה הנתונים `TwoPhaseBarrier` ואת הפונקציות הבאות:\n*   `void init_two_phase_barrier(TwoPhaseBarrier *bar, int N)`: מאתחל את המחסום עבור N חוטים.\n*   `void destroy_two_phase_barrier(TwoPhaseBarrier *bar)`: משחרר משאבים של המחסום.\n*   `void phase1_checkin(TwoPhaseBarrier *bar)`: נקודת סנכרון ראשונה. חוט שקורא לפונקציה זו ממתין עד שכל N החוטים האחרים קראו אף הם ל-`phase1_checkin`. רק אז כולם ממשיכים.\n*   `void phase2_checkin(TwoPhaseBarrier *bar)`: נקודת סנכרון שנייה. חוט שקורא לפונקציה זו ממתין עד שכל N החוטים האחרים קראו אף הם ל-`phase2_checkin`. רק אז כולם ממשיכים.\n\nהמחזור של `phase1_checkin` ואז `phase2_checkin` יכול לחזור על עצמו מספר בלתי מוגבל של פעמים.\nהמימוש חייב להיות חסין בפני תנאי מירוץ (race conditions), קיפאון (deadlock), ורעב (starvation).\nהשתמשו באובייקטי סנכרון סטנדרטיים של POSIX Threads (כגון mutex ו-condition variables).", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "המימוש משתמש ב-mutex אחד וב-condition variable אחד כדי לסנכרן את כל N החוטים. המפתח להבטחת פעולה נכונה במחסום דו-שלבי שניתן לשימוש חוזר הוא ניהול מצב המחזור הנוכחי (current_wave) ומונה החוטים שהגיעו (count).\n\n**מבנה `TwoPhaseBarrier`:**\n```c\n#include <pthread.h>\n\ntypedef struct {\n    int N;\n    int count;          // Threads arrived at the current active wave\n    int current_wave;   // 0 for phase1, 1 for phase2. Increments after all threads pass a phase.\n                        // So, it will be 0 when waiting for phase1_checkin, then 1 for phase2_checkin, then 0 again.\n    pthread_mutex_t mutex;\n    pthread_cond_t cond; // Single condition variable is often sufficient for reusable barriers\n} TwoPhaseBarrier;\n```\n\n**פונקציות המימוש:**\n```c\nvoid init_two_phase_barrier(TwoPhaseBarrier *bar, int N) {\n    bar->N = N;\n    bar->count = 0;\n    bar->current_wave = 0; // Start with phase 0 (phase1_checkin)\n    pthread_mutex_init(&bar->mutex, NULL);\n    pthread_cond_init(&bar->cond, NULL);\n}\n\nvoid destroy_two_phase_barrier(TwoPhaseBarrier *bar) {\n    pthread_mutex_destroy(&bar->mutex);\n    pthread_cond_destroy(&bar->cond);\n}\n\n// Internal helper function for both phases\nvoid phase_checkin(TwoPhaseBarrier *bar, int expected_wave) {\n    pthread_mutex_lock(&bar->mutex);\n\n    // Wait if this thread is too fast and arrived for a future wave\n    // Or if it's too slow and arrived for a past wave (should not happen with correct usage)\n    while (bar->current_wave != expected_wave) {\n        pthread_cond_wait(&bar->cond, &bar->mutex);\n    }\n\n    bar->count++;\n    if (bar->count < bar->N) {\n        // Not the last thread, wait for others in the same wave\n        while (bar->current_wave == expected_wave) { // Wait until the current_wave changes (signaling completion)\n            pthread_cond_wait(&bar->cond, &bar->mutex);\n        }\n    } else {\n        // Last thread for this wave\n        bar->count = 0; // Reset for the next wave\n        bar->current_wave = (bar->current_wave + 1) % 2; // Advance to the next wave (0 -> 1, 1 -> 0)\n        pthread_cond_broadcast(&bar->cond); // Wake up all waiting threads\n    }\n    pthread_mutex_unlock(&bar->mutex);\n}\n\nvoid phase1_checkin(TwoPhaseBarrier *bar) {\n    phase_checkin(bar, 0);\n}\n\nvoid phase2_checkin(TwoPhaseBarrier *bar) {\n    phase_checkin(bar, 1);\n}\n```\n\n**לוגיקת הפעולה:**\n1.  **נעילת mutex**: כל חוט נועל את ה-mutex בכניסה לפונקציה כדי להגן על משתני המצב המשותפים.\n2.  **המתנה לשלב הנכון**: \n    *   `while (bar->current_wave != expected_wave)`: חוטים ממתינים כאן אם הם מנסים להיכנס לשלב שאינו השלב הפעיל כרגע. לדוגמה, אם `current_wave` הוא 0 (מצפה ל-`phase1_checkin`) וחוט מנסה לקרוא ל-`phase2_checkin` (עם `expected_wave` של 1), הוא ימתין. זה מונע מחוטים מהירים להקדים את זמנם לשלב הבא או למחזור הבא.\n3.  **קידום מונה והמתנה**: \n    *   `bar->count++`: החוט מקדם את מונה ההגעה לשלב הנוכחי.\n    *   `if (bar->count < bar->N)`: אם זה לא החוט האחרון שהגיע, הוא ממתין על משתנה התנאי. התנאי `while (bar->current_wave == expected_wave)` מבטיח שהחוט ימשיך להמתין עד שהחוט האחרון ישנה את `current_wave` (כלומר, השלב הנוכחי הושלם).\n4.  **החוט האחרון**: \n    *   `else`: אם זהו החוט ה-N שהגיע לשלב, הוא מבצע את הפעולות הבאות:\n        *   `bar->count = 0`: מאפס את המונה עבור השלב הבא.\n        *   `bar->current_wave = (bar->current_wave + 1) % 2`: מקדם את השלב הפעיל. אם היינו בשלב 0, עוברים לשלב 1; אם היינו בשלב 1, חוזרים לשלב 0 עבור המחזור הבא.\n        *   `pthread_cond_broadcast(&bar->cond)`: מעיר את כל החוטים הממתינים על משתנה התנאי. כעת הם יבדקו מחדש את תנאי ההמתנה שלהם וימשיכו (אלו שחיכו באותו שלב).\n5.  **שחרור mutex**: החוט משחרר את ה-mutex ויוצא מהפונקציה.\n\n**הימנעות מבעיות:**\n*   **Race Conditions**: ה-mutex מגן על כל הגישות למשתני המצב המשותפים (`count`, `current_wave`).\n*   **Deadlock**: לא קיים deadlock מכיוון שכל החוטים פועלים באותו אופן, ורק האחרון מביניהם משחרר את כולם. אין תלות מעגלית במשאבים.\n*   **Starvation**: כל החוטים מעוררים באמצעות `pthread_cond_broadcast`, כך שאף חוט לא נשאר תקוע לנצח.\n*   **Reusability**: ה-`current_wave` ואיפוס ה-`count` מבטיחים שהמחסום עובד נכון למחזורים עוקבים.\n\n**הערה**: המימוש מניח שכל N החוטים אכן יקראו ל-`phase1_checkin` ולאחר מכן ל-`phase2_checkin` (בסדר הנכון) במחזור נתון. אם חוט ינסה לדלג על שלב או לקרוא לשלב לא נכון, הוא ימתין עד שה-`current_wave` יתאים לדרישתו."}, "difficulty_estimation": "Hard", "_source_file": "0190__Synchronization__Open__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:42:23", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Synchronization", "Threads", "Concurrency", "Mutexes", "Condition Variables", "Barriers"], "content": {"text": "במערכות הפעלה מרובות-חוטים, לעיתים קרובות נדרש לסנכרן קבוצת חוטים כך שימתינו זה לזה, אך גם ימתינו לתנאי חיצוני מסוים. נתון אובייקט סנכרון בשם `ConditionalTurnstile` אשר מאפשר ל-N חוטים לעבור יחד, אך ורק כאשר תנאי חיצוני (שנקבע על ידי פונקציה אחרת) מתקיים. לאחר שקבוצה של N חוטים עברה, ה-`ConditionalTurnstile` מתאפס ומוכן לקבוצת החוטים הבאה.\n\nהאובייקט `ConditionalTurnstile` יכלול את הפעולות הבאות:\n*   `init(ConditionalTurnstile *ts, int N)`: מאתחל את ה-`Turnstile` עבור N חוטים.\n*   `destroy(ConditionalTurnstile *ts)`: משחרר משאבים.\n*   `wait_for_batch(ConditionalTurnstile *ts)`: חוט הקורא לפעולה זו ממתין עד ש-N חוטים נוספים (כולל הוא עצמו) קראו לפעולה, וכן שתנאי חיצוני מסוים מתקיים. רק אז, כל N החוטים משוחררים בו זמנית.\n*   `set_condition(ConditionalTurnstile *ts, bool condition_state)`: משנה את מצב התנאי החיצוני. אם התנאי הופך ל-`true` בזמן שחוטים ממתינים, והגיעה קבוצה של N חוטים, יש לשחררם.\n\nיש לממש את ה-`ConditionalTurnstile` תוך שימוש במנעולים (mutexes) ומשתני תנאי (condition variables) בלבד, ובאופן יעיל ככל האפשר. יש להקפיד על פתרון נטול קיפאון (deadlock-free) ותנאי מרוץ (race-condition-free).\n\nשימו לב במיוחד לטיפול במצבים הבאים:\n1.  מה קורה אם `set_condition` נקראת כאשר אין חוטים ממתינים?\n2.  מה קורה אם `set_condition` נקראת מספר פעמים ברצף?\n3.  כיצד מבטיחים שכל N החוטים ישוחררו יחד, ושהמונה יתאפס בצורה בטוחה לקבוצה הבאה, תוך כדי מניעת בעיית \"הנוסע הממהר\" (Early-departer problem) עם מחסומים הניתנים לשימוש חוזר?", "code_snippet": "#include <pthread.h>\n#include <stdbool.h>\n#include <stdlib.h>\n\ntypedef struct {\n    int N;                      // Total threads required for a batch\n    int arrived_count;          // Threads that have arrived in the current \"wave\"\n    int passed_count;           // Threads that have passed the barrier in the current \"wave\"\n    int wave;                   // Current wave number for reusability\n    pthread_mutex_t mutex;\n    pthread_cond_t cond_arrival;   // Threads wait here until batch is full AND condition met\n    pthread_cond_t cond_departure; // Threads wait here until all N have departed\n    bool condition_met;         // The external condition state\n} ConditionalTurnstile;\n\nvoid init(ConditionalTurnstile *ts, int N);\nvoid destroy(ConditionalTurnstile *ts);\nvoid wait_for_batch(ConditionalTurnstile *ts);\nvoid set_condition(ConditionalTurnstile *ts, bool condition_state);", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\nהמימוש משתמש באלגוריתם מחסום דו-שלבי (two-phase barrier) בשילוב עם מונה דורות (generation counter) על מנת לאפשר שימוש חוזר במחסום ולמנוע תנאי מרוץ כגון \"הנוסע הממהר\" (early-departer).\n\nמבנה `ConditionalTurnstile`:\n*   `N`: מספר החוטים הנדרשים לקבוצה אחת.\n*   `arrived_count`: מונה את מספר החוטים שהגיעו לשלב הראשון של המחסום בקבוצה הנוכחית.\n*   `passed_count`: מונה את מספר החוטים שעברו את שלב השחרור ומתקדמים לשלב האיפוס בקבוצה הנוכחית.\n*   `wave`: מונה דורות, מזהה איזו קבוצה של חוטים נמצאת כרגע במחסום. מתקדם כל פעם שקבוצה שלמה עוברת.\n*   `mutex`: מנעול להגנה על משתני המצב (`arrived_count`, `passed_count`, `wave`, `condition_met`).\n*   `cond_arrival`: משתנה תנאי עליו ממתינים חוטים בשלב ההגעה, עד שכל `N` החוטים הגיעו וגם `condition_met` נכון.\n*   `cond_departure`: משתנה תנאי עליו ממתינים חוטים בשלב העזיבה, עד שהחוט האחרון בקבוצה איפס את המחסום.\n*   `condition_met`: דגל בוליאני המייצג את מצב התנאי החיצוני.\n\n```c\n#include <pthread.h>\n#include <stdbool.h>\n#include <stdlib.h>\n\ntypedef struct {\n    int N;\n    int arrived_count;\n    int passed_count;\n    int wave;\n    pthread_mutex_t mutex;\n    pthread_cond_t cond_arrival;\n    pthread_cond_t cond_departure;\n    bool condition_met;\n} ConditionalTurnstile;\n\nvoid init(ConditionalTurnstile *ts, int N) {\n    ts->N = N;\n    ts->arrived_count = 0;\n    ts->passed_count = 0;\n    ts->wave = 0;\n    pthread_mutex_init(&ts->mutex, NULL);\n    pthread_cond_init(&ts->cond_arrival, NULL);\n    pthread_cond_init(&ts->cond_departure, NULL);\n    ts->condition_met = false;\n}\n\nvoid destroy(ConditionalTurnstile *ts) {\n    pthread_mutex_destroy(&ts->mutex);\n    pthread_cond_destroy(&ts->cond_arrival);\n    pthread_cond_destroy(&ts->cond_departure);\n}\n\nvoid wait_for_batch(ConditionalTurnstile *ts) {\n    pthread_mutex_lock(&ts->mutex);\n\n    int my_wave = ts->wave; // Captures the current wave number for this thread\n\n    ts->arrived_count++;\n\n    // Phase 1: Arrival - threads wait for N arrivals AND the external condition\n    if (ts->arrived_count == ts->N) { // This is the N-th thread to arrive\n        // The N-th thread waits until the external condition is met\n        while (!ts->condition_met) {\n            pthread_cond_wait(&ts->cond_arrival, &ts->mutex);\n        }\n        // Condition is met, and N threads have arrived. Release all threads in this batch.\n        // No need to increment wave here, it's done by the last departing thread.\n        pthread_cond_broadcast(&ts->cond_arrival);\n    } else { // Not the N-th thread to arrive\n        // Wait until the N-th thread signals that the batch is ready to proceed\n        // and the condition was met. We use 'my_wave' to ensure we wait for the current batch.\n        while (my_wave == ts->wave) {\n            pthread_cond_wait(&ts->cond_arrival, &ts->mutex);\n        }\n    }\n\n    // All N threads have now passed the arrival barrier and are released.\n    // Phase 2: Departure - threads decrement count and wait for the last thread to reset\n    ts->passed_count++;\n\n    if (ts->passed_count == ts->N) { // This is the N-th thread to depart\n        // Reset counts and advance the wave for the next batch\n        ts->arrived_count = 0;\n        ts->passed_count = 0;\n        ts->wave++; // Advance wave for the next batch of threads\n        // Signal all threads waiting in the departure phase that the barrier is reset\n        pthread_cond_broadcast(&ts->cond_departure);\n    } else { // Not the N-th thread to depart\n        // Wait until the last thread of this batch signals that the barrier is reset\n        while (my_wave == ts->wave) {\n            pthread_cond_wait(&ts->cond_departure, &ts->mutex);\n        }\n    }\n\n    pthread_mutex_unlock(&ts->mutex);\n}\n\nvoid set_condition(ConditionalTurnstile *ts, bool condition_state) {\n    pthread_mutex_lock(&ts->mutex);\n    ts->condition_met = condition_state;\n    // If the condition becomes true AND a full batch of threads is waiting,\n    // wake them up. This is crucial if the N-th thread is waiting for the condition.\n    if (condition_state && ts->arrived_count == ts->N) {\n        pthread_cond_broadcast(&ts->cond_arrival);\n    }\n    pthread_mutex_unlock(&ts->mutex);\n}\n```\n\nהסבר:\n\n**פונקציה `init(ConditionalTurnstile *ts, int N)`:**\n*   מאתחלת את המשתנים `N`, `arrived_count` (מונה חוטים שהגיעו), `passed_count` (מונה חוטים שעזבו), `wave` (מונה דורות לשימוש חוזר במחסום), ואת המנעול ומשתני התנאי. `condition_met` מאותחל ל-`false`.\n\n**פונקציה `destroy(ConditionalTurnstile *ts)`:**\n*   משחררת את המשאבים על ידי השמדת המנעול ומשתני התנאי.\n\n**פונקציה `wait_for_batch(ConditionalTurnstile *ts)`:**\n1.  **נעילה ורישום גל הדור:** החוט נועל את המוטקס ושומר את מספר ה\"גל\" (wave) הנוכחי במשתנה מקומי `my_wave`. זה מאפשר לו לזהות מתי המחסום התקדם ל\"גל\" הבא, ומונע תנאי מרוץ במחסום הניתן לשימוש חוזר.\n2.  **שלב ההגעה (Arrival Phase):**\n    *   `ts->arrived_count` מקודם. זהו מונה החוטים שהגיעו למחסום ב\"גל\" הנוכחי.\n    *   **אם החוט הוא החוט ה-N-י שמגיע (`ts->arrived_count == ts->N`):**\n        *   הוא ממתין (באמצעות `pthread_cond_wait` על `cond_arrival`) עד ש-`condition_met` יהפוך ל-`true`. הוא האחראי לשחרר את הקבוצה.\n        *   ברגע שהתנאי מתקיים, הוא משחרר את כל `N-1` החוטים הממתינים (באמצעות `pthread_cond_broadcast` על `cond_arrival`).\n    *   **אם החוט אינו החוט ה-N-י שמגיע (`ts->arrived_count < ts->N`):**\n        *   הוא ממתין (באמצעות `pthread_cond_wait` על `cond_arrival`) כל עוד `my_wave` שווה ל-`ts->wave`. הוא ישוחרר כאשר החוט ה-N-י ישדר `broadcast` וישנה את `my_wave` (על ידי קידום `ts->wave` בשלב העזיבה של הקבוצה).\n3.  **שלב העזיבה (Departure Phase):**\n    *   לאחר שכל `N` החוטים שוחררו משלב ההגעה, הם מקדמים את `ts->passed_count`. זהו מונה החוטים שעברו את שלב השחרור ב\"גל\" הנוכחי.\n    *   **אם החוט הוא החוט ה-N-י שעובר (`ts->passed_count == ts->N`):**\n        *   הוא מאפס את `arrived_count` ו-`passed_count` ל-0. פעולה זו \"מנקה\" את המחסום לקבוצה הבאה.\n        *   הוא מקדם את `ts->wave` (כדי לסמן שהמחסום מוכן לקבוצה הבאה).\n        *   הוא משחרר את כל `N-1` החוטים הממתינים בשלב העזיבה (באמצעות `pthread_cond_broadcast` על `cond_departure`).\n    *   **אם החוט אינו החוט ה-N-י שעובר (`ts->passed_count < ts->N`):**\n        *   הוא ממתין (באמצעות `pthread_cond_wait` על `cond_departure`) כל עוד `my_wave` שווה ל-`ts->wave`. הוא ישוחרר כאשר החוט האחרון יקדם את `ts->wave` ויבצע `broadcast`.\n4.  **שחרור:** החוט משחרר את המוטקס.\n\n**פונקציה `set_condition(ConditionalTurnstile *ts, bool condition_state)`:**\n1.  נועלת את המוטקס.\n2.  מעדכנת את `ts->condition_met` למצב החדש.\n3.  אם `condition_state` הפך ל-`true` וגם `ts->arrived_count` שווה ל-`ts->N` (כלומר, קבוצה מלאה של חוטים ממתינה על `cond_arrival`): היא משחררת את כל החוטים הממתינים על `cond_arrival` (באמצעות `pthread_cond_broadcast`). זה מאפשר לחוט ה-N-י (אם הוא ממתין על התנאי) או לשאר החוטים להתקדם.\n4.  משחררת את המוטקס.\n\n**טיפול במצבים מיוחדים:**\n1.  **`set_condition` נקראת כאשר אין חוטים ממתינים:** הפונקציה תעדכן את `condition_met`. אם `condition_state` הוא `true`, היא תבצע `broadcast` אך לא יהיו חוטים שיושפעו מכך באופן מיידי. החוטים שיגיעו מאוחר יותר ימצאו את `condition_met` כבר כ-`true` ויפעלו בהתאם.\n2.  **`set_condition` נקראת מספר פעמים ברצף:** רק הערך הסופי של `condition_state` יהיה רלוונטי. כל קריאה עשויה לבצע `broadcast` אם התנאי הופך ל-`true` וקבוצה מלאה ממתינה. אין בכך בעיה מבחינת נכונות, שכן `pthread_cond_broadcast` הוא אידמפוטנטי במובן זה של חוטים ממתינים.\n3.  **שחרור `N` חוטים יחד ואיפוס בטוח (מניעת \"הנוסע הממהר\"):**\n    *   מנגנון ה\"גל\" (`wave` counter) ומשתני התנאי `cond_arrival` ו-`cond_departure` מבטיחים זאת.\n    *   `cond_arrival` מבטיח שכל `N` החוטים יגיעו ושהתנאי יתקיים לפני שמישהו ימשיך. החוט ה-N-י הוא זה שמבצע `broadcast` כדי לשחרר את כולם.\n    *   `cond_departure` ומנגנון ה-`passed_count` מבטיחים שכל `N` החוטים יעברו את המחסום לפני ש-`ts->wave` יתקדם שוב. החוט האחרון שעוזב מאפס את המחסום ומקדם את ה\"גל\", ובכך מונע מחוטים מהגל הבא להתחיל לפני שהגל הקודם סיים את כל שלבי המחסום.\n    *   השימוש ב-`my_wave` המקומי בכל חוט מבטיח שחוט שקדם ל\"גל\" הבא לא ישוחרר בטעות על ידי `broadcast` המיועד ל\"גל\" קודם, וכן שחוט שפיגר לא ייתקע לנצח."}, "difficulty_estimation": "Hard", "_source_file": "0191__Synchronization__Open__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:57:16", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Threads", "Concurrency", "Mutexes", "Condition Variables", "Readers-Writers Problem"], "content": {"text": "במערכת הפעלה נתונה, קיים משאב משותף שניתן לגשת אליו ממספר חוטים במקביל. עם זאת, עקב מגבלות חומרה, לכל היותר M חוטים יכולים לגשת למשאב בו-זמנית (M הוא פרמטר אתחול). בנוסף, למשאב יש שני מצבי גישה: 'קריאה' ו-'כתיבה'.\n\n- חוטים במצב 'קריאה' יכולים לגשת למשאב במקביל, כל עוד המספר הכולל של חוטים הניגשים למשאב (קריאה + כתיבה) אינו עולה על M.\n- רק חוט אחד במצב 'כתיבה' יכול לגשת למשאב בכל רגע נתון.\n- אם חוט 'כתיבה' ממתין, אין לאפשר לחוטי 'קריאה' חדשים להתחיל לגשת למשאב (כדי למנוע הרעבה של כותבים).\n- אם חוט 'קריאה' ממתין, יש לאפשר לו להמשיך אם ישנם פחות מ-M חוטים פעילים ואין כותב ממתין.\n\nממשו את מבנה הנתונים `LimitedAccessResource` ואת הפעולות `init`, `destroy`, `acquire_read_access`, `release_read_access`, `acquire_write_access`, ו-`release_write_access` תוך שימוש באובייקטי סנכרון של POSIX (mutexes ו-condition variables). עליכם למנוע מצבי קיפאון (deadlocks) והרעבה (starvation) של כותבים, תוך ניצול מקסימלי של המשאב הנתון (עד M חוטים בו-זמנית).", "code_snippet": "typedef struct {\n    int max_concurrent_slots; // M\n    int active_readers;       // Number of readers currently accessing\n    int active_writer;        // 1 if a writer is active, 0 otherwise\n    int waiting_readers;      // Number of readers waiting\n    int waiting_writers;      // Number of writers waiting\n\n    pthread_mutex_t mutex;\n    pthread_cond_t reader_cond;\n    pthread_cond_t writer_cond;\n} LimitedAccessResource;\n\nvoid init(LimitedAccessResource *res, int M) {\n    // Implement this function\n}\n\nvoid destroy(LimitedAccessResource *res) {\n    // Implement this function\n}\n\nvoid acquire_read_access(LimitedAccessResource *res) {\n    // Implement this function\n}\n\nvoid release_read_access(LimitedAccessResource *res) {\n    // Implement this function\n}\n\nvoid acquire_write_access(LimitedAccessResource *res) {\n    // Implement this function\n}\n\nvoid release_write_access(LimitedAccessResource *res) {\n    // Implement this function\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון משתמש ב-mutex יחיד להגנה על המשתנים המשותפים (מונה קוראים פעילים, כותב פעיל, מוני קוראים וכותבים ממתינים), ובשני משתני תנאי (condition variables): אחד לקוראים ואחד לכותבים. המשתנים `active_readers` ו-`active_writer` עוקבים אחר מספר החוטים הפעילים, בעוד `waiting_readers` ו-`waiting_writers` עוקבים אחר החוטים הממתינים. הפרמטר `max_concurrent_slots` מגדיר את מגבלת ה-M הכוללת.\n\n**מניעת קיפאון (Deadlock Prevention):**\nהפתרון מונע קיפאון על ידי כך שחוט לעולם אינו מקבל חלק מהמשאבים שלו. חוט ממתין עד שכל התנאים לגישה מתקיימים, כולל מספר המקומות הפנויים וכללי העדיפות לכותבים. התלות ההדדית מנוהלת באמצעות משתני התנאי המאפשרים שחרור חוטים ממתינים באופן מבוקר.\n\n**מניעת הרעבה (Starvation Prevention):**\nהפתרון נותן עדיפות לכותבים (Writer Preference) באופן הבא:\n1.  **לכותבים עדיפות על פני קוראים חדשים:** ב-`acquire_read_access`, קורא ממתין אם `waiting_writers > 0` (כלומר, יש כותב שממתין). זה מונע מקוראים חדשים להיכנס ולגרום לכותב להמתין זמן רב.\n2.  **כותבים מתעוררים ראשונים:** ב-`release_read_access` וב-`release_write_access`, אם ישנם כותבים ממתינים (`waiting_writers > 0`) והתנאים מאפשרים לכותב להתקדם (לדוגמה, אין קוראים פעילים ב-`release_read_access` או שהכותב הפעיל סיים ב-`release_write_access`), אז משתנה התנאי של הכותבים (`writer_cond`) מסומן ראשון.\n\n**מקסימום מקביליות (Maximum Concurrency):**\n-   עד M חוטים יכולים לגשת למשאב בו-זמנית, כל עוד הם קוראים, ואין כותב פעיל או ממתין.\n-   `pthread_cond_broadcast` משמש לשחרור קבוצת קוראים בבת אחת כאשר אין כותבים ממתינים, מה שמאפשר למספר קוראים להיכנס למשאב כל עוד יש מקום (`(active_readers + active_writer) < max_concurrent_slots`).\n\n**מימוש הפונקציות:**\n```c\n#include <pthread.h>\n#include <stdlib.h>\n\ntypedef struct {\n    int max_concurrent_slots; // M\n    int active_readers;       // Number of readers currently accessing\n    int active_writer;        // 1 if a writer is active, 0 otherwise\n    int waiting_readers;      // Number of readers waiting\n    int waiting_writers;      // Number of writers waiting\n\n    pthread_mutex_t mutex;\n    pthread_cond_t reader_cond;\n    pthread_cond_t writer_cond;\n} LimitedAccessResource;\n\nvoid init(LimitedAccessResource *res, int M) {\n    res->max_concurrent_slots = M;\n    res->active_readers = 0;\n    res->active_writer = 0;\n    res->waiting_readers = 0;\n    res->waiting_writers = 0;\n    pthread_mutex_init(&res->mutex, NULL);\n    pthread_cond_init(&res->reader_cond, NULL);\n    pthread_cond_init(&res->writer_cond, NULL);\n}\n\nvoid destroy(LimitedAccessResource *res) {\n    pthread_mutex_destroy(&res->mutex);\n    pthread_cond_destroy(&res->reader_cond);\n    pthread_cond_destroy(&res->writer_cond);\n}\n\nvoid acquire_read_access(LimitedAccessResource *res) {\n    pthread_mutex_lock(&res->mutex);\n    res->waiting_readers++;\n    while (res->active_writer > 0 || \n           res->waiting_writers > 0 || \n           (res->active_readers + res->active_writer) >= res->max_concurrent_slots) {\n        pthread_cond_wait(&res->reader_cond, &res->mutex);\n    }\n    res->waiting_readers--;\n    res->active_readers++;\n    pthread_mutex_unlock(&res->mutex);\n}\n\nvoid release_read_access(LimitedAccessResource *res) {\n    pthread_mutex_lock(&res->mutex);\n    res->active_readers--;\n    // If this was the last reader and there are waiting writers, wake up one writer.\n    if (res->active_readers == 0 && res->waiting_writers > 0) {\n        pthread_cond_signal(&res->writer_cond);\n    } else if ((res->active_readers + res->active_writer) < res->max_concurrent_slots) {\n        // If there's still space and no writer is waiting, wake up readers.\n        if (res->waiting_writers == 0) {\n             pthread_cond_broadcast(&res->reader_cond);\n        }\n    }\n    pthread_mutex_unlock(&res->mutex);\n}\n\nvoid acquire_write_access(LimitedAccessResource *res) {\n    pthread_mutex_lock(&res->mutex);\n    res->waiting_writers++;\n    while (res->active_readers > 0 || \n           res->active_writer > 0 || \n           (res->active_readers + res->active_writer) >= res->max_concurrent_slots) {\n        pthread_cond_wait(&res->writer_cond, &res->mutex);\n    }\n    res->waiting_writers--;\n    res->active_writer = 1;\n    pthread_mutex_unlock(&res->mutex);\n}\n\nvoid release_write_access(LimitedAccessResource *res) {\n    pthread_mutex_lock(&res->mutex);\n    res->active_writer = 0;\n    // After a writer leaves, prioritize waiting writers.\n    if (res->waiting_writers > 0) {\n        pthread_cond_signal(&res->writer_cond);\n    } else {\n        // No waiting writers, wake up all waiting readers that can fit.\n        pthread_cond_broadcast(&res->reader_cond);\n    }\n    pthread_mutex_unlock(&res->mutex);\n}\n```", "difficulty_estimation": "Hard"}, "_source_file": "0192__Synchronization__Open__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:58:05", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Synchronization", "Race Conditions", "Mutexes", "Threads"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בחוטים מרובים לקידום מונה גלובלי משותף. עיין בקוד וענה על השאלות הבאות:", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 100000\n\nint counter = 0;\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, increment_counter, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "101.1", "text": "מהו הערך הסופי הצפוי של המונה `counter` לאחר שכל החוטים סיימו את ריצתם, בהנחה שהקוד רץ ללא שגיאות סנכרון?", "code_snippet": null, "options": null}, {"id": "101.2", "text": "האם ערך זה מובטח בפועל בריצת התוכנית הנתונה? אם לא, הסבר מדוע ומהי התופעה המתוארת. תאר בקצרה דוגמה לתזמון חוטים שיוביל לערך שאינו הערך הצפוי.", "code_snippet": null, "options": null}, {"id": "101.3", "text": "תקן את פונקציית `increment_counter` ואת פונקציית `main` כך שהמונה יגיע תמיד לערכו הצפוי, תוך שימוש במנגנון סנכרון `pthread_mutex_t`.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "101.1: הערך הסופי הצפוי של המונה `counter` הוא `NUM_THREADS * INCREMENTS_PER_THREAD`. במקרה זה, `5 * 100000 = 500000`.\n\n101.2: ערך זה אינו מובטח בפועל. התופעה המתוארת היא מצב מרוץ (Race Condition). מצב מרוץ מתרחש כאשר מספר חוטים ניגשים למשאב משותף (במקרה זה, המשתנה `counter`) ומנסים לשנות אותו במקביל, ללא מנגנון סנכרון מתאים, מה שעלול להוביל לתוצאות בלתי צפויות ושגויות. פעולת הקידום `counter++` אינה אטומית; היא מורכבת משלוש פעולות בסיסיות: קריאת הערך הנוכחי של `counter`, הגדלת הערך, וכתיבת הערך החדש בחזרה ל-`counter`. אם שני חוטים או יותר מבצעים פעולות אלה בו זמנית, חלק מהעדכונים עלולים ללכת לאיבוד.\nדוגמה לתזמון שגוי:\n1. חוט A קורא את `counter` (לדוגמה, הערך הוא 100).\n2. חוט B קורא את `counter` (גם הוא קורא את הערך 100, לפני שחוט A הספיק לכתוב בחזרה).\n3. חוט A מגדיל את הערך שקרא (100+1=101) וכותב אותו בחזרה ל-`counter`. כעת `counter` שווה 101.\n4. חוט B מגדיל את הערך שקרא (100+1=101) וכותב אותו בחזרה ל-`counter`. כעת `counter` שווה 101.\nבמקרה זה, למרות שבוצעו שתי פעולות קידום, המונה גדל באחד בלבד במקום בשניים, וקידום אחד אבד.\n\n101.3: כדי לתקן את הקוד ולהבטיח שהמונה יגיע לערכו הצפוי, יש להגן על הקטע הקריטי (הגישה ל-`counter` ושינויו) באמצעות מנגנון סנכרון כמו mutex. התיקון כולל הוספת משתנה mutex גלובלי, אתחולו, נעילתו לפני הגישה למונה ושחרורו לאחריה, ולבסוף השמדתו.\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 100000\n\nint counter = 0;\npthread_mutex_t mutex; // הצהרה על משתנה mutex גלובלי\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&mutex);   // נעילת ה-mutex לפני הגישה לקטע הקריטי\n        counter++;                     // הקטע הקריטי\n        pthread_mutex_unlock(&mutex); // שחרור ה-mutex לאחר היציאה מהקטע הקריטי\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    pthread_mutex_init(&mutex, NULL); // אתחול ה-mutex\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, increment_counter, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n    \n    pthread_mutex_destroy(&mutex); // השמדת ה-mutex\n    return 0;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0193__Synchronization__CodeAnalysis__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:58:22", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Synchronization", "Mutex", "Threads", "Race Conditions"], "content": {"text": "לפניכם קוד בשפת C המשתמש בחוטים (threads) ובמנעול מסוג Mutex. מה יהיה הפלט של התוכנית בהנחה שכל קריאות המערכת מצליחות?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint counter = 0;\npthread_mutex_t lock;\n\nvoid* increment_task(void* arg) {\n    for (int i = 0; i < 1000; i++) {\n        pthread_mutex_lock(&lock);\n        counter++;\n        pthread_mutex_unlock(&lock);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_mutex_init(&lock, NULL);\n    \n    pthread_create(&t1, NULL, increment_task, NULL);\n    pthread_create(&t2, NULL, increment_task, NULL);\n    \n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    \n    printf(\"%d\\n\", counter);\n    pthread_mutex_destroy(&lock);\n    return 0;\n}", "options": ["הפלט יהיה תמיד 1000", "הפלט יהיה תמיד 2000", "הפלט יהיה ערך אקראי בין 1000 ל-2000 עקב Race Condition", "התוכנית תיכנס למצב של Deadlock ולא תדפיס דבר"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "הפלט יהיה תמיד 2000", "explanation": "התוכנית יוצרת שני חוטים (threads), כאשר כל אחד מהם מבצע לולאה של 1000 איטרציות המקדמות משתנה גלובלי משותף (counter). מכיוון שפעולת הקידום (counter++) מוקפת בנעילה ושחרור של Mutex (pthread_mutex_lock ו-pthread_mutex_unlock), הקטע הקריטי מוגן. הגנה זו מבטיחה שרק חוט אחד יוכל לגשת למשתנה ולעדכן אותו בכל רגע נתון, ובכך נמנע מצב של Race Condition. לכן, כל 2000 הקידומים (1000 מכל חוט) יתבצעו בהצלחה והתוצאה הסופית תהיה תמיד 2000."}, "difficulty_estimation": "Easy", "_source_file": "0194__Synchronization__CodeAnalysis__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:58:44", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Synchronization", "Race Conditions", "Mutexes", "Threads"], "content": {"text": "נתונה תוכנית C המשתמשת בחוטים (threads) לקידום מונה גלובלי משותף. עיין בקוד וזהה את הבעיה הקיימת.", "code_snippet": "1 #include <stdio.h>\n2 #include <pthread.h>\n3 #include <stdlib.h>\n\n4 #define NUM_THREADS 5\n5 #define INCREMENTS_PER_THREAD 100000\n\n6 int counter = 0;\n\n7 void* increment_counter(void* arg) {\n8   for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n9     counter++;\n10  }\n11  return NULL;\n12}\n\n13 int main() {\n14  pthread_t threads[NUM_THREADS];\n\n15  for (int i = 0; i < NUM_THREADS; ++i) {\n16    if (pthread_create(&threads[i], NULL, increment_counter, NULL) != 0) {\n17      perror(\"Failed to create thread\");\n18      return 1;\n19    }\n20  }\n\n21  for (int i = 0; i < NUM_THREADS; ++i) {\n22    if (pthread_join(threads[i], NULL) != 0) {\n23      perror(\"Failed to join thread\");\n24      return 1;\n25    }\n26  }\n\n27  printf(\"Final counter value: %d\\n\", counter);\n28  printf(\"Expected counter value: %d\\n\", NUM_THREADS * INCREMENTS_PER_THREAD);\n\n29  return 0;\n30}", "options": null}, "sub_questions": [{"id": "8.1", "text": "תאר בקצרה את הבעיה שעלולה להתרחש בהרצת הקוד הנתון, והסבר מדוע ערך המונה הסופי אינו צפוי להיות תמיד שווה לערך המצופה.", "code_snippet": null, "options": null}, {"id": "8.2", "text": "תקן את הקוד המקורי כך שיפעל באופן תקין ויבטיח שכל הקידומים יבוצעו כראוי, כלומר, ערך המונה הסופי יהיה תמיד שווה לערך המצופה. השתמש במנעול (mutex) לצורך הסנכרון. ציין אילו שורות קוד הוספת/שינית ומה תפקידן.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "8.1: הבעיה בקוד הנתון היא \"מצב מרוץ\" (Race Condition). הפעולה `counter++` אינה אטומית, אלא מורכבת משלוש פעולות בסיסיות: קריאת ערך המונה מהזיכרון, הגדלתו באחד, וכתיבת הערך החדש בחזרה לזיכרון. כאשר מספר חוטים מריצים פעולה זו במקביל ללא סנכרון, ייתכן שחוט אחד יקרא את ערך המונה, וטרם יספיק לכתוב את הערך המוגדל, יתזמן המעבד חוט אחר שיקרא גם הוא את אותו ערך ישן. כתוצאה מכך, שני החוטים יבצעו הגדלה אך ערך המונה יוגדל פעם אחת בלבד, וקידומים ילכו לאיבוד. לכן, ערך המונה הסופי יהיה בדרך כלל נמוך מהערך המצופה (NUM_THREADS * INCREMENTS_PER_THREAD).\n\n8.2: כדי לתקן את הבעיה, יש להגן על הגישה למשתנה המשותף `counter` באמצעות מנעול (mutex). יש להכריז על מנעול גלובלי, לאתחל אותו, ולנעול ולשחרר אותו סביב הקטע הקריטי (הגדלת המונה).\n\nהקוד המתוקן ייראה כך:\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n#include <stdlib.h>\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 100000\n\nint counter = 0;\npthread_mutex_t counter_mutex; // שורה חדשה: הכרזה על מנעול\n\nvoid* increment_counter(void* arg) {\n  for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n    pthread_mutex_lock(&counter_mutex);   // שורה חדשה: נעילת המוטקס לפני הגישה לקטע הקריטי\n    counter++;\n    pthread_mutex_unlock(&counter_mutex); // שורה חדשה: שחרור המוטקס לאחר הגישה לקטע הקריטי\n  }\n  return NULL;\n}\n\nint main() {\n  pthread_t threads[NUM_THREADS];\n\n  pthread_mutex_init(&counter_mutex, NULL); // שורה חדשה: אתחול המנעול\n\n  for (int i = 0; i < NUM_THREADS; ++i) {\n    if (pthread_create(&threads[i], NULL, increment_counter, NULL) != 0) {\n      perror(\"Failed to create thread\");\n      return 1;\n    }\n  }\n\n  for (int i = 0; i < NUM_THREADS; ++i) {\n    if (pthread_join(threads[i], NULL) != 0) {\n      perror(\"Failed to join thread\");\n      return 1;\n    }\n  }\n\n  printf(\"Final counter value: %d\\n\", counter);\n  printf(\"Expected counter value: %d\\n\", NUM_THREADS * INCREMENTS_PER_THREAD);\n\n  pthread_mutex_destroy(&counter_mutex); // שורה חדשה: השמדת המנעול\n\n  return 0;\n}\n```\n\n**הסבר לשינויים:**\n1.  **`pthread_mutex_t counter_mutex;`**: הוספנו משתנה גלובלי מסוג `pthread_mutex_t` כדי לייצג את המנעול שיגן על המונה. (שורה 7 בקוד המתוקן)\n2.  **`pthread_mutex_init(&counter_mutex, NULL);`**: אתחלנו את המנעול בתחילת פונקציית `main`. (שורה 22 בקוד המתוקן)\n3.  **`pthread_mutex_lock(&counter_mutex);`**: לפני הגישה למשתנה `counter` בתוך הלולאה בפונקציה `increment_counter`, אנו נועלים את המוטקס. זה מבטיח שרק חוט אחד יכול להיכנס לקטע קריטי זה בכל רגע נתון. (שורה 10 בקוד המתוקן)\n4.  **`pthread_mutex_unlock(&counter_mutex);`**: לאחר שחרור הגישה למשתנה `counter` בתוך הלולאה, אנו משחררים את המוטקס, ומאפשרים לחוטים אחרים להיכנס לקטע הקריטי. (שורה 12 בקוד המתוקן)\n5.  **`pthread_mutex_destroy(&counter_mutex);`**: השמדנו את המנעול בסוף פונקציית `main` כדי לשחרר את המשאבים שהוקצו לו. (שורה 36 בקוד המתוקן)\n\nשינויים אלה מבטיחים שהפעולה `counter++` תתבצע באופן אטומי עבור כל חוט, ומונעים את מצב המרוץ, כך שערך המונה הסופי יהיה תמיד נכון."}, "difficulty_estimation": "Easy", "_source_file": "0195__Synchronization__CodeAnalysis__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:58:42", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Synchronization", "Mutex", "Race Conditions"], "content": {"text": "לפניכם תוכנית בשפת C המשתמשת בשני חוטים (threads) ובסנכרון מסוג מוטקס (mutex) כדי לקדם מונה משותף. עיינו בקוד וענו על הסעיפים הבאים:", "code_snippet": "1  #include <pthread.h>\n2  #include <stdio.h>\n3  \n4  int counter = 0;\n5  pthread_mutex_t mtx;\n6  \n7  void* func(void* arg) {\n8      for (int i = 0; i < 1000; i++) {\n9          pthread_mutex_lock(&mtx);\n10         counter++;\n11         pthread_mutex_unlock(&mtx);\n12     }\n13     return NULL;\n14 }\n15 \n16 int main() {\n17     pthread_t t1, t2;\n18     pthread_mutex_init(&mtx, NULL);\n19     pthread_create(&t1, NULL, func, NULL);\n20     pthread_create(&t2, NULL, func, NULL);\n21     pthread_join(t1, NULL);\n22     pthread_join(t2, NULL);\n23     printf(\"counter = %d\\n\", counter);\n24     pthread_mutex_destroy(&mtx);\n25     return 0;\n26 }", "options": null}, "sub_questions": [{"id": "10.1", "text": "מהו הערך המדויק שיודפס על המסך בסיום ריצת התוכנית?", "code_snippet": null, "options": null}, {"id": "10.2", "text": "נניח כי מחקנו את שורות 9 ו-11 מהקוד (הקריאות ל-lock ול-unlock). מהו הערך המקסימלי שייתכן ויודפס כעת? האם מובטח שהערך יהיה זהה בכל הרצה? הסבירו בקצרה.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: הערך שיודפס הוא 2000. השימוש במוטקס מבטיח שרק חוט אחד יוכל לבצע את פעולת הקידום (שורה 10) בכל רגע נתון. מכיוון שכל אחד משני החוטים מבצע 1000 קידומים, והסנכרון מונע איבוד עדכונים, התוצאה הסופית היא 2000.\n\n10.2: הערך המקסימלי שייתכן ויודפס הוא 2000 (במקרה שבו התזמון במקרה מנע חפיפה בין החוטים). לא, הערך אינו מובטח להיות זהה בכל הרצה. ללא המוטקס, הפעולה counter++ אינה אטומית (היא מורכבת מקריאה, הוספה וכתיבה), ונוצר מצב מרוץ (Race Condition). חוטים עלולים לקרוא את אותו ערך ישן ולדרוס זה את העדכון של זה, מה שיוביל לערך סופי נמוך מ-2000 (הערך המינימלי התיאורטי הוא 2)."}, "difficulty_estimation": "Easy", "_source_file": "0196__Synchronization__CodeAnalysis__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:59:09", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Synchronization", "Race Conditions", "Mutexes", "Threads"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בחוטים (threads) לקידום מונה גלובלי משותף. קמפלו והריצו את התוכנית. ניתן להניח שכל קריאות המערכת הצליחו.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#define NUM_THREADS 5\n#define ITERATIONS_PER_THREAD 100000\n\nint counter = 0;\n\nvoid* thread_func(void* arg) {\n    for (int i = 0; i < ITERATIONS_PER_THREAD; ++i) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "מהו הערך הסופי של המונה (counter) שיוצג בפלט התוכנית? נמקו את תשובתכם והסבירו מדוע יתכן שהערך לא יהיה כמצופה.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "תקנו את התוכנית כך שהמונה יתקדם באופן נכון, כלומר, הערך הסופי שלו יהיה תמיד כמצופה (NUM_THREADS * ITERATIONS_PER_THREAD). השתמשו במנגנון סנכרון מתאים (לדוגמה, mutex). יש לכתוב רק את השינויים הנדרשים בקוד (הוספה/שינוי של משתנים גלובליים, קוד בפונקציה thread_func ובפונקציה main).", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: הערך הסופי של המונה יהיה בדרך כלל קטן מ- NUM_THREADS * ITERATIONS_PER_THREAD (כלומר, קטן מ- 500,000 במקרה זה). הסיבה לכך היא תופעת מרוץ (race condition). פעולת `counter++` אינה אטומית; היא מורכבת משלוש פעולות בסיסיות: קריאת ערך המונה לתוך רגיסטר, הגדלת הערך ברגיסטר, וכתיבת הערך המוגדל חזרה לזיכרון. כאשר מספר חוטים מנסים לבצע פעולה זו במקביל, ייתכן שחוט אחד יקרא את ערך המונה, יופסק לפני הכתיבה, וחוט אחר יבצע את כל פעולת הקידום. כאשר החוט הראשון יחזור לרוץ, הוא יכתוב את הערך שקרא בתחילה ועוד 1, ובכך 'ידרוס' את הקידום שבוצע על ידי החוט השני. זה מוביל לאיבוד עדכונים ולערך סופי נמוך מהצפוי.\n\n10.2: כדי לתקן את בעיית המרוץ, נשתמש במנעול הדדי (mutex) כדי להגן על הקטע הקריטי (הפעולה `counter++`).\n\nשינויים נדרשים בקוד:\n\nהוספת משתנה גלובלי למנעול:\n`pthread_mutex_t mutex;`\n\nבפונקציה `main`:\nאתחול המנעול לפני יצירת החוטים:\n`pthread_mutex_init(&mutex, NULL);`\nשחרור המנעול לאחר סיום החוטים:\n`pthread_mutex_destroy(&mutex);`\n\nבפונקציה `thread_func`:\nנעילת המנעול לפני הגישה למשתנה המשותף ושחרורו מיד לאחר מכן:\n```c\nvoid* thread_func(void* arg) {\n    for (int i = 0; i < ITERATIONS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&mutex);\n        counter++;\n        pthread_mutex_unlock(&mutex);\n    }\n    return NULL;\n}\n```\nקוד מלא מתוקן:\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#define NUM_THREADS 5\n#define ITERATIONS_PER_THREAD 100000\n\nint counter = 0;\npthread_mutex_t mutex;\n\nvoid* thread_func(void* arg) {\n    for (int i = 0; i < ITERATIONS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&mutex);\n        counter++;\n        pthread_mutex_unlock(&mutex);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    pthread_mutex_init(&mutex, NULL);\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    pthread_mutex_destroy(&mutex);\n    return 0;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0197__Synchronization__CodeAnalysis__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:59:07", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Synchronization", "Mutex", "Race Conditions", "Threads"], "content": {"text": "נתון קוד ה-C הבא המשתמש בספריית pthreads. התוכנית מגדירה משתנה גלובלי counter ויוצרת שני חוטים המריצים את הפונקציה increment המקדמת את המונה 1000 פעמים.", "code_snippet": "1 #include <pthread.h>\n2 #include <stdio.h>\n3 \n4 int counter = 0;\n5 pthread_mutex_t lock;\n6 \n7 void* increment(void* arg) {\n8     for (int i = 0; i < 1000; i++) {\n9         pthread_mutex_lock(&lock);\n10        counter++;\n11        pthread_mutex_unlock(&lock);\n12    }\n13    return NULL;\n14 }\n15 \n16 int main() {\n17     pthread_t t1, t2;\n18     pthread_mutex_init(&lock, NULL);\n19     pthread_create(&t1, NULL, increment, NULL);\n20     pthread_create(&t2, NULL, increment, NULL);\n21     pthread_join(t1, NULL);\n22     pthread_join(t2, NULL);\n23     printf(\"%d\\n\", counter);\n24     return 0;\n25 }", "options": null}, "sub_questions": [{"id": "1.1", "text": "מה יהיה הערך המודפס של counter בסיום ריצת התוכנית כפי שהיא?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "נניח שהסרנו את השורות המבצעות נעילה ושחרור של המיוטקס (שורות 9 ו-11). מהו הערך המקסימלי והערך המינימלי האפשריים של counter שיודפסו בסיום הריצה?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: הערך שיודפס הוא 2000. השימוש ב-Mutex בשורות 9 ו-11 מבטיח שרק חוט אחד יוכל לגשת למשתנה המשותף counter בכל רגע נתון. מכיוון שכל חוט מבצע 1000 קידומים, והקידומים מוגנים מפני מרוץ תהליכים, התוצאה הסופית היא 1000 + 1000 = 2000.\n\n1.2: הערך המקסימלי הוא 2000 (במקרה שבו התזמון במקרה מנע התנגשויות). הערך המינימלי הוא 2. הסבר לערך המינימלי: חוט א' קורא את הערך 0 ונעצר לפני הקידום. חוט ב' רץ 999 פעמים ומעדכן את המונה ל-999. חוט א' ממשיך, כותב 1 למונה, ואז קורא את הערך 1 עבור האיטרציה השנייה שלו ונעצר. חוט ב' ממשיך לאיטרציה האחרונה שלו, קורא את הערך 1, וממתין לפני הכתיבה. חוט א' רץ כעת את כל שאר 998 האיטרציות שלו ומסיים (הערך במונה כעת 999). לבסוף חוט ב' חוזר וכותב את הערך 2 (הערך 1 שקרא + 1) למונה."}, "difficulty_estimation": "Easy", "_source_file": "0198__Synchronization__CodeAnalysis__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:59:40", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Synchronization", "Threads", "Mutex"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בחוטים (threads) לקידום מונה משותף באמצעות מנגנון סנכרון. עליכם לנתח את הקוד ולענות על השאלה: מה יהיה הערך הסופי של המונה (counter) שיוצג בפלט?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 10\n\nint counter = 0;\npthread_mutex_t mutex;\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&mutex);\n        counter++;\n        pthread_mutex_unlock(&mutex);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    pthread_mutex_init(&mutex, NULL);\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, increment_counter, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    pthread_mutex_destroy(&mutex);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הערך הסופי שיוצג בפלט יהיה 50. ישנם 5 חוטים (NUM_THREADS=5), וכל חוט מגדיל את המונה 10 פעמים (INCREMENTS_PER_THREAD=10). סך הכל יתבצעו 5 * 10 = 50 פעולות הגדלה. השימוש ב-mutex מבטיח שכל פעולת הגדלה של המונה תהיה אטומית, כלומר, לא יהיו מצבי מרוץ (race conditions) שבהם עדכונים אובדים. כל חוט נועל את ה-mutex לפני הגישה למונה, מבצע את ההגדלה, ומשחרר את ה-mutex, ובכך מבטיח גישה בלעדית למשאב המשותף. לכן, כל 50 ההגדלות יבוצעו בהצלחה והמונה יגיע לערכו הסופי הנכון."}, "difficulty_estimation": "Easy", "_source_file": "0199__Synchronization__CodeAnalysis__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:59:17", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Synchronization", "Threads", "Race Conditions", "Mutex"], "content": {"text": "נתונה התוכנית הבאה, המשתמשת במספר חוטים כדי להגדיל מונה משותף. קבוע N מייצג את מספר הפעמים שכל חוט יגדיל את המונה, וקבוע T מייצג את מספר החוטים. ניתן להניח שכל קריאות המערכת הצליחו.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\n#define T 4 // מספר חוטים\n#define N 100000 // מספר הגדלות לכל חוט\n\nint counter = 0;\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < N; ++i) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[T];\n\n    for (int i = 0; i < T; ++i) {\n        pthread_create(&threads[i], NULL, increment_counter, NULL);\n    }\n\n    for (int i = 0; i < T; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "101.1", "text": "מהו טווח הערכים האפשריים (מינימום ומקסימום) שיודפס עבור counter בסוף ריצת התוכנית? הסבירו מדוע.", "code_snippet": null, "options": null}, {"id": "101.2", "text": "תקנו את הקוד הנתון כך שהתוכנית תדפיס תמיד את הערך הנכון (T*N). השתמשו ב-mutexים בלבד. צרפו את הקוד המתוקן והסבירו בקצרה את השינויים.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "101.1: טווח הערכים האפשרי הוא בין N ל- T*N (כולל קצוות). ערך מקסימלי: T*N. זה יקרה אם, במקרה, אף פעם לא יתרחש מצב מרוץ והפעולות על המונה יהיו אטומיות למעשה, כלומר כל הגדלה של המונה תתבצע במלואה לפני שחוט אחר ינסה לגשת אליו. ערך מינימלי: N. זה יקרה עקב מצבי מרוץ (Race Conditions). פעולת 'counter++' אינה אטומית, והיא מתורגמת לקריאה של הערך, הגדלתו, וכתיבתו בחזרה. אם שני חוטים קוראים את אותו ערך של counter בו-זמנית, שניהם יגדילו אותו ויכתבו אותו בחזרה, מה שיגרום לאחת ההגדלות 'להיעלם' או להידרס. במקרה הקיצוני ביותר, כל החוטים (למעט אולי אחד שסיים את כל הגדלותיו) יאבדו את רוב ההגדלות שלהם, ורק N הגדלות (של חוט בודד שסיים את כל פעולותיו) או קצת יותר מזה ישארו במונה הסופי.\n\n101.2: כדי לתקן את מצב המרוץ ולהבטיח שהמונה יגיע תמיד לערך T*N, יש להשתמש ב-mutex כדי להגן על הגישה למשתנה counter. הנה הקוד המתוקן:\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n\n#define T 4 // מספר חוטים\n#define N 100000 // מספר הגדלות לכל חוט\n\nint counter = 0;\npthread_mutex_t mutex; // הגדרת mutex גלובלי\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < N; ++i) {\n        pthread_mutex_lock(&mutex);   // נעילת mutex לפני גישה למונה\n        counter++;\n        pthread_mutex_unlock(&mutex); // שחרור mutex לאחר הגישה למונה\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[T];\n\n    pthread_mutex_init(&mutex, NULL); // אתחול ה-mutex\n\n    for (int i = 0; i < T; ++i) {\n        pthread_create(&threads[i], NULL, increment_counter, NULL);\n    }\n\n    for (int i = 0; i < T; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    pthread_mutex_destroy(&mutex); // השמדת ה-mutex\n\n    return 0;\n}\n```\n\nהשינויים כוללים: (1) הגדרת משתנה `pthread_mutex_t mutex` גלובלי. (2) אתחול ה-mutex באמצעות `pthread_mutex_init` בפונקציה `main`. (3) עטיפת פעולת ההגדלה `counter++` בקריאות `pthread_mutex_lock` ו-`pthread_mutex_unlock` בתוך פונקציית `increment_counter`, מה שמבטיח שרק חוט אחד יוכל לבצע את הפעולה הזו בכל רגע נתון. (4) השמדת ה-mutex באמצעות `pthread_mutex_destroy` בסוף פונקציית `main`."}, "difficulty_estimation": "Easy", "_source_file": "0200__Synchronization__CodeAnalysis__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:59:39", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Synchronization", "Threads", "Race Conditions", "Mutexes"], "content": {"text": "נתונה תוכנית ה-C הבאה המשתמשת בתהליכונים (threads):\nהתוכנית יוצרת שני תהליכונים, כאשר כל אחד מהם מגדיל מונה גלובלי (counter) 100,000 פעמים. קראו את הקוד וענו על השאלות הבאות:\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0;\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < 100000; ++i) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_create(&tid1, NULL, increment_counter, NULL);\n    pthread_create(&tid2, NULL, increment_counter, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}\n```\n\n1. מהו הערך הסופי ה_צפוי_ של המשתנה `counter` לאחר ששני התהליכונים סיימו את פעולתם? נמק.\n2. האם הערך ה_מודפס_ בפועל יהיה תמיד זהה לערך הצפוי? אם לא, הסבר מדוע ומהי הבעיה המרכזית כאן.\n3. שנה את הקוד הנתון כך שיבטיח שהערך המודפס יהיה תמיד נכון (כלומר, שווה לערך הצפוי). הצג את הקוד המתוקן והסבר את השינויים שביצעת.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. **ערך צפוי:** כל תהליכון מגדיל את המונה 100,000 פעמים. מכיוון שיש שני תהליכונים, סך כל ההגדלות הוא 2 * 100,000 = 200,000. לכן, הערך הצפוי של `counter` הוא 200,000.\n2. **ערך מודפס בפועל והבעיה:** הערך המודפס בפועל _לא_ יהיה תמיד זהה לערך הצפוי. הבעיה המרכזית כאן היא **תנאי מירוץ (Race Condition)**. הפעולה `counter++` אינה אטומית. היא מורכבת משלוש פעולות ברמה נמוכה יותר:\n    *   קריאת הערך הנוכחי של `counter` לתוך אוגר.\n    *   הגדלת הערך באוגר באחד.\n    *   כתיבת הערך המעודכן מהאוגר חזרה לזיכרון של `counter`.\n    כאשר שני תהליכונים מנסים לבצע את הפעולה הזו בו-זמנית, ייתכן ששניהם יקראו את אותו ערך של `counter` לפני שאחד מהם הספיק לכתוב את הערך המעודכן בחזרה. לדוגמה, אם `counter` הוא 100:\n    *   תהליכון A קורא 100.\n    *   תהליכון B קורא 100.\n    *   תהליכון A מגדיל ל-101 וכותב 101.\n    *   תהליכון B מגדיל ל-101 (מתוך הערך שקרא קודם) וכותב 101.\n    במקרה זה, למרות שבוצעו שתי הגדלות, המונה גדל רק באחד. כתוצאה מכך, הערך הסופי יהיה נמוך מ-200,000.\n3. **קוד מתוקן עם מנגנוני סנכרון:**\n    כדי לפתור את תנאי המירוץ ולהבטיח שהגידול של `counter` יהיה אטומי, נשתמש במנעול (mutex) מסוג `pthread_mutex_t`.\n    הקוד המתוקן:\n    ```c\n    #include <stdio.h>\n    #include <pthread.h>\n\n    int counter = 0;\n    pthread_mutex_t mutex; // הצהרה על מנעול\n\n    void* increment_counter(void* arg) {\n        for (int i = 0; i < 100000; ++i) {\n            pthread_mutex_lock(&mutex);   // נעל את המנעול לפני גישה למשתנה המשותף\n            counter++;\n            pthread_mutex_unlock(&mutex); // שחרר את המנעול לאחר הגישה\n        }\n        return NULL;\n    }\n\n    int main() {\n        pthread_t tid1, tid2;\n\n        pthread_mutex_init(&mutex, NULL); // אתחל את המנעול\n\n        pthread_create(&tid1, NULL, increment_counter, NULL);\n        pthread_create(&tid2, NULL, increment_counter, NULL);\n\n        pthread_join(tid1, NULL);\n        pthread_join(tid2, NULL);\n\n        printf(\"Final counter value: %d\\n\", counter);\n\n        pthread_mutex_destroy(&mutex); // שחרר משאבי מנעול\n        return 0;\n    }\n    ```\n    **הסבר לשינויים:**\n    *   **`pthread_mutex_t mutex;`**: הוספנו הצהרה על משתנה מטיפוס `pthread_mutex_t` שישמש כמנעול.\n    *   **`pthread_mutex_init(&mutex, NULL);`**: בתוך פונקציית `main`, אתחלנו את המנעול לפני יצירת התהליכונים.\n    *   **`pthread_mutex_lock(&mutex);`**: לפני הפעולה `counter++` בקטע הקריטי (critical section) בתוך `increment_counter`, קראנו לפונקציה זו כדי לנעול את המנעול. רק תהליכון אחד יכול להחזיק במנעול בכל רגע נתון.\n    *   **`pthread_mutex_unlock(&mutex);`**: מיד לאחר הפעולה `counter++`, שחררנו את המנעול. זה מאפשר לתהליכונים אחרים לנסות לנעול אותו.\n    *   **`pthread_mutex_destroy(&mutex);`**: בסיום התוכנית, לאחר ששני התהליכונים סיימו והצטרפו חזרה ל-`main`, שחררנו את משאבי המנעול.\n    שינויים אלה מבטיחים שרק תהליכון אחד יגדיל את `counter` בכל רגע נתון, ובכך מונעים את תנאי המירוץ ומבטיחים שהערך הסופי יהיה 200,000."}, "difficulty_estimation": "Medium", "_source_file": "0201__Synchronization__CodeAnalysis__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:00:02", "_subject": "Concurrency"}, {"id": 7, "type": "CodeAnalysis", "topic": ["Synchronization", "Deadlock", "Mutexes", "Pthreads"], "content": {"text": "נתונה התוכנית הבאה, המשתמשת ב-pthreads ובמנעולים (mutexes) כדי לגשת למשאבים משותפים:\n\n", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex1 = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_t mutex2 = PTHREAD_MUTEX_INITIALIZER;\n\nint resource1 = 0;\nint resource2 = 0;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 1: Locked mutex1. Trying to lock mutex2...\\n\");\n    sleep(1); \n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 1: Locked mutex2. Accessing resources.\\n\");\n\n    resource1++;\n    resource2++;\n\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 1: Unlocked mutex2.\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 1: Unlocked mutex1. Exiting.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to lock mutex2...\\n\");\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2: Locked mutex2. Trying to lock mutex1...\\n\");\n    sleep(1); \n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2: Locked mutex1. Accessing resources.\\n\");\n\n    resource1--;\n    resource2--;\n\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 2: Unlocked mutex1.\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2: Unlocked mutex2. Exiting.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_create(&tid1, NULL, thread_func1, NULL);\n    pthread_create(&tid2, NULL, thread_func2, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    printf(\"Main: Final resource1 = %d, resource2 = %d\\n\", resource1, resource2);\n\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n\n    return 0;\n}"}, "sub_questions": [{"id": "7.1", "text": "האם קיים פוטנציאל למצב של קיפאון (Deadlock) בתוכנית זו? אם כן, הסבר מדוע וציין את התנאים ההכרחיים לקיפאון שמתקיימים כאן. אם לא, הסבר מדוע.", "code_snippet": null, "options": null}, {"id": "7.2", "text": "בהנחה שהתוכנית רצה ללא קיפאון ומסיימת את ריצתה בהצלחה, מה יהיו הערכים הסופיים של המשתנים resource1 ו-resource2 בסיום ריצת התוכנית?", "code_snippet": null, "options": null}, {"id": "7.3", "text": "כיצד ניתן למנוע קיפאון בתוכנית זו על ידי שינוי מינימלי בקוד, תוך שמירה על הפונקציונליות המקורית של גישה למשאבים? ציין את השינוי הספציפי ואת ההיגיון מאחוריו.", "code_snippet": null, "options": null}], "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\nא. כן, קיים פוטנציאל למצב של קיפאון (Deadlock) בתוכנית זו.\nההסבר: קיפאון יכול להתרחש כאשר Thread 1 רוכש את mutex1 ולאחר מכן מנסה לרכוש את mutex2, ובמקביל Thread 2 רוכש את mutex2 ולאחר מכן מנסה לרכוש את mutex1. אם התזמון של ריצת התהליכונים מאפשר לכל אחד מהם לרכוש את המנעול הראשון שלו לפני שהשני רכש את שניהם, שניהם יכנסו למצב המתנה אינסופי זה לזה.\nהתנאים ההכרחיים לקיפאון שמתקיימים כאן הם (תנאי קופמן):\n1.  **הדדיות (Mutual Exclusion)**: המנעולים (mutexes) מבטיחים שרק תהליכון אחד יכול להחזיק במשאב (מנעול) בכל רגע נתון.\n2.  **החזק והמתן (Hold and Wait)**: כל תהליכון מחזיק במנעול אחד (לדוגמה, Thread 1 מחזיק ב-mutex1) וממתין למנעול נוסף (mutex2).\n3.  **אי-הפקעה (No Preemption)**: לא ניתן להפקיע מנעול מתהליכון שמחזיק בו; המנעול ישוחרר רק מרצון על ידי התהליכון המחזיק בו.\n4.  **המתנה מעגלית (Circular Wait)**: נוצרת שרשרת המתנה מעגלית: Thread 1 ממתין ל-mutex2 שמוחזק על ידי Thread 2, ו-Thread 2 ממתין ל-mutex1 שמוחזק על ידי Thread 1.\nהקריאות ל-sleep(1) מגבירות את הסיכוי לתזמון שיגרום לקיפאון.\n\nב. בהנחה שהתוכנית רצה ללא קיפאון ומסיימת את ריצתה בהצלחה, שני התהליכונים יבצעו את פעולותיהם באופן מלא.\n*   Thread 1 מגדיל את resource1 ואת resource2 באחד (resource1 = 1, resource2 = 1).\n*   Thread 2 מקטין את resource1 ואת resource2 באחד (resource1 = 0, resource2 = 0).\nלכן, הערכים הסופיים יהיו:\nresource1 = 0\nresource2 = 0\n\nג. ניתן למנוע קיפאון על ידי שבירת תנאי 'המתנה מעגלית' (Circular Wait) באמצעות קביעת סדר קבוע לרכישת המנעולים. השינוי המינימלי ביותר הוא לגרום לשני התהליכונים לרכוש את המנעולים באותו הסדר. לדוגמה, שניהם ירכשו תמיד את mutex1 ואז את mutex2.\n\nשינוי מוצע בקוד (בפונקציה thread_func2 בלבד):\n```c\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1); // שינוי כאן: קודם mutex1\n    printf(\"Thread 2: Locked mutex1. Trying to lock mutex2...\\n\");\n    sleep(1); \n    pthread_mutex_lock(&mutex2); // ואז mutex2\n    printf(\"Thread 2: Locked mutex2. Accessing resources.\\n\");\n\n    resource1--;\n    resource2--;\n\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2: Unlocked mutex2.\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 2: Unlocked mutex1. Exiting.\\n\");\n    return NULL;\n}\n```\nההיגיון מאחורי השינוי: כאשר כל התהליכונים רוכשים את המנעולים באותו סדר (לדוגמה, תמיד mutex1 ואז mutex2), לא יכולה להיווצר המתנה מעגלית. אם תהליכון אחד מחזיק ב-mutex1 וממתין ל-mutex2, אף תהליכון אחר לא יכול להחזיק ב-mutex2 ולחכות ל-mutex1, מכיוון שהוא היה צריך לרכוש קודם את mutex1 (שכבר מוחזק). זה מבטיח שאם יתרחש חסימה, היא תהיה ליניארית ולא מעגלית, ובסופו של דבר אחד מהתהליכונים יתקדם וישחרר את המשאבים."}, "difficulty_estimation": "Medium", "_source_file": "0202__Synchronization__CodeAnalysis__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:42:50", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Synchronization", "Producer-Consumer", "Mutex", "Condition Variables"], "content": {"text": "נתונה תוכנית C הבאה המשתמשת ב-pthreads, mutexes, ו-condition variables. התוכנית מדמה תהליך יצרן-צרכן עם משאב משותף (מונה `count`) וגודל חיץ מוגבל (`MAX_COUNT`).\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n#include <unistd.h> // For usleep\n\n#define MAX_COUNT 5\n#define NUM_OPERATIONS 10\n\nint count = 0;\npthread_mutex_t mutex;\npthread_cond_t cond_producer; // Condition for producer to wait if buffer is full\npthread_cond_t cond_consumer; // Condition for consumer to wait if buffer is empty\n\nvoid* producer(void* arg) {\n    for (int i = 0; i < NUM_OPERATIONS; ++i) {\n        pthread_mutex_lock(&mutex);\n        while (count == MAX_COUNT) {\n            printf(\"Producer waiting (count=%d)...\\n\", count);\n            pthread_cond_wait(&cond_producer, &mutex);\n        }\n        count++;\n        printf(\"Producer: count = %d\\n\", count);\n        pthread_cond_signal(&cond_consumer);\n        pthread_mutex_unlock(&mutex);\n        usleep(100000); // Simulate work\n    }\n    return NULL;\n}\n\nvoid* consumer(void* arg) {\n    for (int i = 0; i < NUM_OPERATIONS; ++i) {\n        pthread_mutex_lock(&mutex);\n        while (count == 0) {\n            printf(\"Consumer waiting (count=%d)...\\n\", count);\n            pthread_cond_wait(&cond_consumer, &mutex);\n        }\n        count--;\n        printf(\"Consumer: count = %d\\n\", count);\n        pthread_cond_signal(&cond_producer);\n        pthread_mutex_unlock(&mutex);\n        usleep(150000); // Simulate work\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t prod_tid, cons_tid;\n\n    pthread_mutex_init(&mutex, NULL);\n    pthread_cond_init(&cond_producer, NULL);\n    pthread_cond_init(&cond_consumer, NULL);\n\n    pthread_create(&prod_tid, NULL, producer, NULL);\n    pthread_create(&cons_tid, NULL, consumer, NULL);\n\n    pthread_join(prod_tid, NULL);\n    pthread_join(cons_tid, NULL);\n\n    printf(\"Final count value: %d\\n\", count);\n\n    pthread_mutex_destroy(&mutex);\n    pthread_cond_destroy(&cond_producer);\n    pthread_cond_destroy(&cond_consumer);\n\n    return 0;\n}\n```\n\nבהתבסס על התוכנית הנתונה:\n1.  מה יהיה הערך הסופי של המשתנה `count` המודפס על ידי התוכנית הראשית (`main`)? נמקו את תשובתכם.\n2.  תארו את אופי הפלט שיופק על ידי התוכנית, והסבירו מדוע הוא כך. (האם הוא דטרמיניסטי? אילו ערכים יכולים להופיע? מה היחס ביניהם?)\n3.  האם קיימת בתוכנית סכנה למצב קיפאון (Deadlock)? נמקו את תשובתכם.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  **ערך סופי של `count`:**\n    הערך הסופי של `count` יהיה 0.\n    **נימוק:**\n    *   גם תהליכון היצרן וגם תהליכון הצרכן מבצעים `NUM_OPERATIONS` פעולות, שכל אחת מהן מגדילה או מקטינה את `count` באחד.\n    *   היצרן מבצע 10 הגדלות (`count++`).\n    *   הצרכן מבצע 10 הקטנות (`count--`).\n    *   הפעולות מוגנות על ידי mutex ומתואמות באמצעות condition variables כך ש-`count` לעולם לא יעבור את `MAX_COUNT` (5) או ירד מתחת ל-0.\n    *   השפעה נטו על `count` היא `10 - 10 = 0`. מכיוון ש-`count` מתחיל מ-0, הוא יחזור ל-0 בסיום כל הפעולות.\n\n2.  **אופי הפלט:**\n    הפלט לא יהיה דטרמיניסטי מבחינת סדר ההודעות \"Producer: count = X\" ו-\"Consumer: count = Y\", אך הוא יהיה דטרמיניסטי מבחינת רצף הערכים הלוגי.\n    *   **אי-דטרמיניסטיות**: סדר ההרצה של תהליכונים תלוי בתזמן מערכת ההפעלה, ולכן סדר ההדפסות מהיצרן והצרכן ישתנה בין הרצות שונות (בנוסף לשימוש ב-`usleep` שמשפיע על התזמון).\n    *   **דטרמיניסטיות לוגית**: \n        *   הודעות \"Producer: count = X\" יציגו ערכים של `count` בין 1 ל-`MAX_COUNT` (כלומר, 1 עד 5).\n        *   הודעות \"Consumer: count = Y\" יציגו ערכים של `count` בין 0 ל-`MAX_COUNT - 1` (כלומר, 0 עד 4).\n        *   כל הדפסה של היצרן תגדיל את `count` באחד, וכל הדפסה של הצרכן תקטין את `count` באחד.\n        *   הודעות \"Producer waiting...\" יופיעו כאשר `count` מגיע ל-`MAX_COUNT` (5) והיצרן מנסה להגדיל אותו שוב, אך נאלץ להמתין שהצרכן יפנה מקום.\n        *   הודעות \"Consumer waiting...\" יופיעו כאשר `count` מגיע ל-0 והצרכן מנסה להקטין אותו שוב, אך נאלץ להמתין שהיצרן ייצר פריט.\n        *   כל הדפסה מתרחשת בתוך critical section (לאחר נעילת ה-mutex), כך שהערך המודפס של `count` יהיה תמיד עקבי לרגע ההדפסה.\n\n3.  **סכנה למצב קיפאון (Deadlock):**\n    לא, לא קיימת סכנה למצב קיפאון (deadlock) בתוכנית זו.\n    **נימוק:**\n    *   נעילת ה-mutex מתבצעת תמיד לפני כניסה לאזור הקריטי ושחרורו מתבצע תמיד לאחר היציאה ממנו. אין מצב של החזקה ב-mutex אחד וניסיון לנעול mutex אחר.\n    *   התהליכונים ממתינים על condition variables (באמצעות `pthread_cond_wait`) אך עושים זאת תוך שחרור אוטומטי של ה-mutex וחזרה לנעול אותו עם קבלת האות. זה מונע מצב שבו תהליכון אחד מחזיק ב-mutex וממתין לאירוע שתהליכון אחר צריך את אותו mutex כדי לייצר/לצרוך, ובכך לא יאפשר לו להתקדם.\n    *   השימוש בלולאות `while` סביב `pthread_cond_wait` הוא הדרך הנכונה לטפל ב-spurious wakeups ומבטיח שהתהליכון ימשיך רק כאשר התנאי באמת מתקיים, מבלי להכניס באג לוגי או deadlock.\n    *   קיים רק mutex אחד וזוג condition variables, וכל תהליכון משתמש בהם בסדר הגיוני: נועל mutex, בודק תנאי, ממתין אם צריך (משחרר mutex), מבצע פעולה, מאותת, ומשחרר mutex. אין פקודות נעילה מרובות בסדר שונה שיכול להוביל ל-deadlock."}, "difficulty_estimation": "Medium", "_source_file": "0203__Synchronization__CodeAnalysis__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:01:06", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Threads"], "content": {"text": "לפניכם קטע קוד המשתמש בסמפורים לתיאום בין שני חוטים (threads). מה יהיה הפלט של התוכנית בהנחה שכל קריאות המערכת מצליחות והחוטים מסיימים את ריצתם כסדרם?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n\nsem_t s1, s2;\nint count = 0;\n\nvoid* threadA(void* arg) {\n    for(int i = 0; i < 2; i++) {\n        sem_wait(&s1);\n        printf(\"A\");\n        count++;\n        sem_post(&s2);\n    }\n    return NULL;\n}\n\nvoid* threadB(void* arg) {\n    for(int i = 0; i < 2; i++) {\n        sem_wait(&s2);\n        printf(\"B\");\n        count++;\n        sem_post(&s1);\n    }\n    return NULL;\n}\n\nint main() {\n    sem_init(&s1, 0, 1);\n    sem_init(&s2, 0, 0);\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, threadA, NULL);\n    pthread_create(&t2, NULL, threadB, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"%d\", count);\n    return 0;\n}", "options": ["א. ABAB4", "ב. BABA4", "ג. AABB4", "ד. התוכנית תיכנס למצב של Deadlock", "ה. ABAB2"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "הסמפור s1 מאותחל ל-1 והסמפור s2 מאותחל ל-0. חוט A הוא היחיד שיכול להתחיל את הלולאה שלו כי sem_wait(&s1) יצליח מיד. חוט A מדפיס 'A', מעלה את count ל-1, ומבצע sem_post(&s2). כעת הערך של s2 הוא 1, מה שמאפשר לחוט B לבצע sem_wait(&s2), להדפיס 'B', להעלות את count ל-2 ולבצע sem_post(&s1). הסמפורים יוצרים סנכרון מסוג 'פינג-פונג' בין החוטים. מכיוון שכל חוט רץ פעמיים, הפלט יהיה ABAB והערך הסופי של count יהיה 4."}, "difficulty_estimation": "Medium", "_source_file": "0204__Synchronization__CodeAnalysis__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:00:02", "_subject": "Concurrency"}, {"id": 7, "type": "CodeAnalysis", "topic": ["Synchronization", "Threads", "Deadlock"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בספריות `pthread` ו-`stdio`. התוכנית מיועדת לסכם ערכים משותפים באמצעות מספר תהליכונים.\nמה יהיה הערך הסופי של המשתנה `shared_counter` שהודפס על ידי התוכנית, או מה יקרה לתוכנית? (שים לב: `pthread_mutex_t` הוא בדרך כלל mutex לא רקורסיבי, אלא אם צוין אחרת במפורש).", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // לצרכי הדגמה של הקשר, אך לא קריטי לבעיה זו\n\n#define NUM_THREADS 3\n#define NUM_ITERATIONS 1000\n\nlong long shared_counter = 0;\npthread_mutex_t mutex;\n\nvoid* thread_function(void* arg) {\n    for (int i = 0; i < NUM_ITERATIONS; ++i) {\n        pthread_mutex_lock(&mutex);\n        shared_counter++;\n    }\n    pthread_mutex_unlock(&mutex); // שחרור ה-mutex מתבצע מחוץ ללולאה\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    pthread_mutex_init(&mutex, NULL);\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_function, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(&threads[i], NULL);\n    }\n\n    pthread_mutex_destroy(&mutex);\n\n    printf(\"Final shared_counter: %lld\\n\", shared_counter);\n    return 0;\n}", "options": ["א. 0", "ב. 3000", "ג. ערך כלשהו בין 0 ל-3000 (כולל)", "ד. התוכנית תיתקע (Deadlock)", "ה. התוכנית תקרוס (Segmentation Fault)"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "התוכנית תיכנס למצב של Deadlock.\n\n`pthread_mutex_t` כברירת מחדל הוא mutex מסוג `PTHREAD_MUTEX_NORMAL` (לא רקורסיבי). המשמעות היא שתהליכון שמנסה לנעול mutex שכבר נמצא בבעלותו (כלומר, הוא כבר ביצע `pthread_mutex_lock` עליו ולא שחרר אותו עדיין) ייכנס למצב של Deadlock עצמי (self-deadlock).\n\nבפונקציה `thread_function`, כל תהליכון מבצע לולאה `NUM_ITERATIONS` פעמים. בתוך הלולאה, הוא קורא ל-`pthread_mutex_lock(&mutex)`.\n\nבאיטרציה הראשונה של הלולאה (כאשר `i=0`), התהליכון ינעל בהצלחה את ה-mutex.\nבאיטרציה השנייה של הלולאה (כאשר `i=1`), אותו תהליכון ינסה שוב לנעול את אותו ה-mutex. מכיוון שהוא כבר מחזיק ב-mutex והוא מסוג `PTHREAD_MUTEX_NORMAL`, ניסיון נעילה זה ייחסם, והתהליכון ייכנס למצב של Deadlock עצמי. הוא לא יוכל להמשיך לנעול את ה-mutex או לשחרר אותו, מכיוון ששחרור ה-mutex מתבצע רק מחוץ ללולאה.\n\nכל אחד מ-`NUM_THREADS` התהליכונים יגיע למצב Deadlock זה באופן עצמאי. לכן, התוכנית לעולם לא תגיע לשלב שבו היא מדפיסה את הערך הסופי של `shared_counter`, מכיוון שכל התהליכונים ייתקעו בניסיונם השני לנעול את ה-mutex. התוכנית תיתקע ולא תסיים את ריצתה באופן תקין.\n\nהפלט הצפוי הוא שהתוכנית לא תסיים את ריצתה ותיתקע (Deadlock)."}, "difficulty_estimation": "Medium", "_source_file": "0205__Synchronization__CodeAnalysis__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:01:27", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Synchronization", "Threads", "Race Conditions"], "content": {"text": "נתונה התוכנית הבאה, המשתמשת ב-pthreads וב-mutex. יש להניח שכל הקריאות ל-pthread הצליחו.\n\nמהו הערך הסופי של `shared_val` שיודפס על ידי התוכנית? האם הפלט של השורות המודפסות בתוך הפונקציה `worker` (כלומר, 'Thread %ld: shared_val = %d') יהיה דטרמיניסטי? נמק את תשובתך באופן מלא.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n\n#define NUM_THREADS 3\n#define INCREMENTS_PER_THREAD 5\n\nint shared_val = 0;\npthread_mutex_t my_mutex;\n\nvoid* worker(void* arg) {\n    long thread_id = (long)arg;\n\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&my_mutex);\n        shared_val++;\n        pthread_mutex_unlock(&my_mutex);\n        \n        // The printf statement is outside the mutex lock\n        printf(\"Thread %ld: shared_val = %d\\n\", thread_id, shared_val);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    pthread_mutex_init(&my_mutex, NULL);\n\n    for (long i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, worker, (void*)i);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final shared_val: %d\\n\", shared_val);\n    pthread_mutex_destroy(&my_mutex);\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסבר:\n\n1.  **ערך סופי של `shared_val`:**\n    הערך הסופי של `shared_val` שיודפס על ידי התוכנית יהיה **15**.\n    *   ישנם 3 תהליכונים (`NUM_THREADS = 3`).\n    *   כל תהליכון מבצע 5 הגדלות (`INCREMENTS_PER_THREAD = 5`).\n    *   סה\"כ הגדלות אמורות להיות: 3 * 5 = 15.\n    *   פעולת ההגדלה `shared_val++` מוגנת על ידי mutex (באמצעות `pthread_mutex_lock` ו-`pthread_mutex_unlock`). זה מבטיח שכל הגדלה בודדת היא אטומית, ומונע תנאי מרוץ על עדכון המונה עצמו. לכן, כל ההגדלות מבוצעות כראוי והערך הסופי של `shared_val` יהיה מדויק ונכון.\n\n2.  **דטרמיניזם של הפלט בתוך הפונקציה `worker`:**\n    הפלט של השורות המודפסות בתוך הפונקציה `worker` (`printf(\"Thread %ld: shared_val = %d\\n\", thread_id, shared_val);`) **לא יהיה דטרמיניסטי**.\n    *   הקריאה ל-`pthread_mutex_unlock(&my_mutex);` מתרחשת *לפני* הקריאה ל-`printf`.\n    *   משמעות הדבר היא שברגע שתהליכון מסיים להגדיל את `shared_val` ומשחרר את ה-mutex, תהליכון אחר יכול מיד לרכוש את ה-mutex, להגדיל את `shared_val` שוב, ולשחרר אותו. \n    *   בזמן שהתהליכון הראשון ממשיך לשורת ה-`printf` שלו, הערך של `shared_val` עשוי כבר להיות גבוה יותר מכיוון שתהליכונים אחרים הספיקו לעדכן אותו. לכן, הערך של `shared_val` שיודפס בכל שורת `printf` בתוך ה-`worker` יהיה תלוי בסדר הריצה הספציפי של התהליכונים.\n    *   בנוסף, סדר ההדפסה בין התהליכונים אינו מובטח, מה שתורם לאי-דטרמיניסטיות של הפלט הכולל. אין שום מנגנון סנכרון המבטיח ששורת `printf` תופעל מיד לאחר שחרור ה-mutex, או ששני תהליכונים לא ינסו להדפיס בו זמנית, מה שעלול לערבב את הפלט."}, "difficulty_estimation": "Medium", "_source_file": "0206__Synchronization__CodeAnalysis__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:01:48", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Threads"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בסמפורים (Semaphores) לסנכרון בין שני תהליכונים. הניחו שכל הקריאות ל-pthread_create ו-sem_init מצליחות. מה יהיה הפלט של התוכנית?", "code_snippet": "sem_t sem1, sem2;\nint counter = 0;\n\nvoid* threadA(void* arg) {\n    for (int i = 0; i < 5; i++) {\n        sem_wait(&sem1);\n        counter++;\n        printf(\"A%d \", counter);\n        sem_post(&sem2);\n    }\n    return NULL;\n}\n\nvoid* threadB(void* arg) {\n    for (int i = 0; i < 5; i++) {\n        sem_wait(&sem2);\n        counter++;\n        printf(\"B%d \", counter);\n        sem_post(&sem1);\n    }\n    return NULL;\n}\n\nint main() {\n    sem_init(&sem1, 0, 1);\n    sem_init(&sem2, 0, 0);\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, threadA, NULL);\n    pthread_create(&t2, NULL, threadB, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    return 0;\n}", "options": ["א. A1 B2 A3 B4 A5 B6 A7 B8 A9 B10", "ב. A1 A2 A3 A4 A5 B1 B2 B3 B4 B5", "ג. התוכנית תבצע הדפסה אחת ותיכנס למבוי סתום (Deadlock).", "ד. B1 A2 B3 A4 B5 A6 B7 A8 B9 A10", "ה. הפלט אינו דטרמיניסטי ותלוי בסדר הרצת התהליכונים על ידי המעבד."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "הסמפור sem1 מאותחל ל-1, מה שמאפשר לתהליכון A להיכנס לקטע הקריטי ראשון. הסמפור sem2 מאותחל ל-0, ולכן תהליכון B ייחסם בשורה sem_wait(&sem2) עד ש-A יבצע post ל-sem2. לאחר ש-A מעלה את המונה ל-1 ומדפיס 'A1 ', הוא מבצע post ל-sem2 שמשחרר את תהליכון B. כעת B מעלה את המונה ל-2, מדפיס 'B2 ' ומשחרר את A חזרה על ידי post ל-sem1. המבנה הזה יוצר סדר ריצה דטרמיניסטי שבו התהליכונים רצים לסירוגין, ולכן המונה גדל ב-1 בכל הדפסה והאותיות מתחלפות."}, "difficulty_estimation": "Medium", "_source_file": "0207__Synchronization__CodeAnalysis__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:00:24", "_subject": "Concurrency"}, {"id": 7, "type": "CodeAnalysis", "topic": ["Synchronization", "Deadlock", "Threads"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בתהליכונים (threads) ובמנעולים (mutexes). עיין בקוד וקבע האם ייתכן מצב של קיפאון (deadlock) במהלך ריצת התוכנית. נמק את תשובתך.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutexA;\npthread_mutex_t mutexB;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to lock mutexA...\\n\");\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 1: Locked mutexA. Trying to lock mutexB...\\n\");\n    sleep(1); // Simulate work or context switch opportunity\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 1: Locked mutexB. Doing work...\\n\");\n    // Critical section\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 1: Unlocked mutexB.\\n\");\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 1: Unlocked mutexA. Exiting.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to lock mutexB...\\n\");\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 2: Locked mutexB. Trying to lock mutexA...\\n\");\n    sleep(1); // Simulate work or context switch opportunity\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 2: Locked mutexA. Doing work...\\n\");\n    // Critical section\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 2: Unlocked mutexA.\\n\");\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 2: Unlocked mutexB. Exiting.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&mutexA, NULL);\n    pthread_mutex_init(&mutexB, NULL);\n\n    printf(\"Main: Creating threads...\\n\");\n    pthread_create(&tid1, NULL, thread_func1, NULL);\n    pthread_create(&tid2, NULL, thread_func2, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    pthread_mutex_destroy(&mutexA);\n    pthread_mutex_destroy(&mutexB);\n\n    printf(\"Main: All threads finished. Exiting.\\n\");\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, ייתכן מצב של קיפאון (deadlock) בתוכנית זו.\n\nהקיפאון יכול להתרחש בתרחיש הבא:\n1.  תהליכון 1 (thread_func1) רוכש את `mutexA`.\n2.  תהליכון 2 (thread_func2) רוכש את `mutexB`.\n3.  כעת, תהליכון 1 מנסה לרכוש את `mutexB` (שכבר מוחזק על ידי תהליכון 2) ונחסם.\n4.  באותו זמן, תהליכון 2 מנסה לרכוש את `mutexA` (שכבר מוחזק על ידי תהליכון 1) ונחסם.\n\nבמצב זה, שני התהליכונים חסומים וכל אחד מהם ממתין למנעול שמוחזק על ידי השני. תנאי הקיפאון מתקיימים: החזקה והמתנה (Hold and Wait), מניעה הדדית (Mutual Exclusion), אין דריסה מוקדמת (No Preemption), והמתנה מעגלית (Circular Wait). הוספת ה-`sleep(1)` בתהליכונים מגדילה את הסיכוי להתרחשות מצב זה על ידי יצירת חלון זמן שבו הסדר הבעייתי יכול להתקיים, אך הוא אפשרי גם בלעדיו בשל חוסר סדר מובטח ברכישת המנעולים."}, "difficulty_estimation": "Medium", "_source_file": "0208__Synchronization__CodeAnalysis__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:02:02", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Barriers", "Race Conditions"], "content": {"text": "לפניכם קוד המממש מחסום (Barrier) עבור N חוטים (כאשר N > 1). המטרה היא להבטיח שכל N החוטים יסיימו את 'שלב א' (הקריאה ל-do_work_A) לפני שמישהו מהם יתחיל את 'שלב ב' (הקריאה ל-do_work_B). הקוד משתמש בטכניקה הנקראת Chained Signaling בתוך Turnstile כדי לאפשר לחוטים לעבור את המחסום בזה אחר זה. הניחו שכל קריאות המערכת מצליחות וכי do_work_A ו-do_work_B אינן כוללות סנכרון פנימי.", "code_snippet": "sem_t mutex;     // initialized to 1\nsem_t turnstile; // initialized to 0\nint count = 0;\n\nvoid barrier() {\n    // Arrival\n    sem_wait(&mutex);\n    count++;\n    if (count == N) {\n        sem_post(&turnstile);\n    }\n    sem_post(&mutex);\n\n    // The Turnstile\n    sem_wait(&turnstile);\n    sem_post(&turnstile);\n}\n\nvoid* worker(void* arg) {\n    while(1) {\n        do_work_A();\n        barrier();\n        do_work_B();\n        // Point X\n    }\n    return NULL;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "הסבירו מדוע באיטרציה הראשונה של הלולאה, המחסום ימלא את תפקידו וכל החוטים ימתינו זה לזה.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "האם המחסום הנתון הוא Reusable? כלומר, האם מובטח סנכרון תקין גם באיטרציה השנייה והלאה? אם כן - הסבירו מדוע. אם לא - תארו תרחיש (תזמון) שבו חוט מסוים מתחיל את 'שלב ב' של האיטרציה השנייה לפני שחוט אחר סיים את 'שלב א' של אותה איטרציה.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "מהו הערך של הסמפור turnstile כאשר חוט כלשהו נמצא ב-'Point X' באיטרציה הראשונה? כיצד ניתן לתקן את הפונקציה barrier כך שתהיה בטוחה לשימוש חוזר (Reusable) מבלי להשתמש בסמפורים נוספים?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: באיטרציה הראשונה, turnstile מאותחל ל-0. N-1 החוטים הראשונים שיגיעו ל-barrier יגדילו את count אך לא ייכנסו ל-if, ולכן ייחסמו ב-sem_wait בשורה 13. החוט ה-N שיגיע יגדיל את count ל-N, יבצע sem_post ל-turnstile בשורה 9, וישחרר את החוט הראשון. החוט שישתחרר יבצע מיד sem_post בשורה 14 וישחרר את הבא בתור, וכך הלאה (שרשרת). לכן כולם יעברו רק אחרי שהאחרון הגיע.\n\n10.2: המחסום אינו Reusable. הבעיה היא שערך הסמפור turnstile נשאר 1 לאחר שהחוט האחרון עובר (הוא מבצע post בשורה 14 שאיש לא צורך). תרחיש שבירה: חוט T1 מסיים את barrier באיטרציה 1, מסיים את do_work_B במהירות, חוזר לתחילת הלולאה, מסיים את do_work_A של איטרציה 2 ומגיע שוב ל-barrier. מכיוון ש-turnstile הוא 1, T1 יבצע sem_wait ויעבור מיד לשלב ב' של איטרציה 2, למרות שחוטים אחרים אולי עדיין תקועים בשלב ב' של איטרציה 1 או בתחילת איטרציה 2.\n\n10.3: ערך הסמפור turnstile בנקודה X הוא 1. כדי לתקן את המחסום ולהופכו ל-Reusable, יש להוסיף שלב שני (Two-phase barrier) שבו נועלים את ה-turnstile בחזרה. בשיטה זו, לאחר שכל החוטים עברו את ה-turnstile הראשון, הם צריכים להמתין ב-turnstile שני שייפתח רק כאשר כולם סיימו לעבור את הראשון, והחוט האחרון שיעבור את השני יאפס את ה-count וינעל את ה-turnstile (יבצע wait מבלי לבצע post)."}, "difficulty_estimation": "Hard", "_source_file": "0209__Synchronization__CodeAnalysis__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:01:07", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Synchronization", "Deadlock", "Condition Variables", "Mutexes"], "content": {"text": "נתונה תוכנית C המשתמשת בחוטים (threads) לסנכרון גישה למונה משותף `counter`. כל חוט מנסה לקדם את המונה מספר קבוע של פעמים (`INCREMENTS_PER_THREAD`). עם זאת, קיימת הגבלה: חוט יכול לקדם את המונה רק אם ערכו הנוכחי זוגי. אם המונה אי-זוגי, החוט חייב להמתין. לאחר קידום המונה, החוט מאותת לחוטים אחרים. יש לנתח את הקוד ולזהות בעיות סנכרון אפשריות.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <stdlib.h>\n\n#define NUM_THREADS 3\n#define INCREMENTS_PER_THREAD 2\n\nint counter = 0;\npthread_mutex_t mutex;\npthread_cond_t cond_even;\n\nvoid* worker(void* arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&mutex);\n\n        // Wait until counter is even\n        while (counter % 2 != 0) {\n            pthread_cond_wait(&cond_even, &mutex);\n        }\n\n        // Increment counter\n        counter++;\n\n        // Signal that counter has changed.\n        pthread_cond_signal(&cond_even); \n        pthread_mutex_unlock(&mutex);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    long i;\n\n    pthread_mutex_init(&mutex, NULL);\n    pthread_cond_init(&cond_even, NULL);\n\n    for (i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, worker, (void*)i);\n    }\n\n    for (i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    pthread_mutex_destroy(&mutex);\n    pthread_cond_destroy(&cond_even);\n\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "8.1", "text": "האם התוכנית הנתונה עלולה להיכנס למצב של קיפאון (deadlock) או רעב (starvation)? נמקו את תשובתכם והסבירו את התרחיש המוביל לבעיה. מה יהיה הערך הסופי של `counter` במקרה של בעיה?", "code_snippet": null, "options": null}, {"id": "8.2", "text": "תקנו את פונקציית `worker` כך שכל `NUM_THREADS * INCREMENTS_PER_THREAD` הקידומים יבוצעו באופן תקין וללא מצבי מרוץ או קיפאון, ושהתוכנית תסיים את ריצתה. אם תידרשו לשנות או להסיר את אילוץ הזוגיות המקורי כדי להשיג זאת, הסבירו מדוע ואיזה אילוץ חדש (אם בכלל) אתם אוכפים במקומו. ניתן להשתמש רק ב-mutexes ו-condition variables. רשמו את הקוד המתוקן של פונקציית `worker` בלבד.", "code_snippet": "void* worker(void* arg) {\n    // Write your corrected code here\n}", "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "8.1: כן, התוכנית עלולה להיכנס למצב של קיפאון (deadlock). המצב נוצר כדלקמן:\nהמונה `counter` מתחיל מערך 0 (זוגי). חוט כלשהו (נניח חוט A) רוכש את המנעול, בודק שהמונה זוגי (0 % 2 == 0), וממשיך לקדם אותו. המונה הופך ל-1 (אי-זוגי). לאחר מכן, חוט A קורא ל-`pthread_cond_signal(&cond_even)` ומשחרר את המנעול.\nכעת, המונה `counter` שווה ל-1 (אי-זוגי). כל החוטים האחרים, וגם חוט A עצמו בניסיונו הבא לקדם את המונה, ינסו לרכוש את המנעול. לאחר שיצליחו, הם יגיעו ללולאת ה-`while (counter % 2 != 0)`. מכיוון ש-`counter` הוא 1 (אי-זוגי), התנאי נכון, והם יקראו ל-`pthread_cond_wait(&cond_even, &mutex)`.\nהבעיה היא שפעולת הקידום `counter++` תמיד הופכת מספר זוגי לאי-זוגי. כלומר, ברגע שהמונה הופך ל-1, הוא לעולם לא יוכל לחזור להיות זוגי באמצעות פעולת `counter++` תחת האילוץ שרק כאשר הוא זוגי מותר לקדם אותו. אף חוט לא יוכל לקדם את המונה מעבר ל-1, מכיוון שהתנאי \"מונה זוגי\" לעולם לא יתקיים שוב.\nלכן, כל החוטים ימתינו על `cond_even` ללא תקווה שמישהו יאותת להם, והתוכנית תיכנס לקיפאון.\nהערך הסופי של `counter` יהיה 1.\n\n8.2: כדי לאפשר לכל הקידומים להסתיים, יש להסיר את אילוץ הזוגיות המקורי, מכיוון שהוא מוביל לקיפאון אינהרנטי עם פעולת `counter++`. אם נשמור על האילוץ, המונה לעולם לא יוכל לעבור את הערך 1.\nהאילוץ החדש שנוכף הוא פשוט סנכרון נכון של גישה למונה משותף, ללא תלות בזוגיות. המטרה היא להבטיח שכל חוט יקדם את המונה את מספר הפעמים הנדרש, ושהמונה יגיע לערך הסופי הנכון (`NUM_THREADS * INCREMENTS_PER_THREAD`), ללא מצבי מרוץ או קיפאון.\nבמקרה זה, משתנה התנאי `cond_even` אינו נחוץ עוד, שכן אין תנאי מורכב מעבר לגישה בלעדית למשאב. ניתן להשתמש ב-mutex בלבד. אם בכל זאת רוצים להשתמש ב-condition variable, אפשר לאותת על שינוי כלשהו, אך זה אינו הכרחי לתיקון הבעיה הספציפית הזו.\n\nקוד מתוקן (הסרת אילוץ הזוגיות ושימוש ב-mutex בלבד):\n\n```c\nvoid* worker(void* arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&mutex); // נעל את המונה לגישה בלעדית\n        counter++;                 // קדם את המונה\n        pthread_mutex_unlock(&mutex); // שחרר את המנעול\n    }\n    return NULL;\n}\n```\n\nאם נתעקש לשמור על השימוש ב-condition variable (לדוגמה, אם היה אילוץ מורכב יותר):\n```c\nvoid* worker(void* arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&mutex);\n        // אין צורך בלולאת while עם תנאי זוגיות, כי היא הגורם לקיפאון.\n        // אם היה תנאי לגיטימי אחר (למשל, \"מונה קטן מ-X\"), היינו משתמשים בו כאן.\n        counter++;\n        pthread_cond_signal(&cond_even); // מאותת שחל שינוי, למקרה שחוטים אחרים ממתינים לתנאי כלשהו\n        pthread_mutex_unlock(&mutex);\n    }\n    return NULL;\n}\n```\nהתיקון הראשון (שימוש ב-mutex בלבד) הוא הפתרון המינימלי והנכון ביותר לאפשר את השלמת כל הקידומים ללא תלות באילוץ הזוגיות. התיקון השני מראה איך ניתן להשתמש ב-condition variable גם אם התנאי הוסר, אך הוא מיותר במקרה זה."}, "difficulty_estimation": "Hard", "_source_file": "0210__Synchronization__CodeAnalysis__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:02:48", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Synchronization", "Concurrency", "Semaphores", "Reusable Barrier"], "content": {"text": "נתונה התוכנית הבאה המנסה לממש מחסום (Barrier) רב-פעמי. N_THREADS חוטים מקדמים מונה גלובלי משותף shared_counter N_INCREMENTS_PER_THREAD פעמים כל אחד. לאחר כל קידום של המונה, כל החוטים צריכים להגיע למחסום, ורק כאשר כולם הגיעו, הם משוחררים להמשיך לקידום הבא. בסיום התוכנית יודפס הערך הסופי של shared_counter. ניתן להניח שכל קריאות המערכת מצליחות.\n\n", "code_snippet": "1 #include <stdio.h>\n2 #include <pthread.h>\n3 #include <semaphore.h>\n4 #include <unistd.h>\n5\n6 #define N_THREADS 3 // מספר חוטים\n7 #define N_INCREMENTS_PER_THREAD 2 // כמה פעמים כל חוט יקדם את המונה בסך הכל\n8\n9 int shared_counter = 0;\n10 sem_t mutex; // להגנה על shared_counter ו-barrier_count\n11 sem_t barrier_sem; // לחסימת חוטים במחסום\n12 int barrier_count = 0; // מונה חוטים שהגיעו למחסום\n13\n14 void* thread_func(void* arg) {\n15    long tid = (long)arg;\n16\n17    for (int i = 0; i < N_INCREMENTS_PER_THREAD; ++i) {\n18        // --- Critical section for shared_counter ---\n19        sem_wait(&mutex);\n20        shared_counter++;\n21        printf(\"Thread %ld: incremented counter to %d\\n\", tid, shared_counter);\n22        sem_post(&mutex);\n23        // --- End critical section ---\n24\n25        // --- Barrier logic ---\n26        sem_wait(&mutex);\n27        barrier_count++;\n28        if (barrier_count == N_THREADS) {\n29            // Last thread to arrive, release all others\n30            printf(\"Thread %ld: ALL arrived at barrier. Releasing.\\n\", tid);\n31            for (int j = 0; j < N_THREADS; ++j) {\n32                sem_post(&barrier_sem);\n33            }\n34        }\n35        sem_post(&mutex);\n36\n37        sem_wait(&barrier_sem); // Wait for all threads to pass\n38\n39        // --- Post-barrier logic: Reset barrier_count ---\n40        sem_wait(&mutex);\n41        barrier_count--;\n42        if (barrier_count == 0) {\n43            // Last thread to leave resets for next cycle.\n44            // This is where the flaw lies for reusable barriers.\n45            printf(\"Thread %ld: ALL left barrier. Resetting for next cycle.\\n\", tid);\n46        }\n47        sem_post(&mutex);\n48        // --- End barrier logic ---\n49    }\n50    return NULL;\n51}\n52\n53 int main() {\n54    pthread_t threads[N_THREADS];\n55    sem_init(&mutex, 0, 1);\n56    sem_init(&barrier_sem, 0, 0); // Initially closed\n57\n58    for (long i = 0; i < N_THREADS; ++i) {\n59        pthread_create(&threads[i], NULL, thread_func, (void*)i);\n60    }\n61\n62    for (int i = 0; i < N_THREADS; ++i) {\n63        pthread_join(threads[i], NULL);\n64    }\n65\n66    printf(\"Final counter value: %d\\n\", shared_counter);\n67\n68    sem_destroy(&mutex);\n69    sem_destroy(&barrier_sem);\n70    return 0;\n71}"}, "sub_questions": [{"id": "10.1", "text": "הסבירו מדוע המימוש הנתון של המחסום הרב-פעמי אינו עובד בצורה נכונה ועלול להוביל לבעיות. הסבירו את הסיבה העיקרית לכשל זה.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "תארו תזמון ספציפי (לדוגמה, עבור N_THREADS=2 ו-N_INCREMENTS_PER_THREAD=2) שבו מתרחשת הבעיה שתוארה בסעיף הקודם. ציינו בבירור מהו הערך של shared_counter בכל שלב רלוונטי וכיצד הוא מושפע מהכשל במחסום. מהו הערך הסופי המקסימלי של shared_counter שיכול להתקבל במקרה זה?", "code_snippet": null, "options": null}, {"id": "10.3", "text": "תקנו את הפונקציה thread_func כך שהמחסום יעבוד בצורה נכונה ויהיה רב-פעמי. ניתן להוסיף סמפורים ומשתנים גלובליים כנדרש (יש לציין את ערכי האתחול בהערה).", "code_snippet": "void* thread_func(void* arg) {\n    long tid = (long)arg;\n\n    for (int i = 0; i < N_INCREMENTS_PER_THREAD; ++i) {\n        // Critical section for shared_counter\n        sem_wait(&mutex);\n        shared_counter++;\n        printf(\"Thread %ld: incremented counter to %d\\n\", tid, shared_counter);\n        sem_post(&mutex);\n\n        // Barrier logic (corrected)\n        // ... (your corrected code here)\n    }\n    return NULL;\n}", "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: המימוש הנתון של המחסום הרב-פעמי אינו נכון בגלל בעיית ה-'Turnstile' (קרוסלה) או 'Premature Release'. סמפור ה-`barrier_sem` מאותחל ל-0, ולאחר שכל N_THREADS החוטים מגיעים, החוט האחרון קורא ל-`sem_post(&barrier_sem)` N_THREADS פעמים. לאחר מכן, כל חוט קורא ל-`sem_wait(&barrier_sem)` פעם אחת. הבעיה היא שפעולות `sem_post` הן מצטברות. אם חוט מסוים מהיר מאוד, הוא עלול לסיים את מחזור המחסום הנוכחי (כלומר, לבצע את ה-`sem_wait` שלו, להקטין את `barrier_count` ל-0, ולחזור לתחילת הלולאה) ולבצע `sem_wait(&barrier_sem)` עבור האיטרציה הבאה, *לפני* שכל החוטים האחרים סיימו את ה-`sem_wait` שלהם עבור האיטרציה הנוכחית. הדבר מאפשר לחוט המהיר 'לגנוב' `sem_post` שנועד לחוט אחר או לאיטרציה הבאה, ובכך לעבור את המחסום בטרם עת, מבלי שכל החוטים האחרים הגיעו אליו, ומפר את תנאי הסנכרון של המחסום. הדבר עלול להוביל לחסימה (Deadlock) של חוטים אחרים שיחכו ל-`sem_post` שכבר נצרך, או להפרה של סדר הפעולות המתוכנן.\n\n10.2: נניח N_THREADS=2 ו-N_INCREMENTS_PER_THREAD=2. הערך הסופי המצופה של `shared_counter` הוא 4.\n\nתזמון שמוביל לבעיה:\n1.  חוט 0: מבצע `sem_wait(&mutex)`, מקדם `shared_counter` ל-1. מבצע `sem_post(&mutex)`.\n2.  חוט 1: מבצע `sem_wait(&mutex)`, מקדם `shared_counter` ל-2. מבצע `sem_post(&mutex)`.\n3.  חוט 0: מבצע `sem_wait(&mutex)`, מגדיל `barrier_count` ל-1. מבצע `sem_post(&mutex)`.\n4.  חוט 1: מבצע `sem_wait(&mutex)`, מגדיל `barrier_count` ל-2. מכיוון ש-`barrier_count == N_THREADS`, חוט 1 מבצע `sem_post(&barrier_sem)` פעמיים. (ערך `barrier_sem` הופך ל-2). מבצע `sem_post(&mutex)`.\n5.  חוט 0: מבצע `sem_wait(&barrier_sem)`. (ערך `barrier_sem` הופך ל-1). חוט 0 עובר את המחסום. הוא מבצע `sem_wait(&mutex)`, מקטין `barrier_count` ל-1. מבצע `sem_post(&mutex)`.\n6.  **נקודת הכשל**: חוט 0, בהיותו מהיר מאוד, מיד ממשיך לאיטרציה השנייה שלו. הוא מבצע `sem_wait(&mutex)`, מקדם `shared_counter` ל-3. מבצע `sem_post(&mutex)`.\n7.  חוט 0: נכנס שוב ללוגיקת המחסום: מבצע `sem_wait(&mutex)`, מגדיל `barrier_count` ל-2. מכיוון ש-`barrier_count == N_THREADS`, חוט 0 מבצע `sem_post(&barrier_sem)` פעמיים. (ערך `barrier_sem` הופך ל-1 (מה-sem_post שחוט 1 עשה וטרם נצרך) + 2 (מחוט 0) = 3). מבצע `sem_post(&mutex)`.\n8.  חוט 0: מבצע `sem_wait(&barrier_sem)`. (ערך `barrier_sem` הופך ל-2). חוט 0 עובר את המחסום בפעם השנייה.\n9.  בנקודה זו, `shared_counter` הוא 3. חוט 0 סיים את כל פעולות הקידום שלו ועבר את המחסום פעמיים. חוט 1 עדיין לא סיים את האיטרציה הראשונה שלו (הוא תקוע ב-`sem_wait(&barrier_sem)` או בדיוק עבר אותו). כלומר, חוט 0 עבר את המחסום השני לפני שחוט 1 בכלל הגיע למחסום הראשון בפעם השנייה. זה מפר את תנאי המחסום.\n10. חוט 1: לבסוף מבצע `sem_wait(&barrier_sem)`. (ערך `barrier_sem` הופך ל-1). חוט 1 עובר את המחסום. הוא מבצע `sem_wait(&mutex)`, מקטין `barrier_count` ל-0. מבצע `sem_post(&mutex)`.\n11. חוט 1: ממשיך לאיטרציה השנייה שלו. מבצע `sem_wait(&mutex)`, מקדם `shared_counter` ל-4. מבצע `sem_post(&mutex)`.\n12. חוט 1: נכנס ללוגיקת המחסום: מבצע `sem_wait(&mutex)`, מגדיל `barrier_count` ל-1. מבצע `sem_post(&mutex)`.\n13. חוט 1: מבצע `sem_wait(&barrier_sem)`. (ערך `barrier_sem` הופך ל-0). חוט 1 עובר את המחסום. הוא מבצע `sem_wait(&mutex)`, מקטין `barrier_count` ל-0. מבצע `sem_post(&mutex)`.\n\nבמקרה זה, `shared_counter` יגיע ל-4. עם זאת, ייתכן תזמון שבו חוט 1 ייתקע ב-`sem_wait(&barrier_sem)` מכיוון שחוט 0 'גנב' את ה-`sem_post` שנועד לו, מה שיוביל ל-`shared_counter` סופי של 3 (אם חוט 0 מסיים את שתי האיטרציות וחוט 1 נתקע אחרי הקידום הראשון שלו). הערך הסופי המקסימלי של `shared_counter` שעלול להתקבל במקרה של חסימה חלקית הוא `N_THREADS * N_INCREMENTS_PER_THREAD - (מספר החוטים שנתקעו * מספר הקידומים שנותרו להם)`. במקרה של תזמון כשל חמור שבו חוט אחד מסיים את כל הקידומים שלו וחוט אחר נתקע לאחר הקידום הראשון, הערך המקסימלי הוא `(N_INCREMENTS_PER_THREAD * (N_THREADS - 1)) + N_INCREMENTS_PER_THREAD = N_THREADS * N_INCREMENTS_PER_THREAD`. אך אם חוט אחד יכול לעבור את המחסום מספר פעמים מבלי שכולם הגיעו, הדבר עלול לגרום לחוטים אחרים להיתקע. למשל, אם חוט 0 מבצע את כל N_INCREMENTS_PER_THREAD הקידומים שלו וכל המעברים במחסום, וחוט 1 נתקע אחרי הקידום הראשון שלו, אז הערך הסופי יהיה `N_INCREMENTS_PER_THREAD + 1`. לדוגמה, עבור N_THREADS=2 ו-N_INCREMENTS_PER_THREAD=2, הערך המקסימלי שעלול להתקבל הוא 3 (אם חוט 0 מסיים את שתי האיטרציות וחוט 1 נתקע לאחר הקידום הראשון). אם התוכנית הייתה מתרחשת ללא חסימה, הערך הנכון הוא 4.\n\n10.3: תיקון המימוש באמצעות 'Double Turnstile' (קרוסלה כפולה) עם שני סמפורים:\n\nגלובליים (יש לציין ערכי אתחול בהערה):\nsem_t mutex; // Initialized: 1\nsem_t turnstile1; // Initialized: 0\nsem_t turnstile2; // Initialized: 0\nint barrier_count = 0; // Initialized: 0\n\n```c\nvoid* thread_func(void* arg) {\n    long tid = (long)arg;\n\n    for (int i = 0; i < N_INCREMENTS_PER_THREAD; ++i) {\n        // Critical section for shared_counter\n        sem_wait(&mutex);\n        shared_counter++;\n        printf(\"Thread %ld: incremented counter to %d\\n\", tid, shared_counter);\n        sem_post(&mutex);\n\n        // Barrier logic (corrected - Phase 1: All threads arrive at turnstile1)\n        sem_wait(&mutex);\n        barrier_count++;\n        if (barrier_count == N_THREADS) {\n            // Last thread to arrive at turnstile1, open it for all\n            for (int j = 0; j < N_THREADS; ++j) {\n                sem_post(&turnstile1);\n            }\n        }\n        sem_post(&mutex);\n\n        sem_wait(&turnstile1); // Wait for all threads to pass turnstile1\n        // All threads are now past turnstile1\n\n        // Barrier logic (corrected - Phase 2: All threads leave turnstile1 and prepare for next cycle)\n        sem_wait(&mutex);\n        barrier_count--;\n        if (barrier_count == 0) {\n            // Last thread to leave turnstile1, open turnstile2 for all\n            for (int j = 0; j < N_THREADS; ++j) {\n                sem_post(&turnstile2);\n            }\n        }\n        sem_post(&mutex);\n\n        sem_wait(&turnstile2); // Wait for all threads to pass turnstile2 (ensures all left previous phase)\n        // All threads are now past turnstile2, ready for next iteration\n    }\n    return NULL;\n}\n```\n\nבפונקציית `main` יש לשנות את אתחול הסמפורים:\n```c\n// ...\nsem_init(&mutex, 0, 1);\nsem_init(&turnstile1, 0, 0); // סמפור ראשון, סגור בהתחלה\nsem_init(&turnstile2, 0, 0); // סמפור שני, סגור בהתחלה\n// ...\n// יש לשנות את קריאת ה-pthread_create ל-thread_func_corrected אם משנים את שם הפונקציה\n// ...\nsem_destroy(&turnstile1);\nsem_destroy(&turnstile2);\n// ...\n```"}, "difficulty_estimation": "Hard", "_source_file": "0211__Synchronization__CodeAnalysis__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:04:03", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Starvation", "Race Conditions"], "content": {"text": "לפניכם מימוש מוצע למנגנון Read-Write Lock המשתמש בסמפורים. המנגנון נועד לאפשר למספר קוראים (Readers) לקרוא מהמשאב בו-זמנית, אך להבטיח בלעדיות לכותב (Writer) יחיד. הנחו כי כל הסמפורים מאותחלים כראוי (mutex=1, writeBlock=1) וכי המשתנה readersCount מאותחל ל-0.", "code_snippet": "1  sem_t mutex;\n2  sem_t writeBlock;\n3  int readersCount = 0;\n4\n5  void startRead() {\n6    sem_wait(&mutex);\n7    readersCount++;\n8    if (readersCount == 1)\n9      sem_wait(&writeBlock);\n10   sem_post(&mutex);\n11 }\n12\n13 void endRead() {\n14   sem_wait(&mutex);\n15   readersCount--;\n16   if (readersCount == 0)\n17     sem_post(&writeBlock);\n18   sem_post(&mutex);\n19 }\n20\n21 void startWrite() {\n22   sem_wait(&writeBlock);\n23 }\n24\n25 void endWrite() {\n26   sem_post(&writeBlock);\n27 }", "options": null}, "sub_questions": [{"id": "1.1", "text": "האם המימוש הנוכחי עלול לגרום להרעבה (Starvation)? אם כן, של אילו חוטים (קוראים או כותבים) ובאילו תנאים?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "נניח שקיימים שלושה חוטים: R1, R2 (קוראים) ו-W1 (כותב). הציגו סדר פעולות (Interleaving) שבו W1 מגיע בזמן ש-R1 נמצא בקטע הקריטי, אך R2 מצליח להיכנס לקטע הקריטי לפני ש-W1 מתחיל לכתוב.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "מה יקרה אם נעביר את שורה 15 (הורדת המונה) אל מחוץ לבלוק הסנכרון, כלומר מיד אחרי שורה 18? הסבירו את ההשלכה על תקינות הקוד.", "code_snippet": null, "options": null}, {"id": "1.4", "text": "כדי למנוע הרעבת כותבים, מוצע להוסיף סמפור נוסף בשם readTry המאותחל ל-1. היכן יש להוסיף את הקריאות ל-sem_wait ו-sem_post של סמפור זה בפונקציות startRead ו-startWrite?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: המימוש עלול לגרום להרעבת כותבים (Writers). אם יש זרם קבוע של קוראים שנכנסים לקטע הקריטי (startRead) לפני שהקורא האחרון מסיים (endRead), המשתנה readersCount לעולם לא יגיע ל-0, ולכן הסמפור writeBlock לא ישוחרר לעולם עבור הכותב.\n\n1.2: תרחיש אפשרי: \nא. R1 מבצע startRead, נועל את mutex, מקדם ל-1, נועל את writeBlock ומשחרר את mutex.\nב. W1 מבצע startWrite ונעצר (blocked) ב-sem_wait על writeBlock.\nג. R2 מבצע startRead, נועל את mutex, מקדם ל-2. מכיוון ש-2 != 1, הוא מדלג על ה-wait ומשחרר את mutex.\nד. R2 נכנס לקטע הקריטי בזמן ש-W1 עדיין ממתין.\n\n1.3: העברת readersCount-- אל מחוץ ל-mutex תיצור מצב מרוץ (Race Condition). אם שני חוטים יבצעו endRead במקביל, הפעולה האריתמטית (שאינה אטומית) עלולה להסתיים בערך שגוי. בנוסף, הבדיקה if (readersCount == 0) עלולה להתבצע על ערך לא מעודכן, מה שיוביל לכך ש-writeBlock לא ישוחרר לעולם (Deadlock לכותבים) או ישוחרר פעמיים.\n\n1.4: הפתרון למניעת הרעבת כותבים:\nב-startRead: יש להוסיף sem_wait(&readTry) בשורה 5.5 (לפני ה-mutex) ו-sem_post(&readTry) בשורה 10.5 (אחרי שחרור ה-mutex).\nב-startWrite: יש להוסיף sem_wait(&readTry) לפני ה-wait על writeBlock, ו-sem_post(&readTry) מיד לאחר מכן (או בסוף הכתיבה). \nבצורה זו, כותב שמגיע יתפוס את readTry וימנע מקוראים חדשים להיכנס עד שיסיים."}, "difficulty_estimation": "Hard", "_source_file": "0212__Synchronization__CodeAnalysis__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:01:41", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Synchronization", "Threads", "Condition Variables", "Deadlock", "Starvation"], "content": {"text": "נתונה התוכנית הבאה, המנהלת מונה משותף `counter` בין מספר סוגי חוטים. המונה מאותחל ל-0. ישנם שלושה סוגים של חוטים:\n*   **Incrementer**: מגדיל את המונה ב-1.\n*   **Decrementer**: מקטין את המונה ב-1.\n*   **Monitor**: מדפיס את ערך המונה.\n\nהתוכנית מנסה ליישם את דרישות הסנכרון הבאות:\n1.  **מניעת ירידה מתחת לאפס**: המונה `counter` לעולם לא יירד מתחת ל-0. חוט Decrementer שמנסה להקטין את המונה כשהוא 0, ימתין.\n2.  **צפייה רק בערכים זוגיים**: חוט Monitor ידפיס את ערך המונה רק אם הוא זוגי. אם המונה אי-זוגי, הוא ימתין.\n3.  **מניעת הרעבה למקטינים (Decrementers)**: אם המונה הוא 0 וישנם חוטי Decrementer שממתינים, חוטי Incrementer צריכים להיחסם באופן זמני עד שהמונה יהפוך לחיובי ולפחות חוט Decrementer אחד יוכל לרוץ.\n\nענו על השאלות הבאות בהתבסס על הקוד הנתון. יש להניח שכל קריאות המערכת הצליחו.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // for sleep\n\n#define NUM_INCREMENTERS 2\n#define NUM_DECREMENTERS 2\n#define NUM_MONITORS 1\n#define ITERATIONS 5\n\nint counter = 0;\npthread_mutex_t mutex;\npthread_cond_t can_decrement; // For decrementers to wait if counter is 0\npthread_cond_t counter_is_even; // For monitors to wait if counter is odd\n\n// To handle starvation for decrementers\nint waiting_decrementers = 0; // Number of decrementers waiting\npthread_cond_t incrementers_block; // For incrementers to wait if decrementers are starving\n\nvoid* incrementer_thread(void* arg) {\n    for (int i = 0; i < ITERATIONS; ++i) {\n        pthread_mutex_lock(&mutex);\n        // FLAW related to starvation avoidance for decrementers.\n        // If there are waiting decrementers and counter is 0, incrementers should wait.\n        // But what if counter is > 0 and decrementers are waiting? They should run first.\n        while (waiting_decrementers > 0 && counter == 0) {\n            printf(\"Incrementer: Waiting due to starving decrementers. Counter: %d\\n\", counter);\n            pthread_cond_wait(&incrementers_block, &mutex);\n        }\n\n        counter++;\n        printf(\"Incrementer: Counter is now %d\\n\", counter);\n        \n        // Signal decrementers if counter became positive\n        pthread_cond_signal(&can_decrement); \n\n        // Signal monitors if counter became even\n        if (counter % 2 == 0) {\n            pthread_cond_broadcast(&counter_is_even);\n        }\n        pthread_mutex_unlock(&mutex);\n        usleep(50000); // Simulate work\n    }\n    return NULL;\n}\n\nvoid* decrementer_thread(void* arg) {\n    for (int i = 0; i < ITERATIONS; ++i) {\n        pthread_mutex_lock(&mutex);\n        waiting_decrementers++; \n\n        while (counter == 0) {\n            printf(\"Decrementer: Waiting, counter is %d\\n\", counter);\n            // Signal incrementers that we are waiting.\n            pthread_cond_signal(&incrementers_block); \n            pthread_cond_wait(&can_decrement, &mutex);\n        }\n        waiting_decrementers--; \n\n        counter--;\n        printf(\"Decrementer: Counter is now %d\\n\", counter);\n\n        // Signal monitors if counter became even (or odd, which means they might need to wait again)\n        if (counter % 2 == 0) {\n            pthread_cond_broadcast(&counter_is_even);\n        }\n        // If decrementer allowed an incrementer to run, signal it.\n        if (waiting_decrementers == 0) { \n            pthread_cond_signal(&incrementers_block);\n        }\n        pthread_mutex_unlock(&mutex);\n        usleep(70000); // Simulate work\n    }\n    return NULL;\n}\n\nvoid* monitor_thread(void* arg) {\n    for (int i = 0; i < (NUM_INCREMENTERS + NUM_DECREMENTERS) * ITERATIONS / 2 + 1; ++i) { // Run for a bit longer\n        pthread_mutex_lock(&mutex);\n        while (counter % 2 != 0) {\n            printf(\"Monitor: Waiting, counter is %d (odd)\\n\", counter);\n            pthread_cond_wait(&counter_is_even, &mutex);\n        }\n        printf(\"Monitor: Current counter is %d (even)\\n\", counter);\n        pthread_mutex_unlock(&mutex);\n        usleep(100000); // Simulate work\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t incrementers[NUM_INCREMENTERS];\n    pthread_t decrementers[NUM_DECREMENTERS];\n    pthread_t monitors[NUM_MONITORS];\n\n    pthread_mutex_init(&mutex, NULL);\n    pthread_cond_init(&can_decrement, NULL);\n    pthread_cond_init(&counter_is_even, NULL);\n    pthread_cond_init(&incrementers_block, NULL);\n\n    for (int i = 0; i < NUM_INCREMENTERS; ++i) {\n        pthread_create(&incrementers[i], NULL, incrementer_thread, NULL);\n    }\n    for (int i = 0; i < NUM_DECREMENTERS; ++i) {\n        pthread_create(&decrementers[i], NULL, decrementer_thread, NULL);\n    }\n    for (int i = 0; i < NUM_MONITORS; ++i) {\n        pthread_create(&monitors[i], NULL, monitor_thread, NULL);\n    }\n\n    for (int i = 0; i < NUM_INCREMENTERS; ++i) {\n        pthread_join(incrementers[i], NULL);\n    }\n    for (int i = 0; i < NUM_DECREMENTERS; ++i) {\n        pthread_join(decrementers[i], NULL);\n    }\n    pthread_join(monitors[0], NULL); // Join monitors[0] assuming only one monitor\n\n    pthread_mutex_destroy(&mutex);\n    pthread_cond_destroy(&can_decrement);\n    pthread_cond_destroy(&counter_is_even);\n    pthread_cond_destroy(&incrementers_block);\n\n    printf(\"Final counter: %d\\n\", counter);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "זהו את כל בעיות הסנכרון (מצבי מרוץ, קיפאון, הרעבה, או התנהגות שגויה לפי הדרישות) בקוד הנתון. עבור כל בעיה, הסבירו מדוע היא מתרחשת ומהן השלכותיה.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "כתבו גרסה מתוקנת לפונקציה `incrementer_thread` אשר פותרת את כל הבעיות שזוהו בסעיף 1.1 הנוגעות להתנהגותה. ניתן להוסיף משתנים גלובליים ואובייקטי סנכרון במידת הצורך (יש לציין את ערכי האתחול בהערה).", "code_snippet": "void* incrementer_thread(void* arg) {\n    // הקוד המתוקן יבוא כאן\n}", "options": null}, {"id": "1.3", "text": "כתבו גרסה מתוקנת לפונקציה `decrementer_thread` אשר פותרת את כל הבעיות שזוהו בסעיף 1.1 הנוגעות להתנהגותה. ניתן להוסיף משתנים גלובליים ואובייקטי סנכרון במידת הצורך (יש לציין את ערכי האתחול בהערה).", "code_snippet": "void* decrementer_thread(void* arg) {\n    // הקוד המתוקן יבוא כאן\n}", "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1.1. **הרעבת מקטינים (Decrementers) בגלל `pthread_cond_signal` במקום `pthread_cond_broadcast`:**\n    *   **הבעיה**: בפונקציה `incrementer_thread`, נעשה שימוש ב-`pthread_cond_signal(&can_decrement)`. אם מספר חוטי Decrementer ממתינים כשהמונה הוא 0, וחוט Incrementer אחד מגדיל את המונה (למשל ל-1), רק חוט Decrementer אחד יתעורר. אם מספר חוטי Decrementer יכולים כעת לרוץ (לדוגמה, המונה הוגדל ל-2 וכל Decrementer מקטין ב-1), שאר חוטי ה-Decrementer יישארו רדומים ויסבלו מהרעבה, גם אם התנאי עבורם התקיים.\n    *   **השלכות**: הרעבה של חוטי Decrementer, שאינם מתעוררים לטפל במונה גם כאשר הוא חיובי ומאפשר זאת.\n\n1.1.2. **לוגיקה שגויה ופוטנציאל לקיפאון (Deadlock) או הרעבה בטיפול במניעת הרעבת מקטינים (דרישה 3):**\n    *   **הבעיה 1 (ב-`decrementer_thread`):** המשתנה `waiting_decrementers` מוגדל לפני הכניסה ללולאת ה-`while` ובאופן כללי לפני שהחוט אכן ממתין. הוא מוקטן רק אחרי היציאה מהלולאה ולפני ההקטנה בפועל. מצב זה יכול להוביל לכך ש-`waiting_decrementers` יכיל ערך שגוי של חוטים שממתינים בפועל. בנוסף, `pthread_cond_signal(&incrementers_block)` נקרא כשהחוט נכנס למצב המתנה, אך זהו `signal` ולא `broadcast`, כך שאם מספר Incrementers ממתינים, רק אחד מהם יתעורר. יתרה מכך, האיתות הזה יכול להיות מוקדם מדי או מאוחר מדי.\n    *   **הבעיה 2 (ב-`decrementer_thread`):** התנאי `if (waiting_decrementers == 0)` שבו נקרא `pthread_cond_signal(&incrementers_block)` בסוף הפונקציה הוא שגוי. חוט Incrementer צריך להיות מסוגל לרוץ לא רק כאשר אין יותר Decrementers ממתינים, אלא גם כאשר המונה חיובי (גם אם יש Decrementers ממתינים, כי הם ממתינים רק אם המונה 0). לוגיקת האיתות כאן לא מכסה את כל המקרים שבהם Incrementers יכולים להמשיך.\n    *   **הבעיה 3 (ב-`incrementer_thread`):** התנאי `while (waiting_decrementers > 0 && counter == 0)` עבור חוטי Incrementer הוא נכון עקרונית מבחינת התזמון, אך בהינתן הבעיות בניהול `waiting_decrementers` ובאיתות, הוא עלול להוביל לקיפאון. לדוגמה, אם כל חוטי ה-Decrementer ממתינים (כי `counter` הוא 0) ו-`waiting_decrementers` נספר באופן שגוי (לדוגמה, הוא נשאר 0 למרות שיש חוטים שממתינים), וכל חוטי ה-Incrementer נחסמים על `incrementers_block` (כי `waiting_decrementers > 0 && counter == 0` מתקיים במקרה אחר), ואין חוט שיכול לאותת להם, תתרחש הרעבה או קיפאון.\n    *   **השלכות**: קיפאון (Deadlock) פוטנציאלי כאשר Incrementers ו-Decrementers חוסמים זה את זה באופן הדדי, או הרעבה של Incrementers כאשר הם נחסמים שלא לצורך או הרעבה של Decrementers אם אין מי שיעיר את Incrementers.\n\n1.1.3. **אי-דיוק בספירת `waiting_decrementers`:**\n    *   **הבעיה**: כפי שתואר בסעיף הקודם, `waiting_decrementers` מוגדל לפני שחוט ה-Decrementer נכנס ל-`pthread_cond_wait` ומוקטן רק אחרי שהוא מתעורר. זה יכול להוביל למצב שבו `waiting_decrementers` כולל חוטים שכרגע לא ממתינים בפועל, או חוטים שרק התעוררו אבל עדיין לא ביצעו את פעולת ההקטנה. זה פוגע באמינות המשתנה.\n    *   **השלכות**: קבלת החלטות שגויות בטיפול בהרעבה, כפי שתואר לעיל, ובכך פגיעה בדרישה 3.\n\n1.2. **גרסה מתוקנת של `incrementer_thread`:**\n```c\nvoid* incrementer_thread(void* arg) {\n    for (int i = 0; i < ITERATIONS; ++i) {\n        pthread_mutex_lock(&mutex);\n        \n        // Incrementers wait ONLY if there are decrementers waiting AND counter is 0.\n        // This gives priority to decrementers when the counter is at its minimum.\n        while (waiting_decrementers > 0 && counter == 0) {\n            printf(\"Incrementer: Waiting due to starving decrementers. Counter: %d\\n\", counter);\n            pthread_cond_wait(&incrementers_block, &mutex);\n        }\n\n        counter++;\n        printf(\"Incrementer: Counter is now %d\\n\", counter);\n        \n        // Use broadcast for can_decrement because multiple decrementers might be able to run now.\n        pthread_cond_broadcast(&can_decrement); \n\n        // Use broadcast for counter_is_even because multiple monitors might be waiting.\n        if (counter % 2 == 0) {\n            pthread_cond_broadcast(&counter_is_even);\n        }\n        pthread_mutex_unlock(&mutex);\n        usleep(50000); // Simulate work\n    }\n    return NULL;\n}\n```\n\n1.3. **גרסה מתוקנת של `decrementer_thread`:**\n```c\nvoid* decrementer_thread(void* arg) {\n    for (int i = 0; i < ITERATIONS; ++i) {\n        pthread_mutex_lock(&mutex);\n        \n        // Increment count BEFORE potentially waiting.\n        waiting_decrementers++; \n        \n        // Signal to potentially blocked incrementers using broadcast.\n        // This is important if this decrementer is the first one to arrive at counter == 0,\n        // and an incrementer might be trying to proceed. It ensures incrementers re-evaluate their condition.\n        pthread_cond_broadcast(&incrementers_block); \n\n        while (counter == 0) {\n            printf(\"Decrementer: Waiting, counter is %d\\n\", counter);\n            pthread_cond_wait(&can_decrement, &mutex);\n        }\n        // Decrement count AFTER being woken up and before actually changing 'counter'.\n        waiting_decrementers--; \n\n        counter--;\n        printf(\"Decrementer: Counter is now %d\\n\", counter);\n\n        // After a decrementer runs, it might have changed the conditions for incrementers.\n        // If 'counter' is now positive OR there are no more decrementers waiting,\n        // incrementers are no longer blocked by the starvation avoidance rule. So, broadcast to them.\n        if (counter > 0 || waiting_decrementers == 0) {\n            pthread_cond_broadcast(&incrementers_block);\n        }\n\n        // Use broadcast for counter_is_even because multiple monitors might be waiting.\n        if (counter % 2 == 0) {\n            pthread_cond_broadcast(&counter_is_even);\n        }\n        pthread_mutex_unlock(&mutex);\n        usleep(70000); // Simulate work\n    }\n    return NULL;\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0213__Synchronization__CodeAnalysis__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:05:23", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Synchronization", "Threads", "Condition Variables", "Mutexes", "Reusable Barrier", "Deadlock"], "content": {"text": "נתונה מחסום (barrier) לשימוש חוזר הממומש באמצעות mutex ו-condition variables. המחסום מיועד לסנכרן N חוטים כך שכולם יגיעו לנקודה מסוימת בתוכנית לפני שמי מהם ימשיך הלאה. לאחר שחרור המחסום, הוא אמור להיות מוכן לשימוש חוזר.\n\nקראו את קוד המחסום והשימוש בו בקוד המצורף:", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\n#define NUM_THREADS 5\n#define NUM_ITERATIONS 3 // How many times threads pass the barrier\n\npthread_mutex_t barrier_mutex = PTHREAD_MUTEX_INITIALIZER;\npthread_cond_t barrier_cond = PTHREAD_COND_INITIALIZER;\nint barrier_count = 0;\nint barrier_threshold = NUM_THREADS;\n\nvoid my_barrier_wait() {\n    pthread_mutex_lock(&barrier_mutex);\n    barrier_count++;\n    if (barrier_count == barrier_threshold) {\n        // Last thread to arrive\n        barrier_count = 0; // Reset for next use\n        pthread_cond_broadcast(&barrier_cond);\n    } else {\n        // Not the last thread, wait\n        pthread_cond_wait(&barrier_cond, &barrier_mutex);\n    }\n    pthread_mutex_unlock(&barrier_mutex);\n}\n\nvoid* thread_func(void* arg) {\n    long tid = (long)arg;\n    for (int i = 0; i < NUM_ITERATIONS; ++i) {\n        printf(\"Thread %ld arrived at barrier for iteration %d.\\n\", tid, i + 1);\n        my_barrier_wait();\n        printf(\"Thread %ld passed barrier for iteration %d.\\n\", tid, i + 1);\n        usleep(10000); // Simulate work after barrier\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    for (long i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, (void*)i);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"All threads finished.\\n\");\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "זהו את הבעיה העיקרית במנגנון הסנכרון של המחסום הנתון, במיוחד בהקשר של שימוש חוזר. הסבירו מדוע זו בעיה ומה ההשלכות שלה (לדוגמה, האם עלול להיווצר Deadlock, Livelock או התנהגות שגויה אחרת).", "code_snippet": null, "options": null}, {"id": "1.2", "text": "תקנו את קוד הפונקציה `my_barrier_wait` כך שיפעל באופן תקין לשימוש חוזר, תוך שימוש באובייקטי סנכרון הקיימים (mutex ו-condition variables) ומינימום שינויים. הציגו את הקוד המתוקן והסבירו את התיקון שלכם.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: הבעיה העיקרית במחסום הנתון היא תנאי מרוץ (race condition) שעלול להתרחש כאשר המחסום מיועד לשימוש חוזר. הבעיה נובעת מהאיפוס המוקדם של `barrier_count` ל-0 על ידי החוט האחרון שהגיע, מיד לאחר קריאה ל-`pthread_cond_broadcast`.\nאם חוט שהתעורר מה-`pthread_cond_wait` (בעקבות ה-broadcast) מתזמן מחדש *לפני* שהוא יצא מהאזור הקריטי (כלומר, לפני ה-`pthread_mutex_unlock`), וחוט אחר (מהמחזור הבא של המחסום, או אפילו חוט שהתעורר מה-broadcast ורץ מהר) מגיע, הוא יראה ש-`barrier_count` כבר אופס ל-0.\nכתוצאה מכך, חוט שהתעורר זה עתה עלול לבדוק שוב את התנאי `barrier_count == barrier_threshold` (או `barrier_count < barrier_threshold`) ולמצוא אותו שוב שגוי עבור המחזור הנוכחי, ולכן יחזור מיד למצב המתנה (wait) עבור המחזור הבא של המחסום. זה יוצר מצב שבו חלק מהחוטים נתקעים במחסום הנוכחי, בעוד אחרים ממשיכים.\nההשלכה היא מצב של Deadlock או Livelock, כאשר חלק מהחוטים נתקעים ב-`pthread_cond_wait` מבלי שאי פעם יגיעו כולם (N חוטים) ל-`barrier_count == barrier_threshold` עבור המחזור שהם נמצאים בו, כיוון שחוטים אחרים כבר 'קפצו' למחזור הבא של המחסום. גם אם לא deadlock מוחלט, התנהגות התוכנית תהיה שגויה ולא תסנכרן את החוטים כנדרש.\n\n1.2: כדי לתקן את הבעיה ולממש מחסום לשימוש חוזר באופן תקין, נשתמש במשתנה נוסף הנקרא 'דור' (`generation` או `phase`). משתנה זה יאפשר לחוטים להבחין בין מחזורי המחסום השונים. רק כאשר החוט האחרון מגיע, הוא יקדם את הדור ויבצע broadcast, ובכך ישחרר את כל החוטים שמחכים לדור הנוכחי. חוטים שהתעוררו חייבים לוודא שהדור שלהם (הדור שהם חיכו לו) אינו תואם יותר לדור הגלובלי, מה שמעיד שהמחסום התקדם.\n\n**קוד מתוקן לפונקציה `my_barrier_wait`:**\n```c\n// יש להוסיף הצהרה גלובלית:\n// int barrier_generation = 0; // Added for reusable barrier\n\nvoid my_barrier_wait() {\n    pthread_mutex_lock(&barrier_mutex);\n    int my_generation = barrier_generation; // לכידת הדור הנוכחי של החוט\n    barrier_count++;\n    if (barrier_count == barrier_threshold) {\n        // החוט האחרון שהגיע\n        barrier_count = 0;           // איפוס המונה\n        barrier_generation++;        // קידום הדור\n        pthread_cond_broadcast(&barrier_cond); // שחרור כל החוטים\n    } else {\n        // לא החוט האחרון, המתן. לולאת while מטפלת בהתעוררויות שווא ומוודאת התקדמות דור.\n        while (my_generation == barrier_generation) {\n            pthread_cond_wait(&barrier_cond, &barrier_mutex);\n        }\n    }\n    pthread_mutex_unlock(&barrier_mutex);\n}\n```\n\n**הסבר התיקון:**\nהוספנו את המשתנה הגלובלי `barrier_generation` ואת המשתנה המקומי `my_generation`.\n1.  כל חוט, בכניסה ל-`my_barrier_wait`, שומר את ערך `barrier_generation` הנוכחי ב-`my_generation` שלו.\n2.  החוט האחרון שמגיע למחסום (כאשר `barrier_count == barrier_threshold`) הוא זה שאחראי לאפס את `barrier_count` *ולקדם* את `barrier_generation`. לאחר מכן הוא מבצע `pthread_cond_broadcast`.\n3.  חוטים אחרים שמחכים ב-`pthread_cond_wait` יתעוררו. כעת, במקום לצאת מיד מהפונקציה, הם בודקים בלולאת `while` האם `my_generation` שלהם עדיין שווה ל-`barrier_generation` הגלובלי. כל עוד הם זהים, זה אומר שהמחסום לא התקדם עבורם, והם יחזרו למצב המתנה (או שזו הייתה התעוררות שווא). רק כאשר `barrier_generation` התקדם (על ידי החוט האחרון), `my_generation` של החוט כבר לא יהיה שווה ל-`barrier_generation` הגלובלי, והחוט יוכל לצאת מהלולאה ולהמשיך.\nתיקון זה מבטיח שכל החוטים ימתינו למחזור הנכון של המחסום ולא יקפצו למחזור הבא בטרם עת, ובכך מונע את תנאי המרוץ ותופעות ה-Deadlock/Livelock הפוטנציאליות בשימוש חוזר במחסום."}, "difficulty_estimation": "Hard", "_source_file": "0214__Synchronization__CodeAnalysis__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:05:52", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Synchronization", "Threads", "Concurrency", "Condition Variables", "Mutexes", "Barriers"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בחוטים (threads) לביצוע משימה הכוללת שני שלבים (Phase A ו-Phase B) באופן מחזורי. כל T החוטים מבצעים N איטרציות.\nהדרישות הן:\n1. חוט אינו יכול להתחיל את Phase B עבור איטרציה מסוימת, אלא אם כן כל T החוטים סיימו את Phase A עבור אותה איטרציה.\n2. בכל רגע נתון, רק חוט אחד יכול להיות ב-Phase B (קטע קריטי).\n\nיש לנתח את הקוד ולענות על השאלות הבאות:", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n#include <stdbool.h>\n\n#define T 3 // Number of threads\n#define N 2 // Number of iterations per thread\n\npthread_mutex_t mutex_phaseA;\npthread_cond_t cond_phaseA_done;\nint phaseA_counter = 0;\n\npthread_mutex_t mutex_phaseB;\n\nint global_work_counter = 0;\n\nvoid* thread_func(void* arg) {\n    long thread_id = (long)arg;\n\n    for (int i = 0; i < N; ++i) {\n        printf(\"Thread %ld: Iteration %d, starting Phase A\\n\", thread_id, i);\n        usleep(1000 * (thread_id + 1)); // Simulate work\n\n        pthread_mutex_lock(&mutex_phaseA);\n        phaseA_counter++;\n        printf(\"Thread %ld: Iteration %d, finished Phase A. phaseA_counter = %d\\n\", thread_id, i, phaseA_counter);\n\n        if (phaseA_counter < T) {\n            pthread_cond_wait(&cond_phaseA_done, &mutex_phaseA);\n        } else {\n            // Last thread to finish Phase A, reset counter and broadcast\n            printf(\"Thread %ld: Iteration %d, ALL threads finished Phase A. Broadcasting!\\n\", thread_id, i);\n            phaseA_counter = 0;\n            pthread_cond_broadcast(&cond_phaseA_done);\n        }\n        pthread_mutex_unlock(&mutex_phaseA);\n\n        // Phase B critical section\n        pthread_mutex_lock(&mutex_phaseB);\n        printf(\"Thread %ld: Iteration %d, entering Phase B critical section. global_work_counter = %d\\n\", thread_id, i, global_work_counter);\n        global_work_counter++;\n        usleep(500 * (T - thread_id)); // Simulate work\n        printf(\"Thread %ld: Iteration %d, exiting Phase B critical section. global_work_counter = %d\\n\", thread_id, i, global_work_counter);\n        pthread_mutex_unlock(&mutex_phaseB);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[T];\n\n    pthread_mutex_init(&mutex_phaseA, NULL);\n    pthread_cond_init(&cond_phaseA_done, NULL);\n    pthread_mutex_init(&mutex_phaseB, NULL);\n\n    for (long i = 0; i < T; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, (void*)i);\n    }\n\n    for (int i = 0; i < T; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final global_work_counter = %d\\n\", global_work_counter);\n\n    pthread_mutex_destroy(&mutex_phaseA);\n    pthread_cond_destroy(&cond_phaseA_done);\n    pthread_mutex_destroy(&mutex_phaseB);\n\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "האם הסנכרון בקוד עונה על הדרישות באופן מלא ונכון? אם לא, זהו את הבעיה(ות) והסבירו מדוע היא(הן) קיימת(ות).", "code_snippet": null, "options": null}, {"id": "1.2", "text": "מה יהיה הערך הסופי של המשתנה global_work_counter כאשר כל החוטים יסיימו את ריצתם? נמקו את תשובתכם.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "נניח שברצוננו להוסיף קריאה לפונקציה `log_iteration_complete()` בדיוק פעם אחת בכל איטרציה, לאחר שכל החוטים סיימו את Phase A אך לפני שמישהו נכנס ל-Phase B. היכן הייתם מוסיפים את הקריאה הזו, ואיזה סנכרון נוסף (אם בכלל) נדרש כדי להבטיח שהיא תיקרא רק פעם אחת לאיטרציה?", "code_snippet": "void log_iteration_complete() {\n    printf(\"--- Iteration complete for all threads ---\\n\");\n}", "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: הסנכרון אינו עונה על הדרישות באופן מלא ונכון, במיוחד עבור תרחיש של שימוש חוזר במחסום (reusable barrier).\nהבעיה העיקרית היא תנאי מרוץ (race condition) כאשר חוטים עוברים למחזור הבא של האיטרציות. כאשר החוט האחרון מגיע ל-Phase A, הוא מאפס את `phaseA_counter` ל-0 ומשדר (`pthread_cond_broadcast`) לכל החוטים הממתינים. כל החוטים הממתינים מתעוררים וממשיכים ל-Phase B.\nעם זאת, החוט האחרון (ששידר) עשוי לסיים את Phase B שלו במהירות, לחזור ללולאת ה-for, ולהתחיל את Phase A עבור האיטרציה הבאה (ולהגדיל את `phaseA_counter` ל-1), וזאת לפני שכל שאר החוטים שהתעוררו הספיקו לצאת מהמחסום של Phase A ולראות ש-`phaseA_counter` אופס. במצב כזה, חוטים אחרים שיגיעו למחסום Phase A באיטרציה הבאה עלולים לראות ערך שגוי של `phaseA_counter` (למשל, 1 במקום 0) או לפספס את ה-broadcast הבא, מה שעלול לגרום לקיפאון (deadlock) או להפרת הדרישה שכל החוטים יסיימו את Phase A לפני שמישהו יתחיל את Phase B עבור אותה איטרציה. כלומר, חוט אחד יכול להתחיל את Phase A של איטרציה `i+1` לפני שכל החוטים סיימו את Phase B של איטרציה `i`.\nמחסום לשימוש חוזר דורש לרוב מנגנון מורכב יותר, כגון שימוש במונה דורות (generation counter) או במחסום כפול (double barrier), כדי לוודא שכל החוטים עזבו את המחסום לפני שהוא מתאפס ומוכן לשימוש חוזר.\n\n1.2: הערך הסופי של `global_work_counter` יהיה T * N.\nההסבר: המשתנה `global_work_counter` מקודם פעם אחת בכל כניסה ל-Phase B. Phase B הוא קטע קריטי המוגן על ידי `mutex_phaseB`, מה שמבטיח שרק חוט אחד יכול לגשת אליו בו-זמנית ושכל הקידומים מתבצעים באופן אטומי ונכון. כל אחד מ-T החוטים מבצע N איטרציות, ובכל איטרציה הוא נכנס ל-Phase B פעם אחת. לפיכך, סך הקידומים יהיה T כפול N. עם T=3 ו-N=2, הערך הסופי יהיה 3 * 2 = 6.\n\n1.3: היינו מוסיפים את הקריאה ל-`log_iteration_complete()` בתוך בלוק ה-`else` (הבלוק שמטפל בחוט האחרון שמגיע ל-Phase A), לפני איפוס המונה `phaseA_counter` ולפני קריאת ה-`pthread_cond_broadcast`.\n\nדוגמה לשינוי הקוד:\n```c\n            if (phaseA_counter < T) {\n                pthread_cond_wait(&cond_phaseA_done, &mutex_phaseA);\n            } else {\n                log_iteration_complete(); // קריאה לפונקציה כאן\n                phaseA_counter = 0;\n                pthread_cond_broadcast(&cond_phaseA_done);\n            }\n```\nאין צורך בסנכרון נוסף עבור `log_iteration_complete()` עצמה. היא נקראת על ידי חוט יחיד (החוט האחרון שמגיע ל-Phase A) כאשר הוא מחזיק את `mutex_phaseA`. זה מבטיח שהפונקציה תיקרא בדיוק פעם אחת בכל איטרציה, ובזמן הנכון (לאחר שכל החוטים סיימו את Phase A ולפני שמישהו נכנס ל-Phase B) ומבלי ליצור תנאי מרוץ נוספים."}, "difficulty_estimation": "Hard", "_source_file": "0215__Synchronization__CodeAnalysis__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:06:36", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Synchronization", "Threads", "Mutex", "Condition Variables", "Semaphores", "Barrier"], "content": {"text": "נתונה תוכנית C הבאה המשתמשת בחוטים (threads) ובמנגנוני סנכרון (mutexes, condition variables, semaphores) לביצוע עבודה מתואמת. התוכנית מיועדת לבצע את השלבים הבאים:\n1.  **שלב ההכנה**: כל חוט מבצע פעולת הכנה מקומית.\n2.  **שלב ההמתנה הגלובלי**: כל החוטים ממתינים זה לזה עד שכולם יסיימו את שלב ההכנה. רק אז הם יכולים להמשיך.\n3.  **שלב העבודה המתואמת**: החוטים מקדמים מונה גלובלי משותף `global_counter` באופן סבבי (thread 0, thread 1, ..., thread N_THREADS-1, ואז שוב thread 0 וכן הלאה), כאשר כל חוט מבצע `K_ITERATIONS` קידומים. \n\nבהינתן N_THREADS=3 ו-K_ITERATIONS=2, ובהנחה שכל קריאות המערכת הצליחו, מה יהיה ערכו הסופי של `global_counter`? האם קיימים מצבי מרוץ (race conditions) או קיפאון (deadlocks) בקוד? פרט את תשובתך באופן מלא ומנומק.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n\n#define N_THREADS 3 \n#define K_ITERATIONS 2 \n\nint global_counter = 0; \n\n// Barrier synchronization\npthread_mutex_t barrier_mutex;\npthread_cond_t barrier_cond;\nint threads_at_barrier = 0;\n\n// Turn-based synchronization\nsem_t turn_semaphores[N_THREADS]; // One semaphore per thread\n\nvoid* worker_thread(void* arg) {\n    long thread_id = (long)arg;\n\n    // Phase 1: Local Setup\n    printf(\"Thread %ld: Starting setup...\\n\", thread_id);\n    // Simulate setup time if needed\n    printf(\"Thread %ld: Setup complete.\\n\", thread_id);\n\n    // Phase 2: Barrier synchronization - wait for all threads to complete setup\n    pthread_mutex_lock(&barrier_mutex);\n    threads_at_barrier++;\n    if (threads_at_barrier == N_THREADS) {\n        printf(\"All threads reached barrier. Signaling...\\n\");\n        pthread_cond_broadcast(&barrier_cond); // Signal all waiting threads\n    } else {\n        while (threads_at_barrier < N_THREADS) {\n            pthread_cond_wait(&barrier_cond, &barrier_mutex); // Wait for signal\n        }\n    }\n    pthread_mutex_unlock(&barrier_mutex);\n    printf(\"Thread %ld: Passed barrier.\\n\", thread_id);\n\n    // Phase 3: Coordinated Work - ordered increment of global_counter\n    for (int i = 0; i < K_ITERATIONS; ++i) {\n        sem_wait(&turn_semaphores[thread_id]); // Wait for my turn\n\n        // Critical section\n        global_counter++;\n        printf(\"Thread %ld: Incrementing global_counter to %d (iteration %d)\\n\", thread_id, global_counter, i);\n\n        sem_post(&turn_semaphores[(thread_id + 1) % N_THREADS]); // Signal next thread\n    }\n\n    printf(\"Thread %ld: Finished all work.\\n\", thread_id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[N_THREADS];\n\n    // Initialize synchronization primitives\n    pthread_mutex_init(&barrier_mutex, NULL);\npthread_cond_init(&barrier_cond, NULL);\n\n    for (int i = 0; i < N_THREADS; ++i) {\n        sem_init(&turn_semaphores[i], 0, 0); // All initially 0\n    }\n    sem_post(&turn_semaphores[0]); // Grant turn to thread 0 to start\n\n    // Create threads\n    for (long i = 0; i < N_THREADS; ++i) {\n        if (pthread_create(&threads[i], NULL, worker_thread, (void*)i) != 0) {\n            perror(\"Failed to create thread\");\n            return 1;\n        }\n    }\n\n    // Join threads\n    for (int i = 0; i < N_THREADS; ++i) {\n        if (pthread_join(threads[i], NULL) != 0) {\n            perror(\"Failed to join thread\");\n            return 1;\n        }\n    }\n\n    printf(\"Main: All threads finished. Final global_counter = %d\\n\", global_counter);\n\n    // Destroy synchronization primitives\n    pthread_mutex_destroy(&barrier_mutex);\npthread_cond_destroy(&barrier_cond);\n    for (int i = 0; i < N_THREADS; ++i) {\n        sem_destroy(&turn_semaphores[i]);\n    }\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "**ערך סופי של global_counter:**\nהערך הסופי של `global_counter` יהיה 6. כל אחד מ-`N_THREADS` החוטים מקדם את המונה `K_ITERATIONS` פעמים. מכיוון שהסנכרון מבטיח שכל קידום מתבצע באופן אטומי ומוגן, כל הקידומים יצטברו בצורה נכונה. לכן, סך הקידומים יהיה `N_THREADS * K_ITERATIONS = 3 * 2 = 6`.\n\n**מצבי מרוץ או קיפאון:**\nהקוד **אינו מכיל מצבי מרוץ או קיפאון** עבור התרחיש המתואר, והוא מסונכרן באופן נכון בשני השלבים:\n\n1.  **שלב ההמתנה הגלובלי (Barrier Synchronization):**\n    *   החוטים משתמשים ב-`pthread_mutex_t` (`barrier_mutex`) וב-`pthread_cond_t` (`barrier_cond`) יחד עם מונה `threads_at_barrier` כדי ליישם מחסום (barrier). \n    *   המונה `threads_at_barrier` מוגן על ידי המוטקס (`barrier_mutex`), מה שמונע מצב מרוץ על עדכון המונה.\n    *   החוט האחרון שמגיע למחסום (כאשר `threads_at_barrier == N_THREADS`) משדר (broadcast) לכל החוטים הממתינים באמצעות `pthread_cond_broadcast`, ובכך משחרר אותם להמשך הריצה.\n    *   שאר החוטים ממתינים באמצעות `pthread_cond_wait` בתוך לולאת `while`, המבטיחה בדיקה חוזרת של התנאי (`threads_at_barrier < N_THREADS`) גם במקרה של התעוררות שווא (spurious wakeup), ובכך מבטיחה שכל החוטים יעברו את המחסום רק כאשר כולם הגיעו אליו.\n    *   אין קיפאון מכיוון שכל החוטים בסופו של דבר יגיעו למחסום, והחוט האחרון ישחרר את כולם.\n\n2.  **שלב העבודה המתואמת (Ordered Processing):**\n    *   החוטים משתמשים במערך של סמפורים (`turn_semaphores`) כדי לאכוף סדר סבבי קפדני בקידום `global_counter`.\n    *   כל סמפור מיועד לחוט ספציפי (חוט `i` ממתין על `turn_semaphores[i]` ומאותת לחוט `(i+1)%N_THREADS` באמצעות `sem_post(&turn_semaphores[(thread_id + 1) % N_THREADS])`).\n    *   הסמפור `turn_semaphores[0]` מאותחל ל-1 ב-`main` כדי לאפשר לחוט 0 להתחיל ראשון, בעוד שאר הסמפורים מאותחלים ל-0.\n    *   דפוס זה מבטיח שרק חוט אחד בכל פעם ניגש ל-`global_counter` ומקדם אותו, ובכך מונע מצב מרוץ על המונה. \n    *   אין קיפאון מכיוון שיש תמיד חוט אחד שיכול להמשיך (זה שהסמפור שלו הוא 1), והוא תמיד יעביר את ה\"תור\" לחוט הבא בסבב."}, "difficulty_estimation": "Hard", "_source_file": "0216__Synchronization__CodeAnalysis__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:07:08", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Mutexes", "Synchronization", "Concurrency"], "content": {"text": "מהי המטרה העיקרית של שימוש ב-mutex במערכת הפעלה?", "code_snippet": null, "options": ["למנוע מצב של קיפאון.", "לאפשר גישה סימולטנית למשאבים משותפים.", "להבטיח בלעדיות לגישה לקטע קריטי.", "לשפר את ביצועי המערכת."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "להבטיח בלעדיות לגישה לקטע קריטי.", "explanation": "mutex נועד להבטיח שרק תהליך או תהליכון אחד יוכל לגשת לקטע קריטי (critical section) מסוים בכל זמן נתון, ובכך למנוע תנאי מרוץ (race conditions) ולהבטיח עקביות נתונים. בעוד ש-mutexים יכולים להיות מעורבים בתנאים שמובילים לקיפאון או להשפיע על ביצועים, מטרתם העיקרית היא אכיפת בלעדיות (mutual exclusion)."}, "difficulty_estimation": "Easy", "_source_file": "0217__Mutexes__MultipleChoice__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:07:14", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Mutexes", "Concurrency", "Synchronization"], "content": {"text": "מטרתו העיקרית של mutex היא לאפשר לחוטים מרובים להיכנס למקטע קריטי בו זמנית.", "code_snippet": null, "options": ["נכון", "לא נכון"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "לא נכון", "explanation": "לא נכון. מטרתו העיקרית של mutex היא להבטיח גישה הדדית בלבדית (mutual exclusion) למקטע קריטי, כלומר, לאפשר לחוט אחד בלבד להיכנס למקטע הקריטי בכל רגע נתון ובכך למנוע תנאי מרוץ."}, "difficulty_estimation": "Easy", "_source_file": "0218__Mutexes__MultipleChoice__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:07:22", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Mutexes", "Synchronization", "Concurrency"], "content": {"text": "מהו התפקיד העיקרי של Mutex במערכת הפעלה?", "code_snippet": null, "options": ["מניעת קיפאון (Deadlock)", "הבטחת הדרה הדדית (Mutual Exclusion)", "תיאום בין תהליכים שונים (Process Coordination)", "הגברת ביצועים של תוכניות מקביליות"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "הבטחת הדרה הדדית (Mutual Exclusion)", "explanation": "התפקיד העיקרי והבסיסי של Mutex הוא להבטיח הדרה הדדית (mutual exclusion) בין תהליכים או ת'רדים. הדרה הדדית מבטיחה שרק תהליך או ת'רד אחד יוכל לגשת לקטע קריטי (critical section) או למשאב משותף בכל רגע נתון, ובכך למנוע מצבי מרוץ (race conditions) ולשמור על עקביות הנתונים. בעוד ש-Mutex יכול להיות כלי במניעת קיפאון או תיאום, אלה אינם תפקידיו העיקריים ישירות, והוא אינו מיועד להגברת ביצועים באופן ישיר (לרוב הוא אף גורם לסריאליזציה ובכך עלול להקטין ביצועים)."}, "difficulty_estimation": "Easy", "_source_file": "0219__Mutexes__MultipleChoice__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:07:29", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Mutexes", "Synchronization", "Concurrency", "Race Conditions"], "content": {"text": "מהי המטרה העיקרית של מנעול הדדי (mutex)?", "code_snippet": null, "options": ["למנוע קיפאון (deadlock).", "להבטיח גישה הוגנת למשאבים משותפים.", "להגן על קטעים קריטיים (critical sections) מפני מצבי מרוץ (race conditions).", "לאפשר למספר תהליכונים לגשת למשאב משותף בו זמנית."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "להגן על קטעים קריטיים (critical sections) מפני מצבי מרוץ (race conditions).", "explanation": "מנעול הדדי (mutex) נועד בראש ובראשונה להבטיח בלעדיות הדדית (mutual exclusion) בקטעים קריטיים של קוד. כאשר תהליכון אחד מחזיק במנעול, תהליכונים אחרים המנסים לרכוש את אותו המנעול נחסמים עד שהמנעול משוחרר. פעולה זו מונעת מצבי מרוץ (race conditions) ודואגת לעקביות של נתונים משותפים. אף על פי שמנעולים יכולים להיות חלק מפתרונות למניעת קיפאון או הרעבה, זו אינה מטרתם העיקרית. הם אינם מאפשרים גישה בו זמנית למשאב משותף, אלא בדיוק ההפך."}, "difficulty_estimation": "Easy", "_source_file": "0220__Mutexes__MultipleChoice__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:07:37", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Mutexes", "Concurrency", "Synchronization"], "content": {"text": "מהי ההתנהגות הסטנדרטית של חוט המנסה לנעול מנעול (mutex) שכבר נמצא ברשותו?", "code_snippet": null, "options": ["החוט נתקע (deadlock) וממתין לעצמו לשחרר את המנעול.", "החוט מצליח לנעול את המנעול שוב (מנעול רקורסיבי).", "הפעולה מחזירה שגיאה.", "החוט ממשיך בביצוע ללא נעילה נוספת."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "החוט נתקע (deadlock) וממתין לעצמו לשחרר את המנעול.", "explanation": "ברוב מימושי המנעולים הסטנדרטיים (למשל, `PTHREAD_MUTEX_NORMAL` ב-pthreads), מנעול אינו רקורסיבי. כאשר חוט מנסה לנעול מנעול שכבר נמצא ברשותו, הוא ינסה לתפוס אותו שוב, אך מאחר שהמנעול כבר נעול על ידו, הוא ימתין לשחרורו, מה שיוביל לקיפאון (deadlock) מכיוון שרק החוט עצמו יכול לשחרר אותו ולכן החוט ממתין לעצמו."}, "difficulty_estimation": "Easy", "_source_file": "0221__Mutexes__MultipleChoice__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:07:45", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Mutexes", "Synchronization", "Concurrency"], "content": {"text": "מהי המטרה העיקרית של מנעול (mutex)?", "code_snippet": null, "options": ["למנוע קיפאון (deadlock).", "להבטיח אי-הדדיות (mutual exclusion) בקטעים קריטיים.", "לאפשר למספר תהליכונים לגשת למשאבים משותפים בו-זמנית.", "לתזמן תהליכונים."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "להבטיח אי-הדדיות (mutual exclusion) בקטעים קריטיים.", "explanation": "מטרתו העיקרית של מנעול (mutex) היא להבטיח שרק תהליכון אחד יוכל לגשת לקטע קריטי (critical section) או למשאב משותף בכל רגע נתון. זה מונע מצבי מרוץ (race conditions) ומבטיח עקביות נתונים. בעוד ששימוש נכון ב-mutexes יכול למנוע סוגים מסוימים של קיפאון, מניעת קיפאון אינה מטרתם העיקרית, ושימוש לא נכון בהם אף יכול לגרום לקיפאון."}, "difficulty_estimation": "Easy", "_source_file": "0222__Mutexes__MultipleChoice__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:07:53", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Mutexes", "Concurrency", "Synchronization", "Critical Section"], "content": {"text": "מהי המטרה העיקרית של שימוש במנעול (mutex) בתכנות מקבילי?", "code_snippet": null, "options": ["למנוע מצב של קיפאון (deadlock)", "להבטיח גישה בלעדית לקטע קריטי", "לשפר את ביצועי התוכנית", "לאפשר תקשורת בין תהליכים"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "להבטיח גישה בלעדית לקטע קריטי", "explanation": "מנעול (mutex) משמש להגנה על קטעים קריטיים, ומוודא שרק חוט ביצוע אחד ייגש אליהם בכל רגע נתון. זהו המנגנון המרכזי למניעת תנאי מרוץ (race conditions) ולהבטחת עקביות הנתונים. מנעולים אינם מונעים קיפאון באופן אוטומטי ואף יכולים לגרום לו אם לא נעשה בהם שימוש נכון. הם גם אינם משפרים ביצועים באופן ישיר ולרוב מוסיפים תקורה, ואינם מיועדים לתקשורת בין תהליכים אלא לסנכרון גישה למשאבים משותפים."}, "difficulty_estimation": "Easy", "_source_file": "0223__Mutexes__MultipleChoice__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:08:01", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Mutexes", "Concurrency", "Synchronization"], "content": {"text": "מה קורה כאשר חוט (thread) מנסה לנעול (lock) מנעול הדדי (mutex) שכבר נתפס על ידי חוט אחר?", "code_snippet": null, "options": ["החוט ממשיך בביצוע מיד.", "החוט נכנס ללולאת המתנה פעילה (busy-wait).", "החוט נחסם (blocks) עד שהמנעול משוחרר.", "התוכנית קורסת."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "החוט נחסם (blocks) עד שהמנעול משוחרר.", "explanation": "כאשר חוט מנסה לרכוש מנעול הדדי (mutex) שכבר נתפס על ידי חוט אחר, החוט המנסה לרכוש את המנעול נכנס למצב חסימה. הוא ימתין עד שהחוט המחזיק במנעול ישחרר אותו, ורק אז יוכל לנסות לרכוש אותו שוב (או שחוט אחר ירכוש אותו קודם, תלוי במדיניות התזמון). מטרת המנעול ההדדי היא להבטיח גישה הדדית בלעדית לקטע קריטי, ולכן חסימה היא ההתנהגות הצפויה והנכונה."}, "difficulty_estimation": "Easy", "_source_file": "0224__Mutexes__MultipleChoice__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:08:09", "_subject": "Concurrency"}, {"id": 6, "type": "MultipleChoice", "topic": ["Synchronization", "Mutexes", "Concurrency"], "content": {"text": "בהינתן מנעול (mutex) מסוג PTHREAD_MUTEX_NORMAL (לא רקורסיבי) שחוט (thread) מסוים כבר מחזיק בו. מה תהיה התוצאה אם אותו חוט ינסה לבצע שוב קריאה ל-`pthread_mutex_lock()` על מנעול זה?", "code_snippet": "pthread_mutex_t m;\n// assume m is initialized as PTHREAD_MUTEX_NORMAL\n// ...\npthread_mutex_lock(&m); // First acquisition\n// ... some critical section work ...\npthread_mutex_lock(&m); // Second acquisition by the same thread", "options": ["הקריאה השנייה ל-`pthread_mutex_lock()` תחזיר שגיאה (לדוגמה, EDEADLK אם המנעול מסוג PTHREAD_MUTEX_ERRORCHECK).", "החוט יחסם באופן מיידי וייכנס למצב של קיפאון (deadlock).", "הקריאה השנייה תצליח, והחוט ירכוש את המנעול שוב מבלי להיחסם.", "המערכת תבצע שחרור אוטומטי של המנעול ולאחר מכן רכישה מחדש."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. כאשר חוט מנסה לרכוש מנעול מסוג `PTHREAD_MUTEX_NORMAL` (שאינו רקורסיבי) שכבר נמצא ברשותו, הקריאה ל-`pthread_mutex_lock()` תגרום לחוט להיחסם. מכיוון שהחוט עצמו מחזיק במנעול, הוא לעולם לא יוכל לשחרר אותו כדי לאפשר לעצמו להמשיך, וכך נוצר מצב של קיפאון (deadlock). סוג המנעול `PTHREAD_MUTEX_ERRORCHECK` היה מחזיר שגיאה (EDEADLK) במצב כזה, אך `PTHREAD_MUTEX_NORMAL` אינו מבצע בדיקה זו ומוביל לחסימה וקיפאון. מנעול מסוג `PTHREAD_MUTEX_RECURSIVE` מאפשר רכישות מרובות על ידי אותו חוט."}, "difficulty_estimation": "Medium", "_source_file": "0225__Mutexes__MultipleChoice__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:08:25", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Mutexes", "Deadlocks"], "content": {"text": "בהינתן מנעול (mutex) שאינו רקורסיבי (non-recursive), חוט המנסה לנעול אותו פעם שנייה מבלי לשחרר אותו קודם לכן, ייכנס למצב של קיפאון (deadlock).", "code_snippet": "pthread_mutex_t my_mutex;\n\nvoid *thread_func(void *arg) {\n    pthread_mutex_lock(&my_mutex); // First lock\n    // ... critical section ...\n    pthread_mutex_lock(&my_mutex); // Second lock by the same thread\n    // ... This line will cause a deadlock ...\n    pthread_mutex_unlock(&my_mutex);\n    pthread_mutex_unlock(&my_mutex);\n    return NULL;\n}\n\nint main() {\n    // Initialize a default (non-recursive) mutex\n    pthread_mutex_init(&my_mutex, NULL);\n    // Assume thread_func is created and run\n    return 0;\n}", "options": ["נכון", "לא נכון"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "נכון", "explanation": "נכון. מנעול (mutex) שאינו רקורסיבי מיועד להבטיח בלעדיות (mutual exclusion) כך שרק חוט אחד יכול להחזיק בו בכל רגע נתון. כאשר חוט מנסה לנעול מנעול שכבר ננעל על ידו (ולא שוחרר), המערכת רואה זאת כניסיון לנעול מנעול תפוס. מכיוון שהחוט עצמו מחזיק במנעול ואינו יכול לשחרר אותו לפני הנעילה הנוספת, הוא ייכנס למצב המתנה אינסופי (deadlock) לעצמו. בניגוד לכך, מנעול רקורסיבי מאפשר לחוט שנועל אותו לנעול אותו שוב ושוב, כל עוד הוא גם משחרר אותו מספר פעמים זהה."}, "difficulty_estimation": "Medium", "_source_file": "0226__Mutexes__MultipleChoice__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:08:35", "_subject": "Concurrency"}, {"id": 6, "type": "MultipleChoice", "topic": ["Synchronization", "Mutexes", "Concurrency"], "content": {"text": "מה יקרה אם תהליך ינסה לנעול מנעול (mutex) לא-רקורסיבי שכבר ננעל על ידו?", "code_snippet": "pthread_mutex_t my_mutex;\n\n// Initialize mutex (e.g., PTHREAD_MUTEX_NORMAL)\npthread_mutex_init(&my_mutex, NULL);\n\n// Thread A acquires the mutex\npthread_mutex_lock(&my_mutex);\n\n// Thread A attempts to acquire the same mutex again\npthread_mutex_lock(&my_mutex); // What happens here?", "options": ["התהליך יכנס למצב קיפאון (deadlock) עם עצמו.", "פונקציית pthread_mutex_lock תחזיר שגיאה (error code).", "המנעול יינעל בהצלחה שוב, והתהליך ימשיך לרוץ.", "מערכת ההפעלה תסיים את ריצת התהליך."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "התהליך יכנס למצב קיפאון (deadlock) עם עצמו.", "explanation": "כאשר תהליך מנסה לנעול מחדש מנעול לא-רקורסיבי (כמו PTHREAD_MUTEX_NORMAL ב-pthreads) שהוא כבר מחזיק בו, המערכת תגרום לתהליך להיחסם בניסיון לרכוש את המנעול. מכיוון שהתהליך עצמו מחזיק במנעול, הוא לעולם לא ישחרר אותו (כי הוא חסום), וכתוצאה מכך הוא יכנס למצב קיפאון עצמי (self-deadlock). מנעולים רקורסיביים (כמו PTHREAD_MUTEX_RECURSIVE) מתוכננים להתמודד עם מצב זה על ידי מעקב אחר מספר הנעילות על ידי אותו תהליך."}, "difficulty_estimation": "Medium", "_source_file": "0227__Mutexes__MultipleChoice__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:08:44", "_subject": "Concurrency"}, {"id": 6, "type": "MultipleChoice", "topic": ["Synchronization", "Mutexes", "Concurrency"], "content": {"text": "נתון קטע הקוד הבא:\n\n```c\npthread_mutex_t my_mutex;\n\nvoid *thread_func(void *arg) {\n    pthread_mutex_lock(&my_mutex);\n    // קטע קריטי 1\n    pthread_mutex_lock(&my_mutex); // ניסיון נעילה שני\n    // קטע קריטי 2\n    pthread_mutex_unlock(&my_mutex);\n    pthread_mutex_unlock(&my_mutex);\n    return NULL;\n}\n\nint main() {\n    pthread_mutex_init(&my_mutex, NULL); // מנעול רגיל (PTHREAD_MUTEX_NORMAL)\n    // ... יצירת והפעלת thread_func בחוט נפרד ...\n    pthread_mutex_destroy(&my_mutex);\n    return 0;\n}\n```\n\nבמידה וחוט יחיד מריץ את הפונקציה `thread_func`, מה יקרה בניסיון הנעילה השני של `my_mutex`?", "code_snippet": "pthread_mutex_t my_mutex;\n\nvoid *thread_func(void *arg) {\n    pthread_mutex_lock(&my_mutex);\n    // קטע קריטי 1\n    pthread_mutex_lock(&my_mutex); // ניסיון נעילה שני\n    // קטע קריטי 2\n    pthread_mutex_unlock(&my_mutex);\n    pthread_mutex_unlock(&my_mutex);\n    return NULL;\n}\n\nint main() {\n    pthread_mutex_init(&my_mutex, NULL); // מנעול רגיל (PTHREAD_MUTEX_NORMAL)\n    // ... יצירת והפעלת thread_func בחוט נפרד ...\n    pthread_mutex_destroy(&my_mutex);\n    return 0;\n}", "options": ["הנעילה השנייה תצליח ללא בעיה.", "התהליך ייכנס למצב קיפאון (deadlock).", "הנעילה השנייה תחזיר שגיאה (error).", "התנהגות בלתי מוגדרת (Undefined behavior)."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "התהליך ייכנס למצב קיפאון (deadlock).", "explanation": "כאשר חוט מנסה לנעול מנעול רגיל (PTHREAD_MUTEX_NORMAL), כפי שמוגדר על ידי `pthread_mutex_init(&my_mutex, NULL)`, שכבר נמצא ברשותו, פונקציית `pthread_mutex_lock` תחסום את החוט ותמתין לשחרור המנעול. מכיוון שהחוט ממתין לעצמו לשחרר את המנעול, הוא לעולם לא יוכל להמשיך ולשחרר אותו, מה שמוביל למצב של קיפאון עצמי (self-deadlock). ישנם סוגי מנעולים אחרים, כמו מנעולים רקורסיביים (PTHREAD_MUTEX_RECURSIVE), המאפשרים נעילה חוזרת על ידי אותו חוט, אך זה אינו המקרה עבור מנעול רגיל. מנעולי מסוג `PTHREAD_MUTEX_ERRORCHECK` היו מחזירים שגיאה במצב זה."}, "difficulty_estimation": "Medium", "_source_file": "0228__Mutexes__MultipleChoice__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:08:58", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Mutexes", "Concurrency"], "content": {"text": "האם מותר לחוט אחד לנעול מנעול (mutex) וחוט אחר לפתוח אותו?", "code_snippet": null, "options": ["נכון", "לא נכון"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "לא נכון", "explanation": "לא נכון. מנעולים סטנדרטיים (כמו `pthread_mutex_t` ב-Pthreads או `std::mutex` ב-C++) מניחים בעלות (ownership): רק החוט שנועל את המנעול רשאי לפתוח אותו. ניסיון לפתוח מנעול מחוט אחר יוביל בדרך כלל להתנהגות בלתי מוגדרת (undefined behavior) או לשגיאת זמן ריצה (runtime error), כתלות במימוש הספציפי של מערכת ההפעלה או הספרייה. תכונה זו נועדה למנוע מצבי מירוץ (race conditions) ושימוש שגוי במשאבים מוגנים."}, "difficulty_estimation": "Medium", "_source_file": "0229__Mutexes__MultipleChoice__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:09:06", "_subject": "Concurrency"}, {"id": 6, "type": "MultipleChoice", "topic": ["Mutexes", "Synchronization", "Deadlocks"], "content": {"text": "נתון מנעול (mutex) סטנדרטי שאינו רקורסיבי. מה יקרה אם תהליך שכבר מחזיק במנעול ינסה לרכוש אותו שוב?", "code_snippet": null, "options": ["א) התהליך ייחסם לצמיתות (deadlock).", "ב) התהליך ירכוש את המנעול בהצלחה.", "ג) הפעולה תחזיר שגיאה.", "ד) ההתנהגות אינה מוגדרת."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א) התהליך ייחסם לצמיתות (deadlock).", "explanation": "בתכנון סטנדרטי של מנעול (mutex) שאינו רקורסיבי, כאשר תהליך שכבר מחזיק במנעול מנסה לרכוש אותו שוב, הוא ינסה לנעול משאב שכבר נעול על ידו. כיוון שהמנעול אינו רקורסיבי, הוא אינו מזהה שהתהליך המנסה לנעול הוא אותו תהליך שכבר מחזיק בו. לכן, התהליך ייחסם וימתין לשחרור המנעול, אך הוא עצמו זה שאמור לשחרר אותו – מה שמוביל למצב של קיפאון (deadlock). מנעולים רקורסיביים מתוכננים להתמודד עם מצב זה על ידי מעקב אחר מספר הרכישות של המנעול על ידי אותו תהליך, אך זו אינה ההתנהגות הסטנדרטית של מנעול שאינו רקורסיבי."}, "difficulty_estimation": "Medium", "_source_file": "0230__Mutexes__MultipleChoice__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:09:17", "_subject": "Concurrency"}, {"id": 6, "type": "MultipleChoice", "topic": ["Synchronization", "Mutexes", "Concurrency"], "content": {"text": "ברוב מימושי המנעולים (mutex) הסטנדרטיים (לדוגמה, `pthread_mutex_t` ב-C/C++), מהי התוצאה הצפויה אם חוט (thread) מנסה לשחרר מנעול אשר נתפס על ידי חוט אחר?", "code_snippet": null, "options": ["המנעול ישוחרר בהצלחה, והחוט המנסה לשחרר יקבל בעלות עליו.", "התוכנית תיתקל בשגיאת זמן ריצה (runtime error) או תתנהג באופן בלתי מוגדר (undefined behavior), שעלול להוביל לקריסה.", "החוט המנסה לשחרר ייחסם עד שהחוט שתפס את המנעול במקור ישחרר אותו.", "המנעול יישאר תפוס, והפעולה תחזיר קוד שגיאה (לדוגמה, `EPERM`) מבלי לגרום לקריסה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "התוכנית תיתקל בשגיאת זמן ריצה (runtime error) או תתנהג באופן בלתי מוגדר (undefined behavior), שעלול להוביל לקריסה.", "explanation": "רוב מימושי המנעולים הסטנדרטיים (כמו `pthread_mutex_t` עם סוג `PTHREAD_MUTEX_NORMAL` או `PTHREAD_MUTEX_DEFAULT`) מבוססים על קונספט של בעלות (ownership), כאשר רק החוט שתפס את המנעול רשאי לשחרר אותו. ניסיון לשחרר מנעול שלא נתפס על ידי החוט הנוכחי מוביל להתנהגות בלתי מוגדרת (undefined behavior) על פי תקן POSIX. התנהגות בלתי מוגדרת זו מתבטאת לעיתים קרובות בשגיאת זמן ריצה, קריסת התוכנית, או מצב לא עקבי. בעוד שסוגי מנעולים מסוימים (כמו `PTHREAD_MUTEX_ERRORCHECK`) יחזירו קוד שגיאה (לדוגמה, `EPERM`) מבלי לגרום לקריסה, זו אינה התנהגות ברירת המחדל או הנפוצה ביותר עבור מנעולים סטנדרטיים שאינם מוגדרים במפורש לבדיקת שגיאות. לכן, התשובה המכילה התנהגות בלתי מוגדרת וקריסה היא הנפוצה והמדויקת ביותר עבור המקרה הכללי."}, "difficulty_estimation": "Medium", "_source_file": "0231__Mutexes__MultipleChoice__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:09:32", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Mutexes", "Synchronization", "Concurrency"], "content": {"text": "מה יקרה אם תהליך (thread) ינסה לנעול מנעול הדדי (mutex) שאינו רקורסיבי (non-recursive) שכבר ננעל על ידו?", "code_snippet": null, "options": ["הפעולה תחזור בהצלחה והתהליך ימשיך בביצוע.", "התהליך יכנס למצב קיפאון (deadlock).", "התהליך יסיים את פעולתו עם שגיאה.", "הפעולה תיכשל ותחזיר קוד שגיאה (לדוגמה, EDEADLK), אך התהליך ימשיך לפעול."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "התהליך יכנס למצב קיפאון (deadlock).", "explanation": "מנעול הדדי שאינו רקורסיבי (non-recursive mutex) מיועד להיות ננעל רק פעם אחת על ידי תהליך נתון. אם אותו תהליך ינסה לנעול אותו שוב, המנעול יתפוס שהוא כבר ננעל. ברוב המימושים הסטנדרטיים (לדוגמה, PTHREAD_MUTEX_NORMAL ב-POSIX), התהליך המנסה לנעול את המנעול יכנס למצב המתנה (block) עד שהמנעול ישוחרר. מכיוון שהתהליך עצמו הוא זה שמחזיק במנעול, והוא נמצא במצב המתנה, הוא לעולם לא ישחרר את המנעול, וכך יכנס למצב של קיפאון עצמי (self-deadlock). במקרים מסוימים (לדוגמה, PTHREAD_MUTEX_ERRORCHECK ב-POSIX), המערכת עשויה לזהות ניסיון זה ולהחזיר קוד שגיאה (כמו EDEADLK) במקום להיכנס לקיפאון, אך עצם הניסיון מצביע על בעיה לוגית חמורה שעלולה להוביל לקיפאון."}, "difficulty_estimation": "Medium", "_source_file": "0232__Mutexes__MultipleChoice__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:09:54", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Mutexes", "Synchronization", "Deadlock"], "content": {"text": "נתון קטע הקוד הבא ב-C/C++. המנעול `m` מאותחל כברירת מחדל (כלומר, מסוג `PTHREAD_MUTEX_NORMAL`). איזו טענה מתארת נכונה את מה שיקרה כאשר תהליך בודד יקרא לפונקציה `func_b` מתוך `main`?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\npthread_mutex_t m; // Global mutex, default type (PTHREAD_MUTEX_NORMAL)\nint shared_data = 0;\n\nvoid func_a() {\n    printf(\"func_a: Attempting to lock mutex...\\n\");\n    pthread_mutex_lock(&m); // Attempt to lock\n    printf(\"func_a: Mutex locked. shared_data = %d\\n\", ++shared_data);\n    pthread_mutex_unlock(&m);\n    printf(\"func_a: Mutex unlocked.\\n\");\n}\n\nvoid func_b() {\n    printf(\"func_b: Attempting to lock mutex...\\n\");\n    pthread_mutex_lock(&m); // First lock\n    printf(\"func_b: Mutex locked. shared_data = %d. Calling func_a...\\n\", ++shared_data);\n    func_a(); // func_a will attempt to lock 'm' again\n    printf(\"func_b: Returned from func_a. shared_data = %d. Unlocking mutex...\\n\", shared_data);\n    pthread_mutex_unlock(&m); // First unlock\n    printf(\"func_b: Mutex unlocked.\\n\");\n}\n\nint main() {\n    pthread_mutex_init(&m, NULL); // Initializes 'm' as PTHREAD_MUTEX_NORMAL\n    printf(\"Main: Calling func_b...\\n\");\n    func_b();\n    printf(\"Main: func_b returned.\\n\");\n    pthread_mutex_destroy(&m);\n    return 0;\n}", "options": ["א. התוכנית תרוץ בהצלחה ותדפיס \"func_b: Mutex unlocked.\" פעמיים.", "ב. התוכנית תרוץ בהצלחה ותדפיס \"func_a: Mutex locked...\" ולאחר מכן \"func_b: Mutex unlocked.\" פעם אחת.", "ג. התוכנית תיכנס למצב של קיפאון (deadlock) כאשר `func_a` תנסה לתפוס את המנעול `m` בפעם השנייה.", "ד. התוכנית תרוץ בהצלחה אך `shared_data` יודפס עם ערך שגוי עקב תנאי מירוץ.", "ה. התוכנית תקרוס (segmentation fault) כאשר `func_a` תנסה לתפוס את המנעול `m` בפעם השנייה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג. התוכנית תיכנס למצב של קיפאון (deadlock) כאשר `func_a` תנסה לתפוס את המנעול `m` בפעם השנייה.", "explanation": "כאשר מנעול מסוג `PTHREAD_MUTEX_NORMAL` (הוא ברירת המחדל כאשר `NULL` מועבר ל-`pthread_mutex_init`) נתפס על ידי תהליך, ובהמשך אותו תהליך מנסה לתפוס את אותו מנעול שוב לפני ששחרר אותו, התהליך ייכנס למצב של קיפאון (deadlock). במקרה זה, `func_b` תופסת את המנעול `m`, ולאחר מכן קוראת ל-`func_a`. בתוך `func_a`, הפונקציה מנסה לתפוס שוב את המנעול `m` שכבר מוחזק על ידי אותו תהליך, מה שגורם לקיפאון. כדי לאפשר תפיסה חוזרת של מנעול על ידי אותו תהליך, יש לאתחל את המנעול כ-`PTHREAD_MUTEX_RECURSIVE`."}, "difficulty_estimation": "Hard", "_source_file": "0233__Mutexes__MultipleChoice__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:10:14", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Mutexes", "Concurrency", "Deadlock", "Synchronization"], "content": {"text": "נתון קטע הקוד הבא ב-C המשתמש ב-POSIX threads וב-mutex:\n```c\n#include <pthread.h>\n#include <stdio.h>\n\npthread_mutex_t mtx = PTHREAD_MUTEX_INITIALIZER;\nint shared_counter = 0;\n\nvoid safe_increment(int val) {\n    pthread_mutex_lock(&mtx);\n    if (val < 0) {\n        printf(\"Invalid value, returning.\\n\");\n        return; // Potential bug: returning without unlocking\n    }\n    shared_counter += val;\n    pthread_mutex_unlock(&mtx);\n}\n\nvoid* thread_routine(void* arg) {\n    for (int i = 0; i < 10000; ++i) {\n        safe_increment(i);\n    }\n    // If this path was taken, it would cause a deadlock:\n    // safe_increment(-1);\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, thread_routine, NULL);\n    pthread_create(&t2, NULL, thread_routine, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"Final shared_counter: %d\\n\", shared_counter);\n    return 0;\n}\n```\nבהתייחס לפונקציה `safe_increment`, איזו מהטענות הבאות נכונה לגבי פוטנציאל הבעיות בקוד?", "code_snippet": null, "options": ["א. הקוד נכון לחלוטין ואין בו פוטנציאל לבעיות תזמון (concurrency issues) או קיפאון (deadlock).", "ב. קיים בקוד מצב מרוץ (race condition) על `shared_counter` מכיוון שה-mutex אינו מגן עליו בצורה נכונה.", "ג. קיים בקוד פוטנציאל לקיפאון (deadlock) אם פונקציית `safe_increment` תקרא עם ערך שלילי.", "ד. הקוד עלול לגרום לשחרור כפול של ה-mutex (double unlock) אם פונקציית `safe_increment` תקרא עם ערך שלילי."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התשובה הנכונה היא ג'. בפונקציה `safe_increment`, ה-mutex נתפס באמצעות `pthread_mutex_lock(&mtx)`. אם התנאי `val < 0` מתקיים, הפונקציה מבצעת `return` מוקדם מבלי לשחרר את ה-mutex. במצב כזה, ה-mutex נשאר נעול, וכל ניסיון עתידי של תהליכון אחר (או של אותו תהליכון) לתפוס את ה-mutex באמצעות `pthread_mutex_lock` יחסם לצמיתות, מה שיוביל למצב של קיפאון (deadlock). אין כאן מצב מרוץ על `shared_counter` בתוך הקטע המוגן, וגם לא שחרור כפול של ה-mutex מכיוון ש-`pthread_mutex_unlock` פשוט לא נקרא כלל."}, "difficulty_estimation": "Hard", "_source_file": "0234__Mutexes__MultipleChoice__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:10:31", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Mutexes", "Deadlock", "Concurrency", "Pthreads"], "content": {"text": "נתון קטע הקוד הבא המשתמש בספריית `pthread` ב-C. מה תהיה התוצאה הסבירה ביותר כאשר תהליך יפעיל את הפונקציה `main`?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t my_mutex;\n\nvoid* bar(void* arg) {\n    printf(\"Thread %ld: Entering bar, trying to lock mutex...\\n\", (long)pthread_self());\n    pthread_mutex_lock(&my_mutex);\n    printf(\"Thread %ld: Mutex locked in bar.\\n\", (long)pthread_self());\n    // Do some work\n    sleep(1);\n    pthread_mutex_unlock(&my_mutex);\n    printf(\"Thread %ld: Mutex unlocked in bar.\\n\", (long)pthread_self());\n    return NULL;\n}\n\nvoid* foo(void* arg) {\n    printf(\"Thread %ld: Entering foo, trying to lock mutex...\\n\", (long)pthread_self());\n    pthread_mutex_lock(&my_mutex);\n    printf(\"Thread %ld: Mutex locked in foo.\\n\", (long)pthread_self());\n    \n    // Call bar from foo\n    bar(NULL); // This is the problematic part if bar tries to lock the same mutex again\n    \n    printf(\"Thread %ld: Back in foo, unlocking mutex...\\n\", (long)pthread_self());\n    pthread_mutex_unlock(&my_mutex);\n    printf(\"Thread %ld: Mutex unlocked in foo.\\n\", (long)pthread_self());\n    return NULL;\n}\n\nint main() {\n    pthread_mutex_init(&my_mutex, NULL);\n    pthread_t tid;\n    pthread_create(&tid, NULL, foo, NULL);\n    pthread_join(tid, NULL);\n    pthread_mutex_destroy(&my_mutex);\n    return 0;\n}", "options": ["א. התוכנית תרוץ בהצלחה, תדפיס הודעות מ-`foo` ולאחר מכן מ-`bar` ברצף, ותסיים פעולה.", "ב. התוכנית תיכנס למצב של קיפאון (deadlock) כאשר הפונקציה `bar` תנסה לנעול את המנעול, מכיוון שהמנעול כבר מוחזק על ידי אותו תהליך (thread).", "ג. התוכנית תקרוס עקב פעולת מנעול לא חוקית (invalid mutex operation).", "ד. התוכנית תדפיס הודעת שגיאה אך תמשיך לרוץ, כאשר `bar` לא תצליח לרכוש את המנעול."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "מנעול `pthread_mutex_t` שמאותחל עם תכונות ברירת מחדל (NULL) הוא מנעול מסוג 'רגיל' (PTHREAD_MUTEX_NORMAL). מנעול מסוג זה אינו מאפשר לתהליך (thread) שכבר מחזיק בו לנעול אותו שוב. כאשר `foo` נועלת את `my_mutex` ומיד לאחר מכן קוראת ל-`bar` שבתורה מנסה לנעול את אותו המנעול, התהליך ינסה לנעול מנעול שהוא כבר מחזיק בו. במצב כזה, `pthread_mutex_lock` יגרום לתהליך להיכנס למצב המתנה אינסופי (deadlock), מכיוון שהוא ממתין לשחרור מנעול שהוא עצמו צריך לשחרר."}, "difficulty_estimation": "Hard", "_source_file": "0235__Mutexes__MultipleChoice__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:10:47", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Mutexes", "Deadlock", "Concurrency"], "content": {"text": "נתון קטע הקוד הבא המשתמש בשני מנעולים (mutexes) ובשני תהליכונים (threads). איזה מהטענות הבאות נכונה לגבי הרצת קוד זה?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex_A;\npthread_mutex_t mutex_B;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to lock mutex_A...\\n\");\n    pthread_mutex_lock(&mutex_A);\n    printf(\"Thread 1: Locked mutex_A. Trying to lock mutex_B...\\n\");\n    sleep(1); // Simulate some work/context switch\n    pthread_mutex_lock(&mutex_B);\n    printf(\"Thread 1: Locked mutex_B. Doing work...\\n\");\n    // Do some work\n    pthread_mutex_unlock(&mutex_B);\n    pthread_mutex_unlock(&mutex_A);\n    printf(\"Thread 1: Unlocked both mutexes.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to lock mutex_B...\\n\");\n    pthread_mutex_lock(&mutex_B);\n    printf(\"Thread 2: Locked mutex_B. Trying to lock mutex_A...\\n\");\n    sleep(1); // Simulate some work/context switch\n    pthread_mutex_lock(&mutex_A);\n    printf(\"Thread 2: Locked mutex_A. Doing work...\\n\");\n    // Do some work\n    pthread_mutex_unlock(&mutex_A);\n    pthread_mutex_unlock(&mutex_B);\n    printf(\"Thread 2: Unlocked both mutexes.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n\n    pthread_mutex_init(&mutex_A, NULL);\n    pthread_mutex_init(&mutex_B, NULL);\n\n    pthread_create(&t1, NULL, thread_func1, NULL);\n    pthread_create(&t2, NULL, thread_func2, NULL);\n\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n\n    pthread_mutex_destroy(&mutex_A);\n    pthread_mutex_destroy(&mutex_B);\n\n    return 0;\n}", "options": ["א. הקוד ירוץ תמיד בהצלחה וידפיס את כל ההודעות ללא בעיות.", "ב. הקוד עלול להיכנס למצב של קיפאון (deadlock).", "ג. הקוד יגרום לשגיאת זמן ריצה (runtime error) מכיוון שמנעול ננעל פעמיים.", "ד. הקוד ירוץ אבל תוצאות העבודה המוגנת עלולות להיות שגויות עקב תנאי מירוץ (race condition).", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ההסבר: מצב של קיפאון (deadlock) עלול להתרחש. תהליכון 1 תופס את mutex_A ומנסה לתפוס את mutex_B. במקביל, תהליכון 2 תופס את mutex_B ומנסה לתפוס את mutex_A. אם שני התהליכונים תופסים את המנעול הראשון שלהם (כל אחד מנעול אחר) לפני שהשני משחרר אותו, שניהם ימתינו זה לזה באופן אינסופי, מה שיוביל לקיפאון. הוספת sleep(1) מגבירה את הסיכוי להתרחשות תרחיש זה."}, "difficulty_estimation": "Hard", "_source_file": "0236__Mutexes__MultipleChoice__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:11:01", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Synchronization", "Mutexes", "Deadlock", "Pthreads"], "content": {"text": "נתונה תוכנית C המשתמשת בספריות pthreads. תהליך (thread) תופס מנעול מסוג pthread_mutex_t שאינו מוגדר כרקרוסיבי (non-recursive). בתוך המקטע הקריטי, התהליך מנסה לתפוס את אותו המנעול בשנית. מהי התוצאה הסבירה ביותר של פעולה זו?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n\npthread_mutex_t my_mutex;\n\nvoid* thread_func(void* arg) {\n    printf(\"Thread trying to lock mutex for the first time.\\n\");\n    pthread_mutex_lock(&my_mutex);\n    printf(\"Thread acquired mutex for the first time. Trying to lock again...\\n\");\n    pthread_mutex_lock(&my_mutex); // This is the problematic line\n    printf(\"Thread acquired mutex for the second time (should not happen with non-recursive mutex).\\n\");\n    pthread_mutex_unlock(&my_mutex);\n    printf(\"Thread unlocked mutex once.\\n\");\n    pthread_mutex_unlock(&my_mutex);\n    printf(\"Thread unlocked mutex twice.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_mutex_init(&my_mutex, NULL); // Default is PTHREAD_MUTEX_NORMAL (non-recursive)\n\n    pthread_t tid;\n    pthread_create(&tid, NULL, thread_func, NULL);\n    pthread_join(tid, NULL);\n\n    pthread_mutex_destroy(&my_mutex);\n    return 0;\n}", "options": ["א. התוכנית תקרוס מיד עם ניסיון התפיסה השנייה של המנעול.", "ב. התהליך ייכנס למצב קיפאון (deadlock) וימתין לעצמו לשחרר את המנעול.", "ג. המנעול ייתפס בהצלחה בפעם השנייה, אך ישוחרר רק לאחר שחרור כפול.", "ד. התוכנית תמשיך לרוץ כרגיל, אך המנעול לא ייתפס שוב והפעולה השנייה תתעלם.", "ה. התנהגות בלתי מוגדרת (undefined behavior) כתוצאה מניסיון תפיסה כפול."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. על פי תקן POSIX, כאשר תהליך מנסה לתפוס מנעול מסוג PTHREAD_MUTEX_NORMAL (שהוא ברירת המחדל ואינו רקרוסיבי) שהוא כבר מחזיק בו, התוצאה המוגדרת היא קיפאון (deadlock). התהליך ימתין לעצמו לשחרר את המנעול, אך מכיוון שהוא זה שמחזיק בו, השחרור לא יקרה והתהליך ייתקע. מנעולים רקרוסיביים (PTHREAD_MUTEX_RECURSIVE) מאפשרים תפיסה חוזרת על ידי אותו תהליך, אך זה לא המקרה כאן. מנעולים מסוג PTHREAD_MUTEX_ERRORCHECK היו מחזירים שגיאה במקרה כזה, אך PTHREAD_MUTEX_NORMAL מוביל לקיפאון."}, "difficulty_estimation": "Hard", "_source_file": "0237__Mutexes__MultipleChoice__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:11:21", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Mutexes", "Deadlock", "Concurrency", "Synchronization"], "content": {"text": "נתון קטע הקוד הבא ב-C++:\n\n```cpp\n#include <mutex>\n#include <iostream>\n#include <thread>\n#include <vector>\n\nstd::mutex global_mtx;\nint counter = 0;\n\nclass MyProcessor {\npublic:\n    void increment_and_log() {\n        global_mtx.lock();\n        counter++;\n        std::cout << \"Counter: \" << counter << std::endl;\n        global_mtx.unlock();\n    }\n\n    void perform_complex_operation() {\n        global_mtx.lock();\n        // Some initial work...\n        std::cout << \"Performing complex operation...\" << std::endl;\n        increment_and_log(); // Calls another function that also tries to lock global_mtx\n        // More work after increment...\n        global_mtx.unlock();\n    }\n};\n\nvoid worker_thread(MyProcessor* proc) {\n    proc->perform_complex_operation();\n}\n\nint main() {\n    MyProcessor processor_obj;\n    std::thread t1(worker_thread, &processor_obj);\n    std::thread t2(worker_thread, &processor_obj);\n    t1.join();\n    t2.join();\n    std::cout << \"Final counter value: \" << counter << std::endl;\n    return 0;\n}\n```\n\nמה יקרה כאשר תוכנית זו תורץ?", "code_snippet": null, "options": ["א. התוכנית תרוץ ללא בעיות ותדפיס את המונה הסופי 2.", "ב. התוכנית תקרוס (crash) עקב שגיאת זמן ריצה (runtime error) הקשורה לנעילה כפולה.", "ג. התוכנית תיכנס למצב של קיפאון (deadlock) כאשר אחד מהתהליכים ינסה לנעול את המוטקס בשנית.", "ד. התוכנית תיכנס למצב של תחרות (race condition) אשר עלול להוביל לערך סופי שגוי של המונה.", "ה. התוכנית תיכנס למצב של קיפאון (deadlock) כאשר שני התהליכים ינסו לנעול את המוטקס בו זמנית."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התשובה הנכונה היא ג'.\nהקוד מדגים שימוש ב-`std::mutex` רגיל, שאינו מוטקס רקורסיבי. מוטקס רגיל אינו מאפשר לאותו תהליך לנעול אותו מספר פעמים. כאשר תהליך מנסה לנעול מוטקס שכבר נמצא בבעלותו, הקריאה ל-`lock()` תיחסם לנצח, מה שמוביל למצב של קיפאון (deadlock) עבור אותו תהליך.\n\nבמקרה זה:\n1.  הפונקציה `perform_complex_operation` נועלת את `global_mtx`.\n2.  בתוך `perform_complex_operation`, נקראת הפונקציה `increment_and_log`.\n3.  הפונקציה `increment_and_log` מנסה לנעול את `global_mtx` *שוב*.\nמכיוון ש-`global_mtx` כבר נעול על ידי אותו תהליך, הקריאה השנייה ל-`global_mtx.lock()` תגרום לתהליך להיכנס למצב המתנה אינסופי (deadlock), מכיוון שלעולם לא ישוחרר על ידי תהליך אחר, והוא עצמו לא יכול לשחרר אותו לפני שתפיסת הנעילה השנייה תושלם. שני התהליכים יגיעו למצב זה, כל אחד בנפרד, וכך התוכנית כולה תיתקע.\nכדי לפתור בעיה זו, ניתן להשתמש ב-`std::recursive_mutex` במקום `std::mutex`, או לתכנן מחדש את הקוד כך שמוטקס לא יילקח פעמיים על ידי אותו תהליך."}, "difficulty_estimation": "Hard", "_source_file": "0238__Mutexes__MultipleChoice__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:11:43", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Mutexes", "Synchronization", "Deadlock", "Pthreads"], "content": {"text": "נתבונן בקטע הקוד הבא ב-C, בו תהליך יחיד מבצע קריאה לפונקציה `funcA`, אשר רוכשת מנעול (mutex) ולאחר מכן קוראת לפונקציה `funcB`. `funcB` מנסה לרכוש את אותו המנעול שכבר נרכש על ידי `funcA` באותו התהליך. בהנחה שהמנעול `my_mutex` מאותחל כ-`PTHREAD_MUTEX_NORMAL` (ברירת המחדל), מה תהיה התוצאה הסבירה ביותר?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\npthread_mutex_t my_mutex; // Global mutex\n\nvoid funcB() {\n    printf(\"funcB: Attempting to acquire mutex...\\n\");\n    pthread_mutex_lock(&my_mutex);\n    printf(\"funcB: Mutex acquired.\\n\");\n    // Critical section for funcB\n    pthread_mutex_unlock(&my_mutex);\n    printf(\"funcB: Mutex released.\\n\");\n}\n\nvoid funcA() {\n    printf(\"funcA: Attempting to acquire mutex...\\n\");\n    pthread_mutex_lock(&my_mutex);\n    printf(\"funcA: Mutex acquired.\\n\");\n    // Call funcB, which tries to acquire the same mutex\n    funcB();\n    printf(\"funcA: After funcB call.\\n\");\n    pthread_mutex_unlock(&my_mutex);\n    printf(\"funcA: Mutex released.\\n\");\n}\n\n// In main, assume a single thread calls funcA() after mutex initialization:\n// pthread_mutex_init(&my_mutex, NULL); // Initializes as PTHREAD_MUTEX_NORMAL\n// funcA();", "options": ["א. התוכנית תרוץ בהצלחה, שכן מנעול רגיל מאפשר רכישה חוזרת על ידי אותו תהליך.", "ב. התוכנית תיכנס למצב של קיפאון (deadlock) כאשר `funcB` תנסה לרכוש את המנעול, מכיוון שהמנעול כבר מוחזק על ידי אותו תהליך ולא ניתן לרכוש אותו שוב.", "ג. `pthread_mutex_lock` בתוך `funcB` תחזיר שגיאה ותוציא את התוכנית מריצה.", "ד. המערכת תזהה שמדובר באותו תהליך ותאפשר ל-`funcB` לרכוש את המנעול באופן מיידי ללא חסימה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הסבר: מנעול מסוג `PTHREAD_MUTEX_NORMAL` אינו מאפשר רכישה חוזרת (reentrant) על ידי אותו התהליך. כאשר `funcA` רוכשת את `my_mutex`, היא הופכת לבעלים של המנעול. כאשר `funcA` קוראת ל-`funcB`, ו-`funcB` מנסה לרכוש את אותו המנעול באמצעות `pthread_mutex_lock`, המנעול כבר מוחזק על ידי אותו תהליך. מכיוון שהמנעול אינו רב-כניסתי (non-recursive), הקריאה ל-`pthread_mutex_lock` בתוך `funcB` תגרום לתהליך לחכות לעצמו לשחרר את המנעול, מה שמוביל למצב של קיפאון (deadlock). כדי למנוע זאת, ניתן להשתמש במנעול מסוג `PTHREAD_MUTEX_RECURSIVE` אשר מאפשר לתהליך לרכוש את אותו המנעול מספר פעמים."}, "difficulty_estimation": "Hard", "_source_file": "0239__Mutexes__MultipleChoice__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:11:58", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Mutexes", "Deadlock", "Concurrency", "Synchronization"], "content": {"text": "נתון קוד C++ הבא המשתמש ב-std::mutex וב-std::thread. מהי הטענה הנכונה ביותר לגבי הרצת התוכנית?", "code_snippet": "#include <iostream>\n#include <thread>\n#include <mutex>\n#include <chrono>\n\nstd::mutex mtx1;\nstd::mutex mtx2;\n\nvoid thread_func_A() {\n    mtx1.lock();\n    std::this_thread::sleep_for(std::chrono::milliseconds(10)); // Simulate work/delay\n    mtx2.lock();\n    std::cout << \"Thread A acquired both locks\\n\";\n    mtx2.unlock();\n    mtx1.unlock();\n}\n\nvoid thread_func_B() {\n    mtx2.lock();\n    std::this_thread::sleep_for(std::chrono::milliseconds(10)); // Simulate work/delay\n    mtx1.lock();\n    std::cout << \"Thread B acquired both locks\\n\";\n    mtx1.unlock();\n    mtx2.unlock();\n}\n\nint main() {\n    std::thread t1(thread_func_A);\n    std::thread t2(thread_func_B);\n    t1.join();\n    t2.join();\n    return 0;\n}", "options": ["א. התוכנית תמיד תרוץ בהצלחה ותדפיס את שתי ההודעות.", "ב. התוכנית תמיד תיכנס למצב של קיפאון (deadlock).", "ג. התוכנית עשויה להיכנס למצב של קיפאון (deadlock), אך אינה מובטחת לעשות זאת.", "ד. התוכנית עלולה לגרום לתנאי מרוץ (race condition) עקב שימוש לא נכון במנעולים.", "ה. התוכנית תרוץ בהצלחה, אך סדר ההדפסה אינו מובטח."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הקוד מדגים תרחיש קלאסי של קיפאון (deadlock). שני התהליכונים (threads) מנסים לתפוס שני מנעולים (mutexes) בסדר הפוך. תהליכון A תופס את mtx1 ואז מנסה לתפוס את mtx2. תהליכון B תופס את mtx2 ואז מנסה לתפוס את mtx1. אם מתזמן המערכת (scheduler) יאפשר לתהליכון A לתפוס את mtx1 ולתהליכון B לתפוס את mtx2 בערך באותו זמן, לפני שאחד מהם מספיק לתפוס את המנעול השני, שניהם ייחסמו ויחכו זה לזה באופן אינסופי. עם זאת, קיפאון אינו מובטח. ייתכן שאחד התהליכונים יספיק לתפוס את שני המנעולים ולשחרר אותם לפני שהתהליכון השני יגיע לנקודת התנגשות, ובמקרה כזה התוכנית תרוץ בהצלחה. לכן, התוכנית עשויה להיכנס לקיפאון, אך זה לא מובטח."}, "difficulty_estimation": "Hard", "_source_file": "0240__Mutexes__MultipleChoice__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:12:14", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Mutexes", "Synchronization", "Race Conditions", "Threads"], "content": {"text": "נתונה תוכנית C פשוטה המשתמשת במשתנה גלובלי משותף `shared_counter` המוגדל על ידי מספר תהליכונים (threads) במקביל.\nא. הסבר מדוע הקוד הנתון עלול להוביל לתוצאות שגויות.\nב. הצע פתרון לבעיה באמצעות שימוש ב-mutex, ועדכן את קטע הקוד בהתאם.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint shared_counter = 0; // משתנה גלובלי משותף\n\nvoid* increment_thread(void* arg) {\n    for (int i = 0; i < 100000; i++) {\n        shared_counter++; // פעולה לא אטומית\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid[2]; // נניח שני תהליכונים\n    \n    // יצירת התהליכונים\n    pthread_create(&tid[0], NULL, increment_thread, NULL);\n    pthread_create(&tid[1], NULL, increment_thread, NULL);\n    \n    // המתנה לסיום התהליכונים\n    pthread_join(tid[0], NULL);\n    pthread_join(tid[1], NULL);\n    \n    printf(\"Final counter value: %d\\n\", shared_counter);\n    \n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. הבעיה בקוד הנתון היא תנאי מרוץ (race condition). הפעולה `shared_counter++` אינה פעולה אטומית. היא מורכבת למעשה משלוש פעולות:\n1. קריאת הערך הנוכחי של `shared_counter` לתוך אוגר.\n2. הגדלת הערך באוגר ב-1.\n3. כתיבת הערך החדש מהאוגר בחזרה ל-`shared_counter`.\nכאשר מספר תהליכונים מבצעים את הפעולה הזו במקביל, ייתכן ששני תהליכונים יקראו את אותו ערך של `shared_counter` לפני שאחד מהם הספיק לכתוב בחזרה את הערך המוגדל. במקרה כזה, הגדלה אחת תאבד, והמונה הסופי יהיה נמוך מהצפוי. לדוגמה, אם `shared_counter` הוא 0, תהליכון A קורא 0, תהליכון B קורא 0. תהליכון A מגדיל ל-1 וכותב 1. תהליכון B מגדיל ל-1 וכותב 1. במקום 2, המונה נשאר 1.\n\nב. כדי לפתור את בעיית תנאי המרוץ, נשתמש ב-mutex (מנעול הדדי). Mutex מבטיח שרק תהליכון אחד יוכל להיכנס לקטע קריטי (critical section) בכל רגע נתון. הקטע הקריטי במקרה זה הוא הפעולה `shared_counter++`.\n\nנאתחל משתנה `pthread_mutex_t`, ננעל אותו לפני הקטע הקריטי ונשחרר אותו אחריו.\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n\nint shared_counter = 0;\npthread_mutex_t counter_mutex; // הצהרה על mutex\n\nvoid* increment_thread_safe(void* arg) {\n    for (int i = 0; i < 100000; i++) {\n        pthread_mutex_lock(&counter_mutex); // נעל את המוטקס\n        shared_counter++;                   // קטע קריטי מוגן\n        pthread_mutex_unlock(&counter_mutex); // שחרר את המוטקס\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid[2];\n    \n    // אתחול המוטקס\n    pthread_mutex_init(&counter_mutex, NULL);\n    \n    // יצירת התהליכונים\n    pthread_create(&tid[0], NULL, increment_thread_safe, NULL);\n    pthread_create(&tid[1], NULL, increment_thread_safe, NULL);\n    \n    // המתנה לסיום התהליכונים\n    pthread_join(tid[0], NULL);\n    pthread_join(tid[1], NULL);\n    \n    printf(\"Final counter value: %d\\n\", shared_counter);\n    \n    // השמדת המוטקס\n    pthread_mutex_destroy(&counter_mutex);\n    \n    return 0;\n}\n```\nבפתרון זה, בכל פעם שתהליכון רוצה לגשת ל-`shared_counter`, הוא מנסה לנעול את `counter_mutex`. אם המוטקס כבר נעול על ידי תהליכון אחר, התהליכון הנוכחי ימתין עד שהמוטקס ישוחרר. לאחר שהפעולה `shared_counter++` הסתיימה, המוטקס משוחרר, ומאפשר לתהליכון אחר לגשת לקטע הקריטי. כך מובטח שרק תהליכון אחד מבצע את ההגדלה בכל רגע נתון, והתוצאה הסופית תהיה נכונה (200,000 במקרה זה)."}, "difficulty_estimation": "Easy", "_source_file": "0241__Mutexes__Open__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:12:37", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Mutexes", "Synchronization", "Race Conditions"], "content": {"text": "נתונה תוכנית C בה מספר חוטים (threads) מנסים לעדכן מונה גלובלי משותף (global shared counter) במקביל. קוד התוכנית מוצג מטה.\nהסבירו מדוע קוד זה עלול להוביל לתוצאות שגויות, והציעו פתרון לבעיה באמצעות שימוש במוטקס (mutex) על ידי הצגת הקוד המתוקן במלואו.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 100000\n\nlong long global_counter = 0;\n\nvoid *thread_function(void *arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; i++) {\n        global_counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    for (int i = 0; i < NUM_THREADS; i++) {\n        pthread_create(&threads[i], NULL, thread_function, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %lld\\n\", global_counter);\n    printf(\"Expected value: %lld\\n\", (long long)NUM_THREADS * INCREMENTS_PER_THREAD);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הבעיה בקוד המקורי היא תנאי מירוץ (race condition). מספר חוטים ניגשים ומשנים את המשתנה המשותף `global_counter` בו זמנית. הפעולה `global_counter++` אינה אטומית; היא מורכבת מקריאת הערך הנוכחי, הגדלתו באחד, וכתיבת הערך החדש בחזרה. אם שני חוטים או יותר מנסים לבצע פעולה זו במקביל, ייתכן שחוט אחד יקרא את הערך, חוט שני יקרא את אותו ערך לפני שהחוט הראשון הספיק לכתוב את הערך המוגדל, ושניהם יגדילו את אותו ערך ויכתבו אותו בחזרה, מה שיוביל לאובדן עדכונים ולתוצאה סופית שגויה (נמוכה מהצפוי).\n\nכדי לפתור את תנאי המירוץ, נשתמש במוטקס (mutex) כדי להבטיח שרק חוט אחד יוכל לגשת לקטע הקריטי (העדכון של `global_counter`) בכל רגע נתון. המוטקס יגן על המשתנה המשותף. לפני עדכון המונה, כל חוט ינעל את המוטקס באמצעות `pthread_mutex_lock`. לאחר העדכון, החוט ישחרר את המוטקס באמצעות `pthread_mutex_unlock`. בנוסף, יש לאתחל את המוטקס לפני השימוש ולשחרר את המשאבים שלו בסיום.\n\nהקוד המתוקן:\n```c\n#include <stdio.h>\n#include <pthread.h>\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 100000\n\nlong long global_counter = 0;\npthread_mutex_t counter_mutex; // הצהרה על מוטקס\n\nvoid *thread_function(void *arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; i++) {\n        pthread_mutex_lock(&counter_mutex); // נעילת המוטקס\n        global_counter++;\n        pthread_mutex_unlock(&counter_mutex); // שחרור המוטקס\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    pthread_mutex_init(&counter_mutex, NULL); // אתחול המוטקס\n\n    for (int i = 0; i < NUM_THREADS; i++) {\n        pthread_create(&threads[i], NULL, thread_function, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %lld\\n\", global_counter);\n    printf(\"Expected value: %lld\\n\", (long long)NUM_THREADS * INCREMENTS_PER_THREAD);\n\n    pthread_mutex_destroy(&counter_mutex); // שחרור משאבי המוטקס\n\n    return 0;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0242__Mutexes__Open__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:12:58", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Mutexes", "Synchronization", "Concurrency"], "content": {"text": "הסבירו את מטרתו של mutex בתכנות מקבילי. ספקו דוגמת קוד פשוטה ב-C/C++ המדגימה כיצד להשתמש ב-mutex כדי להגן על משתנה גלובלי משותף מפני תנאי מירוץ (race conditions).", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "מטרתו העיקרית של mutex (קיצור של Mutual Exclusion) היא להבטיח שרק תהליך או תהליכון אחד יגש לקטע קוד קריטי (critical section) או למשאב משותף בזמן נתון. זה מונע תנאי מירוץ (race conditions) ומוודא עקביות נתונים בסביבה מקבילית. כאשר תהליכון רוצה לגשת למשאב מוגן, הוא מנסה 'לנעול' את ה-mutex (באמצעות `mtx.lock()`). אם ה-mutex פנוי, הוא ננעל והתהליכון ממשיך. אם ה-mutex כבר נעול על ידי תהליכון אחר, התהליכון המבקש ממתין עד שה-mutex ישוחרר. לאחר סיום השימוש במשאב, התהליכון 'משחרר' את ה-mutex (באמצעות `mtx.unlock()`).\n\nדוגמת קוד המדגימה שימוש ב-mutex להגנה על משתנה גלובלי משותף:\n```cpp\n#include <iostream>\n#include <thread>\n#include <mutex>\n\n// משתנה גלובלי משותף\nint shared_counter = 0;\n\n// Mutex להגנה על shared_counter\nstd::mutex mtx;\n\nvoid increment_counter() {\n    for (int i = 0; i < 100000; ++i) {\n        mtx.lock(); // נעל את ה-mutex\n        shared_counter++; // קטע קריטי\n        mtx.unlock(); // שחרר את ה-mutex\n    }\n}\n\nint main() {\n    // צור מספר תהליכונים\n    std::thread t1(increment_counter);\n    std::thread t2(increment_counter);\n\n    // המתן לסיום התהליכונים\n    t1.join();\n    t2.join();\n\n    // הדפס את הערך הסופי\n    std::cout << \"Final counter value: \" << shared_counter << std::endl;\n\n    return 0;\n}\n```\nבדוגמה זו, שני תהליכונים `t1` ו-`t2` מנסים להגדיל משתנה גלובלי `shared_counter` במקביל. ללא ה-mutex, קיימת סבירות גבוהה לתנאי מירוץ ולערך סופי שגוי של `shared_counter`. השימוש ב-`mtx.lock()` ו-`mtx.unlock()` מבטיח שרק תהליכון אחד יגדיל את המונה בכל רגע נתון, ובכך מונע תנאי מירוץ ומבטיח שהערך הסופי יהיה נכון (200,000 במקרה זה)."}, "difficulty_estimation": "Easy", "_source_file": "0243__Mutexes__Open__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:13:15", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Mutexes", "Synchronization", "Concurrency"], "content": {"text": "מהו Mutex (מנעול הדדי) בהקשר של מערכות הפעלה ותכנות מקבילי? הסבר את מטרתו העיקרית ואת שתי הפעולות הבסיסיות הקשורות אליו. מדוע הוא חיוני בתוכניות מרובות חוטים?", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "Mutex (מנעול הדדי) הוא אובייקט סנכרון המשמש בתכנות מקבילי כדי לאכוף בלעדיות הדדית (mutual exclusion) על משאב משותף או קטע קוד קריטי. מטרתו העיקרית היא למנוע תנאי מרוץ (race conditions) ולהבטיח שרק חוט אחד (thread) יוכל לגשת למשאב המוגן בכל רגע נתון.\n\nשתי הפעולות הבסיסיות הקשורות ל-Mutex הן:\n1.  **lock()** (או `acquire()` / `wait()`): כאשר חוט מעוניין לגשת לקטע קוד קריטי או למשאב משותף המוגן על ידי Mutex, הוא מנסה לרכוש את המנעול באמצעות פעולה זו. אם המנעול פנוי, החוט רוכש אותו וממשיך בביצוע. אם המנעול כבר מוחזק על ידי חוט אחר, החוט הנוכחי נחסם (מושהה) וממתין עד שהמנעול ישוחרר.\n2.  **unlock()** (או `release()` / `signal()`): לאחר שחוט סיים את עבודתו עם המשאב המוגן, הוא משחרר את המנעול באמצעות פעולה זו. שחרור המנעול מאפשר לחוטים אחרים הממתינים לרכוש אותו ולהמשיך בביצוע.\n\nMutexים חיוניים בתוכניות מרובות חוטים מכיוון שללא מנגנון סנכרון כזה, גישה בו-זמנית של מספר חוטים לנתונים משותפים עלולה להוביל לחוסר עקביות בנתונים, לתוצאות שגויות ולבאגים קשים לאיתור (תנאי מרוץ). Mutex מבטיח שהנתונים יישארו עקביים ובמצב תקין על ידי מתן גישה מבוקרת ובלעדית לנתונים אלו."}, "difficulty_estimation": "Easy", "_source_file": "0244__Mutexes__Open__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:13:24", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Mutexes", "Synchronization", "Race Conditions"], "content": {"text": "מהו Mutex ומדוע הוא נחוץ במערכות מרובות חוטים? הסבר כיצד Mutex פועל כדי למנוע תנאי מירוץ. הצג דוגמת קוד פשוטה ב-C/C++ הממחישה שימוש ב-Mutex להגנה על מונה משותף המעודכן על ידי מספר חוטים.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "Mutex (קיצור של Mutual Exclusion) הוא מנגנון סנכרון המשמש במערכות מרובות חוטים (multi-threaded) כדי להבטיח שרק חוט אחד יוכל לגשת לקטע קוד קריטי או למשאב משותף (כמו משתנה גלובלי, קובץ, או מבנה נתונים) בכל רגע נתון. זה מונע 'תנאי מירוץ' (race conditions) שבהם סדר הגישה הלא מבוקר של חוטים מרובים למשאב משותף יכול להוביל לתוצאות שגויות או בלתי צפויות. Mutex פועל על ידי מתן 'נעילה' (lock) לחוט המבקש לגשת למשאב. אם המשאב נעול, חוטים אחרים המנסים לגשת אליו ימתינו עד שהחוט הנוכחי ישחרר את הנעילה (unlock).\n\nדוגמת קוד ב-C/C++ הממחישה שימוש ב-Mutex להגנה על מונה משותף:\n\n```c\n#include <iostream>\n#include <pthread.h>\n#include <vector>\n\n// משאב משותף\nint shared_counter = 0;\n\n// Mutex להגנה על המונה המשותף\npthread_mutex_t counter_mutex;\n\n// פונקציית החוט\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < 100000; ++i) {\n        // נעל את המוטקס לפני הגישה לקטע הקריטי\n        pthread_mutex_lock(&counter_mutex);\n        shared_counter++; // קטע קריטי\n        // שחרר את המוטקס לאחר סיום הגישה לקטע הקריטי\n        pthread_mutex_unlock(&counter_mutex);\n    }\n    return NULL;\n}\n\nint main() {\n    // אתחול המוטקס\n    pthread_mutex_init(&counter_mutex, NULL);\n\n    const int NUM_THREADS = 5;\n    std::vector<pthread_t> threads(NUM_THREADS);\n\n    // יצירת והפעלת החוטים\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, increment_counter, NULL);\n    }\n\n    // המתנה לסיום כל החוטים\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    // השמדת המוטקס\n    pthread_mutex_destroy(&counter_mutex);\n\n    // הדפסת הערך הסופי של המונה המשותף\n    std::cout << \"Final shared counter value: \" << shared_counter << std::endl;\n    // הערך הצפוי הוא 5 * 100000 = 500000\n\n    return 0;\n}\n```\nבדוגמה זו, `pthread_mutex_lock` מבטיח שרק חוט אחד יכול להיכנס לקטע שבו `shared_counter` מוגדל. חוטים אחרים שינסו לקרוא ל-`pthread_mutex_lock` כאשר המוטקס כבר נעול, ימתינו עד שהמוטקס ישוחרר על ידי `pthread_mutex_unlock`."}, "difficulty_estimation": "Easy", "_source_file": "0245__Mutexes__Open__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:13:37", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Mutexes", "Synchronization", "Concurrency", "Threads"], "content": {"text": "הסבר/י בקצרה מהו Mutex (מנעול הדדי) ומה מטרתו העיקרית בתכנות מקבילי.\nהדגם/הדגימי באמצעות קטע קוד פשוט ב-C/C++ כיצד ניתן להשתמש ב-Mutex כדי להגן על משאב משותף (לדוגמה, מונה גלובלי) מפני תנאי מירוץ (Race Condition) כאשר מספר תהליכונים (threads) מנסים לגשת אליו ולעדכן אותו בו זמנית.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "Mutex (מנעול הדדי) הוא אובייקט סנכרון בסיסי המשמש להבטחת בלעדיות הדדית (mutual exclusion) בגישה למשאבים משותפים (כמו משתנים גלובליים, מבני נתונים, קבצים ועוד) בסביבת ריבוי תהליכונים (multi-threading).\nמטרתו העיקרית היא למנוע תנאי מירוץ (Race Conditions), מצב שבו מספר תהליכונים ניגשים למשאב משותף בו-זמנית, ולפחות אחד מהם מבצע שינוי, מה שעלול להוביל לתוצאות בלתי צפויות ולא עקביות.\nMutex מבטיח שרק תהליכון אחד יכול \"לנעול\" (lock) את המשאב, לגשת אליו ולבצע עליו פעולות, ולאחר מכן \"לשחרר\" (unlock) אותו. כל תהליכון אחר שינסה לנעול את ה-Mutex כשהוא כבר נעול ימתין עד שהתהליכון הנוכחי ישחרר אותו.\n\nדוגמה לקטע קוד ב-C/C++ המשתמש ב-Mutex להגנה על מונה גלובלי:\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#define NUM_THREADS 5\n#define ITERATIONS_PER_THREAD 100000\n\nint shared_counter = 0;\npthread_mutex_t counter_mutex;\n\n// פונקציית התהליכון המגדילה את המונה המשותף\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < ITERATIONS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&counter_mutex); // נעל את ה-Mutex לפני גישה למשאב המשותף\n        shared_counter++; // אזור קריטי: גישה למשתנה משותף\n        pthread_mutex_unlock(&counter_mutex); // שחרר את ה-Mutex לאחר סיום הגישה\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    // אתחול ה-Mutex\n    if (pthread_mutex_init(&counter_mutex, NULL) != 0) {\n        fprintf(stderr, \"Mutex init failed\\n\");\n        return 1;\n    }\n\n    // יצירת תהליכונים\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        if (pthread_create(&threads[i], NULL, increment_counter, NULL) != 0) {\n            fprintf(stderr, \"Thread creation failed\\n\");\n            return 1;\n        }\n    }\n\n    // המתנה לסיום כל התהליכונים\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    // השמדת ה-Mutex (שחרור משאבי מערכת)\n    pthread_mutex_destroy(&counter_mutex);\n\n    printf(\"Final shared_counter value: %d\\n\", shared_counter);\n    printf(\"Expected value: %d\\n\", NUM_THREADS * ITERATIONS_PER_THREAD);\n\n    return 0;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0246__Mutexes__Open__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:13:59", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Mutexes", "Synchronization", "Race Conditions"], "content": {"text": "הסבר בקצרה מהו Mutex ומדוע הוא נחוץ במערכות מרובות תהליכונים (multithreaded systems). לאחר מכן, נתון קטע קוד המכיל משתנה גלובלי משותף. הוסף לקטע הקוד שימוש ב-Mutex על מנת להבטיח גישה בטוחה למשתנה המשותף ולמנוע תנאי מרוץ (race conditions).", "code_snippet": "```c\n#include <stdio.h>\n#include <pthread.h>\n\nint global_counter = 0;\n\nvoid* increment_thread(void* arg) {\n    for (int i = 0; i < 100000; ++i) {\n        // קטע קריטי: הגדלת global_counter\n        global_counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_create(&tid1, NULL, increment_thread, NULL);\n    pthread_create(&tid2, NULL, increment_thread, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    printf(\"Final counter value: %d\\n\", global_counter);\n\n    return 0;\n}\n```", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "Mutex (קיצור של Mutual Exclusion) הוא מנגנון סנכרון המשמש להגנה על משאבים משותפים במערכות מרובות תהליכונים. מטרתו העיקרית היא למנוע תנאי מרוץ (race conditions) שבהם גישה סימולטנית למשאב משותף עלולה להוביל לתוצאות בלתי צפויות או שגויות. Mutex מבטיח שרק תהליכון אחד יוכל לגשת לקטע קריטי (critical section) של קוד בו מעורב המשאב המשותף בכל רגע נתון. כאשר תהליכון רוצה לגשת למשאב, הוא נועל את ה-mutex. אם ה-mutex כבר נעול על ידי תהליכון אחר, התהליכון המבקש ימתין עד שה-mutex ישוחרר. לאחר סיום השימוש במשאב, התהליכון משחרר את ה-mutex, ומאפשר לתהליכונים אחרים לגשת אליו.\n\nלהלן קטע הקוד המתוקן עם שימוש ב-Mutex:\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n\nint global_counter = 0;\npthread_mutex_t counter_mutex; // הגדרת Mutex\n\nvoid* increment_thread(void* arg) {\n    for (int i = 0; i < 100000; ++i) {\n        pthread_mutex_lock(&counter_mutex); // נעילת Mutex לפני הכניסה לקטע הקריטי\n        global_counter++; // קטע קריטי\n        pthread_mutex_unlock(&counter_mutex); // שחרור Mutex לאחר היציאה מהקטע הקריטי\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&counter_mutex, NULL); // אתחול Mutex\n\n    pthread_create(&tid1, NULL, increment_thread, NULL);\n    pthread_create(&tid2, NULL, increment_thread, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    pthread_mutex_destroy(&counter_mutex); // השמדת Mutex\n\n    printf(\"Final counter value: %d\\n\", global_counter);\n\n    return 0;\n}\n```\n\nבמימוש המתוקן, המשתנה `counter_mutex` מוגדר כ- `pthread_mutex_t`. לפני יצירת התהליכונים, ה-mutex מאותחל באמצעות `pthread_mutex_init`. בתוך הפונקציה `increment_thread`, קריאות ל-`pthread_mutex_lock` ו-`pthread_mutex_unlock` עוטפות את הקטע הקריטי (`global_counter++`). זה מבטיח שרק תהליכון אחד יכול לגשת ל-`global_counter` בכל רגע נתון, ובכך מונע תנאי מרוץ ומבטיח שהערך הסופי של המונה יהיה נכון (200000 במקרה זה). בסיום התוכנית, ה-mutex מושמד באמצעות `pthread_mutex_destroy`."}, "difficulty_estimation": "Easy", "_source_file": "0247__Mutexes__Open__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:14:10", "_subject": "Concurrency"}, {"id": 100, "type": "Open", "topic": ["Mutexes", "Synchronization", "Race Conditions"], "content": {"text": "מהו מנעול הדדי (Mutex) ומה מטרתו העיקרית בתכנות מקבילי? הסבר כיצד שימוש במנעול הדדי יכול למנוע תנאי מירוץ (race conditions) כאשר מספר תהליכים או תהליכונים ניגשים למשאב משותף.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "מנעול הדדי (Mutex) הוא אובייקט סנכרון המשמש להבטחת גישה בלעדית למשאב משותף (critical section) בזמן נתון. מטרתו העיקרית היא למנוע תנאי מירוץ (race conditions), מצב שבו תוצאת הפעלת התוכנית תלויה בסדר הלא צפוי שבו תהליכים או תהליכונים ניגשים ומשנים נתונים משותפים.\n\nכאשר תהליך/תהליכון רוצה לגשת למשאב משותף, הוא מנסה לנעול את המוטקס (acquire/lock). אם המוטקס אינו נעול, התהליך/תהליכון נועל אותו ומקבל גישה בלעדית למשאב. אם המוטקס כבר נעול על ידי תהליך/תהליכון אחר, התהליך/תהליכון המנסה לנעול ימתין עד שהמוטקס ישוחרר. לאחר שהתהליך/תהליכון מסיים את השימוש במשאב המשותף, הוא משחרר את המוטקס (release/unlock), ובכך מאפשר לתהליכים/תהליכונים אחרים לגשת למשאב. מנגנון זה מבטיח שבכל רגע נתון, רק תהליך/תהליכון אחד יכול לגשת לאזור הקריטי, ובכך מונע תנאי מירוץ ומשמר את עקביות הנתונים.", "code_snippet": null}, "difficulty_estimation": "Easy", "_source_file": "0248__Mutexes__Open__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:14:20", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Mutexes", "Deadlocks", "Synchronization"], "content": {"text": "נתונה תוכנית המשתמשת בשני חוטים (threads) ובשני משאבים (resources), R1 ו-R2, שכל אחד מהם מוגן על ידי מנעול (mutex) משלו, `mutex_R1` ו-`mutex_R2` בהתאמה. כל חוט צריך לגשת לשני המשאבים כדי לבצע את פעולתו. הקוד הבא מציג את לוגיקת הגישה למשאבים עבור שני החוטים:\n\n```c\npthread_mutex_t mutex_R1;\npthread_mutex_t mutex_R2;\n\nvoid* thread_func1(void* arg) {\n    pthread_mutex_lock(&mutex_R1);\n    // Do something with R1\n    pthread_mutex_lock(&mutex_R2);\n    // Do something with R1 and R2\n    pthread_mutex_unlock(&mutex_R2);\n    pthread_mutex_unlock(&mutex_R1);\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    pthread_mutex_lock(&mutex_R2);\n    // Do something with R2\n    pthread_mutex_lock(&mutex_R1);\n    // Do something with R1 and R2\n    pthread_mutex_unlock(&mutex_R1);\n    pthread_mutex_unlock(&mutex_R2);\n    return NULL;\n}\n\nint main() {\n    pthread_mutex_init(&mutex_R1, NULL);\n    pthread_mutex_init(&mutex_R2, NULL);\n\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, thread_func1, NULL);\n    pthread_create(&t2, NULL, thread_func2, NULL);\n\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n\n    pthread_mutex_destroy(&mutex_R1);\n    pthread_mutex_destroy(&mutex_R2);\n    return 0;\n}\n```\n\nהאם קיים סיכון לקיפאון (deadlock) בתוכנית זו? אם כן, הסבירו בפירוט מדוע וכיצד ניתן למנוע אותו. אם לא, הסבירו מדוע.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, קיים סיכון לקיפאון (deadlock) בתוכנית זו. קיפאון יתרחש כאשר כל אחד מהחוטים יחזיק במנעול אחד וימתין למנעול השני, שמוחזק על ידי החוט האחר.\n\nהסבר מפורט: ארבעת התנאים לקיפאון מתקיימים במקרה זה:\n1.  **הדרה הדדית (Mutual Exclusion)**: כל מנעול (`mutex_R1`, `mutex_R2`) מגן על משאב אחד ורק חוט אחד יכול להחזיק בו בזמן נתון. תנאי זה מתקיים.\n2.  **החזקה והמתנה (Hold and Wait)**: חוט יכול להחזיק במנעול אחד (לדוגמה, `thread_func1` מחזיק ב-`mutex_R1`) ובמקביל להמתין למנעול אחר (לדוגמה, `thread_func1` ממתין ל-`mutex_R2`). תנאי זה מתקיים.\n3.  **אי-נשללות (No Preemption)**: לא ניתן לשלול מנעול מחוט שמחזיק בו בכוח. המנעול ישוחרר רק מרצון על ידי החוט שמחזיק בו. תנאי זה מתקיים.\n4.  **המתנה מעגלית (Circular Wait)**: קיים מעגל של המתנה. `thread_func1` מחזיק ב-`mutex_R1` וממתין ל-`mutex_R2`. במקביל, `thread_func2` מחזיק ב-`mutex_R2` וממתין ל-`mutex_R1`. נוצר מעגל שבו כל חוט ממתין למשאב שמוחזק על ידי החוט האחר. תנאי זה מתקיים.\n\nתרחיש לדוגמה לקיפאון:\n1.  `thread_func1` מבצע `pthread_mutex_lock(&mutex_R1)` ומצליח לרכוש את `mutex_R1`.\n2.  `thread_func2` מבצע `pthread_mutex_lock(&mutex_R2)` ומצליח לרכוש את `mutex_R2`.\n3.  `thread_func1` מנסה לבצע `pthread_mutex_lock(&mutex_R2)` אך נחסם, מכיוון ש-`mutex_R2` מוחזק על ידי `thread_func2`.\n4.  `thread_func2` מנסה לבצע `pthread_mutex_lock(&mutex_R1)` אך נחסם, מכיוון ש-`mutex_R1` מוחזק על ידי `thread_func1`.\nבשלב זה, שני החוטים חסומים באופן הדדי ואינם יכולים להמשיך, והתוכנית נמצאת בקיפאון.\n\nמניעת קיפאון:\nהדרך הנפוצה למנוע קיפאון זה היא על ידי אכיפת סדר עולמי קבוע לרכישת המנעולים. כלומר, כל החוטים המעורבים חייבים לרכוש את המנעולים באותו סדר. במקרה זה, ניתן להחליט ש-`mutex_R1` תמיד יירכש לפני `mutex_R2`.\n\nדוגמה לתיקון ב-`thread_func2`:\n```c\nvoid* thread_func2_fixed(void* arg) {\n    pthread_mutex_lock(&mutex_R1); // סדר רכישה אחיד: קודם R1\n    pthread_mutex_lock(&mutex_R2); // ואז R2\n    // Do something with R1 and R2\n    pthread_mutex_unlock(&mutex_R2);\n    pthread_mutex_unlock(&mutex_R1);\n    return NULL;\n}\n```\nעם שינוי זה, שני החוטים ינסו לרכוש קודם את `mutex_R1`. רק אחד מהם יצליח, ולאחר מכן ימשיך לרכוש את `mutex_R2`. לאחר שיסיים את העבודה וישחרר את שני המנעולים, החוט השני יוכל להמשיך. באופן זה, תנאי ההמתנה המעגלית נמנע."}, "difficulty_estimation": "Medium", "_source_file": "0249__Mutexes__Open__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:14:41", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Mutexes", "Synchronization", "Deadlocks"], "content": {"text": "הסבר את ההבדל בין mutex רגיל (שאינו רקורסיבי) לבין mutex רקורסיבי. כתוב קטע קוד ב-C שבו שימוש ב-mutex רגיל יוביל לקיפאון (deadlock), אך שימוש ב-mutex רקורסיבי יפתור את הבעיה. הסבר בפירוט מדוע קטע הקוד גורם לקיפאון עם mutex רגיל וכיצד mutex רקורסיבי פותר זאת.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\n// הגדרת mutex גלובלי\npthread_mutex_t my_mutex;\n\n// פונקציה פנימית המנסה לנעול את ה-mutex\nvoid inner_function() {\n    printf(\"Inner function: Trying to lock mutex...\\n\");\n    pthread_mutex_lock(&my_mutex); // ניסיון נעילה שני על אותו mutex\n    printf(\"Inner function: Mutex locked. Doing work...\\n\");\n    // סימולציה של עבודה\n    pthread_mutex_unlock(&my_mutex);\n    printf(\"Inner function: Mutex unlocked.\\n\");\n}\n\n// פונקציה חיצונית המנסה לנעול את ה-mutex וקוראת לפונקציה הפנימית\nvoid outer_function() {\n    printf(\"Outer function: Trying to lock mutex...\\n\");\n    pthread_mutex_lock(&my_mutex); // ניסיון נעילה ראשון\n    printf(\"Outer function: Mutex locked. Calling inner function...\\n\");\n    inner_function(); // זו תנסה לנעול את אותו mutex שוב\n    printf(\"Outer function: Inner function returned. Doing more work...\\n\");\n    // סימולציה של עבודה נוספת\n    pthread_mutex_unlock(&my_mutex);\n    printf(\"Outer function: Mutex unlocked.\\n\");\n}", "options": null}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ההבדל העיקרי בין mutex רגיל (שאינו רקורסיבי) ל-mutex רקורסיבי טמון באופן שבו הם מטפלים בניסיונות רכישה חוזרים על ידי אותו חוט (thread) שכבר מחזיק ב-mutex.\n\n1.  **Mutex רגיל (PTHREAD_MUTEX_NORMAL):**\n    *   מטרתו העיקרית היא להבטיח בלעדיות הדדית (mutual exclusion) – רק חוט אחד יכול להחזיק בו בזמן נתון.\n    *   אם חוט שכבר מחזיק ב-mutex רגיל מנסה לרכוש אותו שוב (לקרוא ל-`pthread_mutex_lock` עליו), הוא יחסם באופן קבוע (deadlock) או יקבל שגיאה, מכיוון שה-mutex כבר נעול על ידו ואינו מאפשר רכישה חוזרת. אתחול ברירת המחדל של mutex ב-POSIX הוא רגיל: `pthread_mutex_init(&my_mutex, NULL);`\n\n2.  **Mutex רקורסיבי (PTHREAD_MUTEX_RECURSIVE):**\n    *   מאפשר לחוט שכבר מחזיק ב-mutex לרכוש אותו שוב מספר פעמים מבלי להיחסם.\n    *   ה-mutex שומר מונה פנימי של מספר הפעמים שהחוט הנוכחי רכש אותו. כל קריאה ל-`pthread_mutex_lock` מגדילה את המונה, וכל קריאה ל-`pthread_mutex_unlock` מקטינה אותו.\n    *   ה-mutex ישוחרר בפועל (כלומר, יהיה זמין לחוטים אחרים) רק כאשר החוט המחזיק בו יבצע מספר שווה של קריאות `pthread_mutex_unlock` כמספר הקריאות `pthread_mutex_lock` שביצע. אתחול mutex רקורסיבי מתבצע כך:\n        ```c\n        pthread_mutexattr_t attr;\n        pthread_mutexattr_init(&attr);\n        pthread_mutexattr_settype(&attr, PTHREAD_MUTEX_RECURSIVE);\n        pthread_mutex_init(&my_mutex, &attr);\n        pthread_mutexattr_destroy(&attr);\n        ```\n\n**הסבר לקטע הקוד:**\nבקטע הקוד הנתון:\n*   הפונקציה `outer_function` רוכשת את ה-`my_mutex` באמצעות `pthread_mutex_lock(&my_mutex);`\n*   לאחר מכן, `outer_function` קוראת ל-`inner_function`.\n*   הפונקציה `inner_function` מנסה לרכוש את ה-`my_mutex` *שוב* באמצעות `pthread_mutex_lock(&my_mutex);`\n\n**עם mutex רגיל (לאחר אתחול `pthread_mutex_init(&my_mutex, NULL);`):**\n*   כאשר `inner_function` מנסה לנעול את `my_mutex`, ה-mutex כבר נעול על ידי אותו חוט (החוט שמריץ את `outer_function` ואז קורא ל-`inner_function`).\n*   mutex רגיל אינו מאפשר רכישה חוזרת על ידי אותו חוט. לכן, החוט נחסם בניסיון לנעול את ה-mutex, ומכיוון שהוא עצמו מחזיק ב-mutex, הוא לא יוכל לשחרר אותו לעולם. זה מוביל לקיפאון (deadlock) של החוט עם עצמו. התוכנית תיתקע.\n\n**עם mutex רקורסיבי (לאחר אתחול עם `PTHREAD_MUTEX_RECURSIVE`):**\n*   כאשר `inner_function` מנסה לנעול את `my_mutex`, ה-mutex מזהה שהחוט שכבר מחזיק בו מנסה לרכוש אותו שוב.\n*   הפעולה `pthread_mutex_lock` מצליחה, והמונה הפנימי של ה-mutex מוגדל (במקרה זה, מ-1 ל-2).\n*   הפונקציות ממשיכות לפעול כרגיל.\n*   כאשר `inner_function` קוראת ל-`pthread_mutex_unlock`, המונה קטן (מ-2 ל-1).\n*   כאשר `outer_function` קוראת ל-`pthread_mutex_unlock`, המונה קטן שוב (מ-1 ל-0).\n*   רק כשהמונה מגיע ל-0, ה-mutex משוחרר בפועל וחוטים אחרים יכולים לרכוש אותו. במקרה זה, התוכנית תרוץ ללא קיפאון.\n*   לכן, השימוש ב-mutex רקורסיבי פותר את בעיית הקיפאון העצמי במקרה זה."}, "difficulty_estimation": "Medium", "_source_file": "0250__Mutexes__Open__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:15:05", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Mutexes", "Deadlocks", "Synchronization"], "content": {"text": "נתחו את קטע הקוד הבא ב-C++. האם יתכן קיפאון (deadlock) בתוכנית? אם כן, הסבירו מדוע וכיצד ניתן למנוע אותו. אם לא, הסבירו מדוע קיפאון אינו אפשרי.", "code_snippet": "#include <iostream>\n#include <thread>\n#include <mutex>\n#include <chrono>\n\nstd::mutex mutexA;\nstd::mutex mutexB;\n\nint shared_data_A = 0;\nint shared_data_B = 0;\n\nvoid thread_func1() {\n    std::cout << \"Thread 1: Trying to lock mutexA\" << std::endl;\n    mutexA.lock();\n    std::this_thread::sleep_for(std::chrono::milliseconds(100)); // Simulate work\n    std::cout << \"Thread 1: Locked mutexA, trying to lock mutexB\" << std::endl;\n    mutexB.lock();\n    \n    // Critical section\n    shared_data_A++;\n    shared_data_B++;\n    std::cout << \"Thread 1: Acquired both locks. Data A: \" << shared_data_A << \", Data B: \" << shared_data_B << std::endl;\n\n    mutexB.unlock();\n    mutexA.unlock();\n    std::cout << \"Thread 1: Released both locks\" << std::endl;\n}\n\nvoid thread_func2() {\n    std::cout << \"Thread 2: Trying to lock mutexB\" << std::endl;\n    mutexB.lock();\n    std::this_thread::sleep_for(std::chrono::milliseconds(100)); // Simulate work\n    std::cout << \"Thread 2: Locked mutexB, trying to lock mutexA\" << std::endl;\n    mutexA.lock();\n\n    // Critical section\n    shared_data_A++;\n    shared_data_B++;\n    std::cout << \"Thread 2: Acquired both locks. Data A: \" << shared_data_A << \", Data B: \" << shared_data_B << std::endl;\n\n    mutexA.unlock();\n    mutexB.unlock();\n    std::cout << \"Thread 2: Released both locks\" << std::endl;\n}\n\nint main() {\n    std::thread t1(thread_func1);\n    std::thread t2(thread_func2);\n\n    t1.join();\n    t2.join();\n\n    std::cout << \"Final Data A: \" << shared_data_A << \", Final Data B: \" << shared_data_B << std::endl;\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, יתכן קיפאון.\n\nהסבר:\nהקיפאון מתרחש עקב תנאי 'המתנה מעגלית' (Circular Wait) ו'החזקה והמתנה' (Hold and Wait). חוט 1 (thread_func1) מנסה לנעול את mutexA ולאחר מכן את mutexB. חוט 2 (thread_func2) מנסה לנעול את mutexB ולאחר מכן את mutexA.\nתרחיש קיפאון אפשרי הוא שחוט 1 נועל את mutexA וחוט 2 נועל את mutexB. לאחר מכן, חוט 1 מנסה לנעול את mutexB אך נחסם (מכיוון שחוט 2 מחזיק בו), וחוט 2 מנסה לנעול את mutexA אך נחסם (מכיוון שחוט 1 מחזיק בו). שני החוטים חסומים באופן הדדי, כאשר כל אחד מהם מחזיק משאב שהשני דורש, ואינם יכולים להתקדם. זהו קיפאון קלאסי.\n\nפתרון למניעת קיפאון:\nהדרך הנפוצה והיעילה ביותר למנוע קיפאון במצב זה היא להבטיח שכל החוטים ירכשו את המנעולים (mutexes) באותו סדר קבוע. לדוגמה, יש לשנות את thread_func2 כך שגם הוא ירכוש את mutexA לפני mutexB. כלומר, סדר רכישת המנעולים יהיה תמיד mutexA ולאחר מכן mutexB. זה מבטיח שלא ייווצר מצב של המתנה מעגלית."}, "difficulty_estimation": "Medium", "_source_file": "0251__Mutexes__Open__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:15:29", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Mutexes", "Deadlocks", "Synchronization", "Concurrency"], "content": {"text": "נתון קטע הקוד הבא המדמה שני חוטים המנסים לגשת לשני משאבים המוגנים על ידי מוטקסים.\nא. הסבירו מדוע קיים פוטנציאל לקיפאון (deadlock) בקוד זה. פרטו את ארבעת התנאים ההכרחיים לקיום קיפאון והדגימו כיצד הם מתקיימים בתרחיש זה בקוד הנתון.\nב. הציעו פתרון למניעת הקיפאון וכתבו את קטע הקוד המתוקן.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex1 = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_t mutex2 = PTHREAD_MUTEX_INITIALIZER;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 1: Locked mutex1. Trying to lock mutex2...\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 1: Locked mutex2. Critical section...\\n\");\n    // Do some work\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 1: Unlocked mutex2.\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 1: Unlocked mutex1. Exiting.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to lock mutex2...\\n\");\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2: Locked mutex2. Trying to lock mutex1...\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2: Locked mutex1. Critical section...\\n\");\n    // Do some work\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 2: Unlocked mutex1.\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2: Unlocked mutex2. Exiting.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, thread_func1, NULL);\n    pthread_create(&t2, NULL, thread_func2, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n    printf(\"Main: All threads finished.\\n\");\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. פוטנציאל לקיפאון קיים עקב סדר נעילת המוטקסים השונה בין החוטים. אם חוט 1 נועל את mutex1 וחוט 2 נועל את mutex2 בו זמנית (לפני שהשני הספיק לנעול את המוטקס הראשון שלו), שניהם ינסו לנעול את המוטקס שהשני מחזיק, וייכנסו למצב של המתנה אינסופית.\nארבעת התנאים ההכרחיים לקיפאון:\n1.  **מניעה הדדית (Mutual Exclusion):** מתקיים. מוטקס מאפשר גישה למשאב אחד בלבד בכל רגע נתון. אם חוט אחד מחזיק ב-mutex1, חוט אחר לא יכול להשיג אותו.\n2.  **החזק והמתן (Hold and Wait):** מתקיים. חוט 1 מחזיק ב-mutex1 וממתין ל-mutex2. חוט 2 מחזיק ב-mutex2 וממתין ל-mutex1.\n3.  **אי-דריסה (No Preemption):** מתקיים. המוטקסים אינם ניתנים לדריסה (preempt) ורק החוט המחזיק בהם יכול לשחרר אותם.\n4.  **המתנה מעגלית (Circular Wait):** מתקיים. חוט 1 ממתין למשאב (mutex2) המוחזק על ידי חוט 2, וחוט 2 ממתין למשאב (mutex1) המוחזק על ידי חוט 1, ויוצר מעגל המתנה.\n\nב. הפתרון הנפוץ והיעיל למניעת קיפאון במקרה זה הוא אכיפת סדר קבוע וזהה לרכישת המוטקסים (resource ordering) בכל החוטים. לדוגמה, ששני החוטים תמיד ינסו לנעול קודם את mutex1 ואז את mutex2.\n\n**קוד מתוקן:**\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex1 = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_t mutex2 = PTHREAD_MUTEX_INITIALIZER;\n\nvoid* thread_func1_fixed(void* arg) {\n    printf(\"Thread 1: Trying to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1); // נועל קודם את mutex1\n    printf(\"Thread 1: Locked mutex1. Trying to lock mutex2...\\n\");\n    sleep(1); // מדמה עבודה או החלפת הקשר\n    pthread_mutex_lock(&mutex2); // ואז את mutex2\n    printf(\"Thread 1: Locked mutex2. Critical section...\\n\");\n    // Do some work\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 1: Unlocked mutex2.\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 1: Unlocked mutex1. Exiting.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2_fixed(void* arg) {\n    printf(\"Thread 2: Trying to lock mutex1...\\n\"); // גם חוט 2 נועל קודם את mutex1\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2: Locked mutex1. Trying to lock mutex2...\\n\");\n    sleep(1); // מדמה עבודה או החלפת הקשר\n    pthread_mutex_lock(&mutex2); // ואז את mutex2\n    printf(\"Thread 2: Locked mutex2. Critical section...\\n\");\n    // Do some work\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2: Unlocked mutex2.\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 2: Unlocked mutex1. Exiting.\\n\");\n    return NULL;\n}\n\nint main() { \n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, thread_func1_fixed, NULL);\n    pthread_create(&t2, NULL, thread_func2_fixed, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n    printf(\"Main: All threads finished.\\n\");\n    return 0;\n}\n```"}, "difficulty_estimation": "Medium", "_source_file": "0252__Mutexes__Open__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:16:03", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Mutexes", "Condition Variables", "Synchronization", "Producer-Consumer"], "content": {"text": "נתונה בעיית ה-Producer-Consumer, בה מספר יצרנים מוסיפים פריטים למאגר משותף בעל גודל סופי, ומספר צרכנים מוציאים פריטים מהמאגר.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "8.1", "text": "א. נניח שרק Mutex אחד משמש להגנה על המאגר המשותף. הסבר מדוע שימוש ב-Mutex בלבד אינו מספיק לפתרון נכון ויעיל של בעיה זו. תאר תרחישים בהם ייווצרו בעיות.", "code_snippet": null, "options": null}, {"id": "8.2", "text": "ב. תאר כיצד ניתן לשלב Mutex עם Condition Variables (משתני תנאי) כדי לפתור את בעיית ה-Producer-Consumer באופן נכון ויעיל. כלול הסבר על הפעולות העיקריות (wait, signal/broadcast) וכיצד הן עובדות יחד עם ה-Mutex.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון לשאלה 8.1 (סעיף א'):\nשימוש ב-Mutex בלבד אינו מספיק לפתרון בעיית ה-Producer-Consumer מכיוון ש-Mutex מספק רק הגנה על הגישה הקריטית למשאב המשותף (המאגר), אך אינו מאפשר סנכרון מורכב יותר הדורש המתנה על תנאי מסוים. Mutex מאפשר רק חסימה והתעוררות מפורשת של חוטים, אך אינו מאפשר לחוט לישון עד שתנאי מסוים מתקיים.\n\nתרחישים בהם ייווצרו בעיות:\n1.  **צרכן ינסה לצרוך ממאגר ריק:** אם צרכן מנסה להוציא פריט מהמאגר כשהוא ריק, ורק Mutex מגן על הגישה, הצרכן יקבל את ה-Mutex, יגלה שהמאגר ריק, ויאלץ לבצע פעולת busy-waiting (לולאה שבודקת שוב ושוב את מצב המאגר) או לצאת עם שגיאה. busy-waiting מבזבז משאבי מעבד יקרים. בנוסף, אם הצרכן מחזיק ב-Mutex בזמן ה-busy-waiting, הוא מונע מיצרנים לגשת למאגר, ובכך מונע את שינוי המצב (הוספת פריט) שיאפשר לצרכן להמשיך. זה עלול להוביל לקיפאון (deadlock) או לחוסר יעילות קיצוני.\n2.  **יצרן ינסה לייצר למאגר מלא:** באופן דומה, אם יצרן מנסה להכניס פריט למאגר כשהוא מלא, הוא יקבל את ה-Mutex, יגלה שהמאגר מלא, ויאלץ לבצע busy-waiting או לצאת עם שגיאה. גם כאן, החזקת ה-Mutex ב-busy-waiting תמנע מצרכנים לגשת למאגר ולפנות מקום, מה שיוביל לבעיות דומות.\n\nפתרון לשאלה 8.2 (סעיף ב'):\nכדי לפתור את בעיית ה-Producer-Consumer באופן נכון ויעיל, יש לשלב Mutex עם Condition Variables (משתני תנאי).\nה-Mutex ישמש להגנה על הגישה למאגר המשותף ועל משתני המצב שלו (כמו מספר הפריטים במאגר, ראש וזנב המאגר וכו').\nמשתני התנאי ישמשו לאפשר לחוטים להמתין באופן יעיל כאשר תנאי מסוים אינו מתקיים, ולהתעורר כאשר התנאי כן מתקיים, מבלי לבזבז משאבי מעבד ב-busy-waiting.\n\nנשתמש בשני משתני תנאי:\n*   `not_empty`: עבור צרכנים שצריכים להמתין כאשר המאגר ריק.\n*   `not_full`: עבור יצרנים שצריכים להמתין כאשר המאגר מלא.\n\n**התהליך עבור יצרן:**\n1.  היצרן נועל את ה-Mutex כדי להבטיח גישה בלעדית למאגר ולמשתני המצב שלו.\n2.  בתוך לולאה (לטיפול ב-spurious wakeups), היצרן בודק אם המאגר מלא. אם כן, הוא קורא לפעולה `wait(not_full, mutex)`. פעולת `wait` מבצעת באופן אטומי שתי פעולות: היא משחררת את ה-Mutex ומכניסה את החוט למצב שינה, עד שהוא יתעורר על ידי `signal` או `broadcast` על `not_full`. כשהחוט מתעורר, ה-Mutex ננעל מחדש אוטומטית לפני ש-`wait` חוזרת.\n3.  כאשר המאגר אינו מלא, היצרן מוסיף פריט למאגר.\n4.  היצרן קורא לפעולה `signal(not_empty)` (או `broadcast`) כדי להעיר צרכנים שממתינים למאגר שאינו ריק, מכיוון שכעת יש פריט זמין.\n5.  היצרן משחרר את ה-Mutex.\n\n**התהליך עבור צרכן:**\n1.  הצרכן נועל את ה-Mutex כדי להבטיח גישה בלעדית למאגר ולמשתני המצב שלו.\n2.  בתוך לולאה, הצרכן בודק אם המאגר ריק. אם כן, הוא קורא לפעולה `wait(not_empty, mutex)`. פעולה זו מבצעת את אותן פעולות אטומיות כמו אצל היצרן: משחררת את ה-Mutex ומכניסה את החוט למצב שינה, ונועלת את ה-Mutex בחזרה עם ההתעוררות.\n3.  כאשר המאגר אינו ריק, הצרכן מוציא פריט מהמאגר.\n4.  הצרכן קורא לפעולה `signal(not_full)` (או `broadcast`) כדי להעיר יצרנים שממתינים למאגר שאינו מלא, מכיוון שכעת התפנה מקום.\n5.  הצרכן משחרר את ה-Mutex.\n\nהשימוש ב-`wait` בתוך לולאה (לדוגמה `while (buffer_is_full) { wait(not_full, mutex); }`) מבטיח שהתנאי נבדק שוב לאחר ההתעוררות, למקרה שהחוט התעורר מסיבה שאינה קשורה לתנאי (spurious wakeup) או שחוט אחר תפס את המשאב לפניו."}, "difficulty_estimation": "Medium", "_source_file": "0253__Mutexes__Open__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:16:31", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Mutexes", "Synchronization", "Deadlocks", "Concurrency"], "content": {"text": "נתונה תוכנית C++ המשתמשת בשני mutex-ים (mtx1, mtx2) לגישה למשאבים משותפים. קיימים שני תהליכונים (threads) שמנסים לגשת למשאבים אלו. נתח את הקוד הנתון, הסבר מדוע הוא עלול לגרום לקיפאון (deadlock), והצע פתרון לבעיה זו על ידי שינוי מינימלי בקוד, תוך הסבר מדרונותיו של הפתרון.", "code_snippet": "```c++\n#include <iostream>\n#include <thread>\n#include <mutex>\n#include <chrono> // For std::chrono::milliseconds\n\nstd::mutex mtx1;\nstd::mutex mtx2;\n\nvoid thread_func_1() {\n    mtx1.lock();\n    std::cout << \"Thread 1 acquired mtx1\" << std::endl;\n    std::this_thread::sleep_for(std::chrono::milliseconds(100)); // Simulate work\n    mtx2.lock();\n    std::cout << \"Thread 1 acquired mtx2\" << std::endl;\n    // Access shared resources\n    mtx2.unlock();\n    mtx1.unlock();\n    std::cout << \"Thread 1 released mtx1 and mtx2\" << std::endl;\n}\n\nvoid thread_func_2() {\n    mtx2.lock();\n    std::cout << \"Thread 2 acquired mtx2\" << std::endl;\n    std::this_thread::sleep_for(std::chrono::milliseconds(100)); // Simulate work\n    mtx1.lock();\n    std::cout << \"Thread 2 acquired mtx1\" << std::endl;\n    // Access shared resources\n    mtx1.unlock();\n    mtx2.unlock();\n    std::cout << \"Thread 2 released mtx1 and mtx2\" << std::endl;\n}\n\nint main() {\n    std::thread t1(thread_func_1);\n    std::thread t2(thread_func_2);\n\n    t1.join();\n    t2.join();\n\n    std::cout << \"Main finished\" << std::endl;\n    return 0;\n}\n```", "options": null}, "sub_questions": null, "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הקוד הנתון עלול לגרום לקיפאון (deadlock) מכיוון שמתקיימים בו ארבעת התנאים לקיפאון:\n1.  **Mutual Exclusion (מניעה הדדית):** Mutex-ים מטבעם אוכפים מניעה הדדית – רק חוט אחד יכול להחזיק ב-mutex מסוים בכל רגע נתון.\n2.  **Hold and Wait (החזק והמתן):** כל אחד מהתהליכונים מחזיק ב-mutex אחד (T1 מחזיק ב-mtx1, T2 מחזיק ב-mtx2) וממתין לרכישת ה-mutex השני.\n3.  **No Preemption (אי-השתלטות):** לא ניתן לקחת mutex מחוט שמחזיק בו בכוח.\n4.  **Circular Wait (המתנה מעגלית):** T1 ממתין ל-mtx2 שמוחזק על ידי T2, ו-T2 ממתין ל-mtx1 שמוחזק על ידי T1. זהו מעגל המתנה.\n\n**תרחיש לדוגמה לקיפאון:**\n1.  T1 רוכש את `mtx1`.\n2.  T2 רוכש את `mtx2`.\n3.  T1 מנסה לרכוש את `mtx2` ונחסם, כי `mtx2` מוחזק על ידי T2.\n4.  T2 מנסה לרכוש את `mtx1` ונחסם, כי `mtx1` מוחזק על ידי T1.\nשני התהליכונים חסומים זה לזה ולא יוכלו להתקדם, מה שמוביל לקיפאון.\n\n**פתרון מוצע:**\nהפתרון הנפוץ והפשוט ביותר לבעיה זו הוא לוודא שכל התהליכונים רוכשים את ה-mutex-ים באותו סדר. על ידי אכיפת סדר רכישה עקבי (לדוגמה, תמיד `mtx1` ואז `mtx2`), אנו מבטלים את תנאי ה'המתנה מעגלית'.\n\n**שינוי קוד מוצע (שינוי בפונקציה `thread_func_2` בלבד):**\nיש לשנות את הפונקציה `thread_func_2` כך שתבצע את רכישת ה-mutex-ים באותו סדר כמו `thread_func_1`.\nהקוד המתוקן עבור `thread_func_2` ייראה כך:\n```c++\nvoid thread_func_2() {\n    mtx1.lock(); // רכוש mtx1 קודם, כמו ב-thread_func_1\n    std::cout << \"Thread 2 acquired mtx1\" << std::endl;\n    std::this_thread::sleep_for(std::chrono::milliseconds(100));\n    mtx2.lock(); // לאחר מכן רכוש mtx2\n    std::cout << \"Thread 2 acquired mtx2\" << std::endl;\n    // Access shared resources\n    mtx2.unlock();\n    mtx1.unlock();\n    std::cout << \"Thread 2 released mtx1 and mtx2\" << std::endl;\n}\n```\n\n**הסבר על הפתרון:**\nבפתרון זה, שני התהליכונים מנסים לרכוש את `mtx1` קודם, ורק לאחר מכן את `mtx2`. אם T1 רוכש את `mtx1`, אז T2 ייחסם בניסיון לרכוש את `mtx1` עד ש-T1 ישחרר אותו. T1 ימשיך לרכוש את `mtx2`, יבצע את עבודתו וישחרר את שני ה-mutex-ים. רק לאחר ש-T1 ישחרר את `mtx1`, T2 יוכל לרכוש אותו, ולאחר מכן את `mtx2`, ולהמשיך בעבודתו. מצב של המתנה מעגלית נמנע מכיוון שלא יתכן מצב שבו T1 מחכה ל-mtx2 שמוחזק על ידי T2, ובו זמנית T2 מחכה ל-mtx1 שמוחזק על ידי T1 – שניהם תמיד ינסו לרכוש את `mtx1` ראשון, מה ששובר את המעגל."}, "difficulty_estimation": "Medium", "_source_file": "0254__Mutexes__Open__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:16:50", "_subject": "Concurrency"}, {"id": 101, "type": "Open", "topic": ["Mutexes", "Deadlocks", "Synchronization"], "content": {"text": "נתונה פיסת קוד הכוללת שימוש בשני mutex-ים. שני חוטים (threads) מריצים את הפונקציה `do_work` כאשר כל חוט מקבל ערך שונה עבור `id`.\nהאם קיים תרחיש שעלול להוביל לקיפאון (deadlock) בתוכנית זו?\nאם כן, תאר/י תרחיש כזה והסבר/י מדוע הוא מוביל לקיפאון, וכיצד ניתן למנוע אותו.\nאם לא, הסבר/י מדוע קיפאון אינו אפשרי.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex1 = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_t mutex2 = PTHREAD_MUTEX_INITIALIZER;\n\nvoid* do_work(void* arg) {\n    int id = *(int*)arg;\n\n    if (id == 0) {\n        pthread_mutex_lock(&mutex1);\n        printf(\"Thread %d acquired mutex1\\n\", id);\n        sleep(1); // Simulate work or context switch\n        pthread_mutex_lock(&mutex2);\n        printf(\"Thread %d acquired mutex2\\n\", id);\n        // Critical section\n        printf(\"Thread %d in critical section\\n\", id);\n        pthread_mutex_unlock(&mutex2);\n        pthread_mutex_unlock(&mutex1);\n        printf(\"Thread %d released both mutexes\\n\", id);\n    } else { // id == 1\n        pthread_mutex_lock(&mutex2);\n        printf(\"Thread %d acquired mutex2\\n\", id);\n        sleep(1); // Simulate work or context switch\n        pthread_mutex_lock(&mutex1);\n        printf(\"Thread %d acquired mutex1\\n\", id);\n        // Critical section\n        printf(\"Thread %d in critical section\\n\", id);\n        pthread_mutex_unlock(&mutex1);\n        pthread_mutex_unlock(&mutex2);\n        printf(\"Thread %d released both mutexes\\n\", id);\n    }\n    return NULL;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, קיים תרחיש שיוביל לקיפאון (deadlock) בתוכנית זו.\n\n**תיאור התרחיש לקיפאון:**\n1.  חוט 0 (עם `id = 0`) מבצע `pthread_mutex_lock(&mutex1)` ומצליח לרכוש את `mutex1`.\n2.  מתרחש מיתוג הקשר (context switch).\n3.  חוט 1 (עם `id = 1`) מבצע `pthread_mutex_lock(&mutex2)` ומצליח לרכוש את `mutex2`.\n4.  מתרחש מיתוג הקשר (או שחוט 1 ממשיך לרוץ).\n5.  חוט 0 מנסה כעת לבצע `pthread_mutex_lock(&mutex2)`. אך `mutex2` מוחזק כרגע על ידי חוט 1, ולכן חוט 0 נחסם וממתין לשחרורו.\n6.  חוט 1 מנסה כעת לבצע `pthread_mutex_lock(&mutex1)`. אך `mutex1` מוחזק כרגע על ידי חוט 0, ולכן חוט 1 נחסם וממתין לשחרורו.\n\nבשלב זה, שני החוטים חסומים באופן הדדי: חוט 0 ממתין לחוט 1 שישחרר את `mutex2`, וחוט 1 ממתין לחוט 0 שישחרר את `mutex1`. אף אחד מהם לא יכול להמשיך, ולכן נוצר קיפאון.\n\n**הסבר מדוע הוא מוביל לקיפאון (בהתבסס על ארבעת התנאים של Coffman):**\n1.  **Mutual Exclusion (הדרה הדדית):** Mutex-ים מטבעם אוכפים הדרה הדדית; רק חוט אחד יכול להחזיק ב-mutex מסוים בכל רגע נתון. תנאי זה מתקיים.\n2.  **Hold and Wait (החזקה והמתנה):** כל חוט מחזיק במשאב אחד (mutex) בזמן שהוא ממתין לרכישת משאב נוסף. חוט 0 מחזיק ב-`mutex1` וממתין ל-`mutex2`. חוט 1 מחזיק ב-`mutex2` וממתין ל-`mutex1`. תנאי זה מתקיים.\n3.  **No Preemption (אי-הפקעה):** לא ניתן להפקיע mutex מחוט שמחזיק בו; רק החוט שהחזיק בו יכול לשחרר אותו. תנאי זה מתקיים.\n4.  **Circular Wait (המתנה מעגלית):** קיים מעגל של חוטים, כאשר כל חוט במעגל ממתין למשאב שמוחזק על ידי החוט הבא במעגל. במקרה זה, חוט 0 ממתין ל-`mutex2` שמוחזק על ידי חוט 1, וחוט 1 ממתין ל-`mutex1` שמוחזק על ידי חוט 0. זהו מעגל המתנה. תנאי זה מתקיים.\nמכיוון שכל ארבעת התנאים מתקיימים, קיפאון אפשרי.\n\n**כיצד ניתן למנוע קיפאון זה:**\nהדרך הנפוצה והפשוטה ביותר למנוע קיפאון מסוג זה היא להבטיח שכל החוטים ירכשו את ה-mutex-ים באותו סדר עקבי. אם שני החוטים היו מנסים לרכוש קודם את `mutex1` ולאחר מכן את `mutex2` (או להפך, אך באותו סדר עבור שניהם), הקיפאון היה נמנע.\n**תיקון קוד לדוגמה (שני החוטים רוכשים את `mutex1` ואז `mutex2`):**\n```c\nvoid* do_work_fixed(void* arg) {\n    int id = *(int*)arg;\n\n    // Both threads acquire mutex1 then mutex2\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread %d acquired mutex1\\n\", id);\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread %d acquired mutex2\\n\", id);\n\n    // Critical section\n    printf(\"Thread %d in critical section\\n\", id);\n\n    pthread_mutex_unlock(&mutex2);\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread %d released both mutexes\\n\", id);\n    return NULL;\n}\n```\nבמימוש מתוקן זה, גם אם חוט 0 רוכש את `mutex1` ומתרחש מיתוג הקשר, כאשר חוט 1 ינסה לרכוש את `mutex1`, הוא ייחסם. חוט 0 בסופו של דבר ירוץ, ירכוש את `mutex2`, יסיים את הקטע הקריטי, ישחרר את `mutex2` ואז את `mutex1`. רק אז חוט 1 יוכל לרכוש את `mutex1` ולהמשיך."}, "difficulty_estimation": "Medium", "_source_file": "0255__Mutexes__Open__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:17:17", "_subject": "Concurrency"}, {"id": 100, "type": "Open", "topic": ["Mutexes", "Deadlocks", "Synchronization"], "content": {"text": "נתונה מערכת עם שני משאבים משותפים, resource1 ו-resource2, המוגנים על ידי שני מנעולים (mutexes), mutex1 ו-mutex2, בהתאמה. קיימים שני תהליכונים (threads), threadA ו-threadB, המבצעים פעולות הדורשות גישה לשני המשאבים. הקוד הבא מציג את לוגיקת הגישה של כל אחד מהתהליכונים.\n\nא. האם קיים סיכון לקיפאון (deadlock) במערכת זו? נמקו והסבירו את התרחיש המוביל לקיפאון, אם קיים.\nב. אם קיים, הציעו פתרון לקוד המונע קיפאון, והסבירו מדוע הפתרון שלכם עובד.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex1 = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_t mutex2 = PTHREAD_MUTEX_INITIALIZER;\n\nvoid* threadA_func(void* arg) {\n    printf(\"Thread A: Trying to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread A: Locked mutex1. Trying to lock mutex2...\\n\");\n    sleep(1); // Simulate work\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread A: Locked mutex2. Accessing resources.\\n\");\n    // Access resource1 and resource2\n    pthread_mutex_unlock(&mutex2);\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread A: Unlocked mutexes.\\n\");\n    return NULL;\n}\n\nvoid* threadB_func(void* arg) {\n    printf(\"Thread B: Trying to lock mutex2...\\n\");\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread B: Locked mutex2. Trying to lock mutex1...\\n\");\n    sleep(1); // Simulate work\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread B: Locked mutex1. Accessing resources.\\n\");\n    // Access resource1 and resource2\n    pthread_mutex_unlock(&mutex1);\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread B: Unlocked mutexes.\\n\");\n    return NULL;\n}\n\n// Example main function to run these threads:\n/*\nint main() {\n    pthread_t tidA, tidB;\n\n    pthread_create(&tidA, NULL, threadA_func, NULL);\n    pthread_create(&tidB, NULL, threadB_func, NULL);\n\n    pthread_join(tidA, NULL);\n    pthread_join(tidB, NULL);\n\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n\n    return 0;\n}\n*/", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. כן, קיים סיכון לקיפאון (deadlock) במערכת זו. תרחיש אפשרי לקיפאון הוא כדלקמן:\n1.  **תהליכון A** מבצע `pthread_mutex_lock(&mutex1)` ומצליח לנעול את `mutex1`.\n2.  במקביל, **תהליכון B** מבצע `pthread_mutex_lock(&mutex2)` ומצליח לנעול את `mutex2`.\n3.  כעת, **תהליכון A** ממשיך ומנסה לבצע `pthread_mutex_lock(&mutex2)`. מכיוון ש-`mutex2` נעול על ידי תהליכון B, תהליכון A נחסם וממתין לשחרורו.\n4.  במקביל, **תהליכון B** ממשיך ומנסה לבצע `pthread_mutex_lock(&mutex1)`. מכיוון ש-`mutex1` נעול על ידי תהליכון A, תהליכון B נחסם וממתין לשחרורו.\nבשלב זה, שני התהליכונים חסומים וממתינים זה לזה לשחרור המשאב שהשני מחזיק, וכתוצאה מכך אף אחד מהם לא יכול להתקדם. זהו מצב של קיפאון, הנובע מהפרת תנאי ה\"המתנה המעגלית\" (Circular Wait) בשילוב עם שלושת התנאים האחרים לקיפאון (Mutual Exclusion, Hold and Wait, No Preemption).\n\nב. כדי למנוע קיפאון במצב זה, יש לוודא שכל התהליכונים רוכשים את המנעולים באותו סדר קבוע. זה מפר את תנאי ה\"המתנה המעגלית\".\nפתרון אפשרי הוא ששני התהליכונים ינסו לנעול תמיד את `mutex1` ואז את `mutex2`. הנה דוגמה לקוד מתוקן עבור `threadB_func` (יש לוודא שגם `threadA_func` שומר על אותו סדר):\n\n```c\nvoid* threadB_func(void* arg) {\n    printf(\"Thread B: Trying to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1); // סדר הנעילה שונה ל-mutex1 קודם\n    printf(\"Thread B: Locked mutex1. Trying to lock mutex2...\\n\");\n    sleep(1); // Simulate work\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread B: Locked mutex2. Accessing resources.\\n\");\n    // Access resource1 and resource2\n    pthread_mutex_unlock(&mutex2);\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread B: Unlocked mutexes.\\n\");\n    return NULL;\n}\n```\n\n**הסבר הפתרון:**\nעל ידי אכיפת סדר קבוע לרכישת המנעולים (לדוגמה, תמיד `mutex1` ואז `mutex2`), אנו מבטלים את האפשרות למצב של \"המתנה מעגלית\". אם תהליכון A רוכש את `mutex1` ותהליכון B גם מנסה לרכוש את `mutex1`, רק אחד מהם יצליח. השני ימתין עד ש-`mutex1` ישוחרר. לאחר מכן, התהליכון שרכש את `mutex1` ימשיך לרכוש את `mutex2`. אם `mutex2` פנוי, הוא ירכוש אותו ויבצע את עבודתו. אם `mutex2` תפוס (על ידי תהליכון אחר שכבר סיים את `mutex1` ורכש את `mutex2`), הוא ימתין. בכל מקרה, לא ייווצר מצב שבו A מחזיק ב-X וממתין ל-Y, ובמקביל B מחזיק ב-Y וממתין ל-X, מכיוון שכל התהליכונים מנסים לרכוש את המנעולים באותו סדר היררכי. גישה זו מבטיחה שאין שרשרת המתנה מעגלית, ובכך מונעת קיפאון."}, "difficulty_estimation": "Medium", "_source_file": "0256__Mutexes__Open__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:17:35", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Mutexes", "Fairness", "Concurrency"], "content": {"text": "ממשו מנעול הוגן (Fair Mutex) באמצעות mutexים רגילים (pthread_mutex_t) ומשתני תנאי (pthread_cond_t). מנעול הוגן מבטיח שחוטים ירכשו את המנעול לפי הסדר שבו ביקשו אותו (FIFO - First-In, First-Out). כלומר, אם חוט A מבקש את המנעול ואחריו חוט B מבקש אותו, חוט A חייב לרכוש ולשחרר את המנעול לפני שחוט B יוכל לרכוש אותו, גם אם חוט A נדחה (preempted) מיד לאחר בקשתו וחוט B מנסה לרכוש את המנעול.\n\nיש להגדיר את מבנה הנתונים עבור המנעול ההוגן ולממש את הפעולות הבאות: `fair_mutex_init`, `fair_mutex_destroy`, `fair_mutex_lock`, ו-`fair_mutex_unlock`.", "code_snippet": "/* Headers you might need:\n#include <pthread.h>\n#include <stdbool.h>\n#include <stdlib.h>\n*/\n\n\ntypedef struct {\n    // Please define the internal state here\n} fair_mutex_t;\n\nvoid fair_mutex_init(fair_mutex_t *m);\nvoid fair_mutex_destroy(fair_mutex_t *m);\nvoid fair_mutex_lock(fair_mutex_t *m);\nvoid fair_mutex_unlock(fair_mutex_t *m);"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כדי לממש מנעול הוגן בשיטת FIFO, נשתמש במנגנון 'כרטיסים' (tickets). כל חוט המבקש את המנעול מקבל מספר כרטיס ייחודי, והחוטים רוכשים את המנעול לפי הסדר העולה של מספרי הכרטיסים שלהם. נשתמש ב-mutex פנימי (`internal_lock`) כדי להגן על מצב המנעול (מספרי הכרטיסים) ובמשתנה תנאי (`cond`) כדי להשהות חוטים שממתינים לתורם.\n\nמבנה הנתונים `fair_mutex_t` יכלול:\n*   `internal_lock`: mutex רגיל להגנה על השדות הפנימיים של המנעול ההוגן.\n*   `cond`: משתנה תנאי שעליו חוטים ימתינו כאשר אינם בתורם.\n*   `next_ticket`: מונה עולה שמחלק מספרי כרטיסים ייחודיים לכל חוט שמבקש את המנעול.\n*   `serving_ticket`: מונה עולה המציין את מספר הכרטיס של החוט שמותר לו כעת לרכוש את המנעול.\n\n**פעולת `fair_mutex_lock`:**\n1.  החוט רוכש את `internal_lock` כדי לגשת בבטחה לשדות הפנימיים של המנעול ההוגן.\n2.  הוא מקבל מספר כרטיס (`my_ticket`) מתוך `next_ticket` ומקדם את `next_ticket` עבור החוט הבא.\n3.  החוט נכנס ללולאת המתנה: כל עוד `my_ticket` שלו אינו שווה ל-`serving_ticket`, הוא ממתין על משתנה התנאי `cond`. בזמן ההמתנה, `pthread_cond_wait` משחרר את `internal_lock` באופן אטומי ומחזיר אותו עם ההתעוררות.\n4.  כאשר `my_ticket == serving_ticket`, זהו תורו של החוט לרכוש את המנעול. הוא יוצא מהלולאה.\n5.  החוט משחרר את `internal_lock`.\n\n**פעולת `fair_mutex_unlock`:**\n1.  החוט רוכש את `internal_lock`.\n2.  הוא מקדם את `serving_ticket` כדי לאפשר לחוט הבא בתור (בעל הכרטיס הבא) לרכוש את המנעול.\n3.  החוט קורא ל-`pthread_cond_broadcast` כדי להעיר את כל החוטים הממתינים על `cond`. מתוך החוטים שהתעוררו, רק זה ש-`my_ticket` שלו תואם את `serving_ticket` החדש ימשיך.\n4.  החוט משחרר את `internal_lock`.\n\nמימוש זה מבטיח הוגנות FIFO מכיוון שחוטים יכולים לרכוש את המנעול רק כאשר מספר הכרטיס שלהם תואם ל-`serving_ticket`, ו-`serving_ticket` מקודם באופן סדרתי.\n\n```c\n#include <pthread.h>\n#include <stdbool.h>\n#include <stdlib.h>\n\ntypedef struct {\n    pthread_mutex_t internal_lock;      // מגן על המצב הפנימי של המנעול\n    pthread_cond_t  cond;               // משתנה תנאי לחוטים הממתינים\n    int             next_ticket;        // הכרטיס הבא שיחולק\n    int             serving_ticket;     // הכרטיס הנוכחי בתור\n} fair_mutex_t;\n\nvoid fair_mutex_init(fair_mutex_t *m) {\n    pthread_mutex_init(&m->internal_lock, NULL);\n    pthread_cond_init(&m->cond, NULL);\n    m->next_ticket = 0;\n    m->serving_ticket = 0;\n}\n\nvoid fair_mutex_destroy(fair_mutex_t *m) {\n    pthread_mutex_destroy(&m->internal_lock);\n    pthread_cond_destroy(&m->cond);\n}\n\nvoid fair_mutex_lock(fair_mutex_t *m) {\n    pthread_mutex_lock(&m->internal_lock);\n    int my_ticket = m->next_ticket++; // קבל כרטיס וקדם את המונה\n    while (my_ticket != m->serving_ticket) {\n        pthread_cond_wait(&m->cond, &m->internal_lock);\n    }\n    // עכשיו זה התור שלי, אני מחזיק במנעול באופן מרומז\n    pthread_mutex_unlock(&m->internal_lock);\n}\n\nvoid fair_mutex_unlock(fair_mutex_t *m) {\n    pthread_mutex_lock(&m->internal_lock);\n    m->serving_ticket++; // קדם את הכרטיס הבא בתור\n    pthread_cond_broadcast(&m->cond); // העיר את כל החוטים הממתינים לבדוק את תורם\n    pthread_mutex_unlock(&m->internal_lock);\n}\n```\n", "difficulty_estimation": "Hard"}, "_source_file": "0257__Mutexes__Open__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:18:08", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Mutexes", "Synchronization", "Concurrency", "Fairness", "Semaphores", "Atomic Operations"], "content": {"text": "מנעולים סטנדרטיים (כגון `pthread_mutex_t`) מספקים הגנה הדדית (mutual exclusion) אך אינם מבטיחים הוגנות (fairness) בסדר הכניסה לקטע הקריטי. במערכות עם עומס גבוה, חוטים מסוימים עלולים לסבול מהרעבה (starvation) ולעולם לא לזכות במנעול, גם אם הם ממתינים זמן רב.\n\nמטרת שאלה זו היא לממש מנעול הוגן, אשר מבטיח שחוטים ירכשו את המנעול בסדר הגעתם (FIFO – First-In, First-Out). יש להשתמש בסמפורים (`sem_t`) ובפעולות אטומיות (כגון `atomic_uint` מ-C11 או `__sync_fetch_and_add` ב-GCC/Clang) לצורך המימוש, ללא שימוש ישיר ב-`pthread_mutex_t` או `pthread_cond_t`.\n\nהגדירו את מבנה הנתונים עבור המנעול ההוגן (`fair_mutex_t`) ולממש את הפונקציות הבאות: `fair_mutex_init`, `fair_mutex_destroy`, `fair_mutex_lock`, ו-`fair_mutex_unlock`.\n\nהניחו כי מספר החוטים הממתינים במקביל למנעול לא יעלה על `MAX_TICKETS` (קבוע שתגדירו).", "code_snippet": "#include <semaphore.h>\n#include <stdatomic.h>\n\n#define MAX_TICKETS 1024 // Maximum number of unique tickets that can be simultaneously outstanding\n\ntypedef struct fair_mutex {\n    // TODO: Add necessary members for a fair mutex\n} fair_mutex_t;\n\nvoid fair_mutex_init(fair_mutex_t *mutex);\nvoid fair_mutex_destroy(fair_mutex_t *mutex);\nvoid fair_mutex_lock(fair_mutex_t *mutex);\nvoid fair_mutex_unlock(fair_mutex_t *mutex);\n", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כדי לממש מנעול הוגן מסוג FIFO, נשתמש במנגנון \"כרטיסים\" (tickets). כל חוט שמבקש לרכוש את המנעול מקבל מספר כרטיס ייחודי, והחוטים רוכשים את המנעול לפי סדר הכרטיסים. כדי להפוך את המנגנון לחוסם (blocking) במקום ספינינג (spinning), נשתמש במערך של סמפורים, כאשר כל חוט ממתין על הסמפור הספציפי שלו, בהתאם למספר הכרטיס שקיבל.\n\n**מבנה הנתונים:**\n*   `next_ticket` (`atomic_uint`): מונה אטומי המקצה את מספר הכרטיס הבא. כל חוט שמבקש מנעול מקדם מונה זה ומקבל את הערך הקודם ככרטיס שלו.\n*   `now_serving` (`atomic_uint`): מונה אטומי המציין איזה כרטיס תורו להיכנס לקטע הקריטי.\n*   `wait_semaphores[MAX_TICKETS]` (`sem_t`): מערך של סמפורים. חוט שמקבל כרטיס `N` ומגלה שזה עדיין לא תורו (`now_serving != N`), ימתין על הסמפור `wait_semaphores[N % MAX_TICKETS]`. הסמפורים מאותחלים ל-0 (נעולים).\n*   `state_guard` (`sem_t`): סמפור בינארי (מאותחל ל-1) המשמש להגן על הגישה למונים `next_ticket` ו-`now_serving` ועל פעולות ה-`sem_post` בזמן ה-`unlock`, כדי למנוע מצבי מירוץ ולשמור על עקביות המצב הפנימי של המנעול.\n\n**הסבר לפעולות:**\n\n*   `fair_mutex_init`: מאתחל את המונים האטומיים ל-0. מאתחל את `state_guard` ל-1. מאתחל את כל הסמפורים במערך `wait_semaphores` ל-0 (כלומר, כולם נעולים בתחילה).\n\n*   `fair_mutex_destroy`: משחרר את המשאבים של הסמפורים (`sem_destroy`).\n\n*   `fair_mutex_lock`:\n    1.  החוט רוכש את `state_guard` (`sem_wait`) כדי להבטיח גישה יחידה למנגנון הקצאת הכרטיסים ולעדכון המצב.\n    2.  החוט מקבל כרטיס ייחודי על ידי קידום אטומי של `next_ticket` (`atomic_fetch_add`) ושמירת הערך הקודם (`my_ticket`).\n    3.  החוט משחרר את `state_guard` (`sem_post`).\n    4.  החוט בודק אם `my_ticket` שווה ל-`now_serving`. אם כן, זהו תורו של החוט להיכנס מיד לקטע הקריטי (אין צורך להמתין על סמפור). הוא ממשיך בביצוע.\n    5.  אם `my_ticket` אינו שווה ל-`now_serving`, החוט ממתין על הסמפור הספציפי שלו: `sem_wait(&mutex->wait_semaphores[my_ticket % MAX_TICKETS])`. זה חוסם את החוט עד שישוחרר על ידי החוט הקודם בתור.\n\n*   `fair_mutex_unlock`:\n    1.  החוט רוכש את `state_guard` (`sem_wait`) כדי להגן על עדכון המונים ופעולות ה-`sem_post`.\n    2.  החוט מקדם את `now_serving` באופן אטומי (`atomic_fetch_add`), ובכך מסמן שהכרטיס הבא בתור יכול להיכנס לקטע הקריטי.\n    3.  החוט מחשב את מספר הכרטיס של החוט הבא בתור (`next_waiter_ticket = current_ticket + 1`).\n    4.  החוט בודק אם יש חוט שממתין לכרטיס הבא בתור (כלומר, אם `next_waiter_ticket` קטן מ-`next_ticket` הנוכחי, מה שאומר שחוט כבר לקח את הכרטיס הזה והוא ממתין). אם כן, הוא משחרר את הסמפור המתאים (`sem_post`) כדי להעיר את החוט הבא בתור.\n    5.  החוט משחרר את `state_guard` (`sem_post`).\n\n**הערה על `MAX_TICKETS`:** השימוש במודולו (`% MAX_TICKETS`) עלול לגרום לבעיות אם מספר כרטיסים שונים (שאינם נשמרים בו זמנית) ממופים לאותו סמפור בעוד חוטים עדיין ממתינים. בשאלה זו, אנו מניחים ש-`MAX_TICKETS` גדול מספיק כדי למנוע מצב שבו חוטים עם כרטיסים `X` ו-`X + MAX_TICKETS` ממתינים בו-זמנית על אותו סמפור, או שניתן להחשיב את `MAX_TICKETS` כמספר המרבי של חוטים שיכולים להמתין למנעול בכל רגע נתון.", "code_snippet": "#include <semaphore.h>\n#include <stdatomic.h>\n#include <stdio.h>\n\n#define MAX_TICKETS 1024 // Maximum number of unique tickets that can be simultaneously outstanding\n\ntypedef struct fair_mutex {\n    atomic_uint next_ticket; // Next available ticket number\n    atomic_uint now_serving; // Ticket number of the thread currently holding the lock\n    sem_t wait_semaphores[MAX_TICKETS]; // Each thread waits on its specific semaphore\n    sem_t state_guard; // Binary semaphore to protect access to next_ticket, now_serving, and sem_post operations.\n} fair_mutex_t;\n\nvoid fair_mutex_init(fair_mutex_t *mutex) {\n    atomic_init(&mutex->next_ticket, 0);\n    atomic_init(&mutex->now_serving, 0);\n    sem_init(&mutex->state_guard, 0, 1); // Initialize state_guard as a binary semaphore (unlocked)\n    for (int i = 0; i < MAX_TICKETS; ++i) {\n        sem_init(&mutex->wait_semaphores[i], 0, 0); // All waiting semaphores start at 0 (locked)\n    }\n}\n\nvoid fair_mutex_destroy(fair_mutex_t *mutex) {\n    sem_destroy(&mutex->state_guard);\n    for (int i = 0; i < MAX_TICKETS; ++i) {\n        sem_destroy(&mutex->wait_semaphores[i]);\n    }\n}\n\nvoid fair_mutex_lock(fair_mutex_t *mutex) {\n    sem_wait(&mutex->state_guard); // Acquire guard to get a ticket and protect state updates\n    unsigned int my_ticket = atomic_fetch_add(&mutex->next_ticket, 1); // Atomically get next ticket\n    sem_post(&mutex->state_guard); // Release entry gate\n\n    // Check if it's my turn immediately\n    if (my_ticket == atomic_load(&mutex->now_serving)) {\n        // It's my turn, proceed without waiting on a semaphore\n        return;\n    } else {\n        // Not my turn, wait on my specific semaphore\n        sem_wait(&mutex->wait_semaphores[my_ticket % MAX_TICKETS]);\n    }\n}\n\nvoid fair_mutex_unlock(fair_mutex_t *mutex) {\n    sem_wait(&mutex->state_guard); // Acquire guard to update now_serving and potentially post to next waiter\n    unsigned int current_ticket = atomic_load(&mutex->now_serving); // Get current serving ticket\n    atomic_fetch_add(&mutex->now_serving, 1); // Increment now_serving for the next thread\n\n    unsigned int next_waiter_ticket = current_ticket + 1;\n\n    // If there's a thread waiting for the next ticket, unblock it\n    // This check ensures we only post if a thread has already acquired that ticket\n    if (next_waiter_ticket < atomic_load(&mutex->next_ticket)) {\n        sem_post(&mutex->wait_semaphores[next_waiter_ticket % MAX_TICKETS]);\n    }\n    sem_post(&mutex->state_guard); // Release guard\n}\n", "difficulty_estimation": "Hard"}, "_source_file": "0258__Mutexes__Open__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:19:12", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Mutexes", "Synchronization", "Threads", "Concurrency"], "content": {"text": "במערכות הפעלה, מיוטקס (mutex) משמש להבטחת מניעה הדדית לקטע קריטי. עם זאת, מיוטקס רגיל עלול לגרום לקיפאון (deadlock) אם חוט שכבר מחזיק במיוטקס ינסה לרכוש אותו שוב. כדי לפתור בעיה זו, קיים מושג של 'מיוטקס רה-כניסתי' (reentrant mutex), המאפשר לחוט שרכש את המיוטקס לרכוש אותו שוב מספר פעמים מבלי להיחסם, כל עוד הוא גם ישחרר אותו את אותו מספר פעמים.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "הגדירו במדויק את התכונות הנדרשות ממיוטקס רה-כניסתי, בדומה להגדרת תכונות למנעול קוראים-כותבים. התייחסו לנקודות הבאות:\n1. מניעה הדדית (Mutual Exclusion) בין חוטים שונים.\n2. יכולת כניסה חוזרת (Reentrancy) לחוט המחזיק במיוטקס.\n3. שחרור נכון של המיוטקס.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "ממשו מיוטקס רה-כניסתי באמצעות ספריות Pthreads (mutexes ו-condition variables). עליכם להגדיר את מבנה הנתונים של המיוטקס הרה-כניסתי ולממש את הפעולות `init`, `destroy`, `lock` ו-`unlock`. שימו לב שאין להשתמש בפונקציות Pthreads ספציפיות למיוטקס רה-כניסתי (כגון `PTHREAD_MUTEX_RECURSIVE`), אלא לממש את הלוגיקה בעצמכם על בסיס מיוטקסים רגילים ומשתני תנאי.", "code_snippet": " #include <pthread.h>\n #include <stdio.h> // For pthread_self()\n #include <stdlib.h> // For malloc/free\n\n typedef struct {\n     pthread_mutex_t internal_mutex;\n     pthread_cond_t cond;\n     pthread_t owner;\n     int recursion_count;\n } ReentrantMutex;\n\n void reentrant_mutex_init(ReentrantMutex *rm) {\n     // TODO: Implement\n }\n\n void reentrant_mutex_destroy(ReentrantMutex *rm) {\n     // TODO: Implement\n }\n\n void reentrant_mutex_lock(ReentrantMutex *rm) {\n     // TODO: Implement\n }\n\n void reentrant_mutex_unlock(ReentrantMutex *rm) {\n     // TODO: Implement\n }", "options": null}, {"id": "1.3", "text": "הסבירו בקצרה כיצד המימוש שלכם בסעיף הקודם מבטיח את התכונות שהגדרתם בסעיף 1.1.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: הגדרת תכונות למיוטקס רה-כניסתי:\n1.  **מניעה הדדית (Mutual Exclusion):** בכל רגע נתון, רק חוט אחד יכול להיות ה\"בעלים\" של המיוטקס הרה-כניסתי. חוטים אחרים שינסו לרכוש אותו ייחסמו עד שהבעלים הנוכחי ישחרר אותו לחלוטין (כלומר, מונה הכניסות יגיע ל-0).\n2.  **יכולת כניסה חוזרת (Reentrancy):** חוט שכבר רכש את המיוטקס (הוא הבעלים הנוכחי) יכול לבצע קריאות חוזרות ל-`lock` מבלי להיחסם. כל קריאה כזו תגדיל את מונה הכניסות.\n3.  **שחרור נכון (Proper Release):** חוט יכול לשחרר את המיוטקס רק אם הוא הבעלים הנוכחי. כל קריאה ל-`unlock` תפחית את מונה הכניסות. רק כאשר מונה הכניסות מגיע ל-0, המיוטקס נחשב משוחרר לחלוטין, וחוט אחר יכול לרכוש אותו.\n\n1.2: מימוש מיוטקס רה-כניסתי:\n```c\n #include <pthread.h>\n #include <stdio.h> // For pthread_self(), fprintf\n #include <stdlib.h> // For malloc/free\n\n typedef struct {\n     pthread_mutex_t internal_mutex;\n     pthread_cond_t cond;\n     pthread_t owner;\n     int recursion_count;\n } ReentrantMutex;\n\n void reentrant_mutex_init(ReentrantMutex *rm) {\n     pthread_mutex_init(&rm->internal_mutex, NULL);\n     pthread_cond_init(&rm->cond, NULL);\n     rm->owner = 0; // No owner initially (pthread_self() returns non-zero)\n     rm->recursion_count = 0;\n }\n\n void reentrant_mutex_destroy(ReentrantMutex *rm) {\n     // It's good practice to ensure no one holds the lock when destroying.\n     // In a robust system, you might add checks or assert recursion_count == 0.\n     pthread_mutex_destroy(&rm->internal_mutex);\n     pthread_cond_destroy(&rm->cond);\n     rm->owner = 0;\n     rm->recursion_count = 0;\n }\n\n void reentrant_mutex_lock(ReentrantMutex *rm) {\n     pthread_t current_thread = pthread_self();\n\n     pthread_mutex_lock(&rm->internal_mutex);\n\n     if (rm->owner == current_thread) {\n         // Current thread already owns the mutex, just increment count\n         rm->recursion_count++;\n     } else {\n         // Mutex is owned by another thread or unowned.\n         // Wait until it's unowned (recursion_count == 0).\n         while (rm->recursion_count != 0) {\n             pthread_cond_wait(&rm->cond, &rm->internal_mutex);\n         }\n         // Now it's unowned, this thread becomes the owner\n         rm->owner = current_thread;\n         rm->recursion_count = 1;\n     }\n     pthread_mutex_unlock(&rm->internal_mutex);\n }\n\n void reentrant_mutex_unlock(ReentrantMutex *rm) {\n     pthread_t current_thread = pthread_self();\n\n     pthread_mutex_lock(&rm->internal_mutex);\n\n     if (rm->owner != current_thread) {\n         // Error: Thread trying to unlock does not own the mutex.\n         // In a robust system, this would be an assertion failure or return an error code.\n         fprintf(stderr, \"Error: Thread %lu trying to unlock a mutex it doesn't own!\\n\", (unsigned long)current_thread);\n         pthread_mutex_unlock(&rm->internal_mutex);\n         return;\n     }\n\n     rm->recursion_count--;\n\n     if (rm->recursion_count == 0) {\n         // Mutex is now fully released. Reset owner and signal waiting threads.\n         rm->owner = 0; // No owner\n         pthread_cond_broadcast(&rm->cond); // Wake up all waiting threads\n     }\n     pthread_mutex_unlock(&rm->internal_mutex);\n }\n```\n\n1.3: הסבר על עמידה בתכונות:\n1.  **מניעה הדדית:** המימוש משתמש ב-`internal_mutex` כדי להגן על המשתנים הפנימיים `owner` ו-`recursion_count`. רק חוט אחד יכול לשנות או לבדוק את המשתנים הללו בו זמנית. בנוסף, חוט יכול להפוך לבעלים של המיוטקס (`rm->owner = current_thread`) רק כאשר `rm->recursion_count` הוא 0, מה שמבטיח שאין בעלים קודם. כלומר, רק חוט אחד יכול להיות הבעלים של המיוטקס בכל רגע נתון. חוטים אחרים שינסו לרכוש את המיוטקס כשהוא בבעלות חוט אחר (`rm->recursion_count != 0`) ייחסמו על ידי `pthread_cond_wait` עד שהבעלים הנוכחי ישחרר אותו לחלוטין.\n2.  **יכולת כניסה חוזרת:** כאשר חוט קורא ל-`reentrant_mutex_lock` ובודק ש-`rm->owner == current_thread`, הוא מגלה שהוא כבר הבעלים. במקרה זה, במקום להיחסם, הוא פשוט מגדיל את `rm->recursion_count` וממשיך. זה מאפשר לחוט הבעלים להיכנס לקטע הקריטי מספר פעמים.\n3.  **שחרור נכון:** חוט יכול לקרוא ל-`reentrant_mutex_unlock` רק אם `rm->owner == current_thread`. אם חוט אחר מנסה לשחרר, המימוש מזהה זאת (עם הודעת שגיאה) ומונע את השחרור הלא חוקי. כל קריאה ל-`unlock` מקטינה את `rm->recursion_count`. רק כאשר `rm->recursion_count` מגיע ל-0, המיוטקס משוחרר לחלוטין (ה-`owner` מאופס), ו-`pthread_cond_broadcast` נקרא כדי להעיר חוטים ממתינים, המאפשר לחוט חדש לרכוש את המיוטקס."}, "difficulty_estimation": "Hard", "_source_file": "0259__Mutexes__Open__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:19:39", "_subject": "Concurrency"}, {"id": 100, "type": "Open", "topic": ["Mutexes", "Condition Variables", "Synchronization", "Producer-Consumer", "Fairness", "Priority"], "content": {"text": "נתונה בעיית ה-Bounded Buffer (מאגר חסום) עבור מספר מפיקים (Producers) וצרכנים (Consumers). המאגר יכול להכיל עד `BUFFER_SIZE` פריטים. מפיקים מוסיפים פריטים למאגר, וצרכנים מוציאים פריטים מהמאגר. יש לוודא סנכרון נכון כדי למנוע תנאי מרוץ, קיפאון (deadlock) והרעבה (starvation).\n\nבנוסף, נדרש שהמימוש יתעדף צרכנים על פני מפיקים כאשר שניהם ממתינים. כלומר, אם גם צרכנים וגם מפיקים ממתינים לפעולה, הצרכנים יקבלו קדימות בכניסה לקטע הקריטי ובביצוע פעולתם (dequeue) לפני שמפיקים יוכלו להוסיף פריטים (enqueue).\n\nהשלימו את המימוש באמצעות `pthread_mutex_t` ו-`pthread_cond_t` בלבד. עליכם להגדיר את מבנה הנתונים `BoundedBuffer` ולהשלים את הפונקציות `buffer_init`, `buffer_destroy`, `buffer_enqueue`, ו-`buffer_dequeue`.", "code_snippet": "#include <pthread.h>\n#include <stdlib.h>\n#include <stdio.h>\n\n#define BUFFER_SIZE 10\n\ntypedef struct {\n    int buffer[BUFFER_SIZE];\n    int head; // Index of the next item to dequeue\n    int tail; // Index of the next slot to enqueue into\n    int count; // Current number of items in buffer\n\n    pthread_mutex_t mutex;\n    pthread_cond_t not_full; // Signaled when buffer is not full\n    pthread_cond_t not_empty; // Signaled when buffer is not empty\n\n    // Add any additional synchronization variables needed for consumer priority\n    int waiting_consumers;\n\n} BoundedBuffer;\n\nvoid buffer_init(BoundedBuffer *buf);\nvoid buffer_destroy(BoundedBuffer *buf);\nvoid buffer_enqueue(BoundedBuffer *buf, int item);\nint buffer_dequeue(BoundedBuffer *buf);\n"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "המימוש דורש שימוש במוטקס אחד להגנה על מבנה הנתונים של ה-Bounded Buffer, ושני משתני תנאי (Condition Variables): אחד למצב שהמאגר אינו מלא (`not_full`) ואחד למצב שהמאגר אינו ריק (`not_empty`). כדי ליישם את עדיפות הצרכנים, נשתמש במונה `waiting_consumers` אשר יספור כמה צרכנים ממתינים כרגע על משתנה התנאי `not_empty`.\n\n**הסבר מפורט:**\n1.  **`BoundedBuffer` struct:** מכיל את המאגר עצמו, אינדקסים `head` ו-`tail`, מונה `count`, המוטקסים ומשתני התנאי. הוספנו את `waiting_consumers` כדי לעקוב אחר צרכנים ממתינים.\n2.  **`buffer_init`:** מאתחל את כל השדות לערכי ההתחלה שלהם, כולל איפוס המוטקס ומשתני התנאי.\n3.  **`buffer_destroy`:** משחרר את המשאבים של המוטקס ומשתני התנאי.\n4.  **`buffer_enqueue` (מפיק):**\n    *   המפיק נועל את המוטקס.\n    *   הוא בודק את התנאי לכניסה: האם המאגר מלא (`buf->count == BUFFER_SIZE`) או האם יש צרכנים שממתינים (`buf->waiting_consumers > 0`). אם אחד מהתנאים הללו מתקיים, המפיק צריך להמתין.\n    *   המפיק קורא ל-`pthread_cond_wait(&buf->not_full, &buf->mutex)` כדי להמתין. הוא משחרר את המוטקס באופן אוטומטי ונכנס למצב שינה. כשהוא מתעורר, הוא נועל מחדש את המוטקס.\n    *   לאחר שהתנאים מתקיימים, המפיק מוסיף פריט למאגר ומעדכן את המונים.\n    *   לבסוף, הוא מאותת ל-`not_empty` (`pthread_cond_signal`) כדי להעיר צרכן פוטנציאלי שממתין.\n    *   המפיק משחרר את המוטקס.\n5.  **`buffer_dequeue` (צרכן):**\n    *   הצרכן נועל את המוטקס.\n    *   הוא בודק את התנאי לכניסה: האם המאגר ריק (`buf->count == 0`). אם כן, הצרכן מגדיל את `waiting_consumers` וקורא ל-`pthread_cond_wait(&buf->not_empty, &buf->mutex)` כדי להמתין. כשהוא מתעורר, הוא מקטין את `waiting_consumers` ונועל מחדש את המוטקס.\n    *   לאחר שהתנאי מתקיים, הצרכן מוציא פריט מהמאגר ומעדכן את המונים.\n    *   כאן מגיע החלק הקריטי לעדיפות: אם לאחר שהצרכן הוציא פריט, מונה הצרכנים הממתינים (`waiting_consumers`) ירד ל-0, זה אומר שאין יותר צרכנים שממתינים. במצב זה, יש לאפשר למפיקים שחיכו בגלל עדיפות הצרכנים להמשיך. לכן, משתמשים ב-`pthread_cond_broadcast(&buf->not_full)` כדי להעיר את כל המפיקים הממתינים על `not_full`. המפיקים יתעוררו, ינעלו את המוטקס מחדש, ויבדקו שוב את התנאי שלהם (שכעת `waiting_consumers` הוא 0, וייתכן שהמאגר כבר לא מלא).\n    *   הצרכן משחרר את המוטקס ומחזיר את הפריט.\n\n**הקפדה על עדיפות ופתרון בעיות:**\n*   **מניעת תנאי מרוץ:** המוטקס `buf->mutex` מגן על כל הגישה למשתנים המשותפים (`head`, `tail`, `count`, `waiting_consumers`).\n*   **מניעת קיפאון (Deadlock):** הסדר של נעילה ושחרור המוטקס הוא עקבי. אין סדר נעילה מורכב שיכול להוביל לקיפאון.\n*   **מניעת הרעבה (Starvation):** עדיפות הצרכנים מונעת הרעבת צרכנים כאשר מפיקים פעילים. ה-`broadcast` מבטיח שמפיקים לא יורעבו כאשר אין יותר צרכנים ממתינים. השימוש ב-`while` בלולאות ההמתנה מטפל ב-spurious wakeups ומוודא שהתנאי אכן מתקיים לפני ההמשך.\n\n```c\n#include <pthread.h>\n#include <stdlib.h>\n#include <stdio.h>\n\n#define BUFFER_SIZE 10\n\ntypedef struct {\n    int buffer[BUFFER_SIZE];\n    int head; // Index of the next item to dequeue\n    int tail; // Index of the next slot to enqueue into\n    int count; // Current number of items in buffer\n\n    pthread_mutex_t mutex;\n    pthread_cond_t not_full; // Signaled when buffer is not full\n    pthread_cond_t not_empty; // Signaled when buffer is not empty\n\n    int waiting_consumers; // Number of consumers waiting on not_empty\n\n} BoundedBuffer;\n\nvoid buffer_init(BoundedBuffer *buf) {\n    buf->head = 0;\n    buf->tail = 0;\n    buf->count = 0;\n    buf->waiting_consumers = 0;\n    pthread_mutex_init(&buf->mutex, NULL);\n    pthread_cond_init(&buf->not_full, NULL);\n    pthread_cond_init(&buf->not_empty, NULL);\n}\n\nvoid buffer_destroy(BoundedBuffer *buf) {\n    pthread_mutex_destroy(&buf->mutex);\n    pthread_cond_destroy(&buf->not_full);\n    pthread_cond_destroy(&buf->not_empty);\n}\n\nvoid buffer_enqueue(BoundedBuffer *buf, int item) {\n    pthread_mutex_lock(&buf->mutex);\n\n    // Producer waits if buffer is full OR if there are consumers waiting (consumer priority)\n    while (buf->count == BUFFER_SIZE || buf->waiting_consumers > 0) {\n        pthread_cond_wait(&buf->not_full, &buf->mutex);\n    }\n\n    buf->buffer[buf->head] = item;\n    buf->head = (buf->head + 1) % BUFFER_SIZE;\n    buf->count++;\n\n    pthread_cond_signal(&buf->not_empty); // Wake up a waiting consumer\n\n    pthread_mutex_unlock(&buf->mutex);\n}\n\nint buffer_dequeue(BoundedBuffer *buf) {\n    pthread_mutex_lock(&buf->mutex);\n\n    // Consumer waits if buffer is empty\n    while (buf->count == 0) {\n        buf->waiting_consumers++; // Increment count of waiting consumers\n        pthread_cond_wait(&buf->not_empty, &buf->mutex);\n        buf->waiting_consumers--; // Decrement count of waiting consumers after waking up\n    }\n\n    int item = buf->buffer[buf->tail];\n    buf->tail = (buf->tail + 1) % BUFFER_SIZE;\n    buf->count--;\n\n    // If no consumers are waiting, broadcast to all producers (they might be waiting due to consumer priority)\n    // Otherwise, just signal one producer if the buffer was full.\n    // Using broadcast here is safer as producers might be waiting on `waiting_consumers > 0` condition.\n    pthread_cond_broadcast(&buf->not_full);\n\n    pthread_mutex_unlock(&buf->mutex);\n    return item;\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0260__Mutexes__Open__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:20:28", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Mutexes", "Deadlock Prevention", "Fairness", "Synchronization", "Resource Allocation"], "content": {"text": "מערכת ההפעלה מנהלת מערך של N משאבים ייחודיים, `Resource[0]`, `Resource[1]`, ..., `Resource[N-1]`. כל משאב מוגן על ידי מנעול (mutex) משלו. חוטים רבים במערכת נדרשים באופן תדיר לרכוש שני משאבים ספציפיים, נניח `Resource[i]` ו-`Resource[j]` (כאשר `i != j`), לבצע פעולה כלשהי, ולאחר מכן לשחרר אותם.\n\nממשו את הפונקציות `acquire_two_resources(ResourceManager *rm, int i, int j)` ו-`release_two_resources(ResourceManager *rm, int i, int j)`. המימוש צריך לקיים את הדרישות הבאות:\n1. מניעת קיפאון (Deadlock Prevention): המימוש חייב להבטיח שלא יתרחש מצב של קיפאון לעולם.\n2. הוגנות (Fairness): יש להבטיח שאף חוט המבקש לרכוש שני משאבים `i` ו-`j` לא יורעב (starve) ללא הגבלת זמן, בעוד שחוטים אחרים ממשיכים לרכוש ולשחרר משאבים.\n3. יעילות: המימוש צריך למזער המתנה מיותרת ככל הניתן.\n\nהשתמשו באובייקטים מסוג `pthread_mutex_t` ובפעולותיהם בלבד (ללא סמפורים או משתני תנאי).", "code_snippet": "```c\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\ntypedef struct {\n    int N; // Number of resources\n    // Add necessary synchronization primitives here\n} ResourceManager;\n\nvoid init_resource_manager(ResourceManager *rm, int n_resources);\nvoid destroy_resource_manager(ResourceManager *rm);\nvoid acquire_two_resources(ResourceManager *rm, int i, int j);\nvoid release_two_resources(ResourceManager *rm, int i, int j);\n```", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון זה משתמש בשני מנגנוני סנכרון עיקריים כדי לעמוד בדרישות:\n\n1.  **מניעת קיפאון (Deadlock Prevention):** כדי למנוע קיפאון, אנו נוקטים בגישה של רכישת משאבים בסדר קנוני (קבוע). כאשר חוט מבקש לרכוש את משאב `i` ומשאב `j`, הוא תמיד ירכוש קודם את המשאב בעל האינדקס הנמוך יותר, ולאחר מכן את המשאב בעל האינדקס הגבוה יותר. לדוגמה, אם חוט מבקש (3, 7), הוא ירכוש קודם את `resource_locks[3]` ולאחר מכן את `resource_locks[7]`. אם חוט אחר מבקש (7, 3), הוא גם ירכוש קודם את `resource_locks[3]` ואז את `resource_locks[7]`. גישה זו מבטיחה שמעגל המתנה לעולם לא ייווצר, ובכך מונעת קיפאון.\n\n2.  **הוגנות (Fairness):** כדי להבטיח הוגנות ולמנוע הרעבה, אנו משתמשים ב-`request_serializer_mutex` גלובלי. כל חוט המבקש לרכוש זוג משאבים חייב קודם לרכוש את `request_serializer_mutex`. מנעול זה מבטיח שרק חוט אחד בכל רגע נתון יוכל לנסות לרכוש את זוג המשאבים שלו. לאחר שהחוט רכש את `request_serializer_mutex`, הוא ממשיך לרכוש את שני המשאבים הספציפיים שלו בסדר הקנוני שתואר לעיל. רק לאחר ששני המשאבים נרכשו בהצלחה, `request_serializer_mutex` משוחרר. מנגנון זה יוצר תור FIFO (First-In, First-Out) עבור כל הבקשות לרכישת זוגות משאבים, ובכך מבטיח שאף חוט לא יורעב – כל בקשה תקבל את תורה ותטופל בסופו של דבר.\n\n3.  **יעילות:** הפתרון ממזער המתנה מיותרת במובן זה שאחרי שחוט רוכש את `request_serializer_mutex`, הוא ירכוש את המשאבים הנדרשים שלו מיד כשהם פנויים. עם זאת, יש לציין שהשימוש ב-`request_serializer_mutex` גלובלי מפחית את המקביליות האפשרית במערכת, מכיוון שכל בקשות הרכישה נסגרות לסדרה (מועברות בתור אחת אחרי השנייה). לדוגמה, אם חוט אחד מבקש את (R0, R1) וחוט אחר מבקש את (R2, R3) – משאבים שאינם חופפים – הם עדיין יצטרכו לחכות זה לזה ב-`request_serializer_mutex`. זוהי פשרה נפוצה כאשר דורשים הוגנות מחמירה עם מנעולים בלבד, ללא שימוש במשתני תנאי (condition variables) המאפשרים המתנה חכמה יותר.\n\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\ntypedef struct {\n    int N; // Number of resources\n    pthread_mutex_t *resource_locks; // Array of mutexes, one per resource\n    pthread_mutex_t request_serializer_mutex; // Global mutex to ensure fairness for acquisition attempts\n} ResourceManager;\n\n// Initialization function\nvoid init_resource_manager(ResourceManager *rm, int n_resources) {\n    rm->N = n_resources;\n    rm->resource_locks = (pthread_mutex_t *)malloc(sizeof(pthread_mutex_t) * n_resources);\n    if (rm->resource_locks == NULL) {\n        perror(\"Failed to allocate resource_locks\");\n        exit(EXIT_FAILURE);\n    }\n    for (int i = 0; i < n_resources; ++i) {\n        if (pthread_mutex_init(&rm->resource_locks[i], NULL) != 0) {\n            perror(\"Failed to initialize resource mutex\");\n            exit(EXIT_FAILURE);\n        }\n    }\n    if (pthread_mutex_init(&rm->request_serializer_mutex, NULL) != 0) {\n        perror(\"Failed to initialize request serializer mutex\");\n        exit(EXIT_FAILURE);\n    }\n}\n\n// Destruction function\nvoid destroy_resource_manager(ResourceManager *rm) {\n    for (int i = 0; i < rm->N; ++i) {\n        pthread_mutex_destroy(&rm->resource_locks[i]);\n    }\n    free(rm->resource_locks);\n    pthread_mutex_destroy(&rm->request_serializer_mutex);\n}\n\n// Acquire two resources\nvoid acquire_two_resources(ResourceManager *rm, int i, int j) {\n    // Ensure valid indices\n    if (i < 0 || i >= rm->N || j < 0 || j >= rm->N || i == j) {\n        fprintf(stderr, \"Invalid resource indices: %d, %d\\n\", i, j);\n        return;\n    }\n\n    // Use the request_serializer_mutex to ensure fairness for acquisition attempts\n    // This mutex is held for the entire duration of acquiring both resource locks.\n    // This serializes all attempts to acquire a pair of resources.\n    pthread_mutex_lock(&rm->request_serializer_mutex);\n\n    // Acquire resources in canonical order to prevent deadlock\n    int idx1 = (i < j) ? i : j;\n    int idx2 = (i < j) ? j : i;\n\n    pthread_mutex_lock(&rm->resource_locks[idx1]);\n    pthread_mutex_lock(&rm->resource_locks[idx2]);\n\n    // Release the request_serializer_mutex ONLY AFTER both resources are acquired.\n    // This makes the entire acquisition process (for a pair) atomic from the perspective\n    // of other threads trying to acquire any resources.\n    pthread_mutex_unlock(&rm->request_serializer_mutex);\n}\n\n// Release two resources\nvoid release_two_resources(ResourceManager *rm, int i, int j) {\n    // Ensure valid indices\n    if (i < 0 || i >= rm->N || j < 0 || j >= rm->N || i == j) {\n        fprintf(stderr, \"Invalid resource indices: %d, %d\\n\", i, j);\n        return;\n    }\n\n    // Release resources in reverse canonical order (or any order, as release order doesn't cause deadlock)\n    // For consistency, releasing in reverse order of acquisition is good practice.\n    int idx1 = (i < j) ? i : j;\n    int idx2 = (i < j) ? j : i;\n\n    pthread_mutex_unlock(&rm->resource_locks[idx2]);\n    pthread_mutex_unlock(&rm->resource_locks[idx1]);\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0261__Mutexes__Open__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:21:19", "_subject": "Concurrency"}, {"id": 101, "type": "Open", "topic": ["Mutexes", "Synchronization", "Concurrency", "Condition Variables"], "content": {"text": "במערכת מרובת תהליכים, לעיתים קרובות נדרש להגביל את מספר התהליכים שיכולים לגשת לקטע קריטי מסוים בו-זמנית, אך לאו דווקא לאחד בלבד. לדוגמה, קטע קריטי שעושה שימוש במאגר של N חיבורי רשת זמינים. יש לממש אובייקט סנכרון חדש בשם `PermitMutex` שיאפשר לכל היותר N תהליכים להיכנס לקטע קריטי בו-זמנית. כאשר N תהליכים נמצאים בקטע הקריטי, כל תהליך נוסף שינסה להיכנס ימתין עד שאחד מהתהליכים הקיימים יצא. יש להשתמש אך ורק באובייקטי סנכרון מסוג `pthread_mutex_t` ו-`pthread_cond_t`. יש להגדיר את מבנה הנתונים של `PermitMutex` ולממש את הפונקציות `init_permit_mutex()`, `destroy_permit_mutex()`, `acquire_permit()` ו-`release_permit()`.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "המימוש של `PermitMutex` ידרוש מבנה נתונים שיכיל מונה של הרשאות זמינות (`available_permits`), מנעול (`pthread_mutex_t`) להגנה על מונה זה, ומשתנה תנאי (`pthread_cond_t`) לתהליכים הממתינים להרשאה. הנה המימוש:\n\n```c\n#include <pthread.h>\n#include <stdlib.h> // For malloc, free (though not strictly needed for this snippet)\n\ntypedef struct {\n    pthread_mutex_t mutex;\n    pthread_cond_t cond;\n    int available_permits;\n    int max_permits; // Store N for completeness, though not strictly used in logic\n} PermitMutex;\n\n// Initialize the PermitMutex with a maximum number of permits\nvoid init_permit_mutex(PermitMutex *pm, int N) {\n    pthread_mutex_init(&pm->mutex, NULL);\n    pthread_cond_init(&pm->cond, NULL);\n    pm->available_permits = N;\n    pm->max_permits = N; \n}\n\n// Destroy the PermitMutex, releasing associated resources\nvoid destroy_permit_mutex(PermitMutex *pm) {\n    pthread_mutex_destroy(&pm->mutex);\n    pthread_cond_destroy(&pm->cond);\n}\n\n// Acquire a permit (enter critical section if available)\nvoid acquire_permit(PermitMutex *pm) {\n    pthread_mutex_lock(&pm->mutex);\n    // Loop is crucial to handle spurious wakeups and re-check condition\n    while (pm->available_permits == 0) {\n        pthread_cond_wait(&pm->cond, &pm->mutex);\n    }\n    pm->available_permits--;\n    pthread_mutex_unlock(&pm->mutex);\n}\n\n// Release a permit (exit critical section)\nvoid release_permit(PermitMutex *pm) {\n    pthread_mutex_lock(&pm->mutex);\n    pm->available_permits++;\n    // Signal one waiting thread. For this specific problem, signal is generally sufficient\n    // as only one thread can acquire a permit at a time when one becomes available.\n    // In other scenarios, pthread_cond_broadcast might be considered if multiple\n    // threads could simultaneously proceed.\n    pthread_cond_signal(&pm->cond);\n    pthread_mutex_unlock(&pm->mutex);\n}\n```\n\n**הסבר:**\n\n1.  **מבנה `PermitMutex`**: המבנה מכיל `pthread_mutex_t` להבטחת הדדיות (Mutual Exclusion) בעת גישה למשתנים המשותפים, `pthread_cond_t` לתזמון והמתנה של תהליכים, ו-`available_permits` שהוא מונה של ההרשאות הפנויות כרגע.\n\n2.  **`init_permit_mutex(PermitMutex *pm, int N)`**: פונקציה זו מאתחלת את המוטקס, את משתנה התנאי, ומגדירה את מספר ההרשאות הזמינות הראשוני ל-N.\n\n3.  **`acquire_permit(PermitMutex *pm)`**: \n    *   התהליך נועל את המוטקס (`pthread_mutex_lock`) כדי להגן על הגישה ל-`available_permits` ועל הקריאה ל-`pthread_cond_wait`.\n    *   הוא נכנס ללולאת `while (pm->available_permits == 0)`. לולאה זו היא קריטית ממספר סיבות: ראשית, היא מבטיחה שתהליך ימתין *רק* כאשר אין הרשאות זמינות. שנית, היא מטפלת ב\"התעוררויות שווא\" (spurious wakeups) שבהן `pthread_cond_wait` עשוי לחזור למרות שהתנאי עדיין לא מתקיים. הלולאה מבטיחה שהתנאי ייבדק שוב לאחר כל התעוררות.\n    *   אם יש הרשאה זמינה (כלומר, `available_permits > 0`), התהליך מקטין את המונה ב-1 וממשיך בדרכו, לאחר ששחרר את המוטקס (`pthread_mutex_unlock`).\n\n4.  **`release_permit(PermitMutex *pm)`**: \n    *   התהליך נועל את המוטקס.\n    *   הוא מגדיל את `available_permits` ב-1, משמע הרשאה אחת התפנתה.\n    *   הוא קורא ל-`pthread_cond_signal(&pm->cond)` כדי להעיר תהליך אחד הממתין על משתנה התנאי (אם יש כזה). התהליך שהתעורר יוכל כעת לבדוק את התנאי בלולאת ה-`while` שלו ב-`acquire_permit`.\n    *   לבסוף, התהליך משחרר את המוטקס. \n\n**נכונות ודיון:**\n*   **מניעה הדדית מורחבת**: המוטקס מבטיח שהגישה למונה `available_permits` היא הדדית, ומונעת מצבי מירוץ (race conditions) בשינוי ערכו. המונה עצמו מבטיח שכל היותר N תהליכים יחזיקו הרשאה בו-זמנית.\n*   **חופש מקיפאון (Deadlock-free)**: המימוש אינו מכיל תנאים לקיפאון. תהליכים ממתינים רק אם אין הרשאות, ומשתחררים כאשר הרשאה מתפנה. אין תלות מעגלית במשאבים.\n*   **הוגנות (Fairness)**: המימוש עם `pthread_cond_signal` לא מבטיח הוגנות חזקה (לדוגמה, בסדר FIFO) בין התהליכים הממתינים. מערכת ההפעלה קובעת איזה תהליך ממתין יתעורר. עבור הוגנות חזקה יותר, ייתכן שיהיה צורך במנגנוני תור מורכבים יותר או שימוש ב-`pthread_cond_broadcast` יחד עם מונה תהליכים ממתינים, אם כי זה פחות יעיל ויכול להוביל ל\"עדר מתעורר\" (thundering herd) אם רק אחד יכול להמשיך."}, "difficulty_estimation": "Hard", "_source_file": "0262__Mutexes__Open__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:21:46", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Mutexes", "Threads", "Concurrency", "Fairness", "Reentrancy"], "content": {"text": "מנעול הדדי (Mutex) הוא כלי סנכרון בסיסי, אך לרוב הוא אינו תומך בכניסה מחדש (reentrancy) ואינו מבטיח הוגנות (fairness) בסדר רכישת המנעול. מנעול נכנס מחדש מאפשר לחוט שכבר רכש את המנעול לרכוש אותו שוב מבלי להיחסם. מנעול הוגן מבטיח שחוטים ירכשו את המנעול בסדר שבו ביקשו אותו (FIFO).\n\nמטרת שאלה זו היא לממש מנעול הדדי בעל שתי התכונות הללו: כניסה מחדש והוגנות, תוך שימוש במנעולים הדדיים בסיסיים (`pthread_mutex_t`) ומשתני תנאי (`pthread_cond_t`) מספריית `pthreads` בלבד.\n\nיש להשלים את מבנה הנתונים `ReentrantFairMutex` ואת מימוש הפונקציות `rf_mutex_init`, `rf_mutex_destroy`, `rf_mutex_lock`, ו-`rf_mutex_unlock`.\n\nהקפידו על:\n1.  **כניסה מחדש**: חוט שכבר מחזיק במנעול יכול לקרוא ל-`rf_mutex_lock` שוב מבלי להיחסם. כל קריאה ל-`lock` חייבת להיות מותאמת בקריאה ל-`unlock` כדי לשחרר את המנעול באופן סופי.\n2.  **הוגנות**: חוטים ירכשו את המנעול בסדר שבו ביקשו אותו (FIFO).\n3.  **מניעה הדדית**: רק חוט אחד יכול להחזיק במנעול באופן בלעדי (למעט כניסות חוזרות של אותו חוט).", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <stdbool.h> // For bool type\n\n#define INVALID_THREAD_ID (pthread_t)0 // Assuming 0 is not a valid thread ID for pthread_self() or can be used as a sentinel\n\ntypedef struct ReentrantFairMutex {\n    pthread_mutex_t lock_mutex;     // מנעול להגנה על מבנה הנתונים הפנימי\n    pthread_cond_t condition;       // משתנה תנאי להמתנה על המנעול\n    pthread_t owner;                // מזהה החוט שמחזיק במנעול\n    bool is_locked;                 // האם המנעול נעול כרגע על ידי חוט כלשהו?\n    int lock_count;                 // כמה פעמים הבעלים הנוכחי רכש את המנעול\n    unsigned long next_ticket;      // המספר הבא שיינתן לחוט שמבקש להיכנס\n    unsigned long served_ticket;    // המספר של החוט הבא שיקבל את המנעול\n} ReentrantFairMutex;\n\nvoid rf_mutex_init(ReentrantFairMutex *m);\nvoid rf_mutex_destroy(ReentrantFairMutex *m);\nvoid rf_mutex_lock(ReentrantFairMutex *m);\nvoid rf_mutex_unlock(ReentrantFairMutex *m);"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כדי לממש מנעול הדדי נכנס מחדש והוגן, נשתמש בשילוב של מנעול בסיסי (`lock_mutex`) להגנה על המצב הפנימי של המנעול, משתנה תנאי (`condition`) להמתנת חוטים, וכן מנגנון 'כרטיסים' (tickets) להבטחת הוגנות.\n\n**מבנה הנתונים:**\n*   `lock_mutex`: מנעול בסיסי המשמש להגנה על כל הגישה למשתנים הפנימיים של `ReentrantFairMutex`.\n*   `condition`: משתנה תנאי שחוטים ממתינים עליו כאשר המנעול אינו זמין או כאשר הם אינם בתור (לפי מנגנון הכרטיסים).\n*   `owner`: שומר את ה-ID של החוט שמחזיק כרגע במנעול. מאותחל ל-`INVALID_THREAD_ID` כאשר המנעול אינו בשימוש.\n*   `is_locked`: דגל בוליאני המציין אם המנעול נעול כרגע על ידי חוט כלשהו.\n*   `lock_count`: מונה את מספר הפעמים שהחוט הנוכחי המחזיק במנעול רכש אותו. משמש לכניסה מחדש.\n*   `next_ticket`: מונה עולה (מוגן ע\"י `lock_mutex`) הנותן לכל חוט שמבקש את המנעול 'כרטיס' ייחודי.\n*   `served_ticket`: מונה עולה המציין איזה 'כרטיס' כרגע רשאי לרכוש את המנעול.\n\n**מימוש `rf_mutex_init`:**\nמאתחל את כל השדות לערכי ברירת מחדל: המנעול הבסיסי ומשתנה התנאי מאותחלים, `owner` מאופס ל-`INVALID_THREAD_ID`, `is_locked` מוגדר ל-`false`, ו-`lock_count`, `next_ticket`, ו-`served_ticket` מאופסים.\n\n**מימוש `rf_mutex_destroy`:**\nמשחרר את המשאבים של המנעול הבסיסי ומשתנה התנאי.\n\n**מימוש `rf_mutex_lock`:**\n1.  רוכש את `lock_mutex` כדי להגן על המצב הפנימי.\n2.  בודק אם החוט הנוכחי הוא הבעלים של המנעול (עבור כניסה מחדש) באמצעות `is_locked` ו-`owner`.\n    *   אם כן, מקדם את `lock_count` ומשחרר את `lock_mutex`. במקרה זה, החוט כבר מחזיק במנעול, ולכן אינו צריך להמתין.\n    *   אם לא, מקבל 'כרטיס' חדש על ידי קידום `next_ticket`.\n    *   ממתין על `condition` כל עוד: `is_locked` נכון (כלומר, מישהו אחר מחזיק בו) או ה'כרטיס' שלו (`my_ticket`) אינו `served_ticket` (כדי להבטיח הוגנות). תנאי זה מבטיח שהחוט ממתין גם אם המנעול פנוי אך הוא לא הגיע תורו, או אם המנעול תפוס.\n3.  לאחר שהחוט רוכש את המנעול (או ממשיך מכניסה מחדש), הוא מגדיר את `owner` ל-`current_thread`, את `is_locked` ל-`true`, ומאתחל את `lock_count` ל-1 (זו הרכישה הראשונה של המנעול עבור חוט זה).\n4.  משחרר את `lock_mutex`.\n\n**מימוש `rf_mutex_unlock`:**\n1.  רוכש את `lock_mutex` כדי להגן על המצב הפנימי.\n2.  בודק אם החוט הנוכחי הוא אכן הבעלים של המנעול (באמצעות `is_locked` ו-`owner`). אם לא, זו שגיאה, ויש להדפיס הודעה מתאימה.\n3.  מפחית את `lock_count`. כל קריאה ל-`lock` חייבת להיות מותאמת בקריאה ל-`unlock`.\n4.  אם `lock_count` הגיע ל-0, פירושו שהמנעול שוחרר באופן סופי על ידי הבעלים הנוכחי.\n    *   מאפס את `owner` ל-`INVALID_THREAD_ID`.\n    *   מגדיר את `is_locked` ל-`false`.\n    *   מקדם את `served_ticket` כדי לאפשר לחוט הבא בתור לרכוש את המנעול.\n    *   משחרר את כל החוטים הממתינים על `condition` (`pthread_cond_broadcast`) כדי שהחוט בעל ה'כרטיס' התואם יוכל להמשיך. שימוש ב-`broadcast` מבטיח שגם אם חוטים התעוררו מוקדם (spurious wakeup), הם יבדקו שוב את התנאי וימתינו אם אינם בתור, אך החוט הנכון (עם `served_ticket` תואם) יתקדם.\n5.  משחרר את `lock_mutex`.\n\n**הסבר על כניסה מחדש והוגנות:**\n*   **כניסה מחדש**: מתאפשרת על ידי שמירת `owner` ו-`lock_count`. חוט יכול לרכוש את המנעול מספר פעמים כל עוד הוא ה-`owner` הנוכחי, ורק כאשר `lock_count` יורד ל-0 המנעול משוחרר לחוטים אחרים.\n*   **הוגנות**: מושגת באמצעות מנגנון ה'כרטיסים' (`next_ticket` ו-`served_ticket`). כל חוט מקבל מספר עוקב כאשר הוא מנסה לרכוש את המנעול, והוא יכול להמשיך רק כאשר ה-'כרטיס' שלו תואם ל-'כרטיס' ה-`served_ticket` הנוכחי. זה מבטיח סדר FIFO בהשגת המנעול."}, "difficulty_estimation": "Hard", "_source_file": "0263__Mutexes__Open__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:22:33", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Synchronization", "Mutexes", "Threads", "Deadlock", "Concurrency"], "content": {"text": "נתונה ספרייה המכילה שתי פונקציות, `outer_function` ו-`inner_function`, אשר שתיהן ניגשות למשאב משותף כלשהו. הפונקציה `outer_function` קוראת ל-`inner_function` כחלק מפעולתה. שתי הפונקציות חייבות להיות בטוחות לשימוש בריבוי תהליכים (thread-safe) ומוגנות מפני תנאי מירוץ על המשאב המשותף באמצעות מנעול (mutex).\n\n**סעיף 1: ניתוח בעיה**\nהסבירו מדוע שימוש במנעול `pthread_mutex_t` רגיל (שאינו רקורסיבי) יגרום לקיפאון (deadlock) אם `outer_function` תנסה לנעול את המשאב, ואז `inner_function` (שנקראת מתוך `outer_function` על ידי אותו חוט) תנסה לנעול את אותו המשאב שוב.\n\n**סעיף 2: מימוש מנעול רקורסיבי**\nממשו מבנה נתונים בשם `recursive_mutex_t` ואת הפעולות `recursive_mutex_init`, `recursive_mutex_destroy`, `recursive_mutex_lock` ו-`recursive_mutex_unlock` עבורו. המימוש צריך להתנהג כמנעול רקורסיבי, כלומר, חוט שמחזיק כבר במנעול יכול לנעול אותו שוב בהצלחה, אך חייב לשחרר אותו מספר פעמים זהה למספר הפעמים שרכש אותו לפני שחוטים אחרים יוכלו לרכוש אותו. השתמשו אך ורק במנעול `pthread_mutex_t` רגיל, משתנה מצב (condition variable), מונה, ומזהה חוט (`pthread_t`). אין להשתמש ב-`pthread_mutex_t` מסוג `PTHREAD_MUTEX_RECURSIVE` במימוש עצמו.\n\nהקוד עבור ההגדרות והפונקציות הנדרשות:", "code_snippet": "```c\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\ntypedef struct {\n    pthread_mutex_t internal_lock; // Protects owner, count, and cond\n    pthread_cond_t cond;           // For waiting threads\n    pthread_t owner;                // ID of the thread currently holding the lock\n    int count;                      // Recursion count\n} recursive_mutex_t;\n\nvoid recursive_mutex_init(recursive_mutex_t* m);\nvoid recursive_mutex_destroy(recursive_mutex_t* m);\nvoid recursive_mutex_lock(recursive_mutex_t* m);\nvoid recursive_mutex_unlock(recursive_mutex_t* m);\n```"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "**סעיף 1: ניתוח בעיה**\nמנעול `pthread_mutex_t` רגיל הוא מנעול שאינו רקורסיבי. כאשר חוט רוכש מנעול כזה, הוא הופך לבעליו. אם אותו חוט ינסה לרכוש את אותו המנעול שוב, לפני שחרורו, החוט ייחסם וימתין לעצמו שישחרר את המנעול, מה שיוביל לקיפאון עצמי (self-deadlock). בתרחיש הנתון, `outer_function` רוכשת את המנעול. לאחר מכן, `inner_function` (שנקראת על ידי `outer_function`, כלומר על ידי אותו חוט) מנסה לרכוש את אותו המנעול. מכיוון שהמנעול כבר מוחזק על ידי אותו החוט, `inner_function` תחסם, והחוט ייכנס למצב קיפאון.\n\n**סעיף 2: מימוש מנעול רקורסיבי**\nמנעול רקורסיבי מאפשר לאותו חוט לרכוש את המנעול מספר פעמים. הוא שומר מונה של מספר הפעמים שהבעלים הנוכחי רכש אותו. המנעול משוחרר באופן מלא רק כאשר המונה יורד לאפס. המימוש דורש מנעול רגיל להגנה על המצב הפנימי (בעלים, מונה), משתנה מצב להמתנה, מונה ומזהה חוט.\n\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\ntypedef struct {\n    pthread_mutex_t internal_lock; // Protects owner, count, and cond\n    pthread_cond_t cond;           // For waiting threads\n    pthread_t owner;                // ID of the thread currently holding the lock\n    int count;                      // Recursion count\n} recursive_mutex_t;\n\nvoid recursive_mutex_init(recursive_mutex_t* m) {\n    pthread_mutex_init(&m->internal_lock, NULL);\n    pthread_cond_init(&m->cond, NULL);\n    m->owner = 0; // Initialize with a value that pthread_equal will correctly identify as not owned\n    m->count = 0;\n}\n\nvoid recursive_mutex_destroy(recursive_mutex_t* m) {\n    pthread_mutex_destroy(&m->internal_lock);\n    pthread_cond_destroy(&m->cond);\n}\n\nvoid recursive_mutex_lock(recursive_mutex_t* m) {\n    pthread_mutex_lock(&m->internal_lock);\n\n    // If the lock is owned by another thread, wait\n    while (m->count > 0 && !pthread_equal(m->owner, pthread_self())) {\n        pthread_cond_wait(&m->cond, &m->internal_lock);\n    }\n\n    // If the lock is now free or owned by the current thread\n    if (m->count == 0) {\n        m->owner = pthread_self();\n    }\n    m->count++;\n\n    pthread_mutex_unlock(&m->internal_lock);\n}\n\nvoid recursive_mutex_unlock(recursive_mutex_t* m) {\n    pthread_mutex_lock(&m->internal_lock);\n\n    // Error check: attempting to unlock a mutex not owned by the current thread\n    if (!pthread_equal(m->owner, pthread_self())) {\n        fprintf(stderr, \"Error: Attempting to unlock a recursive mutex not owned by current thread!\\n\");\n        pthread_mutex_unlock(&m->internal_lock);\n        return;\n    }\n\n    m->count--;\n\n    // If the count drops to zero, the lock is fully released\n    if (m->count == 0) {\n        m->owner = 0; // Mark as unowned. Value 0 is often used for unowned in pthread_t context.\n        pthread_cond_signal(&m->cond); // Signal one waiting thread\n    }\n\n    pthread_mutex_unlock(&m->internal_lock);\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0264__Mutexes__Open__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:43:15", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Mutexes", "Concurrency", "Race Condition", "Threads"], "content": {"text": "נתונה תוכנית C המשתמשת בחוטים (threads) לביצוע פעולה משותפת. מטרת התוכנית היא להגדיל מונה גלובלי (counter) על ידי שני חוטים. עיין בקוד וזהה את הבעיה העיקרית בו. הסבר מדוע היא מתרחשת וכיצד ניתן לתקן אותה.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h> // For exit\n\nint counter = 0;\npthread_mutex_t my_mutex;\n\nvoid* increment_thread(void* arg) {\n    for (int i = 0; i < 100000; ++i) {\n        // Critical section: incrementing counter\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tids[2];\n\n    pthread_mutex_init(&my_mutex, NULL); // Initialize mutex\n\n    // Create two threads\n    pthread_create(&tids[0], NULL, increment_thread, NULL);\n    pthread_create(&tids[1], NULL, increment_thread, NULL);\n\n    // Wait for threads to finish\n    pthread_join(tids[0], NULL);\n    pthread_join(tids[1], NULL);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    pthread_mutex_destroy(&my_mutex); // Destroy mutex\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הבעיה העיקרית בקוד היא תנאי מרוץ (race condition). שני החוטים מנסים לגשת ולשנות את המונה הגלובלי `counter` במקביל ללא כל מנגנון סנכרון. הפעולה `counter++` אינה אטומית; היא מורכבת משלושה שלבים: קריאת ערך המונה, הגדלתו ב-1, וכתיבת הערך החדש בחזרה לזיכרון. כאשר שני חוטים מבצעים פעולה זו במקביל, ייתכן ששניהם יקראו את אותו ערך של `counter` לפני שאחד מהם יספיק לכתוב את הערך המוגדל בחזרה. לדוגמה, אם `counter` הוא 0, חוט א' קורא 0, חוט ב' קורא 0. חוט א' מגדיל ל-1 וכותב 1. חוט ב' מגדיל ל-1 וכותב 1. התוצאה הסופית תהיה 1 במקום 2. כתוצאה מכך, הערך הסופי של `counter` יהיה בדרך כלל נמוך מ-200,000 (הערך הצפוי של 2 חוטים * 100,000 איטרציות) וישתנה בין הרצות שונות.\n\nכדי לתקן את הבעיה, יש להגן על הקטע הקריטי (הגדלת המונה) באמצעות המוטקס `my_mutex`. יש לנעול את המוטקס לפני הגישה למשתנה המשותף ולשחרר אותו לאחר מכן. התיקון לקוד ייראה כך:\n\n```c\nvoid* increment_thread(void* arg) {\n    for (int i = 0; i < 100000; ++i) {\n        pthread_mutex_lock(&my_mutex);   // נעל את המוטקס לפני הגישה למשתנה המשותף\n        counter++;                       // קטע קריטי\n        pthread_mutex_unlock(&my_mutex); // שחרר את המוטקס לאחר הגישה\n    }\n    return NULL;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0265__Mutexes__CodeAnalysis__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:23:14", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Mutexes", "Concurrency", "Race Conditions", "Threads", "Synchronization"], "content": {"text": "נתונה תוכנית C המשתמשת במספר תהליכונים (threads) כדי להגדיל מונה גלובלי. עיין בקוד הבא. מהו הפלט הצפוי של התוכנית? האם הפלט יהיה תמיד זהה בריצות שונות? אם לא, מדוע? כיצד ניתן לתקן את הקוד כך שהמונה יגיע תמיד לערך הנכון?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <stdlib.h> // For exit\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 100000\n\nint counter = 0;\n\nvoid *increment_counter(void *arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        counter++;\n    }\n    pthread_exit(NULL);\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        if (pthread_create(&threads[i], NULL, increment_counter, NULL) != 0) {\n            perror(\"Failed to create thread\");\n            exit(EXIT_FAILURE);\n        }\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        if (pthread_join(threads[i], NULL) != 0) {\n            perror(\"Failed to join thread\");\n            exit(EXIT_FAILURE);\n        }\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפלט הצפוי התיאורטי של התוכנית הוא 500000 (כלומר, NUM_THREADS * INCREMENTS_PER_THREAD). אולם, בפועל, הפלט יהיה לרוב נמוך יותר מ-500000 וגם לא יהיה זהה בין ריצות שונות של התוכנית. הסיבה לכך היא תנאי מרוץ (Race Condition).\n\nפעולת `counter++` אינה אטומית. היא מורכבת משלוש פעולות ברמה נמוכה יותר (קריאת ערך המונה לתוך רגיסטר, הגדלת הערך ברגיסטר, וכתיבת הערך המעודכן בחזרה לזיכרון). כאשר מספר תהליכונים מבצעים פעולה זו במקביל ללא סנכרון, ייתכן שתהליכון אחד יקרא את ערך המונה, יגדיל אותו, אך לפני שיספיק לכתוב אותו בחזרה לזיכרון, תהליכון אחר יקרא את אותו ערך ישן של המונה. כתוצאה מכך, אחת מההגדלות (increments) תאבד, והמונה לא יגיע לערכו הסופי הנכון.\n\nכדי לתקן את הקוד ולהבטיח שהמונה יגיע תמיד לערך הנכון, יש להשתמש ב-mutex (מנעול הדדי) כדי להגן על הגישה למשתנה המשותף `counter`. יש לאתחל את ה-mutex לפני יצירת התהליכונים, לנעול אותו לפני הגישה ל-`counter++` ולשחרר אותו מיד לאחר מכן, ולבסוף להרוס את ה-mutex בסיום התוכנית. התיקון ייראה כך:\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n#include <stdlib.h>\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 100000\n\nint counter = 0;\npthread_mutex_t mutex; // הצהרה על mutex גלובלי\n\nvoid *increment_counter(void *arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&mutex);   // נעילת ה-mutex לפני גישה למשתנה המשותף\n        counter++;\n        pthread_mutex_unlock(&mutex); // שחרור ה-mutex לאחר הגישה\n    }\n    pthread_exit(NULL);\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    pthread_mutex_init(&mutex, NULL); // אתחול ה-mutex\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        if (pthread_create(&threads[i], NULL, increment_counter, NULL) != 0) {\n            perror(\"Failed to create thread\");\n            exit(EXIT_FAILURE);\n        }\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        if (pthread_join(threads[i], NULL) != 0) {\n            perror(\"Failed to join thread\");\n            exit(EXIT_FAILURE);\n        }\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    pthread_mutex_destroy(&mutex); // השמדת ה-mutex\n    return 0;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0266__Mutexes__CodeAnalysis__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:23:30", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Mutexes", "Concurrency", "Race Conditions"], "content": {"text": "נתונה תוכנית C המשתמשת בשני תהליכונים (threads) כדי להגדיל מונה משותף. עיין בקוד הנתון וענה על השאלות הבאות:", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint shared_counter = 0;\n\nvoid* increment_thread(void* arg) {\n    for (int i = 0; i < 100000; ++i) {\n        shared_counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_create(&tid1, NULL, increment_thread, NULL);\n    pthread_create(&tid2, NULL, increment_thread, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    printf(\"Final counter value: %d\\n\", shared_counter);\n\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "101.1", "text": "מהו הפלט הצפוי של התוכנית? האם הוא יהיה תמיד זהה? נמק.", "code_snippet": null, "options": null}, {"id": "101.2", "text": "תאר את הבעיה העיקרית בקוד הנתון וכיצד היא יכולה להתרחש.", "code_snippet": null, "options": null}, {"id": "101.3", "text": "תקן את הקוד הנתון באמצעות mutex כדי להבטיח שהמונה המשותף יגיע לערכו הנכון. כלול את כל השינויים הנדרשים (הצהרה, אתחול, שימוש וסיום) בקוד המתוקן.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון לשאלה 101:\n\n**101.1 פלט צפוי וקביעות:**\nהפלט הצפוי של התוכנית לא יהיה 200000. לרוב, הפלט יהיה ערך נמוך יותר מ-200000, והוא לא יהיה תמיד זהה בין הרצות שונות של התוכנית. הסיבה לכך היא תנאי מרוץ (Race Condition).\n\n**101.2 תיאור הבעיה:**\nהבעיה העיקרית בקוד היא תנאי מרוץ על המשתנה הגלובלי המשותף `shared_counter`. הפעולה `shared_counter++` נראית אטומית, אך בפועל היא מורכבת משלוש פעולות בסיסיות ברמת המעבד (CPU):\n1. קריאת הערך הנוכחי של `shared_counter` מהזיכרון לרג'יסטר.\n2. הגדלת הערך ברג'יסטר באחד.\n3. כתיבת הערך המעודכן מהרג'יסטר בחזרה לזיכרון.\n\nכאשר שני תהליכונים (או יותר) מנסים לבצע את הפעולה הזו בו-זמנית, ייתכן ששניהם יקראו את אותו ערך ישן של `shared_counter` לפני שאחד מהם הספיק לכתוב בחזרה את הערך המעודכן. לדוגמה, אם `shared_counter` הוא 0:\n- תהליכון A קורא 0.\n- תהליכון B קורא 0.\n- תהליכון A מגדיל ל-1 וכותב בחזרה 1.\n- תהליכון B מגדיל ל-1 (מ-0 שקרא) וכותב בחזרה 1.\nבמקרה זה, בוצעו שתי הגדלות, אך המונה הגיע ל-1 במקום ל-2, ואחת ההגדלות 'אבדה'. כתוצאה מכך, הערך הסופי של `shared_counter` יהיה נמוך מהצפוי (200000) ולא יהיה דטרמיניסטי.\n\n**101.3 תיקון הקוד באמצעות mutex:**\nכדי לתקן את הבעיה ולהבטיח שהמונה יגיע לערכו הנכון (200000), יש להשתמש ב-mutex כדי להגן על הגישה לאזור הקריטי (השורה `shared_counter++`). הנה הקוד המתוקן:\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n\nint shared_counter = 0;\npthread_mutex_t counter_mutex; // 1. הצהרה על mutex גלובלי\n\nvoid* increment_thread(void* arg) {\n    for (int i = 0; i < 100000; ++i) {\n        pthread_mutex_lock(&counter_mutex);   // 3. נעילת mutex לפני גישה לאזור הקריטי\n        shared_counter++;                     // האזור הקריטי\n        pthread_mutex_unlock(&counter_mutex); // 3. שחרור mutex לאחר סיום הגישה\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&counter_mutex, NULL); // 2. אתחול ה-mutex לפני יצירת התהליכונים\n\n    pthread_create(&tid1, NULL, increment_thread, NULL);\n    pthread_create(&tid2, NULL, increment_thread, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    printf(\"Final counter value: %d\\n\", shared_counter);\n\n    pthread_mutex_destroy(&counter_mutex); // 4. השמדת ה-mutex בסיום השימוש בו\n    return 0;\n}\n```\n\n**הסבר לתיקון:**\n1.  **הצהרה על mutex**: הוספנו משתנה גלובלי מסוג `pthread_mutex_t` בשם `counter_mutex`. זהו אובייקט הסנכרון שישמש להגנה על המונה.\n2.  **אתחול mutex**: בתוך פונקציית `main`, לפני יצירת התהליכונים, אתחלנו את ה-mutex באמצעות `pthread_mutex_init(&counter_mutex, NULL)`. אתחול זה מכין את ה-mutex לשימוש.\n3.  **נעילה ושחרור mutex**: בתוך פונקציית `increment_thread`, עטפנו את הפעולה `shared_counter++;` בקריאות ל-`pthread_mutex_lock(&counter_mutex)` ו-`pthread_mutex_unlock(&counter_mutex)`. קריאה ל-`lock` מנסה לנעול את ה-mutex; אם הוא כבר נעול על ידי תהליכון אחר, התהליכון הנוכחי ימתין עד שה-mutex ישוחרר. קריאה ל-`unlock` משחררת את ה-mutex. זה מבטיח שרק תהליכון אחד יוכל להיכנס לאזור הקריטי (להגדיל את `shared_counter`) בכל רגע נתון, ובכך מונע את תנאי המרוץ.\n4.  **השמדת mutex**: לאחר שכל התהליכונים סיימו את ריצתם ואין יותר צורך ב-mutex, השמדנו אותו באמצעות `pthread_mutex_destroy(&counter_mutex)` בתוך פונקציית `main`. פעולה זו משחררת את המשאבים שהוקצו ל-mutex."}, "difficulty_estimation": "Easy", "_source_file": "0267__Mutexes__CodeAnalysis__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:23:59", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Mutexes", "Synchronization", "Concurrency", "Threads"], "content": {"text": "נתונה תוכנית C המשתמשת בחוטים (threads) ובמנעול (mutex) כדי לעדכן משתנה גלובלי. קראו את הקוד המצורף וענו על השאלה הבאה:\n\nמה יהיה הערך הסופי המודפס של המשתנה הגלובלי `counter` לאחר שכל החוטים יסיימו את ריצתם, ומהי הסיבה לכך?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h> // For exit\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 100000\n\nint counter = 0;\npthread_mutex_t mtx;\n\nvoid* thread_function(void* arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&mtx); // Acquire mutex\n        counter++;\n        pthread_mutex_unlock(&mtx); // Release mutex\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    pthread_mutex_init(&mtx, NULL); // Initialize mutex\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_function, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    pthread_mutex_destroy(&mtx); // Destroy mutex\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הערך הסופי המודפס של המשתנה `counter` יהיה 500000.\n\nהסיבה לכך היא שהתוכנית משתמשת במנעול (mutex) כדי להגן על פעולת העדכון של המשתנה הגלובלי `counter`. כל חוט מבצע את הפעולה `counter++` בתוך קטע קריטי המוגן על ידי `pthread_mutex_lock` ו-`pthread_mutex_unlock`. מנגנון זה מבטיח שרק חוט אחד יכול לגשת ולשנות את `counter` בכל רגע נתון, ובכך מונע מצב מרוץ (race condition). כתוצאה מכך, כל אחת מ-100,000 ההגדלות שמבצע כל חוט (ישנם 5 חוטים) מבוצעת באופן בטוח ומשתקפת בערך הסופי של `counter`.\n\nחישוב: 5 חוטים * 100,000 הגדלות לכל חוט = 500,000."}, "difficulty_estimation": "Easy", "_source_file": "0268__Mutexes__CodeAnalysis__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:24:11", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Mutexes", "Synchronization", "Concurrency", "Deadlock"], "content": {"text": "נתונה תוכנית C המשתמשת בספריה `pthreads` ומגדילה משתנה גלובלי משותף `global_counter` באמצעות מספר תהליכונים. התוכנית מנסה להגן על הגישה למשתנה המשותף באמצעות mutex. עיין בקוד הנתון וענה על השאלה.\n\nמהי הבעיה העיקרית בקוד הנתון, וכיצד היא תשפיע על ריצת התוכנית ועל הערך הסופי של `global_counter`? כיצד ניתן לתקן את הבעיה?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep (optional, but good practice for real-world code)\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 100000\n\nint global_counter = 0;\npthread_mutex_t counter_mutex;\n\nvoid *thread_function(void *arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&counter_mutex);\n        global_counter++;\n        // חסר שחרור ה-mutex כאן!\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    pthread_mutex_init(&counter_mutex, NULL);\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_function, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", global_counter);\n\n    pthread_mutex_destroy(&counter_mutex);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הבעיה העיקרית בקוד היא שה-mutex ננעל באמצעות `pthread_mutex_lock()` בתוך הלולאה, אך לעולם אינו משוחרר באמצעות `pthread_mutex_unlock()`.\n\n**השפעה על ריצת התוכנית:**\nכאשר תהליכון כלשהו יקבל את ה-mutex בפעם הראשונה, הוא ינעל אותו. מכיוון שזהו mutex רגיל (לא רקורסיבי, שכן הוא מאותחל עם `NULL` attributes), ניסיון לנעול mutex שכבר ננעל על ידי אותו תהליכון (באיטרציה הבאה של הלולאה) יגרום לקיפאון (deadlock) של התהליכון עצמו. אם תהליכונים אחרים ינסו לנעול את ה-mutex לפני שהתהליכון הראשון נתקע, הם פשוט ימתינו ללא הגבלה מכיוון שה-mutex נשאר נעול. כתוצאה מכך, התוכנית כולה תיתקע ולא תסיים את ריצתה.\n\n**השפעה על הערך הסופי של `global_counter`:**\nהתוכנית לא תדפיס ערך סופי כלל מכיוון שהיא תיתקע לפני השורה המדפיסה את הערך. אם איכשהו היא הייתה ממשיכה, הערך הסופי של `global_counter` יהיה שגוי ולא יגיע ל-`NUM_THREADS * INCREMENTS_PER_THREAD` (שהוא הערך המצופה).\n\n**תיקון:**\nיש לשחרר את ה-mutex לאחר כל פעולת הגדלה של המונה. התיקון הוא הוספת השורה `pthread_mutex_unlock(&counter_mutex);` מיד לאחר השורה `global_counter++;` בתוך לולאת ה-`for` בפונקציה `thread_function`. כך הקטע הקריטי יהיה מוגן כראוי וה-mutex ישוחרר לאחר כל גישה למשתנה המשותף, מה שיאפשר לתהליכונים אחרים לגשת אליו.\n\n**קוד מתוקן (קטע רלוונטי):**\n```c\nvoid *thread_function(void *arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&counter_mutex);\n        global_counter++;\n        pthread_mutex_unlock(&counter_mutex); // התיקון\n    }\n    return NULL;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0269__Mutexes__CodeAnalysis__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:24:26", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Mutexes", "Synchronization", "Concurrency", "Deadlock"], "content": {"text": "נתונה תוכנית C המשתמשת בחוטים (threads) ובמנעול (mutex) כדי להגדיל מונה גלובלי. קראו את הקוד וציינו מה יקרה כאשר התוכנית תרוץ. נמקו את תשובתכם.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <stdlib.h> // For exit\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 100000\n\npthread_mutex_t counter_mutex;\nint counter = 0;\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&counter_mutex);\n        counter++;\n        // Bug: Missing pthread_mutex_unlock(&counter_mutex);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    pthread_mutex_init(&counter_mutex, NULL);\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        if (pthread_create(&threads[i], NULL, increment_counter, NULL) != 0) {\n            perror(\"Failed to create thread\");\n            exit(EXIT_FAILURE);\n        }\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        if (pthread_join(threads[i], NULL) != 0) {\n            perror(\"Failed to join thread\");\n            exit(EXIT_FAILURE);\n        }\n    }\n\n    pthread_mutex_destroy(&counter_mutex);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכנית תיכנס למצב של קיפאון (deadlock). הסיבה לכך היא שבפונקציה `increment_counter`, המנעול `counter_mutex` ננעל באמצעות `pthread_mutex_lock` אך לעולם אינו משוחרר באמצעות `pthread_mutex_unlock`. החוט הראשון שמצליח לנעול את המנעול יבצע את כל האיטרציות שלו בלולאה, אך המנעול יישאר נעול. כל חוט אחר שינסה לנעול את המנעול באמצעות `pthread_mutex_lock` ייחסם וימתין ללא הגבלת זמן לשחרור המנעול. כתוצאה מכך, קריאות `pthread_join` בפונקציית `main` לא יחזרו לעולם עבור החוטים החסומים, והתוכנית תיתקע."}, "difficulty_estimation": "Easy", "_source_file": "0270__Mutexes__CodeAnalysis__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:24:41", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Mutexes", "Concurrency", "Race Condition"], "content": {"text": "נתונה תוכנית C המשתמשת בשני תהליכונים (threads) כדי להגדיל מונה משותף (shared counter). כל תהליכון מגדיל את המונה מספר רב של פעמים. התוכנית מודפסת מטה:\n", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\n#define NUM_THREADS 2\n#define ITERATIONS 100000\n\nint counter = 0;\n\nvoid* increment_thread(void* arg) {\n    for (int i = 0; i < ITERATIONS; ++i) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, increment_thread, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "מהי הבעיה העיקרית בקוד הנתון? הסבירו בקצרה.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "מהו הערך הסופי הצפוי של המונה (counter) לו התוכנית הייתה רצה באופן תקין וללא בעיות סנכרון?", "code_snippet": null, "options": null}, {"id": "1.3", "text": "האם הערך המודפס בפועל על ידי התוכנית יהיה בהכרח זהה לערך הצפוי? אם לא, תארו ערך אפשרי שונה והסבירו מדוע הוא יכול להתקבל.", "code_snippet": null, "options": null}, {"id": "1.4", "text": "תקנו את הפונקציה `increment_thread` ואת פונקציית `main` כך שישתמשו ב-mutex כדי למנוע את הבעיה שתיארתם. הציגו את הקוד המתוקן של שתי הפונקציות.", "code_snippet": "void* increment_thread(void* arg) {\n    // ... קוד מתוקן כאן ...\n}\n\nint main() {\n    // ... קוד מתוקן כאן ...\n}", "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\n1.1. הבעיה העיקרית בקוד היא תנאי מרוץ (race condition). מספר תהליכונים ניגשים ומשנים משתנה גלובלי משותף (counter) ללא מנגנון סנכרון מתאים. הפעולה `counter++` אינה אטומית ומורכבת ממספר הוראות מכונה (קריאה, הגדלה, כתיבה), ולכן תהליכונים שונים יכולים להפריע זה לזה ולגרום לאובדן עדכונים.\n\n1.2. הערך הסופי הצפוי של המונה (counter) לו התוכנית הייתה רצה באופן תקין הוא: `NUM_THREADS * ITERATIONS = 2 * 100000 = 200000`.\n\n1.3. לא, הערך המודפס בפועל על ידי התוכנית לא יהיה בהכרח זהה לערך הצפוי. סביר מאוד שהוא יהיה נמוך יותר מ-200000. לדוגמה, ייתכן ששני תהליכונים קוראים את הערך של `counter` (למשל, שניהם קוראים 100), שניהם מגדילים אותו ל-101, ושניהם כותבים 101 חזרה. במקרה כזה, שתי פעולות הגדלה תרמו רק להגדלה אחת בפועל, ואיבדנו עדכון אחד. ערך אפשרי יכול להיות כל מספר בין 0 ל-200000 (כולל), אך לרוב יהיה קרוב ל-200000 אך קטן ממנו.\n\n1.4. קוד מתוקן באמצעות mutex:\n```c\n#include <stdio.h>\n#include <pthread.h>\n\n#define NUM_THREADS 2\n#define ITERATIONS 100000\n\nint counter = 0;\npthread_mutex_t mutex; // הצהרה על mutex\n\nvoid* increment_thread(void* arg) {\n    for (int i = 0; i < ITERATIONS; ++i) {\n        pthread_mutex_lock(&mutex);   // נעילת mutex לפני הכניסה לקטע קריטי\n        counter++;                    // קטע קריטי\n        pthread_mutex_unlock(&mutex); // שחרור mutex לאחר היציאה מהקטע הקריטי\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    pthread_mutex_init(&mutex, NULL); // אתחול ה-mutex\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, increment_thread, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    pthread_mutex_destroy(&mutex); // השמדת ה-mutex\n\n    return 0;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0271__Mutexes__CodeAnalysis__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:25:01", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Mutexes", "Concurrency", "Deadlock"], "content": {"text": "נתונה תוכנית C המשתמשת ב-mutex להגנה על משתנה גלובלי משותף (counter). מספר תהליכונים (threads) מנסים לעדכן את המונה באמצעות הפונקציה `update_shared_counter`. נתחו את הקוד וזהו בעיה אפשרית.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For usleep\n\npthread_mutex_t counter_mutex = PTHREAD_MUTEX_INITIALIZER;\nint shared_counter = 0;\n\nvoid* update_shared_counter(void* arg) {\n    pthread_mutex_lock(&counter_mutex); // Acquire lock\n\n    shared_counter++; // Critical section\n\n    if (shared_counter % 5 == 0) {\n        printf(\"Counter reached a multiple of 5: %d (Thread ID: %lu)\\n\", shared_counter, (unsigned long)pthread_self());\n        // BUG: Forgot to unlock the mutex before early return\n        return NULL; // Early exit\n    }\n\n    // Simulate some other work that might take time\n    usleep(10); // Small sleep to increase chance of other threads trying to acquire lock\n\n    pthread_mutex_unlock(&counter_mutex); // Release lock\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[10];\n    for (int i = 0; i < 10; ++i) {\n        pthread_create(&threads[i], NULL, update_shared_counter, NULL);\n    }\n\n    for (int i = 0; i < 10; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", shared_counter);\n    pthread_mutex_destroy(&counter_mutex); // Clean up mutex\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הבעיה: קיפאון (Deadlock).\n\nהסבר:\nהפונקציה `update_shared_counter` נועלת את ה-mutex בתחילתה באמצעות `pthread_mutex_lock`. אם התנאי `shared_counter % 5 == 0` מתקיים, הפונקציה מבצעת יציאה מוקדמת (early return) מבלי לשחרר את ה-mutex. כתוצאה מכך, ה-mutex נשאר נעול. כאשר תהליכון אחר ינסה לגשת לקטע הקריטי (כלומר, יקרא ל-`pthread_mutex_lock`), הוא ייחסם לצמיתות וימתין לשחרור ה-mutex שלעולם לא יגיע, מה שיוביל לקיפאון של התוכנית.\n\nתיקון:\nיש לשחרר את ה-mutex בכל נתיבי היציאה מהפונקציה. יש להוסיף קריאה ל-`pthread_mutex_unlock(&counter_mutex);` לפני שורת ה-`return NULL;` בתוך בלוק ה-`if`.\n\nקוד מתוקן (השינוי בשורה 16):\n```c\n#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For usleep\n\npthread_mutex_t counter_mutex = PTHREAD_MUTEX_INITIALIZER;\nint shared_counter = 0;\n\nvoid* update_shared_counter(void* arg) {\n    pthread_mutex_lock(&counter_mutex); // Acquire lock\n\n    shared_counter++; // Critical section\n\n    if (shared_counter % 5 == 0) {\n        printf(\"Counter reached a multiple of 5: %d (Thread ID: %lu)\\n\", shared_counter, (unsigned long)pthread_self());\n        pthread_mutex_unlock(&counter_mutex); // FIX: Release lock before early return\n        return NULL; // Early exit\n    }\n\n    // Simulate some other work that might take time\n    usleep(10); // Small sleep to increase chance of other threads trying to acquire lock\n\n    pthread_mutex_unlock(&counter_mutex); // Release lock\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[10];\n    for (int i = 0; i < 10; ++i) {\n        pthread_create(&threads[i], NULL, update_shared_counter, NULL);\n    }\n\n    for (int i = 0; i < 10; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", shared_counter);\n    pthread_mutex_destroy(&counter_mutex); // Clean up mutex\n    return 0;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0272__Mutexes__CodeAnalysis__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:25:22", "_subject": "Concurrency"}, {"id": 7, "type": "CodeAnalysis", "topic": ["Mutexes", "Concurrency", "Race Conditions", "Pthreads"], "content": {"text": "נתונה תוכנית ה-C הבאה המשתמשת ב-pthreads ובמנעולים (mutexes) כדי לעדכן שני משתנים גלובליים משותפים על ידי מספר תהליכונים (threads). נתחו את התוכנית וענו על השאלות הבאות בהנחה שכל קריאות המערכת מצליחות:\n\n1. מהו הערך *הצפוי* הסופי של `shared_counter_a` ושל `shared_counter_b`?\n2. מהם הערכים *האפשריים* הסופיים של `shared_counter_a` ושל `shared_counter_b` לאחר הרצת התוכנית מספר פעמים?\n3. הסבירו את ההבדל בין התנהגות העדכון של `shared_counter_a` לזו של `shared_counter_b`, ומהו הסיכון הטמון בגישה ל-`shared_counter_b` כפי שהיא ממומשת.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n\n#define NUM_THREADS 5\n#define ITERATIONS_PER_THREAD 100000\n\nint shared_counter_a = 0;\nint shared_counter_b = 0;\npthread_mutex_t counter_mutex;\n\nvoid* thread_func(void* arg) {\n    long thread_id = (long)arg;\n    for (int i = 0; i < ITERATIONS_PER_THREAD; ++i) {\n        // Protecting shared_counter_a with mutex\n        pthread_mutex_lock(&counter_mutex);\n        shared_counter_a++;\n        pthread_mutex_unlock(&counter_mutex);\n\n        // Accessing shared_counter_b without mutex\n        shared_counter_b++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    pthread_mutex_init(&counter_mutex, NULL);\n\n    for (long i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, (void*)i);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    pthread_mutex_destroy(&counter_mutex);\n\n    printf(\"Final shared_counter_a: %d\\n\", shared_counter_a);\n    printf(\"Final shared_counter_b: %d\\n\", shared_counter_b);\n\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. **ערכים צפויים:**\n   - `shared_counter_a`: כל תהליכון מבצע `ITERATIONS_PER_THREAD` (שהוא 100,000) איטרציות, וישנם `NUM_THREADS` (שהוא 5) תהליכונים. כל עדכון של `shared_counter_a` מוגן על ידי המנעול `counter_mutex`. לכן, הערך הצפוי והנכון של `shared_counter_a` יהיה `NUM_THREADS * ITERATIONS_PER_THREAD = 5 * 100,000 = 500,000`.\n   - `shared_counter_b`: באופן לוגי, גם `shared_counter_b` אמור לעבור את אותו מספר עדכונים: `5 * 100,000 = 500,000`.\n\n2. **ערכים אפשריים:**\n   - `shared_counter_a`: הערך האפשרי היחיד עבור `shared_counter_a` הוא `500,000`. המנעול מבטיח שכל פעולת `shared_counter_a++` תתבצע בצורה אטומית ובטוחה ממירוץ תהליכים.\n   - `shared_counter_b`: הערך האפשרי עבור `shared_counter_b` יהיה בין 1 (אם רק תהליכון אחד הספיק לעדכן אותו לפני שכל השאר סיימו או אם מתזמן המשימות גרם לאובדן כל העדכונים למעט אחד) ל-`500,000` (כולל). כלומר, הוא יכול להיות כל ערך בטווח זה, אך לרוב הוא יהיה נמוך מהערך הצפוי של `500,000`. הוא יכול גם להיות 0 אם אף תהליכון לא הספיק לעדכן אותו (אך זה לא סביר עם `pthread_join`). תיאורטית, הוא יכול להיות גם `500,000` במקרה נדיר מאוד של ריצה חסרת מזל של מתזמן התהליכונים, אך הדבר אינו מובטח ואינו סביר.\n\n3. **הסבר ההבדל והסיכון:**\n   - `shared_counter_a` מוגן על ידי `counter_mutex`. לפני כל פעולת הגדלה (`shared_counter_a++`), התהליכון נועל את המנעול, ולאחר הפעולה הוא משחרר אותו. זה מבטיח שהפעולה `shared_counter_a++` (שהיא למעשה קריאה, הגדלה וכתיבה) תתבצע כאופרציה אטומית, ללא הפרעה מתהליכונים אחרים. לכן, אין מצב מרוץ (race condition) עבור `shared_counter_a`, והערך הסופי שלו תמיד יהיה נכון וצפוי.\n   - `shared_counter_b` אינו מוגן על ידי המנעול. הגישה ל-`shared_counter_b` והגדלתו (`shared_counter_b++`) מתבצעת מחוץ לקטע הקריטי המוגן. פעולת הגדלה `x++` אינה אטומית; היא מורכבת משלושה שלבים: 1. קריאת הערך הנוכחי של `x` לתוך רגיסטר. 2. הגדלת הערך ברגיסטר. 3. כתיבת הערך המעודכן חזרה ל-`x`. כאשר מספר תהליכונים מנסים לבצע פעולה זו בו-זמנית, עלול להיווצר מצב מרוץ. לדוגמה, שני תהליכונים יכולים לקרוא את אותו ערך של `shared_counter_b` (למשל 100), שניהם יגדילו אותו ל-101 ברגיסטרים שלהם, ושניהם יכתבו חזרה 101. במקרה כזה, בוצעו שתי פעולות הגדלה אך `shared_counter_b` גדל רק באחד במקום בשניים. כתוצאה מכך, הערך הסופי של `shared_counter_b` יהיה לרוב נמוך מהערך הצפוי, והוא אינו דטרמיניסטי. הסיכון הוא שהתוכנית תפיק תוצאות שגויות ולא עקביות, מה שעלול להוביל לבאגים קשים לאיתור ביישומים מורכבים יותר."}, "difficulty_estimation": "Medium", "_source_file": "0273__Mutexes__CodeAnalysis__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:25:47", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Mutexes", "Concurrency", "Deadlock", "Threads"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בתהליכונים (threads) ובמנעולים (mutexes) לצורך סנכרון גישה למשאבים משותפים. נתח את הקוד וענה על השאלות הבאות:\n\nהאם התוכנית תרוץ עד לסיומה בהצלחה? אם לא, תאר את התקלה שתתרחש והסבר מדוע היא מתרחשת. במידה ותיארת תקלה, הצע שינוי מינימלי בקוד למניעתה, והסבר כיצד השינוי מונע את התקלה. מהם הערכים הסופיים של shared_resource1 ו-shared_resource2 במידה והתוכנית תרוץ בהצלחה (לאחר התיקון)?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For usleep\n\nint shared_resource1 = 0;\nint shared_resource2 = 0;\n\npthread_mutex_t mutex1 = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_t mutex2 = PTHREAD_MUTEX_INITIALIZER;\n\nvoid* thread_func_A(void* arg) {\n    printf(\"Thread A: Attempting to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread A: Locked mutex1. Sleeping...\\n\");\n    usleep(100); // Simulate work or context switch\n    printf(\"Thread A: Attempting to lock mutex2...\\n\");\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread A: Locked mutex2. Modifying resources...\\n\");\n\n    shared_resource1 += 10;\n    shared_resource2 += 20;\n\n    printf(\"Thread A: Unlocking mutex2...\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread A: Unlocking mutex1...\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread A: Finished.\\n\");\n    return NULL;\n}\n\nvoid* thread_func_B(void* arg) {\n    printf(\"Thread B: Attempting to lock mutex2...\\n\");\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread B: Locked mutex2. Sleeping...\\n\");\n    usleep(100); // Simulate work or context switch\n    printf(\"Thread B: Attempting to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread B: Locked mutex1. Modifying resources...\\n\");\n\n    shared_resource1 += 5;\n    shared_resource2 += 15;\n\n    printf(\"Thread B: Unlocking mutex1...\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread B: Unlocking mutex2...\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread B: Finished.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid[2];\n\n    printf(\"Main: Creating thread A...\\n\");\n    pthread_create(&tid[0], NULL, thread_func_A, NULL);\n    printf(\"Main: Creating thread B...\\n\");\n    pthread_create(&tid[1], NULL, thread_func_B, NULL);\n\n    pthread_join(tid[0], NULL);\n    pthread_join(tid[1], NULL);\n\n    printf(\"Main: Final values: shared_resource1 = %d, shared_resource2 = %d\\n\", shared_resource1, shared_resource2);\n\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכנית לא תרוץ עד לסיומה בהצלחה. סביר מאוד שתתרחש תקלת \"קיפאון\" (Deadlock).\n\n**הסבר לתקלה:**\nקיפאון מתרחש כאשר שני תהליכונים (או יותר) מחזיקים במשאבים שונים וכל אחד מהם ממתין למשאב המוחזק על ידי האחר, כך שאף אחד מהם לא יכול להמשיך. במקרה זה:\n1.  **תהליכון A** מנסה לנעול את `mutex1` ואז את `mutex2`.\n2.  **תהליכון B** מנסה לנעול את `mutex2` ואז את `mutex1`.\n\nבעקבות קריאות ה-`usleep` שמדמות עבודת עיבוד או החלפת קונטקסט, ייתכן תרחיש כזה:\n*   תהליכון A מצליח לנעול את `mutex1`.\n*   מערכת ההפעלה מבצעת החלפת קונטקסט לתהליכון B.\n*   תהליכון B מצליח לנעול את `mutex2`.\n*   כעת, תהליכון A, שמחזיק ב-`mutex1`, מנסה לנעול את `mutex2` אך הוא כבר נעול על ידי תהליכון B. תהליכון A נכנס למצב המתנה.\n*   באותו זמן, תהליכון B, שמחזיק ב-`mutex2`, מנסה לנעול את `mutex1` אך הוא כבר נעול על ידי תהליכון A. תהליכון B נכנס גם הוא למצב המתנה.\n\nשני התהליכונים ממתינים זה לזה לשחרר את המנעול שהם צריכים, וכך הם נכנסים למצב של קיפאון ולא יכולים להמשיך את ריצתם. התוכנית תיתקע ולא תגיע לשורות ההדפסה הסופיות ב-`main`.\n\n**שינוי מינימלי למניעת הקיפאון:**\nכדי למנוע קיפאון, יש לוודא שכל התהליכונים מנסים לנעול את המשאבים באותו סדר. אם כל התהליכונים מנסים לנעול את `mutex1` ואז את `mutex2` (או להפך), לא ייווצר מצב בו תהליכון אחד מחזיק ב-`mutex1` ומחכה ל-`mutex2` בעוד שהשני מחזיק ב-`mutex2` ומחכה ל-`mutex1`.\n\nנשנה את הפונקציה `thread_func_B` כך שתנעל את המנעולים באותו סדר כמו `thread_func_A`:\n\n```c\nvoid* thread_func_B(void* arg) {\n    printf(\"Thread B: Attempting to lock mutex1...\\n\"); // Changed order\n    pthread_mutex_lock(&mutex1); // Changed order\n    printf(\"Thread B: Locked mutex1. Sleeping...\\n\");\n    usleep(100); // Simulate work or context switch\n    printf(\"Thread B: Attempting to lock mutex2...\\n\"); // Changed order\n    pthread_mutex_lock(&mutex2); // Changed order\n    printf(\"Thread B: Locked mutex2. Modifying resources...\\n\");\n\n    shared_resource1 += 5;\n    shared_resource2 += 15;\n\n    printf(\"Thread B: Unlocking mutex2...\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread B: Unlocking mutex1...\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread B: Finished.\\n\");\n    return NULL;\n}\n```\n\n**הסבר כיצד השינוי מונע את התקלה:**\nלאחר השינוי, שני התהליכונים (A ו-B) מנסים לנעול את `mutex1` ואז את `mutex2`. אם תהליכון A נועל את `mutex1`, תהליכון B ימתין עד ש-`mutex1` ישוחרר. לאחר ש-`mutex1` ישוחרר, תהליכון אחר (או A או B) יצליח לנעול אותו, ולאחר מכן ינסה לנעול את `mutex2`. מכיוון ששני המנעולים נרכשים באותו סדר, לא ייווצר מצב מעגלי של המתנה הדדית. תהליכון אחד יסיים את הקטע הקריטי שלו וישחרר את המנעולים, מה שיאפשר לתהליכון השני להמשיך.\n\n**ערכים סופיים לאחר התיקון:**\nלאחר התיקון, התוכנית תרוץ בהצלחה. כל תהליכון יבצע את פעולותיו פעם אחת בתוך קטע קריטי המוגן על ידי שני המנעולים.\n*   `shared_resource1` יוגדל ב-10 (על ידי A) וב-5 (על ידי B). סה\"כ: `0 + 10 + 5 = 15`.\n*   `shared_resource2` יוגדל ב-20 (על ידי A) וב-15 (על ידי B). סה\"כ: `0 + 20 + 15 = 35`.\n\nהערכים הסופיים יהיו: `shared_resource1 = 15`, `shared_resource2 = 35`."}, "difficulty_estimation": "Medium", "_source_file": "0274__Mutexes__CodeAnalysis__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:26:16", "_subject": "Concurrency"}, {"id": 7, "type": "CodeAnalysis", "topic": ["Mutexes", "Concurrency", "Threads", "Race Conditions"], "content": {"text": "נתונה תוכנית C המשתמשת ב-pthreads ובמנעול (mutex) כדי להגן על מונה גלובלי משותף. ענו על השאלות הבאות בהתבסס על הקוד:", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <stdlib.h> // For malloc, free, exit\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 100000\n\nlong long global_counter = 0;\npthread_mutex_t counter_mutex;\n\nvoid* thread_function(void* arg) {\n    int thread_id = *(int*)arg;\n    free(arg); // Free memory allocated for thread_id\n\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&counter_mutex);\n        global_counter++;\n        pthread_mutex_unlock(&counter_mutex);\n    }\n    printf(\"Thread %d finished its increments.\\n\", thread_id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    int *thread_ids[NUM_THREADS]; // To pass unique IDs to threads\n\n    pthread_mutex_init(&counter_mutex, NULL);\n\n    printf(\"Main thread: Starting %d threads...\\n\", NUM_THREADS);\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        thread_ids[i] = malloc(sizeof(int));\n        if (thread_ids[i] == NULL) {\n            perror(\"Failed to allocate memory for thread ID\");\n            exit(EXIT_FAILURE);\n        }\n        *thread_ids[i] = i + 1;\n        if (pthread_create(&threads[i], NULL, thread_function, (void*)thread_ids[i]) != 0) {\n            perror(\"pthread_create failed\");\n            // Clean up allocated memory before exiting\n            for (int j = 0; j <= i; ++j) {\n                if (thread_ids[j] != NULL) free(thread_ids[j]);\n            }\n            pthread_mutex_destroy(&counter_mutex);\n            return 1;\n        }\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Main thread: All threads finished.\\n\");\n    printf(\"Main thread: Final global_counter value: %lld\\n\", global_counter);\n\n    pthread_mutex_destroy(&counter_mutex);\n\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "מהו הערך הסופי המובטח של המונה הגלובלי `global_counter` לאחר סיום ריצת כל התהליכונים? נמקו.", "code_snippet": null, "options": null}, {"id": "7.2", "text": "האם סדר הפלט של ההודעות 'Thread X finished its increments.' הוא דטרמיניסטי או לא דטרמיניסטי? נמקו.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. הערך הסופי המובטח של המונה הגלובלי `global_counter` הוא 500000.\n   נימוק: המנעול `counter_mutex` מגן כראוי על הגישה למשתנה המשותף `global_counter`. כל תהליכון מבצע 100,000 הגדלות (INCREMENTS_PER_THREAD), וישנם 5 תהליכונים (NUM_THREADS). מכיוון שכל הגדלה מבוצעת בתוך קטע קריטי המוגן על ידי המנעול, כל הפעולות אטומיות ומונעות מצבי מרוץ. לכן, המונה יגיע לערך הסופי המדויק של 5 * 100,000 = 500,000.\n\n2. סדר הפלט של ההודעות 'Thread X finished its increments.' הוא לא דטרמיניסטי.\n   נימוק: למרות שהמונה הגלובלי מוגן על ידי מנעול, פעולת ההדפסה (`printf`) עצמה מתבצעת *מחוץ* לקטע הקריטי המוגן על ידי `counter_mutex`. תהליכונים שונים רצים במקביל, ומתזמן מערכת ההפעלה קובע את סדר הביצוע שלהם. לכן, אין ערובה לסדר שבו כל תהליכון יסיים את לולאת ההגדלות וידפיס את ההודעה שלו. סדר ההדפסה יכול להשתנות בין הרצות שונות של התוכנית."}, "difficulty_estimation": "Medium", "_source_file": "0275__Mutexes__CodeAnalysis__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:26:41", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Concurrency", "Threads", "Mutexes", "Race Conditions"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בחוטים (threads) ובמנגנון mutex. התוכנית מבצעת שתי סדרות של פעולות הגדלה של מונה משותף: אחת ללא הגנת mutex ואחת עם הגנת mutex.\n\nמה יהיה הפלט הצפוי של התוכנית? הסבירו בפירוט את ההבדל בפלט בין שני המקרים (עם ובלי mutex), וכיצד מנגנון ה-mutex פותר את הבעיה הקיימת במקרה הראשון.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n\n#define NUM_THREADS 5\n#define ITERATIONS_PER_THREAD 100000\n\nint shared_counter = 0;\npthread_mutex_t counter_mutex;\n\nvoid* increment_with_mutex(void* arg) {\n    for (int i = 0; i < ITERATIONS_PER_THREAD; i++) {\n        pthread_mutex_lock(&counter_mutex);\n        shared_counter++;\n        pthread_mutex_unlock(&counter_mutex);\n    }\n    return NULL;\n}\n\nvoid* increment_without_mutex(void* arg) {\n    for (int i = 0; i < ITERATIONS_PER_THREAD; i++) {\n        shared_counter++; // Race condition here\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    int i;\n\n    // Initialize mutex\n    pthread_mutex_init(&counter_mutex, NULL);\n\n    printf(\"Starting threads WITHOUT mutex protection...\\n\");\n    shared_counter = 0; // Reset for the first run\n    for (i = 0; i < NUM_THREADS; i++) {\n        pthread_create(&threads[i], NULL, increment_without_mutex, NULL);\n    }\n    for (i = 0; i < NUM_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    printf(\"Final counter value WITHOUT mutex: %d\\n\", shared_counter);\n\n    printf(\"\\nStarting threads WITH mutex protection...\\n\");\n    shared_counter = 0; // Reset for the second run\n    for (i = 0; i < NUM_THREADS; i++) {\n        pthread_create(&threads[i], NULL, increment_with_mutex, NULL);\n    }\n    for (i = 0; i < NUM_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    printf(\"Final counter value WITH mutex: %d\\n\", shared_counter);\n\n    // Destroy mutex\n    pthread_mutex_destroy(&counter_mutex);\n\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פלט צפוי:\nStarting threads WITHOUT mutex protection...\nFinal counter value WITHOUT mutex: [ערך כלשהו, לרוב נמוך מ-500000]\n\nStarting threads WITH mutex protection...\nFinal counter value WITH mutex: 500000\n\nהסבר:\n\n1.  **מקרה ללא הגנת mutex (increment_without_mutex):**\n    במקרה זה, מספר חוטים (NUM_THREADS = 5) מנסים להגדיל מונה משותף (`shared_counter`) בו-זמנית, כאשר כל חוט מבצע ITERATIONS_PER_THREAD = 100,000 איטרציות. סך האיטרציות הצפוי הוא 5 * 100,000 = 500,000.\n    עם זאת, הפעולה `shared_counter++` אינה אטומית. היא מורכבת למעשה משלוש פעולות ברמה נמוכה יותר:\n    א. קריאת הערך הנוכחי של `shared_counter` מהזיכרון.\n    ב. הגדלת הערך ביחידה.\n    ג. כתיבת הערך החדש חזרה לזיכרון.\n    כאשר מספר חוטים מבצעים פעולות אלו במקביל, עלול להיווצר תנאי מרוץ (Race Condition). לדוגמה, שני חוטים עשויים לקרוא את אותו ערך של `shared_counter`, שניהם יגדילו אותו, ושניהם יכתבו את הערך המוגדל חזרה, וכתוצאה מכך הגדלה אחת תאבד. לכן, הערך הסופי של `shared_counter` במקרה זה יהיה כמעט תמיד נמוך מ-500,000, והוא ישתנה בין הרצות שונות של התוכנית.\n\n2.  **מקרה עם הגנת mutex (increment_with_mutex):**\n    במקרה זה, אנו משתמשים במנגנון `pthread_mutex_t` (mutex) כדי להגן על הקטע הקריטי (Critical Section), שהוא הפעולה `shared_counter++`.\n    *   לפני שחוט ניגש להגדיל את `shared_counter`, הוא קורא ל-`pthread_mutex_lock(&counter_mutex)`. קריאה זו מבטיחה שרק חוט אחד יכול להיכנס לקטע הקריטי בכל רגע נתון. אם חוט אחר כבר מחזיק את ה-mutex, החוט הנוכחי ייחסם (ימתין) עד שה-mutex ישוחרר.\n    *   לאחר שהחוט סיים את הפעולה בקטע הקריטי (הגדלת המונה), הוא קורא ל-`pthread_mutex_unlock(&counter_mutex)` כדי לשחרר את ה-mutex, ובכך לאפשר לחוט אחר שחוסם להיכנס.\n    מנגנון זה מבטיח שהפעולה `shared_counter++` תבוצע באופן אטומי מבחינת הגישה למונה המשותף. כל הגדלה מבוצעת במלואה על ידי חוט אחד לפני שחוט אחר יכול לגשת למונה. לכן, הערך הסופי של `shared_counter` במקרה זה יהיה תמיד 500,000 (5 חוטים * 100,000 איטרציות לחוט). ה-mutex פותר ביעילות את תנאי המרוץ על ידי אכיפת הדרה הדדית (Mutual Exclusion)."}, "difficulty_estimation": "Medium", "_source_file": "0276__Mutexes__CodeAnalysis__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:27:01", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Mutexes", "Threads", "Concurrency", "Shared Memory"], "content": {"text": "נתונה התוכנית הבאה המשתמשת ב-pthread וב-mutex:\nמטרת התוכנית היא להגדיל מונה גלובלי (shared_counter) על ידי מספר תהליכונים (threads) ולהדפיס את מצבו. ענו על השאלות הבאות בהתבסס על הקוד הנתון:", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For usleep\n\n#define NUM_THREADS 5\n#define NUM_INCREMENTS_PER_THREAD 2\n\nint shared_counter = 0;\npthread_mutex_t counter_mutex;\n\nvoid *thread_func(void *arg) {\n    int i;\n    int thread_id = *(int*)arg;\n    int local_val_at_increment;\n\n    for (i = 0; i < NUM_INCREMENTS_PER_THREAD; i++) {\n        pthread_mutex_lock(&counter_mutex);\n        // Critical section\n        shared_counter++;\n        local_val_at_increment = shared_counter; // Capture value inside critical section\n        pthread_mutex_unlock(&counter_mutex);\n\n        // This print is outside the critical section\n        printf(\"Thread %d: Counter incremented to %d (shared: %d)\\n\",\n               thread_id, local_val_at_increment, shared_counter);\n        usleep(1000); // Simulate some work/delay\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    int thread_ids[NUM_THREADS];\n\n    pthread_mutex_init(&counter_mutex, NULL);\n\n    for (int i = 0; i < NUM_THREADS; i++) {\n        thread_ids[i] = i + 1;\n        pthread_create(&threads[i], NULL, thread_func, &thread_ids[i]);\n    }\n\n    for (int i = 0; i < NUM_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final shared_counter value: %d\\n\", shared_counter);\n\n    pthread_mutex_destroy(&counter_mutex);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "מה יהיה הערך הסופי של המשתנה `shared_counter` בסיום ריצת התוכנית? נמק.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "תארו פלט אפשרי אחד של התוכנית. הסבירו מדוע הערך המודפס תחת \"shared: %d\" בשורה `printf(\"Thread %d: Counter incremented to %d (shared: %d)\\n\", ...)` עשוי להיות שונה מהערך המודפס תחת \"Counter incremented to %d\" באותה שורה.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "האם ייתכנו תנאי מרוץ (race conditions) בתוכנית זו? אם כן, ציינו היכן ומדוע. אם לא, הסבירו מדוע.", "code_snippet": null, "options": null}, {"id": "1.4", "text": "מה יקרה אם נזיז את שורת ה-`printf` (שורה 20 בקוד המקורי) אל תוך ה-critical section, מיד לאחר שורת `local_val_at_increment = shared_counter;` (שורה 17 בקוד המקורי)? תארו פלט אפשרי במקרה זה והסבירו את ההבדל מהמקרה המקורי.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  הערך הסופי של `shared_counter` יהיה 10.\n    ישנם NUM_THREADS (5) תהליכונים, וכל תהליכון מבצע NUM_INCREMENTS_PER_THREAD (2) הגדלות. כל הגדלה של `shared_counter` מוגנת על ידי mutex (`counter_mutex`), מה שמבטיח שכל הגדלה מתבצעת באופן אטומי וללא תנאי מרוץ. לכן, כל 5*2=10 ההגדלות יבוצעו בהצלחה, והמונה יגיע לערך 10.\n\n2.  פלט אפשרי אחד יכול להיות: (הסדר של שורות ה-printf יכול להשתנות)\n    ```\n    Thread 1: Counter incremented to 1 (shared: 1)\n    Thread 2: Counter incremented to 2 (shared: 2)\n    Thread 3: Counter incremented to 3 (shared: 3)\n    Thread 4: Counter incremented to 4 (shared: 4)\n    Thread 5: Counter incremented to 5 (shared: 5)\n    Thread 1: Counter incremented to 6 (shared: 6)\n    Thread 2: Counter incremented to 7 (shared: 7)\n    Thread 3: Counter incremented to 8 (shared: 8)\n    Thread 4: Counter incremented to 9 (shared: 9)\n    Thread 5: Counter incremented to 10 (shared: 10)\n    Final shared_counter value: 10\n    ```\n    \n    עם זאת, ייתכן גם פלט שבו הערך של `shared_counter` המודפס תחת \"shared: %d\" יהיה גבוה יותר מהערך של `local_val_at_increment`. לדוגמה:\n    ```\n    Thread 1: Counter incremented to 1 (shared: 3)\n    Thread 2: Counter incremented to 2 (shared: 3)\n    Thread 3: Counter incremented to 3 (shared: 3)\n    Thread 4: Counter incremented to 4 (shared: 4)\n    Thread 5: Counter incremented to 5 (shared: 5)\n    Thread 1: Counter incremented to 6 (shared: 7)\n    Thread 2: Counter incremented to 7 (shared: 7)\n    Thread 3: Counter incremented to 8 (shared: 8)\n    Thread 4: Counter incremented to 9 (shared: 9)\n    Thread 5: Counter incremented to 10 (shared: 10)\n    Final shared_counter value: 10\n    ```\n    ההבדל נובע מכך ש-`local_val_at_increment` הוא משתנה מקומי לכל קריאה של הלולאה בתהליכון, והוא מקבל את ערכו של `shared_counter` *בזמן* ההגדלה, כאשר ה-mutex נעול. לעומת זאת, `shared_counter` (המודפס כ-\"shared: %d\") הוא משתנה גלובלי, והגישה אליו בשורת ה-`printf` מתבצעת *לאחר* שה-mutex שוחרר. בשלב זה, תהליכונים אחרים יכלו כבר לנעול את ה-mutex, להגדיל את `shared_counter`, ולשחרר אותו שוב, כך שהערך הגלובלי יכול להיות גבוה יותר מזה שנקלט במשתנה המקומי של התהליכון הנוכחי.\n\n3.  לא, לא ייתכנו תנאי מרוץ על המשתנה `shared_counter` בכל הנוגע לפעולת ההגדלה (`shared_counter++`). פעולה זו מוגנת באופן מלא על ידי ה-`counter_mutex`. כל תהליכון חייב לנעול את ה-mutex לפני שהוא ניגש ל-`shared_counter` כדי להגדיל אותו, ומשחרר אותו רק לאחר מכן. זה מבטיח אקסקלוסיביות הדדית (mutual exclusion) עבור הגישה למונה. עם זאת, יש לזכור שפעולת ה-`printf` עצמה אינה מוגנת על ידי ה-mutex, מה שאומר ששורות הפלט מתהליכונים שונים יכולות להתערבב באופן לא צפוי. זו אינה 'תנאי מרוץ' במובן של שינוי לא נכון של נתונים משותפים, אלא 'מרוץ' על משאב הפלט (stdout).\n\n4.  אם נזיז את שורת ה-`printf` אל תוך ה-critical section, מיד לאחר שורת `local_val_at_increment = shared_counter;`, הפלט ישתנה באופן הבא:\n    *   הפלט יהיה תמיד עקבי: הערך המודפס תחת \"Counter incremented to %d\" והערך תחת \"shared: %d\" יהיו תמיד זהים, ויישקפו את הערך של `shared_counter` מיד לאחר הגדלתו על ידי אותו תהליכון.\n    *   שורות הפלט של התהליכונים השונים לא יתערבבו ביניהן. כל שורת `printf` תבוצע במלואה כאשר ה-mutex נעול, מה שיבטיח שאף תהליכון אחר לא יפריע להדפסה או ישנה את `shared_counter` באמצע ההדפסה של תהליכון אחר. הפלט יהיה סדרה של הגדלות, כאשר כל הגדלה וההדפסה שלה מהוות יחידה אטומית.\n    *   הסדר הכרונולוגי של ההגדלות וההדפסה ישקף את סדר רכישת ה-mutex על ידי התהליכונים. לדוגמה:\n        ```\n        Thread 1: Counter incremented to 1 (shared: 1)\n        Thread 2: Counter incremented to 2 (shared: 2)\n        Thread 1: Counter incremented to 3 (shared: 3)\n        Thread 3: Counter incremented to 4 (shared: 4)\n        ...\n        ```\n    ההבדל המרכזי הוא שההדפסה הופכת לחלק מהפעולה האטומית, ובכך מבטיחה עקביות בין הערך המקומי שנקלט לערך הגלובלי בזמן ההדפסה, ומונעת ערבוב של פלט תהליכונים שונים."}, "difficulty_estimation": "Medium", "_source_file": "0277__Mutexes__CodeAnalysis__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:27:32", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Mutexes", "Threads", "Concurrency", "Race Conditions"], "content": {"text": "נתונה התוכנית הבאה, המשתמשת בחוטים (threads) ובמוטקס (mutex) כדי לעדכן משתנה גלובלי משותף. נתון שכל קריאות המערכת מצליחות.\n\nמה יהיה הפלט הסופי של התוכנית? הסבירו מדוע, ומה היה קורה אם המוטקס לא היה בשימוש.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\n#define NUM_THREADS 2\n#define INCREMENTS_PER_THREAD 100000\n\nint counter = 0;\npthread_mutex_t mutex;\n\nvoid* thread_func(void* arg) {\n    int i;\n    for (i = 0; i < INCREMENTS_PER_THREAD; i++) {\n        pthread_mutex_lock(&mutex);\n        counter++;\n        pthread_mutex_unlock(&mutex);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    int i;\n\n    pthread_mutex_init(&mutex, NULL);\n\n    for (i = 0; i < NUM_THREADS; i++) {\n        pthread_create(&threads[i], NULL, thread_func, NULL);\n    }\n\n    for (i = 0; i < NUM_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n\n    pthread_mutex_destroy(&mutex);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפלט הסופי של התוכנית יהיה:\nFinal counter value: 200000\n\n**הסבר:**\n1.  התוכנית מאתחלת משתנה גלובלי `counter` ל-0 ומוטקס `mutex`.\n2.  היא יוצרת שני חוטים (threads), כשכל חוט מבצע את הפונקציה `thread_func`.\n3.  בתוך `thread_func`, כל חוט מבצע לולאה `INCREMENTS_PER_THREAD` (שהוגדר כ-100,000) פעמים.\n4.  בכל איטרציה, החוט קורא ל-`pthread_mutex_lock(&mutex)` כדי לנעול את המוטקס. פעולה זו מבטיחה שרק חוט אחד יכול להיכנס לקטע הקריטי (critical section) שבו `counter` מוגדל.\n5.  לאחר הגדלת `counter` ב-1, החוט קורא ל-`pthread_mutex_unlock(&mutex)` כדי לשחרר את המוטקס, ובכך מאפשר לחוטים אחרים (אם ישנם) לנסות ולרכוש את המוטקס.\n6.  מכיוון שכל אחד משני החוטים מבצע 100,000 הגדלות, ופעולות אלו מוגנות על ידי המוטקס, סך ההגדלות יהיה `2 * 100,000 = 200,000`. המוטקס מונע תנאי מרוץ (race condition) ומבטיח שכל פעולת הגדלה תתבצע באופן אטומי ולא יאבדו עדכונים.\n7.  הקריאות ל-`pthread_join` מבטיחות שהחוט הראשי ימתין לסיום שני חוטי העבודה לפני שישמיד את המוטקס וידפיס את הערך הסופי של `counter`.\n\n**מה היה קורה אם המוטקס לא היה בשימוש:**\nאם קריאות ה-`pthread_mutex_lock` וה-`pthread_mutex_unlock` היו מוסרות מהקוד, היה נוצר תנאי מרוץ (race condition).\nפעולת `counter++` אינה אטומית, והיא מורכבת משלושה שלבים עיקריים ברמת המעבד:\n1.  קריאת הערך הנוכחי של `counter` לתוך אוגר.\n2.  הגדלת הערך באוגר.\n3.  כתיבת הערך החדש מהאוגר חזרה לזיכרון (למשתנה `counter`).\n\nללא מוטקס, חוטים מרובים יכלו לשלב את השלבים הללו באופן לא צפוי. לדוגמה:\n*   חוט א' קורא את `counter` (נניח 5).\n*   חוט ב' קורא את `counter` (גם הוא קורא 5).\n*   חוט א' מגדיל את הערך באוגר שלו ל-6 וכותב 6 חזרה ל-`counter`.\n*   חוט ב' מגדיל את הערך באוגר שלו ל-6 וכותב 6 חזרה ל-`counter`.\n\nבמקרה זה, שתי פעולות הגדלה שהיו אמורות להגדיל את `counter` ב-2, בפועל הגדילו אותו ב-1 בלבד, ובכך אבד עדכון אחד. כתוצאה מכך, הערך הסופי של `counter` היה נמוך מ-200,000 ולא דטרמיניסטי (היה משתנה בין הרצות שונות של התוכנית)."}, "difficulty_estimation": "Medium", "_source_file": "0278__Mutexes__CodeAnalysis__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:27:49", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Mutexes", "Concurrency", "Deadlock", "Threads"], "content": {"text": "נתונה התוכנית הבאה המשתמשת ב-pthreads וב-mutexes כדי לגשת למשאבים משותפים. נתח את התוכנית והסבר: א) מהו הפלט הסופי האפשרי של הערכים resource1 ו-resource2? ב) האם קיימת בעיית תחרות (race condition) או קיפאון (deadlock) בתוכנית? אם כן, הסבר מדוע וכיצד היא עלולה להתרחש.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex1;\npthread_mutex_t mutex2;\n\nint resource1 = 0;\nint resource2 = 0;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 1: Locked mutex1. Trying to lock mutex2...\\n\");\n    sleep(1); // Introduce delay to increase likelihood of deadlock\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 1: Locked mutex2. Updating resources...\\n\");\n    resource1++;\n    resource2++;\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 1: Unlocked mutex2.\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 1: Unlocked mutex1. Exiting.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to lock mutex2...\\n\");\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2: Locked mutex2. Trying to lock mutex1...\\n\");\n    sleep(1); // Introduce delay\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2: Locked mutex1. Updating resources...\\n\");\n    resource1--;\n    resource2--;\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 2: Unlocked mutex1.\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2: Unlocked mutex2. Exiting.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n\n    pthread_mutex_init(&mutex1, NULL);\n    pthread_mutex_init(&mutex2, NULL);\n\n    pthread_create(&t1, NULL, thread_func1, NULL);\n    pthread_create(&t2, NULL, thread_func2, NULL);\n\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n\n    printf(\"Final resource1 value: %d\\n\", resource1);\n    printf(\"Final resource2 value: %d\\n\", resource2);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א) הערכים הסופיים של resource1 ו-resource2 יהיו תלויים בשאלה האם התוכנית מסיימת את ריצתה בהצלחה או נכנסת למצב קיפאון (deadlock). במקרה של קיפאון, התהליכונים לא יסיימו את עדכון המשאבים, והערכים עשויים להישאר 0,0 (או הערכים שהיו להם טרם הקיפאון). אם, מסיבה כלשהי, הקיפאון נמנע (למשל, בגלל תזמון ספציפי מאוד של מערכת ההפעלה שגורם לתהליכון אחד לסיים את כל פעולותיו לפני שהשני מתחיל את ניסיונו לנעול), אז resource1 ו-resource2 יסיימו שניהם עם הערך 0. זאת מכיוון שתהליכון אחד מגדיל את שניהם ב-1, והתהליכון השני מקטין את שניהם ב-1, וכך הם מבטלים זה את זה.\n\nב) כן, קיימת בעיית קיפאון (deadlock) קלאסית בתוכנית. הקיפאון עלול להתרחש באופן הבא:\n1. תהליכון 1 (thread_func1) מבצע `pthread_mutex_lock(&mutex1)` ומצליח לנעול את mutex1.\n2. באותו זמן, תהליכון 2 (thread_func2) מבצע `pthread_mutex_lock(&mutex2)` ומצליח לנעול את mutex2.\n3. כעת, תהליכון 1 מנסה לבצע `pthread_mutex_lock(&mutex2)`. הוא ימתין ללא הגבלת זמן מכיוון ש-mutex2 נעול על ידי תהליכון 2.\n4. במקביל, תהליכון 2 מנסה לבצע `pthread_mutex_lock(&mutex1)`. הוא ימתין ללא הגבלת זמן מכיוון ש-mutex1 נעול על ידי תהליכון 1.\nשני התהליכונים ממתינים זה לזה לשחרור המשאב שהם זקוקים לו, וכל אחד מהם מחזיק במשאב שהשני זקוק לו. מצב זה מוביל לקיפאון, והתוכנית תיתקע ולא תסיים את ריצתה. אין כאן בעיית תחרות (race condition) על עדכון המשאבים resource1 ו-resource2 מכיוון ששניהם מוגנים על ידי שני ה-mutexes יחד, כלומר, כל עדכון מתרחש בתוך קטע קריטי המוגן היטב. הבעיה היא שהקטע הקריטי הזה עצמו עלול לא להיות נגיש לעולם עקב הקיפאון."}, "difficulty_estimation": "Medium", "_source_file": "0279__Mutexes__CodeAnalysis__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:28:15", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Mutexes", "Concurrency", "Race Conditions", "Threads"], "content": {"text": "נתונה התוכנית הבאה, המשתמשת ב-pthreads וב-mutex כדי להגדיל מונה משותף על ידי מספר תהליכונים. נתחו את התוכנית וענו על השאלה.\n\nמהו הערך הסופי האפשרי של המשתנה הגלובלי `counter` לאחר שכל התהליכונים סיימו את ריצתם? נמקו את תשובתכם והסבירו מדוע התוכנית עלולה להפיק תוצאה שונה מהצפוי.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\n#define NUM_THREADS 5\n#define ITERATIONS_PER_THREAD 100000\n\nint counter = 0;\npthread_mutex_t mutex;\n\nvoid* thread_func(void* arg) {\n    for (int i = 0; i < ITERATIONS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&mutex);\n        // CRITICAL SECTION START\n        int temp = counter;\n        pthread_mutex_unlock(&mutex); // ERROR: Unlocking too early!\n        temp++;\n        counter = temp; // This write is NOT protected\n        // CRITICAL SECTION END (should extend to here)\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    pthread_mutex_init(&mutex, NULL);\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    pthread_mutex_destroy(&mutex);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הערך הסופי הצפוי של המונה, לו ה-mutex היה בשימוש נכון, הוא 500,000 (5 תהליכונים * 100,000 איטרציות כל אחד). עם זאת, עקב מיקום שגוי של קריאת ה-`pthread_mutex_unlock()`, מתקיים תנאי מרוץ (race condition).\n\nהקטע הקריטי, הכולל קריאת ערך ה-`counter` לתוך משתנה מקומי (`temp`), הגדלתו, וכתיבתו בחזרה ל-`counter` הגלובלי, אינו מוגן במלואו. ספציפית, השורה `counter = temp;` מתבצעת *לאחר* שה-mutex כבר שוחרר. משמעות הדבר היא שמספר תהליכונים יכולים לקרוא את אותו ערך של `counter` לתוך המשתנה המקומי שלהם `temp`, להגדיל אותו, ולאחר מכן לכתוב אותו בחזרה ל-`counter` הגלובלי, ובכך לדרוס את העדכונים של תהליכונים אחרים.\n\nלדוגמה, אם `counter` הוא 0:\n1. תהליכון A נועל את ה-mutex, קורא `temp = 0`, ומשחרר את ה-mutex.\n2. תהליכון B נועל את ה-mutex, קורא `temp = 0` (כי תהליכון A עדיין לא כתב בחזרה ל-`counter`), ומשחרר את ה-mutex.\n3. תהליכון A מגדיל את `temp` ל-1, וכותב `counter = 1`.\n4. תהליכון B מגדיל את `temp` ל-1, וכותב `counter = 1`.\n\nבסוף תהליך זה, שתי פעולות הגדלה הביאו לכך שהמונה בערך 1 במקום 2.\n\nלכן, הערך הסופי של `counter` יהיה **קטן מ-500,000**, והוא אינו דטרמיניסטי ותלוי בתיאום התהליכונים על ידי מערכת ההפעלה.\n\nכדי לתקן את הבעיה, יש להזיז את שחרור ה-mutex לסוף הקטע הקריטי, כך שכל פעולת הקריאה-שינוי-כתיבה תהיה מוגנת:\n```c\nvoid* thread_func(void* arg) {\n    for (int i = 0; i < ITERATIONS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&mutex);\n        // CRITICAL SECTION START\n        counter++; // Atomic increment (read-modify-write protected)\n        // CRITICAL SECTION END\n        pthread_mutex_unlock(&mutex);\n    }\n    return NULL;\n}\n```"}, "difficulty_estimation": "Medium", "_source_file": "0280__Mutexes__CodeAnalysis__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:28:34", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Mutexes", "Synchronization", "Concurrency", "Deadlock"], "content": {"text": "נתונה מערכת מטמון פשוטה בגודל קבוע CACHE_SIZE, המאפשרת אחסון ועדכון של פריטים לפי מפתח-ערך. המערכת משתמשת בשני סוגי מנעולים: מנעול גלובלי cache_mutex להגנה על מבנה המטמון הכללי וחיפוש תאים פנויים/קיימים, ומנעול item_mutex לכל פריט במטמון להגנה על הנתונים הפנימיים שלו (מפתח וערך).\nלהלן מימוש חלקי של המערכת:", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep, if needed for demonstration\n\n#define CACHE_SIZE 5\n\ntypedef struct CacheEntry {\n    int key;\n    int value;\n    pthread_mutex_t item_mutex; // Protects 'value' and 'key' of this specific entry\n    int in_use; // 0 if empty, 1 if in use\n} CacheEntry;\n\nCacheEntry cache[CACHE_SIZE];\npthread_mutex_t cache_mutex = PTHREAD_MUTEX_INITIALIZER; // Protects global cache structure (e.g., 'in_use' flags, finding empty slots)\n\nvoid cache_init() {\n    for (int i = 0; i < CACHE_SIZE; ++i) {\n        cache[i].key = -1;\n        cache[i].value = -1;\n        pthread_mutex_init(&cache[i].item_mutex, NULL);\n        cache[i].in_use = 0;\n    }\n}\n\n// Function to add or update an item in the cache\nvoid cache_put(int key, int value) {\n    pthread_mutex_lock(&cache_mutex); // Lock global cache structure\n\n    int found_idx = -1;\n    for (int i = 0; i < CACHE_SIZE; ++i) {\n        if (cache[i].in_use && cache[i].key == key) {\n            found_idx = i;\n            break;\n        }\n    }\n\n    if (found_idx != -1) {\n        // Item exists, update its value.\n        pthread_mutex_lock(&cache[found_idx].item_mutex); // Lock item\n        cache[found_idx].value = value;\n        pthread_mutex_unlock(&cache[found_idx].item_mutex); // Unlock item\n        pthread_mutex_unlock(&cache_mutex); // Unlock global cache\n        return;\n    }\n\n    // Item does not exist, find an empty slot\n    int empty_idx = -1;\n    for (int i = 0; i < CACHE_SIZE; ++i) {\n        if (!cache[i].in_use) {\n            empty_idx = i;\n            break;\n        }\n    }\n\n    if (empty_idx != -1) {\n        // Found an empty slot\n        pthread_mutex_lock(&cache[empty_idx].item_mutex); // Lock new item slot\n        cache[empty_idx].key = key;\n        cache[empty_idx].value = value;\n        cache[empty_idx].in_use = 1;\n        pthread_mutex_unlock(&cache[empty_idx].item_mutex); // Unlock new item slot\n        pthread_mutex_unlock(&cache_mutex); // Unlock global cache\n        return;\n    }\n\n    // Cache is full. For simplicity, we don't handle eviction here.\n    // In a real scenario, an eviction policy would be applied.\n    pthread_mutex_unlock(&cache_mutex); // Unlock global cache\n    printf(\"Cache is full, cannot add key %d\\n\", key);\n}\n\n// Function to clear all items in the cache\nvoid cache_clear_and_reset() {\n    printf(\"Clearing cache...\\n\");\n    for (int i = 0; i < CACHE_SIZE; ++i) {\n        pthread_mutex_lock(&cache[i].item_mutex); // Acquire item mutex\n        // Simulate some cleanup work for the item\n        usleep(10000); // Simulate work that takes time\n        pthread_mutex_lock(&cache_mutex); // Acquire global cache mutex (PROBLEM HERE)\n        \n        cache[i].key = -1;\n        cache[i].value = -1;\n        cache[i].in_use = 0;\n        \n        pthread_mutex_unlock(&cache_mutex); // Release global cache mutex\n        pthread_mutex_unlock(&cache[i].item_mutex); // Release item mutex\n    }\n    printf(\"Cache cleared.\\n\");\n}"}, "sub_questions": [{"id": "10.1", "text": "הקוד הנ\"ל מכיל בעיה קריטית של סנכרון. תארו איזו בעיה קיימת בקוד וכיצד היא יכולה להתרחש (ציינו ריצה לדוגמה עם מספר חוטים).", "code_snippet": null, "options": null}, {"id": "10.2", "text": "תקנו את הקוד כך שיעבוד באופן תקין. יש להציג את הפונקציה המתוקנת בלבד (cache_clear_and_reset).", "code_snippet": "void cache_clear_and_reset() {\n\n}", "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: הבעיה בקוד היא קיפאון (Deadlock). הקיפאון יכול להתרחש כאשר חוט אחד מנסה לעדכן פריט קיים במטמון באמצעות cache_put, וחוט אחר מנסה לנקות ולאפס את המטמון באמצעות cache_clear_and_reset.\nפונקציית cache_put רוכשת את המנעולים בסדר: cache_mutex ואז item_mutex (עבור הפריט הספציפי). פונקציית cache_clear_and_reset, לעומת זאת, מנסה לרכוש את המנעולים בסדר הפוך: item_mutex (עבור כל פריט בתורו) ואז cache_mutex. סדר רכישת מנעולים שונה זה, במקביל לגישה למשאבים משותפים, יכול להוביל לקיפאון.\n\nריצה לדוגמה:\nנניח ש-key=1 נמצא ב-cache[0].\n\nחוט 1 (מבצע cache_put(1, 100)):\n1. רוכש את cache_mutex (pthread_mutex_lock(&cache_mutex);)\n2. מוצא את key=1 ב-cache[0].\n3. מנסה לרכוש את cache[0].item_mutex (pthread_mutex_lock(&cache[0].item_mutex);)\n   (בשלב זה, חוט 1 מחזיק ב-cache_mutex וממתין ל-cache[0].item_mutex).\n\nחוט 2 (מבצע cache_clear_and_reset()):\n1. נכנס ללולאה עבור i=0.\n2. רוכש את cache[0].item_mutex (pthread_mutex_lock(&cache[0].item_mutex);)\n   (בשלב זה, חוט 2 מחזיק ב-cache[0].item_mutex וממשיך).\n3. מבצע usleep(10000);\n4. מנסה לרכוש את cache_mutex (pthread_mutex_lock(&cache_mutex);)\n   (בשלב זה, חוט 2 מחזיק ב-cache[0].item_mutex וממתין ל-cache_mutex).\n\nתוצאה: חוט 1 מחזיק ב-cache_mutex וממתין ל-cache[0].item_mutex, בעוד שחוט 2 מחזיק ב-cache[0].item_mutex וממתין ל-cache_mutex. שני החוטים חסומים זה לזה במעגל המתנה, מה שגורם לקיפאון.\n\n10.2: כדי לתקן את הקיפאון, יש להבטיח שכל החוטים רוכשים את המנעולים באותו סדר עקבי. מכיוון ש-cache_put רוכש את cache_mutex ואז item_mutex, יש לשנות את cache_clear_and_reset כך שתפעל באותו סדר. הדרך הנכונה היא לרכוש את cache_mutex פעם אחת בתחילת cache_clear_and_reset, ולשחרר אותו בסוף. בתוך הלולאה, יש לרכוש את item_mutex עבור כל פריט.\n\n```c\nvoid cache_clear_and_reset() {\n    printf(\"Clearing cache...\\n\");\n    pthread_mutex_lock(&cache_mutex); // Acquire global cache mutex ONCE at the beginning\n\n    for (int i = 0; i < CACHE_SIZE; ++i) {\n        pthread_mutex_lock(&cache[i].item_mutex); // Acquire item mutex\n        \n        // Cleanup work for the item\n        cache[i].key = -1;\n        cache[i].value = -1;\n        cache[i].in_use = 0;\n        \n        pthread_mutex_unlock(&cache[i].item_mutex); // Release item mutex\n    }\n    \n    pthread_mutex_unlock(&cache_mutex); // Release global cache mutex ONCE at the end\n    printf(\"Cache cleared.\\n\");\n}\n```\n\nהסבר לתיקון:\nעל ידי רכישת cache_mutex פעם אחת בתחילת הפונקציה cache_clear_and_reset ושחרורו בסוף, אנו מבטיחים שכל גישה לנתוני המטמון הגלובליים (כמו מערך ה-cache עצמו והסטטוס in_use של הפריטים) תהיה מוגנת, וכן שסדר רכישת המנעולים יהיה עקבי: תמיד cache_mutex ואז item_mutex. בדרך זו, לא יכול להיווצר מצב שבו חוט אחד מחכה ל-item_mutex בעודו מחזיק ב-cache_mutex, וחוט אחר מחכה ל-cache_mutex בעודו מחזיק ב-item_mutex. התיקון מבטל את התלות המעגלית ומסיר את פוטנציאל הקיפאון. (ה-usleep הוסר מהקוד המתוקן כי הוא נועד רק לסימולציה של עבודה בהקשר של הבעיה המקורית)."}, "difficulty_estimation": "Hard", "_source_file": "0281__Mutexes__CodeAnalysis__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:29:34", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Mutexes", "Concurrency", "Deadlock", "Linked List"], "content": {"text": "נתונה רשימה מקושרת מוגנת מנעולים, בה כל צומת מכיל מנעול (mutex) משלו (`node_mutex`), ובנוסף קיים מנעול גלובלי (`head_ptr_mutex`) המגן על המצביע לראש הרשימה (`head`). הרשימה מאותחלת על ידי `init_list()`.\n\nלהלן מימוש חלקי של פונקציות `add_node` ו-`remove_node`. פונקציית `add_node` מוסיפה צומת חדש לסוף הרשימה ומשתמשת במנגנון \"נעילה ידנית\" (hand-over-hand locking) באופן סטנדרטי (כלומר, נועלת צומת נוכחי P ואז את הצומת הבא N, ומשחררת את המנעול של P). פונקציית `remove_node` מנסה להסיר צומת בעל ערך נתון.\n\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\ntypedef struct Node {\n    int data;\n    struct Node* next;\n    pthread_mutex_t node_mutex; // Mutex protecting this node's data and next pointer\n} Node;\n\nNode* head = NULL;\npthread_mutex_t head_ptr_mutex; // Mutex protecting the global 'head' pointer\n\nvoid init_list() {\n    pthread_mutex_init(&head_ptr_mutex, NULL);\n    head = NULL;\n}\n\nvoid destroy_list() {\n    Node* current = head;\n    while (current != NULL) {\n        Node* temp = current;\n        current = current->next;\n        pthread_mutex_destroy(&temp->node_mutex);\n        free(temp);\n    }\n    pthread_mutex_destroy(&head_ptr_mutex);\n}\n\n// פונקציה להוספת צומת לסוף הרשימה (מימוש סטנדרטי עם hand-over-hand locking)\nvoid add_node(int data) {\n    Node* new_node = (Node*)malloc(sizeof(Node));\n    if (new_node == NULL) {\n        perror(\"malloc failed\");\n        exit(EXIT_FAILURE);\n    }\n    new_node->data = data;\n    new_node->next = NULL;\n    pthread_mutex_init(&new_node->node_mutex, NULL);\n\n    pthread_mutex_lock(&head_ptr_mutex);\n    if (head == NULL) {\n        head = new_node;\n        pthread_mutex_unlock(&head_ptr_mutex);\n    } else {\n        Node* current = head;\n        pthread_mutex_lock(&current->node_mutex); // Lock current (P)\n        pthread_mutex_unlock(&head_ptr_mutex); // Release head_ptr_mutex\n\n        while (current->next != NULL) {\n            Node* next_node = current->next;\n            pthread_mutex_lock(&next_node->node_mutex); // Lock next (N)\n            pthread_mutex_unlock(&current->node_mutex); // Unlock current (P)\n            current = next_node;\n        }\n        // 'current' is now the last node, holding its mutex (P)\n        current->next = new_node; // Modify P->next\n        pthread_mutex_unlock(&current->node_mutex); // Unlock P\n    }\n}\n\n// פונקציה בעייתית להסרת צומת מהרשימה\n// פונקציה זו משתמשת בסדר נעילה לא עקבי שעלול להוביל לקיפאון (deadlock).\nint remove_node(int value) {\n    pthread_mutex_lock(&head_ptr_mutex);\n    Node* current = head;\n    Node* prev = NULL;\n\n    // טיפול במקרה של הסרת צומת הראש\n    if (current != NULL && current->data == value) {\n        pthread_mutex_lock(&current->node_mutex); // נועלים את צומת הראש (N)\n        head = current->next; // משנים את מצביע ה-head\n        pthread_mutex_unlock(&current->node_mutex); // משחררים את N\n        pthread_mutex_destroy(&current->node_mutex);\n        free(current);\n        pthread_mutex_unlock(&head_ptr_mutex);\n        return 1; // הצומת הוסר\n    }\n\n    // משחררים את מנעול ה-head_ptr_mutex כדי לאפשר פעולות אחרות על ה-head\n    // בזמן שאנו עוברים על הרשימה. (לדוגמה, add_node) \n    pthread_mutex_unlock(&head_ptr_mutex);\n\n    // עוברים על הרשימה למצוא את הצומת להסרה\n    // שימו לב: בשלב זה, אין מנעולי צומת נעולים במהלך המעבר עד למציאת הצומת.\n    current = head;\n    while (current != NULL) {\n        if (current->data == value) {\n            // מצאנו את הצומת (N) שיש להסיר. 'prev' הוא קודמו (P).\n            // סדר נעילה לא עקבי שגורם לקיפאון: נועלים את N ואז את P.\n            pthread_mutex_lock(&current->node_mutex); // נועלים את N\n            if (prev != NULL) {\n                pthread_mutex_lock(&prev->node_mutex); // נועלים את P (סדר הפוך!)\n                prev->next = current->next; // משנים את P->next\n                pthread_mutex_unlock(&prev->node_mutex); // משחררים את P\n            }\n            // אם prev הוא NULL, המשמעות היא ש-current הוא ה-head, \n            // אך מקרה זה אמור להיות מטופל כבר למעלה.\n            pthread_mutex_unlock(&current->node_mutex); // משחררים את N\n            pthread_mutex_destroy(&current->node_mutex);\n            free(current);\n            return 1; // הצומת הוסר\n        }\n        prev = current;\n        current = current->next;\n    }\n\n    return 0; // הצומת לא נמצא\n}\n```", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "מה הבעיה במימוש של פונקציית `remove_node`? תארו סיטואציה ספציפית (עם מספר חוטים ופעולות) שבה הבעיה יכולה להתרחש.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "תקנו את פונקציית `remove_node` כך שתעבוד באופן תקין ותמנע קיפאונות, תוך שמירה על רמת מקביליות גבוהה ככל הניתן (כלומר, השתמשו במנעולי צומת היכן שנדרש).", "code_snippet": "int remove_node(int value) {\n    // כתבו את הקוד המתוקן כאן\n}", "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "### פתרון לשאלה 1:\n\n**1.1. הבעיה במימוש פונקציית `remove_node`:**\nהבעיה במימוש פונקציית `remove_node` היא **קיפאון (deadlock)**. הקיפאון יכול להתרחש כתוצאה מסדר נעילה לא עקבי (inconsistent locking order) בין פונקציות המשתמשות באותם מנעולים.\n\n*   **סדר נעילה ב-`add_node` (ובמעבר סטנדרטי):** פונקציית `add_node` (ובאופן כללי, מעבר על הרשימה תוך שימוש במנגנון hand-over-hand locking) נועלת את מנעול הצומת הקודם (P) לפני שהיא נועלת את מנעול הצומת העוקב (N). כלומר, סדר הנעילה הוא **P ואז N**.\n*   **סדר נעילה ב-`remove_node` (הבעייתי):** פונקציית `remove_node`, במקרה של הסרת צומת שאינו ראש הרשימה, מנסה לנעול קודם את מנעול הצומת שיש להסיר (N) ורק לאחר מכן את מנעול קודמו (P). כלומר, סדר הנעילה הוא **N ואז P**.\n\n**תרחיש קיפאון:**\nנניח רשימה מקושרת עם שלושה צמתים: `A -> B -> C`.\n\n1.  **חוט 1** קורא לפונקציה `add_node(D)` (מנסה להוסיף צומת D לסוף הרשימה).\n    *   חוט 1 נועל את `head_ptr_mutex` ומשחרר אותו.\n    *   הוא נועל את המנעול של צומת A: `pthread_mutex_lock(&A->node_mutex);` (P).\n    *   הוא ממשיך למעבר על הרשימה. הוא מנסה לנעול את המנעול של צומת B: `pthread_mutex_lock(&B->node_mutex);` (N).\n    *   **בנקודה זו, חוט 1 מחזיק את `A->node_mutex` ומנסה לרכוש את `B->node_mutex`.**\n2.  **חוט 2** קורא לפונקציה `remove_node(B)` (מנסה להסיר את צומת B).\n    *   חוט 2 נועל את `head_ptr_mutex` ומשחרר אותו.\n    *   הוא עובר על הרשימה (ללא נעילת מנעולי צמתים בשלב זה) עד שהוא מוצא את צומת B (כאשר `prev` מצביע על A ו-`current` מצביע על B).\n    *   חוט 2 נועל את המנעול של צומת B: `pthread_mutex_lock(&B->node_mutex);` (N).\n    *   **בנקודה זו, חוט 2 מחזיק את `B->node_mutex`.**\n    *   חוט 2 מנסה כעת לנעול את המנעול של צומת A (כי הוא צריך את `prev->node_mutex` כדי לעדכן את `A->next`): `pthread_mutex_lock(&A->node_mutex);` (חוט 2 נחסם על ידי חוט 1, שמחזיק את `A->node_mutex`).\n\n**תוצאה:** נוצר קיפאון. חוט 1 ממתין למנעול של B שמוחזק על ידי חוט 2, וחוט 2 ממתין למנעול של A שמוחזק על ידי חוט 1.\n\n**1.2. תיקון פונקציית `remove_node`:**\nכדי לתקן את הבעיה, יש להבטיח סדר נעילה עקבי עבור כל הפעולות ברשימה. הדרך המקובלת היא להשתמש בסדר \"קודם ואז עוקב\" (P ואז N) כאשר שני מנעולים נדרשים בו-זמנית. המימוש המתוקן משתמש ב-hand-over-hand locking גם במהלך המעבר, וכאשר נמצא הצומת להסרה (N), המנעול של קודמו (P) כבר מוחזק, ואז רוכשים את המנעול של N.\n\n```c\nint remove_node(int value) {\n    pthread_mutex_lock(&head_ptr_mutex);\n    Node* current = head;\n    Node* prev = NULL; // prev will not be used in the fixed head case, but for traversal\n\n    // טיפול במקרה של הסרת צומת הראש\n    if (current != NULL && current->data == value) {\n        pthread_mutex_lock(&current->node_mutex); // נועלים את צומת הראש (N)\n        head = current->next; // משנים את מצביע ה-head\n        pthread_mutex_unlock(&current->node_mutex); // משחררים את N\n        pthread_mutex_destroy(&current->node_mutex);\n        free(current);\n        pthread_mutex_unlock(&head_ptr_mutex);\n        return 1; // הצומת הוסר\n    }\n\n    // אם ראש הרשימה אינו הצומת המבוקש, משחררים את מנעול ה-head_ptr_mutex\n    // ומתחילים מעבר עם hand-over-hand locking.\n    pthread_mutex_unlock(&head_ptr_mutex);\n\n    // מתחילים מעבר על הרשימה\n    current = head; \n    if (current == NULL) {\n        return 0; // הרשימה ריקה או הצומת לא נמצא\n    }\n\n    pthread_mutex_lock(&current->node_mutex); // נועלים את הצומת הראשון (P) לצורך התחלת מעבר\n    \n    while (current != NULL) {\n        Node* next_node = current->next; // N\n        \n        // אם next_node הוא הצומת המבוקש להסרה\n        if (next_node != NULL && next_node->data == value) {\n            pthread_mutex_lock(&next_node->node_mutex); // נועלים את N (כאשר P נעול)\n            current->next = next_node->next; // משנים את P->next\n            pthread_mutex_unlock(&next_node->node_mutex); // משחררים את N\n            pthread_mutex_destroy(&next_node->node_mutex);\n            free(next_node);\n            pthread_mutex_unlock(&current->node_mutex); // משחררים את P\n            return 1; // הצומת הוסר\n        }\n\n        // אם לא מצאנו את הצומת, מתקדמים ב-hand-over-hand locking\n        if (next_node != NULL) {\n            pthread_mutex_lock(&next_node->node_mutex); // נועלים את N\n        }\n        pthread_mutex_unlock(&current->node_mutex); // משחררים את P\n        current = next_node;\n    }\n\n    return 0; // הצומת לא נמצא\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0282__Mutexes__CodeAnalysis__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:31:19", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Synchronization", "Mutexes", "Deadlock", "Concurrency"], "content": {"text": "נתונה מערכת המנהלת שני תורים מקושרים, `listA` ו-`listB`, כאשר כל תור מוגן על ידי מנעול (mutex) משלו. מטרת המערכת היא לאפשר העברת פריטים בין התורים באופן בטוח במקביל. להלן מימוש חלקי של הפונקציות `transfer_A_to_B` ו-`transfer_B_to_A` המיועדות להעביר פריט מתור אחד לשני. קוד העזר לניהול הרשימות (אתחול, הוספה, הסרה) תקין ומוגן על ידי המנעולים של הרשימה המתאימה. שימו לב כי פעולות הוספה והסרה בתוך פונקציות ה-`transfer` מניחות שהמנעול המתאים כבר נתפס על ידי הפונקציה הקוראת ואינן תופסות מנעולים בעצמן.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n#include <unistd.h> // for usleep\n\n// Assume a simple linked list structure for demonstration\ntypedef struct Node {\n    int data;\n    struct Node* next;\n} Node;\n\ntypedef struct {\n    Node* head;\n    pthread_mutex_t mutex;\n    int count; \n} List;\n\n// Global lists (assume they are initialized elsewhere)\nList listA;\nList listB;\n\n// Problematic functions\nvoid transfer_A_to_B() {\n    pthread_mutex_lock(&listA.mutex);\n    // Simulate some work to increase deadlock probability\n    usleep(10000); // 10ms\n\n    int item = -1;\n    // Remove from listA (protected by listA.mutex)\n    if (listA.head != NULL) {\n        Node* temp = listA.head;\n        item = temp->data;\n        listA.head = listA.head->next;\n        free(temp);\n        listA.count--;\n    }\n\n    if (item != -1) {\n        pthread_mutex_lock(&listB.mutex);\n        \n        // Add to listB (protected by listB.mutex)\n        Node* new_node = (Node*)malloc(sizeof(Node));\n        new_node->data = item;\n        new_node->next = NULL;\n        if (listB.head == NULL) {\n            listB.head = new_node;\n        } else {\n            Node* current = listB.head;\n            while (current->next != NULL) {\n                current = current->next;\n            }\n            current->next = new_node;\n        }\n        listB.count++;\n\n        pthread_mutex_unlock(&listB.mutex);\n    }\n    pthread_mutex_unlock(&listA.mutex);\n}\n\nvoid transfer_B_to_A() {\n    pthread_mutex_lock(&listB.mutex);\n    // Simulate some work to increase deadlock probability\n    usleep(10000); // 10ms\n\n    int item = -1;\n    // Remove from listB (protected by listB.mutex)\n    if (listB.head != NULL) {\n        Node* temp = listB.head;\n        item = temp->data;\n        listB.head = listB.head->next;\n        free(temp);\n        listB.count--;\n    }\n\n    if (item != -1) {\n        pthread_mutex_lock(&listA.mutex);\n        \n        // Add to listA (protected by listA.mutex)\n        Node* new_node = (Node*)malloc(sizeof(Node));\n        new_node->data = item;\n        new_node->next = NULL;\n        if (listA.head == NULL) {\n            listA.head = new_node;\n        } else {\n            Node* current = listA.head;\n            while (current->next != NULL) {\n                current = current->next;\n            }\n            current->next = new_node;\n        }\n        listA.count++;\n        \n        pthread_mutex_unlock(&listA.mutex);\n    }\n    pthread_mutex_unlock(&listB.mutex);\n}"}, "sub_questions": [{"id": "1.1", "text": "תארו את הבעיה העיקרית במימוש הנוכחי של פונקציות ההעברה (`transfer_A_to_B` ו-`transfer_B_to_A`). הסבירו כיצד בעיה זו יכולה להתרחש, תוך פירוט רצף פעולות של שני חוטים (threads) לפחות המדגים את הבעיה.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "הציעו תיקון למימוש כך שהבעיה שתוארה בסעיף א' תימנע. כתבו את הקוד המתוקן עבור שתי הפונקציות (`transfer_A_to_B` ו-`transfer_B_to_A`) תוך שמירה על יעילות סבירה.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1. **הבעיה:**\nהבעיה העיקרית במימוש הנוכחי היא קיפאון (Deadlock). קיפאון יכול להתרחש כאשר שני חוטים מנסים לתפוס את המנעולים של `listA` ו-`listB` בסדר הפוך.\n\n**תיאור רצף פעולות המדגים קיפאון:**\nנניח שקיימים שני חוטים, חוט 1 וחוט 2:\n*   **חוט 1** קורא לפונקציה `transfer_A_to_B()`:\n    *   תופס את המנעול של `listA` (`pthread_mutex_lock(&listA.mutex)`).\n    *   מבצע פעולות פנימיות (למשל, `usleep`).\n    *   מנסה לתפוס את המנעול של `listB` (`pthread_mutex_lock(&listB.mutex)`). בשלב זה, אם `listB.mutex` כבר תפוס על ידי חוט אחר, חוט 1 יחסם.\n*   באותו זמן, **חוט 2** קורא לפונקציה `transfer_B_to_A()`:\n    *   תופס את המנעול של `listB` (`pthread_mutex_lock(&listB.mutex)`).\n    *   מבצע פעולות פנימיות (למשל, `usleep`).\n    *   מנסה לתפוס את המנעול של `listA` (`pthread_mutex_lock(&listA.mutex)`). בשלב זה, אם `listA.mutex` כבר תפוס על ידי חוט אחר, חוט 2 יחסם.\n\nבשלב זה, חוט 1 מחזיק במנעול של `listA` וממתין למנעול של `listB` (שמוחזק על ידי חוט 2). במקביל, חוט 2 מחזיק במנעול של `listB` וממתין למנעול של `listA` (שמוחזק על ידי חוט 1). שני החוטים חסומים באופן הדדי ואינם יכולים להתקדם, מה שגורם לקיפאון.\n\n1.2. **תיקון:**\nכדי למנוע קיפאון, יש לאכוף סדר קבוע לרכישת המנעולים. כלומר, כל חוט שצריך לתפוס את שני המנעולים (של `listA` ושל `listB`) יתפוס אותם תמיד באותו סדר (לדוגמה, תמיד קודם את `listA.mutex` ואז את `listB.mutex`). לאחר סיום הפעולות, יש לשחרר את המנעולים בסדר הפוך מהסדר בו נתפסו.\n\n**קוד מתוקן:**\n```c\n// Fixed functions\nvoid transfer_A_to_B() {\n    pthread_mutex_lock(&listA.mutex); // Lock A first (consistent order)\n    pthread_mutex_lock(&listB.mutex); // Then lock B\n    \n    // Simulate some work\n    usleep(10000); // 10ms\n\n    int item = -1;\n    // Remove from listA (protected by listA.mutex)\n    if (listA.head != NULL) {\n        Node* temp = listA.head;\n        item = temp->data;\n        listA.head = listA.head->next;\n        free(temp);\n        listA.count--;\n    }\n\n    if (item != -1) {\n        // Add to listB (protected by listB.mutex)\n        Node* new_node = (Node*)malloc(sizeof(Node));\n        new_node->data = item;\n        new_node->next = NULL;\n        if (listB.head == NULL) {\n            listB.head = new_node;\n        } else {\n            Node* current = listB.head;\n            while (current->next != NULL) {\n                current = current->next;\n            }\n            current->next = new_node;\n        }\n        listB.count++;\n    }\n    \n    pthread_mutex_unlock(&listB.mutex); // Unlock B first (reverse order of locking)\n    pthread_mutex_unlock(&listA.mutex); // Then unlock A\n}\n\nvoid transfer_B_to_A() {\n    pthread_mutex_lock(&listA.mutex); // Lock A first (consistent order)\n    pthread_mutex_lock(&listB.mutex); // Then lock B\n    \n    // Simulate some work\n    usleep(10000); // 10ms\n\n    int item = -1;\n    // Remove from listB (protected by listB.mutex)\n    if (listB.head != NULL) {\n        Node* temp = listB.head;\n        item = temp->data;\n        listB.head = listB.head->next;\n        free(temp);\n        listB.count--;\n    }\n\n    if (item != -1) {\n        // Add to listA (protected by listA.mutex)\n        Node* new_node = (Node*)malloc(sizeof(Node));\n        new_node->data = item;\n        new_node->next = NULL;\n        if (listA.head == NULL) {\n            listA.head = new_node;\n        } else {\n            Node* current = listA.head;\n            while (current->next != NULL) {\n                current = current->next;\n            }\n            current->next = new_node;\n        }\n        listA.count++;\n    }\n    \n    pthread_mutex_unlock(&listB.mutex); // Unlock B first (reverse order of locking)\n    pthread_mutex_unlock(&listA.mutex); // Then unlock A\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0283__Mutexes__CodeAnalysis__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:31:57", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Synchronization", "Mutexes", "Concurrency", "Deadlocks"], "content": {"text": "נתונה מערכת המשתמשת במאגר משותף (buffer) ובמונה משותף (counter). המערכת מוגדרת עם שני mutexes: `buffer_mutex` להגנה על המאגר ו-`counter_mutex` להגנה על המונה. המונה מאותחל ל-0. פונקציות העזר `produce_new_item()`, `add_item_to_buffer()`, `remove_item_from_buffer()`, ו-`consume_item()` בטוחות לשימוש ומתוארות בקצרה (אין צורך לממש אותן). להלן קוד המימוש של פונקציות היצרן (producer) והצרכן (consumer) במערכת, המשתמשות במנעולים אלו:", "code_snippet": "#include <pthread.h>\n\n// Global variables\nint counter = 0; // Tracks number of items in buffer\n// Assume a shared buffer implementation (e.g., array with head/tail)\n// For simplicity, buffer overflow/underflow is not the focus of this question.\n\npthread_mutex_t buffer_mutex; // Protects buffer, head, tail\npthread_mutex_t counter_mutex; // Protects counter\n\n// Assume these helper functions exist and are safe to call\n// (i.e., they don't handle their own synchronization, relying on caller)\nint produce_new_item();\nvoid add_item_to_buffer(int item);\nint remove_item_from_buffer();\nvoid consume_item(int item);\n\n// Producer thread function (buggy)\nvoid* producer(void* arg) {\n    while (1) {\n        int item = produce_new_item();\n\n        pthread_mutex_lock(&buffer_mutex); // Acquire buffer_mutex first\n        add_item_to_buffer(item);\n\n        pthread_mutex_lock(&counter_mutex); // Then acquire counter_mutex\n        counter++;\n        pthread_mutex_unlock(&counter_mutex);\n\n        pthread_mutex_unlock(&buffer_mutex);\n    }\n    return NULL;\n}\n\n// Consumer thread function (buggy)\nvoid* consumer(void* arg) {\n    while (1) {\n        pthread_mutex_lock(&counter_mutex); // Acquire counter_mutex first\n        if (counter > 0) {\n            counter--;\n\n            pthread_mutex_lock(&buffer_mutex); // Then acquire buffer_mutex\n            int item = remove_item_from_buffer();\n            pthread_mutex_unlock(&buffer_mutex);\n            consume_item(item);\n        }\n        pthread_mutex_unlock(&counter_mutex);\n    }\n    return NULL;\n}"}, "sub_questions": [{"id": "1.1", "text": "הקוד המתואר אינו תקין. תארו מה הבעיה וכיצד היא יכולה להתרחש. יש לתאר ריצה ספציפית המדגימה את הבעיה.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "תקנו את הקוד כך שיעבוד באופן תקין וימנע את הבעיה שתוארה. יש להציג את הפונקציות producer ו-consumer המתוקנות.", "code_snippet": "void* producer(void* arg) {\n    // הקוד המתוקן של producer כאן\n}\n\nvoid* consumer(void* arg) {\n    // הקוד המתוקן של consumer כאן\n}", "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1. הבעיה בקוד היא קיפאון (Deadlock).\n   הקיפאון יכול להתרחש כתוצאה מסדר תפיסת מנעולים לא עקבי בין החוטים השונים. נניח שמתרחשת הריצה הבאה:\n   1. חוט יצרן (Producer Thread) מבצע `pthread_mutex_lock(&buffer_mutex)`. כעת הוא מחזיק במנעול `buffer_mutex`.\n   2. מתרחש מעבר הקשר (context switch) לחוט צרכן (Consumer Thread).\n   3. חוט צרכן מבצע `pthread_mutex_lock(&counter_mutex)`. כעת הוא מחזיק במנעול `counter_mutex`.\n   4. חוט צרכן ממשיך ובודק `if (counter > 0)`. נניח ש-`counter` אכן גדול מ-0. הוא מבצע `counter--`.\n   5. חוט צרכן מנסה לבצע `pthread_mutex_lock(&buffer_mutex)`, אך המנעול `buffer_mutex` כבר נתפס על ידי חוט היצרן. חוט הצרכן נחסם וממתין לשחרור `buffer_mutex`.\n   6. מתרחש מעבר הקשר בחזרה לחוט יצרן.\n   7. חוט יצרן מנסה לבצע `pthread_mutex_lock(&counter_mutex)`, אך המנעול `counter_mutex` כבר נתפס על ידי חוט הצרכן. חוט היצרן נחסם וממתין לשחרור `counter_mutex`.\n   בשלב זה, שני החוטים חסומים באופן הדדי: היצרן ממתין לצרכן שישחרר את `counter_mutex`, והצרכן ממתין ליצרן שישחרר את `buffer_mutex`. אף אחד מהם לא יכול להמשיך, והמערכת נכנסת למצב של קיפאון.\n\n1.2. כדי למנוע קיפאון, יש לוודא שכל החוטים תופסים את המנעולים באותו סדר עקבי. נבחר בסדר: תחילה `counter_mutex` ואז `buffer_mutex`. שינוי זה דורש התאמה בפונקציית היצרן.\n\nהקוד המתוקן:\n```c\nvoid* producer(void* arg) {\n    while (1) {\n        int item = produce_new_item();\n\n        pthread_mutex_lock(&counter_mutex); // Acquire counter_mutex first (consistent order)\n        pthread_mutex_lock(&buffer_mutex);  // Then acquire buffer_mutex\n\n        // Both mutexes are now held, ensuring atomicity for counter and buffer update.\n        // In a full producer-consumer, one would also check for buffer full here and use condition variables.\n        add_item_to_buffer(item);\n        counter++;\n\n        pthread_mutex_unlock(&buffer_mutex);\n        pthread_mutex_unlock(&counter_mutex);\n    }\n    return NULL;\n}\n\nvoid* consumer(void* arg) {\n    while (1) {\n        pthread_mutex_lock(&counter_mutex); // Acquire counter_mutex first (consistent order)\n        pthread_mutex_lock(&buffer_mutex);  // Then acquire buffer_mutex\n\n        if (counter > 0) { // Check counter under lock\n            counter--;\n            int item = remove_item_from_buffer();\n            consume_item(item);\n        }\n        // If counter <= 0, buffer is empty. Just unlock and retry.\n        \n        pthread_mutex_unlock(&buffer_mutex);\n        pthread_mutex_unlock(&counter_mutex);\n    }\n    return NULL;\n}\n```", "difficulty_estimation": "Hard"}, "_source_file": "0284__Mutexes__CodeAnalysis__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:32:43", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Mutexes", "Synchronization", "Concurrency", "Deadlock"], "content": {"text": "נתונה מערכת המנהלת חשבונות בנק. כל חשבון מיוצג על ידי מבנה `Account` הכולל מזהה (id), יתרה (balance) ומנעול (mutex) משלו. שתי פונקציות עיקריות מוגדרות: `transfer` המעבירה כסף בין שני חשבונות. המערכת מריצה מספר חוטים במקביל המבצעים פעולות אלו. יש לתאר בקצרה ובבירור כל פתרון ולכתוב קוד ברור.", "code_snippet": "```c\n#include <pthread.h>\n#include <stdio.h>\n\ntypedef struct {\n    int id;\n    int balance;\n    pthread_mutex_t mutex;\n} Account;\n\n// Global accounts (assume these are initialized, e.g., in main or init_accounts)\n// Account accountA; Account accountB;\n\n// Function to transfer 'amount' from 'from' account to 'to' account\nvoid transfer(Account* from, Account* to, int amount) {\n    pthread_mutex_lock(&from->mutex);\n    pthread_mutex_lock(&to->mutex);\n\n    if (from->balance >= amount) {\n        from->balance -= amount;\n        to->balance += amount;\n    }\n\n    pthread_mutex_unlock(&to->mutex);\n    pthread_mutex_unlock(&from->mutex);\n}\n```", "options": null}, "sub_questions": [{"id": "8.1", "text": "הקוד הנ\"ל סובל מבעיה חמורה של קיפאון (Deadlock) אשר עלולה להתרחש בנסיבות מסוימות. תארו ריצה אפשרית (עם מספר חוטים כרצונכם) המדגימה את הבעיה, והסבירו מדוע היא מתרחשת.", "code_snippet": null, "options": null}, {"id": "8.2", "text": "תקנו את פונקציית `transfer` כך שתמנע את בעיית הקיפאון, תוך שמירה על עקרונות הסנכרון הנדרשים (ללא שימוש באובייקטי סנכרון נוספים פרט למנעולים הקיימים). כתבו את הקוד המתוקן.", "code_snippet": "void transfer(Account* from, Account* to, int amount) {\n    // כתבו את הקוד המתוקן כאן\n}", "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "### פתרון לשאלה 8\n\n**8.1 תיאור בעיית הקיפאון:**\n\nהבעיה: קיפאון (Deadlock).\n\nהסבר: קיפאון יכול להתרחש כאשר שני חוטים (threads) מנסים לבצע העברה כספית במקביל, אך בכיוונים מנוגדים. לדוגמה:\n\n1.  **חוט 1 (T1)** מנסה להעביר כסף מחשבון A לחשבון B (כלומר, קורא לפונקציה `transfer(&accountA, &accountB, ...)`. הוא נועל את המנעול של חשבון A (`&accountA.mutex`) בהצלחה.\n2.  **במקביל, חוט 2 (T2)** מנסה להעביר כסף מחשבון B לחשבון A (כלומר, קורא לפונקציה `transfer(&accountB, &accountA, ...)`. הוא נועל את המנעול של חשבון B (`&accountB.mutex`) בהצלחה.\n3.  **כעת T1** מנסה לנעול את המנעול של חשבון B (`&accountB.mutex`), אך מנעול זה כבר נעול על ידי T2. לכן, T1 נכנס למצב המתנה.\n4.  **במקביל, T2** מנסה לנעול את המנעול של חשבון A (`&accountA.mutex`), אך מנעול זה כבר נעול על ידי T1. לכן, T2 נכנס למצב המתנה.\n\nשני החוטים ממתינים זה לזה לשחרור המנעול שהם צריכים, וכתוצאה מכך אף אחד מהם לא יכול להתקדם. זהו מצב קלאסי של קיפאון, כאשר כל חוט מחזיק במשאב (מנעול) וממתין למשאב אחר שמוחזק על ידי חוט אחר.\n\n**8.2 תיקון פונקציית `transfer`:**\n\nכדי למנוע קיפאון במצב זה, יש להקפיד על סדר עקבי של תפיסת המנעולים. דרך נפוצה היא לתפוס את המנעולים על בסיס מזהה ייחודי (כמו `id` במקרה זה, או כתובת זיכרון), מה שמבטיח שכל החוטים ינסו לתפוס את אותם מנעולים באותו סדר, ללא קשר לסדר הטיעונים המקוריים לפונקציה.\n\n**הקוד המתוקן:**\n```c\nvoid transfer(Account* from, Account* to, int amount) {\n    // Handle transfer to/from the same account or null accounts\n    if (from == to || from == NULL || to == NULL) {\n        // No operation needed for same account, or invalid accounts\n        return;\n    }\n\n    pthread_mutex_t *mutex1, *mutex2;\n    // Determine a consistent locking order based on account IDs.\n    // Always lock the account with the smaller ID first.\n    if (from->id < to->id) {\n        mutex1 = &from->mutex;\n        mutex2 = &to->mutex;\n    } else { // to->id < from->id (assuming IDs are unique and not equal)\n        mutex1 = &to->mutex;\n        mutex2 = &from->mutex;\n    }\n\n    // Acquire locks in the consistent order\n    pthread_mutex_lock(mutex1);\n    pthread_mutex_lock(mutex2);\n\n    // Perform the transfer logic on the original 'from' and 'to' accounts\n    if (from->balance >= amount) {\n        from->balance -= amount;\n        to->balance += amount;\n    }\n\n    // Release locks in the reverse order of acquisition (or any order, as long as both are released)\n    pthread_mutex_unlock(mutex2);\n    pthread_mutex_unlock(mutex1);\n}\n```", "difficulty_estimation": "Hard"}, "_source_file": "0285__Mutexes__CodeAnalysis__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:33:13", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Mutexes", "Synchronization", "Concurrency", "Deadlock", "Barrier"], "content": {"text": "נתונה תוכנית C המנסה לממש מחסום (barrier) עבור N חוטים באמצעות מוטקס יחיד ומונה משותף. המטרה היא שכל N החוטים יגיעו לנקודה מסוימת בקוד לפני שמי מהם ימשיך הלאה. נתח את קוד המחסום המוצג להלן. האם הקוד יפעל כמצופה? אם לא, תאר את הבעיה (סוגה, כיצד היא מתרחשת, ומהן השלכותיה) והסבר מדוע היא מתרחשת. לאחר מכן, הצע פתרון נכון או ציין את המנגנונים הדרושים לפתרון נכון.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep, though not strictly needed for the problem demonstration\n\n#define N_THREADS 3 // מספר החוטים במערכת\n\npthread_mutex_t barrier_mutex;\nint thread_count = 0; // מונה משותף לחוטים שהגיעו למחסום\n\nvoid *thread_func(void *arg) {\n    long id = (long)arg;\n    printf(\"Thread %ld: Arrived at barrier point 1.\\n\", id);\n\n    pthread_mutex_lock(&barrier_mutex); // תפוס את המוטקס\n\n    thread_count++; // הגדל את מונה החוטים שהגיעו\n\n    if (thread_count < N_THREADS) {\n        // אם זה לא החוט האחרון שהגיע\n        printf(\"Thread %ld: Waiting for other threads. Current count: %d/%d\\n\", id, thread_count, N_THREADS);\n        while (thread_count < N_THREADS) {\n            // המתן לחוטים אחרים בזמן שהמוטקס תפוס\n            // (פעולה זו היא שורש הבעיה)\n        }\n    } else {\n        // זהו החוט האחרון שהגיע\n        printf(\"Thread %ld: Last thread arrived. Releasing barrier.\\n\", id);\n        thread_count = 0; // אפס את המונה לשימוש עתידי במחסום\n    }\n\n    pthread_mutex_unlock(&barrier_mutex); // שחרר את המוטקס\n    printf(\"Thread %ld: Passed barrier point 1.\\n\", id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[N_THREADS];\n    pthread_mutex_init(&barrier_mutex, NULL);\n\n    for (long i = 0; i < N_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, (void *)i);\n    }\n\n    for (int i = 0; i < N_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    pthread_mutex_destroy(&barrier_mutex);\n    printf(\"All threads finished.\\n\");\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הקוד אינו פועל כמצופה ויוביל למצב של קיפאון (Deadlock). \n\n**הבעיה:**\nחוטים מגיעים למחסום, תופסים את המוטקס `barrier_mutex` ומגדילים את המונה `thread_count`. כל עוד `thread_count` קטן מ-`N_THREADS` (כלומר, הם אינם החוט האחרון שהגיע), החוטים נכנסים ללולאת `while (thread_count < N_THREADS)` **כאשר הם עדיין מחזיקים במוטקס**. \n\n**כיצד זה מוביל לקיפאון:**\nאם `N_THREADS` הוא 3, לדוגמה:\n1.  חוט 0 תופס את `barrier_mutex`, מגדיל את `thread_count` ל-1, ונכנס ללולאת ה-`while` כשהוא מחזיק במוטקס.\n2.  כל שאר `N-1` החוטים ינסו לתפוס את `barrier_mutex` באמצעות `pthread_mutex_lock` אך ייחסמו לעד, מכיוון שהחוט הראשון לעולם לא ישחרר את המוטקס (הוא תקוע בלולאה שמחכה למונה שיגדל, אך המונה לא יכול לגדול כי אף חוט אחר לא יכול לתפוס את המוטקס כדי להגדיל אותו). כתוצאה מכך, המערכת תיכנס למצב של קיפאון.\n\n**השלכות:**\nהתוכנית תיתקע ולא תשלים את ריצתה. החוטים יישארו במצב חסום, והמשאבים שהם תופסים (כמו המוטקס) לא ישוחררו, מה שיכול למנוע מחוטים אחרים במערכת (אפילו אלה שלא קשורים למחסום זה) מלהתקדם אם הם זקוקים למשאבים אלה.\n\n**פתרון נכון:**\nמוטקסים מיועדים להבטחת הדרה הדדית (mutual exclusion) על משאב משותף, אך אינם מיועדים למנגנוני איתות (signaling) והמתנה מורכבים כמו מחסום. עבור מנגנוני איתות והמתנה יעילים, יש להשתמש ב**משתני תנאי (Condition Variables)** בשילוב עם מוטקסים. \n\nפתרון נכון למחסום באמצעות מוטקס ומשתנה תנאי ייראה בערך כך:\n```c\n#include <pthread.h>\n#include <stdio.h>\n\n#define N_THREADS 3\n\npthread_mutex_t barrier_mutex;\npthread_cond_t barrier_cond;\nint thread_count = 0;\n\nvoid *thread_func(void *arg) {\n    long id = (long)arg;\n    printf(\"Thread %ld: Arrived at barrier point 1.\\n\", id);\n\n    pthread_mutex_lock(&barrier_mutex);\n    thread_count++;\n\n    if (thread_count < N_THREADS) {\n        // אם זה לא החוט האחרון, המתן על משתנה התנאי\n        while (thread_count < N_THREADS) { // Loop for spurious wakeups\n            pthread_cond_wait(&barrier_cond, &barrier_mutex);\n        }\n    } else {\n        // זהו החוט האחרון, אפס את המונה ואותת לכל הממתינים\n        thread_count = 0; // Reset for next barrier use\n        pthread_cond_broadcast(&barrier_cond);\n    }\n\n    pthread_mutex_unlock(&barrier_mutex);\n    printf(\"Thread %ld: Passed barrier point 1.\\n\", id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[N_THREADS];\n    pthread_mutex_init(&barrier_mutex, NULL);\n    pthread_cond_init(&barrier_cond, NULL);\n\n    for (long i = 0; i < N_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, (void *)i);\n    }\n\n    for (int i = 0; i < N_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    pthread_mutex_destroy(&barrier_mutex);\n    pthread_cond_destroy(&barrier_cond);\n    printf(\"All threads finished.\\n\");\n    return 0;\n}\n```", "difficulty_estimation": "Hard"}, "_source_file": "0286__Mutexes__CodeAnalysis__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:43:51", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Mutexes", "Deadlock", "Concurrency", "Lazy Initialization", "Singleton"], "content": {"text": "במערכת מרובת חוטים, נדרש לממש אובייקט יחיד (singleton) שמאותחל באופן עצלני (lazy initialization). אובייקט זה, `Logger`, אחראי לרישום הודעות ליומן. בניית אובייקט `Logger` היא פעולה יקרה וארוכה, ודורשת גישה למשאב גלובלי נוסף (לדוגמה, קובץ קונפיגורציה), המוגן על ידי מנעול `config_mutex`.\n\nלהלן המימוש המוצע:\n1. הפונקציה `get_logger()` אחראית להחזיר את מופע ה-`Logger` היחיד, וליצור אותו אם טרם נוצר.\n2. הקונסטרוקטור של `Logger` (הפונקציה `Logger::Logger()`) מבצע את האתחול היקר, ובמהלכו נועל את `config_mutex`.\n\nבנוסף, קיימת פונקציה `update_configuration()` המבצעת עדכון כלשהו בקונפיגורציה, ודורשת גישה לשני המנעולים: תחילה `config_mutex` ולאחר מכן `logger_init_mutex` (מסיבות שאינן רלוונטיות לבעיה, אך נדרשות על ידי לוגיקה פנימית).\n\nנתחו את הקוד הנתון וענו על השאלות הבאות.", "code_snippet": "#include <iostream>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\n// Global mutex for lazy initialization of Logger\npthread_mutex_t logger_init_mutex = PTHREAD_MUTEX_INITIALIZER;\n// Global mutex for configuration access (used by Logger constructor and update_configuration)\npthread_mutex_t config_mutex = PTHREAD_MUTEX_INITIALIZER;\n\nclass Logger {\npublic:\n    Logger() {\n        // Simulate expensive initialization requiring config_mutex\n        pthread_mutex_lock(&config_mutex);\n        std::cout << \"Logger constructor: Acquiring config_mutex for expensive initialization...\" << std::endl;\n        sleep(2); // Simulate long initialization\n        std::cout << \"Logger constructor: Finished expensive initialization and releasing config_mutex.\" << std::endl;\n        pthread_mutex_unlock(&config_mutex);\n    }\n\n    void log(const char* message) {\n        std::cout << \"Log message: \" << message << std::endl;\n    }\n};\n\n// The singleton instance\nLogger* g_logger_instance = NULL;\n\n// Function to get the singleton Logger instance\nLogger* get_logger() {\n    if (g_logger_instance == NULL) { // First check (no lock)\n        pthread_mutex_lock(&logger_init_mutex);\n        if (g_logger_instance == NULL) { // Second check (with lock)\n            std::cout << \"Thread \" << pthread_self() << \": Initializing Logger...\" << std::endl;\n            g_logger_instance = new Logger(); // Calls Logger constructor\n            std::cout << \"Thread \" << pthread_self() << \": Logger initialized.\" << std::endl;\n        }\n        pthread_mutex_unlock(&logger_init_mutex);\n    }\n    return g_logger_instance;\n}\n\n// Another function that needs config_mutex then logger_init_mutex\nvoid update_configuration() {\n    std::cout << \"Thread \" << pthread_self() << \": Entering update_configuration()...\" << std::endl;\n    pthread_mutex_lock(&config_mutex);\n    std::cout << \"Thread \" << pthread_self() << \": Acquired config_mutex in update_configuration().\" << std::endl;\n    sleep(1); // Simulate some work\n    \n    pthread_mutex_lock(&logger_init_mutex); // Potential deadlock here\n    std::cout << \"Thread \" << pthread_self() << \": Acquired logger_init_mutex in update_configuration().\" << std::endl;\n    // Perform configuration update that might involve checking logger state or similar\n    // For simplicity, just simulate work.\n    sleep(1);\n    \n    pthread_mutex_unlock(&logger_init_mutex);\n    std::cout << \"Thread \" << pthread_self() << \": Released logger_init_mutex in update_configuration().\" << std::endl;\n    \n    pthread_mutex_unlock(&config_mutex);\n    std::cout << \"Thread \" << pthread_self() << \": Released config_mutex in update_configuration().\" << std::endl;\n}\n\n// Example thread functions\nvoid* thread_logger_task(void* arg) {\n    Logger* logger = get_logger();\n    logger->log(\"Hello from logger thread!\");\n    return NULL;\n}\n\nvoid* thread_config_task(void* arg) {\n    update_configuration();\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n\n    std::cout << \"Starting threads...\" << std::endl;\n    pthread_create(&t1, NULL, thread_logger_task, NULL);\n    pthread_create(&t2, NULL, thread_config_task, NULL);\n\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n\n    std::cout << \"Threads finished.\" << std::endl;\n\n    // Clean up\n    delete g_logger_instance; // Only if initialized\n    pthread_mutex_destroy(&logger_init_mutex);\n    pthread_mutex_destroy(&config_mutex);\n\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "101.1", "text": "זהו את בעיית הסנכרון הקיימת בקוד. תארו כיצד הבעיה יכולה להתרחש באמצעות רצף אירועים ספציפי הכולל את שני החוטים (t1 ו-t2).", "code_snippet": null, "options": null}, {"id": "101.2", "text": "תקנו את הקוד על מנת לפתור את בעיית הסנכרון שזיהיתם. הסבירו בקצרה את הפתרון שלכם ואת השינויים שביצעתם.", "code_snippet": "/* הכניסו כאן את הקוד המתוקן */", "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "### 101.1 זיהוי הבעיה והסבר:\nהבעיה היא **קיפאון (Deadlock)**. קיפאון יכול להתרחש כאשר שני חוטים או יותר ממתינים זה לזה למשאב שהשני מחזיק בו, ויוצרים מעגל המתנה.\n\n**רצף אירועים המוביל לקיפאון:**\n1.  **חוט t1 (מריץ את `thread_logger_task`):** קורא לפונקציה `get_logger()`. הוא מגלה ש-`g_logger_instance` הוא `NULL`.\n2.  **חוט t1:** נועל את `logger_init_mutex`. (כעת t1 מחזיק ב-`logger_init_mutex`).\n3.  **חוט t1:** מתחיל את יצירת אובייקט `Logger` על ידי קריאה ל-`new Logger()`.\n4.  **חוט t1 (בתוך הקונסטרוקטור של `Logger`):** מנסה לנעול את `config_mutex`. כעת הוא ממתין ל-`config_mutex`.\n\n5.  **חוט t2 (מריץ את `thread_config_task`):** קורא לפונקציה `update_configuration()`.\n6.  **חוט t2:** נועל את `config_mutex`. (כעת t2 מחזיק ב-`config_mutex`).\n7.  **חוט t2:** מנסה לנעול את `logger_init_mutex`. כעת הוא ממתין ל-`logger_init_mutex`.\n\n**תוצאה:**\n*   חוט t1 מחזיק ב-`logger_init_mutex` וממתין ל-`config_mutex`.\n*   חוט t2 מחזיק ב-`config_mutex` וממתין ל-`logger_init_mutex`.\n\nשני החוטים חסומים באופן הדדי, ונוצר מצב של קיפאון. אף אחד מהם לא יכול להמשיך, והתוכנית תיתקע.\n\n### 101.2 תיקון הקוד:\nהבעיה נובעת מכך שהחוטים מנסים לנעול את המנעולים בסדר שונה: `get_logger` נועל את `logger_init_mutex` ואז מנסה לנעול את `config_mutex` (דרך הקונסטרוקטור), בעוד ש-`update_configuration` נועל את `config_mutex` ואז מנסה לנעול את `logger_init_mutex`. כדי למנוע קיפאון, יש להקפיד על סדר אחיד של נעילת מנעולים בכל מקום בתוכנית.\n\n**פתרון:** נשנה את סדר נעילת המנעולים בפונקציה `update_configuration()` כך שתמיד ינעל קודם את `logger_init_mutex` ולאחר מכן את `config_mutex`. לחלופין, ניתן לשנות את הקונסטרוקטור של `Logger` כך שינעל את `config_mutex` רק *לאחר* ש-`logger_init_mutex` שוחרר, אך זה מסובך יותר ודורש שינוי לוגיקה של Double-Checked Locking. הסדר העדיף הוא לשנות את `update_configuration` כדי להתאים לסדר של `get_logger` (או להיפך), תוך שמירה על סדר עקבי.\n\n**שינויים שבוצעו:**\nהקוד של `update_configuration()` שונה כך שסדר נעילת המנעולים יהיה זהה לסדר המרומז ב-`get_logger()` (כלומר, קודם `logger_init_mutex` ואז `config_mutex`).\n\n```c\n#include <iostream>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\n// Global mutex for lazy initialization of Logger\npthread_mutex_t logger_init_mutex = PTHREAD_MUTEX_INITIALIZER;\n// Global mutex for configuration access (used by Logger constructor and update_configuration)\npthread_mutex_t config_mutex = PTHREAD_MUTEX_INITIALIZER;\n\nclass Logger {\npublic:\n    Logger() {\n        // Simulate expensive initialization requiring config_mutex\n        pthread_mutex_lock(&config_mutex); // This is still the internal order for Logger init\n        std::cout << \"Logger constructor: Acquiring config_mutex for expensive initialization...\" << std::endl;\n        sleep(2); // Simulate long initialization\n        std::cout << \"Logger constructor: Finished expensive initialization and releasing config_mutex.\" << std::endl;\n        pthread_mutex_unlock(&config_mutex);\n    }\n\n    void log(const char* message) {\n        std::cout << \"Log message: \" << message << std::endl;\n    }\n};\n\n// The singleton instance\nLogger* g_logger_instance = NULL;\n\n// Function to get the singleton Logger instance\nLogger* get_logger() {\n    if (g_logger_instance == NULL) { // First check (no lock)\n        pthread_mutex_lock(&logger_init_mutex);\n        if (g_logger_instance == NULL) { // Second check (with lock)\n            std::cout << \"Thread \" << pthread_self() << \": Initializing Logger...\" << std::endl;\n            g_logger_instance = new Logger(); // Calls Logger constructor\n            std::cout << \"Thread \" << pthread_self() << \": Logger initialized.\" << std::endl;\n        }\n        pthread_mutex_unlock(&logger_init_mutex);\n    }\n    return g_logger_instance;\n}\n\n// Another function that needs config_mutex then logger_init_mutex\nvoid update_configuration() {\n    std::cout << \"Thread \" << pthread_self() << \": Entering update_configuration()...\" << std::endl;\n    \n    // FIX: Changed lock order to prevent deadlock. \n    // Now it always locks logger_init_mutex first, then config_mutex.\n    pthread_mutex_lock(&logger_init_mutex);\n    std::cout << \"Thread \" << pthread_self() << \": Acquired logger_init_mutex in update_configuration().\" << std::endl;\n    sleep(1); // Simulate some work\n\n    pthread_mutex_lock(&config_mutex);\n    std::cout << \"Thread \" << pthread_self() << \": Acquired config_mutex in update_configuration().\" << std::endl;\n    // Perform configuration update that might involve checking logger state or similar\n    // For simplicity, just simulate work.\n    sleep(1);\n    \n    pthread_mutex_unlock(&config_mutex);\n    std::cout << \"Thread \" << pthread_self() << \": Released config_mutex in update_configuration().\" << std::endl;\n    \n    pthread_mutex_unlock(&logger_init_mutex);\n    std::cout << \"Thread \" << pthread_self() << \": Released logger_init_mutex in update_configuration().\" << std::endl;\n}\n\n// Example thread functions\nvoid* thread_logger_task(void* arg) {\n    Logger* logger = get_logger();\n    logger->log(\"Hello from logger thread!\");\n    return NULL;\n}\n\nvoid* thread_config_task(void* arg) {\n    update_configuration();\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n\n    std::cout << \"Starting threads...\" << std::endl;\n    pthread_create(&t1, NULL, thread_logger_task, NULL);\n    pthread_create(&t2, NULL, thread_config_task, NULL);\n\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n\n    std::cout << \"Threads finished.\" << std::endl;\n\n    // Clean up\n    delete g_logger_instance; // Only if initialized\n    pthread_mutex_destroy(&logger_init_mutex);\n    pthread_mutex_destroy(&config_mutex);\n\n    return 0;\n}\n```\n\n**הערה:** חשוב לציין שהפתרון הזה (שינוי סדר הנעילה ב-`update_configuration`) עובד מכיוון שהוא מייצר סדר נעילה גלובלי אחיד: תמיד `logger_init_mutex` ואז `config_mutex` (או רק אחד מהם). אם היה צורך אמיתי לנעול את `config_mutex` לפני `logger_init_mutex` ב-`update_configuration` מסיבות לוגיות אחרות, היה צריך לשקול פתרונות מורכבים יותר כמו `trylock` או שימוש ב-`std::call_once` ב-C++11 ומעלה כדי להימנע מנעילת `logger_init_mutex` באופן ישיר ב-`get_logger` לאחר האתחול הראשון."}, "difficulty_estimation": "Hard", "_source_file": "0287__Mutexes__CodeAnalysis__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:34:39", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Synchronization", "Mutexes", "Concurrency", "Deadlocks"], "content": {"text": "נתונה מערכת עם שני משאבים משותפים, resourceA ו-resourceB, המיוצגים על ידי משתני int. כל משאב מוגן על ידי מוטקס משלו: mutexA עבור resourceA ו-mutexB עבור resourceB.\nהמערכת כוללת שתי פונקציות: transfer_A_to_B(int amount) ו-transfer_B_to_A(int amount), המיועדות להעביר כמות מסוימת של ערך בין המשאבים באופן מאובטח. כלומר, transfer_A_to_B מפחיתה את amount מ-resourceA ומוסיפה אותו ל-resourceB, ו-transfer_B_to_A מבצעת את הפעולה ההפוכה. שתי הפונקציות מיועדות לרוץ במקביל על ידי חוטים שונים.\nלהלן מימוש הפונקציות:\n\nהקוד המתואר אינו תקין ויכול להוביל לבעיה חמורה כאשר הפונקציות נקראות במקביל על ידי חוטים שונים.\n1. תארו מהי הבעיה וכיצד היא יכולה להתרחש (יש לתאר ריצה ברורה עם מספר חוטים כרצונכם).\n2. תקנו את מימוש הפונקציות transfer_A_to_B ו-transfer_B_to_A כך שיעבדו באופן תקין וימנעו את הבעיה. יש לשנות את סדר תפיסת המוטקסים בלבד, ללא הוספת משתנים או אובייקטי סנכרון נוספים.", "code_snippet": "```c\n#include <pthread.h>\n#include <unistd.h> // for sleep\n\n// משאבים משותפים\nint resourceA = 100;\nint resourceB = 100;\n\n// מוטקסים להגנה על המשאבים\npthread_mutex_t mutexA;\npthread_mutex_t mutexB;\n\n// פונקציה להעברת כמות מ-A ל-B\nvoid transfer_A_to_B(int amount) {\n    pthread_mutex_lock(&mutexA);\n    sleep(1); // מדמה עבודה או החלפת הקשר\n    pthread_mutex_lock(&mutexB);\n\n    resourceA -= amount;\n    resourceB += amount;\n\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n}\n\n// פונקציה להעברת כמות מ-B ל-A\nvoid transfer_B_to_A(int amount) {\n    pthread_mutex_lock(&mutexB);\n    sleep(1); // מדמה עבודה או החלפת הקשר\n    pthread_mutex_lock(&mutexA);\n\n    resourceB -= amount;\n    resourceA += amount;\n\n    pthread_mutex_unlock(&mutexA);\n    pthread_mutex_unlock(&mutexB);\n}\n```"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. הבעיה: קיפאון (Deadlock).\n   הבעיה יכולה להתרחש כאשר שני חוטים מנסים לבצע פעולות העברה במקביל, כאשר כל אחד מהם תופס מוטקס אחד וממתין למוטקס השני שנתפס על ידי החוט האחר. לדוגמה:\n\n   *   **חוט 1** קורא ל-`transfer_A_to_B(10)`:\n       *   תופס את `mutexA`.\n       *   מתבצעת `sleep(1)` (מדמה עבודה או החלפת הקשר).\n   *   **חוט 2** קורא ל-`transfer_B_to_A(10)` (במקביל לחוט 1, בזמן שחוט 1 ב-`sleep`):\n       *   תופס את `mutexB`.\n       *   מתבצעת `sleep(1)` (מדמה עבודה או החלפת הקשר).\n   *   **חוט 1** מנסה כעת לתפוס את `mutexB` אך הוא חסום, מכיוון ש-`mutexB` נתפס על ידי חוט 2.\n   *   **חוט 2** מנסה כעת לתפוס את `mutexA` אך הוא חסום, מכיוון ש-`mutexA` נתפס על ידי חוט 1.\n\n   בנקודה זו, שני החוטים חסומים באופן הדדי וממתינים זה לזה לשחרר את המוטקס שהם זקוקים לו. אף אחד מהם לא יכול להמשיך, והמערכת נכנסת למצב של קיפאון.\n\n2. תיקון: כדי למנוע קיפאון, יש להקפיד על סדר אחיד של תפיסת מוטקסים בכל הפונקציות שצריכות לתפוס מספר מוטקסים. במקרה זה, נקבע שכל הפונקציות יתפסו תמיד את `mutexA` לפני `mutexB`.\n\n   ```c\n// פונקציה להעברת כמות מ-A ל-B (ללא שינוי בסדר תפיסת המוטקסים)\nvoid transfer_A_to_B(int amount) {\n    pthread_mutex_lock(&mutexA);\n    pthread_mutex_lock(&mutexB); // תמיד תופסים את mutexA לפני mutexB\n\n    resourceA -= amount;\n    resourceB += amount;\n\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n}\n\n// פונקציה להעברת כמות מ-B ל-A (תיקון סדר תפיסת המוטקסים)\nvoid transfer_B_to_A(int amount) {\n    pthread_mutex_lock(&mutexA); // תופסים קודם את mutexA\n    pthread_mutex_lock(&mutexB); // ואז את mutexB\n\n    resourceB -= amount;\n    resourceA += amount;\n\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n}\n   ```\n   הסבר לתיקון: על ידי אכיפת סדר קבוע (למשל, תמיד `mutexA` ואז `mutexB`), אנו מבטיחים שלעולם לא ייווצר מצב שבו חוט אחד מחזיק ב-`mutexA` וממתין ל-`mutexB` בעוד חוט אחר מחזיק ב-`mutexB` וממתין ל-`mutexA`. חוטים תמיד ינסו לתפוס את המוטקסים באותו סדר, וכך אם חוט אחד כבר תפס את `mutexA`, כל חוט אחר שינסה לתפוס את `mutexA` יחסם עד ש-`mutexA` ישוחרר, ובכך נמנע את מעגל ההמתנה ההדדית שגורם לקיפאון."}, "difficulty_estimation": "Hard", "_source_file": "0288__Mutexes__CodeAnalysis__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:35:04", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Synchronization", "Semaphores"], "content": {"text": "מהי המטרה העיקרית של סמפור (Semaphore)?", "code_snippet": null, "options": ["א. לניהול תזמון מעבד (CPU scheduling).", "ב. לתקשורת בין תהליכים (IPC).", "ג. לסנכרון גישה למשאבים משותפים.", "ד. להקצאת זיכרון."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "ג'. סמפורים משמשים בעיקר כמנגנון סנכרון המאפשר בקרת גישה למשאבים משותפים (כגון קטעים קריטיים) ופתרון בעיות סנכרון בין תהליכים או חוטים, ובכך מונעים תנאי מרוץ (race conditions)."}, "difficulty_estimation": "Easy", "_source_file": "0289__Semaphores__MultipleChoice__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:35:11", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization", "Mutual Exclusion"], "content": {"text": "מהו הערך ההתחלתי המתאים לסמפור בינארי המשמש להבטחת הדדיות (mutual exclusion) באזור קריטי?", "code_snippet": null, "options": ["א. 0", "ב. 1", "ג. -1", "ד. כל מספר שלם חיובי", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. סמפור בינארי המשמש ל-mutual exclusion (הדדיות) צריך להתחיל עם ערך 1. ערך זה מאפשר לתהליך אחד להיכנס לאזור הקריטי. כאשר תהליך קורא לפעולת wait (או P), ערך הסמפור יורד ל-0, וחוסם כניסה של תהליכים נוספים. כאשר התהליך מסיים וקורא לפעולת signal (או V), ערך הסמפור עולה חזרה ל-1, ומאפשר לתהליך הבא להיכנס."}, "difficulty_estimation": "Easy", "_source_file": "0290__Semaphores__MultipleChoice__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:35:18", "_subject": "Concurrency"}, {"id": 2, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization", "Critical Section"], "content": {"text": "מהו הערך ההתחלתי הנכון של סמפור בינארי המשמש להגנה על קטע קריטי (critical section) יחיד?", "code_snippet": null, "options": ["א. 0", "ב. 1", "ג. -1", "ד. כל ערך חיובי", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הסבר: סמפור בינארי המשמש להדדיות בלעדית (mutual exclusion) על קטע קריטי צריך להיות מאותחל ל-1. זה מאפשר לתהליך אחד בלבד להיכנס לקטע הקריטי על ידי ביצוע פעולת wait (המפחיתה את ערך הסמפור ל-0). תהליכים נוספים שינסו להיכנס יחסמו עד שהתהליך שבקטע הקריטי יבצע פעולת signal (המגדילה את ערך הסמפור בחזרה ל-1)."}, "difficulty_estimation": "Easy", "_source_file": "0291__Semaphores__MultipleChoice__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:35:26", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization"], "content": {"text": "מהי מטרתה העיקרית של פעולת ה-wait (או P) על סמפור?", "code_snippet": null, "options": ["א. להגדיל את ערך הסמפור.", "ב. להקטין את ערך הסמפור, ואם ערכו הופך לשלילי, לחסום את התהליך הקורא.", "ג. לשחרר משאב שהתהליך תפס.", "ד. לאתחל את הסמפור לערך מסוים.", "ה. לאפשר לתהליכים לעקוף את מנגנון הסנכרון."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "פעולת ה-wait (או P) על סמפור נועדה לבקש גישה למשאב או להיכנס לקטע קריטי. היא מקטינה את ערך הסמפור. אם לאחר ההקטנה ערך הסמפור שלילי, המשמעות היא שהמשאב אינו זמין (או הקטע הקריטי תפוס), והתהליך הקורא נחסם עד שפעולת signal תשחרר משאב ותגדיל את ערך הסמפור, מה שיאפשר לתהליך להמשיך."}, "difficulty_estimation": "Easy", "_source_file": "0292__Semaphores__MultipleChoice__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:35:34", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization", "Concurrency"], "content": {"text": "מהו הערך ההתחלתי הנכון לסמפור בינארי המשמש להגנה על קטע קריטי (critical section) מפני כניסה בו זמנית של מספר תהליכים?", "code_snippet": null, "options": ["א. 0", "ב. 1", "ג. -1", "ד. כל מספר חיובי גדול מ-1", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הסמפור הבינארי משמש למנגנון הרחקה הדדית (mutual exclusion). כאשר הוא מוגדר לערך 1, הוא מאפשר לתהליך אחד בלבד להיכנס לקטע הקריטי. התהליך הראשון שנכנס מבצע פעולת wait/P ומקטין את ערך הסמפור ל-0. כל תהליך נוסף שינסה להיכנס יחסם (ייכנס למצב המתנה) עד שהתהליך הראשון יצא ויבצע פעולת signal/V, מה שיחזיר את ערך הסמפור ל-1 ויאפשר לתהליך אחר להיכנס."}, "difficulty_estimation": "Easy", "_source_file": "0293__Semaphores__MultipleChoice__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:35:42", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization"], "content": {"text": "איזה ערך התחלתי יש לתת לסמפור בינארי (binary semaphore) המשמש להגנה על קטע קריטי (critical section) באמצעות מנגנון הדדיות (mutual exclusion)?", "code_snippet": null, "options": ["א. 0", "ב. 1", "ג. -1", "ד. כל ערך חיובי", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. סמפור בינארי המשמש להדדיות (mutual exclusion) על קטע קריטי מאותחל לערך 1. ערך זה מאפשר לתהליך אחד להיכנס לקטע הקריטי (על ידי ביצוע פעולת wait שמקטינה את ערך הסמפור ל-0), ומונע מתהליכים נוספים להיכנס עד שהתהליך הנוכחי יוצא מהקטע הקריטי (על ידי ביצוע פעולת signal שמגדילה את ערך הסמפור חזרה ל-1)."}, "difficulty_estimation": "Easy", "_source_file": "0294__Semaphores__MultipleChoice__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:35:47", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization"], "content": {"text": "מהי המטרה העיקרית של שימוש בסמפור בינארי (binary semaphore) במערכת הפעלה?", "code_snippet": null, "options": ["א. לספור את מספר המשאבים הזמינים במערכת.", "ב. להבטיח גישה בלעדית (mutual exclusion) לקטע קריטי (critical section).", "ג. לתזמן את ביצוע התהליכים (process scheduling).", "ד. לנהל את הקצאת הזיכרון הפיזי (physical memory allocation)."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "סמפור בינארי (המכונה לעיתים גם mutex) משמש בעיקר להבטחת גישה בלעדית לקטע קריטי. מטרתו היא לוודא שרק תהליך אחד יבצע את הקטע הקריטי בכל רגע נתון, ובכך למנוע תנאי מרוץ (race conditions) ולשמור על עקביות הנתונים המשותפים."}, "difficulty_estimation": "Easy", "_source_file": "0295__Semaphores__MultipleChoice__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:35:55", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization", "Mutual Exclusion"], "content": {"text": "מהו הערך ההתחלתי הנכון של סמפור בינארי המשמש להבטחת הדרה הדדית (mutual exclusion)?", "code_snippet": null, "options": ["א. 0", "ב. 1", "ג. -1", "ד. כל ערך חיובי", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "סמפור בינארי המיועד להבטחת הדרה הדדית (mutual exclusion) בין חלקים קריטיים של קוד צריך להיות מאותחל לערך 1. ערך זה מציין שהמשאב פנוי וחוט אחד יכול להיכנס לאזור הקריטי. כאשר חוט נכנס, הוא מבצע פעולת wait (P) שמורידה את ערך הסמפור ל-0, ובכך חוסמת חוטים אחרים מלהיכנס. כאשר החוט יוצא מהאזור הקריטי, הוא מבצע פעולת signal (V) שמחזירה את הערך ל-1, ומאפשרת לחוט אחר להיכנס."}, "difficulty_estimation": "Easy", "_source_file": "0296__Semaphores__MultipleChoice__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:36:02", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization"], "content": {"text": "נתון סמפור מונה (counting semaphore) בשם `resource_access` אשר מאותחל לערך `3`. מספר תהליכים מנסים לגשת למשאב משותף המוגן על ידי סמפור זה. כל תהליך מבצע `wait(&resource_access)` לפני הכניסה לאזור קריטי ו-`signal(&resource_access)` ביציאה ממנו.\nבהינתן ש-2 תהליכים כבר נמצאים בתוך האזור הקריטי, וכעת 5 תהליכים *נוספים* מנסים להיכנס לאזור הקריטי (כלומר, מבצעים `wait()`), מה יהיה ערכו הסופי של הסמפור `resource_access` מיד לאחר שכל 5 התהליכים הנוספים ינסו לבצע `wait()`?", "code_snippet": null, "options": ["א. 1", "ב. 0", "ג. -2", "ד. -4", "ה. אף אחת מהתשובות אינה נכונה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "הסמפור `resource_access` מאותחל לערך 3.\nכאשר 2 תהליכים כבר נמצאים באזור הקריטי, פירוש הדבר שהם ביצעו בהצלחה פעולת `wait()` מבלי לבצע עדיין `signal()`.\nלכן, ערכו של הסמפור יורד ב-2: `3 - 2 = 1`.\n\nכעת, 5 תהליכים *נוספים* מנסים להיכנס לאזור הקריטי (מבצעים `wait()`):\n1. התהליך הראשון מתוך ה-5 מבצע `wait()`: ערך הסמפור יורד ל-`1 - 1 = 0`. תהליך זה נכנס לאזור הקריטי.\n2. התהליך השני מתוך ה-5 מבצע `wait()`: ערך הסמפור יורד ל-`0 - 1 = -1`. תהליך זה נחסם (blocked).\n3. התהליך השלישי מתוך ה-5 מבצע `wait()`: ערך הסמפור יורד ל-`-1 - 1 = -2`. תהליך זה נחסם.\n4. התהליך הרביעי מתוך ה-5 מבצע `wait()`: ערך הסמפור יורד ל-`-2 - 1 = -3`. תהליך זה נחסם.\n5. התהליך החמישי מתוך ה-5 מבצע `wait()`: ערך הסמפור יורד ל-`-3 - 1 = -4`. תהליך זה נחסם.\n\nלכן, הערך הסופי של הסמפור `resource_access` יהיה -4."}, "difficulty_estimation": "Medium", "_source_file": "0297__Semaphores__MultipleChoice__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:36:22", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Semaphores"], "content": {"text": "נתון סמפור (semaphore) בשם S שאותחל לערך 3.\nבמהלך ביצוע התוכנית, התרחשו הפעולות הבאות:\n- 5 קריאות לפונקציה wait(S)\n- 3 קריאות לפונקציה signal(S)\nבהנחה שאין פעולות נוספות על הסמפור וכל הקריאות בוצעו במלואן, מה יהיה ערכו הסופי של הסמפור S?", "code_snippet": null, "options": ["א. 0", "ב. 1", "ג. 2", "ד. -1", "ה. 3"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הסמפור S מאותחל לערך 3.\n\nכל קריאה ל-wait(S) מורידה את ערך הסמפור ב-1. אם ערך הסמפור הופך שלילי, התהליך הקורא נחסם. מספר שלילי מציין כמה תהליכים חסומים ממתינים.\nכל קריאה ל-signal(S) מעלה את ערך הסמפור ב-1. אם ערך הסמפור היה שלילי (כלומר, היו תהליכים חסומים), אחד מהם משוחרר.\n\nנתחיל עם S = 3.\n\nלאחר 5 קריאות wait(S):\n1. S = 2\n2. S = 1\n3. S = 0\n4. S = -1 (תהליך נחסם)\n5. S = -2 (תהליך נוסף נחסם)\nבשלב זה, ערך הסמפור הוא -2, ושני תהליכים חסומים.\n\nלאחר 3 קריאות signal(S):\n1. S = -1 (תהליך אחד משוחרר)\n2. S = 0 (התהליך השני משוחרר)\n3. S = 1 (אין תהליכים חסומים, הערך פשוט עולה)\n\nלכן, ערכו הסופי של הסמפור יהיה 1."}, "difficulty_estimation": "Medium", "_source_file": "0298__Semaphores__MultipleChoice__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:37:05", "_subject": "Concurrency"}, {"id": 4, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization", "Critical Section"], "content": {"text": "נתונה מערכת הפעלה שבה שני תהליכים, P1 ו-P2, מנסים לגשת למשאב משותף X. הם משתמשים בסמפור בינארי בשם `mutex` שאותחל ל-1. להלן קטעי הקוד המתארים את פעולתם:", "code_snippet": "sem_t mutex; // Global semaphore variable\n\nvoid init_sem() {\n    sem_init(&mutex, 0, 1); // Initialize mutex to 1 (binary semaphore)\n}\n\nvoid P1_task() {\n    sem_wait(&mutex); // Wait for the semaphore\n    // Critical Section: Access shared resource X\n    printf(\"Process P1 is accessing shared resource X.\\n\");\n    sem_post(&mutex); // Signal (release) the semaphore\n}\n\nvoid P2_task() {\n    sem_wait(&mutex); // Wait for the semaphore\n    // Critical Section: Access shared resource X\n    printf(\"Process P2 is accessing shared resource X.\\n\");\n    sem_post(&mutex); // Signal (release) the semaphore\n}\n\n// Assuming init_sem() is called once before P1_task and P2_task are run concurrently.", "options": ["א. שני התהליכים יכולים לגשת למשאב X בו-זמנית, מה שיוביל לתנאי מרוץ.", "ב. רק תהליך אחד יכול לגשת למשאב X בכל רגע נתון.", "ג. אחד התהליכים יגרום ל-deadlock עבור התהליך השני.", "ד. הגישה למשאב X אינה מובטחת, וקריאות `sem_wait` עשויות להיכשל.", "ה. הסמפור ימנע גישה למשאב X לצמיתות עבור אחד התהליכים עקב רעב (starvation)."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. סמפור בינארי המאותחל ל-1 משמש כמנעול (mutex) להגנה על קטע קריטי. כאשר תהליך קורא ל-`sem_wait()` (או `P()`), הוא מקטין את ערך הסמפור. אם ערכו הופך ל-0, תהליכים אחרים שיקראו ל-`sem_wait()` יחסמו עד שהתהליך הנוכחי יקרא ל-`sem_post()` (או `V()`) וישחרר את הסמפור. לכן, רק תהליך אחד יכול להימצא בקטע הקריטי (הגישה למשאב X) בכל רגע נתון, ובכך נמנעים תנאי מרוץ ומובטחת הדדיות (mutual exclusion)."}, "difficulty_estimation": "Medium", "_source_file": "0299__Semaphores__MultipleChoice__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:37:28", "_subject": "Concurrency"}, {"id": 4, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization"], "content": {"text": "נתון סמפור `s` שהאותחל לערך `3`.\nשלושה תהליכים (P1, P2, P3) מבצעים את הפעולות הבאות בסדר המתואר:\n1. P1 מבצע `wait(s)`\n2. P2 מבצע `wait(s)`\n3. P3 מבצע `signal(s)`\n4. P1 מבצע `wait(s)`\n5. P2 מבצע `signal(s)`\n\nמהו ערכו הסופי של הסמפור `s` לאחר כל הפעולות הללו?\n(הניחו שפעולות `wait` ו-`signal` הינן אטומיות).", "code_snippet": null, "options": ["א. 0", "ב. 1", "ג. 2", "ד. 3", "ה. 4"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "נבצע מעקב אחר ערך הסמפור `s`:\n1. ערך התחלתי: `s = 3`\n2. P1 מבצע `wait(s)`: `s` יורד ל-`2`.\n3. P2 מבצע `wait(s)`: `s` יורד ל-`1`.\n4. P3 מבצע `signal(s)`: `s` עולה ל-`2`.\n5. P1 מבצע `wait(s)`: `s` יורד ל-`1`.\n6. P2 מבצע `signal(s)`: `s` עולה ל-`2`.\n\nלכן, הערך הסופי של הסמפור `s` הוא `2`."}, "difficulty_estimation": "Medium", "_source_file": "0300__Semaphores__MultipleChoice__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:38:06", "_subject": "Concurrency"}, {"id": 4, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization", "Mutual Exclusion"], "content": {"text": "נתון קטע קוד המשתמש במנגנון סמפור (Semaphore) להגנה על משאב משותף. איזה מההצהרות הבאות מתארת נכונה את מטרת השימוש בסמפור בקטע קוד זה?", "code_snippet": "#include <semaphore.h>\n#include <pthread.h>\n#include <stdio.h>\n\nsem_t mutex;\nint shared_resource = 0;\n\nvoid* thread_func(void* arg) {\n    sem_wait(&mutex); // P operation\n    // Critical section\n    shared_resource++;\n    printf(\"Thread %ld: shared_resource = %d\\n\", (long)pthread_self(), shared_resource);\n    sem_post(&mutex); // V operation\n    return NULL;\n}\n\nint main() {\n    sem_init(&mutex, 0, 1); // Initialize semaphore for mutual exclusion\n    pthread_t t1, t2;\n\n    pthread_create(&t1, NULL, thread_func, NULL);\n    pthread_create(&t2, NULL, thread_func, NULL);\n\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n\n    sem_destroy(&mutex);\n    return 0;\n}", "options": ["א. להבטיח שרק תהליך אחד יבצע את פעולת ההדפסה בכל רגע נתון.", "ב. למנוע מצב שבו שני תהליכים ניגשים למשתנה shared_resource בו-זמנית.", "ג. לסנכרן את סדר ההדפסה של התהליכים כך שתהליך t1 תמיד ידפיס לפני t2.", "ד. להגביל את מספר הפעמים שניתן להגדיל את shared_resource לשניים בלבד.", "ה. לאפשר לתהליכים להמתין זה לזה עד ששניהם יסיימו את הפעולה הקריטית."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הסמפור 'mutex' מאותחל לערך 1, מה שהופך אותו לסמפור בינארי (mutex). הפעולה 'sem_wait(&mutex)' מונעת מתהליכים נוספים להיכנס לקטע הקריטי אם תהליך אחר כבר נמצא בו (מורידה את ערך הסמפור ל-0 וגורמת לתהליכים אחרים להמתין). הפעולה 'sem_post(&mutex)' משחררת את הסמפור ומאפשרת לתהליך ממתין להיכנס (מעלה את ערך הסמפור ל-1). לכן, מטרתו העיקרית היא להבטיח שבכל רגע נתון רק תהליך אחד יוכל לגשת למשתנה המשותף 'shared_resource' ולבצע עליו פעולות, ובכך למנוע תנאי מרוץ (race condition) ולוודא עקביות נתונים. אפשרות א' נכונה חלקית כיוון שההדפסה נמצאת בתוך הקטע הקריטי, אך המטרה העיקרית היא הגנה על המשאב המשותף עצמו."}, "difficulty_estimation": "Medium", "_source_file": "0301__Semaphores__MultipleChoice__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:38:19", "_subject": "Concurrency"}, {"id": 4, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization"], "content": {"text": "נתון סמפור (semaphore) בשם `my_semaphore` אשר איתחלנו לערך 3. חמישה תהליכים (threads) מנסים לבצע פעולת `sem_wait(&my_semaphore)`. כמה תהליכים לכל היותר יוכלו לעבור את פעולת ה-`sem_wait` ולהיכנס לקטע הקריטי באופן מיידי, בטרם יתבצעו פעולות `sem_post` כלשהן?", "code_snippet": "sem_t my_semaphore;\nsem_init(&my_semaphore, 0, 3); // Initial value is 3\n\n// Five threads concurrently try to execute:\n// sem_wait(&my_semaphore);\n// // Critical section code\n// sem_post(&my_semaphore);", "options": ["א. 1", "ב. 2", "ג. 3", "ד. 5", "ה. אף תשובה אינה נכונה"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "סמפור המאותחל לערך N מאפשר ל-N תהליכים להיכנס לקטע קריטי (או להשתמש במשאב) באופן מיידי. במקרה זה, הסמפור אותחל לערך 3, ולכן שלושה תהליכים יוכלו לבצע `sem_wait` בהצלחה ולעבור לקטע הקריטי. התהליכים הרביעי והחמישי יחסמו עד שאחד מהתהליכים שכבר נכנסו יבצע `sem_post` וישחרר 'אישור' (permit)."}, "difficulty_estimation": "Medium", "_source_file": "0302__Semaphores__MultipleChoice__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:38:32", "_subject": "Concurrency"}, {"id": 4, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization"], "content": {"text": "סמפור ספירה (counting semaphore) בשם S מאותחל לערך 2. בהמשך, מתבצעות הפעולות הבאות:\n1. שלושה תהליכים (T1, T2, T3) קוראים לפונקציה sem_wait(&S).\n2. לאחר מכן, שני תהליכים (T4, T5) קוראים לפונקציה sem_post(&S).\n\nבהנחה שהפעולות מתבצעות בסדר זה, מהו הערך הסופי של הסמפור S לאחר שכל הפעולות הושלמו, וכמה תהליכים נשארו חסומים (blocked)?", "code_snippet": null, "options": ["א. ערך סופי של S: 1, מספר תהליכים חסומים: 0", "ב. ערך סופי של S: 0, מספר תהליכים חסומים: 1", "ג. ערך סופי של S: 2, מספר תהליכים חסומים: 0", "ד. ערך סופי של S: -1, מספר תהליכים חסומים: 1", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "נסקור את השלבים והשפעתם על ערך הסמפור ומספר התהליכים החסומים:\n\n1.  **אתחול**: הסמפור S מאותחל לערך 2.\n\n2.  **פעולות sem_wait**: שלושה תהליכים (T1, T2, T3) קוראים ל-sem_wait(&S):\n    *   T1 קורא ל-sem_wait: S יורד ל-1. T1 ממשיך.\n    *   T2 קורא ל-sem_wait: S יורד ל-0. T2 ממשיך.\n    *   T3 קורא ל-sem_wait: S יורד ל-1-. מכיוון שערך הסמפור הפך לשלילי, T3 נחסם.\n    בשלב זה: S = -1, ותהליך אחד (T3) חסום.\n\n3.  **פעולות sem_post**: שני תהליכים (T4, T5) קוראים ל-sem_post(&S):\n    *   T4 קורא ל-sem_post: S עולה ל-0. מכיוון שערך הסמפור היה לא חיובי (0 או שלילי), תהליך אחד חסום (T3) משוחרר (unblocked) ועובר למצב 'מוכן' (ready).\n    *   T5 קורא ל-sem_post: S עולה ל-1. מכיוון שאין תהליכים חסומים כרגע, אף תהליך לא משוחרר.\n\n**מצב סופי**: הערך הסופי של הסמפור S הוא 1. כל התהליכים שנחסמו (רק T3) שוחררו, ולכן אין תהליכים שנשארו חסומים בסוף.\n\nלכן, התשובה הנכונה היא: ערך סופי של S: 1, מספר תהליכים חסומים: 0."}, "difficulty_estimation": "Medium", "_source_file": "0303__Semaphores__MultipleChoice__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:38:49", "_subject": "Concurrency"}, {"id": 4, "type": "MultipleChoice", "topic": ["Semaphores", "Concurrency", "Deadlock"], "content": {"text": "נתון קטע הקוד הבא המשתמש בסמפור בינארי `mutex` להגנה על משאב משותף. מה תהיה התוצאה הסבירה ביותר כאשר שני תהליכים (threads) ינסו להריץ את `thread_func`?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n\nsem_t mutex;\nint shared_data = 0;\n\nvoid* thread_func(void* arg) {\n    sem_wait(&mutex); // P operation\n    shared_data++;\n    printf(\"Thread %ld: shared_data = %d\\n\", (long)arg, shared_data);\n    sem_post(&mutex); // V operation\n    return NULL;\n}\n\nint main() {\n    sem_init(&mutex, 0, 0); // Initializing to 0\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, thread_func, (void*)1);\n    pthread_create(&t2, NULL, thread_func, (void*)2);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    sem_destroy(&mutex);\n    return 0;\n}", "options": ["א. שני התהליכים יגדילו את `shared_data` פעם אחת כל אחד, והערך הסופי יהיה 2.", "ב. אחד התהליכים יגדיל את `shared_data` ל-1, והתהליך השני ימתין ללא הגבלת זמן.", "ג. שני התהליכים יחסמו (block) וייכנסו למצב של קיפאון (deadlock) ולא יוכלו להתקדם.", "ד. התוכנית תקרוס עקב שימוש לא חוקי בסמפור.", "ה. אף אחת מהתשובות האחרות אינה נכונה."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הסמפור `mutex` מאותחל לערך 0. כאשר תהליך מנסה לבצע פעולת `sem_wait` (P) על סמפור שערכו 0, הוא נחסם וממתין עד שערך הסמפור יהפוך לחיובי (על ידי פעולת `sem_post` - V). במקרה זה, שני התהליכים מנסים לבצע `sem_wait` על סמפור שערכו 0. שניהם ייחסמו באופן מיידי, ומכיוון שאף אחד מהם לא יצליח להגיע לפעולת `sem_post` כדי לשחרר את הסמפור, שניהם יישארו חסומים לעד. מצב זה מוביל לקיפאון (deadlock)."}, "difficulty_estimation": "Medium", "_source_file": "0304__Semaphores__MultipleChoice__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:39:05", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization", "Deadlock"], "content": {"text": "נתון קטע הקוד הבא המשתמש בסמפורים (semaphores) לצורך סנכרון בין שני תהליכונים (threads) שונים.\n\n```c\n#include <semaphore.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // for sleep\n\nsem_t sem_R1;\nsem_t sem_R2;\n\nvoid* taskA(void* arg) {\n    printf(\"TaskA: Trying to acquire R1\\n\");\n    sem_wait(&sem_R1);\n    printf(\"TaskA: Acquired R1, trying to acquire R2\\n\");\n    sleep(1); // Simulate work or context switch\n    sem_wait(&sem_R2);\n    printf(\"TaskA: Acquired R2. Critical section.\\n\");\n    // ... do work ...\n    sem_post(&sem_R2);\n    printf(\"TaskA: Released R2.\\n\");\n    sem_post(&sem_R1);\n    printf(\"TaskA: Released R1.\\n\");\n    return NULL;\n}\n\nvoid* taskB(void* arg) {\n    printf(\"TaskB: Trying to acquire R2\\n\");\n    sem_wait(&sem_R2);\n    printf(\"TaskB: Acquired R2, trying to acquire R1\\n\");\n    sleep(1); // Simulate work or context switch\n    sem_wait(&sem_R1);\n    printf(\"TaskB: Acquired R1. Critical section.\\n\");\n    // ... do work ...\n    sem_post(&sem_R1);\n    printf(\"TaskB: Released R1.\\n\");\n    sem_post(&sem_R2);\n    printf(\"TaskB: Released R2.\\n\");\n    return NULL;\n}\n\nint main() {\n    sem_init(&sem_R1, 0, 1); // Binary semaphore for R1\n    sem_init(&sem_R2, 0, 1); // Binary semaphore for R2\n\n    pthread_t tidA, tidB;\n    pthread_create(&tidA, NULL, taskA, NULL);\n    pthread_create(&tidB, NULL, taskB, NULL);\n\n    pthread_join(tidA, NULL);\n    pthread_join(tidB, NULL);\n\n    sem_destroy(&sem_R1);\n    sem_destroy(&sem_R2);\n    return 0;\n}\n```\nבאיזו בעיה, סביר להניח, נתקל בעת הרצת התוכנית עם שני התהליכונים taskA ו-taskB במקביל?", "code_snippet": null, "options": ["א. התוכנית תמיד תסיים את ריצתה ללא בעיות סנכרון.", "ב. אחד מהתהליכונים עלול לסבול מרעב (starvation) ולא לסיים את משימתו.", "ג. התוכנית עלולה להיכנס למצב של קיפאון (deadlock).", "ד. התוכנית עלולה לסבול מתנאי מרוץ (race condition) שיובילו לנתונים שגויים.", "ה. אף אחת מהטענות לעיל אינה נכונה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "ג. קטע הקוד מדגים תרחיש קלאסי של קיפאון (deadlock). תהליכון `taskA` מנסה לתפוס את `sem_R1` ולאחר מכן את `sem_R2`. לעומתו, תהליכון `taskB` מנסה לתפוס את `sem_R2` ולאחר מכן את `sem_R1`. אם `taskA` יתפוס את `sem_R1` ולאחר מכן, עקב החלפת הקשר (context switch) או תזמון, `taskB` יתפוס את `sem_R2`, שני התהליכונים ינסו לתפוס את הסמפור המוחזק על ידי השני. מצב זה יוצר תלות הדדית מעגלית (circular wait) ומוביל לקיפאון, כאשר אף אחד מהתהליכונים לא יוכל להמשיך."}, "difficulty_estimation": "Hard", "_source_file": "0305__Semaphores__MultipleChoice__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:39:42", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Semaphores", "Concurrency", "Deadlock", "Resource Allocation"], "content": {"text": "נתונה מערכת עם N משאבים זהים. M תהליכים (processes) רצים במקביל, וכל אחד מהם זקוק ל-K משאבים כדי לבצע את עבודתו. המשאבים מנוהלים באמצעות סמפור מונה `resources` המאותחל ל-N. קטע הקוד הבא מתאר את לוגיקת רכישת ושחרור המשאבים עבור כל תהליך:", "code_snippet": "semaphore resources = N; // N total resources\n\nvoid process_func() {\n    // Acquire K resources\n    for (int i = 0; i < K; i++) {\n        wait(resources);\n    }\n\n    // Critical section: Use K resources\n    // ... perform work ...\n\n    // Release K resources\n    for (int i = 0; i < K; i++) {\n        signal(resources);\n    }\n}", "options": ["א. הפתרון מבטיח מניעת קיפאון (deadlock-free).", "ב. הפתרון מבטיח מניעת הרעבה (starvation-free).", "ג. הפתרון עשוי להוביל לקיפאון (deadlock) בתנאים מסוימים.", "ד. הפתרון מבטיח הדדית בלעדיות (mutual exclusion) על כל K המשאבים.", "ה. אף אחת מהטענות האחרות אינה נכונה בהכרח."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התשובה הנכונה היא ג'.\n\nהסבר:\nכאשר K > 1 ורכישת המשאבים מתבצעת באופן סדרתי (wait() K פעמים), נוצר סיכון לקיפאון (deadlock). דמיינו תרחיש שבו N=2 משאבים, M=2 תהליכים, וכל תהליך זקוק ל-K=2 משאבים. \n1. תהליך P1 מבצע wait(resources) פעם אחת. ערך הסמפור יורד ל-1.\n2. תהליך P2 מבצע wait(resources) פעם אחת. ערך הסמפור יורד ל-0.\n3. כעת, P1 מנסה לבצע wait(resources) בפעם השנייה, אך ערך הסמפור הוא 0, ולכן P1 נחסם.\n4. P2 מנסה לבצע wait(resources) בפעם השנייה, אך ערך הסמפור הוא 0, ולכן P2 נחסם גם הוא.\n\nבמצב זה, P1 מחזיק במשאב אחד וממתין למשאב נוסף ש-P2 עשוי להחזיק בו, ו-P2 מחזיק במשאב אחד וממתין למשאב נוסף ש-P1 עשוי להחזיק בו. זוהי דוגמה קלאסית לקיפאון מעגלי (circular wait), שהיא אחד מארבעת התנאים ההכרחיים לקיפאון. לכן, הפתרון עשוי להוביל לקיפאון בתנאים מסוימים.\n\n- א. הפתרון אינו מבטיח מניעת קיפאון, כפי שהודגם לעיל.\n- ב. קיפאון מוביל בהכרח להרעבה, ולכן אם קיפאון אפשרי, הפתרון אינו מבטיח מניעת הרעבה.\n- ד. הסמפור `resources` הוא סמפור מונה המגביל את המספר הכולל של משאבים בשימוש ל-N. הוא אינו מבטיח הדדית בלעדיות על *סט של K משאבים* עבור תהליך בודד, במובן שרק תהליך אחד יכול להחזיק K משאבים בכל רגע נתון. לדוגמה, אם N=4 ו-K=2, שני תהליכים יכולים להחזיק 2 משאבים כל אחד בו-זמנית. לכן, טענה זו אינה נכונה.\n- ה. מכיוון שטענה ג' נכונה, טענה ה' אינה נכונה."}, "difficulty_estimation": "Hard", "_source_file": "0306__Semaphores__MultipleChoice__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:40:06", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Semaphores", "Concurrency", "Race Conditions", "Synchronization"], "content": {"text": "נתון קטע הקוד הבא המשתמש בסמפור מסוג POSIX counting semaphore. הסמפור `mutex` מאותחל לערך 1 (בינארי). שני תהליכונים (threads), `thread_func(0)` ו-`thread_func(1)`, מורצים במקביל. נניח שהחלפות הקשר (context switches) יכולות להתרחש בכל נקודה בין פקודות. מהו הערך הסופי *האפשרי* של `shared_data` לאחר ששני התהליכונים סיימו את ריצתם?", "code_snippet": "#include <semaphore.h>\n#include <pthread.h>\n#include <stdio.h>\n\nsem_t mutex;\nint shared_data = 0;\n\nvoid* thread_func(void* arg) {\n    long id = (long)arg;\n\n    // Critical section 1\n    sem_wait(&mutex);\n    shared_data++;\n    sem_post(&mutex);\n\n    // Conditional extra post by thread 0\n    if (id % 2 == 0) {\n        sem_post(&mutex);\n    }\n\n    // Critical section 2\n    sem_wait(&mutex);\n    shared_data--;\n    sem_post(&mutex);\n\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[2];\n\n    sem_init(&mutex, 0, 1); // Initialize as a binary semaphore\n\n    pthread_create(&threads[0], NULL, thread_func, (void*)0);\n    pthread_create(&threads[1], NULL, thread_func, (void*)1);\n\n    pthread_join(threads[0], NULL);\n    pthread_join(threads[1], NULL);\n\n    sem_destroy(&mutex);\n    printf(\"Final shared_data: %d\\n\", shared_data);\n    return 0;\n}", "options": ["א. 0 בלבד", "ב. 1 בלבד", "ג. 0 או -1", "ד. 1 או -1", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ה", "explanation": "הסמפור `mutex` מאותחל ל-1, ונועד לשמש להדדיות (mutual exclusion). עם זאת, סמפור POSIX counting semaphore יכול לקבל ערכים גדולים מ-1 כאשר `sem_post` נקראת יותר פעמים מ-`sem_wait` (בניגוד ל-mutex רגיל שלא ניתן 'לשחרר' אותו יותר מפעם אחת מבלי לנעול אותו שוב). \n\nנתבונן בשני תהליכונים, `T0` (id=0) ו-`T1` (id=1):\n*   כל תהליכון מבצע שתי פעולות `sem_wait` ושתי פעולות `sem_post` על `mutex` עבור גישה ל`shared_data`.\n*   `T0` מבצע פעולת `sem_post` נוספת (בגלל התנאי `id % 2 == 0`).\n\nבסך הכל, `T0` מבצע 2 `wait` ו-3 `post`. `T1` מבצע 2 `wait` ו-2 `post`. \nהמשמעות היא ש-`T0` 'משחרר' את הסמפור פעם אחת יותר מדי. זהו המקור לבעיה ולמגוון תוצאות אפשריות.\n\n**ניתוח אפשרויות לערך `shared_data`:**\nהערך `shared_data` מתחיל ב-0, עובר שני `++` ושני `--`. אם לא היו תנאי מרוץ, הערך הסופי היה 0. אולם, קריאת ה-`sem_post` הנוספת של `T0` יכולה לשבור את ההדדיות.\n\n1.  **מקרה אפשרי: `shared_data` שווה 0 (ללא תנאי מרוץ קריטי על `shared_data`):**\n    אם ה-`sem_post` הנוסף של `T0` מתרחש אחרי ש`T1` כבר ביצע את שני הבלוקים המוגנים שלו, או אם סדר הריצה לא מאפשר כניסה בו זמנית של שני תהליכונים לבלוקים המוגנים על `shared_data`. לדוגמה:\n    *   `T0` מבצע `wait`, `++` (shared_data=1), `post`.\n    *   `T1` מבצע `wait`, `++` (shared_data=2), `post`.\n    *   `T0` מבצע `post` נוסף (mutex=2).\n    *   `T0` מבצע `wait`, `--` (shared_data=1), `post`.\n    *   `T1` מבצע `wait`, `--` (shared_data=0), `post`.\n    בסיום: `shared_data=0`.\n\n2.  **מקרה אפשרי: `shared_data` שווה 1 (עם תנאי מרוץ):**\n    זה קורה כאשר ה-`sem_post` הנוסף של `T0` גורם לערך של `mutex` לעלות ל-2, מה שמאפשר לשני תהליכונים להיכנס לבלוקים מוגנים בו-זמנית. נניח את סדר הפעולות הבא:\n    *   `T0`: `sem_wait` (mutex=0), `shared_data++` (shared_data=1), `sem_post` (mutex=1).\n    *   `T0`: `sem_post` (mutex=2). (כעת `shared_data=1`, `mutex=2`)\n    *   `T1`: `sem_wait` (mutex=1). (T1 נכנס לבלוק הראשון שלו)\n    *   `T0`: `sem_wait` (mutex=0). (T0 נכנס לבלוק השני שלו, בו-זמנית עם T1)\n    *   בנקודה זו, `shared_data=1`. `T1` עומד לבצע `shared_data++` ו-`T0` עומד לבצע `shared_data--`. זהו תנאי מרוץ קלאסי (read-modify-write).\n    *   **אם הכתיבה של `T1` (shared_data++) מתרחשת אחרי הכתיבה של `T0` (shared_data--):**\n        1.  `T1` קורא `shared_data` (1).\n        2.  `T0` קורא `shared_data` (1).\n        3.  `T0` כותב `shared_data=0`.\n        4.  `T1` כותב `shared_data=2`.\n        (בסיום תנאי המרוץ, `shared_data=2`)\n    *   `T1`: `sem_post` (mutex=1).\n    *   `T0`: `sem_post` (mutex=2).\n    *   `T1`: `sem_wait` (mutex=1), `shared_data--` (shared_data=1), `sem_post` (mutex=2).\n    בסיום: `shared_data=1`.\n\n3.  **מקרה אפשרי: `shared_data` שווה -1 (עם תנאי מרוץ):**\n    נמשיך מהנקודה שבה `shared_data=1`, `mutex=0` ושני התהליכונים בבלוקים המוגנים שלהם בו-זמנית.\n    *   **אם הכתיבה של `T0` (shared_data--) מתרחשת אחרי הכתיבה של `T1` (shared_data++):**\n        1.  `T1` קורא `shared_data` (1).\n        2.  `T0` קורא `shared_data` (1).\n        3.  `T1` כותב `shared_data=2`.\n        4.  `T0` כותב `shared_data=0`.\n        (בסיום תנאי המרוץ, `shared_data=0`)\n    *   `T1`: `sem_post` (mutex=1).\n    *   `T0`: `sem_post` (mutex=2).\n    *   `T1`: `sem_wait` (mutex=1), `shared_data--` (shared_data=-1), `sem_post` (mutex=2).\n    בסיום: `shared_data=-1`.\n\nלסיכום, עקב ה-`sem_post` הנוסף של תהליכון 0, הסמפור יכול לעלות לערך הגדול מ-1, מה שמבטל למעשה את ההדדיות ומאפשר לשני תהליכונים להיכנס לאזורים קריטיים בו-זמנית. הדבר מוביל לתנאי מרוץ על המשתנה `shared_data` שיכול להסתיים בערכים שונים. הערכים האפשריים הם 0, 1 או -1. מכיוון שאף אחת מהאפשרויות א-ד לא מכסה את כל המקרים האפשריים, תשובה ה' היא הנכונה."}, "difficulty_estimation": "Hard", "_source_file": "0307__Semaphores__MultipleChoice__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:41:05", "_subject": "Concurrency"}, {"id": 10, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization", "Mutual Exclusion", "Race Conditions"], "content": {"text": "נתון קטע קוד בשפת C המשתמש בסמפור (semaphore) מסוג `sem_t` כדי להגן על אזור קריטי (critical section). מטרת הקוד היא להבטיח הדדיות (mutual exclusion) על המשתנה `shared_data`. הסמפור מאותחל בערך התחלתי של 2. איזו טענה מהבאות נכונה בנוגע להתנהגות הקוד?", "code_snippet": "#include <semaphore.h>\n#include <pthread.h>\n#include <stdio.h>\n\nsem_t mutex;\nint shared_data = 0;\n\nvoid* worker(void* arg) {\n    // Simulate some work\n    // ...\n    sem_wait(&mutex); // P operation\n    \n    // Critical Section\n    shared_data++;\n    printf(\"Thread %ld: shared_data = %d\\n\", (long)pthread_self(), shared_data);\n    \n    sem_post(&mutex); // V operation\n    // Simulate more work\n    // ...\n    return NULL;\n}\n\nint main() {\n    // Initialization of the semaphore\n    sem_init(&mutex, 0, 2); // !!! The subtle point is here !!!\n    \n    // Create multiple threads\n    pthread_t t1, t2, t3;\n    pthread_create(&t1, NULL, worker, NULL);\n    pthread_create(&t2, NULL, worker, NULL);\n    pthread_create(&t3, NULL, worker, NULL);\n    \n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    pthread_join(t3, NULL);\n    \n    sem_destroy(&mutex);\n    printf(\"Final shared_data: %d\\n\", shared_data);\n    return 0;\n}", "options": ["א. המנגנון יעבוד כשורה ויבטיח הדדיות (mutual exclusion).", "ב. המנגנון יוביל למצב של קיפאון (deadlock).", "ג. המנגנון יאפשר כניסה בו-זמנית של עד שני תהליכים לאזור הקריטי, ובכך יפר את הדדיות (mutual exclusion).", "ד. המנגנון יוביל להרעבה (starvation) של תהליכים."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "סמפור בינארי (או mutex) שמטרתו להבטיח הדדיות (mutual exclusion) חייב להיות מאותחל בערך 1. ערך זה מבטיח שרק תהליך אחד יוכל לבצע `sem_wait` בהצלחה ולהיכנס לאזור הקריטי בכל רגע נתון. כאשר הסמפור מאותחל בערך 2, המשמעות היא ששני תהליכים יכולים לבצע `sem_wait` בהצלחה ולהיכנס לאזור הקריטי בו-זמנית. הדבר מפר את עקרון ההדדיות ועלול להוביל לתנאי מרוץ (race condition) על המשתנה `shared_data` או כל משאב משותף אחר באזור הקריטי."}, "difficulty_estimation": "Hard", "_source_file": "0308__Semaphores__MultipleChoice__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:41:21", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization", "Concurrency", "Critical Section"], "content": {"text": "נתונים N תהליכים (threads) זהים, שכל אחד מהם מבצע את קטע הקוד הבא. במערכת קיימים שני סמפורים: `mutex` מאותחל ל-1, ו-`sync_point` מאותחל ל-0. בנוסף, קיים משתנה גלובלי `counter` המאותחל ל-0.\n\n```c\nvoid thread_func() {\n    // שלב 1\n    wait(mutex);\n    counter++;\n    if (counter == N) {\n        signal(sync_point);\n    }\n    signal(mutex);\n\n    // שלב 2\n    wait(sync_point);\n    // קטע קריטי לאחר מחסום (Critical Section after barrier)\n    // ...\n    signal(sync_point);\n}\n```\n\nבהנחה שכל N התהליכים מופעלים בו-זמנית ורצים עד לסיום. איזו מהטענות הבאות נכונה לגבי ההתנהגות של המערכת?", "code_snippet": "void thread_func() {\n    // שלב 1\n    wait(mutex);\n    counter++;\n    if (counter == N) {\n        signal(sync_point);\n    }\n    signal(mutex);\n\n    // שלב 2\n    wait(sync_point);\n    // קטע קריטי לאחר מחסום (Critical Section after barrier)\n    // ...\n    signal(sync_point);\n}", "options": ["א. רק תהליך אחד יצליח לעבור את הקריאה ל-`wait(sync_point)` ושאר התהליכים ייתקעו לנצח.", "ב. כל N התהליכים יצליחו לעבור את הקריאה ל-`wait(sync_point)` ויבצעו את \"הקטע הקריטי לאחר המחסום\" באופן סדרתי (אחד אחרי השני).", "ג. כל N התהליכים יצליחו לעבור את הקריאה ל-`wait(sync_point)` ויבצעו את \"הקטע הקריטי לאחר המחסום\" באופן מקבילי (בו-זמנית).", "ד. קיימת סכנת קיפאון (deadlock) שבה אף תהליך לא יצליח לעבור את הקריאה ל-`wait(sync_point)`.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הסבר:\n1.  **שלב 1 (הכנת המחסום):** כל N התהליכים מתחרים על גישה ל-`mutex` כדי להגדיל את המונה `counter`. המונה `counter` מוגן על ידי `mutex` ומבטיח שכל תהליך יגדיל אותו פעם אחת בדיוק.\n2.  **שחרור המחסום הראשוני:** התהליך ה-N שמגדיל את `counter` יגרום לתנאי `if (counter == N)` להיות אמיתי. תהליך זה יבצע קריאה ל-`signal(sync_point)`, מה שיגדיל את ערך `sync_point` ל-1 (מ-0). כל שאר התהליכים יבצעו `signal(mutex)` וישחררו אותו.\n3.  **שלב 2 (מעבר המחסום):** לאחר מכן, כל N התהליכים מגיעים לקריאה `wait(sync_point)`.\n    *   **התהליך הראשון:** התהליך הראשון שיגיע ל-`wait(sync_point)` וימצא את `sync_point` בערך 1 (שסומן על ידי התהליך ה-N) יצליח לעבור. ערך `sync_point` יירד ל-0. תהליך זה ייכנס ל\"קטע קריטי לאחר מחסום\".\n    *   **התהליכים הנותרים:** כל N-1 התהליכים האחרים יגיעו ל-`wait(sync_point)` וימצאו שערכו 0, ולכן ייתקעו בהמתנה.\n4.  **שחרור סדרתי:** התהליך היחיד שנמצא ב\"קטע קריטי לאחר מחסום\" יסיים את עבודתו ויבצע `signal(sync_point)`. קריאה זו תגדיל את ערך `sync_point` בחזרה ל-1, ותשחרר אחד מהתהליכים הממתינים. תהליך זה ישחרר שוב את `sync_point`, וכך הלאה.\n5.  **מסקנה:** כתוצאה מכך, כל N התהליכים אכן יעברו את המחסום `wait(sync_point)`, אך לא בו-זמנית. הם יעברו אחד אחרי השני, בסדרתיות, מכיוון שכל `signal(sync_point)` מאפשר רק לתהליך אחד נוסף לעבור. זהו אינו מחסום אמיתי (barrier) שמשחרר את כל התהליכים בבת אחת, אלא יותר מנגנון \"טורניקט\" או \"שער\" שמאפשר מעבר סדרתי לאחר שהאירוע הראשוני (כל התהליכים הגיעו לנקודה מסוימת) התרחש. לכן, טענה ב' נכונה."}, "difficulty_estimation": "Hard", "_source_file": "0309__Semaphores__MultipleChoice__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:41:46", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Semaphores", "Concurrency", "Barrier Synchronization", "Deadlock"], "content": {"text": "נתון קטע קוד בשפת C המממש מחסום (barrier) עבור N תהליכים באמצעות סמפורים. המחסום מיועד לשימוש חוזר (reusable). מהי התוצאה הסבירה ביותר כאשר קוד זה מופעל מספר פעמים על ידי אותם N תהליכים?", "code_snippet": "#include <pthread.h>\n#include <semaphore.h>\n#include <stdio.h>\n\n#define N 5 // מספר התהליכים במחסום\n\nsem_t barrier_sem;\npthread_mutex_t count_mutex; // מנעול להגנה על המונה\nint count = 0;\n\n// יש לאתחל את הסמפורים ואת המוטקס לפני השימוש:\n// sem_init(&barrier_sem, 0, 0); // סמפור המחסום מאותחל ל-0\n// pthread_mutex_init(&count_mutex, NULL); // מוטקס מאותחל ל-1\n\nvoid barrier_wait() {\n    pthread_mutex_lock(&count_mutex); // תפוס מנעול\n    count++;\n    if (count == N) {\n        // התהליך האחרון הגיע\n        for (int i = 0; i < N; ++i) {\n            sem_post(&barrier_sem); // שחרר את כל התהליכים\n        }\n    }\n    pthread_mutex_unlock(&count_mutex); // שחרר מנעול\n\n    sem_wait(&barrier_sem); // המתן לשחרור\n}", "options": ["א. התהליכים יסתנכרנו בהצלחה בכל פעם, אך עלולה להיות בעיית רעב (starvation) לחלק מהם.", "ב. התהליכים יסתנכרנו בהצלחה בפעם הראשונה, אך בשימושים חוזרים חלק מהם ימתינו ללא סוף (deadlock).", "ג. התהליכים יסתנכרנו בהצלחה בפעם הראשונה, אך בשימושים חוזרים חלק מהם יעברו את המחסום מוקדם מדי (race condition).", "ד. הקוד יגרום לקיפאון (deadlock) כבר בניסיון הראשון, מכיוון שהתהליך האחרון אינו ממתין על הסמפור."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "תשובה ב' נכונה. בפעם הראשונה, המחסום יפעל כצפוי: כל N התהליכים יגיעו, המונה `count` יגיע ל-N, התהליך האחרון ישלח N אותות (`sem_post`) לסמפור `barrier_sem`, וכל N התהליכים ימתינו (`sem_wait`) ויעברו את המחסום.\nאולם, הקוד אינו מאפס את המונה `count` לאחר שכל התהליכים עברו את המחסום. לכן, בשימוש חוזר (במחזור השני), כאשר התהליכים יקראו שוב ל-`barrier_wait()`, המונה `count` ימשיך לעלות מעבר ל-N. התנאי `if (count == N)` לעולם לא יתקיים שוב לאחר הפעם הראשונה, ולכן אף תהליך לא ישלח אותות ל-`barrier_sem`. כתוצאה מכך, כל התהליכים ימתינו ללא סוף ב-`sem_wait(&barrier_sem)` מבלי לקבל אותות, מה שיוביל לקיפאון (deadlock)."}, "difficulty_estimation": "Hard", "_source_file": "0310__Semaphores__MultipleChoice__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:42:08", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization", "Concurrency"], "content": {"text": "נתונים שני תהליכונים (threads) וסמפור בינארי S המאותחל ל-0.\nלהלן הקוד של כל תהליכון:\n\n```c\n// גלובלי\nSemaphore S = 0; // בינארי\n\n// קוד תהליכון 1 (T1)\nvoid *thread1_func(void *arg) {\n    wait(S);\n    printf(\"A\\n\");\n    return NULL;\n}\n\n// קוד תהליכון 2 (T2)\nvoid *thread2_func(void *arg) {\n    printf(\"B\\n\");\n    signal(S);\n    return NULL;\n}\n```\n\nאיזו מהטענות הבאות נכונה **תמיד** לגבי פלט התוכנית?", "code_snippet": null, "options": ["א. הפלט \"A\" יודפס תמיד לפני הפלט \"B\".", "ב. הפלט \"B\" יודפס תמיד לפני הפלט \"A\".", "ג. התוכנית עלולה להיכנס למצב קיפאון (deadlock).", "ד. ייתכן שהפלט \"A\" יודפס לפני הפלט \"B\".", "ה. גם ב' וגם ג' נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הסמפור S מאותחל ל-0. תהליכון T1 מבצע wait(S) ראשון. מכיוון ש-S הוא 0, T1 ייחסם וימתין. תהליכון T2 יבצע printf(\"B\\n\") ולאחר מכן signal(S). פעולת ה-signal(S) תגרום ל-S לעלות ל-1 (או תבטל חסימה של תהליכון שהיה חסום על S). רק לאחר ש-T2 ביצע signal(S), תהליכון T1 יוכל להמשיך את פעולתו, כלומר רק לאחר ש-T2 הדפיס 'B'. לכן, הפלט 'B' יודפס תמיד לפני הפלט 'A'. אין מצב קיפאון מכיוון ש-T2 תמיד יבצע signal(S) ויאפשר ל-T1 להמשיך, גם אם T1 נחסם קודם לכן."}, "difficulty_estimation": "Hard", "_source_file": "0311__Semaphores__MultipleChoice__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:42:31", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization", "Deadlock", "Bounded Buffer"], "content": {"text": "נתונה מערכת המשתמשת במאגר חלופי (bounded buffer) בגודל N, ותהליכי יצרן (producer) וצרכן (consumer). לצורך סנכרון וגישה הדדית למאגר, נעשה שימוש בשלושה סמפורים:\n1.  `mutex`: סמפור בינארי, מאותחל ל-1, לגישה הדדית (mutual exclusion) למאגר.\n2.  `empty`: סמפור סופר, מאותחל ל-N, המייצג את מספר המקומות הפנויים במאגר.\n3.  `full`: סמפור סופר, מאותחל ל-0, המייצג את מספר המקומות המלאים במאגר.\n\nקוד היצרן (producer) נראה כך:\n```c\nvoid producer() {\n    while (true) {\n        // produce item\n        wait(mutex);\n        wait(empty);\n        // add item to buffer\n        signal(full);\n        signal(mutex);\n    }\n}\n```\nוקוד הצרכן (consumer) נראה כך:\n```c\nvoid consumer() {\n    while (true) {\n        wait(full);\n        wait(mutex);\n        // remove item from buffer\n        signal(mutex);\n        signal(empty);\n        // consume item\n    }\n}\n```\nאיזו מהטענות הבאות נכונה לגבי התנהגות המערכת במצב זה?", "code_snippet": null, "options": ["א. המערכת תפעל באופן תקין וללא בעיות סנכרון או קיפאון כלשהן.", "ב. המערכת עלולה להיכנס למצב קיפאון (deadlock) אם המאגר יתמלא לחלוטין.", "ג. המערכת עלולה להיכנס למצב קיפאון (deadlock) אם המאגר יתרוקן לחלוטין.", "ד. המערכת תאפשר גישה בו-זמנית למאגר (race condition) ובכך תפגע בשלמות הנתונים.", "ה. המערכת תמיד תעבוד, אך תהיה לא יעילה בשל סדר הפעולות השגוי בקוד היצרן."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. סדר הפעולות בקוד היצרן שגוי. אם המאגר יתמלא לחלוטין, סמפור `empty` יהיה שווה ל-0. תהליך יצרן שיגיע בשלב זה יבצע `wait(mutex)`, יתפוס את המנעול, ולאחר מכן יבצע `wait(empty)`. מכיוון ש-`empty` הוא 0, היצרן יחסם (block) תוך כדי שהוא מחזיק את ה-`mutex`. כעת, אף תהליך צרכן לא יוכל לגשת למאגר כדי להסיר פריט (ולבצע `signal(empty)`), מכיוון שה-`mutex` תפוס על ידי היצרן החסום. מצב זה יוביל לקיפאון (deadlock). סדר הפעולות הנכון ליצרן הוא: `wait(empty); wait(mutex); // add item; signal(mutex); signal(full);`."}, "difficulty_estimation": "Hard", "_source_file": "0312__Semaphores__MultipleChoice__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:42:46", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Semaphores", "Synchronization", "Concurrency"], "content": {"text": "מהו סמפור (Semaphore) וכיצד הוא משמש לפתרון בעיות סנכרון במערכות הפעלה? הסבירו את שתי הפעולות העיקריות שלו (P/wait ו-V/signal) ותנו דוגמה קצרה לשימוש בסמפור להשגת הדדיות בלעדית (Mutual Exclusion) בקטע קריטי (Critical Section).", "code_snippet": "/* Conceptual C/C++ code demonstrating semaphore usage for mutual exclusion */\n\n// הגדרת סמפור בינארי, מאותחל ל-1\n// (בהתאם לספרייה או מימוש, זה עשוי להיות sem_t mutex; sem_init(&mutex, 0, 1);)\nSemaphore mutex = 1; \n\nvoid critical_section_access() {\n    wait(mutex); // פעולת P: הקטנת הסמפור, המתנה אם ערכו 0\n    \n    // תחילת הקטע הקריטי\n    // קוד שניגש למשאב משותף (לדוגמה: עדכון משתנה גלובלי)\n    // ...\n    // סוף הקטע הקריטי\n    \n    signal(mutex); // פעולת V: הגדלת הסמפור, שחרור תהליכים ממתינים\n}\n\n// בתוכנית מרובת תרדדים, כל תרד יקרא ל-critical_section_access()\n// ויוודא גישה בלעדית למשאב המשותף.", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "סמפור (Semaphore) הוא משתנה שלם (integer variable) המוגן מפני גישה בו-זמנית, ומשמש ככלי סנכרון בסיסי במערכות הפעלה לפתרון בעיות של תחרות (race conditions) והדדיות בלעדית (mutual exclusion) בין תהליכים או תרדדים. הוא מאפשר לשלוט בגישה למשאבים משותפים או לתאם את סדר הפעולות.\n\nשתי הפעולות העיקריות שלו הן:\n1.  **P (או `wait()`)**: פעולה זו מנסה להקטין את ערך הסמפור באחד. אם ערך הסמפור הנוכחי הוא 0, התהליך הקורא לפעולה נחסם וממתין בתור עד שערך הסמפור יהפוך לחיובי (או גדול מ-0) ויתאפשר להקטין אותו. אם ערך הסמפור גדול מ-0, הוא מוקטן מיד והתהליך ממשיך. פעולה זו מבטיחה שרק מספר מוגבל של תהליכים (לפי ערך הסמפור ההתחלתי) יוכלו להמשיך.\n2.  **V (או `signal()`)**: פעולה זו מגדילה את ערך הסמפור באחד. אם ישנם תהליכים החסומים וממתינים על הסמפור (כתוצאה מפעולת P קודמת), אחד מהם ישוחרר ויוכל להמשיך בביצוע (כלומר, לבצע את פעולת ה-P שחסמה אותו).\n\n**דוגמה לשימוש בסמפור להשגת הדדיות בלעדית (Mutual Exclusion) בקטע קריטי:**\nכדי להבטיח שרק תהליך אחד ייכנס לקטע קריטי (חלק בקוד הניגש למשאב משותף) בכל רגע נתון, ניתן להשתמש בסמפור בינארי (סמפור שערכו יכול להיות רק 0 או 1).\n*   מאתחלים סמפור בשם `mutex` (קיצור של mutual exclusion) לערך 1.\n*   לפני הכניסה לקטע הקריטי, כל תהליך מבצע פעולת `wait(mutex)`.\n    *   התהליך הראשון שיבצע `wait(mutex)` יקטין את ערך `mutex` ל-0 וימשיך לקטע הקריטי.\n    *   כל תהליך נוסף שינסה להיכנס לקטע הקריטי (כלומר, יבצע `wait(mutex)`) ימצא את `mutex` בערך 0, ולכן ייחסם וימתין.\n*   לאחר סיום הקטע הקריטי, התהליך שביצע אותו מבצע פעולת `signal(mutex)`.\n    *   פעולה זו מגדילה את ערך `mutex` בחזרה ל-1, ואם ישנם תהליכים ממתינים, אחד מהם ישוחרר ויורשה להיכנס לקטע הקריטי.\n\n**דוגמת קוד:** (כפי שהוצג בשאלה)"}, "difficulty_estimation": "Easy", "_source_file": "0313__Semaphores__Open__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:43:03", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Semaphores", "Concurrency", "Synchronization", "Mutual Exclusion"], "content": {"text": "מהו סמפור? הסבירו את שתי הפעולות העיקריות שלו (P/wait ו-V/signal). כיצד ניתן להשתמש בסמפור להשגת הדדית (mutual exclusion) עבור קטע קריטי?", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "סמפור הוא כלי סנכרון המהווה משתנה שלם, אשר מלבד אתחול, ניתן לגשת אליו רק באמצעות שתי פעולות אטומיות סטנדרטיות: wait() ו-signal().\n\n**פעולות הסמפור:**\n*   **wait() (או P):** פעולה זו מקטינה את ערך הסמפור. אם ערך הסמפור הופך שלילי, התהליך המבצע את הפעולה נחסם (מוכנס לרשימת המתנה) עד שערך הסמפור יהפוך לחיובי (כלומר, משאב יהיה זמין).\n*   **signal() (או V):** פעולה זו מגדילה את ערך הסמפור. אם ישנם תהליכים חסומים הממתינים על סמפור זה, אחד מהם משוחרר (מתעורר) ומוכן לביצוע.\n\n**שימוש בסמפור להשגת הדדית (Mutual Exclusion) עבור קטע קריטי:**\nכדי להבטיח שרק תהליך אחד ייכנס לקטע קריטי בכל רגע נתון, ניתן להשתמש בסמפור בינארי (הנקרא לעיתים קרובות mutex). הנה השלבים:\n1.  **אתחול:** יוצרים סמפור בינארי ומאתחלים את ערכו ל-1. (לדוגמה: `semaphore mutex = 1;`)\n2.  **לפני הכניסה לקטע הקריטי:** כל תהליך שרוצה להיכנס לקטע הקריטי מבצע את פעולת `wait()` על הסמפור. לדוגמה: `wait(mutex);`\n    *   אם `mutex` הוא 1, הוא הופך ל-0 והתהליך נכנס לקטע הקריטי.\n    *   אם `mutex` הוא 0, התהליך נחסם וממתין עד ש-`mutex` יהפוך שוב ל-1.\n3.  **לאחר היציאה מהקטע הקריטי:** כל תהליך שיוצא מהקטע הקריטי מבצע את פעולת `signal()` על הסמפור. לדוגמה: `signal(mutex);`\n    *   פעולה זו מגדילה את ערך `mutex` ל-1, ובכך מאפשרת לתהליך אחר (אם יש כזה ממתין) להיכנס לקטע הקריטי.\n\nבצורה זו, הסמפור מבטיח שרק תהליך אחד יוכל לעבור את ה-`wait(mutex)` ולהיכנס לקטע הקריטי, וכל שאר התהליכים ימתינו מחוץ לו."}, "difficulty_estimation": "Easy", "_source_file": "0314__Semaphores__Open__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:43:14", "_subject": "Concurrency"}, {"id": 7, "type": "Open", "topic": ["Semaphores", "Concurrency", "Synchronization"], "content": {"text": "הסבירו מהו סמפור (Semaphore) וכיצד הוא משמש לסנכרון בין תהליכים (או ת'רדים). פרטו את פעולות הבסיס שלו (`wait`/`P` ו-`signal`/`V`) והדגימו שימוש פשוט בסמפור בינארי (mutex) כדי להגן על קטע קריטי (critical section).", "code_snippet": "/* C/C++ style pseudocode using POSIX semaphores */\n#include <semaphore.h>\n#include <stdio.h>\n\nsem_t mutex; // A binary semaphore (mutex)\n\n// Initialize the semaphore\nvoid init_semaphore() {\n    // sem_init(semaphore, pshared, value)\n    // pshared = 0 for threads in the same process\n    // value = 1 for a binary semaphore (mutex) initially unlocked\n    sem_init(&mutex, 0, 1);\n}\n\n// Function demonstrating critical section protection\nvoid access_critical_section() {\n    // P operation: acquire the lock\n    sem_wait(&mutex);\n\n    // Critical section: code that accesses shared resources\n    printf(\"Thread/Process entered critical section.\\n\");\n    // ... perform operations on shared data ...\n    printf(\"Thread/Process exiting critical section.\\n\");\n\n    // V operation: release the lock\n    sem_post(&mutex);\n}\n\n// Example of how it might be used\nint main() {\n    init_semaphore();\n    // Multiple threads/processes could call access_critical_section()\n    access_critical_section();\n    // ... other calls ...\n    sem_destroy(&mutex); // Clean up the semaphore\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "סמפור הוא כלי סנכרון המאפשר לתהליכים (או ת'רדים) לשתף משאבים מוגבלים או לתאם את פעולותיהם. הוא מורכב ממשתנה שלם (integer variable) שניתן לגשת אליו רק באמצעות שתי פעולות אטומיות (שאינן ניתנות להפרעה): `wait` (הידועה גם כ-`P` או `down`) ו-`signal` (הידועה גם כ-`V` או `up`).\n\n**פעולות הבסיס:**\n1.  **`wait` (או `P`)**: פעולה זו מורידה את ערך הסמפור באחד. אם ערך הסמפור הופך שלילי, התהליך הקורא לפעולה נחסם ונכנס לתור המתנה של הסמפור, עד שיוכל להמשיך. פעולה זו משמשת בדרך כלל לפני כניסה לקטע קריטי או לפני גישה למשאב.\n2.  **`signal` (או `V`)**: פעולה זו מעלה את ערך הסמפור באחד. אם ערך הסמפור קטן או שווה לאפס (מה שמעיד על כך שיש תהליכים חסומים בתור), אחד מהתהליכים החסומים משוחרר ומועבר למצב מוכן (ready). פעולה זו משמשת בדרך כלל לאחר יציאה מקטע קריטי או לאחר שחרור משאב.\n\n**סמפור בינארי (Mutex) והגנה על קטע קריטי:**\nסמפור בינארי הוא סמפור שערכו יכול להיות רק 0 או 1. הוא משמש במיוחד להשגת הדדיות בלעדית (mutual exclusion) בקטעים קריטיים, כלומר להבטיח שרק תהליך אחד יבצע את הקטע הקריטי בכל רגע נתון.\nכדי להגן על קטע קריטי באמצעות סמפור בינארי, יש לאתחל את הסמפור לערך 1. לפני הכניסה לקטע הקריטי, כל תהליך מבצע פעולת `wait` על הסמפור. אם הסמפור הוא 1, הוא הופך ל-0 והתהליך נכנס. אם הסמפור כבר 0 (כי תהליך אחר נמצא בקטע הקריטי), התהליך נחסם. לאחר היציאה מהקטע הקריטי, התהליך מבצע פעולת `signal` על הסמפור, מה שמחזיר את ערכו ל-1 ומשחרר תהליך חסום (אם יש כזה).\n\n**הדגמה בקוד:**\nהקוד המצורף מדגים שימוש בסמפור בינארי (mutex) כדי להגן על קטע קריטי. הסמפור `mutex` מאותחל ל-1. הפונקציה `sem_wait(&mutex)` מנסה לרכוש את המנעול (להיכנס לקטע הקריטי). אם המנעול פנוי (ערך הסמפור 1), הוא הופך ל-0 והתהליך ממשיך. אם המנעול תפוס (ערך הסמפור 0), התהליך נחסם. לאחר סיום העבודה בקטע הקריטי, הפונקציה `sem_post(&mutex)` משחררת את המנעול (מעלה את ערך הסמפור ל-1), ובכך מאפשרת לתהליך אחר להיכנס לקטע הקריטי."}, "difficulty_estimation": "Easy", "_source_file": "0315__Semaphores__Open__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:43:28", "_subject": "Concurrency"}, {"id": 7, "type": "Open", "topic": ["Semaphores", "Concurrency", "Synchronization"], "content": {"text": "מהו סמפור (Semaphore) במערכת הפעלה? הסבר את מטרתו, את שתי הפעולות הבסיסיות שלו (wait/P ו-signal/V), ותאר בקצרה כיצד ניתן להשתמש בו למימוש הדדיות (Mutual Exclusion) ולסנכרון בין תהליכים.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "סמפור הוא משתנה שלם (integer variable) המאפשר שליטה על גישה למשאבים משותפים בין תהליכים מקבילים. הוא משמש לפתרון בעיות סנכרון ותיאום במערכות הפעלה.\n\nהפעולות הבסיסיות של סמפור הן:\n1.  **wait (נקרא גם P או down)**: פעולה זו מקטינה את ערך הסמפור באחד. אם ערך הסמפור הופך שלילי, התהליך המבצע את הפעולה נחסם (מוכנס לרשימת המתנה) עד שסמפור יגדל. פעולה זו היא אטומית.\n2.  **signal (נקרא גם V או up)**: פעולה זו מגדילה את ערך הסמפור באחד. אם יש תהליכים חסומים ברשימת ההמתנה של הסמפור, אחד מהם משוחרר (מועבר למצב מוכן). פעולה זו היא אטומית.\n\nשימושים עיקריים:\n*   **הדדיות (Mutual Exclusion)**: כדי להבטיח שרק תהליך אחד ייכנס לקטע קריטי (critical section) בכל רגע נתון, ניתן להשתמש בסמפור בינארי (מוטקס - mutex) המאותחל ל-1. לפני הכניסה לקטע הקריטי, תהליך יבצע `wait()` על הסמפור. לאחר היציאה מהקטע הקריטי, הוא יבצע `signal()` על הסמפור.\n    ```c\n    semaphore mutex = 1;\n\n    void process() {\n        // ...\n        wait(mutex); // Enter critical section\n        // Critical Section Code\n        signal(mutex); // Exit critical section\n        // ...\n    }\n    ```\n*   **סנכרון (Synchronization)**: סמפורים יכולים לשמש לסנכרון אירועים בין תהליכים. לדוגמה, תהליך א' יכול לאותת לתהליך ב' שאירוע מסוים התרחש. סמפור ספירה (counting semaphore) יכול לאותחל ל-0. תהליך א' יבצע `signal()` כשהאירוע מתרחש, ותהליך ב' יבצע `wait()` לפני שהוא ממשיך, ובכך יבטיח שהאירוע התרחש.\n    ```c\n    semaphore event_occurred = 0; // Initialize to 0\n\n    // Process A\n    void producer() {\n        // ... produce item\n        signal(event_occurred); // Signal that item is ready\n        // ...\n    }\n\n    // Process B\n    void consumer() {\n        // ...\n        wait(event_occurred); // Wait for item to be ready\n        // ... consume item\n    }\n    ```"}, "difficulty_estimation": "Easy", "_source_file": "0316__Semaphores__Open__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:43:39", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Semaphores", "Concurrency", "Mutual Exclusion"], "content": {"text": "הסבירו כיצד ניתן להשתמש בסמפור בינארי (binary semaphore) כדי להבטיח מניעה הדדית (mutual exclusion) עבור קטע קריטי (critical section) בין מספר תהליכונים (threads) המנסים לגשת אליו. תארו את הפעולות הנדרשות ואת הערך ההתחלתי של הסמפור.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "סמפור בינארי הוא סמפור שיכול לקבל רק את הערכים 0 או 1. הוא משמש בדרך כלל למניעה הדדית (mutual exclusion), כלומר להבטיח שרק תהליכון אחד (או תהליך) יוכל לגשת למשאב משותף או להיכנס לקטע קריטי בנקודת זמן נתונה.\n\nכדי להבטיח מניעה הדדית לקטע קריטי באמצעות סמפור בינארי, נבצע את השלבים הבאים:\n1.  **אתחול הסמפור**: ניצור סמפור בינארי אחד ונאתחל אותו לערך 1. ערך זה מציין שהקטע הקריטי פנוי וזמין לכניסה.\n2.  **כניסה לקטע הקריטי**: לפני הכניסה לקטע הקריטי, כל תהליכון המעוניין לגשת אליו יבצע את פעולת ה-`wait()` (או `P()`) על הסמפור. פעולה זו בודקת את ערך הסמפור:\n    *   אם ערך הסמפור הוא 1, הוא מוקטן ל-0, והתהליכון רשאי להיכנס לקטע הקריטי.\n    *   אם ערך הסמפור הוא 0, זה אומר שהקטע הקריטי תפוס על ידי תהליכון אחר. במקרה זה, התהליכון המנסה להיכנס נחסם (מוכנס לתור המתנה) עד שערך הסמפור יחזור ל-1.\n3.  **יציאה מהקטע הקריטי**: לאחר שהתהליכון סיים את עבודתו בתוך הקטע הקריטי, הוא יבצע את פעולת ה-`signal()` (או `V()`) על הסמפור. פעולה זו מגדילה את ערך הסמפור ב-1 (מחזירה אותו ל-1). אם היו תהליכונים חסומים הממתינים על הסמפור, אחד מהם ישוחרר (יועבר למצב 'מוכן') ויוכל לנסות להיכנס לקטע הקריטי.\n\n**דוגמה קוד (C/C++):**\n```c\nsemaphore mutex = 1; // אתחול הסמפור הבינארי ל-1\n\nvoid worker_thread() {\n    // ... עבודה אחרת שהתהליכון מבצע ...\n\n    wait(mutex); // נסה להיכנס לקטע הקריטי (P(mutex))\n\n    // ===================================\n    // קטע קריטי: גישה למשאב משותף\n    // רק תהליכון אחד יכול להיות כאן בו-זמנית\n    // ===================================\n\n    signal(mutex); // צא מהקטע הקריטי (V(mutex))\n\n    // ... עבודה אחרת שהתהליכון מבצע ...\n}\n```\nבצורה זו, הסמפור `mutex` משמש כמנעול. כאשר ערכו 1, המנעול פתוח. כאשר תהליכון נכנס, הוא 'נועל' את המנעול (מציב את הערך 0). תהליכונים אחרים שמגיעים למנעול 'נעול' נחסמים. כאשר התהליכון היוצא 'פותח' את המנעול (מציב את הערך 1), תהליכון חסום אחד יכול להיכנס."}, "difficulty_estimation": "Easy", "_source_file": "0317__Semaphores__Open__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:43:52", "_subject": "Concurrency"}, {"id": 7, "type": "Open", "topic": ["Semaphores", "Concurrency", "Synchronization"], "content": {"text": "הסבירו מהו סמפור (Semaphore) וכיצד הוא משמש לפתרון בעיות סנכרון במערכות הפעלה. תארו את הפעולות הבסיסיות שלו.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "סמפור (Semaphore) הוא משתנה שלם המשמש לפתרון בעיות סנכרון בין תהליכים (או תהליכונים) במערכת הפעלה. הוא מאפשר לתאם גישה למשאבים משותפים ולשלוט על סדר הפעולות. הגישה לסמפור מתבצעת אך ורק באמצעות שתי פעולות אטומיות (בלתי ניתנות להפרעה):\n\n-   **wait() / P()**: פעולה זו מקטינה את ערך הסמפור באחד. אם ערך הסמפור הופך שלילי (או אפס, תלוי במימוש), התהליך המבצע את הפעולה נחסם ומחכה עד שערך הסמפור יהפוך חיובי (כלומר, המשאב יהיה זמין שוב).\n-   **signal() / V()**: פעולה זו מגדילה את ערך הסמפור באחד. אם ישנם תהליכים חסומים הממתינים על הסמפור, אחד מהם משוחרר (מתעורר) וממשיך בביצוע.\n\n**שימושים עיקריים:**\n1.  **הדדיות (Mutual Exclusion)**: סמפור בינארי (שמכונה לעיתים קרובות מוטקס - Mutex) מאותחל ל-1. תהליך מבצע `wait()` לפני כניסה לקטע קריטי (Critical Section) ומבצע `signal()` ביציאה ממנו. זה מבטיח שרק תהליך אחד ייכנס לקטע הקריטי בכל רגע נתון, ובכך מונע מצבי מרוץ (Race Conditions).\n2.  **סנכרון כללי / סדר פעולות**: סמפור ספירה (Counting Semaphore) מאותחל ל-0 או לערך אחר. תהליך אחד מבצע `signal()` כאשר אירוע מסוים מתרחש או כאשר משאב זמין, ותהליך אחר מבצע `wait()` כדי להמתין לאירוע זה או לזמינות המשאב לפני שהוא ממשיך בביצוע. לדוגמה, סנכרון בין מפיק לצרכן."}, "difficulty_estimation": "Easy", "_source_file": "0318__Semaphores__Open__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:44:04", "_subject": "Concurrency"}, {"id": 7, "type": "Open", "topic": ["Semaphores", "Concurrency", "Synchronization"], "content": {"text": "מהו סמפור (Semaphore) ומה תפקידו במערכות הפעלה? הסבירו בקצרה את פעולת הפרימיטיבים P (wait) ו-V (signal).", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "סמפור (Semaphore) הוא כלי סנכרון (Synchronization Tool) המשמש לפתרון בעיות קטע קריטי (Critical Section) ובעיות סנכרון נוספות במערכות הפעלה. הוא משתנה שלם שניתן לגשת אליו (למעט אתחול) רק באמצעות שתי פעולות אטומיות סטנדרטיות: P (wait) ו-V (signal).\n\n**תפקיד הסמפור:**\n*   **הגנה על קטעים קריטיים:** למנוע ממספר תהליכים לגשת בו-זמנית למשאב משותף או לקטע קוד שאינו ניתן לביצוע מקביל.\n*   **סנכרון תהליכים:** לאפשר לתהליכים לתאם את פעולותיהם, למשל, שתהליך אחד ימתין עד שתהליך אחר יסיים משימה מסוימת.\n\n**פעולת הפרימיטיבים:**\n\n*   **פעולת P (או wait):**\n    *   מקטינה את ערך הסמפור באחד.\n    *   אם ערך הסמפור הופך שלילי, התהליך שקרא ל-P נחסם (מוכנס לרשימת המתנה) עד שערך הסמפור יהפוך לא שלילי (כלומר, המשאב יהיה זמין).\n    *   מבטיחה שרק מספר מוגבל של תהליכים (או תהליך אחד עבור סמפור בינארי) יוכלו להיכנס לקטע קריטי או לגשת למשאב בו-זמנית.\n\n*   **פעולת V (או signal):**\n    *   מגדילה את ערך הסמפור באחד.\n    *   אם יש תהליכים חסומים על הסמפור הזה (כלומר, ערכו היה שלילי לפני ההגדלה), אחד מהם משוחרר (מועבר למצב מוכן לריצה).\n    *   מאותתת שתהליך סיים להשתמש במשאב או יצא מקטע קריטי, ובכך מאפשרת לתהליכים אחרים להמשיך."}, "difficulty_estimation": "Easy", "_source_file": "0319__Semaphores__Open__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:44:16", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Semaphores", "Concurrency", "Synchronization"], "content": {"text": "הסבירו מהו סמפור (Semaphore) במערכות הפעלה. תארו את שתי הפעולות העיקריות הקשורות לסמפור, וכיצד ניתן להשתמש בסמפור על מנת לממש מנגנון של Mutual Exclusion (הדדיות בלעדית) בין תהליכים.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "סמפור הוא משתנה שלם (integer variable) המשמש למנגנון סנכרון בין תהליכים (או תהליכונים) במערכת הפעלה. הוא מאפשר לשלוט בגישה למשאבים משותפים ולהבטיח תיאום בין פעולות קונקורנטיות. הגישה למשתנה הסמפור מתבצעת באופן אטומי (atomic), כלומר, הפעולות עליו אינן ניתנות להפרעה.\n\nשתי הפעולות העיקריות הקשורות לסמפור הן:\n1.  **wait()** (או P(), acquire()): פעולה זו מקטינה את ערך הסמפור באחד. אם ערך הסמפור הופך שלילי (או 0 במקרה של סמפור בינארי שכבר ב-0), התהליך הקורא לפעולה נחסם וממתין עד שערך הסמפור יגדל על ידי תהליך אחר. (לרוב, אם הערך הופך שלילי, זה מציין כמה תהליכים ממתינים).\n2.  **signal()** (או V(), release()): פעולה זו מגדילה את ערך הסמפור באחד. אם ישנם תהליכים חסומים הממתינים על סמפור זה, אחד מהם ישוחרר ויוכל להמשיך בביצוע.\n\n**שימוש בסמפור למימוש Mutual Exclusion:**\nכדי לממש Mutual Exclusion (הדדיות בלעדית) לאזור קריטי (Critical Section), נשתמש בסמפור בינארי (הנקרא לעיתים קרובות mutex) המאותחל לערך 1. כל תהליך המעוניין להיכנס לאזור הקריטי יבצע את הפעולות הבאות:\n\n1.  **לפני הכניסה לאזור הקריטי:** יקרא לפעולת `wait()` על הסמפור.\n    *   אם הסמפור היה 1, הוא יהפוך ל-0, והתהליך יורשה להיכנס לאזור הקריטי.\n    *   אם הסמפור היה 0 (כלומר, תהליך אחר כבר נמצא באזור הקריטי), התהליך הקורא ל-`wait()` יחסם וימתין.\n2.  **לאחר היציאה מהאזור הקריטי:** יקרא לפעולת `signal()` על הסמפור.\n    *   פעולה זו תגדיל את ערך הסמפור ל-1 (אם לא היו תהליכים ממתינים) או תשחרר תהליך חסום אחד (אם היו כאלה), שיורשה כעת להיכנס לאזור הקריטי.\n\nבדרך זו, רק תהליך אחד יכול להיכנס לאזור הקריטי בכל רגע נתון, מה שמבטיח Mutual Exclusion."}, "difficulty_estimation": "Easy", "_source_file": "0320__Semaphores__Open__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:44:33", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Synchronization", "Semaphores", "Producer-Consumer"], "content": {"text": "נתון מאגר (buffer) מעגלי בגודל N המשותף למספר תהליכי יצרן (Producers) ותהליכי צרכן (Consumers). תהליכי היצרן מוסיפים פריטים למאגר, ותהליכי הצרכן מוציאים פריטים מהמאגר. בנוסף, קיים תהליך לוגר (Logger) יחיד. תהליך הלוגר צריך לרשום ללוג אך ורק פריטים שכבר הוצאו מהמאגר על ידי תהליך צרכן. עליו להמתין אם אין פריטים שהוצאו וטרם נרשמו ללוג.\n\nיש לממש את הפעולות `produce_item`, `consume_item` ו-`log_item` באמצעות סמפורים (semaphores) ומנעולי הדדיות (mutexes) בלבד, כך שהסנכרון בין התהליכים יתבצע בצורה נכונה. יש להניח שפעולות הוספה/הוצאה למאגר ורישום ללוג (שאינן קשורות לסנכרון) כבר ממומשות ואינן דורשות קוד. ציינו גם את הגדרת המשתנים הגלובליים הנדרשים ואת אתחולם.", "code_snippet": "typedef int item_type; // Placeholder for actual item type\n\n#define N 10 // Buffer size\n\nitem_type buffer[N];\nint head = 0;\nint tail = 0;\n\n// Declare semaphores and mutex here\nsem_t empty_slots;\nsem_t full_slots;\nsem_t consumed_for_logging;\npthread_mutex_t buffer_mutex;\n\n// Function to initialize synchronization primitives\nvoid init_sync_primitives() {\n    sem_init(&empty_slots, 0, N);\n    sem_init(&full_slots, 0, 0);\n    sem_init(&consumed_for_logging, 0, 0);\n    pthread_mutex_init(&buffer_mutex, NULL);\n}\n\n// Function to destroy synchronization primitives (for completeness, not required by question)\nvoid destroy_sync_primitives() {\n    sem_destroy(&empty_slots);\n    sem_destroy(&full_slots);\n    sem_destroy(&consumed_for_logging);\n    pthread_mutex_destroy(&buffer_mutex);\n}\n\nvoid produce_item(item_type item_to_produce) {\n    // Implement producer logic here\n}\n\nitem_type consume_item() {\n    // Implement consumer logic here\n    return 0; // Placeholder return\n}\n\nvoid log_item() {\n    // Implement logger logic here\n}"}, "sub_questions": null, "points": 15, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "הפתרון הנכון כולל שימוש בשלושה סמפורים ובמנעול הדדי אחד:\n\n1.  `empty_slots`: סמפור זה סופר את מספר המקומות הפנויים במאגר. הוא מאותחל ל-N (גודל המאגר) ומנוהל על ידי היצרנים (מבצעים `sem_wait`) והצרכנים (מבצעים `sem_post`).\n2.  `full_slots`: סמפור זה סופר את מספר הפריטים המלאים במאגר. הוא מאותחל ל-0 ומנוהל על ידי היצרנים (מבצעים `sem_post`) והצרכנים (מבצעים `sem_wait`).\n3.  `consumed_for_logging`: סמפור זה סופר את מספר הפריטים שצרכנים הוציאו מהמאגר וטרם נרשמו ללוג. הוא מאותחל ל-0 ומנוהל על ידי הצרכנים (מבצעים `sem_post` לאחר הוצאת פריט) ועל ידי תהליך הלוגר (מבצע `sem_wait`).\n4.  `buffer_mutex`: מנעול הדדי זה משמש להגנה על הגישה למאגר המשותף (הכנסה/הוצאה של פריטים ועדכון מונים `head`, `tail`) כדי למנוע מצבי מירוץ.\n\nהקוד המלא עבור הפעולות הוא כדלקמן:\n\n```c\n#include <semaphore.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\ntypedef int item_type; // Placeholder for actual item type\n\n#define N 10 // Buffer size\n\nitem_type buffer[N];\nint head = 0; // Index for consumer\nint tail = 0; // Index for producer\n\n// Declare semaphores and mutex here\nsem_t empty_slots;\nsem_t full_slots;\nsem_t consumed_for_logging;\npthread_mutex_t buffer_mutex;\n\n// Function to initialize synchronization primitives\nvoid init_sync_primitives() {\n    sem_init(&empty_slots, 0, N); // N empty slots initially\n    sem_init(&full_slots, 0, 0); // 0 full slots initially\n    sem_init(&consumed_for_logging, 0, 0); // 0 consumed items for logging initially\n    pthread_mutex_init(&buffer_mutex, NULL);\n}\n\n// Function to destroy synchronization primitives (for completeness)\nvoid destroy_sync_primitives() {\n    sem_destroy(&empty_slots);\n    sem_destroy(&full_slots);\n    sem_destroy(&consumed_for_logging);\n    pthread_mutex_destroy(&buffer_mutex);\n}\n\nvoid produce_item(item_type item_to_produce) {\n    sem_wait(&empty_slots); // Wait for an empty slot\n\n    pthread_mutex_lock(&buffer_mutex); // Protect buffer access\n    buffer[tail] = item_to_produce;\n    tail = (tail + 1) % N;\n    pthread_mutex_unlock(&buffer_mutex);\n\n    sem_post(&full_slots); // Signal that a slot is full\n}\n\nitem_type consume_item() {\n    item_type consumed_item;\n\n    sem_wait(&full_slots); // Wait for a full slot\n\n    pthread_mutex_lock(&buffer_mutex); // Protect buffer access\n    consumed_item = buffer[head];\n    head = (head + 1) % N;\n    pthread_mutex_unlock(&buffer_mutex);\n\n    sem_post(&empty_slots); // Signal that a slot is empty\n    sem_post(&consumed_for_logging); // Signal that an item has been consumed and is ready for logging\n\n    return consumed_item; // Return the consumed item (conceptually)\n}\n\nvoid log_item() {\n    sem_wait(&consumed_for_logging); // Wait for an item to be consumed and ready for logging\n\n    // Conceptual logging operation (e.g., printf, write to file)\n    // For this problem, we just need to ensure the timing is correct.\n    // printf(\"Logger: An item was consumed and logged.\\n\");\n}\n```\n\n**הסבר:**\n\n*   **תהליך היצרן (`produce_item`):** לפני הוספת פריט, היצרן ממתין (באמצעות `sem_wait(&empty_slots)`) לוודא שיש מקום פנוי במאגר. לאחר מכן, הוא נועל את ה-`buffer_mutex` כדי לגשת למאגר בבטחה, מוסיף את הפריט, משחרר את המנעול, ומסמן (באמצעות `sem_post(&full_slots)`) שיש כעת פריט נוסף במאגר.\n\n*   **תהליך הצרכן (`consume_item`):** לפני הוצאת פריט, הצרכן ממתין (באמצעות `sem_wait(&full_slots)`) לוודא שיש פריט זמין במאגר. לאחר מכן, הוא נועל את ה-`buffer_mutex` כדי לגשת למאגר בבטחה, מוציא את הפריט, משחרר את המנעול, ומסמן (באמצעות `sem_post(&empty_slots)`) שמקום התפנה במאגר. הדבר החשוב כאן הוא שהצרכן גם מסמן (באמצעות `sem_post(&consumed_for_logging)`) פריט נוסף זמין לרישום ללוג, וזאת *לאחר* שהפריט יצא מהמאגר והמנעול שוחרר, כדי לאפשר ללוגר לפעול באופן בלתי תלוי בגישה למאגר.\n\n*   **תהליך הלוגר (`log_item`):** הלוגר ממתין (באמצעות `sem_wait(&consumed_for_logging)`) עד שפריט יוצא מהמאגר על ידי צרכן. רק כאשר יש פריט שהוצא וטרם נרשם, הסמפור מאפשר לו להמשיך ולבצע את פעולת הרישום ללוג. אין צורך במנעול הדדי בלוגר עצמו מכיוון שהוא התהליך היחיד שאמור לבצע את פעולת הרישום ללוג, ואין לו גישה ישירה למאגר המשותף."}, "difficulty_estimation": "Medium", "_source_file": "0321__Semaphores__Open__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:45:12", "_subject": "Concurrency"}, {"id": 101, "type": "Open", "topic": ["Synchronization", "Semaphores", "Concurrency"], "content": {"text": "במערכת הפעלה נתונה, מספר רב של תהליכים (P1, P2, ..., Pn) ניגשים למסד נתונים משותף. קיימות שתי מגבלות סנכרון עיקריות:\n1.  רק עד MAX_CONCURRENT_DB_ACCESS תהליכים יכולים לגשת למסד הנתונים בו-זמנית.\n2.  לפני כל גישה למסד הנתונים, כל תהליך חייב לעדכן מונה גלובלי active_db_queries המייצג את מספר התהליכים הפעילים במסד הנתונים כרגע. עדכון מונה זה (הגדלה או הקטנה) חייב להיות פעולה מוגנת הדדית (mutual exclusion).\nלאחר סיום הגישה למסד הנתונים, התהליך מקטין את המונה active_db_queries ומשחרר את הגישה למסד הנתונים.\n\nנתון קוד C/C++ חלקי עבור פונקציית תהליך (thread_function). עליכם להשלים את הקוד החסר באמצעות סמפורים (semaphores) בלבד, כך שיענה על כל דרישות הסנכרון. בנוסף, הסבירו במילים מדוע הפתרון שלכם נכון וכיצד כל סמפור תורם לסנכרון.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h> // For sleep\n\n#define MAX_CONCURRENT_DB_ACCESS 3\n#define NUM_THREADS 5\n\n// Global variables\nint active_db_queries = 0;\nsem_t db_access_sem; // Semaphore for controlling concurrent DB access\nsem_t mutex_sem;     // Mutex for protecting active_db_queries\n\nvoid *thread_function(void *arg) {\n    int thread_id = *(int *)arg;\n\n    while (1) {\n        printf(\"Thread %d: Waiting to access DB...\\n\", thread_id);\n\n        // Simulate some work before accessing DB\n        sleep(rand() % 2);\n\n        // --- Synchronization Start: Add semaphore logic here ---\n\n        // 1. Acquire mutex for active_db_queries\n        // 2. Increment active_db_queries\n        // 3. Release mutex\n\n        // 4. Acquire access to DB (limited by MAX_CONCURRENT_DB_ACCESS)\n\n        printf(\"Thread %d: Accessing DB. Current active: %d\\n\", thread_id, active_db_queries);\n        // Simulate DB operation\n        sleep(rand() % 3 + 1); // DB operation takes 1-3 seconds\n\n        printf(\"Thread %d: Done with DB access.\\n\", thread_id);\n\n        // 6. Release DB access\n\n        // 7. Acquire mutex for active_db_queries\n        // 8. Decrement active_db_queries\n        // 9. Release mutex\n\n        // --- Synchronization End ---\n\n        // Simulate some work after accessing DB\n        sleep(rand() % 2);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    int thread_ids[NUM_THREADS];\n\n    // Initialize semaphores\n    sem_init(&db_access_sem, 0, MAX_CONCURRENT_DB_ACCESS); // Counting semaphore\n    sem_init(&mutex_sem, 0, 1);                             // Binary semaphore (mutex)\n\n    // Create threads\n    for (int i = 0; i < NUM_THREADS; i++) {\n        thread_ids[i] = i;\n        pthread_create(&threads[i], NULL, thread_function, &thread_ids[i]);\n    }\n\n    // Join threads (in a real scenario, these might run indefinitely)\n    for (int i = 0; i < NUM_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n\n    // Destroy semaphores\n    sem_destroy(&db_access_sem);\n    sem_destroy(&mutex_sem);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 15, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "הפתרון דורש שימוש בשני סמפורים:\n1.  **`db_access_sem`**: סמפור מונה (counting semaphore) שמאתחל לערך `MAX_CONCURRENT_DB_ACCESS`. סמפור זה משמש לשליטה על מספר הגישות המקבילות למסד הנתונים. כל תהליך שרוצה לגשת למסד הנתונים מבצע `sem_wait(&db_access_sem)`. אם הסמפור גדול מ-0, הוא יורד ב-1 והתהליך ממשיך. אם הוא 0, התהליך נחסם עד שתהליך אחר מבצע `sem_post`. לאחר סיום הגישה למסד הנתונים, התהליך מבצע `sem_post(&db_access_sem)` כדי לשחרר מקום עבור תהליכים אחרים.\n2.  **`mutex_sem`**: סמפור בינארי (binary semaphore), או mutex, שמאתחל לערך 1. סמפור זה משמש להבטחת הדרה הדדית (mutual exclusion) על המונה הגלובלי `active_db_queries`. לפני כל פעולת הגדלה או הקטנה של המונה, תהליך מבצע `sem_wait(&mutex_sem)`. זה מבטיח שרק תהליך אחד יכול לעדכן את המונה בכל רגע נתון. לאחר עדכון המונה, התהליך מבצע `sem_post(&mutex_sem)` כדי לשחרר את ה-mutex לתהליכים אחרים.\n\nלהלן הקוד המלא והנכון לפונקציית `thread_function` ולפונקציית `main`:\n#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h> // For sleep\n\n#define MAX_CONCURRENT_DB_ACCESS 3\n#define NUM_THREADS 5\n\n// Global variables\nint active_db_queries = 0;\nsem_t db_access_sem; // Semaphore for controlling concurrent DB access\nsem_t mutex_sem;     // Mutex for protecting active_db_queries\n\nvoid *thread_function(void *arg) {\n    int thread_id = *(int *)arg;\n\n    while (1) {\n        printf(\"Thread %d: Waiting to access DB...\\n\", thread_id);\n\n        // Simulate some work before accessing DB\n        sleep(rand() % 2);\n\n        // --- Synchronization Start ---\n\n        // 1. Acquire mutex for active_db_queries\n        sem_wait(&mutex_sem);\n        // 2. Increment active_db_queries\n        active_db_queries++;\n        printf(\"Thread %d: active_db_queries incremented to %d.\\n\", thread_id, active_db_queries);\n        // 3. Release mutex\n        sem_post(&mutex_sem);\n\n        // 4. Acquire access to DB (limited by MAX_CONCURRENT_DB_ACCESS)\n        sem_wait(&db_access_sem);\n\n        printf(\"Thread %d: Accessing DB. Current active: %d\\n\", thread_id, active_db_queries);\n        // Simulate DB operation\n        sleep(rand() % 3 + 1); // DB operation takes 1-3 seconds\n\n        printf(\"Thread %d: Done with DB access.\\n\", thread_id);\n\n        // 6. Release DB access\n        sem_post(&db_access_sem);\n\n        // 7. Acquire mutex for active_db_queries\n        sem_wait(&mutex_sem);\n        // 8. Decrement active_db_queries\n        active_db_queries--;\n        printf(\"Thread %d: active_db_queries decremented to %d.\\n\", thread_id, active_db_queries);\n        // 9. Release mutex\n        sem_post(&mutex_sem);\n\n        // --- Synchronization End ---\n\n        // Simulate some work after accessing DB\n        sleep(rand() % 2);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    int thread_ids[NUM_THREADS];\n\n    // Initialize semaphores\n    sem_init(&db_access_sem, 0, MAX_CONCURRENT_DB_ACCESS); // Counting semaphore\n    sem_init(&mutex_sem, 0, 1);                             // Binary semaphore (mutex)\n\n    // Create threads\n    for (int i = 0; i < NUM_THREADS; i++) {\n        thread_ids[i] = i;\n        pthread_create(&threads[i], NULL, thread_function, &thread_ids[i]);\n    }\n\n    // Join threads (in a real scenario, these might run indefinitely)\n    for (int i = 0; i < NUM_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n\n    // Destroy semaphores\n    sem_destroy(&db_access_sem);\n    sem_destroy(&mutex_sem);\n\n    return 0;\n}"}, "difficulty_estimation": "Medium", "_source_file": "0322__Semaphores__Open__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:44:34", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Synchronization", "Semaphores", "Concurrency"], "content": {"text": "נתונה מערכת מרובת חוטים בה קיימת מקטע קוד קריטי שיכול להיות מבוצע על ידי מספר חוטים במקביל. יש לממש מנגנון סנכרון המבטיח שבכל רגע נתון, לא יותר מ-K חוטים יבצעו את המקטע הקריטי. השתמשו בסמפורים בלבד. צרפו קוד C/C++ המדגים את השימוש בסמפורים בתוך פונקציה המייצגת את פעולת החוט, והסבירו את הלוגיקה, כולל אתחול הסמפורים ומיקום פעולות ה-wait וה-signal.", "code_snippet": "// Assume semaphore related headers are included (e.g., <semaphore.h>, <pthread.h>)\n// Assume a global semaphore 'resource_access' is declared.\n\nvoid thread_function(int thread_id) {\n    // קוד לפני המקטע הקריטי\n    printf(\"Thread %d attempting to enter critical section.\\n\", thread_id);\n\n    // TODO: הוסף כאן את קריאות ה-wait לסמפור 'resource_access'\n    \n    // המקטע הקריטי (critical section)\n    printf(\"Thread %d entered critical section.\\n\", thread_id);\n    // סימולציה של עבודה במקטע הקריטי\n    sleep(1);\n    printf(\"Thread %d exiting critical section.\\n\", thread_id);\n\n    // TODO: הוסף כאן את קריאות ה-signal לסמפור 'resource_access'\n    \n    // קוד אחרי המקטע הקריטי\n}\n\n// TODO: יש להוסיף אתחול לסמפור הגלובלי 'resource_access' לערך K במיין,\n// וכן אתחול וסיום תהליכונים (threads) ושחרור משאבים.\n// int main() { ... }"}, "sub_questions": null, "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון דורש שימוש בסמפור מונה (counting semaphore). סמפור זה מאותחל לערך K, המייצג את מספר המקומות הפנויים במקטע הקריטי. כל חוט שמעוניין להיכנס למקטע הקריטי מבצע פעולת wait (או P) על הסמפור. פעולה זו מקטינה את מונה הסמפור באחד. אם מונה הסמפור הופך שלילי (כלומר, כל K המקומות תפוסים), החוט נחסם עד שחוט אחר ישחרר מקום. לאחר שהחוט מסיים את ביצוע המקטע הקריטי, הוא מבצע פעולת signal (או V) על הסמפור. פעולה זו מגדילה את מונה הסמפור באחד. אם היו חוטים חסומים שממתינים למקום, אחד מהם ישוחרר ויורשה לו להיכנס למקטע הקריטי.\n\nלהלן מימוש ב-C/C++:\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h> // For sleep\n\n// הגדרת סמפור גלובלי\nsem_t resource_access;\n\nvoid *thread_function(void *arg) {\n    int thread_id = *(int*)arg;\n    \n    // קוד לפני המקטע הקריטי\n    printf(\"חוט %d מנסה להיכנס למקטע הקריטי.\\n\", thread_id);\n\n    // פעולת wait (P) על הסמפור לפני הכניסה למקטע הקריטי\n    // אם מספר המשאבים הפנויים (K) הוא 0, החוט ייחסם כאן.\n    sem_wait(&resource_access);\n    \n    // המקטע הקריטי (critical section)\n    int val;\n    sem_getvalue(&resource_access, &val); // בדיקת ערך הסמפור (לצורך הדגמה)\n    printf(\"חוט %d נכנס למקטע הקריטי. מקומות פנויים נותרו: %d\\n\", thread_id, val);\n    sleep(2); // סימולציה של עבודה במקטע הקריטי\n    printf(\"חוט %d יוצא מהמקטע הקריטי.\\n\", thread_id);\n\n    // פעולת signal (V) על הסמפור לאחר היציאה מהמקטע הקריטי\n    // משחרר \\\"מקום\\\" אחד במקטע הקריטי, ואם יש חוטים חסומים, אחד מהם ישוחרר.\n    sem_post(&resource_access);\n    \n    // קוד אחרי המקטע הקריטי\n    return NULL;\n}\n\nint main() {\n    int N_THREADS = 10; // לדוגמה, 10 חוטים\n    int K_LIMIT = 3;    // לדוגמה, לכל היותר 3 חוטים במקביל\n    pthread_t threads[N_THREADS];\n    int thread_ids[N_THREADS];\n\n    // אתחול הסמפור:\n    // הארגומנט הראשון הוא מצביע לסמפור.\n    // הארגומנט השני הוא 0 אם הסמפור משמש חוטים באותו תהליך, או 1 אם הוא משותף בין תהליכים.\n    // הארגומנט השלישי הוא הערך ההתחלתי של הסמפור, שהוא K_LIMIT במקרה זה.\n    // K_LIMIT מייצג את מספר ה\\\"היתרים\\\" או ה\\\"מקומות\\\" הזמינים במקטע הקריטי.\n    if (sem_init(&resource_access, 0, K_LIMIT) != 0) {\n        perror(\"sem_init failed\");\n        return 1;\n    }\n\n    // יצירת והפעלת החוטים\n    for (int i = 0; i < N_THREADS; i++) {\n        thread_ids[i] = i;\n        if (pthread_create(&threads[i], NULL, thread_function, &thread_ids[i]) != 0) {\n            perror(\"pthread_create failed\");\n            return 1;\n        }\n    }\n\n    // המתנה לסיום החוטים\n    for (int i = 0; i < N_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n\n    // שחרור משאבים - השמדת הסמפור\n    sem_destroy(&resource_access);\n\n    printf(\"כל החוטים סיימו את פעולתם.\\n\");\n\n    return 0;\n}\n```"}, "difficulty_estimation": "Medium", "_source_file": "0323__Semaphores__Open__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:46:17", "_subject": "Concurrency"}, {"id": 101, "type": "Open", "topic": ["Synchronization", "Semaphores", "Producer-Consumer"], "content": {"text": "נתונה מערכת עם חוצץ מעגלי בגודל BUFFER_SIZE (לדוגמה, 10 תאים) שבו מפיקים (Producers) מוסיפים נתונים וצרכנים (Consumers) מסירים נתונים. המטרה היא לממש את הפעולות enqueue (הוספת נתון לחוצץ) ו-dequeue (הסרת נתון מהחוצץ) תוך שימוש בסמפורים בלבד, על מנת להבטיח את הדרישות הבאות:\n1.  גישה הדדית בלעדית (mutual exclusion) לחוצץ עצמו (כלומר, רק תהליך אחד יכול לגשת לחוצץ בכל רגע נתון).\n2.  מפיק ימתין אם החוצץ מלא (כל תאי החוצץ תפוסים).\n3.  צרכן ימתין אם החוצץ ריק (אין נתונים בחוצץ).\n\nא. הגדירו את הסמפורים הנדרשים (שם, סוג – בינארי/מונה – וערך אתחול).\nב. כתבו את קוד ה-C/C++ עבור פונקציות enqueue ו-dequeue המממשות את הדרישות הנ\"ל. יש לכלול את הגדרות הסמפורים ופונקציית אתחול בסיסית.\nג. הסבירו בקצרה מדוע כל סמפור נחוץ ומה תפקידו.", "code_snippet": "#include <semaphore.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#define BUFFER_SIZE 10\n\n// Shared buffer and indices\nint buffer[BUFFER_SIZE];\nint in = 0;  // Next write position\nint out = 0; // Next read position\n\n// Semaphores\nsem_t mutex;    // For mutual exclusion to buffer\nsem_t empty;    // Counts empty slots\nsem_t full;     // Counts full slots\n\n// Initialization function for semaphores and buffer state\nvoid init_buffer_sync() {\n    sem_init(&mutex, 0, 1);             // Binary semaphore, initialized to 1\n    sem_init(&empty, 0, BUFFER_SIZE);   // Counting semaphore, initialized to BUFFER_SIZE\n    sem_init(&full, 0, 0);              // Counting semaphore, initialized to 0\n}\n\n// Producer function to add an item to the buffer\nvoid enqueue(int item) {\n    sem_wait(&empty); // Wait if buffer is full\n    sem_wait(&mutex); // Acquire lock for buffer access\n\n    // Critical section: Add item to buffer\n    buffer[in] = item;\n    in = (in + 1) % BUFFER_SIZE;\n    // printf(\"Producer added: %d\\n\", item); // Optional print for debugging\n\n    sem_post(&mutex); // Release lock\n    sem_post(&full);  // Signal that a slot is now full\n}\n\n// Consumer function to remove an item from the buffer\nint dequeue() {\n    int item;\n    sem_wait(&full);  // Wait if buffer is empty\n    sem_wait(&mutex); // Acquire lock for buffer access\n\n    // Critical section: Remove item from buffer\n    item = buffer[out];\n    out = (out + 1) % BUFFER_SIZE;\n    // printf(\"Consumer removed: %d\\n\", item); // Optional print for debugging\n\n    sem_post(&mutex); // Release lock\n    sem_post(&empty); // Signal that a slot is now empty\n    return item;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. הגדרת סמפורים וערכי אתחול:\nנדרשים שלושה סמפורים:\n1.  mutex: סמפור בינארי (או מנעול).\n    *   תפקיד: להבטיח גישה הדדית בלעדית לחוצץ המשותף (המשתנים buffer, in, out). רק תהליך אחד (מפיק או צרכן) יכול לגשת לחוצץ ולשנות את מצבו בכל רגע נתון.\n    *   ערך אתחול: 1 (כלומר, החוצץ פנוי לגישה).\n2.  empty: סמפור מונה.\n    *   תפקיד: לספור את מספר התאים הריקים בחוצץ. מפיקים מבצעים sem_wait עליו כדי להמתין לתא פנוי, וצרכנים מבצעים sem_post עליו לאחר פינוי תא.\n    *   ערך אתחול: BUFFER_SIZE (מספר התאים הכולל בחוצץ, שכולם ריקים בהתחלה).\n3.  full: סמפור מונה.\n    *   תפקיד: לספור את מספר התאים המלאים בחוצץ. צרכנים מבצעים sem_wait עליו כדי להמתין לתא מלא, ומפיקים מבצעים sem_post עליו לאחר מילוי תא.\n    *   ערך אתחול: 0 (בהתחלה אין תאים מלאים).\n\nב. קוד C/C++ לפונקציות enqueue ו-dequeue:\nהקוד המלא עבור הגדרות הסמפורים, פונקציית האתחול init_buffer_sync, ופונקציות enqueue ו-dequeue כלול בשדה code_snippet של השאלה עצמה.\n\nג. הסבר על נחיצות ותפקיד כל סמפור:\n*   mutex: חיוני למניעת תנאי מרוץ (race conditions) בעת גישה למשתנים המשותפים (buffer, in, out). ללא mutex, שני מפיקים (או שני צרכנים, או מפיק וצרכן) עלולים לנסות לשנות את אותם אינדקסים או תאי חוצץ בו-זמנית, מה שיוביל לשגיאות ולחוסר עקביות בנתונים. הוא מבטיח שרק תהליך אחד נמצא ב\"אזור קריטי\" של גישה לחוצץ בכל רגע נתון.\n*   empty: סמפור זה מונע ממפיקים להוסיף נתונים לחוצץ כשהוא מלא. כאשר מפיק מנסה להוסיף פריט, הוא מוריד את ערך empty. אם empty מגיע ל-0, פירושו שהחוצץ מלא, והמפיק ייחסם עד שצרכן יפנה מקום (יעלה את ערך empty).\n*   full: סמפור זה מונע מצרכנים לנסות להסיר נתונים מחוצץ כשהוא ריק. כאשר צרכן מנסה להסיר פריט, הוא מוריד את ערך full. אם full מגיע ל-0, פירושו שהחוצץ ריק, והצרכן ייחסם עד שמפיק יוסיף פריט (יעלה את ערך full).\n\nהסדר של פעולות ה-sem_wait ו-sem_post הוא קריטי. לדוגמה, אם ב-enqueue נבצע sem_wait(&mutex) לפני sem_wait(&empty), וכל תאי החוצץ יהיו מלאים, המפיק יקבל את המנעול mutex ואז ייחסם בניסיון להוריד את empty. אם באותו זמן צרכן ינסה לגשת לחוצץ כדי לפנות מקום, הוא יצטרך את mutex אך הוא יהיה נעול על ידי המפיק החסום, מה שיוביל למצב של קיפאון (deadlock). לכן, יש להמתין לתנאי המשאב (empty או full) לפני קבלת המנעול לגישה קריטית."}, "difficulty_estimation": "Medium", "_source_file": "0324__Semaphores__Open__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:46:44", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Semaphores", "Synchronization", "Threads"], "content": {"text": "נתונה מערכת עם N חוטים. כל חוט מבצע באופן מחזורי שתי משימות: `Task A` ולאחריה `Task B`. יש דרישת סנכרון לפיה אף חוט לא יכול להתחיל את `Task B` שלו לפני שכל N החוטים סיימו את `Task A` שלהם. כלומר, כל החוטים חייבים להגיע לנקודת מחסום (Barrier) לאחר `Task A` לפני שהם ממשיכים ל`Task B`. מנגנון המחסום צריך להיות ניתן לשימוש חוזר (reusable) עבור המחזורים הבאים.\nכתוב את קוד ה-C/C++ עבור פונקציית `worker_thread` שתממש את ההתנהגות המתוארת, תוך שימוש בסמפורים (semaphores) ובמנעולים (mutexes) בלבד. יש להגדיר את כל המשתנים הגלובליים הנדרשים ולאתחל אותם כראוי. אין להשתמש באובייקטי סנכרון מובנים אחרים (כמו `pthread_barrier_t`).", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון מבוסס על מנגנון \"מחסום דו-שלבי\" (Double Turnstile Barrier), המשתמש בשני סמפורים (turnstiles) ובמנעול (mutex) כדי להבטיח סנכרון נכון ושימוש חוזר.\n\n**1. משתנים גלובליים ואתחול:**\n```c\n#include <pthread.h>\n#include <semaphore.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h> // For sleep (in example tasks)\n\n// הגדרת מספר החוטים הכולל\n#define NUM_THREADS 5 // N לדוגמה\n\nint N = NUM_THREADS;\nint count = 0;\npthread_mutex_t mutex;\nsem_t barrier;\nsem_t barrier_reset;\n\nvoid init_barrier() {\n    pthread_mutex_init(&mutex, NULL);\n    sem_init(&barrier, 0, 0);       // סמפור ראשי (סגור בהתחלה)\n    sem_init(&barrier_reset, 0, 1); // סמפור איפוס (פתוח בהתחלה)\n}\n\nvoid destroy_barrier() {\n    pthread_mutex_destroy(&mutex);\n    sem_destroy(&barrier);\n    sem_destroy(&barrier_reset);\n}\n```\n\n**2. פונקציית `barrier_wait()`:**\nפונקציה זו מממשת את ההמתנה במחסום:\n```c\nvoid barrier_wait() {\n    // שלב 1: איסוף החוטים במחסום הראשון\n    pthread_mutex_lock(&mutex);\n    count++;\n    if (count == N) {\n        // החוט האחרון שהגיע: סוגר את מחסום האיפוס ופותח את המחסום הראשי\n        sem_wait(&barrier_reset); \n        for (int i = 0; i < N; i++) {\n            sem_post(&barrier);\n        }\n    }\n    pthread_mutex_unlock(&mutex);\n    sem_wait(&barrier); // כל החוטים ממתינים כאן עד שהמחסום הראשי ייפתח\n\n    // שלב 2: איפוס המחסום עבור המחזור הבא\n    pthread_mutex_lock(&mutex);\n    count--;\n    if (count == 0) {\n        // החוט האחרון שיוצא: סוגר את המחסום הראשי ופותח את מחסום האיפוס\n        for (int i = 0; i < N; i++) {\n            sem_post(&barrier_reset);\n        }\n    }\n    pthread_mutex_unlock(&mutex);\n    sem_wait(&barrier_reset); // כל החוטים ממתינים כאן עד שמחסום האיפוס ייפתח\n}\n```\n\n**3. פונקציית `worker_thread`:**\nכל חוט מבצע את המשימות שלו ומשתמש ב-`barrier_wait`:\n```c\n// פונקציות לדוגמה למשימות A ו-B (אין צורך לממשן במבחן, רק לצורך הדגמה)\nvoid taskA(int thread_id) {\n    printf(\"Thread %d: Starting Task A\\n\", thread_id);\n    sleep(rand() % 2); // הדמיית עבודה\n    printf(\"Thread %d: Finished Task A\\n\", thread_id);\n}\n\nvoid taskB(int thread_id) {\n    printf(\"Thread %d: Starting Task B\\n\", thread_id);\n    sleep(rand() % 2); // הדמיית עבודה\n    printf(\"Thread %d: Finished Task B\\n\", thread_id);\n}\n\nvoid *worker_thread(void *arg) {\n    int thread_id = *(int *)arg;\n    free(arg); // שחרור הזיכרון שהוקצה למזהה החוט\n\n    while (1) { // לולאה אינסופית עבור מחזורים חוזרים\n        taskA(thread_id);\n        barrier_wait(); // המתן עד שכל N החוטים יסיימו את Task A\n        taskB(thread_id);\n        printf(\"Thread %d: Cycle complete.\\n\", thread_id);\n        sleep(1); // השהייה קטנה לפני המחזור הבא\n    }\n    return NULL;\n}\n```\n\n**הסבר מפורט:**\n\n*   **משתנים גלובליים:**\n    *   `N`: קבוע המגדיר את מספר החוטים הכולל במערכת. יש לאתחל אותו לפני יצירת החוטים.\n    *   `count`: מונה את מספר החוטים שהגיעו לנקודת הסנכרון בשלב הנוכחי. מאופס בכל מחזור.\n    *   `mutex`: מנעול `pthread_mutex_t` המשמש להגנה על הגישה למשתנה `count` המשותף, ובכך מבטיח עדכון אטומי (atomic) של המונה. מאותחל ל-1 (פתוח).\n    *   `barrier`: סמפור `sem_t` המשמש לחסימת חוטים בשלב הראשון של המחסום, עד שכל `N` החוטים מגיעים. מאותחל ל-0 (סגור לחלוטין).\n    *   `barrier_reset`: סמפור `sem_t` נוסף המשמש לחסימת חוטים בשלב השני, ומונע מהם להתחיל מחזור חדש לפני שכל החוטים סיימו את המחזור הקודם. מאותחל ל-1 (פתוח עבור המחזור הראשון).\n\n*   **פעולת `barrier_wait()`:**\n    1.  **שלב ראשון (איסוף):** כל חוט שמגיע קורא ל-`pthread_mutex_lock(&mutex)`, מגדיל את `count`, ומשחרר את ה-`mutex`. כאשר החוט ה-`N` מגיע (כלומר, `count` מגיע ל-`N`), הוא מזהה שהוא האחרון. חוט זה מבצע `sem_wait(&barrier_reset)` כדי \"לסגור\" את שער האיפוס (ובכך למנוע מחזורים עתידיים להתקדם בטרם עת) ולאחר מכן מבצע `sem_post(&barrier)` `N` פעמים. פעולה זו משחררת את כל `N` החוטים שייתכן שממתינים או שיגיעו בקרוב ל-`sem_wait(&barrier)`. כל החוטים, כולל החוט ה-`N`, ממתינים ב-`sem_wait(&barrier)` עד שהסמפור ייפתח.\n    2.  **שלב שני (איפוס):** לאחר שכל החוטים עברו את `sem_wait(&barrier)`, הם נכנסים לשלב השני. כל חוט נועל שוב את ה-`mutex`, מקטין את `count`, ומשחרר את ה-`mutex`. כאשר החוט האחרון שיוצא (כלומר, `count` מגיע ל-`0`) מזהה שהוא האחרון. חוט זה מבצע `sem_post(&barrier_reset)` `N` פעמים כדי \"לפתוח\" מחדש את שער האיפוס עבור המחזור הבא. כל החוטים ממתינים ב-`sem_wait(&barrier_reset)` עד שהסמפור ייפתח. זה מבטיח שכל החוטים סיימו לחלוטין את המחזור הנוכחי (כולל איפוס המונה) לפני שמישהו יתחיל את השלב הראשון של המחזור הבא.\n\n*   **פונקציית `worker_thread`:** כל חוט מבצע בלולאה אינסופית את `taskA`, ולאחר מכן קורא ל-`barrier_wait()` כדי להמתין לשאר החוטים. רק לאחר שכל `N` החוטים סיימו את `taskA` ועברו את המחסום, כולם ממשיכים יחד ל-`taskB`. הדבר מבטיח את דרישת הסנכרון ואת יכולת השימוש החוזר של המחסום."}, "difficulty_estimation": "Medium", "_source_file": "0325__Semaphores__Open__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:47:31", "_subject": "Concurrency"}, {"id": 101, "type": "Open", "topic": ["Synchronization", "Semaphores"], "content": {"text": "מחסום (Barrier) הוא אובייקט סנכרון המיועד ל-N חוטים. כאשר חוט קורא לפעולת `barrier_wait()`, הוא ממתין עד שכל N החוטים קראו לפעולה זו. רק כאשר כל N החוטים הגיעו למחסום, כולם משוחררים בו זמנית וממשיכים בביצוע. המחסום צריך להיות ניתן לשימוש חוזר (reusable), כלומר, לאחר שכל החוטים שוחררו, ניתן להשתמש בו שוב באותו אופן לסנכרון השלב הבא.\nתארו כיצד ניתן לממש מחסום ניתן לשימוש חוזר עבור N חוטים באמצעות סמפורים (POSIX semaphores) ומבנה נתונים פשוט. כתבו את קוד ה-C/C++ עבור הפונקציות `barrier_init()`, `barrier_destroy()` ו-`barrier_wait()`, והסבירו את תפקיד כל סמפור ואת לוגיקת הפעולה של המחסום.", "code_snippet": "```c\n#include <semaphore.h>\n#include <stdlib.h> // For malloc, free (though not directly used in the Barrier struct itself here)\n\ntypedef struct {\n    int N; // Total number of threads for the barrier\n    int count; // Number of threads arrived at the barrier\n    sem_t mutex; // Protects 'count'\n    sem_t turnstile; // Blocks threads until all arrive\n    sem_t turnstile2; // Used to reset the barrier for reuse\n} Barrier;\n\nvoid barrier_init(Barrier *b, int num_threads) {\n    b->N = num_threads;\n    b->count = 0;\n    sem_init(&b->mutex, 0, 1); // Mutex initially open\n    sem_init(&b->turnstile, 0, 0); // Turnstile initially locked\n    sem_init(&b->turnstile2, 0, 1); // Turnstile2 initially open\n}\n\nvoid barrier_destroy(Barrier *b) {\n    sem_destroy(&b->mutex);\n    sem_destroy(&b->turnstile);\n    sem_destroy(&b->turnstile2);\n}\n\nvoid barrier_wait(Barrier *b) {\n    // Phase 1: Gathering threads and releasing them\n    sem_wait(&b->mutex);\n    b->count++;\n    if (b->count == b->N) {\n        sem_wait(&b->turnstile2); // Close turnstile2 to prevent early reset\n        for (int i = 0; i < b->N; i++) {\n            sem_post(&b->turnstile); // Open turnstile to release all threads\n        }\n    }\n    sem_post(&b->mutex);\n\n    sem_wait(&b->turnstile); // All threads wait here until released\n\n    // Phase 2: Resetting the barrier for reuse\n    sem_wait(&b->mutex);\n    b->count--;\n    if (b->count == 0) {\n        for (int i = 0; i < b->N; i++) {\n            sem_post(&b->turnstile2); // Reopen turnstile2 for the next cycle\n        }\n    }\n    sem_post(&b->mutex);\n}\n```", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון מבוסס על מימוש מחסום דו-פאזי (two-phase barrier) באמצעות שני סמפורים (POSIX semaphores) ומונה.\n\n**מבנה הנתונים:**\n*   `N`: מספר החוטים הכולל המשתתפים במחסום.\n*   `count`: מונה העוקב אחר מספר החוטים שהגיעו למחסום בשלב הנוכחי.\n*   `mutex`: סמפור בינארי (או mutex) המשמש להגנה על המונה `count` מפני תנאי מירוץ. מאותחל ל-1 (פתוח).\n*   `turnstile`: סמפור ספירה המאותחל ל-0. חוטים נחסמים עליו עד שכל N החוטים יגיעו. הוא נפתח על ידי החוט האחרון שהגיע.\n*   `turnstile2`: סמפור ספירה המאותחל ל-1. משמש לסנכרון האיפוס של המחסום, כך שרק לאחר שכל N החוטים עברו את המחסום ו\"יצאו\" ממנו, הוא מוכן שוב לשימוש.\n\n**פעולת `barrier_init(Barrier *b, int num_threads)`:**\n*   מאחלת את `N` ל-`num_threads`.\n*   מאחלת את `count` ל-0.\n*   מאחלת את `mutex` ל-1 (פתוח).\n*   מאחלת את `turnstile` ל-0 (סגור).\n*   מאחלת את `turnstile2` ל-1 (פתוח).\n\n**פעולת `barrier_wait(Barrier *b)`:**\n\n**שלב 1: איסוף חוטים והגעה למחסום**\n1.  **`sem_wait(&b->mutex);`**: כל חוט רוכש את ה-`mutex` כדי להגן על הגישה ל-`count`. זה מבטיח שרק חוט אחד מעדכן את `count` בכל רגע נתון.\n2.  **`b->count++;`**: החוט מגדיל את המונה `count`.\n3.  **`if (b->count == b->N)`**: אם זהו החוט ה-N שהגיע למחסום (החוט האחרון):\n    *   **`sem_wait(&b->turnstile2);`**: החוט ה-N סוגר את `turnstile2`. זה מבטיח שאף חוט לא יוכל להיכנס לשלב השני של המחסום (איפוס) לפני שכל החוטים עברו את השלב הראשון. זה מונע מחוטים מהמחזור הבא \"להקדים\" חוטים מהמחזור הנוכחי.\n    *   **`for (int i = 0; i < b->N; i++) { sem_post(&b->turnstile); }`**: החוט ה-N משחרר N פעמים את `turnstile`. פעולה זו פותחת את `turnstile` ומאפשרת לכל N החוטים (כולל הוא עצמו) להמשיך הלאה מהנקודה בה הם חסומים ב-`sem_wait(&b->turnstile)`.\n4.  **`sem_post(&b->mutex);`**: החוט משחרר את ה-`mutex`.\n\n**שלב 2: המתנה לשחרור ואיפוס המחסום**\n5.  **`sem_wait(&b->turnstile);`**: כל החוטים, כולל החוט ה-N, מגיעים לכאן ונחסמים על `turnstile` עד שהוא נפתח על ידי החוט ה-N (בשלב 1). ברגע ש-`turnstile` נפתח, כל החוטים עוברים.\n6.  **`sem_wait(&b->mutex);`**: החוטים רוכשים שוב את ה-`mutex` כדי לעדכן את המונה `count` (כעת הוא משמש לספירת יציאה מהמחסום).\n7.  **`b->count--;`**: החוט מקטין את המונה `count`.\n8.  **`if (b->count == 0)`**: אם זהו החוט האחרון שיוצא מהמחסום (כלומר, כל N החוטים עברו את המחסום ו\"יצאו\" ממנו):\n    *   **`for (int i = 0; i < b->N; i++) { sem_post(&b->turnstile2); }`**: החוט האחרון משחרר N פעמים את `turnstile2`. פעולה זו פותחת מחדש את `turnstile2` ומאפשרת למחסום להיות מוכן לשימוש חוזר בסבב הבא.\n9.  **`sem_post(&b->mutex);`**: החוט משחרר את ה-`mutex`.\n\n**הסבר תפקיד הסמפורים בפתרון זה:**\n*   **`mutex`**: סמפור בינארי המגן על המשתנה `count`. הוא מבטיח שרק חוט אחד יכול לגשת ולשנות את `count` בכל רגע נתון, ובכך מונע תנאי מירוץ.\n*   **`turnstile`**: משמש כ\"שער כניסה\" למחסום. הוא חוסם את כל החוטים עד שכולם יגיעו. רק החוט האחרון (ה-N) פותח אותו N פעמים כדי לשחרר את כל החוטים בו זמנית.\n*   **`turnstile2`**: משמש כ\"שער יציאה\" וכמנגנון איפוס למחסום. הוא מבטיח שכל N החוטים עברו את השלב הראשון של המחסום (כלומר, כולם שוחררו מ-`turnstile`) לפני שהמחסום יתאפס ויהיה מוכן לשימוש חוזר. החוט ה-N סוגר אותו כדי למנוע כניסה מוקדמת לשלב האיפוס, והחוט האחרון שיוצא מהמחסום פותח אותו מחדש."}, "difficulty_estimation": "Medium", "_source_file": "0326__Semaphores__Open__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:47:58", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Semaphores"], "content": {"text": "מערכת הפעלה מנהלת N מדפסות משותפות המשרתות מספר רב של תהליכונים (threads). כל תהליכון המעוניין להדפיס מסמך חייב לתפוס מדפסת זמינה, להשתמש בה (למשל, לבצע פעולת הדפסה), ולבסוף לשחרר אותה. בכל רגע נתון, רק N תהליכונים יכולים להשתמש במדפסת במקביל. עליך לממש את הפונקציות `acquire_printer()` ו-`release_printer()` תוך שימוש בסמפורים, על מנת להבטיח סנכרון נכון ולמנוע מצב בו יותר מ-N תהליכונים משתמשים במדפסות בו זמנית. הנח כי N הוא מספר שלם חיובי, וכי הסמפורים הדרושים מאותחלים כראוי.", "code_snippet": "#include <semaphore.h>\n\n// Assume 'N_PRINTERS' is defined elsewhere, e.g., #define N_PRINTERS 5\n// Assume 'sem_t available_printers;' is declared globally and initialized with N_PRINTERS.\n\nvoid acquire_printer();\nvoid release_printer();", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כדי לפתור בעיה זו, נשתמש בסמפור מונה (counting semaphore). סמפור זה ישמש לייצוג מספר המדפסות הזמינות. הוא יאותחל לערך N, המייצג את המספר הכולל של המדפסות במערכת.\n\n**מימוש הפונקציות:**\n\n```c\n#include <semaphore.h>\n#include <stdio.h> // for example usage, not strictly required for the functions themselves\n#include <stdlib.h> // for example usage\n#include <unistd.h> // for sleep in example usage\n\n// הגדרה והאתחול של הסמפור יבוצעו מחוץ לפונקציות, לדוגמה:\n// #define N_PRINTERS 5\n// sem_t available_printers;\n// void init_printers_semaphore() {\n//     sem_init(&available_printers, 0, N_PRINTERS); // 0 for shared within a process\n// }\n\nvoid acquire_printer() {\n    sem_wait(&available_printers); // מקטין את ערך הסמפור; אם ערכו 0, התהליכון נחסם.\n}\n\nvoid release_printer() {\n    sem_post(&available_printers); // מגדיל את ערך הסמפור; אם יש תהליכונים חסומים, אחד מהם ישוחרר.\n}\n```\n\n**הסבר:**\n1.  **סמפור `available_printers`**: סמפור זה מאותחל ל-N, שהוא המספר המקסימלי של מדפסות זמינות.\n2.  **פונקציה `acquire_printer()`**: כאשר תהליכון רוצה להדפיס, הוא קורא ל-`sem_wait(&available_printers)`. פעולה זו מנסה להקטין את ערך הסמפור. אם ערך הסמפור גדול מ-0, הוא מוקטן והתהליכון ממשיך. אם ערך הסמפור הוא 0 (כלומר, כל המדפסות תפוסות), התהליכון נחסם וממתין עד שמדפסת תתפנה.\n3.  **פונקציה `release_printer()`**: לאחר שתהליכון מסיים להשתמש במדפסת, הוא קורא ל-`sem_post(&available_printers)`. פעולה זו מגדילה את ערך הסמפור. אם היו תהליכונים חסומים הממתינים למדפסת, אחד מהם (התלוי בלוח הזמנים של מערכת ההפעלה) ישוחרר כעת ויוכל להמשיך להשתמש במדפסת.\n\nמנגנון זה מבטיח שבכל רגע נתון, לא יותר מ-N תהליכונים יוכלו לגשת למדפסות, ובכך נשמר הסנכרון הנדרש."}, "difficulty_estimation": "Medium", "_source_file": "0327__Semaphores__Open__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:48:16", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Semaphores", "Synchronization", "Producer-Consumer"], "content": {"text": "נתונה בעיית המאגר החסום (Bounded Buffer) בגודל `BUFFER_SIZE`. ישנם מספר תהליכי יצרן (Producer) שמוסיפים פריטים למאגר ומספר תהליכי צרכן (Consumer) שמוציאים פריטים מהמאגר.\n\nיש לממש את הפונקציות `producer` ו-`consumer` תוך שימוש בסמפורים בלבד (ללא מנעולים או Mutex-ים אחרים) כדי להבטיח סנכרון נכון בין התהליכים.\n\nיש להגדיר את הסמפורים הנדרשים, לאתחל אותם בערכים המתאימים, ולשלב אותם במימוש הפונקציות. הניחו שקיימת מערכת תומכת בפעולות `sem_init`, `sem_wait`, `sem_post` עבור סמפורים. הניחו שקיימות פונקציות `produce_item()` ו-`consume_item(item)` המבצעות את הלוגיקה העסקית של יצירת וצריכת פריטים בהתאמה, וכן פונקציות `insert_item(item)` ו-`remove_item()` המטפלות בגישה למאגר עצמו (אך יש להגן עליהן באמצעות סמפורים).", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h> // For sleep\n\n#define BUFFER_SIZE 5\n\nint buffer[BUFFER_SIZE];\nint in = 0; // Next empty slot\nint out = 0; // Next item to remove\n\n// Declare semaphores here\n// sem_t ...\n\n// Initialize semaphores\nvoid init_semaphores() {\n    // ...\n}\n\nvoid insert_item(int item) {\n    buffer[in] = item;\n    in = (in + 1) % BUFFER_SIZE;\n    printf(\"Producer inserted item %d. Buffer state: \", item);\n    for (int i=0; i<BUFFER_SIZE; ++i) {\n        printf(\"%d \", buffer[i]);\n    }\n    printf(\"]\\n\");\n}\n\nint remove_item() {\n    int item = buffer[out];\n    buffer[out] = -1; // Mark as empty for clarity\n    out = (out + 1) % BUFFER_SIZE;\n    printf(\"Consumer removed item %d. Buffer state: \", item);\n    for (int i=0; i<BUFFER_SIZE; ++i) {\n        printf(\"%d \", buffer[i]);\n    }\n    printf(\"]\\n\");\n    return item;\n}\n\nvoid *producer(void *param) {\n    int item;\n    while (1) {\n        // ... synchronization logic using semaphores ...\n        item = rand() % 100; // Simulate producing an item\n        insert_item(item);\n        // ... synchronization logic using semaphores ...\n        sleep(1); // Simulate work\n    }\n    return NULL;\n}\n\nvoid *consumer(void *param) {\n    int item;\n    while (1) {\n        // ... synchronization logic using semaphores ...\n        item = remove_item();\n        // ... synchronization logic using semaphores ...\n        sleep(2); // Simulate work\n    }\n    return NULL;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "לפתרון בעיית המאגר החסום באמצעות סמפורים נדרשים שלושה סמפורים:\n1.  **`mutex` (סמפור בינארי / סמפור הדדיות):** מגן על הגישה לקטעים הקריטיים של המאגר (הפונקציות `insert_item` ו-`remove_item`) כדי להבטיח שרק תהליך אחד יבצע שינויים במאגר בכל רגע נתון. ערך אתחול: 1 (המאגר פנוי לגישה).\n2.  **`empty` (סמפור ספירה):** עוקב אחר מספר המקומות הריקים במאגר. תהליך יצרן ימתין על סמפור זה אם אין מקום פנוי. ערך אתחול: `BUFFER_SIZE` (בהתחלה כל המאגר ריק).\n3.  **`full` (סמפור ספירה):** עוקב אחר מספר הפריטים המלאים במאגר. תהליך צרכן ימתין על סמפור זה אם המאגר ריק מפריטים. ערך אתחול: 0 (בהתחלה המאגר ריק מפריטים).\n\nהמימוש של הפונקציות `producer` ו-`consumer` ישתמש בסמפורים אלו באופן הבא:\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h> // For sleep\n\n#define BUFFER_SIZE 5\n\nint buffer[BUFFER_SIZE];\nint in = 0; // Next empty slot\nint out = 0; // Next item to remove\n\nsem_t mutex; // For mutual exclusion\nsem_t empty; // Counts empty slots\nsem_t full;  // Counts full slots\n\n// Initialize buffer items to -1 for clarity (empty)\nvoid init_buffer() {\n    for (int i = 0; i < BUFFER_SIZE; ++i) {\n        buffer[i] = -1;\n    }\n}\n\nvoid init_semaphores() {\n    sem_init(&mutex, 0, 1); // Binary semaphore for mutual exclusion, initial value 1\n    sem_init(&empty, 0, BUFFER_SIZE); // Counting semaphore for empty slots, initial value BUFFER_SIZE\n    sem_init(&full, 0, 0); // Counting semaphore for full slots, initial value 0\n}\n\nvoid insert_item(int item) {\n    buffer[in] = item;\n    in = (in + 1) % BUFFER_SIZE;\n    printf(\"Producer inserted item %d. Buffer state: \", item);\n    for (int i=0; i<BUFFER_SIZE; ++i) {\n        printf(\"%d \", buffer[i]);\n    }\n    printf(\"]\\n\");\n}\n\nint remove_item() {\n    int item = buffer[out];\n    buffer[out] = -1; // Mark as empty for clarity\n    out = (out + 1) % BUFFER_SIZE;\n    printf(\"Consumer removed item %d. Buffer state: \", item);\n    for (int i=0; i<BUFFER_SIZE; ++i) {\n        printf(\"%d \", buffer[i]);\n    }\n    printf(\"]\\n\");\n    return item;\n}\n\nvoid *producer(void *param) {\n    int item;\n    while (1) {\n        item = rand() % 100; // Simulate producing an item\n        \n        sem_wait(&empty); // Wait if buffer is full (no empty slots)\n        sem_wait(&mutex); // Acquire lock for critical section\n        \n        insert_item(item);\n        \n        sem_post(&mutex); // Release lock\n        sem_post(&full);  // Signal that a slot is now full\n        \n        sleep(1); // Simulate work\n    }\n    return NULL;\n}\n\nvoid *consumer(void *param) {\n    int item;\n    while (1) {\n        sem_wait(&full);  // Wait if buffer is empty (no full slots)\n        sem_wait(&mutex); // Acquire lock for critical section\n        \n        item = remove_item();\n        \n        sem_post(&mutex); // Release lock\n        sem_post(&empty); // Signal that a slot is now empty\n        \n        sleep(2); // Simulate work\n    }\n    return NULL;\n}\n```"}, "difficulty_estimation": "Medium", "_source_file": "0328__Semaphores__Open__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:48:40", "_subject": "Concurrency"}, {"id": 7, "type": "Open", "topic": ["Semaphores", "Concurrency", "Resource Management", "Deadlock", "Starvation"], "content": {"text": "מערכת מורכבת מ-N תהליכי עבודה (Worker Threads) ומשני סוגי משאבים משותפים: ResourceA (סה\"כ MAX_A יחידות) ו-ResourceB (סה\"כ MAX_B יחידות). משימות מגיעות באופן דינמי. כל משימה דורשת req_A יחידות מ-ResourceA ו-req_B יחידות מ-ResourceB. תהליך עבודה לוקח משימה וצריך לרכוש את *כל* המשאבים הנדרשים באופן אטומי לפני תחילת המשימה, ולשחרר אותם כולם בסיום. בנוסף, למערכת יש מדיניות שמגבילה את המספר הכולל של *משימות פעילות* (משימות שמחזיקות משאבים ומבצעות כעת) ל-MAX_CONCURRENT_TASKS. כל הפעולות של סמפורים הן POSIX standard (`sem_init`, `sem_wait`, `sem_post`, `sem_getvalue`, `sem_trywait`).\n\nא. כתבו את חתימות הפונקציות `acquire_resources(int req_A, int req_B)` ו-`release_resources(int req_A, int req_B)`.\nב. יישמו את הפונקציות הללו באמצעות סמפורים (מונים ו/או בינאריים/Mutex), תוך הקפדה על הדרישות הבאות:\n   1. לא יוקצו יותר מ-MAX_A יחידות מ-ResourceA ולא יותר מ-MAX_B יחידות מ-ResourceB.\n   2. לא יהיו יותר מ-MAX_CONCURRENT_TASKS משימות פעילות בו זמנית.\n   3. המערכת תהיה נקייה מקיפאון (Deadlock-free).\n   4. מנעו הרעבה (Starvation) ככל הניתן בפתרון שלכם.\nג. הסבירו במפורט כיצד הפתרון שלכם מונע קיפאון והרעבה.", "code_snippet": "/* גלובליים / אתחול */\n#include <semaphore.h>\n#include <unistd.h> // for usleep\n\nsem_t sem_A;\nsem_t sem_B;\nsem_t sem_concurrent;\nsem_t mutex_resource_alloc; // להגנה על הקצאת משאבים מרובים\n\nvoid init_synchronization(int MAX_A, int MAX_B, int MAX_CONCURRENT_TASKS) {\n    sem_init(&sem_A, 0, MAX_A);\n    sem_init(&sem_B, 0, MAX_B);\n    sem_init(&sem_concurrent, 0, MAX_CONCURRENT_TASKS);\n    sem_init(&mutex_resource_alloc, 0, 1);\n}\n\nvoid destroy_synchronization() {\n    sem_destroy(&sem_A);\n    sem_destroy(&sem_B);\n    sem_destroy(&sem_concurrent);\n    sem_destroy(&mutex_resource_alloc);\n}\n\n/* פונקציות שיש לממש */\nvoid acquire_resources(int req_A, int req_B);\nvoid release_resources(int req_A, int req_B);", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\n**א. חתימות הפונקציות:**\n```c\nvoid acquire_resources(int req_A, int req_B);\nvoid release_resources(int req_A, int req_B);\n```\n\n**ב. יישום הפונקציות:**\n```c\nvoid acquire_resources(int req_A, int req_B) {\n    // 1. תפוס מקום למשימה מקבילה. זה מגביל את המספר הכולל של משימות שיכולות לנסות לרכוש משאבים.\n    sem_wait(&sem_concurrent);\n\n    // 2. היכנס לקטע קריטי להקצאת משאבים. זה מבטיח שרק תהליך אחד בכל פעם יבדוק וירכוש משאבים.\n    while (1) {\n        sem_wait(&mutex_resource_alloc);\n\n        int val_A, val_B;\n        // בדוק את כמות המשאבים הזמינים. `sem_getvalue` אינה אטומית עם `sem_wait`.\n        // לכן, אנחנו בתוך critical section המוגן על ידי `mutex_resource_alloc`.\n        sem_getvalue(&sem_A, &val_A);\n        sem_getvalue(&sem_B, &val_B);\n\n        if (val_A >= req_A && val_B >= req_B) {\n            // כל המשאבים זמינים. רכוש אותם.\n            // רכישה ביחידות בודדות בתוך הקטע הקריטי.\n            for (int i = 0; i < req_A; ++i) {\n                sem_wait(&sem_A);\n            }\n            for (int i = 0; i < req_B; ++i) {\n                sem_wait(&sem_B);\n            }\n            sem_post(&mutex_resource_alloc); // שחרר את המוטקס לאחר רכישה מוצלחת\n            break; // יצא מהלולאה, המשאבים נרכשו בהצלחה\n        } else {\n            // המשאבים אינם זמינים במלואם. שחרר את המוטקס זמנית ואז נסה שוב.\n            sem_post(&mutex_resource_alloc);\n            usleep(1000); // המתן זמן קצר כדי למנוע busy-waiting ולאפשר לתהליכים אחרים לנסות\n        }\n    }\n}\n\nvoid release_resources(int req_A, int req_B) {\n    // שחרר יחידות של ResourceA\n    for (int i = 0; i < req_A; ++i) {\n        sem_post(&sem_A);\n    }\n    // שחרר יחידות של ResourceB\n    for (int i = 0; i < req_B; ++i) {\n        sem_post(&sem_B);\n    }\n    // שחרר את המקום של המשימה המקבילה\n    sem_post(&sem_concurrent);\n}\n```\n\n**ג. הסבר על מניעת קיפאון והרעבה:**\n\n**מניעת קיפאון (Deadlock Prevention):**\nקיפאון מתרחש כאשר מתקיימים ארבעה תנאים: מניעה הדדית (Mutual Exclusion), החזקה והמתנה (Hold and Wait), אי-הפקעה (No Preemption), והמתנה מעגלית (Circular Wait). הפתרון המוצע מונע קיפאון על ידי שבירת תנאי ה\"החזקה והמתנה\" וה\"המתנה מעגלית\" באופן הבא:\n\n1.  **מניעת הקצאה חלקית (Acquire All or None):** הפונקציה `acquire_resources` משתמשת בסמפור בינארי `mutex_resource_alloc` כדי להגן על קטע קריטי שבו מתבצעת הבדיקה והרכישה של המשאבים `ResourceA` ו-`ResourceB`. תהליך חייב לרכוש את `mutex_resource_alloc` לפני שהוא יכול לבדוק אם המשאבים זמינים. בתוך הקטע הקריטי, התהליך בודק אם *כל* המשאבים הנדרשים (req_A ו-req_B) זמינים באמצעות `sem_getvalue`. רק אם כל המשאבים זמינים, הוא רוכש אותם (באמצעות לולאות של `sem_wait`). אם לא כל המשאבים זמינים, התהליך משחרר את `mutex_resource_alloc` וחוזר לנסות מאוחר יותר. גישה זו מבטיחה שתהליך רוכש את כל המשאבים הנדרשים לו או אף אחד מהם, ובכך נמנע מצב של \"החזקה והמתנה\" שבו תהליך מחזיק במשאב אחד וממתין למשאב אחר, מה שיכול להוביל לקיפאון. מכיוון שרק תהליך אחד יכול לבצע את שלב הבדיקה והרכישה האטומית בכל רגע נתון, לא ייתכן מצב שבו שני תהליכים יחזיקו חלקים מהמשאבים וימתינו זה לזה באופן מעגלי.\n2.  **מניעת המתנה מעגלית (Circular Wait):** למרות שההקצאה האטומית היא המנגנון העיקרי למניעת קיפאון, אם היינו רוכשים את המשאבים בנפרד, היה נדרש סדר קבוע. בפתרון זה, הסדר שבו נרכשים `sem_A` ואז `sem_B` בתוך הקטע הקריטי תורם גם הוא למניעת המתנה מעגלית, אך כאמור, המנגנון של \"הקצה הכל או כלום\" הוא המשמעותי יותר.\n\n**מניעת הרעבה (Starvation Prevention):**\nסמפורי POSIX (כמו אלה המשמשים כאן) בדרך כלל מיישמים תור המתנה הוגן (FIFO - First-In, First-Out) עבור קריאות `sem_wait`. המשמעות היא שתהליכים שממתינים לסמפור יתעוררו בסדר שבו הם נכנסו לתור ההמתנה. זה מסייע במניעת הרעבה במספר דרכים:\n\n1.  **הוגנות ב-`sem_concurrent`:** תהליכים הממתינים למקום במגבלת המשימות המקבילות (`sem_concurrent`) יקבלו את מקומם בסדר הוגן, מה שמבטיח שכל משימה תקבל בסופו של דבר הזדמנות לנסות לרכוש משאבים.\n2.  **הוגנות ב-`mutex_resource_alloc`:** תהליכים הממתינים להיכנס לקטע הקריטי של הקצאת המשאבים (המוגן על ידי `mutex_resource_alloc`) יקבלו את הגישה בסדר הוגן. זה מבטיח שכל תהליך יקבל הזדמנות לבדוק את זמינות המשאבים.\n3.  **הוגנות בסמפורי המשאבים (`sem_A`, `sem_B`):** כאשר תהליך מצליח להיכנס לקטע הקריטי ומוצא שכל המשאבים זמינים, הוא מבצע סדרת קריאות `sem_wait` כדי לרכוש אותם. אם אחד מהסמפורים הללו נחסם, התהליך ימתין בתור הוגן.\n4.  **הפחתת Busy-Waiting:** השימוש ב-`usleep(1000)` בתוך לולאת ה-`while(1)` כאשר המשאבים אינם זמינים, מפחית את ה-busy-waiting. במקום שתהליך ינסה שוב ושוב באופן מיידי, הוא ממתין זמן קצר, מה שמפנה את המעבד לתהליכים אחרים ומאפשר למשאבים להשתחרר. זה גם נותן לתהליכים אחרים (אשר ממתינים ל-`mutex_resource_alloc`) הזדמנות לרכוש את המוטקס ולנסות את מזלם.\n\nלמרות שהפתרון אינו מבטיח מניעת הרעבה אבסולוטית (לדוגמה, תהליך הדורש כמות גדולה מאוד של משאבים עלול למצוא את עצמו ממתין זמן רב אם משימות קטנות יותר ממשיכות להגיע ולרכוש את המשאבים הזמינים), הוא מקטין משמעותית את הסיכון להרעבה על ידי שילוב של הוגנות מובנית בסמפורי POSIX והפחתת busy-waiting."}, "difficulty_estimation": "Hard", "_source_file": "0329__Semaphores__Open__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:49:37", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Semaphores", "Synchronization", "Producer-Consumer", "Concurrency"], "content": {"text": "נתונה מערכת המטפלת בתהליכי יצרן-צרכן עם חיץ מעגלי חסום בגודל `BUFFER_SIZE`.\nקיימים `P` תהליכי יצרן ו-`C` תהליכי צרכן.\nבנוסף למגבלות הסטנדרטיות של חיץ חסום, קיימת הגבלה נוספת:\nבכל רגע נתון, לכל היותר `MAX_ACTIVE_PRODUCERS` תהליכי יצרן יכולים להיות פעילים במקביל (כלומר, נמצאים בתוך הקטע הקריטי שלהם לייצור פריט, לפני ניסיון הכנסתו לחיץ).\n\nיש לממש את הפונקציות `producer_thread_func()` ו-`consumer_thread_func()` תוך שימוש בסמפורים בלבד, על מנת להבטיח:\n1. גישה בטוחה לחיץ המשותף.\n2. מניעת גלישה (overflow) ותת-גלישה (underflow) בחיץ.\n3. אכיפת המגבלה על מספר היצרנים הפעילים.\n4. מניעת מצבי קיפאון (deadlock) ורעב (starvation).\n\nיש להניח כי `BUFFER_SIZE` ו-`MAX_ACTIVE_PRODUCERS` הם קבועים גלובליים חיוביים, וכי הסמפורים הותחלו כראוי. אין צורך לממש את `produce_item()` או `consume_item()`, אלא רק את לוגיקת הסמפורים.", "code_snippet": "/* Global declarations for buffer and semaphores */\n#include <semaphore.h>\n#include <stdlib.h>\n\n#define BUFFER_SIZE 10\n#define MAX_ACTIVE_PRODUCERS 3\n\nint buffer[BUFFER_SIZE];\nint in = 0;\nint out = 0;\n\nsem_t mutex; /* For mutual exclusion to buffer */\nsem_t empty; /* Counts empty slots in buffer */\nsem_t full;  /* Counts full slots in buffer */\nsem_t active_producers_limit; /* Limits concurrent active producers */\n\n/* Assume semaphores are initialized as follows:\n * sem_init(&mutex, 0, 1);\n * sem_init(&empty, 0, BUFFER_SIZE);\n * sem_init(&full, 0, 0);\n * sem_init(&active_producers_limit, 0, MAX_ACTIVE_PRODUCERS);\n */\n\nvoid *producer_thread_func(void *arg) {\n    int item;\n    while (1) {\n        // Step 1: Limit active producers\n        // Acquire a slot to be an active producer for item production\n        sem_wait(&active_producers_limit);\n\n        // Simulate item production (critical section for production)\n        // This is the phase where the producer is \"actively trying to produce\"\n        item = rand() % 100; // Placeholder for produce_item()\n\n        // Release the active producer slot once item is produced.\n        // This allows another producer to start producing while this one waits for buffer space.\n        sem_post(&active_producers_limit);\n\n        // Step 2: Add item to buffer (standard bounded buffer logic)\n        sem_wait(&empty); // Wait for an empty slot in the buffer\n        sem_wait(&mutex); // Acquire buffer access lock\n\n        buffer[in] = item;\n        in = (in + 1) % BUFFER_SIZE;\n\n        sem_post(&mutex); // Release buffer access lock\n        sem_post(&full);  // Signal that a slot is now full\n\n        // Simulate some delay or other work after adding to buffer\n    }\n    return NULL;\n}\n\nvoid *consumer_thread_func(void *arg) {\n    int item;\n    while (1) {\n        // Step 1: Remove item from buffer (standard bounded buffer logic)\n        sem_wait(&full);  // Wait for a full slot in the buffer\n        sem_wait(&mutex); // Acquire buffer access lock\n\n        item = buffer[out];\n        out = (out + 1) % BUFFER_SIZE;\n\n        sem_post(&mutex); // Release buffer access lock\n        sem_post(&empty); // Signal that a slot is now empty\n\n        // Simulate some delay or other work after consuming\n    }\n    return NULL;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון משתמש בארבעה סמפורים:\n\n1.  `mutex` (סמפור בינארי, מאותחל ל-1): מגן על הגישה לחיץ המשותף (`buffer`, `in`, `out`) כדי להבטיח בלעדיות הדדית (mutual exclusion) בזמן הוספה או הוצאה של פריטים.\n2.  `empty` (סמפור סופר, מאותחל ל-`BUFFER_SIZE`): סופר את מספר המקומות הפנויים בחיץ. יצרנים מבצעים `sem_wait` עליו לפני הוספת פריט, וצרכנים מבצעים `sem_post` עליו לאחר הוצאת פריט.\n3.  `full` (סמפור סופר, מאותחל ל-0): סופר את מספר המקומות התפוסים בחיץ. צרכנים מבצעים `sem_wait` עליו לפני הוצאת פריט, ויצרנים מבצעים `sem_post` עליו לאחר הוספת פריט.\n4.  `active_producers_limit` (סמפור סופר, מאותחל ל-`MAX_ACTIVE_PRODUCERS`): סמפור זה אוכף את המגבלה על מספר היצרנים שיכולים להיות פעילים במקביל בשלב ייצור הפריט. יצרן מבצע `sem_wait` עליו לפני תחילת ייצור הפריט, ומבצע `sem_post` עליו מיד לאחר סיום הייצור, אך לפני הניסיון להכניס את הפריט לחיץ.\n\n**הסבר למימוש ולעמידה בדרישות:**\n\n*   **גישה בטוחה לחיץ המשותף (Mutual Exclusion):** הסמפור `mutex` מבטיח שרק תהליך אחד (יצרן או צרכן) יוכל לגשת לחיץ (`buffer`, `in`, `out`) בכל רגע נתון. הסדר של `sem_wait(&mutex)` ו-`sem_post(&mutex)` מבטיח שהקטע הקריטי (הוספה/הוצאה מהחיץ) מוגן.\n\n*   **מניעת גלישה ותת-גלישה (Overflow/Underflow):**\n    *   הסמפור `empty` מונע מיצרנים להוסיף פריטים לחיץ מלא. יצרן ייחסם על `sem_wait(&empty)` אם אין מקומות פנויים.\n    *   הסמפור `full` מונע מצרכנים להוציא פריטים מחיץ ריק. צרכן ייחסם על `sem_wait(&full)` אם אין פריטים בחיץ.\n\n*   **אכיפת המגבלה על מספר היצרנים הפעילים (`MAX_ACTIVE_PRODUCERS`):**\n    *   הסמפור `active_producers_limit` מאותחל ל-`MAX_ACTIVE_PRODUCERS`. כל יצרן שרוצה להתחיל לייצר פריט מבצע `sem_wait(&active_producers_limit)`. אם מספר היצרנים הפעילים הגיע למגבלה, יצרנים נוספים ייחסמו עד שיצרן פעיל ישחרר את הסמפור.\n    *   המיקום של `sem_post(&active_producers_limit)` מיד לאחר ייצור הפריט ולפני הגישה לחיץ הוא קריטי. הוא מאפשר ליצרן אחר להתחיל לייצר פריט חדש, גם אם היצרן הנוכחי ממתין למקום פנוי בחיץ. זה מגביר את המקביליות וממקסם את ניצולת המעבד עבור שלב הייצור.\n\n*   **מניעת מצבי קיפאון (Deadlock) ורעב (Starvation):**\n    *   הסדר הנכון של פעולות הסמפורים (`sem_wait` לפני `sem_post`, וסדר ספציפי עבור `mutex` ביחס ל-`empty`/`full`) בתבנית יצרן-צרכן הסטנדרטית מונע מצבי קיפאון.\n    *   הוספת הסמפור `active_producers_limit` אינה מציגה מצב קיפאון חדש מכיוון שהוא נרכש ומשוחרר לפני הגישה לסמפורי החיץ (`empty`, `mutex`, `full`), ובכך לא יוצר תלות מעגלית במשאבים.\n    *   השימוש בסמפורים, בהנחה שיישום `sem_wait` הוא הוגן (לרוב FIFO), מסייע במניעת רעב בכך שהוא מבטיח שבסופו של דבר כל תהליך ממתין יקבל גישה למשאב."}, "difficulty_estimation": "Hard", "_source_file": "0330__Semaphores__Open__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:50:29", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Semaphores", "Concurrency", "Resource Allocation", "Deadlock", "Starvation"], "content": {"text": "מערכת הפעלה מנהלת N תאי זיכרון רציפים (בלוקים בגודל יחידה), הממוספרים מ-0 עד N-1. תהליכים שונים צריכים להקצות בלוק של k תאי זיכרון רציפים לשימושם. כלומר, אם תהליך מבקש k תאים, הוא חייב לקבל את התאים `i, i+1, ..., i+k-1` עבור איזה `i` מתאים. לאחר שימוש, הוא משחרר את הבלוק. נניח שכל תא זיכרון מיוצג על ידי סמפור בינארי `sem_t slot_sem[N]` המאופס ל-1 בתחילת הריצה. הקוד הבא מציג ניסיון לממש את פונקציית ההקצאה `acquire_contiguous_slots(int k)`:\n\n1.  זהו את כל הבעיות בקוד המוצג (כגון תנאי מירוץ, קיפאון, רעב, חוסר יעילות). נמקו את תשובתכם.\n2.  כתבו פתרון מתוקן ומלא באמצעות סמפורים (ובמידת הצורך, מנעולים) שימנע את הבעיות שזיהיתם, ימנע קיפאון ורעב, ויאפשר מקסום מקביליות. הציגו את הקוד המלא של הפונקציות `acquire_contiguous_slots(int k)` ו-`release_contiguous_slots(int start_idx, int k)`.\n", "code_snippet": "#define N_SLOTS 10 // מספר כולל של תאי זיכרון\nsem_t slot_sem[N_SLOTS]; // סמפור בינארי לכל תא, מאותחל ל-1\n\n// פונקציית אתחול (נקראת פעם אחת בתחילת הריצה)\nvoid init_resources() {\n    for (int i = 0; i < N_SLOTS; ++i) {\n        sem_init(&slot_sem[i], 0, 1);\n    }\n}\n\n// פונקציה להקצאת k תאי זיכרון רציפים\nint acquire_contiguous_slots(int k) {\n    int start_idx = -1;\n    while (start_idx == -1) { // לולאת busy-wait\n        for (int i = 0; i <= N_SLOTS - k; ++i) {\n            bool all_acquired = true;\n            for (int j = 0; j < k; ++j) {\n                if (sem_trywait(&slot_sem[i+j]) != 0) { // ניסיון לרכוש\n                    all_acquired = false;\n                    // שחרור סמפורים שכבר נרכשו בבלוק הנוכחי\n                    for (int l = 0; l < j; ++l) {\n                        sem_post(&slot_sem[i+l]);\n                    }\n                    break;\n                }\n            }\n            if (all_acquired) {\n                start_idx = i;\n                break; // נמצא בלוק וכולו נרכש\n            }\n        }\n    }\n    return start_idx; // מחזיר את אינדקס ההתחלה של הבלוק\n}\n\n// פונקציה לשחרור k תאי זיכרון רציפים\nvoid release_contiguous_slots(int start_idx, int k) {\n    for (int j = 0; j < k; ++j) {\n        sem_post(&slot_sem[start_idx + j]);\n    }\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\n**1. זיהוי בעיות בקוד המוצג:**\n\n*   **רעב (Starvation):** תהליך עשוי לסבול מרעב. אם תהליך מנסה לרכוש בלוק של k תאים, הוא עשוי שוב ושוב למצוא בלוקים פנויים חלקית, לרכוש אותם, לשחרר אותם (כאשר הוא מגלה שאינו יכול להשלים את הבלוק כולו), ולנסות שוב. בינתיים, תהליכים אחרים (אולי כאלה שמבקשים בלוקים קטנים יותר או בלוקים אחרים) עשויים להצליח לרכוש משאבים. אין מנגנון הוגנות שמבטיח שתהליך יקבל את המשאבים בסופו של דבר.\n*   **Busy-waiting (בזבוז משאבי מעבד):** לולאת ה-`while (start_idx == -1)` החיצונית היא busy-wait. אם אין בלוק זמין באופן מיידי, התהליך ממשיך לבדוק שוב ושוב את כל הבלוקים האפשריים בלולאה אינסופית, ובכך מבזבז משאבי מעבד יקרים במקום להיכנס למצב חסימה ולהמתין לאירוע כלשהו (כמו שחרור בלוק).\n*   **חוסר יעילות:** שחרור ורכישה חוזרים ונשנים של סמפורים בתוך הלולאה הפנימית (כאשר `sem_trywait` נכשל) הוא לא יעיל. בנוסף, כל תהליך מבצע סריקה מלאה של כל תאי הזיכרון בכל איטרציה, גם אם לא היה שינוי משמעותי במצב התאים.\n*   **תנאי מירוץ (Race Conditions) לוגיים:** למרות שפעולות `sem_trywait` ו-`sem_post` הן אטומיות, הלוגיקה הכוללת של איתור בלוק פנוי ורכישתו אינה מוגנת. שני תהליכים יכולים לזהות בו-זמנית את אותו בלוק פנוי או בלוקים חופפים, מה שיוביל לכך שאחד מהם ירכוש חלקית, ישחרר וינסה שוב, או ששניהם יחמיצו בלוק שהיה זמין אם היו מתואמים. זה יכול להחמיר את בעיית הרעב.\n*   **קיפאון (Deadlock):** במקרה זה, הקוד המוצג אינו מוביל ישירות לקיפאון במובן הקלאסי של מעגל המתנה. מכיוון שהוא משתמש ב-`sem_trywait` ומשחרר משאבים מיד עם כישלון, הוא נמנע ממצב של החזקה והמתנה מעגלית. עם זאת, הוא סובל מהבעיות החמורות של רעב ובזבוז משאבים כמפורט לעיל.\n\n**2. פתרון מתוקן:**\n\nהפתרון הנכון דורש מנגנון מרכזי שיגן על תהליך האיתור וההקצאה של הבלוק הרציף. נשתמש במנעול (mutex) כדי להבטיח שרק תהליך אחד יחפש ויקצה בלוק בכל רגע נתון. בנוסף, נשתמש במערך בוליאני כדי לעקוב אחר מצב התאים (פנוי/תפוס) לצורך חיפוש יעיל.\n\n```c\n#include <semaphore.h>\n#include <pthread.h>\n#include <stdbool.h>\n#include <stdio.h>\n\n#define N_SLOTS 10 // מספר כולל של תאי זיכרון\n\nsem_t slot_sem[N_SLOTS]; // סמפור בינארי לכל תא, מאותחל ל-1\npthread_mutex_t allocation_mutex; // מנעול להגנה על לוגיקת ההקצאה/שחרור\nbool is_slot_free[N_SLOTS]; // עוקב אחר מצב פנוי/תפוס של כל תא\npthread_cond_t new_slots_available_cond; // משתנה תנאי להתראה על שחרור תאים\n\n// פונקציית אתחול (נקראת פעם אחת בתחילת הריצה)\nvoid init_resources() {\n    for (int i = 0; i < N_SLOTS; ++i) {\n        sem_init(&slot_sem[i], 0, 1); // כל סמפור מאותחל ל-1\n        is_slot_free[i] = true; // כל התאים פנויים בתחילה\n    }\n    pthread_mutex_init(&allocation_mutex, NULL); // אתחול מנעול\n    pthread_cond_init(&new_slots_available_cond, NULL); // אתחול משתנה תנאי\n}\n\n// פונקציה להקצאת k תאי זיכרון רציפים\nint acquire_contiguous_slots(int k) {\n    int start_idx = -1;\n\n    pthread_mutex_lock(&allocation_mutex); // נכנסים לאזור קריטי\n    while (start_idx == -1) {\n        // סורקים למצוא בלוק רציף פנוי\n        for (int i = 0; i <= N_SLOTS - k; ++i) {\n            bool possible = true;\n            for (int j = 0; j < k; ++j) {\n                if (!is_slot_free[i + j]) {\n                    possible = false;\n                    i = i + j; // מדלגים מעבר לבלוק תפוס\n                    break;\n                }\n            }\n            if (possible) {\n                start_idx = i;\n                // מסמנים את התאים כתפוסים במערך המעקב\n                for (int j = 0; j < k; ++j) {\n                    is_slot_free[i + j] = false;\n                }\n                break; // נמצא בלוק\n            }\n        }\n\n        if (start_idx == -1) {\n            // אם לא נמצא בלוק, ממתינים לשחרור תאים\n            pthread_cond_wait(&new_slots_available_cond, &allocation_mutex);\n        }\n    }\n    pthread_mutex_unlock(&allocation_mutex); // יוצאים מהאזור הקריטי\n\n    // כעת, כשהבלוק סומן כתפוס במערך is_slot_free, רוכשים את הסמפורים הספציפיים.\n    // אנו יודעים שהם פנויים כי ה-allocation_mutex הגן על הלוגיקה.\n    for (int j = 0; j < k; ++j) {\n        sem_wait(&slot_sem[start_idx + j]);\n    }\n\n    return start_idx;\n}\n\n// פונקציה לשחרור k תאי זיכרון רציפים\nvoid release_contiguous_slots(int start_idx, int k) {\n    if (start_idx < 0 || start_idx + k > N_SLOTS) {\n        fprintf(stderr, \"Error: Invalid release range.\\n\");\n        return;\n    }\n\n    // משחררים את הסמפורים הספציפיים\n    for (int j = 0; j < k; ++j) {\n        sem_post(&slot_sem[start_idx + j]);\n    }\n\n    pthread_mutex_lock(&allocation_mutex); // נכנסים לאזור קריטי\n    // מסמנים את התאים כפנויים במערך המעקב\n    for (int j = 0; j < k; ++j) {\n        is_slot_free[start_idx + j] = true;\n    }\n    // מודיעים לתהליכים ממתינים שאולי יש תאים פנויים כעת\n    pthread_cond_broadcast(&new_slots_available_cond); \n    pthread_mutex_unlock(&allocation_mutex); // יוצאים מהאזור הקריטי\n}\n```\n\n**הסבר לפתרון המתוקן:**\n\n1.  **מנעול `allocation_mutex`:** מנעול זה מגן על המצב המשותף של מערך `is_slot_free` ועל לוגיקת החיפוש וההקצאה. הוא מבטיח שרק תהליך אחד בכל פעם יבצע את פעולת החיפוש והסימון של הבלוקים כפנויים/תפוסים, ובכך מונע תנאי מירוץ לוגיים.\n2.  **מערך `is_slot_free`:** מערך בוליאני זה משמש למעקב מהיר ויעיל אחר מצב הפניות של כל תא זיכרון. החיפוש מתבצע על מערך זה תחת הגנת ה-`allocation_mutex`.\n3.  **משתנה תנאי `new_slots_available_cond`:** במקום busy-waiting, תהליכים שלא מוצאים בלוק פנוי נכנסים למצב חסימה באמצעות `pthread_cond_wait`. כאשר תהליך משחרר בלוק (בפונקציה `release_contiguous_slots`), הוא מאותת (באמצעות `pthread_cond_broadcast`) לכל התהליכים הממתינים שאולי יש כעת תאים פנויים, והם מתעוררים כדי לנסות שוב להקצות.\n4.  **רכישת סמפורים בודדים לאחר ההקצאה הלוגית:** לאחר שבלוק רציף זוהה וסומן כתפוס במערך `is_slot_free` (תחת הגנת ה-`allocation_mutex`), התהליך משחרר את ה-`allocation_mutex` ורק אז מבצע `sem_wait` על הסמפורים הספציפיים של התאים בבלוק. פעולה זו בטוחה מכיוון שה-`allocation_mutex` הבטיח שאף תהליך אחר לא יסמן את התאים הללו כתפוסים, ולכן הסמפורים יהיו זמינים לרכישה מיידית (או שהם כבר נרכשו על ידי תהליך זה עצמו, אם היה צורך בכך – אך במקרה זה הם תמיד יהיו זמינים כי ה-`is_slot_free` מגן על כך). גישה זו מונעת קיפאון ומאפשרת מקביליות מקסימלית על ידי כך שהיא משחררת את המנעול המרכזי בזמן השימוש בפועל במשאבים.\n5.  **מניעת רעב:** השימוש ב-`pthread_cond_wait` וב-`pthread_cond_broadcast` בשילוב עם מנעול מבטיח שכל תהליך שממתין יקבל הזדמנות לנסות להקצות בלוק כאשר משאבים משתחררים, ובכך מפחית משמעותית את הסיכון לרעב (בהתחשב בהוגנות של מתזמן התהליכים).\n6.  **יעילות:** נמנע בזבוז משאבי מעבד כתוצאה מ-busy-waiting. החיפוש הופך ליעיל יותר מכיוון שהוא מוגן ואינו מתנגש עם חיפושים של תהליכים אחרים."}, "difficulty_estimation": "Hard", "_source_file": "0331__Semaphores__Open__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:51:35", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Semaphores", "Synchronization", "Producer-Consumer", "Deadlock", "Starvation"], "content": {"text": "נתונה מערכת ייצור המורכבת משני סוגי תהליכים: `Assembler` (מרכיב) ו-`Finisher` (מסיים). תהליכים אלו משתפים ביניהם חוצץ (buffer) בגודל קבוע `BUFFER_SIZE` עבור מוצרים בהרכבה חלקית.\n\n*   **תהליכי `Assembler`:**\n    *   כל תהליך `Assembler` צריך לקבל זרוע רובוטית (`RobotArm`) כדי להרכיב מוצר חלקי. קיימות `R` זרועות רובוטיות זמינות במפעל.\n    *   לאחר הרכבת המוצר החלקי, הוא מוכנס לחוצץ.\n*   **תהליכי `Finisher`:**\n    *   כל תהליך `Finisher` מוציא מוצר חלקי מהחוצץ.\n    *   לאחר מכן, הוא צריך לקבל עמדת בקרת איכות (`QualityControlStation`) כדי לסיים את המוצר. קיימות `Q` עמדות בקרת איכות זמינות במפעל.\n\n**מגבלות נוספות:**\n1.  החוצץ יכול להכיל לכל היותר `BUFFER_SIZE` מוצרים חלקיים.\n2.  כדי למנוע עומס יתר, מספר המוצרים החלקיים הכולל בכל רגע נתון (אלו הנמצאים בחוצץ, בתוספת אלו שמטופלים כרגע על ידי תהליכי `Finisher`) מוגבל ל-`MAX_WIP`.\n\nכתבו את פונקציות `assemble_product()` ו-`finish_product()` המממשות את הלוגיקה של תהליכי ה-`Assembler` וה-`Finisher` בהתאמה, תוך שימוש בסמפורים בלבד. עליכם להגדיף את כל הסמפורים הנדרשים ולציין את ערכי האתחול שלהם.\n\n**שאלה:**\nהאם המימוש שהצעתם עלול לגרום לקיפאון (deadlock) או להרעבה (starvation)? אם כן, הסבירו מדוע וכיצד ניתן לפתור זאת. אם לא, הסבירו מדוע.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\n**הגדרת סמפורים וערכי אתחול:**\n```c\n#include <semaphore.h>\n#include <stdio.h>\n#include <stdlib.h> \n#include <pthread.h>\n#include <unistd.h> \n\n// הגדרות קבועים (לדוגמה)\n#define R 2             // מספר זרועות רובוטיות זמינות\n#define Q 1             // מספר עמדות בקרת איכות זמינות\n#define BUFFER_SIZE 5   // גודל החוצץ המשותף\n#define MAX_WIP 7       // מגבלת מוצרים בהרכבה (Work-In-Progress) הכוללת (בחוצץ + בטיפול)\n\n// סמפורים\nsem_t robotArms;        // סמפור ספירה לאתחול ב-R. שולט בגישה לזרועות רובוטיות.\nsem_t qcStations;       // סמפור ספירה לאתחול ב-Q. שולט בגישה לעמדות בקרת איכות.\nsem_t emptySlots;       // סמפור ספירה לאתחול ב-BUFFER_SIZE. מייצג מקומות פנויים בחוצץ.\nsem_t filledSlots;      // סמפור ספירה לאתחול ב-0. מייצג מקומות תפוסים בחוצץ.\nsem_t buffer_mutex;     // סמפור בינארי (mutex) לאתחול ב-1. להגנה על גישה לחוצץ.\nsem_t wip_limit;        // סמפור ספירה לאתחול ב-MAX_WIP. מגביל את כמות המוצרים בהרכבה הכוללת.\n\n// חוצץ משותף (לדוגמה, מערך פשוט)\nint buffer[BUFFER_SIZE];\nint in = 0, out = 0;\n\n// פונקציית אתחול לסמפורים (תקרא פעם אחת בתוכנית הראשית)\nvoid init_semaphores() {\n    sem_init(&robotArms, 0, R);\n    sem_init(&qcStations, 0, Q);\n    sem_init(&emptySlots, 0, BUFFER_SIZE);\n    sem_init(&filledSlots, 0, 0);\n    sem_init(&buffer_mutex, 0, 1);\n    sem_init(&wip_limit, 0, MAX_WIP);\n}\n```\n\n**פונקציות `assemble_product()` ו-`finish_product()`:**\n\n```c\nvoid assemble_product() {\n    // תהליך מרכיב (Assembler)\n    // 1. קבל חריץ במגבלת ה-WIP הכוללת (מונים מוצר זה כ-WIP מרגע שההרכבה החלה).\n    sem_wait(&wip_limit); \n\n    // 2. קבל זרוע רובוטית.\n    sem_wait(&robotArms); \n    printf(\"Assembler: Acquired Robot Arm, assembling product...\\n\");\n    // simulate_assembly(); // סימולציית הרכבה\n    // 3. שחרר זרוע רובוטית.\n    sem_post(&robotArms); \n\n    // 4. קבל חריץ פנוי בחוצץ.\n    sem_wait(&emptySlots); \n    // 5. קבל מנעול לגישה לחוצץ.\n    sem_wait(&buffer_mutex); \n\n    // הוסף פריט לחוצץ\n    buffer[in] = 1; // ייצוג פשוט של מוצר\n    in = (in + 1) % BUFFER_SIZE;\n    printf(\"Assembler: Product assembled and put into buffer. (WIP slot taken, Robot Arm used)\\n\");\n    \n    // 6. שחרר מנעול לגישה לחוצץ.\n    sem_post(&buffer_mutex); \n    // 7. אותת שהחוצץ מכיל כעת פריט נוסף.\n    sem_post(&filledSlots);  \n}\n\nvoid finish_product() {\n    // תהליך מסיים (Finisher)\n    // 1. קבל חריץ מלא מהחוצץ.\n    sem_wait(&filledSlots); \n    // 2. קבל מנעול לגישה לחוצץ.\n    sem_wait(&buffer_mutex); \n\n    // הוצא פריט מהחוצץ\n    // int product = buffer[out];\n    out = (out + 1) % BUFFER_SIZE;\n    printf(\"Finisher: Took product from buffer.\\n\");\n\n    // 3. שחרר מנעול לגישה לחוצץ.\n    sem_post(&buffer_mutex); \n    // 4. אותת שהחוצץ מכיל כעת חריץ פנוי נוסף.\n    sem_post(&emptySlots); \n\n    // 5. קבל עמדת בקרת איכות.\n    sem_wait(&qcStations); \n    printf(\"Finisher: Acquired QC Station, finishing product...\\n\");\n    // simulate_finishing(product); // סימולציית סיום\n    // 6. שחרר עמדת בקרת איכות.\n    sem_post(&qcStations); \n\n    // 7. המוצר גמור לחלוטין, שחרר את חריץ ה-WIP הגלובלי.\n    sem_post(&wip_limit); \n    printf(\"Finisher: Product finished and released. (WIP slot released, QC Station used)\\n\");\n}\n```\n\n**ניתוח קיפאון (Deadlock) והרעבה (Starvation):**\n\n**קיפאון (Deadlock):**\nהמימוש המוצע אינו צפוי לגרום לקיפאון. קיפאון נוצר כאשר קיימת תלות מעגלית במשאבים בין תהליכים. נבחן את סדר רכישת המשאבים:\n*   **תהליכי `Assembler` רוכשים משאבים בסדר הבא:** `wip_limit` -> `robotArms` (משוחרר) -> `emptySlots` -> `buffer_mutex`.\n*   **תהליכי `Finisher` רוכשים משאבים בסדר הבא:** `filledSlots` -> `buffer_mutex` -> `qcStations` (משוחרר).\n\nאין כאן תלות מעגלית ברכישת משאבים: `buffer_mutex` נרכש תמיד לאחר `emptySlots` (על ידי `Assembler`) או `filledSlots` (על ידי `Finisher`). סדר זה, יחד עם העובדה ש-`wip_limit` נרכש על ידי המרכיב ומשוחרר על ידי המסיים (ומשמש כבקרת זרימה גלובלית ולא כמשאב שנתקע במחזור), מונע מצב של קיפאון. למשל, `Assembler` לא יכול להחזיק ב-`buffer_mutex` ולחכות ל-`emptySlots` כי הוא רוכש את `emptySlots` לפני ה-`buffer_mutex`. באופן דומה, `Finisher` לא יכול להחזיק ב-`buffer_mutex` ולחכות ל-`filledSlots` מסיבה דומה.\n\n**הרעבה (Starvation):**\nמימוש סמפורים סטנדרטי (כמו זה שב-`POSIX semaphores`) בדרך כלל אינו מבטיח הוגנות (fairness) בסדר ההתעוררות של תהליכים הממתינים לסמפור. כאשר מספר תהליכים ממתינים על סמפור (באמצעות `sem_wait`) ותהליך אחר מבצע `sem_post`, מערכת ההפעלה בוחרת איזה תהליך להעיר. ייתכן מצב שבו תהליך מסוים נדחה שוב ושוב לטובת תהליכים אחרים, ובכך הוא \"מורעב\" מגישה למשאב. מצב זה יכול להתרחש עבור כל אחד מהסמפורים: `robotArms`, `qcStations`, `emptySlots`, `filledSlots`, `buffer_mutex`, ו-`wip_limit`. כדי למנוע הרעבה באופן מוחלט, נדרש מנגנון תור הוגן (כמו תור FIFO) הממומש על גבי הסמפורים, אך זהו מימוש מורכב יותר שאינו חלק משימוש בסיסי בסמפורים."}, "difficulty_estimation": "Hard", "_source_file": "0332__Semaphores__Open__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:52:21", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Semaphores", "Synchronization", "Reader-Writer Problem", "Deadlock Prevention", "Starvation Prevention"], "content": {"text": "נתונה מערכת עם משאב משותף אליו ניגשים תהליכי קוראים (Readers) ותהליכי כותבים (Writers).\nמספר קוראים יכולים לגשת למשאב בו זמנית.\nרק כותב אחד יכול לגשת למשאב בכל רגע נתון, ואין קוראים או כותבים אחרים בזמן כתיבה.\nנדרש לממש מדיניות עדיפות לכותבים: אם כותב ממתין, אף קורא חדש לא יוכל להתחיל לקרוא עד שהכותב יסיים את פעולתו (קוראים שכבר קוראים יכולים להמשיך עד לסיום).\nמדיניות זו נועדה למנוע הרעבה (Starvation) של כותבים.\n\nהשלם את קטעי הקוד הבאים עבור הפונקציות reader_task ו-writer_task תוך שימוש בסמפורים בלבד, כך שיענו על הדרישות הנ\"ל.\nהנח שהסמפורים והמשתנים הגלובליים (read_count, write_count) מוגדרים ומאותחלים כראוי.", "code_snippet": "#include <semaphore.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\n// Global semaphores and counters (to be initialized)\nsem_t resource_access;        // Controls access to the shared resource\nsem_t mutex_read_count;     // Protects read_count\nsem_t mutex_write_count;    // Protects write_count\nsem_t readers_queue_block;  // Blocks new readers if writers are waiting\n\nint read_count = 0;   // Number of readers currently reading\nint write_count = 0;  // Number of writers currently writing (should be 0 or 1)\n\n// Shared resource (simplified)\nint shared_data = 0;\n\nvoid reader_task() {\n    // TODO: Implement semaphore logic for reader\n    \n    // Critical Section: Reading\n    printf(\"Reader %lu is reading: %d\\n\", pthread_self(), shared_data);\n    sleep(1); // Simulate reading time\n    \n    // TODO: Implement semaphore logic for reader\n}\n\nvoid writer_task() {\n    // TODO: Implement semaphore logic for writer\n    \n    // Critical Section: Writing\n    shared_data++;\n    printf(\"Writer %lu is writing: %d\\n\", pthread_self(), shared_data);\n    sleep(2); // Simulate writing time\n    \n    // TODO: Implement semaphore logic for writer\n}\n\n// Main function for initialization and thread creation (not part of the answer)\n// int main() {\n//     sem_init(&resource_access, 0, 1);\n//     sem_init(&mutex_read_count, 0, 1);\n//     sem_init(&mutex_write_count, 0, 1);\n//     sem_init(&readers_queue_block, 0, 1);\n//     // ... create threads ...\n//     return 0;\n// }"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\n**1. השלמת קטעי הקוד:**\n\n```c\n#include <semaphore.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\n// Global semaphores and counters (to be initialized)\nsem_t resource_access;        // Controls access to the shared resource\nsem_t mutex_read_count;     // Protects read_count\nsem_t mutex_write_count;    // Protects write_count\nsem_t readers_queue_block;  // Blocks new readers if writers are waiting\n\nint read_count = 0;   // Number of readers currently reading\nint write_count = 0;  // Number of writers currently writing (should be 0 or 1)\n\n// Shared resource (simplified)\nint shared_data = 0;\n\nvoid reader_task() {\n    sem_wait(&readers_queue_block); // Wait if writers are waiting/writing\n    sem_wait(&mutex_read_count);\n    read_count++;\n    if (read_count == 1) { // First reader\n        sem_wait(&resource_access); // Acquire resource_access\n    }\n    sem_post(&mutex_read_count);\n    sem_post(&readers_queue_block); // Allow other readers to pass readers_queue_block\n\n    // Critical Section: Reading\n    printf(\"Reader %lu is reading: %d\\n\", pthread_self(), shared_data);\n    sleep(1); // Simulate reading time\n\n    sem_wait(&mutex_read_count);\n    read_count--;\n    if (read_count == 0) { // Last reader\n        sem_post(&resource_access); // Release resource_access\n    }\n    sem_post(&mutex_read_count);\n}\n\nvoid writer_task() {\n    sem_wait(&mutex_write_count);\n    write_count++;\n    if (write_count == 1) { // First writer\n        sem_wait(&readers_queue_block); // Block new readers from entering\n    }\n    sem_post(&mutex_write_count);\n\n    sem_wait(&resource_access); // Get exclusive access\n\n    // Critical Section: Writing\n    shared_data++;\n    printf(\"Writer %lu is writing: %d\\n\", pthread_self(), shared_data);\n    sleep(2); // Simulate writing time\n\n    sem_post(&resource_access); // Release exclusive access\n\n    sem_wait(&mutex_write_count);\n    write_count--;\n    if (write_count == 0) { // Last writer\n        sem_post(&readers_queue_block); // Allow readers to enter again\n    }\n    sem_post(&mutex_write_count);\n}\n\n// Main function for initialization and thread creation (not part of the answer)\n// int main() {\n//     sem_init(&resource_access, 0, 1);\n//     sem_init(&mutex_read_count, 0, 1);\n//     sem_init(&mutex_write_count, 0, 1);\n//     sem_init(&readers_queue_block, 0, 1);\n//     // ... create threads ...\n//     return 0;\n// }\n```\n\n**2. הסבר על הפתרון ומניעת הרעבה:**\n\nהפתרון המוצע מיישם את בעיית קוראים-כותבים בעדיפות לכותבים, תוך שימוש בארבעה סמפורים בינאריים ושני מונים גלובליים.\n\n**תפקידי הסמפורים והמשתנים הגלובליים:**\n*   `resource_access` (סמפור בינארי, מאותחל ל-1): זהו הסמפור הראשי השולט על הגישה למשאב המשותף עצמו. כותבים חייבים לבצע `sem_wait` עליו כדי לגשת למשאב באופן בלעדי. קוראים משתמשים בו באופן קולקטיבי: הקורא הראשון שנכנס מבצע `sem_wait` והקורא האחרון שיוצא מבצע `sem_post`. זה מבטיח שרק כותב אחד או מספר קוראים יכולים לגשת למשאב, אך לא שניהם יחד.\n*   `mutex_read_count` (סמפור בינארי, מאותחל ל-1): מגן על הגישה למונה `read_count`. הוא מבטיח שרק תהליך אחד בכל רגע נתון יכול לעדכן את `read_count` כדי למנוע תנאי מירוץ (Race Condition) בגישה למונה זה.\n*   `mutex_write_count` (סמפור בינארי, מאותחל ל-1): מגן על הגישה למונה `write_count`. בדומה ל-`mutex_read_count`, הוא מונע תנאי מירוץ בעת עדכון `write_count`.\n*   `readers_queue_block` (סמפור בינארי, מאותחל ל-1): זהו המנגנון העיקרי למתן עדיפות לכותבים ולמניעת הרעבתם. כותב ראשון שמגיע (כלומר `write_count` הופך ל-1) מבצע `sem_wait` על סמפור זה, ובכך חוסם כל קורא חדש מלהיכנס ללולאת הגישה למשאב. רק כאשר הכותב האחרון מסיים (כלומר `write_count` חוזר ל-0), הוא מבצע `sem_post` ובכך מאפשר לקוראים חדשים להמשיך.\n*   `read_count` (מונה שלם, מאותחל ל-0): סופר את מספר הקוראים הפעילים כרגע במשאב המשותף. כאשר הוא מגיע ל-1, הקורא הראשון מנסה לרכוש את `resource_access`. כאשר הוא מגיע ל-0, הקורא האחרון משחרר את `resource_access`.\n*   `write_count` (מונה שלם, מאותחל ל-0): סופר את מספר הכותבים הממתינים או הפעילים (בפועל, רק 0 או 1 פעילים). כאשר הוא מגיע ל-1, הכותב הראשון חוסם את `readers_queue_block`. כאשר הוא חוזר ל-0, הכותב האחרון משחרר את `readers_queue_block`.\n\n**מניעת הרעבה (Starvation) של כותבים:**\n\nהפתרון מונע הרעבה של כותבים באמצעות הסמפור `readers_queue_block` והמונה `write_count`. כאשר כותב מגיע ומגדיל את `write_count` ל-1 (כלומר, הוא הכותב הראשון שמגיע או הראשון שמתחיל לכתוב לאחר תקופה של חוסר כותבים), הוא מבצע `sem_wait(&readers_queue_block)`. פעולה זו חוסמת כל קורא עתידי מלהיכנס לאזור הקריטי של הקוראים. קוראים שכבר נמצאים באזור הקריטי ימשיכו לסיים את עבודתם, וכאשר הקורא האחרון יצא, הוא ישחרר את `resource_access`. בשלב זה, הכותב הממתין יוכל לרכוש את `resource_access` ולהתחיל לכתוב. רק לאחר שהכותב מסיים ו-`write_count` חוזר ל-0, הוא משחרר את `readers_queue_block`, מה שמאפשר לקוראים חדשים להיכנס שוב. בכך, לכותבים יש עדיפות מובהקת על פני קוראים חדשים, ומונעת מצב שבו זרם בלתי פוסק של קוראים ימנע מכותב אי פעם לגשת למשאב."}, "difficulty_estimation": "Hard", "_source_file": "0333__Semaphores__Open__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:53:00", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Semaphores", "Synchronization", "Resource Management", "Starvation Prevention", "Mutual Exclusion"], "content": {"text": "נתונה מערכת בעלת N יחידות עיבוד (לדוגמה, GPU). ישנם שני סוגי משימות:\n1.  **משימות אצווה (Batch Jobs)**: כל משימת אצווה דורשת את כל N יחידות העיבוד באופן בלעדי. רק משימת אצווה אחת יכולה לרוץ בכל רגע נתון.\n2.  **משימות אינטראקטיביות (Interactive Jobs)**: כל משימה אינטראקטיבית דורשת יחידת עיבוד אחת בלבד. מספר משימות אינטראקטיביות יכולות לרוץ במקביל, כל עוד יש יחידות פנויות.\n\nעליכם לתכנן מנגנון סנכרון באמצעות סמפורים בשפת C/C++ אשר יבטיח את הדברים הבאים:\nא.  הקצאת משאבים נכונה: משימות אצווה מקבלות את כל N היחידות, ומשימות אינטראקטיביות מקבלות יחידה אחת.\nב.  הדדיות (Mutual Exclusion): כאשר משימת אצווה רצה, אף משימה אינטראקטיבית אינה יכולה לרוץ, ולהיפך.\nג.  מניעת הרעבה (Starvation Prevention): אף סוג של משימה לא יסבול מהרעבה.\n\nיש לכלול את הגדרות הסמפורים והמשתנים הגלובליים, ואת קוד המבנה של הפונקציות עבור כל סוג משימה (acquire/release).", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\nהבעיה היא וריאציה של בעיית ה\"קוראים והכותבים\" (Readers-Writers Problem) עם העדפה לכותבים (Writer Preference), כאשר משימות אצווה הן ה\"כותבים\" ומשימות אינטראקטיביות הן ה\"קוראים\". ההבדל העיקרי הוא שמשימות אצווה דורשות את כל N היחידות באופן בלעדי, בעוד שמשימות אינטראקטיביות דורשות יחידה אחת בלבד מתוך N היחידות הזמינות. מנגנון העדפה לכותבים (משימות אצווה) מבטיח מניעת הרעבה.\n\n**הגדרות גלובליות:**\n```c\n#include <semaphore.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n\n#define N_UNITS 5 // מספר יחידות העיבוד הכולל\n\n// סמפורים\nsem_t mutex;                 // מגן על המשתנים המשותפים active_interactive_jobs ו-waiting_batch_jobs. אתחול: 1\nsem_t batch_lock;            // מנגנון הדדיות למשימות אצווה מול משימות אינטראקטיביות. אתחול: 1\nsem_t interactive_slots;     // סמפור מונה עבור N היחידות הזמינות למשימות אינטראקטיביות. אתחול: N_UNITS\nsem_t batch_turnstile;       // מנגנון תור למשימות אצווה למניעת הרעבה של משימות אצווה. אתחול: 1\n\n// משתנים משותפים\nint active_interactive_jobs = 0; // מספר משימות אינטראקטיביות פעילות כרגע\nint waiting_batch_jobs = 0;      // מספר משימות אצווה שממתינות לריצה\n```\n\n**קוד עבור משימת אצווה (Batch Job):**\n```c\nvoid batch_job_acquire() {\n    sem_wait(&batch_turnstile);   // 1. נכנסים לתור העדיפות של משימות האצווה (מונע ממשימות אינטראקטיביות חדשות להתחיל אם יש משימות אצווה שממתינות)\n    sem_wait(&mutex);              // 2. מגן על המשתנים המשותפים\n    waiting_batch_jobs++;          // 3. הגדל מונה של משימות אצווה ממתינות\n    sem_post(&mutex);              // 4. שחרר מגן על המשתנים המשותפים\n\n    sem_wait(&batch_lock);         // 5. המתן לקבלת גישה בלעדית לכל N היחידות (משימת אצווה ממתינה עד שמשימות אינטראקטיביות יסיימו)\n    \n    // *** משימת האצווה מבצעת את עבודתה ***\n    printf(\"Batch Job acquired all %d units.\\n\", N_UNITS);\n    sleep(2); // הדמיית עבודה\n    printf(\"Batch Job released all %d units.\\n\", N_UNITS);\n}\n\nvoid batch_job_release() {\n    sem_post(&batch_lock);         // 6. שחרר את הגישה הבלעדית ל-N היחידות\n\n    sem_wait(&mutex);              // 7. מגן על המשתנים המשותפים\n    waiting_batch_jobs--;          // 8. הקטן מונה של משימות אצווה ממתינות\n    sem_post(&mutex);              // 9. שחרר מגן על המשתנים המשותפים\n    sem_post(&batch_turnstile);    // 10. אפשר למשימת האצווה הבאה (או למשימה אינטראקטיבית) לנסות להיכנס\n}\n```\n\n**קוד עבור משימה אינטראקטיבית (Interactive Job):**\n```c\nvoid interactive_job_acquire() {\n    sem_wait(&batch_turnstile);    // 1. נכנסים לתור העדיפות של משימות האצווה (אם משימת אצווה ממתינה, משימה אינטראקטיבית זו תמתין)\n    sem_wait(&mutex);              // 2. מגן על המשתנים המשותפים\n    active_interactive_jobs++;     // 3. הגדל מונה של משימות אינטראקטיביות פעילות\n    if (active_interactive_jobs == 1) { // 4. אם זו המשימה האינטראקטיבית הראשונה\n        sem_wait(&batch_lock);     // 5. חסום משימות אצווה מלהיכנס\n    }\n    sem_post(&mutex);              // 6. שחרר מגן על המשתנים המשותפים\n    sem_post(&batch_turnstile);    // 7. אפשר למשימה אינטראקטיבית הבאה לנסות להיכנס\n\n    sem_wait(&interactive_slots);  // 8. רכוש יחידת עיבוד אחת\n\n    // *** המשימה האינטראקטיבית מבצעת את עבודתה ***\n    printf(\"Interactive Job acquired 1 unit.\\n\");\n    sleep(1); // הדמיית עבודה\n    printf(\"Interactive Job released 1 unit.\\n\");\n}\n\nvoid interactive_job_release() {\n    sem_post(&interactive_slots);  // 9. שחרר יחידת עיבוד אחת\n\n    sem_wait(&mutex);              // 10. מגן על המשתנים המשותפים\n    active_interactive_jobs--;     // 11. הקטן מונה של משימות אינטראקטיביות פעילות\n    if (active_interactive_jobs == 0) { // 12. אם זו המשימה האינטראקטיבית האחרונה\n        sem_post(&batch_lock);     // 13. שחרר את החסימה עבור משימות אצווה\n    }\n    sem_post(&mutex);              // 14. שחרר מגן על המשתנים המשותפים\n}\n```\n\n**הסבר:**\nהפתרון המובא מיישם את תבנית \"קוראים וכותבים עם העדפה לכותבים\", כאשר:\n*   **משימות אצווה** מתנהגות כ\"כותבים\": הן דורשות גישה בלעדית לכל המשאבים (N יחידות)..\n*   **משימות אינטראקטיביות** מתנהגות כ\"קוראים\": הן דורשות יחידה אחת בלבד ויכולות לרוץ במקביל.\n\n1.  `batch_lock`: סמפור בינארי המשמש כמנגנון ההדדיות העיקרי. כאשר משימת אצווה פעילה, היא מחזיקה ב-`batch_lock`, ובכך מונעת ממשימות אינטראקטיביות להיכנס. כאשר משימות אינטראקטיביות פעילות, המשימה האינטראקטיבית הראשונה שרוכשת משאב רוכשת את `batch_lock`, ובכך מונעת ממשימות אצווה להיכנס.\n2.  `interactive_slots`: סמפור מונה המאותחל ל-N_UNITS. הוא מאפשר למשימות אינטראקטיביות לרכוש יחידת עיבוד אחת בכל פעם, עד שמגיעים למגבלה של N יחידות.\n3.  `mutex`: סמפור בינארי המגן על הגישה למשתנים המשותפים `active_interactive_jobs` ו-`waiting_batch_jobs`, אשר סופרים את מספר המשימות הפעילות והממתינות.\n4.  `batch_turnstile`: סמפור בינארי המשמש כמנגנון תור שנותן עדיפות למשימות אצווה. משימת אצווה רוכשת אותו בתחילת דרכה, ומשחררת אותו רק לאחר שרכשה (או המתינה ל-`batch_lock`). משימות אינטראקטיביות חייבות לרכוש ולשחרר אותו גם כן. אם משימת אצווה ממתינה על `batch_turnstile`, משימות אינטראקטיביות חדשות יחסמו שם, ובכך מובטח שמשימות אצווה לא יסבלו מהרעבה ויוכלו להיכנס כאשר המשאבים יתפנו.\n\n**תהליך ריצה:**\n*   **משימת אצווה:** רוכשת את `batch_turnstile` כדי למנוע ממשימות אינטראקטיביות חדשות להיכנס. מגדילה את `waiting_batch_jobs`. ממתינה ל-`batch_lock` (כלומר, ממתינה שכל המשימות האינטראקטיביות הפעילות יסיימו). ברגע ש-`batch_lock` נרכש, היא מקבלת גישה בלעדית לכל N היחידות. בסיום, היא משחררת את `batch_lock`, מקטינה את `waiting_batch_jobs`, ומשחררת את `batch_turnstile`.\n*   **משימה אינטראקטיבית:** רוכשת את `batch_turnstile` (אם משימת אצווה ממתינה על `batch_turnstile`, היא תמתין שם). מגדילה את `active_interactive_jobs`. אם היא המשימה האינטראקטיבית הראשונה שנכנסת, היא רוכשת את `batch_lock` (ובכך חוסמת משימות אצווה מלהיכנס). משחררת את `batch_turnstile` כדי לאפשר למשימות אינטראקטיביות נוספות להיכנס. רוכשת יחידה אחת מ-`interactive_slots`. בסיום, משחררת את יחידת העיבוד, מקטינה את `active_interactive_jobs`, ואם היא המשימה האינטראקטיבית האחרונה, משחררת את `batch_lock`."}, "difficulty_estimation": "Hard", "_source_file": "0334__Semaphores__Open__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:45:28", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Semaphores", "Synchronization", "Deadlock Prevention", "Concurrency"], "content": {"text": "נתבונן במערכת הכוללת שני סוגי משאבים: R1 ו-R2. קיימים N יחידות של R1 ו-M יחידות של R2. תהליכים במערכת צריכים יחידה אחת מכל סוג משאב (יחידה אחת מ-R1 ויחידה אחת מ-R2) כדי לבצע משימה כלשהי. התהליכים מבצעים את הפעולות הבאות ברצף:\n1.  מנסים לרכוש יחידה אחת מ-R1.\n2.  מנסים לרכוש יחידה אחת מ-R2.\n3.  מבצעים את המשימה.\n4.  משחררים את היחידה מ-R1.\n5.  משחררים את היחידה מ-R2.\n\nנתון קטע הקוד הבא המדמה תהליך כזה, כאשר sem_R1 ו-sem_R2 הם סמפורים המייצגים את כמות היחידות הזמינות מכל משאב בהתאמה (ערכם ההתחלתי הוא N ו-M):\n\nא. הסבירו מדוע קיים סיכון למצב של קיפאון (Deadlock) במערכת המתוארת. תארו תרחיש ספציפי שבו יתרחש קיפאון, בהינתן N=1, M=1, ושני תהליכים שמנסים לרכוש משאבים.\nב. הציעו פתרון לבעיית הקיפאון באמצעות סמפורים נוספים או שינוי באופן השימוש בסמפורים הקיימים, כך שהתהליכים יוכלו תמיד לבצע את משימתם ללא חשש מקיפאון, תוך שמירה על רמת מקביליות סבירה. צרפו קטע קוד מתוקן המדגים את הפתרון שלכם. הסבירו מדוע הפתרון שלכם מונע קיפאון ומהם היתרונות/חסרונות של הפתרון שבחרתם.", "code_snippet": "#include <semaphore.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For usleep\n\n// Global semaphores (initialized elsewhere with N and M)\nsem_t sem_R1; // Represents available units of Resource 1\nsem_t sem_R2; // Represents available units of Resource 2\n\nvoid *process_task(void *arg) {\n    long process_id = (long)arg;\n\n    printf(\"Process %ld: Attempting to acquire R1...\\n\", process_id);\n    sem_wait(&sem_R1); // Acquire R1\n    printf(\"Process %ld: Acquired R1. Attempting to acquire R2...\\n\", process_id);\n    \n    // Simulate some delay to increase deadlock probability\n    usleep(100); \n    \n    sem_wait(&sem_R2); // Acquire R2\n    printf(\"Process %ld: Acquired R2. Performing task...\\n\", process_id);\n    \n    // Simulate task execution\n    usleep(500); \n    \n    printf(\"Process %ld: Task complete. Releasing R1 and R2...\\n\", process_id);\n    sem_post(&sem_R1); // Release R1\n    sem_post(&sem_R2); // Release R2\n    \n    printf(\"Process %ld: Resources released.\\n\", process_id);\n    return NULL;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "חלק א' - הסבר לקיפאון:\nמצב של קיפאון (Deadlock) מתרחש כאשר קבוצת תהליכים חוסמים זה את זה ללא הרף, כאשר כל תהליך בקבוצה ממתין למשאב המוחזק על ידי תהליך אחר בקבוצה. במערכת המתוארת, מתקיימים ארבעת התנאים ההכרחיים לקיפאון:\n1.  **הדרה הדדית (Mutual Exclusion):** משאבי R1 ו-R2 ניתנים לרכישה בלעדית. יחידה אחת מכל משאב יכולה להיות מוחזקת על ידי תהליך אחד בלבד בכל רגע נתון.\n2.  **החזקה והמתנה (Hold and Wait):** תהליך יכול להחזיק במשאב אחד (למשל R1) תוך כדי שהוא ממתין למשאב אחר (R2).\n3.  **אי-נשללות (No Preemption):** משאבים אינם נשללים בכוח מתהליכים שמחזיקים בהם; רק התהליך המחזיק יכול לשחררם.\n4.  **המתנה מעגלית (Circular Wait):** תרחיש ספציפי: נניח N=1, M=1 ושני תהליכים P0 ו-P1.\n    *   P0 מבצע sem_wait(&sem_R1) ומצליח לרכוש את יחידת R1.\n    *   P1 מבצע sem_wait(&sem_R2) ומצליח לרכוש את יחידת R2 (בהנחה ש-P0 עוד לא ניסה לרכוש R2, או ש-P1 רץ במקביל).\n    *   כעת, P0 מנסה לבצע sem_wait(&sem_R2) אך נחסם, כיוון ש-R2 מוחזק על ידי P1.\n    *   במקביל, P1 מנסה לבצע sem_wait(&sem_R1) אך נחסם, כיוון ש-R1 מוחזק על ידי P0.\n    *   נוצרה המתנה מעגלית: P0 ממתין ל-P1 ו-P1 ממתין ל-P0. אף אחד מהם לא ישחרר את המשאב שברשותו, והמערכת נכנסת לקיפאון.\n\nחלק ב' - פתרון והסבר:\n\nפתרון מוצע: סמפור גלובלי (Mutex) להבטחת רכישה אטומית של שני המשאבים.\nכדי למנוע קיפאון, נשבור את תנאי 'החזקה והמתנה' על ידי הבטחה שתהליך ירכוש את כל המשאבים הדרושים לו (R1 ו-R2) בפעולה אטומית, או שלא ירכוש אף אחד מהם. ניתן לעשות זאת באמצעות סמפור בינארי (mutex) נוסף, שיגן על קטע הקוד שבו מתבצעת רכישת שני המשאבים. רק תהליך אחד יוכל להיכנס לקטע קריטי זה בכל רגע נתון, ובכך למנוע מצב שבו תהליכים מחזיקים חלק מהמשאבים וממתינים לאחרים.\n\nקוד מתוקן:\n```c\n#include <semaphore.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For usleep\n\n// Global semaphores\nsem_t sem_R1; // Represents available units of Resource 1\nsem_t sem_R2; // Represents available units of Resource 2\nsem_t acquisition_mutex; // New mutex for atomic resource acquisition\n\nvoid *process_task_fixed(void *arg) {\n    long process_id = (long)arg;\n\n    printf(\"Process %ld: Attempting to acquire both R1 and R2...\\n\", process_id);\n    sem_wait(&acquisition_mutex); // Enter critical section for acquisition\n    \n    // Now acquire R1 and R2 within the mutex protection\n    sem_wait(&sem_R1); // Acquire R1\n    sem_wait(&sem_R2); // Acquire R2\n    \n    sem_post(&acquisition_mutex); // Exit critical section for acquisition\n    \n    printf(\"Process %ld: Acquired R1 and R2. Performing task...\\n\", process_id);\n    \n    // Simulate task execution\n    usleep(500); \n    \n    printf(\"Process %ld: Task complete. Releasing R1 and R2...\\n\", process_id);\n    sem_post(&sem_R1); // Release R1\n    sem_post(&sem_R2); // Release R2\n    \n    printf(\"Process %ld: Resources released.\\n\", process_id);\n    return NULL;\n}\n```\n\nהסבר מדוע הפתרון מונע קיפאון:\nהוספת הסמפור acquisition_mutex מבטיחה שרק תהליך אחד יוכל לבצע את רכישת שני המשאבים (R1 ו-R2) בו-זמנית. מרגע שתהליך נכנס לקטע הקריטי המוגן על ידי acquisition_mutex, הוא ירכוש את sem_R1 ואת sem_R2 בזה אחר זה ללא הפרעה מתהליכים אחרים המנסים לרכוש משאבים. רק לאחר שירכוש את שניהם, הוא ישחרר את acquisition_mutex ויאפשר לתהליך אחר לנסות לרכוש.\nפתרון זה שובר את תנאי 'החזקה והמתנה' (Hold and Wait) בכך שהוא מבטיח שתהליך לא יחזיק במשאב אחד (R1) וימתין לאחר (R2) כאשר תהליך אחר יכול להיות במצב דומה. במקום זאת, תהליך ימתין על acquisition_mutex עד שיוכל לרכוש את *כל* המשאבים הדרושים לו לפני שהוא משחרר את ה-mutex. אם אין מספיק משאבים זמינים, הוא ייחסם בתוך ה-mutex (על sem_R1 או sem_R2), אך כיוון שהוא היחיד שמנסה לרכוש באותו רגע, לא תיווצר המתנה מעגלית עם תהליך אחר שמחזיק משאב אחר ומונע ממנו להתקדם.\nהוא גם מונע המתנה מעגלית מכיוון שכל תהליך שמצליח להיכנס לקטע הקריטי של הרכישה מבטיח לעצמו את כל המשאבים. אין מצב שבו תהליך A מחזיק R1 ומחכה ל-R2, ותהליך B מחזיק R2 ומחכה ל-R1, כיוון שרק אחד מהם יכול להיות בקטע הרכישה בו זמנית.\n\nיתרונות וחסרונות של הפתרון:\n*   **יתרונות:**\n    *   **מניעת קיפאון מובטחת:** הפתרון אכן מונע קיפאון ביעילות במקרה זה.\n    *   **פשטות יחסית:** קל להבנה וליישום.\n*   **חסרונות:**\n    *   **הפחתת מקביליות (Reduced Concurrency):** זהו החיסרון המרכזי. רק תהליך אחד יכול לרכוש משאבים (R1 ו-R2) בכל רגע נתון, גם אם יש מספיק יחידות מכל משאב כדי לאפשר לכמה תהליכים לרכוש בו-זמנית מבלי לגרום לקיפאון. לדוגמה, אם N=10 ו-M=10, יכולים להיות 10 תהליכים שמחזיקים R1 ו-10 תהליכים שמחזיקים R2 (אם נרכשו בסדר שונה), אך הפתרון שלנו מאפשר רק לתהליך אחד לרכוש את *זוג* המשאבים בכל רגע. זה מגביל את היכולת של המערכת לנצל את המקביליות הפוטנציאלית.\n    *   **בעיית רעב (Starvation) פוטנציאלית:** אם יש תהליכים רבים, ותהליך מסוים נתקל בחסימה על sem_R1 או sem_R2 בתוך ה-mutex, הוא יחזיק את ה-mutex וימנע מכל שאר התהליכים אפילו לנסות לרכוש משאבים, עד שיצליח או ישחרר (אם היינו משתמשים ב-trywait). במקרה הנוכחי, הוא פשוט ייחסם בתוך ה-mutex על אחד מסמפורי המשאבים, מה שיכול להוביל לחוסר יעילות."}, "difficulty_estimation": "Hard", "_source_file": "0335__Semaphores__Open__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:54:42", "_subject": "Concurrency"}, {"id": 7, "type": "Open", "topic": ["Semaphores", "Concurrency", "Deadlock", "Synchronization"], "content": {"text": "נתבונן במערכת המדמה פס ייצור תעשייתי, הכוללת שלושה סוגי עובדים (תהליכונים) ושני חוצצים (buffers) משותפים. עובדי הרכבה (Assemblers) מרכיבים חלקים ומכניסים אותם לחוצץ החלקים המורכבים (assembled_parts_buffer). עובדי בדיקה (Testers) לוקחים חלקים מהחוצץ הראשון, בודקים אותם, ומכניסים אותם לחוצץ החלקים המבוקרים (tested_parts_buffer). לבסוף, עובדי אריזה (Packers) לוקחים חלקים מהחוצץ השני ואורזים אותם. המערכת משתמשת בסמפורים לצורך סנכרון וניהול גישה לחוצצים. גודל כל חוצץ מוגבל.\n\nלפניכם קטע קוד בשפת C/C++ המממש חלק מהלוגיקה של עובד הבדיקה (tester). קטע קוד זה מכיל פגם לוגי.\n\n", "code_snippet": "/* כלולות: <semaphore.h>, <pthread.h>, <stdio.h>, <stdlib.h>, <unistd.h> */\n\n#define BUFFER_SIZE_A 5 // גודל חוצץ חלקים מורכבים\n#define BUFFER_SIZE_T 5 // גודל חוצץ חלקים מבוקרים\n\nsem_t mutex_A, full_A, empty_A; // סמפורים לחוצץ חלקים מורכבים\nsem_t mutex_T, full_T, empty_T; // סמפורים לחוצץ חלקים מבוקרים\n\n// במציאות, אלו יהיו מבני נתונים של חוצצים. לצורך הבעיה, נשתמש במונים פשוטים.\nint assembled_parts_count = 0;\nint tested_parts_count = 0;\n\n// פונקציות assembler ו-packer לא מוצגות במלואן, אך פועלות כצרכן/יצרן סטנדרטי.\n// לדוגמה, assembler:\n/*\nvoid *assembler(void *arg) {\n    while (1) {\n        sem_wait(&empty_A);\n        sem_wait(&mutex_A);\n        assembled_parts_count++;\n        printf(\"Assembler: Added part. Total assembled: %d\\n\", assembled_parts_count);\n        sem_post(&mutex_A);\n        sem_post(&full_A);\n        // ... (השהיה וכו')\n    }\n    return NULL;\n}\n*/\n\n// פונקציית עובד הבדיקה (Tester) - מכילה את הפגם\nvoid *tester(void *arg) {\n    while (1) {\n        // שלב 1: צריכת חלק מורכב מ-assembled_parts_buffer\n        sem_wait(&full_A);  // ממתין לחלק מורכב זמין\n        sem_wait(&mutex_A); // נועל גישה לחוצץ assembled_parts_buffer\n\n        assembled_parts_count--; // צורך חלק\n        printf(\"Tester: Consumed assembled part. Remaining: %d\\n\", assembled_parts_count);\n\n        // מדמה פעולת בדיקה\n        usleep(rand() % 100000 + 50000); \n\n        // שלב 2: ייצור חלק מבוקר והכנסתו ל-tested_parts_buffer\n        // ** פגם לוגי פוטנציאלי מתרחש כאן **\n        sem_wait(&empty_T); // ממתין למקום פנוי בחוצץ tested_parts_buffer\n        sem_wait(&mutex_T); // נועל גישה לחוצץ tested_parts_buffer\n\n        // רק לאחר שקיבלנו את שני הסמפורים לחוצץ T, אנו משחררים את הסמפורים של חוצץ A.\n        sem_post(&mutex_A); // שחרור נעילה לחוצץ assembled_parts_buffer\n        sem_post(&empty_A); // איתות על מקום פנוי בחוצץ assembled_parts_buffer\n\n        tested_parts_count++; // מייצר חלק מבוקר\n        printf(\"Tester: Added tested part. Total tested: %d\\n\", tested_parts_count);\n\n        sem_post(&mutex_T); // שחרור נעילה לחוצץ tested_parts_buffer\n        sem_post(&full_T);  // איתות על חלק מבוקר זמין\n\n        usleep(rand() % 100000 + 50000);\n    }\n    return NULL;\n}", "options": null}, "sub_questions": null, "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הבעיה בקוד של פונקציית ה-`tester` היא פוטנציאל לקיפאון (Deadlock) כתוצאה מסדר שגוי של פעולות `sem_wait` ו-`sem_post`.\n\n**הסבר הקיפאון:**\n1.  **תנאים מקדימים לקיפאון:** נניח שכל המקומות ב-`tested_parts_buffer` מלאים (כלומר, `empty_T` שווה ל-0) ו/או עובדי האריזה (Packers) אינם צורכים מספיק מהר. במקביל, נניח שעובדי ההרכבה (Assemblers) מילאו את רוב ה-`assembled_parts_buffer` (כלומר, `empty_A` קרוב ל-0 או שווה לו).\n2.  **תרחיש קיפאון:**\n    *   תהליכון `tester` כלשהו מצליח לצרוך חלק מורכב מ-`assembled_parts_buffer`. הוא מבצע `sem_wait(&full_A)` ו-`sem_wait(&mutex_A)` בהצלחה, צורך את החלק, ומגיע לשלב 2 בקוד.\n    *   כעת, תהליכון ה-`tester` מנסה להכניס את החלק המבוקר ל-`tested_parts_buffer`. הוא מבצע `sem_wait(&empty_T)`. מכיוון ש-`empty_T` שווה ל-0 (בהתאם לתנאים המקדימים), תהליכון ה-`tester` נכנס למצב חסימה וממתין שמקום יתפנה ב-`tested_parts_buffer`.\n    *   **הבעיה המרכזית:** בזמן שתהליכון ה-`tester` חסום בהמתנה ל-`empty_T`, הוא עדיין מחזיק בסמפור `mutex_A` (הוא לא שחרר אותו עדיין). הוא גם מחזיק בעצם את ה\"חלק\" שצרך מ-`assembled_parts_buffer` (הוא עדיין לא ביצע `sem_post(&empty_A)`).\n    *   כתוצאה מכך:\n        *   **עובדי הרכבה (Assemblers):** אם `assembled_parts_buffer` מלא, או אם `empty_A` קרוב ל-0, עובדי ההרכבה יצטרכו לבצע `sem_wait(&empty_A)`. אם הם יצליחו, הם יצטרכו לבצע `sem_wait(&mutex_A)`. אך `mutex_A` מוחזק על ידי תהליכון ה-`tester` החסום, ולכן עובדי ההרכבה ייחסמו.\n        *   **עובדי אריזה (Packers):** כדי ש-`empty_T` יגדל ויאפשר ל-`tester` להמשיך, עובדי האריזה צריכים לצרוך חלקים מ-`tested_parts_buffer`. אך אם אין חלקים ב-`tested_parts_buffer` (כי ה-`tester` חסום ולא יכול לייצר), או אם הם צריכים לגשת ל-`mutex_T` שגם הוא עלול להיות מוחזק (אם תהליכונים אחרים של `tester` הגיעו לשלב זה וגם הם חסומים על `empty_T` או `mutex_T`), הם לא יוכלו להתקדם.\n    *   נוצר מעגל המתנה: ה-`tester` ממתין ל-`packer` שיפנה מקום ב-`tested_parts_buffer`, אך ה-`packer` לא יכול לפנות מקום כי ה-`tester` לא ייצר, וה-`tester` לא יכול לייצר כי הוא חסום על `empty_T` (תוך כדי שהוא חוסם את ה-`assemblers` מלהתקדם על ידי החזקת `mutex_A`).\n\n**התיקון המוצע:**\nהפתרון הוא לשחרר את הסמפורים של חוצץ `assembled_parts_buffer` מיד לאחר סיום השימוש בהם (כלומר, לאחר צריכת החלק המורכב), ורק לאחר מכן לנסות לרכוש את הסמפורים של חוצץ `tested_parts_buffer`. זה מבטיח שתהליכון ה-`tester` לא יחזיק נעילה מיותרת על משאב אחד (`mutex_A`) בזמן שהוא ממתין למשאב אחר (`empty_T`).\n\n**קוד מתוקן עבור פונקציית `tester`:**\n```c\nvoid *tester(void *arg) {\n    while (1) {\n        // שלב 1: צריכת חלק מורכב מ-assembled_parts_buffer\n        sem_wait(&full_A);  // ממתין לחלק מורכב זמין\n        sem_wait(&mutex_A); // נועל גישה לחוצץ assembled_parts_buffer\n\n        assembled_parts_count--; // צורך חלק\n        printf(\"Tester: Consumed assembled part. Remaining: %d\\n\", assembled_parts_count);\n\n        // שחרור הסמפורים של חוצץ A מיד לאחר השימוש בהם\n        sem_post(&mutex_A); // שחרור נעילה לחוצץ assembled_parts_buffer\n        sem_post(&empty_A); // איתות על מקום פנוי בחוצץ assembled_parts_buffer\n\n        // מדמה פעולת בדיקה\n        usleep(rand() % 100000 + 50000); \n\n        // שלב 2: ייצור חלק מבוקר והכנסתו ל-tested_parts_buffer\n        sem_wait(&empty_T); // ממתין למקום פנוי בחוצץ tested_parts_buffer\n        sem_wait(&mutex_T); // נועל גישה לחוצץ tested_parts_buffer\n\n        tested_parts_count++; // מייצר חלק מבוקר\n        printf(\"Tester: Added tested part. Total tested: %d\\n\", tested_parts_count);\n\n        sem_post(&mutex_T); // שחרור נעילה לחוצץ tested_parts_buffer\n        sem_post(&full_T);  // איתות על חלק מבוקר זמין\n\n        usleep(rand() % 100000 + 50000);\n    }\n    return NULL;\n}\n```\nתיקון זה מבטיח שהתהליכון `tester` ישחרר את המשאבים מחוצץ A לפני שהוא ינסה לרכוש משאבים מחוצץ T, ובכך מונע את התנאי המרכזי לקיפאון בשרשרת זו."}, "difficulty_estimation": "Hard", "_source_file": "0336__Semaphores__Open__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:46:06", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Concurrency", "Threads"], "content": {"text": "נתונה תוכנית C המשתמשת בסמפור (semaphore) לסנכרון גישה למשתנה גלובלי משותף. קראו את הקוד וענו על השאלה.\n\nמה יהיה הערך הסופי של המשתנה הגלובלי `global_counter` לאחר שכל ה-`NUM_THREADS` יסיימו את ריצתן?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n\n#define NUM_THREADS 5\n#define ITERATIONS_PER_THREAD 10\n\nint global_counter = 0;\nsem_t mutex;\n\nvoid *thread_function(void *arg) {\n    for (int i = 0; i < ITERATIONS_PER_THREAD; ++i) {\n        sem_wait(&mutex);\n        global_counter++;\n        sem_post(&mutex);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    // Initialize semaphore to 1 for mutual exclusion\n    sem_init(&mutex, 0, 1);\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_function, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", global_counter);\n\n    sem_destroy(&mutex);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "הסבר: הסמפור `mutex` מאותחל לערך 1 (באמצעות `sem_init(&mutex, 0, 1)`), מה שהופך אותו למעשה למנעול בינארי (mutex). כל תהליך מבצע `sem_wait` לפני הכניסה לקטע הקריטי (הגדלת `global_counter`) ו-`sem_post` לאחר היציאה ממנו. זה מבטיח שרק תהליך אחד יכול לגשת ל-`global_counter` בכל רגע נתון, ובכך מונע תנאי מירוץ (race condition).\n\nמכיוון שכל אחד מ-`NUM_THREADS` (שהוגדר כ-5) התהליכים מבצע את ההגדלה `ITERATIONS_PER_THREAD` (שהוגדר כ-10) פעמים, והגישה מוגנת באופן הנכון, הערך הסופי של `global_counter` יהיה סך כל ההגדלות, כלומר `NUM_THREADS * ITERATIONS_PER_THREAD = 5 * 10 = 50`."}, "difficulty_estimation": "Easy", "_source_file": "0337__Semaphores__CodeAnalysis__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:56:23", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Concurrency", "Threads"], "content": {"text": "נתונה תוכנית C הבאה המשתמשת בסמפורים וב-pthreads. יש לנתח את הקוד ולענות על השאלה: מה יהיה הפלט הסופי של התוכנית? הסבר מדוע.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n\n#define N_ITERATIONS 100000\n\nint counter = 0;\nsem_t mutex; // A semaphore acting as a mutex\n\nvoid* increment_thread(void* arg) {\n    for (int i = 0; i < N_ITERATIONS; ++i) {\n        sem_wait(&mutex); // Acquire lock\n        counter++;\n        sem_post(&mutex); // Release lock\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    // Initialize the semaphore to 1 (binary semaphore for mutual exclusion)\n    sem_init(&mutex, 0, 1);\n\n    pthread_create(&tid1, NULL, increment_thread, NULL);\n    pthread_create(&tid2, NULL, increment_thread, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    sem_destroy(&mutex); // Destroy the semaphore\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכנית מאתחלת מונה גלובלי (counter) ל-0 וסמפור בינארי (mutex) לערך 1. נוצרים שני תהליכונים, שניהם מריצים את הפונקציה increment_thread. כל תהליכון מבצע N_ITERATIONS פעולות הגדלה למונה. קריאות ל-sem_wait(&mutex) לפני הגדלת המונה ול-sem_post(&mutex) לאחריה מבטיחות בלעדיות הדדית (mutual exclusion), כלומר, רק תהליכון אחד יכול לגשת ולשנות את המונה בכל רגע נתון. זה מונע תנאי מירוץ (race conditions).\nמכיוון שכל אחד משני התהליכונים מגדיל את המונה N_ITERATIONS פעמים, והגישה למונה מוגנת באמצעות הסמפור, הערך הסופי של המונה יהיה סך ההגדלות שבוצעו על ידי שני התהליכונים. עם N_ITERATIONS = 100000, כל תהליכון מגדיל את המונה 100,000 פעמים. לכן, הערך הסופי של המונה יהיה 2 * 100000 = 200000.\nהתוכנית תדפיס: \"Final counter value: 200000\"."}, "difficulty_estimation": "Easy", "_source_file": "0338__Semaphores__CodeAnalysis__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:56:34", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Semaphores", "Synchronization", "Threads", "Concurrency"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בסמפור. יש לנתח את קוד התוכנית ולענות על השאלה:\n\nמהו הפלט המובטח (Guaranteed Output) של התוכנית? הסבר מדוע.\n", "code_snippet": "#include <semaphore.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n\nsem_t sem;\n\nvoid* thread_func1(void* arg) {\n    printf(\"A\\n\");\n    sem_post(&sem);\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    sem_wait(&sem);\n    printf(\"B\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    // Initialize semaphore to 0\n    sem_init(&sem, 0, 0);\n\n    pthread_create(&tid1, NULL, thread_func1, NULL);\n    pthread_create(&tid2, NULL, thread_func2, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    sem_destroy(&sem);\n\n    return 0;\n}\n", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפלט המובטח של התוכנית הוא:\nA\nB\n\nההסבר:\n1.  הסמפור 'sem' מאותחל לערך 0. המשמעות היא שבתחילה, כל קריאה ל-`sem_wait` תחסום את התהליך הקורא עד שערך הסמפור יהפוך לחיובי.\n2.  `thread_func1` (הפונקציה של tid1) מדפיסה קודם כל את התו 'A' ולאחר מכן מבצעת `sem_post(&sem)`. פעולה זו מגדילה את ערך הסמפור מ-0 ל-1 (או מכל ערך קודם ב-1).\n3.  `thread_func2` (הפונקציה של tid2) מבצעת קודם כל `sem_wait(&sem)` ולאחר מכן מדפיסה את התו 'B'.\n4.  בגלל ש-`sem_wait` ב-`thread_func2` חייבת להצליח (כלומר, ערך הסמפור חייב להיות גדול מ-0) לפני ש-`thread_func2` יכולה להמשיך ולהדפיס 'B', ופעולת ה-`sem_post` שמעלה את ערך הסמפור מתבצעת רק לאחר הדפסת 'A' ב-`thread_func1`, מובטח ש-'A' תמיד יודפס לפני 'B'.\n5.  אם `thread_func2` תנסה לבצע `sem_wait` לפני ש-`thread_func1` ביצעה `sem_post`, היא תחסם. רק לאחר ש-`thread_func1` תדפיס 'A' ותבצע `sem_post`, ערך הסמפור יעלה ל-1, ו-`thread_func2` תוכל להמשיך (לקרוא `sem_wait`, להקטין את ערך הסמפור ל-0, ואז להדפיס 'B').\n\nלכן, הסדר 'A' ואחריו 'B' מובטח."}, "difficulty_estimation": "Easy", "_source_file": "0339__Semaphores__CodeAnalysis__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:56:48", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Threads", "Concurrency"], "content": {"text": "נתונה תוכנית C המשתמשת בסמפור (Semaphore) כדי לסנכרן גישה למשתנה משותף. קראו את הקוד וענו על השאלה:\n\nמה יהיה הפלט הסופי של התוכנית? נמקו את תשובתכם.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n\n#define NUM_THREADS 2\n#define INCREMENTS_PER_THREAD 5\n\nint counter = 0;\nsem_t sem;\n\nvoid *thread_func(void *arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        sem_wait(&sem); // Wait for semaphore\n        counter++;      // Critical section\n        sem_post(&sem); // Signal semaphore\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    // Initialize semaphore to 1 (mutex)\n    sem_init(&sem, 0, 1);\n\n    // Create threads\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, NULL);\n    }\n\n    // Join threads\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    // Destroy semaphore\n    sem_destroy(&sem);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסמפור `sem` מאותחל לערך 1, מה שהופך אותו למעשה למנעול (mutex). כל חוט (thread) מבצע לולאה 5 פעמים. בכל איטרציה, הוא קורא ל-`sem_wait()` לפני הכניסה לקטע הקריטי (הגדלת `counter`) ו-`sem_post()` לאחר היציאה ממנו. פעולות אלו מבטיחות שרק חוט אחד יכול לגשת למשתנה המשותף `counter` בכל רגע נתון. כתוצאה מכך, פעולת ההגדלה `counter++` היא אטומית ומוגנת מתנאי מירוץ. מכיוון שיש 2 חוטים וכל אחד מגדיל את המונה 5 פעמים, הערך הסופי של `counter` יהיה 2 * 5 = 10. הפלט יהיה:\n`Final counter value: 10`"}, "difficulty_estimation": "Easy", "_source_file": "0340__Semaphores__CodeAnalysis__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:56:58", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Concurrency", "Threads"], "content": {"text": "נתונה תוכנית C המשתמשת בסמפור (semaphore) ובמספר תהליכונים (threads) כדי לגשת למשאב משותף. עיין בקוד המצורף וענה על השאלה:\n\nמה יהיה הערך הסופי של המשתנה `shared_resource` לאחר שכל התהליכונים יסיימו את ריצתם? הסבר מדוע.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n\n#define NUM_THREADS 5\n\nsem_t my_semaphore;\nint shared_resource = 0;\n\nvoid* thread_function(void* arg) {\n    // Wait for the semaphore\n    sem_wait(&my_semaphore);\n\n    // Critical section\n    shared_resource++;\n    printf(\"Thread %ld entered. shared_resource = %d\\n\", (long)arg, shared_resource);\n\n    // Signal the semaphore\n    sem_post(&my_semaphore);\n\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    int i;\n\n    // Initialize the semaphore to 1 (binary semaphore)\n    sem_init(&my_semaphore, 0, 1);\n\n    for (i = 0; i < NUM_THREADS; i++) {\n        pthread_create(&threads[i], NULL, thread_function, (void*)(long)i);\n    }\n\n    for (i = 0; i < NUM_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final shared_resource value: %d\\n\", shared_resource);\n\n    // Destroy the semaphore\n    sem_destroy(&my_semaphore);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הערך הסופי של המשתנה `shared_resource` יהיה 5. הסיבה לכך היא שהסמפור `my_semaphore` מאותחל לערך 1, מה שהופך אותו לסמפור בינארי (או mutex). זה מבטיח שבכל רגע נתון, רק תהליכון אחד יכול להיכנס לקטע הקריטי (החלק בקוד שבין `sem_wait` ל-`sem_post`) ולגשת למשתנה `shared_resource`. פעולת ההגדלה `shared_resource++` מתבצעת באופן אטומי עבור כל תהליכון, כך שאין אובדן של עדכונים עקב תנאי מירוץ (race conditions). מכיוון שישנם 5 תהליכונים (`NUM_THREADS` מוגדר כ-5), וכל אחד מהם מגדיל את המשתנה פעם אחת באופן בטוח, הערך הסופי יהיה 5."}, "difficulty_estimation": "Easy", "_source_file": "0341__Semaphores__CodeAnalysis__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:57:13", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Semaphores", "Synchronization", "Threads", "Concurrency"], "content": {"text": "נתונה תוכנית C המשתמשת בסמפור בינארי (binary semaphore) כדי להגן על קטע קריטי. שני תהליכונים (threads) מריצים את אותה פונקציה, שבה כל אחד מהם מגדיל מונה משותף 5 פעמים. מה יהיה הערך הסופי של המונה המשותף `counter` לאחר ששני התהליכונים יסיימו את ריצתם?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n\n#define NUM_THREADS 2\n#define INCREMENTS_PER_THREAD 5\n\nint counter = 0;\nsem_t binary_semaphore;\n\nvoid* thread_func(void* arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        sem_wait(&binary_semaphore); // Acquire lock\n        counter++;                   // Critical section\n        sem_post(&binary_semaphore); // Release lock\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    // Initialize binary semaphore to 1 (binary semaphore acting as a mutex)\n    sem_init(&binary_semaphore, 0, 1);\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    sem_destroy(&binary_semaphore);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון:\nהתוכנית יוצרת שני תהליכונים, כאשר כל אחד מהם מבצע 5 הגדלות למונה המשותף `counter`. הסמפור הבינארי `binary_semaphore` מאותחל לערך 1, מה שאומר שהוא פועל כמו מנעול (mutex) ומבטיח שרק תהליכון אחד יכול להיכנס לקטע הקריטי (הגדלת המונה) בכל רגע נתון.\nכל קריאה ל-`sem_wait` משיגה את המנעול, וכל קריאה ל-`sem_post` משחררת אותו. כיוון שהגישה ל-`counter` מוגנת כהלכה על ידי הסמפור, כל פעולת הגדלה היא אטומית ומובטח שלא יתרחשו תנאי מרוץ (race conditions) שישנו את סדר הפעולות או יגרמו לאיבוד עדכונים.\nסה\"כ מספר ההגדלות שיבוצעו הוא: מספר התהליכונים * מספר ההגדלות לכל תהליכון = 2 * 5 = 10.\nלכן, הערך הסופי של `counter` יהיה 10."}, "difficulty_estimation": "Easy", "_source_file": "0342__Semaphores__CodeAnalysis__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:57:24", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Semaphores", "Concurrency", "Synchronization", "Threads"], "content": {"text": "נתונה תוכנית C הבאה המשתמשת בסמפורים. עיין בקוד וענה על השאלה הבאה:\n\nמהו/מהם הפלט/ים האפשרי/ים של התוכנית? נמק את תשובתך.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h> // for sleep\n\nsem_t sem;\nint counter = 0;\n\nvoid *thread_A(void *arg) {\n    // Simulate some work before incrementing\n    sleep(1);\n    counter++;\n    printf(\"Thread A: counter incremented to %d\\n\", counter);\n    sem_post(&sem);\n    return NULL;\n}\n\nvoid *thread_B(void *arg) {\n    printf(\"Thread B: Waiting for semaphore...\\n\");\n    sem_wait(&sem);\n    printf(\"Thread B: Semaphore acquired. Counter value is %d\\n\", counter);\n    return NULL;\n}\n\nint main() {\n    pthread_t tid_a, tid_b;\n\n    // Initialize semaphore to 0\n    sem_init(&sem, 0, 0);\n\n    // Create threads\n    pthread_create(&tid_b, NULL, thread_B, NULL); // Create B first\n    pthread_create(&tid_a, NULL, thread_A, NULL); // Create A second\n\n    // Wait for threads to finish\n    pthread_join(tid_a, NULL);\n    pthread_join(tid_b, NULL);\n\n    sem_destroy(&sem);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסמפור `sem` מאותחל לערך 0. המשמעות היא שכל קריאה ל-`sem_wait` תחסום את התהליך הקורא עד שקריאה ל-`sem_post` תשחרר את הסמפור.\n\nהתהליך הראשי יוצר תחילה את `thread_B` ולאחר מכן את `thread_A`.\n1.  `thread_B` מתחיל לרוץ ומיד קורא ל-`sem_wait(&sem)`. מכיוון שערך הסמפור הוא 0, `thread_B` נחסם וממתין.\n2.  `thread_A` מתחיל לרוץ. הוא מבצע `sleep(1)` (המדמה עבודה כלשהי), מגדיל את `counter` ל-1, ומדפיס את מצב המונה.\n3.  לאחר מכן, `thread_A` קורא ל-`sem_post(&sem)`. פעולה זו מגדילה את ערך הסמפור ל-1 ומשחררת את `thread_B` החסום.\n4.  `thread_B` ממשיך את ריצתו, מדפיס הודעה שהוא שוחרר ואת ערך `counter`. בנקודה זו, `counter` כבר עודכן על ידי `thread_A` ולכן ערכו יהיה 1.\n\nהפלט תמיד יציג את ערך המונה כ-1 כאשר `thread_B` מסיים את המתנתו. הסמפור מבטיח ש-`thread_B` ימתין תמיד ל-`thread_A` שיסיים את עדכון המונה וישחרר את הסמפור.\n\nהפלט האפשרי היחיד (בסדר הדפסה ספציפי) הוא:\nThread B: Waiting for semaphore...\nThread A: counter incremented to 1\nThread B: Semaphore acquired. Counter value is 1\n\nייתכן גם סדר הדפסה אחר בין שתי השורות הראשונות (בהתאם לתיזמון), אך השורה האחרונה תמיד תופיע בסוף ותציג את הערך 1."}, "difficulty_estimation": "Easy", "_source_file": "0343__Semaphores__CodeAnalysis__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:57:41", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Concurrency", "Threads"], "content": {"text": "נתונה תוכנית C המשתמשת בסמפור ובמספר תהליכים (threads). עיין בקוד וקבע מהו הערך הסופי של המשתנה המשותף `shared_counter` לאחר שכל התהליכים יסיימו את ריצתם. הסבר את תשובתך.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n\n#define NUM_THREADS 5\n\nsem_t my_semaphore;\nint shared_counter = 0;\n\nvoid* thread_func(void* arg) {\n    sem_wait(&my_semaphore); // Wait for semaphore\n    \n    // Critical section\n    shared_counter++;\n    printf(\"Thread %ld: shared_counter is now %d\\n\", (long)arg, shared_counter);\n    \n    sem_post(&my_semaphore); // Release semaphore\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    int i;\n\n    // Initialize semaphore to 1 (binary semaphore/mutex)\n    sem_init(&my_semaphore, 0, 1); \n\n    for (i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, (void*)(long)i);\n    }\n\n    for (i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final value of shared_counter: %d\\n\", shared_counter);\n\n    sem_destroy(&my_semaphore);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הערך הסופי של המשתנה `shared_counter` יהיה 5.\n\nהסבר:\nהסמפור `my_semaphore` מאותחל לערך 1 באמצעות `sem_init(&my_semaphore, 0, 1)`. אתחול זה הופך אותו לסמפור בינארי, הפועל למעשה כמו mutex (מנעול).\n\nבפונקציה `thread_func`, כל תהליך מבצע `sem_wait(&my_semaphore)` לפני שהוא נכנס לקטע הקריטי, ומבצע `sem_post(&my_semaphore)` כשהוא יוצא מהקטע הקריטי.\n\nמכיוון שהסמפור מאותחל ל-1, רק תהליך אחד יכול להיכנס לקטע הקריטי (שבו מתבצעת הפעולה `shared_counter++`) בכל רגע נתון. אם תהליך אחר ינסה להיכנס כשהסמפור תפוס, הוא ייחסם בקריאה ל-`sem_wait` עד שהתהליך הנוכחי ישחרר את הסמפור.\n\nפעולה זו מבטיחה שההגדלה של `shared_counter` היא אטומית ומוגנת מתנאי מירוץ. מכיוון שישנם `NUM_THREADS` (שהוגדר כ-5) תהליכים, וכל אחד מהם מגדיל את `shared_counter` בדיוק פעם אחת באופן מסונכרן, הערך הסופי של `shared_counter` יהיה 5."}, "difficulty_estimation": "Easy", "_source_file": "0344__Semaphores__CodeAnalysis__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:57:54", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Semaphores", "Concurrency", "Processes", "IPC"], "content": {"text": "נתונה תוכנית C המשתמשת בסמפור לתיאום בין תהליכים בנים. התוכנית יוצרת מספר תהליכי בן (NUM_CHILDREN = 3), וכל אחד מהם מנסה להיכנס לקטע קריטי המוגן על ידי הסמפור. לאחר הכניסה, התהליך מדפיס הודעה, מדמה עבודה, מדפיס הודעה נוספת ויוצא מהקטע הקריטי.\n\nנתחו את הקוד וענו על השאלות הבאות:", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <semaphore.h>\n#include <sys/mman.h> // For shared memory with semaphore\n\n#define NUM_CHILDREN 3\n\nsem_t *shared_semaphore; // Pointer to shared semaphore\n\nvoid child_task(int id) {\n    printf(\"Child %d (PID %d): Trying to access resource.\\n\", id, getpid());\n    sem_wait(shared_semaphore); // Acquire lock\n    // Critical Section\n    printf(\"Child %d (PID %d): *** Entered Critical Section ***\\n\", id, getpid());\n    sleep(1); // Simulate work\n    printf(\"Child %d (PID %d): --- Exiting Critical Section ---\\n\", id, getpid());\n    sem_post(shared_semaphore); // Release lock\n    exit(0);\n}\n\nint main() {\n    setbuf(stdout, NULL); // Disable buffering for immediate output\n\n    // Allocate shared memory for the semaphore\n    shared_semaphore = mmap(NULL, sizeof(sem_t), PROT_READ | PROT_WRITE, MAP_SHARED | MAP_ANONYMOUS, -1, 0);\n    if (shared_semaphore == MAP_FAILED) {\n        perror(\"mmap failed\");\n        return 1;\n    }\n\n    // Initialize semaphore for process sharing (1), initial value 1 (mutual exclusion)\n    if (sem_init(shared_semaphore, 1, 1) == -1) {\n        perror(\"sem_init failed\");\n        return 1;\n    }\n\n    pid_t pids[NUM_CHILDREN];\n\n    for (int i = 0; i < NUM_CHILDREN; i++) {\n        pids[i] = fork();\n        if (pids[i] == -1) {\n            perror(\"fork failed\");\n            return 1;\n        } else if (pids[i] == 0) { // Child process\n            child_task(i);\n        }\n    }\n\n    // Parent waits for all children\n    for (int i = 0; i < NUM_CHILDREN; i++) {\n        wait(NULL);\n    }\n\n    printf(\"Parent: All children finished. Cleaning up.\\n\");\n\n    // Destroy the semaphore\n    if (sem_destroy(shared_semaphore) == -1) {\n        perror(\"sem_destroy failed\");\n        return 1;\n    }\n\n    // Unmap shared memory\n    if (munmap(shared_semaphore, sizeof(sem_t)) == -1) {\n        perror(\"munmap failed\");\n        return 1;\n    }\n\n    return 0;\n}"}, "sub_questions": [{"id": "8.1", "text": "מהו פלט אפשרי אחד של התוכנית? ציינו במפורש מה מובטח לגבי סדר ההדפסות של ההודעות '*** Entered Critical Section ***' ו-'--- Exiting Critical Section ---' ביחס זו לזו, ומדוע.", "code_snippet": null, "options": null}, {"id": "8.2", "text": "אם נשנה את ערך האתחול של הסמפור מ-1 ל-NUM_CHILDREN (כלומר, sem_init(shared_semaphore, 1, NUM_CHILDREN)), כיצד זה ישפיע על הפלט ועל מאפייני התיאום בין התהליכים? האם עדיין מובטח שרק תהליך אחד יהיה בקטע הקריטי בכל רגע נתון?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "8.1. פלט אפשרי אחד של התוכנית יכול להיות כדוגמה הבאה (סדר ההודעות 'Trying to access resource' יכול להשתנות, אך סדר הכניסה/יציאה מהקטע הקריטי יהיה תמיד סדרתי):\nChild 0 (PID XXX): Trying to access resource.\nChild 1 (PID YYY): Trying to access resource.\nChild 2 (PID ZZZ): Trying to access resource.\nChild 0 (PID XXX): *** Entered Critical Section ***\nChild 0 (PID XXX): --- Exiting Critical Section ---\nChild 2 (PID ZZZ): *** Entered Critical Section ***\nChild 2 (PID ZZZ): --- Exiting Critical Section ---\nChild 1 (PID YYY): *** Entered Critical Section ***\nChild 1 (PID YYY): --- Exiting Critical Section ---\nParent: All children finished. Cleaning up.\n\nמובטח שרק תהליך אחד יכול להימצא בקטע הקריטי (בין קריאת `sem_wait` לקריאת `sem_post`) בכל רגע נתון. הסיבה לכך היא שהסמפור מאותחל לערך 1, מה שמקנה לו תכונת הדדיות (mutual exclusion). כתוצאה מכך, עבור כל תהליך בן בנפרד, ההודעה '*** Entered Critical Section ***' תמיד תודפס לפני ההודעה '--- Exiting Critical Section ---' של אותו תהליך. בנוסף, מובטח שלא תופיענה שתי הודעות '*** Entered Critical Section ***' ברצף ללא הודעת '--- Exiting Critical Section ---' ביניהן, כלומר, תמיד תהיה זוגיות של כניסה ויציאה מהקטע הקריטי, ותהליך אחד יסיים את הקטע הקריטי לפני שתהליך אחר ייכנס אליו.\n\n8.2. אם נשנה את ערך האתחול של הסמפור ל-NUM_CHILDREN (כלומר, 3), הסמפור יהפוך לסמפור סופר (counting semaphore) המאפשר עד 3 תהליכים להיכנס לקטע הקריטי בו-זמנית.\nההשפעה על הפלט תהיה שכל שלושת תהליכי הבן יוכלו לעבור את קריאת `sem_wait` כמעט מיד, ללא חסימה, ולהיכנס לקטע הקריטי שלהם במקביל. כתוצאה מכך, הפלט של ההודעות '*** Entered Critical Section ***' ו-'--- Exiting Critical Section ---' לא יהיה בהכרח סדרתי (תהליך אחד מסיים לפני שהבא נכנס). לדוגמה, ייתכן שכל שלושת תהליכי הבן ידפיסו את הודעת הכניסה לקטע הקריטי לפני שמישהו מהם ידפיס את הודעת היציאה.\nעדיין מובטח שעבור כל תהליך בן *ספציפי*, הודעת הכניסה שלו תופיע לפני הודעת היציאה שלו. אולם, *לא* מובטח שרק תהליך אחד יהיה בקטע הקריטי בכל רגע נתון; בפועל, עד שלושה תהליכים יכולים להיות שם בו-זמנית. הדדיות (mutual exclusion) אינה נשמרת במקרה זה.\nדוגמה לפלט אפשרי במקרה זה:\nChild 0 (PID XXX): Trying to access resource.\nChild 1 (PID YYY): Trying to access resource.\nChild 2 (PID ZZZ): Trying to access resource.\nChild 0 (PID XXX): *** Entered Critical Section ***\nChild 1 (PID YYY): *** Entered Critical Section ***\nChild 2 (PID ZZZ): *** Entered Critical Section ***\nChild 1 (PID YYY): --- Exiting Critical Section ---\nChild 0 (PID XXX): --- Exiting Critical Section ---\nChild 2 (PID ZZZ): --- Exiting Critical Section ---\nParent: All children finished. Cleaning up."}, "difficulty_estimation": "Medium", "_source_file": "0345__Semaphores__CodeAnalysis__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:58:25", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Semaphores", "Concurrency", "Threads", "Race Conditions"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בסמפורים להגנה על משאב משותף:\n", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 100000\n\nint counter = 0;\nsem_t mutex; // סמפור בינארי\n\nvoid *thread_func(void *arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        sem_wait(&mutex); // נעל את המשאב\n        counter++;        // קטע קריטי\n        sem_post(&mutex); // שחרר את המשאב\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    // אתחל את הסמפור הבינארי ל-1\n    sem_init(&mutex, 0, 1); // pshared = 0 (בין תהליכונים), value = 1\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    sem_destroy(&mutex); // השמד את הסמפור\n    return 0;\n}"}, "sub_questions": [{"id": "8.1", "text": "מה יהיה הערך הסופי של המונה (`counter`) לאחר שכל התהליכונים יסיימו את ריצתם? נמקו.", "code_snippet": null, "options": null}, {"id": "8.2", "text": "האם קיים תנאי מרוץ (race condition) בקטע הקוד הזה? נמקו.", "code_snippet": null, "options": null}, {"id": "8.3", "text": "נניח שהשורה `sem_init(&mutex, 0, 1);` שונתה ל-`sem_init(&mutex, 0, NUM_THREADS);`. מה יהיה טווח הערכים האפשריים לערך הסופי של המונה (`counter`)? נמקו.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  **ערך סופי של המונה:**\n    הערך הסופי של המונה יהיה `500,000`. ישנם `NUM_THREADS` (5) תהליכונים, וכל תהליכון מבצע `INCREMENTS_PER_THREAD` (100,000) הגדלות. בסך הכל יבוצעו `5 * 100,000 = 500,000` הגדלות. הסמפור `mutex` מאותחל ל-1, ומשמש כסמפור בינארי (או מיוטקס). הקריאות `sem_wait` ו-`sem_post` עוטפות כהלכה את הפעולה `counter++`, המהווה קטע קריטי. זה מבטיח שרק תהליכון אחד יכול לגשת למשתנה `counter` בכל רגע נתון, ובכך מונע אובדן עדכונים וכל ההגדלות נספרות כהלכה.\n\n2.  **תנאי מרוץ (race condition):**\n    לא, לא קיים תנאי מרוץ בקטע הקוד הזה. הפעולה `counter++` היא קטע קריטי מכיוון שהיא כוללת רצף של קריאה, שינוי וכתיבה (טעינת הערך של `counter`, הגדלתו, ואחסון הערך החדש). ללא הגנה, מספר תהליכונים יכלו לקרוא את אותו ערך, לבצע הגדלה, ולכתוב בחזרה את אותו ערך מוגדל, מה שיוביל לאובדן עדכונים. עם זאת, הקריאות ל-`sem_wait(&mutex)` ו-`sem_post(&mutex)` מבטיחות הדדיות (mutual exclusion). רק תהליכון אחד יכול לעבור בהצלחה את `sem_wait` ולהיכנס לקטע הקריטי בכל פעם. תהליכונים אחרים יחסמו עד שהסמפור ישוחרר. זה מבטיח ש-`counter++` מבוצע באופן אטומי ביחס לתהליכונים אחרים, ומונע תנאי מרוץ.\n\n3.  **שינוי אתחול הסמפור ל-`NUM_THREADS`:**\n    אם השורה `sem_init(&mutex, 0, 1);` תשונה ל-`sem_init(&mutex, 0, NUM_THREADS);` (כלומר, `sem_init(&mutex, 0, 5);`), הסמפור יהפוך לסמפור סופר (counting semaphore) שיאפשר עד 5 תהליכונים להיכנס לקטע הקריטי בו זמנית. מכיוון שישנם בדיוק 5 תהליכונים בתוכנית, זה למעשה אומר שאין הגנה של הדדיות על הפעולה `counter++`. הפעולה `counter++` אינה אטומית בפני עצמה, וכאשר מספר תהליכונים יבצעו אותה במקביל, ייווצר תנאי מרוץ. כתוצאה מכך, חלק מההגדלות ילכו לאיבוד.\n    \n    *   **הערך המקסימלי האפשרי:** `NUM_THREADS * INCREMENTS_PER_THREAD = 500,000`. זה יקרה אם, במקרה, מתזמן מערכת ההפעלה יאפשר לתהליכונים לבצע את הפעולה `counter++` בטוריות מלאה, אחד אחרי השני, ללא שילוב שלבי הקריאה/שינוי/כתיבה שלהם.\n    *   **הערך המינימלי האפשרי:** `INCREMENTS_PER_THREAD = 100,000`. זה יכול לקרות אם, עבור כל פעולת `counter++`, כל 5 התהליכונים קוראים את אותו ערך נוכחי של `counter`, ואז כולם מגדילים אותו לערך הבא, וכולם כותבים בחזרה את אותו ערך חדש. בתרחיש קיצוני זה, רק הגדלה אפקטיבית אחת תתרחש עבור כל 5 הגדלות מיועדות. לדוגמה, אם `counter` הוא 0, כל 5 התהליכונים קוראים 0, כולם מחשבים 1, וכולם כותבים 1. ערך המונה הוא כעת 1. אם דפוס זה חוזר על עצמו, לאחר 100,000 \"מחזורים\" כאלה על ידי כל תהליכון, הספירה הכוללת תהיה 100,000.\n    \n    לכן, טווח הערכים האפשריים לערך הסופי של המונה הוא `[100,000, 500,000]`."}, "difficulty_estimation": "Medium", "_source_file": "0346__Semaphores__CodeAnalysis__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:58:48", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Semaphores", "Concurrency", "Threads", "Synchronization"], "content": {"text": "נתונה התוכנית הבאה, המשתמשת בסמפור (semaphore) לצורך סנכרון בין תהליכונים (threads).\nהתוכנית יוצרת מספר תהליכונים, כאשר כל תהליכון מבצע מספר מסוים של פעולות הגדלה על משתנה גלובלי משותף `counter`.\n\nמה יהיה הערך הסופי של המשתנה `counter` לאחר שכל התהליכונים יסיימו את ריצתם? הסבירו את תשובתכם.", "code_snippet": "#include <pthread.h>\n#include <semaphore.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#define NUM_THREADS 3\n#define INCREMENTS_PER_THREAD 100000\n\nint counter = 0;\nsem_t mutex;\n\nvoid* thread_function(void* arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; i++) {\n        sem_wait(&mutex); // Acquire lock\n        counter++;        // Critical section\n        sem_post(&mutex); // Release lock\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    // Initialize semaphore for mutual exclusion (value = 1)\n    if (sem_init(&mutex, 0, 1) != 0) {\n        perror(\"sem_init failed\");\n        exit(EXIT_FAILURE);\n    }\n\n    // Create threads\n    for (int i = 0; i < NUM_THREADS; i++) {\n        if (pthread_create(&threads[i], NULL, thread_function, NULL) != 0) {\n            perror(\"pthread_create failed\");\n            exit(EXIT_FAILURE);\n        }\n    }\n\n    // Join threads\n    for (int i = 0; i < NUM_THREADS; i++) {\n        if (pthread_join(threads[i], NULL) != 0) {\n            perror(\"pthread_join failed\");\n            exit(EXIT_FAILURE);\n        }\n    }\n\n    // Destroy semaphore\n    sem_destroy(&mutex);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הערך הסופי של המשתנה `counter` יהיה 300000.\n\nהסבר:\nהתוכנית יוצרת 3 תהליכונים (`NUM_THREADS = 3`), וכל תהליכון מגדיל את המשתנה הגלובלי `counter` מספר קבוע של פעמים (`INCREMENTS_PER_THREAD = 100000`). בסך הכל, צפויות להתבצע 3 * 100000 = 300000 פעולות הגדלה.\n\nהסמפור `mutex` מאותחל לערך 1 (`sem_init(&mutex, 0, 1)`), מה שהופך אותו לסמפור בינארי (מנעול). לפני כל פעולת הגדלה של `counter`, כל תהליכון קורא ל-`sem_wait(&mutex)` כדי לנסות לרכוש את המנעול. אם המנעול זמין (ערך הסמפור הוא 1), התהליכון רוכש אותו (ערך הסמפור יורד ל-0) ונכנס לקטע הקריטי. אם המנעול אינו זמין (ערך הסמפור הוא 0), התהליכון נחסם עד שהמנעול ישוחרר.\n\nלאחר הגדלת `counter`, התהליכון קורא ל-`sem_post(&mutex)` כדי לשחרר את המנעול (ערך הסמפור עולה ל-1). מנגנון זה מבטיח שבכל רגע נתון, רק תהליכון אחד יכול לגשת ולשנות את המשתנה `counter`. הדבר מונע מצב מרוץ (race condition) ומבטיח שכל פעולות ההגדלה יתבצעו כהלכה, ושהערך הסופי של `counter` ישקף את סך כל ההגדלות שבוצעו על ידי כל התהליכונים.\n\nלכן, הערך הסופי יהיה בדיוק סכום ההגדלות: 3 * 100000 = 300000."}, "difficulty_estimation": "Medium", "_source_file": "0347__Semaphores__CodeAnalysis__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:59:01", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Semaphores", "Concurrency", "Threads"], "content": {"text": "נתונה תוכנית C המשתמשת בסמפור סופר (counting semaphore) כדי לווסת גישה למקטע קריטי (critical section) בין מספר תהליכונים (threads). עיין בקוד והשב על השאלות הבאות:\n\n1. מהו המספר המקסימלי של תהליכונים שיכולים להימצא במקטע הקריטי בו-זמנית, וכיצד נקבע מספר זה בקוד?\n2. תארו את רצף האירועים הצפוי בריצת התוכנית, ובפרט את סדר ההדפסות של כניסה ויציאה מהמקטע הקריטי, בהנחה שהמתזמן (scheduler) מעדיף תהליכונים בעלי ID נמוך יותר כאשר מספר תהליכונים מוכנים לריצה. הסבירו מדוע ייתכן שסדר היציאה לא יהיה זהה לסדר הכניסה.\n3. מה יקרה אם נשנה את ערך האתחול של הסמפור `MAX_CONCURRENT_ACCESS` ל-0? תארו את השפעת השינוי על התנהגות התוכנית.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h> // For sleep\n\n#define NUM_THREADS 10\n#define MAX_CONCURRENT_ACCESS 3 // K\n\nsem_t resource_sem;\n\nvoid *worker_thread(void *arg) {\n    long thread_id = (long)arg;\n\n    printf(\"Thread %ld: Waiting to enter critical section...\\n\", thread_id);\n    sem_wait(&resource_sem); // Acquire access\n\n    printf(\"Thread %ld: !!! Entering critical section !!!\\n\", thread_id);\n    sleep(1); // Simulate work in critical section\n    printf(\"Thread %ld: Exiting critical section.\\n\", thread_id);\n\n    sem_post(&resource_sem); // Release access\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    int i;\n\n    // Initialize the semaphore to allow MAX_CONCURRENT_ACCESS threads\n    if (sem_init(&resource_sem, 0, MAX_CONCURRENT_ACCESS) != 0) {\n        perror(\"sem_init failed\");\n        return 1;\n    }\n\n    for (i = 0; i < NUM_THREADS; i++) {\n        if (pthread_create(&threads[i], NULL, worker_thread, (void *)(long)i) != 0) {\n            perror(\"pthread_create failed\");\n            return 1;\n        }\n    }\n\n    for (i = 0; i < NUM_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n\n    sem_destroy(&resource_sem); // Clean up semaphore\n    printf(\"All threads finished. Main exiting.\\n\");\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. המספר המקסימלי של תהליכונים שיכולים להימצא במקטע הקריטי בו-זמנית הוא 3. מספר זה נקבע על ידי הקבוע `MAX_CONCURRENT_ACCESS` אשר משמש כערך האתחול של הסמפור `resource_sem` בשורה `sem_init(&resource_sem, 0, MAX_CONCURRENT_ACCESS);`. סמפור סופר מאפשר למספר `MAX_CONCURRENT_ACCESS` של תהליכונים לבצע פעולת `sem_wait` בהצלחה לפני שהוא יחסום תהליכונים נוספים.\n\n2. בהנחה שהמתזמן מעדיף תהליכונים בעלי ID נמוך יותר, סדר הכניסה למקטע הקריטי יהיה בדרך כלל: Thread 0, Thread 1, Thread 2. לאחר מכן, תהליכונים אלו יתחילו לבצע את ה-\"עבודה\" שלהם (שינה למשך שנייה). בזמן זה, Thread 3 ימתין בתור לכניסה. כאשר אחד מהתהליכונים הראשונים (לדוגמה Thread 0) יסיים את עבודתו ויבצע `sem_post`, הוא ישחרר מקום במקטע הקריטי, ו-Thread 3 (או הבא בתור בעל ה-ID הנמוך ביותר) ייכנס. כתוצאה מכך, סדר הכניסה הצפוי למקטע הקריטי יהיה 0, 1, 2, ואז 3, 4, 5 וכן הלאה, בקבוצות של 3. סדר היציאה מהמקטע הקריטי אינו בהכרח זהה לסדר הכניסה. הסיבה לכך היא שכל תהליכון מבצע `sleep(1)` בתוך המקטע הקריטי, אך אין ערובה שכל התהליכונים יתחילו את ה-sleep באותו המיקרו-שנייה או שיסיימו אותו באותו סדר. יתכן ש-Thread 0 יסיים את ה-sleep ויצא לפני Thread 1 או Thread 2, גם אם הוא נכנס ראשון. לכן, סדר ההדפסות של 'Exiting critical section' יכול להיות שונה מסדר ה-'Entering critical section'.\n\n3. אם נשנה את ערך האתחול של הסמפור `MAX_CONCURRENT_ACCESS` ל-0, התוכנית תתנהג באופן שונה מהותית. כאשר הסמפור מאותחל ל-0, כל קריאה ראשונה ל-`sem_wait(&resource_sem)` תחסום את התהליכון הקורא, מכיוון שאין היתרים זמינים (הערך של הסמפור הוא 0). כתוצאה מכך, אף תהליכון לא יוכל להיכנס למקטע הקריטי. כל עשרת התהליכונים יבצעו `sem_wait` ויחסמו מיד, והם ימתינו באופן אינסופי (deadlock) מכיוון שאף אחד מהם לא יגיע ל-`sem_post` כדי לשחרר היתר ולאפשר לתהליכונים אחרים להמשיך. התוכנית תיתקע ולא תדפיס אף הודעת כניסה או יציאה מהמקטע הקריטי, למעט הודעות ההתחלה של התהליכונים."}, "difficulty_estimation": "Medium", "_source_file": "0348__Semaphores__CodeAnalysis__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:59:28", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Semaphores", "Concurrency", "Threads", "Mutual Exclusion"], "content": {"text": "נתונה תוכנית C++ המשתמשת בסמפורים (POSIX semaphores) לסנכרון גישה למשתנה משותף. התוכנית יוצרת מספר תהליכונים (threads) שכל אחד מהם מגדיל מונה גלובלי מספר פעמים. נתחו את הקוד וענו: מהו הערך הסופי של המשתנה `shared_counter` לאחר שכל התהליכונים סיימו את ריצתם? נמקו את תשובתכם והסבירו כיצד הסמפור מבטיח את הערך הנכון.", "code_snippet": "#include <iostream>\n#include <thread>\n#include <vector>\n#include <semaphore.h> // For POSIX semaphores\n\n// Global shared counter\nint shared_counter = 0;\n\n// Semaphore for mutual exclusion\nsem_t mutex;\n\n// Number of increments per thread\nconst int INCREMENTS_PER_THREAD = 100000;\n// Number of threads\nconst int NUM_THREADS = 5;\n\nvoid thread_function() {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        // Acquire the semaphore (P operation)\n        sem_wait(&mutex);\n\n        // Critical section\n        shared_counter++;\n\n        // Release the semaphore (V operation)\n        sem_post(&mutex);\n    }\n}\n\nint main() {\n    // Initialize the semaphore for mutual exclusion (initial value 1)\n    // 0 means semaphore is shared between threads of a process\n    sem_init(&mutex, 0, 1);\n\n    std::vector<std::thread> threads;\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        threads.emplace_back(thread_function);\n    }\n\n    for (std::thread& t : threads) {\n        t.join();\n    }\n\n    // Destroy the semaphore\n    sem_destroy(&mutex);\n\n    std::cout << \"Final value of shared_counter: \" << shared_counter << std::endl;\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הערך הסופי של המשתנה `shared_counter` יהיה 500,000.\n\nהסבר:\n1.  המשתנה `shared_counter` הוא משאב משותף אליו ניגשים מספר תהליכונים בו-זמנית. ללא סנכרון, פעולת ההגדלה (`shared_counter++`) אינה אטומית ויכולה להוביל למצב מרוץ (race condition), שבו מספר תהליכונים קוראים את אותו ערך, מגדילים אותו, וכותבים בחזרה, וכתוצאה מכך חלק מההגדלות עלולות ללכת לאיבוד והערך הסופי יהיה שגוי.\n2.  התוכנית משתמשת בסמפור בינארי (`mutex`) שמאותחל לערך 1 (`sem_init(&mutex, 0, 1);`). סמפור בינארי עם ערך התחלתי 1 משמש כמעין מנעול (lock) להבטחת הדרה הדדית (mutual exclusion).\n3.  כל תהליכון מבצע קריאה ל-`sem_wait(&mutex)` לפני הכניסה לקטע הקריטי (השורה `shared_counter++;`) וקריאה ל-`sem_post(&mutex)` לאחר היציאה ממנו.\n4.  קריאה ל-`sem_wait` (פעולת P) מקטינה את ערך הסמפור. אם הערך הופך לשלילי, התהליכון נחסם עד שתהליכון אחר יבצע `sem_post`. זה מבטיח שרק תהליכון אחד יכול להחזיק בסמפור (ובכך להיות בקטע הקריטי) בכל רגע נתון.\n5.  קריאה ל-`sem_post` (פעולת V) מגדילה את ערך הסמפור, ומשחררת תהליכון ממתין אם יש כזה.\n6.  בזכות מנגנון ההדרה ההדדית הזה, כל פעולת הגדלה של `shared_counter` מתבצעת באופן אטומי ביחס לתהליכונים האחרים. אין שני תהליכונים שיכולים להגדיל את המונה בו-זמנית.\n7.  לכן, הערך הסופי של `shared_counter` יהיה סכום מדויק של כל ההגדלות שבוצעו על ידי כל התהליכונים.\n8.  החישוב הוא: `NUM_THREADS` (5) * `INCREMENTS_PER_THREAD` (100,000) = 500,000."}, "difficulty_estimation": "Medium", "_source_file": "0349__Semaphores__CodeAnalysis__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:59:47", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Semaphores", "Concurrency", "Pthreads"], "content": {"text": "נתונה התוכנית הבאה בשפת C, המשתמשת בסמפורים ובתהליכונים (pthreads). יש לנתח את הקוד ולענות על השאלות הבאות:", "code_snippet": "#include <pthread.h>\n#include <semaphore.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h> // For usleep\n\n#define NUM_THREADS 5\n#define SEM_VALUE 2 // Allow up to 2 threads concurrently\n\nsem_t my_semaphore;\nint g_critical_count = 0; // To track concurrent threads\n\nvoid* thread_func(void* arg) {\n    int id = *(int*)arg;\n    \n    printf(\"Thread %d starting...\\n\", id);\n\n    sem_wait(&my_semaphore); // Acquire semaphore\n\n    // Critical section\n    g_critical_count++;\n    printf(\"Thread %d entered critical section. Current concurrent threads: %d\\n\", id, g_critical_count);\n    usleep(100000); // Simulate work\n    g_critical_count--;\n    printf(\"Thread %d exiting critical section. Current concurrent threads: %d\\n\", id, g_critical_count);\n\n    sem_post(&my_semaphore); // Release semaphore\n\n    printf(\"Thread %d finished.\\n\", id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    int thread_ids[NUM_THREADS];\n\n    // Initialize semaphore allowing SEM_VALUE concurrent accesses\n    if (sem_init(&my_semaphore, 0, SEM_VALUE) != 0) {\n        perror(\"sem_init failed\");\n        return 1;\n    }\n\n    printf(\"Main: Creating %d threads...\\n\", NUM_THREADS);\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        thread_ids[i] = i + 1;\n        if (pthread_create(&threads[i], NULL, thread_func, &thread_ids[i]) != 0) {\n            perror(\"pthread_create failed\");\n            return 1;\n        }\n    }\n\n    printf(\"Main: All threads created. Waiting for them to finish...\\n\");\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Main: All threads finished.\\n\");\n\n    sem_destroy(&my_semaphore); // Destroy semaphore\n    return 0;\n}"}, "sub_questions": [{"id": "1.1", "text": "מהו פלט אפשרי אחד של התוכנית? (אין צורך לרשום את כל הפלט, אלא דוגמה מייצגת של סדר האירועים וערכי המשתנים המודפסים)", "code_snippet": null, "options": null}, {"id": "1.2", "text": "מהו המספר המקסימלי של תהליכונים שיכולים להימצא בקטע הקריטי (בין קריאות sem_wait ל-sem_post) בו-זמנית? נמקו את תשובתכם.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "האם ייתכן מצב של קיפאון (deadlock) בתוכנית זו? נמקו את תשובתכם.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1. פלט אפשרי של התוכנית:\nהתוכנית יוצרת 5 תהליכונים. הסמפור my_semaphore מאותחל לערך 2. המשמעות היא שעד 2 תהליכונים יכולים להיכנס לקטע הקריטי (הקוד שבין sem_wait ל-sem_post) בו-זמנית. המשתנה g_critical_count עוקב אחר מספר התהליכונים בקטע הקריטי, ולכן ערכו המקסימלי יהיה 2. סדר ההדפסות של 'starting' ו-'finished' עבור התהליכונים יכול להשתנות, אך סדר הכניסה והיציאה מהקטע הקריטי יהיה מוגבל על ידי הסמפור. יש לזכור ש-printf אינה פעולה אטומית, וייתכנו שיבושים קלים בפלט אם שני תהליכונים מנסים להדפיס בו-זמנית, אך המבנה הכללי ישקף את ההגבלה של הסמפור.\n\nדוגמת פלט אפשרי:\nMain: Creating 5 threads...\nThread 1 starting...\nThread 2 starting...\nThread 3 starting...\nThread 4 starting...\nThread 5 starting...\nMain: All threads created. Waiting for them to finish...\nThread 1 entered critical section. Current concurrent threads: 1\nThread 2 entered critical section. Current concurrent threads: 2\nThread 1 exiting critical section. Current concurrent threads: 1\nThread 3 entered critical section. Current concurrent threads: 2\nThread 2 exiting critical section. Current concurrent threads: 1\nThread 4 entered critical section. Current concurrent threads: 2\nThread 1 finished.\nThread 3 exiting critical section. Current concurrent threads: 1\nThread 5 entered critical section. Current concurrent threads: 2\nThread 2 finished.\nThread 4 exiting critical section. Current concurrent threads: 1\nThread 3 finished.\nThread 5 exiting critical section. Current concurrent threads: 0\nThread 4 finished.\nThread 5 finished.\nMain: All threads finished.\n\n1.2. המספר המקסימלי של תהליכונים בקטע הקריטי בו-זמנית הוא 2.\nהסמפור my_semaphore מאותחל לערך SEM_VALUE, שהוא 2. המשמעות היא ששני תהליכונים יכולים לבצע sem_wait בהצלחה ולהיכנס לקטע הקריטי לפני שמישהו יבצע sem_post. ברגע ששני תהליכונים בפנים, כל תהליכון שלישי שינסה לבצע sem_wait יחסם עד שאחד מהתהליכונים שבפנים יבצע sem_post וישחרר את הסמפור. המשתנה g_critical_count, שמתעד את מספר התהליכונים בקטע הקריטי, לעולם לא יעלה על 2, מה שמוכיח את ההגבלה.\n\n1.3. לא, לא ייתכן מצב של קיפאון (deadlock) בתוכנית זו.\nכל קריאה ל-sem_wait תמיד מלווה בקריאה תואמת ל-sem_post בתוך אותה פונקציית תהליכון (thread_func). אין תרחיש שבו תהליכון רוכש את הסמפור ולא משחרר אותו (למשל, עקב מסלול שגיאה שגורם ליציאה מוקדמת או לולאה אינסופית לפני sem_post). אין כאן מספר משאבים הנרכשים בסדר שונה על ידי תהליכונים שונים, שהיא אחת הסיבות הנפוצות לקיפאון. התהליך הראשי (main) רק יוצר וממתין לתהליכונים ומעורבותו בפעולות הסמפור אינה יכולה לגרום לקיפאון עם תהליכוני העבודה. התוכנית מתוכננת בצורה כזו שכל תהליכון רוכש משאב אחד (מקום בסמפור) ומשחרר אותו באופן עקבי, מה שמונע קיפאון."}, "difficulty_estimation": "Medium", "_source_file": "0350__Semaphores__CodeAnalysis__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:00:17", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Semaphores", "Concurrency", "Threads", "Mutual Exclusion"], "content": {"text": "נתונה תוכנית C המשתמשת בסמפור בינארי על מנת להגן על קטע קריטי בו משתנה גלובלי משותף (shared_resource) מעודכן. התוכנית יוצרת 3 תהליכונים (threads) המנסים לגשת לקטע הקריטי. הקוד הבא מציג את לוגיקת התוכנית:\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h> // for sleep\n\nsem_t mutex;\nint shared_resource = 0; // A simple shared resource\n\nvoid* thread_function(void* arg) {\n    long thread_id = (long)arg;\n\n    printf(\"Thread %ld trying to enter critical section.\\n\", thread_id);\n    sem_wait(&mutex); // P operation\n\n    // Critical Section\n    shared_resource++;\n    printf(\"Thread %ld entered critical section. shared_resource = %d\\n\", thread_id, shared_resource);\n    sleep(1); // Simulate work\n    shared_resource--;\n    printf(\"Thread %ld exiting critical section. shared_resource = %d\\n\", thread_id, shared_resource);\n\n    sem_post(&mutex); // V operation\n    printf(\"Thread %ld released critical section.\\n\", thread_id);\n\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[3];\n    int i;\n\n    // Initialize semaphore with initial value 1 (for mutual exclusion)\n    sem_init(&mutex, 0, 1);\n\n    for (i = 0; i < 3; i++) {\n        pthread_create(&threads[i], NULL, thread_function, (void*)(long)i);\n    }\n\n    for (i = 0; i < 3; i++) {\n        pthread_join(threads[i], NULL);\n    }\n\n    sem_destroy(&mutex);\n    printf(\"Main: All threads finished. Final shared_resource = %d\\n\", shared_resource);\n\n    return 0;\n}\n```\n\n1. תארו פלט אפשרי אחד של התוכנית. הסבירו מדוע הוא אפשרי.\n2. מה יקרה אם נחליף את השורות `shared_resource--;` ו-`sem_post(&mutex);` כך ש-`sem_post(&mutex);` תבוצע לפני `shared_resource--;` בתוך הפונקציה `thread_function`? האם עלול להיווצר מצב מרוץ (race condition) או חוסר עקביות בנתונים? נמקו.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. **פלט אפשרי והסבר:**\nהסמפור `mutex` מאותחל לערך 1, מה שהופך אותו לסמפור בינארי המשמש להדדיות (mutual exclusion). כלומר, רק תהליכון אחד יכול להיכנס לקטע הקריטי בכל רגע נתון. הפעולה `sem_wait(&mutex)` (המקבילה ל-P) מקטינה את ערך הסמפור וממתינה אם הוא 0. הפעולה `sem_post(&mutex)` (המקבילה ל-V) מגדילה את ערך הסמפור.\nבתוך הקטע הקריטי, `shared_resource` מוגדל ואז מוקטן. מכיוון שרק תהליכון אחד יכול להיות בקטע הקריטי, ערכו של `shared_resource` יעלה ל-1 כאשר תהליכון נכנס, ויחזור ל-0 כאשר הוא יוצא. לכן, הפלט יראה שכל תהליכון נכנס ויוצא מהקטע הקריטי בנפרד, וערך `shared_resource` יהיה תמיד 1 בתוך הקטע הקריטי (לאחר ההגדלה) ו-0 מחוץ לו (לאחר ההקטנה).\n\n**פלט אפשרי לדוגמה:**\n```\nThread 0 trying to enter critical section.\nThread 1 trying to enter critical section.\nThread 2 trying to enter critical section.\nThread 0 entered critical section. shared_resource = 1\nThread 0 exiting critical section. shared_resource = 0\nThread 0 released critical section.\nThread 1 entered critical section. shared_resource = 1\nThread 1 exiting critical section. shared_resource = 0\nThread 1 released critical section.\nThread 2 entered critical section. shared_resource = 1\nThread 2 exiting critical section. shared_resource = 0\nThread 2 released critical section.\nMain: All threads finished. Final shared_resource = 0\n```\n(הערה: סדר ההודעות \"trying to enter critical section\" יכול להשתנות בהתאם לתיזמון של מתזמן התהליכונים, אך סדר הכניסה והיציאה מהקטע הקריטי יהיה מוגן על ידי הסמפור).\n\n2. **השלכות של שינוי סדר הפעולות:**\nאם נחליף את השורות `shared_resource--;` ו-`sem_post(&mutex);` כך ש-`sem_post(&mutex);` תבוצע לפני `shared_resource--;` בתוך הפונקציה `thread_function`, נקבל את הקוד הבא (באופן לוגי):\n```c\n    // ... קוד קודם ...\n    shared_resource++;\n    printf(\"Thread %ld entered critical section. shared_resource = %d\\n\", thread_id, shared_resource);\n    sleep(1); // Simulate work\n\n    sem_post(&mutex); // V operation - הסמפור משוחרר מוקדם מדי!\n    printf(\"Thread %ld released critical section (prematurely).\\n\", thread_id);\n\n    shared_resource--; // פעולה זו מתבצעת כעת מחוץ לקטע הקריטי המוגן!\n    printf(\"Thread %ld exiting critical section. shared_resource = %d\\n\", thread_id, shared_resource);\n    // ... קוד קודם ...\n```\nבמקרה כזה, התהליכון ישחרר את הסמפור (כלומר, יאפשר לתהליכון אחר להיכנס לקטע הקריטי) *לפני* שהוא מסיים את כל העבודה בקטע הקריטי (בפרט, לפני שהוא מקטין את `shared_resource`).\n\nזה יוביל ל:\n*   **מצב מרוץ (Race Condition)**: תהליכון אחד יכול לשחרר את הסמפור, ואז תהליכון אחר יכול להיכנס לקטע הקריטי ולהגדיל את `shared_resource`. אם התהליכון הראשון עדיין לא הספיק להקטין את `shared_resource` לפני שהתהליכון השני מגדיל אותו, ערכו של `shared_resource` יכול להגיע ל-2 (או יותר אם יש יותר תהליכונים), מה שמנוגד להנחת ההדדיות.\n*   **חוסר עקביות בנתונים**: ערך `shared_resource` לא יהיה מוגן כהלכה. הוא יכול להגיע לערכים גבוהים מ-1 בתוך מה שהיה אמור להיות הקטע הקריטי, ובסופו של דבר ערכו הסופי ב-`main` עשוי להיות שונה מ-0, מה שמצביע על שגיאה לוגית. לדוגמה, תהליכון A מגדיל את `shared_resource` ל-1, משחרר את הסמפור. מיד לאחר מכן, תהליכון B נכנס לקטע הקריטי ומגדיל את `shared_resource` ל-2. רק אז תהליכון A ממשיך ומקטין את `shared_resource` ל-1, ואז תהליכון B מקטין אותו ל-0. זה יוצר חוסר עקביות בזמן אמת ופוטנציאל לנתונים שגויים.\n\nהשינוי הזה למעשה מזיז את חלק מהפעולות שהיו אמורות להיות מוגנות על ידי הסמפור אל מחוץ לקטע הקריטי המוגן, ובכך מבטל את מנגנון ההדדיות הרצויה ומציג פגיעות למצבי מרוץ."}, "difficulty_estimation": "Medium", "_source_file": "0351__Semaphores__CodeAnalysis__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:00:38", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Semaphores", "Concurrency", "Threads"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בסמפורים לצורך סנכרון בין שני תהליכונים (threads). ניתן להניח שכל קריאות המערכת מצליחות.", "code_snippet": "#include <pthread.h>\n#include <semaphore.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h> \n\nsem_t semA, semB;\n\nvoid *thread_A_func(void *arg) {\n    for (int i = 0; i < 3; ++i) {\n        sem_wait(&semA);\n        printf(\"A\");\n        fflush(stdout); \n        sem_post(&semB);\n    }\n    return NULL;\n}\n\nvoid *thread_B_func(void *arg) {\n    for (int i = 0; i < 3; ++i) {\n        sem_wait(&semB);\n        printf(\"B\");\n        fflush(stdout); \n        sem_post(&semA);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tidA, tidB;\n\n    // Initialize semaphores\n    // semA allows thread A to start (value 1)\n    // semB blocks thread B initially (value 0)\n    sem_init(&semA, 0, 1); // Line 30\n    sem_init(&semB, 0, 0); // Line 31\n\n    pthread_create(&tidA, NULL, thread_A_func, NULL);\n    pthread_create(&tidB, NULL, thread_B_func, NULL);\n\n    pthread_join(tidA, NULL);\n    pthread_join(tidB, NULL);\n\n    sem_destroy(&semA);\n    sem_destroy(&semB);\n\n    printf(\"\\n\"); \n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "מהו הפלט המדויק של התוכנית? נמקו את תשובתכם.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "נניח שהקריאות לאתחול הסמפורים בשורות 30 ו-31 (sem_init) היו משתנות ל- `sem_init(&semA, 0, 0);` ו- `sem_init(&semB, 0, 0);` בהתאמה. מה תהיה השפעת השינוי על ריצת התוכנית? נמקו את תשובתכם.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. התוכנית יוצרת שני תהליכונים, Thread A ו-Thread B, המשתמשים בשני סמפורים (semA, semB) כדי להבטיח סדר הדפסה מתחלף. סמפור semA מאותחל ל-1, מה שמאפשר ל-Thread A להתחיל מיד. סמפור semB מאותחל ל-0, מה שחוסם את Thread B בתחילה.\nThread A מבצע `sem_wait(&semA)`, מדפיס 'A', ואז מבצע `sem_post(&semB)`. פעולה זו מאפשרת ל-Thread B להמשיך.\nThread B מבצע `sem_wait(&semB)`, מדפיס 'B', ואז מבצע `sem_post(&semA)`. פעולה זו מאפשרת ל-Thread A להמשיך.\nהלולאה מתבצעת 3 פעמים בכל תהליכון, וכך נוצרת סדרה של הדפסות מתחלפות. הפלט המדויק יהיה: ABABAB.\n\n2. אם שני הסמפורים יאותחלו ל-0, כלומר `sem_init(&semA, 0, 0);` ו- `sem_init(&semB, 0, 0);`:\nכאשר Thread A יתחיל, הוא יבצע `sem_wait(&semA)`. מכיוון ש-semA מאותחל ל-0, Thread A יחסם מיד וימתין ש-semA יהפוך לחיובי. הוא לעולם לא יגיע לשלב של `sem_post(&semB)`.\nבאופן דומה, כאשר Thread B יתחיל, הוא יבצע `sem_wait(&semB)`. מכיוון ש-semB מאותחל ל-0, Thread B יחסם מיד וימתין ש-semB יהפוך לחיובי. הוא לעולם לא יגיע לשלב של `sem_post(&semA)`.\nכתוצאה מכך, שני התהליכונים יחסמו באופן הדדי לנצח, והתוכנית תיכנס למצב של קיפאון (deadlock) ולא תדפיס דבר."}, "difficulty_estimation": "Medium", "_source_file": "0352__Semaphores__CodeAnalysis__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:01:03", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Deadlock", "Concurrency", "Resource Management"], "content": {"text": "נתונה מערכת המכילה N יחידות ממשאב A ו-M יחידות ממשאב B (כאשר N, M > 0). קיימים K חוטי עבודה (worker threads) המנסים במקביל לרכוש יחידה אחת מכל משאב (גם A וגם B) על מנת לבצע משימה כלשהי. לאחר סיום המשימה, החוטים משחררים את המשאבים. הקוד הבא מציג את לוגיקת הרכישה והשחרור של המשאבים עבור חוט עבודה יחיד.", "code_snippet": "// גלובליים:\n// sem_t sem_A; // מאותחל ל-N\n// sem_t sem_B; // מאותחל ל-M\n\nvoid worker_thread_func_type1() {\n    // שלב 1: רכישת משאבים\n    sem_wait(&sem_A);\n    sem_wait(&sem_B);\n\n    // שלב 2: ביצוע המשימה (משתמש במשאבים A ו-B)\n    do_task(); // פונקציה המייצגת את העבודה, אינה משפיעה על הסנכרון\n\n    // שלב 3: שחרור משאבים\n    sem_post(&sem_B);\n    sem_post(&sem_A);\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "הניחו שכל K חוטי העבודה מריצים את הפונקציה `worker_thread_func_type1` בלבד. האם במצב זה עלול להיווצר קיפאון (Deadlock)? נמקו את תשובתכם.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "כעת הניחו שבמערכת קיימים שני סוגים של חוטי עבודה: סוג 1 מריץ את `worker_thread_func_type1` (כפי שמוצג לעיל), וסוג 2 מריץ את הפונקציה `worker_thread_func_type2` הבאה:\n```c\nvoid worker_thread_func_type2() {\n    sem_wait(&sem_B);\n    sem_wait(&sem_A);\n    do_task();\n    sem_post(&sem_A);\n    sem_post(&sem_B);\n}\n```\nהאם במצב זה (כאשר שני הסוגים של החוטים רצים במקביל) עלול להיווצר קיפאון? אם כן, תארו תרחיש ספציפי המוביל לקיפאון והסבירו מדוע הוא מתרחש. אם לא, נמקו מדוע.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "הציעו שינוי מינימלי בקוד של אחת הפונקציות (למשל, `worker_thread_func_type2`), או הוספת סמפור/מנעול נוסף, על מנת למנוע קיפאון במערכת המתוארת בסעיף 2, מבלי לפגוע ביעילות ובמקביליות מעבר לנדרש. הציגו את הקוד המתוקן והסבירו כיצד הוא מונע קיפאון.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון שאלה 10:\n\n**סעיף 10.1:**\nלא, במצב זה לא עלול להיווצר קיפאון. קיפאון (Deadlock) דורש קיום של ארבעה תנאים בו-זמנית: מניעה הדדית (Mutual Exclusion), החזקה והמתנה (Hold and Wait), אי-יכולת לדרוס (No Preemption), והמתנה מעגלית (Circular Wait). במקרה זה, כל חוטי העבודה רוכשים את המשאבים באותו סדר קבוע (קודם A, אחר כך B). סדר רכישה עקבי זה מונע את התנאי של המתנה מעגלית, ולכן לא יכול להתרחש קיפאון.\n\n**סעיף 10.2:**\nכן, במצב זה עלול להיווצר קיפאון. התרחיש הבא מדגים זאת:\n1. חוט עבודה מסוג 1 (T1) מבצע `sem_wait(&sem_A)` ומצליח לרכוש יחידה מ-A.\n2. חוט עבודה מסוג 2 (T2) מבצע `sem_wait(&sem_B)` ומצליח לרכוש יחידה מ-B.\n3. כעת, T1 מנסה לבצע `sem_wait(&sem_B)` אך נחסם מכיוון ש-B נרכש על ידי T2.\n4. במקביל, T2 מנסה לבצע `sem_wait(&sem_A)` אך נחסם מכיוון ש-A נרכש על ידי T1.\nשני החוטים נמצאים כעת במצב של המתנה הדדית (T1 ממתין ל-B שמוחזק על ידי T2, ו-T2 ממתין ל-A שמוחזק על ידי T1), ובכך נוצרת המתנה מעגלית והמערכת נכנסת לקיפאון.\n\n**סעיף 10.3:**\nהפתרון היעיל ביותר והמינימלי ביותר למניעת קיפאון במקרה זה הוא לכפות סדר רכישה גלובלי אחיד על כל חוטי העבודה. נתקן את הפונקציה `worker_thread_func_type2` כך שתבצע את רכישת המשאבים באותו סדר כמו `worker_thread_func_type1` (כלומר, קודם A ואז B).\n\nקוד מתוקן עבור `worker_thread_func_type2`:\n```c\nvoid worker_thread_func_type2_fixed() {\n    // שלב 1: רכישת משאבים (סדר מתוקן)\n    sem_wait(&sem_A);\n    sem_wait(&sem_B);\n\n    // שלב 2: ביצוע המשימה\n    do_task();\n\n    // שלב 3: שחרור משאבים\n    sem_post(&sem_B);\n    sem_post(&sem_A);\n}\n```\nהסבר: על ידי אכיפת סדר רכישה גלובלי אחיד (A ואז B) לכל סוגי החוטים, אנו מבטלים את האפשרות להיווצרות תנאי ההמתנה המעגלית. אם כל החוטים מנסים לרכוש את A ואז את B, חוט אחד עשוי להחזיק ב-A ולהמתין ל-B, אך אף חוט אחר לא יחזיק ב-B וימתין ל-A, מכיוון שכולם ינסו לרכוש את A תחילה. בכך נמנע הקיפאון תוך שמירה על רמת מקביליות גבוהה יחסית, שכן חוטים עדיין יכולים לעבוד במקביל כל עוד הם לא מתחרים על אותם משאבים באופן שיוצר מעגל."}, "difficulty_estimation": "Hard", "_source_file": "0353__Semaphores__CodeAnalysis__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:46:43", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Deadlock", "Resource Allocation", "Concurrency", "Threads"], "content": {"text": "נתונה בעיית הקצאת משאבים במערכת. קיימת בריכה של `NUM_RESOURCES` משאבים זהים ומוגבלים. מספר חוטים (threads) רצים במקביל, וכל חוט נדרש לתפוס `RESOURCES_PER_THREAD` משאבים, לבצע עבודה כלשהי, ולאחר מכן לשחרר את כל המשאבים שתפס.\nלהלן קטע קוד המנסה לממש את לוגיקת העבודה של חוט כזה. שימו לב לערכים של `NUM_RESOURCES`, `RESOURCES_PER_THREAD` ו-`NUM_THREADS`.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h> // For sleep\n\n#define NUM_RESOURCES 5       // Total available resources\n#define RESOURCES_PER_THREAD 3 // Resources each thread needs\n#define NUM_THREADS 3        // Number of threads attempting to acquire resources\n\nsem_t resource_pool; // Initialized to NUM_RESOURCES\n\nvoid* worker_thread(void* arg) {\n    int thread_id = *(int*)arg;\n    printf(\"Thread %d: Attempting to acquire %d resources...\\n\", thread_id, RESOURCES_PER_THREAD);\n\n    for (int i = 0; i < RESOURCES_PER_THREAD; ++i) {\n        sem_wait(&resource_pool);\n        printf(\"Thread %d: Acquired resource #%d.\\n\", thread_id, i + 1);\n        // Introduce a small delay to increase deadlock probability\n        usleep(10000); \n    }\n\n    printf(\"Thread %d: All %d resources acquired. Working...\\n\", thread_id, RESOURCES_PER_THREAD);\n    sleep(1); // Simulate work\n    \n    printf(\"Thread %d: Releasing %d resources.\\n\", thread_id, RESOURCES_PER_THREAD);\n    for (int i = 0; i < RESOURCES_PER_THREAD; ++i) {\n        sem_post(&resource_pool);\n    }\n    return NULL;\n}\n\nint main() {\n    sem_init(&resource_pool, 0, NUM_RESOURCES); // Initialize semaphore with total resources\n\n    pthread_t threads[NUM_THREADS];\n    int tids[NUM_THREADS];\n\n    printf(\"System initialized with %d total resources. Each thread needs %d resources.\\n\", NUM_RESOURCES, RESOURCES_PER_THREAD);\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        tids[i] = i;\n        pthread_create(&threads[i], NULL, worker_thread, &tids[i]);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"All threads finished.\\n\");\n    sem_destroy(&resource_pool);\n    return 0;\n}"}, "sub_questions": [{"id": "10.1", "text": "האם קטע הקוד הנתון יכול להוביל לקיפאון (Deadlock)? אם כן, תארו תרחיש ספציפי (לפי סדר פעולות החוטים) שמוביל לקיפאון והסבירו מדוע הוא מתרחש.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "הציעו תיקון לבעיה שתיארתם בסעיף הקודם. צרפו את קטע הקוד המתוקן עבור הפונקציה `worker_thread` בלבד (כולל הצהרה על משתנים גלובליים חדשים אם נדרש), והסבירו את התיקון שהצעתם.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "האם התיקון שהצעתם בסעיף 2 עלול להציג בעיות חדשות (כגון הרעבה (Starvation) או חוסר יעילות) או טרייד-אופים מסוימים? נמקו.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "סעיף 1: קיפאון (Deadlock)\nכן, קטע הקוד הנתון עלול להוביל לקיפאון.\n\n**תרחיש לדוגמה:**\nבהינתן:\n*   `NUM_RESOURCES = 5` (סה\"כ משאבים זמינים)\n*   `RESOURCES_PER_THREAD = 3` (משאבים שכל חוט צריך)\n*   `NUM_THREADS = 3` (מספר החוטים)\n\n1.  **חוט 0** מבצע `sem_wait` פעם אחת, תופס משאב 1. סמפור `resource_pool` כעת 4.\n2.  **חוט 1** מבצע `sem_wait` פעם אחת, תופס משאב 1. סמפור `resource_pool` כעת 3.\n3.  **חוט 2** מבצע `sem_wait` פעם אחת, תופס משאב 1. סמפור `resource_pool` כעת 2.\n4.  **חוט 0** מבצע `sem_wait` פעם שנייה, תופס משאב 1. סמפור `resource_pool` כעת 1.\n5.  **חוט 1** מבצע `sem_wait` פעם שנייה, תופס משאב 1. סמפור `resource_pool` כעת 0.\n\nבשלב זה, חוט 0 מחזיק 2 משאבים וממתין למשאב שלישי. חוט 1 מחזיק 2 משאבים וממתין למשאב שלישי. חוט 2 מחזיק משאב 1 וממתין למשאב שני.\nהסמפור `resource_pool` הגיע ל-0, כלומר אין יותר משאבים פנויים.\nאף אחד מהחוטים לא יכול להמשיך לתפוס את המשאבים הנותרים לו, ולכן אף אחד מהם לא יכול לשחרר את המשאבים שהוא מחזיק כרגע. נוצר מעגל המתנה (circular wait) בין החוטים, וכולם נשארים חסומים לצמיתות. זהו מצב של קיפאון.\n\nסעיף 2: תיקון מוצע\nכדי למנוע קיפאון במקרה זה, יש לוודא שחוט רוכש את כל המשאבים הנדרשים לו באופן אטומי, או שהוא לא רוכש אף אחד מהם. אחת הדרכים לעשות זאת היא להשתמש במנעול (mutex) נוסף שיגן על שלב רכישת המשאבים. המנעול מבטיח שרק חוט אחד יוכל לנסות לרכוש משאבים בכל רגע נתון.\n\n**קוד מתוקן עבור `worker_thread`:**\n```c\n// הגדרה גלובלית של המנעול החדש\npthread_mutex_t acquisition_lock = PTHREAD_MUTEX_INITIALIZER;\n\nvoid* worker_thread(void* arg) {\n    int thread_id = *(int*)arg;\n    printf(\"Thread %d: Attempting to acquire %d resources (using mutex for atomicity)...\\n\", thread_id, RESOURCES_PER_THREAD);\n\n    // תפוס את המנעול כדי להבטיח רכישה אטומית של כל המשאבים\n    pthread_mutex_lock(&acquisition_lock);\n\n    // המתן לכל המשאבים בזה אחר זה בתוך המנעול\n    for (int i = 0; i < RESOURCES_PER_THREAD; ++i) {\n        sem_wait(&resource_pool); // עלול לחסום כאן, אך המנעול מוחזק\n        printf(\"Thread %d: Acquired resource #%d within mutex.\\n\", thread_id, i + 1);\n        usleep(10000); \n    }\n    \n    // שחרר את המנעול רק לאחר שכל המשאבים נרכשו בהצלחה\n    pthread_mutex_unlock(&acquisition_lock);\n\n    printf(\"Thread %d: All %d resources acquired. Working...\\n\", thread_id, RESOURCES_PER_THREAD);\n    sleep(1); // Simulate work\n    \n    printf(\"Thread %d: Releasing %d resources.\\n\", thread_id, RESOURCES_PER_THREAD);\n    for (int i = 0; i < RESOURCES_PER_THREAD; ++i) {\n        sem_post(&resource_pool);\n    }\n    return NULL;\n}\n// הערה: ב-main() יש לוודא אתחול ושיחרור המנעול: pthread_mutex_init(&acquisition_lock, NULL); ו- pthread_mutex_destroy(&acquisition_lock);\n```\n**הסבר לתיקון:**\nהוספנו מנעול גלובלי (`acquisition_lock`) המגן על הלולאה שבה החוטים רוכשים את המשאבים. כאשר חוט נכנס ללולאת הרכישה, הוא תופס את המנעול `acquisition_lock`. רק לאחר שרכש בהצלחה את כל `RESOURCES_PER_THREAD` המשאבים (כלומר, כל קריאות `sem_wait` בלולאה הסתיימו בהצלחה), הוא משחרר את המנעול.\nגישה זו מונעת קיפאון מכיוון שהיא מבטיחה שרק חוט אחד יכול להימצא בשלב \"ניסיון רכישת כל המשאבים\" בכל רגע נתון. אם חוט מתחיל לרכוש משאבים, אף חוט אחר לא יכול להתחיל תהליך רכישה משלו עד שהחוט הראשון יסיים או יקבל את כל המשאבים שלו וישחרר את המנעול. זה מונע הקצאה חלקית של משאבים לחוטים מרובים שעלולה להוביל למעגל המתנה.\n\nסעיף 3: טרייד-אופים ובעיות פוטנציאליות\nהתיקון שהוצע אכן מונע קיפאון, אך הוא מציג מספר טרייד-אופים ובעיות פוטנציאליות:\n\n1.  **ירידה במקביליות (Reduced Concurrency):** התיקון הופך את שלב רכישת המשאבים לטורי (sequential). רק חוט אחד יכול להיכנס לקטע הקריטי המוגן על ידי `acquisition_lock` ולנסות לרכוש משאבים. גם אם יש מספיק משאבים פנויים בבריכה עבור חוט אחר, הוא לא יוכל להתחיל לרכוש אותם עד שהחוט הנוכחי יסיים את רכישת כל המשאבים שלו וישחרר את `acquisition_lock`. זה עלול להפחית משמעותית את רמת המקביליות וניצול המשאבים במערכת.\n2.  **חוסר יעילות (Inefficiency):** אם חוט תופס את `acquisition_lock` ונקלע למצב שבו הוא ממתין על `sem_wait` (כי אין מספיק משאבים זמינים), הוא ימשיך להחזיק את `acquisition_lock`. במצב כזה, כל שאר החוטים שינסו לרכוש משאבים ייחסמו על `pthread_mutex_lock` ולא יוכלו אפילו לנסות לרכוש משאבים, גם אם חלקם פנויים. זה מבזבז זמן מעבד ומעכב חוטים אחרים שלא לצורך.\n3.  **פוטנציאל להרעבה (Potential for Starvation):** למרות שהפתרון מונע קיפאון, הוא עלול להוביל להרעבה בתרחישים מסוימים. אם יש זרם קבוע של חוטים שמבקשים משאבים, והחוטים שנבחרים על ידי המתזמן (scheduler) הם תמיד אלו שזקוקים למספר רב של משאבים או נתקעים בהמתנה ארוכה בתוך הקטע הקריטי, חוטים אחרים שזקוקים למעט משאבים או יכולים לסיים מהר עלולים להמתין זמן רב באופן בלתי מוגבל.\n\nלסיכום, בעוד שהתיקון מונע קיפאון בצורה יעילה, הוא עושה זאת במחיר של הגבלת המקביליות ופוטנציאל לחוסר יעילות, במיוחד במערכות עם דרישות משאבים מגוונות או עומס גבוה."}, "difficulty_estimation": "Hard", "_source_file": "0354__Semaphores__CodeAnalysis__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:02:18", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Concurrency", "Threads", "Barrier"], "content": {"text": "נתון מימוש של מחסום (Barrier) עבור N_THREADS חוטים, המיועד לשימוש חוזר (reusable barrier). המחסום אמור להבטיח שכל החוטים יגיעו לנקודה מסוימת בתוכנית לפני שמי מהם יוכל להמשיך הלאה. לאחר שכולם עברו, המחסום אמור להתאפס ולהיות מוכן לשימוש חוזר.\n\nיש לנתח את קוד המחסום הנתון ולזהות האם הוא פועל באופן תקין. אם כן, הסבירו מדוע. אם לא, תארו בפירוט את התרחיש הבעייתי (Race Condition / Deadlock / Starvation) והסבירו מדוע הוא מתרחש. בנוסף, הציעו תיקון לקוד שיפתור את הבעיה תוך שימוש בסמפורים בלבד.", "code_snippet": "#include <pthread.h>\n#include <semaphore.h>\n#include <stdio.h>\n#include <unistd.h>\n\n#define N_THREADS 5 // מספר החוטים המשתתפים במחסום\n\nsem_t mutex;         // מנעול להגנה על המונה\nsem_t barrier_sem;   // סמפור לחסימת חוטים\nint count = 0;       // מונה חוטים שהגיעו למחסום\n\nvoid barrier_init() {\n    sem_init(&mutex, 0, 1);\n    sem_init(&barrier_sem, 0, 0); // מאותחל ל-0, כך שחוטים יחסמו מיד\n    count = 0;\n}\n\nvoid barrier_wait() {\n    sem_wait(&mutex);\n    count++;\n    if (count == N_THREADS) {\n        // החוט האחרון שהגיע משחרר את כל החוטים\n        for (int i = 0; i < N_THREADS; ++i) {\n            sem_post(&barrier_sem);\n        }\n        count = 0; // איפוס המונה עבור שימוש חוזר במחסום\n    }\n    sem_post(&mutex);\n\n    sem_wait(&barrier_sem); // כל החוטים ממתינים כאן\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "המימוש הנתון של המחסום אינו פועל באופן תקין לשימוש חוזר. הוא סובל מבעיית \"מצב מרוץ\" (Race Condition) שעלולה לגרום לחוטים לעבור את המחסום בטרם עת, מבלי להמתין לשאר החוטים, ובכך מפרה את תכונת המחסום.\n\n**תיאור התרחיש הבעייתי (Race Condition):**\nנניח ש-N_THREADS = 2 (שני חוטים, T1 ו-T2). המחסום אמור לוודא ששניהם יגיעו לנקודה מסוימת לפני שימשיכו.\n\n1.  T1 קורא ל-`barrier_wait()`: נועל את `mutex`, `count` הופך ל-1, ומשחרר את `mutex`.\n2.  T2 קורא ל-`barrier_wait()`: נועל את `mutex`, `count` הופך ל-2.\n3.  `count == N_THREADS` מתקיים. T2 נכנס לבלוק ה-`if`.\n4.  T2 מבצע לולאה וקורא ל-`sem_post(&barrier_sem)` פעמיים. כעת ערך `barrier_sem` הוא 2.\n5.  T2 מיד מאפס את המונה: `count = 0;`.\n6.  T2 משחרר את `mutex`.\n7.  גם T1 וגם T2 ממשיכים לקרוא ל-`sem_wait(&barrier_sem)`. שניהם יעברו בהצלחה, וערך `barrier_sem` יחזור ל-0.\n8.  **הנקודה הקריטית:** נניח ש-T2 הוא חוט מהיר במיוחד. מיד לאחר שעבר את `sem_wait(&barrier_sem)` עבור המחזור הראשון של המחסום, הוא קורא שוב ל-`barrier_wait()` עבור המחזור השני.\n9.  T2 נועל את `mutex`, `count` הופך ל-1, ומשחרר את `mutex`.\n10. בינתיים, T1 הוא חוט איטי. ייתכן שהוא עדיין מבצע עיבוד כלשהו לאחר שעבר את המחסום הראשון, או שהוא עדיין בדרך לקריאה ל-`barrier_wait()` עבור המחזור השני.\n11. אם T2 ממשיך בריצתו המהירה ומגיע שוב למצב שבו `count == N_THREADS` (לדוגמה, אם T1 עדיין לא הגיע למחסום השני ו-T2 הוא החוט היחיד שהספיק להתקדם), T2 שוב יבצע `sem_post(&barrier_sem)` פעמיים ויאפס את `count`.\n12. כתוצאה מכך, כאשר T1 יגיע בסופו של דבר ל-`barrier_wait()` עבור המחזור השני, הוא ימצא את `barrier_sem` עם ערך חיובי (מכיוון ש-T2 כבר פירסם עבורו מראש). T1 יעבור את המחסום באופן מיידי מבלי להמתין ל-T2, ובכך תכונת המחסום נשברת.\n\nהבעיה נובעת מכך שאיפוס המונה `count = 0;` מתבצע על ידי החוט האחרון שמגיע למחסום, וזאת *לפני* שכל שאר החוטים הספיקו לעבור את `sem_wait(&barrier_sem)`. חוט מהיר יכול להיכנס מחדש למחסום, לאפס את המונה שוב ולשחרר סמפורים עודפים, מה שמאפשר לחוטים לעקוף את המחסום.\n\n**תיקון הקוד (מימוש \"מחסום כפול\" - Double Turnstile Barrier):**\nכדי לפתור בעיה זו ולממש מחסום ניתן לשימוש חוזר, נדרש מנגנון מורכב יותר, המכונה לעיתים \"מחסום כפול\" (Double Turnstile Barrier). מנגנון זה משתמש בשני סמפורים בנוסף למנעול ולמונה, כדי לשלוט בכניסה וביציאה מהמחסום ולהבטיח איפוס נכון.\n\n```c\n#include <pthread.h>\n#include <semaphore.h>\n#include <stdio.h>\n#include <unistd.h>\n\n#define N_THREADS 5 // מספר החוטים המשתתפים במחסום\n\nsem_t mutex;         // מנעול להגנה על המונה\nsem_t turnstile1;    // סמפור למחסום הכניסה (מאותחל ל-0)\nsem_t turnstile2;    // סמפור למחסום היציאה/איפוס (מאותחל ל-1)\nint count = 0;       // מונה חוטים שהגיעו למחסום\n\nvoid barrier_init() {\n    sem_init(&mutex, 0, 1);\n    sem_init(&turnstile1, 0, 0); // חוסם את כולם בהתחלה\n    sem_init(&turnstile2, 0, 1); // מאפשר לחוט אחד לעבור כדי לאפס את השער הבא\n    count = 0;\n}\n\nvoid barrier_wait() {\n    sem_wait(&mutex);\n    count++;\n    if (count == N_THREADS) { // החוט האחרון הגיע\n        sem_wait(&turnstile2); // נועל את turnstile2 כדי למנוע כניסה מוקדמת למחזור הבא\n        for (int i = 0; i < N_THREADS; ++i) {\n            sem_post(&turnstile1); // משחרר את כל החוטים דרך turnstile1\n        }\n    }\n    sem_post(&mutex);\n\n    sem_wait(&turnstile1); // כל החוטים ממתינים כאן (שער כניסה)\n\n    // שלב שני של המחסום (יציאה ואיפוס)\n    sem_wait(&mutex);\n    count--;\n    if (count == 0) { // החוט האחרון שעוזב את המחסום\n        for (int i = 0; i < N_THREADS; ++i) {\n            sem_wait(&turnstile1); // אוסף בחזרה את ההיתרים מ-turnstile1 (סוגר את שער הכניסה)\n        }\n        sem_post(&turnstile2); // משחרר את turnstile2 עבור המחזור הבא\n    }\n    sem_post(&mutex);\n}\n```\n\n**הסבר על התיקון:**\nהתיקון משתמש בשני סמפורים כ\"שערי ביטחון\" (turnstiles).\n*   `turnstile1` משמש לשחרור כל החוטים לאחר שהאחרון הגיע, בדומה לפתרון המקורי.\n*   `turnstile2` משמש כדי לוודא שרק חוט אחד (החוט האחרון שעוזב את המחזור הנוכחי) יכול לאפס את `turnstile1` ולשחרר את השער למחזור הבא. זה מונע מחוטים מהירים להיכנס למחזור הבא לפני שכל החוטים סיימו את המחזור הקודם, ובכך נמנע מצב המרוץ של איפוס מוקדם של המונה והסמפורים העודפים."}, "difficulty_estimation": "Hard", "_source_file": "0355__Semaphores__CodeAnalysis__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:03:13", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Concurrency", "Resource Management", "Deadlock"], "content": {"text": "נתון קטע קוד המדמה מערכת שבה מספר רב של חוטים (threads) מנסים לגשת לבריכת משאבים משותפת המכילה `NUM_RESOURCES` משאבים זהים. בכל פעם, חוט רוצה לתפוס משאב אחד, להשתמש בו, ולשחרר אותו. בנוסף, ישנו מונה גלובלי `total_operations` שמתעד את מספר הפעולות הכולל של תפיסה ושחרור, ועדכון המונה דורש קטע קריטי.\nהקוד הבא מנסה לממש את ההתנהגות הזו באמצעות סמפורים:\n\nנתחו את קטע הקוד הנתון. האם הוא פותר את בעיית הגישה לבריכת המשאבים והעדכון של המונה הגלובלי באופן נכון? אם כן, הסבירו מדוע. אם לא, זהו את הבעיה (או הבעיות) המרכזית, הסבירו אותה בפירוט, והציעו תיקון מינימלי לקוד.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h> // For usleep\n\n#define NUM_RESOURCES 3\n#define NUM_THREADS 5\n#define OPERATIONS_PER_THREAD 2\n\nsem_t resource_pool; // Limits concurrent access to N resources\nsem_t mutex;         // Protects the shared counter\nint total_operations = 0;\n\nvoid use_resource() {\n    // Simulate using the resource\n    usleep(10000); // 10ms\n}\n\nvoid* thread_func(void* arg) {\n    for (int i = 0; i < OPERATIONS_PER_THREAD; ++i) {\n        // Attempt to acquire a resource and update counter\n        sem_wait(&mutex);        // Acquire mutex first\n        sem_wait(&resource_pool); // Then acquire resource slot\n\n        total_operations++;\n        printf(\"Thread %ld acquired resource. Total ops: %d\\n\", (long)arg, total_operations);\n\n        use_resource(); // Use the resource\n\n        sem_post(&resource_pool); // Release resource slot\n        sem_post(&mutex);         // Release mutex last\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    sem_init(&resource_pool, 0, NUM_RESOURCES); // Initialize with N available resources\n    sem_init(&mutex, 0, 1);                   // Initialize mutex for critical section\n\n    printf(\"Starting simulation with %d resources and %d threads...\\n\", NUM_RESOURCES, NUM_THREADS);\n\n    for (long i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, (void*)i);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Simulation finished. Final total operations: %d\\n\", total_operations);\n\n    sem_destroy(&resource_pool);\n    sem_destroy(&mutex);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הקוד הנתון אינו פותר את הבעיה באופן נכון. הבעיה המרכזית בקוד היא סדר רכישת הסמפורים (semaphores) בתוך פונקציית `thread_func`.\n\n**הסבר הבעיה:**\n1.  **מטרת הסמפורים:**\n    *   הסמפור `resource_pool` הוא סמפור סופר (counting semaphore) המאותחל ל-`NUM_RESOURCES`. מטרתו לאפשר ל-`NUM_RESOURCES` חוטים לגשת למשאבים באופן מקביל. כלומר, הוא מגביל את מספר החוטים שיכולים להיות בקטע הקוד שבו הם 'מחזיקים' משאב.\n    *   הסמפור `mutex` הוא סמפור בינארי (binary semaphore) / מנעול (mutex) המאותחל ל-1. מטרתו להגן על המונה המשותף `total_operations` מפני תנאי מירוץ (race conditions), ולוודא שרק חוט אחד מעדכן את המונה בכל רגע נתון.\n\n2.  **סדר הרכישה השגוי:** בקוד הנתון, חוט רוכש קודם את ה-`mutex` (`sem_wait(&mutex);`) ורק לאחר מכן מנסה לרכוש משבצת משאב מ-`resource_pool` (`sem_wait(&resource_pool);`).\n\n3.  **ההשלכות:**\n    *   ברגע שחוט אחד רוכש את ה-`mutex`, אף חוט אחר אינו יכול לרכוש את ה-`mutex` ולהמשיך הלאה. המשמעות היא שרק חוט אחד יכול להיכנס לקטע הקוד שמתחיל ב-`sem_wait(&mutex)` בכל רגע נתון. \n    *   זה הופך למעשה את המערכת למערכת שבה רק חוט אחד יכול לתפוס משאב (ולהיכנס לקטע הקריטי של עדכון המונה) בכל רגע נתון, במקום לאפשר ל-`NUM_RESOURCES` חוטים לתפוס משאבים במקביל. זה מגביל באופן חמור את הקונקרנטיות (concurrency) של המערכת וסותר את מטרת ה-`resource_pool` כסמפור סופר המאפשר גישה מקבילה למספר משאבים.\n    *   במילים אחרות, גם אם ישנם `NUM_RESOURCES` זמינים (לדוגמה, `NUM_RESOURCES=3`) ורק חוט אחד משתמש במשאב, חוטים אחרים לא יוכלו להתחיל בתהליך רכישת המשאב מכיוון שהם יחסמו בניסיון לרכוש את ה-`mutex`.\n    *   אמנם במקרה זה לא ייווצר בהכרח קיפאון (deadlock) קלאסי, אך ייווצר מצב של חוסר יעילות דרמטי וביצועים ירודים, מכיוון שהגישה למשאבים הופכת לטורית (sequential) במקום מקבילית.\n\n**תיקון מינימלי לקוד:**\nכדי לפתור את הבעיה, יש לשנות את סדר רכישת הסמפורים. יש לרכוש את הסמפור `resource_pool` קודם, כדי לאפשר ל-`NUM_RESOURCES` חוטים להיכנס לקטע שבו הם מחזיקים משאב. רק לאחר מכן, בתוך קטע זה, יש לרכוש את ה-`mutex` כדי להגן על עדכון המונה `total_operations` בקטע הקריטי הקצר בלבד.\n\n```c\nvoid* thread_func(void* arg) {\n    for (int i = 0; i < OPERATIONS_PER_THREAD; ++i) {\n        // 1. רכישת משבצת משאב קודם - מאפשר ל-NUM_RESOURCES חוטים להחזיק משאבים במקביל\n        sem_wait(&resource_pool);\n\n        // 2. כעת, עדכון המונה המשותף בתוך קטע קריטי המוגן ע\"י mutex\n        sem_wait(&mutex);\n        total_operations++;\n        printf(\"Thread %ld acquired resource. Total ops: %d\\n\", (long)arg, total_operations);\n        sem_post(&mutex); // שחרור ה-mutex מיד לאחר עדכון המונה\n\n        use_resource(); // 3. שימוש במשאב - יכול להתבצע במקביל ע\"י NUM_RESOURCES חוטים\n\n        // 4. שחרור משבצת המשאב\n        sem_post(&resource_pool);\n    }\n    return NULL;\n}\n```\nהתיקון מבטיח ש-`NUM_RESOURCES` חוטים יכולים להחזיק משאבים במקביל, בעוד שעדכון המונה `total_operations` מוגן כהלכה מפני תנאי מירוץ על ידי ה-`mutex` הנרכש ומשוחרר בקטע קריטי קצר בלבד. זה מאפשר ניצול יעיל של המשאבים ומקסום הקונקרנטיות."}, "difficulty_estimation": "Hard", "_source_file": "0356__Semaphores__CodeAnalysis__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:03:46", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Deadlock", "Concurrency", "Threads"], "content": {"text": "נתונה תוכנית המשתמשת בשלושה סמפורים: sem_A, sem_B (שניהם סמפורים בינאריים, כלומר מאותחלים ל-1), ו-sem_limit (סמפור סופר המאותחל לערך K). התוכנית מריצה במקביל N חוטים, כאשר חלקם מריצים את הפונקציה thread_func_X וחלקם את הפונקציה thread_func_Y.\n\nשימו לב: פעולות ה-printf וה-usleep הוסרו מהקוד לנוחות הניתוח, אך הן אינן משנות את ההתנהגות הסנכרונית הבסיסית.", "code_snippet": "/* הגדרות ואיתחול סמפורים (בדוגמה זו, נניח שהם גלובליים ומאותחלים): */\n/* sem_t sem_A; sem_init(&sem_A, 0, 1); // סמפור בינארי למשאב A */\n/* sem_t sem_B; sem_init(&sem_B, 0, 1); // סמפור בינארי למשאב B */\n/* sem_t sem_limit; sem_init(&sem_limit, 0, K); // סמפור סופר, מאותחל ל-K */\n\nvoid critical_operation(int thread_id, const char* func_name) {\n    // פעולה קריטית הדורשת את שני המשאבים A ו-B\n    // ... (מבצעת עבודה, אינה משנה את מצב הסמפורים)\n}\n\nvoid *thread_func_X(void *arg) {\n    int id = *(int*)arg;\n    sem_wait(&sem_limit);\n    sem_wait(&sem_A);\n    sem_wait(&sem_B);\n\n    critical_operation(id, \"X\");\n\n    sem_post(&sem_B);\n    sem_post(&sem_A);\n    sem_post(&sem_limit);\n    return NULL;\n}\n\nvoid *thread_func_Y(void *arg) {\n    int id = *(int*)arg;\n    sem_wait(&sem_limit);\n    sem_wait(&sem_B);\n    sem_wait(&sem_A);\n\n    critical_operation(id, \"Y\");\n\n    sem_post(&sem_A);\n    sem_post(&sem_B);\n    sem_post(&sem_limit);\n    return NULL;\n}", "options": null}, "sub_questions": [{"id": "101.1", "text": "האם קיפאון (deadlock) אפשרי במערכת זו? אם כן, תאר תרחיש ספציפי המוביל לקיפאון, בהנחה ש-N=4 (סה\"כ 4 חוטים) ו-K=2 (ערך אתחול של sem_limit).", "code_snippet": null, "options": null}, {"id": "101.2", "text": "כיצד המצב ישתנה אם ערך האתחול של sem_limit יהיה K=1? האם קיפאון עדיין אפשרי? הסבר.", "code_snippet": null, "options": null}, {"id": "101.3", "text": "הצע פתרון לבעיית הקיפאון (אם קיימת) על ידי שינוי מינימלי בקוד, והסבר מדוע הפתרון שלך מונע קיפאון. כתוב את הקוד המעודכן עבור הפונקציה ששונתה.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  **האם קיפאון אפשרי כאשר N=4 ו-K=2?**\n    כן, קיפאון אפשרי במערכת זו.\n    \n    **תרחיש ספציפי לקיפאון:**\n    נניח ששני חוטים, T1 (מריץ את thread_func_X) ו-T2 (מריץ את thread_func_Y), מתחילים לרוץ במקביל.\n    *   **שלב 1:** T1 מבצע `sem_wait(&sem_limit)` ומצליח (sem_limit יורד ל-1).\n    *   **שלב 2:** T2 מבצע `sem_wait(&sem_limit)` ומצליח (sem_limit יורד ל-0). כעת, אף חוט נוסף לא יוכל להיכנס לקטע קריטי זה עד ש-T1 או T2 ישחררו את sem_limit.\n    *   **שלב 3:** T1 מבצע `sem_wait(&sem_A)` ומצליח (sem_A יורד ל-0). T1 מחזיק כעת את משאב A.\n    *   **שלב 4:** T2 מבצע `sem_wait(&sem_B)` ומצליח (sem_B יורד ל-0). T2 מחזיק כעת את משאב B.\n    *   **שלב 5:** T1 מנסה לבצע `sem_wait(&sem_B)`, אך sem_B מוחזק על ידי T2. T1 נחסם וממתין ל-sem_B.\n    *   **שלב 6:** T2 מנסה לבצע `sem_wait(&sem_A)`, אך sem_A מוחזק על ידי T1. T2 נחסם וממתין ל-sem_A.\n    \n    כעת, גם T1 וגם T2 חסומים וממתינים למשאב שמוחזק על ידי החוט השני. נוצר מצב של המתנה מעגלית (circular wait), שהיא אחד מארבעת התנאים ההכרחיים לקיפאון. מכיוון שכל התנאים לקיפאון מתקיימים, המערכת תיכנס לקיפאון.\n\n2.  **כיצד המצב ישתנה אם K=1? האם קיפאון עדיין אפשרי?**\n    אם ערך האתחול של `sem_limit` יהיה `K=1`, קיפאון **אינו** אפשרי.\n    \n    **הסבר:**\n    כאשר `sem_limit` מאותחל ל-1, רק חוט אחד יכול לבצע `sem_wait(&sem_limit)` בהצלחה בכל רגע נתון. המשמעות היא שרק חוט אחד יכול להיכנס לקטע הקוד שבו מתבצעות פעולות `sem_wait` עבור `sem_A` ו-`sem_B`. מכיוון שרק חוט אחד יכול לנסות לרכוש את `sem_A` ו-`sem_B`, לא ייתכן מצב שבו שני חוטים מחזיקים משאבים שונים ומנסים לרכוש את המשאב של השני בו-זמנית. `sem_limit` מתפקד למעשה כ-mutex גלובלי עבור הרכישה של `sem_A` ו-`sem_B`, ומבטיח סדרתיות בגישה אליהם, ובכך מונע את תנאי ההמתנה המעגלית.\n\n3.  **פתרון לבעיית הקיפאון וקוד מעודכן:**\n    הפתרון הנפוץ והפשוט ביותר למניעת קיפאון במקרה זה הוא לכפות סדר רכישה אחיד של המשאבים על כל החוטים. אם כל החוטים רוכשים את המשאבים באותו סדר (לדוגמה, תמיד קודם `sem_A` ואז `sem_B`), תנאי ההמתנה המעגלית נמנע.\n    \n    **קוד מעודכן עבור `thread_func_Y`:**\n    ```c\n    void *thread_func_Y_fixed(void *arg) {\n        int id = *(int*)arg;\n        sem_wait(&sem_limit);\n        // סדר רכישת המשאבים שונה כדי להתאים ל-thread_func_X\n        sem_wait(&sem_A); // רכוש את A קודם\n        sem_wait(&sem_B); // ואז רכוש את B\n\n        critical_operation(id, \"Y\");\n\n        sem_post(&sem_B);\n        sem_post(&sem_A);\n        sem_post(&sem_limit);\n        return NULL;\n    }\n    ```\n    \n    **הסבר מדוע הפתרון מונע קיפאון:**\n    על ידי הקפדה על סדר רכישה עקבי (לדוגמה, תמיד `sem_A` ואז `sem_B`), אנו מבטלים את האפשרות להיווצרות המתנה מעגלית. חוט שרוצה לרכוש את `sem_B` חייב קודם לרכוש את `sem_A`. אם `sem_A` כבר מוחזק על ידי חוט אחר, החוט הנוכחי ייחסם בהמתנה ל-`sem_A` ולא יוכל להחזיק את `sem_B` בו-זמנית. באופן זה, לא ייתכן מצב שבו חוט אחד מחזיק את `sem_A` וממתין ל-`sem_B`, בעוד חוט אחר מחזיק את `sem_B` וממתין ל-`sem_A`. זה מונע את תנאי ההמתנה המעגלית ובכך מונע קיפאון."}, "difficulty_estimation": "Hard", "_source_file": "0357__Semaphores__CodeAnalysis__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:04:31", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Concurrency", "Deadlock"], "content": {"text": "נתונה בעיית סנכרון בה שני סוגי תהליכונים (thread_X ו-thread_Y) מנסים לגשת לשני משאבים שיתופיים, המיוצגים על ידי סמפורים בינאריים A ו-B. שני הסמפורים מאותחלים לערך 1. הקוד הבא מתאר את לוגיקת הגישה למשאבים עבור כל סוג תהליכון, וכן את פונקציית main המאתחלת ומפעילה אותם. נתחו את הקוד וענו על השאלות הבאות:\n\n1.  האם הקוד הנתון פותר נכונה את בעיית הסנכרון? אם לא, מהי הבעיה וכיצד היא מתרחשת (תארו תרחיש ספציפי)?\n2.  הציעו פתרון מתוקן לקוד אשר מונע את הבעיה, והסבירו מדוע הוא פותר אותה.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h> // For sleep\n\nsem_t A;\nsem_t B;\n\nvoid* thread_X(void* arg) {\n    printf(\"Thread X: Trying to acquire semaphore A\\n\");\n    sem_wait(&A);\n    printf(\"Thread X: Acquired semaphore A, trying to acquire B\\n\");\n    sleep(1); // Simulate work or context switch\n    sem_wait(&B);\n    printf(\"Thread X: Acquired both A and B\\n\");\n    // Critical section\n    printf(\"Thread X: Releasing semaphores\\n\");\n    sem_post(&B);\n    sem_post(&A);\n    return NULL;\n}\n\nvoid* thread_Y(void* arg) {\n    printf(\"Thread Y: Trying to acquire semaphore B\\n\");\n    sem_wait(&B);\n    printf(\"Thread Y: Acquired semaphore B, trying to acquire A\\n\");\n    sleep(1); // Simulate work or context switch\n    sem_wait(&A);\n    printf(\"Thread Y: Acquired both B and A\\n\");\n    // Critical section\n    printf(\"Thread Y: Releasing semaphores\\n\");\n    sem_post(&A);\n    sem_post(&B);\n    return NULL;\n}\n\nint main() {\n    sem_init(&A, 0, 1);\n    sem_init(&B, 0, 1);\n\n    pthread_t tid_x, tid_y;\n\n    printf(\"Main: Creating threads...\\n\");\n    pthread_create(&tid_x, NULL, thread_X, NULL);\n    pthread_create(&tid_y, NULL, thread_Y, NULL);\n\n    pthread_join(tid_x, NULL);\n    pthread_join(tid_y, NULL);\n\n    sem_destroy(&A);\n    sem_destroy(&B);\n\n    printf(\"Main: Both threads finished (or deadlocked)\\n\");\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הקוד הנתון סובל מבעיית קיפאון (Deadlock). נסביר את התרחיש הבעייתי ואת הפתרון הנכון.\n\n**1. זיהוי הבעיה ותיאור התרחיש הבעייתי:**\nהקוד הנתון אינו פותר נכונה את בעיית הסנכרון והוא מוביל למצב של קיפאון (Deadlock). הסיבה לכך היא ששני סוגי התהליכונים מנסים לרכוש את המשאבים (הסמפורים) בסדר שונה:\n*   `thread_X` מנסה לרכוש את A ואז את B.\n*   `thread_Y` מנסה לרכוש את B ואז את A.\n\nתרחיש ספציפי המוביל לקיפאון:\n1.  `thread_X` מתחיל לרוץ ומבצע בהצלחה `sem_wait(&A)`. כעת `thread_X` מחזיק בסמפור A.\n2.  `thread_X` מבצע `sleep(1)`, מה שמאפשר ל-`thread_Y` לקבל הקצאת מעבד ולהתחיל לרוץ.\n3.  `thread_Y` מתחיל לרוץ ומבצע בהצלחה `sem_wait(&B)`. כעת `thread_Y` מחזיק בסמפור B.\n4.  `thread_Y` מבצע `sleep(1)`.\n5.  כאשר `thread_X` מתעורר מהשינה, הוא מנסה לבצע `sem_wait(&B)`. מכיוון ש-`thread_Y` מחזיק כעת בסמפור B, `thread_X` נחסם וממתין לשחרור B.\n6.  כאשר `thread_Y` מתעורר מהשינה, הוא מנסה לבצע `sem_wait(&A)`. מכיוון ש-`thread_X` מחזיק כעת בסמפור A, `thread_Y` נחסם וממתין לשחרור A.\n\nבשלב זה, `thread_X` מחכה ל-`thread_Y` שישחרר את B, ו-`thread_Y` מחכה ל-`thread_X` שישחרר את A. נוצר מעגל המתנה הדדית (circular wait), והמערכת נכנסת למצב קיפאון. שני התהליכונים חסומים ולא יוכלו להמשיך.\n\n**2. פתרון מתוקן:**\nהדרך הנפוצה למנוע קיפאון במקרה זה היא לוודא שכל התהליכונים מנסים לרכוש את המשאבים באותו סדר קבוע (resource hierarchy). לדוגמה, שניהם ירכשו תמיד את A ואז את B. במימוש זה, אם `thread_X` רוכש את A, הוא ינסה לרכוש את B. אם `thread_Y` גם רוצה את A, הוא יחסם עד ש-`thread_X` ישחרר אותו (לאחר שסיים את כל המקטע הקריטי ושחרר את B ואז את A). כך נמנעת המתנה מעגלית.\n\n**קוד מתוקן לדוגמה (שינוי ב-`thread_Y`):**\n```c\n#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h> // For sleep\n\nsem_t A;\nsem_t B;\n\nvoid* thread_X_corrected(void* arg) { // Renamed for clarity, logic is same as original thread_X\n    printf(\"Thread X (Corrected): Trying to acquire semaphore A\\n\");\n    sem_wait(&A);\n    printf(\"Thread X (Corrected): Acquired semaphore A, trying to acquire B\\n\");\n    sleep(1); // Simulate work or context switch\n    sem_wait(&B);\n    printf(\"Thread X (Corrected): Acquired both A and B\\n\");\n    // Critical section\n    printf(\"Thread X (Corrected): Releasing semaphores\\n\");\n    sem_post(&B);\n    sem_post(&A);\n    return NULL;\n}\n\nvoid* thread_Y_corrected(void* arg) { // Corrected to acquire A then B\n    printf(\"Thread Y (Corrected): Trying to acquire semaphore A\\n\"); // Changed order\n    sem_wait(&A); // Always acquire A first\n    printf(\"Thread Y (Corrected): Acquired semaphore A, trying to acquire B\\n\");\n    sleep(1); // Simulate work or context switch\n    sem_wait(&B);\n    printf(\"Thread Y (Corrected): Acquired both A and B\\n\");\n    // Critical section\n    printf(\"Thread Y (Corrected): Releasing semaphores\\n\");\n    sem_post(&B);\n    sem_post(&A);\n    return NULL;\n}\n\nint main() {\n    sem_init(&A, 0, 1);\n    sem_init(&B, 0, 1);\n\n    pthread_t tid_x, tid_y;\n\n    printf(\"Main: Creating corrected threads...\\n\");\n    pthread_create(&tid_x, NULL, thread_X_corrected, NULL);\n    pthread_create(&tid_y, NULL, thread_Y_corrected, NULL);\n\n    pthread_join(tid_x, NULL);\n    pthread_join(tid_y, NULL);\n\n    sem_destroy(&A);\n    sem_destroy(&B);\n\n    printf(\"Main: Both corrected threads finished successfully\\n\");\n    return 0;\n}\n```\n**הסבר לפתרון המתוקן:**\nעל ידי אכיפת סדר רכישה אחיד (A ואז B) לכל התהליכונים, אנו מבטלים את התנאי של המתנה מעגלית, שהוא אחד מארבעת התנאים ההכרחיים לקיפאון. אם `thread_X` מחזיק ב-A וממתין ל-B, ו-`thread_Y` מנסה לרכוש את A, הוא יחסם ב-`sem_wait(&A)` עד ש-`thread_X` ישחרר את A (לאחר שסיים את כל המקטע הקריטי ושחרר את B ואז את A). כך, אף פעם לא ייווצר מצב שבו `thread_X` מחכה ל-B ו-`thread_Y` מחכה ל-A בו-זמנית."}, "difficulty_estimation": "Hard", "_source_file": "0358__Semaphores__CodeAnalysis__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:05:01", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Producer-Consumer", "Concurrency", "Deadlock", "Starvation"], "content": {"text": "נתון קוד C הבא לבעיית יצרן-צרכן. המערכת משתמשת בחוצץ משותף בגודל קבוע (BUFFER_SIZE). בנוסף לסמפורים הסטנדרטיים (`mutex`, `full`, `empty`), נעשה שימוש בסמפור נוסף `production_limit` המאותחל ל-`MAX_CONCURRENT_PRODUCTION`. מטרת ה-`production_limit` היא להגביל את מספר היצרנים שיכולים *בו-זמנית להיות בשלב של יצירת פריט וניסיון להוסיפו לחוצץ* (כלומר, בין הקריאה הראשונה ל-`sem_wait(&production_limit)` ועד הקריאה האחרונה ל-`sem_post(&production_limit)`). נתחו את הקוד הנתון וענו על השאלות הבאות:", "code_snippet": "#include <semaphore.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n\n#define BUFFER_SIZE 5\n#define MAX_CONCURRENT_PRODUCTION 2 // מספר היצרנים המקסימלי שיכולים להיות בשלב יצירה והוספה\n\nint buffer[BUFFER_SIZE];\nint in = 0;\nint out = 0;\n\nsem_t mutex; // להגנה הדדית על גישה לחוצץ\nsem_t full;  // סופר מקומות מלאים בחוצץ\nsem_t empty; // סופר מקומות פנויים בחוצץ\nsem_t production_limit; // מגביל יצרנים פעילים בו-זמנית\n\n// מדמה יצירת פריט (למשל, עבודה חישובית)\nint produce_item_sim() {\n    // sleep(1); // לדמות עבודה\n    return rand() % 100;\n}\n\n// מדמה צריכת פריט (למשל, עבודה חישובית)\nvoid consume_item_sim(int item) {\n    // sleep(1); // לדמות עבודה\n    (void)item; // למנוע אזהרת משתנה שאינו בשימוש\n}\n\nvoid *producer(void *arg) {\n    int item;\n    for (int i = 0; i < 10; ++i) { // כל יצרן מייצר 10 פריטים\n        // שלב 1: יצירת פריט והוספה לחוצץ, מוגבל ע\"י production_limit\n        sem_wait(&production_limit); // (1) רכישת production_limit\n\n        item = produce_item_sim(); // יצירת הפריט\n\n        sem_wait(&empty); // (2) המתנה למקום פנוי\n        sem_wait(&mutex);  // (3) רכישת mutex לגישה לחוצץ\n\n        // קטע קריטי: הוספת פריט לחוצץ\n        buffer[in] = item;\n        in = (in + 1) % BUFFER_SIZE;\n        printf(\"Producer %ld: Added item %d. Buffer state: full=%d\\n\", (long)arg, item, sem_getvalue(&full));\n\n        sem_post(&mutex); // (4) שחרור mutex\n        sem_post(&full);  // (5) איתות על מקום מלא\n\n        sem_post(&production_limit); // (6) שחרור production_limit\n    }\n    return NULL;\n}\n\nvoid *consumer(void *arg) {\n    int item;\n    for (int i = 0; i < 10; ++i) { // כל צרכן צורך 10 פריטים\n        sem_wait(&full);  // (7) המתנה למקום מלא\n        sem_wait(&mutex);  // (8) רכישת mutex לגישה לחוצץ\n\n        // קטע קריטי: הסרת פריט מהחוצץ\n        item = buffer[out];\n        out = (out + 1) % BUFFER_SIZE;\n        printf(\"Consumer %ld: Removed item %d. Buffer state: full=%d\\n\", (long)arg, item, sem_getvalue(&full));\n\n        sem_post(&mutex);  // (9) שחרור mutex\n        sem_post(&empty); // (10) איתות על מקום פנוי\n\n        consume_item_sim(item); // צריכת הפריט (ניתן לעשות במקביל)\n    }\n    return NULL;\n}\n\nint main() {\n    sem_init(&mutex, 0, 1);\n    sem_init(&full, 0, 0);\n    sem_init(&empty, 0, BUFFER_SIZE);\n    sem_init(&production_limit, 0, MAX_CONCURRENT_PRODUCTION);\n\n    pthread_t prod_threads[3], cons_threads[3];\n\n    for (long i = 0; i < 3; ++i) {\n        pthread_create(&prod_threads[i], NULL, producer, (void *)(i + 1));\n        pthread_create(&cons_threads[i], NULL, consumer, (void *)(i + 1));\n    }\n\n    for (int i = 0; i < 3; ++i) {\n        pthread_join(prod_threads[i], NULL);\n        pthread_join(cons_threads[i], NULL);\n    }\n\n    sem_destroy(&mutex);\n    sem_destroy(&full);\n    sem_destroy(&empty);\n    sem_destroy(&production_limit);\n\n    return 0;\n}\n"}, "sub_questions": [{"id": "1.1", "text": "האם המימוש הנתון משיג באופן נכון את המטרה המיועדת של `production_limit`?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "האם קוד זה מציג פוטנציאל לקיפאון (deadlock) או הרעבה (starvation)? נמקו.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "דונו ברמת המקביליות המושגת על ידי מימוש זה, בהתחשב בתפקידו של `production_limit`.", "code_snippet": null, "options": null}], "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "### פתרון שאלה 1\n\n**1.1 האם המימוש הנתון משיג באופן נכון את המטרה המיועדת של `production_limit`?**\n\nכן, המימוש משיג באופן נכון את המטרה. הסמפור `production_limit` נרכש לפני תחילת שלב יצירת הפריט והוספתו לחוצץ (שורה 1 בקוד היצרן) ומשוחרר רק לאחר סיום כל השלבים הללו, כולל הוספת הפריט בפועל לחוצץ ושחרור הסמפורים `mutex` ו-`full` (שורה 6 בקוד היצרן). המשמעות היא שבכל רגע נתון, לא יותר מ-`MAX_CONCURRENT_PRODUCTION` יצרנים יכולים להיות בו-זמנית בתוך קטע הקוד המוגן על ידי `production_limit`, אשר כולל את `produce_item_sim()`, המתנה למקום פנוי בחוצץ, רכישת מנעול, הוספה לחוצץ, ושחרור מנעולים.\n\n**1.2 האם קוד זה מציג פוטנציאל לקיפאון (deadlock) או הרעבה (starvation)? נמקו.**\n\n**קיפאון (Deadlock):**\nלא, הקוד אינו מציג פוטנציאל לקיפאון. הסמפורים נרכשים ומשוחררים בסדר עקבי:\n*   **יצרן:** `production_limit` -> `empty` -> `mutex`\n*   **צרכן:** `full` -> `mutex`\nאין כאן תלות מעגלית בין הסמפורים. `production_limit` משמש כמעין 'שער כניסה' לשלב היצרן, ואינו יוצר תלות הדדית עם הסמפורים `empty` או `full` באופן שיכול להוביל לקיפאון. יצרן שלוקח `production_limit` אך נחסם על `empty` או `mutex` לא ימנע מצרכן לשחרר `full` או `empty`.\n\n**הרעבה (Starvation):**\nהקוד עצמו אינו מציג מנגנון מובנה המבטיח הוגנות (fairness) בין חוטים, בדומה לסמפורים רגילים שאינם בהכרח הוגנים. עם זאת, אין תרחיש מובהק של הרעבה כתוצאה מכשל לוגי בלוגיקת הסמפורים עצמה. אם חוטים ממתינים בתור לסמפור (כמו `empty` או `mutex`), ייתכן שחוט מסוים יקבל את הסמפור שוב ושוב לפני חוטים אחרים, אך זהו מאפיין כללי של סמפורים ללא תור הוגן, ולא כשל לוגי בפתרון הספציפי. הסמפור `production_limit` עלול לגרום לכך שיצרנים רבים ימתינו מחוץ לקטע המוגן, אך ברגע שהם נכנסים, הם מתמודדים על משאבי החוצץ בצורה סטנדרטית.\n\n**1.3 דונו ברמת המקביליות המושגת על ידי מימוש זה, בהתחשב בתפקידו של `production_limit`.**\n\nהמימוש משפיע על רמת המקביליות בכמה דרכים:\n\n*   **הגבלת יצרנים פעילים:** `production_limit` מגביל את מספר היצרנים שיכולים לבצע את `produce_item_sim()` *וגם* לנסות להוסיף פריטים לחוצץ בו-זמנית ל-`MAX_CONCURRENT_PRODUCTION`. זהו יתרון אם `produce_item_sim()` היא פעולה עתירת משאבים (למשל, CPU או זיכרון) שאיננו רוצים שכל היצרנים יבצעו במקביל ללא הגבלה. אם `MAX_CONCURRENT_PRODUCTION` נמוך מאוד (למשל 1), זה עלול להפחית את המקביליות הכוללת של היצרנים.\n\n*   **הפרדת שלבים:** ה-`produce_item_sim()` מתבצעת כחלק מהקטע המוגן על ידי `production_limit`, אך `consume_item_sim()` מתבצעת מחוץ לכל מנעול או סמפור מיוחד בצרכן. זה מאפשר לצרכנים לצרוך פריטים במקביל ללא הגבלה נוספת מעבר לזמינות הפריטים בחוצץ עצמו. זוהי הפרדה נכונה שממקסמת את המקביליות של פעולת הצריכה.\n\n*   **צוואר בקבוק פוטנציאלי:** אם `MAX_CONCURRENT_PRODUCTION` קטן מ-`BUFFER_SIZE` ומספר היצרנים גדול, ה-`production_limit` יכול להפוך לצוואר בקבוק, שיגביל את קצב הוספת הפריטים לחוצץ, גם אם יש מקומות פנויים רבים בחוצץ (`empty` > 0). מצד שני, אם `MAX_CONCURRENT_PRODUCTION` גדול מדי או שווה למספר היצרנים הכולל, ייתכן שתפקידו של `production_limit` יפחת או יהפוך ללא רלוונטי, וההגבלה העיקרית תהיה על ידי `empty` ו-`mutex` בלבד.\n\nבסך הכל, המימוש מאפשר שליטה עדינה יותר על התנהגות היצרנים, במחיר של פוטנציאל להפחתת מקביליות אם `MAX_CONCURRENT_PRODUCTION` נבחר נמוך מדי ביחס ליכולות המערכת או מספר היצרנים."}, "difficulty_estimation": "Hard", "_source_file": "0359__Semaphores__CodeAnalysis__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:06:04", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Deadlock", "Concurrency", "Threads"], "content": {"text": "נתונה תוכנית המשתמשת בשני סמפורים בינאריים, `sem_A` ו-`sem_B`, המאותחלים ל-1, כדי להגן על שני משאבים משותפים. שני סוגי חוטים פועלים במקביל במערכת. חוטים מסוג `thread_A_then_B` מנסים לתפוס את `sem_A` ולאחר מכן את `sem_B`, ואילו חוטים מסוג `thread_B_then_A` מנסים לתפוס את `sem_B` ולאחר מכן את `sem_A`. לאחר תפיסת שני הסמפורים, החוטים מבצעים פעולה כלשהי (כגון עדכון משתנה משותף `shared_counter`) ומשחררים אותם בסדר הפוך. נתון קטע הקוד הבא:\n\nהאם קטע הקוד הנתון יכול להוביל למצב של קיפאון (deadlock)? אם כן, תאר/י תרחיש ספציפי המוביל לקיפאון והסבר/י מדוע הוא מתרחש. בנוסף, הצע/י שינוי מינימלי בקוד כדי למנוע קיפאון, והסבר/י מדוע הפתרון שלך מונע קיפאון.", "code_snippet": "sem_t sem_A; // initialized to 1\nsem_t sem_B; // initialized to 1\nint shared_counter = 0;\n\nvoid* thread_A_then_B(void* arg) {\n    sem_wait(&sem_A);\n    // Simulate some work or context switch\n    // usleep(10000);\n    sem_wait(&sem_B);\n    \n    // Critical section\n    shared_counter++;\n\n    sem_post(&sem_B);\n    sem_post(&sem_A);\n    return NULL;\n}\n\nvoid* thread_B_then_A(void* arg) {\n    sem_wait(&sem_B);\n    // Simulate some work or context switch\n    // usleep(10000);\n    sem_wait(&sem_A);\n    \n    // Critical section\n    shared_counter++;\n\n    sem_post(&sem_A);\n    sem_post(&sem_B);\n    return NULL;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, קטע הקוד הנתון יכול להוביל למצב של קיפאון (deadlock). קיפאון מתרחש כאשר שני חוטים או יותר ממתינים זה לזה באופן בלתי הפיך, כאשר כל אחד מהם מחזיק במשאב שהאחר זקוק לו וממתין למשאב המוחזק על ידי האחר.\n\n**תרחיש קיפאון ספציפי:**\n1.  **חוט `thread_A_then_B` רץ:** הוא מבצע `sem_wait(&sem_A)` ומצליח לתפוס את `sem_A`. בשלב זה, `sem_A` מוחזק על ידו ו-`sem_B` חופשי.\n2.  **מתרחש מעבר הקשר (context switch) לחוט `thread_B_then_A`:**\n3.  **חוט `thread_B_then_A` רץ:** הוא מבצע `sem_wait(&sem_B)` ומצליח לתפוס את `sem_B`. בשלב זה, `sem_B` מוחזק על ידו ו-`sem_A` מוחזק על ידי `thread_A_then_B`.\n4.  **מתרחש מעבר הקשר בחזרה לחוט `thread_A_then_B`:**\n5.  **חוט `thread_A_then_B` מנסה להמשיך:** הוא מנסה לבצע `sem_wait(&sem_B)`. אך `sem_B` מוחזק כעת על ידי `thread_B_then_A`, ולכן `thread_A_then_B` נכנס למצב המתנה על `sem_B`.\n6.  **מתרחש מעבר הקשר בחזרה לחוט `thread_B_then_A`:**\n7.  **חוט `thread_B_then_A` מנסה להמשיך:** הוא מנסה לבצע `sem_wait(&sem_A)`. אך `sem_A` מוחזק כעת על ידי `thread_A_then_B`, ולכן `thread_B_then_A` נכנס למצב המתנה על `sem_A`.\n\nבנקודה זו, שני החוטים נמצאים במצב המתנה הדדית: `thread_A_then_B` ממתין ל-`sem_B` המוחזק על ידי `thread_B_then_A`, ו-`thread_B_then_A` ממתין ל-`sem_A` המוחזק על ידי `thread_A_then_B`. אף אחד מהם לא יכול להמשיך, והמערכת נכנסת לקיפאון.\n\n**פתרון למניעת קיפאון (שינוי מינימלי):**\nכדי למנוע קיפאון במצב כזה, יש להבטיח שכל החוטים תופסים את המשאבים באותו סדר. שינוי זה מונע את התנאי של 'המתנה מעגלית' (Circular Wait), שהוא אחד מארבעת התנאים ההכרחיים לקיפאון (על פי תנאי קופמן). לדוגמה, נוכל לשנות את `thread_B_then_A` כך שתתפוס את `sem_A` לפני `sem_B`.\n\n**קוד מתוקן (שינוי ב-`thread_B_then_A`):**\n```c\nsem_t sem_A; // initialized to 1\nsem_t sem_B; // initialized to 1\nint shared_counter = 0;\n\nvoid* thread_A_then_B(void* arg) {\n    sem_wait(&sem_A);\n    // usleep(10000);\n    sem_wait(&sem_B);\n    \n    shared_counter++;\n\n    sem_post(&sem_B);\n    sem_post(&sem_A);\n    return NULL;\n}\n\nvoid* thread_B_then_A(void* arg) {\n    sem_wait(&sem_A); // שינוי: תופסים את sem_A קודם\n    // usleep(10000);\n    sem_wait(&sem_B); // ואז את sem_B\n    \n    shared_counter++;\n\n    sem_post(&sem_B);\n    sem_post(&sem_A); // משחררים בסדר הפוך: B ואז A\n    return NULL;\n}\n```\n\n**הסבר מדוע הפתרון מונע קיפאון:**\nעל ידי אכיפת סדר תפיסת משאבים אחיד (תמיד קודם `sem_A` ואז `sem_B`) עבור כל החוטים שצריכים את שני המשאבים, אנו מבטלים את האפשרות ל'המתנה מעגלית'. אם חוט אחד תפס את `sem_A` וממתין ל-`sem_B`, החוט השני לא יוכל לתפוס את `sem_B` לפני שהוא תפס את `sem_A` (אשר אולי כבר מוחזק על ידי החוט הראשון). במקרה כזה, החוט השני פשוט ימתין ל-`sem_A` עד שיתפנה, ולא יוכל לתפוס את `sem_B` ולגרום להמתנה מעגלית. כאשר `sem_A` ישוחרר, החוט השני יוכל לתפוס אותו, ואז לתפוס את `sem_B` (אשר יהיה זמין ברגע שהחוט הראשון ישחרר אותו), וכך שניהם יוכלו להשלים את פעולתם ללא קיפאון."}, "difficulty_estimation": "Hard", "_source_file": "0360__Semaphores__CodeAnalysis__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:06:34", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Deadlocks"], "content": {"text": "כדי שיתרחש קיפאון (deadlock), כל ארבעת התנאים של קופמן (הדרה הדדית, החזקה והמתנה, אי-הפקעה, המתנה מעגלית) חייבים להתקיים בו-זמנית.\nנכון / לא נכון", "code_snippet": null, "options": ["נכון", "לא נכון"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "נכון", "explanation": "נכון. קיפאון (deadlock) מתרחש רק כאשר כל ארבעת התנאים של קופמן (הדרה הדדית - Mutual Exclusion, החזקה והמתנה - Hold and Wait, אי-הפקעה - No Preemption, והמתנה מעגלית - Circular Wait) מתקיימים בו-זמנית במערכת. אם אחד מהם אינו מתקיים, קיפאון לא יכול להתרחש."}, "difficulty_estimation": "Easy", "_source_file": "0361__Deadlocks__MultipleChoice__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:06:40", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Deadlocks", "Concurrency", "Processes"], "content": {"text": "קיפאון (deadlock) מתרחש כאשר:", "code_snippet": null, "options": ["תהליך אחד בלבד ממתין למשאב.", "מספר תהליכים ממתינים למשאבים זה מזה בשרשרת מעגלית.", "תהליך ממתין למשאב שאינו קיים.", "תהליך נכנס ללולאה אינסופית."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "מספר תהליכים ממתינים למשאבים זה מזה בשרשרת מעגלית.", "explanation": "קיפאון (deadlock) מתרחש כאשר קבוצה של תהליכים חוסמת זה את זה, כך שכל תהליך בקבוצה ממתין למשאב המוחזק על ידי תהליך אחר באותה קבוצה. תנאי זה ידוע גם כתנאי 'המתנה מעגלית' (Circular Wait), והוא תנאי הכרחי להתרחשות קיפאון, יחד עם שלושה תנאים נוספים: הדרה הדדית, החזקה והמתנה, ואי-הפקעה."}, "difficulty_estimation": "Easy", "_source_file": "0362__Deadlocks__MultipleChoice__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:06:49", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Deadlocks"], "content": {"text": "האם קיפאון (deadlock) יכול להתרחש במערכת ללא המתנה מעגלית (circular wait)?", "code_snippet": null, "options": ["נכון", "לא נכון"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "לא נכון", "explanation": "קיפאון מתרחש רק כאשר מתקיימים ארבעה תנאים הכרחיים: הדרה הדדית (Mutual Exclusion), החזקה והמתנה (Hold and Wait), אי-פקיעה (No Preemption), והמתנה מעגלית (Circular Wait). אם אין המתנה מעגלית, לא ייתכן קיפאון."}, "difficulty_estimation": "Easy", "_source_file": "0363__Deadlocks__MultipleChoice__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:06:56", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Deadlocks"], "content": {"text": "האם הדדיות (Mutual Exclusion) היא תנאי הכרחי לקיומו של קיפאון (Deadlock)?", "code_snippet": null, "options": ["נכון", "לא נכון"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "נכון", "explanation": "נכון. הדדיות (Mutual Exclusion) היא אחד מארבעת התנאים ההכרחיים לקיומו של קיפאון, יחד עם החזקה והמתנה (Hold and Wait), אי-הפקעה (No Preemption) והמתנה מעגלית (Circular Wait). אם תנאי זה לא מתקיים, כלומר משאבים ניתנים לשיתוף, אזי לא ייתכן קיפאון על משאבים אלו."}, "difficulty_estimation": "Easy", "_source_file": "0364__Deadlocks__MultipleChoice__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:07:02", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Deadlocks", "Concurrency"], "content": {"text": "אם אחד מארבעת התנאים ההכרחיים לקיפאון (Deadlock) אינו מתקיים, קיפאון אינו יכול להתרחש.", "code_snippet": null, "options": ["נכון", "לא נכון"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "נכון", "explanation": "נכון. ארבעת התנאים ההכרחיים לקיפאון הם: הדרה הדדית (Mutual Exclusion), החזק והמתן (Hold and Wait), אי-דריסה (No Preemption), והמתנה מעגלית (Circular Wait). אם לפחות אחד מהתנאים הללו לא מתקיים, המערכת מוגנת מפני קיפאון."}, "difficulty_estimation": "Easy", "_source_file": "0365__Deadlocks__MultipleChoice__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:07:09", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Deadlocks"], "content": {"text": "כדי למנוע קיפאון (deadlock), יש צורך לשבור לפחות אחד מארבעת התנאים ההכרחיים להתרחשותו.", "code_snippet": null, "options": ["נכון", "לא נכון"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "נכון", "explanation": "נכון. קיפאון (deadlock) מתרחש רק כאשר כל ארבעת התנאים ההכרחיים (הדרה הדדית, החזקה והמתנה, אי-הפקעה, והמתנה מעגלית) מתקיימים בו-זמנית. לכן, על מנת למנוע קיפאון, יש לשבור או למנוע את התקיימותו של לפחות אחד מהתנאים הללו."}, "difficulty_estimation": "Easy", "_source_file": "0366__Deadlocks__MultipleChoice__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:07:16", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Deadlocks", "Concurrency"], "content": {"text": "אם תנאי 'אי-נתיקה' (No Preemption) אינו מתקיים, כלומר ניתן לבצע נתיקה של משאבים, אזי עדיין ייתכן קיפאון (deadlock).", "code_snippet": null, "options": ["נכון", "לא נכון"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "לא נכון", "explanation": "לא נכון. קיפאון (deadlock) מתרחש רק כאשר כל ארבעת התנאים ההכרחיים מתקיימים: מניעה הדדית (Mutual Exclusion), אחיזה והמתנה (Hold and Wait), אי-נתיקה (No Preemption), והמתנה מעגלית (Circular Wait). אם תנאי 'אי-נתיקה' אינו מתקיים, כלומר ניתן ליטול משאב מחוט שמחזיק בו, אזי אחד מהתנאים ההכרחיים לקיפאון נמנע, ולכן קיפאון אינו יכול להתרחש."}, "difficulty_estimation": "Easy", "_source_file": "0367__Deadlocks__MultipleChoice__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:07:24", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Deadlocks", "Concurrency"], "content": {"text": "איזה מהתנאים הבאים אינו תנאי הכרחי להתרחשות קיפאון (Deadlock)?", "code_snippet": null, "options": ["הדרה הדדית (Mutual Exclusion)", "החזק והמתן (Hold and Wait)", "הקצאה דינמית של משאבים (Dynamic Resource Allocation)", "אי-הפקעה (No Preemption)", "המתנה מעגלית (Circular Wait)"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "הקצאה דינמית של משאבים (Dynamic Resource Allocation)", "explanation": "ארבעת התנאים ההכרחיים לקיפאון (Deadlock) הם: הדרה הדדית, החזק והמתן, אי-הפקעה והמתנה מעגלית. 'הקצאה דינמית של משאבים' אינה אחד מתנאים אלה, אלא מתארת שיטה להקצאת משאבים או התנהגות של המערכת ולא תנאי הכרחי לקיפאון."}, "difficulty_estimation": "Easy", "_source_file": "0368__Deadlocks__MultipleChoice__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:07:33", "_subject": "Concurrency"}, {"id": 10, "type": "MultipleChoice", "topic": ["Deadlocks", "Deadlock Prevention", "Concurrency"], "content": {"text": "איזו מהטענות הבאות לגבי מניעת קיפאון (Deadlock Prevention) נכונה?", "code_snippet": null, "options": ["א. מניעת תנאי 'החזקה והמתנה' (Hold and Wait) על ידי דרישה מחוט לתפוס את כל המשאבים הנדרשים לו בתחילת פעולתו, עלולה להוביל לניצול נמוך של משאבים.", "ב. מניעת תנאי 'אי-דריסה' (No Preemption) קלה ליישום עבור כל סוגי המשאבים.", "ג. מניעת תנאי 'הדרה הדדית' (Mutual Exclusion) אפשרית תמיד על ידי הפיכת כל המשאבים לניתנים לשיתוף.", "ד. מניעת תנאי 'המתנה מעגלית' (Circular Wait) מחייבת בהכרח הגדרת סדר היררכי גלובלי לכל המשאבים במערכת."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "תשובה א' נכונה. אסטרטגיה נפוצה למניעת 'החזקה והמתנה' היא לדרוש מכל תהליך לבקש את כל המשאבים שהוא צריך לפני תחילת ביצועו (או לשחרר את כל המשאבים שהוא מחזיק לפני שהוא מבקש משאבים נוספים). גישה זו עלולה להוביל לכך שמשאבים יישארו תפוסים לזמן ארוך יותר מהנדרש בפועל, או שיידרשו בבת אחת, מה שיפגע ביעילות ויוביל לניצול נמוך של המשאבים. תשובה ב' אינה נכונה מכיוון שמניעת 'אי-דריסה' קשה ליישום עבור משאבים כמו מנעולים (mutexes) שאינם ניתנים לדריסה בקלות. תשובה ג' אינה נכונה מכיוון שלא ניתן למנוע 'הדרה הדדית' מכל המשאבים; חלקם, כמו מדפסת או זיכרון, דורשים גישה בלעדית ולכן אינם ניתנים לשיתוף באופן מלא. תשובה ד' אינה נכונה מכיוון שאף על פי שקביעת סדר היררכי גלובלי היא דרך נפוצה ויעילה למנוע 'המתנה מעגלית', היא אינה הדרך ה'בהכרח' יחידה. ישנן שיטות נוספות כמו דרישת שחרור משאבים לפני בקשת חדשים, אשר גם שוברות את התנאי."}, "difficulty_estimation": "Medium", "_source_file": "0369__Deadlocks__MultipleChoice__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:07:47", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Deadlocks", "Deadlock Prevention", "Starvation"], "content": {"text": "איזו מהטענות הבאות נכונה ביותר לגבי אסטרטגיות מניעת קיפאון ותנאיו?", "code_snippet": null, "options": ["א. קיום של שלושה מתוך ארבעת תנאי קיפאון בהכרח יגרום לקיפאון.", "ב. הפרת תנאי 'החזקה והמתנה' (Hold and Wait) תמיד מונעת קיפאון, אך עלולה לגרום להרעבה.", "ג. הפרת תנאי 'מניעה הדדית' (Mutual Exclusion) אפשרית רק במשאבים הניתנים לשיתוף, ואינה רלוונטית למשאבים בלעדיים.", "ד. המתנה מעגלית (Circular Wait) יכולה להתרחש גם אם לא מתקיים תנאי 'אי-הפקעה' (No Preemption)."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. הפרת תנאי 'החזקה והמתנה' (Hold and Wait) מתבצעת על ידי כך שתהליך יבקש את כל המשאבים הדרושים לו מראש, או ישחרר את כל המשאבים שברשותו אם אינו מצליח לקבל משאב נוסף. אסטרטגיות אלו אכן מונעות קיפאון מכיוון שהן מבטיחות שתנאי 'החזקה והמתנה' לא יתקיים. עם זאת, הן עלולות לגרום להרעבה (starvation) אם תהליך מסוים דורש סט משאבים גדול או פופולרי במיוחד, ואינו מצליח אף פעם להשיג את כולם בבת אחת, או נאלץ לשחרר משאבים שוב ושוב.\n\nא. לא נכון. קיפאון דורש את קיומם של כל ארבעת התנאים (מניעה הדדית, החזקה והמתנה, אי-הפקעה, והמתנה מעגלית). קיום שלושה תנאים בלבד אינו מספיק כדי לגרום לקיפאון.\nג. לא נכון. מניעה הדדית היא תכונה אינהרנטית למשאבים בלעדיים (כמו מדפסת או מנעול). הפרת תנאי זה משמעותה להפוך משאב בלעדי למשותף, מה שלא תמיד אפשרי או רצוי. הטענה שאינה רלוונטית למשאבים בלעדיים אינה נכונה; היא רלוונטית במיוחד עבורם, וכדי למנוע קיפאון על ידי הפרת תנאי זה, נדרש לנסות להפוך אותם למשותפים.\nד. לא נכון. אם תנאי 'אי-הפקעה' (No Preemption) אינו מתקיים (כלומר, מותרת הפקעת משאבים), המערכת יכולה לכפות שחרור משאבים מתהליכים ולהשתמש בהם כדי לשבור מעגלי המתנה. לכן, קיפאון (שדורש את קיומו של תנאי אי-הפקעה) לא יכול להתרחש במצב כזה באופן מתמשך. המתנה מעגלית כשלעצמה יכולה להיווצר לרגע, אך אם מותרת הפקעה, היא לא תוכל להתמשך ולהפוך לקיפאון."}, "difficulty_estimation": "Medium", "_source_file": "0370__Deadlocks__MultipleChoice__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:08:06", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Deadlocks", "Deadlock Prevention", "Resource Management"], "content": {"text": "איזו מהאסטרטגיות הבאות מונעת מצב של קיפאון (deadlock) על ידי שבירת התנאי 'החזק והמתן' (Hold and Wait)?", "code_snippet": null, "options": ["א. לאפשר החרמה (preemption) של משאבים מתהליך המחזיק בהם.", "ב. לדרוש מתהליך לבקש ולקבל את כל המשאבים הנחוצים לו בתחילת ריצתו, לפני שיתחיל לבצע משימות כלשהן.", "ג. להגדיר סדר כולל (total ordering) לכל סוגי המשאבים ולדרוש מכל תהליך לבקש משאבים לפי סדר עולה.", "ד. לוודא כי משאבים מסוימים ניתנים לשימוש על ידי תהליך אחד בלבד בכל רגע נתון."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "תנאי 'החזק והמתן' (Hold and Wait) מתאר מצב שבו תהליך מחזיק במשאב אחד לפחות וממתין למשאבים נוספים המוחזקים על ידי תהליכים אחרים. אסטרטגיה ב' דורשת מתהליכים לבקש את כל המשאבים שלהם מראש. אם כל המשאבים זמינים, הם מוקצים לתהליך, והוא יכול להמשיך. אם לא, התהליך לא מקבל אף משאב וממתין עד שכולם יהיו זמינים. בדרך זו, תהליך לעולם לא יחזיק במשאבים כלשהם בזמן שהוא ממתין למשאבים אחרים, ובכך נשבר תנאי 'החזק והמתן'."}, "difficulty_estimation": "Medium", "_source_file": "0371__Deadlocks__MultipleChoice__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:08:18", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Deadlocks", "Synchronization", "Resource Management"], "content": {"text": "איזו מהטענות הבאות לגבי קיפאון (Deadlock) ושיטות הטיפול בו נכונה?", "code_snippet": null, "options": ["א. שיטות מניעת קיפאון (Deadlock Prevention) תמיד מבטיחות ניצול משאבים אופטימלי.", "ב. אלגוריתם הבנקאי (Banker's Algorithm) הוא דוגמה לשיטת גילוי קיפאון (Deadlock Detection).", "ג. הרעבה (Starvation) לעולם אינה יכולה להתרחש במערכת שבה קיפאון נמנע לחלוטין.", "ד. הפרת תנאי 'מניעה הדדית' (Mutual Exclusion) היא דרך אפשרית למנוע קיפאון, אך אינה ישימה לכל סוגי המשאבים."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "הסבר: \nא. לא נכון. שיטות מניעת קיפאון (לדוגמה, דרישת כל המשאבים מראש או אי-הפקעה) עלולות להוביל לניצול משאבים נמוך מכיוון שהן מחזיקות משאבים שלא בשימוש או מונעות הפקעה יעילה.\nב. לא נכון. אלגוריתם הבנקאי הוא שיטה למניעת קיפאון (Deadlock Avoidance), לא גילוי קיפאון (Deadlock Detection).\nג. לא נכון. הרעבה יכולה להתרחש גם במערכות שמונעות קיפאון (לדוגמה, תהליך בעל עדיפות נמוכה שנדחה באופן תמידי על ידי תהליכים בעלי עדיפות גבוהה יותר, ללא קשר לקיפאון).\nד. נכון. אם ניתן לאפשר למשאב שימוש משותף (לדוגמה, קריאה מקובץ), אין צורך ב'מניעה הדדית' עבורו, ובכך נמנע קיפאון הקשור למשאב זה. עם זאת, עבור משאבים שאינם ניתנים לשיתוף (כמו מדפסת), הפרת תנאי זה אינה אפשרית."}, "difficulty_estimation": "Medium", "_source_file": "0372__Deadlocks__MultipleChoice__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:08:40", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Deadlocks", "Synchronization"], "content": {"text": "נתבונן במערכת הכוללת מספר תהליכים (threads) ושני משאבים (R1 ו-R2), המוגנים על ידי מנעולים (mutex_R1 ו-mutex_R2 בהתאמה). כל תהליך זקוק לשני המשאבים כדי להשלים את פעולתו. איזה מהבאים מהווה שיטה יעילה למניעת קיפאון (deadlock) על ידי שבירת התנאי \"המתנה מעגלית\" (Circular Wait)?", "code_snippet": null, "options": ["א. כל תהליך מנסה לתפוס את mutex_R1, ואם הוא מצליח, הוא מנסה לתפוס את mutex_R2. אם הוא נכשל בתפיסת mutex_R2, הוא משחרר את mutex_R1 ומנסה שוב לאחר המתנה אקראית.", "ב. תהליכים מסוימים תופסים את mutex_R1 ואז את mutex_R2, בעוד שאחרים תופסים את mutex_R2 ואז את mutex_R1.", "ג. כל התהליכים במערכת תמיד תופסים את המנעולים בסדר קבוע ומוגדר מראש, למשל: תמיד mutex_R1 תחילה, ולאחר מכן mutex_R2.", "ד. המערכת אוכפת שכל תהליך יבקש את כל המשאבים שהוא צריך בבת אחת. אם לא ניתן להקצות את כולם, הוא לא מקבל אף אחד מהם."]}, "sub_questions": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התנאי 'המתנה מעגלית' מתקיים כאשר קיימת שרשרת של תהליכים, כאשר כל תהליך בשרשרת ממתין למשאב המוחזק על ידי התהליך הבא בשרשרת, והתהליך האחרון ממתין למשאב המוחזק על ידי התהליך הראשון. קביעת סדר גלובלי קבוע ומוגדר מראש ללקיחת משאבים (כמו תמיד R1 ואז R2) מונעת היווצרות של שרשרת כזו. אם כל התהליכים לוקחים את המשאבים באותו סדר, תהליך שלקח את R2 לא יכול לנסות לקחת את R1 (שכן זה מנוגד לסדר), ובכך נשבר התנאי של המתנה מעגלית. אפשרות א' מתייחסת יותר לשבירת 'החזק והמתן' או הימנעות מקיפאון, ואפשרות ד' שוברת את 'החזק והמתן'. אפשרות ב' היא למעשה תרחיש קלאסי שיוצר קיפאון."}, "difficulty_estimation": "Medium", "_source_file": "0373__Deadlocks__MultipleChoice__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:08:53", "_subject": "Concurrency"}, {"id": 10, "type": "MultipleChoice", "topic": ["Deadlocks", "Synchronization", "Concurrency"], "content": {"text": "איזו מהטענות הבאות נכונה לגבי תנאי קיפאון ומניעתם?", "code_snippet": null, "options": ["א. מניעת הדדיות (Mutual Exclusion) היא תמיד האסטרטגיה היעילה ביותר למניעת קיפאון.", "ב. אם מונעים מתהליכים להחזיק במשאב אחד תוך כדי המתנה למשאב אחר, קיפאון נמנע בהכרח.", "ג. יכולת הקצאת משאבים מחדש (Preemption) מבטיחה מניעת קיפאון לכל סוגי המשאבים.", "ד. אם גרף הקצאת המשאבים אינו מכיל מעגלים, קיפאון עדיין יכול להתרחש אם ישנם מספר מופעים מאותו סוג משאב."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "קיפאון (deadlock) מתרחש רק כאשר כל ארבעת התנאים ההכרחיים מתקיימים: מניעה הדדית (Mutual Exclusion), החזקה והמתנה (Hold and Wait), אי-פקיעה (No Preemption) והמתנה מעגלית (Circular Wait). מניעת אחד מהתנאים הללו מונעת קיפאון. אפשרות ב' מתארת מניעת החזקה והמתנה, ששוברת את אחד התנאים ההכרחיים ובכך מונעת קיפאון. אפשרות א' אינה נכונה מכיוון שלא תמיד ניתן או רצוי למנוע הדדיות (לדוגמה, במשאבים שאינם ניתנים לשיתוף). אפשרות ג' אינה נכונה מכיוון שלא כל המשאבים ניתנים לפקיעה (למשל, מדפסת באמצע הדפסה). אפשרות ד' אינה נכונה מכיוון שמעגל בגרף הקצאת המשאבים (Resource Allocation Graph) הוא תנאי הכרחי לקיפאון, וללא מעגל לא ייתכן קיפאון."}, "difficulty_estimation": "Medium", "_source_file": "0374__Deadlocks__MultipleChoice__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:09:04", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Deadlocks", "Deadlock Prevention", "Concurrency"], "content": {"text": "מערכת הפעלה מתמודדת עם האפשרות לקיפאון (deadlock) בין תהליכים. איזו אסטרטגיה נועדה למנוע באופן ישיר מצב של המתנה מעגלית (circular wait)?", "code_snippet": null, "options": ["א. ויתור על תנאי ההדרה ההדדית (mutual exclusion) על ידי הפיכת כל המשאבים לניתנים לשיתוף.", "ב. דרישה מכל תהליך לבקש את כל המשאבים הנדרשים לו בתחילת פעולתו, או לא לבקש כלל.", "ג. הגדרת סדר מוחלט (total ordering) לכל סוגי המשאבים, ודרישה מכל תהליך לבקש משאבים אך ורק בסדר עולה.", "ד. מתן אפשרות למערכת להפקיע משאבים מתהליך שמחזיק בהם וביקש משאבים נוספים שאינם זמינים."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "המתנה מעגלית (circular wait) מתרחשת כאשר קיימת שרשרת תהליכים, כאשר כל תהליך בשרשרת ממתין למשאב שמוחזק על ידי התהליך הבא בשרשרת. הגדרת סדר מוחלט לקבלת משאבים ודרישה מכל התהליכים לבקש משאבים רק בסדר עולה (למשל, ממשאב R1 למשאב R2, וכו') מונעת באופן ישיר היווצרות של מעגל המתנה. אם תהליך מחזיק במשאב R_i, הוא יכול לבקש רק משאבים R_j כאשר j > i. לכן, לא ניתן ליצור שרשרת שבה תהליך ממתין למשאב שמוחזק על ידי תהליך קודם בשרשרת, ובכך נמנעת המתנה מעגלית. אפשרות א' מונעת הדרה הדדית, ב' מונעת 'החזק והמתן' (hold and wait), ו-ד' מונעת 'אי-הפקעה' (no preemption). כל אלו הן אסטרטגיות למניעת קיפאון, אך ג' היא זו שמכוונת ישירות למניעת המתנה מעגלית."}, "difficulty_estimation": "Medium", "_source_file": "0375__Deadlocks__MultipleChoice__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:09:19", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Deadlocks", "Deadlock Avoidance", "Banker's Algorithm"], "content": {"text": "איזה מתנאי הקיפאון הבאים נמנע באופן ישיר על ידי שימוש באלגוריתם בנקאי (Banker's Algorithm)?", "code_snippet": null, "options": ["א. מניעה הדדית (Mutual Exclusion)", "ב. החזק והמתן (Hold and Wait)", "ג. אי-הפקעה (No Preemption)", "ד. המתנה מעגלית (Circular Wait)", "ה. אלגוריתם הבנקאי אינו מפר אף אחד מתנאי הקיפאון באופן ישיר, אלא מונע קיפאון על ידי הבטחת מצב בטוח."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ה", "explanation": "אלגוריתם הבנקאי הוא דוגמה לאסטרטגיית מניעת קיפאון (Deadlock Avoidance). אסטרטגיות מניעה (Avoidance) אינן מפרות אף אחד מארבעת תנאי הקיפאון (מניעה הדדית, החזק והמתן, אי-הפקעה, המתנה מעגלית) באופן ישיר. במקום זאת, הן דורשות מידע מוקדם על דרישות המשאבים של תהליכים ומקצות משאבים באופן דינמי רק אם המערכת נשארת במצב בטוח (safe state). מצב בטוח מבטיח שקיימת סדרה כלשהי של הקצאות משאבים המאפשרת לכל התהליכים לסיים את ביצועם מבלי להיכנס לקיפאון. לכן, האלגוריתם מונע קיפאון על ידי הבטחת מצב בטוח, ולא על ידי הפרת תנאי ספציפי."}, "difficulty_estimation": "Medium", "_source_file": "0376__Deadlocks__MultipleChoice__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:09:40", "_subject": "Concurrency"}, {"id": 10, "type": "MultipleChoice", "topic": ["Deadlocks", "Concurrency", "Synchronization"], "content": {"text": "נתון קטע הקוד הבא בשפת C++ המשתמש בשני מנעולים (mutexes) ובשני תהליכונים (threads). האם קיים סיכון למבוי סתום (deadlock) בקוד זה, ואם כן, מדוע?", "code_snippet": "#include <iostream>\n#include <thread>\n#include <mutex>\n#include <chrono>\n\nstd::mutex mutex_A;\nstd::mutex mutex_B;\n\nvoid thread_func1() {\n    std::cout << \"Thread 1: Trying to acquire mutex_A...\\n\";\n    mutex_A.lock();\n    std::cout << \"Thread 1: Acquired mutex_A. Trying to acquire mutex_B...\\n\";\n    std::this_thread::sleep_for(std::chrono::milliseconds(10)); // Simulate some work/delay\n    mutex_B.lock();\n    std::cout << \"Thread 1: Acquired mutex_B. Doing work...\\n\";\n    std::this_thread::sleep_for(std::chrono::milliseconds(50));\n    mutex_B.unlock();\n    std::cout << \"Thread 1: Released mutex_B.\\n\";\n    mutex_A.unlock();\n    std::cout << \"Thread 1: Released mutex_A.\\n\";\n}\n\nvoid thread_func2() {\n    std::cout << \"Thread 2: Trying to acquire mutex_B...\\n\";\n    mutex_B.lock();\n    std::cout << \"Thread 2: Acquired mutex_B. Trying to acquire mutex_A...\\n\";\n    std::this_thread::sleep_for(std::chrono::milliseconds(10)); // Simulate some work/delay\n    mutex_A.lock();\n    std::cout << \"Thread 2: Acquired mutex_A. Doing work...\\n\";\n    std::this_thread::sleep_for(std::chrono::milliseconds(50));\n    mutex_A.unlock();\n    std::cout << \"Thread 2: Released mutex_A.\\n\";\n    mutex_B.unlock();\n    std::cout << \"Thread 2: Released mutex_B.\\n\";\n}\n\n// Example usage (not part of the snippet for the question):\n// int main() {\n//     std::thread t1(thread_func1);\n//     std::thread t2(thread_func2);\n//     t1.join();\n//     t2.join();\n//     return 0;\n// }", "options": ["א. לא, מכיוון שכל תהליכון משחרר את המנעולים שהוא תפס בסופו של דבר.", "ב. כן, מכיוון ששני התהליכונים מנסים לתפוס את אותם מנעולים בסדר שונה, מה שעלול ליצור מצב של המתנה מעגלית.", "ג. לא, מכיוון שמערכת ההפעלה תזהה ותמנע מבוי סתום באופן אוטומטי.", "ד. כן, אך רק אם אחד התהליכונים יבצע פעולת I/O ארוכה בין תפיסת המנעול הראשון לשני.", "ה. לא, מכיוון ששימוש במנעולים (mutexes) תמיד מונע מבוי סתום."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. מבוי סתום (deadlock) יכול להתרחש בקוד זה. תהליכון 1 מנסה לתפוס את mutex_A ואז את mutex_B. תהליכון 2 מנסה לתפוס את mutex_B ואז את mutex_A. אם תהליכון 1 יתפוס את mutex_A ותהליכון 2 יתפוס את mutex_B בו-זמנית (או בסמיכות זמנים), אז תהליכון 1 ימתין ל-mutex_B שתפוס על ידי תהליכון 2, ותהליכון 2 ימתין ל-mutex_A שתפוס על ידי תהליכון 1. זהו מצב קלאסי של המתנה מעגלית (circular wait) הממלא את כל ארבעת התנאים למבוי סתום: הדרה הדדית (mutual exclusion), אחיזה והמתנה (hold and wait), אי-הפקעה (no preemption), והמתנה מעגלית. זמן ההמתנה הקצר (sleep_for) אינו הכרחי כדי ליצור את התנאים למבוי סתום, אלא רק מגדיל את הסיכוי שהוא יתרחש בפועל."}, "difficulty_estimation": "Hard", "_source_file": "0377__Deadlocks__MultipleChoice__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:09:55", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Deadlocks"], "content": {"text": "נתון קטע הקוד הבא בשפת C++ המכיל שלושה תהליכונים (threads) ושלושה מנעולים (mutexes). כל תהליכון מנסה לתפוס שני מנעולים בסדר מסוים.\n\n```cpp\n#include <iostream>\n#include <thread>\n#include <mutex>\n#include <vector>\n#include <chrono> // For std::this_thread::sleep_for\n\nstd::mutex m1, m2, m3;\n\nvoid thread_func_1() {\n    m1.lock();\n    std::this_thread::sleep_for(std::chrono::milliseconds(10)); // Simulate work\n    m2.lock();\n    // Do some work\n    m2.unlock();\n    m1.unlock();\n}\n\nvoid thread_func_2() {\n    m2.lock();\n    std::this_thread::sleep_for(std::chrono::milliseconds(10)); // Simulate work\n    m3.lock();\n    // Do some work\n    m3.unlock();\n    m2.unlock();\n}\n\nvoid thread_func_3() {\n    m3.lock();\n    std::this_thread::sleep_for(std::chrono::milliseconds(10)); // Simulate work\n    m1.lock();\n    // Do some work\n    m1.unlock();\n    m3.unlock();\n}\n```\n\nבהנחה שכל שלושת התהליכונים מופעלים במקביל, איזו מהטענות הבאות מתארת באופן המדויק ביותר את הסיבה למצב קיפאון פוטנציאלי בקוד הנתון?", "code_snippet": null, "options": ["א. לא ייתכן מצב קיפאון מכיוון שכל מנעול נתפס ומשוחרר בסופו של דבר.", "ב. מצב קיפאון ייתכן, והוא נובע בעיקר מהפרה של תנאי \"החזק והמתן\" (Hold and Wait).", "ג. מצב קיפאון ייתכן, והוא נובע בעיקר מהפרה של תנאי \"המתנה מעגלית\" (Circular Wait).", "ד. מצב קיפאון ייתכן, אך הוא אינו נובע מתנאי קיפאון קלאסיים אלא מתזמון לא נכון של קריאות ל-`sleep_for`.", "ה. מצב קיפאון ייתכן, וניתן למנוע אותו באופן יעיל על ידי הבטחת סדר תפיסה היררכי קבוע של המנעולים (לדוגמה, תמיד M1 ואז M2 ואז M3)."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הסבר: מצב קיפאון (deadlock) ייתכן בקוד הנתון. הוא נובע באופן מובהק מהפרה של תנאי \"המתנה מעגלית\" (Circular Wait). שלושת התהליכונים יוצרים שרשרת המתנה מעגלית: תהליכון 1 תופס את M1 וממתין ל-M2; תהליכון 2 תופס את M2 וממתין ל-M3; תהליכון 3 תופס את M3 וממתין ל-M1. אם כל אחד מהם יתפוס את המנעול הראשון שלו וינסה לתפוס את המנעול השני, כולם ימתינו זה לזה באופן אינסופי.\n\nא. לא נכון. עצם השחרור הסופי של המנעולים אינו מונע קיפאון אם סדר התפיסה מאפשר מעגל המתנה לפני השחרור.\nב. נכון שתנאי \"החזק והמתן\" מתקיים (כל תהליכון מחזיק במנעול אחד וממתין לאחר), אך \"המתנה מעגלית\" היא הסיבה הספציפית והישירה ביותר לקיפאון במקרה זה, ומתארת טוב יותר את דפוס הבעיה.\nד. לא נכון. קריאות ל-`sleep_for` רק מגדילות את הסיכוי שתיווצר הסיטואציה שתוביל לקיפאון, אך הן אינן הגורם היסודי לקיפאון. הגורם הוא סדר תפיסת המנעולים המאפשר המתנה מעגלית.\nה. נכון שזו דרך יעילה למנוע קיפאון על ידי שבירת תנאי ההמתנה המעגלית, אך השאלה מבקשת לתאר באופן המדויק ביותר את הסיבה לקיפאון בקוד הנתון, ולא להציע פתרון."}, "difficulty_estimation": "Hard", "_source_file": "0378__Deadlocks__MultipleChoice__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:10:24", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Deadlocks", "Synchronization", "Resource Allocation"], "content": {"text": "במערכת הפעלה קיימים N תהליכים. קיימים שני סוגי משאבים: ResourceA עם M_A מופעים, ו-ResourceB עם M_B מופעים. כל תהליך זקוק למופע אחד מ-ResourceA ולמופע אחד מ-ResourceB כדי לבצע את משימתו. כל התהליכים מקפידים על סדר קבוע של תפיסת משאבים: תחילה ResourceA, ולאחר מכן ResourceB. \n\nאיזו מהטענות הבאות נכונה בהכרח לגבי מצבי קיפאון (deadlocks) במערכת זו?", "code_snippet": null, "options": ["א. מצב קיפאון בלתי אפשרי, ללא קשר לערכי N, M_A ו-M_B (כל עוד הם חיוביים).", "ב. מצב קיפאון אפשרי אם N גדול יותר מ-M_A וגם מ-M_B.", "ג. מצב קיפאון אפשרי רק אם M_A=1 ו-M_B=1 ו-N>1.", "ד. מצב קיפאון אפשרי אם סכום המופעים הזמינים (M_A + M_B) קטן מ-N + 1.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "התשובה הנכונה היא א'. אחת מארבעת התנאים ההכרחיים למצב קיפאון הוא 'המתנה מעגלית' (Circular Wait). כאשר כל התהליכים מקפידים על סדר קבוע בתפיסת המשאבים (במקרה זה, תמיד ResourceA ואז ResourceB), נמנעת האפשרות ליצירת מעגל המתנה. תהליך שתופס את ResourceB לעולם לא ימתין ל-ResourceA, מכיוון שהוא כבר תפס אותו לפני ResourceB. לכן, לא ניתן ליצור שרשרת המתנה מעגלית שבה תהליך T1 ממתין למשאב שמוחזק על ידי T2, ותהליך T2 ממתין למשאב שמוחזק על ידי T1 (או שרשרת ארוכה יותר). מניעת תנאי 'המתנה מעגלית' מספיקה למניעת מצבי קיפאון, ללא קשר למספר התהליכים או למספר מופעי המשאבים הזמינים (כל עוד קיימים מופעים חיוביים). יש לשים לב כי שיטה זו מונעת קיפאון אך אינה מונעת בהכרח הרעבה (starvation)."}, "difficulty_estimation": "Hard", "_source_file": "0379__Deadlocks__MultipleChoice__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:11:00", "_subject": "Concurrency"}, {"id": 6, "type": "MultipleChoice", "topic": ["Deadlocks", "Concurrency", "C++ STL"], "content": {"text": "נתון קטע הקוד הבא ב-C++ המשתמש ב-`std::mutex`:\n\n```cpp\n#include <iostream>\n#include <thread>\n#include <mutex>\n#include <chrono>\n\nstd::mutex m1, m2;\n\nvoid process_data_A() {\n    m1.lock();\n    std::this_thread::sleep_for(std::chrono::milliseconds(50));\n    m2.lock();\n    std::cout << \"Process A acquired m1 and m2\\n\";\n    // ... critical section ...\n    m2.unlock();\n    m1.unlock();\n}\n\nvoid process_data_B() {\n    m2.lock();\n    std::this_thread::sleep_for(std::chrono::milliseconds(50));\n    m1.lock();\n    std::cout << \"Process B acquired m2 and m1\\n\";\n    // ... critical section ...\n    m1.unlock();\n    m2.unlock();\n}\n\nint main() {\n    std::thread t1(process_data_A);\n    std::thread t2(process_data_B);\n\n    t1.join();\n    t2.join();\n\n    std::cout << \"Main finished.\\n\";\n    return 0;\n}\n```\n\nאיזו מהטענות הבאות מתארת את הדרך *הנכונה והבטוחה ביותר* למנוע מצב קיפאון (deadlock) בקוד זה, תוך שימוש ביכולות ספריית ה-STL ב-C++?", "code_snippet": null, "options": ["א. יש לשנות את סדר נעילת המנעולים בפונקציה `process_data_B` כך שתמיד תנעל את `m1` ואז את `m2`, בדומה ל-`process_data_A`.", "ב. להשתמש ב-`std::lock_guard<std::mutex>` במקום קריאות `lock()` ו-`unlock()` ישירות, אך זה לא ימנע את הקיפאון.", "ג. במקום `lock()` ישיר, יש להשתמש ב-`m1.try_lock()` ו-`m2.try_lock()` ובמקרה של כישלון לשחרר את המנעולים שננעלו ולנסות שוב (backoff).", "ד. בכל אחת מהפונקציות (`process_data_A` ו-`process_data_B`), יש להחליף את הקריאות ל-`m1.lock(); m2.lock();` (או `m2.lock(); m1.lock();`) בקריאה אחת ל-`std::lock(m1, m2);` ולאחר מכן ליצור אובייקטי `std::unique_lock` עם `std::adopt_lock`.", "ה. אין דרך למנוע קיפאון בקוד זה ללא שינוי מהותי בארכיטקטורה של התוכנית."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "הקוד המקורי יכול לגרום למצב קיפאון (deadlock) בשל סדר נעילה שונה של המנעולים בשני התהליכים (`process_data_A` נועלת את `m1` ואז את `m2`, ואילו `process_data_B` נועלת את `m2` ואז את `m1`). אם כל תהליך מצליח לנעול את המנעול הראשון שלו לפני שהשני נועל את המנעול הראשון שלו, שניהם ימתינו זה לזה באופן אינסופי (מצב של 'החזק והמתן' ו'המתנה מעגלית').\n\nא. שינוי סדר הנעילה לשני התהליכים (למשל, תמיד `m1` ואז `m2`) אכן ימנע קיפאון, שכן הוא מבטל את תנאי ה'המתנה מעגלית'. זוהי דרך נכונה למנוע קיפאון, אך לא בהכרח ה'טובה ביותר' או ה'בטוחה ביותר' תוך שימוש ביכולות ספציפיות של ה-STL עבור מצב של נעילת מספר מנעולים במקביל, מכיוון שהיא דורשת הקפדה ידנית על הסדר בכל מקום בקוד.\nב. שימוש ב-`std::lock_guard` משפר את בטיחות הקוד מבחינת שחרור מנעולים אוטומטי (RAII) במקרה של יציאה מהבלוק או זריקת חריגה, אך הוא לא משנה את סדר הנעילה הפוטנציאלי לקיפאון אם הסדר נשאר שונה בין התהליכים.\nג. שימוש ב-`try_lock()` עם backoff הוא אכן אסטרטגיה למניעת קיפאון (על ידי ביטול תנאי ה'החזק והמתן' או 'אין כפייה'), אך היא דורשת מימוש ידני של לוגיקת הניסיון החוזר והיא מורכבת יותר מאשר הפתרון של `std::lock` עבור מצב זה של נעילת מספר מנעולים קבועים.\nד. הפונקציה `std::lock(m1, m2);` היא הפתרון המומלץ והבטוח ביותר בספריית ה-STL של C++ עבור נעילת מספר מנעולים במקביל. היא מבצעת את הנעילה של כל המנעולים באופן אטומי, כלומר, או שכל המנעולים ננעלים בהצלחה, או שאף אחד מהם לא ננעל (ובמקרה כזה היא מנסה שוב). בכך היא מונעת מצב שבו תהליך אחד מחזיק במנעול אחד וממתין למנעול אחר (hold and wait) בעוד תהליך אחר עושה את אותו הדבר בסדר הפוך. לאחר קריאה ל-`std::lock`, יש להשתמש ב-`std::unique_lock` עם `std::adopt_lock` כדי להעביר את הבעלות על המנעולים ל-RAII (Resource Acquisition Is Initialization) ולהבטיח שחרור נכון ואוטומטי של המנעולים בסיום הסקופ.\nה. טענה זו אינה נכונה; קיימות דרכים למנוע קיפאון בקוד זה, כפי שמודגם באפשרויות האחרות."}, "difficulty_estimation": "Hard", "_source_file": "0380__Deadlocks__MultipleChoice__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:11:28", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Deadlocks", "Synchronization", "Concurrency"], "content": {"text": "נתון קטע הקוד הבא המשתמש בשני מנעולים (mutexes), `mutexA` ו-`mutexB`, ובשני תהליכונים, `thread_func1` ו-`thread_func2`. ההנחה היא ששני המנעולים מאותחלים כראוי וששני התהליכונים רצים במקביל. איזה מהטענות הבאות נכונה לגבי קטע קוד זה?", "code_snippet": "#include <pthread.h>\n\n// Assume mutexA and mutexB are initialized globally.\npthread_mutex_t mutexA;\npthread_mutex_t mutexB;\n\nvoid* thread_func1(void* arg) {\n    pthread_mutex_lock(&mutexA);\n    // Critical section 1: uses mutexA\n    pthread_mutex_lock(&mutexB);\n    // Critical section 2: uses mutexA and mutexB\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    pthread_mutex_lock(&mutexB); // Different acquisition order\n    // Critical section 3: uses mutexB\n    pthread_mutex_lock(&mutexA); // Different acquisition order\n    // Critical section 4: uses mutexB and mutexA\n    pthread_mutex_unlock(&mutexA);\n    pthread_mutex_unlock(&mutexB);\n    return NULL;\n}\n// Assume main function creates and runs thread_func1 and thread_func2 concurrently.", "options": ["א. הקוד לעולם לא יגיע למצב של Deadlock, מכיוון שכל תהליכון משחרר את המנעולים בסדר הפוך לסדר שבו תפס אותם.", "ב. הקוד יגיע ל-Deadlock בוודאות בכל הרצה, מכיוון שסדר תפיסת המנעולים שונה בין התהליכונים.", "ג. הקוד עלול להגיע למצב של Deadlock עקב הפרה של תנאי \"אין מניעה מוקדמת\" (No Preemption), כיוון שהמנעולים אינם ניתנים להפקעה.", "ד. הקוד עלול להגיע למצב של Deadlock עקב הפרה של תנאי \"החזקה והמתנה\" (Hold and Wait) ו\"המתנה מעגלית\" (Circular Wait).", "ה. ניתן למנוע את ה-Deadlock בקלות על ידי החלפת כל קריאות `pthread_mutex_lock` ל-`pthread_mutex_trylock`."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "התשובה הנכונה היא ד'.\nהקוד מדגים מצב קלאסי של Deadlock שיכול להתרחש עקב הפרה של שני תנאים הכרחיים ל-Deadlock:\n1.  **החזקה והמתנה (Hold and Wait)**: כל אחד מהתהליכונים תופס מנעול אחד (thread_func1 תופס את mutexA, ו-thread_func2 תופס את mutexB) ולאחר מכן ממתין למנעול נוסף (thread_func1 ממתין ל-mutexB, ו-thread_func2 ממתין ל-mutexA) מבלי לשחרר את המנעול שכבר תפס.\n2.  **המתנה מעגלית (Circular Wait)**: נוצרת שרשרת המתנה מעגלית: thread_func1 ממתין למשאב (mutexB) המוחזק על ידי thread_func2, אשר ממתין בתורו למשאב (mutexA) המוחזק על ידי thread_func1.\nשני התנאים הנוספים ל-Deadlock, **מניעה הדדית (Mutual Exclusion)** ו**אין מניעה מוקדמת (No Preemption)**, מתקיימים באופן טאבוטי במנעולים (mutexes).\n\nא. שגויה. Deadlock אכן יכול להתרחש, כפי שהוסבר לעיל.\nב. שגויה. Deadlock אינו מובטח בכל הרצה; הוא תלוי בתזמון המדויק של פעולות התהליכונים, אך הוא אפשרי מאוד.\nג. שגויה. למרות שתנאי \"אין מניעה מוקדמת\" מתקיים במנעולים (לא ניתן להפקיע מנעול מתהליכון שתפס אותו), הוא אינו הגורם הישיר ל-Deadlock במקרה זה. הבעיה העיקרית נובעת מסדר תפיסת המשאבים השונה בין התהליכונים שמוביל להמתנה מעגלית.\nה. שגויה. שימוש ב-`pthread_mutex_trylock` מאפשר לתהליכון לנסות לתפוס מנעול מבלי להיחסם אם הוא תפוס. זהו כלי שימושי לאיתור וטיפול ב-Deadlock (למשל, על ידי שחרור מנעולים שכבר נתפסו וניסיון חוזר), אך הוא אינו מונע את תנאי ה-Deadlock מלהתקיים מלכתחילה. כדי למנוע Deadlock, נדרשת אסטרטגיה כמו תפיסת מנעולים בסדר קבוע ומוסכם על ידי כל התהליכונים."}, "difficulty_estimation": "Hard", "_source_file": "0381__Deadlocks__MultipleChoice__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:11:51", "_subject": "Concurrency"}, {"id": 6, "type": "MultipleChoice", "topic": ["Deadlocks", "Concurrency", "Synchronization"], "content": {"text": "נתון קטע הקוד הבא המשתמש בשני מנעולים (mutexes) ושני תהליכונים (threads) ב-C++:\n\n```cpp\n#include <iostream>\n#include <thread>\n#include <mutex>\n#include <chrono>\n\nstd::mutex mutexA;\nstd::mutex mutexB;\n\nvoid thread1_func() {\n    std::cout << \"Thread 1: Trying to lock mutexA...\" << std::endl;\n    mutexA.lock();\n    std::cout << \"Thread 1: Locked mutexA. Trying to lock mutexB...\" << std::endl;\n    std::this_thread::sleep_for(std::chrono::milliseconds(100)); // Simulate work\n    mutexB.lock();\n    std::cout << \"Thread 1: Locked mutexB.\" << std::endl;\n    // ... critical section ...\n    mutexB.unlock();\n    mutexA.unlock();\n    std::cout << \"Thread 1: Unlocked mutexA and mutexB.\" << std::endl;\n}\n\nvoid thread2_func() {\n    std::cout << \"Thread 2: Trying to lock mutexB...\" << std::endl;\n    mutexB.lock();\n    std::cout << \"Thread 2: Locked mutexB. Trying to lock mutexA...\" << std::endl;\n    std::this_thread::sleep_for(std::chrono::milliseconds(100)); // Simulate work\n    mutexA.lock();\n    std::cout << \"Thread 2: Locked mutexA.\" << std::endl;\n    // ... critical section ...\n    mutexA.unlock();\n    mutexB.unlock();\n    std::cout << \"Thread 2: Unlocked mutexA and mutexB.\" << std::endl;\n}\n\nint main() {\n    std::thread t1(thread1_func);\n    std::thread t2(thread2_func);\n\n    t1.join();\n    t2.join();\n\n    std::cout << \"Main: All threads finished.\" << std::endl;\n    return 0;\n}\n```\n\nבהתייחס לקטע הקוד לעיל, איזו מהטענות הבאות נכונה ביותר לגבי האפשרות למבוי סתום (deadlock)?", "code_snippet": null, "options": ["א. מבוי סתום אינו אפשרי בקוד זה מכיוון שכל תהליכון מנסה לנעול את המנעולים בזמן אחר.", "ב. מבוי סתום אפשרי, והדרך היחידה למנוע אותו היא להשתמש במנגנון `std::lock` עבור שני המנעולים יחד.", "ג. מבוי סתום אפשרי, והוא נגרם עקב העובדה שכל תהליכון מנסה לנעול את המשאבים בסדר שונה, מה שמהווה הפרה של התנאי \"המתנה מעגלית\" (Circular Wait).", "ד. מבוי סתום אינו אפשרי בקוד זה מכיוון שאין תלות בין המנעולים.", "ה. מבוי סתום אפשרי, אך ניתן למנוע אותו רק על ידי שימוש ב- `try_lock` ובדיקה חוזרת בלולאה עד להשגת שני המנעולים."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הקוד הנתון מדגים תרחיש קלאסי של מבוי סתום (deadlock) העומד בכל ארבעת התנאים ההכרחיים למבוי סתום:\n1.  **Mutual Exclusion (מניעה הדדית)**: המנעולים (`std::mutex`) מספקים מניעה הדדית; רק תהליכון אחד יכול להחזיק במנעול בכל רגע נתון.\n2.  **Hold and Wait (החזק והמתן)**: כל תהליכון תופס מנעול אחד (תהליכון 1 תופס את `mutexA`, תהליכון 2 תופס את `mutexB`) וממתין לתפוס את המנעול השני.\n3.  **No Preemption (אין דריסה)**: המנעולים אינם נלקחים בכוח מהתהליכונים; הם משוחררים רק מרצון על ידי התהליכון שמחזיק בהם.\n4.  **Circular Wait (המתנה מעגלית)**: זהו התנאי המרכזי שמופר כאן. תהליכון 1 מחזיק ב-`mutexA` וממתין ל-`mutexB` (שייתכן ומוחזק על ידי תהליכון 2). תהליכון 2 מחזיק ב-`mutexB` וממתין ל-`mutexA` (שייתכן ומוחזק על ידי תהליכון 1). נוצרת שרשרת המתנה מעגלית: תהליכון 1 ממתין למשאב שתהליכון 2 מחזיק, ותהליכון 2 ממתין למשאב שתהליכון 1 מחזיק. הסיבה העיקרית למצב זה היא הסדר השונה שבו התהליכונים מנסים לנעול את המשאבים.\n\nלכן, טענה ג' נכונה: מבוי סתום אפשרי, והוא נגרם עקב העובדה שכל תהליכון מנסה לנעול את המשאבים בסדר שונה, מה שמהווה הפרה של התנאי \"המתנה מעגלית\"."}, "difficulty_estimation": "Hard", "_source_file": "0382__Deadlocks__MultipleChoice__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:12:13", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Deadlocks", "Synchronization", "Concurrency"], "content": {"text": "נתונה מערכת עם N תהליכים (threads) ו-M מנעולים מסוג `pthread_mutex_t` המאוחסנים במערך `m[M]`. כל תהליך `i` (כאשר `i` נע מ-`0` עד `N-1`) מנסה לרכוש את המנעולים `m[0]` ו-`m[1]`. סדר רכישת המנעולים נקבע כדלקמן:\n\n- אם `i` זוגי, התהליך רוכש קודם את `m[0]` ולאחר מכן את `m[1]`.\n- אם `i` אי-זוגי, התהליך רוכש קודם את `m[1]` ולאחר מכן את `m[0]`.\n\nאיזו מהטענות הבאות נכונה לגבי התרחשות מצב קיפאון (Deadlock) במערכת זו? (הניחו כי M >= 2).", "code_snippet": "pthread_mutex_t m[M]; // M mutexes, M >= 2 assumed\n\nvoid* thread_func(void* arg) {\n    long thread_id = (long)arg;\n\n    if (thread_id % 2 == 0) { // Even threads\n        pthread_mutex_lock(&m[0]);\n        // Simulate some work or context switch\n        // usleep(1);\n        pthread_mutex_lock(&m[1]);\n    } else { // Odd threads\n        pthread_mutex_lock(&m[1]);\n        // Simulate some work or context switch\n        // usleep(1);\n        pthread_mutex_lock(&m[0]);\n    }\n\n    // Critical Section\n    // printf(\"Thread %ld acquired m[0] and m[1]\\n\", thread_id);\n\n    pthread_mutex_unlock(&m[1]); // Unlock in reverse order of acquisition\n    pthread_mutex_unlock(&m[0]);\n    return NULL;\n}", "options": ["א. מצב קיפאון יכול להתרחש רק אם N > M.", "ב. מצב קיפאון יכול להתרחש רק אם M > N.", "ג. מצב קיפאון יכול להתרחש אם N >= 2.", "ד. מצב קיפאון אינו יכול להתרחש כלל בשל אסטרטגיית הרכישה המתחלפת.", "ה. מצב קיפאון יכול להתרחש רק אם N אי-זוגי."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התשובה הנכונה היא ג'. מצב קיפאון (Deadlock) יכול להתרחש אם N >= 2. ננתח מדוע:\n\nהתנאים ההכרחיים למצב קיפאון הם: הדדיות (Mutual Exclusion), החזקה והמתנה (Hold and Wait), אי-הפקעה (No Preemption), והמתנה מעגלית (Circular Wait).\n\n1.  **הדדיות, החזקה והמתנה, אי-הפקעה:** מנעולי `pthread_mutex_t` מספקים את שלושת התנאים הללו באופן טבעי. תהליכים מחזיקים במנעול אחד וממתינים לאחר, ולא ניתן להפקיע מנעול מתהליך שמחזיק בו.\n2.  **המתנה מעגלית:** זהו התנאי הקריטי כאן. נבחן את תהליך 0 ואת תהליך 1:\n    *   **תהליך 0 (thread_id = 0, זוגי):** מנסה לרכוש את `m[0]` ולאחר מכן את `m[1]`.\n    *   **תהליך 1 (thread_id = 1, אי-זוגי):** מנסה לרכוש את `m[1]` ולאחר מכן את `m[0]`.\n\n    אם קיימים לפחות שני תהליכים (כלומר N >= 2), אז יהיה קיים לפחות תהליך אחד זוגי (לדוגמה, תהליך 0) ולפחות תהליך אחד אי-זוגי (לדוגמה, תהליך 1). נניח שתהליך 0 רוכש את `m[0]` ותהליך 1 רוכש את `m[1]`. כעת, תהליך 0 ממתין ל-`m[1]` (שמוחזק על ידי תהליך 1), ותהליך 1 ממתין ל-`m[0]` (שמוחזק על ידי תהליך 0). זהו מצב של המתנה מעגלית קלאסית (AB-BA deadlock).\n\n    ההנחה ש-M >= 2 מבטיחה ש-`m[0]` ו-`m[1]` הם מנעולים שונים וקיימים.\n\n    לכן, ברגע שישנם לפחות שני תהליכים (N >= 2), תמיד יכול להיווצר תרחיש שבו תהליך זוגי ותהליך אי-זוגי יכנסו למצב המתנה מעגלית. התשובות האחרות שגויות מכיוון שהן מציעות תנאים שאינם הכרחיים או שגויים לגבי התרחשות הקיפאון."}, "difficulty_estimation": "Hard", "_source_file": "0383__Deadlocks__MultipleChoice__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:12:56", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Deadlocks", "Synchronization", "Concurrency"], "content": {"text": "נתון קטע הקוד הבא בשפת C המציג שני תהליכונים המנסים לרכוש שני משאבים (mutexes) באמצעות אסטרטגיית 'שחרור וניסיון חוזר' (release and retry) כאשר רכישת המשאב השני נכשלת. איזה מבין המשפטים הבאים נכון לגבי קטע קוד זה?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex_resA = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_t mutex_resB = PTHREAD_MUTEX_INITIALIZER;\n\n// Function to simulate a process acquiring resources\nvoid* acquire_resources(void* arg) {\n    long thread_id = (long)arg;\n    int first_res_id = (thread_id == 0) ? 0 : 1; // Thread 0 tries A then B, Thread 1 tries B then A\n    int second_res_id = (thread_id == 0) ? 1 : 0;\n\n    pthread_mutex_t* first_mutex = (first_res_id == 0) ? &mutex_resA : &mutex_resB;\n    pthread_mutex_t* second_mutex = (second_res_id == 0) ? &mutex_resA : &mutex_resB;\n\n    printf(\"Thread %ld trying to acquire mutex %d\\n\", thread_id, first_res_id);\n    pthread_mutex_lock(first_mutex);\n    printf(\"Thread %ld acquired mutex %d\\n\", thread_id, first_res_id);\n\n    sleep(1); // Simulate some work/hold time\n\n    printf(\"Thread %ld trying to acquire mutex %d\\n\", thread_id, second_res_id);\n    while (pthread_mutex_trylock(second_mutex) != 0) {\n        printf(\"Thread %ld failed to acquire mutex %d, releasing mutex %d and retrying...\\n\", thread_id, second_res_id, first_res_id);\n        pthread_mutex_unlock(first_mutex);\n        sleep(1); // Wait a bit before retrying\n        pthread_mutex_lock(first_mutex);\n        printf(\"Thread %ld re-acquired mutex %d\\n\", thread_id, first_res_id);\n    }\n    printf(\"Thread %ld acquired mutex %d\\n\", thread_id, second_res_id);\n\n    // Critical section\n    printf(\"Thread %ld in critical section with both mutexes\\n\", thread_id);\n    sleep(1);\n\n    pthread_mutex_unlock(second_mutex);\n    pthread_mutex_unlock(first_mutex);\n    printf(\"Thread %ld released both mutexes and finished\\n\", thread_id);\n    return NULL;\n}\n\nint main() {\n    pthread_t t0, t1;\n    pthread_create(&t0, NULL, acquire_resources, (void*)0);\n    pthread_create(&t1, NULL, acquire_resources, (void*)1);\n\n    pthread_join(t0, NULL);\n    pthread_join(t1, NULL);\n\n    printf(\"Main: All threads completed.\\n\");\n    return 0;\n}", "options": ["א. הקוד יכנס למצב קיפאון (deadlock) בוודאות, מכיוון שתנאי \"המתנה מעגלית\" (Circular Wait) מתקיים.", "ב. הקוד לעולם לא יכנס למצב קיפאון, מכיוון שהוא מונע את תנאי \"החזק והמתן\" (Hold and Wait).", "ג. הקוד לעולם לא יכנס למצב קיפאון, מכיוון שהוא מונע את תנאי \"אי-נטילה מוקדמת\" (No Preemption).", "ד. הקוד עלול להיכנס למצב קיפאון, אך רק תחת עומס גבוה מאוד של תהליכונים נוספים.", "ה. הקוד לעולם לא יכנס למצב קיפאון, אך עלול לסבול מרעב (starvation) של אחד התהליכונים לאורך זמן."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הקוד מיישם אסטרטגיה שבה אם תהליכון אינו מצליח לרכוש את המשאב השני הנדרש לו באמצעות `pthread_mutex_trylock`, הוא *משחרר* את המשאב הראשון שהוא מחזיק ומנסה שוב את תהליך הרכישה. פעולה זו מונעת במפורש את תנאי \"החזק והמתן\" (Hold and Wait) הנדרש להיווצרות קיפאון. תנאי זה קובע שתהליך מחזיק במשאב אחד לפחות וממתין לרכישת משאבים נוספים המוחזקים על ידי תהליכים אחרים. על ידי שחרור המשאב הראשון, התהליכון אינו \"מחזיק וממתין\" במובן הבעייתי, ובכך נמנעת היווצרות תלות מעגלית שתוביל לקיפאון. בעוד שאסטרטגיה זו עשויה באופן תיאורטי להוביל לרעב (starvation) - מצב בו תהליכון מסוים נכשל שוב ושוב ברכישת שני המשאבים וממשיך לנסות ללא הצלחה - היא מונעת ביעילות מצב קיפאון (deadlock)."}, "difficulty_estimation": "Hard", "_source_file": "0384__Deadlocks__MultipleChoice__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:13:27", "_subject": "Concurrency"}, {"id": 9, "type": "Open", "topic": ["Deadlocks"], "content": {"text": "נתונות שתי תוכניות (תהליכים/תהליכונים) P1 ו-P2, ושני משאבים R1 ו-R2. כל תוכנית זקוקה לשני המשאבים כדי להשלים את פעולתה.\n\nP1 מבקש תחילה את R1, ואז את R2.\nP2 מבקש תחילה את R2, ואז את R1.\n\nהאם מצב זה עלול להוביל לקיפאון (Deadlock)? אם כן, הסבירו מדוע, תוך התייחסות לארבעת התנאים ההכרחיים לקיומו של קיפאון.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, מצב זה עלול להוביל לקיפאון (Deadlock).\n\nהסבר תוך התייחסות לארבעת התנאים ההכרחיים לקיפאון:\n\n1.  **מניעה הדדית (Mutual Exclusion):** מתקיים. המשאבים R1 ו-R2 הם משאבים שאינם ניתנים לשיתוף (לדוגמה, מנעולים או התקנים בלעדיים), ולכן רק תוכנית אחת יכולה להחזיק כל משאב בכל רגע נתון. אם תוכנית אחת תופסת את R1, תוכנית אחרת לא יכולה לתפוס אותו בו זמנית.\n\n2.  **החזק והמתן (Hold and Wait):** מתקיים. נניח ש-P1 תופס את R1 ו-P2 תופס את R2. כעת, P1 מחזיק ב-R1 וממתין ל-R2 (שמוחזק על ידי P2), ו-P2 מחזיק ב-R2 וממתין ל-R1 (שמוחזק על ידי P1). כל תוכנית מחזיקה משאב אחד לפחות וממתינה למשאב נוסף המוחזק על ידי תוכנית אחרת.\n\n3.  **אי-הפקעה (No Preemption):** מתקיים. מניחים שהמשאבים R1 ו-R2 אינם ניתנים להפקעה. כלומר, ברגע שתוכנית תפסה משאב, היא תשחרר אותו רק מרצונה החופשי לאחר שסיימה את השימוש בו. המערכת לא יכולה לקחת את המשאב מתוכנית בכוח.\n\n4.  **המתנה מעגלית (Circular Wait):** מתקיים. במצב שבו P1 מחזיק ב-R1 וממתין ל-R2, ו-P2 מחזיק ב-R2 וממתין ל-R1, נוצרת שרשרת המתנה מעגלית: P1 ממתין למשאב שמוחזק על ידי P2, ו-P2 ממתין למשאב שמוחזק על ידי P1. כלומר, P1 -> P2 -> P1.\n\nמכיוון שכל ארבעת התנאים יכולים להתקיים בו זמנית בתרחיש זה, קיפאון הוא אפשרי."}, "difficulty_estimation": "Easy", "_source_file": "0385__Deadlocks__Open__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:13:37", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Deadlocks"], "content": {"text": "הגדר מהו קיפאון (deadlock) במערכת הפעלה, ופרט את ארבעת התנאים ההכרחיים לקיומו.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "קיפאון (deadlock) הוא מצב במערכת הפעלה שבו שני תהליכים או יותר חסומים באופן אינסופי, כאשר כל אחד מהם ממתין למשאב שמוחזק על ידי תהליך אחר בקבוצה.\n\nארבעת התנאים ההכרחיים לקיומו של קיפאון הם:\n1.  **מניעה הדדית (Mutual Exclusion)**: לפחות משאב אחד חייב להיות בלתי ניתן לשיתוף, כלומר, רק תהליך אחד יכול להשתמש בו בכל פעם.\n2.  **החזק והמתן (Hold and Wait)**: תהליך חייב להחזיק לפחות משאב אחד, תוך כדי שהוא ממתין למשאבים נוספים שמוחזקים על ידי תהליכים אחרים.\n3.  **אי-נשללות (No Preemption)**: משאבים אינם יכולים להילקח מתהליך בכוח; הם חייבים להשתחרר מרצון על ידי התהליך שמחזיק אותם, רק לאחר שהשלים את השימוש בהם.\n4.  **המתנה מעגלית (Circular Wait)**: חייבת להתקיים שרשרת מעגלית של תהליכים, כאשר כל תהליך בשרשרת ממתין למשאב שמוחזק על ידי התהליך הבא בשרשרת."}, "difficulty_estimation": "Easy", "_source_file": "0386__Deadlocks__Open__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:13:47", "_subject": "Concurrency"}, {"id": 9, "type": "Open", "topic": ["Deadlocks"], "content": {"text": "מהם ארבעת התנאים ההכרחיים לקיום קיפאון (deadlock) במערכת הפעלה? הסבר בקצרה כל אחד מהם.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ארבעת התנאים ההכרחיים לקיום קיפאון הם:\n1.  **מניעה הדדית (Mutual Exclusion):** לפחות משאב אחד במערכת חייב להיות משאב לא שיתופי (non-sharable), כלומר, ניתן לשימוש על ידי תהליך אחד בלבד בכל רגע נתון. אם משאב ניתן לשיתוף, תהליכים יכולים להשתמש בו במקביל ולא ייווצר קיפאון עליו.\n2.  **החזק והמתן (Hold and Wait):** תהליך אחד מחזיק במשאב אחד לפחות וממתין לרכישת משאבים נוספים המוחזקים על ידי תהליכים אחרים.\n3.  **אי-הפקעה (No Preemption):** לא ניתן להפקיע משאב מתהליך המחזיק בו; המשאב חייב להשתחרר באופן וולונטרי על ידי התהליך לאחר שסיים את השימוש בו.\n4.  **המתנה מעגלית (Circular Wait):** קיימת שרשרת מעגלית של תהליכים, כאשר כל תהליך בשרשרת ממתין למשאב המוחזק על ידי התהליך הבא בשרשרת, והתהליך האחרון ממתין למשאב המוחזק על ידי התהליך הראשון."}, "difficulty_estimation": "Easy", "_source_file": "0387__Deadlocks__Open__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:13:55", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Deadlocks"], "content": {"text": "הגדר מהו קיפאון (deadlock) בהקשר של מערכות הפעלה. בנוסף, ציין והסבר בקצרה את ארבעת התנאים ההכרחיים לקיומו של קיפאון.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסבר:\nקיפאון (Deadlock) הוא מצב במערכת הפעלה שבו שני תהליכים (או יותר) חסומים באופן קבוע, כאשר כל אחד מהם ממתין למשאב המוחזק על ידי תהליך אחר שנמצא גם הוא במצב חסימה.\n\nארבעת התנאים ההכרחיים לקיום קיפאון הם:\n1.  **מניעה הדדית (Mutual Exclusion):** לפחות משאב אחד חייב להיות בלתי ניתן לשיתוף, כלומר, רק תהליך אחד יכול להשתמש בו בכל רגע נתון. אם משאב ניתן לשיתוף (כמו קובץ לקריאה בלבד), מניעה הדדית אינה נדרשת וקיפאון אינו יכול להתרחש עבור משאבים כאלה.\n2.  **החזק והמתן (Hold and Wait):** תהליך חייב להחזיק לפחות משאב אחד ובמקביל להמתין למשאבים נוספים המוחזקים על ידי תהליכים אחרים.\n3.  **אי-הפקעה (No Preemption):** משאב לא יכול להילקח בכוח מתהליך שמחזיק בו. הוא חייב להשתחרר באופן וולונטרי על ידי התהליך לאחר שסיים את השימוש בו.\n4.  **המתנה מעגלית (Circular Wait):** קיימת שרשרת מעגלית של תהליכים {P0, P1, ..., Pn} כך ש-P0 ממתין למשאב המוחזק על ידי P1, P1 ממתין למשאב המוחזק על ידי P2, וכן הלאה, עד ש-Pn ממתין למשאב המוחזק על ידי P0."}, "difficulty_estimation": "Easy", "_source_file": "0388__Deadlocks__Open__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:14:03", "_subject": "Concurrency"}, {"id": 9, "type": "Open", "topic": ["Deadlocks", "Operating Systems Concepts"], "content": {"text": "הגדר מהו קיפאון (Deadlock) במערכת הפעלה, וציין את ארבעת התנאים ההכרחיים לקיומו.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסבר: קיפאון (Deadlock) הוא מצב במערכת הפעלה שבו שני תהליכים או יותר חסומים באופן בלתי מוגבל, כאשר כל אחד מהם ממתין למשאב שמוחזק על ידי תהליך אחר שנמצא גם הוא במצב חסימה. כלומר, אף תהליך לא יכול להמשיך בביצועו.\n\nארבעת התנאים ההכרחיים לקיום קיפאון הם:\n1.  **מניעה הדדית (Mutual Exclusion):** לפחות משאב אחד חייב להיות מוחזק במצב לא שיתופי (non-sharable mode), כלומר, רק תהליך אחד יכול להשתמש במשאב זה בזמן נתון.\n2.  **החזק והמתן (Hold and Wait):** תהליך שמחזיק לפחות משאב אחד ממתין לרכישת משאבים נוספים המוחזקים על ידי תהליכים אחרים.\n3.  **אי-הפקעה (No Preemption):** לא ניתן להפקיע משאבים מתהליך שמחזיק בהם; משאב יכול להשתחרר רק באופן וולונטרי על ידי התהליך המחזיק בו, לאחר שהתהליך סיים את משימתו.\n4.  **המתנה מעגלית (Circular Wait):** קיימת קבוצת תהליכים {P0, P1, ..., Pn} כך ש-P0 ממתין למשאב המוחזק על ידי P1, P1 ממתין למשאב המוחזק על ידי P2, ..., Pn-1 ממתין למשאב המוחזק על ידי Pn, ו-Pn ממתין למשאב המוחזק על ידי P0."}, "difficulty_estimation": "Easy", "_source_file": "0389__Deadlocks__Open__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:14:12", "_subject": "Concurrency"}, {"id": 9, "type": "Open", "topic": ["Deadlocks"], "content": {"text": "הסבר בקצרה מהו קיפאון (deadlock) במערכת הפעלה, וציין את ארבעת התנאים ההכרחיים לקיומו.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "קיפאון (deadlock) הוא מצב במערכת הפעלה שבו שני תהליכים או יותר חסומים באופן קבוע וממתינים זה לזה לשחרור משאבים, כאשר כל אחד מהם מחזיק במשאב שהאחר זקוק לו ואינו יכול להמשיך.\n\nארבעת התנאים ההכרחיים לקיומו של קיפאון הם:\n1.  **מניעה הדדית (Mutual Exclusion):** משאב יכול להיות מוחזק על ידי תהליך אחד בלבד בכל רגע נתון. אם תהליך אחר מבקש את המשאב, עליו להמתין עד שהמשאב ישוחרר.\n2.  **החזקה והמתנה (Hold and Wait):** תהליך מחזיק במשאב אחד לפחות וממתין למשאבים נוספים המוחזקים על ידי תהליכים אחרים.\n3.  **אי-הפקעה (No Preemption):** משאבים אינם ניתנים להפקעה. הם יכולים להשתחרר רק באופן וולונטרי על ידי התהליך שמחזיק אותם, לאחר שסיים את השימוש בהם.\n4.  **המתנה מעגלית (Circular Wait):** קיימת שרשרת מעגלית של תהליכים, כאשר כל תהליך בשרשרת ממתין למשאב המוחזק על ידי התהליך הבא בשרשרת."}, "difficulty_estimation": "Easy", "_source_file": "0390__Deadlocks__Open__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:14:21", "_subject": "Concurrency"}, {"id": 9, "type": "Open", "topic": ["Deadlocks"], "content": {"text": "מהו קיפאון (Deadlock) במערכות הפעלה? פרטו את ארבעת התנאים ההכרחיים לקיומו.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "קיפאון (Deadlock) הוא מצב במערכת הפעלה שבו שני תהליכים או יותר חסומים באופן קבוע, כאשר כל אחד מהם ממתין למשאב שמוחזק על ידי תהליך אחר בקבוצה.\n\nארבעת התנאים ההכרחיים לקיום קיפאון הם:\n1.  **מניעה הדדית (Mutual Exclusion):** לפחות משאב אחד חייב להיות בלתי ניתן לשיתוף. כלומר, רק תהליך אחד יכול להשתמש במשאב בכל רגע נתון.\n2.  **החזקה והמתנה (Hold and Wait):** תהליך חייב להחזיק לפחות משאב אחד ובמקביל להמתין למשאבים נוספים שמוחזקים על ידי תהליכים אחרים.\n3.  **אי-נשללות (No Preemption):** משאבים אינם ניתנים לשלילה בכוח. משאב יכול להשתחרר רק באופן יזום על ידי התהליך שמחזיק אותו, לאחר שסיים את השימוש בו.\n4.  **המתנה מעגלית (Circular Wait):** קיימת שרשרת מעגלית של שני תהליכים או יותר, כאשר כל תהליך בשרשרת ממתין למשאב שמוחזק על ידי התהליך הבא בשרשרת."}, "difficulty_estimation": "Easy", "_source_file": "0391__Deadlocks__Open__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:14:29", "_subject": "Concurrency"}, {"id": 9, "type": "Open", "topic": ["Deadlocks"], "content": {"text": "מהו קיפאון (deadlock) בהקשר של מערכות הפעלה, ומהם ארבעת התנאים ההכרחיים לקיומו?", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "קיפאון הוא מצב שבו שני תהליכים או יותר חוסמים זה את זה באופן הדדי, כאשר כל אחד מהם ממתין למשאב שמוחזק על ידי תהליך אחר בקבוצה, ולאף אחד מהם אין את היכולת להמשיך בביצוע. כתוצאה מכך, אף אחד מהתהליכים לא יכול להשלים את משימתו ולשחרר את המשאבים שברשותו.\n\nארבעת התנאים ההכרחיים לקיום קיפאון הם:\n1.  **מניעה הדדית (Mutual Exclusion)**: לפחות משאב אחד חייב להיות בלתי ניתן לשיתוף. כלומר, רק תהליך אחד יכול להשתמש במשאב בכל רגע נתון.\n2.  **החזקה והמתנה (Hold and Wait)**: תהליך חייב להחזיק לפחות במשאב אחד ולהמתין למשאב נוסף שמוחזק על ידי תהליך אחר.\n3.  **אי-נשללות (No Preemption)**: לא ניתן לשלול משאבים מתהליך בכוח. משאב יכול להשתחרר רק באופן יזום על ידי התהליך שמחזיק בו, לאחר שסיים את השימוש בו.\n4.  **המתנה מעגלית (Circular Wait)**: חייבת להתקיים שרשרת מעגלית של תהליכים, כאשר כל תהליך ממתין למשאב שמוחזק על ידי התהליך הבא בשרשרת."}, "difficulty_estimation": "Easy", "_source_file": "0392__Deadlocks__Open__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:14:38", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Deadlocks", "Synchronization", "Concurrency"], "content": {"text": "נתונים שני תהליכונים (threads), P1 ו-P2, המנסים לגשת לשני משאבים משותפים, R1 ו-R2. כל משאב מוגן על ידי מנעול (mutex) נפרד, M1 ו-M2 בהתאמה.\n\nהקוד הבא מציג את אופן הגישה למשאבים על ידי שני התהליכונים:\n\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t M1;\npthread_mutex_t M2;\n\nvoid* thread_func_P1(void* arg) {\n    printf(\"P1: Trying to acquire M1...\\n\");\n    pthread_mutex_lock(&M1);\n    printf(\"P1: Acquired M1. Trying to acquire M2...\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&M2);\n    printf(\"P1: Acquired M2. Critical section...\\n\");\n    // Critical section\n    pthread_mutex_unlock(&M2);\n    printf(\"P1: Released M2.\\n\");\n    pthread_mutex_unlock(&M1);\n    printf(\"P1: Released M1. Exiting.\\n\");\n    return NULL;\n}\n\nvoid* thread_func_P2(void* arg) {\n    printf(\"P2: Trying to acquire M2...\\n\");\n    pthread_mutex_lock(&M2);\n    printf(\"P2: Acquired M2. Trying to acquire M1...\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&M1);\n    printf(\"P2: Acquired M1. Critical section...\\n\");\n    // Critical section\n    pthread_mutex_unlock(&M1);\n    printf(\"P2: Released M1.\\n\");\n    pthread_mutex_unlock(&M2);\n    printf(\"P2: Released M2. Exiting.\\n\");\n    return NULL;\n}\n```\n\n1. האם קיימת אפשרות לקיפאון (deadlock) בתרחיש זה? נמקו והסבירו אילו מתנאי הקיפאון (Mutual exclusion, Hold-and-wait, No preemption, Circular wait) מתקיימים במקרה זה.\n2. הציעו פתרון לבעיית הקיפאון על ידי שינוי הקוד הנתון, והסבירו מדוע הפתרון שלכם מונע קיפאון.", "code_snippet": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. כן, קיימת אפשרות לקיפאון (deadlock) בתרחיש זה. הקיפאון יתרחש אם P1 יתפוס את M1 ו-P2 יתפוס את M2 בו זמנית, ולאחר מכן כל אחד מהם ינסה לתפוס את המנעול השני שמוחזק על ידי האחר.\n\nתנאי הקיפאון המתקיימים הם:\n*   **מניעה הדדית (Mutual exclusion)**: מתקיים. המנעולים M1 ו-M2 הם mutexes, מה שאומר שרק תהליכון אחד יכול להחזיק בכל מנעול נתון בזמן מסוים. אין אפשרות למשאב להישאר משותף לחלוטין.\n*   **החזק והמתן (Hold and Wait)**: מתקיים. תהליכון P1 מחזיק במנעול M1 וממתין למנעול M2. תהליכון P2 מחזיק במנעול M2 וממתין למנעול M1.\n*   **אי-הפקעה (No Preemption)**: מתקיים. המנעולים לא יכולים להילקח בכוח מתהליכון שמחזיק בהם. תהליכון חייב לשחרר את המנעול מרצונו.\n*   **המתנה מעגלית (Circular Wait)**: מתקיים. P1 ממתין למנעול M2 שמוחזק על ידי P2, ו-P2 ממתין למנעול M1 שמוחזק על ידי P1. זה יוצר מעגל המתנה.\n\n2. כדי למנוע קיפאון, ניתן להבטיח סדר קבוע לרכישת המשאבים (מנעולים) על ידי כל התהליכונים. גישה זו שוברת את תנאי ה'המתנה מעגלית'.\n\n**פתרון מוצע**: כל התהליכונים ירכשו את M1 תחילה, ולאחר מכן את M2. לדוגמה, נשנה את הפונקציה `thread_func_P2` כך שתתפוס את M1 לפני M2:\n\n```c\nvoid* thread_func_P2(void* arg) {\n    printf(\"P2: Trying to acquire M1...\\n\");\n    pthread_mutex_lock(&M1); // Changed order\n    printf(\"P2: Acquired M1. Trying to acquire M2...\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&M2); // Changed order\n    printf(\"P2: Acquired M2. Critical section...\\n\");\n    // Critical section\n    pthread_mutex_unlock(&M2);\n    printf(\"P2: Released M2.\\n\");\n    pthread_mutex_unlock(&M1);\n    printf(\"P2: Released M1. Exiting.\\n\");\n    return NULL;\n}\n```\n\n**הסבר מדוע הפתרון מונע קיפאון**: על ידי אכיפת סדר רכישה עקבי (לדוגמה, תמיד M1 ואז M2), אנו מבטיחים שלא תיווצר לעולם שרשרת המתנה מעגלית. אם P1 תופס את M1 וממתין ל-M2, ו-P2 מגיע ומנסה לתפוס את M1, P2 ייחסם על M1 עד ש-P1 ישחרר אותו. P1 יצליח לתפוס את M2, יסיים את הקטע הקריטי, וישחרר את שני המנעולים. רק אז P2 יוכל להמשיך ולתפוס את M1 (ולאחר מכן את M2). מכיוון שאין אפשרות ש-P1 יחזיק את M1 וימתין ל-M2, בעוד P2 יחזיק את M2 וימתין ל-M1, תנאי ה'המתנה מעגלית' נשבר והקיפאון נמנע."}, "difficulty_estimation": "Medium", "_source_file": "0393__Deadlocks__Open__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:15:02", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Deadlocks", "Synchronization", "Concurrency"], "content": {"text": "נתונה פיסת קוד בשפת C++ המממשת שתי פונקציות, `transfer_money` ו-`update_balance`, המשתמשות בשני מנעולים (mutexes) שונים, `lockA` ו-`lockB`. נתחו את הקוד המצורף והסבירו האם קיים סיכון לקיפאון (deadlock). אם כן, תארו מצב שבו קיפאון אכן מתרחש, והציעו פתרון לבעיה. הפתרון צריך למנוע קיפאון תוך שמירה על נכונות הפעולות.", "code_snippet": "#include <mutex>\n#include <thread>\n#include <iostream>\n\nstd::mutex lockA;\nstd::mutex lockB;\n\nvoid transfer_money(int from_account, int to_account, double amount) {\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Trying to lock A for transfer.\" << std::endl;\n    lockA.lock();\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Locked A. Trying to lock B.\" << std::endl;\n    lockB.lock();\n    \n    // Simulate money transfer\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Transferring \" << amount \n              << \" from \" << from_account << \" to \" << to_account << std::endl;\n    \n    lockB.unlock();\n    lockA.unlock();\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Unlocked A and B. Transfer complete.\" << std::endl;\n}\n\nvoid update_balance(int account, double new_balance) {\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Trying to lock B for update.\" << std::endl;\n    lockB.lock();\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Locked B. Trying to lock A.\" << std::endl;\n    lockA.lock();\n\n    // Simulate balance update\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Updating balance for account \" \n              << account << \" to \" << new_balance << std::endl;\n\n    lockA.unlock();\n    lockB.unlock();\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Unlocked B and A. Update complete.\" << std::endl;\n}\n\nint main() {\n    std::thread t1(transfer_money, 101, 102, 50.0);\n    std::thread t2(update_balance, 101, 1000.0);\n\n    t1.join();\n    t2.join();\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ניתוח קיפאון (Deadlock Analysis):\nכן, קיים סיכון לקיפאון בקוד המצורף. קיפאון יכול להתרחש כאשר מתקיימים ארבעת התנאים הבאים:\n1.  **מניעה הדדית (Mutual Exclusion):** המנעולים (`lockA`, `lockB`) מבטיחים שתא אחד בלבד יכול להחזיק משאב מסוים (את המנעול) בכל רגע נתון.\n2.  **החזקה והמתנה (Hold and Wait):** חוט יכול להחזיק במנעול אחד (למשל, `lockA` בפונקציה `transfer_money`) ולהמתין למנעול אחר (למשל, `lockB`).\n3.  **אי-הפקעה (No Preemption):** לא ניתן להפקיע מנעול מחוט שמחזיק בו; רק החוט עצמו יכול לשחרר אותו.\n4.  **המתנה מעגלית (Circular Wait):** זהו התנאי שמופר בקוד הנתון.\n\nתרחיש קיפאון:\nנניח שמתרחש הרצף הבא:\n*   **חוט 1** קורא לפונקציה `transfer_money`. הוא נועל את `lockA`.\n*   **חוט 2** קורא לפונקציה `update_balance`. הוא נועל את `lockB`.\n*   כעת, **חוט 1** מנסה לנעול את `lockB`, אך `lockB` מוחזק על ידי חוט 2. חוט 1 נכנס למצב המתנה.\n*   באותו זמן, **חוט 2** מנסה לנעול את `lockA`, אך `lockA` מוחזק על ידי חוט 1. חוט 2 נכנס למצב המתנה.\nשני החוטים ממתינים זה לזה באופן מעגלי, ולעולם לא יוכלו להמשיך, מה שמוביל לקיפאון.\n\nפתרון:\nהדרך הנפוצה והיעילה ביותר למנוע קיפאון מסוג זה היא לשבור את תנאי \"המתנה מעגלית\" על ידי אכיפת סדר עקבי של רכישת מנעולים. כלומר, כל החוטים שצריכים לנעול את `lockA` וגם את `lockB`, חייבים לנעול אותם תמיד באותו סדר (לדוגמה, תמיד `lockA` ואז `lockB`).\n\nקוד פתרון (השינויים בפונקציה `update_balance`):\n```c++\n#include <mutex>\n#include <thread>\n#include <iostream>\n\nstd::mutex lockA;\nstd::mutex lockB;\n\nvoid transfer_money(int from_account, int to_account, double amount) {\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Trying to lock A for transfer.\" << std::endl;\n    lockA.lock();\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Locked A. Trying to lock B.\" << std::endl;\n    lockB.lock();\n    \n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Transferring \" << amount \n              << \" from \" << from_account << \" to \" << to_account << std::endl;\n    \n    lockB.unlock();\n    lockA.unlock();\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Unlocked A and B. Transfer complete.\" << std::endl;\n}\n\nvoid update_balance(int account, double new_balance) {\n    // פתרון: אכיפת סדר נעילה קבוע: תמיד lockA ואז lockB\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Trying to lock A for update.\" << std::endl;\n    lockA.lock(); // שינוי: נועלים את lockA קודם\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Locked A. Trying to lock B.\" << std::endl;\n    lockB.lock(); // שינוי: נועלים את lockB אחר כך\n\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Updating balance for account \" \n              << account << \" to \" << new_balance << std::endl;\n\n    lockB.unlock();\n    lockA.unlock();\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Unlocked B and A. Update complete.\" << std::endl;\n}\n\nint main() {\n    std::thread t1(transfer_money, 101, 102, 50.0);\n    std::thread t2(update_balance, 101, 1000.0);\n\n    t1.join();\n    t2.join();\n\n    return 0;\n}\n```\nעל ידי אכיפת סדר נעילה עקבי (לדוגמה, תמיד `lockA` ואז `lockB`), אנו מבטיחים שלעולם לא תיווצר המתנה מעגלית. אם חוט 1 מחזיק ב-`lockA` וממתין ל-`lockB`, וחוט 2 מנסה לנעול את `lockB`, הוא יצטרך קודם לנעול את `lockA`. אם `lockA` כבר מוחזק על ידי חוט 1, חוט 2 ימתין ל-`lockA` מבלי להחזיק ב-`lockB`, ובכך נשברת המעגליות.", "difficulty_estimation": "Medium"}, "_source_file": "0394__Deadlocks__Open__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:15:25", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Deadlocks", "Synchronization", "Threads", "Mutexes"], "content": {"text": "נתון קטע קוד בשפת C המשתמש במנגנוני סנכרון של POSIX Threads (pthreads). הקוד כולל שני חוטים (threads) אשר מנסים לגשת לשני משאבים משותפים, resource_A ו-resource_B, כאשר כל משאב מוגן באמצעות מנעול (mutex) משלו, mutex_A ו-mutex_B בהתאמה. החוטים מבצעים פעולות הדורשות גישה לשני המשאבים.\n\nעיין בקוד המצורף וענה על הסעיפים הבאים:\nא. האם קיים פוטנציאל לקיפאון (deadlock) במערכת זו? נמק את תשובתך על ידי זיהוי והסבר ארבעת התנאים ההכרחיים לקיום קיפאון, והצג כיצד הם מתקיימים במקרה זה.\nב. הצע פתרון למניעת קיפאון במערכת זו. הצג את השינויים הנדרשים בקוד (או תאר אותם בפירוט) והסבר כיצד הפתרון שלך מונע את הקיפאון על ידי הפרה של אחד או יותר מהתנאים שצוינו בסעיף א'.", "code_snippet": "pthread_mutex_t mutex_A;\npthread_mutex_t mutex_B;\n\nvoid* thread_func_1(void* arg) {\n    printf(\"Thread 1: Trying to acquire Mutex A...\\n\");\n    pthread_mutex_lock(&mutex_A);\n    printf(\"Thread 1: Acquired Mutex A. Trying to acquire Mutex B...\\n\");\n    // sleep(1); // Simulate work or delay\n    pthread_mutex_lock(&mutex_B);\n    printf(\"Thread 1: Acquired Mutex B. Performing operation...\\n\");\n    // Critical section\n    printf(\"Thread 1: Releasing Mutex B...\\n\");\n    pthread_mutex_unlock(&mutex_B);\n    printf(\"Thread 1: Releasing Mutex A...\\n\");\n    pthread_mutex_unlock(&mutex_A);\n    printf(\"Thread 1: Finished.\\n\");\n    return NULL;\n}\n\nvoid* thread_func_2(void* arg) {\n    printf(\"Thread 2: Trying to acquire Mutex B...\\n\");\n    pthread_mutex_lock(&mutex_B);\n    printf(\"Thread 2: Acquired Mutex B. Trying to acquire Mutex A...\\n\");\n    // sleep(1); // Simulate work or delay\n    pthread_mutex_lock(&mutex_A);\n    printf(\"Thread 2: Acquired Mutex A. Performing operation...\\n\");\n    // Critical section\n    printf(\"Thread 2: Releasing Mutex A...\\n\");\n    pthread_mutex_unlock(&mutex_A);\n    printf(\"Thread 2: Releasing Mutex B...\\n\");\n    pthread_mutex_unlock(&mutex_B);\n    printf(\"Thread 2: Finished.\\n\");\n    return NULL;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. כן, קיים פוטנציאל לקיפאון במערכת זו. הקיפאון יכול להתרחש כאשר חוט 1 תופס את `mutex_A` וחוט 2 תופס את `mutex_B` בו-זמנית, ולאחר מכן כל אחד מהם מנסה לתפוס את המנעול שהשני מחזיק. לדוגמה, חוט 1 תופס את `mutex_A`, ואז מתרחש מיתוג הקשר (context switch) לחוט 2. חוט 2 תופס את `mutex_B`. כעת, חוט 1 מנסה לתפוס את `mutex_B` (שמוחזק על ידי חוט 2) וחוט 2 מנסה לתפוס את `mutex_A` (שמוחזק על ידי חוט 1). שניהם חסומים וממתינים זה לזה.\n\nארבעת התנאים ההכרחיים לקיום קיפאון מתקיימים במקרה זה:\n1.  **מניעה הדדית (Mutual Exclusion)**: מתקיים. המנעולים `mutex_A` ו-`mutex_B` מבטיחים שרק חוט אחד יכול להחזיק בכל מנעול בכל רגע נתון. משאב (המנעול) אינו ניתן לשיתוף.\n2.  **החזק והמתן (Hold-and-Wait)**: מתקיים. כל חוט תופס מנעול אחד (למשל, חוט 1 תופס את `mutex_A`, חוט 2 תופס את `mutex_B`) וממתין למנעול נוסף (חוט 1 ממתין ל-`mutex_B`, חוט 2 ממתין ל-`mutex_A`) בעודו מחזיק במנעול הראשון.\n3.  **אי-הפקעה (No Preemption)**: מתקיים. מנעולים של pthreads אינם ניתנים להפקעה. חוט אינו יכול להילקח ממנו מנעול בכוח; הוא חייב לשחרר אותו מרצונו.\n4.  **המתנה מעגלית (Circular Wait)**: מתקיים. נוצרת שרשרת המתנה מעגלית: חוט 1 מחזיק ב-`mutex_A` וממתין ל-`mutex_B`, בעוד שחוט 2 מחזיק ב-`mutex_B` וממתין ל-`mutex_A`.\n\nב. הפתרון הנפוץ והיעיל ביותר במקרים כאלה הוא למנוע את תנאי \"ההמתנה המעגלית\" על ידי קביעת סדר קבוע לרכישת משאבים. אם כל החוטים ירכשו את המנעולים באותו סדר, המתנה מעגלית לא תוכל להיווצר.\n\n**שינויים בקוד:**\nנשנה את `thread_func_2` כך שתתפוס את המנעולים באותו סדר כמו `thread_func_1`, כלומר, קודם `mutex_A` ואז `mutex_B`.\n\n**קוד מעודכן עבור `thread_func_2`:**\n```c\nvoid* thread_func_2_fixed(void* arg) {\n    printf(\"Thread 2: Trying to acquire Mutex A...\\n\");\n    pthread_mutex_lock(&mutex_A); // Changed order\n    printf(\"Thread 2: Acquired Mutex A. Trying to acquire Mutex B...\\n\");\n    // sleep(1);\n    pthread_mutex_lock(&mutex_B); // Changed order\n    printf(\"Thread 2: Acquired Mutex B. Performing operation...\\n\");\n    // Critical section\n    printf(\"Thread 2: Releasing Mutex B...\\n\");\n    pthread_mutex_unlock(&mutex_B);\n    printf(\"Thread 2: Releasing Mutex A...\\n\");\n    pthread_mutex_unlock(&mutex_A);\n    printf(\"Thread 2: Finished.\\n\");\n    return NULL;\n}\n```\n\n**הסבר כיצד הפתרון מונע קיפאון:**\nפתרון זה מונע את תנאי **המתנה מעגלית (Circular Wait)**. כאשר כל החוטים רוכשים את המנעולים באותו סדר (לדוגמה, תמיד `mutex_A` ואז `mutex_B`), לא ייתכן מצב שבו חוט אחד מחזיק ב-`mutex_A` וממתין ל-`mutex_B`, בעוד חוט אחר מחזיק ב-`mutex_B` וממתין ל-`mutex_A`. אם חוט 1 תפס את `mutex_A`, חוט 2 יצטרך להמתין לשחרור `mutex_A` לפני שיוכל להמשיך לתפוס את `mutex_B`. ברגע שחוט 1 ישחרר את `mutex_A` (לאחר שסיים עם `mutex_B`), חוט 2 יוכל לתפוס אותו, ובכך נשברת השרשרת המעגלית. שלושת התנאים האחרים (מניעה הדדית, החזק והמתן, אי-הפקעה) עדיין עשויים להתקיים, אך מכיוון שכל ארבעת התנאים הכרחיים לקיום קיפאון, הפרה של אחד מהם מספיקה כדי למנוע אותו."}, "difficulty_estimation": "Medium", "_source_file": "0395__Deadlocks__Open__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:15:56", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Deadlocks", "Resource Management", "Concurrency"], "content": {"text": "נניח שיש לנו מערכת עם שני סוגי משאבים: משאב A ומשאב B. במערכת קיימים סך הכל N יחידות ממשאב A ו-M יחידות ממשאב B.\nישנם K תהליכים (P1, P2, ..., PK) המתחרים על המשאבים. כל תהליך Pi דורש a_i יחידות ממשאב A ו-b_i יחידות ממשאב B כדי להשלים את ריצתו. תהליכים מבקשים יחידה אחת של משאב בכל פעם.\n\n1. תארו תרחיש ספציפי (עם דוגמה מספרית קטנה, למשל N=3, M=3, K=2) שבו עלול להתרחש קיפאון (deadlock) במערכת זו. הסבירו מדוע זהו קיפאון תוך התייחסות לארבעת התנאים ההכרחיים לקיפאון.\n2. הציעו אסטרטגיה פשוטה למניעת קיפאון במערכת זו. הסבירו איזו מבין ארבעת התנאים ההכרחיים לקיפאון האסטרטגיה שלכם מונעת, וכיצד היא עושה זאת.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "חלק 1: תרחיש קיפאון\nנניח N=3 יחידות של A, M=3 יחידות של B, ושני תהליכים P1 ו-P2.\nP1 דורש 2 יחידות A ו-2 יחידות B.\nP2 דורש 2 יחידות A ו-2 יחידות B.\n\nתרחיש קיפאון אפשרי:\n1.  P1 מבקש ומקבל יחידה אחת של A. (A_available=2, B_available=3)\n2.  P2 מבקש ומקבל יחידה אחת של B. (A_available=2, B_available=2)\n3.  P1 מבקש ומקבל יחידה אחת של B. (A_available=2, B_available=1)\n4.  P2 מבקש ומקבל יחידה אחת של A. (A_available=1, B_available=1)\n\nבשלב זה:\n*   P1 מחזיק ב-1 יחידת A ו-1 יחידת B. הוא זקוק לעוד 1 יחידת A ועוד 1 יחידת B.\n*   P2 מחזיק ב-1 יחידת A ו-1 יחידת B. הוא זקוק לעוד 1 יחידת A ועוד 1 יחידת B.\n\nהמשאבים הזמינים: 1 יחידת A, 1 יחידת B.\nאף תהליך לא יכול להמשיך:\n*   P1 לא יכול לקבל עוד A (זמין 1, P1 צריך 1) ולא יכול לקבל עוד B (זמין 1, P1 צריך 1).\n*   P2 לא יכול לקבל עוד A (זמין 1, P2 צריך 1) ולא יכול לקבל עוד B (זמין 1, P2 צריך 1).\n\nהתייחסות לארבעת התנאים ההכרחיים לקיפאון:\n1.  מניעה הדדית (Mutual Exclusion): מתקיים. יחידות המשאבים אינן ניתנות לחלוקה (non-shareable) – יחידת A או B יכולה להיות מוחזקת על ידי תהליך אחד בלבד בכל רגע נתון.\n2.  החזקה והמתנה (Hold and Wait): מתקיים. P1 מחזיק יחידת A ויחידת B וממתין ליחידות נוספות. P2 מחזיק יחידת A ויחידת B וממתין ליחידות נוספות.\n3.  אי-דריסה (No Preemption): מתקיים. המשאבים שהוקצו לתהליך אינם נלקחים ממנו בכוח; הם משוחררים רק מרצון על ידי התהליך המחזיק בהם.\n4.  המתנה מעגלית (Circular Wait): מתקיים. P1 ממתין למשאבים ש-P2 מחזיק, ו-P2 ממתין למשאבים ש-P1 מחזיק, ויוצר מעגל המתנה.\n\nחלק 2: אסטרטגיה למניעת קיפאון\nאסטרטגיה פשוטה למניעת קיפאון היא למנוע את תנאי ה\"החזקה והמתנה\" (Hold and Wait).\n\nכיצד?\nנחייב כל תהליך לבקש את כל המשאבים הנדרשים לו (a_i יחידות A ו-b_i יחידות B) בבת אחת בתחילת ריצתו. אם המערכת לא יכולה להקצות את כל המשאבים הנדרשים לתהליך באותו רגע, התהליך לא יקבל אף משאב וימתין (ללא החזקת משאבים) עד שכל המשאבים יהיו זמינים.\n\nהסבר:\nבגישה זו, תהליך לעולם לא יחזיק במשאבים כלשהם ובו זמנית ימתין למשאבים נוספים. הוא יקבל את כל משאביו מראש, או שימתין ללא החזקת משאבים. בכך, אנו מונעים את התנאי \"החזקה והמתנה\", ולכן מונעים קיפאון.\nלדוגמה, בתרחיש הקודם: P1 יבקש 2A ו-2B. אם זמינים, יקבל וירוץ. אם P1 קיבל, אז נותרו 1A ו-1B. P2 יבקש 2A ו-2B, אך לא יוכל לקבל אותם (כי אין מספיק). P2 ימתין עד ש-P1 יסיים וישחרר את משאביו, ורק אז P2 יוכל לקבל את משאביו ולרוץ. בדרך זו, אין קיפאון."}, "difficulty_estimation": "Medium", "_source_file": "0396__Deadlocks__Open__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:16:14", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Deadlocks", "Synchronization"], "content": {"text": "נתונה מערכת עם שני תהליכים (P1, P2) ושני משאבים (R1, R2). כל משאב מיוצג על ידי סמפור בינארי (mutex). התהליכים מנסים לגשת למשאבים בסדר הבא:\n\nP1:\nlock(R1);\nlock(R2);\n// קטע קריטי\nunlock(R2);\nunlock(R1);\n\nP2:\nlock(R2);\nlock(R1);\n// קטע קריטי\nunlock(R1);\nunlock(R2);\n\nא. האם קיים תרחיש שבו יכול להיווצר קיפאון (deadlock) במערכת זו? הסבר בפירוט מדוע, תוך התייחסות לארבעת התנאים ההכרחיים לקיום קיפאון.\nב. אם כן, הצע פתרון למניעת קיפאון עבור המקרה המתואר, תוך שינוי מינימלי בקוד, והסבר כיצד הפתרון שלך מונע את הקיפאון.", "code_snippet": "typedef void Semaphore;\n\n// Assume lock(Semaphore* s) and unlock(Semaphore* s) are defined\n// and implement standard binary semaphore (mutex) operations.\n\nvoid process_P1(Semaphore* R1, Semaphore* R2) {\n    lock(R1);\n    lock(R2);\n    // critical section for P1\n    // ...\n    unlock(R2);\n    unlock(R1);\n}\n\nvoid process_P2(Semaphore* R1, Semaphore* R2) {\n    lock(R2);\n    lock(R1);\n    // critical section for P2\n    // ...\n    unlock(R1);\n    unlock(R2);\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. כן, קיים תרחיש שבו יכול להיווצר קיפאון (deadlock) במערכת זו.\n\nתרחיש לדוגמה:\n1. תהליך P1 מבצע `lock(R1)` ותופס את משאב R1.\n2. תהליך P2 מבצע `lock(R2)` ותופס את משאב R2.\n3. P1 מנסה לבצע `lock(R2)` אך R2 תפוס על ידי P2, ולכן P1 נחסם וממתין ל-R2.\n4. P2 מנסה לבצע `lock(R1)` אך R1 תפוס על ידי P1, ולכן P2 נחסם וממתין ל-R1.\n\nבנקודה זו, P1 מחזיק ב-R1 וממתין ל-R2, בעוד P2 מחזיק ב-R2 וממתין ל-R1. נוצר מעגל המתנה הדדי, והתהליכים נמצאים בקיפאון.\n\nהתנאים ההכרחיים לקיום קיפאון מתקיימים:\n*   **מניעה הדדית (Mutual Exclusion):** הסמפורים הבינאריים מבטיחים שרק תהליך אחד יכול להחזיק במשאב R1 או R2 בכל רגע נתון.\n*   **החזק והמתן (Hold and Wait):** כל תהליך מחזיק במשאב אחד (P1 ב-R1, P2 ב-R2) וממתין למשאב נוסף (P1 ל-R2, P2 ל-R1).\n*   **אי-הפקעה (No Preemption):** לא ניתן להפקיע משאב מתהליך המחזיק בו; רק התהליך עצמו יכול לשחרר אותו.\n*   **המתנה מעגלית (Circular Wait):** P1 ממתין למשאב R2 המוחזק על ידי P2, ו-P2 ממתין למשאב R1 המוחזק על ידי P1. נוצר מעגל המתנה.\n\nב. כדי למנוע קיפאון, ניתן ליישם את אסטרטגיית **סדר משאבים (Resource Ordering)**, המונעת את התנאי של המתנה מעגלית.\nנחליט על סדר גלובלי עבור המשאבים, למשל: R1 < R2.\nכל התהליכים חייבים לבקש משאבים לפי סדר עולה זה.\n\nהשינוי המינימלי בקוד יהיה בתהליך P2, כך שיבקש את R1 לפני R2, בדומה ל-P1:\n\n```c\n// Process P1 (no change)\nvoid process_P1(Semaphore* R1, Semaphore* R2) {\n    lock(R1);\n    lock(R2);\n    // critical section for P1\n    // ...\n    unlock(R2);\n    unlock(R1);\n}\n\n// Process P2 (modified)\nvoid process_P2(Semaphore* R1, Semaphore* R2) {\n    lock(R1); // Changed from lock(R2)\n    lock(R2); // Changed from lock(R1)\n    // critical section for P2\n    // ...\n    unlock(R2);\n    unlock(R1);\n}\n```\n\n**הסבר כיצד הפתרון מונע קיפאון:**\nעל ידי אכיפת סדר בקשת משאבים, אנו מונעים היווצרות של המתנה מעגלית.\nכעת, שני התהליכים (P1 ו-P2) מנסים לתפוס קודם את R1, ורק לאחר מכן את R2.\n*   אם P1 מצליח לתפוס את R1, אז P2 ייחסם כאשר ינסה לתפוס את R1. P1 יוכל להמשיך, לתפוס את R2, לבצע את הקטע הקריטי ולשחרר את R2 ואז את R1. לאחר ש-R1 ישוחרר, P2 יוכל לתפוס אותו ולהמשיך.\n*   אם P2 מצליח לתפוס את R1, אז P1 ייחסם כאשר ינסה לתפוס את R1. P2 יוכל להמשיך, לתפוס את R2, לבצע את הקטע הקריטי ולשחרר את R2 ואז את R1. לאחר ש-R1 ישוחרר, P1 יוכל לתפוס אותו ולהמשיך.\n\nבשני המקרים, לא יכול להיווצר מצב שבו P1 מחכה ל-R2 שמוחזק על ידי P2, ובו זמנית P2 מחכה ל-R1 שמוחזק על ידי P1, מכיוון ששניהם תמיד ינסו לתפוס את R1 קודם. תהליך אחד ישיג את R1 וימשיך, בעוד השני ימתין בסבלנות לשחרורו, ובכך נמנעת המתנה מעגלית."}, "difficulty_estimation": "Medium", "_source_file": "0397__Deadlocks__Open__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:16:43", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Deadlocks", "Deadlock Prevention", "Concurrency"], "content": {"text": "במערכת הפעלה, קיפאון (deadlock) יכול להתרחש כאשר קבוצת תהליכים נחסמת באופן קבוע, כאשר כל תהליך בקבוצה ממתין למשאב שמוחזק על ידי תהליך אחר בקבוצה.\nנתונה מערכת עם שני סוגי משאבים, R1 ו-R2, כאשר מכל סוג קיים מופע יחיד. במערכת רצים שני תהליכים, P1 ו-P2, אשר מבצעים את הקוד הבא:\n\n```c\n// Process P1\nvoid process_P1() {\n    lock(&R1);\n    lock(&R2);\n    // קטע קריטי\n    unlock(&R2);\n    unlock(&R1);\n}\n\n// Process P2\nvoid process_P2() {\n    lock(&R2);\n    lock(&R1);\n    // קטע קריטי\n    unlock(&R1);\n    unlock(&R2);\n}\n```\n\nא) הסבירו כיצד קיפאון יכול להתרחש במערכת זו. תארו רצף אירועים ספציפי שמוביל לקיפאון.\nב) הציעו מנגנון פשוט למניעת קיפאון במערכת זו, תוך התייחסות לאחד מארבעת התנאים למניעת קיפאון. הסבירו את המנגנון שבחרתם והדגימו כיצד הוא מונע את הקיפאון בתרחיש הספציפי הזה.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "חלק א': הסבר על קיפאון\n\nקיפאון יכול להתרחש במערכת זו עקב קיום כל ארבעת התנאים לקיפאון:\n1.  מניעה הדדית (Mutual Exclusion): המשאבים R1 ו-R2 הם משאבים בלעדיים, כלומר רק תהליך אחד יכול להחזיק בכל משאב נתון בזמן מסוים (ה-lock מבטיח זאת).\n2.  החזק והמתן (Hold-and-Wait): תהליך יכול להחזיק במשאב אחד (לדוגמה, P1 מחזיק ב-R1) ובמקביל לבקש משאב נוסף (P1 ממתין ל-R2).\n3.  אי-נשללות (No Preemption): לא ניתן לקחת משאב מתהליך שמחזיק בו בכוח. תהליך משחרר משאב רק מרצונו החופשי (באמצעות unlock).\n4.  המתנה מעגלית (Circular Wait): קיים מעגל של תהליכים, כאשר כל תהליך ממתין למשאב שמוחזק על ידי התהליך הבא במעגל.\n\nרצף אירועים המוביל לקיפאון:\n1.  P1 מבצע lock(&R1): P1 תופס את R1.\n2.  P2 מבצע lock(&R2): P2 תופס את R2.\n3.  P1 מבצע lock(&R2): P1 מנסה לתפוס את R2 אך נחסם, מכיוון ש-R2 מוחזק על ידי P2. P1 ממתין ל-R2.\n4.  P2 מבצע lock(&R1): P2 מנסה לתפוס את R1 אך נחסם, מכיוון ש-R1 מוחזק על ידי P1. P2 ממתין ל-R1.\n\nבשלב זה, P1 מחזיק ב-R1 וממתין ל-R2, בעוד P2 מחזיק ב-R2 וממתין ל-R1. נוצרה המתנה מעגלית, ושני התהליכים חסומים באופן קבוע – קיפאון.\n\nחלק ב': מנגנון למניעת קיפאון\n\nניתן למנוע את הקיפאון על ידי שבירת תנאי ה\"המתנה מעגלית\" (Circular Wait), באמצעות הקפדה על סדר קבוע לרכישת משאבים.\n\nמנגנון: הקצאת סדר גלובלי לכל סוגי המשאבים במערכת. לדוגמה, נקבע ש-R1 יבוא לפני R2 (כלומר, R1 < R2). כל התהליכים במערכת חייבים לבקש משאבים לפי סדר זה. אם תהליך זקוק למשאבים R1 ו-R2, הוא חייב לבקש קודם את R1 ורק אחר כך את R2.\n\nיישום בתרחיש זה:\nנשנה את קוד התהליכים כך ששניהם יבקשו את המשאבים בסדר קבוע (לדוגמה, R1 ואז R2):\n\n```c\n// Process P1 (ללא שינוי)\nvoid process_P1() {\n    lock(&R1);\n    lock(&R2);\n    // קטע קריטי\n    unlock(&R2);\n    unlock(&R1);\n}\n\n// Process P2 (לאחר שינוי)\nvoid process_P2_modified() {\n    lock(&R1); // שינוי: קודם מבקש R1\n    lock(&R2); // ואז מבקש R2\n    // קטע קריטי\n    unlock(&R2);\n    unlock(&R1);\n}\n```\n\nכיצד זה מונע קיפאון:\nננתח שוב את רצף האירועים האפשרי:\n1.  P1 מבצע lock(&R1): P1 תופס את R1.\n2.  P2 מנסה לבצע lock(&R1): P2 נחסם מכיוון ש-R1 מוחזק על ידי P1. P2 ממתין ל-R1.\n3.  P1 מבצע lock(&R2): P1 תופס את R2 (מכיוון ש-P2 חסום על R1, הוא לא יכול לתפוס את R2).\n4.  P1 מסיים את הקטע הקריטי ומשחרר את R2 ואז את R1.\n5.  כאשר R1 משוחרר, P2 (שממתין ל-R1) מקבל את R1.\n6.  P2 ממשיך ומבצע lock(&R2).\n7.  P2 מסיים את הקטע הקריטי ומשחרר את R2 ואז את R1.\n\nבכל תרחיש אפשרי, אחד מהתהליכים יתפוס את R1 ראשון. התהליך השני ייחסם וימתין. התהליך הראשון ימשיך, יתפוס את R2, יסיים את עבודתו וישחרר את שני המשאבים. רק אז התהליך השני יוכל להמשיך. תמיד יהיה תהליך שיסיים את עבודתו וישחרר משאבים, ובכך לא תיווצר המתנה מעגלית ולכן לא יהיה קיפאון."}, "difficulty_estimation": "Medium", "_source_file": "0398__Deadlocks__Open__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:17:04", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Deadlocks", "Synchronization", "Resource Allocation"], "content": {"text": "נתונה מערכת עם שני סוגי משאבים, R1 ו-R2, כאשר כל אחד מהם מוגן על ידי מנעול (mutex_R1, mutex_R2). קיימים N חוטים, וכל חוט נדרש לרכוש את R1 ו-R2 כדי לבצע את משימתו, ולאחר מן לשחרר אותם. מוצגים שני חוטים, חוט A וחוט B, המנסים לרכוש משאבים אלו:\n\n**חוט A:**\n```c\npthread_mutex_lock(&mutex_R1);\npthread_mutex_lock(&mutex_R2);\n// גישה למשאבים R1 ו-R2\npthread_mutex_unlock(&mutex_R2);\npthread_mutex_unlock(&mutex_R1);\n```\n\n**חוט B:**\n```c\npthread_mutex_lock(&mutex_R2);\npthread_mutex_lock(&mutex_R1);\n// גישה למשאבים R1 ו-R2\npthread_mutex_unlock(&mutex_R1);\npthread_mutex_unlock(&mutex_R2);\n```\n\nא. הסבירו מדוע תרחיש זה עלול להוביל לקיפאון (deadlock).\nב. הציעו פתרון למניעת קיפאון זה, וספקו קטע קוד עבור לוגיקת רכישת המשאבים המתוקנת עבור שני החוטים.\nג. דון בתנאי מניעת הקיפאון שהפתרון שלך מטפל בו.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. תרחיש זה עלול להוביל לקיפאון מכיוון שהוא מקיים את כל ארבעת התנאים ההכרחיים לקיפאון:\n1.  **מניעה הדדית (Mutual Exclusion):** כל משאב (mutex_R1 ו-mutex_R2) יכול להיות מוחזק על ידי חוט אחד בלבד בכל רגע נתון. זהו מאפיין מובנה של מנעולים.\n2.  **החזק והמתן (Hold and Wait):** חוט יכול להחזיק במשאב אחד (לדוגמה, חוט A מחזיק ב-mutex_R1) ובמקביל להמתין למשאב אחר (חוט A ממתין ל-mutex_R2).\n3.  **ללא דריסה (No Preemption):** משאבים אינם נלקחים בכוח מחוט שמחזיק בהם; חוט חייב לשחרר את המשאבים מרצונו.\n4.  **המתנה מעגלית (Circular Wait):** תנאי זה מתקיים כאשר קיים מעגל של חוטים, כאשר כל חוט בשרשרת ממתין למשאב המוחזק על ידי החוט הבא בשרשרת. בתרחיש הנתון, אם חוט A רוכש את mutex_R1 וחוט B רוכש את mutex_R2 בו-זמנית (או בסמיכות), אז חוט A ממתין ל-mutex_R2 (שמוחזק על ידי B), וחוט B ממתין ל-mutex_R1 (שמוחזק על ידי A). זה יוצר מעגל המתנה: A ממתין ל-B, ו-B ממתין ל-A.\n\nב. הפתרון למניעת קיפאון זה הוא לכפות סדר רכישה עקבי של המשאבים על כל החוטים. כלומר, כל החוטים ינסו תמיד לרכוש את המשאבים באותו סדר. לדוגמה, כל החוטים ירכשו תמיד את mutex_R1 ואז את mutex_R2. שינוי זה מונע את התנאי של המתנה מעגלית.\n\nלהלן קטע הקוד המתוקן עבור שני החוטים:\n\n```c\npthread_mutex_t mutex_R1; // יש לאתחל את המנעולים\npthread_mutex_t mutex_R2;\n\nvoid *thread_A_func(void *arg) {\n    // ... עבודה כלשהי ...\n    pthread_mutex_lock(&mutex_R1); // תמיד רכוש את R1 ראשון\n    pthread_mutex_lock(&mutex_R2); // ואז את R2\n    // גישה למשאבים R1 ו-R2\n    pthread_mutex_unlock(&mutex_R2);\n    pthread_mutex_unlock(&mutex_R1);\n    // ... עבודה נוספת ...\n    return NULL;\n}\n\nvoid *thread_B_func(void *arg) {\n    // ... עבודה כלשהי ...\n    pthread_mutex_lock(&mutex_R1); // גם חוט B רוכש את R1 ראשון\n    pthread_mutex_lock(&mutex_R2); // ואז את R2\n    // גישה למשאבים R1 ו-R2\n    pthread_mutex_unlock(&mutex_R2);\n    pthread_mutex_unlock(&mutex_R1);\n    // ... עבודה נוספת ...\n    return NULL;\n}\n```\n\nג. הפתרון המוצע מטפל בתנאי מניעת הקיפאון של **המתנה מעגלית (Circular Wait)**. על ידי אכיפת סדר רכישה עקבי וגלובלי (לדוגמה, תמיד R1 ואז R2), אנו מבטיחים שלא יכולה להיווצר שרשרת המתנה מעגלית. אם חוט A מחזיק ב-R1 וממתין ל-R2, וחוט B רוצה גם הוא את R1 ו-R2, הוא יצטרך להמתין ש-R1 ישוחרר על ידי A לפני שיוכל לרכוש אותו. מכיוון שכל החוטים רוכשים את המשאבים באותו סדר, לא ייתכן מצב שחוט A ממתין ל-R2 שמוחזק על ידי B, ובמקביל B ממתין ל-R1 שמוחזק על ידי A, מכיוון ש-B לא היה מנסה לרכוש את R2 לפני שרכש את R1 (שמוחזק על ידי A). כך אנו שוברים את המעגל הפוטנציאלי."}, "difficulty_estimation": "Medium", "_source_file": "0399__Deadlocks__Open__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:17:21", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Deadlocks", "Resource Allocation", "Deadlock Prevention"], "content": {"text": "מערכת הפעלה מנהלת שלושה סוגי משאבים: A, B ו-C. לכל סוג משאב יש מספר מופעים קבוע (לדוגמה: 2 מופעי A, 2 מופעי B, 2 מופעי C). במערכת רצים מספר תהליכים. כל תהליך דורש שני סוגי משאבים שונים כדי להשלים את משימתו. לדוגמה, תהליך P1 זקוק למופע אחד מ-A ומופע אחד מ-B, תהליך P2 זקוק למופע אחד מ-B ומופע אחד מ-C, וכך הלאה.\n\nא. תארו מצב שבו יכול להתרחש קיפאון (deadlock) במערכת כזו. ציינו אילו מהתנאים ההכרחיים לקיפאון (mutual exclusion, hold and wait, no preemption, circular wait) מתקיימים במצב שתיארתם.\nב. הציעו אסטרטגיה למניעת קיפאון במערכת זו. הסבירו כיצד האסטרטגיה שהצעתם שוברת לפחות אחד מהתנאים ההכרחיים לקיפאון.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "חלק א': תיאור מצב קיפאון ותנאים\nנניח שיש לנו 2 מופעים מכל סוג משאב (A, B, C) ושלושה תהליכים: P1, P2, P3.\n*   P1 זקוק למופע אחד מ-A ומופע אחד מ-B.\n*   P2 זקוק למופע אחד מ-B ומופע אחד מ-C.\n*   P3 זקוק למופע אחד מ-C ומופע אחד מ-A.\n\nמצב קיפאון אפשרי:\n1.  P1 רוכש מופע אחד של A.\n2.  P2 רוכש מופע אחד של B.\n3.  P3 רוכש מופע אחד של C.\n\nבשלב זה:\n*   P1 מחזיק ב-A וממתין ל-B.\n*   P2 מחזיק ב-B וממתין ל-C.\n*   P3 מחזיק ב-C וממתין ל-A.\n\nכל תהליך מחזיק במשאב אחד וממתין למשאב אחר שמוחזק על ידי תהליך אחר, ונוצר מעגל המתנה. אף תהליך לא יכול להמשיך, וזהו מצב קיפאון.\n\nהתנאים ההכרחיים לקיפאון המתקיימים במצב זה:\n*   **Mutual Exclusion (מניעה הדדית):** מתקיים. משאבים ניתנים לשימוש בלעדי (מופע של משאב יכול להיות מוחזק רק על ידי תהליך אחד). \n*   **Hold and Wait (החזק והמתן):** מתקיים. כל תהליך מחזיק במשאב אחד (לדוגמה, P1 מחזיק ב-A) וממתין למשאב נוסף (P1 ממתין ל-B) שמוחזק על ידי תהליך אחר.\n*   **No Preemption (אי-הפקעה):** מתקיים. לא ניתן להפקיע משאבים מתהליך שמחזיק בהם בכוח; התהליך חייב לשחרר אותם מרצונו.\n*   **Circular Wait (המתנה מעגלית):** מתקיים. P1 ממתין למשאב שמוחזק על ידי P2, P2 ממתין למשאב שמוחזק על ידי P3, ו-P3 ממתין למשאב שמוחזק על ידי P1. נוצר מעגל סגור של המתנה.\n\nחלק ב': אסטרטגיה למניעת קיפאון\nאחת האסטרטגיות למניעת קיפאון היא לשבור את תנאי **המתנה מעגלית (Circular Wait)** באמצעות **היררכיה של משאבים (Resource Ordering)**.\n\n**תיאור האסטרטגיה:**\nנקצה סדר מספרי גלובלי לכל סוג משאב. לדוגמה: A=1, B=2, C=3. כל תהליך במערכת חייב לבקש משאבים בסדר עולה בלבד. כלומר, אם תהליך זקוק למשאבים מסוג R_i ו-R_j, והמספר הסידורי של R_i קטן מהמספר הסידורי של R_j, אזי התהליך חייב לבקש את R_i לפני R_j.\n\n**הסבר כיצד האסטרטגיה שוברת את תנאי Circular Wait:**\nעם היררכיה של משאבים, לא ייתכן שיתקיים מעגל המתנה. נניח שקיימת שרשרת המתנה מעגלית: P1 ממתין למשאב שמוחזק על ידי P2, P2 ממתין למשאב שמוחזק על ידי P3, ..., Pn ממתין למשאב שמוחזק על ידי P1. אם כל תהליך חייב לבקש משאבים בסדר עולה, אז:\n*   המשאב ש-P1 ממתין לו (שמוחזק על ידי P2) חייב להיות בעל מספר סידורי גבוה יותר מהמשאב ש-P1 מחזיק בו.\n*   המשאב ש-P2 ממתין לו (שמוחזק על ידי P3) חייב להיות בעל מספר סידורי גבוה יותר מהמשאב ש-P2 מחזיק בו.\n*   וכך הלאה, עד Pn.\n\nאם Pn ממתין למשאב שמוחזק על ידי P1, אז המשאב ש-Pn ממתין לו חייב להיות בעל מספר סידורי גבוה יותר מהמשאב ש-Pn מחזיק בו. אך זה אומר שהמשאב ש-P1 מחזיק בו יהיה בעל מספר סידורי גבוה יותר מהמשאב ש-Pn מחזיק בו. בסופו של דבר, אם נלך לאורך המעגל, המשאב הראשון בשרשרת יהיה בעל מספר סידורי גבוה יותר מעצמו, וזו סתירה. לכן, לא ניתן ליצור מעגל המתנה כאשר משאבים נרכשים בסדר היררכי עולה, ובכך נשבר תנאי ה-Circular Wait."}, "difficulty_estimation": "Medium", "_source_file": "0400__Deadlocks__Open__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:17:45", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Deadlocks", "Resource Management", "Synchronization", "Concurrency"], "content": {"text": "נתונה מערכת מרובת חוטים בה קיימים שני סוגי משאבים: Resource A ו-Resource B. ידוע כי קיימים סך הכל `TotalA` יחידות מ-Resource A ו-`TotalB` יחידות מ-Resource B. חוטים במערכת מבצעים פעולות הדורשות כמות מסוימת של יחידות מכל אחד מהמשאבים בו-זמנית (לדוגמה, חוט מבקש `a` יחידות מ-A ו-`b` יחידות מ-B).\n\nעליכם לממש מנהל משאבים (Resource Manager) ב-C/C++ שיספק שתי פונקציות:\n1.  `request_resources(int a, int b)`: חוט קורא לפונקציה זו כדי לבקש `a` יחידות מ-Resource A ו-`b` יחידות מ-Resource B.\n2.  `release_resources(int a, int b)`: חוט קורא לפונקציה זו כדי לשחרר `a` יחידות מ-Resource A ו-`b` יחידות מ-Resource B.\n\nהמימוש שלכם חייב לעמוד בדרישות הבאות:\n*   **מניעת קיפאון (Deadlock Prevention):** המערכת לעולם לא תיכנס למצב קיפאון.\n*   **חופש מרעב (Starvation-Free):** אם בקשה למשאבים יכולה להתמלא בסופו של דבר (כלומר, סך המשאבים הנדרשים זמין במערכת), היא אכן תתמלא בתוך זמן סופי. יש להבטיח הוגנות במידת האפשר.\n*   **מימוש:** השתמשו באובייקטי סנכרון סטנדרטיים של POSIX Threads (כגון mutexes, condition variables, semaphores).\n\nיש לכלול את הגדרת מבנה הנתונים של מנהל המשאבים, פונקציית אתחול, ומימוש מלא של `request_resources` ו-`release_resources`. בנוסף, הסבירו בפירוט כיצד המימוש שלכם מבטיח מניעת קיפאון וחופש מרעב.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון מתבסס על עקרון \"בקש הכל או כלום\" (All-or-nothing) בשילוב עם משתני תנאי (condition variables) כדי למנוע קיפאון ולהבטיח חופש מרעב.\n\n### מבנה הנתונים של מנהל המשאבים:\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\ntypedef struct {\n    int total_A;\n    int total_B;\n    int available_A;\n    int available_B;\n    pthread_mutex_t lock;\n    pthread_cond_t cond;\n} ResourceManager;\n\n// פונקציית אתחול למנהל המשאבים\nvoid init_resource_manager(ResourceManager *rm, int initial_A, int initial_B) {\n    rm->total_A = initial_A;\n    rm->total_B = initial_B;\n    rm->available_A = initial_A;\n    rm->available_B = initial_B;\n    pthread_mutex_init(&rm->lock, NULL);\n    pthread_cond_init(&rm->cond, NULL);\n}\n\n// פונקציית השמדה למנהל המשאבים\nvoid destroy_resource_manager(ResourceManager *rm) {\n    pthread_mutex_destroy(&rm->lock);\n    pthread_cond_destroy(&rm->cond);\n}\n\n// פונקציה לבקשת משאבים\nvoid request_resources(ResourceManager *rm, int a, int b) {\n    pthread_mutex_lock(&rm->lock);\n\n    // חוט ממתין בלולאה כל עוד אין מספיק משאבים משני הסוגים\n    // ה-while loop מבטיח שגם לאחר התעוררות, התנאי נבדק שוב (spurious wakeup)\n    // וכן במקרה שחוט אחר לקח את המשאבים לפנינו.\n    while (rm->available_A < a || rm->available_B < b) {\n        // משחרר את המנעול ונכנס למצב המתנה. כשהוא מתעורר, הוא רוכש את המנעול שוב.\n        pthread_cond_wait(&rm->cond, &rm->lock);\n    }\n\n    // יש מספיק משאבים, מבצעים הקצאה\n    rm->available_A -= a;\n    rm->available_B -= b;\n    printf(\"Thread %lu acquired: A=%d, B=%d. Available: A=%d, B=%d\\n\",\n           pthread_self(), a, b, rm->available_A, rm->available_B);\n\n    pthread_mutex_unlock(&rm->lock);\n}\n\n// פונקציה לשחרור משאבים\nvoid release_resources(ResourceManager *rm, int a, int b) {\n    pthread_mutex_lock(&rm->lock);\n\n    // משחרר את המשאבים ומעדכן את המונים\n    rm->available_A += a;\n    rm->available_B += b;\n    printf(\"Thread %lu released: A=%d, B=%d. Available: A=%d, B=%d\\n\",\n           pthread_self(), a, b, rm->available_A, rm->available_B);\n\n    // מאותת לכל החוטים הממתינים לבדוק שוב את תנאי הבקשה שלהם.\n    // שימוש ב-broadcast חיוני למניעת רעב.\n    pthread_cond_broadcast(&rm->cond);\n\n    pthread_mutex_unlock(&rm->lock);\n}\n```\n\n### הסבר:\n\n**1. מניעת קיפאון (Deadlock Prevention):**\nהמימוש מונע קיפאון על ידי מניעת קיום של התנאי \"החזק והמתן\" (Hold and Wait) וכן על ידי מניעת קיום של \"מעגל המתנה\" (Circular Wait).\n*   **\"בקש הכל או כלום\" (All-or-nothing):** חוט שמבקש משאבים לעולם לא יחזיק חלק מהמשאבים הנדרשים וימתין לאחרים. הוא תמיד ממתין (באמצעות `pthread_cond_wait`) עד שכל המשאבים הנדרשים (גם מ-A וגם מ-B) זמינים עבורו. רק כאשר כל המשאבים זמינים, הוא רוכש אותם באופן אטומי (תחת הגנת המוטקס). מצב זה מבטיח שאף חוט לא יחזיק משאבים בזמן שהוא ממתין למשאבים נוספים, ובכך נמנע התנאי של \"החזק והמתן\".\n*   **נעילה אטומית:** המוטקס `rm->lock` מגן על המשתנים `available_A` ו-`available_B` ועל כל תהליך הבדיקה וההקצאה. זה מבטיח שאף שני חוטים לא יקבלו החלטות סותרות לגבי זמינות המשאבים בו-זמנית, ושפעולת ההקצאה היא אטומית. מכיוון שהקצאת המשאבים היא אטומית וכוללת את כל המשאבים הנדרשים, לא יכול להיווצר מצב של מעגל המתנה שבו חוטים ממתינים זה לזה למשאבים שהם כבר החלו להחזיק.\n\n**2. חופש מרעב (Starvation-Free):**\nהמימוש מבטיח חופש מרעב בזכות השימוש ב-`pthread_cond_broadcast`:\n*   **`pthread_cond_broadcast` ב-`release_resources`:** כאשר חוט משחרר משאבים, הוא קורא ל-`pthread_cond_broadcast`. פעולה זו מעירה את *כל* החוטים הממתינים על משתנה התנאי `cond`.\n*   **בדיקה מחודשת של התנאי:** כל חוט שהתעורר חוזר לבדוק את התנאי בלולאת ה-`while` (`rm->available_A < a || rm->available_B < b`). מאחר שכל המשאבים משוחררים בסופו של דבר, וכל חוט ממתין מקבל הזדמנות לבדוק אם בקשתו יכולה להתמלא, כל בקשה שניתן למלאה (כלומר, יש מספיק משאבים במערכת הכוללת) תתמלא בתוך זמן סופי. אין חוט ספציפי שיכול \"להיתקע\" לנצח בזמן שחוטים אחרים מקבלים משאבים, מכיוון שכל שחרור משאבים נותן לכולם הזדמנות שווה לבדוק את תנאיהם.\n*   **הוגנות:** שימוש ב-`pthread_cond_broadcast` מספק רמה טובה של הוגנות בכך שהוא מאפשר לכל בקשה פוטנציאלית להתמלא, גם אם היא לא הראשונה שהגיעה לתור ההמתנה. זה מונע מצב שבו בקשות קטנות יותר, שיכולות להתמלא מיד עם שחרור משאבים, נחסמות על ידי בקשה גדולה יותר שנמצאת בראש התור אך עדיין לא יכולה להתמלא."}, "difficulty_estimation": "Hard", "_source_file": "0401__Deadlocks__Open__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:18:12", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Deadlocks", "Concurrency", "Resource Management"], "content": {"text": "במערכת הפעלה מרובת תהליכים, נניח שיש לנו N תהליכים (או חוטים) שכל אחד מהם צריך לבצע משימה הדורשת שני סוגי משאבים: 'משאב X' ו'משאב Y'. קיימים `num_X` יחידות של משאב X ו-`num_Y` יחידות של משאב Y במערכת. כל תהליך זקוק ליחידה אחת מכל סוג משאב כדי להשלים את משימתו. התהליכים רוכשים את המשאבים באמצעות מנעולים (mutexes).", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "תארו תרחיש ספציפי (באמצעות סדר פעולות של שני תהליכים לפחות) שבו עלול להתרחש קיפאון (deadlock) במערכת המתוארת. הסבירו מדוע תרחיש זה מוביל לקיפאון תוך התייחסות לארבעת התנאים של קיפאון (מניעה הדדית, החזקה והמתנה, אי-נשללות, המתנה מעגלית).", "code_snippet": null, "options": null}, {"id": "1.2", "text": "הציעו אסטרטגיה למניעת קיפאון במערכת זו. לאחר מכן, כתבו מימוש בפסאודו-קוד (או C/C++) לפונקציות `acquire_resources` ו-`release_resources` עבור תהליך בודד, המשתמשות ב-`pthread_mutex_t` ומיישמות את האסטרטגיה שהצעתם. הניחו ש-`mutex_X` ו-`mutex_Y` הם מנעולים גלובליים המגנים על המשאבים.", "code_snippet": "pthread_mutex_t mutex_X; // מגן על משאב X\npthread_mutex_t mutex_Y; // מגן על משאב Y\n\nvoid acquire_resources() {\n    // יש לממש כאן את לוגיקת רכישת המשאבים עם מניעת קיפאון\n}\n\nvoid release_resources() {\n    // יש לממש כאן את לוגיקת שחרור המשאבים\n}", "options": null}, {"id": "1.3", "text": "נתחו את השפעת האסטרטגיה שהצעתם על רמת המקביליות (concurrency) וניצול המשאבים במערכת. האם יש חסרונות לגישה זו? פרטו.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "### סעיף 1.1: תרחיש קיפאון\nתרחיש קיפאון יכול להתרחש כדלקמן:\n\n**תהליך P1 מבצע:**\n1. `pthread_mutex_lock(&mutex_X);` // P1 רוכש את מנעול X\n\n**תהליך P2 מבצע בו זמנית:**\n1. `pthread_mutex_lock(&mutex_Y);` // P2 רוכש את מנעול Y\n\n**לאחר מכן:**\n2. `pthread_mutex_lock(&mutex_Y);` // P1 מנסה לרכוש את מנעול Y. P1 נחסם כיוון ש-P2 מחזיק ב-Y.\n\n2. `pthread_mutex_lock(&mutex_X);` // P2 מנסה לרכוש את מנעול X. P2 נחסם כיוון ש-P1 מחזיק ב-X.\n\nבשלב זה, P1 מחזיק ב-X וממתין ל-Y, בעוד P2 מחזיק ב-Y וממתין ל-X. זהו מצב של קיפאון.\n\n**הסבר לפי ארבעת התנאים לקיפאון:**\n1.  **מניעה הדדית (Mutual Exclusion):** מתקיים. כל מנעול (mutex) מאפשר לתהליך אחד בלבד להחזיק בו בו-זמנית. משאבים X ו-Y הם בלעדיים.\n2.  **החזקה והמתנה (Hold and Wait):** מתקיים. תהליך P1 מחזיק במנעול X וממתין למנעול Y. תהליך P2 מחזיק במנעול Y וממתין למנעול X.\n3.  **אי-נשללות (No Preemption):** מתקיים. המנעולים אינם ניתנים להילקח בכוח מתהליך שמחזיק בהם; רק התהליך המחזיק יכול לשחרר אותם.\n4.  **המתנה מעגלית (Circular Wait):** מתקיים. P1 ממתין למשאב המוחזק על ידי P2, ו-P2 ממתין למשאב המוחזק על ידי P1. נוצר מעגל המתנה: P1 -> P2 -> P1.\n\n### סעיף 1.2: אסטרטגיה למניעת קיפאון ומימוש\n**אסטרטגיה למניעת קיפאון:** הזמנה סדרתית של משאבים (Resource Ordering).\nעל מנת למנוע קיפאון, נקבע סדר גלובלי לרכישת המשאבים. לדוגמה, כל התהליכים ירכשו תמיד את `mutex_X` לפני `mutex_Y`. גישה זו מבטלת את תנאי ההמתנה המעגלית.\n\n**מימוש הפונקציות:**\n```c\npthread_mutex_t mutex_X; // מגן על משאב X\npthread_mutex_t mutex_Y; // מגן על משאב Y\n\nvoid acquire_resources() {\n    pthread_mutex_lock(&mutex_X); // רוכש תמיד את מנעול X ראשון\n    pthread_mutex_lock(&mutex_Y); // רוכש את מנעול Y שני\n}\n\nvoid release_resources() {\n    pthread_mutex_unlock(&mutex_Y); // משחרר את מנעול Y (בסדר הפוך לרכישה)\n    pthread_mutex_unlock(&mutex_X); // משחרר את מנעול X (בסדר הפוך לרכישה)\n}\n```\n**הערה:** יש לשחרר את המנעולים בסדר הפוך לסדר הרכישה כדי למנוע מצבי מירוץ ולשחרר את המשאבים כראוי.\n\n### סעיף 1.3: ניתוח השפעת האסטרטגיה\n**ניתוח השפעת האסטרטגיה:**\n\n**מקביליות (Concurrency):** אסטרטגיה זו עלולה להפחית את רמת המקביליות במערכת. אם תהליכים רבים זקוקים למשאבים X ו-Y, הם יתחרו כולם על `mutex_X` תחילה. תהליך אחד ירכוש את `mutex_X`, ולאחר מכן את `mutex_Y`. רק לאחר שישחרר את שניהם, יוכל תהליך אחר לרכוש את `mutex_X`. ייתכנו מקרים שבהם `mutex_Y` פנוי, אך תהליך נאלץ להמתין לשחרור `mutex_X` לפני שיוכל לרכוש את `mutex_Y`.\n\n**ניצול משאבים (Resource Utilization):** ניצול המשאבים עלול להיפגע. אם תהליך רוכש את `mutex_X` וממתין זמן רב לרכישת `mutex_Y` (או להיפך, אם הסדר היה הפוך), `mutex_X` יהיה תפוס ללא שימוש יעיל בזמן ההמתנה. זה יכול להוביל למשאבים שאינם בשימוש למרות שהם זמינים, רק בגלל סדר הרכישה הכפוי.\n\n**חסרונות נוספים לגישה זו:**\n1.  **מורכבות ביישום ובאכיפה:** דורש הקפדה קפדנית על סדר הרכישה בכל מקום בקוד שבו נדרשים משאבים אלו. במידה ונוספים משאבים או משתנה הדרישה, יש לעדכן את סדר הרכישה הגלובלי, וכל סטייה מהסדר עלולה להחזיר את בעיית הקיפאון.\n2.  **קשיים בהרחבה (Scalability):** במערכות עם סוגי משאבים רבים, קביעת סדר גלובלי אופטימלי ויעיל יכולה להיות קשה מאוד או בלתי אפשרית לניהול.\n3.  **הגבלת גמישות:** מגביל את הגמישות של התהליכים ברכישת משאבים בהתאם לצרכים הספציפיים שלהם או לזמינות המשאבים, מה שעלול להפחית את היעילות במקרים מסוימים שבהם סדר שונה היה יעיל יותר."}, "difficulty_estimation": "Hard", "_source_file": "0402__Deadlocks__Open__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:18:38", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Deadlocks", "Synchronization", "Concurrency", "Mutexes"], "content": {"text": "נתונה מערכת מרובת חוטים המטפלת בהעברת נתונים בין שני מאגרים (buffers), `bufferA` ו-`bufferB`. לכל מאגר יש מנעול (mutex) משלו: `mutexA` עבור `bufferA` ו-`mutexB` עבור `bufferB`. חוטים שונים עשויים לנסות לגשת למאגרים אלו, כאשר חלקם זקוקים לגישה לשניהם בו-זמנית (לדוגמה, כדי להעביר נתונים מ-A ל-B או מ-B ל-A).\nהקוד הבא מדגים שתי פונקציות, `transfer_A_to_B` ו-`transfer_B_to_A`, המנסות להעביר נתונים בין המאגרים. שימו לב לסדר נעילת המנעולים בכל פונקציה.\n\n1.  **זיהוי בעיה:** האם קיים תרחיש שבו המערכת המתוארת עלולה להיכנס למצב של קיפאון (Deadlock)? אם כן, תארו את התרחיש הספציפי והסבירו אילו מהתנאים ההכרחיים לקיפאון (Mutual Exclusion, Hold and Wait, No Preemption, Circular Wait) מתקיימים במקרה זה.\n2.  **פתרון:** הציעו שינוי בקוד או אסטרטגיה שתמנע את הקיפאון. יש להציג את השינויים בקוד (אם רלוונטי) או לתאר בבירור את האסטרטגיה.\n3.  **הוכחת נכונות:** הסבירו מדוע הפתרון שהצעתם מונע קיפאון, ואיזה מהתנאים ההכרחיים לקיפאון הוא מפר.", "code_snippet": "```c\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutexA;\npthread_mutex_t mutexB;\n\nvoid transfer_A_to_B() {\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread %lu acquired mutexA in A_to_B.\\n\", pthread_self());\n    // Simulate work or data transfer\n    sleep(1);\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread %lu acquired mutexB in A_to_B.\\n\", pthread_self());\n    // Perform data transfer from A to B\n    printf(\"Thread %lu performing A_to_B transfer.\\n\", pthread_self());\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread %lu released both mutexes in A_to_B.\\n\", pthread_self());\n}\n\nvoid transfer_B_to_A() {\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread %lu acquired mutexB in B_to_A.\\n\", pthread_self());\n    // Simulate work or data transfer\n    sleep(1);\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread %lu acquired mutexA in B_to_A.\\n\", pthread_self());\n    // Perform data transfer from B to A\n    printf(\"Thread %lu performing B_to_A transfer.\\n\", pthread_self());\n    pthread_mutex_unlock(&mutexA);\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread %lu released both mutexes in B_to_A.\\n\", pthread_self());\n}\n\n/* Example main function to demonstrate:\nint main() {\n    pthread_mutex_init(&mutexA, NULL);\n    pthread_mutex_init(&mutexB, NULL);\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, (void*(*)(void*))transfer_A_to_B, NULL);\n    pthread_create(&t2, NULL, (void*(*)(void*))transfer_B_to_A, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    pthread_mutex_destroy(&mutexA);\n    pthread_mutex_destroy(&mutexB);\n    return 0;\n}\n*/\n```", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "1.  **זיהוי בעיה:**\n    כן, קיים תרחיש קיפאון.\n    **תרחיש:**\n    נניח ששני חוטים, T1 ו-T2, מופעלים במקביל:\n    *   T1 קורא ל-`transfer_A_to_B()`\n    *   T2 קורא ל-`transfer_B_to_A()`\n    *   **שלב 1:** T1 מבצע `pthread_mutex_lock(&mutexA)` ומצליח לנעול את `mutexA`.\n    *   **שלב 2:** T2 מבצע `pthread_mutex_lock(&mutexB)` ומצליח לנעול את `mutexB`.\n    *   **שלב 3:** T1 מנסה כעת לבצע `pthread_mutex_lock(&mutexB)`. הוא נחסם מכיוון ש-`mutexB` נעול על ידי T2.\n    *   **שלב 4:** T2 מנסה כעת לבצע `pthread_mutex_lock(&mutexA)`. הוא נחסם מכיוון ש-`mutexA` נעול על ידי T1.\n    בנקודה זו, T1 ממתין ל-`mutexB` שנעול על ידי T2, ו-T2 ממתין ל-`mutexA` שנעול על ידי T1. אף אחד מהם לא יכול להמשיך, והמערכת נכנסת לקיפאון.\n\n    **תנאי קיפאון:**\n    *   **מניעה הדדית (Mutual Exclusion):** מתקיים. המנעולים (`mutexA`, `mutexB`) מאפשרים רק לחוט אחד להחזיק בהם בכל רגע נתון.\n    *   **החזק והמתן (Hold and Wait):** מתקיים. T1 מחזיק ב-`mutexA` וממתין ל-`mutexB`. T2 מחזיק ב-`mutexB` וממתין ל-`mutexA`.\n    *   **אי-הפקעה (No Preemption):** מתקיים. המנעולים לא ניתנים להפקעה מחוט שמחזיק בהם; רק החוט עצמו יכול לשחרר אותם.\n    *   **המתנה מעגלית (Circular Wait):** מתקיים. T1 ממתין למשאב שמוחזק על ידי T2, ו-T2 ממתין למשאב שמוחזק על ידי T1, יוצר מעגל המתנה.\n\n2.  **פתרון:**\n    הדרך הנפוצה והפשוטה ביותר למנוע קיפאון במקרה זה היא להבטיח **סדר קבוע של נעילת המשאבים**. כלומר, כל החוטים שזקוקים למספר משאבים ינעלו אותם תמיד באותו סדר. בדוגמה זו, נחליט שכל החוטים ינעלו תמיד את `mutexA` לפני `mutexB`.\n\n    **שינויים בקוד:**\n    ```c\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutexA;\npthread_mutex_t mutexB;\n\nvoid transfer_A_to_B_fixed_order() {\n    pthread_mutex_lock(&mutexA); // Acquire mutexA first\n    printf(\"Thread %lu acquired mutexA in A_to_B_fixed_order.\\n\", pthread_self());\n    sleep(1);\n    pthread_mutex_lock(&mutexB); // Then acquire mutexB\n    printf(\"Thread %lu acquired mutexB in A_to_B_fixed_order.\\n\", pthread_self());\n    // Perform data transfer from A to B\n    printf(\"Thread %lu performing A_to_B transfer.\\n\", pthread_self());\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread %lu released both mutexes in A_to_B_fixed_order.\\n\", pthread_self());\n}\n\nvoid transfer_B_to_A_fixed_order() {\n    pthread_mutex_lock(&mutexA); // Acquire mutexA first, even if it's for B_to_A\n    printf(\"Thread %lu acquired mutexA in B_to_A_fixed_order.\\n\", pthread_self());\n    sleep(1);\n    pthread_mutex_lock(&mutexB); // Then acquire mutexB\n    printf(\"Thread %lu acquired mutexB in B_to_A_fixed_order.\\n\", pthread_self());\n    // Perform data transfer from B to A\n    printf(\"Thread %lu performing B_to_A transfer.\\n\", pthread_self());\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread %lu released both mutexes in B_to_A_fixed_order.\\n\", pthread_self());\n}\n    ```\n\n3.  **הוכחת נכונות:**\n    הפתרון מונע קיפאון על ידי הפרת התנאי של **המתנה מעגלית (Circular Wait)**.\n    כאשר כל החוטים מקפידים על סדר קבוע של נעילת המשאבים (לדוגמה, תמיד `mutexA` ואז `mutexB`), לא ייתכן שחוט אחד (T1) יחזיק ב-`mutexA` וימתין ל-`mutexB`, ובאותו זמן חוט אחר (T2) יחזיק ב-`mutexB` וימתין ל-`mutexA`.\n    אם חוט T1 תופס את `mutexA`, וחוט T2 מנסה לתפוס את `mutexA`, T2 ייחסם. T2 לא יוכל לתפוס את `mutexB` לפני `mutexA` (לפי הכלל החדש של סדר קבוע), ולכן לא יכול להיווצר המצב שבו T2 מחזיק ב-`mutexB` בזמן ש-T1 ממתין לו. הסדר הקבוע מבטיח היררכיה של נעילת משאבים, ובכך מונע היווצרות של מעגל המתנה."}, "difficulty_estimation": "Hard", "_source_file": "0403__Deadlocks__Open__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:47:16", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Deadlocks", "Synchronization", "Resource Management", "Concurrency"], "content": {"text": "במערכת מרובת תהליכונים (threads), קיפאון (deadlock) הוא מצב קריטי שיש למנוע או לטפל בו. שאלה זו בוחנת את הבנתך בגורמים לקיפאון ובדרכים למנוע אותו, תוך התייחסות לתרחיש ספציפי ומימוש קוד.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "a", "text": "תאר בקצרה את ארבעת התנאים ההכרחיים להתרחשות קיפאון במערכת.", "code_snippet": null, "options": null}, {"id": "b", "text": "נתונה מערכת עם שני משאבים משותפים, `ResourceA` ו-`ResourceB`, כאשר כל אחד מהם מוגן על ידי מנעול (mutex) נפרד. במערכת פועלים מספר תהליכוני עבודה (worker threads), וכל תהליכון זקוק לשניהם, `ResourceA` ו-`ResourceB`, כדי לבצע את משימתו. תאר תרחיש ספציפי (באמצעות רצף פעולות או פסאודו-קוד) שבו יכול להתרחש קיפאון במערכת זו. הסבר מדוע תרחיש זה מוביל לקיפאון תוך התייחסות לארבעת התנאים שתיארת בסעיף א'.", "code_snippet": null, "options": null}, {"id": "c", "text": "בהתבסס על התרחיש שתואר בסעיף ב', כתוב פונקציית C/C++ בשם `acquire_both_resources()` המקבלת מצביעים למנעולים של `ResourceA` ו-`ResourceB` (לדוגמה, `pthread_mutex_t*`). הפונקציה צריכה לרכוש את שני המשאבים באופן בטוח, כך שתמנע את הקיפאון שתואר. עליך להשתמש במנעולי `pthread_mutex_t` בלבד. אין לשנות את סדר הרכישה של המנעולים בתוך הפונקציה (כלומר, `ResourceA` ואז `ResourceB`), אך מותר להשתמש בפונקציות נעילה לא חוסמות (לדוגמה, `pthread_mutex_trylock`).", "code_snippet": "void acquire_both_resources(pthread_mutex_t* resA_mutex, pthread_mutex_t* resB_mutex) {\n    // Implement your solution here\n}", "options": null}, {"id": "d", "text": "הסבר איזו אסטרטגיה למניעת קיפאון (Deadlock Prevention) או הימנעות מקיפאון (Deadlock Avoidance) יישמת בסעיף ג'. דון ביתרונות ובחסרונות של אסטרטגיה זו, לרבות השלכותיה על ביצועי המערכת (לדוגמה, רעב או ניצול משאבים).", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. ארבעת התנאים ההכרחיים לקיפאון:\n1.  **מניעה הדדית (Mutual Exclusion):** לפחות משאב אחד חייב להיות בלעדי, כלומר, רק תהליך אחד יכול להשתמש בו בכל רגע נתון. אם תהליך אחר מבקש את המשאב, עליו להמתין עד שהתהליך הראשון ישחרר אותו.\n2.  **החזקה והמתנה (Hold and Wait):** תהליך חייב להחזיק לפחות במשאב אחד ובמקביל לבקש משאבים נוספים המוחזקים על ידי תהליכים אחרים.\n3.  **אי-שלילה (No Preemption):** משאבים אינם ניתנים לשלילה בכוח. הם יכולים להשתחרר רק באופן וולונטרי על ידי התהליך שמחזיק בהם, לאחר שסיים את השימוש בהם.\n4.  **המתנה מעגלית (Circular Wait):** קיימת שרשרת מעגלית של שניים או יותר תהליכים, כאשר כל תהליך בשרשרת ממתין למשאב המוחזק על ידי התהליך הבא בשרשרת.\n\nב. תרחיש קיפאון:\nנניח שיש שני תהליכונים, Thread 0 ו-Thread 1.\nהתרחיש הבא יכול להוביל לקיפאון:\n1.  Thread 0 רוכש את `ResourceA`.\n    (`pthread_mutex_lock(&mutexA);`)\n2.  Thread 1 רוכש את `ResourceB`.\n    (`pthread_mutex_lock(&mutexB);`)\n3.  Thread 0 מנסה לרכוש את `ResourceB`. הוא נחסם מכיוון ש-Thread 1 מחזיק בו.\n    (`pthread_mutex_lock(&mutexB);` - Thread 0 נחסם)\n4.  Thread 1 מנסה לרכוש את `ResourceA`. הוא נחסם מכיוון ש-Thread 0 מחזיק בו.\n    (`pthread_mutex_lock(&mutexA);` - Thread 1 נחסם)\n\n**הסבר מדוע תרחיש זה מוביל לקיפאון:**\n*   **מניעה הדדית:** מתקיימת עבור `mutexA` ו-`mutexB`, שכן רק תהליכון אחד יכול להחזיק בכל מנעול בכל רגע נתון.\n*   **החזקה והמתנה:** Thread 0 מחזיק ב-`mutexA` וממתין ל-`mutexB`. Thread 1 מחזיק ב-`mutexB` וממתין ל-`mutexA`.\n*   **אי-שלילה:** המנעולים אינם נשללים בכוח. הם ישוחררו רק כאשר התהליכונים יחליטו לשחרר אותם (וזה לא יקרה כי הם חסומים).\n*   **המתנה מעגלית:** נוצרה שרשרת המתנה מעגלית: Thread 0 ממתין למשאב ש-Thread 1 מחזיק בו (`mutexB`), ו-Thread 1 ממתין למשאב ש-Thread 0 מחזיק בו (`mutexA`).\n\nכל ארבעת התנאים מתקיימים, ולכן המערכת נמצאת בקיפאון.\n\nג. מימוש פונקציית `acquire_both_resources()`:\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\nvoid acquire_both_resources(pthread_mutex_t* resA_mutex, pthread_mutex_t* resB_mutex) {\n    while (1) { // Keep trying until both resources are acquired\n        // Try to acquire ResourceA\n        int resA_locked = pthread_mutex_trylock(resA_mutex);\n\n        if (resA_locked == 0) { // Successfully acquired ResourceA\n            // Try to acquire ResourceB\n            int resB_locked = pthread_mutex_trylock(resB_mutex);\n            if (resB_locked == 0) { // Successfully acquired ResourceB\n                // Both resources acquired, exit loop\n                return;\n            } else { // Could not acquire ResourceB\n                // Release ResourceA and retry\n                pthread_mutex_unlock(resA_mutex);\n                // Optional: Add a small delay to avoid busy-waiting or to allow other threads to progress\n                usleep(1000); // Sleep for 1ms\n            }\n        } else { // Could not acquire ResourceA\n            // Optional: Add a small delay\n            usleep(1000); // Sleep for 1ms\n        }\n    }\n}\n```\n\nד. אסטרטגיה, יתרונות וחסרונות:\nהאסטרטגיה שיושמה היא וריאציה של **מניעת קיפאון (Deadlock Prevention)**, ובפרט, שבירת התנאי של **החזקה והמתנה (Hold and Wait)**.\nבמקום לאפשר לתהליך להחזיק במשאבים שכבר רכש בזמן שהוא ממתין למשאבים נוספים, הפונקציה `acquire_both_resources` מנסה לרכוש את כל המשאבים הנדרשים (במקרה זה, שניים) בו-זמנית או לשחרר את כל המשאבים שכבר נרכשו אם לא ניתן לרכוש את כולם.\nבמקרה הספציפי של המימוש, אם תהליכון מצליח לרכוש את `ResourceA` אך נכשל ברכישת `ResourceB` (כי הוא מוחזק על ידי תהליכון אחר), הוא משחרר את `ResourceA` שהחזיק בו ומנסה שוב. זה מבטיח שאף תהליכון לא יחזיק במשאב אחד וימתין לאחר, ובכך נמנעת ההמתנה המעגלית שמובילה לקיפאון.\n\n**יתרונות:**\n*   **מניעת קיפאון מובטחת:** המנגנון מבטיח שאף תהליכון לא יחזיק במשאב אחד וימתין למשאב אחר, ובכך מונע את התנאי של Hold and Wait ואת הקיפאון.\n*   **פשטות יחסית ליישום:** עבור מספר קטן של משאבים, כמו במקרה זה, קל יחסית ליישם את הלוגיקה של ניסיון רכישה ושחרור.\n\n**חסרונות:**\n*   **רעב (Starvation) פוטנציאלי:** ייתכן שתהליכון מסוים ינסה שוב ושוב לרכוש את המשאבים, אך תמיד ייכשל (לדוגמה, אם יש עומס רב ותהליכונים אחרים תמיד מצליחים לרכוש לפניו). הוספת `usleep()` עוזרת להפחית את הצריכה של CPU אך לא מונעת רעב לחלוטין.\n*   **חוסר יעילות / בזבוז משאבים (Resource Utilization):** המשאבים שנרכשו ונשחררו מיד (כמו `ResourceA` בתרחיש שבו `ResourceB` לא זמין) אינם מנוצלים ביעילות. תהליכון עלול לבצע פעולות רכישה ושחרור רבות לפני שיצליח לרכוש את כל המשאבים הדרושים.\n*   **עלויות ביצועים (Performance Overhead):** השימוש ב-`pthread_mutex_trylock` בלולאה, יחד עם השחרור והניסיון החוזר, יכול להוביל לצריכת CPU גבוהה (busy-waiting) אם המשאבים תפוסים לפרקי זמן ארוכים. הוספת `usleep` מקטינה את הצריכה אך מגדילה את זמן ההמתנה.\n*   **מורכבות עם מספר רב של משאבים:** עבור מספר גדול של משאבים, יישום לוגיקה זו הופך למורכב יותר (לדוגמה, צורך לשחרר מספר משאבים שנרכשו חלקית) ופחות יעיל."}, "difficulty_estimation": "Hard", "_source_file": "0404__Deadlocks__Open__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:19:50", "_subject": "Concurrency"}, {"id": 101, "type": "Open", "topic": ["Deadlocks", "Resource Management", "Banker's Algorithm"], "content": {"text": "נתונה מערכת הפעלה המנהלת שלושה סוגי משאבים: R1, R2, R3. מספר היחידות הכולל מכל סוג משאב הוא: R1=10, R2=5, R3=7.\nבמערכת פועלים ארבעה תהליכים: P0, P1, P2, P3.\nלהלן טבלת הקצאת המשאבים הנוכחית (Allocation) וטבלת הדרישה המקסימלית (Max) של כל תהליך:\n\n**Allocation:**\n| Process | R1 | R2 | R3 |\n|---------|----|----|----|\n| P0      | 0  | 1  | 0  |\n| P1      | 2  | 0  | 0  |\n| P2      | 3  | 0  | 2  |\n| P3      | 2  | 1  | 1  |\n\n**Max:**\n| Process | R1 | R2 | R3 |\n|---------|----|----|----|\n| P0      | 7  | 5  | 3  |\n| P1      | 3  | 2  | 2  |\n| P2      | 9  | 0  | 2  |\n| P3      | 2  | 2  | 2  |\n\nענו על השאלות הבאות בהתבסס על אלגוריתם הבנקאי:", "code_snippet": null, "options": null}, "sub_questions": [{"id": "a", "text": "מהו מצב המשאבים הזמינים כרגע (Available)? האם המצב הנוכחי בטוח? אם כן, הציגו רצף בטוח.", "code_snippet": null, "options": null}, {"id": "b", "text": "נניח שתהליך P1 מבקש משאבים נוספים: (R1=1, R2=0, R3=2). האם ניתן לאשר בקשה זו באופן מיידי? נמקו את תשובתכם.", "code_snippet": null, "options": null}, {"id": "c", "text": "דון במגבלות של אלגוריתם הבנקאי ביישום במערכת הפעלה אמיתית.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "חלק 1: בטיחות המצב ההתחלתי\n\nראשית, נחשב את וקטור המשאבים הזמינים (Available) ואת מטריצת הדרישה (Need).\nסה\"כ משאבים: R1=10, R2=5, R3=7.\nסה\"כ משאבים מוקצים (Allocation Sum):\nR1: 0+2+3+2 = 7\nR2: 1+0+0+1 = 2\nR3: 0+0+2+1 = 3\nוקטור המשאבים המוקצים = (7, 2, 3).\nוקטור המשאבים הזמינים (Available) = סה\"כ משאבים - וקטור המשאבים המוקצים = (10, 5, 7) - (7, 2, 3) = **(3, 3, 4)**.\n\nמטריצת הדרישה (Need = Max - Allocation):\nP0: (7, 5, 3) - (0, 1, 0) = (7, 4, 3)\nP1: (3, 2, 2) - (2, 0, 0) = (1, 2, 2)\nP2: (9, 0, 2) - (3, 0, 2) = (6, 0, 0)\nP3: (2, 2, 2) - (2, 1, 1) = (0, 1, 1)\n\nנפעיל את אלגוריתם הבנקאי לבדיקת בטיחות המצב:\nWork = (3, 3, 4), Finish = [False, False, False, False]\n\n1.  **תהליך P1**: Need(P1)=(1,2,2) <= Work(3,3,4). כן.\n    Work = Work + Allocation(P1) = (3,3,4) + (2,0,0) = (5,3,4)\n    Finish[1] = True\n    רצף בטוח עד כה: <P1>\n\n2.  **תהליך P3**: Need(P3)=(0,1,1) <= Work(5,3,4). כן.\n    Work = Work + Allocation(P3) = (5,3,4) + (2,1,1) = (7,4,5)\n    Finish[3] = True\n    רצף בטוח עד כה: <P1, P3>\n\n3.  **תהליך P0**: Need(P0)=(7,4,3) <= Work(7,4,5). כן.\n    Work = Work + Allocation(P0) = (7,4,5) + (0,1,0) = (7,5,5)\n    Finish[0] = True\n    רצף בטוח עד כה: <P1, P3, P0>\n\n4.  **תהליך P2**: Need(P2)=(6,0,0) <= Work(7,5,5). כן.\n    Work = Work + Allocation(P2) = (7,5,5) + (3,0,2) = (10,5,7)\n    Finish[2] = True\n    רצף בטוח סופי: <P1, P3, P0, P2>\n\nמכיוון שנמצא רצף בטוח שבו כל התהליכים יכולים להשלים את ביצועם, **המצב הנוכחי בטוח**.\n\nחלק 2: בקשת משאבים נוספים מ-P1\n\nתהליך P1 מבקש משאבים נוספים: Request(P1) = (1, 0, 2).\nמצב נוכחי: Available = (3, 3, 4), Allocation(P1) = (2, 0, 0), Need(P1) = (1, 2, 2).\n\nנבדוק את תנאי הבקשה:\n1.  האם Request(P1) <= Need(P1)? כלומר, (1,0,2) <= (1,2,2)? כן (1<=1, 0<=2, 2<=2). הבקשה אינה חורגת מהדרישה המקסימלית שהתהליך הצהיר עליה.\n2.  האם Request(P1) <= Available? כלומר, (1,0,2) <= (3,3,4)? כן (1<=3, 0<=3, 2<=4). יש מספיק משאבים זמינים כדי לספק את הבקשה.\n\nמכיוון ששני התנאים מתקיימים, נדמה הקצאה ונבדוק שוב את בטיחות המצב:\nAvailable' = Available - Request(P1) = (3,3,4) - (1,0,2) = (2,3,2)\nAllocation'(P1) = Allocation(P1) + Request(P1) = (2,0,0) + (1,0,2) = (3,0,2)\nNeed'(P1) = Need(P1) - Request(P1) = (1,2,2) - (1,0,2) = (0,2,0)\n\nמטריצת Need המעודכנת:\nP0: (7, 4, 3)\nP1: (0, 2, 0)\nP2: (6, 0, 0)\nP3: (0, 1, 1)\n\nנפעיל את אלגוריתם הבנקאי עם המצב החדש:\nWork = (2, 3, 2), Finish = [False, False, False, False]\n\n1.  **תהליך P1**: Need(P1)=(0,2,0) <= Work(2,3,2). כן.\n    Work = Work + Allocation'(P1) = (2,3,2) + (3,0,2) = (5,3,4)\n    Finish[1] = True\n    רצף בטוח עד כה: <P1>\n\n2.  **תהליך P3**: Need(P3)=(0,1,1) <= Work(5,3,4). כן.\n    Work = Work + Allocation(P3) = (5,3,4) + (2,1,1) = (7,4,5)\n    Finish[3] = True\n    רצף בטוח עד כה: <P1, P3>\n\n3.  **תהליך P0**: Need(P0)=(7,4,3) <= Work(7,4,5). כן.\n    Work = Work + Allocation(P0) = (7,4,5) + (0,1,0) = (7,5,5)\n    Finish[0] = True\n    רצף בטוח עד כה: <P1, P3, P0>\n\n4.  **תהליך P2**: Need(P2)=(6,0,0) <= Work(7,5,5). כן.\n    Work = Work + Allocation(P2) = (7,5,5) + (3,0,2) = (10,5,7)\n    Finish[2] = True\n    רצף בטוח סופי: <P1, P3, P0, P2>\n\nמכיוון שגם לאחר הקצאת המשאבים לבקשת P1 נמצא רצף בטוח, **ניתן לאשר את הבקשה באופן מיידי**.\n\nחלק 3: מגבלות אלגוריתם הבנקאי במערכת הפעלה אמיתית\n\nאלגוריתם הבנקאי הוא יעיל במניעת קיפאון (deadlock), אך יש לו מספר מגבלות המקשות על יישומו במערכות הפעלה אמיתיות:\n\n1.  **ידיעה מוקדמת של דרישות מקסימליות (Max Needs)**: כל תהליך חייב להצהיר מראש על הדרישה המקסימלית שלו לכל סוג משאב. במקרים רבים, תהליכים אינם יודעים מראש את כל דרישות המשאבים שלהם לאורך כל זמן הריצה.\n2.  **מספר קבוע של תהליכים ומשאבים**: האלגוריתם מניח מספר קבוע של תהליכים ומספר קבוע של יחידות מכל סוג משאב. במערכת הפעלה דינמית, תהליכים נוצרים ומסתיימים כל הזמן, וייתכן שגם משאבים מתווספים או מוסרים. שינויים אלו דורשים עדכון מתמיד של מצב המערכת, מה שמסבך את היישום.\n3.  **שחרור משאבים בסיום**: ההנחה היא שתהליך משחרר את כל המשאבים שהוקצו לו בסיום ביצועו. למרות שזה נכון בדרך כלל, ישנם תהליכים ארוכי טווח שעשויים להחזיק משאבים לזמן רב.\n4.  **תקורה חישובית גבוהה**: בדיקת הבטיחות (Safety Algorithm) צריכה להתבצע בכל פעם שתהליך מבקש משאבים. במערכות עם מספר רב של תהליכים וסוגי משאבים, הדבר עלול להוביל לתקורה חישובית משמעותית ולפגוע בביצועי המערכת.\n5.  **רעב (Starvation)**: למרות שהאלגוריתם מונע קיפאון, הוא אינו מונע בהכרח רעב. תהליך בעל דרישות משאבים גבוהות עלול להידחות שוב ושוב אם הקצאת המשאבים עבורו תוביל למצב לא בטוח, גם אם המשאבים זמינים באופן תיאורטי."}, "difficulty_estimation": "Hard", "_source_file": "0405__Deadlocks__Open__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:20:26", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Deadlocks", "Synchronization", "Resource Management", "Concurrency"], "content": {"text": "נתונה מערכת הפעלה שבה מספר רב של תהליכים ניגשים למספר סוגים שונים של משאבים. נניח שישנם M סוגי משאבים, המסומנים R0, R1, ..., RM-1. לכל סוג משאב יש מופע יחיד (לדוגמה, מדפסת ספציפית, סורק ספציפי). תהליכים צריכים לרכוש גישה למשאבים אלו כדי לבצע את עבודתם. המערכת משתמשת במנעולים (mutexes) כדי להבטיח מניעה הדדית לכל מופע משאב. נתון קטע הקוד הבא המדגים רכישת משאבים על ידי תהליך, כאשר הסדר שבו התהליך רוכש את המשאבים הוא שרירותי:\n\n```c\n// M הוא מספר סוגי המשאבים הכולל במערכת\npthread_mutex_t resource_locks[M]; // מערך מנעולים, אחד לכל סוג משאב\n\nvoid acquire_resources_arbitrary(int resource1_type_id, int resource2_type_id) {\n    // תהליך רוכש משאב ראשון\n    pthread_mutex_lock(&resource_locks[resource1_type_id]);\n    printf(\"Acquired R%d\\n\", resource1_type_id);\n\n    // תהליך רוכש משאב שני\n    pthread_mutex_lock(&resource_locks[resource2_type_id]);\n    printf(\"Acquired R%d\\n\", resource2_type_id);\n\n    // ... שימוש במשאבים ...\n\n    // שחרור משאבים (בסדר הפוך לרכישה, או בכל סדר)\n    pthread_mutex_unlock(&resource_locks[resource2_type_id]);\n    pthread_mutex_unlock(&resource_locks[resource1_type_id]);\n}\n```\n\n1.  הסבירו כיצד מצב של קיפאון (Deadlock) יכול להתרחש במערכת זו. תארו תרחיש ספציפי הכולל שני תהליכים ושני סוגי משאבים (לדוגמה, R0 ו-R1) כדי להדגים את הקיפאון.\n\n2.  הציעו פתרון למניעת קיפאון במערכת זו, על ידי שינוי אופן רכישת המשאבים. ספקו מימוש קוד ב-C/C++ (או פסאודו-קוד) המדגים את הפתרון שלכם, והסבירו איזו משלוש התכונות ההכרחיות לקיפאון נשברת על ידי הפתרון.\n\n3.  דונו בשני חסרונות פוטנציאליים של הפתרון שהצעתם (לדוגמה, השפעה על מקביליות, רעב).", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  **הסבר לקיפאון:**\n    מצב של קיפאון (deadlock) יכול להתרחש במערכת זו כאשר מתקיימים ארבעת התנאים ההכרחיים לקיפאון: מניעה הדדית, החזקה והמתנה, אי-יכולת לדרוס, והמתנה מעגלית.\n    *   **מניעה הדדית (Mutual Exclusion):** תנאי זה מתקיים, שכן כל מופע משאב מוגן על ידי מנעול (mutex), ורק תהליך אחד יכול להחזיק בו זמנית מנעול על משאב ספציפי.\n    *   **החזקה והמתנה (Hold and Wait):** תנאי זה מתקיים, שכן תהליך יכול להחזיק במשאב אחד (על ידי נעילת המוטקס שלו) ובמקביל להמתין לרכישת משאב נוסף (על ידי ניסיון לנעול מוטקס אחר).\n    *   **אי-יכולת לדרוס (No Preemption):** תנאי זה מתקיים, שכן משאבים אינם נלקחים מתהליכים בכוח; הם משוחררים רק מרצון על ידי התהליך שהחזיק בהם.\n    *   **המתנה מעגלית (Circular Wait):** זהו התנאי שעלול להיווצר כתוצאה מהרכישה השרירותית של המשאבים. אם תהליך A רוכש את R_i וממתין ל-R_j, ובמקביל תהליך B רוכש את R_j וממתין ל-R_i, נוצר מעגל המתנה שבו כל תהליך ממתין למשאב המוחזק על ידי התהליך הבא במעגל.\n\n    **תרחיש ספציפי לקיפאון (שני תהליכים, שני משאבים R0, R1):**\n    נניח שיש לנו שני תהליכים, `P1` ו-`P2`, ושני סוגי משאבים `R0` ו-`R1`. שני התהליכים מנסים לרכוש את שני המשאבים.\n    1.  `P1` קורא ל-`acquire_resources_arbitrary(0, 1)`. הוא מבצע `pthread_mutex_lock(&resource_locks[0])` ורוכש את `R0`.\n    2.  מיד לאחר מכן (לפני ש-`P1` רוכש את `R1`), `P2` קורא ל-`acquire_resources_arbitrary(1, 0)`. הוא מבצע `pthread_mutex_lock(&resource_locks[1])` ורוכש את `R1`.\n    3.  כעת, `P1` מנסה לבצע `pthread_mutex_lock(&resource_locks[1])`. `R1` מוחזק על ידי `P2`, ולכן `P1` נחסם וממתין.\n    4.  במקביל, `P2` מנסה לבצע `pthread_mutex_lock(&resource_locks[0])`. `R0` מוחזק על ידי `P1`, ולכן `P2` נחסם וממתין.\n    בשלב זה, `P1` מחזיק ב-`R0` וממתין ל-`R1`, ו-`P2` מחזיק ב-`R1` וממתין ל-`R0`. נוצרה המתנה מעגלית, ושני התהליכים נמצאים בקיפאון.\n\n2.  **פתרון למניעת קיפאון (רכישה בסדר קבוע):**\n    כדי למנוע קיפאון, ניתן לשבור את תנאי ה**המתנה מעגלית** (Circular Wait). הדרך הנפוצה לעשות זאת היא על ידי הטלת סדר גלובלי (Total Ordering) על כל סוגי המשאבים. כלומר, תהליכים חייבים לרכוש משאבים תמיד בסדר עולה (או יורד) של מזהי המשאבים שלהם. לדוגמה, אם יש לנו `M` סוגי משאבים עם מזהים מ-0 עד `M-1`, תהליך שזקוק למשאבים `R_i` ו-`R_j` ירכוש תמיד את המשאב בעל המזהה הנמוך יותר תחילה.\n\n    **מימוש קוד ב-C/C++:**\n    ```c\n    // M הוא מספר סוגי המשאבים הכולל במערכת\n    pthread_mutex_t resource_locks[M]; // מערך מנעולים, אחד לכל סוג משאב\n\n    // פונקציה כללית לרכישת מערך של משאבים בסדר קבוע\n    // resource_types הוא מערך של מזהי סוגי המשאבים הנדרשים\n    // count הוא מספר המשאבים במערך resource_types\n    void acquire_multiple_resources_ordered(int* resource_types, int count) {\n        // צור עותק של המזהים ומין אותם בסדר עולה\n        int* sorted_resource_types = (int*)malloc(sizeof(int) * count);\n        for (int i = 0; i < count; i++) {\n            sorted_resource_types[i] = resource_types[i];\n        }\n\n        // מיון פשוט (לדוגמה, מיון בועות) יכול לשמש כאן\n        for (int i = 0; i < count - 1; i++) {\n            for (int j = i + 1; j < count; j++) {\n                if (sorted_resource_types[i] > sorted_resource_types[j]) {\n                    int temp = sorted_resource_types[i];\n                    sorted_resource_types[i] = sorted_resource_types[j];\n                    sorted_resource_types[j] = temp;\n                }\n            }\n        }\n\n        // רכוש את המשאבים בסדר הממוין\n        for (int i = 0; i < count; i++) {\n            // הימנע מרכישה כפולה אם יש מזהים זהים במערך הממוין (לאחר מיון ובמקרה של קלט עם כפילויות)\n            if (i > 0 && sorted_resource_types[i] == sorted_resource_types[i-1]) {\n                continue;\n            }\n            pthread_mutex_lock(&resource_locks[sorted_resource_types[i]]);\n            printf(\"Acquired R%d\\n\", sorted_resource_types[i]);\n        }\n\n        // ... שימוש במשאבים ...\n\n        // שחרור משאבים בסדר הפוך לרכישה (מומלץ לשחרור נכון של המנעולים)\n        for (int i = count - 1; i >= 0; i--) {\n            if (i < count - 1 && sorted_resource_types[i] == sorted_resource_types[i+1]) {\n                continue;\n            }\n            pthread_mutex_unlock(&resource_locks[sorted_resource_types[i]]);\n            printf(\"Released R%d\\n\", sorted_resource_types[i]);\n        }\n        free(sorted_resource_types);\n    }\n    ```\n\n    **איזו תכונה נשברת:**\n    הפתרון שובר את תנאי ה**המתנה מעגלית** (Circular Wait). על ידי אכיפת סדר גלובלי לרכישת משאבים, לא ניתן ליצור שרשרת המתנה מעגלית. אם תהליך A מחזיק ב-R_i וממתין ל-R_j, ו-R_i < R_j, אז תהליך B לא יכול להחזיק ב-R_j ולהמתין ל-R_i, מכיוון שהוא יצטרך לרכוש את R_i (שהוא בעל מזהה נמוך יותר) לפני שיוכל לרכוש את R_j. כלומר, לא ייתכן מצב שבו תהליך P1 מחכה ל-Rj שמוחזק על ידי P2, ותהליך P2 מחכה ל-Ri שמוחזק על ידי P1, כאשר Ri < Rj. לכן, כל שרשרת המתנה תהיה ליניארית ולא מעגלית, ובכך נמנע קיפאון.\n\n3.  **חסרונות פוטנציאליים של הפתרון:**\n    *   **הפחתת מקביליות (Reduced Concurrency):** הטלת סדר גלובלי על רכישת משאבים עלולה להפחית את רמת המקביליות במערכת. תהליך שזקוק למשאב בעל מזהה גבוה (לדוגמה, R_M-1) אך גם למשאב בעל מזהה נמוך (לדוגמה, R0) חייב לרכוש קודם את R0. אם R0 מוחזק על ידי תהליך אחר, התהליך הראשון ייאלץ להמתין, גם אם R_M-1 פנוי וזמין לשימוש. זה עלול לגרום לתהליכים להחזיק משאבים לזמן ארוך יותר ממה שהיה נחוץ באמת, או להמתין זמן רב למשאבים פנויים, ובכך להפחית את ניצולת המשאבים הכוללת ואת ביצועי המערכת.\n    *   **פוטנציאל לרעב (Potential for Starvation):** למרות שהפתרון מונע קיפאון, הוא עלול לגרום לרעב (starvation) במקרים מסוימים. תהליך שדורש משאבים רבים בעלי מזהים נמוכים מאוד, או משאב בעל מזהה נמוך במיוחד שנמצא בשימוש תדיר, עלול להיתקל בקשיים תמידיים ברכישת המשאבים הללו ולהידחק הצידה שוב ושוב על ידי תהליכים אחרים. לדוגמה, תהליך שזקוק ל-R0 יחכה זמן רב אם ישנם תהליכים רבים אחרים שרוכשים ומשחררים את R0 כל הזמן, גם אם הוא זקוק רק ל-R0 ול-R_M-1, בעוד R_M-1 פנוי. זה אמנם אינו קיפאון, אך עדיין מונע מהתהליך להתקדם בביצועו ללא הגבלת זמן."}, "difficulty_estimation": "Hard", "_source_file": "0406__Deadlocks__Open__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:21:01", "_subject": "Concurrency"}, {"id": 101, "type": "Open", "topic": ["Deadlocks", "Concurrency", "Synchronization", "Mutexes"], "content": {"text": "נתונה מערכת בנקאית הממומשת באמצעות קוד C++ כפי שמוצג להלן. המערכת מאפשרת העברת כספים בין חשבונות שונים. כל חשבון מוגן על ידי מנעול (mutex) משלו כדי להבטיח עקביות במהלך טרנזקציות. פונקציית `transfer` מקבלת מזהי חשבון מקור ויעד וסכום להעברה.", "code_snippet": "#include <iostream>\n#include <thread>\n#include <mutex>\n#include <vector>\n#include <map>\n#include <chrono>\n\n// Assume Account IDs are integers\nstd::map<int, std::mutex> account_locks;\nstd::map<int, double> account_balances;\n\n// Initialize accounts (for example purposes)\nvoid init_accounts(int num_accounts) {\n    for (int i = 0; i < num_accounts; ++i) {\n        account_locks[i]; // Default constructs mutex for each account ID\n        account_balances[i] = 100.0;\n    }\n}\n\n// Transaction function\nvoid transfer(int from_account_id, int to_account_id, double amount) {\n    // Simulate some work before locking\n    std::this_thread::sleep_for(std::chrono::milliseconds(10));\n\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Trying to lock \" << from_account_id << \" and \" << to_account_id << std::endl;\n\n    // Acquire locks for the source and destination accounts\n    account_locks[from_account_id].lock();\n    account_locks[to_account_id].lock();\n\n    // Check for sufficient balance and perform transfer\n    if (account_balances[from_account_id] >= amount) {\n        account_balances[from_account_id] -= amount;\n        account_balances[to_account_id] += amount;\n        std::cout << \"Thread \" << std::this_thread::get_id() << \": Transferred \" << amount\n                  << \" from \" << from_account_id << \" to \" << to_account_id << std::endl;\n    } else {\n        std::cout << \"Thread \" << std::this_thread::get_id() << \": Insufficient balance in \"\n                  << from_account_id << \" to transfer \" << amount << std::endl;\n    }\n\n    // Release locks\n    account_locks[to_account_id].unlock();\n    account_locks[from_account_id].unlock();\n}\n\nint main() {\n    init_accounts(3); // Initialize accounts 0, 1, 2\n\n    // Create multiple threads attempting transfers\n    // This specific combination is designed to demonstrate deadlock potential\n    std::thread t1(transfer, 0, 1, 10.0);\n    std::thread t2(transfer, 1, 0, 20.0);\n    std::thread t3(transfer, 0, 2, 5.0);\n    std::thread t4(transfer, 2, 0, 15.0);\n\n    t1.join();\n    t2.join();\n    t3.join();\n    t4.join();\n\n    std::cout << \"\\nFinal Balances:\" << std::endl;\n    for (int i = 0; i < 3; ++i) {\n        std::cout << \"Account \" << i << \": \" << account_balances[i] << std::endl;\n    }\n\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "a", "text": "האם בקוד הנתון קיים פוטנציאל לדדלוק? אם כן, תארו מצב ספציפי (לדוגמה, עם חוטים T1 ו-T2 ומזהי חשבונות ספציפיים) שבו דדלוק יתרחש. הסבירו בקצרה מדוע זהו דדלוק על בסיס ארבעת התנאים ההכרחיים (מניעה הדדית, החזק והמתן, אי-הפקעה, המתנה מעגלית).", "code_snippet": null, "options": null}, {"id": "b", "text": "הציעו שינוי מינימלי בקוד של פונקציית `transfer` כדי למנוע דדלוק. כתבו את הקוד המתוקן והסבירו בקצרה מדוע השינוי מונע דדלוק.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "### פתרון סעיף א' - זיהוי דדלוק\n\n**כן, בקוד הנתון קיים פוטנציאל לדדלוק.**\n\n**תיאור מצב ספציפי לדדלוק:**\nנניח ששני חוטים, T1 ו-T2, מבצעים טרנזקציות בו-זמנית:\n*   חוט T1 קורא ל-`transfer(0, 1, 10.0)` (מעביר מחשבון 0 לחשבון 1).\n*   חוט T2 קורא ל-`transfer(1, 0, 20.0)` (מעביר מחשבון 1 לחשבון 0).\n\nהתרחיש שיוביל לדדלוק הוא כדלקמן:\n1.  חוט T1 מבצע `account_locks[0].lock()` ותופס את המנעול של חשבון 0.\n2.  חוט T2 מבצע `account_locks[1].lock()` ותופס את המנעול של חשבון 1.\n3.  חוט T1 מנסה לבצע `account_locks[1].lock()` אך המנעול תפוס על ידי T2. T1 נכנס למצב המתנה.\n4.  חוט T2 מנסה לבצע `account_locks[0].lock()` אך המנעול תפוס על ידי T1. T2 נכנס למצב המתנה.\n\nבמצב זה, T1 מחזיק במנעול ש-T2 זקוק לו, ו-T2 מחזיק במנעול ש-T1 זקוק לו. שני החוטים ממתינים זה לזה לנצח, ולכן מתרחש דדלוק.\n\n**הסבר על בסיס ארבעת התנאים ההכרחיים לדדלוק:**\n1.  **מניעה הדדית (Mutual Exclusion):** כל מנעול (mutex) של חשבון יכול להיות מוחזק על ידי חוט אחד בלבד בכל רגע נתון. זה מתקיים בקוד כי `std::mutex` הוא אובייקט סנכרון בלעדי.\n2.  **החזק והמתן (Hold and Wait):** חוטים מחזיקים במשאב אחד (מנעול של חשבון) וממתינים למשאב נוסף שתפוס על ידי חוט אחר. בדוגמה לעיל, T1 מחזיק את מנעול 0 וממתין למנעול 1, ו-T2 מחזיק את מנעול 1 וממתין למנעול 0.\n3.  **אי-הפקעה (No Preemption):** משאבים (מנעולים) אינם ניתנים להפקעה בכוח מחוט שמחזיק בהם. חוט חייב לשחרר אותם מרצונו. זה מתקיים עם `std::mutex`.\n4.  **המתנה מעגלית (Circular Wait):** קיימת שרשרת של חוטים, שבה כל חוט ממתין למשאב שמוחזק על ידי החוט הבא בשרשרת, והחוט האחרון ממתין למשאב שמוחזק על ידי החוט הראשון. בדוגמה שלנו, T1 ממתין ל-T2, ו-T2 ממתין ל-T1, ויוצרים מעגל המתנה.\n\n### פתרון סעיף ב' - מניעת דדלוק\n\nכדי למנוע דדלוק, ניתן להטיל סדר גלובלי על רכישת המשאבים (המנעולים). במקרה זה, נגדיר כי יש לרכוש תמיד את המנעול של החשבון בעל המזהה הקטן יותר, ורק לאחר מכן את המנעול של החשבון בעל המזהה הגדול יותר. זה מבטל את תנאי ה'המתנה מעגלית'.\n\n**קוד `transfer` מתוקן:**\n```c++\nvoid transfer(int from_account_id, int to_account_id, double amount) {\n    std::this_thread::sleep_for(std::chrono::milliseconds(10));\n\n    // קביעת סדר נעילה עקבי על בסיס מזהי החשבונות\n    // תמיד ננעל קודם את המזהה הקטן יותר, ואז את הגדול יותר\n    std::mutex& lock1 = (from_account_id < to_account_id) ? account_locks[from_account_id] : account_locks[to_account_id];\n    std::mutex& lock2 = (from_account_id < to_account_id) ? account_locks[to_account_id] : account_locks[from_account_id];\n\n    int first_id = (from_account_id < to_account_id) ? from_account_id : to_account_id;\n    int second_id = (from_account_id < to_account_id) ? to_account_id : from_account_id;\n\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Trying to lock \" << first_id << \" then \" << second_id << std::endl;\n\n    // רכישת המנעולים בסדר קבוע\n    lock1.lock();\n    lock2.lock();\n\n    // לאחר הנעילה, נשמור על ההתייחסות המקורית לחשבונות המקור והיעד\n    double* actual_from_balance = &account_balances[from_account_id];\n    double* actual_to_balance = &account_balances[to_account_id];\n\n    // בדיקת יתרה מספקת וביצוע ההעברה\n    if (*actual_from_balance >= amount) {\n        *actual_from_balance -= amount;\n        *actual_to_balance += amount;\n        std::cout << \"Thread \" << std::this_thread::get_id() << \": Transferred \" << amount\n                  << \" from \" << from_account_id << \" to \" << to_account_id << std::endl;\n    } else {\n        std::cout << \"Thread \" << std::this_thread::get_id() << \": Insufficient balance in \"\n                  << from_account_id << \" to transfer \" << amount << std::endl;\n    }\n\n    // שחרור המנעולים בסדר הפוך לסדר הרכישה (פרקטיקה מומלצת)\n    lock2.unlock();\n    lock1.unlock();\n}\n```\n\n**הסבר מדוע השינוי מונע דדלוק:**\nהשינוי מבטל את תנאי ה'המתנה מעגלית' (Circular Wait). על ידי הטלת סדר גלובלי ועקבי לרכישת מנעולים (תמיד קודם המנעול של החשבון בעל המזהה הקטן יותר, ואז את המנעול של החשבון בעל המזהה הגדול יותר), אנו מבטיחים שלעולם לא תיווצר שרשרת המתנה מעגלית. אם חוט T1 מנסה להעביר מ-0 ל-1, וחוט T2 מנסה להעביר מ-1 ל-0, שניהם ינסו לרכוש קודם את המנעול של חשבון 0 (מכיוון ש-0 < 1). החוט שיצליח לתפוס את מנעול 0 ראשון, ימשיך לנסות לתפוס את מנעול 1. החוט השני ימתין למנעול 0. במצב זה, תמיד אחד החוטים יתקדם, ולא ייתכן מצב שבו כל חוט מחזיק במשאב שחוט אחר זקוק לו, ובו בזמן ממתין למשאב שמוחזק על ידי אותו חוט אחר, בסבב מעגלי."}, "difficulty_estimation": "Hard", "_source_file": "0407__Deadlocks__Open__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:21:43", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Deadlocks", "Synchronization", "Concurrency", "Mutexes"], "content": {"text": "נתונה מערכת מרובת תהליכונים (multi-threaded system) הכוללת N תהליכוני עבודה (worker threads) ושני משאבים גלובליים נפרדים: `ResourceX` ו-`ResourceY`. כל אחד מהמשאבים מוגן על ידי מנעול הדדי (mutex) משלו. כל תהליכון במערכת נדרש לרכוש את שני המשאבים, `ResourceX` ו-`ResourceY`, על מנת לבצע משימה יחידה.\nאופן רכישת המשאבים מוגדר באופן הבא:\n*   תהליכונים בעלי מזהה זוגי (even ID) רוכשים תחילה את `ResourceX` ולאחר מכן את `ResourceY`.\n*   תהליכונים בעלי מזהה אי-זוגי (odd ID) רוכשים תחילה את `ResourceY` ולאחר מכן את `ResourceX`.\n\nלהלן קטע קוד המדגים את מבנה המערכת ואת לוגיקת הפעולה של תהליכון בודד:", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex_X;\npthread_mutex_t mutex_Y;\n\nvoid init_resources() {\n    pthread_mutex_init(&mutex_X, NULL);\n    pthread_mutex_init(&mutex_Y, NULL);\n}\n\nvoid destroy_resources() {\n    pthread_mutex_destroy(&mutex_X);\n    pthread_mutex_destroy(&mutex_Y);\n}\n\nvoid* worker_thread(void* arg) {\n    long thread_id = (long)arg;\n\n    if (thread_id % 2 == 0) { // Even ID: acquire X then Y\n        printf(\"Thread %ld: Trying to acquire ResourceX...\\n\", thread_id);\n        pthread_mutex_lock(&mutex_X);\n        printf(\"Thread %ld: Acquired ResourceX. Trying to acquire ResourceY...\\n\", thread_id);\n        // Simulate work or delay to increase deadlock probability\n        sleep(1);\n        pthread_mutex_lock(&mutex_Y);\n        printf(\"Thread %ld: Acquired ResourceY. Performing task...\\n\", thread_id);\n        // Task execution\n        sleep(2);\n        printf(\"Thread %ld: Releasing ResourceY...\\n\", thread_id);\n        pthread_mutex_unlock(&mutex_Y);\n        printf(\"Thread %ld: Releasing ResourceX...\\n\", thread_id);\n        pthread_mutex_unlock(&mutex_X);\n        printf(\"Thread %ld: Task completed.\\n\", thread_id);\n    } else { // Odd ID: acquire Y then X\n        printf(\"Thread %ld: Trying to acquire ResourceY...\\n\", thread_id);\n        pthread_mutex_lock(&mutex_Y);\n        printf(\"Thread %ld: Acquired ResourceY. Trying to acquire ResourceX...\\n\", thread_id);\n        // Simulate work or delay to increase deadlock probability\n        sleep(1);\n        pthread_mutex_lock(&mutex_X);\n        printf(\"Thread %ld: Acquired ResourceX. Performing task...\\n\", thread_id);\n        // Task execution\n        sleep(2);\n        printf(\"Thread %ld: Releasing ResourceX...\\n\", thread_id);\n        pthread_mutex_unlock(&mutex_X);\n        printf(\"Thread %ld: Releasing ResourceY...\\n\", thread_id);\n        pthread_mutex_unlock(&mutex_Y);\n        printf(\"Thread %ld: Task completed.\\n\", thread_id);\n    }\n    return NULL;\n}\n// פונקציית main ליצירת תהליכונים תהיה כאן, אך אינה נחוצה לשאלה", "options": null}, "sub_questions": [{"id": "a", "text": "האם תצורה זו של רכישת משאבים עלולה להוביל למצב של קיפאון (deadlock)? אם כן, הסבירו בפירוט מדוע, תוך התייחסות לארבעת התנאים ההכרחיים לקיפאון של Coffman (מניעה הדדית, החזק והמתן, אי-הפקעה, המתנה מעגלית).", "code_snippet": null, "options": null}, {"id": "b", "text": "הציעו פתרון קוד מתוקן, המונע קיפאון במערכת זו, תוך שמירה על רמת מקביליות סבירה. נמקו את הפתרון שלכם והסבירו כיצד הוא מונע את תנאי הקיפאון הספציפיים שהובילו לבעיה בסעיף הקודם.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "**סעיף א': ניתוח קיפאון**\nכן, תצורה זו של רכישת משאבים עלולה בהחלט להוביל למצב של קיפאון (deadlock). ננתח זאת באמצעות ארבעת התנאים ההכרחיים לקיפאון של Coffman:\n\n1.  **מניעה הדדית (Mutual Exclusion)**: תנאי זה מתקיים. כל אחד מהמשאבים, `ResourceX` ו-`ResourceY`, מוגן על ידי מנעול הדדי (mutex). פירוש הדבר הוא שרק תהליכון אחד יכול להחזיק במנעול של משאב נתון בכל רגע נתון.\n2.  **החזק והמתן (Hold and Wait)**: תנאי זה מתקיים. תהליכונים רוכשים מנעול אחד (למשל, `mutex_X` עבור תהליכון זוגי או `mutex_Y` עבור תהליכון אי-זוגי) ומחזיקים בו, תוך כדי שהם ממתינים למנעול השני שהם צריכים (למשל, `mutex_Y` עבור תהליכון זוגי או `mutex_X` עבור תהליכון אי-זוגי).\n3.  **אי-הפקעה (No Preemption)**: תנאי זה מתקיים. מנעולי `pthread_mutex_t` אינם ניתנים להפקעה. ברגע שתהליכון רוכש מנעול, הוא יחזיק בו עד שישחרר אותו מרצונו.\n4.  **המתנה מעגלית (Circular Wait)**: תנאי זה יכול להתקיים, והוא הגורם הישיר לקיפאון בתצורה זו.\n    *   דמיינו תהליכון זוגי (לדוגמה, `thread_id = 0`) רוכש את `mutex_X`.\n    *   באותו זמן, דמיינו תהליכון אי-זוגי (לדוגמה, `thread_id = 1`) רוכש את `mutex_Y`.\n    *   כעת, `thread_id = 0` מחזיק ב-`mutex_X` ומנסה לרכוש את `mutex_Y` (שמוחזק על ידי `thread_id = 1`).\n    *   במקביל, `thread_id = 1` מחזיק ב-`mutex_Y` ומנסה לרכוש את `mutex_X` (שמוחזק על ידי `thread_id = 0`).\n    *   נוצר מעגל המתנה: `thread_id = 0` ממתין ל-`mutex_Y` שמוחזק על ידי `thread_id = 1`, ו-`thread_id = 1` ממתין ל-`mutex_X` שמוחזק על ידי `thread_id = 0`. שני התהליכונים חסומים זה על ידי זה, והמערכת נכנסת לקיפאון.\n\n**סעיף ב': פתרון למניעת קיפאון**\nהדרך היעילה ביותר למנוע קיפאון במקרה זה היא לשבור את תנאי \"המתנה מעגלית\" על ידי אכיפת סדר עקבי (כלל גלובלי) לרכישת משאבים עבור כל התהליכונים. במקום לאפשר סדרי רכישה שונים, כל התהליכונים ירכשו את המשאבים באותו סדר קבוע.\n\n**קוד מתוקן:**\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex_X;\npthread_mutex_t mutex_Y;\n\nvoid init_resources() {\n    pthread_mutex_init(&mutex_X, NULL);\n    pthread_mutex_init(&mutex_Y, NULL);\n}\n\nvoid destroy_resources() {\n    pthread_mutex_destroy(&mutex_X);\n    pthread_mutex_destroy(&mutex_Y);\n}\n\nvoid* worker_thread_fixed(void* arg) {\n    long thread_id = (long)arg;\n\n    // אכיפת סדר רכישה עקבי לכל התהליכונים: תמיד X ואז Y\n    printf(\"Thread %ld: Trying to acquire ResourceX...\\n\", thread_id);\n    pthread_mutex_lock(&mutex_X);\n    printf(\"Thread %ld: Acquired ResourceX. Trying to acquire ResourceY...\\n\", thread_id);\n    // מדמה עבודה או עיכוב להגברת סבירות לבעיה (כעת למטרת הדגמה בלבד)\n    sleep(1);\n    pthread_mutex_lock(&mutex_Y);\n    printf(\"Thread %ld: Acquired ResourceY. Performing task...\\n\", thread_id);\n    // ביצוע המשימה\n    sleep(2);\n    printf(\"Thread %ld: Releasing ResourceY...\\n\", thread_id);\n    pthread_mutex_unlock(&mutex_Y);\n    printf(\"Thread %ld: Releasing ResourceX...\\n\", thread_id);\n    pthread_mutex_unlock(&mutex_X);\n    printf(\"Thread %ld: Task completed.\\n\", thread_id);\n\n    return NULL;\n}\n// פונקציית main ליצירת תהליכונים תהיה כאן, אך אינה נחוצה לשאלה\n```\n\n**הסבר לפתרון:**\nהפתרון המתוקן אוכף סדר רכישה גלובלי: כל התהליכונים, ללא קשר למזהה שלהם, ינסו לרכוש תחילה את `mutex_X` ולאחר מכן את `mutex_Y`. \nפעולה זו מונעת את תנאי ה\"המתנה מעגלית\". כעת, לא ייתכן מצב שבו תהליכון אחד מחזיק ב-`mutex_X` וממתין ל-`mutex_Y`, בעוד שתהליכון אחר מחזיק ב-`mutex_Y` וממתין ל-`mutex_X`. כל התהליכונים מחכים לאותו משאב ראשון (`mutex_X`), ורק לאחר קבלתו ממשיכים למשאב השני (`mutex_Y`).\nהדבר מבטיח שאם `mutex_X` מוחזק, כל מי שרוצה אותו ימתין לו. אם `mutex_X` פנוי, תהליכון ירכוש אותו, ואז ינסה לרכוש את `mutex_Y`. אם `mutex_Y` תפוס, הוא יחכה, אבל הוא לא יחזיק ב-`mutex_Y` וימתין ל-`mutex_X`, ובכך נשבר המעגל.\nפתרון זה שומר על רמת מקביליות סבירה מכיוון שתהליכונים עדיין יכולים לבצע את משימותיהם במקביל, כל עוד הם לא מתחרים על אותם מנעולים באותו רגע, או אם המנעולים משוחררים במהירות. למרות שיש סדר רכישה מחמיר, עדיין יתכן שתהליכון אחד יחזיק בשני המנעולים ויבצע את משימתו, בזמן שתהליכונים אחרים ממתינים בתור מסודר."}, "difficulty_estimation": "Hard", "_source_file": "0408__Deadlocks__Open__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:47:48", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Deadlocks", "Concurrency", "Mutexes"], "content": {"text": "נתון קטע קוד בשפת C המשתמש בספריות ת'רדים ומנעולים (pthread). שני חוטים (thread_A ו-thread_B) מנסים לגשת למשאבים המוגנים על ידי מנעולים (mutex_X ו-mutex_Y). עיין בקוד המצורף וענה על השאלה הבאה:\n\nהאם קטע קוד זה יכול להוביל למצב של קיפאון (deadlock)? אם כן, הסבר מדוע וכיצד ניתן למנוע אותו. אם לא, הסבר מדוע.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex_X;\npthread_mutex_t mutex_Y;\n\nvoid* thread_A_func(void* arg) {\n    printf(\"Thread A: Attempting to lock mutex_X...\\n\");\n    pthread_mutex_lock(&mutex_X);\n    printf(\"Thread A: Locked mutex_X. Sleeping...\\n\");\n    sleep(1); // Simulate work or delay\n\n    printf(\"Thread A: Attempting to lock mutex_Y...\\n\");\n    pthread_mutex_lock(&mutex_Y);\n    printf(\"Thread A: Locked mutex_Y. Critical section A...\\n\");\n\n    // Critical section A\n    printf(\"Thread A: Releasing mutex_Y...\\n\");\n    pthread_mutex_unlock(&mutex_Y);\n    printf(\"Thread A: Releasing mutex_X...\\n\");\n    pthread_mutex_unlock(&mutex_X);\n    printf(\"Thread A: Exiting.\\n\");\n    return NULL;\n}\n\nvoid* thread_B_func(void* arg) {\n    printf(\"Thread B: Attempting to lock mutex_Y...\\n\");\n    pthread_mutex_lock(&mutex_Y);\n    printf(\"Thread B: Locked mutex_Y. Sleeping...\\n\");\n    sleep(1); // Simulate work or delay\n\n    printf(\"Thread B: Attempting to lock mutex_X...\\n\");\n    pthread_mutex_lock(&mutex_X);\n    printf(\"Thread B: Locked mutex_X. Critical section B...\\n\");\n\n    // Critical section B\n    printf(\"Thread B: Releasing mutex_X...\\n\");\n    pthread_mutex_unlock(&mutex_X);\n    printf(\"Thread B: Releasing mutex_Y...\\n\");\n    pthread_mutex_unlock(&mutex_Y);\n    printf(\"Thread B: Exiting.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t thread_A, thread_B;\n\n    pthread_mutex_init(&mutex_X, NULL);\n    pthread_mutex_init(&mutex_Y, NULL);\n\n    pthread_create(&thread_A, NULL, thread_A_func, NULL);\n    pthread_create(&thread_B, NULL, thread_B_func, NULL);\n\n    pthread_join(thread_A, NULL);\n    pthread_join(thread_B, NULL);\n\n    pthread_mutex_destroy(&mutex_X);\n    pthread_mutex_destroy(&mutex_Y);\n\n    printf(\"Main: Program finished.\\n\");\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, קטע קוד זה יכול להוביל למצב של קיפאון (deadlock). קיפאון הוא מצב שבו שני חוטים או יותר ממתינים זה לזה באופן בלתי הפיך למשאבים שהם צריכים כדי להמשיך.\n\nבמקרה זה, התנאים לקיפאון מתקיימים:\n1.  **מניעה הדדית (Mutual Exclusion)**: המנעולים (mutex_X, mutex_Y) מבטיחים שרק חוט אחד יכול להחזיק במשאב (המנעול) בכל רגע נתון.\n2.  **החזקה והמתנה (Hold and Wait)**: חוט A מחזיק במנעול X וממתין למנעול Y. במקביל, חוט B מחזיק במנעול Y וממתין למנעול X.\n3.  **אין שחרור מוקדם (No Preemption)**: אף חוט לא יכול לקחת בכוח מנעול מחוט אחר. המנעולים משוחררים רק על ידי החוט שתפס אותם.\n4.  **המתנה מעגלית (Circular Wait)**: קיים מעגל המתנה: חוט A ממתין למנעול Y שמוחזק על ידי חוט B, וחוט B ממתין למנעול X שמוחזק על ידי חוט A.\n\n**תרחיש לדוגמה לקיפאון:**\n1.  חוט A נועל את `mutex_X`.\n2.  חוט B נועל את `mutex_Y`.\n3.  חוט A מנסה לנעול את `mutex_Y` אך הוא תפוס על ידי חוט B, ולכן חוט A נחסם וממתין.\n4.  חוט B מנסה לנעול את `mutex_X` אך הוא תפוס על ידי חוט A, ולכן חוט B נחסם וממתין.\nבמצב זה, שני החוטים חסומים באופן הדדי, וכל אחד מהם מחזיק במשאב שהשני זקוק לו, וכך נוצר קיפאון.\n\n**מניעת קיפאון:**\nהדרך הנפוצה ביותר למנוע קיפאון במקרה זה היא על ידי אכיפת סדר קבוע ללקיחת המנעולים. אם כל החוטים ינסו לתפוס את המנעולים באותו סדר (לדוגמה, תמיד קודם `mutex_X` ואז `mutex_Y`), אזי תנאי ההמתנה המעגלית לא יכול להתקיים.\n\n**תיקון הקוד:**\nיש לשנות את הפונקציה `thread_B_func` כך שתנסה לנעול את `mutex_X` לפני `mutex_Y`, בדיוק כמו `thread_A_func`.\n\n**קוד מתוקן לדוגמה עבור `thread_B_func`:**\n```c\nvoid* thread_B_func(void* arg) {\n    printf(\"Thread B: Attempting to lock mutex_X...\\n\");\n    pthread_mutex_lock(&mutex_X); // סדר המנעולים שונה\n    printf(\"Thread B: Locked mutex_X. Sleeping...\\n\");\n    sleep(1);\n\n    printf(\"Thread B: Attempting to lock mutex_Y...\\n\");\n    pthread_mutex_lock(&mutex_Y); // סדר המנעולים שונה\n    printf(\"Thread B: Locked mutex_Y. Critical section B...\\n\");\n\n    printf(\"Thread B: Releasing mutex_Y...\\n\");\n    pthread_mutex_unlock(&mutex_Y);\n    printf(\"Thread B: Releasing mutex_X...\\n\");\n    pthread_mutex_unlock(&mutex_X);\n    printf(\"Thread B: Exiting.\\n\");\n    return NULL;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0409__Deadlocks__CodeAnalysis__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:22:34", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Concurrency"], "content": {"text": "נתון קטע הקוד הבא המשתמש בשני מנעולים (mutexes) ושני תהליכונים (threads). עיין בקוד וענה על השאלה הבאה:\n\nהאם קטע קוד זה עלול להוביל למצב של קיפאון (deadlock)? אם כן, הסבר מהם התנאים שיובילו לקיפאון וכיצד ניתן למנוע אותו.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutexA;\npthread_mutex_t mutexB;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to acquire mutexA...\\n\");\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 1: Acquired mutexA. Trying to acquire mutexB...\\n\");\n    sleep(1); // Simulate some work or context switch\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 1: Acquired mutexB. Critical section.\\n\");\n    // ... critical section ...\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 1: Released mutexes.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to acquire mutexB...\\n\");\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 2: Acquired mutexB. Trying to acquire mutexA...\\n\");\n    sleep(1); // Simulate some work or context switch\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 2: Acquired mutexA. Critical section.\\n\");\n    // ... critical section ...\n    pthread_mutex_unlock(&mutexA);\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 2: Released mutexes.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&mutexA, NULL);\n    pthread_mutex_init(&mutexB, NULL);\n\n    pthread_create(&tid1, NULL, thread_func1, NULL);\n    pthread_create(&tid2, NULL, thread_func2, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    pthread_mutex_destroy(&mutexA);\n    pthread_mutex_destroy(&mutexB);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, קטע הקוד הזה עלול להוביל למצב של קיפאון (deadlock).\n\n**הסבר:**\nקיפאון יכול להתרחש כאשר שני התהליכונים (threads) מנסים לרכוש את המנעולים בסדר הפוך. נניח את התרחיש הבא:\n1.  תהליכון 1 רוכש בהצלחה את `mutexA`.\n2.  מתרחש מעבר הקשר (context switch) לתהליכון 2.\n3.  תהליכון 2 רוכש בהצלחה את `mutexB`.\n4.  תהליכון 2 מנסה לרכוש את `mutexA`, אך הוא נעול על ידי תהליכון 1, ולכן תהליכון 2 נחסם וממתין.\n5.  מתרחש מעבר הקשר בחזרה לתהליכון 1.\n6.  תהליכון 1 מנסה לרכוש את `mutexB`, אך הוא נעול על ידי תהליכון 2, ולכן תהליכון 1 נחסם וממתין.\nבשלב זה, תהליכון 1 ממתין למנעול שמוחזק על ידי תהליכון 2, ותהליכון 2 ממתין למנעול שמוחזק על ידי תהליכון 1. נוצר מעגל המתנה (circular wait) שמוביל לקיפאון. תנאים נוספים לקיפאון המתקיימים כאן הם: מניעה הדדית (mutual exclusion) – כל מנעול יכול להיות מוחזק ע\"י תהליכון אחד בלבד; החזקה והמתנה (hold and wait) – תהליכון מחזיק במשאב אחד וממתין למשאב אחר; וחוסר עקיפה (no preemption) – לא ניתן לקחת מנעול מתהליכון שמחזיק בו בכוח.\n\n**מניעה:**\nהדרך הנפוצה והפשוטה ביותר למנוע קיפאון במקרה זה היא לוודא שכל התהליכונים רוכשים את המנעולים באותו סדר קבוע. לדוגמה, אם שני התהליכונים ירכשו תמיד קודם את `mutexA` ואז את `mutexB`, לא ייווצר מעגל המתנה. הנה דוגמה לשינוי בקוד עבור `thread_func2` כדי למנוע קיפאון:\n\n```c\nvoid* thread_func2_fixed(void* arg) {\n    printf(\"Thread 2: Trying to acquire mutexA...\\n\");\n    pthread_mutex_lock(&mutexA); // Acquire A first\n    printf(\"Thread 2: Acquired mutexA. Trying to acquire mutexB...\\n\");\n    sleep(1);\n    pthread_mutex_lock(&mutexB); // Then B\n    printf(\"Thread 2: Acquired mutexB. Critical section.\\n\");\n    // ... critical section ...\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 2: Released mutexes.\\n\");\n    return NULL;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0410__Deadlocks__CodeAnalysis__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:22:50", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Concurrency", "Mutexes"], "content": {"text": "נתון קוד C הבא המשתמש בספריות `pthread` לניהול תהליכונים ומנעולים. קראו את הקוד וענו על השאלה:\n\nהאם קיפאון (Deadlock) יכול להתרחש בריצת קוד זה? אם כן, הסבירו מדוע וציינו את ארבעת התנאים לקיפאון המתקיימים בקוד. אם לא, הסבירו מדוע.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex1;\npthread_mutex_t mutex2;\n\nvoid* thread_func1(void* arg) {\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 1 acquired mutex1\\n\");\n    sleep(1); // Simulate work\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 1 acquired mutex2\\n\");\n    printf(\"Thread 1 doing work with both mutexes\\n\");\n    pthread_mutex_unlock(&mutex2);\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 1 released both mutexes\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2 acquired mutex2\\n\");\n    sleep(1); // Simulate work\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2 acquired mutex1\\n\");\n    printf(\"Thread 2 doing work with both mutexes\\n\");\n    pthread_mutex_unlock(&mutex1);\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2 released both mutexes\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n\n    pthread_mutex_init(&mutex1, NULL);\n    pthread_mutex_init(&mutex2, NULL);\n\n    pthread_create(&t1, NULL, thread_func1, NULL);\n    pthread_create(&t2, NULL, thread_func2, NULL);\n\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "כן, קיפאון (Deadlock) יכול להתרחש בקוד זה.\n\n**הסבר:**\nהקיפאון יתרחש כאשר התהליכון הראשון (Thread 1) יתפוס את `mutex1` והתהליכון השני (Thread 2) יתפוס את `mutex2`. לאחר מכן, Thread 1 ינסה לתפוס את `mutex2` (שכבר תפוס על ידי Thread 2) ו-Thread 2 ינסה לתפוס את `mutex1` (שכבר תפוס על ידי Thread 1). במצב זה, שני התהליכונים ימתינו זה לזה באופן אינסופי, מה שיוביל לקיפאון.\n\n**ארבעת התנאים לקיפאון המתקיימים בקוד הם:**\n1.  **מניעה הדדית (Mutual Exclusion)**: המנעולים `mutex1` ו-`mutex2` הם משאבים בלעדיים. רק חוט אחד יכול לתפוס כל מנעול בכל רגע נתון. אם חוט אחד תופס מנעול, חוט אחר המנסה לתפוס אותו ייחסם.\n2.  **החזקה והמתנה (Hold and Wait)**: כל חוט (למשל, Thread 1) תופס מנעול אחד (לדוגמה, `mutex1`) וממתין לתפוס מנעול נוסף (במקרה זה, `mutex2`) שמוחזק על ידי חוט אחר, מבלי לשחרר את המנעול שכבר ברשותו.\n3.  **אי-נתיקה (No Preemption)**: לא ניתן לקחת מנעול מחוט שתפס אותו בכוח. חוט חייב לשחרר את המנעול מרצונו לאחר שסיים להשתמש בו.\n4.  **המתנה מעגלית (Circular Wait)**: קיים מעגל המתנה. Thread 1 ממתין ל-Thread 2 שישחרר את `mutex2`, ובמקביל, Thread 2 ממתין ל-Thread 1 שישחרר את `mutex1`. מעגל זה יוצר תלות הדדית שאינה ניתנת לשבירה ללא התערבות חיצונית.\n\n**פתרון למניעת קיפאון (לא נדרש בשאלה אך רלוונטי):**\nכדי למנוע קיפאון במקרה זה, ניתן לוודא שכל התהליכונים תופסים את המנעולים באותו סדר עקבי (לדוגמה, תמיד קודם `mutex1` ואז `mutex2`)."}, "difficulty_estimation": "Easy", "_source_file": "0411__Deadlocks__CodeAnalysis__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:23:04", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Deadlocks", "Concurrency", "Synchronization", "Mutexes"], "content": {"text": "נתון קטע קוד בשפת C המשתמש בשני חוטים (threads) ובשני מנעולים (mutexes). עיין בקוד המצורף וענה על השאלה הבאה:\n\nהאם הקוד הנתון עלול לגרום למצב של קיפאון (Deadlock)? נמק את תשובתך. אם כן, הסבר אילו תנאים לקיפאון מתקיימים, והצע דרך פשוטה למנוע אותו.", "code_snippet": " #include <pthread.h>\n #include <stdio.h>\n #include <unistd.h>\n\n pthread_mutex_t mutex1;\n pthread_mutex_t mutex2;\n\n void* thread_func1(void* arg) {\n     pthread_mutex_lock(&mutex1);\n     sleep(1); // להגברת הסיכוי לקיפאון\n     pthread_mutex_lock(&mutex2);\n     printf(\"Thread 1: In critical section.\\n\");\n     pthread_mutex_unlock(&mutex2);\n     pthread_mutex_unlock(&mutex1);\n     return NULL;\n }\n\n void* thread_func2(void* arg) {\n     pthread_mutex_lock(&mutex2);\n     sleep(1); // להגברת הסיכוי לקיפאון\n     pthread_mutex_lock(&mutex1);\n     printf(\"Thread 2: In critical section.\\n\");\n     pthread_mutex_unlock(&mutex1);\n     pthread_mutex_unlock(&mutex2);\n     return NULL;\n }\n // (פונקציית main מאתחלת את המנעולים ויוצרת את החוטים t1 ו-t2 המריצים את thread_func1 ו-thread_func2 בהתאמה)", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, הקוד הנתון אכן עלול לגרום למצב של קיפאון (Deadlock).\n\n**נימוק - תנאי הקיפאון המתקיימים:**\nקיפאון מתרחש כאשר מתקיימים בו-זמנית ארבעה תנאים:\n1.  **מניעה הדדית (Mutual Exclusion):** תנאי זה מתקיים. המנעולים (`mutex1`, `mutex2`) הם משאבים שאינם ניתנים לשיתוף, ורק חוט אחד יכול להחזיק במנעול נתון בכל רגע. אם חוט אחד תופס מנעול, חוט אחר לא יכול לתפוס אותו עד שהראשון ישחרר אותו.\n2.  **החזקה והמתנה (Hold and Wait):** תנאי זה מתקיים. כל אחד מהחוטים תופס מנעול אחד (חוט 1 תופס את `mutex1`, וחוט 2 תופס את `mutex2`) ולאחר מכן ממתין למנעול השני כדי להמשיך בביצוע הקטע הקריטי.\n3.  **אי-נטילה (No Preemption):** תנאי זה מתקיים. המנעולים אינם ניתנים לנטילה בכוח מחוט שמחזיק בהם. חוט חייב לשחרר את המנעול באופן יזום.\n4.  **המתנה מעגלית (Circular Wait):** תנאי זה מתקיים. נוצרת שרשרת מעגלית של חוטים הממתינים למשאבים המוחזקים על ידי חוטים אחרים בשרשרת. במקרה זה, חוט 1 מחזיק את `mutex1` וממתין ל-`mutex2` (המוחזק על ידי חוט 2), בעוד שחוט 2 מחזיק את `mutex2` וממתין ל-`mutex1` (המוחזק על ידי חוט 1).\n\n**הסבר:** אם חוט 1 מצליח לתפוס את `mutex1` וחוט 2 מצליח לתפוס את `mutex2` בערך באותו זמן (לפני שכל אחד מהם מנסה לתפוס את המנעול השני), אז כל אחד מהם יחזיק במנעול אחד וימתין למנעול השני המוחזק על ידי יריבו, וכך יווצר קיפאון.\n\n**דרך פשוטה למנוע קיפאון:**\nהדרך הפשוטה ביותר למנוע קיפאון במקרה זה היא להבטיח שכל החוטים יתפסו את המנעולים באותו סדר עקבי. לדוגמה, שניהם יתפסו תמיד קודם את `mutex1` ואז את `mutex2`:\n\n```c\n// עבור thread_func1 וגם עבור thread_func2\nvoid* thread_func_fixed(void* arg) {\n    pthread_mutex_lock(&mutex1);\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread: In critical section (fixed order).\\n\");\n    pthread_mutex_unlock(&mutex2);\n    pthread_mutex_unlock(&mutex1);\n    return NULL;\n}\n```\nעל ידי שמירה על סדר קבוע, נמנע את תנאי ההמתנה המעגלית."}, "difficulty_estimation": "Easy", "_source_file": "0412__Deadlocks__CodeAnalysis__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:23:26", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Concurrency"], "content": {"text": "נתון קטע הקוד הבא המשתמש בשני מנעולים (mutexes) ובשני חוטים (threads). האם יכול להתרחש קיפאון (deadlock) בקוד זה? אם כן, הסבירו מדוע, וכיצד ניתן למנוע אותו על ידי שינוי מינימלי בקוד.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutexA;\npthread_mutex_t mutexB;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to acquire mutexA...\\n\");\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 1: Acquired mutexA. Waiting a bit...\\n\");\n    sleep(1); // Simulate work or context switch\n    printf(\"Thread 1: Trying to acquire mutexB...\\n\");\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 1: Acquired mutexB. Doing work...\\n\");\n    // Critical section\n    printf(\"Thread 1: Releasing mutexB...\\n\");\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 1: Releasing mutexA...\\n\");\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 1: Finished.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to acquire mutexB...\\n\");\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 2: Acquired mutexB. Waiting a bit...\\n\");\n    sleep(1); // Simulate work or context switch\n    printf(\"Thread 2: Trying to acquire mutexA...\\n\");\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 2: Acquired mutexA. Doing work...\\n\");\n    // Critical section\n    printf(\"Thread 2: Releasing mutexA...\\n\");\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 2: Releasing mutexB...\\n\");\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 2: Finished.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&mutexA, NULL);\n    pthread_mutex_init(&mutexB, NULL);\n\n    pthread_create(&tid1, NULL, thread_func1, NULL);\n    pthread_create(&tid2, NULL, thread_func2, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    pthread_mutex_destroy(&mutexA);\n    pthread_mutex_destroy(&mutexB);\n\n    printf(\"Main: All threads finished.\\n\");\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "כן, קיפאון (deadlock) יכול להתרחש בקטע קוד זה.\n\n**מדוע קיפאון יכול להתרחש:**\nהקיפאון מתרחש עקב תנאי 'המתנה מעגלית' (Circular Wait) בשילוב עם שלושת התנאים הנוספים לקיפאון:\n1.  **מניעה הדדית (Mutual Exclusion):** המנעולים (mutexA ו-mutexB) מבטיחים שרק חוט אחד יכול להחזיק בהם בכל רגע נתון.\n2.  **החזקה והמתנה (Hold and Wait):**\n    *   חוט 1 תופס את `mutexA` ולאחר מכן מנסה לתפוס את `mutexB`. אם `mutexB` מוחזק על ידי חוט 2, חוט 1 ימתין תוך כדי שהוא מחזיק ב-`mutexA`.\n    *   חוט 2 תופס את `mutexB` ולאחר מכן מנסה לתפוס את `mutexA`. אם `mutexA` מוחזק על ידי חוט 1, חוט 2 ימתין תוך כדי שהוא מחזיק ב-`mutexB`.\n3.  **אי-הפקעה (No Preemption):** חוט אינו יכול להפקיע מנעול מחוט אחר; המנעול ישוחרר רק על ידי החוט שתפס אותו.\n4.  **המתנה מעגלית (Circular Wait):** זהו התנאי המרכזי שגורם לקיפאון במקרה זה. חוט 1 ממתין למשאב (`mutexB`) שמוחזק על ידי חוט 2, בעוד חוט 2 ממתין למשאב (`mutexA`) שמוחזק על ידי חוט 1. נוצר מעגל המתנה שבו אף חוט אינו יכול להתקדם.\n\n**כיצד ניתן למנוע קיפאון:**\nהדרך הנפוצה והפשוטה ביותר למנוע קיפאון במקרה זה היא על ידי אכיפת סדר עקבי וקבוע לרכישת המשאבים (המנעולים). אם כל החוטים ינסו לתפוס את המנעולים באותו סדר, תנאי ההמתנה המעגלית יישבר.\n\n**שינוי קוד מינימלי:**\nיש לשנות את הפונקציה `thread_func2` כך שתתפוס את `mutexA` לפני `mutexB`, בדומה ל-`thread_func1`.\n\n```c\n// ... (שאר הקוד נשאר כפי שהוא)\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to acquire mutexA...\\n\"); // שינוי כאן: תופס קודם את mutexA\n    pthread_mutex_lock(&mutexA);                        // שינוי כאן\n    printf(\"Thread 2: Acquired mutexA. Waiting a bit...\\n\");\n    sleep(1);\n    printf(\"Thread 2: Trying to acquire mutexB...\\n\");\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 2: Acquired mutexB. Doing work...\\n\");\n    // Critical section\n    printf(\"Thread 2: Releasing mutexB...\\n\");\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 2: Releasing mutexA...\\n\");          // שינוי כאן: משחרר את mutexA לבסוף\n    pthread_mutex_unlock(&mutexA);                      // שינוי כאן\n    printf(\"Thread 2: Finished.\\n\");\n    return NULL;\n}\n\n// ... (שאר הקוד נשאר כפי שהוא)\n```"}, "difficulty_estimation": "Easy", "_source_file": "0413__Deadlocks__CodeAnalysis__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:23:45", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Deadlocks", "Concurrency", "Synchronization"], "content": {"text": "נתון קוד C הבא המשתמש בשני מנעולים (mutexes) ובשני תהליכונים (threads). קראו את הקוד בעיון. האם קוד זה עלול להוביל למצב של קיפאון (deadlock)? אם כן, הסבירו מדוע וכיצד ניתן למנוע זאת.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex1;\npthread_mutex_t mutex2;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 1: Locked mutex1. Trying to lock mutex2...\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 1: Locked mutex2. Critical section...\\n\");\n    // Do some work\n    pthread_mutex_unlock(&mutex2);\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 1: Unlocked mutexes.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to lock mutex2...\\n\");\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2: Locked mutex2. Trying to lock mutex1...\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2: Locked mutex1. Critical section...\\n\");\n    // Do some work\n    pthread_mutex_unlock(&mutex1);\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2: Unlocked mutexes.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_mutex_init(&mutex1, NULL);\n    pthread_mutex_init(&mutex2, NULL);\n\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, thread_func1, NULL);\n    pthread_create(&t2, NULL, thread_func2, NULL);\n\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "כן, קוד זה עלול להוביל למצב של קיפאון (deadlock).\n\n**הסבר:** קיפאון יכול להתרחש בתרחיש הבא:\n1.  Thread 1 תופס בהצלחה את `mutex1`.\n2.  במקביל, Thread 2 תופס בהצלחה את `mutex2`.\n3.  לאחר מכן, Thread 1 מנסה לתפוס את `mutex2`, אך הוא כבר תפוס על ידי Thread 2. לכן, Thread 1 נחסם וממתין ש-Thread 2 ישחרר את `mutex2`.\n4.  באותו זמן, Thread 2 מנסה לתפוס את `mutex1`, אך הוא כבר תפוס על ידי Thread 1. לכן, Thread 2 נחסם וממתין ש-Thread 1 ישחרר את `mutex1`.\n\nכתוצאה מכך, שני התהליכונים ממתינים זה לזה באופן הדדי ואינסופי, וזהו מצב של קיפאון (Circular Wait).\n\n**מניעה:** הדרך הנפוצה והפשוטה ביותר למנוע קיפאון במקרה זה היא להבטיח סדר עקבי של תפיסת מנעולים (consistent locking order) בכל התהליכונים. כלומר, שכל התהליכונים ינסו לתפוס את המנעולים באותו סדר. לדוגמה, שניהם יתפסו קודם את `mutex1` ואז את `mutex2`.\n\n**דוגמה לתיקון (שמירה על סדר `mutex1` ואז `mutex2`):**\n```c\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 1: Locked mutex1. Trying to lock mutex2...\\n\");\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 1: Locked mutex2. Critical section...\\n\");\n    pthread_mutex_unlock(&mutex2);\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 1: Unlocked mutexes.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to lock mutex1...\\n\"); // Changed order\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2: Locked mutex1. Trying to lock mutex2...\\n\"); // Changed order\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2: Locked mutex2. Critical section...\\n\");\n    pthread_mutex_unlock(&mutex2); // Unlocked in correct order\n    pthread_mutex_unlock(&mutex1); // Unlocked in correct order\n    printf(\"Thread 2: Unlocked mutexes.\\n\");\n    return NULL;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0414__Deadlocks__CodeAnalysis__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:24:00", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Concurrency", "Mutexes"], "content": {"text": "השאלה עוסקת בקיפאון (Deadlock). נתון קטע הקוד הבא המשתמש בשני מנעולים (mutexes) ושני תהליכונים (threads).\n\nאנא נתח את הקוד וענה על השאלה הבאה: האם קיפאון יכול להתרחש בקטע קוד זה? אם כן, הסבר מדוע וכיצד הוא מתרחש. אם לא, הסבר מדוע לא.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex1;\npthread_mutex_t mutex2;\n\nvoid* thread_func1(void* arg) {\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 1 acquired mutex1\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 1 acquired mutex2\\n\");\n    \n    // Critical section\n    \n    pthread_mutex_unlock(&mutex2);\n    pthread_mutex_unlock(&mutex1);\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2 acquired mutex2\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2 acquired mutex1\\n\");\n    \n    // Critical section\n    \n    pthread_mutex_unlock(&mutex1);\n    pthread_mutex_unlock(&mutex2);\n    return NULL;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, קיפאון (Deadlock) יכול להתרחש בקטע קוד זה.\n\n**הסבר:**\nקיפאון מתרחש כאשר קבוצה של תהליכים או תהליכונים חוסמת זה את זה, כך שכל אחד ממתין למשאב המוחזק על ידי אחר בקבוצה. ארבעת התנאים ההכרחיים לקיפאון הם:\n1.  **מניעה הדדית (Mutual Exclusion)**: משאבים (כמו מנעולים) ניתנים לשימוש על ידי תהליך אחד בלבד בכל רגע נתון. במקרה זה, `mutex1` ו-`mutex2` מספקים מניעה הדדית.\n2.  **החזקה והמתנה (Hold and Wait)**: תהליך מחזיק במשאב אחד לפחות וממתין למשאב נוסף המוחזק על ידי תהליך אחר. בקוד הנתון, `thread_func1` מחזיק ב-`mutex1` וממתין ל-`mutex2`, בעוד ש-`thread_func2` מחזיק ב-`mutex2` וממתין ל-`mutex1`.\n3.  **אי-הפקעה (No Preemption)**: משאבים אינם ניתנים להפקעה מתהליך שמחזיק בהם; הם משוחררים רק מרצון על ידי התהליך המחזיק בהם. המנעולים בקוד פועלים באופן זה.\n4.  **המתנה מעגלית (Circular Wait)**: קיימת שרשרת סגורה של תהליכים, כאשר כל תהליך בשרשרת ממתין למשאב המוחזק על ידי התהליך הבא בשרשרת. זהו התנאי העיקרי שמוביל לקיפאון כאן.\n\n**תרחיש קיפאון ספציפי:**\nנניח ששני התהליכונים מתחילים לרוץ בו-זמנית:\n1.  `thread_func1` מבצע `pthread_mutex_lock(&mutex1)` בהצלחה, תופס את `mutex1`.\n2.  מיד לאחר מכן (או במקביל), `thread_func2` מבצע `pthread_mutex_lock(&mutex2)` בהצלחה, תופס את `mutex2`.\n3.  כעת, `thread_func1` מחזיק ב-`mutex1` ומגיע לשורה `pthread_mutex_lock(&mutex2)`. מכיוון ש-`mutex2` מוחזק על ידי `thread_func2`, `thread_func1` נכנס למצב המתנה.\n4.  באותו זמן, `thread_func2` מחזיק ב-`mutex2` ומגיע לשורה `pthread_mutex_lock(&mutex1)`. מכיוון ש-`mutex1` מוחזק על ידי `thread_func1`, `thread_func2` נכנס למצב המתנה.\n\nבנקודה זו, `thread_func1` ממתין ל-`mutex2` שמוחזק על ידי `thread_func2`, ו-`thread_func2` ממתין ל-`mutex1` שמוחזק על ידי `thread_func1`. נוצרה המתנה מעגלית, ושני התהליכונים חסומים זה על ידי זה, מה שמוביל לקיפאון. קריאות ה-`sleep(1)` מגבירות את הסבירות שאכן יתרחש מצב כזה על ידי יצירת חלון זמן שבו שני המנעולים יכולים להיתפס על ידי תהליכונים שונים לפני שהם מנסים לתפוס את המנעול השני."}, "difficulty_estimation": "Easy", "_source_file": "0415__Deadlocks__CodeAnalysis__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:24:18", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Concurrency", "Mutexes"], "content": {"text": "נתון קוד C המשתמש בספריות `pthread` ליצירת שני תהליכונים (threads) ושני מנעולים (mutexes). כל תהליכון מנסה לרכוש את שני המנעולים בסדר מסוים. נתחו את הקוד הבא וענו על השאלה:\n\nהאם קיים סיכון לקיפאון (deadlock) בקוד זה? אם כן, הסבירו מדוע וכיצד ניתן למנוע אותו. אם לא, הסבירו מדוע.", "code_snippet": "```c\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutexA;\npthread_mutex_t mutexB;\n\nvoid* thread1_func(void* arg) {\n    printf(\"Thread 1: Trying to lock mutexA...\\n\");\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 1: Locked mutexA. Trying to lock mutexB...\\n\");\n    sleep(1); // Simulate some work or context switch\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 1: Locked mutexB. Doing work...\\n\");\n    // Critical section\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 1: Unlocked mutexA and mutexB. Exiting.\\n\");\n    return NULL;\n}\n\nvoid* thread2_func(void* arg) {\n    printf(\"Thread 2: Trying to lock mutexB...\\n\");\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 2: Locked mutexB. Trying to lock mutexA...\\n\");\n    sleep(1); // Simulate some work or context switch\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 2: Locked mutexA. Doing work...\\n\");\n    // Critical section\n    pthread_mutex_unlock(&mutexA);\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 2: Unlocked mutexB and mutexA. Exiting.\\n\");\n    return NULL;\n}\n\n// main function (not part of the snippet for analysis, but for context)\n// int main() {\n//     pthread_t tid1, tid2;\n//     pthread_mutex_init(&mutexA, NULL);\n//     pthread_mutex_init(&mutexB, NULL);\n\n//     pthread_create(&tid1, NULL, thread1_func, NULL);\n//     pthread_create(&tid2, NULL, thread2_func, NULL);\n\n//     pthread_join(tid1, NULL);\n//     pthread_join(tid2, NULL);\n\n//     pthread_mutex_destroy(&mutexA);\n//     pthread_mutex_destroy(&mutexB);\n//     return 0;\n// }\n```", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "כן, קיים סיכון לקיפאון (deadlock) בקוד זה. הקיפאון יכול להתרחש כאשר תהליכון 1 רוכש בהצלחה את `mutexA` ותהליכון 2 רוכש בהצלחה את `mutexB`. בשלב זה, תהליכון 1 מחזיק ב-`mutexA` וממתין ל-`mutexB` (שמוחזק על ידי תהליכון 2), בעוד שתהליכון 2 מחזיק ב-`mutexB` וממתין ל-`mutexA` (שמוחזק על ידי תהליכון 1). נוצרת כאן המתנה מעגלית.\n\nהתנאים לקיפאון מתקיימים:\n1.  **מניעה הדדית (Mutual Exclusion):** המנעולים מבטיחים שרק תהליכון אחד יכול להחזיק משאב (מנעול) בכל רגע נתון. תנאי זה מתקיים.\n2.  **החזקה והמתנה (Hold and Wait):** כל תהליכון מחזיק במנעול אחד וממתין למנעול נוסף. תהליכון 1 מחזיק ב-`mutexA` וממתין ל-`mutexB`, ותהליכון 2 מחזיק ב-`mutexB` וממתין ל-`mutexA`. תנאי זה מתקיים.\n3.  **אי-הפקעה (No Preemption):** לא ניתן להפקיע מנעול מתהליכון שמחזיק בו בכוח. תנאי זה מתקיים.\n4.  **המתנה מעגלית (Circular Wait):** תהליכון 1 ממתין למשאב שמוחזק על ידי תהליכון 2, ותהליכון 2 ממתין למשאב שמוחזק על ידי תהליכון 1, ויוצר מעגל תלות. תנאי זה מתקיים.\n\n**פתרון למניעת קיפאון:**\nכדי למנוע קיפאון זה, יש להבטיח סדר עקבי ברכישת המנעולים על ידי כל התהליכונים. לדוגמה, שני התהליכונים צריכים לרכוש קודם את `mutexA` ולאחר מכן את `mutexB` (או להיפך, כל עוד הסדר זהה בשניהם).\n\nדוגמה לתיקון:\n```c\nvoid* thread1_func(void* arg) {\n    pthread_mutex_lock(&mutexA);\n    sleep(1);\n    pthread_mutex_lock(&mutexB);\n    // Critical section\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n    return NULL;\n}\n\nvoid* thread2_func(void* arg) {\n    pthread_mutex_lock(&mutexA); // Changed order to match thread1\n    sleep(1);\n    pthread_mutex_lock(&mutexB); // Changed order to match thread1\n    // Critical section\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n    return NULL;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0416__Deadlocks__CodeAnalysis__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:24:35", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Deadlocks", "Concurrency", "Mutexes", "Threads"], "content": {"text": "נתון קטע הקוד הבא המשתמש בשני מנעולים ושני תהליכונים (threads). נתחו את הקוד וענו על השאלה: האם קטע הקוד עלול להוביל למצב של קיפאון (Deadlock)? נמקו את תשובתכם.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex1;\npthread_mutex_t mutex2;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to acquire mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 1: Acquired mutex1. Trying to acquire mutex2...\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 1: Acquired mutex2. Critical section...\\n\");\n    // Critical section\n    pthread_mutex_unlock(&mutex2);\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 1: Released mutexes.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to acquire mutex2...\\n\");\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2: Acquired mutex2. Trying to acquire mutex1...\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2: Acquired mutex1. Critical section...\\n\");\n    // Critical section\n    pthread_mutex_unlock(&mutex1);\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2: Released mutexes.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&mutex1, NULL);\n    pthread_mutex_init(&mutex2, NULL);\n\n    pthread_create(&tid1, NULL, thread_func1, NULL);\n    pthread_create(&tid2, NULL, thread_func2, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, קטע הקוד עלול להוביל למצב של קיפאון (Deadlock).\n\nקיפאון מתרחש כאשר כל אחד משני התהליכונים (threads) מחזיק במשאב (מנעול) אחד וממתין למשאב השני המוחזק על ידי התהליכון האחר. במקרה זה:\n\n*   **תהליכון 1 (thread_func1)** מנסה לרכוש את `mutex1` ולאחר מכן את `mutex2`.\n*   **תהליכון 2 (thread_func2)** מנסה לרכוש את `mutex2` ולאחר מכן את `mutex1`.\n\n**תרחיש לקיפאון:**\n1.  תהליכון 1 מתחיל לרוץ ורוכש בהצלחה את `mutex1`.\n2.  מתרחש מעבר הקשר (context switch) ותהליכון 2 מתחיל לרוץ.\n3.  תהליכון 2 רוכש בהצלחה את `mutex2`.\n4.  כעת, תהליכון 1 מנסה לרכוש את `mutex2`, אך הוא כבר מוחזק על ידי תהליכון 2. לכן, תהליכון 1 נחסם וממתין לשחרורו.\n5.  תהליכון 2 מנסה לרכוש את `mutex1`, אך הוא כבר מוחזק על ידי תהליכון 1. לכן, תהליכון 2 נחסם וממתין לשחרורו.\n\nבמצב זה, שני התהליכונים חסומים באופן הדדי וכל אחד מהם ממתין למשאב שהשני מחזיק, וכך נוצר קיפאון. הכללת ה-`sleep(1)` בקוד מגבירה את הסיכוי למעבר הקשר כזה שיביא לתרחיש הקיפאון."}, "difficulty_estimation": "Medium", "_source_file": "0417__Deadlocks__CodeAnalysis__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:24:48", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Mutexes", "Concurrency"], "content": {"text": "נתון קטע הקוד הבא המדמה שני חוטים המנסים לבצע פעולות על משאבים שונים. נתחו את הקוד וענו על השאלות:", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n\npthread_mutex_t mutex1;\npthread_mutex_t mutex2;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Attempting to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 1: Locked mutex1. Attempting to lock mutex2...\\n\");\n    usleep(100000); // Simulate some work or context switch\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 1: Locked mutex2. Performing operations...\\n\");\n    // Critical section\n    printf(\"Thread 1: Releasing mutex2...\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 1: Releasing mutex1...\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 1: Exiting.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Attempting to lock mutex2...\\n\");\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2: Locked mutex2. Attempting to lock mutex1...\\n\");\n    usleep(100000); // Simulate some work or context switch\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2: Locked mutex1. Performing operations...\\n\");\n    // Critical section\n    printf(\"Thread 2: Releasing mutex1...\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 2: Releasing mutex2...\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2: Exiting.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n\n    pthread_mutex_init(&mutex1, NULL);\n    pthread_mutex_init(&mutex2, NULL);\n\n    pthread_create(&t1, NULL, thread_func1, NULL);\n    pthread_create(&t2, NULL, thread_func2, NULL);\n\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n\n    printf(\"Main: Both threads finished.\\n\");\n    return 0;\n}\n", "options": null}, "sub_questions": [{"id": "a", "text": "האם קטע הקוד הנתון עלול להוביל לקיפאון (Deadlock)? נמקו את תשובתכם תוך התייחסות לתנאים ההכרחיים לקיפאון.", "code_snippet": null, "options": ["כן", "לא"], "solution": {"is_present_in_file": true, "correct_option": "כן", "explanation": "כן, קטע הקוד עלול להוביל לקיפאון (Deadlock). קיפאון יכול להתרחש כאשר מתקיימים ארבעת התנאים ההכרחיים לקיפאון:\n1.  **מניעה הדדית (Mutual Exclusion)**: המנעולים `mutex1` ו-`mutex2` הם משאבים שאינם ניתנים לשיתוף. רק חוט אחד יכול להחזיק במנעול נתון בכל רגע נתון.\n2.  **החזקה והמתנה (Hold and Wait)**: חוט 1 לוכד את `mutex1` ולאחר מכן מנסה לנעול את `mutex2`. במקביל, חוט 2 לוכד את `mutex2` ולאחר מכן מנסה לנעול את `mutex1`. כל חוט מחזיק במשאב אחד (מנעול) וממתין למשאב אחר שמוחזק על ידי חוט אחר.\n3.  **אי-הפקעה (No Preemption)**: לא ניתן להפקיע מנעול מחוט שהחזיק בו; רק החוט עצמו יכול לשחרר אותו באופן יזום באמצעות `pthread_mutex_unlock`.\n4.  **המתנה מעגלית (Circular Wait)**: חוט 1 ממתין למשאב (`mutex2`) שמוחזק על ידי חוט 2, בעוד שחוט 2 ממתין למשאב (`mutex1`) שמוחזק על ידי חוט 1. נוצרת שרשרת המתנה מעגלית.\n\n**תרחיש לדוגמה לקיפאון:**\nא.  חוט 1 מבצע `pthread_mutex_lock(&mutex1)` ומצליח לנעול את `mutex1`.\nב.  חוט 2 מבצע `pthread_mutex_lock(&mutex2)` ומצליח לנעול את `mutex2`.\nג.  חוט 1 מנסה לבצע `pthread_mutex_lock(&mutex2)`, אך `mutex2` נעול על ידי חוט 2, ולכן חוט 1 נחסם ונכנס למצב המתנה.\nד.  חוט 2 מנסה לבצע `pthread_mutex_lock(&mutex1)`, אך `mutex1` נעול על ידי חוט 1, ולכן חוט 2 נחסם ונכנס למצב המתנה.\nבשלב זה, שני החוטים חסומים באופן הדדי וממתינים זה לזה, מה שמוביל לקיפאון."}}, {"id": "b", "text": "הצע פתרון לבעיית הקיפאון בקטע קוד זה. הצג את קטע הקוד המתוקן והסבר בקצרה מדוע הפתרון מונע קיפאון.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n\npthread_mutex_t mutex1;\npthread_mutex_t mutex2;\n\n// Solution: Ensure consistent lock ordering\nvoid* thread_func1_fixed(void* arg) {\n    printf(\"Thread 1 (fixed): Attempting to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 1 (fixed): Locked mutex1. Attempting to lock mutex2...\\n\");\n    usleep(100000);\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 1 (fixed): Locked mutex2. Performing operations...\\n\");\n    // Critical section\n    printf(\"Thread 1 (fixed): Releasing mutex2...\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 1 (fixed): Releasing mutex1...\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 1 (fixed): Exiting.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2_fixed(void* arg) {\n    printf(\"Thread 2 (fixed): Attempting to lock mutex1...\\n\"); // Changed order\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2 (fixed): Locked mutex1. Attempting to lock mutex2...\\n\"); // Changed order\n    usleep(100000);\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2 (fixed): Locked mutex2. Performing operations...\\n\");\n    // Critical section\n    printf(\"Thread 2 (fixed): Releasing mutex2...\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2 (fixed): Releasing mutex1...\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 2 (fixed): Exiting.\\n\");\n    return NULL;\n}\n\nint main_fixed() { // Renamed main to avoid conflict if compiled with original\n    pthread_t t1, t2;\n\n    pthread_mutex_init(&mutex1, NULL);\n    pthread_mutex_init(&mutex2, NULL);\n\n    pthread_create(&t1, NULL, thread_func1_fixed, NULL);\n    pthread_create(&t2, NULL, thread_func2_fixed, NULL);\n\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n\n    printf(\"Main (fixed): Both threads finished.\\n\");\n    return 0;\n}", "options": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון הנפוץ והפשוט ביותר למניעת קיפאון במקרה זה הוא לוודא שכל החוטים מנסים לתפוס את המנעולים באותו סדר קבוע (Fixed Lock Ordering). על ידי אכיפת סדר קבוע לרכישת מנעולים, אנו מונעים את תנאי ההמתנה המעגלית (Circular Wait).\n\nכפי שמוצג בקטע הקוד המתוקן, גם `thread_func1_fixed` וגם `thread_func2_fixed` מנסים לתפוס קודם את `mutex1` ולאחר מכן את `mutex2`. המשמעות היא שאף פעם לא ייווצר מצב שבו חוט 1 מחזיק את `mutex1` וממתין ל-`mutex2`, בעוד חוט 2 מחזיק את `mutex2` וממתין ל-`mutex1`.\n\n**הסבר מדוע הפתרון מונע קיפאון:**\nאם חוט 1 לוכד את `mutex1`, וחוט 2 מנסה גם הוא לנעול את `mutex1`, חוט 2 יחסם וימתין שחוט 1 ישחרר את `mutex1`. חוט 1, לאחר שינעל את `mutex1`, ימשיך לנעול את `mutex2`. אם `mutex2` פנוי, הוא ינעל אותו ויבצע את פעולותיו. אם `mutex2` היה נעול על ידי חוט אחר (שלא ייתכן שיהיה חוט 2, כי הוא ממתין ל-`mutex1`), חוט 1 היה ממתין לו, אך עדיין לא נוצרת המתנה מעגלית בין חוט 1 לחוט 2. בסופו של דבר, חוט 1 ישחרר את שני המנעולים, ואז חוט 2 יוכל לנעול את `mutex1` ואז את `mutex2` (או להיפך, אם חוט 2 היה הראשון לתפוס את `mutex1`).\n\nבדרך זו, אנו מבטיחים שגם אם חוטים מתחרים על אותם משאבים, הם יעשו זאת בסדר עקבי, ובכך נמנע את היווצרות שרשרת ההמתנה המעגלית, שהיא אחד מארבעת התנאים ההכרחיים לקיפאון."}}], "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": null}, "difficulty_estimation": "Medium", "_source_file": "0418__Deadlocks__CodeAnalysis__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:25:15", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Mutexes", "Concurrency", "Threads"], "content": {"text": "נתון קטע הקוד הבא המדמה שני תהליכונים (threads) המנסים לגשת לשני משאבים (המיוצגים על ידי mutexes).", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutexA;\npthread_mutex_t mutexB;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to acquire Mutex A...\\n\");\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 1: Acquired Mutex A. Trying to acquire Mutex B...\\n\");\n    sleep(1); // Introduce a delay to increase deadlock probability\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 1: Acquired Mutex B. Critical Section 1.\\n\");\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 1: Released Mutex A and B.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to acquire Mutex B...\\n\");\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 2: Acquired Mutex B. Trying to acquire Mutex A...\\n\");\n    sleep(1); // Introduce a delay\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 2: Acquired Mutex A. Critical Section 2.\\n\");\n    pthread_mutex_unlock(&mutexA);\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 2: Released Mutex B and A.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&mutexA, NULL);\n    pthread_mutex_init(&mutexB, NULL);\n\n    pthread_create(&tid1, NULL, thread_func1, NULL);\n    pthread_create(&tid2, NULL, thread_func2, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    pthread_mutex_destroy(&mutexA);\n    pthread_mutex_destroy(&mutexB);\n\n    printf(\"Main: Program finished.\\n\");\n    return 0;\n}"}, "sub_questions": [{"id": "a", "text": "האם קיים סיכוי למצב קיפאון (Deadlock) בקטע קוד זה? נמק את תשובתך על בסיס ארבעת התנאים לקיפאון.", "code_snippet": null, "options": ["כן", "לא"], "solution": {"is_present_in_file": true, "correct_option": "כן", "explanation": "כן, קיים סיכוי למצב קיפאון (Deadlock).\nארבעת התנאים לקיפאון מתקיימים במערכת זו:\n1.  **מניעה הדדית (Mutual Exclusion):** המוטקסים (mutexA, mutexB) מספקים מניעה הדדית, כלומר רק תהליכון אחד יכול להחזיק במוטקס נתון בכל רגע. אם תהליכון מנסה לתפוס מוטקס תפוס, הוא נחסם עד שהמוטקס ישוחרר.\n2.  **החזקה והמתנה (Hold and Wait):** כל תהליכון יכול להחזיק במוטקס אחד (לדוגמה, Thread 1 מחזיק ב-mutexA) ולהמתין למוטקס אחר (Thread 1 ממתין ל-mutexB). במקרה של קיפאון, Thread 1 יחזיק ב-mutexA וימתין ל-mutexB, בעוד Thread 2 יחזיק ב-mutexB וימתין ל-mutexA.\n3.  **אי-שלילה (No Preemption):** המוטקסים לא נשללים בכוח מתהליכון שמחזיק בהם; הם משוחררים רק מרצון על ידי התהליכון שהחזיק בהם. מערכת ההפעלה או תהליכון אחר אינם יכולים לכפות שחרור של מוטקס.\n4.  **המתנה מעגלית (Circular Wait):** תרחיש אפשרי לקיפאון הוא כדלקמן:\n    *   Thread 1 מבצע `pthread_mutex_lock(&mutexA)` ומצליח לתפוס את mutexA.\n    *   מיד לאחר מכן (או תוך כדי ה-`sleep(1)` של Thread 1), Thread 2 מבצע `pthread_mutex_lock(&mutexB)` ומצליח לתפוס את mutexB.\n    *   כעת, Thread 1 מנסה לבצע `pthread_mutex_lock(&mutexB)` אך mutexB מוחזק על ידי Thread 2, ולכן Thread 1 נחסם.\n    *   ובמקביל, Thread 2 מנסה לבצע `pthread_mutex_lock(&mutexA)` אך mutexA מוחזק על ידי Thread 1, ולכן Thread 2 נחסם.\n    *   נוצר מעגל המתנה: Thread 1 ממתין ל-Thread 2 שישחרר את mutexB, ו-Thread 2 ממתין ל-Thread 1 שישחרר את mutexA. אף אחד מהם לא יכול להמשיך, לשחרר את המשאב שברשותו, או להתקדם, וכתוצאה מכך נוצר מצב קיפאון. ה-`sleep(1)` המכוון בקוד מגדיל את הסבירות להתרחשות תרחיש זה על ידי יצירת חלון זמן שבו שני התהליכונים יכולים לתפוס את המוטקס הראשון שלהם לפני שהשני ניסה לתפוס את המוטקס השני."}}], "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": null}, "difficulty_estimation": "Medium", "_source_file": "0419__Deadlocks__CodeAnalysis__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:25:36", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Deadlocks", "Concurrency", "Mutexes", "Threads"], "content": {"text": "נתון קטע הקוד הבא המשתמש במנעולים (mutexes) ובחוטים (threads) לגישה למשאבים משותפים:\n\nהאם קיים סיכון לקיפאון (deadlock) בתוכנית זו? אם כן, הסבר מדוע וכיצד הוא יכול להתרחש.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutexA;\npthread_mutex_t mutexB;\n\nvoid *thread_func1(void *arg) {\n    printf(\"Thread 1: Attempting to lock Mutex A...\\n\");\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 1: Mutex A locked. Attempting to lock Mutex B...\\n\");\n    sleep(1); // Introduce a delay to increase likelihood of deadlock\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 1: Mutex B locked. Critical section for Thread 1.\\n\");\n\n    // Do some work\n    printf(\"Thread 1: Releasing Mutex B.\\n\");\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 1: Releasing Mutex A.\\n\");\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 1: Exiting.\\n\");\n    return NULL;\n}\n\nvoid *thread_func2(void *arg) {\n    printf(\"Thread 2: Attempting to lock Mutex B...\\n\");\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 2: Mutex B locked. Attempting to lock Mutex A...\\n\");\n    sleep(1); // Introduce a delay\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 2: Mutex A locked. Critical section for Thread 2.\\n\");\n\n    // Do some work\n    printf(\"Thread 2: Releasing Mutex A.\\n\");\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 2: Releasing Mutex B.\\n\");\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 2: Exiting.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&mutexA, NULL);\n    pthread_mutex_init(&mutexB, NULL);\n\n    pthread_create(&tid1, NULL, thread_func1, NULL);\n    pthread_create(&tid2, NULL, thread_func2, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    pthread_mutex_destroy(&mutexA);\n    pthread_mutex_destroy(&mutexB);\n\n    printf(\"Main: All threads finished.\\n\");\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, קיים סיכון לקיפאון (deadlock) בתוכנית זו. קיפאון יכול להתרחש כאשר מתקיימים בו זמנית ארבעה תנאים הכרחיים:\n\n1.  **מניעה הדדית (Mutual Exclusion):** מתקיימת. המנעולים `mutexA` ו-`mutexB` מבטיחים שרק חוט אחד יכול להחזיק כל משאב (מנעול) בכל רגע נתון. אם חוט אחד מחזיק מנעול, חוט אחר המנסה לתפוס אותו ייחסם.\n\n2.  **החזקה והמתנה (Hold and Wait):** מתקיימת. כל חוט תופס מנעול אחד (לדוגמה, `thread_func1` תופס את `mutexA`, ו-`thread_func2` תופס את `mutexB`) וממתין למנעול השני תוך כדי החזקת המנעול הראשון. הם לא משחררים את המשאב שהם כבר מחזיקים.\n\n3.  **אי-הפקעה (No Preemption):** מתקיימת. לא ניתן להפקיע מנעול מחוט שמחזיק בו; חוט חייב לשחרר אותו מרצונו לאחר שסיים להשתמש בו. מערכת ההפעלה אינה יכולה לקחת מנעול מחוט בכוח.\n\n4.  **המתנה מעגלית (Circular Wait):** מתקיימת. חוט 1 (`thread_func1`) מנסה לתפוס את `mutexA` ולאחר מכן את `mutexB`. חוט 2 (`thread_func2`) מנסה לתפוס את `mutexB` ולאחר מכן את `mutexA`. אם חוט 1 תופס את `mutexA` (שורת קוד 11) ומיד לאחר מכן חוט 2 תופס את `mutexB` (שורת קוד 27), אז:\n    *   חוט 1 ימתין ל-`mutexB` שמוחזק על ידי חוט 2 (שורת קוד 14).\n    *   חוט 2 ימתין ל-`mutexA` שמוחזק על ידי חוט 1 (שורת קוד 30).\n    מצב זה יוצר מעגל המתנה שבו כל חוט ממתין למשאב שמוחזק על ידי חוט אחר במעגל, מה שמוביל לקיפאון.\n\nהשימוש בפונקציית `sleep(1)` בתוך כל חוט מגדיל את הסיכוי לכך ששני החוטים יתפסו את המנעולים שלהם (אחד כל אחד) לפני שהם ינסו לתפוס את המנעול השני, ובכך יגיעו למצב של המתנה מעגלית וקיפאון."}, "difficulty_estimation": "Medium", "_source_file": "0420__Deadlocks__CodeAnalysis__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:25:51", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Deadlocks", "Concurrency", "Synchronization", "Mutexes", "Threads"], "content": {"text": "נתון קטע הקוד הבא המשתמש במנעולים (mutexes) ובחוטים (threads) לסינכרון. נתח את הקוד וענה על השאלה:", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutexA;\npthread_mutex_t mutexB;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to lock mutexA...\\n\");\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 1: Locked mutexA. Trying to lock mutexB...\\n\");\n    sleep(1); // Introduce delay to increase likelihood of deadlock\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 1: Locked mutexB. Doing work...\\n\");\n    // Simulate work\n    sleep(1);\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 1: Unlocked mutexA and mutexB. Exiting.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to lock mutexB...\\n\");\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 2: Locked mutexB. Trying to lock mutexA...\\n\");\n    sleep(1); // Introduce delay\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 2: Locked mutexA. Doing work...\\n\");\n    // Simulate work\n    sleep(1);\n    pthread_mutex_unlock(&mutexA);\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 2: Unlocked mutexB and mutexA. Exiting.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&mutexA, NULL);\n    pthread_mutex_init(&mutexB, NULL);\n\n    pthread_create(&tid1, NULL, thread_func1, NULL);\n    pthread_create(&tid2, NULL, thread_func2, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    pthread_mutex_destroy(&mutexA);\n    pthread_mutex_destroy(&mutexB);\n\n    printf(\"Main: Both threads finished.\\n\");\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "a", "text": "האם קטע קוד זה עלול להוביל למצב קיפאון (deadlock)? אם כן, הסבר מדוע וציין אילו מהתנאים ההכרחיים למצב קיפאון מתקיימים בקוד זה.", "code_snippet": null, "options": ["כן", "לא"], "solution": {"is_present_in_file": true, "correct_option": "כן", "explanation": "כן, קטע קוד זה עלול להוביל למצב קיפאון (deadlock). מצב קיפאון מתרחש כאשר שני חוטים או יותר חוסמים זה את זה וכל אחד מהם ממתין למשאב שמוחזק על ידי חוט אחר במעגל. ארבעת התנאים ההכרחיים למצב קיפאון מתקיימים בקוד זה:\n\n1.  **מניעה הדדית (Mutual Exclusion)**: מתקיים. המנעולים `mutexA` ו-`mutexB` מבטיחים שרק חוט אחד יכול להחזיק כל מנעול בזמן נתון. אם חוט אחד לוקח מנעול, חוט אחר לא יכול לקחת אותו עד שהוא ישוחרר.\n\n2.  **החזק והמתן (Hold and Wait)**: מתקיים. חוט `thread_func1` מחזיק את `mutexA` וממתין ל-`mutexB`. במקביל, חוט `thread_func2` מחזיק את `mutexB` וממתין ל-`mutexA`. כל חוט מחזיק במשאב אחד לפחות בזמן שהוא ממתין למשאב נוסף.\n\n3.  **אי-הפקעה (No Preemption)**: מתקיים. לא ניתן להפקיע מנעול מחוט שמחזיק אותו. המנעולים ישוחררו רק מרצונם החופשי של החוטים המחזיקים אותם, באמצעות `pthread_mutex_unlock`.\n\n4.  **המתנה מעגלית (Circular Wait)**: מתקיים. קיים מעגל המתנה: חוט `thread_func1` ממתין ל-`mutexB` שמוחזק על ידי `thread_func2`, וחוט `thread_func2` ממתין ל-`mutexA` שמוחזק על ידי `thread_func1`. זה יוצר תלות מעגלית שמונעת מכל אחד מהחוטים להתקדם.\n\nכתוצאה מכך, אם החוטים ירוצו בסדר קריטי שבו כל אחד מהם יתפוס מנעול אחד וינסה לתפוס את השני, שניהם ייתקעו בהמתנה אינסופית."}}], "points": 15, "solution": null, "difficulty_estimation": "Medium", "_source_file": "0421__Deadlocks__CodeAnalysis__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:26:08", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Deadlocks", "Concurrency", "Synchronization", "Mutexes"], "content": {"text": "נתון קטע הקוד הבא המשתמש במנעולים (mutexes) של pthreads. נתח את הקוד וענה על השאלות:", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex1;\npthread_mutex_t mutex2;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Attempting to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 1: Locked mutex1. Attempting to lock mutex2...\\n\");\n    sleep(1); // Introduce a delay to increase likelihood of deadlock\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 1: Locked mutex2. Critical section...\\n\");\n    // Do some work\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 1: Unlocked mutex2.\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 1: Unlocked mutex1. Exiting.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Attempting to lock mutex2...\\n\");\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2: Locked mutex2. Attempting to lock mutex1...\\n\");\n    sleep(1); // Introduce a delay to increase likelihood of deadlock\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2: Locked mutex1. Critical section...\\n\");\n    // Do some work\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 2: Unlocked mutex1.\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2: Unlocked mutex2. Exiting.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&mutex1, NULL);\n    pthread_mutex_init(&mutex2, NULL);\n\n    printf(\"Main: Creating threads...\\n\");\n    pthread_create(&tid1, NULL, thread_func1, NULL);\n    pthread_create(&tid2, NULL, thread_func2, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n\n    printf(\"Main: All threads finished. Exiting.\\n\");\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "a", "text": "האם עלול להיווצר קיפאון (deadlock) בתוכנית זו?", "code_snippet": null, "options": ["כן", "לא"], "solution": {"is_present_in_file": true, "correct_option": "כן", "explanation": "קיפאון אכן עלול להיווצר. המצב הקלאסי של קיפאון מתרחש כאשר שני חוטים או יותר מנסים לתפוס משאבים (במקרה זה, מנעולים) בסדר הפוך. חוט 1 תופס את `mutex1` ואז מנסה לתפוס את `mutex2`. חוט 2 תופס את `mutex2` ואז מנסה לתפוס את `mutex1`. אם חוט 1 תופס את `mutex1` וחוט 2 תופס את `mutex2` בערך באותו זמן, ואז כל אחד מנסה לתפוס את המנעול השני, שניהם יחסמו וייכנסו למצב של קיפאון (המתנה מעגלית)."}}, {"id": "b", "text": "כיצד ניתן למנוע קיפאון במקרה זה?", "code_snippet": null, "options": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ניתן למנוע קיפאון על ידי אכיפת סדר תפיסת משאבים עקבי (Resource Ordering). כלומר, כל החוטים צריכים לתפוס את המנעולים באותו סדר. לדוגמה, שניהם יתפסו תמיד את `mutex1` קודם ואז את `mutex2`. זה מונע את התנאי של המתנה מעגלית (Circular Wait), שהוא הגורם העיקרי לקיפאון במקרה זה. דרכים נוספות למניעה כוללות: \n1.  **החזקה והמתנה (Hold and Wait):** ניתן למנוע על ידי דרישה מחוט לתפוס את כל המשאבים הדרושים לו בבת אחת, או לשחרר את כל המשאבים שהוא מחזיק לפני שהוא מנסה לתפוס משאב נוסף. במקרה זה, חוט יכול לנסות לתפוס את שני המנעולים באופן אטומי (לדוגמה, באמצעות `pthread_mutex_trylock` עם לוגיקת חזרה ושחרור אם לא הצליח לתפוס את שניהם). \n2.  **אי קדימות (No Preemption):** ניתן להשתמש בשיטות בהן ניתן להפקיע משאב מחוט שמחזיק בו, אך זה פחות נפוץ וקשה ליישום עם מנעולים סטנדרטיים. \n3.  **המתנה מעגלית (Circular Wait):** זוהי הבעיה העיקרית כאן, והיא נמנעת ביעילות על ידי אכיפת סדר תפיסת משאבים."}}], "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": null}, "difficulty_estimation": "Medium", "_source_file": "0422__Deadlocks__CodeAnalysis__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:26:29", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Concurrency", "Mutexes"], "content": {"text": "נתון קטע קוד המדמה תרחיש שבו שני חוטים (threads) מנסים לגשת למשאבים משותפים המוגנים על ידי מנעולים (mutexes). עיין בקוד וענה על השאלות הבאות:", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For usleep\n\npthread_mutex_t mutexA;\npthread_mutex_t mutexB;\n\nvoid *thread_func1(void *arg) {\n    printf(\"Thread 1: Trying to acquire mutexA...\\n\");\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 1: Acquired mutexA. Trying to acquire mutexB...\\n\");\n    // Simulate some work or context switch\n    usleep(100000); // 100ms\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 1: Acquired mutexB. Performing work...\\n\");\n    // Critical section\n    printf(\"Thread 1: Releasing mutexB...\\n\");\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 1: Releasing mutexA...\\n\");\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 1: Exiting.\\n\");\n    return NULL;\n}\n\nvoid *thread_func2(void *arg) {\n    printf(\"Thread 2: Trying to acquire mutexB...\\n\");\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 2: Acquired mutexB. Trying to acquire mutexA...\\n\");\n    // Simulate some work or context switch\n    usleep(100000); // 100ms\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 2: Acquired mutexA. Performing work...\\n\");\n    // Critical section\n    printf(\"Thread 2: Releasing mutexA...\\n\");\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 2: Releasing mutexB...\\n\");\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 2: Exiting.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&mutexA, NULL);\n    pthread_mutex_init(&mutexB, NULL);\n\n    printf(\"Main: Creating Thread 1...\\n\");\n    pthread_create(&tid1, NULL, thread_func1, NULL);\n    printf(\"Main: Creating Thread 2...\\n\");\n    pthread_create(&tid2, NULL, thread_func2, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    pthread_mutex_destroy(&mutexA);\n    pthread_mutex_destroy(&mutexB);\n\n    printf(\"Main: All threads finished. Exiting.\\n\");\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "a", "text": "האם קטע הקוד הנתון עלול להוביל למצב של קיפאון (deadlock)? נמק.", "code_snippet": null, "options": ["כן", "לא"], "solution": {"is_present_in_file": true, "correct_option": "כן", "explanation": "כן, קטע הקוד עלול להוביל למצב של קיפאון (deadlock). זהו תרחיש קלאסי של המתנה מעגלית (circular wait), אחד מארבעת התנאים ההכרחיים לקיפאון. חוט 1 מנסה לרכוש את mutexA ואז את mutexB. חוט 2 מנסה לרכוש את mutexB ואז את mutexA. סדר רכישת המנעולים השונה בין החוטים יוצר פוטנציאל לקיפאון."}}, {"id": "b", "text": "אם כן, תאר סדר אירועים אפשרי שיוביל לקיפאון.", "code_snippet": null, "options": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "סדר אירועים אפשרי שיוביל לקיפאון:\n1.  חוט 1 מתחיל לרוץ ורוכש בהצלחה את mutexA.\n2.  מתבצעת החלפת הקשר (context switch) לחוט 2.\n3.  חוט 2 מתחיל לרוץ ורוכש בהצלחה את mutexB.\n4.  חוט 2 מנסה לרכוש את mutexA, אך הוא כרגע מוחזק על ידי חוט 1, ולכן חוט 2 נחסם וממתין.\n5.  מתבצעת החלפת הקשר לחוט 1.\n6.  חוט 1 מנסה לרכוש את mutexB, אך הוא כרגע מוחזק על ידי חוט 2, ולכן חוט 1 נחסם וממתין.\nבשלב זה, שני החוטים חסומים באופן הדדי: חוט 1 ממתין ל-mutexB שמוחזק על ידי חוט 2, וחוט 2 ממתין ל-mutexA שמוחזק על ידי חוט 1. אף אחד מהם לא יכול להמשיך, והמערכת נכנסת לקיפאון."}}, {"id": "c", "text": "הצע שינוי מינימלי בקוד כדי למנוע קיפאון, והסבר מדוע השינוי מונע אותו.", "code_snippet": null, "options": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כדי למנוע קיפאון, יש להבטיח שכל החוטים ירכשו את המנעולים באותו סדר עקבי. שינוי מינימלי יהיה לשנות את סדר רכישת המנעולים באחת מהפונקציות, לדוגמה ב-`thread_func2`, כך שהיא תנסה לרכוש את `mutexA` לפני `mutexB`.\n\n**השינוי המוצע ב-`thread_func2`:**\n```c\nvoid *thread_func2(void *arg) {\n    printf(\"Thread 2: Trying to acquire mutexA...\\n\"); // שינוי סדר\n    pthread_mutex_lock(&mutexA); // שינוי סדר\n    printf(\"Thread 2: Acquired mutexA. Trying to acquire mutexB...\\n\");\n    usleep(100000); // 100ms\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 2: Acquired mutexB. Performing work...\\n\");\n    // Critical section\n    printf(\"Thread 2: Releasing mutexB...\\n\");\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 2: Releasing mutexA...\\n\");\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 2: Exiting.\\n\");\n    return NULL;\n}\n```\n\n**הסבר:**\nעל ידי אכיפת סדר רכישה עקבי (לדוגמה, תמיד `mutexA` ואז `mutexB`) עבור כל החוטים, אנו מונעים את תנאי ה'המתנה מעגלית'. אם חוט 1 רוכש את `mutexA` וממתין ל-`mutexB`, וחוט 2 מנסה גם הוא לרכוש את `mutexA` (לפני `mutexB`), חוט 2 יחסם על `mutexA` ולא ירכוש את `mutexB`. בדרך זו, לעולם לא ייווצר מצב שבו חוט 1 מחזיק את `mutexA` וממתין ל-`mutexB` בעוד חוט 2 מחזיק את `mutexB` וממתין ל-`mutexA`. תמיד רק חוט אחד יוכל להחזיק ב-`mutexA` בבת אחת, ובכך נשבר המעגל של התלות ההדדית."}}], "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": null}, "difficulty_estimation": "Medium", "_source_file": "0423__Deadlocks__CodeAnalysis__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:26:48", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Mutexes", "Concurrency"], "content": {"text": "נתון קטע הקוד הבא המדמה הקצאת משאבים בין שני תהליכונים (threads). נתחו את הקוד וענו על השאלות:", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex1;\npthread_mutex_t mutex2;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 1: Locked mutex1. Trying to lock mutex2...\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 1: Locked mutex2. Performing work...\\n\");\n    // Critical section\n    printf(\"Thread 1: Unlocking mutex2...\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 1: Unlocking mutex1...\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 1: Finished.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to lock mutex2...\\n\");\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2: Locked mutex2. Trying to lock mutex1...\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2: Locked mutex1. Performing work...\\n\");\n    // Critical section\n    printf(\"Thread 2: Unlocking mutex1...\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 2: Unlocking mutex2...\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2: Finished.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&mutex1, NULL);\n    pthread_mutex_init(&mutex2, NULL);\n\n    pthread_create(&tid1, NULL, thread_func1, NULL);\n    pthread_create(&tid2, NULL, thread_func2, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n\n    printf(\"Main: Both threads finished.\\n\");\n    return 0;\n}"}, "sub_questions": [{"id": "a", "text": "האם קיפאון (deadlock) יכול להתרחש בקוד זה? נמקו את תשובתכם.", "code_snippet": null, "options": ["כן", "לא"], "solution": {"is_present_in_file": true, "correct_option": "כן", "explanation": "כן, קיפאון יכול להתרחש בקוד זה. הקוד מדגים את התנאים ההכרחיים לקיפאון (תנאי ה-Coffman):\n1. מניעה הדדית (Mutual Exclusion): המנעולים (mutexes) מספקים גישה בלעדית למשאבים.\n2. החזק והמתן (Hold and Wait): כל תהליכון מחזיק במנעול אחד וממתין למנעול נוסף.\n3. אי-שלילה (No Preemption): לא ניתן לקחת מנעול מתהליכון בכוח.\n4. המתנה מעגלית (Circular Wait): תהליכון 1 מחכה למנעול 2 שתפוס ע\"י תהליכון 2, ותהליכון 2 מחכה למנעול 1 שתפוס ע\"י תהליכון 1."}}, {"id": "b", "text": "אם התשובה לשאלה הקודמת חיובית, תארו סדר אירועים אפשרי המוביל לקיפאון.", "code_snippet": null, "options": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "סדר אירועים אפשרי לקיפאון:\n1. תהליכון 1 (thread_func1) מבצע pthread_mutex_lock(&mutex1) ונועל את mutex1.\n2. מתרחשת החלפת הקשר (context switch).\n3. תהליכון 2 (thread_func2) מבצע pthread_mutex_lock(&mutex2) ונועל את mutex2.\n4. תהליכון 2 מנסה לבצע pthread_mutex_lock(&mutex1) אך נחסם מכיוון ש-mutex1 נעול על ידי תהליכון 1.\n5. מתרחשת החלפת הקשר.\n6. תהליכון 1 מנסה לבצע pthread_mutex_lock(&mutex2) אך נחסם מכיוון ש-mutex2 נעול על ידי תהליכון 2.\nבשלב זה, תהליכון 1 מחכה ל-mutex2 שתפוס על ידי תהליכון 2, ותהליכון 2 מחכה ל-mutex1 שתפוס על ידי תהליכון 1. נוצר קיפאון, ושני התהליכונים יישארו חסומים לעד."}}, {"id": "c", "text": "כיצד ניתן למנוע קיפאון בקוד זה תוך שימוש בשינויים מינימליים? הציגו את השינויים בקוד.", "code_snippet": null, "options": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כדי למנוע קיפאון, יש לוודא שתנאי ההמתנה המעגלית לא יתקיים. הדרך הנפוצה והפשוטה ביותר היא להקצות סדר קבוע לרכישת המשאבים. אם כל התהליכונים ינסו לרכוש את המנעולים באותו סדר (לדוגמה, תמיד mutex1 ואז mutex2), לא ייתכן מצב של המתנה מעגלית.\n\n**שינויים בקוד:**\nיש לשנות את הפונקציה `thread_func2` כך שתנסה לנעול את `mutex1` לפני `mutex2`.\n\n```c\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2: Locked mutex1. Trying to lock mutex2...\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2: Locked mutex2. Performing work...\\n\");\n    // Critical section\n    printf(\"Thread 2: Unlocking mutex2...\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2: Unlocking mutex1...\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 2: Finished.\\n\");\n    return NULL;\n}\n```\n\nבשינוי זה, שני התהליכונים מנסים לנעול את `mutex1` ראשון ולאחר מכן את `mutex2`. זה מבטיח שאם `mutex1` נתפס על ידי אחד התהליכונים, התהליכון השני ימתין לו לפני שינסה לתפוס את `mutex2`. רק כאשר `mutex1` פנוי, התהליכון השני יוכל לנעול אותו ולהמשיך לנסות לנעול את `mutex2`. כך נמנעת המתנה מעגלית ולכן קיפאון."}}], "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": null}, "difficulty_estimation": "Medium", "_source_file": "0424__Deadlocks__CodeAnalysis__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:27:09", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Concurrency"], "content": {"text": "במערכת הפעלה נתונה, קיימים N משאבים מסוג יחיד, המסומנים כ- `R_0, R_1, ..., R_{N-1}`. כל משאב מוגן על ידי מנעול `pthread_mutex_t` משלו. חוטים במערכת צריכים לרכוש בו-זמנית שני משאבים ספציפיים, `R_i` ו- `R_j` (כאשר `i` שונה מ- `j`), לבצע עליהם פעולה כלשהי, ולאחר מכן לשחרר אותם. נתון המימוש הראשוני הבא לפונקציות רכישה ושחרור:\n\n", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h> // For usleep\n\n#define N_RESOURCES 5 // לדוגמה, מספר המשאבים במערכת\n\npthread_mutex_t resource_mutexes[N_RESOURCES];\n\nvoid init_resources() {\n    for (int k = 0; k < N_RESOURCES; ++k) {\n        pthread_mutex_init(&resource_mutexes[k], NULL);\n    }\n}\n\nvoid destroy_resources() {\n    for (int k = 0; k < N_RESOURCES; ++k) {\n        pthread_mutex_destroy(&resource_mutexes[k]);\n    }\n}\n\n// פונקציית רכישה ראשונית\nvoid acquire_two_resources_initial(int id1, int id2) {\n    if (id1 == id2 || id1 < 0 || id1 >= N_RESOURCES || id2 < 0 || id2 >= N_RESOURCES) {\n        fprintf(stderr, \"Invalid resource IDs: %d, %d\\n\", id1, id2);\n        exit(1);\n    }\n    printf(\"Thread %lu attempting to acquire R%d then R%d\\n\", pthread_self(), id1, id2);\n    pthread_mutex_lock(&resource_mutexes[id1]);\n    printf(\"Thread %lu acquired R%d, attempting R%d\\n\", pthread_self(), id1, id2);\n    pthread_mutex_lock(&resource_mutexes[id2]);\n    printf(\"Thread %lu acquired R%d and R%d\\n\", pthread_self(), id1, id2);\n}\n\n// פונקציית שחרור ראשונית\nvoid release_two_resources_initial(int id1, int id2) {\n    printf(\"Thread %lu releasing R%d and R%d\\n\", pthread_self(), id1, id2);\n    pthread_mutex_unlock(&resource_mutexes[id2]);\n    pthread_mutex_unlock(&resource_mutexes[id1]);\n}\n\n// פונקציית עבודה לדוגמה\nvoid* thread_func_initial(void* arg) {\n    int* ids = (int*)arg;\n    int r1 = ids[0];\n    int r2 = ids[1];\n\n    acquire_two_resources_initial(r1, r2);\n    // Simulate work\n    usleep(100);\n    release_two_resources_initial(r1, r2);\n    return NULL;\n}\n\n// פונקציית main לדוגמה להדגמת קיפאון\n// int main() {\n//     init_resources();\n//     pthread_t t1, t2;\n//     int ids1[] = {0, 1}; // Thread 1 wants R0, then R1\n//     int ids2[] = {1, 0}; // Thread 2 wants R1, then R0\n//\n//     pthread_create(&t1, NULL, thread_func_initial, (void*)ids1);\n//     pthread_create(&t2, NULL, thread_func_initial, (void*)ids2);\n//\n//     pthread_join(t1, NULL);\n//     pthread_join(t2, NULL);\n//\n//     destroy_resources();\n//     return 0;\n// }\n", "options": null}, "sub_questions": [{"id": "8.1", "text": "האם המימוש הראשוני של `acquire_two_resources_initial` יכול להוביל לקיפאון (deadlock)? אם כן, תאר תרחיש ספציפי שבו קיפאון כזה יתרחש, והסבר מדוע.", "code_snippet": null, "options": null}, {"id": "8.2", "text": "שנה את המימוש של הפונקציות `acquire_two_resources` ו- `release_two_resources` כך שימנעו קיפאון באופן מוחלט, תוך שמירה על העיקרון שחוט תמיד ינסה לרכוש את `id1` *לפני* `id2`. המימוש החדש צריך להיות יעיל ככל האפשר ולא לכלול מנעול גלובלי יחיד שמסרסל את כל הבקשות. השתמש בפעולות סנכרון סטנדרטיות בלבד (כגון `pthread_mutex_t` ופונקציותיה, כולל `trylock`).", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "8.1: כן, המימוש הראשוני יכול להוביל לקיפאון.\n\n**תרחיש לקיפאון:**\nנניח שני חוטים, חוט A וחוט B, ושני משאבים `R_0` ו- `R_1`.\n1.  **חוט A** קורא ל- `acquire_two_resources_initial(0, 1)`:\n    *   חוט A נועל את `resource_mutexes[0]`.\n    *   חוט A מנסה לנעול את `resource_mutexes[1]`.\n2.  **במקביל, חוט B** קורא ל- `acquire_two_resources_initial(1, 0)`:\n    *   חוט B נועל את `resource_mutexes[1]`.\n    *   חוט B מנסה לנעול את `resource_mutexes[0]`.\n\n**הסבר:**\nבנקודה זו:\n*   חוט A מחזיק במנעול של `R_0` וממתין למנעול של `R_1`.\n*   חוט B מחזיק במנעול של `R_1` וממתין למנעול של `R_0`.\n\nזהו מצב של **קיפאון (deadlock)** מכיוון שמתקיימים כל ארבעת התנאים של קיפאון:\n1.  **מניעה הדדית (Mutual Exclusion):** כל משאב מוגן על ידי מנעול, כך שרק חוט אחד יכול להחזיק בו זמנית.\n2.  **החזק והמתן (Hold and Wait):** כל חוט מחזיק במשאב אחד (A מחזיק ב-`R_0`, B מחזיק ב-`R_1`) וממתין למשאב נוסף (A ממתין ל-`R_1`, B ממתין ל-`R_0`).\n3.  **אין שלילה מוקדמת (No Preemption):** לא ניתן לכפות על חוט לשחרר משאב שהוא מחזיק בו.\n4.  **המתנה מעגלית (Circular Wait):** חוט A ממתין למשאב שחוט B מחזיק, וחוט B ממתין למשאב שחוט A מחזיק, ויוצר מעגל המתנה.\n\n8.2: כדי למנוע קיפאון תוך שמירה על סדר הרכישה `id1` ואז `id2`, נשתמש בגישת ה- `trylock` עם מנגנון גיבוי (back-off). הרעיון הוא לנסות לרכוש את המנעולים בסדר הנדרש. אם הרכישה השנייה נכשלת (כי המשאב כבר תפוס), החוט ישחרר את המשאב הראשון שתפס, ימתין זמן קצר (כדי למנוע רעב מיידי ולתת לחוטים אחרים סיכוי), וינסה שוב. זה מפר את תנאי ה-\"החזק והמתן\" ובכך מונע קיפאון.\n\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h> // For usleep\n\n#define N_RESOURCES 5\n#define RETRY_DELAY_US 1000 // 1 מ\"ש\n\npthread_mutex_t resource_mutexes[N_RESOURCES];\n\nvoid init_resources() {\n    for (int k = 0; k < N_RESOURCES; ++k) {\n        pthread_mutex_init(&resource_mutexes[k], NULL);\n    }\n}\n\nvoid destroy_resources() {\n    for (int k = 0; k < N_RESOURCES; ++k) {\n        pthread_mutex_destroy(&resource_mutexes[k]);\n    }\n}\n\n// פונקציית רכישה מתוקנת ללא קיפאון\nvoid acquire_two_resources(int id1, int id2) {\n    if (id1 == id2 || id1 < 0 || id1 >= N_RESOURCES || id2 < 0 || id2 >= N_RESOURCES) {\n        fprintf(stderr, \"Invalid resource IDs: %d, %d\\n\", id1, id2);\n        exit(1);\n    }\n\n    while (1) { // ננסה לרכוש עד שנצליח\n        printf(\"Thread %lu attempting to acquire R%d then R%d\\n\", pthread_self(), id1, id2);\n\n        // ננסה לנעול את המשאב הראשון\n        pthread_mutex_lock(&resource_mutexes[id1]);\n        printf(\"Thread %lu acquired R%d, attempting R%d\\n\", pthread_self(), id1, id2);\n\n        // ננסה לנעול את המשאב השני\n        if (pthread_mutex_trylock(&resource_mutexes[id2]) == 0) {\n            // הצלחנו לנעול את שניהם\n            printf(\"Thread %lu acquired R%d and R%d\\n\", pthread_self(), id1, id2);\n            return;\n        } else {\n            // לא הצלחנו לנעול את המשאב השני, נשחרר את הראשון וננסה שוב\n            printf(\"Thread %lu failed to acquire R%d, releasing R%d and retrying...\\n\", pthread_self(), id2, id1);\n            pthread_mutex_unlock(&resource_mutexes[id1]);\n            usleep(RETRY_DELAY_US + (rand() % 1000)); // השהיה עם רנדומיזציה למניעת רעב\n        }\n    }\n}\n\n// פונקציית שחרור מתוקנת\nvoid release_two_resources(int id1, int id2) {\n    printf(\"Thread %lu releasing R%d and R%d\\n\", pthread_self(), id1, id2);\n    pthread_mutex_unlock(&resource_mutexes[id2]);\n    pthread_mutex_unlock(&resource_mutexes[id1]);\n}\n\n// פונקציית עבודה לדוגמה עם המימוש המתוקן\nvoid* thread_func_fixed(void* arg) {\n    int* ids = (int*)arg;\n    int r1 = ids[0];\n    int r2 = ids[1];\n\n    acquire_two_resources(r1, r2);\n    // Simulate work\n    usleep(100);\n    release_two_resources(r1, r2);\n    return NULL;\n}\n\n// פונקציית main לדוגמה להדגמת פעולה ללא קיפאון\n// int main() {\n//     init_resources();\n//     pthread_t t1, t2;\n//     int ids1[] = {0, 1}; // Thread 1 wants R0, then R1\n//     int ids2[] = {1, 0}; // Thread 2 wants R1, then R0\n//\n//     pthread_create(&t1, NULL, thread_func_fixed, (void*)ids1);\n//     pthread_create(&t2, NULL, thread_func_fixed, (void*)ids2);\n//\n//     pthread_join(t1, NULL);\n//     pthread_join(t2, NULL);\n//\n//     destroy_resources();\n//     return 0;\n// }\n```\n\n**הסבר לפתרון:**\nהפתרון מונע קיפאון על ידי שבירת תנאי ה-\"החזק והמתן\". כאשר חוט מצליח לרכוש את המשאב הראשון (`id1`) אך נכשל ברכישת המשאב השני (`id2`) באמצעות `pthread_mutex_trylock`, הוא אינו ממתין לנצח כשהוא מחזיק במשאב הראשון. במקום זאת, הוא משחרר את המשאב הראשון (`id1`), ממתין זמן קצר (עם תוספת רנדומית כדי למנוע תזמון חוזר שיוביל לרעב), ורק אז מנסה שוב את כל תהליך הרכישה. פעולה זו מבטיחה שחוט לעולם לא יחזיק במשאב אחד ויחסום חוט אחר, בזמן שהוא עצמו ממתין למשאב שחוט אחר מחזיק. בסופו של דבר, אחד החוטים יצליח לרכוש את שני המשאבים, והמערכת תתקדם."}, "difficulty_estimation": "Hard", "_source_file": "0425__Deadlocks__CodeAnalysis__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:28:01", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Resource Ordering"], "content": {"text": "מערכת מורכבת מ-N משאבים גנריים, כאשר כל משאב מוגן על ידי מנעול `pthread_mutex_t` משלו. חוטים במערכת צריכים לבצע פעולות הדורשות גישה בו-זמנית לשני משאבים שונים. לדוגמה, חוט עשוי להזדקק למשאבים `R_i` ו-`R_j` (כאשר `i != j`).\n\nכתוב פונקציה בשם `acquire_two_resources` שתקבל שני אינדקסים של משאבים (`idx1`, `idx2`) ומערך של מצביעים למנעולים (`mutexes`). הפונקציה צריכה לנעול את שני המנעולים המתאימים למשאבים אלו באופן בטוח, כלומר, למנוע קיפאון (deadlock) בכל מקרה.\n\n**דרישות:**\n1.  הפונקציה חייבת למנוע קיפאון.\n2.  הפונקציה צריכה להיות יעילה ככל האפשר.\n3.  אין להשתמש בפעולות אטומיות או אובייקטי סנכרון נוספים מעבר ל-`pthread_mutex_t` ופונקציות הנעילה/שחרור הרגילות שלהן (`pthread_mutex_lock`, `pthread_mutex_unlock`).\n\n**שקול את תרחיש הקיפאון הבא:**\nחוט T1 מנסה לנעול את משאב `R_A` ואז את `R_B`.\nחוט T2 מנסה לנעול את משאב `R_B` ואז את `R_A`.\nאם T1 נועל את `R_A` ו-T2 נועל את `R_B` בו-זמנית, שניהם יחכו זה לזה בנצח.\n\n**קוד התחלתי (להשלמה):**", "code_snippet": "```c\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n// Assume 'num_resources' and 'resource_mutexes' are globally available\n// for simplicity, or passed as part of a context struct.\n// For this question, assume mutexes is an array of pthread_mutex_t pointers.\n\n// Function to initialize N mutexes (not part of the solution, just context)\nvoid init_resource_mutexes(pthread_mutex_t* mutexes[], int N) {\n    for (int i = 0; i < N; ++i) {\n        mutexes[i] = (pthread_mutex_t*) malloc(sizeof(pthread_mutex_t));\n        if (mutexes[i] == NULL) {\n            perror(\"malloc failed\");\n            exit(EXIT_FAILURE);\n        }\n        pthread_mutex_init(mutexes[i], NULL);\n    }\n}\n\n// Function to destroy N mutexes (not part of the solution, just context)\nvoid destroy_resource_mutexes(pthread_mutex_t* mutexes[], int N) {\n    for (int i = 0; i < N; ++i) {\n        pthread_mutex_destroy(mutexes[i]);\n        free(mutexes[i]);\n    }\n}\n\n// TODO: Implement this function to acquire two resources safely\nvoid acquire_two_resources(int idx1, int idx2, pthread_mutex_t* mutexes[]) {\n    // Your implementation here\n}\n\n// TODO: Implement this function to release two resources\nvoid release_two_resources(int idx1, int idx2, pthread_mutex_t* mutexes[]) {\n    // Your implementation here\n}\n```", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסבר לקיפאון בגישה נאיבית:\nגישה נאיבית, שבה חוטים נועלים את המשאבים בסדר שבו הם ניתנים (לדוגמה, `pthread_mutex_lock(mutexes[idx1]); pthread_mutex_lock(mutexes[idx2]);`), עלולה להוביל לקיפאון (deadlock). נניח שחוט T1 מנסה לנעול את משאב R_A ואז את R_B, וחוט T2 מנסה לנעול את משאב R_B ואז את R_A. אם T1 מצליח לנעול את R_A ו-T2 מצליח לנעול את R_B בו-זמנית, אזי T1 ימתין ל-R_B שמוחזק על ידי T2, ו-T2 ימתין ל-R_A שמוחזק על ידי T1. נוצרת שרשרת המתנה מעגלית, והחוטים יישארו במצב קיפאון.\n\nפתרון למניעת קיפאון:\nכדי למנוע קיפאון בתרחיש של רכישת משאבים מרובים, אנו חייבים למנוע את התנאי של \"המתנה מעגלית\" (Circular Wait). הדרך הנפוצה והיעילה ביותר לעשות זאת היא להטיל סדר גלובלי (total order) על המשאבים. כלומר, חוטים חייבים תמיד לרכוש את המשאבים לפי סדר קבוע מראש.\n\nבמקרה שלנו, מכיוון שלכל משאב יש אינדקס מספרי ייחודי, נוכל להשתמש באינדקסים אלה כדי להגדיר את הסדר. הפתרון הוא תמיד לנעול את המנעול של המשאב בעל האינדקס הקטן יותר ראשון, ולאחר מכן לנעול את המנעול של המשאב בעל האינדקס הגדול יותר.\n\nפירוט המימוש:\n1.  **קביעת סדר רכישה:** לפני ביצוע פעולות הנעילה, אנו קובעים מי מהאינדקסים `idx1` ו-`idx2` הוא הקטן ומי הגדול. נגדיר `first_idx` להיות `min(idx1, idx2)` ו-`second_idx` להיות `max(idx1, idx2)`.\n2.  **נעילה לפי סדר:** אנו קוראים ל-`pthread_mutex_lock` עבור `mutexes[first_idx]` ולאחר מכן עבור `mutexes[second_idx]`.\n3.  **שחרור:** בעת שחרור המנעולים, מומלץ לשחרר בסדר הפוך מסדר הנעילה (כלומר, קודם את `second_idx` ואז את `first_idx`), אף על פי שסדר השחרור פחות קריטי למניעת קיפאון.\n\nעל ידי הקפדה על סדר רכישה אחיד זה, מובטח שלא תיווצר שרשרת המתנה מעגלית. אם חוט T1 צריך את R_A ו-R_B, וחוט T2 צריך את R_B ו-R_A, שניהם ינסו קודם לנעול את `min(A,B)` ולאחר מכן את `max(A,B)`. החוט שיצליח לנעול את `min(A,B)` ראשון ימשיך לנעול את `max(A,B)`, ואילו החוט השני ימתין בסבלנות עד ש-`min(A,B)` ישוחרר. אין מצב שבו כל חוט מחזיק במשאב שנדרש על ידי האחר וממתין למשאב המוחזק על ידי האחר, ובכך נמנע קיפאון.\n\n```c\nvoid acquire_two_resources(int idx1, int idx2, pthread_mutex_t* mutexes[]) {\n    // For this problem, we assume idx1 and idx2 are distinct and valid indices.\n    // If idx1 == idx2, locking the same non-recursive mutex twice would cause a deadlock.\n    \n    // Impose an order to prevent deadlock: always lock the smaller index first.\n    int first_idx = (idx1 < idx2) ? idx1 : idx2;\n    int second_idx = (idx1 > idx2) ? idx1 : idx2;\n\n    pthread_mutex_lock(mutexes[first_idx]);\n    pthread_mutex_lock(mutexes[second_idx]);\n}\n\nvoid release_two_resources(int idx1, int idx2, pthread_mutex_t* mutexes[]) {\n    // It's good practice to unlock in the reverse order of locking,\n    // or at least consistently. Here, locking order was first_idx then second_idx.\n    // So, unlock second_idx then first_idx.\n    int first_idx = (idx1 < idx2) ? idx1 : idx2;\n    int second_idx = (idx1 > idx2) ? idx1 : idx2;\n\n    pthread_mutex_unlock(mutexes[second_idx]);\n    pthread_mutex_unlock(mutexes[first_idx]);\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0426__Deadlocks__CodeAnalysis__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:28:27", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Atomic Operations", "Resource Allocation"], "content": {"text": "במערכת נתונה, ישנם שני משאבים מסוגים שונים, `משאב A` ו-`משאב B`. כל משאב קיים במופע יחיד. תהליכים (או חוטים) במערכת נדרשים לרכוש את שני המשאבים, `משאב A` ו-`משאב B`, על מנת לבצע משימה כלשהי. לרשותנו עומדות שתי פעולות אטומיות בלבד: `TestAndSet` ו-`atomic_release`.\n\nהפעולה `TestAndSet(int *lock_ptr)` מבצעת באופן אטומי את הפעולות הבאות: היא קובעת את הערך של `*lock_ptr` ל-1, ומחזירה את ערכו הקודם (לפני השינוי). אם `*lock_ptr` היה 0, המשאב היה פנוי וכעת נתפס. אם `*lock_ptr` היה 1, המשאב כבר היה תפוס.\n\nהפעולה `atomic_release(int *lock_ptr)` מבצעת באופן אטומי את הפעולה הבאה: היא קובעת את הערך של `*lock_ptr` ל-0, ובכך משחררת את המשאב.\n\nנתון קטע הקוד הבא המנסה לרכוש את שני המשאבים:\n", "code_snippet": "extern int TestAndSet(int *lock_ptr);\nextern void atomic_release(int *lock_ptr);\n\n// משתנים גלובליים המייצגים את מצב המשאבים (0 = פנוי, 1 = תפוס)\nint resource_A = 0; \nint resource_B = 0; \n\nvoid acquire_two_resources_naive() {\n    while (TestAndSet(&resource_A) == 1); // נסה לרכוש את משאב A\n    while (TestAndSet(&resource_B) == 1); // נסה לרכוש את משאב B\n}\n\nvoid release_two_resources() {\n    atomic_release(&resource_B);\n    atomic_release(&resource_A);\n}\n", "options": null}, "sub_questions": [{"id": "1.1", "text": "א. נתח את קטע הקוד `acquire_two_resources_naive()` והסבר מדוע הוא עלול לגרום למצב של קיפאון (Deadlock) במערכת. ציין אילו תנאים לקיפאון מתקיימים.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "ב. כתוב מחדש את הפונקציות `acquire_two_resources()` ו-`release_two_resources()` כך שימנעו קיפאון, תוך שימוש אך ורק בפעולות האטומיות `TestAndSet` ו-`atomic_release`. המימוש חייב להבטיח שאם חוט לא מצליח לרכוש את שני המשאבים יחד, הוא לא יחזיק באף אחד מהם (כלומר, לא תתקיים החזקה והמתנה חלקית). קוד המימוש צריך להיות יעיל ככל האפשר.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\nא. ניתוח `acquire_two_resources_naive()` וגורמי קיפאון:\nהפונקציה `acquire_two_resources_naive()` אכן עלולה לגרום למצב של קיפאון (Deadlock) במערכת. קיפאון מתרחש כאשר ארבעה תנאים הכרחיים מתקיימים בו-זמנית:\n\n1.  **מניעה הדדית (Mutual Exclusion)**: תנאי זה מתקיים. פעולות `TestAndSet` מבטיחות שרק חוט אחד יכול להחזיק במשאב A ורק חוט אחד יכול להחזיק במשאב B בכל רגע נתון. אם חוט מנסה לרכוש משאב שכבר תפוס, `TestAndSet` יחזיר 1 והחוט ימשיך בלולאת המתנה פעילה (busy-waiting) עד שהמשאב ישתחרר.\n\n2.  **החזקה והמתנה (Hold and Wait)**: תנאי זה מתקיים. חוט יכול לרכוש את `משאב A` (כלומר, להחזיק בו), ולאחר מכן לנסות לרכוש את `משאב B`. אם `משאב B` תפוס על ידי חוט אחר, החוט הראשון ימתין ל-`משאב B` תוך כדי שהוא ממשיך להחזיק ב-`משאב A`.\n\n3.  **אי-נשללות (No Preemption)**: תנאי זה מתקיים. משאבים אינם נשללים מחוט בכוח. חוט חייב לשחרר את המשאבים מרצונו החופשי באמצעות `atomic_release` לאחר שסיים את השימוש בהם.\n\n4.  **המתנה מעגלית (Circular Wait)**: תנאי זה עלול להיווצר. נניח שני חוטים, T1 ו-T2:\n    *   T1 מבצע בהצלחה `TestAndSet(&resource_A)` (תופס את A).\n    *   T2 מבצע בהצלחה `TestAndSet(&resource_B)` (תופס את B).\n    *   כעת, T1 מנסה לבצע `TestAndSet(&resource_B)`, אך מגלה ש-B תפוס על ידי T2. T1 נכנס למצב המתנה על B.\n    *   בו-זמנית, T2 מנסה לבצע `TestAndSet(&resource_A)`, אך מגלה ש-A תפוס על ידי T1. T2 נכנס למצב המתנה על A.\n    *   במצב זה, T1 ממתין ל-T2 שישחרר את B, ו-T2 ממתין ל-T1 שישחרר את A. נוצרת שרשרת המתנה מעגלית, ושני החוטים נמצאים בקיפאון.\n\nב. מימוש פונקציות `acquire_two_resources()` ו-`release_two_resources()` למניעת קיפאון:\nכדי למנוע קיפאון, נשבור את תנאי ה\"החזקה והמתנה\" על ידי הבטחה שחוט לא יחזיק באף משאב אם הוא לא מצליח לרכוש את כל המשאבים הנדרשים לו באופן מיידי. אסטרטגיה נפוצה לכך היא \"ניסיון וביטול\" (try-and-rollback) או רכישה בסדר קבוע ומוסכם. נבחר באסטרטגיה של רכישה בסדר קבוע (תמיד A ואז B) בשילוב עם מנגנון ביטול:\n\n```c\nvoid acquire_two_resources() {\n    while (1) {\n        // נסה לרכוש את משאב A\n        while (TestAndSet(&resource_A) == 1); // המתן באופן פעיל עד ש-A יהיה פנוי ותפוס אותו\n\n        // משאב A נתפס. כעת נסה לרכוש את משאב B.\n        if (TestAndSet(&resource_B) == 0) {\n            // אם B היה פנוי ונתפס בהצלחה, רכשנו את שני המשאבים.\n            return; // יציאה מהלולאה, שני המשאבים בידינו.\n        } else {\n            // משאב B היה תפוס. שחרר את משאב A וחזור לנסות לרכוש את שניהם מההתחלה.\n            atomic_release(&resource_A);\n            // ניתן להוסיף כאן השהיה קצרה (למשל, thread_yield) כדי למנוע בזבוז משאבי מעבד ב-busy-waiting אגרסיבי,\n            // אך מכיוון שלא ניתנו פרימיטיבים נוספים, נסתפק בלולאה.\n        }\n    }\n}\n\nvoid release_two_resources() {\n    atomic_release(&resource_B); // שחרר את משאב B\n    atomic_release(&resource_A); // שחרר את משאב A\n}\n```\n\n**הסבר לפתרון:**\n\n1.  **מניעת החזקה והמתנה חלקית:** המימוש מבטיח שחוט שרוכש את `משאב A` אך מגלה ש-`משאב B` תפוס, ישחרר מיד את `משאב A` לפני שהוא מנסה שוב. בכך, חוט אף פעם לא יחזיק במשאב אחד (A) וימתין למשאב אחר (B) לזמן בלתי מוגבל. זה שובר את תנאי ה\"החזקה והמתנה\" באופן שמבטיח שחוט לא ייכנס למצב המתנה מעגלית.\n\n2.  **סדר רכישה קבוע:** כל החוטים מנסים לרכוש את המשאבים באותו סדר: תמיד `משאב A` תחילה, ורק לאחר מכן `משאב B`. זהו תנאי מונע קיפאון קלאסי בפני עצמו, אך במקרה שלנו הוא משולב עם מנגנון ה\"ניסיון וביטול\" כדי להתמודד עם מצב שבו המשאב השני אינו זמין מיד. אם כל החוטים ינסו לרכוש A ואז B, לעולם לא תיווצר המתנה מעגלית שבה חוט אחד מחזיק ב-A ומחכה ל-B, וחוט אחר מחזיק ב-B ומחכה ל-A, מכיוון שחוט שיתפוס את B ראשון לעולם לא ינסה לתפוס את A (הוא תמיד ינסה A ואז B).\n\n3.  **חופש מקיפאון:** המימוש מבטיח חופש מקיפאון. גם אם חוטים רבים מתחרים על המשאבים, בסופו של דבר אחד מהם יצליח לתפוס את שניהם, משום שהם משחררים משאבים שהוחזקו חלקית, ובכך מאפשרים לחוטים אחרים להתקדם. אין מצב שבו קבוצת חוטים ממתינה זה לזה באופן בלתי הפיך.\n\n4.  **יעילות (בהינתן המגבלות):** בהיעדר פרימיטיבים כמו `sleep` או `yield`, השימוש ב-`while (TestAndSet(...) == 1);` הוא צורת busy-waiting. למרות שזה לא יעיל מבחינת ניצול מעבד, זהו המימוש היעיל ביותר האפשרי עם הפרימיטיבים האטומיים הנתונים בלבד, מכיוון שאין דרך אחרת להמתין לשחרור משאב מבלי לצרוך זמן מעבד בלולאה."}, "difficulty_estimation": "Hard", "_source_file": "0427__Deadlocks__CodeAnalysis__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:29:10", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Resource Management", "Concurrency"], "content": {"text": "מערכת הפעלה מנהלת שני סוגי משאבים: ResourceA ו-ResourceB. לכל סוג משאב קיים מספר מוגבל של יחידות זמינות. תהליכים במערכת נדרשים לתפוס יחידה אחת מכל סוג משאב (אחת מ-ResourceA ואחת מ-ResourceB) כדי לבצע עבודה מסוימת, ולאחר מכן לשחרר אותם. הקוד הבא מציג מימוש של מנגנון תפיסה ושחרור של המשאבים, ופונקציית תהליך המשתמשת בהם. נתון כי עבור ResourceA ו-ResourceB, מספר היחידות הזמינות ההתחלתי הוא 1 לכל אחד (כלומר, `init_resource(&resourceA, 1);` ו-`init_resource(&resourceB, 1);`), וכי קיימים שני תהליכים (חוטים) הפועלים במקביל.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\n// Resource structure definition\ntypedef struct {\n    pthread_mutex_t lock;\n    pthread_cond_t cond;\n    int available_count;\n    int total_count;\n} Resource;\n\n// Global resources (for simplicity in this example)\nResource resourceA;\nResource resourceB;\n\n// Function to initialize a resource\nvoid init_resource(Resource* res, int count) {\n    pthread_mutex_init(&res->lock, NULL);\n    pthread_cond_init(&res->cond, NULL);\n    res->available_count = count;\n    res->total_count = count;\n}\n\n// Function to acquire a resource instance\nvoid acquire_resource(Resource* res) {\n    pthread_mutex_lock(&res->lock);\n    while (res->available_count <= 0) {\n        pthread_cond_wait(&res->cond, &res->lock);\n    }\n    res->available_count--;\n    pthread_mutex_unlock(&res->lock);\n}\n\n// Function to release a resource instance\nvoid release_resource(Resource* res) {\n    pthread_mutex_lock(&res->lock);\n    res->available_count++;\n    pthread_cond_signal(&res->cond); // Signal one waiting thread\n    pthread_mutex_unlock(&res->lock);\n}\n\n// Thread function that attempts to acquire both resources\nvoid* thread_func(void* arg) {\n    long thread_id = (long)arg;\n\n    // Simulate different acquisition orders based on thread ID\n    if (thread_id % 2 == 0) { // Even threads acquire A then B\n        acquire_resource(&resourceA);\n        sleep(1); // Simulate some work or delay\n        acquire_resource(&resourceB);\n        \n        // Simulate critical section work\n        sleep(2);\n\n        release_resource(&resourceB);\n        release_resource(&resourceA);\n    } else { // Odd threads acquire B then A\n        acquire_resource(&resourceB);\n        sleep(1); // Simulate some work or delay\n        acquire_resource(&resourceA);\n        \n        // Simulate critical section work\n        sleep(2);\n\n        release_resource(&resourceA);\n        release_resource(&resourceB);\n    }\n    return NULL;\n}"}, "sub_questions": [{"id": "101.1", "text": "האם ייתכן מצב של קיפאון (Deadlock) במערכת המתוארת? נמקו את תשובתכם בהתבסס על ארבעת התנאים ההכרחיים לקיפאון של קופמן (Coffman Conditions).", "code_snippet": null, "options": null}, {"id": "101.2", "text": "אם אכן ייתכן קיפאון, הציעו שינוי קוד מינימלי למנגנון תפיסת המשאבים שימנע קיפאון, תוך שמירה על עקרונות המניעה ההדדית ושימוש יעיל במשאבים. הציגו את הקוד המעודכן והסבירו מדוע הוא פותר את הבעיה.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. כן, ייתכן מצב של קיפאון (Deadlock) במערכת המתוארת. נבחן את ארבעת התנאים ההכרחיים לקיפאון:\n   א. מניעה הדדית (Mutual Exclusion): מתקיים. כל יחידת משאב (ResourceA או ResourceB) ניתנת לתפיסה בלעדית על ידי תהליך אחד בלבד בכל רגע נתון. המנעולים (`pthread_mutex_t`) והמונה `available_count` מבטיחים זאת.\n   ב. אחיזה והמתנה (Hold and Wait): מתקיים. תהליך (חוט) יכול לתפוס משאב אחד (לדוגמה, ResourceA) ולהמתין לתפיסת משאב נוסף (ResourceB) תוך כדי שהוא מחזיק במשאב הראשון.\n   ג. אי-הפקעה (No Preemption): מתקיים. ברגע שתהליך תפס משאב, המשאב לא יכול להילקח ממנו בכוח; התהליך חייב לשחרר אותו מרצונו.\n   ד. המתנה מעגלית (Circular Wait): מתקיים. בתרחיש של שני חוטים ושתי יחידות משאב (אחת מכל סוג), אם חוט 0 (זוגי) תופס את ResourceA וממתין ל-ResourceB, ובמקביל חוט 1 (אי-זוגי) תופס את ResourceB וממתין ל-ResourceA, נוצר מעגל המתנה. חוט 0 ממתין למשאב שחוט 1 מחזיק, וחוט 1 ממתין למשאב שחוט 0 מחזיק.\n\n2. כדי למנוע קיפאון, ניתן לשנות את הקוד כך שימנע את תנאי ההמתנה המעגלית על ידי אכיפת סדר עקבי לתפיסת המשאבים. כלומר, כל התהליכים יתפסו את ResourceA תחילה, ורק לאחר מכן את ResourceB. שינוי זה מבטיח שלא תיווצר שרשרת המתנה מעגלית.\n\n   הקוד המעודכן לפונקציית `thread_func` ייראה כך:\n   ```c\nvoid* thread_func(void* arg) {\n    long thread_id = (long)arg;\n\n    // כל החוטים תופסים את ResourceA ואז את ResourceB\n    acquire_resource(&resourceA);\n    sleep(1); // לדמות עבודה או עיכוב\n    acquire_resource(&resourceB);\n    \n    // לדמות עבודה בקטע הקריטי\n    sleep(2);\n\n    release_resource(&resourceB);\n    release_resource(&resourceA);\n    \n    return NULL;\n}\n   ```\n   **הסבר לפתרון:**\n   שינוי זה מונע את תנאי ההמתנה המעגלית. כעת, כל החוטים מנסים לתפוס את ResourceA ראשונים. אם יש רק יחידה אחת של ResourceA, רק חוט אחד יצליח לתפוס אותה. חוט זה ימשיך לתפוס את ResourceB. לאחר מכן, הוא ישחרר את שני המשאבים, מה שיאפשר לחוט אחר לתפוס את ResourceA. לעולם לא ייווצר מצב שבו חוט אחד מחזיק ב-ResourceA וממתין ל-ResourceB, בעוד חוט אחר מחזיק ב-ResourceB וממתין ל-ResourceA, מכיוון שכולם מנסים לתפוס את ResourceA קודם. בכך, אנו מבטלים את האפשרות להמתנה מעגלית ושומרים על שאר התנאים ההכרחיים לקיפאון, שהם לגיטימיים במערכות המשתמשות במשאבים משותפים."}, "difficulty_estimation": "Hard", "_source_file": "0428__Deadlocks__CodeAnalysis__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:48:22", "_subject": "Concurrency"}, {"id": 4, "type": "CodeAnalysis", "topic": ["Deadlocks", "Resource Allocation", "Synchronization", "Atomic Operations"], "content": {"text": "מנהל משאבים חסין קיפאון\n\nבמערכת קיימים R משאבים שונים, הממוספרים מ-0 עד R-1. כל משאב מיוצג על ידי משתנה שלם (int) בזיכרון, כאשר 0 מציין שהמשאב פנוי ו-1 מציין שהוא תפוס. מספר רב של חוטים (threads) מתחרים על תפיסת קבוצות של משאבים. כל חוט מעוניין לתפוס קבוצה ספציפית של M משאבים. נדרש לממש פונקציות לתפיסה ולשחרור של קבוצת משאבים באופן שימנע קיפאון (deadlock).\n\nלרשותכם עומדת פקודת חומרה אטומית אחת בלבד: test_and_set. פקודה זו מקבלת מצביע למשתנה שלם, קובעת את ערכו ל-1, ומחזירה את ערכו הקודם באופן אטומי. אם הערך הקודם היה 0, המנעול נתפס בהצלחה. אם היה 1, המנעול כבר היה תפוס.\n\nהבהרה: תיאור הפעולה הוא קוד C לצורך הסבר בלבד. פעולת המעבד מבצעת זאת באופן אטומי ולא בכמה פעולות. אין להשתמש באובייקטי סנכרון או פעולות מעבד אטומיות אחרות מלבד test_and_set.\n\nממשו את הפונקציות acquire_resources_deadlock_safe ו-release_resources תחת ההנחות הבאות:\n1. המשאבים הגלובליים resources מוגדרים ומאותחלים ל-0.\n2. מערך ה-resource_ids המועבר לפונקציית acquire_resources_deadlock_safe ממוין כבר בסדר עולה של מזהי המשאבים.\n3. יש לדאוג למניעת קיפאון (deadlock) וחופש מקיפאון (livelock) ככל הניתן (אך busy-waiting מותר).", "code_snippet": "#include <stdbool.h>\n#include <stdlib.h>\n\n#define MAX_RESOURCES 100 // Example maximum number of resources\nint resources[MAX_RESOURCES]; // Global array of resource states (0: unlocked, 1: locked)\n\n// Atomic hardware instruction (for explanation only)\nint test_and_set(int *lock_ptr) {\n    int old_val = *lock_ptr;\n    *lock_ptr = 1;\n    return old_val;\n}\n\n// Function to initialize resources (e.g., in main)\nvoid init_resources(int num_resources) {\n    for (int i = 0; i < num_resources; ++i) {\n        resources[i] = 0;\n    }\n}\n\n// Implement these two functions:\nvoid acquire_resources_deadlock_safe(int *resource_ids, int count) {\n    // Your implementation here\n}\n\nvoid release_resources(int *resource_ids, int count) {\n    // Your implementation here\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון מבוסס על שתי אסטרטגיות למניעת קיפאון: סדר תפיסת משאבים (Resource Ordering) וגישת 'תפוס הכל או לא כלום' (Acquire All or Nothing).\n\n1.  **סדר תפיסת משאבים (Resource Ordering):** כדי למנוע המתנה מעגלית (Circular Wait), אשר היא אחד מארבעת התנאים ההכרחיים לקיפאון, אנו דורשים מכל החוטים לתפוס את המשאבים בסדר עולה של מזהיהם. ההנחה בשאלה היא שמערך ה-`resource_ids` כבר ממוין, מה שמפשט את המימוש. אם המערך לא היה ממוין, היה צורך למיין אותו בתחילת הפונקציה `acquire_resources_deadlock_safe`.\n\n2.  **'תפוס הכל או לא כלום' (Acquire All or Nothing):** כדי למנוע את תנאי 'החזק והמתן' (Hold and Wait), חוט שמנסה לתפוס קבוצת משאבים חייב להצליח לתפוס את כולם. אם בשלב כלשהו הוא נתקל במשאב תפוס, הוא משחרר את כל המשאבים שתפס עד לאותה נקודה ומתחיל מחדש את ניסיון התפיסה. זה מבטיח שחוט לעולם לא יחזיק במשאב אחד וימתין לאחר, ובכך מונע קיפאון.\n\n**מימוש `acquire_resources_deadlock_safe`:**\nהפונקציה נכנסת ללולאה אינסופית (while true) המייצגת ניסיונות חוזרים ונשנים לתפוס את המשאבים. בתוך הלולאה, היא עוברת על המשאבים לפי הסדר הממוין. עבור כל משאב, היא מנסה לתפוס אותו באמצעות `test_and_set`. אם ה-`test_and_set` מחזיר 0, המשאב נתפס בהצלחה והחוט ממשיך למשאב הבא. אם הוא מחזיר 1 (כלומר המשאב כבר תפוס), החוט מבין שהוא לא יכול להשלים את התפיסה הנוכחית. במקרה זה, הוא משחרר את כל המשאבים שתפס בהצלחה בניסיון הנוכחי (באמצעות לולאה פנימית) ושובר את הלולאה הפנימית כדי להתחיל ניסיון תפיסה חדש מההתחלה.\nלאחר יציאה מהלולאה הפנימית (או אם כל המשאבים נתפסו), נבדק דגל `acquired_all`. אם הוא `true`, כל המשאבים נתפסו בהצלחה והפונקציה מסתיימת. אחרת, הלולאה החיצונית ממשיכה לניסיון תפיסה נוסף.\n\n**מימוש `release_resources`:**\nפונקציה זו פשוט עוברת על כל המשאבים ברשימה ומשחררת אותם על ידי הגדרת ערכם ל-0. פעולה זו בטוחה מכיוון שהחוט הוא הבעלים הבלעדי של המשאבים שהוא משחרר, ולכן אין צורך בפעולה אטומית לשחרור (אך שימוש ב-CAS להגדרת 0 היה גם אפשרי).\n\n**חופש מקיפאון (Livelock):** הפתרון משתמש ב-busy-waiting. במקרים של עומס גבוה, מספר חוטים עלולים לנסות לתפוס משאבים, להיתקל במשאב תפוס, לשחרר ולנסות שוב במהירות, מה שעלול להוביל לבזבוז משאבי מעבד. כדי למזער livelock, ניתן להוסיף השהיה קצרה (למשל, `sched_yield()` או `usleep()`) לפני כל ניסיון חוזר לתפיסת משאבים, אך זה לא נדרש במימוש הבסיסי למניעת קיפאון.\n\n```c\n#include <stdbool.h>\n#include <stdlib.h>\n// For sched_yield() or usleep() if adding backoff\n// #include <sched.h>\n// #include <unistd.h>\n\n#define MAX_RESOURCES 100 \nint resources[MAX_RESOURCES]; \n\n// Atomic hardware instruction (for explanation only)\nint test_and_set(int *lock_ptr) {\n    int old_val = *lock_ptr;\n    *lock_ptr = 1;\n    return old_val;\n}\n\nvoid init_resources(int num_resources) {\n    for (int i = 0; i < num_resources; ++i) {\n        resources[i] = 0;\n    }\n}\n\nvoid acquire_resources_deadlock_safe(int *resource_ids, int count) {\n    while (true) {\n        bool acquired_all = true;\n        for (int i = 0; i < count; ++i) {\n            int res_id = resource_ids[i];\n            if (test_and_set(&resources[res_id]) == 1) {\n                // Failed to acquire this resource.\n                // Must release all resources acquired so far in this attempt\n                // and retry.\n                acquired_all = false;\n                for (int j = 0; j < i; ++j) {\n                    resources[resource_ids[j]] = 0; // Release (safe as owner)\n                }\n                // Optional: Add a short delay (e.g., sched_yield() or usleep()) before retrying to reduce busy-waiting\n                // sched_yield(); // Yield CPU to other threads\n                break; // Break from inner loop, retry outer loop\n            }\n        }\n        if (acquired_all) {\n            break; // Successfully acquired all resources\n        }\n    }\n}\n\nvoid release_resources(int *resource_ids, int count) {\n    for (int i = 0; i < count; ++i) {\n        resources[resource_ids[i]] = 0; // Release (safe as owner)\n    }\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0429__Deadlocks__CodeAnalysis__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:30:12", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Resource Allocation", "Atomic Operations"], "content": {"text": "במערכת מרובת חוטים (threads), קיימים N_RESOURCES משאבים משותפים, ממוספרים מ-0 עד N_RESOURCES-1. מצבו של כל משאב i מיוצג על ידי המשתנה הגלובלי resource_status[i], כאשר 0 מציין משאב פנוי ו-1 מציין משאב תפוס. חוטים נדרשים לרכוש מספר משאבים בו-זמנית על מנת לבצע משימותיהם. לרשותנו עומדת פקודת חומרה אטומית אחת בלבד, compare_and_swap, אשר פועלת באופן הבא: int compare_and_swap(int* ptr, int old_val, int new_val). פקודה זו משווה באופן אטומי את הערך בכתובת ptr לערך old_val. אם הם זהים, היא מחליפה את הערך ב-ptr ל-new_val. הפקודה מחזירה את הערך שהיה ב-ptr *לפני* הניסיון לבצע את ההחלפה. אסור להשתמש באובייקטי סנכרון אחרים (כגון mutexes או semaphores) או בפעולות אטומיות אחרות מלבד compare_and_swap. יש לממש את הפונקציות acquire_multiple_resources ו-release_multiple_resources כך שתמנענה מצב של קיפאון (deadlock) ותאפשרנה רכישה ושחרור תקינים של קבוצת משאבים.", "code_snippet": "#include <stdlib.h>    // For qsort, malloc, free\n#include <unistd.h>    // For usleep (optional for backoff)\n\n// Assume N_RESOURCES is a global constant\n#define N_RESOURCES 10 // Example value, can be any positive integer\n\n// Global array representing resource status\n// 0 = free, 1 = taken\nint resource_status[N_RESOURCES];\n\n// This function represents the atomic hardware instruction compare_and_swap.\n// For implementation, you will use __sync_val_compare_and_swap (GCC intrinsic).\n// int compare_and_swap(int* ptr, int old_val, int new_val); // Conceptual signature\n\n// Helper for qsort (provided for convenience)\nint compare_ints(const void *a, const void *b) {\n    return (*(int*)a - *(int*)b);\n}\n\n// You need to implement these functions:\nvoid acquire_multiple_resources(int* resources_needed, int num_resources) {\n    // Your implementation here\n}\n\nvoid release_multiple_resources(int* resources_held, int num_resources) {\n    // Your implementation here\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון מבוסס על מניעת קיפאון באמצעות עמידה בתנאי הסדר הכולל (Total Ordering) לרכישת משאבים. כאשר חוט נדרש לרכוש מספר משאבים, הוא ינסה לרכוש אותם תמיד באותו סדר קבוע ומוגדר מראש, במקרה זה, לפי מזהה המשאב (ID) בסדר עולה.\n\n**פונקציית `acquire_multiple_resources`:**\n1.  **מיון משאבים:** ראשית, הפונקציה יוצרת עותק מקומי של רשימת המשאבים הנדרשים וממיינת אותם בסדר עולה. זה מבטיח שכל החוטים ינסו לרכוש את אותם משאבים באותו סדר, ובכך נמנע מצב שבו חוטים מחכים זה לזה במעגל (\"hold and wait\" ו-\"circular wait\").\n2.  **לולאת ניסיון-חזרה (Retry Loop):** הפונקציה נכנסת ללולאה אינסופית שמנסה לרכוש את כל המשאבים. לולאה זו נחוצה מכיוון שייתכן שחלק מהמשאבים אינם פנויים בניסיון הראשון.\n3.  **רכישה סדרתית:** בתוך הלולאה, החוט עובר על רשימת המשאבים הממוינת ומנסה לרכוש כל אחד מהם באמצעות `compare_and_swap`. הקריאה `__sync_val_compare_and_swap(&resource_status[resource_id], 0, 1)` מנסה לשנות את מצב המשאב מ-0 (פנוי) ל-1 (תפוס). אם הפעולה מחזירה 0, המשאב נרכש בהצלחה.\n4.  **שחרור והמתנה (Rollback and Back-off):** אם הפעולה מחזירה 1, המשאב כבר היה תפוס על ידי חוט אחר. במקרה זה, החוט נכשל ברכישת המשאב הנוכחי. עליו לשחרר באופן מיידי את כל המשאבים שכבר רכש בניסיון הנוכחי. פעולה זו מונעת את תנאי \"החזק והמתן\" (Hold and Wait) שמוביל לקיפאון. לאחר השחרור, החוט ממתין פרק זמן קצר (באמצעות `usleep`) כדי להפחית עומס ולמנוע מצב של livelock, ואז מנסה לרכוש מחדש את כל המשאבים מההתחלה.\n5.  **הצלחה:** אם החוט הצליח לרכוש את כל המשאבים ברשימה, הוא יוצא מלולאת הניסיון-חזרה.\n\n**פונקציית `release_multiple_resources`:**\nפונקציה זו פשוט עוברת על רשימת המשאבים שהוחזקו ומשחררת אותם. השחרור מתבצע באמצעות `__sync_val_compare_and_swap`, כאשר החוט מוודא שהמשאב אכן היה תפוס (ערך 1) לפני שחרורו (הגדרת ערך 0). אין צורך בסדר מסוים לשחרור, מכיוון שהחוט מחזיק באופן בלעדי במשאבים אלו.\n\n```c\n#include <stdlib.h>    // For qsort, malloc, free\n#include <unistd.h>    // For usleep\n#include <stdio.h>     // For fprintf, exit (error handling)\n\n// Assume N_RESOURCES is a global constant\n#define N_RESOURCES 10 \n\n// Global array representing resource status\n// 0 = free, 1 = taken\nint resource_status[N_RESOURCES];\n\n// Helper for qsort\nint compare_ints(const void *a, const void *b) {\n    return (*(int*)a - *(int*)b);\n}\n\nvoid acquire_multiple_resources(int* resources_needed, int num_resources) {\n    // Create a local sorted copy to ensure fixed acquisition order\n    int* sorted_resources = (int*)malloc(sizeof(int) * num_resources);\n    if (!sorted_resources) {\n        fprintf(stderr, \"Memory allocation failed for sorted_resources.\\n\");\n        exit(EXIT_FAILURE);\n    }\n    for (int i = 0; i < num_resources; ++i) {\n        sorted_resources[i] = resources_needed[i];\n    }\n    qsort(sorted_resources, num_resources, sizeof(int), compare_ints);\n\n    int acquired_count;\n\n    while (1) { // Retry loop for deadlock prevention\n        acquired_count = 0;\n        int failed_to_acquire = 0;\n\n        for (int i = 0; i < num_resources; ++i) {\n            int resource_id = sorted_resources[i];\n            // Try to acquire the resource using compare_and_swap\n            // __sync_val_compare_and_swap(ptr, old_val, new_val) returns the original value of *ptr\n            if (__sync_val_compare_and_swap(&resource_status[resource_id], 0, 1) == 0) {\n                // Successfully acquired\n                acquired_count++;\n            } else {\n                // Resource was already taken\n                failed_to_acquire = 1;\n                break; // Break from inner loop, need to release and retry\n            }\n        }\n\n        if (!failed_to_acquire) {\n            // All resources successfully acquired\n            break; // Exit the retry loop\n        } else {\n            // Failed to acquire all. Release the ones we did acquire (rollback).\n            for (int j = 0; j < acquired_count; ++j) {\n                int resource_id_to_release = sorted_resources[j];\n                // Release using compare_and_swap: set from 1 (taken) to 0 (free)\n                __sync_val_compare_and_swap(&resource_status[resource_id_to_release], 1, 0);\n            }\n            // Optional: small back-off to reduce contention and livelock risk\n            usleep(rand() % 1000); // Sleep for up to 1ms\n        }\n    }\n\n    free(sorted_resources);\n}\n\nvoid release_multiple_resources(int* resources_held, int num_resources) {\n    // Releasing doesn't require a specific order, as we own them exclusively.\n    // We use compare_and_swap to ensure the resource was indeed held by us (value 1)\n    // before setting it to 0 (free).\n    for (int i = 0; i < num_resources; ++i) {\n        int resource_id = resources_held[i];\n        __sync_val_compare_and_swap(&resource_status[resource_id], 1, 0);\n    }\n}\n```", "difficulty_estimation": "Hard"}, "_source_file": "0430__Deadlocks__CodeAnalysis__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:30:52", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Deadlocks", "Concurrency", "Synchronization", "Mutexes"], "content": {"text": "יישום מרובה חוטים מדמה מערכת של N יחידות עיבוד המסודרות בטבעת. כל יחידת עיבוד מוגנת על ידי מנעול (mutex). כדי לבצע משימה, חוט צריך לרכוש שתי יחידות עיבוד סמוכות. נתון קוד המממש את ההתנהגות הזו. ענה על השאלות הבאות:", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h> // For sleep\n\n#define NUM_UNITS 5 // N\n\npthread_mutex_t units_mutex[NUM_UNITS];\n\nvoid* worker_thread(void* arg) {\n    int id = *(int*)arg;\n    int unit1 = id;\n    int unit2 = (id + 1) % NUM_UNITS;\n\n    printf(\"Thread %d trying to acquire unit %d and unit %d\\n\", id, unit1, unit2);\n\n    pthread_mutex_lock(&units_mutex[unit1]);\n    printf(\"Thread %d acquired unit %d\\n\", id, unit1);\n    \n    // Simulate some work or contention\n    usleep(10000); // 10ms\n\n    pthread_mutex_lock(&units_mutex[unit2]);\n    printf(\"Thread %d acquired unit %d and unit %d\\n\", id, unit1, unit2);\n\n    // Simulate work in critical section\n    printf(\"Thread %d working with units %d and %d\\n\", id, unit1, unit2);\n    usleep(50000); // 50ms\n\n    pthread_mutex_unlock(&units_mutex[unit2]);\n    printf(\"Thread %d released unit %d\\n\", id, unit2);\n\n    pthread_mutex_unlock(&units_mutex[unit1]);\n    printf(\"Thread %d released unit %d\\n\", id, unit1);\n\n    free(arg);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_UNITS];\n    int* thread_ids[NUM_UNITS];\n\n    for (int i = 0; i < NUM_UNITS; ++i) {\n        pthread_mutex_init(&units_mutex[i], NULL);\n    }\n\n    for (int i = 0; i < NUM_UNITS; ++i) {\n        thread_ids[i] = (int*)malloc(sizeof(int));\n        *thread_ids[i] = i;\n        pthread_create(&threads[i], NULL, worker_thread, thread_ids[i]);\n    }\n\n    for (int i = 0; i < NUM_UNITS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    for (int i = 0; i < NUM_UNITS; ++i) {\n        pthread_mutex_destroy(&units_mutex[i]);\n    }\n\n    printf(\"All threads finished.\\n\");\n    return 0;\n}"}, "sub_questions": [{"id": "1.1", "text": "האם הקוד הנתון עלול לסבול מקיפאון (Deadlock)? אם כן, הסבר את התנאים המובילים לקיפאון.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "שנה את פונקציית `worker_thread` כדי למנוע קיפאון, תוך שמירה על מניעה הדדית (mutual exclusion) ליחידות הסמוכות והבטחת התקדמות (progress). מותר לך להשתמש רק במערך המנעולים הקיים (`units_mutex`) ואין להוסיף אובייקטי סנכרון חדשים או לשנות את גודל `NUM_UNITS`.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: כן, הקוד הנתון עלול לסבול מקיפאון. תרחיש קיפאון קלאסי יכול להתרחש כאשר כל החוטים מתחילים לפעול בערך באותו זמן ומנסים לרכוש את המנעולים שלהם.\n\nהקיפאון מתרחש מכיוון שמתקיימים ארבעת התנאים ההכרחיים לקיפאון:\n1.  **מניעה הדדית (Mutual Exclusion):** כל מנעול (`units_mutex[i]`) מגן על יחידת עיבוד אחת וניתן להחזיק בו על ידי חוט אחד בלבד בכל רגע נתון.\n2.  **החזק והמתן (Hold and Wait):** כל חוט רוכש את המנעול הראשון שלו (`units_mutex[id]`) ומחזיק בו, ואז מנסה לרכוש את המנעול השני (`units_mutex[(id+1)%NUM_UNITS]`). בזמן שהוא ממתין למנעול השני, הוא ממשיך להחזיק במנעול הראשון.\n3.  **אין דריסה (No Preemption):** מנעולים אינם ניתנים לדריסה. ברגע שחוט רוכש מנעול, הוא יכול לשחרר אותו רק מרצונו.\n4.  **המתנה מעגלית (Circular Wait):** זהו התנאי הקריטי ביותר במקרה זה. אם כל `NUM_UNITS` החוטים יתחילו בו זמנית, כל חוט `id` ירכוש את `units_mutex[id]`. לאחר מכן, חוט `id` ינסה לרכוש את `units_mutex[(id+1)%NUM_UNITS]`, אשר מוחזק על ידי חוט `(id+1)%NUM_UNITS`. כך נוצרת שרשרת המתנה מעגלית: חוט 0 ממתין למנעול 1 (שמוחזק על ידי חוט 1), חוט 1 ממתין למנעול 2 (שמוחזק על ידי חוט 2), וכן הלאה, עד שחוט `NUM_UNITS-1` ממתין למנעול 0 (שמוחזק על ידי חוט 0). כתוצאה מכך, אף חוט לא יכול להתקדם, וכל המערכת נכנסת לקיפאון.\n\n1.2: כדי למנוע קיפאון, יש לשבור את תנאי ההמתנה המעגלית. הדרך הנפוצה והיעילה ביותר לעשות זאת במקרה זה, תוך שימוש במשאבים הקיימים בלבד, היא על ידי אכיפת סדר רכישת משאבים (Resource Ordering).\nהרעיון הוא להגדיר סדר גלובלי למנעולים ולדרוש מכל החוטים לרכוש אותם לפי סדר זה. במקרה שלנו, נבצע רכישה תמיד מהמנעול בעל האינדקס הנמוך יותר למנעול בעל האינדקס הגבוה יותר.\n\nעבור חוט `id` המבקש את יחידות `unit1_idx = id` ו-`unit2_idx = (id + 1) % NUM_UNITS`:\n1.  אם `unit1_idx < unit2_idx` (לדוגמה, חוט 0 רוצה יחידות 0 ו-1), החוט ירכוש קודם את `units_mutex[unit1_idx]` ואז את `units_mutex[unit2_idx]`.\n2.  אם `unit1_idx > unit2_idx` (המקרה המיוחד של חוט `NUM_UNITS-1` שרוצה יחידות `NUM_UNITS-1` ו-0), החוט ירכוש קודם את `units_mutex[unit2_idx]` (שהוא 0) ואז את `units_mutex[unit1_idx]` (שהוא `NUM_UNITS-1`).\n\nיישום זה מבטיח שאין המתנה מעגלית. אף חוט לא ימתין למשאב שמוחזק על ידי חוט אחר שימתין בעצמו למשאב שמוחזק על ידי החוט הראשון, מכיוון שסדר הרכישה גלובלי ומונע יצירת מעגל. לדוגמה, חוט `NUM_UNITS-1` לא ימתין למשאב 0 שמוחזק על ידי חוט 0, בעוד שחוט 0 ממתין למשאב 1. במקום זאת, חוט `NUM_UNITS-1` ינסה לרכוש קודם את משאב 0 (שמוחזק על ידי חוט 0), יחסם וימתין, בעוד שחוט 0 ירכוש את משאב 0 ולאחר מכן את משאב 1. הסדר המוגדר מראש מבטיח שכל חוט יצליח בסופו של דבר לרכוש את שני המנעולים שלו.\n\nהקוד המעודכן עבור `worker_thread`:\n```c\nvoid* worker_thread(void* arg) {\n    int id = *(int*)arg;\n    int unit1_idx = id;\n    int unit2_idx = (id + 1) % NUM_UNITS;\n\n    int first_lock_idx, second_lock_idx;\n\n    if (unit1_idx < unit2_idx) { \n        first_lock_idx = unit1_idx;\n        second_lock_idx = unit2_idx;\n    } else { // Handles the case where unit1_idx is NUM_UNITS-1 and unit2_idx is 0\n        first_lock_idx = unit2_idx; \n        second_lock_idx = unit1_idx;\n    }\n\n    printf(\"Thread %d trying to acquire unit %d and unit %d (ordered: %d then %d)\\n\", id, unit1_idx, unit2_idx, first_lock_idx, second_lock_idx);\n\n    pthread_mutex_lock(&units_mutex[first_lock_idx]);\n    printf(\"Thread %d acquired unit %d\\n\", id, first_lock_idx);\n    \n    usleep(10000); // 10ms\n\n    pthread_mutex_lock(&units_mutex[second_lock_idx]);\n    printf(\"Thread %d acquired unit %d and unit %d (original: %d and %d)\\n\", id, first_lock_idx, second_lock_idx, unit1_idx, unit2_idx);\n\n    printf(\"Thread %d working with units %d and %d\\n\", id, unit1_idx, unit2_idx);\n    usleep(50000); // 50ms\n\n    pthread_mutex_unlock(&units_mutex[second_lock_idx]);\n    printf(\"Thread %d released unit %d\\n\", id, second_lock_idx);\n\n    pthread_mutex_unlock(&units_mutex[first_lock_idx]);\n    printf(\"Thread %d released unit %d\\n\", id, first_lock_idx);\n\n    free(arg);\n    return NULL;\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0431__Deadlocks__CodeAnalysis__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:31:29", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Concurrency", "Mutexes"], "content": {"text": "מערכת בנקאית מנהלת מספר חשבונות בנק. כל חשבון מיוצג על ידי מבנה BankAccount הכולל יתרה (balance) ומנעול (mutex) להגנה על היתרה. פונקציית transfer_money מיועדת להעביר סכום כסף מחשבון מקור לחשבון יעד. כדי להבטיח עקביות ושלמות הנתונים, הפונקציה נועלת את שני החשבונות המעורבים לפני ביצוע ההעברה ומשחררת אותם לאחריה. נתון קוד המימוש הבא:\n\nבחנו את הקוד לעיל.\n1. האם קיימת אפשרות לקיפאון (Deadlock) במימוש הפונקציה transfer_money? אם כן, תארו את התרחיש המדויק שיוביל לקיפאון ואת תנאי הקיפאון המתקיימים (Mutual Exclusion, Hold and Wait, No Preemption, Circular Wait).\n2. הציעו פתרון לבעיית הקיפאון וכתבו מחדש את פונקציית transfer_money כך שתמנע קיפאונות, תוך שמירה על נכונות וביצועים סבירים.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h> // For usleep\n\n// Define a BankAccount structure\ntypedef struct {\n    int id;\n    long balance;\n    pthread_mutex_t mutex;\n} BankAccount;\n\n// Function to initialize a bank account\nvoid init_account(BankAccount* account, int id, long initial_balance) {\n    account->id = id;\n    account->balance = initial_balance;\n    pthread_mutex_init(&account->mutex, NULL);\n}\n\n// Function to destroy a bank account\nvoid destroy_account(BankAccount* account) {\n    pthread_mutex_destroy(&account->mutex);\n}\n\n// Function to transfer money between two accounts (BUGGY VERSION)\nvoid transfer_money(BankAccount* source, BankAccount* destination, long amount) {\n    if (source == destination) {\n        return; // Cannot transfer to self\n    }\n\n    // Acquire locks in a potentially problematic order\n    pthread_mutex_lock(&source->mutex);\n    printf(\"Thread %lu locked account %d (source)\\n\", pthread_self(), source->id);\n    \n    // Simulate some work or delay to increase deadlock probability\n    usleep(10000); // 10ms delay\n\n    pthread_mutex_lock(&destination->mutex);\n    printf(\"Thread %lu locked account %d (destination)\\n\", pthread_self(), destination->id);\n\n    if (source->balance >= amount) {\n        source->balance -= amount;\n        destination->balance += amount;\n        printf(\"Transfer %ld from %d to %d successful. Balances: %d=%ld, %d=%ld\\n\", \n               amount, source->id, destination->id, source->id, source->balance, destination->id, destination->balance);\n    } else {\n        printf(\"Transfer %ld from %d to %d failed: insufficient funds.\\n\", amount, source->id, destination->id);\n    }\n\n    pthread_mutex_unlock(&destination->mutex);\n    printf(\"Thread %lu unlocked account %d (destination)\\n\", pthread_self(), destination->id);\n    pthread_mutex_unlock(&source->mutex);\n    printf(\"Thread %lu unlocked account %d (source)\\n\", pthread_self(), source->id);\n}\n", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, קיימת אפשרות לקיפאון (Deadlock) במימוש הנוכחי של transfer_money.\n\n**תרחיש הקיפאון:**\nנניח שני חוטים, Thread 1 ו-Thread 2, ושני חשבונות, Account A ו-Account B.\n*   Thread 1 מנסה להעביר כסף מ-Account A ל-Account B (קורא ל-transfer_money(A, B, amount1)).\n*   Thread 2 מנסה להעביר כסף מ-Account B ל-Account A (קורא ל-transfer_money(B, A, amount2)).\n\n**השתלשלות אירועים אפשרית לקיפאון:**\n1.  Thread 1 נועל את mutex של Account A.\n2.  Thread 2 נועל את mutex של Account B.\n3.  Thread 1 מנסה כעת לנעול את mutex של Account B, אך הוא כבר נעול על ידי Thread 2. Thread 1 נחסם וממתין.\n4.  Thread 2 מנסה כעת לנעול את mutex של Account A, אך הוא כבר נעול על ידי Thread 1. Thread 2 נחסם וממתין.\n\nבשלב זה, שני החוטים חסומים וממתינים זה לזה לשחרור המשאב שהם צריכים, ונוצר קיפאון.\n\n**תנאי הקיפאון המתקיימים:**\n*   **מניעה הדדית (Mutual Exclusion):** כל מנעול (mutex) יכול להיות מוחזק על ידי חוט אחד בלבד בכל רגע נתון.\n*   **החזקה והמתנה (Hold and Wait):** כל חוט מחזיק במנעול אחד (למשל, Thread 1 מחזיק ב-mutex של Account A) וממתין למנעול נוסף (למשל, Thread 1 ממתין ל-mutex של Account B).\n*   **אי-הפקעה (No Preemption):** מנעול שהוחזק על ידי חוט לא יכול להילקח ממנו בכוח; הוא חייב לשחרר אותו מרצונו.\n*   **המתנה מעגלית (Circular Wait):** קיים מעגל של חוטים, כאשר כל חוט במעגל ממתין למשאב המוחזק על ידי החוט הבא במעגל. בתרחיש לעיל, Thread 1 ממתין ל-mutex של Account B שמוחזק על ידי Thread 2, ו-Thread 2 ממתין ל-mutex של Account A שמוחזק על ידי Thread 1.\n\n**פתרון מוצע:**\nכדי למנוע קיפאון במקרה של צורך בנעילת מספר משאבים, הגישה הנפוצה היא להבטיח שכל החוטים ירכשו את המשאבים באותו סדר קבוע (Global Ordering). במקרה זה, ניתן להחליט על סדר רכישת מנעולים לפי כתובות הזיכרון של אובייקטי BankAccount, או לפי מזהה ייחודי (ID) אם קיים. הפתרון יכלול השוואה בין כתובות הזיכרון של חשבונות המקור והיעד, ונעילה תמיד של החשבון בעל הכתובת הנמוכה יותר תחילה, ולאחר מכן את החשבון בעל הכתובת הגבוהה יותר.\n\n**מימוש מתוקן של transfer_money:**\n```c\nvoid transfer_money_safe(BankAccount* source, BankAccount* destination, long amount) {\n    if (source == destination) {\n        printf(\"Cannot transfer to self (account %d).\\n\", source->id);\n        return; \n    }\n\n    pthread_mutex_t *first_mutex, *second_mutex;\n    BankAccount *first_account, *second_account;\n\n    // Determine a consistent locking order based on memory addresses\n    // This ensures that all threads attempting to lock these two specific accounts\n    // will always try to acquire them in the same sequence, preventing circular wait.\n    if (source < destination) { // Compare memory addresses of the account objects\n        first_mutex = &source->mutex;\n        second_mutex = &destination->mutex;\n        first_account = source;\n        second_account = destination;\n    } else {\n        first_mutex = &destination->mutex;\n        second_mutex = &source->mutex;\n        first_account = destination;\n        second_account = source;\n    }\n\n    // Acquire locks in the consistent order\n    pthread_mutex_lock(first_mutex);\n    printf(\"Thread %lu locked account %d (first in order)\\n\", pthread_self(), first_account->id);\n\n    // Simulate some work or delay\n    usleep(10000); // 10ms delay\n\n    pthread_mutex_lock(second_mutex);\n    printf(\"Thread %lu locked account %d (second in order)\\n\", pthread_self(), second_account->id);\n\n    // Perform the transfer logic with both locks held\n    // The source and destination pointers remain as they were passed to the function,\n    // only the order of mutex acquisition changes.\n    if (source->balance >= amount) {\n        source->balance -= amount;\n        destination->balance += amount;\n        printf(\"Transfer %ld from %d to %d successful. Balances: %d=%ld, %d=%ld\\n\", \n               amount, source->id, destination->id, source->id, source->balance, destination->id, destination->balance);\n    } else {\n        printf(\"Transfer %ld from %d to %d failed: insufficient funds. Balances: %d=%ld, %d=%ld\\n\", \n               amount, source->id, destination->id, source->id, source->balance, destination->id, destination->balance);\n    }\n\n    // Release locks in reverse order of acquisition (or simply both, order doesn't matter for unlock)\n    pthread_mutex_unlock(second_mutex);\n    printf(\"Thread %lu unlocked account %d (second in order)\\n\", pthread_self(), second_account->id);\n    pthread_mutex_unlock(first_mutex);\n    printf(\"Thread %lu unlocked account %d (first in order)\\n\", pthread_self(), first_account->id);\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0432__Deadlocks__CodeAnalysis__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:32:09", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Memory Management"], "content": {"text": "איזו מבין הפעולות הבאות אחראית להקצאת זיכרון דינמית בשפת C?", "code_snippet": null, "options": ["א. `new`", "ב. `free`", "ג. `malloc`", "ד. `sizeof`", "ה. `delete`"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הפונקציה `malloc` (memory allocate) היא הדרך הסטנדרטית להקצאת זיכרון דינמית בשפת C. היא מקבלת כארגומנט את מספר הבתים שיש להקצות ומחזירה מצביע (pointer) מסוג `void*` לבלוק הזיכרון שהוקצה, או NULL במקרה של כישלון. `new` ו-`delete` הן אופרטורים להקצאה ושחרור זיכרון ב-C++, בהתאמה. `free` משחררת זיכרון שהוקצה באמצעות `malloc`. `sizeof` הוא אופרטור שמחזיר את גודל בבתים של טיפוס או משתנה."}, "difficulty_estimation": "Easy", "_source_file": "0433__Memory_Management__MultipleChoice__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:32:18", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Memory Management"], "content": {"text": "מהו התפקיד העיקרי של יחידת ניהול הזיכרון (MMU)?", "code_snippet": null, "options": ["א. לנהל את תזמון המעבד.", "ב. לתרגם כתובות וירטואליות לכתובות פיזיות.", "ג. לנהל פעולות קלט/פלט.", "ד. לאחסן אוגרי מעבד."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "התפקיד העיקרי של יחידת ניהול הזיכרון (MMU - Memory Management Unit) הוא לתרגם כתובות וירטואליות, בהן משתמשים תהליכים, לכתובות פיזיות בזיכרון הראשי. זהו מרכיב חיוני במימוש זיכרון וירטואלי ובניהול זיכרון בכלל."}, "difficulty_estimation": "Easy", "_source_file": "0434__Memory_Management__MultipleChoice__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:32:25", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Memory Management", "Virtual Memory"], "content": {"text": "אחד היתרונות העיקריים של זיכרון וירטואלי הוא:", "code_snippet": null, "options": ["א. להגדיל את כמות הזיכרון הפיזי הזמין למערכת.", "ב. לאפשר למעבד גישה ישירה לדיסק הקשיח.", "ג. לספק לכל תהליך מרחב כתובות פרטי ומבודד.", "ד. להאיץ את מהירות הגישה לזיכרון הפיזי."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "ג. זיכרון וירטואלי מאפשר לכל תהליך לראות מרחב כתובות לוגי משלו, המבודד ממרחבי הכתובות של תהליכים אחרים, ובכך מספק הגנה ופשטות בניהול זיכרון. הוא אינו מגדיל את הזיכרון הפיזי בפועל, אינו מאפשר גישה ישירה לדיסק, ובדרך כלל אינו מאיץ גישה לזיכרון הפיזי (אלא להיפך, מוסיף שכבת תרגום)."}, "difficulty_estimation": "Easy", "_source_file": "0435__Memory_Management__MultipleChoice__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:32:31", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Memory Management", "Virtual Memory"], "content": {"text": "מהו סוג הכתובת שהמעבד (CPU) מייצר כאשר הוא ניגש לזיכרון?", "code_snippet": null, "options": ["א. כתובת וירטואלית", "ב. כתובת פיזית", "ג. כתובת דיסק", "ד. כתובת יחסית"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "המעבד (CPU) תמיד מייצר כתובות וירטואליות (Virtual Addresses). יחידת ניהול הזיכרון (MMU) היא זו שאחראית לתרגם את הכתובות הוירטואליות לכתובות פיזיות (Physical Addresses) לפני הגישה לזיכרון הפיזי."}, "difficulty_estimation": "Easy", "_source_file": "0436__Memory_Management__MultipleChoice__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:32:38", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Memory Management"], "content": {"text": "מהו התפקיד העיקרי של יחידת ניהול הזיכרון (MMU)?", "code_snippet": null, "options": ["א. הקצאת זיכרון לתהליכים.", "ב. תרגום כתובות וירטואליות לכתובות פיזיות.", "ג. שמירת נתונים בזיכרון מטמון בשימוש תכוף.", "ד. ניהול פעולות קלט/פלט.", "ה. הגנה על המעבד מפני הוראות לא חוקיות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. התפקיד העיקרי של יחידת ניהול הזיכרון (MMU) הוא לתרגם כתובות וירטואליות, המופקות על ידי המעבד, לכתובות פיזיות בזיכרון הראשי. זהו מרכיב חיוני ביישום זיכרון וירטואלי, הגנת זיכרון ומיפוי זיכרון."}, "difficulty_estimation": "Easy", "_source_file": "0437__Memory_Management__MultipleChoice__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:32:45", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Memory Management"], "content": {"text": "מהי פרגמנטציה חיצונית (External Fragmentation)?", "code_snippet": null, "options": ["א. בזבוז זיכרון בתוך בלוק שהוקצה לתהליך, מכיוון שהתהליך דרש פחות מהגודל שהוקצה.", "ב. מצב שבו יש מספיק זיכרון פנוי בסך הכל כדי למלא בקשה חדשה, אך הוא מפוזר בבלוקים קטנים ולא רציפים.", "ג. מצב שבו יש יותר מדי תהליכים בזיכרון הפיזי, מה שגורם להאטה במערכת.", "ד. בזבוז זיכרון הנגרם כתוצאה מהחלפת דפים (paging) תכופה מדי בין הזיכרון הראשי לדיסק.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. פרגמנטציה חיצונית מתרחשת כאשר סך הזיכרון הפנוי מספיק כדי למלא בקשת הקצאה, אך הוא אינו רציף ומפוזר בבלוקים קטנים שאינם יכולים להכיל את הבקשה כולה. אפשרות א' מתארת פרגמנטציה פנימית."}, "difficulty_estimation": "Easy", "_source_file": "0438__Memory_Management__MultipleChoice__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:32:52", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Memory Management", "Paging"], "content": {"text": "איזו סוג של פרגמנטציה קיימת בשיטת ניהול הזיכרון Paging (חלוקה לדפים)?", "code_snippet": null, "options": ["א. פרגמנטציה פנימית בלבד.", "ב. פרגמנטציה חיצונית בלבד.", "ג. גם פרגמנטציה פנימית וגם פרגמנטציה חיצונית.", "ד. אף סוג של פרגמנטציה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "בשיטת Paging, הזיכרון הפיזי מחולק לדפים (frames) בגודל קבוע. תהליכים מחולקים גם הם לדפים (pages) באותו גודל. כאשר תהליך מוקצה לזיכרון, הוא מקבל דפים שלמים. אם גודל התהליך אינו כפולה של גודל הדף, הדף האחרון שהוקצה לתהליך יכיל שטח לא מנוצל – זוהי פרגמנטציה פנימית. פרגמנטציה חיצונית, שהיא חורים קטנים ולא רציפים בין בלוקים מוקצים, אינה מתרחשת ב-Paging מכיוון שכל יחידות ההקצאה (הדפים) הן בגודל קבוע וניתן להשתמש בכל דף פנוי."}, "difficulty_estimation": "Easy", "_source_file": "0439__Memory_Management__MultipleChoice__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:33:00", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Memory Management", "Virtual Memory"], "content": {"text": "מהו התפקיד העיקרי של יחידת ניהול הזיכרון (MMU)?", "code_snippet": null, "options": ["א. ניהול תזמון המעבד.", "ב. תרגום כתובות וירטואליות לכתובות פיזיות.", "ג. טיפול בפעולות קלט/פלט של דיסק.", "ד. אחסון הוראות תוכנית."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "יחידת ניהול הזיכרון (MMU) היא רכיב חומרה שאחראי על תרגום כתובות וירטואליות, בהן משתמשים תהליכים, לכתובות פיזיות בזיכרון הראשי (RAM)."}, "difficulty_estimation": "Easy", "_source_file": "0440__Memory_Management__MultipleChoice__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:33:08", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Memory Management", "Paging", "Fragmentation"], "content": {"text": "איזו משיטות ניהול הזיכרון הבאות פותרת ביעילות את בעיית הפיצול החיצוני (External Fragmentation), אך עלולה להציג פיצול פנימי (Internal Fragmentation)?", "code_snippet": null, "options": ["א. סגמנטציה (Segmentation)", "ב. דפדוף (Paging)", "ג. מחיצות בגודל קבוע (Fixed Partitioning)", "ד. מחיצות בגודל משתנה (Variable Partitioning)", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "דפדוף (Paging) מחלק את הזיכרון הפיזי למסגרות (frames) בגודל קבוע ואת המרחב הלוגי לדפים (pages) באותו גודל. בכך, הוא מבטיח שכל חלקי התהליך יכולים להיות מפוזרים במסגרות לא רציפות בזיכרון הפיזי, ובכך מונע פיצול חיצוני לחלוטין. עם זאת, מכיוון שתהליך אינו חייב למלא בדיוק מספר שלם של דפים, הדף האחרון של התהליך עלול להכיל שטח לא מנוצל, מה שמוביל לפיצול פנימי. סגמנטציה, מחיצות בגודל קבוע ומחיצות בגודל משתנה סובלות מפיצול חיצוני."}, "difficulty_estimation": "Medium", "_source_file": "0441__Memory_Management__MultipleChoice__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:33:16", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Memory Management", "Paging", "Fragmentation"], "content": {"text": "במערכת ניהול זיכרון מבוססת דפדוף (paging), איזו מהטענות הבאות מתארת נכונה את הסיבה העיקרית לפרגמנטציה פנימית (internal fragmentation)?", "code_snippet": null, "options": ["א. היא נגרמת כאשר זיכרון פיזי פנוי מתפזר לגושים קטנים ולא רציפים ברחבי ה-RAM.", "ב. היא נוצרת מכיוון שתהליכים מקבלים הקצאת זיכרון ביחידות של דפים שלמים, וכמעט תמיד הדף האחרון אינו מנוצל במלואו.", "ג. היא מתרחשת כאשר טבלת הדפים (page table) גדולה מדי וצורכת חלק משמעותי מזיכרון ה-RAM.", "ד. היא נגרמת כתוצאה משימוש יתר בשטח ההחלפה (swap space) כאשר ה-RAM מלא.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "פרגמנטציה פנימית במערכת דפדוף מתרחשת מכיוון שהזיכרון מוקצה לתהליכים ביחידות של דפים בגודל קבוע. גם אם תהליך זקוק רק לחלק קטן מהדף האחרון שהוקצה לו, הוא מקבל דף שלם. השטח הנותר באותו דף אינו מנוצל ואינו יכול לשמש תהליכים אחרים, ולכן הוא נחשב לפרגמנטציה פנימית."}, "difficulty_estimation": "Medium", "_source_file": "0442__Memory_Management__MultipleChoice__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:33:25", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Memory Management", "Paging", "Fragmentation"], "content": {"text": "איזו משיטות ניהול הזיכרון הבאות סובלת מפיצול פנימי (internal fragmentation) אך אינה סובלת מפיצול חיצוני (external fragmentation)?", "code_snippet": null, "options": ["א. סגמנטציה (Segmentation)", "ב. דפדוף (Paging)", "ג. ניהול זיכרון רציף (Contiguous Memory Allocation)", "ד. זיכרון מטמון לטבלת דפים (TLB)"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. דפדוף (Paging). בשיטת הדפדוף, הזיכרון מחולק לדפים בגודל קבוע. דף הנתונים האחרון של תהליך עלול להיות לא מלא, מה שגורם לפיצול פנימי. עם זאת, מכיוון שכל הדפים באותו גודל וניתן למקם אותם בכל מסגרת פנויה בזיכרון הפיזי, לא נוצרים חורים בזיכרון שאינם ניתנים לשימוש עקב גודלם, ובכך נמנע פיצול חיצוני. סגמנטציה וניהול זיכרון רציף סובלים מפיצול חיצוני. TLB הוא מנגנון מטמון לטבלאות דפים, לא שיטת ניהול זיכרון בפני עצמה."}, "difficulty_estimation": "Medium", "_source_file": "0443__Memory_Management__MultipleChoice__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:33:33", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Memory Management", "Fragmentation", "Paging", "Segmentation"], "content": {"text": "איזו משיטות ניהול הזיכרון הבאות סובלת מפרגמנטציה פנימית (internal fragmentation) אך אינה סובלת מפרגמנטציה חיצונית (external fragmentation)?", "code_snippet": null, "options": ["א. סגמנטציה (Segmentation)", "ב. דפדוף (Paging)", "ג. הקצאה רציפה (Contiguous Allocation)", "ד. שניהם, סגמנטציה ודפדוף (Both Segmentation and Paging)", "ה. אף אחת מהתשובות אינה נכונה"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "דפדוף (Paging) מחלק את הזיכרון הפיזי למסגרות בגודל קבוע ואת הזיכרון הלוגי לדפים בגודל זהה. כתוצאה מכך, אין פרגמנטציה חיצונית מכיוון שכל מסגרת פנויה שוות ערך לאחרת וניתן להשתמש בה. עם זאת, ייתכן שהדף האחרון של תהליך לא ימלא מסגרת שלמה, מה שמוביל לפרגמנטציה פנימית. סגמנטציה (Segmentation) סובלת מפרגמנטציה חיצונית מכיוון שהסגמנטים הם בגדלים משתנים, אך אינה סובלת מפרגמנטציה פנימית."}, "difficulty_estimation": "Medium", "_source_file": "0444__Memory_Management__MultipleChoice__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:33:41", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Memory Management", "Paging", "Fragmentation"], "content": {"text": "איזו בעיית פרגמנטציה קיימת במערכת ניהול זיכרון המבוססת על דפדוף (Paging)?", "code_snippet": null, "options": ["א. פרגמנטציה חיצונית (External Fragmentation) בלבד.", "ב. פרגמנטציה פנימית (Internal Fragmentation) בלבד.", "ג. גם פרגמנטציה פנימית וגם פרגמנטציה חיצונית.", "ד. ללא בעיות פרגמנטציה כלל.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "בדפדוף, הזיכרון הפיזי מחולק למסגרות (frames) בגודל קבוע, והזיכרון הלוגי מחולק לדפים (pages) באותו גודל. תהליכים מקבלים הקצאה של דפים שלמים. אם תהליך זקוק לפחות זיכרון מהדף האחרון שהוקצה לו, החלק הנותר של הדף אינו בשימוש ומהווה פרגמנטציה פנימית. פרגמנטציה חיצונית, שבה ישנם חללים פנויים קטנים שאינם רציפים ולא מספיק גדולים להכיל יחידת הקצאה, אינה קיימת בדפדוף כי הקצאת הזיכרון היא ביחידות קבועות וקטנות (דפים/מסגרות), והזיכרון הפנוי מנוהל ברמת המסגרת, לא כבלוקים רציפים בגודל משתנה."}, "difficulty_estimation": "Medium", "_source_file": "0445__Memory_Management__MultipleChoice__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:33:48", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Memory Management", "Fragmentation", "Paging", "Segmentation"], "content": {"text": "איזו משיטות ניהול הזיכרון הבאות סובלת בעיקר מפרגמנטציה חיצונית (external fragmentation)?", "code_snippet": null, "options": ["א. דפדוף (Paging)", "ב. פילוח (Segmentation)", "ג. גם דפדוף וגם פילוח", "ד. אף אחת מהתשובות אינה נכונה"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "דפדוף (Paging) סובל מפרגמנטציה פנימית (internal fragmentation) מכיוון שדפים מוקצים בגודל קבוע, וייתכן שהתהליך לא ישתמש בכל הזיכרון בדף האחרון. פילוח (Segmentation) לעומת זאת, סובל מפרגמנטציה חיצונית (external fragmentation) מכיוון שסגמנטים יכולים להיות בגדלים שונים ומשתנים, וכאשר הם משוחררים, נוצרים 'חורים' בגדלים שונים בזיכרון הפיזי, מה שמקשה על מציאת מקום רציף לסגמנטים חדשים, גם אם סך הזיכרון הפנוי מספיק."}, "difficulty_estimation": "Medium", "_source_file": "0446__Memory_Management__MultipleChoice__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:33:56", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Memory Management", "Paging", "Fragmentation"], "content": {"text": "איזה סוג של פרגמנטציה קשור בעיקר למנגנון דפדוף (Paging), ומדוע?", "code_snippet": null, "options": ["א. פרגמנטציה חיצונית, מכיוון שדפים בגדלים שונים אינם יכולים להתאים למסגרות זיכרון.", "ב. פרגמנטציה פנימית, מכיוון שהזיכרון המוקצה לתהליך מגיע ביחידות קבועות (דפים), וייתכן שהדף האחרון של תהליך לא ינוצל במלואו.", "ג. פרגמנטציה חיצונית, מכיוון שעלולים להיווצר חורים קטנים בזיכרון הפיזי בין מסגרות שהוקצו לתהליכים שונים.", "ד. פרגמנטציה פנימית, מכיוון שכל תהליך מקבל בלוק זיכרון בגודל קבוע ללא קשר לגודל בפועל של הנתונים.", "ה. אין פרגמנטציה כלל במנגנון דפדוף."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. במנגנון דפדוף, הזיכרון הווירטואלי והפיזי מחולקים ליחידות בגודל קבוע הנקראות דפים ומסגרות בהתאמה. כאשר תהליך מקבל הקצאת זיכרון, הוא מקבל מספר שלם של דפים. אם גודל התהליך אינו כפולה מדויקת של גודל הדף, הדף האחרון שהוקצה לתהליך לא ינוצל במלואו, מה שמוביל לפרגמנטציה פנימית. פרגמנטציה חיצונית אינה בעיה מרכזית בדפדוף מכיוון שכל המסגרות הן באותו גודל וניתן למלא כל מסגרת פנויה."}, "difficulty_estimation": "Medium", "_source_file": "0447__Memory_Management__MultipleChoice__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:34:05", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Memory Management", "Fragmentation", "Paging", "Segmentation"], "content": {"text": "איזו משיטות ניהול הזיכרון הבאות סובלת בעיקר מפרגמנטציה חיצונית (External Fragmentation)?", "code_snippet": null, "options": ["א. Paging (דפדוף)", "ב. Segmentation (פילוח)", "ג. גם דפדוף וגם פילוח", "ד. לא דפדוף ולא פילוח"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "פרגמנטציה חיצונית מתרחשת כאשר יש מספיק זיכרון פנוי בסך הכל, אך הוא מפוזר בבלוקים קטנים שאינם רציפים, כך שלא ניתן להקצות יחידה גדולה יותר. שיטת הפילוח (Segmentation) מקצה בלוקים בגדלים משתנים עבור סגמנטים, מה שמוביל לפרגמנטציה חיצונית. שיטת הדפדוף (Paging) מחלקת את הזיכרון לבלוקים בגודל קבוע (דפים ומסגרות), ובכך מונעת פרגמנטציה חיצונית אך עלולה לגרום לפרגמנטציה פנימית."}, "difficulty_estimation": "Medium", "_source_file": "0448__Memory_Management__MultipleChoice__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:34:12", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Memory Management", "Paging", "TLB", "Page Faults", "Page Table Walk"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם כתובות וירטואליות בנות 32 ביטים וגודל דף של 4KB. טבלת הדפים היא דו-מפלסית, כאשר כל כניסה בטבלת דפים (PTE) היא בגודל 4 בתים. ה-TLB במערכת הינו בגודל 128 כניסות, אסוציאטיבי מלא (fully associative) ומשתמש במדיניות החלפה LRU. ה-TLB ריק בתחילת הריצה.\n\nתהליך מבצע את הלולאה הבאה:\n```c\nint arr[1024 * 1024 * 2]; // 2M integers\nfor (int i = 0; i < 1024 * 1024 * 2; i++) {\n    arr[i] = i;\n}\n```\nהנח כי הזיכרון הפיזי ריק בתחילת הריצה, וכי המערך `arr` ממוקם בכתובת וירטואלית המתחילה ביישור של דף (page-aligned). כמה אירועים מכל סוג יתרחשו במהלך ביצוע הלולאה?", "code_snippet": "int arr[1024 * 1024 * 2];\nfor (int i = 0; i < 1024 * 1024 * 2; i++) {\n    arr[i] = i;\n}", "options": ["א. 2048 Page Faults, 2048 TLB Misses, 2048 גישות לטבלת דפים (P1) ו-2048 גישות לטבלת דפים (P2).", "ב. 2048 Page Faults, 2048 TLB Misses, 2 גישות לטבלת דפים (P1) ו-2048 גישות לטבלת דפים (P2).", "ג. 2048 Page Faults, 2048 TLB Misses, 4096 גישות לטבלת דפים (סה\"כ).", "ד. 2048 Page Faults, 2048 * 1024 TLB Misses, 4096 גישות לטבלת דפים (סה\"כ).", "ה. אף אחת מהתשובות אינה נכונה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "ניתוח המערכת:\n*   **גודל כתובת וירטואלית:** 32 ביטים.\n*   **גודל דף:** 4KB = 2^12 בתים. לכן, 12 הביטים הפחות משמעותיים (LSB) של הכתובת הווירטואלית הם ה-offset בתוך הדף.\n*   **מספר ביטים ל-VPN (Virtual Page Number):** 32 - 12 = 20 ביטים.\n*   **טבלת דפים דו-מפלסית:** כל כניסה בטבלת דפים (PTE) היא 4 בתים. גודל דף הוא 4KB. לכן, כל טבלת דפים (מפלס 1 או מפלס 2) יכולה להכיל `4096 / 4 = 1024` כניסות.\n    *   `log2(1024) = 10` ביטים. לכן, 10 הביטים הבאים משמשים לאינדקס בטבלת הדפים מפלס 2 (P2), ו-10 הביטים העליונים משמשים לאינדקס בטבלת הדפים מפלס 1 (P1). (P1: 10 ביטים, P2: 10 ביטים, Offset: 12 ביטים).\n\n*   **המערך `arr`:** מכיל `2 * 1024 * 1024` אינטגרים. כל אינטגר הוא 4 בתים.\n    *   גודל המערך הכולל: `2 * 1024 * 1024 * 4` בתים = `8MB`.\n    *   מספר הדפים שהמערך תופס: `8MB / 4KB לדף` = `2048` דפים.\n    *   כל דף מכיל `4KB / 4B לאינטגר` = `1024` אינטגרים.\n*   **גישה למערך:** הלולאה ניגשת לכל אלמנט במערך באופן סדרתי. סך הגישות: `2048 * 1024`.\n*   **TLB:** בגודל 128 כניסות, אסוציאטיבי מלא, LRU, ריק בתחילה.\n\n**חישובים:**\n1.  **Page Faults:**\n    *   המערך משתרע על פני 2048 דפים ייחודיים.\n    *   מכיוון שהזיכרון הפיזי ריק בתחילת הריצה, הגישה הראשונה לכל אחד מ-2048 הדפים הללו תגרום לפסיקת דף (Page Fault).\n    *   **סה\"כ Page Faults: 2048.**\n\n2.  **TLB Misses:**\n    *   עבור כל אחד מ-2048 הדפים הייחודיים, הגישה הראשונה לאינטגר כלשהו באותו דף תגרום ל-TLB Miss.\n    *   לאחר ה-TLB Miss, הכניסה לדף תוכנס ל-TLB. בתוך כל דף ישנם 1024 אינטגרים. לאחר הגישה הראשונה (שהיא Miss), 1023 הגישות הבאות לאינטגרים באותו דף יהיו TLB Hits.\n    *   מדיניות ה-LRU ב-TLB בגודל 128 כניסות: מכיוון שיש 2048 דפים ייחודיים ורק 128 כניסות ב-TLB, ה-TLB יתמלא ויתחיל להחליף כניסות. בגישה סדרתית, בכל פעם שניגשים לדף חדש שאינו ב-TLB (כלומר, הגישה הראשונה לכל אחד מ-2048 הדפים), תתרחש TLB Miss. הגישות הבאות לאותו דף יהיו Hits עד שהדף יוחלף. (הערה: הגישה הראשונה לכל דף תהיה TLB miss, אך כל 1023 הגישות הבאות לאותו דף יהיו TLB hit, כל עוד הדף לא יוחלף מה-TLB. אך מכיוון שעל כל 128 דפים יש החלפה, עדיין רק הגישה הראשונה לכל דף תגרום ל-miss). \n    *   **סה\"כ TLB Misses: 2048** (אחת לכל דף ייחודי).\n\n3.  **גישות לטבלת הדפים (Page Table Accesses):**\n    *   כל TLB Miss גורם לביצוע Page Table Walk.\n    *   **סה\"כ Page Table Walks: 2048.**\n    *   בטבלת דפים דו-מפלסית, כל Page Table Walk דורש שתי גישות לזיכרון:\n        1.  גישה לטבלת הדפים מפלס 1 (P1) כדי למצוא את הבסיס של טבלת הדפים מפלס 2.\n        2.  גישה לטבלת הדפים מפלס 2 (P2) כדי למצוא את ה-PTE של הדף המבוקש.\n    *   המערך משתרע על 2048 דפים. כל טבלת דפים מפלס 2 יכולה למפות 1024 דפים (4MB). לכן, המערך משתרע על פני שתי טבלאות דפים מפלס 2 (ולכן שתי כניסות P1 שונות).\n    *   עבור כל אחד מ-2048 ה-TLB Misses, תבוצע גישה אחת ל-P1 וגישה אחת ל-P2.\n    *   **סה\"כ גישות לטבלת דפים מפלס 1 (P1): 2048.**\n    *   **סה\"כ גישות לטבלת דפים מפלס 2 (P2): 2048.**\n\nלפי החישובים, התשובה המתאימה ביותר היא א'."}, "difficulty_estimation": "Hard", "_source_file": "0449__Memory_Management__MultipleChoice__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:34:53", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Memory Management", "Heap Allocation", "Fragmentation"], "content": {"text": "נתונה מערכת ניהול זיכרון המשתמשת באלגוריתם First-Fit להקצאת זיכרון, ומעגלת כל בקשת הקצאה לגודל הקרוב ביותר שהוא כפולה של 16 בתים. גודל הערימה (heap) הכולל הוא 256 בתים, ובתחילה הוא בלוק פנוי אחד בגודל 256 בתים.\nבוצעו הפעולות הבאות ברצף:\n", "code_snippet": "void* ptr1 = malloc(20);\nvoid* ptr2 = malloc(10);\nvoid* ptr3 = malloc(40);\nvoid* ptr4 = malloc(5);\nfree(ptr2);\nfree(ptr4);\nvoid* ptr5 = malloc(30);", "options": ["א. 0 בתים", "ב. 16 בתים", "ג. 32 בתים", "ד. 128 בתים", "ה. 144 בתים"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "נבחן את מצב הערימה לאחר כל שלב, כאשר כל הקצאה מעוגלת לכפולה הקרובה ביותר של 16 בתים, והאלגוריתם הוא First-Fit:\n\n*   **התחלה**: [F: 256] (בלוק פנוי של 256 בתים)\n*   **1. `malloc(20)`**: מעוגל ל-32 בתים. הערימה: [U: 32 (ptr1)] [F: 224]\n*   **2. `malloc(10)`**: מעוגל ל-16 בתים. הערימה: [U: 32 (ptr1)] [U: 16 (ptr2)] [F: 208]\n*   **3. `malloc(40)`**: מעוגל ל-48 בתים. הערימה: [U: 32 (ptr1)] [U: 16 (ptr2)] [U: 48 (ptr3)] [F: 160]\n*   **4. `malloc(5)`**: מעוגל ל-16 בתים. הערימה: [U: 32 (ptr1)] [U: 16 (ptr2)] [U: 48 (ptr3)] [U: 16 (ptr4)] [F: 144]\n\n*   **5. `free(ptr2)`**: משחרר את הבלוק בגודל 16 בתים. אין איחוד (coalescing) כי הבלוק מוקף בבלוקים תפוסים.\n    הערימה: [U: 32 (ptr1)] [F: 16 (ptr2)] [U: 48 (ptr3)] [U: 16 (ptr4)] [F: 144]\n\n*   **6. `free(ptr4)`**: משחרר את הבלוק בגודל 16 בתים. הבלוק ששוחרר (`ptr4`) צמוד לבלוק הפנוי הגדול (144 בתים), ולכן מתבצע איחוד: [F: 16 (ptr4)] [F: 144] הופך ל- [F: 160].\n    הערימה: [U: 32 (ptr1)] [F: 16 (ptr2)] [U: 48 (ptr3)] [F: 160]\n    הבלוקים הפנויים כעת הם 16 בתים ו-160 בתים.\n\n*   **7. `malloc(30)`**: מעוגל ל-32 בתים. אלגוריתם First-Fit יחפש את הבלוק הפנוי הראשון בגודל מספק.\n    הבלוק הראשון (16 בתים) קטן מדי.\n    הבלוק השני (160 בתים) גדול מספיק. יוקצו ממנו 32 בתים, ויישאר בלוק פנוי של 128 בתים.\n    הערימה: [U: 32 (ptr1)] [F: 16 (ptr2)] [U: 48 (ptr3)] [U: 32 (ptr5)] [F: 128]\n\nבסיום כל הפעולות, קיימים שני בלוקים פנויים: אחד בגודל 16 בתים, ואחד בגודל 128 בתים.\n\n*   **סך הזיכרון הפנוי**: 16 + 128 = 144 בתים.\n*   **הבלוק הפנוי הגדול ביותר**: 128 בתים.\n\nפיצול חיצוני (external fragmentation) מוגדר כסך הזיכרון הפנוי שאינו יכול לשמש להקצאה אחת, כלומר סך הזיכרון הפנוי פחות גודל הבלוק הפנוי הגדול ביותר.\nפיצול חיצוני = (סך הזיכרון הפנוי) - (גודל הבלוק הפנוי הגדול ביותר)\nפיצול חיצוני = 144 - 128 = 16 בתים.\n\nלכן התשובה הנכונה היא ב'."}, "difficulty_estimation": "Hard", "_source_file": "0450__Memory_Management__MultipleChoice__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:35:16", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Memory Management", "Virtual Memory", "Paging", "TLB"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם כתובות וירטואליות בנות 64 ביטים וגודל דף של 4KB. טבלת הדפים היא בעלת 4 רמות. ה-TLB מכיל 128 כניסות ומשתמש במדיניות החלפה LRU. בהתחלה, ה-TLB ריק וכל הדפים אינם נמצאים בזיכרון הפיזי.\n\nכמה החטאות TLB (TLB misses), כמה פסיקות דף (page faults) וכמה גישות זיכרון כוללות (memory accesses) יתרחשו במהלך ביצוע הלולאה הבאה? יש לכלול בגישות הזיכרון גם גישות לטבלאות הדפים וגם גישות לנתונים עצמם. הנח כי עדכון PTE בזיכרון וטעינת ה-PTE ל-TLB נחשבים כגישת זיכרון אחת כל אחד, וכי טעינת דף מהדיסק אינה נחשבת גישת זיכרון.", "code_snippet": "long long *arr = (long long *)0x100000000000; // כתובת וירטואלית התחלתית\nfor (int i = 0; i < 200; ++i) {\n    arr[i * 1024]; // גישה לאיבר\n}", "options": ["א. 200 החטאות TLB, 200 פסיקות דף, 600 גישות זיכרון.", "ב. 200 החטאות TLB, 200 פסיקות דף, 1200 גישות זיכרון.", "ג. 128 החטאות TLB, 200 פסיקות דף, 1000 גישות זיכרון.", "ד. 200 החטאות TLB, 128 פסיקות דף, 800 גישות זיכרון.", "ה. אף אחת מהתשובות האחרות אינה נכונה."]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ה", "explanation": "נתונים:\n*   גודל כתובת וירטואלית: 64 ביטים\n*   גודל דף: 4KB (2^12 בתים)\n*   מבנה טבלת הדפים: 4 רמות\n*   גודל TLB: 128 כניסות, מדיניות LRU\n*   מצב התחלתי: TLB ריק, כל הדפים אינם בזיכרון הפיזי.\n\nניתוח קטע הקוד:\nהלולאה מבצעת 200 איטרציות. בכל איטרציה, מתבצעת גישה לאיבר `arr[i * 1024]`. גודל `long long` הוא 8 בתים. לכן, הגישה היא לכתובת `base_address + (i * 1024 * 8)`. המרווח בין גישות עוקבות הוא `1024 * 8 = 8192` בתים.\nמאחר שגודל הדף הוא 4KB (4096 בתים) והמרווח בין גישות הוא 8192 בתים, כל גישה בלולאה תהיה לדף וירטואלי *שונה* וחדש. כלומר, 200 דפים וירטואליים נפרדים ייגשו במהלך הלולאה.\n\n1.  **החטאות TLB (TLB misses)**:\n    *   200 דפים וירטואליים נפרדים נגשים. גודל ה-TLB הוא 128 כניסות. מכיוון שקבוצת העבודה (200 דפים) גדולה מקיבולת ה-TLB (128 כניסות), וכל גישה היא לדף חדש שלא נגש קודם לכן בלולאה, כל 200 הגישות יגרמו להחטאת TLB. גם לאחר שה-TLB יתמלא (אחרי 128 גישות), כל גישה חדשה לדף תגרום להחלפה של דף אחר (לפי LRU) ולכן תהיה החטאה. מכיוון שהדפים נגשים באופן סדרתי ולא חוזרים על עצמם בתוך 200 הגישות, כל גישה תהיה החטאה.\n    *   **סה\"כ החטאות TLB: 200**.\n\n2.  **פסיקות דף (Page Faults)**:\n    *   נאמר שכל הדפים אינם בזיכרון הפיזי בתחילה. מכיוון שנגשים ל-200 דפים וירטואליים נפרדים, וכל גישה היא לדף חדש עבור הלולאה, כל אחת מ-200 הגישות תגרום לפסיקת דף (page fault) בפעם הראשונה שדף זה נגש.\n    *   **סה\"כ פסיקות דף: 200**.\n\n3.  **גישות זיכרון כוללות (Total Memory Accesses)**:\n    *   כל אחת מ-200 הגישות לזיכרון תגרום גם להחטאת TLB וגם לפסיקת דף.\n    *   כאשר מתרחשת פסיקת דף:\n        1.  ה-CPU מבצע מעבר על טבלת הדפים (page table walk) כדי לאתר את ה-PTE (Page Table Entry). עבור טבלת דפים בעלת 4 רמות, זה דורש **4 גישות קריאה לזיכרון** (ל-PML4, PDPT, PDIR, PT).\n        2.  ה-PTE מציין שהדף אינו נמצא. מערכת ההפעלה מטפלת בפסיקת הדף: טוענת את הדף מהדיסק (לא נחשב גישת זיכרון לפי הנתון), ומעדכנת את ה-PTE בזיכרון הראשי. זוהי **1 גישת כתיבה לזיכרון** (עדכון ה-PTE).\n        3.  מערכת ההפעלה טוענת את ה-PTE החדש ל-TLB. הנח כי פעולה זו נחשבת גם היא ל**1 גישת זיכרון** (לפי הנתון בשאלה).\n        4.  ההוראה המקורית מופעלת מחדש. כעת, בדיקת ה-TLB תמצא את ה-PTE (כיוון שהוא נטען). לאחר מכן, מתבצעת גישה לנתון עצמו. זוהי **1 גישת קריאה לזיכרון**.\n    *   לכן, עבור כל גישה שגורמת לפסיקת דף, מתרחשות `4 (קריאות לטבלאות דפים) + 1 (כתיבת PTE בזיכרון) + 1 (טעינת PTE ל-TLB) + 1 (קריאת נתון)` = **7 גישות זיכרון**.\n    *   סה\"כ גישות זיכרון כוללות = `200 גישות * 7 גישות זיכרון/גישה = 1400 גישות זיכרון`.\n\nהתוצאה היא: 200 החטאות TLB, 200 פסיקות דף, 1400 גישות זיכרון. אף אחת מהאפשרויות א-ד אינה תואמת תוצאה זו.\n\nהתשובה הנכונה היא ה'."}, "difficulty_estimation": "Hard", "_source_file": "0451__Memory_Management__MultipleChoice__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:35:57", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Memory Management", "Paging", "Virtual Memory", "TLB"], "content": {"text": "מערכת הפעלה משתמשת בכתובות וירטואליות בגודל 48 ביטים ובכתובות פיזיות בגודל 40 ביטים. גודל דף הוא 4KB. טבלת הדפים היא בעלת 4 רמות, כאשר כל ערך בטבלת דפים (PTE) הוא בגודל 8 בתים. ה-TLB מלא ומכיל 128 רשומות.\nתהליך מנסה לגשת לראשונה לכתובת וירטואלית מסוימת. ידוע כי הרשומה המתאימה אינה נמצאת ב-TLB (TLB Miss), וגם הדף הפיזי המתאים אינו נמצא בזיכרון הראשי (Page Fault).\nבהנחה שכל דפי טבלת הדפים נמצאים בזיכרון הראשי, וכי לאחר טעינת הדף מהדיסק, מערכת ההפעלה מעדכנת את טבלת הדפים ואת ה-TLB לפני הפעלת הפקודה מחדש.\nכמה גישות לזיכרון הראשי (RAM) נדרשות לכל היותר כדי להשלים בהצלחה פעולת קריאה יחידה לכתובת זו?", "code_snippet": null, "options": ["א. 5", "ב. 6", "ג. 7", "ד. 8", "ה. 9"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הסבר:\n1.  **TLB Miss**: כאשר ה-MMU מנסה לתרגם את הכתובת הוירטואלית, הוא מגלה שהרשומה אינה ב-TLB. אין גישת זיכרון ל-RAM בשלב זה.\n2.  **Page Table Walk**: ה-MMU (או מערכת ההפעלה) מתחילה לחפש את ה-PTE המתאים בטבלת הדפים. מכיוון שיש 4 רמות, נדרשות 4 גישות לזיכרון הראשי (קריאה של PTE מכל רמה) כדי להגיע ל-PTE הסופי. (4 גישות RAM)\n3.  **Page Fault**: ה-PTE הסופי מצביע על כך שהדף אינו נמצא בזיכרון הפיזי (valid bit = 0).\n4.  **טיפול ב-Page Fault (Page Fault Handler)**:\n    *   מערכת ההפעלה מוצאת מסגרת פיזית פנויה.\n    *   מערכת ההפעלה טוענת את הדף מהדיסק למסגרת הפיזית. פעולה זו אינה נחשבת כגישת RAM (היא גישת דיסק).\n    *   לאחר טעינת הדף, מערכת ההפעלה מעדכנת את ה-PTE הסופי בטבלת הדפים (כתיבה של ה-PTE החדש ל-RAM). (1 גישת RAM)\n    *   מערכת ההפעלה מעדכנת את ה-TLB עם המיפוי החדש. פעולה זו נחשבת פנימית למעבד/MMU ואינה גישת RAM.\n5.  **הפעלה מחדש של הפקודה**: הפקודה המקורית שגרמה ל-Page Fault מופעלת מחדש.\n    *   כעת, ה-TLB מכיל את הרשומה המתאימה (TLB Hit).\n    *   ה-MMU מתרגם את הכתובת באמצעות ה-TLB.\n    *   מתבצעת גישת הקריאה בפועל לנתונים בזיכרון הראשי. (1 גישת RAM)\n\nסה\"כ גישות לזיכרון הראשי: 4 (עבור ה-Page Table Walk) + 1 (עדכון ה-PTE לאחר טעינת הדף) + 1 (גישת הנתונים בפועל) = 6 גישות RAM."}, "difficulty_estimation": "Hard", "_source_file": "0452__Memory_Management__MultipleChoice__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:36:24", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Memory Management", "Paging", "Multi-level Page Tables"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בטבלאות דפים רב-שכבתיות עם 3 רמות (P1 -> P2 -> P3 -> דף פיזי). כתובת וירטואלית היא באורך 48 ביטים. גודל דף הוא 4KB. גודל כניסת טבלת דפים (PTE) הוא 8 בתים. תהליך יחיד מקצה לעצמו 16GB של זיכרון וירטואלי, אך משתמש באופן פעיל (כלומר, דפי הנתונים שלו נמצאים בזיכרון פיזי) רק ב-512MB מתוכו. הזיכרון הפעיל מפוזר באופן דליל (sparsely distributed) על פני מרחב הכתובות הוירטואלי. בהנחה שמערכת ההפעלה מקצה טבלאות דפים באופן אופטימלי (כלומר, רק כאשר יש צורך), מהו נפח הזיכרון המינימלי (בבתים) הנדרש לאחסון כל טבלאות הדפים עבור תהליך זה?", "code_snippet": null, "options": ["א. 1,024,000 בתים", "ב. 1,032,000 בתים", "ג. 1,056,768 בתים", "ד. 1,048,576 בתים", "ה. 1,060,864 בתים"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הסבר:\n1.  **חישוב פרמטרים בסיסיים:**\n    *   גודל דף: 4KB = 2^12 בתים. לכן, 12 ביטים משמשים ל-offset בתוך הדף.\n    *   אורך כתובת וירטואלית: 48 ביטים.\n    *   מספר ביטי ה-Virtual Page Number (VPN): 48 - 12 = 36 ביטים.\n    *   גודל כניסת טבלת דפים (PTE): 8 בתים.\n    *   מספר כניסות טבלה לדף טבלה בודד: 4KB / 8 בתים = 512 כניסות.\n    *   מספר ביטים לכל אינדקס בדף טבלת דפים: 2^9 = 512, לכן 9 ביטים לאינדקס.\n\n2.  **חלוקת ביטי ה-VPN בין הרמות:**\n    *   נתונה טבלת דפים בעלת 3 רמות (P1 -> P2 -> P3 -> דף פיזי). זה אומר שה-VPN מחולק לשלושה אינדקסים: I1, I2, I3.\n    *   אינדקס לרמה 1 (I1): 9 ביטים (מצביע לדף P2).\n    *   אינדקס לרמה 2 (I2): 9 ביטים (מצביע לדף P3).\n    *   הביטים הנותרים עבור אינדקס לרמה 3 (I3): 36 - 9 - 9 = 18 ביטים (מצביע לדף נתונים פיזי).\n\n3.  **חישוב מספר דפי נתונים פעילים:**\n    *   זיכרון פעיל: 512MB.\n    *   מספר דפי נתונים = 512MB / 4KB = 2^29 בתים / 2^12 בתים לדף = 2^17 דפים = 131,072 דפים.\n\n4.  **חישוב נפח הזיכרון עבור טבלאות דפים (מלמטה למעלה, בהנחה של הקצאה אופטימלית עבור זיכרון מפוזר):**\n    *   **רמה 3 (P3):**\n        *   כל דף טבלה ברמה 3 מכיל 512 PTEs (כל PTE מצביע לדף נתונים). כלומר, דף P3 אחד יכול לשרת 512 דפי נתונים.\n        *   כדי לטפל ב-2^17 דפי נתונים פעילים, נצטרך: ceil(2^17 / 512) = ceil(2^17 / 2^9) = 2^8 = 256 דפי טבלה ברמה 3.\n        *   נפח זיכרון עבור דפי P3 = 256 * 4KB = 1024KB = 1MB.\n\n    *   **רמה 2 (P2):**\n        *   כל דף טבלה ברמה 2 מכיל 512 PTEs (כל PTE מצביע לדף טבלה ברמה 3). כלומר, דף P2 אחד יכול לשרת 512 דפי P3.\n        *   כדי לטפל ב-256 דפי טבלה ברמה 3, נצטרך: ceil(256 / 512) = 1 דף טבלה ברמה 2.\n        *   נפח זיכרון עבור דפי P2 = 1 * 4KB = 4KB.\n\n    *   **רמה 1 (P1 - טבלת הבסיס):**\n        *   כל דף טבלה ברמה 1 מכיל 512 PTEs (כל PTE מצביע לדף טבלה ברמה 2). כלומר, דף P1 אחד יכול לשרת 512 דפי P2.\n        *   כדי לטפל ב-1 דף טבלה ברמה 2, נצטרך: ceil(1 / 512) = 1 דף טבלה ברמה 1 (זהו דף טבלת הבסיס/השורש).\n        *   נפח זיכרון עבור דפי P1 = 1 * 4KB = 4KB.\n\n5.  **סה\"כ נפח זיכרון לטבלאות דפים:**\n    *   סה\"כ = נפח P1 + נפח P2 + נפח P3\n    *   סה\"כ = 4KB + 4KB + 1024KB = 1032KB.\n    *   המרת לבתים: 1032KB * 1024 בתים/KB = 1,056,768 בתים.\n\nלכן, התשובה הנכונה היא ג'."}, "difficulty_estimation": "Hard", "_source_file": "0453__Memory_Management__MultipleChoice__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:48:54", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Memory Management", "Virtual Memory", "Paging", "TLB"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם כתובות וירטואליות בגודל 48 ביטים. גודל דף הוא 4KB. טבלת הדפים בנויה ב-4 רמות (multi-level page table), כאשר כל רמת טבלה יכולה להכיל 512 כניסות. גודל כניסה בטבלת דפים (PTE) הוא 8 בתים. בנוסף, קיימת יחידת TLB (Translation Lookaside Buffer) עם שיעור פגיעה (hit rate) של 99%. כמה גישות זיכרון RAM בממוצע נדרשות עבור תרגום כתובת וירטואלית אחת וגישה לנתונים בכתובת זו?", "code_snippet": null, "options": ["א. 1.01", "ב. 1.04", "ג. 1.05", "ד. 1.08", "ה. 1.12"]}, "sub_questions": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הסבר:\nכתובת וירטואלית בגודל 48 ביטים.\nגודל דף 4KB = 2^12 בתים. לכן, 12 ביטים מוקצים ל-offset בתוך הדף.\nמספר הביטים לכתובת דף וירטואלי (VPN) הוא 48 - 12 = 36 ביטים.\nטבלת הדפים בנויה ב-4 רמות, כאשר כל רמה מכילה 512 כניסות. מכיוון ש-512 = 2^9, כל אינדקס ברמת טבלה דורש 9 ביטים.\nבסך הכל, 4 רמות דורשות 4 * 9 = 36 ביטים, מה שמתאים בדיוק לגודל ה-VPN.\n\nחישוב גישות זיכרון:\n1.  **במקרה של פגיעה ב-TLB (TLB Hit Rate = 99%)**:\n    הכתובת הפיזית נמצאת ב-TLB. נדרשת גישת זיכרון אחת בלבד ל-RAM כדי לגשת לנתונים בכתובת הפיזית.\n    מספר גישות זיכרון = 1.\n\n2.  **במקרה של החטאה ב-TLB (TLB Miss Rate = 1 - 0.99 = 1%)**:\n    ה-TLB לא מכיל את הכתובת. יש לבצע מהלך טבלת דפים (page table walk) כדי למצוא את הכתובת הפיזית:\n    -   גישת זיכרון אחת לטבלת הדפים ברמה 1 (P1).\n    -   גישת זיכרון אחת לטבלת הדפים ברמה 2 (P2).\n    -   גישת זיכרון אחת לטבלת הדפים ברמה 3 (P3).\n    -   גישת זיכרון אחת לטבלת הדפים ברמה 4 (P4), אשר מכילה את מספר המסגרת הפיזית (PFN).\n    -   סה\"כ 4 גישות זיכרון עבור תרגום הכתובת.\n    -   לאחר מכן, יש גישת זיכרון אחת ל-RAM כדי לגשת לנתונים.\n    -   סה\"כ גישות זיכרון = 4 (לטבלאות דפים) + 1 (לנתונים) = 5 גישות זיכרון.\n\nחישוב ממוצע גישות זיכרון:\nממוצע גישות = (שיעור פגיעה * גישות בפגיעה) + (שיעור החטאה * גישות בהחטאה)\nממוצע גישות = (0.99 * 1) + (0.01 * 5)\nממוצע גישות = 0.99 + 0.05\nממוצע גישות = 1.04\n\nלכן, התשובה הנכונה היא ב'."}, "difficulty_estimation": "Hard", "_source_file": "0454__Memory_Management__MultipleChoice__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:49:15", "_subject": "Virtualization"}, {"id": 101, "type": "MultipleChoice", "topic": ["Memory Management", "Paging", "Locality", "Virtual Memory"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי מבוסס דפים (demand paging) עם גודל דף של 4KB. תהליך מקצה דינמית מערך דו-ממדי בגודל `int arr[1024][1024]` (כאשר `sizeof(int) = 4` בתים). ההקצאה מתבצעת באופן רציף בזיכרון הוירטואלי והמערך מתחיל בגבול דף. נניח שזיכרון פיזי זמין מוגבל ואינו מסוגל להכיל את כל המערך. שקול את שני קטעי הקוד הבאים לאתחול המערך:\n\n```c\n// קטע קוד א'\nfor (int i = 0; i < 1024; ++i) {\n    for (int j = 0; j < 1024; ++j) {\n        arr[i][j] = i + j;\n    }\n}\n\n// קטע קוד ב'\nfor (int j = 0; j < 1024; ++j) {\n    for (int i = 0; i < 1024; ++i) {\n        arr[i][j] = i + j;\n    }\n}\n```\n\nאיזו טענה נכונה לגבי מספר פסיקות הדף (page faults) שייגרמו על ידי שני קטעי הקוד?", "code_snippet": null, "options": ["א. קטע קוד א' וקטע קוד ב' יגרמו למספר זהה של פסיקות דף, מכיוון שהם ניגשים לאותם נתונים.", "ב. קטע קוד א' יגרום לכ-1024 פסיקות דף, בעוד שקטע קוד ב' יגרום למספר קטן יותר, מכיוון שהוא מנצל טוב יותר את ה-TLB.", "ג. קטע קוד א' יגרום למספר נמוך משמעותית של פסיקות דף בהשוואה לקטע קוד ב', מכיוון שהוא מנצל טוב יותר את לוקליות הנתונים.", "ד. קטע קוד ב' יגרום למספר נמוך משמעותית של פסיקות דף בהשוואה לקטע קוד א', מכיוון שהוא מאפשר טעינה מקבילית של דפים.", "ה. מספר פסיקות הדף תלוי רק באלגוריתם החלפת הדפים ובכמות הזיכרון הפיזי, ולא בסדר הגישה."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "ג. גודל המערך הוא `1024 * 1024 * 4` בתים = 4MB. גודל הדף הוא 4KB.\n\n**קטע קוד א' (גישה לפי שורות - row-major):**\nכל שורה במערך היא בגודל `1024 * 4 = 4096` בתים, שזה בדיוק גודל דף אחד (4KB).\nכאשר קטע קוד א' ניגש לנתונים, הוא קורא את כל הנתונים של שורה מסוימת ברצף. מכיוון שהשורה כולה נכנסת לדף אחד, גישה לשורה תגרום לפסיקת דף אחת בלבד (אם הדף אינו בזיכרון). לאחר מכן, כל הגישות לשאר האיברים באותה שורה יהיו בתוך אותו דף שכבר נטען.\nבסך הכל, יהיו כ-1024 פסיקות דף (אחת לכל שורה), מכיוון שיש 1024 שורות וכל שורה תופסת דף אחר בזיכרון הוירטואלי. זהו ניצול טוב של לוקליות מרחבית (spatial locality).\n\n**קטע קוד ב' (גישה לפי עמודות - column-major):**\nכאשר קטע קוד ב' ניגש לנתונים, הלולאה הפנימית משתנה על `i` עבור `j` קבוע. הגישה היא ל-`arr[0][j]`, `arr[1][j]`, `arr[2][j]`, וכו'.\nכתובת הזיכרון של `arr[i][j]` היא `base + (i * 1024 + j) * sizeof(int)`.\nההפרש בכתובות בין `arr[i][j]` ל-`arr[i+1][j]` הוא `1024 * sizeof(int) = 1024 * 4 = 4096` בתים, שזה בדיוק גודל דף אחד.\nמשמעות הדבר היא שכל גישה ל-`arr[i][j]` כאשר `i` עולה, תהיה כמעט בוודאות בדף זיכרון וירטואלי שונה. מכיוון שיש 1024 שורות, הלולאה הפנימית תנסה לגשת ל-1024 דפים שונים ברצף מהיר.\nאם הזיכרון הפיזי מוגבל (לדוגמה, פחות מ-1024 דפים זמינים), אז עבור כל `i` בלולאה הפנימית, תתרחש ככל הנראה פסיקת דף, מכיוון שהדף הנדרש סביר להניח שהוחלף כבר על ידי דף אחר (במיוחד עם אלגוריתמי החלפת דפים נפוצים כמו LRU).\nלכן, עבור כל `j` (הלולאה החיצונית), הלולאה הפנימית תגרום לכ-1024 פסיקות דף. ובסה\"כ, מספר פסיקות הדף יכול להגיע לכ-`1024 * 1024 = 1,048,576` פסיקות דף.\nזהו ניצול גרוע מאוד של לוקליות מרחבית וגורם למספר עצום של פסיקות דף.\n\nלכן, קטע קוד א' יגרום למספר נמוך משמעותית של פסיקות דף בהשוואה לקטע קוד ב'."}, "difficulty_estimation": "Hard", "_source_file": "0455__Memory_Management__MultipleChoice__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:49:42", "_subject": "Virtualization"}, {"id": 6, "type": "MultipleChoice", "topic": ["Memory Management", "Paging", "Multi-level Page Tables"], "content": {"text": "במערכת הפעלה המשתמשת בזיכרון וירטואלי עם טבלת דפים דו-מפלסית, נתונים הפרטים הבאים:\n*   גודל כתובת וירטואלית: 32 ביטים.\n*   גודל דף: 4 קילובייט (KB).\n*   גודל כניסה בטבלת דפים (PTE): 4 בתים.\n\nכמה זיכרון פיזי *לכל היותר* נדרש עבור טבלאות הדפים בלבד, עבור תהליך המשתמש ב-1 מגהבייט (MB) רציף של זיכרון וירטואלי (החל מכתובת 0)?", "code_snippet": null, "options": ["א. 4 קילובייט (KB)", "ב. 8 קילובייט (KB)", "ג. 12 קילובייט (KB)", "ד. 1 מגהבייט (MB)", "ה. 2 מגהבייט (MB)"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "נחשב את גודל חלקים של הכתובת הוירטואלית ואת מספר הכניסות בכל טבלת דפים:\n*   גודל דף: 4KB = 2^12 בתים. לכן, ה-offset בכתובת הוירטואלית הוא 12 ביטים.\n*   גודל כתובת וירטואלית: 32 ביטים. לכן, מספר הדף הוירטואלי (VPN) הוא 32 - 12 = 20 ביטים.\n*   גודל כניסה בטבלת דפים (PTE): 4 בתים.\n*   מספר הכניסות בטבלת דפים בגודל דף אחד: 4KB / 4 בתים/כניסה = 1024 כניסות.\n*   מכיוון שטבלת הדפים היא דו-מפלסית, ה-VPN (20 ביטים) מתחלק ל-P1 (אינדקס לטבלת דפים מפלס ראשון) ול-P2 (אינדקס לטבלת דפים מפלס שני). כל אחד מהם יכול להיות בגודל log2(1024) = 10 ביטים. (P1=10 ביטים, P2=10 ביטים, סה\"כ 20 ביטים ל-VPN).\n\nהתהליך משתמש ב-1 מגהבייט (MB) זיכרון וירטואלי רציף, החל מכתובת 0:\n*   מספר הדפים הוירטואליים שנדרשים: 1MB / 4KB = 2^20 בתים / 2^12 בתים/דף = 2^8 = 256 דפים.\n*   דפים אלו הם דפים וירטואליים מספר 0 עד 255.\n\nכעת נחשב כמה זיכרון פיזי נדרש עבור טבלאות הדפים בלבד:\n1.  **טבלת דפים מפלס ראשון (P1)**:\n    *   היא מכסה טווח של 1024 * 1024 דפים וירטואליים. \n    *   הדפים 0-255 כולם נופלים תחת הכניסה הראשונה בטבלת הדפים מפלס ראשון (P1[0]).\n    *   לכן, נדרשת טבלת דפים אחת מפלס ראשון. טבלה זו תופסת דף פיזי אחד (4KB).\n2.  **טבלאות דפים מפלס שני (P2)**:\n    *   הכניסה P1[0] מצביעה על טבלת דפים מפלס שני. טבלה זו מכסה את הדפים הוירטואליים 0 עד 1023.\n    *   מכיוון שאנו משתמשים בדפים 0 עד 255, כולם כלולים בטבלה זו.\n    *   לכן, נדרשת טבלת דפים אחת מפלס שני. טבלה זו תופסת דף פיזי אחד (4KB).\n\nסה\"כ זיכרון פיזי הנדרש עבור טבלאות הדפים בלבד הוא: 1 דף (P1) + 1 דף (P2) = 2 דפים.\nסה\"כ זיכרון פיזי: 2 דפים * 4KB/דף = 8KB.\n\nהתשובה הנכונה היא ב'."}, "difficulty_estimation": "Hard", "_source_file": "0456__Memory_Management__MultipleChoice__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:50:09", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Memory Management", "Logical vs. Physical Address"], "content": {"text": "הסבירו מדוע ניהול זיכרון הכרחי במערכת הפעלה מרובת משימות (multiprogramming), ותארו בקצרה את ההבדל בין כתובת לוגית לכתובת פיזית.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "במערכת הפעלה מרובת משימות, מספר תהליכים רצים בו-זמנית ומשתמשים באותו זיכרון פיזי. ניהול זיכרון הכרחי מכמה סיבות עיקריות:\n1.  **הגנה (Protection):** מניעת תהליכים מלגשת או לשנות בטעות או בכוונה את מרחב הזיכרון של תהליכים אחרים או של מערכת ההפעלה עצמה. זה מבטיח יציבות ואבטחה.\n2.  **שיתוף (Sharing):** לאפשר לתהליכים שונים לשתף קטעי קוד או נתונים בזיכרון, מה שחוסך זיכרון ומאפשר תקשורת יעילה בין תהליכים.\n3.  **הקצאה יעילה (Efficient Allocation):** הקצאת זיכרון פיזי לתהליכים בצורה יעילה, תוך ניסיון למזער בזבוז זיכרון (פרגמנטציה) ולמקסם את ניצול הזיכרון.\n4.  **מיקום מחדש (Relocation):** לאפשר למערכת ההפעלה להעמיס תהליכים לכל מקום פנוי בזיכרון הפיזי, ואף להזיז אותם במהלך הריצה, מבלי שהתהליך יצטרך להיות מודע לכך.\n\nההבדל בין כתובת לוגית לכתובת פיזית:\n*   **כתובת לוגית (Logical Address):** זוהי כתובת שנוצרת על ידי ה-CPU (המעבד) עבור תהליך מסוים. היא מתייחסת למיקום בתוך מרחב הכתובות הווירטואלי של התהליך עצמו, והיא אינה בהכרח תואמת למיקום בפועל בזיכרון הפיזי. כל תהליך רואה את עצמו כבעל מרחב כתובות לוגי משלו, המתחיל בדרך כלל ב-0.\n*   **כתובת פיזית (Physical Address):** זוהי הכתובת האמיתית והממשית בזיכרון הראשי (RAM). זו הכתובת אליה ניגשת יחידת ניהול הזיכרון (MMU) והחומרה של הזיכרון. הכתובת הפיזית היא חד-משמעית ומצביעה על מיקום ספציפי בתאי הזיכרון הפיזיים.\nההמרה מכתובת לוגית לפיזית מתבצעת על ידי ה-MMU, בהתבסס על מנגנוני ניהול הזיכרון (כמו דפדוף או סגמנטציה) שמנוהלים על ידי מערכת ההפעלה."}, "difficulty_estimation": "Easy", "_source_file": "0457__Memory_Management__Open__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:50:21", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Memory Management", "Fragmentation"], "content": {"text": "הסבירו את המושגים 'פרגמנטציה פנימית' (Internal Fragmentation) ו'פרגמנטציה חיצונית' (External Fragmentation) בניהול זיכרון. תנו דוגמה קצרה לכל אחד מהמושגים.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פרגמנטציה פנימית (Internal Fragmentation):\nמתרחשת כאשר מקצים בלוק זיכרון גדול יותר מהגודל המבוקש בפועל, והזיכרון העודף בתוך הבלוק אינו בשימוש. הזיכרון המבוזבז נמצא בתוך הבלוק שהוקצה. לדוגמה: במערכת דפדוף (Paging) עם גודל דף של 4KB, אם תהליך זקוק רק ל-3KB עבור דף מסוים, ה-1KB הנותר בתוך אותו דף יהווה פרגמנטציה פנימית.\n\nפרגמנטציה חיצונית (External Fragmentation):\nמתרחשת כאשר יש מספיק זיכרון פנוי בסך הכל כדי לספק בקשה, אך הזיכרון הפנוי מפוזר בבלוקים קטנים ולא רציפים, כך שלא ניתן להקצות בלוק רציף אחד בגודל הנדרש. הזיכרון המבוזבז נמצא מחוץ לכל בלוק שהוקצה. לדוגמה: אם יש לנו 20KB זיכרון פנוי, המחולק לארבעה בלוקים של 5KB כל אחד, ותהליך מבקש 12KB זיכרון רציף, הבקשה תיכשל למרות שסך הזיכרון הפנוי (20KB) גדול מהנדרש (12KB)."}, "difficulty_estimation": "Easy", "_source_file": "0458__Memory_Management__Open__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:50:29", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Memory Management", "Stack", "Heap"], "content": {"text": "הסבירו את ההבדלים העיקריים בין זיכרון ה-Stack לזיכרון ה-Heap בהקשר של ניהול זיכרון במערכות הפעלה. התייחסו לאופן הקצאת הזיכרון, שחרורו, אורך חיי הנתונים ושימושים אופייניים לכל אחד. תנו דוגמת קוד פשוטה ב-C/C++ המדגימה שימוש בשני סוגי הזיכרון.", "code_snippet": "#include <iostream>\n#include <vector> // For dynamic array elements on heap implicitly\n\nvoid exampleFunction() {\n    // Stack allocation: 'x' is allocated on the stack\n    int x = 10;\n    std::cout << \"Stack variable x: \" << x << std::endl;\n\n    // Heap allocation: 'ptr_heap_int' points to memory on the heap\n    int* ptr_heap_int = new int; // Explicit heap allocation\n    *ptr_heap_int = 20;\n    std::cout << \"Heap variable pointed by ptr_heap_int: \" << *ptr_heap_int << std::endl;\n\n    // Another stack allocation: 'arr_stack' is a fixed-size array on the stack\n    int arr_stack[5] = {1, 2, 3, 4, 5};\n    std::cout << \"Stack array element: \" << arr_stack[0] << std::endl;\n\n    // Another heap allocation: 'vec_heap' object itself is on stack,\n    // but its elements are stored on the heap.\n    std::vector<int> vec_heap; \n    vec_heap.push_back(30);\n    std::cout << \"Heap vector element: \" << vec_heap[0] << std::endl;\n\n    // Deallocate explicitly allocated heap memory\n    delete ptr_heap_int;\n    // 'vec_heap' destructor will automatically deallocate its heap memory when it goes out of scope\n}\n\nint main() {\n    exampleFunction();\n    // After exampleFunction returns, all stack-allocated variables within it\n    // (like x, arr_stack, ptr_heap_int pointer, and vec_heap object) are deallocated.\n    // The memory pointed to by ptr_heap_int was explicitly deleted.\n    // The memory used by vec_heap for its elements was implicitly deleted by its destructor.\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "**זיכרון ה-Stack (מחסנית):**\n*   **אופן הקצאה ושחרור:** הקצאה ושחרור אוטומטיים (LIFO - Last-In, First-Out). הזיכרון מוקצה כאשר פונקציה נקראת ומשתנים מקומיים נוצרים, ומשוחרר אוטומטית כאשר הפונקציה מסיימת את ריצתה וחוזרת.\n*   **אורך חיים:** קצר, מוגבל לסקופ (scope) של הפונקציה או הבלוק בו הוגדרו המשתנים.\n*   **גודל:** בדרך כלל קבוע ומוגבל יחסית (נקבע בזמן קומפילציה או בתחילת ריצת התוכנית). ניסיונות להקצות יותר מדי זיכרון על ה-Stack יכולים לגרום ל-Stack Overflow.\n*   **מהירות:** מהיר מאוד, מכיוון שההקצאה פשוטה וכוללת הזזת מצביע (stack pointer).\n*   **שימושים אופייניים:** משתנים מקומיים, פרמטרים של פונקציות, כתובות חזרה מפונקציות (call frames).\n\n**זיכרון ה-Heap (ערימה):**\n*   **אופן הקצאה ושחרור:** הקצאה דינמית וידנית. הזיכרון מוקצה באופן מפורש על ידי המתכנת (באמצעות פונקציות כמו `malloc`/`calloc` ב-C או `new` ב-C++), ודורש שחרור ידני מפורש (באמצעות `free` ב-C או `delete` ב-C++). אי שחרור זיכרון עלול לגרום לדליפות זיכרון (memory leaks).\n*   **אורך חיים:** ארוך, יכול להישאר זמין גם לאחר שהפונקציה שהקצתה אותו סיימה את ריצתה, עד לשחרורו המפורש או סיום התוכנית.\n*   **גודל:** גמיש ולא מוגבל מראש כמו ה-Stack (מוגבל רק על ידי גודל הזיכרון הפיזי/וירטואלי הזמין במערכת).\n*   **מהירות:** איטי יחסית ל-Stack, מכיוון שהקצאה ושחרור דורשים חיפוש של בלוק זיכרון מתאים וניהול מורכב יותר.\n*   **שימושים אופייניים:** אובייקטים ונתונים שגודלם אינו ידוע בזמן קומפילציה, אובייקטים שצריכים לשרוד מעבר לסקופ של פונקציה מסוימת, מבני נתונים דינמיים (רשימות מקושרות, עצים, מערכים דינמיים).\n\n**דוגמת קוד:**\nבקוד המצורף:\n*   `int x` ו-`int arr_stack[5]` מוקצים על ה-Stack. הם קיימים רק כל עוד `exampleFunction` רצה.\n*   `int* ptr_heap_int = new int;` מקצה זיכרון עבור שלם בודד על ה-Heap. המצביע `ptr_heap_int` עצמו מוקצה על ה-Stack, אך הזיכרון אליו הוא מצביע נמצא על ה-Heap. זיכרון זה חייב להיות משוחרר ידנית באמצעות `delete ptr_heap_int;`.\n*   `std::vector<int> vec_heap;` יוצר אובייקט `vector` על ה-Stack. עם זאת, ה-`vector` מנהל באופן פנימי מערך דינמי על ה-Heap עבור האלמנטים שלו. כאשר `vec_heap` יוצא מטווח (scope), ה-destructor שלו משחרר אוטומטית את הזיכרון שהוקצה על ה-Heap עבור האלמנטים."}, "difficulty_estimation": "Easy", "_source_file": "0459__Memory_Management__Open__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:50:47", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Memory Management", "Fragmentation", "Paging", "Segmentation"], "content": {"text": "הסבירו את המושגים של פרגמנטציה פנימית (Internal Fragmentation) ופרגמנטציה חיצונית (External Fragmentation) בניהול זיכרון. עבור כל סוג, ספקו דוגמה קצרה לאופן התרחשותו והציעו טכניקת ניהול זיכרון אחת המסייעת בהפחתתו.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פרגמנטציה פנימית (Internal Fragmentation):\n*   הסבר: מתרחשת כאשר זיכרון מוקצה גדול יותר מהזיכרון הנדרש בפועל, וכתוצאה מכך נותר שטח לא מנוצל בתוך הבלוק שהוקצה.\n*   דוגמה: במערכת המשתמשת בדפדוף (Paging), אם גודל דף הוא 4KB ותהליך זקוק ל-3.5KB, הוא יקבל דף שלם של 4KB. ה-0.5KB הנותרים בתוך הדף אינם מנוצלים על ידי התהליך ומהווים פרגמנטציה פנימית.\n*   הפחתה: ניתן להפחית פרגמנטציה פנימית על ידי שימוש בגדלי דפים (או בלוקים) קטנים יותר, אם כי זה מגדיל את גודל טבלאות הדפים ועשוי להוביל לתקורה (overhead) גבוהה יותר.\n\nפרגמנטציה חיצונית (External Fragmentation):\n*   הסבר: מתרחשת כאשר יש מספיק זיכרון פנוי בסך הכל כדי לספק בקשה, אך הוא מפוזר בבלוקים לא רציפים (חורים), כך שאין בלוק רציף אחד גדול מספיק כדי לעמוד בבקשה.\n*   דוגמה: במערכת המשתמשת בפילוח (Segmentation) או הקצאת זיכרון דינמית (Dynamic Partitioning), לאחר שתהליכים נטענים ונפרקים, נוצרים חורי זיכרון פנויים בגדלים שונים. אם תהליך חדש דורש בלוק זיכרון רציף גדול, ייתכן שלא יוכל להיטען למרות שסך הזיכרון הפנוי מספיק.\n*   הפחתה: טכניקת הדפדוף (Paging) מסייעת רבות בהפחתת פרגמנטציה חיצונית, מכיוון שהיא מאפשרת לטעון את דפי התהליך למסגרות זיכרון פיזיות שאינן רציפות. טכניקה נוספת היא איחוי זיכרון (Compaction), המזיזה בלוקים מוקצים כדי לאסוף את כל הזיכרון הפנוי לבלוק רציף אחד, אך זוהי פעולה יקרה מבחינת ביצועים."}, "difficulty_estimation": "Easy", "_source_file": "0460__Memory_Management__Open__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:50:59", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Memory Management", "Fragmentation"], "content": {"text": "הסבירו מהי פרגמנטציה פנימית (Internal Fragmentation) ופרגמנטציה חיצונית (External Fragmentation) בהקשר של ניהול זיכרון. ציינו גורם אפשרי לכל אחת מהן והציעו דרך אחת לצמצם את הפרגמנטציה החיצונית.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פרגמנטציה פנימית מתרחשת כאשר הזיכרון מוקצה בגושים בגודל קבוע (לדוגמה, דפים), והתהליך או הנתונים אינם ממלאים את הגוש כולו. החלק הנותר בתוך הגוש המוקצה אינו בשימוש אך אינו זמין להקצאות אחרות. גורם אפשרי: הקצאת זיכרון ביחידות בגודל קבוע (למשל, דפים במערכת דפדוף) כאשר בקשות הזיכרון קטנות יותר מגודל היחידה.\n\nפרגמנטציה חיצונית מתרחשת כאשר יש מספיק זיכרון פנוי בסך הכל כדי למלא בקשה, אך הוא מפוזר בבלוקים קטנים ולא רציפים ברחבי הזיכרון, כך שלא ניתן להקצות בלוק רציף אחד בגודל הנדרש. גורם אפשרי: תהליכים נטענים ונפרקים מהזיכרון באופן דינמי, ויוצרים חורים קטנים בין בלוקים תפוסים.\n\nדרך אחת לצמצם פרגמנטציה חיצונית היא באמצעות איחוי (Compaction), שמעביר את כל הבלוקים התפוסים יחד, ובכך מאחד את כל הזיכרון הפנוי לבלוק רציף אחד גדול. דרך נוספת היא שימוש בסגמנטציה או דפדוף, המאפשרים לתהליכים להשתמש בזיכרון לא רציף."}, "difficulty_estimation": "Easy", "_source_file": "0461__Memory_Management__Open__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:51:09", "_subject": "Virtualization"}, {"id": 101, "type": "Open", "topic": ["Memory Management", "Paging", "Virtual Memory"], "content": {"text": "נתונה מערכת הפעלה המשתמשת במנגנון ניהול זיכרון מבוסס דפדוף (paging).\nגודל הדף במערכת הוא 4KB.\nתהליך מסוים ניגש לכתובת וירטואלית `0x1A3B5`.\nבהתאם לטבלת הדפים של התהליך, הדף הוירטואלי הרלוונטי ממופה למסגרת פיזית מספר `0x00F`.\nחשבו את הכתובת הפיזית המתאימה לכתובת הוירטואלית הנתונה ופרטו את שלבי החישוב.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  **חישוב גודל היסט הדף (Page Offset):**\n    גודל הדף הוא 4KB, שזה 4 * 1024 בתים = 4096 בתים.\n    כדי לייצג 4096 ערכים שונים (כתובות בתוך הדף), נדרשים 12 ביטים (2^12 = 4096).\n    לכן, ההיסט (offset) בכתובת הוירטואלית יתפוס את 12 הביטים הפחות משמעותיים (הימניים ביותר).\n\n2.  **פירוק הכתובת הוירטואלית:**\n    הכתובת הוירטואלית הנתונה היא `0x1A3B5`.\n    נמיר אותה לבסיס בינארי: `0x1A3B5` = `0001 1010 0011 1011 0101`.\n    נחלק אותה למספר דף וירטואלי ולהיסט:\n    -   **היסט (Offset):** 12 הביטים הימניים ביותר הם `0011 1011 0101`, שזה בבסיס הקסדצימלי `0x3B5`.\n    -   **מספר דף וירטואלי (Virtual Page Number):** הביטים הנותרים משמאל הם `0001 1010`, שזה בבסיס הקסדצימלי `0x1A`.\n\n3.  **הרכבת הכתובת הפיזית:**\n    נתון שמספר המסגרת הפיזית (Physical Frame Number - PFN) אליו ממופה הדף הוירטואלי `0x1A` הוא `0x00F`.\n    הכתובת הפיזית מורכבת מצירוף מספר המסגרת הפיזית (PFN) וההיסט. ה-PFN מהווה את הביטים המשמעותיים יותר (השמאליים) של הכתובת הפיזית, ואחריו מגיעים ביטי ההיסט.\n    -   PFN (`0x00F`) בבינארי: `0000 1111`\n    -   היסט (`0x3B5`) בבינארי: `0011 1011 0101`\n    נצרף את ה-PFN ל-12 הביטים של ההיסט (כאשר ה-PFN מהווה את הביטים הגבוהים): `0000 1111` (PFN) `0011 1011 0101` (Offset).\n    התוצאה בבינארי היא `0000 1111 0011 1011 0101`.\n    בבסיס הקסדצימלי, זו הכתובת `0x0F3B5`.\n\n    **הכתובת הפיזית הסופית היא `0x0F3B5`.**"}, "difficulty_estimation": "Easy", "_source_file": "0462__Memory_Management__Open__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:51:24", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Memory Management", "Fragmentation"], "content": {"text": "הסבר מהי פרגמנטציה פנימית ומהי פרגמנטציה חיצונית בניהול זיכרון. תאר בקצרה מצב שבו כל אחד מסוגי הפרגמנטציה מתרחש.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פרגמנטציה פנימית (Internal Fragmentation) מתרחשת כאשר זיכרון מוקצה ליחידות בגודל קבוע (לדוגמה, דפים או בלוקים בגודל קבוע), והתהליך זקוק לפחות זיכרון ממה שהוקצה לו. השטח הלא מנוצל בתוך הבלוק המוקצה הוא פרגמנטציה פנימית. לדוגמה: אם גודל דף הוא 4KB ותהליך זקוק ל-3KB, אז 1KB מבוזבז בתוך הדף.\n\nפרגמנטציה חיצונית (External Fragmentation) מתרחשת כאשר יש מספיק זיכרון פנוי בסך הכל כדי לספק בקשה, אך הזיכרון הפנוי מפוזר בבלוקים קטנים ולא רציפים, כך שאף בלוק בודד אינו גדול מספיק כדי לעמוד בבקשה. לדוגמה: במערכת עם הקצאת זיכרון דינמית בגודל משתנה, כאשר תהליכים נטענים ופורקים מהזיכרון, נוצרים 'חורים' קטנים של זיכרון פנוי. תהליך חדש הדורש בלוק זיכרון גדול ורציף לא יוכל להיטען, גם אם סך הזיכרון הפנוי מספיק."}, "difficulty_estimation": "Easy", "_source_file": "0463__Memory_Management__Open__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:51:34", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Memory Management", "Fragmentation"], "content": {"text": "הגדירו מהי 'פרגמנטציה פנימית' (Internal Fragmentation) ומהי 'פרגמנטציה חיצונית' (External Fragmentation) בהקשר של ניהול זיכרון. הסבירו מדוע כל אחד מסוגי הפרגמנטציה הללו מתרחש, ותנו דוגמה לשיטת ניהול זיכרון שעלולה להוביל אליו.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פרגמנטציה פנימית (Internal Fragmentation):\nהגדרה: זיכרון שהוקצה לתהליך אך אינו בשימוש בפועל על ידו, ונשאר ריק בתוך יחידת ההקצאה. זיכרון זה אינו נגיש לתהליכים אחרים.\nהסבר מדוע מתרחשת: מתרחשת כאשר זיכרון מוקצה בגושים בגודל קבוע (לדוגמה, דפים במערכת דפדוף). אם תהליך זקוק לפחות זיכרון מגודל הגוש המוקצה, השארית בתוך הגוש מבוזבזת ואינה ניתנת לשימוש על ידי תהליכים אחרים.\nדוגמה לשיטת ניהול זיכרון: מערכת דפדוף (Paging). לדוגמה, אם גודל דף הוא 4KB ותהליך זקוק רק ל-1KB, אז 3KB בתוך הדף מבוזבזים כפרגמנטציה פנימית.\n\nפרגמנטציה חיצונית (External Fragmentation):\nהגדרה: מצב שבו קיים מספיק זיכרון פנוי במערכת כדי לעמוד בדרישת הקצאה, אך הוא מפוזר בחלקים קטנים ולא רצופים, כך שלא ניתן להקצותו לתהליך הדורש גוש זיכרון רצוף בגודל מסוים.\nהסבר מדוע מתרחשת: מתרחשת כאשר תהליכים נטענים ופורקים זיכרון באופן דינמי, ויוצרים \"חורים\" קטנים של זיכרון פנוי בין אזורים תפוסים. עם הזמן, הזיכרון הפיזי עלול להפוך למקוטע מאוד.\nדוגמה לשיטת ניהול זיכרון: מערכת סגמנטציה (Segmentation) או מערכות המשתמשות בהקצאת זיכרון בגושים בגודל משתנה (Variable-sized partitions) ללא מנגנון איחוי (compaction) יעיל. לדוגמה, אם יש 10MB פנויים בסך הכל, אך הם מפוזרים כעשרה גושים של 1MB, לא ניתן להקצות גוש רצוף של 5MB."}, "difficulty_estimation": "Easy", "_source_file": "0464__Memory_Management__Open__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:51:46", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Memory Management", "Virtual Memory", "Paging"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי וב-Paging. המערכת כוללת זיכרון וירטואלי בגודל 2GB, זיכרון פיזי בגודל 512MB, וגודל דף הוא 4KB. כל רשומת טבלת דפים (PTE) כוללת 4 ביטי סטטוס בנוסף לכתובת המסגרת הפיזית (PFN). יש לפרט ולנמק את כל החישובים.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "10.1", "text": "מהו גודל ה-VPN ומהו גודל ה-PFN בביטים?", "code_snippet": null, "options": null}, {"id": "10.2", "text": "מהו הגודל המינימלי של רשומת טבלת דפים (PTE) בבתים, בהנחה שהיא מעוגלת לחזקה הקרובה של 2 בבתים?", "code_snippet": null, "options": null}, {"id": "10.3", "text": "כמה רשומות PTE יכולות להיכנס לדף טבלה בודד?", "code_snippet": null, "options": null}, {"id": "10.4", "text": "כמה רמות נדרשות לטבלת הדפים ההיררכית במערכת זו, וכמה ביטים מכתובת ה-VPN משמשים לכל רמה?", "code_snippet": null, "options": null}, {"id": "10.5", "text": "מהו סך הזיכרון הפיזי שיידרש לטבלת הדפים של תהליך, אם כל המרחב הוירטואלי שלו מאוכלס (fully populated)?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  גודל הזיכרון הווירטואלי הוא 2GB = 2^31 בתים, לכן כתובת וירטואלית היא באורך 31 ביטים. גודל הדף הוא 4KB = 2^12 בתים, לכן ההיסט בתוך הדף הוא 12 ביטים. מכאן, גודל ה-VPN הוא 31 - 12 = 19 ביטים.\n    גודל הזיכרון הפיזי הוא 512MB = 2^29 בתים, לכן כתובת פיזית היא באורך 29 ביטים. ההיסט בתוך המסגרת זהה לזה שבתוך הדף – 12 ביטים. מכאן, גודל ה-PFN הוא 29 - 12 = 17 ביטים.\n2.  רשומת PTE צריכה להכיל את ה-PFN (17 ביטים) ואת ביטי הסטטוס (4 ביטים), סה\"כ 17 + 4 = 21 ביטים. בהנחה שהגודל מעוגל לחזקה הקרובה של 2 בבתים, 21 ביטים דורשים 4 בתים (שכן 2 בתים הם 16 ביטים ואינם מספיקים, ואילו 4 בתים הם 32 ביטים ומספיקים).\n3.  גודל דף הוא 4KB = 4096 בתים. גודל רשומת PTE הוא 4 בתים. לכן, מספר רשומות PTE שיכולות להיכנס לדף טבלה בודד הוא 4096 / 4 = 1024 רשומות.\n4.  גודל ה-VPN הוא 19 ביטים. בכל דף טבלה נכנסות 1024 רשומות, כלומר כל אינדקס ברמת טבלה יכול להיות באורך log2(1024) = 10 ביטים. כדי למפות 19 ביטים נדרשות 2 רמות (19 / 10 = 1.9, מעוגל למעלה). הרמה העליונה (Level 1) תשתמש ב-10 ביטים, והרמה התחתונה (Level 2) תשתמש ב-9 ביטים (19 - 10 = 9).\n5.  עבור טבלת דפים מאוכלסת במלואה:\n    *   רמת טבלת הדפים הראשונה (Page Directory) דורשת דף אחד.\n    *   רמת טבלת הדפים הראשונה מכילה 1024 רשומות. מכיוון שרק 9 ביטים משמשים לאינדקס ברמה השנייה, רק 2^9 = 512 רשומות ברמה הראשונה יצביעו לטבלאות דפים ברמה השנייה. לכן, יהיו 512 טבלאות דפים ברמה השנייה.\n    *   סה\"כ דפים שנדרשים עבור טבלת הדפים: 1 (לרמה 1) + 512 (לרמה 2) = 513 דפים.\n    *   הזיכרון הפיזי הכולל שיידרש הוא 513 דפים * 4KB/דף = 2052KB."}, "difficulty_estimation": "Medium", "_source_file": "0465__Memory_Management__Open__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:52:14", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Memory Management", "Virtual Memory", "Paging", "TLB"], "content": {"text": "נתונה מערכת עם זיכרון וירטואלי של 16MB, זיכרון פיזי של 32MB וגודל דף של 4KB. רשומת טבלת דפים (PTE) מכילה 4 ביטים לסטטוס בנוסף לכתובת המסגרת הפיזית (PFN). זמן גישה לזיכרון הראשי הוא 100ns וזמן גישה ל-TLB הוא 20ns. נתון ששיעור הפגיעה (Hit Rate) ב-TLB הוא 95%.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "10.1", "text": "מהם הגדלים של ה-VPN, ה-PFN ו-Offset בביטים?", "code_snippet": null, "options": null}, {"id": "10.2", "text": "מהו הגודל המינימלי של רשומת טבלת דפים (PTE) בבתים?", "code_snippet": null, "options": null}, {"id": "10.3", "text": "מהו הגודל של טבלת דפים לינארית של תהליך אחד בבתים?", "code_snippet": null, "options": null}, {"id": "10.4", "text": "מהו זמן הגישה האפקטיבי לזיכרון (Effective Access Time - EAT) במערכת זו?", "code_snippet": null, "options": null}], "points": 30, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. חישוב גודל ביטים: \n   זיכרון וירטואלי: 16MB = 2^24 בתים, לכן כתובת וירטואלית היא באורך 24 ביטים.\n   זיכרון פיזי: 32MB = 2^25 בתים, לכן כתובת פיזית היא באורך 25 ביטים.\n   גודל דף: 4KB = 2^12 בתים, לכן ההיסט (Offset) הוא באורך 12 ביטים.\n   VPN (Virtual Page Number): 24 ביטים (VA) - 12 ביטים (Offset) = 12 ביטים.\n   PFN (Physical Frame Number): 25 ביטים (PA) - 12 ביטים (Offset) = 13 ביטים.\n   \n   לכן: VPN = 12 ביטים, PFN = 13 ביטים, Offset = 12 ביטים.\n\n2. גודל רשומת טבלת דפים (PTE):\n   PFN = 13 ביטים.\n   ביטי סטטוס = 4 ביטים.\n   סה\"כ ביטים לרשומת PTE = 13 + 4 = 17 ביטים.\n   כדי לאחסן 17 ביטים, נדרשים מינימום 3 בתים (17 ביטים / 8 ביטים/בית = 2.125, מעוגל למעלה ל-3 בתים).\n   \n   לכן: גודל PTE מינימלי הוא 3 בתים.\n\n3. גודל טבלת דפים לינארית:\n   מספר הדפים הווירטואליים: 2^VPN = 2^12 = 4096 דפים.\n   גודל טבלת הדפים = מספר דפים * גודל PTE.\n   גודל טבלת הדפים = 4096 * 3 בתים = 12288 בתים = 12KB.\n   \n   לכן: גודל טבלת דפים לינארית הוא 12KB.\n\n4. זמן גישה אפקטיבי לזיכרון (EAT):\n   EAT = (שיעור פגיעה ב-TLB * (זמן גישה ל-TLB + זמן גישה לזיכרון)) + (שיעור החטאה ב-TLB * (זמן גישה ל-TLB + 2 * זמן גישה לזיכרון))\n   שיעור פגיעה = 0.95\n   שיעור החטאה = 1 - 0.95 = 0.05\n   זמן גישה ל-TLB = 20ns\n   זמן גישה לזיכרון = 100ns\n   \n   EAT = (0.95 * (20ns + 100ns)) + (0.05 * (20ns + 100ns + 100ns))\n   EAT = (0.95 * 120ns) + (0.05 * 220ns)\n   EAT = 114ns + 11ns\n   EAT = 125ns\n   \n   לכן: זמן הגישה האפקטיבי לזיכרון הוא 125ns."}, "difficulty_estimation": "Medium", "_source_file": "0466__Memory_Management__Open__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:52:33", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Memory Management", "Virtual Memory", "Paging"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם כתובות וירטואליות בגודל 2GB, וזיכרון פיזי בגודל 16GB. גודל דף הוא 8KB. טבלת הדפים היא דו-רמתית (Two-level page table), וגודל כל רשומת טבלת דפים (PTE) הוא 4 בתים. יש לפרט ולנמק את כל החישובים.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "10.1", "text": "כמה ביטים מוקצים לכל אחד מהשדות הבאים בכתובת הווירטואלית: VPN (Virtual Page Number) והיסט (Offset)? כמה ביטים מוקצים ל-PFN (Physical Frame Number) בכתובת הפיזית?", "code_snippet": null, "options": null}, {"id": "10.2", "text": "כמה רשומות (PTEs) יכולות להיכנס לדף בודד של טבלת הדפים? בהתאם לכך, כמה ביטים משמשים לכל רמה בטבלת הדפים הדו-רמתית (VPN1 ו-VPN2)?", "code_snippet": null, "options": null}, {"id": "10.3", "text": "תהליך חדש מבצע הקצאת זיכרון דינמית (malloc) של 10MB. כמה מסגרות פיזיות יתפסו על ידי הנתונים עצמם, וכמה מסגרות יתפסו על ידי טבלאות הדפים הנדרשות כדי למפות זיכרון זה, במקרה המקסימלי (כלומר, כל הדפים וטבלאות הדפים מוצבים בזיכרון פיזי)?", "code_snippet": null, "options": null}], "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  **חישוב ביטים:**\n    *   זיכרון וירטואלי: 2GB = 2^31 בתים, לכן כתובת וירטואלית היא 31 ביטים.\n    *   זיכרון פיזי: 16GB = 2^34 בתים, לכן כתובת פיזית היא 34 ביטים.\n    *   גודל דף: 8KB = 2^13 בתים, לכן ההיסט (Offset) הוא 13 ביטים.\n    *   **VPN**: 31 ביטים (VA) - 13 ביטים (Offset) = 18 ביטים.\n    *   **PFN**: 34 ביטים (PA) - 13 ביטים (Offset) = 21 ביטים.\n\n2.  **רשומות בדף ורמות בטבלה:**\n    *   גודל דף: 8KB = 8192 בתים.\n    *   גודל רשומת PTE: 4 בתים.\n    *   מספר רשומות בדף טבלה: 8192 / 4 = 2048 רשומות.\n    *   2048 = 2^11, לכן כל רמה בטבלת הדפים יכולה למפות 11 ביטים מכתובת ה-VPN.\n    *   יש לנו 18 ביטים ל-VPN וטבלה דו-רמתית:\n        *   רמה שנייה (VPN2 - offset בתוך טבלת דפים של רמה 1): 11 ביטים.\n        *   רמה ראשונה (VPN1 - אינדקס בטבלת הדפים הראשית): 18 - 11 = 7 ביטים.\n\n3.  **הקצאת 10MB זיכרון:**\n    *   **מספר דפים לנתונים:** 10MB = 10 * 1024 KB = 10240 KB.\n    *   גודל דף: 8KB.\n    *   מספר דפים נדרשים לנתונים: 10240KB / 8KB = 1280 דפים.\n    *   לכן, הנתונים עצמם יתפסו **1280 מסגרות פיזיות**.\n\n    *   **מספר דפים לטבלאות הדפים (במקרה המקסימלי):**\n        *   כל דף טבלת דפים ברמה 2 מכיל 2048 רשומות (PTEs).\n        *   כדי למפות 1280 דפים, במקרה המקסימלי, ההקצאה יכולה להתפרס על פני 2 דפי טבלאות ברמה 2 (לדוגמה, אם ההקצאה מתחילה ב-VPN שהינו הרשומה האחרונה בדף טבלה ברמה 2 מסוים, והשאר גולשים לדף הטבלה הבא ברמה 2).\n        *   לכן, נצטרך **2 מסגרות פיזיות** עבור טבלאות הדפים ברמה 2.\n        *   (בהתאם לדוגמאות, הרמה הראשונה של טבלת הדפים, ה-Page Directory, נחשבת כקיימת מראש ואינה נכללת בחישוב ההקצאה החדשה).\n\n    *   **סה\"כ מסגרות פיזיות:** 1280 (לנתונים) + 2 (לטבלאות דפים ברמה 2) = **1282 מסגרות פיזיות**."}, "difficulty_estimation": "Medium", "_source_file": "0467__Memory_Management__Open__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:53:06", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Memory Management", "Virtual Memory", "Paging", "Page Table"], "content": {"text": "נתונה מערכת עם זיכרון וירטואלי של 2GB וזיכרון פיזי של 128GB. גודל דף הוא 8KB.\nבכל רשומת טבלת דפים (PTE) נשמרים 3 ביטים של סטטוס בנוסף למספר מסגרת פיזית (PFN).\nיש לפרט ולנמק את כל החישובים.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "10.1", "text": "מהם הגדלים של ה-VPN וה-PFN (בביטים)?", "code_snippet": null, "options": null}, {"id": "10.2", "text": "מהו גודל רשומת טבלת דפים (PTE) בבתים?", "code_snippet": null, "options": null}, {"id": "10.3", "text": "בהנחה שמערכת ההפעלה משתמשת בטבלת דפים היררכית, וכאשר כל חלק בטבלת הדפים תופס דף אחד בזיכרון הפיזי, כמה רמות דרושות לטבלת הדפים של תהליך, וכמה ביטים בכתובת הווירטואלית מוקצים לכל רמה?", "code_snippet": null, "options": null}, {"id": "10.4", "text": "כמה זיכרון פיזי (בבתים) תתפוס טבלת דפים היררכית של תהליך, במקרה הגרוע ביותר (worst case), אם כל הזיכרון הוירטואלי שלו ממופה?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. **גודל VPN ו-PFN (בביטים):**\n   *   גודל זיכרון וירטואלי: 2GB = 2^31 בתים. לכן, כתובת וירטואלית היא באורך 31 ביטים.\n   *   גודל זיכרון פיזי: 128GB = 2^37 בתים. לכן, כתובת פיזית היא באורך 37 ביטים.\n   *   גודל דף: 8KB = 2^13 בתים. לכן, ההיסט (Offset) בכתובת הוא באורך 13 ביטים.\n   *   VPN (Virtual Page Number) = אורך כתובת וירטואלית - אורך היסט = 31 - 13 = 18 ביטים.\n   *   PFN (Physical Frame Number) = אורך כתובת פיזית - אורך היסט = 37 - 13 = 24 ביטים.\n\n2. **גודל רשומת טבלת דפים (PTE) בבתים:**\n   *   רשומת PTE מכילה PFN (24 ביטים) ו-3 ביטים של סטטוס.\n   *   סה\"כ ביטים ב-PTE = 24 + 3 = 27 ביטים.\n   *   בדרך כלל, רשומות PTE מעוגלות לגודל של מילה (לרוב 4 בתים = 32 ביטים) לצורך יישור וגישה יעילה.\n   *   לכן, גודל רשומת PTE הוא 4 בתים.\n\n3. **מספר רמות וחלוקת ביטים לטבלת דפים היררכית:**\n   *   גודל דף: 8KB. גודל PTE: 4 בתים.\n   *   מספר רשומות שיכולות להיכנס לדף אחד של טבלת דפים = גודל דף / גודל PTE = 8KB / 4 בתים = 8192 / 4 = 2048 רשומות.\n   *   מספר ביטים לכל אינדקס ברמת טבלת דפים = log2(2048) = 11 ביטים.\n   *   סה\"כ ביטי VPN = 18 ביטים.\n   *   מספר רמות דרושות = ceil(VPN ביטים / ביטים לרמה) = ceil(18 / 11) = 2 רמות.\n   *   חלוקת הביטים (מהרמה העליונה ביותר): \n        *   רמה 1 (מדריך דפים - Page Directory Index): 11 ביטים.\n        *   רמה 2 (טבלת דפים - Page Table Index): 18 - 11 = 7 ביטים.\n        *   (Offset): 13 ביטים.\n        *   סה\"כ ביטי כתובת וירטואלית = 11 (P1) + 7 (P2) + 13 (Offset) = 31 ביטים.\n\n4. **זיכרון פיזי שתתפוס טבלת דפים היררכית (במקרה הגרוע ביותר):**\n   *   במקרה הגרוע ביותר, כל הזיכרון הוירטואלי של התהליך ממופה, כלומר כל 2^18 הדפים הוירטואליים נמצאים בשימוש.\n   *   רמת ה-P1 (מדריך הדפים הראשי) תתפוס דף אחד בזיכרון הפיזי (8KB).\n   *   רמת ה-P1 מכילה 2^11 רשומות (מכיוון שהאינדקס לרמה זו הוא 11 ביטים). במקרה הגרוע, כל הרשומות הללו מצביעות על טבלאות דפים ברמה P2.\n   *   לכן, יהיו 2^11 טבלאות דפים ברמה P2.\n   *   כל טבלת דפים ברמה P2 תופסת דף אחד (8KB) בזיכרון הפיזי.\n   *   סה\"כ זיכרון פיזי עבור טבלאות הדפים:\n        *   1 דף (עבור מדריך P1) + 2^11 דפים (עבור טבלאות P2) \n        *   = 1 + 2048 = 2049 דפים.\n        *   סה\"כ זיכרון פיזי = 2049 דפים * 8KB לדף = 16392KB.\n        *   בבתים: 16392 * 1024 = 16,785,408 בתים."}, "difficulty_estimation": "Medium", "_source_file": "0468__Memory_Management__Open__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:53:31", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Memory Management", "Virtual Memory", "Paging"], "content": {"text": "נתונה מערכת עם זיכרון וירטואלי של 2GB, גודל דף של 8KB, וזיכרון פיזי של 16GB.\nמהם הגדלים של ה-VPN, ה-PFN, וכמה זיכרון פיזי תתפוס טבלת דפים (לינארית) של תהליך, במינימום?\nגודל VPN: ________ גודל PFN: ________ גודל טבלה: ________", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.   **חישוב גודל VPN (Virtual Page Number):**\n    *   זיכרון וירטואלי הוא 2GB. בביטים, זה 2 * 2^30 = 2^31 בתים. לכן, אורך הכתובת הוירטואלית הוא 31 ביטים.\n    *   גודל דף הוא 8KB. בביטים, זה 8 * 2^10 = 2^3 * 2^10 = 2^13 בתים. לכן, אורך ההיסט (Offset) בתוך הדף הוא 13 ביטים.\n    *   גודל ה-VPN הוא אורך הכתובת הוירטואלית פחות אורך ההיסט: 31 ביטים - 13 ביטים = 18 ביטים.\n\n2.   **חישוב גודל PFN (Physical Frame Number):**\n    *   זיכרון פיזי הוא 16GB. בביטים, זה 16 * 2^30 = 2^4 * 2^30 = 2^34 בתים. לכן, אורך הכתובת הפיזית הוא 34 ביטים.\n    *   אורך ההיסט (Offset) זהה לזה שבכתובת הוירטואלית: 13 ביטים.\n    *   גודל ה-PFN הוא אורך הכתובת הפיזית פחות אורך ההיסט: 34 ביטים - 13 ביטים = 21 ביטים.\n\n3.   **חישוב גודל טבלת דפים לינארית (במינימום):**\n    *   מספר הדפים הוירטואליים הכולל בתהליך הוא גודל הזיכרון הוירטואלי חלקי גודל הדף: 2GB / 8KB = (2^31 בתים) / (2^13 בתים) = 2^(31-13) = 2^18 דפים.\n    *   טבלת דפים לינארית מכילה רשומה אחת (PTE) עבור כל דף וירטואלי, ולכן יש בה 2^18 רשומות.\n    *   כל רשומת PTE צריכה להכיל לפחות את ה-PFN. גודל ה-PFN הוא 21 ביטים. כדי לאחסן 21 ביטים, נדרשים 3 בתים (שכן 2 בתים מכילים 16 ביטים ו-3 בתים מכילים 24 ביטים, וזה המספר המינימלי של בתים הנדרש).\n    *   גודל טבלת הדפים הכולל הוא מספר הרשומות כפול גודל רשומה: 2^18 רשומות * 3 בתים/רשומה = 262,144 * 3 בתים = 786,432 בתים.\n    *   להמרה ל-KB: 786,432 בתים / 1024 בתים/KB = 768KB."}, "difficulty_estimation": "Medium", "_source_file": "0469__Memory_Management__Open__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:53:48", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Memory Management", "Virtual Memory", "Paging"], "content": {"text": "נתונה מערכת עם זיכרון וירטואלי של 2GB, גודל דף של 8KB, וזיכרון פיזי של 16GB.\nבהנחה שכל רשומת טבלת דפים (PTE) תופסת 4 בתים, מהם הגדלים של ה-VPN, ה-PFN, וכמה זיכרון פיזי תתפוס טבלת דפים (לינארית) של תהליך, במינימום?\nגודל VPN: ________ גודל PFN: ________ גודל טבלה: ________", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כתובת וירטואלית היא 31 ביטים (זיכרון וירטואלי 2GB = 2^31 בתים).\nגודל ההיסט הוא 13 ביטים (גודל דף 8KB = 2^13 בתים).\nלכן, גודל ה-VPN הוא 31 - 13 = 18 ביטים.\n\nכתובת פיזית היא 34 ביטים (זיכרון פיזי 16GB = 2^34 בתים).\nגודל ההיסט זהה – 13 ביטים.\nלכן, גודל ה-PFN הוא 34 - 13 = 21 ביטים.\n\nלכל תהליך יש 2^18 דפים וירטואליים (2GB / 8KB = 2^31 / 2^13).\nטבלת הדפים הלינארית מכילה 2^18 רשומות.\nכל רשומה תופסת 4 בתים (נתון).\nלכן, גודל הטבלה כולה הוא 2^18 * 4 בתים = 262,144 * 4 בתים = 1,048,576 בתים = 1MB."}, "difficulty_estimation": "Medium", "_source_file": "0470__Memory_Management__Open__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:53:59", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Memory Management", "Virtual Memory", "Paging"], "content": {"text": "נתונה מערכת עם זיכרון וירטואלי בגודל 2GB וזיכרון פיזי בגודל 256MB. גודל דף במערכת הוא 8KB. רשומת טבלת דפים (PTE) כוללת 3 ביטים של סטטוס (לדוגמה, Valid, Dirty, Accessed) בנוסף לביטי ה-PFN. יש לפרט ולנמק את כל החישובים.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "10.1", "text": "מהם הגדלים של ה-VPN (Virtual Page Number) וה-PFN (Physical Frame Number) בביטים?", "code_snippet": null, "options": null}, {"id": "10.2", "text": "מה גודל רשומת טבלת דפים (PTE) בבתים, בהנחה שהיא מעוגלת לגודל מילה סטנדרטי (4 בתים)?", "code_snippet": null, "options": null}, {"id": "10.3", "text": "מה גודל טבלת דפים לינארית (single-level) של תהליך, במידה והיא ממפה את כל הזיכרון הווירטואלי שלו?", "code_snippet": null, "options": null}, {"id": "10.4", "text": "אם המערכת משתמשת בטבלת דפים היררכית בעלת שתי רמות, כמה ביטים משמשים לכל רמה של הכתובת הוירטואלית?", "code_snippet": null, "options": null}, {"id": "10.5", "text": "כמה מסגרות פיזיות יתפסו על ידי טבלת הדפים (היררכית, שתי רמות) של תהליך המשתמש בכל הזיכרון הוירטואלי שהוקצה לו?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  **חישוב גדלי VPN ו-PFN:**\n    *   גודל זיכרון וירטואלי = 2GB = 2^31 בתים. לכן, כתובת וירטואלית היא באורך 31 ביטים.\n    *   גודל זיכרון פיזי = 256MB = 2^28 בתים. לכן, כתובת פיזית היא באורך 28 ביטים.\n    *   גודל דף = 8KB = 2^13 בתים. לכן, ההיסט בתוך הדף (offset) הוא באורך 13 ביטים.\n    *   **VPN** (Virtual Page Number) = אורך כתובת וירטואלית - אורך היסט = 31 - 13 = **18 ביטים**.\n    *   **PFN** (Physical Frame Number) = אורך כתובת פיזית - אורך היסט = 28 - 13 = **15 ביטים**.\n\n2.  **גודל רשומת טבלת דפים (PTE):**\n    *   PTE מכילה PFN ועוד 3 ביטי סטטוס.\n    *   סה\"כ ביטים ל-PTE = 15 (PFN) + 3 (סטטוס) = 18 ביטים.\n    *   בהנחה שה-PTE מעוגלת לגודל מילה סטנדרטי של 4 בתים (32 ביטים) לצורך יישור ויעילות, למרות ש-18 ביטים טכנית יכולים להיכנס ב-3 בתים.\n    *   **גודל PTE = 4 בתים**.\n\n3.  **גודל טבלת דפים לינארית:**\n    *   מספר הדפים הוירטואליים הכולל שצריך למפות: 2GB / 8KB = 2^31 / 2^13 = 2^18 דפים.\n    *   גודל טבלת הדפים הלינארית = מספר דפים * גודל PTE = 2^18 * 4 בתים = 2^20 בתים = **1MB**.\n\n4.  **ביטים לכל רמה בטבלת דפים היררכית (שתי רמות):**\n    *   מספר ביטי ה-VPN הוא 18.\n    *   גודל דף הוא 8KB = 2^13 בתים.\n    *   בכל דף יכולות להיכנס: גודל דף / גודל PTE = 2^13 בתים / 4 בתים = 2^11 = 2048 רשומות.\n    *   לכן, כל רמה בטבלת הדפים יכולה למפות עד 2^11 דפים/טבלאות. כלומר, כל רמה משתמשת ב-11 ביטים לכל היותר.\n    *   מכיוון שיש לנו 18 ביטי VPN, נצטרך שתי רמות:\n        *   רמה עליונה (Page Directory): תשתמש ב-18 - 11 = **7 ביטים**.\n        *   רמה תחתונה (Page Table): תשתמש ב-**11 ביטים**.\n\n5.  **מספר מסגרות פיזיות לטבלת הדפים ההיררכית (שתי רמות):**\n    *   **רמת ה-Page Directory (PD):**\n        *   מכילה 2^7 = 128 רשומות (PTEs). \n        *   גודל ה-PD = 128 רשומות * 4 בתים/רשומה = 512 בתים.\n        *   ה-PD נכנס כולו למסגרת פיזית אחת (512 בתים < 8KB).\n        *   **1 מסגרת** עבור ה-PD.\n    *   **רמות ה-Page Tables (PTs):**\n        *   ישנם 2^7 = 128 מצביעים ב-PD. במקרה שהתהליך משתמש בכל הזיכרון הוירטואלי, כל המצביעים ב-PD תקפים, וכל אחד מצביע ל-PT נפרדת. לכן, יהיו 128 טבלאות PT.\n        *   כל PT מכילה 2^11 = 2048 רשומות.\n        *   גודל כל PT = 2048 רשומות * 4 בתים/רשומה = 8192 בתים = 8KB.\n        *   כל PT תופסת בדיוק מסגרת פיזית אחת.\n        *   סה\"כ מסגרות עבור ה-PTs = 128 PTs * 1 מסגרת/PT = **128 מסגרות**.\n    *   **סה\"כ מסגרות לטבלת הדפים = 1 (PD) + 128 (PTs) = 129 מסגרות**."}, "difficulty_estimation": "Medium", "_source_file": "0471__Memory_Management__Open__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:54:21", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Memory Management", "Virtual Memory", "Paging"], "content": {"text": "נתונה מערכת עם זיכרון וירטואלי של 2GB וגודל דף של 8KB. נתון שבכל דף/חלק של טבלת הדפים נכנסות 1024 רשומות (PTE / PDE), וגודל רשומת טבלת דפים הוא 4 בתים. יש לפרט ולנמק את כל החישובים.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "מהם הגדלים של ה-VPN וה-PFN במערכת זו?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "כמה רמות דרושות לטבלת הדפים במערכת זו, וכמה ביטים בכתובת הווירטואלית משמשים לכל רמה?", "code_snippet": null, "options": null}, {"id": "1.3", "text": "תהליך ביצע הקצאת זיכרון דינמית (malloc) של 10MB. כמה מסגרות יתפסו בזיכרון הראשי בעקבות ביצוע פקודה זו, במקרה המקסימלי?", "code_snippet": null, "options": null}], "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1. זיכרון וירטואלי של 2GB הוא 2^31 בתים, לכן כתובת וירטואלית היא באורך 31 ביטים. גודל דף הוא 8KB, כלומר 2^13 בתים, לכן ההיסט (Offset) הוא באורך 13 ביטים. מכאן, VPN = 31 - 13 = 18 ביטים.\nגודל רשומת טבלת דפים (PTE) הוא 4 בתים (32 ביטים). בהינתן 5 ביטים של סטטוס (כמקובל במערכות רבות), ה-PFN הוא באורך 32 - 5 = 27 ביטים. (גודל ה-PFN נגזר מגודל ה-PTE ומספר ביטי הסטטוס, ומגדיר את הזיכרון הפיזי המקסימלי הנתמך על ידי ה-PTE).\n\n1.2. מספר הדפים הווירטואליים הכולל בתהליך הוא 2GB / 8KB = 2^31 / 2^13 = 2^18 דפים.\nבכל דף של טבלת הדפים נכנסות 1024 = 2^10 רשומות.\nכדי למפות 2^18 דפים, נצטרך (2^18) / (2^10) = 2^8 רשומות ברמה העליונה. מכיוון ש-2^8 הוא קטן מ-2^10 (מספר הרשומות בדף בודד של טבלת דפים), נצטרך שתי רמות לטבלת הדפים. עבור הרמה התחתונה (ה-VPN התחתון) נשתמש ב-10 ביטים, ועבור הרמה העליונה (ה-VPN העליון) נשתמש ב-8 ביטים. (סה\"כ 10+8=18 ביטים עבור VPN).\n\n1.3. הקצאה של 10MB היא למעשה הקצאה של 10MB / 8KB = (10 * 1024 KB) / 8KB = 10 * 128 = 1280 דפים.\nבמקרה המקסימלי, אם ההקצאה אינה מיושרת לתחילת דף (כלומר, מתחילה באמצע דף ונגמרת באמצע דף אחר), היא יכולה להתפרס על פני 1280 + 1 = 1281 דפים בזיכרון הווירטואלי.\nעבור טבלת הדפים: 1281 רשומות דרושות עבור הדפים שהוקצו. כל דף בטבלת הדפים מכיל 1024 רשומות. לכן, כדי לאחסן 1281 רשומות, נצטרך ⌈1281 / 1024⌉ = 2 דפים של טבלת דפים ברמה השנייה. (2^10 רשומות בדף אחד).\nהדפים הללו עצמם (של טבלת הדפים) צריכים להיות מוקצים בזיכרון הפיזי. הרמה הראשונה של טבלת הדפים (ה-Page Directory) קיימת תמיד ולא נספרת כהקצאה חדשה במקרה זה (אלא אם צוין אחרת).\nסה\"כ מסגרות בזיכרון הראשי במקרה המקסימלי: 1281 (עבור הנתונים) + 2 (עבור דפי טבלת הדפים ברמה השנייה) = 1283 מסגרות."}, "difficulty_estimation": "Medium", "_source_file": "0472__Memory_Management__Open__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:54:40", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Memory Management", "Paging", "Virtual Memory", "TLB", "Page Replacement", "Protection"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם מנגנון דפדוף (paging) רב-שכבתי. להלן פרטי המערכת:\n*   גודל מרחב הכתובות הווירטואלי (Virtual Address Space) הוא 48 ביטים.\n*   גודל דף פיזי ולוגי הוא 8KB (כלומר, 2^13 בתים).\n*   טבלאות הדפים הן רב-שכבתיות (Multi-level Page Tables), וכל טבלת דפים ברמה מסוימת נשמרת בדף פיזי אחד בדיוק.\n*   כל כניסה בטבלת דפים (Page Table Entry - PTE) היא בגודל 64 ביטים (8 בתים) ומכילה את מספר המסגרת הפיזית (Physical Frame Number - PFN) וכן 6 ביטי בקרה (Valid, Dirty, Accessed, Read/Write, Execute, Global).\n*   המערכת כוללת TLB בגודל 128 כניסות, שהוא Fully Associative.\n*   זמני גישה:\n    *   גישה ל-TLB: 1 מחזור שעון (CPU cycle).\n    *   גישה לזיכרון ראשי (RAM): 100 מחזורי שעון.\n    *   גישה לזיכרון משני (דיסק): 10^7 מחזורי שעון.\n*   מדיניות החלפת הדפים (Page Replacement Policy) היא LRU.\n", "code_snippet": null, "options": null}, "sub_questions": [{"id": "7.1", "text": "כמה רמות של טבלאות דפים נדרשות במערכת זו כדי למפות את מרחב הכתובות הווירטואלי? פרט את החישוב.", "code_snippet": null, "options": null}, {"id": "7.2", "text": "מהו גודל הזיכרון הפיזי המקסימלי במערכת זו? פרט את החישוב.", "code_snippet": null, "options": null}, {"id": "7.3", "text": "תהליך מנסה לבצע פעולת כתיבה (write) לכתובת וירטואלית מסוימת. תאר את רצף הפעולות שיתרחשו במקרה הגרוע ביותר (worst-case scenario), וחשב את הזמן הכולל שייקח לפעולה זו במחזורי שעון.", "code_snippet": null, "options": null}, {"id": "7.4", "text": "נניח שתהליך מנסה לבצע קוד (fetch instruction) מכתובת וירטואלית שה-PTE שלה מציין Read/Write=1, Execute=0. מה יקרה? הסבר.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון שאלה 7:\n\n7.1: חישוב מספר רמות טבלת הדפים:\n*   גודל מרחב הכתובות הווירטואלי (VA) הוא 48 ביטים.\n*   גודל דף הוא 8KB, כלומר 2^13 בתים. לכן, ההיסט (offset) בתוך הדף הוא 13 ביטים.\n*   מספר הביטים לכתובת הדף הווירטואלי (VPN) הוא: 48 ביטים (VA) - 13 ביטים (offset) = 35 ביטים.\n*   כל כניסה בטבלת דפים (PTE) היא בגודל 8 בתים (64 ביטים).\n*   כל טבלת דפים מאוחסנת בדף פיזי אחד בגודל 8KB. לכן, מספר הכניסות בכל טבלת דפים הוא: 8KB / 8 בתים/PTE = 1024 כניסות (2^10 כניסות).\n*   כל רמה בטבלת הדפים משתמשת ב-10 ביטים מתוך ה-VPN כדי לבחור את הכניסה המתאימה.\n*   מספר הרמות הנדרשות הוא: ceil(35 ביטים / 10 ביטים לרמה) = ceil(3.5) = 4 רמות.\n    *   רמה 1: 10 ביטים\n    *   רמה 2: 10 ביטים\n    *   רמה 3: 10 ביטים\n    *   רמה 4: 5 ביטים\n    (סה\"כ 35 ביטים עבור VPN).\n\n7.2: חישוב גודל הזיכרון הפיזי המקסימלי:\n*   גודל PTE הוא 64 ביטים. 6 ביטים מוקדשים לביטי בקרה (Valid, Dirty, Accessed, Read/Write, Execute, Global).\n*   לכן, מספר הביטים הזמינים עבור מספר המסגרת הפיזית (PFN) הוא: 64 ביטים - 6 ביטים = 58 ביטים.\n*   מספר המסגרות הפיזיות המקסימלי הוא 2^58.\n*   גודל כל מסגרת פיזית הוא 8KB (2^13 בתים).\n*   גודל הזיכרון הפיזי המקסימלי הוא: 2^58 (מספר מסגרות) * 2^13 (גודל מסגרת) = 2^71 בתים.\n\n7.3: עלות גישה לכתובת וירטואלית במקרה הגרוע ביותר:\nמקרה גרוע ביותר כולל:\n1.  **TLB Miss**: הכניסה המבוקשת אינה נמצאת ב-TLB. עלות: 1 מחזור שעון.\n2.  **Page Table Walk עם Page Faults עבור טבלאות הדפים**: כל 4 הרמות של טבלאות הדפים אינן נמצאות בזיכרון הראשי (RAM) ודורשות טעינה מהדיסק.\n    *   עבור כל רמה (4 רמות): גישה לדיסק כדי לטעון את דף טבלת הדפים (10^7 מחזורי שעון) + כתיבת הדף ל-RAM (100 מחזורי שעון) + קריאת ה-PTE מאותו דף ב-RAM (100 מחזורי שעון).\n    *   סה\"כ עבור Page Table Walk: 4 * (10^7 + 100 + 100) = 4 * (10^7 + 200) מחזורי שעון.\n3.  **Page Fault עבור דף הנתונים**: ה-PTE הסופי מצביע על כך שדף הנתונים אינו נמצא ב-RAM (Valid=0).\n    *   נניח שהדף שיש לפנות (victim page) הוא 'מלוכלך' (Dirty=1) ולכן יש לכתוב אותו לדיסק: 10^7 מחזורי שעון (Disk Write).\n    *   טעינת הדף המבוקש מהדיסק ל-RAM: 10^7 מחזורי שעון (Disk Read).\n    *   עדכון ה-PTE המתאים ב-RAM (לציין Valid=1, PFN החדש): 100 מחזורי שעון (RAM Write).\n4.  **גישה בפועל לנתונים**: ביצוע פעולת הכתיבה לכתובת הפיזית ב-RAM: 100 מחזורי שעון (RAM Write).\n\nחישוב סך הזמן הכולל:\n1 (TLB Miss) +\n4 * (10^7 + 200) (Page Table Walk עם 4 Page Faults עבור טבלאות הדפים) +\n10^7 (Disk Write ל-victim page) +\n10^7 (Disk Read לדף המבוקש) +\n100 (עדכון PTE ב-RAM) +\n100 (גישה בפועל לנתונים ב-RAM)\n\n= 1 + 4*10^7 + 800 + 10^7 + 10^7 + 100 + 100\n= (4 + 1 + 1) * 10^7 + (1 + 800 + 100 + 100)\n= 6 * 10^7 + 1001 מחזורי שעון.\n\n7.4: השפעת ביט ה-Execute:\nאם תהליך מנסה לבצע קוד (fetch instruction) מכתובת וירטואלית שה-PTE שלה מציין Execute=0, המערכת תזהה הפרת הרשאה (protection violation). גם אם ביט Read/Write מוגדר כ-1, אין לתהליך הרשאת ביצוע (Execute) באותו דף. במקרה כזה, מערכת ההפעלה תייצר חריגה (exception) כגון 'הפרת סגמנטציה' (segmentation fault) או 'הפרת הגנה' (protection fault), ותסיים את ריצת התהליך הפוגע. זהו מנגנון אבטחה קריטי למניעת הרצת קוד זדוני או לא מורשה מאזורי זיכרון המיועדים לנתונים בלבד."}, "difficulty_estimation": "Hard", "_source_file": "0473__Memory_Management__Open__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:26:53", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Memory Management", "Virtual Memory", "Paging", "TLB", "Page Faults"], "content": {"text": "נתונה מערכת הפעלה המממשת זיכרון וירטואלי באמצעות דפדוף (paging) רב-שכבתי (multi-level paging). פרטי המערכת הם כדלקמן:\n*   מרחב כתובות וירטואלי: 48 ביטים.\n*   מרחב כתובות פיזי: 40 ביטים.\n*   גודל דף: 4KB.\n*   גודל כניסה בטבלת דפים (PTE): 8 בתים.\n\nבנוסף, המערכת משתמשת ב-Translation Lookaside Buffer (TLB) בעל המאפיינים הבאים:\n*   מספר כניסות כולל: 16.\n*   אסוציאטיביות: 4-way set associative.\n*   מדיניות החלפה: LRU (בתוך כל סט).\n*   אינדקס ה-TLB נגזר משני הביטים הפחות משמעותיים (LSB) של מספר הדף הווירטואלי (VPN) המלא.\n\nנתון תהליך המנסה לגשת לראשונה לכתובת הווירטואלית `0x0000_1234_5678_9ABC`.\nהניחו כי טבלאות הדפים של התהליך ריקות לחלוטין (כלומר, כל ביט Valid ב-PTE הוא 0 עבור כל הרמות), וה-TLB ריק לחלוטין לפני הגישה.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "כמה רמות של טבלאות דפים יש במערכת זו? כמה כניסות (PTEs) יכולה להכיל כל טבלת דפים ברמה אחת?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "תארו בפירוט את כל השלבים המתבצעים במערכת (חומרה ותוכנה) מרגע ניסיון הגישה לכתובת הווירטואלית `0x0000_1234_5678_9ABC` ועד להשלמתה או לטיפול בפסיקה. יש לכלול את כל הגישות ל-TLB, לזיכרון הראשי (RAM) ולזיכרון המשני (דיסק), ואת העדכונים הנדרשים (ל-TLB ולטבלאות הדפים). הניחו שנדרשת טעינת דף מהדיסק, וכי זיכרון ה-RAM מלא, כך שיש צורך לפנות דף קיים לדיסק.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "כמה גישות לזיכרון הראשי (RAM), לזיכרון המשני (דיסק), ול-TLB בסך הכל מתבצעות עבור תרגום כתובת יחידה זו, בהתאם לתיאורכם בסעיף ב'?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\n**סעיף 1.1:**\n*   **חישוב גודל היסט הדף (Offset):** גודל דף הוא 4KB = 2^12 בתים. לכן, ההיסט בכתובת הוא 12 ביטים.\n*   **חישוב מספר ביטים של Virtual Page Number (VPN):** מרחב כתובות וירטואלי הוא 48 ביטים. VPN = 48 - 12 = 36 ביטים.\n*   **חישוב מספר כניסות לטבלת דפים ברמה אחת:** כל טבלת דפים מאוחסנת בדף אחד (4KB). גודל כניסה בטבלת דפים (PTE) הוא 8 בתים. לכן, מספר הכניסות בכל טבלת דפים הוא 4KB / 8 בתים = 4096 כניסות (2^12).\n*   **חישוב מספר ביטים שכל רמה בטבלת הדפים ממפה:** כל רמה ממפה 12 ביטים (log2(4096)).\n*   **חישוב מספר רמות:** מספר ביטים של VPN הוא 36. כל רמה ממפה 12 ביטים. לכן, מספר הרמות הוא 36 / 12 = 3 רמות.\n\n**תשובה:** ישנן 3 רמות של טבלאות דפים במערכת. כל טבלת דפים ברמה אחת יכולה להכיל 4096 כניסות.\n\n**סעיף 1.2:**\nהכתובת הווירטואלית היא `0x0000_1234_5678_9ABC`.\n*   **היסט (Offset):** 12 הביטים הפחות משמעותיים: `0x9ABC`.\n*   **מספר הדף הווירטואלי (VPN):** 36 הביטים הנותרים: `0x0000_1234_5678`.\n    *   P1 (אינדקס לרמה 1): 12 הביטים העליונים של ה-VPN: `0x000`.\n    *   P2 (אינדקס לרמה 2): 12 הביטים הבאים של ה-VPN: `0x123`.\n    *   P3 (אינדקס לרמה 3): 12 הביטים התחתונים של ה-VPN: `0x456`.\n*   **אינדקס TLB:** שני הביטים הפחות משמעותיים של ה-VPN (0x0000_1234_5678 בבינארי מסתיים ב-`00`). לכן, אינדקס ה-TLB הוא `00`.\n*   **תג TLB (Tag):** 34 הביטים הנותרים של ה-VPN.\n\n**שלבי הגישה:**\n1.  **חיפוש ב-TLB (חומרה):** ה-MMU מחלצת את ה-VPN ומחשבת את אינדקס ה-TLB (`00`). היא בודקת בסט 00 של ה-TLB האם יש כניסה עם התג המתאים (ה-34 ביטים הנותרים של ה-VPN) וביט Valid דולק. מכיוון שה-TLB ריק, מתרחש **TLB Miss**.\n    *   (1 גישה ל-TLB)\n\n2.  **מעבר על טבלאות הדפים (Page Table Walk - חומרה):** מכיוון שה-TLB Miss, ה-MMU מתחילה בחיפוש בטבלאות הדפים בזיכרון הראשי (RAM) כדי למצוא את ה-PFN המתאים. הניחו שכתובת הבסיס של טבלת הדפים הראשית (P1) נמצאת ברגיסטר CR3.\n    *   **גישה לרמה 1 (P1):** ה-MMU ניגשת לכתובת `CR3 + (P1 * PTE_size)` כדי לקרוא את ה-PTE עבור P1 (`0x000`). מכיוון שכל טבלאות הדפים ריקות (Valid=0), ה-PTE עבור `0x000` יהיה לא חוקי.\n        *   (1 גישה ל-RAM)\n    *   **התרחשות Page Fault:** ה-MMU מזהה שה-PTE אינו חוקי (Valid=0) ומאותת למעבד על **Page Fault**.\n\n3.  **טיפול ב-Page Fault (תוכנה - מערכת ההפעלה):**\n    *   מערכת ההפעלה מקבלת את פסיקת ה-Page Fault. היא מזהה שהדף הווירטואלי `0x0000_1234_5678` אינו קיים בזיכרון הפיזי וגם טבלאות הדפים המובילות אליו אינן מאותחלות.\n    *   **הקצאת דפי טבלאות דפים:** מערכת ההפעלה מקצה דפי זיכרון פיזיים חדשים עבור טבלאות הדפים ברמות P1, P2 ו-P3 (אם הן טרם הוקצו). כיוון שהן ריקות לחלוטין, יש צורך להקצות 3 דפים חדשים ב-RAM עבור טבלאות P1, P2 ו-P3.\n        *   (3 גישות ל-RAM: כתיבה ל-PTE בטבלת P1, כתיבה ל-PTE בטבלת P2, כתיבה ל-PTE בטבלת P3, כדי לעדכן את המצביעים לדפי הטבלאות הבאות ולדף הנתונים).\n    *   **טיפול בדף הנתונים:** מערכת ההפעלה מזהה שגם דף הנתונים עצמו (הדף הממופה ל-VPN `0x0000_1234_5678`) אינו נמצא ב-RAM.\n        *   **פינוי דף קיים (Page-out):** מכיוון שזיכרון ה-RAM מלא, מערכת ההפעלה בוחרת דף קורבן (לפי מדיניות החלפת דפים כלשהי, למשל LRU גלובלי). אם דף הקורבן 'מלוכלך' (Dirty=1), הוא נכתב לדיסק.\n            *   (1 גישה לדיסק: כתיבה של דף קורבן)\n        *   **טעינת הדף המבוקש (Page-in):** מערכת ההפעלה קוראת את דף הנתונים עבור הכתובת הווירטואלית `0x0000_1234_5678` מהדיסק ומטעינה אותו למסגרת הפיזית שהתפנתה (או חדשה).\n            *   (1 גישה לדיסק: קריאה של הדף המבוקש)\n        *   **עדכון טבלת הדפים:** מערכת ההפעלה מעדכנת את ה-PTE המתאים בטבלת הדפים ברמה P3 (עבור P3=`0x456`) עם מספר המסגרת הפיזית (PFN) של הדף החדש, ומגדירה את ביט Valid ל-1, את ביט Dirty ל-0 ואת ביט Access ל-1.\n            *   (1 גישה ל-RAM: כתיבת PTE מעודכן לטבלת P3).\n\n4.  **עדכון TLB (מערכת הפעלה/חומרה):** לאחר שהדף נטען וטבלאות הדפים עודכנו, מערכת ההפעלה מוסיפה את המיפוי החדש (VPN -> PFN) ל-TLB. אם הסט המתאים ב-TLB (סט `00`) מלא, הכניסה ה'פחות בשימוש לאחרונה' (LRU) מוחלפת.\n\n5.  **הפעלה מחדש של הפקודה (חומרה):** הפקודה שגרמה ל-Page Fault מופעלת מחדש.\n    *   **חיפוש חוזר ב-TLB:** ה-MMU שוב מחפשת את ה-VPN ב-TLB. הפעם, המיפוי קיים ומתרחש **TLB Hit**.\n        *   (1 גישה ל-TLB)\n    *   **בניית כתובת פיזית וגישה לנתונים:** ה-MMU מקבלת את ה-PFN מה-TLB, משלבת אותו עם ההיסט (`0x9ABC`) ויוצרת את הכתובת הפיזית. לבסוף, היא ניגשת לזיכרון הראשי כדי לבצע את פעולת ה-read/write המקורית על הנתונים.\n        *   (1 גישה ל-RAM: לנתונים עצמם).\n\n**סעיף 1.3:**\nבהתאם לתיאור המפורט בסעיף ב', סך הגישות עבור תרגום כתובת יחידה זו (כולל הגישה לנתונים עצמם) הן:\n*   **גישות ל-TLB:** 2 (אחת ל-TLB Miss, אחת ל-TLB Hit לאחר הטיפול ב-Page Fault).\n*   **גישות לזיכרון הראשי (RAM):**\n    *   1 (קריאת PTE ראשונית בטבלת P1).\n    *   3 (כתיבת PTEs לעדכון טבלאות P1, P2, P3 במהלך הטיפול ב-Page Fault - יצירת מצביעים לטבלאות הבאות ולדף הנתונים).\n    *   1 (כתיבת PTE מעודכן לטבלת P3 עבור דף הנתונים).\n    *   1 (גישה לנתונים עצמם לאחר התרגום המוצלח).\n    *   **סה\"כ גישות ל-RAM:** 1 + 3 + 1 + 1 = 6 גישות.\n\n*   **גישות לזיכרון המשני (דיסק):**\n    *   1 (כתיבת דף קורבן לדיסק – Page-out).\n    *   1 (קריאת הדף המבוקש מהדיסק – Page-in).\n    *   **סה\"כ גישות לדיסק:** 2 גישות.\n\n**סיכום:**\n*   **TLB:** 2 גישות\n*   **RAM:** 6 גישות\n*   **דיסק:** 2 גישות"}, "difficulty_estimation": "Hard", "_source_file": "0474__Memory_Management__Open__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:27:49", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Memory Management", "Paging", "Virtual Memory", "TLB", "Page Replacement"], "content": {"text": "נתונה מערכת הפעלה 64 ביט המשתמשת בזיכרון וירטואלי עם טבלת דפים היררכית בעלת 4 רמות (כמו ב-x86-64). גודל כתובת וירטואלית הוא 48 ביט, וגודל דף הוא 4KB. כל כניסה בטבלת הדפים (PTE) היא בגודל 8 בתים ומכילה מספר מסגרת פיזית (PFN) באורך 40 ביט ו-4 ביטי סטטוס (Valid, Dirty, Accessed, Global). \nבמערכת קיים TLB בגודל 128 כניסות, בעל אסוציאטיביות של 4 דרכים (4-way set associative), ומשתמש באלגוריתם החלפה LRU. כל כניסה ב-TLB שומרת את ה-VPN המלא, ה-PFN וביטי הגנה (Valid, Dirty, Accessed). \n\nהניחו כי ה-TLB ריק בתחילת הריצה. כמו כן, הניחו שכל טבלאות הדפים הביניים (PML4, PDPT, PD, PT) תמיד נמצאות בזיכרון הפיזי וכניסותיהן תקינות (Valid, Present). Page Fault יתרחש רק אם דף הנתונים עצמו אינו נמצא בזיכרון הפיזי (PTE.Present=0). במקרה של Page Fault, הדף נטען לזיכרון הפיזי, ה-PTE מעודכן (Present=1, Dirty=0, Accessed=1) והגישה ממשיכה. במקרה של TLB Miss, יש לגשת לטבלת הדפים בזיכרון הראשי כדי לבצע את התרגום.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "מהו גודל הזיכרון הפיזי המקסימלי הנתמך על ידי מערכת זו? נמקו.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "עקבו אחר רצף הגישות לכתובות הוירטואליות הבאות (בסדר נתון). עבור כל גישה, ציינו האם מדובר ב-TLB Hit או TLB Miss, האם מתרחש Page Fault, וכמה גישות לזיכרון הראשי (Main Memory) נדרשות עבור תרגום הכתובת (לא כולל הגישה לנתון עצמו).\n\nנתוני מיפוי PFN ראשוניים:\n*   `VPN (0x100_0000_00)` ממופה ל-`PFN 0x1000`, `Present=1`.\n*   `VPN (0x100_0000_01)` ממופה ל-`PFN 0x2000`, `Present=1`.\n*   `VPN (0x100_0000_02)` ממופה ל-`PFN 0x3000`, `Present=1`.\n*   `VPN (0x200_0000_00)` ממופה ל-`PFN 0x4000`, `Present=1`.\n*   `VPN (0x300_0000_00)` ממופה ל-`PFN 0x5000`, `Present=1`.\n*   `VPN (0x400_0000_00)` ממופה ל-`PFN 0x6000`, `Present=0` (גורם ל-Page Fault).\n*   לאחר Page Fault, `VPN (0x400_0000_00)` ממופה ל-`PFN 0x6000`, `Present=1`.\n\nרצף הכתובות הוירטואליות:\n1.  `0x1000_0000_0000`\n2.  `0x1000_0000_1000`\n3.  `0x1000_0000_0000`\n4.  `0x1000_0000_2000`\n5.  `0x2000_0000_0000`\n6.  `0x3000_0000_0000`\n7.  `0x4000_0000_0000`", "code_snippet": null, "options": null}, {"id": "1.3", "text": "תארו את מצב ה-TLB (אילו VPNs נמצאים באילו סטים ובאילו דרכים, ומה סדר ה-LRU בכל סט) לאחר סיום כל הגישות ברצף הנתון בסעיף 2.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "**פתרון:**\n\n**1.1. גודל הזיכרון הפיזי המקסימלי:**\n*   גודל כניסה בטבלת הדפים (PTE) הוא 8 בתים.\n*   מספר מסגרת פיזית (PFN) הוא באורך 40 ביט.\n*   מספר ביטי ה-PFN קובע את מספר המסגרות הפיזיות המקסימלי: 2^40 מסגרות.\n*   גודל דף נתון כ-4KB (2^12 בתים).\n*   גודל הזיכרון הפיזי המקסימלי = מספר המסגרות * גודל דף = 2^40 * 2^12 = 2^52 בתים.\n*   2^52 בתים = 4 פטה-בתים (PB).\n\n**1.2. מעקב אחר רצף הגישות:**\n**חישובים מקדימים:**\n*   כתובת וירטואלית (VA) = 48 ביט.\n*   היסט (Offset) = 12 ביט (מכיוון שגודל דף = 4KB = 2^12).\n*   מספר דף וירטואלי (VPN) = 48 - 12 = 36 ביט.\n*   טבלת דפים היררכית בעלת 4 רמות: כל רמה משתמשת ב- 36 / 4 = 9 ביטים עבור האינדקס שלה (PML4_idx, PDPT_idx, PD_idx, PT_idx).\n*   TLB: 128 כניסות, 4-way set associative.\n*   מספר הסטים ב-TLB = 128 כניסות / 4 דרכים = 32 סטים (2^5 סטים).\n*   אינדקס הסט ב-TLB: 5 הביטים האחרונים של ה-VPN (VPN[4:0]). במקרה זה, אלו 5 הביטים האחרונים של אינדקס טבלת הדפים ברמה האחרונה (PT_idx[4:0]).\n*   תגית (Tag) ב-TLB: שאר ביטי ה-VPN (VPN[35:5]).\n*   מספר גישות זיכרון לתרגום (במקרה של TLB Miss): 4 גישות (אחת לכל רמה בטבלת הדפים: PML4, PDPT, PD, PT).\n\n**פירוט VPN ו-TLB עבור הכתובות:**\n*   `VPN_A = 0x100_0000_00` (PML4=0x1, PDPT=0x0, PD=0x0, PT=0x0). `PT_idx=0x000`. `TLB_set=0` (`00000` בינארי). `TLB_tag=0x100_0000_0`.\n*   `VPN_B = 0x100_0000_01` (PML4=0x1, PDPT=0x0, PD=0x0, PT=0x1). `PT_idx=0x001`. `TLB_set=1` (`00001` בינארי). `TLB_tag=0x100_0000_0`.\n*   `VPN_C = 0x100_0000_02` (PML4=0x1, PDPT=0x0, PD=0x0, PT=0x2). `PT_idx=0x002`. `TLB_set=2` (`00010` בינארי). `TLB_tag=0x100_0000_0`.\n*   `VPN_D = 0x200_0000_00` (PML4=0x2, PDPT=0x0, PD=0x0, PT=0x0). `PT_idx=0x000`. `TLB_set=0` (`00000` בינארי). `TLB_tag=0x200_0000_0`.\n*   `VPN_E = 0x300_0000_00` (PML4=0x3, PDPT=0x0, PD=0x0, PT=0x0). `PT_idx=0x000`. `TLB_set=0` (`00000` בינארי). `TLB_tag=0x300_0000_0`.\n*   `VPN_F = 0x400_0000_00` (PML4=0x4, PDPT=0x0, PD=0x0, PT=0x0). `PT_idx=0x000`. `TLB_set=0` (`00000` בינארי). `TLB_tag=0x400_0000_0`.\n\n**טבלת מעקב:**\n\n| גישה # | כתובת וירטואלית | VPN            | TLB Set | TLB Hit/Miss | Page Fault | גישות לזיכרון (תרגום) | מצב סט 0 (LRU -> MRU) |\n| :----- | :--------------- | :------------- | :------ | :----------- | :--------- | :--------------------- | :------------------------------------ |\n| 1      | `0x1000_0000_0000` | `VPN_A`        | 0       | Miss         | No         | 4                      | {(`VPN_A`)}                         |\n| 2      | `0x1000_0000_1000` | `VPN_B`        | 1       | Miss         | No         | 4                      | {(`VPN_A`)}                         |\n| 3      | `0x1000_0000_0000` | `VPN_A`        | 0       | Hit          | No         | 0                      | {(`VPN_A`)}                         |\n| 4      | `0x1000_0000_2000` | `VPN_C`        | 2       | Miss         | No         | 4                      | {(`VPN_A`)}                         |\n| 5      | `0x2000_0000_0000` | `VPN_D`        | 0       | Miss         | No         | 4                      | {(`VPN_A`), (`VPN_D`)}              |\n| 6      | `0x3000_0000_0000` | `VPN_E`        | 0       | Miss         | No         | 4                      | {(`VPN_A`), (`VPN_D`), (`VPN_E`)}   |\n| 7      | `0x4000_0000_0000` | `VPN_F`        | 0       | Miss         | Yes        | 4                      | {(`VPN_A`), (`VPN_D`), (`VPN_E`), (`VPN_F`)} |\n\n**הסבר למצב סט 0:**\n*   **גישה 1 (VPN_A):** TLB Miss. `VPN_A` נטען לסט 0. מצב: {(`VPN_A`)}. `VPN_A` הוא ה-MRU (Most Recently Used).\n*   **גישה 3 (VPN_A):** TLB Hit. `VPN_A` נשאר בסט 0 והופך שוב ל-MRU. מצב: {(`VPN_A`)}.\n*   **גישה 5 (VPN_D):** TLB Miss. `VPN_D` נטען לסט 0. מצב: {(`VPN_A`), (`VPN_D`)}. `VPN_A` הוא ה-LRU (Least Recently Used), `VPN_D` הוא ה-MRU.\n*   **גישה 6 (VPN_E):** TLB Miss. `VPN_E` נטען לסט 0. מצב: {(`VPN_A`), (`VPN_D`), (`VPN_E`)}. סדר LRU -> MRU: `VPN_A`, `VPN_D`, `VPN_E`.\n*   **גישה 7 (VPN_F):** TLB Miss. סט 0 אינו מלא (יש בו 3 כניסות מתוך 4). `VPN_F` נטען לכניסה הפנויה. מתרחש Page Fault עבור `VPN_F`, הדף נטען וה-PTE מתעדכן. מצב: {(`VPN_A`), (`VPN_D`), (`VPN_E`), (`VPN_F`)}. סדר LRU -> MRU: `VPN_A`, `VPN_D`, `VPN_E`, `VPN_F`.\n\n**1.3. מצב ה-TLB לאחר כל הגישות:**\n\n*   **סט 0 (LRU -> MRU):**\n    *   `VPN_A` (Tag `0x100_0000_0`, PFN `0x1000`)\n    *   `VPN_D` (Tag `0x200_0000_0`, PFN `0x4000`)\n    *   `VPN_E` (Tag `0x300_0000_0`, PFN `0x5000`)\n    *   `VPN_F` (Tag `0x400_0000_0`, PFN `0x6000`)\n\n*   **סט 1 (LRU -> MRU):**\n    *   `VPN_B` (Tag `0x100_0000_0`, PFN `0x2000`)\n\n*   **סט 2 (LRU -> MRU):**\n    *   `VPN_C` (Tag `0x100_0000_0`, PFN `0x3000`)\n\n*   **שאר הסטים ב-TLB (סטים 3-31) ריקים.**"}, "difficulty_estimation": "Hard", "_source_file": "0475__Memory_Management__Open__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:58:15", "_subject": "Virtualization"}, {"id": 11, "type": "Open", "topic": ["Memory Management", "Virtual Memory", "Paging", "TLB", "Page Faults", "Page Replacement"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם המאפיינים הבאים:\n*   כתובת וירטואלית: 48 ביטים\n*   כתובת פיזית: 32 ביטים\n*   גודל דף: 4KB\n*   גודל כניסה בטבלת דפים (PTE): 4 בתים (32 ביטים), המכילה מספר מסגרת פיזית (PFN), וביטים Valid, Dirty, Accessed, וביטי הרשאות קריאה/כתיבה/הרצה.\n*   TLB (Translation Lookaside Buffer): בעל 128 כניסות, ממומש כ-fully associative, ומשתמש במדיניות החלפה LRU. כל כניסה ב-TLB כוללת VPN, PFN, וביטי הרשאות.\n\nתהליך מנסה לבצע פעולת כתיבה לכתובת הווירטואלית `0x0000_1234_5678`.\nתארו באופן מלא ומפורט את תהליך תרגום הכתובת, החל מהגישה הראשונית ועד להשלמת הכתיבה, בהנחה שמדובר ב'מקרה הגרוע ביותר' (worst-case scenario).\nיש לכלול בתיאור:\n1.  פירוט מבנה טבלת הדפים (מספר רמות, חלוקת ביטי ה-VPN).\n2.  כיצד ה-TLB מעורב בתהליך (בכל שלב).\n3.  את כל הגישות לזיכרון הראשי (RAM) ולזיכרון המשני (דיסק) שיתרחשו.\n4.  כיצד מטופלת פסיקת דף (Page Fault) במקרה זה (בהנחה שכל המסגרות הפיזיות בשימוש, ונדרשת החלפת דף 'מלוכלך').\n5.  את השינויים הנדרשים במבני הנתונים (TLB וטבלת הדפים) בעקבות התהליך.\nיש לפרט את כל החישובים הרלוונטיים.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  **פירוק הכתובת הווירטואלית ומבנה טבלת הדפים:**\n    *   גודל כתובת וירטואלית: 48 ביטים.\n    *   גודל דף: 4KB = 2^12 בתים. לכן, 12 הביטים האחרונים של הכתובת הווירטואלית הם ה-Offset בתוך הדף.\n    *   מספר דף וירטואלי (VPN): 48 - 12 = 36 ביטים.\n    *   גודל כניסה בטבלת דפים (PTE): 4 בתים (32 ביטים).\n    *   מספר כניסות PTE בדף בודד: גודל דף / גודל PTE = 4KB / 4 בתים = 1024 כניסות (2^10).\n    *   כל רמה בטבלת הדפים משתמשת ב-10 ביטים מה-VPN.\n    *   מספר רמות נדרש: VPN באורך 36 ביטים. 36 חלקי 10 שווה 3 עם שארית 6. לכן, נדרשות 4 רמות של טבלאות דפים:\n        *   רמה 1: 6 ביטים (המצביעים לטבלת דפים רמה 2)\n        *   רמה 2: 10 ביטים (המצביעים לטבלת דפים רמה 3)\n        *   רמה 3: 10 ביטים (המצביעים לטבלת דפים רמה 4)\n        *   רמה 4: 10 ביטים (המצביעים לדף הפיזי)\n    *   סה\"כ ביטי VPN: 6 + 10 + 10 + 10 = 36 ביטים.\n    *   הכתובת הווירטואלית `0x0000_1234_5678`:\n        *   Offset: `0x678` (12 ביטים).\n        *   VPN: `0x0000_1234_5` (36 ביטים).\n        *   פירוק ה-VPN (בייצוג בינארי של 36 ביטים: `00000000000000010010001101000101`):\n            *   L1 Index (6 ביטים עליונים): `000000` (0)\n            *   L2 Index (10 ביטים הבאים): `0000000100` (4)\n            *   L3 Index (10 ביטים הבאים): `1000110100` (564)\n            *   L4 Index (10 ביטים תחתונים): `0100010101` (277)\n\n2.  **תהליך תרגום הכתובת במקרה הגרוע ביותר:**\n    *   **שלב 1: גישה ל-TLB (TLB Miss)**: ה-CPU מקבל את הכתובת הווירטואלית. הוא מנסה למצוא את ה-VPN (`0x0000_1234_5`) ב-TLB. במקרה הגרוע ביותר, ה-VPN לא נמצא ב-TLB (TLB Miss). זוהי גישת TLB אחת.\n\n    *   **שלב 2: הליכה בטבלת הדפים (Page Table Walk)**: מאחר שה-VPN לא נמצא ב-TLB, מערכת ההפעלה (או חומרת MMU) מבצעת הליכה בטבלאות הדפים המרובות בזיכרון הראשי:\n        *   ה-CPU ניגש לזיכרון הראשי (RAM) כדי לקרוא את ה-PTE המתאים בטבלת הדפים של רמה 1 (כתובת הבסיס של L1 נמצאת ברגיסטר כמו CR3). הוא משתמש ב-L1 Index (0) כדי למצוא את המצביע לטבלת הדפים של רמה 2. (גישת RAM 1).\n        *   ה-CPU ניגש לזיכרון הראשי (RAM) כדי לקרוא את ה-PTE המתאים בטבלת הדפים של רמה 2. הוא משתמש ב-L2 Index (4) כדי למצוא את המצביע לטבלת הדפים של רמה 3. (גישת RAM 2).\n        *   ה-CPU ניגש לזיכרון הראשי (RAM) כדי לקרוא את ה-PTE המתאים בטבלת הדפים של רמה 3. הוא משתמש ב-L3 Index (564) כדי למצוא את המצביע לטבלת הדפים של רמה 4. (גישת RAM 3).\n        *   ה-CPU ניגש לזיכרון הראשי (RAM) כדי לקרוא את ה-PTE המתאים בטבלת הדפים של רמה 4. הוא משתמש ב-L4 Index (277) כדי לקבל את ה-PTE המלא של הדף המבוקש. (גישת RAM 4).\n\n    *   **שלב 3: פסיקת דף (Page Fault)**: במקרה הגרוע ביותר, ה-PTE שנקרא מרמה 4 מצביע על כך שהדף אינו נמצא בזיכרון הפיזי (Valid bit = 0), או שאין לו הרשאות כתיבה עבור הפעולה המבוקשת (Write permission bit = 0). במקרה כזה תתרחש פסיקת דף.\n        *   מערכת ההפעלה מקבלת פסיקת דף.\n        *   **טיפול בפסיקה:**\n            *   מערכת ההפעלה צריכה למצוא מסגרת פיזית פנויה לטעינת הדף. בהנחה שכל המסגרות בשימוש, היא תפעיל אלגוריתם החלפת דפים (לדוגמה, LRU) כדי לבחור דף לפינוי.\n            *   אם הדף הנבחר לפינוי הוא \"מלוכלך\" (Dirty bit = 1), כלומר תוכנו השתנה מאז נטען, יש לכתוב אותו בחזרה לדיסק לפני פינויו. (גישת דיסק 1 – כתיבת דף מלוכלך לדיסק).\n            *   מערכת ההפעלה טוענת את הדף המבוקש מהדיסק לתוך המסגרת הפיזית שהתפנתה. (גישת דיסק 2 – קריאת דף מהדיסק).\n            *   מערכת ההפעלה מעדכנת את ה-PTE המתאים בטבלת הדפים של רמה 4 (אותו PTE שגרם לפסיקה): היא מכניסה את ה-PFN של המסגרת החדשה, קובעת Valid bit = 1, Dirty bit = 0, Accessed bit = 1, ומאפשרת הרשאות כתיבה. (גישת RAM 5 – כתיבה ל-PTE ב-RAM).\n\n    *   **שלב 4: עדכון ה-TLB**: לאחר שהדף נטען וה-PTE עודכן, מערכת ההפעלה מוסיפה את המיפוי החדש (VPN, PFN, הרשאות) ל-TLB. אם ה-TLB מלא, כניסה אחרת (לפי LRU) תפונה. (גישת TLB 2 – כתיבה ל-TLB).\n\n    *   **שלב 5: הפעלת ההוראה מחדש וגישה ל-TLB (TLB Hit)**: ה-CPU מפעיל מחדש את ההוראה שגרמה לפסיקת הדף. הפעם, כאשר הוא ניגש ל-TLB, הוא ימצא את ה-VPN (TLB Hit). (גישת TLB 3 – קריאה מ-TLB).\n\n    *   **שלב 6: גישה פיזית לזיכרון**: ה-CPU משתמש ב-PFN שהתקבל מה-TLB וב-Offset המקורי כדי לגשת לכתובת הפיזית ולבצע את פעולת הכתיבה בפועל. (גישת RAM 6 – כתיבה לזיכרון הפיזי).\n\n3.  **סיכום גישות במקרה הגרוע ביותר:**\n    *   **גישות ל-TLB:** 3 (אחת ל-miss, אחת לכתיבת entry חדש, אחת ל-hit לאחר הטיפול בפסיקה).\n    *   **גישות לזיכרון הראשי (RAM):** 6 (4 להליכה בטבלת הדפים, 1 לעדכון PTE, 1 לכתיבת הנתון בפועל).\n    *   **גישות לדיסק:** 2 (אחת לכתיבת דף מלוכלך מפונה, אחת לקריאת הדף המבוקש)."}, "difficulty_estimation": "Hard", "_source_file": "0476__Memory_Management__Open__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:58:55", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Memory Management", "Paging", "Virtual Memory", "Superpages", "TLB", "Fragmentation"], "content": {"text": "נתונה מערכת הפעלה 64-ביט המשתמשת במנגנון זיכרון וירטואלי מבוסס דפדוף (paging). גודל הדף הסטנדרטי הוא 4KB. המערכת משתמשת בטבלת דפים היררכית בת 3 רמות (multi-level page table) למיפוי כתובות וירטואליות לכתובות פיזיות. על מנת לשפר ביצועים עבור אזורי זיכרון גדולים ורציפים, המערכת תומכת גם ב\"דפי-על\" (superpages) בגודל 2MB. דפי-על אלו יכולים למפות אזורים גדולים של זיכרון וירטואלי לבלוקים רציפים גדולים בזיכרון הפיזי, ובכך להפחית את מספר הכניסות בטבלת הדפים ואת מספר הגישות ל-TLB/זיכרון.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "מבנה PTE: תארו בפירוט את מבנה כניסת טבלת הדפים (PTE) עבור דף סטנדרטי (4KB) ועבור דף-על (2MB). ציינו אילו שדות נדרשים וכיצד הם עשויים להשתנות בין שני סוגי הדפים.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "תהליך תרגום כתובות ו-TLB: הסבירו כיצד מתבצע תרגום כתובות וירטואליות לכתובות פיזיות במערכת זו, תוך התחשבות בקיום שני סוגי הדפים. פרטו את תפקיד ה-TLB בתהליך זה ואילו שינויים או הרחבות נדרשים ב-TLB כדי לתמוך ביעילות בשני גדלי הדפים.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "הקצאת זיכרון ופרגמנטציה: תהליך מבקש להקצות בלוק זיכרון וירטואלי רציף בגודל 8MB. המערכת מנסה להשתמש בדפי-על כדי למפות את הבלוק הזה, אך הזיכרון הפיזי מפוצל (fragmented) מאוד, ואין מסגרות פיזיות רציפות בגודל 2MB זמינות. תארו כיצד מערכת ההפעלה תטפל בבקשת ההקצאה במקרה זה, ומהן ההשלכות הביצועיות של פתרון זה לעומת שימוש בדפי-על.", "code_snippet": null, "options": null}, {"id": "1.4", "text": "הגנה ושיתוף זיכרון: כיצד יכולה התמיכה בדפי-על להשפיע על מנגנוני הגנה על זיכרון ושיתוף זיכרון בין תהליכים? תארו את האתגרים והיתרונות הפוטנציאליים.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסבר מפורט:\n\n1.1. מבנה PTE:\n   *   **PTE לדף סטנדרטי (4KB):** כניסה זו תכיל את מספר המסגרת הפיזית (PFN) של דף ה-4KB. בנוסף, היא תכלול ביטים נפוצים כמו: Valid (האם הכניסה חוקית), Present (האם הדף נמצא בזיכרון הפיזי או בדיסק), Dirty (האם הדף שונה), Accessed (האם הדף נוגש), וביטים להרשאות (קריאה, כתיבה, הרצה). מכיוון שזו מערכת 64-ביט, וגודל דף 4KB (12 ביטים להיסט), אז נותרו 52 ביטים למספר הדף הווירטואלי (VPN). בטבלת דפים 3 רמות, כל רמה משתמשת בחלק מביטי ה-VPN. ה-PFN יצטרך להיות מספיק גדול כדי למפות את כל הזיכרון הפיזי. אם נניח זיכרון פיזי של 2^48 בתים (256TB), אז ה-PFN יהיה באורך של 36 ביטים (48-12).\n   *   **PTE לדף-על (2MB):** כניסה זו תהיה ברמה גבוהה יותר בטבלת הדפים (לרוב ברמה השנייה או השלישית, תלוי איך מחלקים את ביטי ה-VPN). במקום PFN של 4KB, היא תכיל PFN של 2MB. כלומר, ההיסט עבור דף-על בגודל 2MB הוא 21 ביטים (2^21 בתים). לכן, ה-PFN יתייחס לבלוק פיזי בגודל 2MB. בנוסף לביטים הסטנדרטיים (Valid, Present, Dirty, Accessed, הרשאות), ייתכן שיידרש ביט נוסף שיציין האם זו כניסה לדף סטנדרטי או לדף-על (Superpage bit), או שניתן להסיק זאת ממיקום ה-PTE בטבלת הדפים (לדוגמה, אם PTE ברמה 2 מצביע ישירות למסגרת פיזית, זהו דף-על). ה-PFN עבור דף-על יהיה קצר יותר ב-9 ביטים (21-12=9) מאשר PFN של דף רגיל, כי הוא מכסה בלוק גדול יותר.\n\n1.2. תהליך תרגום כתובות ו-TLB:\n   *   **תרגום כתובות:** כאשר ה-MMU מקבל כתובת וירטואלית 64-ביט, הוא מפרק אותה לביטי ה-VPN (מספר דף וירטואלי) ולביטי ההיסט (offset).\n       *   עבור דף סטנדרטי (4KB), ה-VPN יחולק לשלושה חלקים (לדוגמה, 9 ביטים לכל רמה, או חלוקה אחרת שתסכם ל-52 ביטים), שישמשו כאינדקסים לטבלאות הדפים ברמות השונות. ה-MMU יגש לטבלת הדפים ברמה 1, ימצא PTE שמצביע לטבלת דפים ברמה 2, משם לטבלת דפים ברמה 3, ובסוף ימצא PTE שמכיל את ה-PFN של דף ה-4KB.\n       *   עבור דף-על (2MB), ההיסט הוא 21 ביטים. ה-VPN יחולק בהתאם. ייתכן שה-PTE המצביע לדף-על נמצא ברמה 2 (לדוגמה, אם הרמה הראשונה והשניה יחד מכסות 21 ביטים). במקרה כזה, ה-MMU יגש לטבלת הדפים ברמה 1, ימצא PTE שמצביע לטבלת דפים ברמה 2, ושם ימצא PTE שמסומן כדף-על ומכיל ישירות את ה-PFN של בלוק ה-2MB. התרגום מסתיים בשלב מוקדם יותר, ללא צורך לגשת לטבלת הרמה הנמוכה ביותר.\n   *   **תפקיד ה-TLB:** ה-TLB (Translation Lookaside Buffer) הוא זיכרון מטמון מהיר של מיפויי כתובות וירטואליות-פיזיות.\n       *   כאשר ה-MMU מקבל כתובת וירטואלית, הוא מנסה למצוא מיפוי ב-TLB.\n       *   כדי לתמוך בשני גדלי הדפים, כל כניסה ב-TLB צריכה לכלול לא רק את ה-VPN וה-PFN, אלא גם את גודל הדף (Page Size bit/field) המשויך למיפוי. זה מאפשר ל-TLB להבחין בין כניסה של דף 4KB לכניסה של דף 2MB.\n       *   **אתגרים ושינויים ב-TLB:**\n           *   **חיפוש:** ה-TLB צריך לתמוך בחיפוש לפי VPN ובגודל הדף. לדוגמה, אם מחפשים VPN מסוים, ה-TLB צריך לבדוק אם יש כניסה עבורו בגודל 4KB או בגודל 2MB.\n           *   **כיסוי (Coverage):** דפי-על מגדילים משמעותית את הכיסוי של ה-TLB. כניסה אחת לדף-על מכסה 512 דפים סטנדרטיים (2MB / 4KB). זה מפחית את שיעור ה-TLB Miss עבור אזורי זיכרון גדולים.\n           *   **מורכבות חומרה:** הוספת שדה גודל הדף והלוגיקה לטיפול בו מגדילה את מורכבות ה-TLB. ייתכנו TLBs נפרדים עבור גדלי דפים שונים, או TLB מאוחד עם לוגיקת חיפוש מורכבת יותר.\n\n1.3. הקצאת זיכרון ופרגמנטציה:\n   *   **טיפול בבקשה:** כאשר תהליך מבקש 8MB רציפים, ומערכת ההפעלה מנסה להקצות אותם כדפי-על אך נתקלת בפרגמנטציה פיזית (אין 2MB רציפים), היא תיאלץ לחזור לשימוש בדפים סטנדרטיים של 4KB. במקרה זה, ה-8MB ימופו באמצעות 2048 דפים סטנדרטיים (8MB / 4KB). כל אחד מהם יקבל מסגרת פיזית נפרדת. טבלת הדפים תצטרך להכיל 2048 כניסות ברמה הנמוכה ביותר עבור בלוק זיכרון זה.\n   *   **השלכות ביצועיות:**\n       *   **גודל טבלת דפים:** במקום 4 כניסות של דפי-על (8MB / 2MB), יהיו 2048 כניסות לדפים סטנדרטיים. זה מגדיל משמעותית את נפח טבלת הדפים בזיכרון.\n       *   **TLB Miss Rate:** כל גישה לכתובת בטווח ה-8MB תצטרך כניסת TLB נפרדת עבור דף 4KB. אם ה-TLB קטן, שיעור ה-TLB Miss יעלה באופן דרמטי, מכיוון ש-2048 כניסות יידרשו במקום 4. כל TLB Miss מוביל לגישות מרובות לזיכרון הראשי (לשלוש רמות טבלת הדפים), מה שמאט את הגישה לזיכרון.\n       *   **Overhead של מערכת ההפעלה:** ניהול 2048 דפים במקום 4 דפי-על דורש יותר משאבי CPU וזיכרון ממערכת ההפעלה (לדוגמה, עבור page faults, ניהול רשימות דפים פנויים).\n       *   **פרגמנטציה פנימית:** למרות שדפי-על מפחיתים פרגמנטציה פנימית כאשר הם מנוצלים במלואם, שימוש בדפים סטנדרטיים עשוי להחמיר פרגמנטציה חיצונית אם לא ניתן להקצות אותם בצורה רציפה. במקרה זה, הבעיה היא פרגמנטציה חיצונית בזיכרון הפיזי שמונעת שימוש בדפי-על.\n\n1.4. הגנה ושיתוף זיכרון:\n   *   **הגנה על זיכרון:**\n       *   **יתרון:** דפי-על מפשטים הגנה על אזורי זיכרון גדולים. במקום להגדיר הרשאות ל-512 דפי 4KB בנפרד, ניתן להגדיר הרשאות (קריאה, כתיבה, הרצה) פעם אחת עבור דף-על שלם. זה מפחית את העומס על מערכת ההפעלה ומפשט את הלוגיקה.\n       *   **אתגר:** אם נדרשת הגנה עדינה יותר בתוך דף-על (לדוגמה, חלק מ-2MB מוגן בכתיבה וחלק לא), לא ניתן לעשות זאת ישירות עם דף-על יחיד. במקרה כזה, יש צורך לפרק את דף-העל לדפים סטנדרטיים ולנהל את ההגנה ברמת ה-4KB, מה שמבטל את יתרונות הביצועים של דף-העל.\n   *   **שיתוף זיכרון:**\n       *   **יתרון:** שיתוף אזורי זיכרון גדולים ורציפים בין תהליכים הופך ליעיל יותר. במקום שכל תהליך ימפה בנפרד אלפי דפים סטנדרטיים, הם יכולים למפות דף-על יחיד לאותו אזור פיזי. זה חוסך מקום בטבלאות הדפים של כל תהליך ומפחית את העומס על ה-TLB.\n       *   **אתגר:** בדומה להגנה, אם תהליכים שונים צריכים גישות שונות (לדוגמה, תהליך אחד קריאה-כתיבה, אחר קריאה בלבד) לאותו אזור בתוך דף-על, או אם רק חלק מדף-העל צריך להיות משותף, אז דף-על יחיד אינו מתאים. יש צורך לפרק אותו לדפים סטנדרטיים ולנהל את השיתוף וההרשאות ברמת ה-4KB. זה דורש לוגיקה מורכבת יותר במערכת ההפעלה כדי להחליט מתי להשתמש בדפי-על ומתי לפצל אותם."}, "difficulty_estimation": "Hard", "_source_file": "0477__Memory_Management__Open__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:28:28", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Memory Management", "Paging", "Virtual Memory", "TLB", "Shared Memory"], "content": {"text": "נתונה מערכת הפעלה מודרנית המשתמשת בזיכרון וירטואלי מבוסס דפדוף (paging) עם מרחב כתובות וירטואלי של 48 ביטים. גודל דף הוא 4KB. כל כניסה בטבלת הדפים (PTE) היא בגודל 8 בתים. המערכת כוללת גם TLB עם 64 כניסות, הפועל בשיטת אסוציאטיביות מלאה (fully associative).\n\nהמערכת תומכת גם בזיכרון משותף (shared memory) בין תהליכים, כאשר דפים המשותפים בין תהליכים ממופים לאותה מסגרת פיזית בזיכרון הפיזי, אך עשויים להופיע בכתובות וירטואליות שונות במרחבי הכתובות של התהליכים השונים.\n\nענו על השאלות הבאות ופרטו את כל החישובים וההנחות:", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "כמה רמות של טבלאות דפים נדרשות במערכת זו כדי למפות את מרחב הכתובות הוירטואלי? מהו גודל טבלת הדפים ברמה העליונה (root page table) בבתים?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "תהליך P1 ניגש לכתובת וירטואלית X, שאינה דף משותף. הדף המכיל את X אינו נמצא ב-TLB, אך הוא נמצא בזיכרון הפיזי (כלומר, ה-PTE שלו מסומן כ-Present=1). תארו את רצף הפעולות המלא מתחילת הגישה לכתובת X ועד לקבלת הנתונים, כולל גישות ל-TLB, לטבלאות הדפים ולזיכרון הפיזי. כמה גישות לזיכרון הראשי (RAM) מתבצעות במקרה זה?", "code_snippet": null, "options": null}, {"id": "1.3", "text": "תהליך P2 ניגש לכתובת וירטואלית Y, הממופה לדף המשותף עם תהליך P3. נניח שהדף המשותף *אינו* ב-TLB של P2 וגם *אינו* נמצא בזיכרון הפיזי (Present=0 ב-PTE). לאחר מכן, תהליך P3 ניגש לאותה כתובת וירטואלית Y (אותו VPN), שגם עבורו הדף המשותף *אינו* ב-TLB. תארו את רצף הפעולות המלא עבור שתי הגישות (של P2 ולאחר מכן P3), כולל גישות ל-TLB, לטבלאות הדפים, לדיסק ולזיכרון הפיזי. כמה גישות לזיכרון הראשי (RAM) ולדיסק מתבצעות בסך הכל עבור שתי הגישות יחד?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\n**1.1. חישוב רמות טבלאות הדפים וגודל טבלת הדפים ברמה העליונה:**\n*   גודל מרחב הכתובות הוירטואלי: 48 ביטים.\n*   גודל דף: 4KB = 2^12 בתים. לכן, ההיסט (offset) הוא 12 ביטים.\n*   מספר ביטים עבור מספר הדף הוירטואלי (VPN): 48 - 12 = 36 ביטים.\n*   גודל כניסה בטבלת הדפים (PTE): 8 בתים.\n*   מספר כניסות PTE שיכולות להיכנס לדף אחד: 4KB / 8 בתים/PTE = 512 כניסות (2^9 כניסות).\n*   לכן, כל רמה בטבלת הדפים משתמשת ב-9 ביטים מתוך ה-VPN כדי לאנדקס את הכניסה המתאימה.\n*   מספר רמות טבלאות הדפים הנדרשות: 36 ביטים / 9 ביטים לרמה = 4 רמות.\n*   טבלת הדפים ברמה העליונה (root page table) מכילה 512 כניסות (כיוון שהיא מאוחסנת בדף אחד). גודלה בבתים: 512 כניסות * 8 בתים/כניסה = 4096 בתים = 4KB.\n\n**תשובה:** נדרשות 4 רמות של טבלאות דפים. גודל טבלת הדפים ברמה העליונה הוא 4KB.\n\n**1.2. רצף פעולות עבור גישה לכתובת וירטואלית X (דף פרטי, TLB Miss, Page Table Hit):**\n1.  **גישה ל-TLB:** המעבד מנסה לתרגם את הכתובת הוירטואלית X באמצעות ה-TLB. מכיוון שהדף אינו ב-TLB (TLB Miss), תתרחש החמאה ב-TLB.\n2.  **גישה לטבלאות הדפים (4 רמות):** מערכת ההפעלה תתחיל לעבור על טבלאות הדפים כדי למצוא את ה-PTE המתאים:\n    *   גישה לזיכרון הראשי כדי לקרוא את הכניסה המתאימה מטבלת הדפים ברמה 1.\n    *   גישה לזיכרון הראשי כדי לקרוא את הכניסה המתאימה מטבלת הדפים ברמה 2.\n    *   גישה לזיכרון הראשי כדי לקרוא את הכניסה המתאימה מטבלת הדפים ברמה 3.\n    *   גישה לזיכרון הראשי כדי לקרוא את ה-PTE הסופי מטבלת הדפים ברמה 4. מכיוון שהדף נמצא בזיכרון הפיזי (Present=1), ה-PTE יכיל את מספר המסגרת הפיזית (PFN).\n3.  **עדכון TLB:** ה-PTE שנמצא בטבלאות הדפים יוכנס ל-TLB. מכיוון שה-TLB מלא אסוציאטיבי, הוא יוכנס לאחת הכניסות (בהתאם למדיניות ההחלפה).\n4.  **גישה לזיכרון הפיזי:** המעבד משתמש ב-PFN שהתקבל וב-offset מכתובת X כדי לגשת לכתובת הפיזית ולקבל את הנתונים.\n\n**סה\"כ גישות לזיכרון הראשי (RAM):**\n*   4 גישות לטבלאות הדפים (אחת לכל רמה).\n*   1 גישה לנתונים עצמם.\n*   סה\"כ: 5 גישות לזיכרון הראשי.\n\n**תשובה:** 5 גישות לזיכרון הראשי.\n\n**1.3. רצף פעולות עבור גישות לכתובת וירטואלית Y (דף משותף, TLB Miss, Page Fault):**\n\n**עבור גישת P2 לכתובת Y:**\n1.  **גישה ל-TLB של P2:** המעבד מנסה לתרגם את הכתובת Y. TLB Miss (הדף אינו ב-TLB).\n2.  **גישה לטבלאות הדפים של P2 (4 רמות):** מערכת ההפעלה עוברת על טבלאות הדפים של P2.\n    *   4 גישות לזיכרון הראשי לקריאת ה-PTEs ברמות 1-4.\n    *   ה-PTE הסופי נמצא, אך Present=0 (הדף אינו בזיכרון הפיזי).\n3.  **Page Fault:** מכיוון ש-Present=0, תתרחש פסיקת דף (page fault).\n    *   **טיפול בפסיקת הדף:**\n        *   מערכת ההפעלה בוחרת מסגרת פיזית פנויה (או מפנה אחת, אם אין). נניח שהיא בוחרת מסגרת F.\n        *   מערכת ההפעלה טוענת את תוכן הדף המבוקש מהדיסק למסגרת F. זוהי **גישה לדיסק** (קריאה).\n        *   מערכת ההפעלה מעדכנת את ה-PTE של דף Y בטבלאות הדפים של P2 עם ה-PFN של מסגרת F, ומסמנת Present=1 ו-Dirty=0 (אם הדף לא השתנה).\n        *   **גישה לזיכרון הראשי** לעדכון ה-PTE.\n4.  **עדכון TLB של P2:** ה-PTE המעודכן (VPN של Y, PFN של F) מוכנס ל-TLB של P2.\n5.  **גישה לזיכרון הפיזי:** המעבד משתמש ב-PFN וב-offset כדי לגשת לכתובת הפיזית ולקבל את הנתונים.\n\n**סה\"כ עבור P2:**\n*   גישות ל-RAM: 4 (לטבלאות דפים) + 1 (לעדכון PTE) + 1 (לנתונים) = 6 גישות.\n*   גישות לדיסק: 1 (לטעינת הדף).\n\n**עבור גישת P3 לכתובת Y (אותו דף משותף):**\n1.  **גישה ל-TLB של P3:** המעבד מנסה לתרגם את הכתובת Y. TLB Miss (הדף אינו ב-TLB של P3).\n2.  **גישה לטבלאות הדפים של P3 (4 רמות):** מערכת ההפעלה עוברת על טבלאות הדפים של P3.\n    *   4 גישות לזיכרון הראשי לקריאת ה-PTEs ברמות 1-4. (חשוב לזכור ש-P3 צריך את ה-PTE שלו. הדף *כבר* בזיכרון הפיזי בזכות P2, לכן ה-PTE של P3 יהיה Present=1 ומצביע על אותה מסגרת F). \n    *   מערכת ההפעלה תמצא את ה-PTE המתאים שמצביע על אותה מסגרת פיזית F, עם Present=1.\n3.  **עדכון TLB של P3:** ה-PTE שנמצא (VPN של Y, PFN של F) מוכנס ל-TLB של P3.\n4.  **גישה לזיכרון הפיזי:** המעבד משתמש ב-PFN וב-offset כדי לגשת לכתובת הפיזית ולקבל את הנתונים.\n\n**סה\"כ עבור P3:**\n*   גישות ל-RAM: 4 (לטבלאות דפים) + 1 (לנתונים) = 5 גישות.\n*   גישות לדיסק: 0 (הדף כבר נטען ע\"י P2).\n\n**סה\"כ עבור שתי הגישות יחד:**\n*   סה\"כ גישות לזיכרון הראשי (RAM): 6 (עבור P2) + 5 (עבור P3) = 11 גישות.\n*   סה\"כ גישות לדיסק: 1 (עבור P2) + 0 (עבור P3) = 1 גישה.\n\n**תשובה:** 11 גישות לזיכרון הראשי ו-1 גישה לדיסק."}, "difficulty_estimation": "Hard", "_source_file": "0478__Memory_Management__Open__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:00:50", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Memory Management", "Segmentation", "Paging", "Virtual Memory", "TLB", "Page Fault"], "content": {"text": "נתונה מערכת הפעלה המשלבת ניהול זיכרון באמצעות סגמנטציה ודפדוף (Segmentation with Paging). מרחב הכתובות הוירטואלי הוא בגודל 64 ביט. גודל דף הוא 4KB.\n\nלכל תהליך יש טבלת סגמנטים (Segment Table - ST), כאשר כל כניסה בטבלת הסגמנטים (STE) היא בגודל 64 ביט ומכילה:\n*   כתובת בסיס פיזית לטבלת הדפים של הסגמנט (Page Table Base Address PFN) – מצביע למסגרת הפיזית הראשונה של טבלת הדפים.\n*   אורך הסגמנט בבתים (Segment Length) – מספר הבתים המקסימלי הנגיש בסגמנט.\n*   ביט Valid (V), ביט Read/Write (RW), ביט Execute (X) – שלושה ביטים עבור הרשאות וסטטוס.\n\nכל סגמנט ממופה באמצעות טבלת דפים לינארית משלו. כל כניסה בטבלת הדפים (PTE) היא בגודל 32 ביט ומכילה:\n*   מספר מסגרת פיזית (PFN).\n*   ביט Present (P), ביט Dirty (D), ביט Accessed (A) – שלושה ביטים עבור סטטוס הדף.\n\nבמערכת קיים TLB מאוחד (עבור סגמנטים ודפים) המכיל 128 כניסות, בשיטת מיפוי סט אסוציאטיבי בעל 4 דרכים (4-way set associative).\n\n", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "פרטו כיצד כתובת וירטואלית מתפרקת למרכיביה (מספר סגמנט, מספר דף בתוך סגמנט, היסט דף). הציגו את מספר הביטים לכל רכיב, ונמקו את גודלם.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "תארו את תהליך תרגום כתובת וירטואלית לכתובת פיזית במערכת זו, כולל כל הבדיקות הנדרשות (לדוגמה, חריגה מגבולות סגמנט, Page Fault, TLB Miss/Hit).", "code_snippet": null, "options": null}, {"id": "1.3", "text": "כמה גישות לזיכרון הראשי (Main Memory) וכמה גישות לדיסק יתבצעו במקרים הבאים, עבור גישת תהליך לכתובת וירטואלית מסוימת לצורך קריאה (Read)? הניחו שבכל מקרה של Page Fault נדרשת החלפת דף קיים בזיכרון, והדף המוחלף מלוכלך (Dirty). יש לכלול את הגישות לדיסק הנדרשות עבור טיפול ב-Page Fault.\nא. TLB Hit, והדף נמצא בזיכרון הפיזי.\nב. TLB Miss, אך הדף נמצא בזיכרון הפיזי.\nג. TLB Miss, והדף אינו נמצא בזיכרון הפיזי (Page Fault).", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון לשאלה:\n\n**1.1. פירוק כתובת וירטואלית למרכיביה:**\n*   **גודל כתובת וירטואלית:** 64 ביט.\n*   **גודל דף:** 4KB = 2^12 בתים. לכן, ההיסט בתוך הדף (Page Offset - PO) הוא **12 ביטים**.\n\n*   **גודל כניסה לטבלת דפים (PTE):** 32 ביט. מתוכם 3 ביטים עבור P, D, A. לכן, מספר המסגרת הפיזית (PFN) הוא 32 - 3 = **29 ביטים**.\n    *   מספר ביטים זה מגדיר את גודל הזיכרון הפיזי המקסימלי: 2^29 מסגרות * 2^12 בתים/מסגרת = 2^41 בתים (2 טרה-בייט). כלומר, כל מספר דף בתוך סגמנט (Page Number - PN) חייב להיות מיוצג על ידי לכל היותר 29 ביטים כדי שיוכל להיות ממופה למסגרת פיזית.\n    *   לכן, מספר הדף בתוך סגמנט (PN) הוא **29 ביטים**.\n\n*   **מספר הסגמנט (Segment Number - SN):** נותרו 64 ביט (סה\"כ) - 12 ביט (PO) - 29 ביט (PN) = **23 ביטים**.\n    *   זה מאפשר לכל תהליך עד 2^23 סגמנטים.\n\n**סיכום פירוק הכתובת הוירטואלית:**\n*   **Segment Number (SN): 23 ביטים**\n*   **Page Number (PN): 29 ביטים** (בתוך הסגמנט)\n*   **Page Offset (PO): 12 ביטים**\n\n**בדיקת עקביות עם STE:**\n*   **גודל כניסה לטבלת סגמנטים (STE):** 64 ביט.\n*   **PT_Base (PFN):** 29 ביטים (כפי שנקבע מגודל ה-PTE).\n*   **ביטים V, RW, X:** 3 ביטים.\n*   **נותר עבור Segment Length (SL):** 64 - 29 - 3 = **32 ביטים**.\n    *   לכן, אורך סגמנט מקסימלי (SL) הוא 2^32 בתים (4 ג'יגה-בייט). למרות שכתובת וירטואלית בתוך סגמנט (PN+PO) יכולה לכאורה לייצג 2^41 בתים, שדה ה-SL מגביל בפועל את הגודל המקסימלי של סגמנט ל-4GB.\n\n**1.2. תהליך תרגום כתובת וירטואלית לכתובת פיזית:**\nתהליך התרגום מתבצע באופן הבא:\n\n1.  **פירוק הכתובת הוירטואלית:** ה-CPU מפרק את הכתובת הוירטואלית (64 ביט) למספר סגמנט (SN), מספר דף בתוך סגמנט (PN) והיסט דף (PO) כפי שחושב בסעיף 1.1.\n\n2.  **בדיקת TLB:**\n    *   ה-CPU מנסה למצוא התאמה ב-TLB עבור הזוג (SN, PN).\n    *   **TLB Hit:** אם נמצאה כניסה מתאימה, ה-TLB מחזיר את מספר המסגרת הפיזית (PFN) ישירות, יחד עם ביטי ההרשאות והסטטוס (כגון P,D,A, RW, X). ה-CPU מבצע בדיקות הרשאה (לדוגמה, האם מותר לקרוא לכתובת זו לפי ביט RW). אם הכל תקין, הכתובת הפיזית מחושבת (PFN * Page_Size + PO) ומתבצעת גישה לזיכרון הפיזי. ביט Accessed (A) בכניסת ה-TLB מעודכן, וביט Dirty (D) מעודכן אם הגישה היא כתיבה.\n    *   **TLB Miss:** אם לא נמצאה כניסה מתאימה, ה-CPU ממשיך לגישה לטבלאות בזיכרון הראשי.\n\n3.  **גישה לטבלת הסגמנטים (ST):** (במקרה של TLB Miss)\n    *   ה-CPU משתמש במספר הסגמנט (SN) כדי לאתר את כניסת ה-STE המתאימה בטבלת הסגמנטים. כתובת הבסיס של טבלת הסגמנטים (STBR) נמצאת באוגר מיוחד ב-CPU.\n    *   ה-CPU קורא את ה-STE מכתובת: `STBR + SN * sizeof(STE)`. זוהי גישה לזיכרון הראשי.\n    *   **בדיקת Valid (V):** אם ביט V ב-STE הוא 0, מתרחשת פסיקת סגמנט (Segment Fault) – הסגמנט אינו חוקי.\n    *   **בדיקת אורך סגמנט:** ה-CPU בודק שההיסט בתוך הסגמנט (PN * Page_Size + PO) קטן מאורך הסגמנט (SL) הרשום ב-STE. אם ההיסט גדול או שווה ל-SL, מתרחשת פסיקת סגמנט (Segment Fault) – חריגה מגבולות הסגמנט.\n    *   **בדיקת הרשאות:** ה-CPU בודק את ביטי RW ו-X ב-STE מול סוג הגישה המבוקש (קריאה, כתיבה, הרצה). אם יש הפרת הרשאה, מתרחשת פסיקת הגנה (Protection Fault).\n    *   אם כל הבדיקות עברו בהצלחה, ה-CPU מחלץ את כתובת הבסיס הפיזית של טבלת הדפים של הסגמנט (PT_Base PFN) מה-STE.\n\n4.  **גישה לטבלת הדפים (PT):** (במקרה של TLB Miss)\n    *   ה-CPU משתמש במספר הדף (PN) כדי לאתר את כניסת ה-PTE המתאימה בטבלת הדפים של הסגמנט.\n    *   ה-CPU קורא את ה-PTE מכתובת: `PT_Base_PFN * Page_Size + PN * sizeof(PTE)`. זוהי גישה נוספת לזיכרון הראשי.\n    *   **בדיקת Present (P):** אם ביט P ב-PTE הוא 0, מתרחשת פסיקת דף (Page Fault).\n        *   **טיפול ב-Page Fault:** מערכת ההפעלה משתלטת. היא בוחרת מסגרת פיזית פנויה (או מפנה מסגרת קיימת לפי אלגוריתם החלפה). אם המסגרת המפונה הייתה 'מלוכלכת' (Dirty=1), תוכנה לדיסק. לאחר מכן, הדף המבוקש נטען מהדיסק למסגרת הפיזית החדשה. ה-PTE מעודכן (P=1, D=0, A=1, PFN חדש). ה-TLB מעודכן עם המיפוי החדש. הפקודה שגרמה ל-Page Fault מופעלת מחדש.\n    *   **בדיקת הרשאות:** ה-CPU בודק את ביטי ההרשאה ב-PTE מול סוג הגישה המבוקש. אם יש הפרת הרשאה, מתרחשת פסיקת הגנה.\n    *   אם הכל תקין, ה-CPU מחלץ את מספר המסגרת הפיזית (PFN) מה-PTE. ביט Accessed (A) ב-PTE מעודכן ל-1. אם הגישה היא כתיבה, ביט Dirty (D) ב-PTE מעודכן ל-1.\n    *   ה-TLB מתעדכן עם המיפוי החדש (SN, PN) -> PFN.\n\n5.  **חישוב כתובת פיזית וגישה לזיכרון הפיזי:**\n    *   הכתובת הפיזית מחושבת: `Physical_Address = PFN * Page_Size + PO`.\n    *   ה-CPU ניגש לזיכרון הפיזי בכתובת זו כדי לבצע את הפעולה המבוקשת (קריאה/כתיבה).\n\n**1.3. מספר גישות לזיכרון הראשי ולדיסק:**\n\n**א. TLB Hit, והדף נמצא בזיכרון הפיזי (גישת קריאה):**\n*   **גישות ל-TLB:** 1 (Hit).\n*   **גישות לזיכרון הראשי:** 1 (לנתון/פקודה עצמה). אין צורך לגשת לטבלאות בזיכרון הראשי.\n*   **גישות לדיסק:** 0.\n\n**ב. TLB Miss, אך הדף נמצא בזיכרון הפיזי (גישת קריאה):**\n*   **גישות ל-TLB:** 1 (Miss).\n*   **גישות לזיכרון הראשי:**\n    1.  קריאת STE מזיכרון ראשי (עבור SN).\n    2.  קריאת PTE מזיכרון ראשי (עבור PN).\n    3.  קריאת הנתון/פקודה עצמה מזיכרון ראשי.\n    *   **סה\"כ גישות לזיכרון הראשי: 3.** (לאחר מכן ה-TLB מתעדכן).\n*   **גישות לדיסק:** 0.\n\n**ג. TLB Miss, והדף אינו נמצא בזיכרון הפיזי (Page Fault, גישת קריאה):**\n*   **גישות ל-TLB:** 1 (Miss).\n*   **גישות לזיכרון הראשי:**\n    1.  קריאת STE מזיכרון ראשי (עבור SN).\n    2.  קריאת PTE מזיכרון ראשי (עבור PN) – גורם ל-Page Fault.\n    *   **בטיפול ב-Page Fault (בהנחה של דף מוחלף מלוכלך):**\n        3.  קריאת PTE של הדף המוחלף מזיכרון ראשי (כדי לבדוק P, D, A).\n        4.  קריאת תוכן הדף המוחלף מזיכרון ראשי (כדי לכתוב לדיסק).\n        5.  כתיבת PTE של הדף המוחלף לזיכרון ראשי (לסמן P=0).\n        6.  כתיבת תוכן הדף המבוקש לזיכרון ראשי (לאחר קריאה מהדיסק).\n        7.  כתיבת PTE של הדף המבוקש לזיכרון ראשי (לסמן P=1, D=0, A=1, PFN).\n    8.  קריאת הנתון/פקודה עצמה מזיכרון ראשי (לאחר שהדף נטען והפקודה מופעלת מחדש).\n    *   **סה\"כ גישות לזיכרון הראשי: 8.**\n*   **גישות לדיסק:**\n    1.  כתיבת הדף המוחלף לדיסק (כי הוא Dirty).\n    2.  קריאת הדף המבוקש מהדיסק.\n    *   **סה\"כ גישות לדיסק: 2.**"}, "difficulty_estimation": "Hard", "_source_file": "0479__Memory_Management__Open__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:29:31", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Memory Management", "Virtual Memory", "Paging", "Segmentation", "Address Translation", "TLB"], "content": {"text": "נתונה מערכת הפעלה המשתמשת במודל ניהול זיכרון היברידי המשלב סגמנטציה ודפדוף (Segmented Paging). במערכת זו, מרחב הכתובות הווירטואלי הוא 64 ביט, ומרחב הכתובות הפיזי הוא 48 ביט. גודל דף הוא 4KB.\n\nלכל סגמנט במערכת יש טבלת דפים רב-שכבתית משלו, עצמאית לחלוטין. טבלת מתארי הסגמנטים (Segment Descriptor Table - SDT) מכילה כניסות עבור כל הסגמנטים של תהליך, כאשר כל כניסה (Segment Descriptor Entry - SDE) מצביעה על בסיס טבלת הדפים מהרמה הראשונה של הסגמנט המתאים. גודל כל SDE הוא 16 בתים. גודל כל כניסה בטבלת דפים (Page Table Entry - PTE) הוא 8 בתים.\n\nנדרש שכל טבלת דפים (בכל רמה) וכן טבלת מתארי הסגמנטים (SDT) יאוחסנו בדף אחד בדיוק.\n\nיש לענות על השאלות הבאות:", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "תארו בפירוט את תהליך תרגום הכתובת המלא מכתובת וירטואלית (המורכבת מבורר סגמנט והיסט בתוך הסגמנט) לכתובת פיזית. ציינו את כל הגישות הנדרשות לזיכרון הראשי ול-TLB במקרה הגרוע ביותר (worst-case).", "code_snippet": null, "options": null}, {"id": "1.2", "text": "חשבו את הפרטים הבאים:\nא. כמה רמות של טבלאות דפים נדרשות עבור כל סגמנט?\nב. מהו המספר המקסימלי של סגמנטים שתהליך יכול להכיל?\nג. מהו הגודל המקסימלי של סגמנט בבתים?", "code_snippet": null, "options": null}, {"id": "1.3", "text": "דונו ביתרונות ובחסרונות של מודל ניהול זיכרון זה בהשוואה למערכת המשתמשת בדפדוף בלבד (Pure Paging) או סגמנטציה בלבד (Pure Segmentation). התייחסו למורכבות המימוש, ניצול הזיכרון (פנימי וחיצוני) והשפעה על ביצועים (כגון זמן גישה לזיכרון).", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\n**נתונים ראשוניים:**\n*   מרחב כתובות וירטואלי: 64 ביט.\n*   מרחב כתובות פיזי: 48 ביט.\n*   גודל דף: 4KB = 2^12 בתים. מכאן שההיסט בתוך הדף (offset) הוא 12 ביטים.\n*   גודל SDE: 16 בתים.\n*   גודל PTE: 8 בתים.\n*   כל טבלה (SDT או טבלת דפים) מאוחסנת בדף אחד בדיוק.\n\n**1.1 תהליך תרגום הכתובת:**\nכתובת וירטואלית מורכבת מבורר סגמנט (Segment Selector) והיסט בתוך הסגמנט (Offset). ההיסט בתוך הסגמנט מתורגם באמצעות טבלאות הדפים של הסגמנט.\n\n**שלבי התרגום:**\n1.  **פיצול הכתובת הווירטואלית:** המעבד מקבל כתובת וירטואלית של 64 ביט. יש לפצל אותה לבורר סגמנט (Segment Selector) ולהיסט בתוך הסגמנט (Segment Offset).\n2.  **גישה ל-SDT:**\n    *   בורר הסגמנט משמש כאינדקס לטבלת מתארי הסגמנטים (SDT). ה-SDT היא טבלה הממוקמת בזיכרון הראשי (בכתובת בסיס הידועה למערכת ההפעלה, למשל, מתוך רגיסטר).\n    *   המעבד ניגש ל-SDT כדי למצוא את ה-SDE המתאים.\n    *   **במקרה הגרוע ביותר (החטאות ב-TLB וב-Cache):** גישה ל-TLB (עבור מיפוי דף ה-SDT) – החטאה (miss), ואז גישה לזיכרון הראשי כדי להביא את ה-SDE. ה-SDE מכיל את כתובת הבסיס של טבלת הדפים מהרמה הראשונה של הסגמנט, וכן מידע על זכויות גישה, גודל הסגמנט וכו'.\n3.  **תרגום בתוך טבלת הדפים של הסגמנט:**\n    *   ההיסט בתוך הסגמנט (Segment Offset) מפולח למספרי דפים עבור כל רמה של טבלת הדפים, ולבסוף להיסט בתוך הדף (Page Offset).\n    *   **רמה 1:** ה-SDE נותן את כתובת הבסיס של טבלת הדפים ברמה הראשונה (לדוגמה, Page Directory Pointer Table). מספר הדף הראשון מתוך ה-Segment Offset משמש כאינדקס לטבלה זו.\n        *   **במקרה הגרוע ביותר:** גישה ל-TLB (עבור מיפוי דף טבלת הדפים ברמה 1) – החטאה, ואז גישה לזיכרון הראשי כדי להביא את ה-PTE ברמה 1. ה-PTE מצביע על טבלת הדפים ברמה הבאה.\n    *   **רמה 2:** מספר הדף השני משמש כאינדקס לטבלת הדפים ברמה השנייה.\n        *   **במקרה הגרוע ביותר:** גישה לזיכרון הראשי כדי להביא את ה-PTE ברמה 2. ה-PTE מצביע על טבלת הדפים ברמה הבאה.\n    *   **... עד לרמה האחרונה (6):** מספר הדף האחרון משמש כאינדקס לטבלת הדפים ברמה האחרונה.\n        *   **במקרה הגרוע ביותר:** גישה לזיכרון הראשי כדי להביא את ה-PTE ברמה האחרונה. ה-PTE הזה מכיל את מספר המסגרת הפיזית (Page Frame Number - PFN).\n    *   **בכל שלב:** יש לבדוק את ביט ה-Present (P) ב-PTE. אם P=0, מתרחשת Page Fault. אם ה-PTE אינו Valid (V=0), זו שגיאה. יש גם לבדוק את זכויות הגישה.\n4.  **הרכבת הכתובת הפיזית:** מספר המסגרת הפיזית (PFN) שהתקבל מה-PTE האחרון, יחד עם ההיסט בתוך הדף (Page Offset) מתוך הכתובת הווירטואלית המקורית, מרכיבים את הכתובת הפיזית הסופית.\n\n**מספר גישות לזיכרון הראשי ול-TLB במקרה הגרוע ביותר (Cache/TLB Miss):**\n*   **גישות ל-TLB:** 2 (אחת עבור מיפוי דף ה-SDT, ואחת עבור מיפוי דף הנתונים הסופי). כל גישה ל-TLB מניחה החטאה.\n*   **גישות לזיכרון הראשי:**\n    *   1 גישה ל-SDT כדי לקרוא את ה-SDE.\n    *   N גישות לטבלאות הדפים (אחת לכל רמה), כאשר N הוא מספר רמות טבלאות הדפים (6, כפי שיחושב בסעיף 1.2.א).\n    *   1 גישה עבור הנתון עצמו לאחר תרגום הכתובת.\n    *   **סה\"כ:** 1 (SDE) + 6 (PTEs) + 1 (נתון) = 8 גישות לזיכרון הראשי.\n\n**1.2 חישובים:**\n*   **גודל דף:** 4KB = 2^12 בתים.\n*   **מספר כניסות בדף:**\n    *   עבור SDEs: גודל דף / גודל SDE = 4096 / 16 = 256 כניסות.\n    *   עבור PTEs: גודל דף / גודל PTE = 4096 / 8 = 512 כניסות.\n*   **היסט בתוך הדף (Offset):** 12 ביטים.\n\n**א. כמה רמות של טבלאות דפים נדרשות עבור כל סגמנט?**\n*   מרחב כתובות וירטואלי 64 ביט. ההיסט בתוך הדף הוא 12 ביטים.\n*   לכן, מספר הביטים עבור ה-VPN (Virtual Page Number) הוא 64 - 12 = 52 ביטים.\n*   כל רמה של טבלת דפים יכולה למפות 512 כניסות, כלומר 2^9 דפים.\n*   לכן, כל רמה 'בולעת' 9 ביטים ממספר ה-VPN.\n*   מספר הרמות הנדרשות: ceil(52 ביטים / 9 ביטים לרמה) = ceil(5.77) = 6 רמות.\n*   **תשובה:** 6 רמות של טבלאות דפים.\n\n**ב. מהו המספר המקסימלי של סגמנטים שתהליך יכול להכיל?**\n*   טבלת מתארי הסגמנטים (SDT) מאוחסנת בדף אחד בדיוק.\n*   כל דף יכול להכיל 256 כניסות SDE.\n*   לכן, תהליך יכול להכיל מקסימום 256 סגמנטים.\n*   **תשובה:** 256 סגמנטים.\n\n**ג. מהו הגודל המקסימלי של סגמנט בבתים?**\n*   מספר ביטים עבור ה-VPN בתוך סגמנט הוא 52 ביטים (64 ביט וירטואלי - 12 ביט היסט).\n*   הגודל המקסימלי של סגמנט נקבע על ידי מרחב הכתובות הווירטואלי שניתן למפות. מאחר שה-VPN הוא 52 ביטים, ניתן למפות 2^52 דפים.\n*   גודל מקסימלי של סגמנט = מספר דפים * גודל דף = 2^52 * 2^12 = 2^64 בתים.\n*   **תשובה:** הגודל המקסימלי של סגמנט הוא 2^64 בתים (כל מרחב הכתובות הווירטואלי).\n\n**1.3 יתרונות וחסרונות בהשוואה למודלים אחרים:**\n\n**יתרונות:**\n1.  **הגנה מוגברת וגמישות:**\n    *   **הגנה:** סגמנטציה מאפשרת הגנה ברמת יחידות לוגיות (קוד, נתונים, מחסנית), כאשר כל סגמנט יכול לקבל הרשאות גישה שונות (קריאה, כתיבה, הרצה). בנוסף, ניתן להגדיר גודל מקסימלי לכל סגמנט.\n    *   **שיתוף קל יותר:** סגמנטים מאפשרים שיתוף קל יותר של אזורי זיכרון בין תהליכים, למשל, סגמנט קוד משותף. כל תהליך יכול למפות את אותו סגמנט לתוך מרחב הכתובות שלו עם טבלת דפים משלו (או משותפת), מה שמפשט את הניהול.\n    *   **ניהול זיכרון לוגי:** המפתחים יכולים לחשוב על הזיכרון כיחידות לוגיות משמעותיות, במקום רצף ליניארי של דפים.\n2.  **טיפול בפירבור (Fragmentation):**\n    *   **פירבור חיצוני:** הדפדוף מטפל ביעילות בפירבור חיצוני. סגמנטים לא צריכים להיות רציפים בזיכרון הפיזי, וגם הדפים בתוך סגמנט לא צריכים להיות רציפים.\n    *   **פירבור פנימי:** נשאר פירבור פנימי ברמת הדף האחרון של כל סגמנט.\n\n**חסרונות:**\n1.  **מורכבות מימוש גבוהה:**\n    *   המערכת דורשת ניהול של שתי רמות של טבלאות: טבלת מתארי סגמנטים (SDT) וטבלאות דפים רב-שכבתיות לכל סגמנט. זה מגדיל את מורכבות מערכת ההפעלה הן במימוש והן בתחזוקה.\n    *   תהליך תרגום הכתובת ארוך ומורכב יותר (ראו סעיף 1.1), ודורש יותר גישות לזיכרון הראשי.\n2.  **עלויות ביצועים (Performance Overhead):**\n    *   **זמן גישה לזיכרון:** כל גישה לכתובת וירטואלית דורשת מספר רב של גישות לזיכרון הראשי (SDT + N רמות של טבלאות דפים). זהו חיסרון משמעותי בהשוואה לדפדוף בלבד, שבו נדרשות N גישות בלבד, או סגמנטציה בלבד (שבה נדרשת גישה אחת לטבלת הסגמנטים). גם עם TLB, מספר ההחטאות ל-TLB עלול להיות גבוה יותר, והעלות של כל החטאה יקרה יותר.\n    *   **TLB:** ה-TLB חייב להיות גדול ומורכב יותר כדי לטפל גם במיפויי סגמנטים וגם במיפויי דפים, או שיהיו שני TLBs נפרדים. החטאות ב-TLB יהיו יקרות יותר בגלל המספר הרב של גישות לזיכרון הראשי הנדרשות כדי לטעון מיפוי חדש.\n3.  **ניצול זיכרון (Memory Overhead):**\n    *   **טבלאות:** ישנה עלות זיכרון משמעותית עבור טבלאות הדפים וה-SDT. לכל סגמנט יש היררכיית טבלאות דפים משלו, מה שיכול לצרוך כמות גדולה של זיכרון, במיוחד אם יש הרבה סגמנטים קטנים או סגמנטים עם מרחב כתובות דליל. אמנם כל טבלה מאוחסנת בדף אחד, אך מספר הטבלאות הכולל יכול להיות גדול.\n    *   **פירבור פנימי:** עדיין קיים פירבור פנימי בדפים האחרונים של כל סגמנט.\n\n**בהשוואה למודלים אחרים:**\n*   **דפדוף בלבד (Pure Paging):** פשוט יותר למימוש, תרגום כתובת מהיר יותר (פחות גישות לזיכרון אם אין סגמנטים), וניצול זיכרון טוב יותר עבור טבלאות (לרוב טבלת דפים אחת לכל תהליך). החיסרון הוא שאין תמיכה מובנית במבנה לוגי של התוכנית (סגמנטים) ופחות גמישות בהגנה ובשיתוף יחידות לוגיות.\n*   **סגמנטציה בלבד (Pure Segmentation):** תומך במבנה לוגי ובהגנה ברמת סגמנטים, אך סובל מפירבור חיצוני (External Fragmentation) ודורש אלגוריתמי הקצאת זיכרון מורכבים יותר עבור הסגמנטים. תרגום כתובת מהיר יותר (גישה אחת לטבלת סגמנטים).\n\n**לסיכום:** מודל Segmented Paging מציע שילוב של יתרונות משני המודלים (הגנה לוגית וטיפול בפירבור חיצוני), אך מגיע עם עלות משמעותית במורכבות המימוש, במספר גישות הזיכרון הנדרשות לתרגום כתובת, ובצריכת זיכרון עבור מבני הנתונים. הוא מתאים למערכות שבהן דרישות הגנה וארגון לוגי הן קריטיות, ומוכנות לשלם מחיר בביצועים ובמורכבות."}, "difficulty_estimation": "Hard", "_source_file": "0480__Memory_Management__Open__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:30:18", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Memory Management"], "content": {"text": "נתונה התוכנית הבאה ב-C:\n\nהסבירו בקצרה היכן מאוחסנים המשתנים `global_var`, `stack_var`, והזיכרון שהוקצה עבור `heap_ptr` במרחב הכתובות של התהליך.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\nint global_var = 10;\n\nvoid func() {\n    int stack_var = 20;\n    int* heap_ptr = (int*)malloc(sizeof(int));\n    if (heap_ptr == NULL) {\n        perror(\"malloc failed\");\n        exit(EXIT_FAILURE);\n    }\n    *heap_ptr = 30;\n    printf(\"Global var address: %p\\n\", &global_var);\n    printf(\"Stack var address: %p\\n\", &stack_var);\n    printf(\"Heap var address: %p\\n\", (void*)heap_ptr);\n    free(heap_ptr);\n}\n\nint main() {\n    func();\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "המשתנה `global_var` הוא משתנה גלובלי מאותחל, ולכן הוא מאוחסן בקטע הנתונים (Data Segment) של מרחב הכתובות של התהליך.\nהמשתנה `stack_var` הוא משתנה מקומי לפונקציה `func`, ולכן הוא מאוחסן על המחסנית (Stack) של התהליך.\nהזיכרון שהוקצה באמצעות `malloc` עבור `heap_ptr` (כלומר, המיקום שאליו `heap_ptr` מצביע) מאוחסן בערימה (Heap) של התהליך. `heap_ptr` עצמו (הפוינטר) הוא משתנה מקומי לפונקציה `func` ולכן מאוחסן על המחסנית, אך השאלה התייחסה לזיכרון *שהוקצה עבורו*, כלומר הזיכרון אליו הוא מצביע."}, "difficulty_estimation": "Easy", "_source_file": "0481__Memory_Management__CodeAnalysis__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:02:36", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Memory Management", "Virtual Memory", "Paging", "Heap"], "content": {"text": "נתונה התוכנית הבאה בשפת C:\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n\nint main() {\n    int* arr;\n    // Allocate space for 1000 integers\n    arr = (int*) malloc(1000 * sizeof(int));\n\n    if (arr == NULL) {\n        printf(\"Memory allocation failed!\\n\");\n        return 1;\n    }\n\n    // Access some elements to ensure pages are touched\n    for (int i = 0; i < 10; ++i) {\n        arr[i] = i;\n    }\n\n    printf(\"Array allocated and accessed.\\n\");\n\n    free(arr);\n    return 0;\n}\n```\n\nבהנחה שגודל דף זיכרון במערכת הוא 4KB (קילובייט) וכי `sizeof(int)` הוא 4 בתים.\nכמה דפי זיכרון וירטואליים לכל הפחות נדרשים עבור הנתונים שהוקצו על ידי קריאת `malloc` בשורה 7?\nיש להתעלם מזיכרון הנדרש עבור קוד התוכנית, המחסנית, הערימה (למעט הנתונים שהוקצו ב-malloc), וטבלת הדפים. התייחסו אך ורק לזיכרון שהוקצה ישירות עבור המערך `arr`.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכנית מקצה זיכרון עבור 1000 מספרים שלמים (integers) באמצעות `malloc`.\nגודלו של טיפוס `int` הוא 4 בתים.\nלכן, סך הזיכרון המוקצה למערך `arr` הוא: `1000 * 4 בתים = 4000 בתים`.\n\nגודל דף זיכרון נתון כ-4KB, שזה שווה ל-`4 * 1024 בתים = 4096 בתים`.\n\nמכיוון ש-4000 בתים (הזיכרון המוקצה) קטנים מ-4096 בתים (גודל דף בודד), כל הזיכרון שהוקצה עבור המערך `arr` יכול להיכנס לדף זיכרון וירטואלי אחד בלבד.\n\nלכן, נדרש דף זיכרון וירטואלי אחד לכל הפחות עבור נתוני המערך.", "code_snippet": null}, "difficulty_estimation": "Easy", "_source_file": "0482__Memory_Management__CodeAnalysis__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:02:47", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Memory Management", "Dynamic Memory Allocation", "Memory Leaks"], "content": {"text": "נתונה תוכנית ה-C הבאה. עברו על הקוד וענו על השאלות הבאות:\n1. מה הפלט של התוכנית כאשר היא רצה?\n2. האם קיימת בעיה כלשהי בתוכנית? אם כן, תארו אותה במפורט והסבירו מדוע היא מתרחשת.\n3. הציעו תיקון לבעיה שזיהיתם.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\nvoid allocate_and_print() {\n    int* ptr = (int*)malloc(sizeof(int));\n    if (ptr == NULL) {\n        perror(\"malloc failed\");\n        return;\n    }\n    *ptr = 10;\n    printf(\"Value: %d\\n\", *ptr);\n    // Missing free(ptr);\n}\n\nint main() {\n    for (int i = 0; i < 3; ++i) {\n        allocate_and_print();\n    }\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכנית תדפיס:\nValue: 10\nValue: 10\nValue: 10\n\nכן, קיימת בעיה של דליפת זיכרון (memory leak). בפונקציה `allocate_and_print`, אנו מקצים זיכרון באמצעות `malloc` עבור משתנה מסוג `int`. לאחר השימוש בזיכרון והדפסת הערך, הזיכרון שהוקצה אינו משוחרר באמצעות `free`. מכיוון שהפונקציה נקראת בלולאה שלוש פעמים, בכל קריאה מוקצה זיכרון חדש, והזיכרון שהוקצה בקריאות קודמות הופך לבלתי נגיש (unreachable) אך נשאר תפוס, מה שמוביל לדליפת זיכרון. לאורך זמן, בריצות ארוכות או בהקצאות גדולות, הדבר יכול להוביל לצריכת זיכרון מופרזת ואף לקריסת המערכת עקב חוסר בזיכרון זמין.\n\nכדי לתקן את הבעיה, יש לשחרר את הזיכרון שהוקצה באמצעות `free(ptr);` לפני שהפונקציה `allocate_and_print` מסתיימת.\n\nהקוד המתוקן ייראה כך:\n```c\n#include <stdio.h>\n#include <stdlib.h>\n\nvoid allocate_and_print() {\n    int* ptr = (int*)malloc(sizeof(int));\n    if (ptr == NULL) {\n        perror(\"malloc failed\");\n        return;\n    }\n    *ptr = 10;\n    printf(\"Value: %d\\\\n\", *ptr);\n    free(ptr); // תיקון: שחרור הזיכרון\n}\n\nint main() {\n    for (int i = 0; i < 3; ++i) {\n        allocate_and_print();\n    }\n    return 0;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0483__Memory_Management__CodeAnalysis__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:03:06", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Memory Management"], "content": {"text": "נתונה תוכנית ה-C הבאה. ציין עבור כל אחד מהמשתנים הבאים היכן הוא מאוחסן בזיכרון (מחסנית (Stack), ערימה (Heap), או מקטע נתונים (Data Segment / BSS)). הסבר בקצרה את בחירתך:\n1.  `global_var`\n2.  `static_var`\n3.  `local_main_var`\n4.  `local_func_var`\n5.  הזיכרון שהוקצה על ידי `malloc` (שאליו מצביע `heap_ptr`)\n6.  המשתנה `heap_ptr` עצמו", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\nint global_var = 10; // Global variable\nstatic int static_var = 20; // Static global variable\n\nvoid func() {\n    int local_func_var = 30; // Local variable in func\n    printf(\"Address of local_func_var in func: %p\\n\", (void*)&local_func_var);\n}\n\nint main() {\n    int local_main_var = 40; // Local variable in main\n    char* heap_ptr = (char*)malloc(100); // Dynamically allocated memory\n\n    printf(\"Address of global_var: %p\\n\", (void*)&global_var);\n    printf(\"Address of static_var: %p\\n\", (void*)&static_var);\n    printf(\"Address of local_main_var: %p\\n\", (void*)&local_main_var);\n    printf(\"Address of heap_ptr (pointer itself): %p\\n\", (void*)&heap_ptr);\n    printf(\"Address pointed to by heap_ptr (heap memory): %p\\n\", (void*)heap_ptr);\n\n    func();\n\n    free(heap_ptr);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "להלן פירוט מיקום האחסון בזיכרון עבור כל אחד מהמשתנים:\n\n1.  `global_var`: מאוחסן במקטע הנתונים (Data Segment).\n    **הסבר:** זהו משתנה גלובלי מאותחל, והוא נטען לזיכרון כחלק ממקטע הנתונים של התוכנית בזמן טעינה.\n\n2.  `static_var`: מאוחסן במקטע הנתונים (Data Segment).\n    **הסבר:** זהו משתנה סטטי גלובלי מאותחל. משתנים סטטיים (בין אם גלובליים ובין אם מקומיים) מאוחסנים במקטע הנתונים (או במקטע BSS אם אינם מאותחלים), ומחזיקים את ערכם לאורך כל חיי התוכנית.\n\n3.  `local_main_var`: מאוחסן במחסנית (Stack).\n    **הסבר:** זהו משתנה מקומי לפונקציה `main`. משתנים מקומיים (אוטומטיים) נוצרים על המחסנית כאשר הפונקציה נקראת ונמחקים כאשר הפונקציה מסתיימת.\n\n4.  `local_func_var`: מאוחסן במחסנית (Stack).\n    **הסבר:** בדומה ל-`local_main_var`, זהו משתנה מקומי לפונקציה `func` ונוצר על המחסנית כאשר `func` נקראת.\n\n5.  הזיכרון שהוקצה על ידי `malloc` (שאליו מצביע `heap_ptr`): מאוחסן בערימה (Heap).\n    **הסבר:** פונקציית `malloc` משמשת להקצאת זיכרון דינמי בזמן ריצה, וזיכרון זה מוקצה מהערימה. יש לשחרר זיכרון זה במפורש באמצעות `free`.\n\n6.  המשתנה `heap_ptr` עצמו: מאוחסן במחסנית (Stack).\n    **הסבר:** `heap_ptr` הוא משתנה מצביע מקומי לפונקציה `main`. כמו כל משתנה מקומי אחר, הוא מאוחסן על המחסנית. רק הזיכרון שאליו הוא מצביע נמצא בערימה."}, "difficulty_estimation": "Easy", "_source_file": "0484__Memory_Management__CodeAnalysis__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:03:24", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Memory Management", "Heap", "malloc", "free"], "content": {"text": "נתונה התוכנית הבאה בשפת C. עיין בקוד וענה על השאלה:\n\nלאחר ביצוע הקריאה לפונקציה `free(ptr)` בשורה 12, מהו המצב הנכון ביותר לגבי הזיכרון שהיה מצביע אליו `ptr`?", "code_snippet": "#include <stdio.h>\n#include <stdlib.h> // For malloc and free\n\nint main() {\n    int* ptr = (int*) malloc(sizeof(int));\n    if (ptr == NULL) {\n        printf(\"Memory allocation failed!\\n\");\n        return 1;\n    }\n\n    *ptr = 10;\n    printf(\"Value before free: %d\\n\", *ptr);\n\n    free(ptr); // Line 12\n    printf(\"Memory freed.\\n\");\n\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הקריאה לפונקציה `free(ptr)` משחררת את הזיכרון שהוקצה בעבר באמצעות `malloc` בחזרה לבריכת הזיכרון (heap) של התהליך. זיכרון זה מסומן כעת כזמין להקצאות עתידיות על ידי `malloc`. חשוב לציין שהזיכרון אינו מוחזר בהכרח מיד למערכת ההפעלה, אלא נשאר זמין לשימוש פנימי של מנהל הזיכרון של התהליך. הגישה לזיכרון זה לאחר שחרורו (use-after-free) היא התנהגות בלתי מוגדרת (undefined behavior) ויכולה להוביל לקריסות או פרצות אבטחה."}, "difficulty_estimation": "Easy", "_source_file": "0485__Memory_Management__CodeAnalysis__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:03:38", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Memory Management", "Heap", "Memory Leaks", "C/C++"], "content": {"text": "נתונה התוכנית הבאה בשפת C. עיין בקוד וענה על השאלה:\n\nמהי הבעיה העיקרית עם ניהול הזיכרון בתוכנית זו? הסבר בפירוט כיצד הבעיה מתרחשת ומהן ההשלכות האפשריות שלה.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\nvoid allocate_and_print() {\n    int* ptr = (int*)malloc(sizeof(int));\n    if (ptr == NULL) {\n        printf(\"Memory allocation failed!\\n\");\n        return;\n    }\n    *ptr = 100;\n    printf(\"Value: %d\\n\", *ptr);\n    // חסרה קריאה ל-free(ptr);\n}\n\nint main() {\n    allocate_and_print();\n    allocate_and_print();\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הבעיה העיקרית בתוכנית זו היא דליפת זיכרון (memory leak). הפונקציה `allocate_and_print` מקצה זיכרון על הערימה (heap) באמצעות `malloc` עבור משתנה מסוג `int` אך אינה משחררת אותו באמצעות `free` לפני שהיא מסיימת את ריצתה. בכל פעם שהפונקציה נקראת (כמו במקרה זה, פעמיים מתוך `main`), היא מקצה בלוק זיכרון חדש. המצביע `ptr` הוא משתנה מקומי לפונקציה, וכאשר הפונקציה מסיימת את ריצתה, המצביע הזה נעלם (מפונה מהמחסנית). כתוצאה מכך, הכתובת לבלוק הזיכרון שהוקצה הולכת לאיבוד, והזיכרון נשאר תפוס על הערימה אך אינו נגיש יותר לתוכנית, ולא ניתן לשחררו. לאורך זמן, אם התוכנית הייתה ממשיכה לקרוא לפונקציה זו שוב ושוב, היא הייתה צורכת יותר ויותר זיכרון פנוי מהמערכת, מה שעלול להוביל לחוסר זיכרון (Out Of Memory) ולגרום לקריסת התוכנית או להאט את ביצועי המערכת כולה.", "code_snippet": "// תיקון לבעיית דליפת הזיכרון:\n#include <stdio.h>\n#include <stdlib.h>\n\nvoid allocate_and_print() {\n    int* ptr = (int*)malloc(sizeof(int));\n    if (ptr == NULL) {\n        printf(\"Memory allocation failed!\\n\");\n        return;\n    }\n    *ptr = 100;\n    printf(\"Value: %d\\n\", *ptr);\n    free(ptr); // שחרור הזיכרון שהוקצה\n}\n\nint main() {\n    allocate_and_print();\n    allocate_and_print();\n    return 0;\n}"}, "difficulty_estimation": "Easy", "_source_file": "0486__Memory_Management__CodeAnalysis__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:03:54", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Memory Management", "Stack", "Heap", "Memory Leak", "C/C++"], "content": {"text": "נתונה תוכנית ה-C הבאה. נתח את השימוש בזיכרון בתוכנית זו. ציין אילו סוגי זיכרון (לדוגמה: מחסנית, ערימה, גלובלי) משמשים לאחסון המשתנים השונים, והאם התוכנית סובלת מדליפת זיכרון. אם קיימת דליפת זיכרון, הסבר היכן היא מתרחשת ומדוע.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h> // For malloc and free\n\nvoid allocate_and_lose() {\n    int *data = (int *)malloc(10 * sizeof(int)); // Allocate 40 bytes\n    if (data == NULL) {\n        printf(\"Memory allocation failed!\\n\");\n        return;\n    }\n    // No free(data) here\n}\n\nint main() {\n    int stack_array[5]; // Allocate 20 bytes on stack\n    for (int i = 0; i < 5; ++i) {\n        stack_array[i] = i;\n    }\n\n    int *heap_ptr = (int *)malloc(20 * sizeof(int)); // Allocate 80 bytes\n    if (heap_ptr == NULL) {\n        printf(\"Memory allocation failed!\\n\");\n        return 1;\n    }\n    for (int i = 0; i < 20; ++i) {\n        heap_ptr[i] = i * 2;\n    }\n\n    allocate_and_lose(); // This call will cause a leak\n\n    free(heap_ptr); // Correctly free memory allocated in main\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הניתוח: \n1.  **`stack_array`**: משתנה זה הוא מערך מקומי (local array) המוגדר בתוך הפונקציה `main`. הוא מוקצה על **המחסנית (Stack)**. גודלו ידוע בזמן קומפילציה, והוא משוחרר אוטומטית כאשר הפונקציה `main` מסתיימת.\n2.  **`heap_ptr`**: זהו מצביע (pointer) מקומי המוגדר בתוך הפונקציה `main`, ולכן הוא עצמו מוקצה על **המחסנית (Stack)**. אולם, הזיכרון שאליו הוא מצביע (20 אינטגרים) מוקצה באופן דינמי על **הערימה (Heap)** באמצעות קריאה ל-`malloc`. זיכרון זה משוחרר כראוי באמצעות `free(heap_ptr)` לפני סיום התוכנית.\n3.  **`data`** (בתוך הפונקציה `allocate_and_lose`): זהו מצביע מקומי המוגדר בתוך הפונקציה `allocate_and_lose`, ולכן הוא עצמו מוקצה על **המחסנית (Stack)**. הזיכרון שאליו הוא מצביע (10 אינטגרים) מוקצה באופן דינמי על **הערימה (Heap)** באמצעות קריאה ל-`malloc`.\n\n**דליפת זיכרון (Memory Leak):**\nהתוכנית **סובלת מדליפת זיכרון**.\nהדליפה מתרחשת בפונקציה `allocate_and_lose`. בתוך פונקציה זו, מוקצה זיכרון על הערימה באמצעות `malloc` עבור המצביע `data`. אולם, הפונקציה מסתיימת מבלי לבצע קריאה ל-`free(data)`. כתוצאה מכך, הזיכרון שהוקצה על הערימה נשאר תפוס על ידי התהליך, אך המצביע `data` (שהיה על המחסנית) נעלם עם סיום הפונקציה. אין עוד דרך לגשת לזיכרון שהוקצה או לשחרר אותו, ולכן הוא הופך לזיכרון דולף (leaked memory) שאינו בשימוש ואינו ניתן לשחרור עד לסיום התהליך כולו."}, "difficulty_estimation": "Easy", "_source_file": "0487__Memory_Management__CodeAnalysis__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:04:08", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Memory Management", "Stack vs Heap", "Dangling Pointers", "Undefined Behavior"], "content": {"text": "נתונה תוכנית ה-C הבאה. מהי הבעיה העיקרית בקוד הנתון, וכיצד היא קשורה לניהול זיכרון? הסבר מהו הפלט הצפוי של התוכנית (או מדוע הוא אינו מוגדר), וכיצד ניתן לתקן את הקוד כך שיפעל כראוי ויחזיר מערך שלם.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\nint* createArray() {\n    int arr[5]; // Allocated on the stack\n    for (int i = 0; i < 5; i++) {\n        arr[i] = i * 10;\n    }\n    printf(\"Inside createArray: arr[0] = %d\\n\", arr[0]);\n    return arr; // Returning address of a local stack variable\n}\n\nint main() {\n    int* myArray = createArray();\n    printf(\"Back in main: myArray[0] = %d\\n\", myArray[0]);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הבעיה העיקרית בקוד היא ניסיון להחזיר מצביע למערך מקומי שהוקצה על המחסנית (stack). כאשר הפונקציה `createArray` מסיימת את ריצתה, מסגרת המחסנית שלה נמחקת, והזיכרון שהוקצה למערך `arr` הופך להיות לא חוקי. לכן, המצביע `myArray` ב-`main` הוא מצביע תלוי (dangling pointer) המצביע לזיכרון שכבר אינו מובטח להיות תקף או להכיל את הערכים המקוריים. גישה לזיכרון זה היא התנהגות בלתי מוגדרת (Undefined Behavior).\n\n**הפלט הצפוי:**\nהשורה הראשונה `Inside createArray: arr[0] = 0` תמיד תודפס. \nהשורה השנייה `Back in main: myArray[0] = ...` תדפיס ערך בלתי מוגדר. במערכות מסוימות, ייתכן שתראה 0 (אם זיכרון המחסנית לא נדרס מיד), אך זה אינו מובטח. ייתכנו גם קריסות (segmentation fault) או ערכים אקראיים. לכן, הפלט אינו מוגדר ואינו צפוי להיות עקבי.\n\n**תיקון הקוד:**\nכדי לתקן את הקוד, יש להקצות את המערך באופן דינמי על הערימה (heap) באמצעות `malloc` (או `new` ב-C++), ולזכור לשחרר את הזיכרון באמצעות `free` כאשר הוא אינו נחוץ יותר, כדי למנוע דליפת זיכרון.\n\n**קוד מתוקן לדוגמה:**\n```c\n#include <stdio.h>\n#include <stdlib.h> // For malloc and free\n\nint* createArray() {\n    int* arr = (int*)malloc(5 * sizeof(int)); // Allocated on the heap\n    if (arr == NULL) {\n        perror(\"Failed to allocate memory\");\n        exit(EXIT_FAILURE);\n    }\n    for (int i = 0; i < 5; i++) {\n        arr[i] = i * 10;\n    }\n    printf(\"Inside createArray: arr[0] = %d\\n\", arr[0]);\n    return arr; // Returning address of heap-allocated memory\n}\n\nint main() {\n    int* myArray = createArray();\n    if (myArray != NULL) {\n        printf(\"Back in main: myArray[0] = %d\\n\", myArray[0]);\n        free(myArray); // Free the allocated memory\n        myArray = NULL; // Prevent dangling pointer\n    }\n    return 0;\n}\n```", "difficulty_estimation": "Easy"}, "_source_file": "0488__Memory_Management__CodeAnalysis__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:04:26", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Memory Management", "Paging", "Locality of Reference", "Page Faults"], "content": {"text": "נתונה תוכנית C המשתמשת במטריצה דו-ממדית גדולה. המערכת מריצה את התוכנית על מעבד יחיד. גודל דף זיכרון הוא 4KB. גודל משתנה `int` הוא 4 בתים. המטריצה `matrix` מוגדרת כמשתנה גלובלי. נניח שבהתחלה אף דף של המטריצה אינו נמצא בזיכרון הפיזי (כלומר, כל גישה לדף חדש תגרום ל-Page Fault). כמו כן, נניח שגודל הזיכרון הפיזי הזמין לתהליך הוא 100 דפים בלבד, ושמדיניות החלפת הדפים היא LRU (Least Recently Used).\n\nהקוד הבא מראה שתי פונקציות המגשות לאלמנטים במטריצה בסדרים שונים.\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n\n#define ROWS 1024\n#define COLS 1024\n#define PAGE_SIZE_BYTES 4096 // 4 KB\n#define INT_SIZE 4           // size of int in bytes\n\nint matrix[ROWS][COLS]; // Global static array\n\nvoid access_row_major() {\n    for (int i = 0; i < ROWS; ++i) {\n        for (int j = 0; j < COLS; ++j) {\n            matrix[i][j] = i * COLS + j;\n        }\n    }\n}\n\nvoid access_col_major() {\n    for (int j = 0; j < COLS; ++j) {\n        for (int i = 0; i < ROWS; ++i) {\n            matrix[i][j] = i * COLS + j;\n        }\n    }\n}\n\nint main() {\n    access_row_major();\n    access_col_major();\n    return 0;\n}\n```\n\nנתחו את הקוד הנתון וענו על השאלות הבאות:\n1.  כמה Page Faults סך הכל יתרחשו במהלך קריאה לפונקציה `access_row_major()`? נמקו.\n2.  כמה Page Faults סך הכל יתרחשו במהלך קריאה לפונקציה `access_col_major()`? נמקו.\n3.  הסבירו מדוע יש הבדל (אם יש) במספר ה-Page Faults בין שתי הפונקציות, ואיזה עיקרון של ניהול זיכרון מודגם כאן.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "חישובים מקדימים:\n*   גודל `int`: 4 בתים.\n*   גודל דף: 4096 בתים.\n*   מספר משתני `int` לדף: 4096 / 4 = 1024 משתני `int`.\n*   ממדי המטריצה: `ROWS = 1024`, `COLS = 1024`.\n*   גודל שורה במטריצה: `COLS * INT_SIZE = 1024 * 4 = 4096` בתים. כלומר, שורה אחת תופסת בדיוק דף אחד.\n*   מספר הדפים הכולל של המטריצה: `ROWS` (1024 שורות) * 1 דף לשורה = 1024 דפים.\n*   מספר פריימים פיזיים זמינים: 100.\n*   מדיניות החלפת דפים: LRU.\n\n1.  **Page Faults בפונקציה `access_row_major()`:**\n    בפונקציה זו, הגישה למטריצה מתבצעת בסדר שורה-אחר-שורה (`matrix[i][j]`). מכיוון שכל שורה תופסת בדיוק דף אחד והמטריצה מאוחסנת בזיכרון בסדר שורות (row-major order), גישה ל-`matrix[i][j]` עבור `j` משתנה (כש-`i` קבוע) תמיד תישאר באותו דף. רק כאשר `i` משתנה, אנו עוברים לשורה חדשה, ולכן לדף חדש.\n    *   עבור `i=0`, אנו ניגשים לראשונה לדף 0 (המכיל את `matrix[0][0]` עד `matrix[0][1023]`). זה יגרום ל-Page Fault (PF). הדף נטען לזיכרון הפיזי.\n    *   לאחר מכן, עבור `j=1` עד `COLS-1`, הגישות נשארות באותו דף 0, ולכן לא נגרמים Page Faults נוספים.\n    *   כאשר `i` מתקדם ל-1, אנו ניגשים לראשונה לדף 1 (המכיל את `matrix[1][0]` עד `matrix[1][1023]`). זה יגרום ל-Page Fault.\n    *   דפוס זה חוזר על עצמו עבור כל אחת מ-`ROWS` (1024) השורות. בכל פעם שאנו מתחילים שורה חדשה, אנו ניגשים לדף חדש.\n    *   מכיוון שכל גישה לדף חדש גורמת ל-PF, ופונקציה זו ניגשת ל-1024 דפים שונים באופן סדרתי, יהיו בסך הכל **1024 Page Faults**. מדיניות ה-LRU ומגבלת הזיכרון הפיזי (100 דפים) אינן משפיעות על המספר הכולל במקרה זה, כיוון שהגישה היא סדרתית וכל דף נקרא פעם אחת בלבד. ה-Working Set של הפונקציה הוא דף אחד בלבד.\n\n2.  **Page Faults בפונקציה `access_col_major()`:**\n    בפונקציה זו, הגישה למטריצה מתבצעת בסדר עמודה-אחר-עמודה (`matrix[i][j]`). עבור `j` קבוע, הלולאה הפנימית משנה את `i` מ-0 עד `ROWS-1`. זה אומר שאנו ניגשים ל-`matrix[0][j]`, `matrix[1][j]`, ..., `matrix[1023][j]`.\n    *   כפי שחישבנו, `matrix[i][j]` ו-`matrix[i+1][j]` נמצאים בדפים שונים (דף `i` ודף `i+1` בהתאמה).\n    *   עבור `j=0` (העמודה הראשונה):\n        *   הגישה ל-`matrix[0][0]` גורמת ל-PF (טוען דף 0). \n        *   הגישה ל-`matrix[1][0]` גורמת ל-PF (טוען דף 1). \n        *   ... \n        *   הגישה ל-`matrix[99][0]` גורמת ל-PF (טוען דף 99). בשלב זה, 100 פריימים פיזיים מלאים.\n        *   הגישה ל-`matrix[100][0]` גורמת ל-PF (טוען דף 100, מחליף את דף 0 שהוא ה-LRU).\n        *   דפוס זה ממשיך: כל גישה ל-`matrix[i][0]` (עבור `i` מ-0 עד 1023) תגרום ל-PF. סך הכל 1024 Page Faults עבור העמודה הראשונה.\n        *   בסיום סריקת העמודה הראשונה, הדפים בזיכרון הפיזי הם דפים 924 עד 1023.\n    *   עבור `j=1` (העמודה השנייה):\n        *   הלולאה הפנימית ניגשת שוב לדפים 0, 1, ..., 1023.\n        *   הגישה ל-`matrix[0][1]` פירושה גישה לדף 0. דף 0 יצא מהזיכרון הפיזי במהלך סריקת העמודה הראשונה (הוחלף כאשר `i=100`). לכן, גישה זו תגרום שוב ל-PF. דף 0 ייטען מחדש ויחליף את דף 924 (ה-LRU).\n        *   דפוס זה חוזר על עצמו עבור כל גישה ל-`matrix[i][1]` עבור `i` מ-0 עד 1023. כלומר, 1024 Page Faults נוספים עבור העמודה השנייה.\n    *   מכיוון שהלולאה החיצונית רצה `COLS` (1024) פעמים, ובכל פעם היא גורמת ל-1024 Page Faults, סך הכל יתרחשו `COLS * ROWS` = `1024 * 1024` = **1,048,576 Page Faults**.\n\n3.  **הסבר ההבדל ועיקרון ניהול הזיכרון:**\n    ההבדל הדרמטי במספר ה-Page Faults נובע מעיקרון \"עקרון המקומיות\" (Locality of Reference), ובפרט \"מקומיות מרחבית\" (Spatial Locality).\n    *   **`access_row_major()`** מציגה מקומיות מרחבית מצוינת. היא ניגשת לאלמנטים בזיכרון בסדר רציף (או קרוב לרציף). כאשר דף נטען לזיכרון הפיזי, הוא מכיל את כל הנתונים הנדרשים לגישות הבאות (בתוך אותה שורה). זה ממזער את מספר ה-Page Faults, שכן דף אחד מספיק \"לכסות\" את כל הגישות בשורה אחת. ה-Working Set (קבוצת הדפים הפעילים) של הפונקציה קטן (דף אחד) ומתאים בקלות לזיכרון הפיזי.\n    *   **`access_col_major()`** מציגה מקומיות מרחבית ירודה מאוד. היא ניגשת לאלמנטים בזיכרון בקפיצות גדולות. כל גישה ל-`matrix[i][j]` עבור `i` חדש (כש-`j` קבוע) קופצת לדף חדש לחלוטין. מכיוון שגודל הזיכרון הפיזי (100 דפים) קטן משמעותית ממספר הדפים הכולל של המטריצה (1024 דפים) הנדרשים בכל איטרציה של הלולאה הפנימית, ובכל איטרציה של הלולאה החיצונית אנו סורקים מחדש את כל טווח הדפים של המטריצה, דפים ישנים נזרקים מהזיכרון הפיזי רק כדי להיטען מחדש מיד לאחר מכן. תופעה זו נקראת \"Thrashing\" (סחף דפים), והיא גורמת לירידה חמורה בביצועים עקב מספר עצום של Page Faults ופעולות קריאה/כתיבה לדיסק.\n    העיקרון המודגם הוא חשיבות ה-Spatial Locality (מקומיות מרחבית) ויכולת מערכת ההפעלה לנצל אותה באמצעות טעינת דפים. גישה לא רציפה לזיכרון, במיוחד כאשר ה-Working Set (קבוצת הדפים הפעילים) גדולה מהזיכרון הפיזי הזמין, עלולה להוביל לביצועים גרועים ביותר."}, "difficulty_estimation": "Medium", "_source_file": "0489__Memory_Management__CodeAnalysis__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:05:14", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Memory Management", "Heap", "Virtual Memory", "Paging", "malloc"], "content": {"text": "נתונה התוכנית הבאה, המבצעת הקצאות זיכרון באמצעות `malloc`.\nהניחו כי גודל דף במערכת ההפעלה הוא 4096 בתים (4KB).\nהניחו שכל קריאה ל-`malloc(CHUNK_SIZE)` דורשת מ-`malloc` לנהל בלוק בגודל `CHUNK_SIZE + 16` בתים (כאשר 16 בתים הם עבור מידע פנימי של `malloc` כמו גודל הבלוק, מצביע לבלוק הבא/קודם ב-free list וכו').\nכמו כן, הניחו ש-`malloc` מקצה זיכרון מה-heap, וכי ה-heap גדל בצעדים של דפים שלמים כאשר נדרש זיכרון חדש מהמערכת (כלומר, קריאות `sbrk` או `mmap` של `malloc` מבקשות בלוקים בגודל דף או כפולה של דף).\nהתעלמו מזיכרון הנדרש עבור קוד, נתונים גלובליים ומחסנית, והתמקדו רק בזיכרון הווירטואלי המוקצה ל-heap עבור הנתונים וה-overhead של `malloc`.\nמהו המספר המינימלי של דפי זיכרון וירטואליים שיוקצו ל-heap של התהליך לאחר סיום לולאת ההקצאות?", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define NUM_ALLOCATIONS 100\n#define CHUNK_SIZE 100 // bytes\n\nint main() {\n    void* ptrs[NUM_ALLOCATIONS];\n\n    for (int i = 0; i < NUM_ALLOCATIONS; ++i) {\n        ptrs[i] = malloc(CHUNK_SIZE);\n        if (ptrs[i] == NULL) {\n            perror(\"malloc failed\");\n            return 1;\n        }\n    }\n\n    // Assume the program reaches this point.\n\n    // Cleanup for completeness, not part of the question's analysis point\n    for (int i = 0; i < NUM_ALLOCATIONS; ++i) {\n        free(ptrs[i]);\n    }\n\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התהליך מבצע 100 הקצאות של 100 בתים כל אחת.\nעל פי הנתון, כל הקצאה של `CHUNK_SIZE` דורשת מ-`malloc` לנהל בלוק בגודל `CHUNK_SIZE + 16` בתים (הכולל את הנתונים ומידע פנימי של `malloc`).\nלכן, כל בלוק זיכרון בפועל שתופס `malloc` הוא בגודל `100 + 16 = 116` בתים.\nהזיכרון הכולל ש-`malloc` צריך לנהל עבור כל ההקצאות הוא `100 * 116 = 11600` בתים.\nמערכת ההפעלה מקצה זיכרון ל-heap בצעדים של דפים שלמים, שגודלם 4096 בתים.\nכדי לספק 11600 בתים, `malloc` יצטרך לבקש מהמערכת מספר דפים שיכיל לפחות כמות זו.\nמספר הדפים הנדרש הוא `ceil(11600 / 4096)`.\n`11600 / 4096 = 2.832...`\nלכן, `malloc` יבקש 3 דפים ממערכת ההפעלה.\n`3 * 4096 = 12288` בתים.\nהמספר המינימלי של דפים וירטואליים שיוקצו ל-heap יהיה 3.\n(הערה: חלק מהזיכרון בתוך הדפים הללו יהיה \"פנוי\" או ישמש לצרכים פנימיים אחרים של `malloc` מעבר לבלוקים המוקצים בפועל, אך מנקודת מבט של דפי זיכרון וירטואליים שהוקצו ל-heap מה-OS, יהיו אלה 3 דפים)."}, "difficulty_estimation": "Medium", "_source_file": "0490__Memory_Management__CodeAnalysis__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:05:37", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Memory Management", "Stack", "Pointers", "Undefined Behavior"], "content": {"text": "נתונה התוכנית הבאה בשפת C.\nהתוכנית מנסה להקצות מערך בתוך פונקציה ולהחזיר מצביע אליו.\n\nהסבירו מהו הפלט הצפוי של התוכנית. אם התוכנית עלולה לקרוס או להתנהג באופן בלתי צפוי, הסבירו מדוע ומה הסיבות לכך בהקשר לניהול זיכרון במערכת ההפעלה.", "code_snippet": "#include <stdio.h>\n\nint* createArray() {\n    int arr[5]; // מערך מקומי המוקצה על המחסנית (stack)\n    for (int i = 0; i < 5; ++i) {\n        arr[i] = i * 10;\n    }\n    printf(\"Inside createArray: arr[0] = %d, address = %p\\n\", arr[0], (void*)arr);\n    return arr; // החזרת כתובת של משתנה מקומי במחסנית\n}\n\nint main() {\n    int* ptr = createArray();\n    printf(\"Inside main: ptr = %p\\n\", (void*)ptr);\n    // ניסיון לגשת לזיכרון לאחר שהפונקציה createArray הסתיימה\n    printf(\"Inside main: *ptr = %d\\n\", *ptr);\n    printf(\"Inside main: ptr[1] = %d\\n\", ptr[1]);\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הבעיה המרכזית בתוכנית זו היא שהפונקציה `createArray` מחזירה מצביע למערך `arr` שהוקצה על המחסנית (stack). כאשר הפונקציה `createArray` מסיימת את ריצתה, מסגרת המחסנית (stack frame) שלה מוסרת (או מסומנת כזמינה לשימוש חוזר). המשמעות היא שהזיכרון שבו שכן המערך `arr` אינו מוקצה עוד באופן חוקי עבור `arr`.\n\n**פלט צפוי והסבר:**\n1.  **הפלט הראשון (מתוך `createArray`):** `Inside createArray: arr[0] = 0, address = <כתובת כלשהי>`\n    *   פלט זה יהיה תקין ומדויק. בתוך הפונקציה `createArray`, המערך `arr` נמצא עדיין בתחום החיים שלו על המחסנית, והגישה אליו תקינה.\n\n2.  **הפלט השני (מתוך `main`):** `Inside main: ptr = <אותה כתובת כמו בפלט הראשון>`\n    *   פלט זה גם יהיה תקין, שכן `ptr` פשוט מקבל ומחזיק את הכתובת שהוחזרה מ-`createArray`. הבעיה אינה בהחזקת הכתובת, אלא בשימוש בה.\n\n3.  **הפלט השלישי והרביעי (מתוך `main`):** `Inside main: *ptr = <ערך בלתי צפוי>`, `Inside main: ptr[1] = <ערך בלתי צפוי>`\n    *   כאן מתרחשת התנהגות בלתי מוגדרת (Undefined Behavior). לאחר ש-`createArray` סיימה, הזיכרון שאליו `ptr` מצביע אינו מוקצה עוד עבור המערך `arr`. הגישה לזיכרון זה היא למעשה גישה לזיכרון תלוי (dangling pointer).\n    *   **הסיבות והתוצאות האפשריות:**\n        *   **הדפסת הערכים המקוריים:** במקרים רבים, במיוחד בתוכניות פשוטות, ייתכן שהזיכרון במחסנית לא יידרס מיד על ידי קריאות פונקציות אחרות. במצב כזה, התוכנית עשויה להדפיס בטעות את הערכים המקוריים (0 ו-10), מה שעלול ליצור אשליה שהקוד תקין. זוהי סכנה גדולה, מכיוון שהתנהגות זו אינה מובטחת ועלולה להשתנות בין ריצות שונות, קומפיילרים שונים או סביבות הפעלה שונות.\n        *   **הדפסת ערכי זבל:** אם הזיכרון שבו שכן `arr` נדרס על ידי נתונים אחרים (לדוגמה, אם פונקציה אחרת נקראה מיד לאחר `createArray` והשתמשה באותו אזור זיכרון במחסנית), אז `*ptr` ו-`ptr[1]` יכילו ערכי זבל.\n        *   **קריסה (Segmentation Fault):** במקרים מסוימים, מערכת ההפעלה או רכיבי זמן ריצה עשויים לזהות ניסיון גישה לזיכרון לא חוקי ולגרום לקריסת התוכנית (לרוב עם שגיאת Segmentation Fault). זה קורה אם הזיכרון סומן כלא נגיש או אם הגישה חורגת מגבולות הזיכרון שהוקצה לתהליך.\n\n**בהקשר לניהול זיכרון במערכת ההפעלה:**\nמערכת ההפעלה מקצה לכל תהליך מרחב כתובות וירטואלי משלו, הכולל בין היתר את מקטע המחסנית (Stack). המחסנית משמשת לאחסון משתנים מקומיים וכתובות חזרה של פונקציות. כאשר פונקציה נקראת, מסגרת מחסנית חדשה נוצרת עבורה. כאשר היא מסיימת, המסגרת שלה 'נמחקת' (כלומר, ה-stack pointer מתעדכן, והזיכרון נחשב לזמין לשימוש עתידי). הגישה לזיכרון זה לאחר ה'מחיקה' היא לגיטימית מבחינת מרחב הכתובות הוירטואלי של התהליך, אך לא חוקית מבחינה לוגית של התוכנית, ועלולה להוביל לשגיאות קשות שקשה לאתר."}, "difficulty_estimation": "Medium", "_source_file": "0491__Memory_Management__CodeAnalysis__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:06:00", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Memory Management", "Dynamic Memory Allocation", "Memory Leaks"], "content": {"text": "נתונה התוכנית הבאה ב-C. התוכנית מקצה זיכרון למערך של N מצביעים למספרים שלמים, ולאחר מכן מקצה זיכרון ל-N מספרים שלמים בודדים ומאתחלת אותם. לבסוף, היא משחררת את הזיכרון שהוקצה למספרים השלמים הבודדים.\n1. תארו מהי בעיית ניהול הזיכרון המרכזית בתוכנית זו.\n2. הציגו את השינוי הנדרש בקוד כדי לתקן את הבעיה.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define N 5\n\nint main() {\n    int **arr_of_ptrs;\n    int i;\n\n    // Allocate memory for N integer pointers\n    arr_of_ptrs = (int **)malloc(N * sizeof(int *));\n    if (arr_of_ptrs == NULL) {\n        perror(\"malloc arr_of_ptrs failed\");\n        return 1;\n    }\n\n    // Allocate memory for N integers and store their addresses\n    for (i = 0; i < N; i++) {\n        arr_of_ptrs[i] = (int *)malloc(sizeof(int));\n        if (arr_of_ptrs[i] == NULL) {\n            perror(\"malloc int failed\");\n            // In a real program, a cleanup of previously allocated memory would be needed here.\n            return 1;\n        }\n        *arr_of_ptrs[i] = i * 10; // Initialize values\n    }\n\n    // Print values (optional)\n    printf(\"Values:\\n\");\n    for (i = 0; i < N; i++) {\n        printf(\"arr_of_ptrs[%d] = %d\\n\", i, *arr_of_ptrs[i]);\n    }\n\n    // Free individual integers\n    for (i = 0; i < N; i++) {\n        free(arr_of_ptrs[i]);\n        arr_of_ptrs[i] = NULL; // Good practice to nullify after freeing\n    }\n\n    // Missing: free(arr_of_ptrs);\n\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "**1. תיאור הבעיה:\n**הבעיה המרכזית בתוכנית היא **דליפת זיכרון (Memory Leak)**.\nהתוכנית מבצעת שתי הקצאות זיכרון דינמיות נפרדות:\nא. `arr_of_ptrs = (int **)malloc(N * sizeof(int *));` - מקצה בלוק זיכרון עבור המערך של המצביעים עצמו.\nב. בתוך הלולאה, `arr_of_ptrs[i] = (int *)malloc(sizeof(int));` - מקצה בלוק זיכרון עבור כל אחד מ-N המספרים השלמים הבודדים.\n\nהלולאה השנייה בתוכנית (`for (i = 0; i < N; i++) { free(arr_of_ptrs[i]); }`) משחררת בהצלחה את כל הזיכרון שהוקצה למספרים השלמים הבודדים.\nאך, בלוק הזיכרון שהוקצה עבור המערך `arr_of_ptrs` עצמו (שנוצר על ידי הקריאה הראשונה ל-`malloc`) **אינו משוחרר לעולם**.\nכתוצאה מכך, הזיכרון הזה נשאר תפוס על ידי התהליך גם לאחר שהפונקציה `main` מסתיימת, והוא אינו זמין לשימוש חוזר על ידי המערכת. זוהי דליפת זיכרון קלאסית, אשר עלולה להצטבר ולגרום לבעיות בביצועי המערכת ובזמינות הזיכרון אם התוכנית רצה לאורך זמן או במחזורים חוזרים.\n\n**2. התיקון הנדרש:\n**כדי לתקן את דליפת הזיכרון, יש להוסיף קריאה ל-`free(arr_of_ptrs);` לאחר שכל המצביעים בתוך המערך שוחררו, ולפני סיום הפונקציה `main`.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define N 5\n\nint main() {\n    int **arr_of_ptrs;\n    int i;\n\n    arr_of_ptrs = (int **)malloc(N * sizeof(int *));\n    if (arr_of_ptrs == NULL) {\n        perror(\"malloc arr_of_ptrs failed\");\n        return 1;\n    }\n\n    for (i = 0; i < N; i++) {\n        arr_of_ptrs[i] = (int *)malloc(sizeof(int));\n        if (arr_of_ptrs[i] == NULL) {\n            perror(\"malloc int failed\");\n            // Proper cleanup for previously allocated arr_of_ptrs[0...i-1] would be here.\n            // For simplicity of this example, we just exit.\n            return 1;\n        }\n        *arr_of_ptrs[i] = i * 10;\n    }\n\n    printf(\"Values:\\n\");\n    for (i = 0; i < N; i++) {\n        printf(\"arr_of_ptrs[%d] = %d\\n\", i, *arr_of_ptrs[i]);\n    }\n\n    for (i = 0; i < N; i++) {\n        free(arr_of_ptrs[i]);\n        arr_of_ptrs[i] = NULL;\n    }\n\n    // תיקון: שחרור הזיכרון שהוקצה למערך arr_of_ptrs עצמו\n    free(arr_of_ptrs);\n\n    return 0;\n}"}, "difficulty_estimation": "Medium", "_source_file": "0492__Memory_Management__CodeAnalysis__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:06:21", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Memory Management", "Paging", "Locality", "Performance"], "content": {"text": "נתונה התוכנית הבאה המאתחלת מטריצה גדולה.\nהמערכת עליה רצה התוכנית משתמשת בזיכרון וירטואלי עם חלוקה לדפים (paging).\nנתונים:\n- גודל דף הוא 4KB.\n- גודל משתנה `int` הוא 4 בתים.\n- המטריצה מאוחסנת בזיכרון באופן רציף (row-major order).\n- המערכת מתחילה עם זיכרון ריק (כלומר, כל גישה לדף בפעם הראשונה תגרום ל-page fault).\n- יש מספיק מסגרות פיזיות (physical frames) להכיל את כל דפי המטריצה.\n\nיש לנתח את קטעי הקוד הבאים ולענות על השאלה.\n\nכמה page faults (לערך) יתרחשו בעת הפעלת הפונקציה `init_matrix_row_major()` וכמה page faults (לערך) יתרחשו בעת הפעלת הפונקציה `init_matrix_col_major()`?\nהסבר מדוע, למרות שמספר ה-page faults הכולל זהה בשני המקרים, הפונקציה `init_matrix_row_major()` תהיה מהירה יותר באופן משמעותי בפועל.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define ROWS 1024\n#define COLS 1024\n\nint matrix[ROWS][COLS]; // Global static allocation\n\nvoid init_matrix_row_major() {\n    for (int i = 0; i < ROWS; ++i) {\n        for (int j = 0; j < COLS; ++j) {\n            matrix[i][j] = i * COLS + j;\n        }\n    }\n}\n\nvoid init_matrix_col_major() {\n    for (int j = 0; j < COLS; ++j) {\n        for (int i = 0; i < ROWS; ++i) {\n            matrix[i][j] = i * COLS + j;\n        }\n    }\n}\n\nint main() {\n    // ניתן להריץ כל אחת מהפונקציות בנפרד\n    // init_matrix_row_major();\n    // init_matrix_col_major();\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "חישוב גודל המטריצה ומספר הדפים:\nגודל המטריצה הכולל: `1024 שורות * 1024 עמודות * 4 בתים/int = 4,194,304 בתים = 4MB`.\nגודל דף: `4KB = 4096 בתים`.\nמספר הדפים הכולל הנדרש למטריצה: `4MB / 4KB = 1024 דפים`.\n\nעל פי הנתונים, המערכת מתחילה עם זיכרון ריק וכל גישה לדף בפעם הראשונה גורמת ל-page fault. בנוסף, יש מספיק מסגרות פיזיות להכיל את כל דפי המטריצה, כלומר דף שנטען לזיכרון הפיזי יישאר שם ולא יוחלף.\nלכן, כל אחד מ-1024 דפי המטריצה ייטען לזיכרון הפיזי בדיוק פעם אחת.\n**מספר ה-page faults הכולל יהיה 1024 עבור שתי הפונקציות.**\n\nהסבר להבדל בביצועים:\n\n1.  **`init_matrix_row_major()`:**\n    *   פונקציה זו ניגשת לאלמנטים בסדר שבו הם מאוחסנים בזיכרון (row-major). כלומר, `matrix[i][j]` ואחריו `matrix[i][j+1]` הם סמוכים בזיכרון.\n    *   גודל שורה: `1024 עמודות * 4 בתים/int = 4096 בתים = 4KB`. כלומר, כל שורה תופסת בדיוק דף אחד.\n    *   כאשר ניגשים ל-`matrix[i][0]` בפעם הראשונה, מתרחש page fault וכל הדף (השורה כולה) נטען לזיכרון הפיזי.\n    *   הגישות הבאות לאלמנטים `matrix[i][1]` עד `matrix[i][1023]` ימצאו את הנתונים כבר בזיכרון הפיזי (ולרוב גם ב-cache) ולא יגרמו ל-page faults נוספים או ל-cache misses רבים.\n    *   הגישות מתבצעות עם לוקליות מרחבית (spatial locality) מצוינת.\n    *   סה\"כ: 1024 page faults, המתרחשים באופן סדרתי (אחד לכל שורה).\n\n2.  **`init_matrix_col_major()`:**\n    *   פונקציה זו ניגשת לאלמנטים בסדר טור-אחרי-טור. כלומר, `matrix[0][j]`, `matrix[1][j]`, `matrix[2][j]` וכן הלאה.\n    *   אלמנטים אלו אינם סמוכים בזיכרון. `matrix[0][j]` נמצא בדף של שורה 0, `matrix[1][j]` נמצא בדף של שורה 1 וכו'. המרחק בין `matrix[i][j]` ל-`matrix[i+1][j]` הוא `1024 * 4 = 4KB`, כלומר בדיוק גודל דף.\n    *   כאשר `j=0`, בלולאה הפנימית (`i`):\n        *   `matrix[0][0]` נגיש - page fault לדף של שורה 0.\n        *   `matrix[1][0]` נגיש - page fault לדף של שורה 1.\n        *   ...\n        *   `matrix[1023][0]` נגיש - page fault לדף של שורה 1023.\n        *   בשלב זה, כל 1024 דפי המטריצה נטענו לזיכרון הפיזי.\n    *   הגישות מתבצעות עם לוקליות מרחבית (spatial locality) ירודה מאוד. בכל איטרציה של הלולאה הפנימית (`i`), אנו קופצים לדף זיכרון אחר.\n    *   למרות שסה\"כ מספר ה-page faults הוא גם 1024, הם מתרחשים כולם ברצף מהיר מאוד בתחילת הביצוע (בעת איפוס הטור הראשון). רצף כה גדול של page faults דורש עבודה רבה ממערכת ה-I/O ומהמעבד (לטיפול בהפרעות) ופוגע קשות בביצועים.\n    *   בנוסף, לוקליות מרחבית ירודה זו גורמת למספר גבוה בהרבה של Cache misses וגם ל-TLB misses רבים (אם ה-TLB אינו גדול מספיק להכיל את כל 1024 הדפים בו זמנית), מה שמאט את הביצועים באופן דרמטי גם לאחר שכל הדפים כבר נטענו לזיכרון הפיזי.\n\n**לסיכום:**\nבשני המקרים יתרחשו 1024 page faults.\nעם זאת, `init_matrix_row_major()` תהיה מהירה יותר באופן משמעותי מכיוון שהיא מנצלת לוקליות מרחבית טובה יותר, מה שמביא לפחות Cache misses ושימוש יעיל יותר ב-TLB, ופיזור טוב יותר של ה-page faults לאורך זמן. לעומתה, `init_matrix_col_major()` סובלת מלוקליות מרחבית ירודה, גורמת ל-1024 page faults כמעט בו-זמנית בתחילת הריצה, וכן למספר רב של Cache/TLB misses לאורך כל הריצה.", "code_snippet": null}, "difficulty_estimation": "Medium", "_source_file": "0493__Memory_Management__CodeAnalysis__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:07:01", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Memory Management", "Paging", "Page Faults", "Locality of Reference"], "content": {"text": "נתונה תוכנית C המשתמשת במערך דו-ממדי גדול. המערכת ההפעלה משתמשת בזיכרון וירטואלי עם דפים בגודל 4KB. נניח שהמערך `int arr[1024][1024];` (כאשר כל `int` הוא בגודל 4 בתים) מאוחסן בזיכרון רציף ומתחיל בכתובת המיושרת לגבול דף.\n\nיש לנתח את שני קטעי הקוד הבאים ולחשב את המספר המינימלי של כשלים בדף (page faults) שיתרחשו עבור כל אחד מהם, בהנחה שכל הדפים של המערך אינם טעונים לזיכרון הפיזי בתחילת הריצה.", "code_snippet": "// Assume int is 4 bytes\n// Array: int arr[1024][1024];\n// Total array size: 1024 * 1024 * 4 bytes = 4,194,304 bytes = 4MB\n// Page size: 4KB = 4096 bytes\n\n// Access Pattern A (row-major)\nvoid pattern_A_access(int arr[1024][1024]) {\n    for (int i = 0; i < 1024; ++i) {\n        for (int j = 0; j < 1024; ++j) {\n            arr[i][j] = i * j;\n        }\n    }\n}\n\n// Access Pattern B (column-major)\nvoid pattern_B_access(int arr[1024][1024]) {\n    for (int j = 0; j < 1024; ++j) {\n        for (int i = 0; i < 1024; ++i) {\n            arr[i][j] = i * j;\n        }\n    }\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "חישובים מקדימים:\nגודל המערך הכולל: 1024 שורות * 1024 עמודות * 4 בתים/int = 4,194,304 בתים = 4MB.\nגודל דף: 4KB = 4096 בתים.\nמספר הדפים הכולל הנדרש למערך: 4MB / 4KB = 1024 דפים.\n\n**ניתוח תבנית גישה A (שורות):**\nב-C, מערכים דו-ממדיים מאוחסנים בזיכרון בסדר שורות (row-major). כלומר, כל האלמנטים של שורה `i` (`arr[i][0]` עד `arr[i][1023]`) מאוחסנים באופן רציף בזיכרון.\nגודל שורה אחת: 1024 איברים * 4 בתים/איבר = 4096 בתים = 1 דף.\nכאשר הלולאה החיצונית קובעת את `i` (מספר השורה), והלולאה הפנימית עוברת על `j` (מספר העמודה), הגישה לאיבר `arr[i][0]` תגרום לכשל דף (page fault) מכיוון שהדף של שורה `i` אינו בזיכרון. הדף הזה (שגודלו 4KB) ייטען לזיכרון הפיזי.\nלאחר מכן, כל הגישות הבאות לאיברים `arr[i][1]` עד `arr[i][1023]` יהיו באותו דף שכבר נטען, ולכן לא יגרמו לכשלי דף נוספים עבור שורה זו.\nכאשר הלולאה החיצונית עוברת לשורה הבאה (`i+1`), הגישה לאיבר `arr[i+1][0]` תגרום שוב לכשל דף, מכיוון שזוהי שורה חדשה הממוקמת בדף חדש.\nמכיוון שיש 1024 שורות במערך, וכל שורה תופסת בדיוק דף אחד, יהיו בסך הכל **1024 כשלי דף** עבור תבנית גישה זו.\n\n**ניתוח תבנית גישה B (עמודות):**\nכאשר הלולאה החיצונית קובעת את `j` (מספר העמודה), והלולאה הפנימית עוברת על `i` (מספר השורה), סדר הגישה הוא `arr[0][j], arr[1][j], ..., arr[1023][j]`.\nמכיוון שמערכים מאוחסנים בסדר שורות, האיבר `arr[i][j]` והאיבר `arr[i+1][j]` נמצאים בשורות שונות לגמרי. למעשה, `arr[i+1][j]` ממוקם 1024 * 4 = 4096 בתים (דף שלם) אחרי `arr[i][j]` בזיכרון.\nלכן, כל גישה לאיבר `arr[i][j]` עבור `i` שונה (עבור `j` קבוע) תהיה לכתובת בזיכרון הנמצאת בדף שונה.\nכתוצאה מכך, עבור כל איטרציה של הלולאה הפנימית (כלומר, עבור כל `i` מ-0 עד 1023), תתרחש ככל הנראה כשל דף חדש.\nבסך הכל, עבור עמודה אחת (`j` קבוע), יהיו 1024 כשלי דף.\nמכיוון שיש 1024 עמודות, המספר הכולל של כשלי דף יהיה 1024 עמודות * 1024 כשלי דף/עמודה = **1,048,576 כשלי דף**."}, "difficulty_estimation": "Medium", "_source_file": "0494__Memory_Management__CodeAnalysis__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:07:26", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Memory Management", "Paging", "TLB", "Cache Locality"], "content": {"text": "נתונה תוכנית C המבצעת סכימה על מערך דו-ממדי גדול של מספרים שלמים. המערכת פועלת עם זיכרון וירטואלי, גודל דף הוא 4KB (קילו-בתים), וגודל ערך `int` הוא 4 בתים. נניח שה-TLB (Translation Lookaside Buffer) קטן מאוד ומכיל מספר מוגבל של תרגומי כתובות (לדוגמה, 4 כניסות). המערך `arr` מוגדר בגודל `N x N` כאשר `N = 1024`.\nשתי פונקציות מוצגות להלן, המבצעות סכימה של כל האיברים במערך.\n\nנתחו איזו פונקציה (sum_row_major או sum_col_major) צפויה לגרום לפחות page faults ופחות TLB misses, והסבירו מדוע. פרטו את כמות ה-page faults וה-TLB misses המשוערת לכל פונקציה.", "code_snippet": "```c\n#include <stdio.h>\n#include <stdlib.h>\n\n#define N 1024 // N x N array\n\nint arr[N][N]; // Global array, initialized with some values\n\nvoid sum_row_major() {\n    long long total_sum = 0;\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            total_sum += arr[i][j];\n        }\n    }\n    printf(\"Row-major sum: %lld\\n\", total_sum);\n}\n\nvoid sum_col_major() {\n    long long total_sum = 0;\n    for (int j = 0; j < N; ++j) {\n        for (int i = 0; i < N; ++i) {\n            total_sum += arr[i][j];\n        }\n    }\n    printf(\"Column-major sum: %lld\\n\", total_sum);\n}\n\n// main function is omitted for brevity, assume it calls these functions\n// and arr is initialized.\n```", "options": null}, "sub_questions": null, "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון מבוסס על הבנת אופן אחסון מערכים דו-ממדיים בזיכרון ב-C וכיצד הוא משפיע על ניצול הזיכרון הווירטואלי (paging, TLB).\n\n1.  **גודל המערך וגודל הדף**:\n    *   המערך `arr` הוא בגודל `N x N` כאשר `N = 1024`.\n    *   גודל המערך הכולל הוא `1024 * 1024 * sizeof(int) = 1024 * 1024 * 4 בתים = 4MB`.\n    *   גודל דף הוא `4KB`.\n    *   מספר הדפים הנדרשים לאחסון המערך הוא `4MB / 4KB = 1024 דפים`.\n    *   מערכי C מאוחסנים בזיכרון בסדר שורה-אחר-שורה (row-major order). כלומר, `arr[i][j]` ו-`arr[i][j+1]` הם סמוכים בזיכרון. שורה אחת של המערך (`arr[i][0]` עד `arr[i][N-1]`) תופסת `N * sizeof(int) = 1024 * 4 = 4096 בתים = 1 דף`.\n\n2.  **ניתוח `sum_row_major()`**:\n    *   הלולאה הפנימית עוברת על `j` מ-`0` עד `N-1` עבור `i` קבוע.\n    *   גישה זו היא `arr[i][0], arr[i][1], ..., arr[i][N-1]`.\n    *   דפוס גישה זה הוא **רציף בזיכרון** (contiguous). כל הגישות בתוך הלולאה הפנימית עבור `i` קבוע הן לאלמנטים סמוכים באותה שורה.\n    *   כאשר ניגשים ל-`arr[i][0]`, אם הדף המכיל אותו אינו בזיכרון הפיזי, תתרחש page fault והדף יוטען. דף זה מכיל את כל השורה `i` (מכיוון ששורה תופסת בדיוק דף אחד).\n    *   לאחר מכן, הגישות ל-`arr[i][1]` עד `arr[i][N-1]` יהיו כולן להיטים באותו דף שכבר נטען, ולכן לא יגרמו ל-page faults נוספים עבור שורה זו.\n    *   באופן דומה, עבור TLB: כאשר `arr[i][0]` נגיש, כתובתו הווירטואלית מתורגמת לכתובת פיזית, והתרגום נשמר ב-TLB. כל שאר הגישות באותה שורה ימצאו את התרגום ב-TLB (TLB hit) מכיוון שהן באותו דף.\n    *   **סה\"כ page faults**: בערך `N` page faults (אחד לכל שורה, שכן כל שורה היא דף חדש).\n    *   **סה\"כ TLB misses**: בערך `N` TLB misses (אחד לכל שורה, שכן כל שורה היא דף חדש).\n\n3.  **ניתוח `sum_col_major()`**:\n    *   הלולאה הפנימית עוברת על `i` מ-`0` עד `N-1` עבור `j` קבוע.\n    *   גישה זו היא `arr[0][j], arr[1][j], ..., arr[N-1][j]`.\n    *   דפוס גישה זה **אינו רציף בזיכרון**. `arr[i][j]` ו-`arr[i+1][j]` נמצאים במרחק של `N * sizeof(int) = 4096 בתים = 1 דף` זה מזה.\n    *   כלומר, כל גישה ל-`arr[i][j]` עבור `i` שונה (בתוך הלולאה הפנימית עבור `j` קבוע) תגרום לגישה לדף זיכרון שונה לגמרי. לדוגמה, `arr[0][j]` נמצא בדף `P0`, `arr[1][j]` נמצא בדף `P1` (שונה מ-`P0`), `arr[2][j]` נמצא בדף `P2` (שונה מ-`P0`, `P1`), וכן הלאה.\n    *   לכן, כמעט כל גישה ל-`arr[i][j]` (עבור `i` משתנה) תגרום ל-page fault, שכן סביר להניח שהדף המבוקש אינו נמצא בזיכרון הפיזי או הוצא ממנו עקב המחסור במקום (כי כל הגישות הקודמות היו לדפים שונים).\n    *   באופן דומה, עבור TLB: מכיוון שכל גישה היא לדף שונה, ובהינתן שה-TLB קטן מאוד (לדוגמה, 4 כניסות), כל גישה כזו תגרום כמעט בוודאות ל-TLB miss. ה-TLB לא יכול להכיל את כל תרגומי הכתובות של `N` דפים שונים בבת אחת, ולכן בכל פעם יהיה צורך לטעון תרגום חדש.\n    *   **סה\"כ page faults**: בערך `N * N` page faults (אחד לכל גישה, שכן כל גישה היא לדף אחר).\n    *   **סה\"כ TLB misses**: בערך `N * N` TLB misses (אחד לכל גישה, שכן כל גישה היא לדף אחר).\n\n4.  **מסקנה**:\n    *   הפונקציה `sum_row_major()` תגרום למספר נמוך בהרבה של page faults ו-TLB misses (בערך `N` מול `N*N`), מכיוון שהיא מנצלת טוב יותר את עקרון **לוקליות המרחב (spatial locality)**. היא ניגשת לנתונים באופן רציף בזיכרון, מה שמאפשר לדפים ולשורות מטמון (cache lines) לשרת מספר רב של גישות.\n    *   הפונקציה `sum_col_major()` סובלת מביצועים גרועים בהרבה מכיוון שהיא מדלגת על פני דפים רבים בכל גישה, מה שמוביל ל-page faults ו-TLB misses רבים."}, "difficulty_estimation": "Medium", "_source_file": "0495__Memory_Management__CodeAnalysis__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:07:56", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Memory Management", "Paging", "Locality"], "content": {"text": "נתונה התוכנית הבאה בשפת C/C++. המערך matrix מוגדר גלובלית, ולכן נמצא בקטע הנתונים (data segment) של התהליך.\nנתוני המערכת:\n*   גודל דף (page size) הוא 4KB.\n*   גודל משתנה `int` הוא 4 בתים.\n*   המערך `matrix` ממוקם באזור זיכרון שבתחילה אינו טעון לזיכרון פיזי (כל הדפים אינם תקפים).\n*   הניחו כי זיכרון פיזי זמין למערך קטן ממספר הדפים הכולל של המערך, כך שמתרחשים חילופי דפים (page replacements).\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n\n#define ROWS 1024\n#define COLS 1024\n\nint matrix[ROWS][COLS]; // Global array\n\nvoid access_row_major() {\n    for (int i = 0; i < ROWS; ++i) {\n        for (int j = 0; j < COLS; ++j) {\n            matrix[i][j] = i * j; // Access row by row\n        }\n    }\n}\n\nvoid access_col_major() {\n    for (int j = 0; j < COLS; ++j) {\n        for (int i = 0; i < ROWS; ++i) {\n            matrix[i][j] = i * j; // Access column by column\n        }\n    }\n}\n\nint main() {\n    // Assume one of the functions is called here:\n    // access_row_major();\n    // OR\n    // access_col_major();\n    return 0;\n}\n```\n\nענו על השאלות הבאות:\n1.  כמה page faults (כשל דף) יתרחשו כאשר הפונקציה `access_row_major()` תתבצע? הסבירו.\n2.  כמה page faults יתרחשו כאשר הפונקציה `access_col_major()` תתבצע? הסבירו.\n3.  איזו תבנית גישה יעילה יותר מבחינת כשל דף ומדוע?", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define ROWS 1024\n#define COLS 1024\n\nint matrix[ROWS][COLS]; // Global array\n\nvoid access_row_major() {\n    for (int i = 0; i < ROWS; ++i) {\n        for (int j = 0; j < COLS; ++j) {\n            matrix[i][j] = i * j; // Access row by row\n        }\n    }\n}\n\nvoid access_col_major() {\n    for (int j = 0; j < COLS; ++j) {\n        for (int i = 0; i < ROWS; ++i) {\n            matrix[i][j] = i * j; // Access column by column\n        }\n    }\n}\n\nint main() {\n    // Assume one of the functions is called here:\n    // access_row_major();\n    // OR\n    // access_col_major();\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "נתחיל בניתוח גודל המערך וחלוקתו לדפים:\n*   גודל המערך הכולל: `1024 שורות * 1024 עמודות * 4 בתים/שלם = 4,194,304 בתים = 4MB`.\n*   גודל דף: `4KB = 4096 בתים`.\n*   מספר שלמים בדף אחד: `4096 בתים / 4 בתים/שלם = 1024 שלמים`.\n*   מכיוון ש-C מאחסנת מערכים רב-ממדיים בסדר שורה-עיקרי (row-major order), כל שורה במערך `matrix` תופסת בדיוק דף אחד: `1024 שלמים/שורה * 4 בתים/שלם = 4096 בתים = 1 דף`.\n*   סה\"כ דפים למערך: `4MB / 4KB = 1024 דפים`.\n\n**ניתוח `access_row_major()`:**\nהפונקציה ניגשת לאלמנטים בסדר שורה-עיקרי, כלומר, היא משלימה את כל הגישות לשורה `i` לפני שהיא עוברת לשורה `i+1`.\n*   כאשר ניגשים לראשונה לאלמנט כלשהו בשורה `i` (לדוגמה `matrix[i][0]`), יתרחש כשל דף עבור הדף המכיל את שורה `i`. דף זה יוטען לזיכרון הפיזי.\n*   כל הגישות הבאות לאלמנטים באותה שורה (`matrix[i][1]` עד `matrix[i][1023]`) יתבצעו בתוך אותו דף שכבר נטען, ולכן לא יגרמו לכשלי דף נוספים.\n*   כאשר הפונקציה עוברת לשורה הבאה (`i+1`), היא תיגש שוב לדף חדש (דף `i+1`), מה שיגרום לכשל דף נוסף.\n*   מכיוון שיש `ROWS` (1024) שורות, וכל שורה תופסת דף אחד, יתרחשו בסך הכל `1024` כשלי דף.\n\n**ניתוח `access_col_major()`:**\nהפונקציה ניגשת לאלמנטים בסדר עמודה-עיקרי, כלומר, היא משלימה את כל הגישות לעמודה `j` לפני שהיא עוברת לעמודה `j+1`.\n*   כאשר הפונקציה ניגשת לאלמנטים בעמודה `j`, היא ניגשת ל-`matrix[0][j]`, `matrix[1][j]`, ..., `matrix[1023][j]`.\n*   `matrix[0][j]` נמצא בדף 0. `matrix[1][j]` נמצא בדף 1. ... `matrix[1023][j]` נמצא בדף 1023.\n*   בכל פעם שהלולאה הפנימית (`for i`) מתקדמת, היא ניגשת לאלמנט הנמצא בדף שונה.\n*   מכיוון שהזיכרון הפיזי מוגבל (כפי שצוין בשאלה), הדפים שנטענו עבור גישות קודמות באותה עמודה (או בעמודות קודמות) יוחלפו בזיכרון הפיזי לפני שתידרש גישה חוזרת אליהם (בהתאם למדיניות החלפת הדפים). כלומר, סביר מאוד שכל גישה לאלמנט תגרור כשל דף.\n*   לולאת ה-`i` הפנימית מבצעת `ROWS` (1024) גישות, וכל אחת מהן תגרום לכשל דף.\n*   לולאת ה-`j` החיצונית מבצעת `COLS` (1024) איטרציות.\n*   לכן, סך כשלי הדף יהיה `ROWS * COLS = 1024 * 1024 = 1,048,576`.\n\n**השוואת יעילות:**\nהפונקציה `access_row_major()` יעילה בהרבה מבחינת כשלי דף. היא גורמת ל-`1024` כשלי דף, בעוד ש-`access_col_major()` גורמת ל-`1,048,576` כשלי דף.\nהסיבה לכך היא עקרון המיקום המרחבי (spatial locality). המערך מאוחסן בזיכרון בסדר שורה-עיקרי.\n*   `access_row_major()` מנצלת את העובדה שאלמנטים סמוכים בשורה נמצאים באותו דף (או בדפים סמוכים). ברגע שדף נטען, ניתן לגשת לכל האלמנטים שבו ללא כשלי דף נוספים, מה שממזער את מספר כשלי הדף הכולל.\n*   `access_col_major()`, לעומת זאת, קופצת בין דפים שונים עבור כל גישה לאלמנט בעמודה. הדפים הנדרשים לכל עמודה הם הדפים של כל השורות, ובהינתן זיכרון פיזי מוגבל, הדפים האלה יוחלפו כל הזמן, מה שמוביל למספר עצום של כשלי דף וביצועים ירודים."}, "difficulty_estimation": "Medium", "_source_file": "0496__Memory_Management__CodeAnalysis__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:08:34", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Memory Management", "Cache", "Paging", "TLB", "Performance Optimization"], "content": {"text": "נתונה תוכנית C המבצעת פעולות על מטריצה דו-ממדית גדולה. התוכנית מאתחלת את המטריצה ולאחר מכן מבצעת שתי פעולות עיבוד דומות, אך בסדר גישה שונה לזיכרון. יש להניח כי המערכת פועלת על ארכיטקטורת x86-64 עם גודל עמוד זיכרון סטנדרטי (לדוגמה, 4KB) ובעלת זיכרון מטמון (cache) מרובה רמות.\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n\n#define N 4096 // גודל המטריצה N x N\n\nint matrix[N][N]; // מטריצה גלובלית שלמים\n\nvoid init_matrix() {\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            matrix[i][j] = i + j;\n        }\n    }\n}\n\n// פונקציה 1: סריקה בסדר שורות (row-major)\nvoid process_row_major() {\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            matrix[i][j] *= 2;\n        }\n    }\n}\n\n// פונקציה 2: סריקה בסדר עמודות (column-major)\nvoid process_col_major() {\n    for (int j = 0; j < N; j++) {\n        for (int i = 0; i < N; i++) {\n            matrix[i][j] *= 2;\n        }\n    }\n}\n\nint main() {\n    init_matrix();\n\n    clock_t start, end;\n    double cpu_time_used;\n\n    printf(\"Starting row-major processing...\\n\");\n    start = clock();\n    process_row_major();\n    end = clock();\n    cpu_time_used = ((double) (end - start)) / CLOCKS_PER_SEC;\n    printf(\"Row-major processing took %f seconds.\\n\", cpu_time_used);\n\n    // אתחול מחדש לצורך השוואה הוגנת\n    init_matrix();\n\n    printf(\"Starting column-major processing...\\n\");\n    start = clock();\n    process_col_major();\n    end = clock();\n    cpu_time_used = ((double) (end - start)) / CLOCKS_PER_SEC;\n    printf(\"Column-major processing took %f seconds.\\n\", cpu_time_used);\n\n    return 0;\n}\n```\n\n**שאלות:**\n1. הסבירו מדוע הפונקציה `process_col_major` צפויה להיות איטית באופן משמעותי מ-`process_row_major`. בתשובתכם התייחסו לעקרונות ניהול זיכרון כגון זיכרון מטמון (CPU cache), עמודים (paging) ו-TLB (Translation Lookaside Buffer).\n2. הציעו דרך לשפר את ביצועי הפונקציה `process_col_major` כך שתהיה מהירה יותר, מבלי לשנות את הלוגיקה החישובית שלה (כלומר, היא עדיין צריכה לבצע את אותה פעולה על אותם אלמנטים). כתבו את הקוד המתוקן של הפונקציה.", "code_snippet": null, "options": null}, "sub_questions": null, "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "**הסבר:**\n\n1.  **אופן אחסון מטריצות ב-C:** ב-C, מטריצות דו-ממדיות מאוחסנות בזיכרון בסדר שורות (row-major order). כלומר, כל השלמים בשורה 0 מאוחסנים ברצף, אחריהם כל השלמים בשורה 1 ברצף, וכן הלאה. גישה לאלמנט `matrix[i][j]` ולאחריו `matrix[i][j+1]` תהיה גישה לכתובות זיכרון סמוכות. לעומת זאת, גישה לאלמנט `matrix[i][j]` ולאחריו `matrix[i+1][j]` תהיה גישה לכתובת זיכרון המרוחקת ב-`N * sizeof(int)` בתים.\n\n2.  **זיכרון מטמון (CPU Cache):**\n    *   **`process_row_major`**: הפונקציה הזו סורקת את המטריצה בסדר שורות. כאשר ניגשים ל-`matrix[i][j]`, המעבד טוען לזיכרון המטמון (cache) בלוק של זיכרון (cache line) שמכיל את `matrix[i][j]` ואת האלמנטים הסמוכים לו באותה שורה (כלומר, `matrix[i][j+1]`, `matrix[i][j+2]` וכו'). מכיוון שהלולאה הפנימית ממשיכה לגשת לאלמנטים אלו ברצף, רוב הגישות יהיו \"פגיעות מטמון\" (cache hits), מה שמוביל לביצועים מהירים. זהו ניצול יעיל של עקרון המקומיות המרחבית (spatial locality).\n    *   **`process_col_major`**: הפונקציה הזו סורקת את המטריצה בסדר עמודות. כאשר ניגשים ל-`matrix[i][j]`, המעבד טוען בלוק זיכרון ל-cache. מיד לאחר מכן, הלולאה הפנימית ניגשת ל-`matrix[i+1][j]`. אלמנט זה נמצא בכתובת זיכרון רחוקה מאוד מהקודם (במערך הגלובלי, הוא נמצא `N` שלמים קדימה). סביר מאוד שהאלמנט `matrix[i+1][j]` אינו נמצא באותו בלוק זיכרון שנטען קודם לכן. לכן, כל גישה ל-`matrix[i][j]` עבור `i` שונה כנראה תגרום ל\"החטאת מטמון\" (cache miss) חדשה, שתדרוש טעינה של בלוק זיכרון חדש מהזיכרון הראשי (RAM) ל-cache. פעולה זו איטית בהרבה מגישה ל-cache. זהו ניצול לא יעיל של עקרון המקומיות המרחבית.\n\n3.  **עמודים (Paging) ו-TLB (Translation Lookaside Buffer):**\n    *   **Paging**: המטריצה בגודל `N=4096` מכילה `4096 * 4096` שלמים. אם שלם הוא 4 בתים, גודל המטריצה הוא `4096 * 4096 * 4` בתים, שהם `64 MB`. גודל זה גדול בהרבה מזיכרון המטמון ברמות L1/L2/L3 ברוב המעבדים. בנוסף, הוא עשוי להיות גדול יותר מהזיכרון הפיזי הזמין לתהליך במקרים מסוימים, או לפחות לדרוש עמודים רבים.\n        *   ב-`process_row_major`, גישה רציפה משמעותה שברגע שעמוד מסוים נטען לזיכרון פיזי, ניתן לגשת לכל הנתונים שבו ביעילות, מה שמפחית את מספר \"תקלות העמוד\" (page faults).\n        *   ב-`process_col_major`, גישה לא רציפה עלולה לגרום לכך שכל גישה ל-`matrix[i][j]` (עבור `i` שונה) תהיה בכתובת זיכרון וירטואלית השייכת לעמוד אחר. אם מספר העמודים הפעילים עולה על מספר ה-frames הפנויים בזיכרון הפיזי, תהיה סבירות גבוהה לתקלות עמוד רבות, מה שדורש קריאה מהדיסק ואיטי מאוד.\n    *   **TLB (Translation Lookaside Buffer)**: ה-TLB הוא מטמון קטן ומהיר המאחסן מיפויים מכתובות וירטואליות לכתובות פיזיות.\n        *   ב-`process_row_major`, הגישה הרציפה גורמת לכך שמעט מאוד מיפויי עמודים נדרשים בפרק זמן קצר. סביר להניח שמיפויי העמודים יישארו ב-TLB, מה שימנע חיפוש יקר בטבלאות העמודים (page tables) בזיכרון הראשי.\n        *   ב-`process_col_major`, הגישה המפוזרת על פני עמודים רבים גורמת ל\"החטאות TLB\" (TLB misses) תכופות. כל החטאה דורשת מעבר על טבלאות העמודים, פעולה שלוקחת זמן רב ומוסיפה לעיכוב בביצוע.\n\n**קוד מתוקן (אופטימיזציה):**\n\nכדי לשפר את ביצועי `process_col_major` מבלי לשנות את הלוגיקה החישובית, ניתן להשתמש בטכניקת \"חסימה\" (blocking) או \"אריחים\" (tiling). הרעיון הוא לעבד בלוקים קטנים של המטריצה בכל פעם, כך שהנתונים הרלוונטיים ייכנסו לזיכרון המטמון ויישארו שם עד לסיום עיבוד הבלוק.\n\n```c\n#define BLOCK_SIZE 64 // גודל בלוק אופטימלי תלוי בגודל ה-cache ובגודל ה-cache line. 64 הוא לרוב סביר.\n\n// פונקציה 2 משופרת: סריקה בסדר עמודות באמצעות חסימה (tiling)\nvoid process_col_major_optimized() {\n    for (int block_j = 0; block_j < N; block_j += BLOCK_SIZE) {\n        for (int block_i = 0; block_i < N; block_i += BLOCK_SIZE) {\n            // עיבוד בלוק בגודל BLOCK_SIZE x BLOCK_SIZE\n            for (int j = block_j; j < block_j + BLOCK_SIZE && j < N; j++) {\n                for (int i = block_i; i < block_i + BLOCK_SIZE && i < N; i++) {\n                    matrix[i][j] *= 2;\n                }\n            }\n        }\n    }\n}\n```\n\n**הסבר לאופטימיזציה:**\nהאופטימיזציה משפרת את הניצול של עקרון המקומיות המרחבית והזמנית. במקום לסרוק עמוד שלם (שעלול להיות גדול מאוד) לפני המעבר לעמוד הבא, אנו סורקים \"אריח\" (tile) קטן.\nכאשר אנו מעבדים בלוק `BLOCK_SIZE x BLOCK_SIZE`, הגישה ל-`matrix[i][j]` ולאחר מכן ל-`matrix[i+1][j]` עדיין מדלגת על שורות, אך הפעם הדילוגים מתרחשים בתוך בלוק קטן יחסית. אם `BLOCK_SIZE` נבחר נכון (כך שבלוק של `BLOCK_SIZE * BLOCK_SIZE` אלמנטים יכול להיכנס ל-cache), אז לאחר הגישה הראשונית לאלמנטים בבלוק וטעינתם ל-cache, הגישות הבאות לאותם אלמנטים בתוך הבלוק יהיו מהירות יותר (cache hits). זה מפחית באופן דרמטי את מספר ה-cache misses ואף את ה-TLB misses, שכן העבודה מתרכזת באזור זיכרון קטן יותר בכל פעם. אנו עדיין ניגשים בסדר עמודות בתוך הבלוק, אך מכיוון שהבלוק קטן מספיק כדי להישאר ב-cache, עלות ה-cache misses מצטמצמת משמעותית."}, "difficulty_estimation": "Hard", "_source_file": "0497__Memory_Management__CodeAnalysis__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:09:17", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Memory Management", "Virtual Memory", "Paging", "Address Translation"], "content": {"text": "מערכת הפעלה נתונה משתמשת בזיכרון וירטואלי עם כתובות וירטואליות בנות 32 סיביות, וגודל עמוד (page size) של 4KB. המערכת מיישמת טבלת עמודים דו-שלבית לתרגום כתובות. פורמט הכתובת הווירטואלית מחולק לשלושה חלקים: 10 סיביות עבור אינדקס טבלת ספריות העמודים (Page Directory Index), 10 סיביות עבור אינדקס טבלת העמודים (Page Table Index), ו-12 סיביות עבור היסט בתוך העמוד (Offset).\n\nמבנה כניסה בטבלת עמודים (PTE) מוגדר כדלקמן:\n```c\ntypedef struct {\n    uint32_t present : 1;      // 1: page is in physical memory, 0: not present (page fault)\n    uint32_t rw : 1;           // 1: read/write, 0: read-only\n    uint32_t user_supervisor : 1; // 1: user access allowed, 0: supervisor only\n    uint32_t accessed : 1;     // Set by hardware on access\n    uint32_t dirty : 1;        // Set by hardware on write\n    uint32_t global : 1;       // Global page (TLB won't flush on context switch)\n    uint32_t unused : 6;       // Unused/available for OS use\n    uint32_t frame_addr_high : 20; // High 20 bits of the physical frame address (bits 12-31)\n} pte_t;\n```\n\nהפונקציה `translate_virtual_to_physical` מקבלת את הכתובת הפיזית של בסיס ספריית העמודים (page_directory_base), כתובת וירטואלית לתרגום (virtual_address), ודגל המציין האם הגישה היא גישת כתיבה (is_write_access). עליכם להשלים את מימוש הפונקציה כך שתחזיר את הכתובת הפיזית המתאימה, או קוד שגיאה במקרה של כשל.\n\nהפונקציה צריכה לטפל במקרים הבאים:\n1. **כשל עמוד (Page Fault)**: אם כניסה כלשהי בטבלת העמודים (PTE או PDE) אינה מסומנת כ-'present' (הסיבית present היא 0), יש להחזיר את קוד השגיאה `E_PAGE_FAULT`.\n2. **שגיאת הרשאה (Permission Denied)**: אם מבוצעת גישת כתיבה (is_write_access הוא true) לעמוד המסומן כ'קריאה בלבד' (הסיבית rw היא 0), יש להחזיר את קוד השגיאה `E_PERMISSION_DENIED`.\n3. **תרגום מוצלח**: אם כל הבדיקות עוברות, יש לחשב ולהחזיר את הכתובת הפיזית המלאה.\n\nלצורך פשטות המודל, יש להניח כי `page_directory_base` וכן השדה `frame_addr_high` ב-`pte_t` מכילים כתובות פיזיות שניתן להתייחס אליהן ישירות כאל מצביעים בזיכרון הסימולטבי שלנו (כלומר, אין צורך לדאוג למיפוי זיכרון פיזי לכתובות וירטואליות של הקרנל בתוך הפונקציה עצמה).\n\n```c\n#include <stdint.h>\n\n// Constants for system parameters\n#define PAGE_SIZE 4096 // 4KB\n#define BITS_FOR_OFFSET 12\n#define BITS_FOR_INDEX 10 // (32 - BITS_FOR_OFFSET) / 2 = 10\n\n// Masks for extracting parts of a virtual address\n#define PD_INDEX_MASK 0xFFC00000 // Bits 31-22\n#define PT_INDEX_MASK 0x003FF000 // Bits 21-12\n#define OFFSET_MASK   0x00000FFF // Bits 11-0\n\n// Page Table Entry (PTE) structure (as described in the problem)\ntypedef struct {\n    uint32_t present : 1;      // 1: page is in physical memory, 0: not present (page fault)\n    uint32_t rw : 1;           // 1: read/write, 0: read-only\n    uint32_t user_supervisor : 1; // 1: user access allowed, 0: supervisor only\n    uint32_t accessed : 1;     // Set by hardware on access\n    uint32_t dirty : 1;        // Set by hardware on write\n    uint32_t global : 1;       // Global page (TLB won't flush on context switch)\n    uint32_t unused : 6;       // Unused/available for OS use\n    uint32_t frame_addr_high : 20; // High 20 bits of the physical frame address (bits 12-31)\n} pte_t;\n\n// Error codes (using uint64_t to ensure distinct values from valid 32-bit physical addresses)\n#define E_PAGE_FAULT        ((uint64_t)-1)\n#define E_PERMISSION_DENIED ((uint64_t)-2)\n\n// Function signature to implement\nuint64_t translate_virtual_to_physical(uint64_t page_directory_base, uint32_t virtual_address, int is_write_access) {\n    // השלם את הקוד כאן\n}\n```", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון דורש פירוק של הכתובת הווירטואלית למרכיביה: אינדקס ספריית עמודים (PD_INDEX), אינדקס טבלת עמודים (PT_INDEX) והיסט בתוך העמוד (OFFSET). כל אינדקס משמש לגישה לכניסה המתאימה בטבלת העמודים ברמתה. לאחר מכן, יש לבצע בדיקות תקינות והרשאות בכל שלב.\n\n**שלבי הפתרון:**\n1.  **פירוק כתובת וירטואלית**: באמצעות מסכות והזזות סיביות, מחלצים את ה-PD_INDEX, PT_INDEX וה-OFFSET מה-`virtual_address`.\n    *   PD_INDEX (10 סיביות עליונות): מחושב מסיביות 22-31.\n    *   PT_INDEX (10 סיביות אמצעיות): מחושב מסיביות 12-21.\n    *   OFFSET (12 סיביות תחתונות): מחושב מסיביות 0-11.\n2.  **גישה ל-PDE (Page Directory Entry)**: ה-`page_directory_base` מצביע לתחילת ספריית העמודים. אנו מחשבים את הכתובת של ה-PDE המתאים באמצעות `pd_index` וכופלים בגודל של `pte_t`.\n3.  **בדיקת PDE**:\n    *   אם `pde->present` הוא 0, מחזירים `E_PAGE_FAULT`.\n    *   אם `is_write_access` הוא true וגם `pde->rw` הוא 0, מחזירים `E_PERMISSION_DENIED` (בהנחה שסיבית ה-rw ב-PDE חלה על כל טבלת העמודים שהיא מפנה אליה).\n    *   השדה `pde->frame_addr_high` מכיל את 20 הסיביות העליונות של הכתובת הפיזית של טבלת העמודים מהרמה השנייה. אנו משלבים אותו עם 12 סיביות אפסים (הזזה שמאלה ב-`BITS_FOR_OFFSET`) כדי לקבל את כתובת הבסיס של טבלת העמודים.\n4.  **גישה ל-PTE (Page Table Entry)**: באמצעות כתובת הבסיס של טבלת העמודים ו-`pt_index`, מחשבים את הכתובת של ה-PTE המתאים.\n5.  **בדיקת PTE**:\n    *   אם `pte->present` הוא 0, מחזירים `E_PAGE_FAULT`.\n    *   אם `is_write_access` הוא true וגם `pte->rw` הוא 0, מחזירים `E_PERMISSION_DENIED`.\n    *   השדה `pte->frame_addr_high` מכיל את 20 הסיביות העליונות של הכתובת הפיזית של העמוד בפועל (frame).\n6.  **חישוב כתובת פיזית סופית**: משלבים את 20 הסיביות העליונות של כתובת ה-frame (מתוך `pte->frame_addr_high` לאחר הזזה) עם ה-OFFSET כדי לקבל את הכתובת הפיזית המלאה.\n\n```c\n#include <stdint.h>\n#include <stdio.h> // רק לצורך הדגמה/בדיקה, לא נדרש לפתרון עצמו\n\n// Constants for system parameters\n#define PAGE_SIZE 4096 // 4KB\n#define BITS_FOR_OFFSET 12\n#define BITS_FOR_INDEX 10 // (32 - BITS_FOR_OFFSET) / 2 = 10\n\n// Masks for extracting parts of a virtual address\n#define PD_INDEX_MASK 0xFFC00000 // Bits 31-22\n#define PT_INDEX_MASK 0x003FF000 // Bits 21-12\n#define OFFSET_MASK   0x00000FFF // Bits 11-0\n\n// Page Table Entry (PTE) structure\ntypedef struct {\n    uint32_t present : 1;      // 1: page is in physical memory, 0: not present (page fault)\n    uint32_t rw : 1;           // 1: read/write, 0: read-only\n    uint32_t user_supervisor : 1; // 1: user access allowed, 0: supervisor only\n    uint32_t accessed : 1;     // Set by hardware on access\n    uint32_t dirty : 1;        // Set by hardware on write\n    uint32_t global : 1;       // Global page (TLB won't flush on context switch)\n    uint32_t unused : 6;       // Unused/available for OS use\n    uint32_t frame_addr_high : 20; // High 20 bits of the physical frame address (bits 12-31)\n} pte_t;\n\n// Error codes (using uint64_t to ensure distinct values from valid 32-bit physical addresses)\n#define E_PAGE_FAULT        ((uint64_t)-1)\n#define E_PERMISSION_DENIED ((uint64_t)-2)\n\nuint64_t translate_virtual_to_physical(uint64_t page_directory_base, uint32_t virtual_address, int is_write_access) {\n    // Extract indices and offset\n    uint32_t pd_index = (virtual_address & PD_INDEX_MASK) >> (BITS_FOR_OFFSET + BITS_FOR_INDEX);\n    uint32_t pt_index = (virtual_address & PT_INDEX_MASK) >> BITS_FOR_OFFSET;\n    uint32_t offset   = (virtual_address & OFFSET_MASK);\n\n    // Level 1: Page Directory Entry (PDE)\n    // The page_directory_base points to the start of an array of pte_t\n    // Each entry is sizeof(pte_t) bytes\n    pte_t* pde = (pte_t*)(page_directory_base + (pd_index * sizeof(pte_t)));\n\n    // Check PDE validity\n    if (!pde->present) {\n        return E_PAGE_FAULT;\n    }\n\n    // Check PDE permissions for write access (if PDE itself is read-only)\n    // This check assumes PDE's `rw` bit applies to the entire page table it points to.\n    if (is_write_access && !pde->rw) {\n        return E_PERMISSION_DENIED;\n    }\n\n    // Level 2: Page Table Entry (PTE)\n    // The frame_addr_high of the PDE gives the base physical address of the Page Table\n    uint64_t page_table_base = (uint64_t)pde->frame_addr_high << BITS_FOR_OFFSET;\n    pte_t* pte = (pte_t*)(page_table_base + (pt_index * sizeof(pte_t)));\n\n    // Check PTE validity\n    if (!pte->present) {\n        return E_PAGE_FAULT;\n    }\n\n    // Check PTE permissions for write access\n    if (is_write_access && !pte->rw) {\n        return E_PERMISSION_DENIED;\n    }\n\n    // If all checks pass, calculate physical address\n    uint64_t physical_frame_base = (uint64_t)pte->frame_addr_high << BITS_FOR_OFFSET;\n    uint64_t physical_address = physical_frame_base | offset;\n\n    return physical_address;\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0498__Memory_Management__CodeAnalysis__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:09:57", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Memory Management", "Virtual Memory", "Custom Allocator", "Concurrency", "Synchronization"], "content": {"text": "נתבקשתם לתכנן ולממש מנהל זיכרון (Memory Allocator) מותאם אישית עבור יישום הדורש שליטה מדויקת על הקצאת זיכרון, ביצועים גבוהים, ויכולת פעולה בסביבה מרובת חוטים. המנהל אמור לנהל מאגר זיכרון גדול וקבוע בגודלו, שיוקצה פעם אחת בתחילת ריצת התוכנית באמצעות `mmap`.\n\nדרישות המימוש הן כדלקמן:\n1.  **אתחול (Initialization)**: פונקציה `init_allocator()` שתקצה מאגר זיכרון בגודל קבוע (לדוגמה, 1GB) באמצעות `mmap`. קריאה זו תתבצע פעם אחת בלבד.\n2.  **הקצאה (Allocation)**: פונקציה `void *my_malloc(size_t size)` שתקצה בלוק זיכרון בגודל `size` בתים מתוך המאגר המנוהל. הפונקציה צריכה להחזיר מצביע לאזור הנתונים של הבלוק המוקצה. אם אין מספיק זיכרון, הפונקציה תחזיר `NULL`.\n3.  **שחרור (Deallocation)**: פונקציה `void my_free(void *ptr)` שתשחרר בלוק זיכרון שהוקצה בעבר על ידי `my_malloc`. שחרור כפול או שחרור מצביע לא חוקי צריך להיות מטופל באופן בטוח (לדוגמה, על ידי הדפסת שגיאה).\n4.  **איחוד בלוקים (Coalescing)**: כאשר בלוק משוחרר, יש לאחד אותו עם בלוקים חופשיים סמוכים פיזית (אם קיימים) כדי למנוע פיצול חיצוני (External Fragmentation). בלוקים מאוחדים צריכים ליצור בלוק חופשי גדול יותר.\n5.  **בטיחות חוטים (Thread-Safety)**: המנהל חייב להיות בטוח לשימוש בסביבה מרובת חוטים, כלומר, קריאות מקבילות ל-`my_malloc` ו-`my_free` לא יגרמו לשחיתות נתונים או למצבי מרוץ (Race Conditions).\n6.  **יישור (Alignment)**: הזיכרון המוקצה למשתמש צריך להיות מיושר כראוי (לדוגמה, ליישור של `sizeof(long)` או 8 בתים) כדי למנוע שגיאות גישה לזיכרון.\n7.  **יעילות**: יש לשאוף ליעילות סבירה הן מבחינת זמן הריצה של ההקצאה/שחרור והן מבחינת ניצול הזיכרון (overhead מינימלי למטא-דאטה).\n8.  **הגבלות**: אין להשתמש בפונקציות `malloc`, `free`, `calloc`, `realloc` או `sbrk` בתוך המימוש של מנהל הזיכרון. מותר להשתמש ב-`mmap` וב-`pthread_mutex_t` בלבד.\n\nיש להשלים את הקוד המצורף, כולל הגדרות המבנים ומשתנים גלובליים נדרשים.", "code_snippet": "#include <stddef.h> // For size_t\n#include <sys/mman.h> // For mmap, munmap\n#include <unistd.h> // For sysconf (page size)\n#include <pthread.h> // For pthread_mutex_t\n#include <stdio.h> // For perror, fprintf\n\n#define HEAP_SIZE (1 * 1024 * 1024 * 1024UL) // 1GB\n\n// Global variables for the allocator state\nstatic void *heap_start = NULL;\n// Add necessary synchronization primitives and free list structures here\n\n// Forward declaration for block_header_t\ntypedef struct block_header block_header_t;\n\nstruct block_header {\n    size_t size; // Size of the block (including header and footer). MSB indicates allocated/free.\n    // Add pointers for free list or status flags\n    struct block_header *next_free; // Used only if block is free.\n    struct block_header *prev_free; // Used only if block is free.\n};\n\n// Mutex for thread safety\nstatic pthread_mutex_t allocator_mutex;\n\n// Pointer to the head of the free list\nstatic block_header_t *free_list_head = NULL;\n\n// Initialization function\nvoid init_allocator() {\n    // 1. Initialize mutex (if not static)\n    // 2. mmap the HEAP_SIZE region\n    // 3. Initialize the first block_header_t to cover the entire heap\n    // 4. Add this block to the free list\n}\n\n// Allocation function\nvoid *my_malloc(size_t size) {\n    // 1. Lock the mutex\n    // 2. Adjust size for alignment, header, and footer\n    // 3. Search free list for a suitable block (e.g., best-fit)\n    // 4. If found:\n    //    a. Remove block from free list\n    //    b. Split block if remaining space is large enough for another block\n    //    c. Mark block as allocated (update header and footer)\n    // 5. Unlock mutex\n    // 6. Return pointer to user data area\n}\n\n// Deallocation function\nvoid my_free(void *ptr) {\n    // 1. Lock the mutex\n    // 2. Get block header from ptr\n    // 3. Basic validation (is it valid, is it allocated?)\n    // 4. Mark block as free (update header and footer)\n    // 5. Coalesce with adjacent free blocks (previous and next in memory) using boundary tags\n    // 6. Insert/update block in free list, maintaining address order\n    // 7. Unlock mutex\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון המוצע מממש מנהל זיכרון מותאם אישית המבוסס על רשימה מקושרת כפולה של בלוקים חופשיים (Free List). הבלוקים ברשימה מסודרים לפי כתובת זיכרון עולה, מה שמקל על איחוד בלוקים סמוכים פיזית. כל בלוק זיכרון, בין אם הוא מוקצה או חופשי, מכיל כותרת (Header) ורגל (Footer) עם מידע על גודלו, מה שמאפשר מעבר קדימה ואחורה בין בלוקים פיזיים במאגר הזיכרון.\n\n**מבנה הבלוק (`block_header_t`)**:\n- `size_t size`: גודל הבלוק הכולל (כולל הכותרת והרגל). הסיבית המשמעותית ביותר (MSB) של השדה משמשת כדגל לציון אם הבלוק מוקצה (1) או חופשי (0).\n- `block_header_t *next_free`, `block_header_t *prev_free`: מצביעים לבלוק החופשי הבא והקודם ברשימת הבלוקים החופשיים, בהתאמה. מצביעים אלו רלוונטיים רק כאשר הבלוק חופשי.\n- בנוסף, כל בלוק מכיל `size_t` בסופו (כ'רגל' או 'Boundary Tag') המכיל את גודל הבלוק. זה מאפשר לבלוקים 'להביט לאחור' ולמצוא את הכותרת של הבלוק הפיזי הקודם.\n\n**פונקציות עזר:**\n- `is_allocated(block_header_t *block)`: בודקת אם הבלוק מוקצה על ידי בדיקת ה-MSB של שדה הגודל.\n- `get_block_total_size(block_header_t *block)`: מחזירה את גודל הבלוק האמיתי (ללא דגל ההקצאה).\n- `mark_allocated(block_header_t *block, size_t size)`: מסמנת בלוק כמוקצה ומעדכנת את הכותרת והרגל.\n- `mark_free(block_header_t *block, size_t size)`: מסמנת בלוק כחופשי ומעדכנת את הכותרת והרגל.\n- `remove_from_free_list(block_header_t *block)`: מסירה בלוק מרשימת הבלוקים החופשיים.\n- `insert_into_free_list(block_header_t *block)`: מכניסה בלוק לרשימת הבלוקים החופשיים, תוך שמירה על סדר כתובות עולה.\n- `calculate_aligned_block_size(size_t user_size)`: מחשבת את הגודל הכולל של הבלוק (כולל כותרת, רגל ויישור) הנדרש עבור `user_size` נתון. היא גם מבטיחה גודל מינימלי לבלוק על מנת שיוכל להכיל את המטא-דאטה הדרושה.\n\n**`init_allocator()`**:\n- משתמשת ב-`mmap` כדי להקצות מאגר זיכרון רציף בגודל `HEAP_SIZE`.\n- מאתחלת בלוק חופשי יחיד בגודל המאגר כולו, ומכניסה אותו לרשימת הבלוקים החופשיים.\n\n**`my_malloc(size_t size)`**:\n- נועלת Mutex כדי להבטיח בטיחות חוטים.\n- מחשבת את הגודל הכולל הנדרש לבלוק (כולל מטא-דאטה ויישור).\n- סורקת את רשימת הבלוקים החופשיים (בסטרטגיית Best-Fit) כדי למצוא את הבלוק החופשי הקטן ביותר שיכול להכיל את הבקשה.\n- אם נמצא בלוק מתאים:\n    - מסירה אותו מרשימת הבלוקים החופשיים.\n    - בודקת אם ניתן לפצל את הבלוק: אם הגודל הנותר לאחר ההקצאה מספיק גדול עבור בלוק חופשי חדש (כולל מטא-דאטה מינימלית), הבלוק מפוצל. החלק המוקצה מסומן כמוקצה, והחלק הנותר מסומן כחופשי ומוכנס חזרה לרשימת הבלוקים החופשיים בסדר כתובות.\n    - אם לא ניתן לפצל, הבלוק כולו מוקצה.\n- מחזירה מצביע לאזור הנתונים של הבלוק המוקצה (לאחר הכותרת), ומשחררת את ה-Mutex.\n- אם לא נמצא בלוק מתאים, מחזירה `NULL`.\n\n**`my_free(void *ptr)`**:\n- נועלת Mutex.\n- ממירה את מצביע המשתמש למצביע לכותרת הבלוק.\n- מבצעת בדיקת תקינות בסיסית (האם המצביע בתוך המאגר והאם הבלוק אכן מוקצה) כדי למנוע שחרור כפול או שחרור מצביע לא חוקי.\n- מסמנת את הבלוק כחופשי ומעדכנת את הכותרת והרגל.\n- **איחוד (Coalescing)**:\n    - בודקת את הבלוק הפיזי הקודם: באמצעות הרגל של הבלוק הנוכחי, ניתן למצוא את גודלו של הבלוק הפיזי הקודם, ולפיכך את כותרתו. אם הבלוק הפיזי הקודם חופשי, הוא מאוחד עם הבלוק הנוכחי. הבלוק הקודם מוסר מרשימת הבלוקים החופשיים, וגודלו מעודכן.\n    - בודקת את הבלוק הפיזי הבא: אם הבלוק הפיזי הבא חופשי, הוא מאוחד לתוך הבלוק המאוחד הקיים. הבלוק הבא מוסר מרשימת הבלוקים החופשיים, וגודלו של הבלוק המאוחד מעודכן.\n- לאחר איחודים אפשריים, הבלוק (המאוחד כעת) מוכנס חזרה לרשימת הבלוקים החופשיים, תוך שמירה על סדר כתובות עולה.\n- משחררת את ה-Mutex.\n\nפתרון זה מציע איזון טוב בין יעילות (Best-Fit, רשימה מקושרת כפולה ממוינת, איחוד) לבין מורכבות, ועומד בכל הדרישות, כולל בטיחות חוטים וטיפול בפיצול זיכרון.\n\n```c\n#include <stddef.h> // For size_t\n#include <sys/mman.h> // For mmap, munmap\n#include <unistd.h> // For sysconf (page size)\n#include <pthread.h> // For pthread_mutex_t\n#include <stdio.h> // For perror, fprintf\n\n#define HEAP_SIZE (1 * 1024 * 1024 * 1024UL) // 1GB\n#define MIN_ALLOC_USER_SIZE 16 // Minimum user data size to ensure block can hold pointers for free list\n#define ALIGNMENT sizeof(long) // General alignment for malloc\n\n// Block header structure (for both free and allocated blocks)\ntypedef struct block_header {\n    size_t size; // Size of the block (including header and footer). MSB indicates allocated/free.\n    struct block_header *next_free; // Used only if block is free. Points to next free block in address order.\n    struct block_header *prev_free; // Used only if block is free. Points to previous free block in address order.\n} block_header_t;\n\n// A block also has a footer, which is just a size_t storing the block's total size (without flag).\n// This allows traversing backwards.\n\nstatic void *heap_start = NULL;\nstatic block_header_t *free_list_head = NULL; // Head of the doubly linked list of FREE blocks, sorted by address.\nstatic pthread_mutex_t allocator_mutex = PTHREAD_MUTEX_INITIALIZER; // Statically initialize mutex\n\n// Helper to get the footer pointer for a given block header\nstatic size_t *get_footer(block_header_t *block) {\n    return (size_t *)((char *)block + (block->size & ~(1UL << (sizeof(size_t)*8 - 1))) - sizeof(size_t));\n}\n\n// Helper to check if a block is allocated (MSB of size is set)\nstatic int is_allocated(block_header_t *block) {\n    return (block->size & (1UL << (sizeof(size_t)*8 - 1))) != 0;\n}\n\n// Helper to get the true size of a block (without allocated flag)\nstatic size_t get_block_total_size(block_header_t *block) {\n    return block->size & ~(1UL << (sizeof(size_t)*8 - 1));\n}\n\n// Helper to mark a block as allocated\nstatic void mark_allocated(block_header_t *block, size_t size) {\n    block->size = size | (1UL << (sizeof(size_t)*8 - 1)); // Set MSB\n    *get_footer(block) = size; // Update footer\n}\n\n// Helper to mark a block as free\nstatic void mark_free(block_header_t *block, size_t size) {\n    block->size = size; // Clear MSB\n    *get_footer(block) = size; // Update footer\n}\n\n// Helper to remove a block from the free list\nstatic void remove_from_free_list(block_header_t *block) {\n    if (block->prev_free) {\n        block->prev_free->next_free = block->next_free;\n    } else {\n        free_list_head = block->next_free;\n    }\n    if (block->next_free) {\n        block->next_free->prev_free = block->prev_free;\n    }\n    block->next_free = NULL; // Clear pointers\n    block->prev_free = NULL;\n}\n\n// Helper to insert a block into the free list (maintaining address order)\nstatic void insert_into_free_list(block_header_t *block) {\n    block_header_t *current = free_list_head;\n    block_header_t *prev = NULL;\n\n    while (current != NULL && current < block) {\n        prev = current;\n        current = current->next_free;\n    }\n\n    if (prev == NULL) { // Insert at head\n        block->next_free = free_list_head;\n        if (free_list_head) free_list_head->prev_free = block;\n        free_list_head = block;\n    } else { // Insert in middle or at end\n        block->next_free = current;\n        block->prev_free = prev;\n        prev->next_free = block;\n        if (current) current->prev_free = block;\n    }\n}\n\n// Helper to get actual aligned size needed for user data + header + footer\nstatic size_t calculate_aligned_block_size(size_t user_size) {\n    // Minimum block size must accommodate header, footer, and MIN_ALLOC_USER_SIZE\n    // This ensures that even small user requests result in a block large enough to be split later\n    size_t min_effective_user_size = (user_size < MIN_ALLOC_USER_SIZE) ? MIN_ALLOC_USER_SIZE : user_size;\n    size_t total_size = sizeof(block_header_t) + min_effective_user_size + sizeof(size_t); // Header + user_data + Footer\n    return (total_size + ALIGNMENT - 1) & ~(ALIGNMENT - 1); // Align total block size\n}\n\n// Function to initialize the allocator\nvoid init_allocator() {\n    if (heap_start != NULL) {\n        return; // Already initialized\n    }\n\n    // Allocate the heap using mmap\n    heap_start = mmap(NULL, HEAP_SIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);\n    if (heap_start == MAP_FAILED) {\n        perror(\"mmap failed\");\n        // In a real system, handle this gracefully, perhaps by exiting or throwing an exception.\n        return;\n    }\n\n    // Initialize the first (and only) free block spanning the entire heap\n    block_header_t *initial_block = (block_header_t *)heap_start;\n    mark_free(initial_block, HEAP_SIZE); // Mark free, set size in header and footer\n    initial_block->next_free = NULL;\n    initial_block->prev_free = NULL;\n    free_list_head = initial_block;\n}\n\n// Function to allocate memory\nvoid *my_malloc(size_t size) {\n    if (size == 0) {\n        return NULL;\n    }\n\n    pthread_mutex_lock(&allocator_mutex);\n\n    // Calculate the total block size needed (user_size + header + footer), aligned\n    size_t required_block_total_size = calculate_aligned_block_size(size);\n\n    block_header_t *current = free_list_head;\n    block_header_t *best_fit = NULL; // Best-fit strategy\n\n    // Search for the best-fit free block\n    while (current != NULL) {\n        if (get_block_total_size(current) >= required_block_total_size) {\n            if (best_fit == NULL || get_block_total_size(current) < get_block_total_size(best_fit)) {\n                best_fit = current;\n            }\n        }\n        current = current->next_free;\n    }\n\n    if (best_fit == NULL) {\n        // No suitable block found\n        pthread_mutex_unlock(&allocator_mutex);\n        return NULL;\n    }\n\n    block_header_t *block_to_allocate = best_fit;\n    size_t original_block_total_size = get_block_total_size(block_to_allocate);\n\n    // Remove block_to_allocate from the free list\n    remove_from_free_list(block_to_allocate);\n\n    // Check if the remaining part after allocation is large enough to form a new free block\n    if (original_block_total_size - required_block_total_size >= calculate_aligned_block_size(1)) { // Check against minimal block size\n        // Split the block\n        mark_allocated(block_to_allocate, required_block_total_size); // Mark the allocated part\n\n        block_header_t *new_free_block = (block_header_t *)((char *)block_to_allocate + required_block_total_size);\n        mark_free(new_free_block, original_block_total_size - required_block_total_size); // Mark the new free part\n\n        // Insert the new free block back into the free list, maintaining address order\n        insert_into_free_list(new_free_block);\n    } else {\n        // Not enough space to split, allocate the entire block\n        mark_allocated(block_to_allocate, original_block_total_size);\n    }\n\n    pthread_mutex_unlock(&allocator_mutex);\n    return (void *)((char *)block_to_allocate + sizeof(block_header_t)); // Return pointer to user data area\n}\n\n// Function to free memory\nvoid my_free(void *ptr) {\n    if (ptr == NULL) {\n        return;\n    }\n\n    pthread_mutex_lock(&allocator_mutex);\n\n    // Get the block header from the user pointer\n    block_header_t *block_to_free = (block_header_t *)((char *)ptr - sizeof(block_header_t));\n\n    // Basic validation: ensure it's within our heap and marked as allocated\n    if ((void*)block_to_free < heap_start || (void*)block_to_free >= (char*)heap_start + HEAP_SIZE || !is_allocated(block_to_free)) {\n        fprintf(stderr, \"Error: Attempt to free an invalid or unallocated block at %p.\\n\", ptr);\n        pthread_mutex_unlock(&allocator_mutex);\n        return;\n    }\n\n    // Mark the current block as free\n    size_t current_block_total_size = get_block_total_size(block_to_free);\n    mark_free(block_to_free, current_block_total_size);\n\n    // Attempt to coalesce with physically adjacent free blocks\n\n    // Check previous physical block using its footer\n    block_header_t *prev_phys_block = NULL;\n    if (block_to_free > (block_header_t *)heap_start) { // If not the very first block in the heap\n        size_t *prev_footer_ptr = (size_t *)((char *)block_to_free - sizeof(size_t));\n        size_t prev_phys_size = *prev_footer_ptr; // Get size of previous block from its footer\n        prev_phys_block = (block_header_t *)((char *)block_to_free - prev_phys_size);\n\n        // Ensure prev_phys_block is valid and free\n        if ((void*)prev_phys_block >= heap_start && !is_allocated(prev_phys_block)) {\n            // Merge current block into prev_phys_block\n            remove_from_free_list(prev_phys_block); // Remove prev_phys_block from free list\n            mark_free(prev_phys_block, get_block_total_size(prev_phys_block) + current_block_total_size);\n            block_to_free = prev_phys_block; // Now block_to_free refers to the merged block\n            current_block_total_size = get_block_total_size(block_to_free); // Update size\n        }\n    }\n\n    // Check next physical block\n    block_header_t *next_phys_block = (block_header_t *)((char *)block_to_free + current_block_total_size);\n    if ((void *)next_phys_block < (char *)heap_start + HEAP_SIZE && !is_allocated(next_phys_block)) {\n        // Ensure next_phys_block is valid and free\n        // Merge next_phys_block into block_to_free\n        remove_from_free_list(next_phys_block); // Remove next_phys_block from free list\n        mark_free(block_to_free, get_block_total_size(block_to_free) + get_block_total_size(next_phys_block));\n    }\n\n    // Insert the (potentially merged) block into the free list\n    insert_into_free_list(block_to_free);\n\n    pthread_mutex_unlock(&allocator_mutex);\n}\n```\n"}, "difficulty_estimation": "Hard", "_source_file": "0499__Memory_Management__CodeAnalysis__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:11:13", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Memory Management", "Virtual Memory", "Paging", "TLB"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם טבלאות דפים דו-שכבתיות (two-level page tables).\nמרחב הכתובות הווירטואלי הוא בגודל 32 ביט.\nגודל דף (page size) הוא 4 קילובייט (KB).\nכל כניסה בטבלת דפים (Page Table Entry - PTE) היא בגודל 4 בתים.\nגודל טבלת דפים (הן השכבה הראשונה והן השכבה השנייה) הוא 4 קילובייט.\n\nהמערכת מצוידת ב-TLB (Translation Lookaside Buffer) בגודל 16 כניסות, הפועל בשיטה אסוציאטיבית מלאה (fully associative) עם מדיניות החלפה LRU (Least Recently Used).\nנניח שה-TLB ריק לחלוטין בתחילת ריצת התוכנית.\n\nנתונה תוכנית ה-C הבאה שמבצעת גישה למערך גדול.\nיש לנתח את קטע הקוד ולחשב את:\n1.  מספר ה-TLB misses הכולל שיתרחשו במהלך ריצת הלולאה הפנימית בתוכנית הנתונה.\n2.  מספר הגישות הכולל לטבלאות הדפים (page table walks), כאשר כל \"walk\" כזה כולל גישה לכל רמת טבלת דפים.\nיש להניח שכל הדפים הדרושים נמצאים בזיכרון הפיזי (אין page faults) ושכל הגישות לזיכרון הפיזי, כולל גישות לטבלאות דפים, לוקחות זמן זהה. אין להניח שדפי טבלאות הדפים נשארים ב-CPU cache בין גישות שונות, אלא אם צוין אחרת במפורש.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define ARRAY_SIZE (1024 * 1024) // 1M integers\n#define PAGE_SIZE (4 * 1024)     // 4KB\n#define INT_SIZE (sizeof(int))   // 4 bytes\n\nint main() {\n    int *arr = (int *)malloc(ARRAY_SIZE * INT_SIZE);\n    if (arr == NULL) {\n        perror(\"malloc failed\");\n        return 1;\n    }\n\n    // Access pattern\n    for (int i = 0; i < 1024; ++i) { // Outer loop\n        for (int j = 0; j < ARRAY_SIZE; j += (PAGE_SIZE / INT_SIZE)) { // Inner loop: Accesses start of each page\n            arr[j] = i; // Write access\n        }\n    }\n\n    free(arr);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "נתחיל בניתוח מבנה הזיכרון הווירטואלי והגישה לזיכרון:\n1.  **מבנה כתובת וירטואלית:**\n    *   גודל דף (Page Size) הוא 4KB = 2^12 בתים. לכן, ה-Offset בכתובת הווירטואלית הוא 12 ביטים.\n    *   גודל כניסה בטבלת דפים (PTE) הוא 4 בתים.\n    *   גודל טבלת דפים הוא 4KB. לכן, מספר הכניסות בכל טבלת דפים הוא 4KB / 4 בתים = 1024 כניסות = 2^10 כניסות.\n    *   מספר הביטים הנדרש לכל אינדקס בטבלת דפים (P1 Index ו-P2 Index) הוא 10 ביטים.\n    *   מבנה הכתובת הווירטואלית (32 ביטים): 10 ביטים עבור P1 Index, 10 ביטים עבור P2 Index, ו-12 ביטים עבור Offset.\n\n2.  **גודל המערך וכיסוי דפים:**\n    *   `ARRAY_SIZE = 1024 * 1024` שלמים.\n    *   גודל שלם (`sizeof(int)`) הוא 4 בתים.\n    *   סה\"כ גודל המערך בזיכרון הוא `1024 * 1024 * 4` בתים = `4MB`.\n    *   מספר הדפים שהמערך תופס בזיכרון הווירטואלי הוא `4MB / 4KB = (4 * 1024 * 1024) / (4 * 1024) = 1024` דפים.\n\n3.  **תבנית הגישה לזיכרון (Access Pattern):**\n    *   הלולאה החיצונית רצה 1024 פעמים (`i` מ-0 עד 1023).\n    *   הלולאה הפנימית רצה מ-`j=0` וקופצת בכל פעם ב-`PAGE_SIZE / INT_SIZE`.\n    *   `PAGE_SIZE / INT_SIZE = 4KB / 4 bytes = 1024`.\n    *   כלומר, הלולאה הפנימית ניגשת לאיברים `arr[0]`, `arr[1024]`, `arr[2048]`, וכן הלאה.\n    *   אלו הם בדיוק האיבר הראשון בכל אחד מהדפים של המערך. כל גישה בתוך הלולאה הפנימית מתבצעת לדף ייחודי (כל פעם לדף הבא מתוך 1024 הדפים שהמערך תופס).\n    *   מספר הגישות בלולאה הפנימית הוא `ARRAY_SIZE / (PAGE_SIZE / INT_SIZE) = (1024 * 1024) / 1024 = 1024` גישות.\n\n4.  **חישוב TLB Misses:**\n    *   גודל ה-TLB הוא 16 כניסות.\n    *   בכל איטרציה של הלולאה החיצונית (`i`), הלולאה הפנימית ניגשת ל-1024 דפים ייחודיים שונים בזיכרון.\n    *   מכיוון ש-1024 (מספר הדפים הייחודיים הנגשים) גדול בהרבה מ-16 (גודל ה-TLB), ה-TLB יחווה \"Thrashing\".\n    *   לאחר 16 הגישות הראשונות בלולאה הפנימית (עבור `i` מסוים), ה-TLB יתמלא. בכל גישה נוספת לדף חדש, יתרחש TLB miss ודף ישן (ה-LRU) ייזרק מה-TLB.\n    *   כאשר הלולאה החיצונית מתקדמת לאיטרציה הבאה (`i+1`), ה-TLB מכיל את ה-16 הדפים האחרונים שנגשו אליהם באיטרציה הקודמת של הלולאה הפנימית. אולם, הלולאה הפנימית תתחיל שוב מ-`arr[0]` (דף 0), ותעבור שוב על 1024 הדפים. אף אחד מהדפים הללו לא יימצא ב-TLB מהאיטרציה הקודמת של הלולאה החיצונית, שכן ה-TLB קטן מדי בכדי להחזיק את כל 1024 הדפים לאורך כל איטרציות הלולאה החיצונית.\n    *   לכן, בכל גישה לזיכרון בתוך הלולאה הפנימית, יתרחש TLB miss.\n    *   סה\"כ TLB misses = (מספר איטרציות הלולאה החיצונית) * (מספר גישות בלולאה הפנימית)\n    *   סה\"כ TLB misses = `1024 * 1024 = 1,048,576`.\n\n5.  **חישוב גישות לטבלאות הדפים (Page Table Walks):**\n    *   כל TLB miss גורם לביצוע Page Table Walk.\n    *   עבור טבלת דפים דו-שכבתית, כל Page Table Walk דורש שתי גישות לזיכרון הפיזי:\n        *   גישה אחת לטבלת הדפים של השכבה הראשונה (P1).\n        *   גישה אחת לטבלת הדפים של השכבה השנייה (P2).\n    *   סה\"כ גישות לטבלאות הדפים = (סה\"כ TLB misses) * (מספר גישות זיכרון לכל Page Table Walk).\n    *   סה\"כ גישות לטבלאות הדפים = `1,048,576 * 2 = 2,097,152`."}, "difficulty_estimation": "Hard", "_source_file": "0500__Memory_Management__CodeAnalysis__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:11:48", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Memory Management", "Virtual Memory", "Paging", "TLB", "Page Faults"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם חלוקה לדפים (paging) ובמנגנון דפדוף לפי דרישה (demand paging). למערכת יש TLB (Translation Lookaside Buffer) המטמון תרגומי כתובות.\n\n**מאפייני המערכת:**\n*   **מרחב כתובות וירטואלי:** 16 ביטים.\n*   **מרחב כתובות פיזי:** 16 ביטים.\n*   **גודל דף:** 256 בתים (0x100). המשמעות היא שה-offset הוא 8 ביטים, ומספר הדף הווירטואלי (VPN) או הפיזי (PPN) הוא 8 ביטים.\n*   **טבלת דפים (Page Table):** כל כניסה בטבלת הדפים (PTE) מכילה את הביטים הבאים: Valid (V), Dirty (D), Referenced (R) ואת מספר הדף הפיזי (PPN).\n*   **TLB:** מכיל 4 כניסות, אסוציאטיבי מלא (fully associative) ומשתמש במדיניות החלפה LRU (Least Recently Used).\n*   **טיפול בתקלות דף (Page Faults):** כאשר מתרחשת תקלת דף (כלומר, ביט V=0 ב-PTE), מוקצה דף פיזי חדש. לצורך הבעיה, הניחו כי PPN חדשים מוקצים באופן סדרתי החל מ-0x14 (כלומר, 0x14, 0x15, וכו'). ביט V של ה-PTE החדש יוגדר ל-1, וביטי D ו-R יוגדרו ל-0 בתחילה (אלא אם הגישה היא כתיבה, שאז D יוגדר ל-1).\n\n**מצב התחלתי:**\n*   **TLB:** ריק לחלוטין.\n*   **טבלת דפים (חלקית):**\n    | VPN  | V | D | R | PPN   |\n    |------|---|---|---|-------|\n    | 0x00 | 1 | 0 | 0 | 0x10  |\n    | 0x01 | 1 | 0 | 0 | 0x11  |\n    | 0x02 | 0 | 0 | 0 | (לא תקף)|\n    | 0x03 | 1 | 0 | 0 | 0x12  |\n    | 0x04 | 0 | 0 | 0 | (לא תקף)|\n    | 0x05 | 1 | 0 | 0 | 0x13  |\n    (כל שאר ה-VPNs אינם תקפים (V=0) ו-PPN לא מוגדר).\n\n**רצף גישות לזיכרון:**\nעקבו אחר רצף הגישות לזיכרון המפורט בקוד הבא. עבור כל גישה, ציין את הפרטים הבאים:\n1.  הכתובת הווירטואלית (VA) המבוקשת.\n2.  מספר הדף הווירטואלי (VPN) וה-offset.\n3.  האם זו פגיעה (Hit) או החטאה (Miss) ב-TLB? נמק.\n4.  אם זו החטאה ב-TLB, האם זו פגיעה (Hit) או החטאה (Miss) בטבלת הדפים? (כלומר, האם מתרחשת תקלת דף?) נמק.\n5.  הכתובת הפיזית (PA) המתקבלת לאחר התרגום.\n6.  כיצד משתנים מצבי ה-TLB וטבלת הדפים (כולל ביטי V, D, R) כתוצאה מהגישה. הצג את מצב ה-TLB הסופי ואת השינויים בטבלת הדפים הרלוונטיים.\n", "code_snippet": "void simulate_memory_accesses() {\n    // Initial Page Table State (simplified representation):\n    // VPN | Valid | Dirty | Referenced | PPN\n    // ---------------------------------------\n    // 0x00 |   1   |   0   |     0      | 0x10\n    // 0x01 |   1   |   0   |     0      | 0x11\n    // 0x02 |   0   |   0   |     0      | (invalid)\n    // 0x03 |   1   |   0   |     0      | 0x12\n    // 0x04 |   0   |   0   |     0      | (invalid)\n    // 0x05 |   1   |   0   |     0      | 0x13\n    // (Other VPNs are initially invalid)\n\n    // Initial TLB State: Empty\n\n    // Memory Access Sequence:\n    read_memory(0x0050); // Read operation at VA 0x0050\n    write_memory(0x01A0); // Write operation at VA 0x01A0\n    read_memory(0x03F0);  // Read operation at VA 0x03F0\n    read_memory(0x0020);  // Read operation at VA 0x0020\n    write_memory(0x0210); // Write operation at VA 0x0210\n    read_memory(0x05B0);  // Read operation at VA 0x05B0\n    read_memory(0x0150);  // Read operation at VA 0x0150\n    write_memory(0x0270); // Write operation at VA 0x0270\n}\n", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "להלן פירוט הגישות לזיכרון וכיצד הן משפיעות על ה-TLB וטבלת הדפים:\n\n**מצב התחלתי:**\n*   **TLB:** ריק.\n*   **טבלת דפים (PT):**\n    | VPN  | V | D | R | PPN   |\n    |------|---|---|---|-------|\n    | 0x00 | 1 | 0 | 0 | 0x10  |\n    | 0x01 | 1 | 0 | 0 | 0x11  |\n    | 0x02 | 0 | 0 | 0 | N/A   |\n    | 0x03 | 1 | 0 | 0 | 0x12  |\n    | 0x04 | 0 | 0 | 0 | N/A   |\n    | 0x05 | 1 | 0 | 0 | 0x13  |\n\n**מספר דף פיזי פנוי הבא:** 0x14\n\n---\n\n**1. גישה: `read_memory(0x0050)`**\n*   **VA:** 0x0050\n*   **VPN:** 0x00, **Offset:** 0x50\n*   **TLB:** החטאה (Miss) – ה-TLB ריק.\n*   **טבלת דפים:** פגיעה (Hit) – PTE עבור 0x00 (V=1, PPN=0x10). אין תקלת דף. ביט R ב-PTE מוגדר ל-1.\n*   **PA:** 0x1050 (0x10 << 8 | 0x50)\n*   **עדכון מצב:**\n    *   **TLB:** נוספת כניסה (0x00, 0x10, V=1, D=0, R=1). הופכת ל-MRU.\n        TLB: `[(0x00, 0x10, V=1, D=0, R=1)]` (MRU)\n    *   **PT (VPN 0x00):** V=1, D=0, R=1, PPN=0x10\n\n---\n\n**2. גישה: `write_memory(0x01A0)`**\n*   **VA:** 0x01A0\n*   **VPN:** 0x01, **Offset:** 0xA0\n*   **TLB:** החטאה (Miss) – VPN 0x01 אינו ב-TLB.\n*   **טבלת דפים:** פגיעה (Hit) – PTE עבור 0x01 (V=1, PPN=0x11). אין תקלת דף. ביט R ב-PTE מוגדר ל-1, וביט D מוגדר ל-1 (כתיבה).\n*   **PA:** 0x11A0 (0x11 << 8 | 0xA0)\n*   **עדכון מצב:**\n    *   **TLB:** נוספת כניסה (0x01, 0x11, V=1, D=1, R=1). הופכת ל-MRU.\n        TLB: `[(0x00, 0x10, V=1, D=0, R=1) (LRU), (0x01, 0x11, V=1, D=1, R=1) (MRU)]`\n    *   **PT (VPN 0x01):** V=1, D=1, R=1, PPN=0x11\n\n---\n\n**3. גישה: `read_memory(0x03F0)`**\n*   **VA:** 0x03F0\n*   **VPN:** 0x03, **Offset:** 0xF0\n*   **TLB:** החטאה (Miss) – VPN 0x03 אינו ב-TLB.\n*   **טבלת דפים:** פגיעה (Hit) – PTE עבור 0x03 (V=1, PPN=0x12). אין תקלת דף. ביט R ב-PTE מוגדר ל-1.\n*   **PA:** 0x12F0 (0x12 << 8 | 0xF0)\n*   **עדכון מצב:**\n    *   **TLB:** נוספת כניסה (0x03, 0x12, V=1, D=0, R=1). הופכת ל-MRU.\n        TLB: `[(0x00, 0x10, V=1, D=0, R=1) (LRU), (0x01, 0x11, V=1, D=1, R=1), (0x03, 0x12, V=1, D=0, R=1) (MRU)]`\n    *   **PT (VPN 0x03):** V=1, D=0, R=1, PPN=0x12\n\n---\n\n**4. גישה: `read_memory(0x0020)`**\n*   **VA:** 0x0020\n*   **VPN:** 0x00, **Offset:** 0x20\n*   **TLB:** פגיעה (Hit) – VPN 0x00 נמצא ב-TLB. PPN=0x10. ביט R ב-PTE (וב-TLB) מוגדר ל-1 (כבר 1).\n*   **PA:** 0x1020 (0x10 << 8 | 0x20)\n*   **עדכון מצב:**\n    *   **TLB:** הכניסה (0x00, 0x10, V=1, D=0, R=1) מועברת למיקום ה-MRU.\n        TLB: `[(0x01, 0x11, V=1, D=1, R=1) (LRU), (0x03, 0x12, V=1, D=0, R=1), (0x00, 0x10, V=1, D=0, R=1) (MRU)]`\n    *   **PT (VPN 0x00):** ללא שינוי (V=1, D=0, R=1, PPN=0x10).\n\n---\n\n**5. גישה: `write_memory(0x0210)`**\n*   **VA:** 0x0210\n*   **VPN:** 0x02, **Offset:** 0x10\n*   **TLB:** החטאה (Miss) – VPN 0x02 אינו ב-TLB.\n*   **טבלת דפים:** החטאה (Miss) – PTE עבור 0x02 (V=0). **תקלת דף!** מוקצה דף פיזי חדש: PPN 0x14.\n*   **PA:** 0x1410 (0x14 << 8 | 0x10)\n*   **עדכון מצב:**\n    *   **TLB:** נוספת כניסה (0x02, 0x14, V=1, D=1, R=1). הופכת ל-MRU. ה-TLB כעת מלא.\n        TLB: `[(0x01, 0x11, V=1, D=1, R=1) (LRU), (0x03, 0x12, V=1, D=0, R=1), (0x00, 0x10, V=1, D=0, R=1), (0x02, 0x14, V=1, D=1, R=1) (MRU)]`\n    *   **PT (VPN 0x02):** V=1, D=1, R=1, PPN=0x14. (ביט D מוגדר ל-1 עקב פעולת כתיבה).\n    *   **מספר דף פיזי פנוי הבא:** 0x15\n\n---\n\n**6. גישה: `read_memory(0x05B0)`**\n*   **VA:** 0x05B0\n*   **VPN:** 0x05, **Offset:** 0xB0\n*   **TLB:** החטאה (Miss) – VPN 0x05 אינו ב-TLB.\n*   **טבלת דפים:** פגיעה (Hit) – PTE עבור 0x05 (V=1, PPN=0x13). אין תקלת דף. ביט R ב-PTE מוגדר ל-1.\n*   **PA:** 0x13B0 (0x13 << 8 | 0xB0)\n*   **עדכון מצב:**\n    *   **TLB:** ה-TLB מלא. כניסת ה-LRU (0x01, 0x11) מוצאת. נוספת כניסה (0x05, 0x13, V=1, D=0, R=1). הופכת ל-MRU.\n        TLB: `[(0x03, 0x12, V=1, D=0, R=1) (LRU), (0x00, 0x10, V=1, D=0, R=1), (0x02, 0x14, V=1, D=1, R=1), (0x05, 0x13, V=1, D=0, R=1) (MRU)]`\n    *   **PT (VPN 0x05):** V=1, D=0, R=1, PPN=0x13\n\n---\n\n**7. גישה: `read_memory(0x0150)`**\n*   **VA:** 0x0150\n*   **VPN:** 0x01, **Offset:** 0x50\n*   **TLB:** החטאה (Miss) – VPN 0x01 הוצא מה-TLB בצעד הקודם.\n*   **טבלת דפים:** פגיעה (Hit) – PTE עבור 0x01 (V=1, PPN=0x11). אין תקלת דף. ביט R ב-PTE מוגדר ל-1 (כבר 1).\n*   **PA:** 0x1150 (0x11 << 8 | 0x50)\n*   **עדכון מצב:**\n    *   **TLB:** ה-TLB מלא. כניסת ה-LRU (0x03, 0x12) מוצאת. נוספת כניסה (0x01, 0x11, V=1, D=1, R=1). הופכת ל-MRU.\n        TLB: `[(0x00, 0x10, V=1, D=0, R=1) (LRU), (0x02, 0x14, V=1, D=1, R=1), (0x05, 0x13, V=1, D=0, R=1), (0x01, 0x11, V=1, D=1, R=1) (MRU)]`\n    *   **PT (VPN 0x01):** ללא שינוי (V=1, D=1, R=1, PPN=0x11).\n\n---\n\n**8. גישה: `write_memory(0x0270)`**\n*   **VA:** 0x0270\n*   **VPN:** 0x02, **Offset:** 0x70\n*   **TLB:** פגיעה (Hit) – VPN 0x02 נמצא ב-TLB. PPN=0x14. ביט R ב-PTE (וב-TLB) מוגדר ל-1 (כבר 1), וביט D מוגדר ל-1 (כבר 1).\n*   **PA:** 0x1470 (0x14 << 8 | 0x70)\n*   **עדכון מצב:**\n    *   **TLB:** הכניסה (0x02, 0x14, V=1, D=1, R=1) מועברת למיקום ה-MRU.\n        TLB: `[(0x00, 0x10, V=1, D=0, R=1) (LRU), (0x05, 0x13, V=1, D=0, R=1), (0x01, 0x11, V=1, D=1, R=1), (0x02, 0x14, V=1, D=1, R=1) (MRU)]`\n    *   **PT (VPN 0x02):** ללא שינוי (V=1, D=1, R=1, PPN=0x14).\n"}, "difficulty_estimation": "Hard", "_source_file": "0501__Memory_Management__CodeAnalysis__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:12:44", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Memory Management", "Virtual Memory", "Paging", "TLB", "Page Faults"], "content": {"text": "נתונה מערכת זיכרון וירטואלי בעלת המאפיינים הבאים:\n*   כתובות וירטואליות בגודל 32 סיביות.\n*   גודל דף: 4 קילובייט (KB).\n*   טבלת דפים דו-שכבתית (Two-level Page Table).\n    *   אינדקס לטבלת דפי ספריות (Page Directory Index - PDI) בגודל 10 סיביות.\n    *   אינדקס לטבלת דפים (Page Table Index - PTI) בגודל 10 סיביות.\n    *   קיזוז (Offset) בגודל 12 סיביות.\n*   TLB (Translation Lookaside Buffer) בגודל 4 כניסות, אסוציאטיבי מלא (Fully Associative), עם מדיניות החלפה LRU (Least Recently Used). ה-TLB ריק בתחילת הריצה.\n*   כל טבלאות הדפים (Page Directory ו-Page Tables) נמצאות בזיכרון הפיזי ונגישות מיד (כלומר, אין Page Faults בגין גישה לטבלאות דפים).\n*   כל דפי הנתונים (Data Pages) אינם נמצאים בזיכרון הפיזי בתחילת הריצה. גישה ראשונה לדף נתונים כלשהו תגרום ל-Page Fault, ולאחר מכן הדף יטען לזיכרון הפיזי. מסגרות דפים פיזיות (PPNs) מוקצות באופן סדרתי החל מ-PPN 100.\n\nנתונה רשימת הגישות לכתובות וירטואליות הבאות:\n\nעקבו אחר רצף הגישות לזיכרון הווירטואלי הנתון. עבור כל גישה, ציינו האם היא גורמת ל-TLB Hit או TLB Miss, והאם היא גורמת ל-Page Fault.\nבסיום, סכמו את המספר הכולל של TLB Misses ואת המספר הכולל של Page Faults.\nיש לפרט את מצב ה-TLB (אילו כניסות קיימות ובאיזה סדר LRU) בכל שלב.", "code_snippet": "unsigned int addresses[] = {\n    0x00001000,\n    0x00002000,\n    0x00001004,\n    0x00003000,\n    0x00004000,\n    0x00001008,\n    0x00005000,\n    0x0000200C,\n    0x00006000,\n    0x00003010\n};", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ניתוח הגישות לזיכרון:\n\nנתונים:\n*   גודל VA: 32 ביט.\n*   גודל דף: 4KB = 2^12 בתים.\n*   Offset: 12 ביט.\n*   VPN (Virtual Page Number) = VA >> 12.\n*   TLB בגודל 4 כניסות, LRU.\n*   בתחילה, TLB ריק.\n*   בתחילה, אף דף נתונים אינו בזיכרון פיזי. PPNs מתחילים מ-100.\n\n| גישה | כתובת וירטואלית | VPN | מצב TLB (VPN:PPN, מהפחות-עדכני ליותר-עדכני) | TLB Hit/Miss | Page Fault? | PPN שהוקצה | הערות                                                                                                    |\n| :--- | :-------------- | :-- | :----------------------------------------- | :----------- | :---------- | :-------- | :------------------------------------------------------------------------------------------------------- |\n| 1    | `0x00001000`    | 1   | `[]`                                       | Miss         | כן          | 100       | דף 1 אינו ב-TLB, אינו בזיכרון. טוענים ל-PPN 100. TLB: `[1:100]`                                          |\n| 2    | `0x00002000`    | 2   | `[1:100]`                                  | Miss         | כן          | 101       | דף 2 אינו ב-TLB, אינו בזיכרון. טוענים ל-PPN 101. TLB: `[1:100, 2:101]`                                   |\n| 3    | `0x00001004`    | 1   | `[2:101, 1:100]`                           | Hit          | לא          |           | דף 1 נמצא ב-TLB. מעדכנים LRU. TLB: `[2:101, 1:100]`                                                      |\n| 4    | `0x00003000`    | 3   | `[2:101, 1:100]`                           | Miss         | כן          | 102       | דף 3 אינו ב-TLB, אינו בזיכרון. טוענים ל-PPN 102. TLB: `[2:101, 1:100, 3:102]`                             |\n| 5    | `0x00004000`    | 4   | `[2:101, 1:100, 3:102]`                    | Miss         | כן          | 103       | דף 4 אינו ב-TLB, אינו בזיכרון. טוענים ל-PPN 103. TLB: `[2:101, 1:100, 3:102, 4:103]`                      |\n| 6    | `0x00001008`    | 1   | `[2:101, 3:102, 4:103, 1:100]`             | Hit          | לא          |           | דף 1 נמצא ב-TLB. מעדכנים LRU. TLB: `[2:101, 3:102, 4:103, 1:100]`                                        |\n| 7    | `0x00005000`    | 5   | `[2:101, 3:102, 4:103, 1:100]`             | Miss         | כן          | 104       | דף 5 אינו ב-TLB, אינו בזיכרון. ה-TLB מלא, מוציאים את 2 (LRU). טוענים ל-PPN 104. TLB: `[3:102, 4:103, 1:100, 5:104]` |\n| 8    | `0x0000200C`    | 2   | `[3:102, 4:103, 1:100, 5:104]`             | Miss         | לא          |           | דף 2 אינו ב-TLB, אך הוא בזיכרון (PPN 101). ה-TLB מלא, מוציאים את 3 (LRU). TLB: `[4:103, 1:100, 5:104, 2:101]` |\n| 9    | `0x00006000`    | 6   | `[4:103, 1:100, 5:104, 2:101]`             | Miss         | כן          | 105       | דף 6 אינו ב-TLB, אינו בזיכרון. ה-TLB מלא, מוציאים את 4 (LRU). טוענים ל-PPN 105. TLB: `[1:100, 5:104, 2:101, 6:105]` |\n| 10   | `0x00003010`    | 3   | `[1:100, 5:104, 2:101, 6:105]`             | Miss         | לא          |           | דף 3 אינו ב-TLB, אך הוא בזיכרון (PPN 102). ה-TLB מלא, מוציאים את 1 (LRU). TLB: `[5:104, 2:101, 6:105, 3:102]` |\n\nסיכום:\n*   סה\"כ גישות: 10\n*   סה\"כ TLB Misses: 8\n*   סה\"כ Page Faults: 7 (עבור VPNs 1, 2, 3, 4, 5, 6)"}, "difficulty_estimation": "Hard", "_source_file": "0502__Memory_Management__CodeAnalysis__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:13:16", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Memory Management", "Dynamic Allocation", "Heap Management", "Fragmentation", "Coalescing"], "content": {"text": "נתונה תוכנית המממשת מנהל זיכרון פשוט משלה, הכולל פונקציות `my_malloc` ו-`my_free`. המנהל משתמש ברשימה מקושרת של בלוקים פנויים. הפונקציה `my_malloc` מיישמת אסטרטגיית \"ההתאמה הראשונה\" (First-Fit) ומפצלת בלוקים גדולים מדי. הפונקציה `my_free` מוסיפה בלוקים פנויים בחזרה לרשימה הממוינת לפי כתובת ומנסה לאחד בלוקים סמוכים פיזית (coalescing) כדי למנוע פיצול חיצוני (external fragmentation).\n\nקראו בעיון את הקוד המצורף וענו על השאלות הבאות:\n\n1.  **זיהוי באג ודוגמה:** תארו תרחיש ספציפי (רצף של קריאות ל-`my_malloc` ו-`my_free` עם גדלים מסוימים) שבו הבאג בפונקציה `my_free` מוביל לפיצול חיצוני שניתן היה למנוע. הסבירו מדוע הפיצול מתרחש בתרחיש שתיארתם.\n2.  **הסבר הבאג:** הסבירו לעומק את שורש הבאג בקוד של `my_free` שגורם לפיצול החיצוני. התייחסו לאופן שבו לולאת האיחוד עובדת ומהי הבעיה בה.\n3.  **תיקון הבאג:** הציעו תיקון לקוד של `my_free` שיפתור את הבאג שתואר לעיל, ויבטיח איחוד מלא של בלוקים סמוכים פיזית. כתבו את קטע הקוד המתוקן.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h> // For sbrk\n\n// Define block structure\ntypedef struct Block {\n    size_t size; // Total size of the block including header\n    struct Block *next;\n    // Data area starts here\n} Block;\n\n#define BLOCK_HEADER_SIZE sizeof(Block)\n#define ALIGNMENT 8 // Align all allocations to 8 bytes\n\n// Global head of the free list.\nBlock *free_list_head = NULL;\n\n// Helper to align size\nsize_t align_size(size_t size) {\n    return (size + ALIGNMENT - 1) & ~(ALIGNMENT - 1);\n}\n\n// Custom malloc - first fit\nvoid* my_malloc(size_t size) {\n    size = align_size(size);\n    size_t total_required_size = size + BLOCK_HEADER_SIZE;\n\n    Block *current = free_list_head;\n    Block *prev = NULL;\n\n    while (current != NULL) {\n        if (current->size >= total_required_size) {\n            // Found a suitable block\n            if (current->size - total_required_size >= BLOCK_HEADER_SIZE + ALIGNMENT) { // If enough space to split\n                // Split the block\n                Block *new_free_block = (Block*)((char*)current + total_required_size);\n                new_free_block->size = current->size - total_required_size;\n                new_free_block->next = current->next; // The new free block inherits the rest of the list\n\n                current->size = total_required_size; // 'current' is now the allocated block\n\n                // Update the free list: 'new_free_block' replaces 'current'\n                if (prev == NULL) {\n                    free_list_head = new_free_block;\n                } else {\n                    prev->next = new_free_block;\n                }\n            } else { // Not enough space to split, take the whole block\n                // Remove 'current' from the free list\n                if (prev == NULL) {\n                    free_list_head = current->next;\n                } else {\n                    prev->next = current->next;\n                }\n            }\n            current->next = NULL; // Mark allocated block's next as NULL for safety/clarity\n            return (void*)((char*)current + BLOCK_HEADER_SIZE);\n        }\n        prev = current;\n        current = current->next;\n    }\n\n    // No suitable block found, extend heap\n    Block *new_block = (Block*)sbrk(total_required_size);\n    if (new_block == (void*)-1) {\n        return NULL; // sbrk failed\n    }\n    new_block->size = total_required_size;\n    new_block->next = NULL; // This block is fully allocated, not part of free list yet\n\n    return (void*)((char*)new_block + BLOCK_HEADER_SIZE);\n}\n\n// Custom free with merging logic (BUGGY VERSION for the question)\nvoid my_free(void *ptr) {\n    if (ptr == NULL) return;\n\n    Block *block_to_free = (Block*)((char*)ptr - BLOCK_HEADER_SIZE);\n    \n    // Insert the block into the free list, keeping it sorted by address\n    Block *current_node = free_list_head;\n    Block *prev_node = NULL;\n\n    while (current_node != NULL && current_node < block_to_free) {\n        prev_node = current_node;\n        current_node = current_node->next;\n    }\n\n    if (prev_node == NULL) { // Insert at head\n        block_to_free->next = free_list_head;\n        free_list_head = block_to_free;\n    } else { // Insert in middle or at end\n        block_to_free->next = current_node;\n        prev_node->next = block_to_free;\n    }\n\n    // Now, attempt to merge adjacent free blocks in a single pass.\n    // This is where the bug lies for the question.\n    current_node = free_list_head;\n    while (current_node != NULL && current_node->next != NULL) {\n        // Check if current_node and its successor are physically adjacent\n        if ((char*)current_node + current_node->size == (char*)current_node->next) {\n            // Merge current_node and current_node->next\n            current_node->size += current_node->next->size;\n            current_node->next = current_node->next->next; // Skip the merged block\n            // BUG: After merging, current_node is immediately advanced in the next line,\n            // preventing it from checking if the newly enlarged block can merge with its new successor.\n        } \n        current_node = current_node->next; // BUG: This line executes unconditionally, even after a merge.\n    }\n}"}, "sub_questions": null, "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  **זיהוי באג ודוגמה:**\n    נניח מצב התחלתי שבו הזיכרון הפנוי מכיל שלושה בלוקים סמוכים פיזית (A, B, C) שמופיעים ברשימה המקושרת בסדר פיזי:\n    `free_list_head -> [Block A, size=X] -> [Block B, size=Y] -> [Block C, size=Z] -> NULL`\n    (כאשר A, B, C הם בלוקים סמוכים פיזית בזיכרון, וגודלם כולל את ה-header). נניח ש-X, Y, Z מספיק גדולים.\n    \n    כאשר לולאת האיחוד ב-`my_free` רצה:\n    1.  `current_node = A`. `current_node->next = B`. נניח ש-A ו-B סמוכים פיזית.\n        *   מתבצע איחוד: `A->size` גדל (לכלול את B), ו-`A->next` מצביע כעת על `C`. הרשימה נראית כעת: `free_list_head -> [Block A+B] -> [Block C] -> NULL`.\n        *   **הבאג:** שורת `current_node = current_node->next;` מתבצעת מיד לאחר האיחוד, מכיוון שהיא מחוץ לתנאי ה-`if`.\n            לכן, `current_node` מקודם ל-`C`.\n    2.  `current_node = C`. `current_node->next = NULL`. הלולאה מסתיימת.\n    \n    **תוצאה:** הבלוקים A ו-B אוחדו בהצלחה לבלוק גדול אחד `A+B`. עם זאת, הבלוק `C` נשאר בלוק נפרד, למרות שהוא סמוך פיזית לבלוק `A+B`. נוצר פיצול חיצוני: במקום בלוק אחד גדול בגודל `X+Y+Z`, יש לנו שני בלוקים: `A+B` ו-`C`. אם נבקש עכשיו `my_malloc(X+Y+Z-BLOCK_HEADER_SIZE)` (גודל שיתאים ל-`A+B+C` אך לא לכל אחד מהם בנפרד), הבקשה תיכשל למרות שיש מספיק זיכרון פנוי בסך הכל.\n\n2.  **הסבר הבאג:**\n    הבאג טמון בלולאת האיחוד ב-`my_free`. כאשר מתבצע איחוד בין `current_node` לבין `current_node->next`, הבלוק `current_node` גדל ו-`current_node->next` מעודכן לדלג על הבלוק שאוחד. הבעיה היא שאחרי האיחוד, ייתכן ש-`current_node` (שגדל) סמוך פיזית גם לבלוק הבא ברשימה (שהיה במקור `current_node->next->next`). אך שורת `current_node = current_node->next;` מתבצעת באופן בלתי מותנה, כלומר, היא תמיד מקדמת את `current_node` לשלב הבא בלולאה, גם אם הרגע בוצע איחוד. כתוצאה מכך, `current_node` (לאחר שגדל) לא נבדק שוב לאפשרות של איחוד עם הבלוק הבא בתור. למעשה, ברגע ש-`current_node` גדל, הוא צריך לנסות שוב לאחד את עצמו עם הבלוק שאליו הוא מצביע כעת (שבמקור היה הבלוק שאחרי הבלוק שאוחד). הקידום הבלתי מותנה של `current_node` לאחר איחוד גורם לכך שרצף של בלוקים סמוכים פיזית יאוחד לכל היותר לשני בלוקים במקום לבלוק אחד גדול ויחיד.\n\n3.  **תיקון הבאג:**\n    כדי לתקן את הבאג, יש לשנות את לולאת האיחוד כך שאחרי איחוד מוצלח, הבלוק `current_node` יישאר באותה עמדה בלולאה וינסה שוב לבצע איחוד עם הבלוק הבא ברשימה. רק אם לא התרחש איחוד, `current_node` יתקדם לבלוק הבא. בכך, בלוק שגדל יוכל להמשיך ולאחד בלוקים סמוכים נוספים ברצף.\n\n    **קוד מתוקן עבור `my_free`:**\n    ```c\n// Custom free with merging logic (FIXED VERSION)\nvoid my_free(void *ptr) {\n    if (ptr == NULL) return;\n\n    Block *block_to_free = (Block*)((char*)ptr - BLOCK_HEADER_SIZE);\n    \n    // Insert the block into the free list, keeping it sorted by address\n    Block *current_node_for_insertion = free_list_head;\n    Block *prev_node_for_insertion = NULL;\n\n    while (current_node_for_insertion != NULL && current_node_for_insertion < block_to_free) {\n        prev_node_for_insertion = current_node_for_insertion;\n        current_node_for_insertion = current_node_for_insertion->next;\n    }\n\n    if (prev_node_for_insertion == NULL) { // Insert at head\n        block_to_free->next = free_list_head;\n        free_list_head = block_to_free;\n    } else { // Insert in middle or at end\n        block_to_free->next = current_node_for_insertion;\n        prev_node_for_insertion->next = block_to_free;\n    }\n\n    // Now, attempt to merge adjacent free blocks.\n    // Iterate and re-check current_node after each merge.\n    Block *current_node = free_list_head; \n    while (current_node != NULL && current_node->next != NULL) {\n        // Check if current_node and its successor are physically adjacent\n        if ((char*)current_node + current_node->size == (char*)current_node->next) {\n            // Merge current_node and current_node->next\n            current_node->size += current_node->next->size;\n            current_node->next = current_node->next->next; // Skip the merged block\n            // IMPORTANT: Do NOT advance current_node here. Re-evaluate it for further merges.\n            // The loop will re-check current_node with its *new* next pointer in the next iteration.\n        } else {\n            // Only advance if no merge happened\n            current_node = current_node->next;\n        }\n    }\n}\n    ```"}, "difficulty_estimation": "Hard", "_source_file": "0503__Memory_Management__CodeAnalysis__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:14:41", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Memory Management", "Virtual Memory", "Page Tables", "Address Translation"], "content": {"text": "נתונה מערכת הפעלה פשוטה המממשת זיכרון וירטואלי עבור תהליכים, כאשר לכל תהליך יש טבלת דפים (page table) משלו. טבלת הדפים מיוצגת כרגע באופן גלובלי לצורך פשטות, והיא מערך של מבנים מסוג `PageTableEntry`. כל כניסה בטבלה מכילה את מספר מסגרת הדף הפיזי (PFN) וביטים נוספים כגון `valid` (האם הדף חוקי) ו-`read_only` (האם הדף מוגן מכתיבה).\n\nהמערכת תומכת בגודל דף קבוע של 4KB. נניח ש-`PAGE_SIZE` מוגדר כ-4096 ו-`PAGE_SHIFT` מוגדר כ-12. הקוד המצורף כולל את הגדרות אלו ואת מבנה ה-`PageTableEntry`.\n\nיש להשלים את הפונקציה `translate_and_access(uint32_t virtual_address, bool is_write)` כך שתבצע את תרגום הכתובת הווירטואלית לכתובת פיזית, תוך כדי טיפול נכון בכשלי דף (page faults) והגנות זיכרון. הפונקציה צריכה לבצע את השלבים הבאים:\n1. חלץ את מספר הדף הווירטואלי (VPN) ואת היסט הדף (offset) מהכתובת הווירטואלית הנתונה. יש לוודא שה-VPN נמצא בטווח חוקי של טבלת הדפים (`PTE_COUNT`). אם לא, יש להדפיס הודעת שגיאה מתאימה ולסיים.\n2. בדוק את כניסת טבלת הדפים המתאימה ל-VPN שהתקבל. אם ביט ה-`valid` של הכניסה כבוי, הדפס הודעת שגיאה המציינת כשל דף מסוג 'Page fault: Invalid page'.\n3. אם הדף חוקי, בדוק את ביט ההגנה `read_only`. אם הפעולה המבוקשת היא כתיבה (`is_write` הוא `true`) וביט `read_only` דלוק, הדפס הודעת שגיאה המציינת כשל דף מסוג 'Page fault: Write to read-only page'.\n4. אם כל הבדיקות עברו בהצלחה, חשב את הכתובת הפיזית המתאימה. הדפס את הכתובת הווירטואלית והפיזית המתורגמת. בנוסף, אם הפעולה הייתה כתיבה, הדפס 'Data written successfully', ואם קריאה, הדפס 'Data read successfully'.\n\nיש להשלים את החלק המסומן ב-`// TODO: Implement this function` בקוד המצורף.", "code_snippet": "#include <stdio.h>\n#include <stdint.h>\n#include <stdbool.h>\n\n#define PAGE_SIZE 4096 // 4KB\n#define PAGE_SHIFT 12\n#define PTE_COUNT (1 << (32 - PAGE_SHIFT)) // For 32-bit virtual addresses\n\n// Page Table Entry structure\ntypedef struct {\n    uint32_t pfn : 20;       // Physical Frame Number (assuming 32-bit physical address, 20 bits for PFN)\n    uint32_t valid : 1;      // Is this page table entry valid?\n    uint32_t read_only : 1;  // Is this page read-only?\n    uint32_t reserved : 10;  // Reserved bits\n} PageTableEntry;\n\n// Simplified Page Table (global for simplicity, in real OS it's per-process)\nPageTableEntry current_page_table[PTE_COUNT];\n\n// Function to simulate initializing a page table entry\nvoid init_pte(uint32_t vpn, uint32_t pfn, bool valid, bool read_only) {\n    if (vpn < PTE_COUNT) {\n        current_page_table[vpn].pfn = pfn;\n        current_page_table[vpn].valid = valid;\n        current_page_table[vpn].read_only = read_only;\n    }\n}\n\n// Function to translate and access a virtual address\nvoid translate_and_access(uint32_t virtual_address, bool is_write) {\n    // TODO: Implement this function\n    // 1. Extract VPN and offset\n    // 2. Check PTE validity\n    // 3. Check write protection\n    // 4. Calculate physical address and print status\n}\n\nint main() {\n    // Initialize some page table entries\n    // VPN 0 -> PFN 100, valid, read/write\n    init_pte(0, 100, true, false);\n    // VPN 1 -> PFN 200, valid, read-only\n    init_pte(1, 200, true, true);\n    // VPN 2 -> PFN 300, valid, read/write (but we won't access it here)\n    init_pte(2, 300, true, false);\n    // VPN 3 -> invalid\n    init_pte(3, 0, false, false);\n\n    printf(\"Testing virtual address translations:\\n\");\n\n    // Test case 1: Valid read access\n    printf(\"\\nTest 1: Read from VA 0x00001234 (VPN 0, Offset 0x234)\\n\");\n    translate_and_access(0x00001234, false);\n\n    // Test case 2: Valid write access\n    printf(\"\\nTest 2: Write to VA 0x00001234 (VPN 0, Offset 0x234)\\n\");\n    translate_and_access(0x00001234, true);\n\n    // Test case 3: Read from read-only page\n    printf(\"\\nTest 3: Read from VA 0x00005678 (VPN 1, Offset 0x1678)\\n\");\n    translate_and_access(0x00005678, false);\n\n    // Test case 4: Write to read-only page (should fail)\n    printf(\"\\nTest 4: Write to VA 0x00005678 (VPN 1, Offset 0x1678)\\n\");\n    translate_and_access(0x00005678, true);\n\n    // Test case 5: Access invalid page (should fail)\n    printf(\"\\nTest 5: Read from VA 0x0000DABC (VPN 3, Offset 0xABC)\\n\");\n    translate_and_access(0x0000DABC, false);\n\n    // Test case 6: Access invalid page (should fail)\n    printf(\"\\nTest 6: Write to VA 0x0000DABC (VPN 3, Offset 0xABC)\\n\n\");\n    translate_and_access(0x0000DABC, true);\n\n    // Test case 7: Access non-existent VPN (should implicitly be invalid)\n    printf(\"\\nTest 7: Read from VA 0x00011000 (VPN 4, Offset 0x0)\\n\");\n    translate_and_access(0x00011000, false);\n\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפונקציה `translate_and_access` מבצעת את הפעולות הנדרשות לתרגום כתובת וירטואלית לכתובת פיזית, תוך כדי בדיקת הרשאות וטיפול בכשלי דף (page faults).\n\nראשית, היא מחלצת את מספר הדף הווירטואלי (VPN) ואת היסט הדף (offset) מהכתובת הווירטואלית. ה-VPN מתקבל על ידי הזזת הכתובת הווירטואלית ימינה ב-`PAGE_SHIFT` (12 ביטים, שכן גודל דף הוא 4KB). ההיסט מתקבל על ידי ביצוע פעולת AND בין הכתובת הווירטואלית לבין `PAGE_SIZE - 1` (מסכה של 12 הביטים הפחות משמעותיים).\n\nלאחר מכן, הפונקציה בודקת את תקינות ה-VPN (האם הוא בטווח טבלת הדפים). אם הוא מחוץ לטווח, מודפסת הודעת שגיאה מתאימה ומסתיימת הפעולה.\n\nהשלב הבא הוא גישה לכניסה המתאימה בטבלת הדפים (`current_page_table[vpn]`). נבדק ה-`valid` ביט של הכניסה. אם הוא כבוי, הדף אינו קיים בזיכרון הפיזי (או לא הוקצה), ומופק כשל דף מסוג 'Invalid page'.\n\nאם הדף חוקי, נבדקת הרשאת הכתיבה. אם הפעולה המבוקשת היא כתיבה (`is_write` הוא `true`) וביט ה-`read_only` בכניסת טבלת הדפים דלוק, אזי מדובר בניסיון כתיבה לדף מוגן, ומופק כשל דף מסוג 'Write to read-only page'.\n\nאם כל הבדיקות עברו בהצלחה, מחושבת הכתובת הפיזית על ידי שילוב מספר מסגרת הדף הפיזי (PFN) מה-PTE עם היסט הדף. ה-PFN מוזז שמאלה ב-`PAGE_SHIFT` כדי ליצור את החלק העליון של הכתובת הפיזית, ואז מוסיפים אליו את ההיסט.\n\nלבסוף, מודפסת הכתובת הפיזית המתורגמת והודעת סטטוס המציינת אם בוצעה פעולת קריאה או כתיבה מוצלחת.\n\nהקוד המלא של הפונקציה `translate_and_access`:\n```c\nvoid translate_and_access(uint32_t virtual_address, bool is_write) {\n    // 1. Extract VPN and offset\n    uint32_t vpn = virtual_address >> PAGE_SHIFT;\n    uint32_t offset = virtual_address & (PAGE_SIZE - 1);\n\n    // Check if VPN is within bounds of our simplified page table\n    if (vpn >= PTE_COUNT) {\n        printf(\"Page fault: Virtual address 0x%X has an out-of-bounds VPN %u.\\n\", virtual_address, vpn);\n        return;\n    }\n\n    PageTableEntry pte = current_page_table[vpn];\n\n    // 2. Check PTE validity\n    if (!pte.valid) {\n        printf(\"Page fault: Invalid page for virtual address 0x%X (VPN %u).\\n\", virtual_address, vpn);\n        return;\n    }\n\n    // 3. Check write protection\n    if (is_write && pte.read_only) {\n        printf(\"Page fault: Write to read-only page for virtual address 0x%X (VPN %u).\\n\", virtual_address, vpn);\n        return;\n    }\n\n    // 4. If all checks pass, calculate physical address and print status\n    uint32_t physical_address = (pte.pfn << PAGE_SHIFT) | offset;\n    printf(\"Virtual address 0x%X translates to Physical address 0x%X.\\n\", virtual_address, physical_address);\n    if (is_write) {\n        printf(\"Data written successfully.\\n\");\n    } else {\n        printf(\"Data read successfully.\\n\");\n    }\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0504__Memory_Management__CodeAnalysis__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:15:08", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Virtual Memory", "Memory Management"], "content": {"text": "מהו היתרון העיקרי של שימוש בזיכרון וירטואלי?", "code_snippet": null, "options": ["א. להגדיל את מהירות הגישה לזיכרון הפיזי.", "ב. לאפשר לכל תהליך לראות מרחב כתובות לוגי משלו, שעשוי להיות גדול יותר מהזיכרון הפיזי הזמין.", "ג. למנוע פרגמנטציה פנימית בזיכרון הפיזי.", "ד. לספק למעבד גישה ישירה להתקני קלט/פלט מבלי לערב את הזיכרון הראשי.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. היתרון העיקרי של זיכרון וירטואלי הוא לאפשר לכל תהליך להשתמש במרחב כתובות לוגי עצמאי, שאינו מוגבל על ידי גודל הזיכרון הפיזי הקיים. זה מאפשר להריץ תוכניות גדולות יותר מהזיכרון הפיזי ומספק בידוד והגנה בין תהליכים שונים."}, "difficulty_estimation": "Easy", "_source_file": "0505__Virtual_Memory__MultipleChoice__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:15:17", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Virtual Memory", "Memory Management"], "content": {"text": "מהי המטרה העיקרית של זיכרון וירטואלי?", "code_snippet": null, "options": ["א. להגדיל את מהירות המעבד.", "ב. לאפשר לכל תהליך להשתמש במרחב כתובות זיכרון עצמאי וגדול יותר מהזיכרון הפיזי הזמין.", "ג. למנוע לחלוטין פרגמנטציה פנימית וחיצונית.", "ד. לאחסן את כל קבצי מערכת ההפעלה באופן קבוע בזיכרון הפיזי."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. זיכרון וירטואלי נועד לספק לכל תהליך אשליה של מרחב זיכרון עצמאי וגדול, שלעיתים קרובות גדול יותר מהזיכרון הפיזי הקיים במערכת. זה מאפשר הגנה בין תהליכים, ניצול יעיל יותר של הזיכרון הפיזי ופישוט תכנות היישומים."}, "difficulty_estimation": "Easy", "_source_file": "0506__Virtual_Memory__MultipleChoice__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:15:26", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Virtual Memory"], "content": {"text": "מהו אחד היתרונות המרכזיים של זיכרון וירטואלי?", "code_snippet": null, "options": ["א. להגדיל את מהירות פעולת המעבד (CPU).", "ב. לאפשר לתוכניות להשתמש במרחב כתובות זיכרון גדול יותר ממה שקיים פיזית.", "ג. להפחית את מספר הקריאות למערכת (system calls).", "ד. לשפר את ביצועי כונני ה-SSD."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. זיכרון וירטואלי הוא טכניקה המאפשרת לתוכניות להשתמש במרחב כתובות גדול ורציף, שאינו תלוי בכמות הזיכרון הפיזי הזמין במערכת. הוא משיג זאת על ידי מיפוי כתובות וירטואליות לכתובות פיזיות ושימוש באחסון משני (כמו דיסק) כהרחבה לזיכרון הפיזי."}, "difficulty_estimation": "Easy", "_source_file": "0507__Virtual_Memory__MultipleChoice__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:15:31", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Virtual Memory", "Memory Management"], "content": {"text": "מהי המטרה העיקרית של זיכרון וירטואלי (Virtual Memory)?", "code_snippet": null, "options": ["א. להגדיל את כמות הזיכרון הפיזי הזמין למערכת.", "ב. לאפשר לכל תהליך להשתמש במרחב כתובות לוגי משלו, ולבודד תהליכים אחד מהשני.", "ג. להאיץ את מהירות העיבוד של המעבד על ידי שימוש בזיכרון מטמון (cache).", "ד. לספק דרך מהירה יותר לגשת לקבצים המאוחסנים בדיסק."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. זיכרון וירטואלי מאפשר לכל תהליך להשתמש במרחב כתובות לוגי משלו, שלרוב גדול יותר מהזיכרון הפיזי, ומספק שכבת הפשטה שמבודדת תהליכים זה מזה ומגנה על הזיכרון הפיזי מפני גישה לא חוקית. זה גם מאפשר לטעון רק חלקים מהתהליך לזיכרון הפיזי בעת הצורך."}, "difficulty_estimation": "Easy", "_source_file": "0508__Virtual_Memory__MultipleChoice__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:15:39", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Virtual Memory", "Memory Management"], "content": {"text": "מהו היתרון העיקרי של זיכרון וירטואלי (Virtual Memory)?", "code_snippet": null, "options": ["א. האצת מהירות הגישה לנתונים בזיכרון הפיזי.", "ב. מניעת צורך בשימוש בדיסק הקשיח לאחסון נתונים.", "ג. מתן אשליה של מרחב זיכרון גדול ורציף לכל תהליך, ובידוד בין מרחבי כתובות של תהליכים שונים.", "ד. הקטנת כמות הזיכרון הפיזי הנדרשת להפעלת מערכת ההפעלה.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "ג. זיכרון וירטואלי מאפשר למערכת ההפעלה לספק לכל תהליך אשליה של מרחב כתובות פרטי, גדול ורציף, גם אם הזיכרון הפיזי קטן יותר או מפוצל. בנוסף, הוא מאפשר בידוד בין תהליכים, כך שתהליך אחד לא יכול לגשת לזיכרון של תהליך אחר."}, "difficulty_estimation": "Easy", "_source_file": "0509__Virtual_Memory__MultipleChoice__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:15:47", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Virtual Memory", "Memory Management"], "content": {"text": "מהו אחד היתרונות העיקריים של זיכרון וירטואלי?", "code_snippet": null, "options": ["א. הוא מאפשר לתוכניות להשתמש בזיכרון רב יותר מזה הפיזי הקיים במערכת.", "ב. הוא מאיץ את ביצועי המעבד באופן ישיר.", "ג. הוא מפחית את זמן ההחלפה בין תהליכים (context switch).", "ד. הוא משפר את ביצועי הקלט/פלט של המערכת."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "א. זיכרון וירטואלי מאפשר לכל תהליך לראות מרחב כתובות זיכרון גדול ורציף, ובכך מאפשר לתוכניות להשתמש בזיכרון רב יותר מהזיכרון הפיזי הקיים, על ידי שימוש בדיסק כהרחבה לזיכרון הפיזי וניהול יעיל של הזיכרון.", "explanation_hebrew": "א. זיכרון וירטואלי מאפשר לכל תהליך לראות מרחב כתובות זיכרון גדול ורציף, ובכך מאפשר לתוכניות להשתמש בזיכרון רב יותר מהזיכרון הפיזי הקיים, על ידי שימוש בדיסק כהרחבה לזיכרון הפיזי וניהול יעיל של הזיכרון."}, "difficulty_estimation": "Easy", "_source_file": "0510__Virtual_Memory__MultipleChoice__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:15:53", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Virtual Memory"], "content": {"text": "מהי המטרה העיקרית של זיכרון וירטואלי?", "code_snippet": null, "options": ["א. לאפשר לתוכניות להשתמש בזיכרון רב יותר מהזיכרון הפיזי הזמין.", "ב. לספק הגנת זיכרון בין תהליכים שונים.", "ג. לפשט את ניהול הזיכרון עבור המתכנתים על ידי מתן מרחב כתובות לוגי אחיד.", "ד. כל התשובות נכונות.", "ה. אף אחת מהתשובות אינה נכונה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "ד'. זיכרון וירטואלי משיג מספר מטרות חשובות: הוא מאפשר לתוכניות להשתמש במרחב כתובות גדול יותר מהזיכרון הפיזי הזמין (א'), מספק הגנת זיכרון בין תהליכים שונים (ב'), ומפשט את ניהול הזיכרון בכך שכל תהליך מקבל מרחב כתובות וירטואלי פרטי משלו (ג'). לכן, כל התשובות נכונות."}, "difficulty_estimation": "Easy", "_source_file": "0511__Virtual_Memory__MultipleChoice__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:16:00", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Virtual Memory"], "content": {"text": "מהו היתרון העיקרי של זיכרון וירטואלי?", "code_snippet": null, "options": ["א. מגדיל את נפח הזיכרון הפיזי הזמין למערכת.", "ב. מאפשר לתהליכים להשתמש בזיכרון רב יותר ממה שזמין פיזית.", "ג. מאיץ את ביצועי המעבד.", "ד. מונע לחלוטין פרגמנטציה חיצונית.", "ה. אף אחת מהתשובות האחרות אינה נכונה."]}, "sub_questions": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. היתרון העיקרי של זיכרון וירטואלי הוא שהוא מאפשר לתהליכים להשתמש במרחב כתובות לוגי (וירטואלי) גדול יותר מהזיכרון הפיזי הקיים במערכת, ובכך נותן אשליה של זיכרון גדול יותר ומאפשר לטעון רק חלקים רלוונטיים של תהליך לזיכרון הפיזי לפי הצורך."}, "difficulty_estimation": "Easy", "_source_file": "0512__Virtual_Memory__MultipleChoice__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:16:07", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Virtual Memory", "Demand Paging", "Memory Management"], "content": {"text": "מהו היתרון המרכזי של שימוש במנגנון דפדוף לפי דרישה (Demand Paging) במערכות הפעלה מודרניות?", "code_snippet": null, "options": ["א. הוא מבטל לחלוטין את הצורך בזיכרון החלפה (swap space).", "ב. הוא מאפשר טעינה מהירה יותר של תהליכים על ידי טעינת דפים רק כאשר הם נדרשים.", "ג. הוא מקטין את כמות הזיכרון הפיזי הדרושה לכל תהליך באופן קבוע.", "ד. הוא מפחית את פיצול הזיכרון הפנימי (Internal Fragmentation) בזיכרון הראשי.", "ה. הוא משפר את ביצועי גישת הדיסק על ידי שמירת כל הדפים בזיכרון הראשי."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. דפדוף לפי דרישה (Demand Paging) מאפשר למערכת ההפעלה לטעון דפים של תהליך לזיכרון הפיזי רק כאשר הם באמת נדרשים (כלומר, כאשר יש התייחסות אליהם). זה מביא לטעינה מהירה יותר של תהליכים, מכיוון שלא כל התהליך נטען לזיכרון בזמן ההפעלה, וחוסך זיכרון פיזי על ידי שמירת דפים שאינם בשימוש פעיל על הדיסק."}, "difficulty_estimation": "Medium", "_source_file": "0513__Virtual_Memory__MultipleChoice__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:16:17", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Virtual Memory", "Paging", "TLB", "Address Translation"], "content": {"text": "כאשר תהליך ניגש לכתובת וירטואלית, ותרגום הכתובת אינו נמצא ב-TLB (Translation Lookaside Buffer), מהו הצעד הבא שהמערכת תבצע?", "code_snippet": null, "options": ["א. תתרחש מיד תקלת דף (Page Fault).", "ב. המערכת תבדוק את טבלת הדפים (Page Table) בזיכרון הראשי.", "ג. המערכת תטען את הדף מהדיסק לזיכרון הראשי.", "ד. התהליך יופסק (terminated)."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "כאשר מתרחש TLB Miss, המערכת מחפשת את תרגום הכתובת בטבלת הדפים (Page Table) שנמצאת בזיכרון הראשי (RAM). רק אם מתגלה בטבלת הדפים שהדף אינו נמצא בזיכרון הפיזי (כלומר, ה-Present Bit הוא 0), תתרחש תקלת דף (Page Fault). אם הדף נמצא בזיכרון הפיזי, ה-TLB יעודכן והגישה תמשיך."}, "difficulty_estimation": "Medium", "_source_file": "0514__Virtual_Memory__MultipleChoice__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:16:25", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Virtual Memory", "Paging", "TLB", "Memory Management"], "content": {"text": "תהליך מנסה לגשת לכתובת וירטואלית מסוימת. המעבד מחפש את התרגום ב-TLB ומגלה 'פספוס' (TLB miss). לאחר מכן, מערכת ההפעלה מבצעת חיפוש בטבלת הדפים של התהליך ומגלה שהדף קיים בזיכרון הפיזי (RAM) וכי יש לתהליך הרשאה לגשת אליו. מהו הצעד הבא שהמעבד יבצע?", "code_snippet": null, "options": ["א. המעבד יגרום ל-Page Fault, מכיוון שהתרגום לא נמצא ב-TLB.", "ב. המעבד יתרגם את הכתובת הווירטואלית לכתובת פיזית, יטען את התרגום ל-TLB וימשיך בביצוע הפקודה.", "ג. המעבד יגרום ל-Segmentation Fault, כיוון שהתרגום לא נמצא ב-TLB.", "ד. המעבד יבקש ממע' ההפעלה לטעון את הדף מהדיסק לזיכרון הפיזי."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "במקרה של פספוס ב-TLB (TLB miss), המעבד יפנה לטבלת הדפים (Page Table) כדי למצוא את התרגום מהכתובת הווירטואלית לכתובת הפיזית. מכיוון שהדף נמצא בזיכרון הפיזי וקיימות הרשאות גישה, המעבד יבצע את התרגום, יעדכן את ה-TLB עם הרשומה החדשה (כדי לזרז גישות עתידיות לאותו דף), וימשיך בביצוע הפקודה כאילו לא היה פספוס מלכתחילה (אך עם השהיה קלה)."}, "difficulty_estimation": "Medium", "_source_file": "0515__Virtual_Memory__MultipleChoice__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:16:37", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Virtual Memory", "Paging", "Demand Paging", "Page Faults"], "content": {"text": "איזו מהטענות הבאות מתארת בצורה הטובה ביותר את היתרון המרכזי של מנגנון דפדוף לפי דרישה (Demand Paging) בזיכרון וירטואלי, המסתמך על Page Faults?", "code_snippet": null, "options": ["א. הוא מאפשר לטעון את כל התוכנית לזיכרון הפיזי מראש, ובכך מונע עיכובים בזמן ריצה.", "ב. הוא מאפשר להריץ תוכניות שגודלן גדול יותר מהזיכרון הפיזי הזמין, על ידי טעינת חלקים מהן רק בעת הצורך.", "ג. הוא מפחית את הצורך ב-TLB (Translation Lookaside Buffer) על ידי אופטימיזציה של גישה לטבלאות דפים.", "ד. הוא מבטיח שכל הנתונים של תהליך יהיו תמיד בזיכרון הפיזי, ובכך משפר את ביצועי ה-CPU.", "ה. הוא מגדיל את ניצול ה-CPU על ידי הקצאת זיכרון פיזי קבוע לכל תהליך, ללא קשר לשימוש בפועל."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. דפדוף לפי דרישה מאפשר לטעון דפי זיכרון פיזיים רק כאשר הם נדרשים בפועל (בעת גישה לדף וגרימת Page Fault). יתרון זה מאפשר להריץ תוכניות גדולות יותר מהזיכרון הפיזי הזמין, מכיוון שרק חלק קטן מהתוכנית צריך להיות ב-RAM בכל רגע נתון. זה גם משפר את ניצול הזיכרון הפיזי ומאפשר ריבוי משימות יעיל יותר. שאר האפשרויות אינן נכונות: א' ו-ד' מתארות מצב הפוך מדפדוף לפי דרישה; ג' אינו נכון מכיוון ש-TLB עדיין חיוני לביצועים; ה' אינו יתרון של מנגנון זה ולרוב גם לא המטרה."}, "difficulty_estimation": "Medium", "_source_file": "0516__Virtual_Memory__MultipleChoice__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:16:47", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Virtual Memory", "Paging", "Memory Management"], "content": {"text": "מהו התפקיד המרכזי של ה-dirty bit (ביט ה'מלוכלך') ברשומת טבלת דפים (Page Table Entry) במערכת זיכרון וירטואלי?", "code_snippet": null, "options": ["א. לציין אם הדף הנוכחי נמצא בזיכרון הפיזי או בזיכרון המשני (דיסק).", "ב. לציין אם הדף שונה (נכתב אליו) מאז שהובא לזיכרון הפיזי.", "ג. לציין אם לדף יש הרשאות כתיבה (write permission).", "ד. לציין אם הדף נגיש לשימוש על ידי תהליכי משתמש או רק על ידי הליבה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ה-dirty bit משמש כדי לסמן אם דף זיכרון בזיכרון הפיזי שונה (נכתב אליו) מאז שהועלה מהדיסק. מידע זה קריטי עבור אלגוריתמי החלפת דפים (page replacement algorithms). אם דף מלוכלך (dirty), יש לכתוב את תוכנו חזרה לדיסק (לשטח ההחלפה או לקובץ המקורי) לפני שניתן לפנות את מסגרת הזיכרון הפיזי שלו. אם הדף אינו מלוכלך, אין צורך לכתוב אותו לדיסק, מה שחוסך פעולת I/O יקרה."}, "difficulty_estimation": "Medium", "_source_file": "0517__Virtual_Memory__MultipleChoice__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:16:56", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Virtual Memory", "Memory Management", "Process Isolation"], "content": {"text": "איזו מהטענות הבאות מתארת בצורה הטובה ביותר יתרון מרכזי של זיכרון וירטואלי במערכות הפעלה מודרניות?", "code_snippet": null, "options": ["א. מאפשרת ל-CPU לגשת לזיכרון פיזי מהר יותר.", "ב. מגדילה את כמות הזיכרון הפיזי הזמין למערכת.", "ג. מספקת הפרדה והגנה בין מרחבי כתובות של תהליכים שונים.", "ד. מבטלת לחלוטין את הצורך בגישה לדיסק עבור נתוני תהליכים."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "זיכרון וירטואלי מספק לכל תהליך מרחב כתובות פרטי משלו, הממופה לזיכרון פיזי באמצעות טבלאות דפים. מנגנון זה מונע מתהליך אחד לגשת בטעות או בזדון לזיכרון של תהליך אחר, ובכך מספק הפרדה והגנה חיוניות. הוא גם מאפשר להריץ תוכניות גדולות יותר מהזיכרון הפיזי הזמין ומאפשר שיתוף קוד ונתונים בין תהליכים, אך יתרון ההפרדה וההגנה הוא מרכזי ביותר לאמינות ובטיחות המערכת. אפשרות א' אינה נכונה מכיוון שתרגום כתובות מוסיף תקורה, אם כי TLB מפחית אותה. אפשרות ב' אינה נכונה מכיוון שזיכרון וירטואלי אינו מגדיל את הזיכרון הפיזי בפועל, אלא יוצר אשליה של זיכרון גדול יותר. אפשרות ד' אינה נכונה מכיוון שזיכרון וירטואלי עדיין מסתמך על הדיסק (swap space) כדי לנהל דפים שאינם נמצאים ב-RAM."}, "difficulty_estimation": "Medium", "_source_file": "0518__Virtual_Memory__MultipleChoice__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:17:07", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Virtual Memory", "Paging", "TLB", "Page Faults", "Memory Management"], "content": {"text": "כאשר המעבד מנסה לגשת לכתובת וירטואלית, ומתרחש TLB Miss, ולאחר מכן מתברר מטבלת הדפים שהדף אינו נמצא בזיכרון הפיזי (page fault), מהי הפעולה העיקרית שמערכת ההפעלה תבצע כדי לטפל בכך?", "code_snippet": null, "options": ["א. המערכת תבצע החלפת דפים (page replacement) ותעדכן את ה-TLB.", "ב. המערכת תסמן את הדף כ\"לא קיים\" ותסיים את התהליך.", "ג. המערכת תטען את הדף מזיכרון המשני (דיסק) לזיכרון הפיזי, תעדכן את טבלת הדפים וה-TLB, ותאפשר את המשך ביצוע ההוראה.", "ד. המערכת תבקש מהתהליך להקצות זיכרון חדש לדף.", "ה. המערכת תתעלם מהגישה ותמשיך לכתובת הבאה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "כאשר מתרחש page fault, מערכת ההפעלה מטפלת בהפרעה (interrupt) על ידי איתור הדף בזיכרון המשני (דיסק), טעינתו למסגרת פנויה בזיכרון הפיזי (RAM) – ייתכן שתצטרך לבצע החלפת דפים (page replacement) אם אין מסגרות פנויות – עדכון רשומת טבלת הדפים המתאימה כדי שתצביע על המיקום החדש ב-RAM, וכן עדכון ה-TLB (אם הדף נטען למסגרת חדשה או אם ה-TLB עדיין לא הכיל את הרשומה החדשה). לאחר מכן, המערכת חוזרת ומבצעת מחדש את ההוראה שגרמה ל-page fault."}, "difficulty_estimation": "Medium", "_source_file": "0519__Virtual_Memory__MultipleChoice__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:17:21", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Virtual Memory", "Memory Management", "Paging"], "content": {"text": "אחד היתרונות המרכזיים של מנגנון הזיכרון הוירטואלי (Virtual Memory) הוא:", "code_snippet": null, "options": ["א. הגדלת מהירות הגישה לזיכרון הפיזי (RAM).", "ב. מתן אשליה של מרחב זיכרון רציף וגדול לכל תהליך, ללא תלות בזיכרון הפיזי בפועל.", "ג. ביטול מוחלט של הצורך בטעינת קוד תוכניות לזיכרון הראשי.", "ד. מניעת כל סוגי שגיאות הגישה לזיכרון (segmentation faults)."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. זיכרון וירטואלי מספק לכל תהליך מרחב כתובות לוגי משלו, שנראה רציף וגדול יותר ממה שקיים בפועל בזיכרון הפיזי. זה מאפשר למערכת ההפעלה למקם דפי זיכרון פיזיים לא רציפים עבור תהליך, ולנהל את הזיכרון בצורה גמישה ויעילה יותר, תוך מתן אשליה של רציפות לתהליך. אפשרות א' אינה נכונה, מכיוון שלרוב זיכרון וירטואלי מוסיף תקורה (overhead) ועלול להאט גישה עקב צורך בחיפושי טבלאות דפים ו-TLB misses. אפשרות ג' אינה נכונה, קוד תוכניות עדיין נטען לזיכרון הראשי. אפשרות ד' אינה נכונה, זיכרון וירטואלי מספק הגנה ועוזר לזהות שגיאות גישה לא חוקיות, אך אינו מונע את התרחשותן באופן מוחלט."}, "difficulty_estimation": "Medium", "_source_file": "0520__Virtual_Memory__MultipleChoice__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:17:34", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Virtual Memory", "Copy-on-Write", "Paging", "Page Faults"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי ובדפים בגודל 4KB. תהליך אב (Parent) מקצה מערך בגודל 1GB ומאתחל אותו. מיד לאחר מכן, תהליך האב מבצע קריאה ל-`fork()`, היוצרת תהליך בן (Child).\nלאחר ה-`fork()`, גם תהליך האב וגם תהליך הבן מבצעים לולאה שלמה על כל המערך בגודל 1GB, וכותבים לכל איבר במערך (לדוגמה: `array[i] = array[i] + 1;`).\nהנח כי המערך כולו היה טעון בזיכרון פיזי לפני קריאת ה-`fork()`, וכי יש מספיק זיכרון פיזי במערכת כדי להכיל את כל הדפים הנדרשים.\nמהו המספר המינימלי של פסיקות דף (page faults) שיתרחשו *עקב פעולות כתיבה* למערך זה, בסך הכל עבור שני התהליכים (אב ובן)?", "code_snippet": null, "options": ["א. 0", "ב. 262,144", "ג. 524,288", "ד. 1,048,576", "ה. לא ניתן לקבוע ללא מידע נוסף"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "ראשית, נחשב את מספר הדפים במערך בגודל 1GB:\n1GB = 1024 MB = 1024 * 1024 KB = 1,048,576 KB.\nמספר הדפים = 1,048,576 KB / 4 KB/דף = 262,144 דפים.\n\nכאשר תהליך האב קורא ל-`fork()`, כל הדפים של המערך משותפים בין האב לבן במצב Copy-on-Write (CoW). המשמעות היא שהדפים יועתקו רק כאשר אחד התהליכים ינסה לכתוב אליהם.\n\nשני התהליכים, האב והבן, מבצעים לולאה שלמה וכותבים לכל איבר במערך. עבור כל דף במערך:\n1.  התהליך הראשון (אב או בן) שיכתוב לאיבר כלשהו בדף זה, יגרום לפסיקת דף CoW. מערכת ההפעלה תיצור עותק פרטי של הדף עבור תהליך זה. זוהי פסיקת דף אחת.\n2.  התהליך השני שיכתוב לאיבר כלשהו באותו דף (שעדיין משותף במובן של כתובת וירטואלית, אך ייתכן שכבר עבר CoW עבור התהליך הראשון), יגרום גם הוא לפסיקת דף CoW. מערכת ההפעלה תיצור עותק פרטי של הדף עבור תהליך זה. זוהי פסיקת דף נוספת.\n\nלכן, כל אחד מ-262,144 הדפים יגרום לשתי פסיקות דף CoW בסך הכל (אחת עבור הכתיבה הראשונה של האב לדף, ואחת עבור הכתיבה הראשונה של הבן לדף). לאחר שדף הפך לפרטי עבור תהליך מסוים, כתיבות נוספות לאותו דף על ידי אותו תהליך לא יגרמו לפסיקות CoW נוספות.\n\nסה\"כ פסיקות דף CoW = 262,144 דפים * 2 פסיקות/דף = 524,288 פסיקות דף."}, "difficulty_estimation": "Hard", "_source_file": "0521__Virtual_Memory__MultipleChoice__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:17:53", "_subject": "Virtualization"}, {"id": 101, "type": "MultipleChoice", "topic": ["Virtual Memory", "Paging", "Page Faults", "Multi-level Page Tables", "TLB"], "content": {"text": "מערכת הפעלה משתמשת בטבלת דפים היררכית בעלת 3 רמות (3-level page table) וכן ב-TLB. תהליך מנסה לגשת לכתובת וירטואלית מסוימת (VA) בכדי לבצע פעולת קריאה. נניח את המצבים הבאים בתחילת הגישה: 1. ה-TLB ריק לגמרי. 2. דף טבלת הדפים ברמה הראשונה (L1 Page Table Page) *נמצא* בזיכרון הפיזי. 3. דף טבלת הדפים ברמה השנייה (L2 Page Table Page) *אינו נמצא* בזיכרון הפיזי. 4. דף טבלת הדפים ברמה השלישית (L3 Page Table Page) *נמצא* בזיכרון הפיזי. 5. דף הנתונים (Data Page) אליו מתייחסת הכתובת VA *אינו נמצא* בזיכרון הפיזי. בהתבסס על תנאים אלו, כמה *פסיקות דף (page faults)* לכל היותר יתרחשו במהלך ניסיון הגישה ל-VA, עד שהנתונים ייטענו לזיכרון הפיזי ויהיו נגישים? (יש להתעלם מפסיקות דף אפשריות שאינן קשורות ישירות לתרגום הכתובת או לטעינת דף הנתונים, למשל עבור מבני נתונים פנימיים של מערכת ההפעלה שאינם חלק מטבלאות הדפים).", "code_snippet": null, "options": ["א. 1", "ב. 2", "ג. 3", "ד. 4", "ה. אף אחת מהתשובות אינה נכונה."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ננתח את שלבי הגישה לכתובת הוירטואלית:\n1.  **בדיקת TLB**: ה-TLB ריק, ולכן מתרחש TLB Miss. זו אינה פסיקת דף, אלא רק אי-הצלחה בחיפוש במטמון.\n2.  **גישה ל-PTE ברמה 1**: המעבד מנסה לאתר את דף טבלת הדפים ברמה 1 (L1 Page Table Page). נתון שדף זה *נמצא* בזיכרון הפיזי. לכן, אין פסיקת דף בשלב זה. המעבד קורא את ה-PTE המתאים ברמה 1.\n3.  **גישה ל-PTE ברמה 2**: ה-PTE ברמה 1 מפנה לדף טבלת הדפים ברמה 2 (L2 Page Table Page). נתון שדף זה *אינו נמצא* בזיכרון הפיזי. לכן, מתרחשת **פסיקת דף ראשונה**. מערכת ההפעלה מטפלת בפסיקה, טוענת את דף טבלת הדפים ברמה 2 מהדיסק לזיכרון הפיזי, והמעבד יכול כעת לקרוא את ה-PTE המתאים ברמה 2.\n4.  **גישה ל-PTE ברמה 3**: ה-PTE ברמה 2 מפנה לדף טבלת הדפים ברמה 3 (L3 Page Table Page). נתון שדף זה *נמצא* בזיכרון הפיזי. לכן, אין פסיקת דף בשלב זה. המעבד קורא את ה-PTE המתאים ברמה 3.\n5.  **גישה לדף הנתונים**: ה-PTE ברמה 3 מפנה לדף הנתונים (Data Page) עצמו. נתון שדף הנתונים *אינו נמצא* בזיכרון הפיזי. לכן, מתרחשת **פסיקת דף שנייה**. מערכת ההפעלה מטפלת בפסיקה, טוענת את דף הנתונים מהדיסק לזיכרון הפיזי, והמעבד יכול כעת לגשת לנתונים.\n\nבסך הכל, התרחשו 2 פסיקות דף."}, "difficulty_estimation": "Hard", "_source_file": "0522__Virtual_Memory__MultipleChoice__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:18:27", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Virtual Memory", "Paging", "TLB", "Memory Accesses"], "content": {"text": "מערכת הפעלה משתמשת בזיכרון וירטואלי עם כתובות וירטואליות בנות 32 ביט. גודל דף הוא 4KB. טבלת הדפים היא דו-שכבתית, כאשר כל רמת טבלה (גם ה-Page Directory וגם ה-Page Table) מאוחסנת בדף זיכרון אחד. גודל כל כניסה בטבלת הדפים (PTE/PDE) הוא 4 בתים. למערכת קיים TLB בגודל 4 כניסות, המשתמש במדיניות החלפה LRU (Least Recently Used).\nבהנחה שה-TLB ריק בתחילה, וכי כל הדפים הווירטואליים הנדרשים נמצאים בזיכרון הפיזי (אין Page Faults), כמה גישות לזיכרון הפיזי (לצורך טבלת דפים ולצורך הנתונים) יתבצעו בסך הכל עבור סדרת הגישות לכתובות הווירטואליות הבאות?\n\n0x10000, 0x11000, 0x12000, 0x13000, 0x10000, 0x14000, 0x11000", "code_snippet": null, "options": ["א. 15", "ב. 17", "ג. 19", "ד. 21", "ה. 23"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הסבר:\nכתובת וירטואלית: 32 ביט. גודל דף: 4KB = 2^12 בתים. לכן, 12 הביטים הפחות משמעותיים הם ה-offset בתוך הדף.\nמספר הדף הווירטואלי (VPN) הוא 32-12 = 20 ביט.\nטבלת דפים דו-שכבתית, כאשר כל רמה מאוחסנת בדף אחד (4KB). גודל כניסה 4 בתים.\nמספר כניסות לדף: 4KB / 4 בתים = 1024 = 2^10.\nלכן, 20 ביטים של ה-VPN יחולקו ל-10 ביטים עבור ה-Page Directory Index (PDI) ו-10 ביטים עבור ה-Page Table Index (PTI).\n\nמספר גישות לזיכרון פיזי עבור תרגום כתובת:\n*   TLB Hit: גישה אחת (לנתונים).\n*   TLB Miss (ללא Page Fault): שתי גישות לטבלת הדפים (אחת ל-PDE ב-Page Directory, אחת ל-PTE ב-Page Table), וגישה אחת לנתונים. סך הכל 3 גישות. ה-TLB מתעדכן.\n\nמעקב אחר הגישות וה-TLB (גודל 4, LRU):\nTLB = {} (ריק בתחילה)\n\n1.  **גישה ל-0x10000 (VPN 0x10)**:\n    *   TLB Miss.\n    *   3 גישות לזיכרון (2 לטבלת דפים + 1 לנתונים).\n    *   TLB: {0x10 (MRU)}\n    *   סה\"כ גישות: 3\n\n2.  **גישה ל-0x11000 (VPN 0x11)**:\n    *   TLB Miss.\n    *   3 גישות לזיכרון.\n    *   TLB: {0x10, 0x11 (MRU)}\n    *   סה\"כ גישות: 3 + 3 = 6\n\n3.  **גישה ל-0x12000 (VPN 0x12)**:\n    *   TLB Miss.\n    *   3 גישות לזיכרון.\n    *   TLB: {0x10, 0x11, 0x12 (MRU)}\n    *   סה\"כ גישות: 6 + 3 = 9\n\n4.  **גישה ל-0x13000 (VPN 0x13)**:\n    *   TLB Miss.\n    *   3 גישות לזיכרון.\n    *   TLB: {0x10, 0x11, 0x12, 0x13 (MRU)} (TLB מלא)\n    *   סה\"כ גישות: 9 + 3 = 12\n\n5.  **גישה ל-0x10000 (VPN 0x10)**:\n    *   TLB Hit.\n    *   1 גישה לזיכרון (לנתונים).\n    *   TLB: {0x11, 0x12, 0x13, 0x10 (MRU)} (0x10 הופך ל-MRU)\n    *   סה\"כ גישות: 12 + 1 = 13\n\n6.  **גישה ל-0x14000 (VPN 0x14)**:\n    *   TLB Miss.\n    *   TLB מלא, 0x11 הוא ה-LRU ויוחלף.\n    *   3 גישות לזיכרון.\n    *   TLB: {0x12, 0x13, 0x10, 0x14 (MRU)}\n    *   סה\"כ גישות: 13 + 3 = 16\n\n7.  **גישה ל-0x11000 (VPN 0x11)**:\n    *   TLB Miss.\n    *   TLB מלא, 0x12 הוא ה-LRU ויוחלף.\n    *   3 גישות לזיכרון.\n    *   TLB: {0x13, 0x10, 0x14, 0x11 (MRU)}\n    *   סה\"כ גישות: 16 + 3 = 19\n\nהתשובה הנכונה היא ג. 19."}, "difficulty_estimation": "Hard", "_source_file": "0523__Virtual_Memory__MultipleChoice__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:18:52", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Virtual Memory", "Paging", "Page Tables", "TLB"], "content": {"text": "במערכת הפעלה המשתמשת בזיכרון וירטואלי ובטבלאות דפים מרובות רמות (multi-level page tables), נניח שהכתובת הוירטואלית היא באורך 64 ביט וגודל הדף הוא 4KB. המערכת משתמשת בטבלת דפים בעלת 3 רמות. כל כניסה בטבלת דפים (PTE) היא באורך 8 בתים.\nכאשר מתבצעת גישה לכתובת וירטואלית, מתבצעת בדיקה ראשונית במטמון ה-TLB. אם מתרחש TLB miss, המעבד מבצע הליכה בטבלאות הדפים (page table walk) כדי למצוא את הכתובת הפיזית המתאימה.\nבהנחה שהדף הנדרש כבר נמצא בזיכרון הפיזי (כלומר, אין page fault), וכל רמות טבלת הדפים עצמן נמצאות בזיכרון הראשי (RAM) ונגישות, כמה גישות לזיכרון הראשי (main memory accesses) נדרשות לכל היותר כדי להשלים גישת קריאה אחת לבת בודד מכתובת וירטואלית זו?", "code_snippet": null, "options": ["א. 1", "ב. 2", "ג. 3", "ד. 4", "ה. 5"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "ד. 4. כאשר מתרחש TLB miss, המעבד צריך לבצע \"הליכה\" בטבלאות הדפים. במערכת עם 3 רמות של טבלאות דפים, הליך זה דורש: \n1.  גישה לזיכרון הראשי כדי לקרוא את הכניסה בטבלת הדפים ברמה הראשונה (PTE Level 0). \n2.  גישה לזיכרון הראשי כדי לקרוא את הכניסה בטבלת הדפים ברמה השנייה (PTE Level 1). \n3.  גישה לזיכרון הראשי כדי לקרוא את הכניסה בטבלת הדפים ברמה השלישית (PTE Level 2), אשר מכילה את הכתובת הפיזית של הדף הנדרש. \n4.  לאחר מציאת הכתובת הפיזית של הדף, מתבצעת גישה נוספת לזיכרון הראשי כדי לקרוא את הנתון עצמו מהדף הפיזי. \nבסך הכל, נדרשות 3 גישות לזיכרון הראשי עבור ה-page table walk, ועוד גישה אחת עבור הנתון עצמו, מה שמביא לסך של 4 גישות לזיכרון הראשי."}, "difficulty_estimation": "Hard", "_source_file": "0524__Virtual_Memory__MultipleChoice__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:19:08", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Virtual Memory", "Copy-on-Write", "Paging", "Page Faults"], "content": {"text": "תהליך אב (parent process) יוצר תהליך בן (child process) באמצעות קריאת המערכת `fork()`. לאחר מכן, הם חולקים בתחילה דפי זיכרון בשיטת Copy-on-Write (CoW). גודל הדף הוא 4KB. נניח שדף מסוים (דף X) נמצא בזיכרון הפיזי וסומן CoW לאחר ה-`fork()`.\n\nבשלב מאוחר יותר, גם תהליך האב וגם תהליך הבן מנסים לכתוב לדף X (כל אחד כותב לדף בנפרד, ובזמנים שונים). מהו המספר המינימלי של פסיקות דף (page faults) שיתרחשו *עקב פעולות הכתיבה הללו בלבד* על דף X, במערכת המיישמת CoW באופן סטנדרטי?", "code_snippet": null, "options": ["א. 0", "ב. 1", "ג. 2", "ד. 3", "ה. לא ניתן לקבוע ללא מידע נוסף"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התשובה הנכונה היא ג. 2.\nבמערכת המיישמת Copy-on-Write (CoW) באופן סטנדרטי, כאשר תהליך אב מבצע `fork()`, דפי הזיכרון שלו משותפים עם תהליך הבן אך מסומנים במנגנון ניהול הזיכרון (MMU) כקריאה בלבד (read-only) ו-CoW.\nכאשר אחד מהתהליכים (האב או הבן) מנסה לכתוב לדף כזה בפעם הראשונה, מתרחשת פסיקת דף (page fault). מערכת ההפעלה מזהה שהדף מסומן CoW, מקצה מסגרת פיזית חדשה, מעתיקה אליה את תוכן הדף המקורי, ולאחר מכן מעדכנת את טבלת הדפים של התהליך הכותב כך שתצביע על המסגרת החדשה עם הרשאות כתיבה. התהליך השני ממשיך להשתמש בדף המקורי.\nלכן, אם תהליך הבן כותב לדף X ראשון, תתרחש פסיקת דף אחת, ועותק של דף X ייווצר עבור הבן. לאחר מכן, כאשר תהליך האב ינסה לכתוב לדף X (שעבורו הוא עדיין מצביע על הדף המקורי המסומן CoW), תתרחש פסיקת דף נוספת, ועותק נוסף של דף X ייווצר עבור האב. בסך הכל, שתי פסיקות דף ושני עותקים נפרדים של הדף X ייווצרו."}, "difficulty_estimation": "Hard", "_source_file": "0525__Virtual_Memory__MultipleChoice__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:19:24", "_subject": "Virtualization"}, {"id": 101, "type": "MultipleChoice", "topic": ["Virtual Memory", "Paging", "TLB", "Memory Access Time"], "content": {"text": "מערכת הפעלה משתמשת בכתובות וירטואליות בגודל 64 ביט, גודל דף הוא 4KB, וטבלת הדפים היא בת 4 רמות. כל ערך בטבלת הדפים (PTE) הוא בגודל 8 בתים. לזיכרון ה-TLB (Translation Lookaside Buffer) יש שיעור פגיעה (Hit Rate) של 80%. זמן גישה ל-TLB הוא 20 ננו-שניות, וזמן גישה לזיכרון הראשי (RAM) הוא 100 ננו-שניות.\nבהנחה שדף הנתונים המבוקש תמיד נמצא בזיכרון הפיזי, מהו זמן הגישה האפקטיבי הממוצע לנתון בזיכרון?", "code_snippet": null, "options": ["א. 120 ננו-שניות", "ב. 200 ננו-שניות", "ג. 220 ננו-שניות", "ד. 500 ננו-שניות", "ה. 520 ננו-שניות"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "זמן גישה אפקטיבי ממוצע מחושב כך:\n(שיעור פגיעה ב-TLB * זמן גישה בפגיעה) + (שיעור החמצה ב-TLB * זמן גישה בהחמצה)\n\n1.  **זמן גישה בפגיעה ב-TLB (TLB Hit):**\n    *   גישה ל-TLB: 20 ננו-שניות\n    *   גישה לזיכרון הראשי (לאחר קבלת הכתובת הפיזית מה-TLB): 100 ננו-שניות\n    *   סה\"כ זמן בפגיעה: 20 + 100 = 120 ננו-שניות\n\n2.  **זמן גישה בהחמצה ב-TLB (TLB Miss):**\n    *   גישה ל-TLB (החמצה): 20 ננו-שניות (עלות הבדיקה ב-TLB גם אם היא נכשלת).\n    *   הליכה בטבלת הדפים (Page Table Walk): ישנן 4 רמות בטבלת הדפים. כל רמה דורשת גישה לזיכרון הראשי כדי להביא את ה-PTE המתאים. לכן, 4 * 100 ננו-שניות = 400 ננו-שניות.\n    *   גישה לזיכרון הראשי (לאחר מציאת הכתובת הפיזית בטבלת הדפים): 100 ננו-שניות\n    *   סה\"כ זמן בהחמצה: 20 (TLB) + 400 (Page Table Walk) + 100 (Data Access) = 520 ננו-שניות\n\n3.  **חישוב זמן הגישה האפקטיבי הממוצע:**\n    *   (0.80 * 120 ננו-שניות) + (0.20 * 520 ננו-שניות)\n    *   96 ננו-שניות + 104 ננו-שניות = 200 ננו-שניות"}, "difficulty_estimation": "Hard", "_source_file": "0526__Virtual_Memory__MultipleChoice__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:19:39", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Virtual Memory", "Paging", "TLB", "Page Faults", "Memory Access Patterns"], "content": {"text": "במערכת הפעלה מסוימת, כתובת וירטואלית היא בת 48 ביטים, גודל דף הוא 4KB, וגודל כניסה בטבלת דפים (PTE) הוא 8 בתים. מערכת ההפעלה משתמשת בטבלת דפים מרובת רמות (4 רמות), כאשר כל אינדקס ברמה הוא בן 9 ביטים. ה-TLB הוא אסוציאטיבי לחלוטין (fully associative) עם 64 כניסות ומשתמש באלגוריתם LRU להחלפה. תהליך ניגש באופן סדרתי למערך שלם בגודל `int arr[256 * 1024]` (כלומר, מ-`arr[0]` ועד `arr[256*1024 - 1]`). נניח שהמערך מתחיל בכתובת וירטואלית מיושרת לדף (page-aligned), וכל הדפים המשמשים את המערך אינם נמצאים בזיכרון הפיזי בתחילת הריצה (cold start). כמה סך הכל פספוסי TLB (TLB misses) וכמה סך הכל פסיקות דף (page faults) יתרחשו במהלך הגישה לכל המערך?", "code_snippet": "int arr[256 * 1024];\nfor (int i = 0; i < 256 * 1024; ++i) {\n    arr[i] = i; // Accessing arr[i]\n}", "options": ["א. פספוסי TLB: 256, פסיקות דף: 256", "ב. פספוסי TLB: 256 * 1024, פסיקות דף: 256", "ג. פספוסי TLB: 256 + (256 - 64) * 1024, פסיקות דף: 256", "ד. פספוסי TLB: 256, פסיקות דף: 256 * 4", "ה. אף אחת מהתשובות האחרות אינה נכונה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "חישוב מספר הדפים:\nגודל המערך הוא `256 * 1024` איברים. כל איבר `int` הוא 4 בתים. סך הכל `256 * 1024 * 4 = 1,048,576` בתים (1MB).\nגודל דף הוא 4KB (`4 * 1024 = 4096` בתים).\nמספר הדפים הייחודיים הנדרשים למערך הוא `1MB / 4KB = 1024KB / 4KB = 256` דפים.\n\nפסיקות דף (Page Faults):\nמכיוון שכל 256 הדפים המשמשים את המערך אינם נמצאים בזיכרון הפיזי בתחילת הריצה (cold start), וכל דף ייחודי נגיש לפחות פעם אחת, כל גישה ראשונה לדף תגרום לפסיקת דף. לכן, יתרחשו בדיוק 256 פסיקות דף. כל פסיקת דף טוענת דף אחד לזיכרון הפיזי.\n\nפספוסי TLB (TLB Misses):\nכל דף מכיל `4096 / 4 = 1024` איברי `int`.\nהגישה היא סדרתית מ-`arr[0]` ועד `arr[256*1024 - 1]`.\n\n1.  הגישה הראשונה לכל אחד מ-256 הדפים הייחודיים (לדוגמה, ל-`arr[0]` שהוא בדף 0, ל-`arr[1024]` שהוא בדף 1, וכו') תגרום לפספוס TLB, מכיוון שכניסת טבלת הדפים (PTE) עבור דף זה אינה נמצאת ב-TLB. זה מצטבר ל-256 פספוסי TLB עבור הגישות הראשונות לכל דף.\n2.  לאחר פספוס TLB והטיפול בפסיקת הדף (אם הייתה), ה-PTE של הדף הנדרש נטען ל-TLB.\n3.  ה-TLB מכיל 64 כניסות. לאחר ש-64 הדפים הראשונים (דפים 0 עד 63) נגישים לראשונה, ה-TLB יתמלא. הגישה הראשונה לדף ה-64 (דף מספר 63) תגרום לפספוס TLB ותטען את ה-PTE שלו ל-TLB.\n4.  כאשר ניגשים לדף ה-65 (דף מספר 64), זהו פספוס TLB נוסף. כעת, כניסת ה-LRU ב-TLB (שהיא ה-PTE של דף 0) תפונה, וה-PTE של דף 64 יוכנס במקומה.\n5.  דפוס זה ממשיך: כל גישה ראשונה לדף חדש לאחר שה-TLB התמלא תגרום לפספוס TLB ולפינוי כניסה ב-TLB לפי LRU. עם זאת, מכיוון שהגישה היא סדרתית, וכל 1024 הגישות לאיברים בתוך דף מסוים מתבצעות ברצף לפני המעבר לדף הבא, לאחר שה-PTE של דף נטען ל-TLB, כל 1023 הגישות הנותרות לאיברים באותו דף יהיו פגיעות TLB (TLB hits).\n6.  עד שהתהליך יגיע לדף שה-PTE שלו פונה מה-TLB (לדוגמה, דף 0 פונה כאשר נטען דף 64), התהליך כבר עבר את כל הגישות לדף 0 ולא יחזור אליו יותר בסיבוב זה. לכן, אין פספוסי TLB נוספים עקב פינוי כניסות והצורך בטעינה מחדש של PTE עבור דפים שכבר נגישו בעבר בתוך לולאת הגישה הנוכחית.\n\nלסיכום, סך הכל פספוסי TLB שווים למספר הדפים הייחודיים הנגישים, שהם 256. סך הכל פסיקות דף שוות גם הן למספר הדפים הייחודיים הנגישים, שהם 256.\n\nלכן, התשובה הנכונה היא א'."}, "difficulty_estimation": "Hard", "_source_file": "0527__Virtual_Memory__MultipleChoice__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:20:11", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Virtual Memory", "Paging", "TLB", "Address Translation", "Memory Accesses"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בכתובות וירטואליות של 64 ביט, גודל דף של 4KB, ומבנה טבלאות דפים בעל 4 רמות (4-level page table). ה-TLB (Translation Lookaside Buffer) ריק בתחילת ריצת תהליך חדש. נתייחס לפעם הראשונה בה התהליך מבצע את הפעולה הבאה:", "code_snippet": "*(int*)0x00007FFFFFFF0000 = 10;", "options": ["א. הפעולה תוביל ל-page fault מכיוון שה-TLB ריק.", "ב. הפעולה תדרוש בדיוק 5 גישות לזיכרון הראשי (RAM): 4 גישות עבור תרגום הכתובת דרך טבלאות הדפים, וגישה אחת לכתיבת הנתון.", "ג. הפעולה תדרוש בדיוק 4 גישות לזיכרון הראשי (RAM) לצורך תרגום הכתובת בלבד, אך לא תבוצע גישת כתיבה לנתון.", "ד. הפעולה תדרוש גישה אחת בלבד לזיכרון הראשי (RAM) לאחר ה-TLB miss, מכיוון שהדף כבר טעון.", "ה. הפעולה לא תכלול גישות לטבלאות הדפים כלל, מכיוון שהדף כבר נמצא בזיכרון הפיזי."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "התשובה הנכונה היא ב'.\nכאשר הכתובת הוירטואלית `0x00007FFFFFFF0000` נגישה לראשונה:\n1.  **TLB Miss**: ה-TLB ריק, ולכן תתרחש החטאה (miss).\n2.  **Page Table Walk**: המעבד יצטרך לבצע תרגום כתובת דרך טבלאות הדפים. מכיוון שמדובר במערכת 64 ביט עם דפים בגודל 4KB ו-4 רמות של טבלאות דפים, התרגום יכלול 4 גישות לזיכרון הראשי (RAM) כדי לאחזר את רשומות טבלת הדפים השונות (PML4, PDPT, PD, PT) עד למציאת רשומת הדף הסופית (PTE). כל גישה לרמת טבלה היא גישת זיכרון ל-RAM.\n3.  **TLB Update**: לאחר שהכתובת הפיזית נמצאה, ה-TLB יעודכן עם המיפוי החדש.\n4.  **Data Write**: לבסוף, תתבצע גישה נוספת לזיכרון הראשי (RAM) כדי לכתוב את הערך `10` לכתובת הפיזית המתורגמת.\nלכן, סך הכל 4 גישות ל-RAM עבור ה-page table walk + גישה אחת ל-RAM עבור כתיבת הנתון = 5 גישות ל-RAM.\n\nטענה א' שגויה מכיוון ש-TLB miss אינו בהכרח page fault. page fault מתרחש כאשר הדף אינו בזיכרון הפיזי או לא נגיש, ולא רק בגלל שה-TLB ריק.\nטענות ג', ד', ה' שגויות מכיוון שהן אינן מתארות נכונה את מספר הגישות לזיכרון או את התהליך כולו."}, "difficulty_estimation": "Hard", "_source_file": "0528__Virtual_Memory__MultipleChoice__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:20:32", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Virtual Memory", "Paging", "Memory Management"], "content": {"text": "נתונה מערכת עם זיכרון וירטואלי של 2MB, גודל דף של 4KB, וזיכרון פיזי של 16MB.\nמהם הגדלים של ה-VPN, ה-PFN, וכמה זיכרון פיזי תתפוס טבלת דפים (לינארית) של תהליך, במינימום?\nגודל VPN: ________ גודל PFN: ________ גודל טבלה: ________", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כתובת וירטואלית היא 21 ביטים (זיכרון וירטואלי 2MB = 2^21 בתים), מתוכם 12 ביטים מייצגים את ההיסט (גודל דף 4KB = 2^12 בתים), לכן נשאר VPN=9 ביטים.\nכתובת פיזית היא 24 ביטים (זיכרון פיזי 16MB = 2^24 בתים), ההיסט זהה – 12 ביטים, לכן נשאר PFN=12 ביטים.\nלכל תהליך יש 512 דפים (2^9) בזיכרון הוירטואלי, כלומר שטבלת הדפים שלו מכילה 512 רשומות. כל רשומה מכילה לפחות 2 בתים (12 ביטים עבור PFN, מעוגל מעלה ל-16 ביטים שהם 2 בתים), לכן הטבלה כולה תתפוס 512 רשומות * 2 בתים/רשומה = 1024 בתים = 1KB."}, "difficulty_estimation": "Easy", "_source_file": "0529__Virtual_Memory__Open__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:20:41", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Virtual Memory", "Memory Management"], "content": {"text": "הסבירו בקצרה מהו זיכרון וירטואלי (Virtual Memory) וציינו שני יתרונות עיקריים בשימוש בו.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "זיכרון וירטואלי הוא מנגנון לניהול זיכרון המאפשר לתהליכים להשתמש במרחב כתובות לוגי גדול יותר ממה שזמין פיזית בזיכרון ה-RAM. הוא יוצר אשליה של זיכרון רציף וגדול לכל תהליך, ומערכת ההפעלה מטפלת במיפוי כתובות וירטואליות לכתובות פיזיות, לרוב באמצעות דפדוף (paging) ושימוש בדיסק כמקום אחסון משני.\n\nשני יתרונות עיקריים בשימוש בזיכרון וירטואלי הם:\n1.  **הרחבת מרחב הכתובות**: מאפשר לתהליכים להשתמש בזיכרון גדול יותר ממה שזמין בזיכרון הפיזי, על ידי שימוש בדיסק כמחסן זמני לחלקים מהזיכרון שאינם בשימוש פעיל.\n2.  **הגנה על זיכרון**: מספק הפרדה בין מרחבי הכתובות של תהליכים שונים, ובכך מונע מתהליך אחד לגשת או לשנות בטעות או בזדון את הזיכרון של תהליך אחר. כל תהליך רואה את הזיכרון שלו כמרחב פרטי."}, "difficulty_estimation": "Easy", "_source_file": "0530__Virtual_Memory__Open__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:20:50", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Virtual Memory", "Memory Management"], "content": {"text": "הסבר בקצרה את המטרה העיקרית של זיכרון וירטואלי (Virtual Memory) במערכות הפעלה, וציין שני יתרונות מרכזיים שהוא מספק.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "המטרה העיקרית של זיכרון וירטואלי היא לאפשר לתהליכים להשתמש במרחב כתובות גדול יותר מזה הזמין בזיכרון הפיזי, וליצור אשליה של זיכרון רציף ופרטי לכל תהליך.\n\nיתרונות מרכזיים:\n1.  **הרחבת מרחב הכתובות:** מאפשר לתהליכים להשתמש בזיכרון גדול יותר ממה שקיים פיזית במערכת, על ידי שימוש בדיסק כהרחבה לזיכרון הראשי (swapping).\n2.  **הגנה ובידוד:** מספק הפרדה ובידוד בין מרחבי הכתובות של תהליכים שונים, ובכך מונע מתהליך אחד לגשת או לשנות בטעות או בזדון את הזיכרון של תהליך אחר.\n3.  **ניהול זיכרון פשוט יותר למתכנת:** משחרר את המתכנת מהצורך לנהל את הזיכרון הפיזי, ומאפשר לו לכתוב קוד כאילו כל הזיכרון זמין ורציף."}, "difficulty_estimation": "Easy", "_source_file": "0531__Virtual_Memory__Open__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:20:58", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Virtual Memory", "Memory Management"], "content": {"text": "הסבירו מהן הסיבות העיקריות לכך שמערכות הפעלה משתמשות בזיכרון וירטואלי. ציינו לפחות שני יתרונות מרכזיים.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "זיכרון וירטואלי מספק מספר יתרונות מרכזיים למערכות הפעלה:\n1.  **הפרדה והגנה (Isolation and Protection)**: כל תהליך מקבל מרחב כתובות וירטואלי משלו, מה שמונע מתהליך אחד לגשת בטעות או בזדון לזיכרון של תהליך אחר או של מערכת ההפעלה. זה משפר את יציבות ואבטחת המערכת.\n2.  **גודל זיכרון גדול יותר מהפיזי (Memory Larger Than Physical)**: מאפשר לתהליכים להשתמש במרחב כתובות וירטואלי גדול יותר מהזיכרון הפיזי הזמין במערכת. חלקים מהזיכרון הוירטואלי שאינם בשימוש פעיל יכולים להישלח לדיסק (swapping/paging), ובכך לאפשר הרצת תוכניות גדולות יותר ממה שהזיכרון הפיזי יכול להכיל.\n3.  **שיתוף זיכרון (Memory Sharing)**: מאפשר למספר תהליכים לשתף בקלות קטעי קוד או נתונים משותפים (כמו ספריות דינמיות) על ידי מיפויים לאותו אזור בזיכרון הפיזי ממרחבי כתובות וירטואליים שונים.\n4.  **פישוט תכנות (Simplified Programming)**: מתכנתים אינם צריכים לדאוג לגבי כתובות פיזיות או ניהול זיכרון מפורט, אלא עובדים עם מרחב כתובות לוגי רציף ופשוט יותר לניהול.\n(נדרש לציין לפחות שניים מהיתרונות הללו.)"}, "difficulty_estimation": "Easy", "_source_file": "0532__Virtual_Memory__Open__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:30:27", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Virtual Memory", "Memory Management"], "content": {"text": "הסבירו בקצרה את שני היתרונות העיקריים של שימוש בזיכרון וירטואלי (Virtual Memory) במערכות הפעלה.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "זיכרון וירטואלי מספק מספר יתרונות מרכזיים במערכות הפעלה:\n1.  **הגדלת מרחב הכתובות וריבוי משימות**: מאפשר לכל תהליך להשתמש במרחב כתובות פרטי ונפרד, לרוב גדול יותר מהזיכרון הפיזי הזמין. זה מאפשר להריץ יותר תהליכים במקביל ממה שהיה אפשרי ללא זיכרון וירטואלי, מכיוון שחלקים מהזיכרון של תהליכים לא פעילים יכולים להיות מועברים לדיסק (swapping).\n2.  **הגנה ובידוד בין תהליכים**: כל תהליך פועל במרחב כתובות וירטואלי משלו, מה שמונע מתהליך אחד לגשת או לשנות בטעות או בזדון את הזיכרון של תהליך אחר. זה משפר את יציבות ואבטחת המערכת."}, "difficulty_estimation": "Easy", "_source_file": "0533__Virtual_Memory__Open__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:30:36", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Virtual Memory"], "content": {"text": "הסבירו במילים שלכם מהו זיכרון וירטואלי (Virtual Memory) וציינו יתרון מרכזי אחד שהוא מספק למערכת ההפעלה.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "זיכרון וירטואלי הוא טכניקת ניהול זיכרון המאפשרת למערכת ההפעלה להעניק לכל תהליך אשליה של מרחב זיכרון גדול ורציף משלו, ללא תלות בכמות הזיכרון הפיזי הזמין. בפועל, המערכת ממפה כתובות וירטואליות לכתובות פיזיות ב-RAM, ואם הנתונים אינם ב-RAM, היא טוענת אותם מהדיסק.\nיתרון מרכזי: מאפשר הפעלה של תוכניות גדולות יותר מהזיכרון הפיזי הזמין, ומאפשר למספר רב יותר של תהליכים לרוץ במקביל, גם אם סך דרישות הזיכרון שלהם עולה על גודל הזיכרון הפיזי."}, "difficulty_estimation": "Easy", "_source_file": "0534__Virtual_Memory__Open__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:30:44", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Virtual Memory", "Memory Management"], "content": {"text": "הסבר בקצרה שני יתרונות מרכזיים של זיכרון וירטואלי (Virtual Memory).", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "זיכרון וירטואלי מספק מספר יתרונות חשובים:\n1.  **הגדלת מרחב הכתובות הזמין לתהליכים:** הוא מאפשר לתהליכים להשתמש במרחב כתובות לוגי גדול יותר מנפח הזיכרון הפיזי הקיים במערכת. זה מקל על פיתוח והרצת יישומים גדולים מבלי לדאוג למגבלות הזיכרון הפיזי, שכן חלק מהנתונים יכולים להיות מאוחסנים בדיסק.\n2.  **הגנה בין תהליכים:** כל תהליך פועל במרחב כתובות וירטואלי משלו, מופרד לחלוטין ממרחבי הכתובות של תהליכים אחרים. הפרדה זו מונעת מתהליך אחד לגשת בטעות או בזדון לזיכרון של תהליך אחר, ובכך משפרת את יציבות, אבטחה ואמינות המערכת."}, "difficulty_estimation": "Easy", "_source_file": "0535__Virtual_Memory__Open__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:30:55", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Virtual Memory", "Memory Management"], "content": {"text": "מהם שני היתרונות העיקריים של שימוש בזיכרון וירטואלי (Virtual Memory) במערכת הפעלה? הסבר בקצרה כל אחד מהיתרונות.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. **הפרדה והגנה (Isolation and Protection)**: זיכרון וירטואלי מספק לכל תהליך מרחב כתובות פרטי משלו, מבודד ממרחבי הכתובות של תהליכים אחרים. זה מונע מתהליך אחד לגשת בטעות או בזדון לזיכרון של תהליך אחר, ובכך מגביר את יציבות ואבטחת המערכת.\n2. **שימוש יעיל בזיכרון פיזי (Efficient Use of Physical Memory)**: בעזרת זיכרון וירטואלי, ניתן לטעון לזיכרון הפיזי רק את החלקים הנחוצים (דפים) מתהליך מסוים. זה מאפשר להריץ תוכניות גדולות יותר מהזיכרון הפיזי הזמין, ומאפשר ריבוי משימות על ידי שיתוף יעיל של הזיכרון הפיזי בין מספר תהליכים. בנוסף, הוא מאפשר שיתוף קוד ונתונים בין תהליכים שונים."}, "difficulty_estimation": "Easy", "_source_file": "0536__Virtual_Memory__Open__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:31:03", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Virtual Memory", "Paging", "Memory Management"], "content": {"text": "נתונה מערכת עם זיכרון וירטואלי של 2GB, גודל דף של 8KB, וזיכרון פיזי של 512MB.\nמהם הגדלים של ה-VPN, ה-PFN, וכמה זיכרון פיזי תתפוס טבלת דפים (לינארית) של תהליך, במינימום?\nגודל VPN: ________ גודל PFN: ________ גודל טבלה: ________", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כתובת וירטואלית היא 31 ביטים (זיכרון וירטואלי 2GB = 2^31 בתים). מתוכם 13 ביטים מייצגים את ההיסט (גודל דף 8KB = 2^13 בתים), לכן נשאר VPN=18 ביטים (31-13).\nכתובת פיזית היא 29 ביטים (זיכרון פיזי 512MB = 2^29 בתים). ההיסט זהה – 13 ביטים, לכן נשאר PFN=16 ביטים (29-13).\nלכל תהליך יש 2^18 דפים בזיכרון הוירטואלי. טבלת הדפים שלו מכילה 2^18 רשומות (Page Table Entries - PTEs). כל רשומה צריכה להכיל לפחות 16 ביטים עבור ה-PFN, ולכן תתפוס 2 בתים (כדי להכיל 16 ביטים). לכן, הטבלה כולה תתפוס 2^18 רשומות * 2 בתים/רשומה = 2^19 בתים = 512KB."}, "difficulty_estimation": "Medium", "_source_file": "0537__Virtual_Memory__Open__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:31:13", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Virtual Memory", "Paging", "Memory Management"], "content": {"text": "נתונה מערכת עם זיכרון וירטואלי של 2GB, גודל דף של 8KB, וזיכרון פיזי של 16GB. נתון שגודל רשומת טבלת דפים (PTE) הוא 4 בתים. המערכת משתמשת בטבלת דפים היררכית. יש לפרט ולנמק את כל החישובים.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "10.1", "text": "מהם הגדלים של ה-VPN וה-PFN?", "code_snippet": null, "options": null}, {"id": "10.2", "text": "כמה רמות דרושות לטבלת הדפים במערכת זו? פרט כמה ביטים משמשים לכל רמה.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "כמה זיכרון פיזי תתפוס טבלת הדפים של תהליך שמשתמש בכל הזיכרון הוירטואלי שלו?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. **חישוב VPN ו-PFN**:\n   *   זיכרון וירטואלי: 2GB = 2^31 בתים. לכן, הכתובת הוירטואלית היא באורך 31 ביטים.\n   *   גודל דף: 8KB = 2^13 בתים. לכן, ההיסט (offset) בתוך הדף הוא באורך 13 ביטים.\n   *   VPN (Virtual Page Number) = אורך כתובת וירטואלית - אורך היסט = 31 - 13 = 18 ביטים.\n   *   זיכרון פיזי: 16GB = 2^34 בתים. לכן, הכתובת הפיזית היא באורך 34 ביטים.\n   *   PFN (Physical Frame Number) = אורך כתובת פיזית - אורך היסט = 34 - 13 = 21 ביטים.\n\n2. **מספר רמות לטבלת הדפים וחלוקת ביטים**:\n   *   גודל רשומת טבלת דפים (PTE) הוא 4 בתים.\n   *   גודל דף הוא 8KB (8192 בתים).\n   *   מספר רשומות PTE שיכולות להיכנס לדף פיזי אחד: 8192 בתים / 4 בתים/רשומה = 2048 רשומות.\n   *   לכן, כל רמה בטבלת הדפים יכולה למפות 2048 ערכים, מה שדורש log2(2048) = 11 ביטים עבור אינדקס הרמה.\n   *   סה\"כ ביטים עבור ה-VPN הם 18 ביטים.\n   *   מספר הרמות הנדרש: 18 ביטים / 11 ביטים לרמה = 1.63. לכן, דרושות 2 רמות לטבלת הדפים ההיררכית.\n   *   חלוקת הביטים בכתובת הוירטואלית:\n       *   רמה 1 (העליונה): תשתמש ב-11 ביטים (מתוך 18 ביטים של ה-VPN).\n       *   רמה 2 (התחתונה): תשתמש ב-18 - 11 = 7 ביטים (הנותרים מה-VPN).\n\n3. **זיכרון פיזי שתתפוס טבלת הדפים של תהליך שמשתמש בכל הזיכרון הוירטואלי**:\n   *   תהליך שמשתמש בכל הזיכרון הוירטואלי שלו (2GB) צריך למעשה 2^18 דפים וירטואליים.\n   *   **טבלת דפים רמה 1 (Page Directory)**:\n       *   טבלת הרמה העליונה צריכה להכיל מצביעים לכל טבלאות רמה 2. מכיוון שרמה 2 משתמשת ב-7 ביטים, יהיו 2^7 = 128 טבלאות רמה 2 פוטנציאליות.\n       *   לכן, טבלת רמה 1 תכיל 128 רשומות. כל רשומה היא בגודל 4 בתים, לכן סה\"כ 128 * 4 = 512 בתים.\n       *   512 בתים אלו נכנסים לדף פיזי אחד (8KB). לכן, טבלת הדפים העליונה תופסת דף אחד (8KB) בזיכרון הפיזי.\n   *   **טבלאות דפים רמה 2**:\n       *   כדי למפות את כל הזיכרון הוירטואלי, כל אחת מ-128 הרשומות בטבלת רמה 1 תצביע לטבלת דפים של רמה 2. כלומר, יהיו 128 טבלאות דפים של רמה 2.\n       *   כל טבלת דפים רמה 2 תופסת דף פיזי אחד (8KB) מכיוון שהיא מכילה 2048 רשומות (2048 * 4 בתים = 8192 בתים).\n       *   סה\"כ זיכרון עבור טבלאות רמה 2: 128 טבלאות * 8KB/טבלה = 1024KB = 1MB.\n   *   **סה\"כ זיכרון פיזי לטבלת הדפים**: 8KB (עבור רמה 1) + 1MB (עבור רמה 2) = 1MB + 8KB."}, "difficulty_estimation": "Medium", "_source_file": "0538__Virtual_Memory__Open__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:31:31", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Virtual Memory", "Paging", "Memory Management", "Multi-level Page Tables"], "content": {"text": "נתונה מערכת עם זיכרון וירטואלי של 2GB, גודל דף של 8KB, וזיכרון פיזי של 128MB.\nהמערכת משתמשת בטבלת דפים היררכית דו-רמתית (Two-level page table), כאשר גודל כל רשומה בטבלת הדפים (PTE) הוא 4 בתים.\n\n1. מהם הגדלים של ה-VPN וה-PFN?\n2. כמה ביטים מוקצים לכל רמה בטבלת הדפים הדו-רמתית, וכמה ביטים מוקצים להיסט (offset)? נמקו.\n3. כמה דפים פיזיים מינימליים יידרשו לאחסון טבלת הדפים עבור תהליך המשתמש בכל הזיכרון הוירטואלי שלו?", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. **VPN ו-PFN**:\n   *   גודל זיכרון וירטואלי: 2GB = 2^31 בתים, לכן כתובת וירטואלית היא באורך 31 ביטים.\n   *   גודל דף: 8KB = 2^13 בתים, לכן ההיסט (offset) הוא באורך 13 ביטים.\n   *   VPN (Virtual Page Number): כתובת וירטואלית פחות היסט = 31 - 13 = 18 ביטים.\n   *   גודל זיכרון פיזי: 128MB = 2^27 בתים, לכן כתובת פיזית היא באורך 27 ביטים.\n   *   PFN (Physical Frame Number): כתובת פיזית פחות היסט = 27 - 13 = 14 ביטים.\n\n2. **ביטים לכל רמה ולהיסט**:\n   *   כפי שחושב לעיל, ההיסט הוא 13 ביטים.\n   *   נותרו 18 ביטים עבור ה-VPN שיחולקו בין שתי רמות טבלת הדפים.\n   *   גודל דף הוא 8KB, וגודל רשומת טבלה (PTE) הוא 4 בתים.\n   *   מספר הרשומות המקסימלי שיכול להיכנס לדף אחד הוא: 8KB / 4B = 2^13 / 2^2 = 2^11 = 2048 רשומות.\n   *   לכן, כל אינדקס (עבור רמה P1 או P2) יכול להיות לכל היותר 11 ביטים (log2(2048)).\n   *   מכיוון שצריך לחלק 18 ביטים לשתי רמות (P1 + P2 = 18), וכל רמה לא יכולה להיות גדולה מ-11 ביטים, נבחר חלוקה סימטרית של 9 ביטים לכל רמה.\n   *   לכן, P1 = 9 ביטים, P2 = 9 ביטים, וההיסט = 13 ביטים.\n\n3. **דפים פיזיים לאחסון טבלת הדפים**: \n   *   תהליך המשתמש בכל הזיכרון הוירטואלי שלו משמעותו שכל 2^18 דפים וירטואליים ממופים.\n   *   **רמה ראשונה (Page Directory)**: מכילה 2^P1 רשומות. עם P1=9, יש 2^9 = 512 רשומות.\n     *   גודל ה-Page Directory הוא 512 רשומות * 4 בתים/רשומה = 2048 בתים = 2KB.\n     *   גודל זה נכנס לדף פיזי אחד (8KB), לכן נדרש 1 דף פיזי ל-Page Directory.\n   *   **רמה שנייה (Page Tables)**: כל רשומה ב-Page Directory מצביעה על טבלת דפים ברמה השנייה.\n     *   מכיוון שכל הזיכרון הוירטואלי בשימוש, כל 512 הרשומות ב-Page Directory יהיו תקפות ויצביעו על טבלת דפים ברמה השנייה.\n     *   כל טבלת דפים ברמה השנייה מכילה 2^P2 רשומות. עם P2=9, יש 2^9 = 512 רשומות.\n     *   גודל כל טבלת דפים ברמה השנייה הוא 512 רשומות * 4 בתים/רשומה = 2048 בתים = 2KB.\n     *   גודל זה נכנס לדף פיזי אחד (8KB).\n     *   מכיוון שיש 512 טבלאות דפים ברמה השנייה (אחת לכל רשומה ב-Page Directory), נדרשים 512 דפים פיזיים עבורן.\n   *   **סה\"כ דפים פיזיים**: 1 (ל-Page Directory) + 512 (לטבלאות הדפים ברמה השנייה) = 513 דפים פיזיים."}, "difficulty_estimation": "Medium", "_source_file": "0539__Virtual_Memory__Open__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:31:53", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Virtual Memory", "Paging", "Memory Management"], "content": {"text": "נתונה מערכת עם זיכרון וירטואלי של 2GB, גודל דף של 8KB, וזיכרון פיזי של 16GB. נתון שגודל רשומת טבלת דפים (PTE) הוא 4 בתים.\nמהם הגדלים של ה-VPN, ה-PFN, וכמה זיכרון פיזי תתפוס טבלת דפים (לינארית) של תהליך, במינימום?\nגודל VPN: ________ גודל PFN: ________ גודל טבלה: ________", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כתובת וירטואלית היא 31 ביטים (זיכרון וירטואלי 2GB = 2^31 בתים). גודל דף הוא 8KB (2^13 בתים), לכן ההיסט הוא 13 ביטים. נשאר VPN = 31 - 13 = 18 ביטים.\nכתובת פיזית היא 34 ביטים (זיכרון פיזי 16GB = 2^34 בתים). ההיסט זהה – 13 ביטים. נשאר PFN = 34 - 13 = 21 ביטים.\nלכל תהליך יש 2^18 דפים בזיכרון הוירטואלי. כל רשומת טבלת דפים (PTE) היא בגודל 4 בתים. לכן, טבלת הדפים הלינארית כולה תתפוס 2^18 * 4 בתים = 262,144 * 4 בתים = 1,048,576 בתים = 1MB."}, "difficulty_estimation": "Medium", "_source_file": "0540__Virtual_Memory__Open__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:32:02", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Virtual Memory", "Paging", "Memory Management", "Multi-level Page Tables"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם מרחב כתובות וירטואלי בגודל 256TB, זיכרון פיזי בגודל 128GB, וגודל דף זיכרון של 4KB. כל רשומת טבלת דפים (PTE) היא בגודל 8 בתים.\n\nא. כמה ביטים נדרשים לכתובת וירטואלית ולכתובת פיזית?\nב. כמה ביטים מוקצים להיסט הדף (offset), לכמה ביטים מוקצה ה-VPN (Virtual Page Number) ולכמה ביטים מוקצה ה-PFN (Physical Frame Number)?\nג. כמה רמות נדרשות לטבלת הדפים ההיררכית במערכת זו, וכמה ביטים מוקצים לכל רמת אינדקס?\nד. מהו הגודל המינימלי של טבלת הדפים ברמה העליונה (Page Directory) בזיכרון הפיזי?", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. חישוב ביטים לכתובות:\n   *   מרחב כתובות וירטואלי: 256TB = 2^8 * 2^40 = 2^48 בתים. לכן נדרשים 48 ביטים לכתובת וירטואלית.\n   *   זיכרון פיזי: 128GB = 2^7 * 2^30 = 2^37 בתים. לכן נדרשים 37 ביטים לכתובת פיזית.\n\nב. חישוב ביטים לרכיבי הכתובת:\n   *   היסט הדף (Offset): גודל דף הוא 4KB = 2^12 בתים. לכן נדרשים 12 ביטים להיסט הדף.\n   *   VPN (Virtual Page Number): כתובת וירטואלית (48 ביטים) - היסט הדף (12 ביטים) = 36 ביטים.\n   *   PFN (Physical Frame Number): כתובת פיזית (37 ביטים) - היסט הדף (12 ביטים) = 25 ביטים.\n\nג. חישוב רמות טבלת הדפים:\n   *   גודל רשומת טבלת דפים (PTE) הוא 8 בתים.\n   *   גודל דף הוא 4KB = 4096 בתים.\n   *   מספר רשומות PTE שיכולות להיכנס בדף אחד: 4096 בתים / 8 בתים לרשומה = 512 רשומות.\n   *   מספר הביטים לאינדקס בכל רמה: log2(512) = 9 ביטים.\n   *   מספר רמות נדרשות: ה-VPN הוא 36 ביטים. מכיוון שכל רמה משתמשת ב-9 ביטים, מספר הרמות הוא 36 / 9 = 4 רמות.\n   *   לכן, נדרשות 4 רמות לטבלת הדפים ההיררכית, ומוקצים 9 ביטים לכל רמת אינדקס.\n\nד. גודל טבלת הדפים ברמה העליונה:\n   *   טבלת הדפים ברמה העליונה (Page Directory) מכילה אינדקסים לרמה הבאה. מכיוון שכל רמה משתמשת ב-9 ביטים, טבלת הדפים ברמה העליונה תכיל 2^9 = 512 רשומות.\n   *   גודל טבלת הדפים ברמה העליונה = 512 רשומות * 8 בתים לרשומה = 4096 בתים = 4KB.\n   *   לכן, הגודל המינימלי של טבלת הדפים ברמה העליונה הוא 4KB (היא תתפוס מסגרת זיכרון פיזי אחת)."}, "difficulty_estimation": "Medium", "_source_file": "0541__Virtual_Memory__Open__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:32:19", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Virtual Memory", "Paging", "Memory Management", "TLB"], "content": {"text": "נתונה מערכת הפעלה עם זיכרון וירטואלי בגודל 2GB, זיכרון פיזי בגודל 256MB, וגודל דף של 8KB. טבלת הדפים ממומשת באופן היררכי, כאשר כל דף של טבלת הדפים יכול להכיל 1024 רשומות (PTEs). גודל כל רשומת PTE הוא 8 בתים.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "10.1", "text": "מהם הגדלים של ה-VPN וה-PFN (בביטים)?", "code_snippet": null, "options": null}, {"id": "10.2", "text": "כמה רמות של טבלת דפים נדרשות במערכת זו? כמה ביטים בכתובת הווירטואלית משמשים לאינדקס בכל רמה?", "code_snippet": null, "options": null}, {"id": "10.3", "text": "תהליך מסוים משתמש ב-100MB של זיכרון וירטואלי (מפוזר באופן אקראי). כמה דפים של טבלת דפים (כולל כל הרמות) יוקצו עבור מיפוי זיכרון זה, במקרה המקסימלי? (הנח שדף טבלת הדפים ברמה העליונה כבר קיים).", "code_snippet": null, "options": null}, {"id": "10.4", "text": "תיאור מצב: המעבד מנסה לגשת לכתובת וירטואלית מסוימת. מתרחש TLB miss, ולאחר מכן מתרחש page fault עבור הדף המבוקש (הדף לא נמצא בזיכרון הפיזי וצריך להיטען מהדיסק). לאחר שהדף נטען, הגישה לנתונים מתבצעת בהצלחה. כמה גישות זיכרון (ל-RAM) בוצעו בסך הכל בתרחיש זה, עד לגישה לנתונים? פרט כל גישה.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\n**סעיף א':**\n*   **זיכרון וירטואלי (VA)**: 2GB = 2^31 בתים, לכן כתובת וירטואלית היא באורך 31 ביטים.\n*   **גודל דף**: 8KB = 2^13 בתים, לכן היסט (Offset) הוא באורך 13 ביטים.\n*   **VPN**: אורך VA - אורך Offset = 31 - 13 = 18 ביטים.\n*   **זיכרון פיזי (PA)**: 256MB = 2^28 בתים, לכן כתובת פיזית היא באורך 28 ביטים.\n*   **PFN**: אורך PA - אורך Offset = 28 - 13 = 15 ביטים.\n\n**סעיף ב':**\n*   **מספר ביטים לאינדקס בכל רמה**: כל דף טבלה יכול להכיל 1024 רשומות. 1024 = 2^10, לכן כל אינדקס ברמה הוא באורך 10 ביטים.\n*   **מספר רמות**: ה-VPN הוא באורך 18 ביטים. מכיוון שכל רמה משתמשת ב-10 ביטים, נדרשות 2 רמות:\n    *   רמה 1 תשתמש ב-10 ביטים (מתוך ה-18 של ה-VPN).\n    *   רמה 2 תשתמש ב-8 הביטים הנותרים (18 - 10 = 8).\n*   לכן, נדרשות 2 רמות. רמה ראשונה משתמשת ב-10 ביטים, רמה שנייה משתמשת ב-8 ביטים.\n\n**סעיף ג':**\n*   **מספר דפים וירטואליים המשמשים על ידי התהליך**: 100MB / 8KB = (100 * 1024 KB) / 8 KB = 12,800 דפים.\n*   **מספר דפי טבלה ברמה 2**: כל דף טבלה ברמה 2 יכול למפות 1024 דפים וירטואליים (בהתבסס על הנתון שכל דף טבלה מכיל 1024 רשומות). לכן, נצטרך ceil(12,800 / 1024) = ceil(12.5) = 13 דפי טבלה ברמה 2.\n*   **מספר דפי טבלה ברמה 1**: מכיוון שדף טבלת הדפים ברמה העליונה (רמה 1) כבר קיים (לפי ההנחה), וכל דף כזה יכול להכיל 1024 רשומות, 13 דפי הטבלה ברמה 2 יצביעו מתוך דף טבלה אחד בלבד ברמה 1. לכן, לא יוקצו דפי טבלה נוספים ברמה 1.\n*   **סה\"כ דפים של טבלת דפים שיוקצו**: 13 דפים (עבור רמה 2).\n\n**סעיף ד':**\nבתרחיש זה יבוצעו 4 גישות זיכרון (ל-RAM) בסך הכל:\n1.  **קריאת PTE מרמה 1 בטבלת הדפים**: בעקבות TLB Miss, ה-MMU מתחיל בחיפוש טבלת הדפים. הגישה הראשונה היא לדף טבלת הדפים ברמה 1 כדי לקרוא את ה-PTE המתאים (1 גישת RAM).\n2.  **קריאת PTE מרמה 2 בטבלת הדפים**: ה-PTE מרמה 1 מכיל כתובת לדף טבלת דפים ברמה 2. ה-MMU ניגש לדף זה כדי לקרוא את ה-PTE הסופי (1 גישת RAM).\n    *   בשלב זה מתגלה Page Fault (ה-PTE מרמה 2 מסומן כלא תקין/לא נמצא בזיכרון הפיזי).\n3.  **כתיבת PTE מעודכן לרמה 2 בטבלת הדפים**: מערכת ההפעלה מטפלת ב-Page Fault: טוענת את הדף הנדרש מהדיסק לזיכרון הפיזי, ואז מעדכנת את ה-PTE המתאים ברמה 2 (מגדירה אותו כתקף ומכניסה את ה-PFN החדש). עדכון זה הוא כתיבה ל-RAM (1 גישת RAM).\n4.  **גישה לנתונים עצמם בזיכרון הפיזי**: לאחר שה-PTE עודכן והדף נטען, ה-MMU מבצע שוב את התרגום וניגש לכתובת הפיזית שהתקבלה כדי לגשת לנתונים המבוקשים (1 גישת RAM)."}, "difficulty_estimation": "Medium", "_source_file": "0542__Virtual_Memory__Open__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:32:49", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Virtual Memory", "Paging", "Memory Management", "TLB"], "content": {"text": "נתונה מערכת עם זיכרון וירטואלי בגודל 4GB, זיכרון פיזי בגודל 1GB, וגודל דף של 4KB. רשומת טבלת דפים (PTE) היא בגודל 4 בתים. במערכת קיימת יחידת TLB עם 128 רשומות והיא 4-way set associative.\n\nתהליך מבצע גישה סדרתית לכל הבתים במערך בגודל 1MB, החל מתחילת המערך. נניח שהמערך אינו טעון בזיכרון הפיזי ואינו נמצא ב-TLB בתחילת הגישה.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "10.1", "text": "מהם הגדלים של ה-VPN וה-PFN?", "code_snippet": null, "options": null}, {"id": "10.2", "text": "כמה רמות דרושות לטבלת הדפים במערכת זו? נמק.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "כמה Page Faults יתרחשו במהלך גישה זו למערך? נמק.", "code_snippet": null, "options": null}, {"id": "10.4", "text": "כמה TLB Misses יתרחשו במהלך גישה זו למערך? נמק.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  **חישוב VPN ו-PFN:**\n    *   גודל זיכרון וירטואלי: 4GB = 2^32 בתים. לכן, כתובת וירטואלית היא 32 ביטים.\n    *   גודל דף: 4KB = 2^12 בתים. לכן, ההיסט (Offset) הוא 12 ביטים.\n    *   גודל VPN = כתובת וירטואלית - היסט = 32 - 12 = 20 ביטים.\n    *   גודל זיכרון פיזי: 1GB = 2^30 בתים. לכן, כתובת פיזית היא 30 ביטים.\n    *   גודל PFN = כתובת פיזית - היסט = 30 - 12 = 18 ביטים.\n\n2.  **מספר רמות לטבלת הדפים:**\n    *   ישנם 2^20 דפים וירטואליים (מכיוון ש-VPN הוא 20 ביטים).\n    *   גודל רשומת טבלת דפים (PTE) הוא 4 בתים.\n    *   בכל דף טבלת דפים (שהוא בגודל 4KB) יכולות להיכנס 4KB / 4 בתים/רשומה = 1024 רשומות (2^10 רשומות).\n    *   לכן, כל רמה בטבלת הדפים יכולה למפות 10 ביטים מה-VPN.\n    *   מכיוון שגודל ה-VPN הוא 20 ביטים, נידרש ל-20 / 10 = 2 רמות לטבלת הדפים.\n\n3.  **מספר Page Faults:**\n    *   גודל המערך הוא 1MB = 2^20 בתים.\n    *   גודל דף הוא 4KB = 2^12 בתים.\n    *   מספר הדפים שהמערך תופס = 1MB / 4KB = 2^20 / 2^12 = 2^8 = 256 דפים.\n    *   מכיוון שהגישה היא סדרתית, וכל המערך אינו טעון בזיכרון הפיזי בתחילה, כל גישה לדף חדש במערך תגרום ל-Page Fault. מכיוון שיש 256 דפים שונים במערך, יתרחשו 256 Page Faults.\n\n4.  **מספר TLB Misses:**\n    *   מספר הדפים הייחודיים שאליהם ניגשים הוא 256.\n    *   גודל ה-TLB הוא 128 רשומות.\n    *   מכיוון שנגישים ל-256 דפים ייחודיים בסדר עוקב, וגודל ה-TLB קטן ממספר הדפים הייחודיים, כל גישה ראשונית לדף חדש תגרום ל-TLB Miss. לאחר שה-TLB מתמלא, גישה לדף חדש תגרום ל-TLB Miss ולפליטת רשומה קיימת (לפי מדיניות ההחלפה, למשל LRU). היות ולא חוזרים לאף דף שכבר נגשו אליו (כי הגישה היא סדרתית וחד-פעמית לכל בית במערך), כל אחד מ-256 הדפים יגרום ל-TLB Miss לפחות פעם אחת. מכיוון שאין גישות חוזרות לדפים שכבר נגשו אליהם, לא יתרחשו TLB Hits לאחר גישה ראשונית לדף. לכן, מספר ה-TLB Misses יהיה שווה למספר הדפים הייחודיים, כלומר 256 TLB Misses."}, "difficulty_estimation": "Medium", "_source_file": "0543__Virtual_Memory__Open__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:33:14", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Virtual Memory", "TLB", "Paging", "Performance", "Effective Access Time"], "content": {"text": "נתונה מערכת זיכרון וירטואלי עם יחידת TLB. זמן גישה לזיכרון הפיזי (RAM) הוא 100 ננו-שניות. זמן גישה ל-TLB הוא 20 ננו-שניות. שיעור הפגיעה ב-TLB (TLB Hit Rate) הוא 98%. שיעור כשל הדף (Page Fault Rate) מכלל הגישות לזיכרון הוא 0.1%. זמן שירות כשל דף (הכולל גישה לדיסק ועדכון טבלת הדפים) הוא 10 מילי-שניות.\n\nחשב את זמן הגישה האפקטיבי הממוצע לזיכרון במערכת זו. פרט את כל החישובים.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "חישוב זמן גישה אפקטיבי ממוצע (EAT):\n\nנפרק את זמן הגישה הממוצע לשני מקרים עיקריים: גישות ללא כשל דף וגישות עם כשל דף.\n\n1.  **זמן גישה במקרה שאין כשל דף (Avg_no_PF):**\n    במקרה זה, הדף נמצא בזיכרון הפיזי. ישנן שתי אפשרויות:\n    *   **פגיעה ב-TLB (TLB Hit):** ההסתברות היא 98% (0.98).\n        הזמן הנדרש: זמן גישה ל-TLB + זמן גישה לזיכרון פיזי = 20 ננו-שניות + 100 ננו-שניות = 120 ננו-שניות.\n    *   **החטאה ב-TLB (TLB Miss):** ההסתברות היא 2% (0.02).\n        במקרה זה, יש לחפש את הרשומה בטבלת הדפים שבזיכרון הראשי, ורק אז לגשת לנתונים.\n        הזמן הנדרש: זמן גישה ל-TLB + זמן גישה לטבלת הדפים (זיכרון פיזי) + זמן גישה לנתונים (זיכרון פיזי) = 20 ננו-שניות + 100 ננו-שניות + 100 ננו-שניות = 220 ננו-שניות.\n\n    לכן, זמן הגישה הממוצע כאשר אין כשל דף הוא:\n    `Avg_no_PF = (0.98 * 120 ns) + (0.02 * 220 ns)`\n    `Avg_no_PF = 117.6 ns + 4.4 ns = 122 ns`\n\n2.  **זמן גישה במקרה של כשל דף (Time_PF):**\n    ההסתברות לכשל דף מכלל הגישות היא 0.1% (0.001).\n    כאשר מתרחש כשל דף, התהליך כולל: גישה ל-TLB (שמסתיימת בהחטאה), גישה לטבלת הדפים בזיכרון הראשי (שמגלה שהדף אינו בזיכרון), ולאחר מכן זמן שירות כשל הדף (שכולל גישה לדיסק, טעינת הדף לזיכרון ועדכון טבלת הדפים וה-TLB).\n    `Time_PF = זמן גישה ל-TLB + זמן גישה לטבלת הדפים (זיכרון פיזי) + זמן שירות כשל דף`\n    יש להמיר את זמן שירות כשל הדף לננו-שניות: `10 ms = 10 * 1,000,000 ns = 10,000,000 ns`\n    `Time_PF = 20 ns + 100 ns + 10,000,000 ns = 10,000,120 ns`\n\n3.  **חישוב זמן הגישה האפקטיבי הממוצע הכולל (EAT):**\n    נשלב את שני המקרים לפי שיעורי ההסתברות שלהם:\n    `EAT = (הסתברות ללא כשל דף * Avg_no_PF) + (הסתברות לכשל דף * Time_PF)`\n    `EAT = (1 - 0.001) * 122 ns + 0.001 * 10,000,120 ns`\n    `EAT = 0.999 * 122 ns + 0.001 * 10,000,120 ns`\n    `EAT = 121.878 ns + 10000.12 ns`\n    `EAT = 10121.998 ns`\n\n    מעוגל, זמן הגישה האפקטיבי הממוצע הוא כ-`10122 ns` או `10.122 מיקרו-שניות`."}, "difficulty_estimation": "Medium", "_source_file": "0544__Virtual_Memory__Open__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:33:39", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Virtual Memory", "Paging", "Multi-level Page Tables", "TLB", "Page Faults", "Memory Management", "Superpages"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם מנגנון דפדוף (paging). המערכת מוגדרת באופן הבא:\n*   כתובות וירטואליות הן בגודל 64 ביטים.\n*   כתובות פיזיות הן בגודל 48 ביטים.\n*   גודל דף הוא 4KB (קילובייט).\n*   כל כניסה בטבלת הדפים (PTE) היא בגודל 8 בתים (64 ביטים).\n*   כל טבלת דפים (ברמה כלשהי) מאוחסנת בדף פיזי אחד בדיוק.\n*   למערכת יש TLB המכיל 128 כניסות (entries) והוא fully associative.\n\nענה על השאלות הבאות, פרט ונמק את חישוביך:", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "חישוב מבנה טבלת הדפים:\nא. כמה רמות של טבלאות דפים נדרשות במערכת זו? פרט את חלוקת הביטים של הכתובת הוירטואלית (Virtual Page Number - VPN) עבור כל רמה.\nב. מהו הגודל המקסימלי של היררכיית טבלאות דפים (בבתים וביחידות של דפים) עבור תהליך המשתמש במלוא מרחב הכתובות הוירטואלי (כלומר, כל הכתובות הוירטואליות ממופות)?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "תרגום כתובת וירטואלית וגישות לזיכרון:\nתאר, צעד אחר צעד, את רצף הפעולות (בדיקת TLB, גישות לזיכרון הראשי עבור טבלאות דפים, גישות לדיסק) המתרחשות כאשר תהליך ניגש לכתובת וירטואלית מסוימת, במקרה הגרוע ביותר (TLB Miss, ולאחר מכן Page Fault הדורש החלפה של דף מלוכלך (dirty page) מהזיכרון הראשי לדיסק וטעינה של דף חדש מהדיסק). כמה גישות לזיכרון הראשי (RAM) וכמה גישות לדיסק יתבצעו במקרה זה, לפני שהגישה לנתון עצמו תושלם? (פרט את החישוב).", "code_snippet": null, "options": null}, {"id": "1.3", "text": "השפעת TLB גדול יותר:\nהצע שינוי אפשרי במבנה או באופן הפעולה של ה-TLB (או במנגנון הזיכרון הוירטואלי בכללותו) שישפר משמעותית את ביצועי המערכת עבור תוכניות המשתמשות במרחבי כתובות גדולים מאוד, אך בעלות לוקליות חזקה (spatial locality) בתוך בלוקים גדולים של זיכרון (לדוגמה, גישה לבלוקים של 2MB או 1GB ברצף). נמק את הצעתך והסבר כיצד היא פותרת את הבעיה.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון לשאלה:\n\n**סעיף 1.1: חישוב מבנה טבלת הדפים**\n\nא. **מספר רמות וחלוקת ביטים של הכתובת הוירטואלית (VPN):**\n*   גודל דף = 4KB = 2^12 בתים. לכן, ההיסט (Offset) הוא 12 ביטים.\n*   כתובת וירטואלית היא 64 ביטים. מספר הדף הוירטואלי (VPN) הוא 64 - 12 = 52 ביטים.\n*   גודל כניסה בטבלת הדפים (PTE) = 8 בתים = 64 ביטים.\n*   כל טבלת דפים מאוחסנת בדף פיזי אחד (4KB). לכן, מספר הכניסות בכל טבלת דפים הוא 4KB / 8 בתים = 4096 / 8 = 512 כניסות.\n*   מספר הביטים הנדרשים למיפוי אינדקס בתוך כל טבלת דפים הוא log2(512) = 9 ביטים.\n*   כדי למפות 52 ביטים של VPN באמצעות אינדקסים בני 9 ביטים, נחלק: 52 / 9 = 5 עם שארית 7. כלומר, נדרשות 6 רמות של טבלאות דפים.\n*   **חלוקת הביטים:**\n    *   רמה 5 (PML5): 7 ביטים (הביטים הגבוהים ביותר של ה-VPN)\n    *   רמה 4 (PML4): 9 ביטים\n    *   רמה 3 (PML3): 9 ביטים\n    *   רמה 2 (PML2): 9 ביטים\n    *   רמה 1 (PML1): 9 ביטים\n    *   רמה 0 (Page Table - PT): 9 ביטים (הביטים הנמוכים ביותר של ה-VPN לפני ההיסט)\n    *   סה\"כ ביטים ל-VPN: 7 + 9 + 9 + 9 + 9 + 9 = 52 ביטים.\n\nב. **הגודל המקסימלי של היררכיית טבלאות דפים:**\nעבור תהליך המשתמש במלוא מרחב הכתובות הוירטואלי (כלומר, כל 2^52 הדפים הוירטואליים ממופים), היררכיית טבלאות הדפים תהיה מלאה.\n*   מספר הדפים בכל רמה (אם היא מלאה): \n    *   PML5 (רמת הבסיס): 1 דף (הטבלה הראשית)\n    *   PML4: 2^7 דפים (כל כניסה ב-PML5 מצביעה על טבלת PML4)\n    *   PML3: 2^7 * 2^9 = 2^16 דפים\n    *   PML2: 2^16 * 2^9 = 2^25 דפים\n    *   PML1: 2^25 * 2^9 = 2^34 דפים\n    *   PT (רמת הדפים הסופית): 2^34 * 2^9 = 2^43 דפים\n*   **סה\"כ דפים עבור היררכיית טבלאות דפים:** סכום כל הדפים הנ\"ל:\n    1 + 2^7 + 2^16 + 2^25 + 2^34 + 2^43 דפים.\n    סכום זה נשלט על ידי המספר הגדול ביותר: 2^43 דפים.\n*   **גודל בבתים:** 2^43 דפים * 4KB/דף = 2^43 * 2^12 בתים = 2^55 בתים.\n    2^55 בתים = 32 פטה-בתים (PB). (כלומר, 32,768 טרה-בתים).\n\n**סעיף 1.2: תרגום כתובת וירטואלית וגישות לזיכרון במקרה הגרוע ביותר**\n\nהמקרה הגרוע ביותר כולל TLB Miss, Page Fault, וצורך בהחלפת דף מלוכלך מהזיכרון הראשי לדיסק לפני טעינת הדף המבוקש.\n\n**רצף הפעולות:**\n1.  **בדיקת TLB**: המעבד מנסה למצוא את ה-PTE המתאים ב-TLB. מתרחש **TLB Miss**. (0 גישות ל-RAM/דיסק בשלב זה).\n2.  **מעבר על טבלאות הדפים (Page Table Walk)**: ה-MMU נדרש לגשת לזיכרון הראשי כדי לאתר את ה-PTE המתאים.\n    *   גישה לטבלת PML5 (ב-RAM) כדי למצוא את ה-PTE עבור רמה 5. (1 גישה ל-RAM)\n    *   גישה לטבלת PML4 (ב-RAM) כדי למצוא את ה-PTE עבור רמה 4. (1 גישה ל-RAM)\n    *   גישה לטבלת PML3 (ב-RAM) כדי למצוא את ה-PTE עבור רמה 3. (1 גישה ל-RAM)\n    *   גישה לטבלת PML2 (ב-RAM) כדי למצוא את ה-PTE עבור רמה 2. (1 גישה ל-RAM)\n    *   גישה לטבלת PML1 (ב-RAM) כדי למצוא את ה-PTE עבור רמה 1. (1 גישה ל-RAM)\n    *   גישה לטבלת PT (ב-RAM) כדי למצוא את ה-PTE עבור הדף המבוקש. (1 גישה ל-RAM)\n    *   **סה\"כ 6 גישות ל-RAM עבור ה-Page Table Walk.**\n3.  **זיהוי Page Fault**: ה-PTE שנמצא ברמת PT (רמה 0) מציין שהדף אינו נוכח בזיכרון הראשי (Present bit = 0). מתרחשת **Page Fault**. מערכת ההפעלה מקבלת שליטה.\n4.  **טיפול ב-Page Fault (מקרה גרוע – החלפת דף מלוכלך):**\n    *   מערכת ההפעלה בוחרת דף (נניח דף 'קורבן') לפי אלגוריתם החלפה. במקרה הגרוע, דף זה הוא 'מלוכלך' (Dirty bit = 1), ולכן יש לכתוב את תוכנו בחזרה לדיסק.\n        *   קריאת תוכן דף ה'קורבן' מ-RAM. (1 גישה ל-RAM)\n        *   כתיבת תוכן דף ה'קורבן' לדיסק. (1 גישה לדיסק)\n        *   עדכון ה-PTE של דף ה'קורבן' בטבלת הדפים שלו (ב-RAM) כדי לסמן אותו כלא נוכח ולעדכן את מיקומו בדיסק. (1 גישה ל-RAM)\n    *   מערכת ההפעלה מקצה מסגרת פיזית (Frame) פנויה (או זו שפונתה כרגע) לדף המבוקש.\n    *   קריאת תוכן הדף המבוקש מהדיסק לתוך המסגרת שהוקצתה ב-RAM. (1 גישה לדיסק, 1 גישה ל-RAM עבור כתיבת התוכן).\n    *   עדכון ה-PTE של הדף המבוקש בטבלת הדפים שלו (ב-RAM) כדי לסמן אותו כנוכח ולעדכן את מספר המסגרת הפיזית שלו. (1 גישה ל-RAM).\n5.  **עדכון TLB**: ה-PTE החדש של הדף המבוקש מתווסף ל-TLB. (פעולה פנימית של החומרה, 0 גישות ל-RAM/דיסק).\n6.  **חזרה על הפקודה**: המעבד מחדש את הפקודה שגרמה ל-Page Fault. כעת, הגישה לכתובת הוירטואלית תצליח.\n    *   ה-TLB ימצא את ה-PTE (TLB Hit). (0 גישות ל-RAM/דיסק).\n    *   גישה לנתון עצמו ב-RAM. (1 גישה ל-RAM).\n\n**סיכום גישות:**\n*   **סה\"כ גישות לזיכרון הראשי (RAM):**\n    6 (Page Table Walk) + 1 (קריאת דף קורבן) + 1 (עדכון PTE דף קורבן) + 1 (כתיבת דף חדש) + 1 (עדכון PTE דף חדש) + 1 (גישה לנתון) = **11 גישות ל-RAM**.\n*   **סה\"כ גישות לדיסק:**\n    1 (כתיבת דף קורבן) + 1 (קריאת דף חדש) = **2 גישות לדיסק**.\n\n**סעיף 1.3: הצעת שינוי לשיפור ביצועים עם Superpages (Huge Pages)**\n\n**הצעה:** יש להוסיף תמיכה ב\"דפי ענק\" (Superpages או Huge Pages) למערכת הזיכרון הוירטואלי.\n\n**הסבר ונימוק:**\nתוכניות המשתמשות במרחבי כתובות גדולים מאוד ובעלות לוקליות חזקה בתוך בלוקים גדולים (לדוגמה, מערכים גדולים של נתונים, או קוד שרץ ברצף) יסבלו משיעור גבוה של TLB Misses אם גודל הדף הסטנדרטי הוא קטן (כמו 4KB). כל דף של 4KB בתוך בלוק של 2MB או 1GB דורש כניסת TLB נפרדת. המשמעות היא שגם אם יש לוקליות מצוינת, ה-TLB עלול להתמלא במהירות ולגרום ל-TLB Misses רבים.\n\n**כיצד Superpages פותרים את הבעיה:**\n*   **הגדרת Superpages:** המערכת תאפשר מיפוי של אזורים רציפים בזיכרון הוירטואלי לאזורים רציפים בזיכרון הפיזי באמצעות דפים גדולים יותר, לדוגמה 2MB או 1GB. במקום 512 כניסות TLB עבור 2MB של זיכרון (512 * 4KB = 2MB), כניסה אחת בלבד ב-TLB תספיק למיפוי כל ה-2MB.\n*   **שינויים במנגנון הזיכרון הוירטואלי:**\n    *   **טבלאות דפים:** ה-PTE ברמות גבוהות יותר של טבלת הדפים (לדוגמה, PML3 או PML2) יכול להכיל ביט מיוחד (לדוגמה, 'Page Size Extension' או 'Huge Page bit') שיציין שה-PTE הזה אינו מצביע על טבלת דפים ברמה נמוכה יותר, אלא ישירות על מסגרת פיזית גדולה (Large Physical Frame). במקרה זה, ביטי ה-VPN הנותרים (אלו שהיו משמשים לאינדוקס ברמות הנמוכות יותר) הופכים להיות חלק מההיסט של הדף הגדול.\n    *   **TLB:** ה-TLB צריך להיות מסוגל לאחסן כניסות בגדלים שונים. במערכות מודרניות, זה נפוץ שיש ל-TLB תמיכה בדפים בגדלים שונים. כאשר מתרחש TLB Hit עבור Superpage, הכתובת הפיזית מתקבלת ישירות, ללא צורך במעבר על טבלאות דפים נוספות.\n\n**היתרונות:**\n*   **הפחתה דרמטית ב-TLB Misses:** כניסת TLB אחת יכולה לכסות נפח זיכרון גדול בהרבה, מה שמגדיל את שיעור ה-TLB Hit ומשפר את ביצועי המערכת.\n*   **הפחתה ב-Page Table Walks:** מכיוון ש-PTE ברמה גבוהה יותר יכול למפות דף ענק, ייתכן שלא יהיה צורך לגשת לרמות נמוכות יותר של טבלאות הדפים, מה שמפחית את מספר הגישות ל-RAM.\n*   **חיסכון בזיכרון טבלאות דפים:** עבור אזורים גדולים הממופים כדפי ענק, אין צורך בטבלאות דפים ברמות הנמוכות, מה שיכול לחסוך בזיכרון המשמש לאחסון טבלאות דפים.\n\nפתרון זה מנצל את הלוקליות המרחבית החזקה בבלוקים גדולים על ידי הקטנת מספר המיפויים הנדרשים ב-TLB ובטבלאות הדפים, ובכך משפר משמעותית את זמן הגישה לזיכרון."}, "difficulty_estimation": "Hard", "_source_file": "0545__Virtual_Memory__Open__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:34:28", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Virtual Memory", "Paging", "Memory Management", "TLB", "Copy-on-Write", "Performance Analysis"], "content": {"text": "נתונה מערכת 64 ביט המממשת זיכרון וירטואלי עם טבלת דפים בעלת 4 רמות עבור מרחב כתובות וירטואלי בגודל 48 ביט. גודל דף הוא 4KB. כל כניסה בטבלת הדפים (PTE) היא בגודל 8 בתים.\nהמערכת כוללת TLB עם 128 כניסות, בארגון 4-way set associative, המשתמש באלגוריתם החלפה LRU. זמן גישה ל-TLB הוא 1 מחזור שעון, זמן גישה לזיכרון הראשי הוא 100 מחזורי שעון, וזמן גישה לדיסק הוא 10,000,000 מחזורי שעון.\n\nתהליך במערכת מבצע פעולה הכוללת איטרציה על מערך גדול מסוג `int arr[10^9];` כאשר `sizeof(int)` הוא 4 בתים.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "מבנה טבלת הדפים וגודלה:\n1. כמה ביטים משמשים למספר דף וירטואלי (VPN) וכמה להיסט (offset)?\n2. פרט את חלוקת הביטים של ה-VPN לאינדקסים עבור 4 הרמות של טבלת הדפים.\n3. חשב את הגודל המקסימלי (בבתים) של טבלת דפים עבור תהליך בודד המנצל את כל מרחב הכתובות הוירטואלי שלו, בהנחה שכל הדפים נמצאים בזיכרון הראשי (resident).", "code_snippet": null, "options": null}, {"id": "1.2", "text": "ניתוח ביצועים עבור דפוס גישה ספציפי:\nנתבונן בלולאה הבאה המבוצעת על ידי תהליך:\n```c\nfor (long i = 0; i < N; i++) { // N הוא מספר גדול מאוד, נניח 10^8 איטרציות\n    arr[i * (1 << 12)] = i;\n}\n```\nהנח שהמערך `arr` מתחיל בכתובת מיושרת לדף (page-aligned address).\n1. נתח את מספר ה-TLB misses ואת מספר ה-page faults שיקרו לכל איטרציה (בממוצע, לאחר שלב ה-\"חימום\" הראשוני שבו ה-TLB וטבלת הדפים מתייצבים), בהינתן גודל ה-TLB, האסוציאטיביות ומדיניות ההחלפה. הנח שה-TLB ריק בתחילה ושאין דפים בזיכרון.\n2. מהו זמן הגישה הממוצע לזיכרון עבור לולאה זו, לאחר שלב ה-\"חימום\" הראשוני?", "code_snippet": "for (long i = 0; i < N; i++) { // N הוא מספר גדול מאוד, נניח 10^8 איטרציות\n    arr[i * (1 << 12)] = i;\n}", "options": null}, {"id": "1.3", "text": "השפעת Copy-on-Write עם `fork()`:\nאם התהליך יוצר תהליך בן (child process) באמצעות `fork()` מיד לפני ביצוע הלולאה הנ\"ל, ורק תהליך הבן מבצע את הלולאה, כיצד מנגנון Copy-on-Write (CoW) ישפיע על צריכת הזיכרון ועל מספר ה-page faults הפוטנציאליים עבור תהליך האב ותהליך הבן?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1. מבנה טבלת הדפים וגודלה:\n1. כתובת וירטואלית: 48 ביטים. גודל דף: 4KB = 2^12 בתים.\n   לכן, ההיסט (offset) הוא 12 ביטים.\n   מספר הדף הוירטואלי (VPN) הוא 48 - 12 = 36 ביטים.\n2. כל כניסה בטבלת הדפים (PTE) היא בגודל 8 בתים. גודל דף הוא 4KB = 4096 בתים.\n   מספר הכניסות בכל דף טבלה הוא 4096 בתים / 8 בתים/כניסה = 512 כניסות = 2^9 כניסות.\n   לכן, כל רמה בטבלת הדפים דורשת log2(512) = 9 ביטים עבור האינדקס שלה.\n   חלוקת ה-VPN (36 ביטים) ל-4 רמות תהיה: 9 ביטים עבור L4, 9 ביטים עבור L3, 9 ביטים עבור L2, 9 ביטים עבור L1 (סה\"כ 36 ביטים).\n3. הגודל המקסימלי של טבלת דפים עבור תהליך המנצל את כל מרחב הכתובות הוירטואלי (48 ביט, כלומר 2^36 דפים): \n   * רמה 4 (PGD): דף אחד (השורש).\n   * רמה 3 (PUD): 2^9 דפים (512 דפים, כל אחד מהם מצביע על דפים ברמה L2).\n   * רמה 2 (PMD): 2^9 * 2^9 = 2^18 דפים (262,144 דפים, כל אחד מהם מצביע על דפים ברמה L1).\n   * רמה 1 (PTE): 2^9 * 2^9 * 2^9 = 2^27 דפים (134,217,728 דפים, כל אחד מהם מכיל PTEs המצביעים על מסגרות פיזיות).\n   סה\"כ מספר דפים עבור טבלת הדפים: 1 + 2^9 + 2^18 + 2^27 דפים.\n   הגודל הכולל (בבתים) הוא: (1 + 2^9 + 2^18 + 2^27) * 4KB.\n   זהו בקירוב 2^27 * 4KB = 2^27 * 2^12 בתים = 2^39 בתים = 512GB.\n\n1.2. ניתוח ביצועים עבור דפוס גישה ספציפי:\n1. גודל המערך `arr` הוא 10^9 * 4 בתים = 4GB. גודל דף הוא 4KB.\n   הלולאה ניגשת לאלמנטים בכתובות: `BaseAddr`, `BaseAddr + 4096*4`, `BaseAddr + 2*4096*4`, וכו'.\n   ההפרש בין גישות עוקבות הוא 4096 * 4 בתים = 16KB.\n   מכיוון שגודל דף הוא 4KB, כל גישה בלולאה מתייחסת לדף וירטואלי חדש ושונה לחלוטין מהדף הקודם (הגישה מדלגת על 3 דפים מלאים ונוחתת על הדף הרביעי הבא).\n   *   **TLB Misses:** ה-TLB מכיל 128 כניסות. מכיוון שכל גישה היא לדף חדש, וכמות הדפים הייחודיים שאליהם ניגשים (4GB / 16KB = 2^18) גדולה בהרבה מכמות הכניסות ב-TLB, כל גישה תגרום ל-TLB miss לאחר שלב ה-\"חימום\" הראשוני. מדיניות LRU לא תעזור במקרה זה כי אין שימוש חוזר בדפים בטווח ה-TLB. לכן, שיעור ה-TLB misses הוא 100%.\n   *   **Page Faults:** באופן דומה, מכיוון שכל גישה היא לדף וירטואלי חדש, וכמות הדפים הייחודיים גדולה בהרבה מכל כמות סבירה של מסגרות זיכרון פיזיות שיכולות להיות זמינות לתהליך, כל גישה צפויה לגרום ל-page fault לאחר שלב ה-\"חימום\" הראשוני (כלומר, לאחר שהזיכרון הפיזי הזמין לתהליך התמלא והדפים הישנים מפונים). לכן, שיעור ה-page faults הוא 100% (במקרה הגרוע ביותר).\n2. **זמן הגישה הממוצע לזיכרון (AMAT):**\n   בכל גישה מתרחשים: TLB Miss -> Page Table Walk (4 רמות) -> Page Fault -> Disk I/O (לטעינת דף) -> עדכון טבלת דפים ו-TLB -> גישה לנתון.\n   *   עלות TLB miss (חיפוש ב-TLB שנופל): 1 מחזור שעון.\n   *   הליכה בטבלת הדפים (Page Table Walk): 4 רמות * 100 מחזורי שעון/רמה (גישה לזיכרון ראשי) = 400 מחזורי שעון.\n   *   Page Fault: \n      *   גישה לדיסק כדי לטעון את הדף המבוקש (page-in): 10,000,000 מחזורי שעון.\n      *   במקרה הגרוע ביותר, אם יש צורך לפנות דף מלוכלך מהזיכרון לדיסק (page-out): 10,000,000 מחזורי שעון נוספים.\n      *   עדכון טבלת הדפים וה-TLB.\n   *   גישה לנתון עצמו (לאחר שהדף בזיכרון): 100 מחזורי שעון.\n   לכן, AMAT (במקרה הגרוע ביותר עם page-out) = 1 (TLB miss) + 400 (PT walk) + 10,000,000 (page-in) + 10,000,000 (page-out) + 100 (גישת נתון) ≈ 20,000,000 מחזורי שעון.\n\n1.3. השפעת Copy-on-Write עם `fork()`:\n*   **לפני ה-fork():** תהליך האב מחזיק את המערך `arr` במרחב הכתובות הוירטואלי שלו, והדפים הפיזיים המכילים את המערך ממופים אליו.\n*   **לאחר ה-fork():**\n    *   תהליך האב ותהליך הבן חולקים את אותם דפים פיזיים עבור המערך `arr`. כניסות טבלת הדפים (PTEs) המצביעות על דפים אלו מסומנות כקריאה בלבד (read-only) בשני התהליכים.\n    *   בתחילה, אף אחד מהתהליכים לא צורך זיכרון פיזי נוסף עבור `arr`.\n    *   **כאשר תהליך הבן מבצע את הלולאה וכותב ל-`arr`:**\n        *   כל ניסיון כתיבה של תהליך הבן לכתובת `arr[i * (1 << 12)]` יגרום ל-**Copy-on-Write (CoW) fault**, מכיוון שהדף מסומן כקריאה בלבד.\n        *   מערכת ההפעלה תטפל בתקלה: היא תקצה דף פיזי חדש, תעתיק אליו את התוכן של הדף המקורי המשותף, ותעדכן את כניסת טבלת הדפים של תהליך הבן כך שתצביע על הדף הפיזי החדש והפרטי הזה, ותסמן אותו כניתן לכתיבה. ה-PTE של תהליך האב ימשיך להצביע על הדף המקורי (או עותק שלו אם היה משותף עם תהליכים נוספים).\n        *   **השפעה על Page Faults:** מכיוון שכל גישה בלולאה היא לדף חדש וייחודי (כפי שנותח בסעיף 1.2), כל גישה ראשונה לדף כזה על ידי תהליך הבן תגרור CoW fault. בנוסף, אם הדף אינו נמצא בזיכרון הפיזי (page fault רגיל), הוא יטען קודם מהדיסק, ורק אז יתבצע ה-CoW (או שה-CoW fault handler יטפל בטעינה ובהעתקה). לכן, תהליך הבן יחווה שיעור גבוה מאוד של CoW faults, בנוסף ל-page faults רגילים אם הדפים אינם בזיכרון.\n        *   **השפעה על צריכת זיכרון:** תהליך הבן יצרוך בהדרגה זיכרון פיזי פרטי חדש ככל שיבצע פעולות CoW. עבור הלולאה כולה, אם הוא כותב ל-2^18 דפים ייחודיים, הוא יצרוך בסופו של דבר 2^18 * 4KB = 2^30 בתים = 1GB של זיכרון פיזי *פרטי* עבור הדפים ששונו במערך `arr`.\n        *   תהליך האב לא משנה את המערך, ולכן צריכת הזיכרון שלו עבור `arr` לא תשתנה. הדפים שלו יישארו מצביעים על הדפים המקוריים (המשותפים) או על עותקים שלהם, והם יישארו במצב קריאה בלבד (אלא אם כן גם האב ינסה לכתוב)."}, "difficulty_estimation": "Hard", "_source_file": "0546__Virtual_Memory__Open__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:35:12", "_subject": "Virtualization"}, {"id": 6, "type": "Open", "topic": ["Virtual Memory", "Paging", "Memory Management", "TLB", "Context Switching", "Memory Protection", "Copy-on-Write"], "content": {"text": "מערכת הפעלה מודרנית פועלת על מעבד 64-ביט התומך במרחב כתובות וירטואלי בגודל 48 ביטים. גודל הדף במערכת הוא 4KB. המערכת נדרשת לתמוך ביעילות בתהליכים עם מרחבי כתובות וירטואליים דלילים (sparse) ובמעבר מהיר בין הקשרים (context switches).", "code_snippet": null, "options": null}, "sub_questions": [{"id": "6.1", "text": "תארו ובססו חישובית את מבנה טבלת הדפים הרב-רמתית הנדרשת במערכת זו. כמה רמות טבלאות דפים יהיו, ומה יהיה גודל כל אינדקס רמה (ביחידות ביטים)? הניחו שכל כניסה בטבלת דפים (PTE) תופסת 8 בתים.", "code_snippet": null, "options": null}, {"id": "6.2", "text": "כיצד מבנה טבלת הדפים שבחרתם משפיע על ביצועי ה-TLB, ובאילו דרכים ניתן למזער את העלות של פסיקות TLB (TLB misses) הנובעות ממעבר הקשרים (context switches)?", "code_snippet": null, "options": null}, {"id": "6.3", "text": "פרטו כיצד ניתן להשתמש בדגלים (flags) בכניסות טבלת הדפים (PTEs) כדי לממש הגנת זיכרון (read/write/execute) ושיתוף זיכרון בין תהליכים (לדוגמה, ספריות משותפות או Copy-on-Write)?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "6.1: גודל מרחב הכתובות הוירטואלי הוא 48 ביטים. גודל הדף הוא 4KB (2^12 בתים), לכן ההיסט (offset) בתוך הדף הוא 12 ביטים. מספר הדף הוירטואלי (VPN) הוא 48 - 12 = 36 ביטים.\nכל כניסה בטבלת הדפים (PTE) היא בגודל 8 בתים. גודל דף הוא 4KB (4096 בתים). מספר הכניסות בכל טבלת דפים (שמאוחסנת בדף אחד) הוא 4096 בתים / 8 בתים/כניסה = 512 כניסות. כל אינדקס רמה בטבלת הדפים יצטרך log2(512) = 9 ביטים.\nכדי למפות VPN באורך 36 ביטים באמצעות אינדקסים של 9 ביטים, נדרש: מספר רמות = ceil(36 ביטים / 9 ביטים לרמה) = 4 רמות. מבנה טבלת הדפים יהיה רב-רמתי עם 4 רמות, כאשר כל אינדקס בכל רמה הוא באורך 9 ביטים.\n\n6.2: מבנה טבלת הדפים הרב-רמתי מגדיל את מספר הגישות לזיכרון הראשי הנדרשות לתרגום כתובת וירטואלית (במקרה של TLB miss). במערכת 4 רמות, זה יכול לדרוש עד 4 גישות לזיכרון הראשי רק כדי למצוא את ה-PTE הסופי. ה-TLB נועד לצמצם את העלות הזו על ידי שמירת מיפויים בזיכרון מטמון מהיר.\nעל מנת למזער את עלות פסיקות TLB (TLB misses) הנובעות ממעבר הקשרים:\n*   **ASID (Address Space ID)**: הוספת מזהה מרחב כתובות (ASID) לכל כניסה ב-TLB. כאשר מתבצע מעבר הקשרים, במקום לנקות את כל ה-TLB, המערכת יכולה פשוט לטעון את ה-ASID של התהליך החדש. כניסות TLB של תהליכים אחרים יישארו, אך לא ישומשו אלא אם ה-ASID שלהן תואם את ה-ASID הפעיל. זה מפחית את הצורך ב-TLB flush מלא.\n*   **Large Pages / Huge Pages**: שימוש בדפים גדולים יותר (לדוגמה, 2MB או 1GB) עבור אזורים גדולים ורציפים בזיכרון. דף גדול אחד יכול לכסות טווח זיכרון נרחב יותר, ובכך להפחית את מספר כניסות ה-TLB הנדרשות עבור אותו טווח, מה שמוביל לפחות TLB misses.\n*   **Global Pages**: סימון דפים מסוימים (כמו קוד ליבת מערכת ההפעלה) כ\"גלובליים\" (Global). כניסות TLB עבור דפים גלובליים אינן מנוקות במעבר הקשרים, מכיוון שהן רלוונטיות לכל התהליכים.\n*   **Hardware Prefetching**: מעבדים מודרניים כוללים מנגנוני prefetching חומרתיים שיכולים לזהות דפוסי גישה לטבלאות דפים ולטעון מראש PTEs ל-TLB, לפני שהם נדרשים בפועל.\n\n6.3: דגלים (flags) בכניסות טבלת הדפים (PTEs) חיוניים ליישום הגנת זיכרון ושיתוף זיכרון:\n*   **הגנת זיכרון (Memory Protection)**:\n    *   **Read/Write/Execute (R/W/X) bits**: ביטים אלו קובעים את הרשאות הגישה לדף. לדוגמה, דף המכיל קוד יסומן כ-Read/Execute בלבד, דף נתונים יסומן כ-Read/Write, ודף stack יכול להיות Read/Write. ניסיון גישה שאינו תואם את ההרשאות יגרום ל-page fault (פסיקת הגנת זיכרון).\n    *   **User/Supervisor bit**: ביט זה קובע אם הדף נגיש למצב משתמש (User mode) או רק למצב מנהל (Supervisor mode). דפים המכילים קוד ונתוני ליבה נגישים רק במצב מנהל.\n*   **שיתוף זיכרון (Memory Sharing)**:\n    *   **Shared Libraries**: כדי לשתף ספריות משותפות (לדוגמה, libc.so), כניסות PTE שונות במרחבי כתובות של תהליכים שונים יכולות להצביע לאותה מסגרת פיזית (PFN). דפי קוד ונתונים קבועים של הספריות יסומנו כ-Read-only וישותפו בין תהליכים מרובים.\n    *   **Copy-on-Write (CoW)**: מנגנון זה משמש לשיתוף דפים בין תהליכים (לדוגמה, לאחר קריאת fork()). דפים מסומנים כ-Read-only ומשותפים. כאשר אחד התהליכים מנסה לכתוב לדף משותף, מתרחשת פסיקת דף. מערכת ההפעלה יוצרת עותק פיזי של הדף, מעדכנת את ה-PTE של התהליך הכותב להצביע על המסגרת החדשה, ומסמנת אותה כ-Writable. הדף המקורי נשאר משותף (אם יש לו עדיין שותפים) או נשאר בבעלותו של התהליך השני."}, "difficulty_estimation": "Hard", "_source_file": "0547__Virtual_Memory__Open__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:35:42", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Virtual Memory", "Paging", "Memory Management", "TLB", "Page Faults", "Performance"], "content": {"text": "נתונה מערכת הפעלה עם מנגנון זיכרון וירטואלי המשתמש בטבלאות דפים מרובות רמות וב-TLB. פרטי המערכת הם כדלקמן:\n*   מרחב כתובות וירטואלי (VA): 48 ביטים.\n*   מרחב כתובות פיזי (PA): 40 ביטים.\n*   גודל דף (Page Size): 4KB.\n*   גודל כניסה בטבלת דפים (PTE): 8 בתים.\n*   כל טבלת דפים (בכל רמה) מאוחסנת בדף אחד בדיוק.\n*   ה-TLB הוא בגודל 128 כניסות, אסוציאטיבי מלא (Fully Associative), ומשתמש במדיניות החלפה LRU.\n*   מספר המסגרות הפיזיות הזמינות לתהליך (לצורך טעינת דפי נתונים בלבד, לא דפי טבלאות דפים): 100 מסגרות.\n*   זמני גישה:\n    *   TLB Hit: 1ns\n    *   גישה לזיכרון הראשי (לדף נתונים או כניסה בטבלת דפים): 100ns\n    *   גישה לדיסק (עקב Page Fault): 10ms (10,000,000ns)\n\nנתון הקוד הבא המופעל על ידי תהליך יחיד. המערך `arr` מתחיל בכתובת וירטואלית מיושרת לדף (page-aligned).\n\nענו על השאלות הבאות, ופרטו את כל החישובים וההנחות:", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define NUM_PAGES 2560 // Total pages to access\n#define PAGE_SIZE 4096 // 4KB\n\nint main() {\n    char *arr = (char *)malloc(NUM_PAGES * PAGE_SIZE); // Allocate 10MB\n    if (arr == NULL) {\n        perror(\"malloc failed\");\n        return 1;\n    }\n\n    for (int i = 0; i < NUM_PAGES; i++) {\n        arr[i * PAGE_SIZE] = 0; // Access the first byte of each page\n    }\n\n    free(arr);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "מבנה כתובת וירטואלית וטבלאות דפים:\n    *   כמה רמות של טבלאות דפים נדרשות? פרטו את חלוקת הביטים של הכתובת הוירטואלית לכל רמה ולהיסט.\n    *   מהו הגודל הכולל (בבתים) של כל טבלאות הדפים הנדרשות כדי למפות את כל המרחב הוירטואלי של תהליך אחד? (הניחו שכל הדפים במרחב הוירטואלי יכולים להיות ממופים, גם אם לא כולם בזיכרון הפיזי).", "code_snippet": null, "options": null}, {"id": "1.2", "text": "ביצועי TLB ו-Page Faults:\n    *   כמה גישות ל-TLB יתבצעו במהלך ריצת הלולאה?\n    *   כמה TLB misses יתרחשו במהלך ריצת הלולאה?\n    *   כמה Page Faults יתרחשו במהלך ריצת הלולאה? (הניחו שה-TLB והזיכרון הפיזי ריקים בתחילת הלולאה, ורק דפי הנתונים נכנסים ל-100 המסגרות הזמינות, לא דפי טבלאות דפים).", "code_snippet": null, "options": null}, {"id": "1.3", "text": "זמן גישה אפקטיבי:\n    *   מהו זמן הגישה הממוצע (Effective Access Time - EAT) לכל גישת זיכרון בתוך הלולאה?\n    *   מהו הזמן הכולל לביצוע הלולאה, בהתחשב בזמני הגישה שצוינו? (התעלמו מזמני CPU, התמקדו רק בגישות לזיכרון).", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\n1.1. מבנה כתובת וירטואלית וטבלאות דפים:\n*   **גודל היסט (Offset)**: גודל דף הוא 4KB = 2^12 בתים. לכן, ההיסט הוא 12 ביטים.\n*   **ביטים עבור מספר דף וירטואלי (VPN)**: מרחב הכתובות הוירטואלי הוא 48 ביטים. לאחר הפחתת ההיסט, נשארים 48 - 12 = 36 ביטים עבור ה-VPN.\n*   **מספר כניסות לטבלת דפים בדף אחד**: גודל כניסה בטבלת דפים (PTE) הוא 8 בתים. גודל דף הוא 4KB = 4096 בתים. לכן, מספר הכניסות בכל טבלת דפים הוא 4096 / 8 = 512 כניסות. 512 = 2^9, כלומר כל רמה בטבלת הדפים משתמשת ב-9 ביטים מתוך ה-VPN.\n*   **מספר רמות**: ה-VPN הוא 36 ביטים, וכל רמה צורכת 9 ביטים. לכן, מספר הרמות הנדרשות הוא 36 / 9 = 4 רמות.\n*   **חלוקת הכתובת הוירטואלית**: P1 (רמה 1): 9 ביטים | P2 (רמה 2): 9 ביטים | P3 (רמה 3): 9 ביטים | P4 (רמה 4): 9 ביטים | Offset (היסט): 12 ביטים. סה\"כ: 9 + 9 + 9 + 9 + 12 = 48 ביטים.\n\n*   **גודל כולל של טבלאות הדפים (למיפוי כל המרחב הוירטואלי):**\n    *   כדי למפות את כל המרחב הוירטואלי (2^36 דפים), נדרשות טבלאות דפים בכל הרמות:\n        *   רמה 1 (טבלת הבסיס): 1 דף.\n        *   רמה 2: 2^9 טבלאות (כי לרמה 1 יש 2^9 כניסות, וכל כניסה מצביעה על טבלת רמה 2).\n        *   רמה 3: 2^9 * 2^9 = 2^18 טבלאות.\n        *   רמה 4: 2^9 * 2^9 * 2^9 = 2^27 טבלאות.\n    *   סה\"כ דפים לטבלאות דפים = 1 + 2^9 + 2^18 + 2^27.\n    *   הגודל הכולל בבתים = (1 + 512 + 262,144 + 134,217,728) * 4KB.\n    *   מכיוון שהמספר הגדול ביותר דומיננטי, הגודל הוא בקירוב 2^27 * 4KB = 2^27 * 2^12 בתים = 2^39 בתים.\n    *   2^39 בתים = 512 ג'יגה-בייט (GB).\n\n1.2. ביצועי TLB ו-Page Faults:\n*   **מספר גישות ל-TLB**: הלולאה מבצעת גישה לדף אחד בכל איטרציה, ובסה\"כ 2560 איטרציות (NUM_PAGES). לכן, יהיו 2560 גישות ל-TLB.\n*   **מספר TLB misses**: ה-TLB בגודל 128 כניסות. המערך ניגש ל-2560 דפים ייחודיים באופן סדרתי. מכיוון שכל דף נגיש פעם אחת בלבד במהלך הלולאה, ואין גישות חוזרות לדפים שכבר הוצאו מה-TLB, כל 2560 הגישות יגרמו ל-TLB misses.\n*   **מספר Page Faults**: מספר המסגרות הפיזיות הזמינות לדפי נתונים הוא 100. אנו ניגשים ל-2560 דפים ייחודיים. בדומה ל-TLB, מכיוון שכל דף נגיש פעם אחת בלבד והזיכרון הפיזי יכול להכיל רק 100 דפים, כל 2560 הגישות יגרמו ל-Page Faults (ה-100 הראשונים יטענו דפים, וה-2460 הנותרים יגרמו להחלפה של דפים קיימים שאינם נגישים יותר).\n\n1.3. זמן גישה אפקטיבי:\nכל גישת זיכרון בתוך הלולאה גורמת ל-TLB miss וגם ל-Page Fault. נחשב את הזמן הכולל עבור גישת זיכרון לוגית אחת:\n\n*   **1. גישת TLB (Miss)**: 1ns.\n*   **2. מעבר על טבלאות הדפים (Page Table Walk)**: ישנן 4 רמות של טבלאות דפים. כל גישה ל-PTE בזיכרון הראשי אורכת 100ns. לכן, 4 * 100ns = 400ns. במהלך המעבר הזה מתגלה שקיים Page Fault.\n*   **3. טיפול ב-Page Fault**: (בהנחה שדף מלוכלך וצריך להיכתב לדיסק)\n    *   קריאה מהדיסק (Page-in) של הדף המבוקש: 10,000,000ns (10ms).\n    *   כתיבה לדיסק (Page-out) של דף שהוצא מהזיכרון: 10,000,000ns (10ms).\n    *   עדכון כניסת טבלת הדפים (PTE) בזיכרון הראשי (לאחר טעינת הדף): 100ns.\n    *   עדכון ה-TLB עם הכניסה החדשה: 1ns.\n    *   בשלב זה, הפקודה המקורית מופעלת מחדש.\n*   **4. ביצוע הפקודה מחדש**: (לאחר שהדף כבר בזיכרון הפיזי וה-TLB מעודכן)\n    *   גישת TLB (כעת Hit): 1ns.\n    *   גישה לנתונים בזיכרון הראשי: 100ns.\n\n*   **זמן גישה אפקטיבי (EAT) לגישת זיכרון לוגית אחת**:\n    EAT = (1ns TLB miss) + (400ns PT walk) + (10,000,000ns Page-in) + (10,000,000ns Page-out) + (100ns PTE update) + (1ns TLB update) + (1ns TLB hit) + (100ns data access)\n    EAT = 1 + 400 + 10,000,000 + 10,000,000 + 100 + 1 + 1 + 100\n    EAT = 20,000,603 ns.\n\n*   **זמן כולל לביצוע הלולאה**:\n    סה\"כ גישות זיכרון = 2560.\n    זמן כולל = EAT * מספר הגישות\n    זמן כולל = 20,000,603 ns * 2560\n    זמן כולל = 51,201,543,680 ns\n    זמן כולל = 51.20154368 שניות (כ-51.2 שניות)."}, "difficulty_estimation": "Hard", "_source_file": "0549__Virtual_Memory__Open__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:37:19", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Virtual Memory", "Paging", "TLB", "Page Faults", "Memory Management", "C/C++"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם המאפיינים הבאים:\n*   מרחב כתובות וירטואלי: 48 ביטים.\n*   מרחב כתובות פיזי: 40 ביטים.\n*   גודל דף (Page Size): 4KB.\n*   טבלת דפים רב-שכבתית (Multi-level Page Table).\n*   גודל כניסה בטבלת הדפים (PTE): 8 בתים (64 ביטים).\n*   TLB: מכיל 16 כניסות, אסוציאטיבי מלא (Fully Associative), מדיניות החלפה LRU.\n*   מדיניות החלפת דפים בזיכרון הפיזי: LRU.\n*   לכל תהליך מוקצים 32 מסגרות פיזיות (frames) בלבד עבור קטע הנתונים שלו (data segment).\n*   ה-TLB ריק בתחילת הפעלת הקוד, ואין דפים טעונים מראש לזיכרון הפיזי עבור קטע הנתונים של התהליך.\n\nנתון קטע הקוד הבא בשפת C, המאתחל מטריצה גדולה:\n", "code_snippet": "#define ARRAY_SIZE_X 1024\n#define ARRAY_SIZE_Y 1024\nint matrix[ARRAY_SIZE_X][ARRAY_SIZE_Y];\n\nvoid initialize_matrix() {\n    for (int i = 0; i < ARRAY_SIZE_X; ++i) {\n        for (int j = 0; j < ARRAY_SIZE_Y; ++j) {\n            matrix[i][j] = i + j;\n        }\n    }\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "כמה רמות קיימות בטבלת הדפים? פרטו את החישוב.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "כמה דפים יידרשו לאחסון המטריצה `matrix` כולה? פרטו את החישוב.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "כמה Page Faults סך הכל יתרחשו במהלך ביצוע הפונקציה `initialize_matrix`? נמקו והסבירו את מדיניות החלפת הדפים.", "code_snippet": null, "options": null}, {"id": "1.4", "text": "כמה TLB Misses סך הכל יתרחשו במהלך ביצוע הפונקציה `initialize_matrix`? נמקו והסבירו את מדיניות החלפת ה-TLB.", "code_snippet": null, "options": null}, {"id": "1.5", "text": "מהו המספר הכולל של גישות לזיכרון הראשי (RAM) עבור נתוני המטריצה ועבור טבלאות הדפים (ללא ספירת גישות לדיסק) במהלך ביצוע הפונקציה `initialize_matrix`? פרטו את החישוב עבור כל סוג גישה (TLB hit, TLB miss, Page Fault).", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "### פתרון\n\n**1.1. כמה רמות קיימות בטבלת הדפים?**\n*   גודל כתובת וירטואלית: 48 ביטים.\n*   גודל דף: 4KB = 2^12 בתים. לכן, ה-Offset בדף הוא 12 ביטים.\n*   מספר הביטים לכתובת דף וירטואלי (VPN): 48 - 12 = 36 ביטים.\n*   גודל כניסה בטבלת הדפים (PTE): 8 בתים.\n*   מספר כניסות בטבלת דפים אחת (שממוקמת בדף פיזי אחד): 4KB / 8 בתים/כניסה = 512 כניסות = 2^9 כניסות.\n*   לכן, כל רמה בטבלת הדפים משתמשת ב-9 ביטים מתוך ה-VPN.\n*   מספר הרמות הנדרש: 36 ביטים (VPN) / 9 ביטים/רמה = 4 רמות.\n\n**תשובה: 4 רמות.**\n\n**1.2. כמה דפים יידרשו לאחסון המטריצה `matrix` כולה?**\n*   גודל `int`: 4 בתים.\n*   גודל שורה במטריצה: `1024 * 4` בתים = `4096` בתים = `4KB`.\n*   מאחר שגודל דף הוא 4KB, כל שורה במטריצה תופסת בדיוק דף אחד.\n*   מספר השורות במטריצה: 1024.\n*   לכן, המטריצה כולה תתפרס על פני 1024 דפים שונים.\n\n**תשובה: 1024 דפים.**\n\n**1.3. כמה Page Faults סך הכל יתרחשו?**\n*   המטריצה מתפרסת על 1024 דפים שונים (כפי שחושב בסעיף 1.2).\n*   לכל תהליך מוקצים 32 מסגרות פיזיות בלבד עבור קטע הנתונים שלו.\n*   מדיניות החלפת הדפים היא LRU.\n*   בהתחלה, אף דף של המטריצה אינו טעון לזיכרון הפיזי, וה-TLB ריק.\n*   הלולאה החיצונית רצה `i` מ-0 עד 1023. הלולאה הפנימית רצה `j` מ-0 עד 1023, וניגשת לכל האלמנטים בשורה `i`.\n*   גישה ראשונה לכל שורה `i` (לדוגמה `matrix[i][0]`) תגרום ל-Page Fault, מכיוון שהדף עבור שורה `i` אינו נמצא בזיכרון הפיזי.\n*   **ה-32 דפים הראשונים (שורות 0 עד 31)**: כל גישה ראשונה לדף חדש תגרום ל-Page Fault. מכיוון שיש מספיק מסגרות פנויות (32), הדפים ייטענו לזיכרון הפיזי. סך הכל 32 Page Faults.\n*   **הדפים הבאים (שורות 32 עד 1023)**: כאשר ניגשים לדף עבור שורה `i` (כאשר `i >= 32`), 32 המסגרות הפיזיות כבר מלאות. לכן, כל גישה לדף חדש תגרום ל-Page Fault, אשר תפעיל את מדיניות LRU. הדף שהיה בשימוש הכי פחות לאחרונה (במקרה זה, דף `i-32`) יוחלף על ידי הדף החדש. כלומר, עבור כל אחת מ-`1024 - 32 = 992` השורות הנותרות, יתרחש Page Fault.\n*   סה\"כ Page Faults = 32 (לדפים הראשונים) + 992 (לדפים הבאים עם החלפה) = 1024.\n*   יש לציין שכל דפי המטריצה נכתבים (`matrix[i][j] = i + j;`), ולכן כולם יהיו \"מלוכלכים\" (dirty). כאשר דף מלוכלך מוחלף (החל מה-33 Page Fault ואילך), הוא ייכתב לדיסק לפני טעינת הדף החדש.\n\n**תשובה: 1024 Page Faults.**\n\n**1.4. כמה TLB Misses סך הכל יתרחשו?**\n*   ה-TLB מכיל 16 כניסות, אסוציאטיבי מלא, מדיניות החלפה LRU.\n*   ה-TLB ריק בתחילת הפונקציה.\n*   כל גישה לדף וירטואלי חדש (שאינו ב-TLB) תגרום ל-TLB Miss. לאחר ה-TLB Miss, ה-PTE המתאים יוכנס ל-TLB.\n*   הלולאה הפנימית (`j`) ניגשת ל-1024 אלמנטים בתוך אותה שורה (כלומר, באותו דף). לכן, הגישה הראשונה לאלמנט בשורה `i` (לדוגמה `matrix[i][0]`) תגרום ל-TLB Miss עבור הדף של שורה `i`. כל 1023 הגישות הבאות לאלמנטים באותה שורה (`matrix[i][1]` עד `matrix[i][1023]`) יגרמו ל-TLB Hit, מכיוון שהדף של שורה `i` נמצא כעת ב-TLB.\n*   כאשר הלולאה החיצונית עוברת לשורה הבאה (`i+1`), ניגשים לדף חדש. גישה זו תגרום ל-TLB Miss.\n*   מכיוון שה-TLB יכול להכיל רק 16 כניסות, ולאחר 16 גישות לדפים שונים, הכניסה ה-17 תגרום ל-TLB Miss ותחליף את הכניסה שהייתה בשימוש הכי פחות לאחרונה (LRU).\n*   בסך הכל, יש 1024 דפים ייחודיים שהמטריצה מתפרסת עליהם. כל גישה *ראשונה* לכל אחד מ-1024 הדפים הללו תגרום ל-TLB Miss.\n\n**תשובה: 1024 TLB Misses.**\n\n**1.5. מהו המספר הכולל של גישות לזיכרון הראשי (RAM) עבור נתוני המטריצה ועבור טבלאות הדפים?**\n*   סה\"כ גישות לכתיבת נתונים למטריצה: `1024 * 1024 = 1,048,576` פעולות כתיבה.\n\n*   **ניתוח גישות לזיכרון הראשי (RAM) לכל פעולת כתיבה למטריצה:**\n    1.  **TLB Hit**: אם הכניסה לדף נמצאת ב-TLB, מתבצעת גישה אחת ל-RAM (כתיבת הנתון).\n    2.  **TLB Miss**: אם הכניסה לדף אינה ב-TLB, מתבצעת סריקת טבלת הדפים (Page Table Walk).\n        *   **Page Table Walk**: 4 רמות של טבלת דפים, כל רמה דורשת גישה ל-RAM. סך הכל 4 גישות ל-RAM.\n        *   **אם ה-PTE תקף (Present Bit = 1)**: ה-PTE נטען ל-TLB. לאחר מכן, מתבצעת גישה אחת ל-RAM (כתיבת הנתון). סך הכל 4 (PT) + 1 (נתון) = 5 גישות ל-RAM.\n        *   **אם ה-PTE אינו תקף (Present Bit = 0) - Page Fault**: \n            *   מתבצעות 4 גישות ל-RAM עבור סריקת טבלת הדפים.\n            *   מערכת ההפעלה מטפלת ב-Page Fault: בוחרת מסגרת פיזית (ייתכן שכוללת החלפת דף קיים לדיסק אם הוא מלוכלך - *פעולות דיסק אינן נספרות כאן*), טוענת את הדף החדש מהדיסק.\n            *   לאחר טעינת הדף, ה-PTE בטבלת הדפים מתעדכן (Present Bit = 1, PFN, Dirty, Accessed). זה דורש גישת כתיבה אחת ל-RAM.\n            *   ה-PTE החדש נטען ל-TLB.\n            *   הפקודה המקורית מבוצעת מחדש: כעת ה-TLB יכיל את ה-PTE (TLB Hit), ומתבצעת גישה אחת ל-RAM (כתיבת הנתון).\n            *   סה\"כ עבור מקרה Page Fault (ללא דיסק): 4 (PT) + 1 (עדכון PTE) + 1 (כתיבת נתון) = 6 גישות ל-RAM.\n\n*   **חישוב כולל:**\n    *   **מספר TLB Misses שהם גם Page Faults**: 1024 (כפי שחושב בסעיף 1.3 ו-1.4). עבור כל אחד מהם: 6 גישות ל-RAM.\n        *   סה\"כ גישות מ-Page Faults: `1024 * 6 = 6144` גישות ל-RAM.\n    *   **מספר TLB Hits**: סה\"כ גישות לנתונים פחות מספר ה-TLB Misses = `1,048,576 - 1024 = 1,047,552`.\n        *   עבור כל TLB Hit: גישה אחת ל-RAM (כתיבת הנתון).\n        *   סה\"כ גישות מ-TLB Hits: `1,047,552 * 1 = 1,047,552` גישות ל-RAM.\n\n*   **סה\"כ גישות ל-RAM**: `6144 (מ-Page Faults) + 1,047,552 (מ-TLB Hits) = 1,053,696` גישות ל-RAM.\n\n**תשובה: 1,053,696 גישות לזיכרון הראשי (RAM).**"}, "difficulty_estimation": "Hard", "_source_file": "0550__Virtual_Memory__Open__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:38:07", "_subject": "Virtualization"}, {"id": 101, "type": "Open", "topic": ["Virtual Memory", "Paging", "Memory Management", "Page Table Structures", "Large Address Spaces"], "content": {"text": "נתונה מערכת הפעלה הפועלת על ארכיטקטורת 64 ביט, עם כתובות וירטואליות בגודל 64 ביט וגודל דף של 4KB. ידוע כי תהליכים רבים במערכת משתמשים במרחבי כתובות וירטואליים דלילים (sparse), כלומר, הם מנצלים רק חלק קטן מהמרחב העצום של 2^64 בתים, וזאת באופן לא רציף, עם פערים גדולים בין אזורים ממופים.\nתאר/י מבנה טבלאות דפים אלטרנטיבי לטבלאות דפים מרובות רמות (multi-level page tables) קונבנציונליות, שיאפשר ניהול יעיל יותר של מרחבי כתובות וירטואליים דלילים וגדולים במיוחד.\nעליך לפרט את המבנה המוצע, להסביר כיצד הוא עובד (תרגום כתובות), ולנתח את יתרונותיו וחסרונותיו ביחס לטבלאות דפים מרובות רמות במקרה הנתון. התייחס/י לשיקולים כגון צריכת זיכרון, ביצועי תרגום כתובות (כולל השפעה על ה-TLB), ומורכבות הטיפול ב-page faults.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון המוצע מתאר מבנה Hashed Page Table (HPT) כחלופה לטבלאות דפים מרובות רמות:\n\n**מבנה מוצע: Hashed Page Table (HPT) – טבלת דפים מבוססת גיבוב**\nבמקום טבלאות היררכיות, HPT משתמשת בטבלת גיבוב (Hash Table) אחת גדולה. כל כניסה בטבלת הגיבוב מצביעה על רשימה מקושרת של רשומות טבלת דפים (PTEs) שערך ה-Virtual Page Number (VPN) שלהן יצר את אותו ערך גיבוב. כל PTE ברשימה מכילה את ה-VPN המלא (כדי להתמודד עם התנגשויות), את ה-PFN (Physical Frame Number), וביטי בקרה (כגון valid, dirty, accessed).\n\n**תהליך תרגום כתובת:**\n1.  **חלוקת הכתובת הוירטואלית**: הכתובת הוירטואלית (64 ביט) מחולקת ל-VPN (64-12 = 52 ביט, עבור גודל דף 4KB) ולהיסט (12 ביט).\n2.  **חישוב גיבוב**: מחושבת פונקציית גיבוב על ה-VPN. תוצאת הגיבוב משמשת כאינדקס לכניסה בטבלת הגיבוב הראשית.\n3.  **גישה לטבלת הגיבוב**: ניגשים לכניסה המתאימה בטבלת הגיבוב.\n4.  **סריקת רשימה מקושרת**: עוברים על הרשימה המקושרת של ה-PTEs המחוברת לכניסה זו. עבור כל PTE ברשימה, משווים את ה-VPN המלא השמור בו ל-VPN המקורי של הכתובת הוירטואלית.\n5.  **התאמה נמצאה**: אם נמצאה התאמה, מחלצים את ה-PFN מה-PTE ומרכיבים את הכתובת הפיזית על ידי שילוב ה-PFN עם ההיסט המקורי.\n6.  **Page Fault**: אם לא נמצאה התאמה לאחר סריקת כל הרשימה המקושרת, מתרחשת Page Fault.\n\n**יתרונות עבור מרחבי כתובות דלילים וגדולים:**\n*   **יעילות בזיכרון**: המבנה הזה דורש זיכרון רק עבור הדפים שממופים בפועל. אין צורך להקצות טבלאות דפים ברמות ביניים (כמו בטבלאות מרובות רמות) עבור אזורים ריקים או לא ממופים במרחב הכתובות הוירטואלי העצום (2^64 בתים). זה חוסך כמויות אדירות של זיכרון עבור תהליכים עם מרחבי כתובות דלילים, שהם המקרה הנפוץ במערכות 64 ביט.\n*   **סקלאביליות**: מתאים היטב לטיפול בכתובות וירטואליות רחבות מאוד (כמו 64 ביט), שכן גודל טבלת הדפים אינו תלוי ישירות בגודל מרחב הכתובות הוירטואלי, אלא במספר הדפים הממופים בפועל ובגודל טבלת הגיבוב.\n\n**חסרונות:**\n*   **ביצועי תרגום כתובות**: במקרה של התנגשויות (hash collisions), תרגום כתובת דורש סריקה של רשימה מקושרת, מה שמוסיף זמן השהיה משמעותי בהשוואה לגישה ישירה בטבלאות מרובות רמות. הדבר פוגע בביצועים כאשר ה-TLB מחמיץ (TLB miss), שכן הגישה לזיכרון עבור טבלת הדפים עלולה להיות יקרה יותר.\n*   **השפעה על ה-TLB**: ה-TLB הופך להיות קריטי אף יותר. כיוון שגישה ל-HPT איטית יותר, שיעור פגיעות גבוה ב-TLB חיוני לשמירה על ביצועים טובים. אם ה-TLB מחמיץ, העלות של תרגום הכתובת דרך ה-HPT גבוהה יותר.\n*   **מורכבות**: ניהול טבלת גיבוב (בחירת פונקציית גיבוב טובה, טיפול יעיל בהתנגשויות, שינוי גודל הטבלה דינמית) מורכב יותר ליישום במערכת ההפעלה.\n*   **locality cache**: סריקת רשימות מקושרות עלולה לפגוע ב-locality cache, בניגוד לטבלאות דפים מרובות רמות שבהן הגישות לרמות השונות הן לרוב רציפות בזיכרון.\n*   **טיפול ב-page faults**: מורכבות הטיפול ב-page faults עולה מעט, שכן יש למצוא מקום בשרשרת הגיבוב המתאימה ולהוסיף PTE חדש, או להסיר PTE קיים במקרה של החלפת דף.\n\n**השוואה לטבלאות דפים מרובות רמות במקרה הנתון:**\n*   **טבלאות מרובות רמות**: עבור מרחב כתובות וירטואלי של 64 ביט ודף בגודל 4KB, נדרשים 52 ביטים ל-VPN. אם כל רמה ממפה 9-10 ביטים, ידרשו 5-6 רמות של טבלאות דפים. זהו מבנה בזבזני מאוד בזיכרון עבור מרחבי כתובות דלילים או עצומים, שכן הוא דורש הקצאת טבלאות ביניים רבות גם אם רובן ריקות. עם זאת, כאשר ה-TLB מחמיץ, הגישה לטבלת הדפים היא לרוב מהירה יותר ובעלת locality cache טובה יותר.\n*   **HPT**: חוסכת זיכרון משמעותית עבור מרחבי כתובות דלילים ועצומים על חשבון מורכבות וזמן תרגום ארוך יותר במקרה של TLB miss (בגלל התנגשויות וסריקת רשימות). היא יעילה יותר בזיכרון וסקלאבילית יותר למרחבי כתובות ענקיים, אך דורשת TLB גדול ויעיל מאוד כדי למזער את עלויות התרגום."}, "difficulty_estimation": "Hard", "_source_file": "0552__Virtual_Memory__Open__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:39:27", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Virtual Memory", "Paging", "Cache", "Locality of Reference"], "content": {"text": "נתונה המערכת הבאה המשתמשת בזיכרון וירטואלי. גודל דף זיכרון הוא 4KB. נתון קטע קוד בשפת C המאתחל מטריצה דו-ממדית בגודל גדול מספיק כך שתחרוג מגודל דף בודד. \n\nאיזה מקטע קוד מבין השניים הבאים צפוי להיות בעל ביצועים טובים יותר מבחינת גישה לזיכרון (לדוגמה, פחות Page Faults או יותר Cache Hits), ומדוע?", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define N 1024 // לדוגמה, N*N * sizeof(int) = 1024*1024*4 בתים = 4MB\n\nint matrix[N][N];\n\nvoid initialize_row_major() {\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            matrix[i][j] = i * N + j;\n        }\n    }\n}\n\nvoid initialize_column_major() {\n    for (int j = 0; j < N; j++) { // לולאה חיצונית לעמודות\n        for (int i = 0; i < N; i++) { // לולאה פנימית לשורות\n            matrix[i][j] = i * N + j;\n        }\n    }\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "מקטע הקוד `initialize_row_major` צפוי להיות בעל ביצועים טובים יותר.\n\n**הסבר:**\nבשפת C, מטריצות דו-ממדיות מאוחסנות בזיכרון בצורה רציפה, שורה אחר שורה (row-major order). כלומר, האלמנטים `matrix[i][0]`, `matrix[i][1]`, ..., `matrix[i][N-1]` מאוחסנים בכתובות זיכרון סמוכות פיזית, ולאחר מכן מגיעה השורה הבאה `matrix[i+1][0]`, וכו'.\n\n**ניתוח `initialize_row_major`:**\nלולאות הקינון במקטע זה (הלולאה החיצונית עבור `i` והפנימית עבור `j`) ניגשות לאלמנטים בסדר שבו הם מאוחסנים פיזית בזיכרון: `matrix[0][0]`, `matrix[0][1]`, ..., `matrix[0][N-1]`, ולאחר מכן `matrix[1][0]`, וכן הלאה. גישה זו מנצלת היטב את עקרון המיקום המרחבי (spatial locality). כאשר מערכת ההפעלה טוענת דף זיכרון לזיכרון הפיזי (במקרה של Page Fault), היא טוענת בלוק שלם של נתונים (4KB בדוגמה זו). מכיוון שכל שורה של המטריצה בגודל 1024 * 4 בתים = 4096 בתים (4KB) מתאימה בדיוק לגודל דף זיכרון אחד, הגישה הרציפה לכל אלמנטים השורה תגרום למספר מינימלי של Page Faults (בערך Page Fault אחד לכל שורה). בנוסף, זה מנצל ביעילות את Cache Lines של המעבד, כאשר בלוק של נתונים נטען מהזיכרון הראשי ל-cache בבת אחת.\n\n**ניתוח `initialize_column_major`:**\nבמקטע קוד זה, הלולאה החיצונית היא עבור `j` (עמודות) והפנימית עבור `i` (שורות). המשמעות היא שהגישה לאלמנטים היא בסדר: `matrix[0][0]`, `matrix[1][0]`, ..., `matrix[N-1][0]`, ולאחר מכן `matrix[0][1]`, וכן הלאה. כאשר אנו ניגשים מ-`matrix[i][j]` ל-`matrix[i+1][j]`, אנו למעשה מדלגים על `N-1` אלמנטים (כל השאר של שורה `i` ועוד `j` אלמנטים של שורה `i+1`) בזיכרון הפיזי. המרחק בין `matrix[i][j]` ל-`matrix[i+1][j]` הוא `N * sizeof(int)` בתים, שזה בדוגמה שלנו 4096 בתים (4KB), כלומר בדיוק גודל של דף זיכרון. לכן, כל גישה לאלמנט הבא באותה עמודה (`matrix[i+1][j]`) עלולה לגרום ל-Page Fault חדש, מכיוון שהאלמנט נמצא בדף זיכרון שונה לגמרי. זה מוביל לניצול גרוע של המיקום המרחבי, למספר רב מאוד של Page Faults (בערך Page Fault אחד לכל אלמנט, כלומר N*N Page Faults במקרה הגרוע), ולביצועים ירודים משמעותית."}, "difficulty_estimation": "Easy", "_source_file": "0553__Virtual_Memory__CodeAnalysis__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:39:47", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Virtual Memory", "Paging", "Page Faults"], "content": {"text": "נתונה תוכנית C הבאה. הניחו שגודל הזיכרון הפיזי (RAM) במערכת קטן בהרבה מגודל המערך large_array, וכי גודל דף זיכרון הוא 4KB (קילו-בייט).\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n\n#define GB (1024 * 1024 * 1024LL) // Using LL for long long literal\n#define ARRAY_SIZE (2 * GB) // 2GB array\n\nint main() {\n    char *large_array = (char *)malloc(ARRAY_SIZE);\n    if (large_array == NULL) {\n        perror(\"malloc failed\");\n        return 1;\n    }\n\n    // Access the array sequentially\n    for (long long i = 0; i < ARRAY_SIZE; i++) {\n        large_array[i] = (char)(i % 256);\n    }\n\n    printf(\"Array access complete.\\n\");\n    free(large_array);\n    return 0;\n}\n```\n\n**שאלה:**\nכמה page faults (כשלים בדף) צפויים להתרחש בקירוב במהלך ביצוע הלולאה בתוכנית זו? הסבירו בקצרה מדוע.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "**כמות Page Faults צפויה:** כ-524,288 page faults.\n\n**הסבר:**\nהתוכנית מקצה זיכרון וירטואלי בגודל 2GB עבור המערך `large_array`. חשוב לציין שהקצאת זיכרון וירטואלי באמצעות `malloc` אינה גורמת ל-page faults באופן מיידי; ה-page faults מתרחשים כאשר התוכנית מנסה לגשת לראשונה לכתובת וירטואלית הנמצאת בדף זיכרון שאינו טעון כרגע בזיכרון הפיזי (RAM).\n\nבלולאה, התוכנית עוברת על כל בייט במערך באופן סדרתי, החל מהכתובת הראשונה ועד האחרונה. מכיוון שגודל המערך (2GB) גדול בהרבה מהזיכרון הפיזי הזמין, ומכיוון שהגישה היא לכל בייט בסדר עוקב, כל פעם שהתוכנית תגיע לבייט שנמצא בדף זיכרון וירטואלי שטרם נטען לזיכרון הפיזי, יתרחש page fault.\n\nמספר הדפים הכולל של המערך הוא:\n`גודל המערך / גודל דף זיכרון = 2GB / 4KB`\n`2 * 1024 * 1024 * 1024 בייטים / 4096 בייטים לדף = 524,288 דפים.`\n\nמכיוון שהגישה היא סדרתית, כל דף במערך ייגש לראשונה בדיוק פעם אחת (בהנחה שאין דפים שנטענים מראש או נפלטים ונטענים מחדש באופן מיידי לפני הגישה הבאה לאותו דף). לכן, צפוי שיתרחשו כ-524,288 page faults. לאחר שדף נטען לזיכרון הפיזי, גישות עתידיות לאותו דף לא יגרמו ל-page fault, עד שאותו דף ייפלט מהזיכרון הפיזי (אם יתרחשו החלפות דפים), אך מאחר והגישה היא סדרתית ועל מערך גדול מאד, כל דף נחשב כגישה ראשונה לדף חדש."}, "difficulty_estimation": "Easy", "_source_file": "0554__Virtual_Memory__CodeAnalysis__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:40:04", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Virtual Memory"], "content": {"text": "נתונה תוכנית C הבאה:\n```c\n#include <stdio.h>\n#include <stdlib.h>\n\n#define ARRAY_SIZE (1024 * 1024 * 100) // 100 MB of integers\n\nint main() {\n    int* large_array = (int*)malloc(ARRAY_SIZE * sizeof(int));\n\n    if (large_array == NULL) {\n        perror(\"malloc failed\");\n        return 1;\n    }\n\n    printf(\"Memory allocated (virtually).\\n\");\n\n    // Access various elements in the array\n    large_array[0] = 10;\n    large_array[ARRAY_SIZE / 2] = 20;\n    large_array[ARRAY_SIZE - 1] = 30;\n\n    printf(\"Elements accessed.\\n\");\n\n    free(large_array);\n    return 0;\n}\n```\nבהתבסס על הקוד לעיל, תאר בקצרה מה קורה במונחים של זיכרון וירטואלי ופיזי כאשר התוכנית מופעלת. התייחס במיוחד לשלבי הקצאת הזיכרון (malloc) וגישת הזיכרון (השמת ערכים לאיברים במערך).", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define ARRAY_SIZE (1024 * 1024 * 100) // 100 MB of integers\n\nint main() {\n    int* large_array = (int*)malloc(ARRAY_SIZE * sizeof(int));\n\n    if (large_array == NULL) {\n        perror(\"malloc failed\");\n        return 1;\n    }\n\n    printf(\"Memory allocated (virtually).\\n\");\n\n    // Access various elements in the array\n    large_array[0] = 10;\n    large_array[ARRAY_SIZE / 2] = 20;\n    large_array[ARRAY_SIZE - 1] = 30;\n\n    printf(\"Elements accessed.\\n\");\n\n    free(large_array);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "הפתרון:\nכאשר התוכנית מופעלת:\n1.  **קריאה ל-`malloc`**: הפונקציה `malloc` מקצה בלוק של זיכרון וירטואלי בגודל המבוקש (100MB * sizeof(int)) למרחב הכתובות של התהליך. בשלב זה, מערכת ההפעלה אינה מקצה בהכרח זיכרון פיזי בפועל. היא פשוט מעדכנת את טבלת הדפים של התהליך כך שהכתובות הווירטואליות הללו מסומנות כזמינות, אך ללא מיפוי לכתובות פיזיות. זהו תהליך \"הקצאה עצלה\" (lazy allocation).\n2.  **גישה לאיברים במערך (`large_array[0] = 10;` וכו')**: כאשר התוכנית ניגשת לראשונה לכתובת וירטואלית בתוך הבלוק שהוקצה על ידי `malloc` (לדוגמה, `large_array[0]`), נוצר \"כשל דף\" (page fault). מערכת ההפעלה מזהה שכשל דף התרחש עבור הכתובת הווירטואלית הזו.\n    *   בתגובה לכשל הדף, מערכת ההפעלה מקצה דף זיכרון פיזי (בדרך כלל 4KB) וממפה אותו לכתובת הווירטואלית של הדף הרלוונטי בטבלת הדפים של התהליך.\n    *   הפקודה `large_array[0] = 10;` תגרום לכשל דף עבור הדף הראשון של המערך (אם אינו כבר בזיכרון הפיזי).\n    *   הפקודה `large_array[ARRAY_SIZE / 2] = 20;` תגרום לכשל דף עבור הדף המכיל את אמצע המערך (אם דף זה לא נגיש כבר).\n    *   הפקודה `large_array[ARRAY_SIZE - 1] = 30;` תגרום לכשל דף עבור הדף האחרון של המערך (אם דף זה לא נגיש כבר).\n    *   חשוב לציין שרק הדפים המכילים את הכתובות אליהן ניגשים בפועל יוקצו בזיכרון פיזי. שאר הדפים ב-100MB שהוקצו וירטואלית יישארו לא ממופים לזיכרון פיזי עד שיגשו אליהם.\n3.  **קריאה ל-`free`**: הפונקציה `free` משחררת את הזיכרון הווירטואלי שהוקצה. מערכת ההפעלה מסירה את המיפויים מדפי הזיכרון הפיזיים שהיו בשימוש ומסמנת את הכתובות הווירטואליות כלא זמינות עבור התהליך. הזיכרון הפיזי שהיה בשימוש חוזר למאגר הזיכרון הפנוי של מערכת ההפעלה."}, "difficulty_estimation": "Easy", "_source_file": "0555__Virtual_Memory__CodeAnalysis__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:40:20", "_subject": "Virtualization"}, {"id": 100, "type": "CodeAnalysis", "topic": ["Virtual Memory", "Demand Paging", "Page Faults"], "content": {"text": "נתונה פיסת הקוד הבאה בשפת C. המערכת משתמשת בזיכרון וירטואלי עם דפדוף לפי דרישה (demand paging).\nתאר מה מתרחש ברמת הזיכרון הפיזי (RAM) כאשר השורה `arr[0] = 10;` מבוצעת בפעם הראשונה, בהנחה שזו הגישה הראשונה לכל חלק של המערך `arr`.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\nint main() {\n    int *arr = (int *)malloc(1024 * 1024 * sizeof(int)); // Allocate 4MB\n    if (arr == NULL) {\n        perror(\"malloc failed\");\n        return 1;\n    }\n\n    printf(\"Array allocated at virtual address: %p\\n\", (void*)arr);\n\n    // Access an element for the first time\n    arr[0] = 10; // Line of interest\n    printf(\"Value at arr[0]: %d\\n\", arr[0]);\n\n    free(arr);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כאשר מתבצעת הקריאה ל-`malloc`, מערכת ההפעלה מקצה בלוק רציף של זיכרון *וירטואלי* עבור התוכנית. עם זאת, זיכרון *פיזי* אינו מוקצה בדרך כלל בשלב זה במערכות המשתמשות בדפדוף לפי דרישה. במקום זאת, מערכת ההפעלה רק מעדכנת את טבלת הדפים (page table) כדי לסמן את הדפים הווירטואליים הללו כתקפים אך עדיין לא נוכחים בזיכרון הפיזי.\nכאשר השורה `arr[0] = 10;` מבוצעת בפעם הראשונה, המעבד מנסה לגשת לכתובת הווירטואלית המתאימה ל-`arr[0]`. יחידת ניהול הזיכרון (MMU) מתייעצת עם טבלת הדפים. מכיוון שהדף המכיל את `arr[0]` מסומן כלא נוכח (או לא חוקי), מתרחשת 'תקלת דף' (page fault). מטפל תקלת הדף של מערכת ההפעלה נכנס לפעולה:\n1. הוא מוצא מסגרת דף פיזית פנויה (או מפנה דף קיים אם הזיכרון מלא).\n2. הוא ממפה את הדף הווירטואלי המכיל את `arr[0]` למסגרת הדף הפיזית שהוקצתה זה עתה.\n3. הוא מעדכן את הרשומה בטבלת הדפים עבור הדף הווירטואלי הזה כדי לשקף את הכתובת הפיזית החדשה שלו ולסמן אותו כנוכח.\n4. פקודת `arr[0] = 10;` מבוצעת מחדש. הפעם, ה-MMU מוצא את המיפוי התקף, והערך `10` נכתב בהצלחה למיקום הזיכרון הפיזי.\nתהליך זה מבטיח שזיכרון פיזי נצרך רק כאשר הוא נחוץ בפועל, ובכך מייעל את השימוש בזיכרון."}, "difficulty_estimation": "Easy", "_source_file": "0556__Virtual_Memory__CodeAnalysis__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:40:35", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Virtual Memory", "Page Faults", "Locality of Reference"], "content": {"text": "נתון קטע הקוד הבא בשפת C. הקוד מבצע שתי גישות שונות למערך גדול המוקצה דינמית. הניחו כי גודל דף זיכרון הוא 4KB (4096 בתים) וכי זיכרון המטמון (cache) קטן בהרבה מגודל המערך, כך שאין לו השפעה משמעותית על מספר ה-page faults, וכי המערך מאותחל לאפס ולא נטען לזיכרון פיזי לפני הגישות.\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n\n#define ARRAY_SIZE (1024 * 1024 * 10) // 10MB array (10 * 1024 * 1024 bytes)\n#define PAGE_SIZE 4096              // Standard page size (4KB)\n\nint main() {\n    int* arr = (int*)malloc(ARRAY_SIZE * sizeof(int));\n    if (arr == NULL) {\n        perror(\"malloc failed\");\n        return 1;\n    }\n\n    // Access 1: Sequential access\n    printf(\"Accessing array sequentially...\\n\");\n    for (int i = 0; i < ARRAY_SIZE; i++) {\n        arr[i] = i; // Write operation\n    }\n\n    // Access 2: Strided access, jumping across pages\n    printf(\"Accessing array with large stride...\\n\");\n    for (int i = 0; i < ARRAY_SIZE; i += (PAGE_SIZE / sizeof(int))) {\n        arr[i] = i; // Write operation\n    }\n\n    free(arr);\n    return 0;\n}\n```\n\nבהתבסס על קטע הקוד וההנחות:\nא. תארו בקצרה מהו 'page fault' בהקשר של זיכרון וירטואלי.\nב. הסבירו איזה מבין שני הלולאות (Access 1 או Access 2) צפויה לייצר יותר 'page faults', ומדוע. נמקו את תשובתכם תוך התייחסות לעקרון 'locality of reference'.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define ARRAY_SIZE (1024 * 1024 * 10) // 10MB array (10 * 1024 * 1024 bytes)\n#define PAGE_SIZE 4096              // Standard page size (4KB)\n\nint main() {\n    int* arr = (int*)malloc(ARRAY_SIZE * sizeof(int));\n    if (arr == NULL) {\n        perror(\"malloc failed\");\n        return 1;\n    }\n\n    // Access 1: Sequential access\n    printf(\"Accessing array sequentially...\\n\");\n    for (int i = 0; i < ARRAY_SIZE; i++) {\n        arr[i] = i; // Write operation\n    }\n\n    // Access 2: Strided access, jumping across pages\n    printf(\"Accessing array with large stride...\\n\");\n    for (int i = 0; i < ARRAY_SIZE; i += (PAGE_SIZE / sizeof(int))) {\n        arr[i] = i; // Write operation\n    }\n\n    free(arr);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. **מהו 'page fault'?**\n'Page fault' (כשל דף) מתרחש כאשר תוכנית מנסה לגשת לכתובת זיכרון וירטואלית שאינה נמצאת כרגע בזיכרון הפיזי (RAM), אלא מאוחסנת בזיכרון משני (לרוב דיסק). כאשר מתרחש page fault, מערכת ההפעלה נכנסת לפעולה: היא עוצרת את ביצוע התוכנית, מאתרת את הדף הנדרש בזיכרון המשני, טוענת אותו לזיכרון פיזי פנוי (או מפנה דף קיים אם אין מקום), מעדכנת את טבלת הדפים, ומחדשת את ביצוע התוכנית מהנקודה שבה הפסיקה. זהו מנגנון חיוני בזיכרון וירטואלי המאפשר לתוכניות להשתמש בזיכרון גדול יותר ממה שזמין פיזית.\n\nב. **השוואת page faults עבור Access 1 לעומת Access 2**\nהלולאה `Access 2` (גישה עם קפיצות גדולות) צפויה לייצר באופן משמעותי יותר page faults מאשר הלולאה `Access 1` (גישה רציפה).\n\n**הסבר:**\n*   **Access 1 (גישה רציפה):** בלולאה זו, הגישה למערך היא סדרתית (arr[0], arr[1], arr[2]...). נניח שכל איבר `int` הוא בגודל 4 בתים. גודל דף הוא 4096 בתים, כלומר דף יכול להכיל 4096 / 4 = 1024 איברי `int`. כאשר מתרחשת גישה לכתובת וירטואלית כלשהי בתוך דף, ודף זה אינו נמצא בזיכרון הפיזי, יתרחש page fault. מערכת ההפעלה תטען את הדף כולו לזיכרון הפיזי. מכיוון שהגישות הבאות (ל-arr[i+1], arr[i+2] וכו') הן לכתובות סמוכות, סביר להניח שהן ייפלו בתוך אותו דף שזה עתה נטען. זהו ביטוי לעקרון ה**לוקליות המרחבית (Spatial Locality)** – אם ניגשנו לפריט זיכרון מסוים, סביר להניח שניגש בקרוב לפריטים סמוכים אליו. לכן, לאחר ה-page fault הראשון לדף מסוים, רוב הגישות הבאות לאותו דף לא יגרמו ל-page fault נוסף, עד שנעבור לדף הבא במערך. מספר ה-page faults יהיה נמוך יחסית, בקירוב שווה למספר הדפים הכולל שהמערך תופס (ARRAY_SIZE * sizeof(int) / PAGE_SIZE).\n\n*   **Access 2 (גישה עם קפיצות גדולות):** בלולאה זו, הגישה למערך היא בקפיצות גדולות (arr[0], arr[PAGE_SIZE/sizeof(int)], arr[2*PAGE_SIZE/sizeof(int)]...). מכיוון ש-`PAGE_SIZE / sizeof(int)` שווה ל-1024, כל גישה כזו קופצת למעשה לתחילתו של דף זיכרון וירטואלי חדש. כלומר, כמעט כל גישה למערך תהיה לכתובת שנמצאת בדף שונה מזה של הגישה הקודמת. גם אם הדף הקודם נטען, הגישה הבאה היא לדף אחר לגמרי. זה מפר באופן מובהק את עקרון הלוקליות המרחבית, שכן הגישות אינן סמוכות זו לזו בזיכרון הפיזי. כתוצאה מכך, סביר שכל גישה בלולאה זו תגרום ל-page fault, שכן כל גישה מנסה לגשת לכתובת בדף שונה, שכנראה אינו נמצא בזיכרון הפיזי. מספר ה-page faults יהיה גבוה בהרבה, בקירוב שווה למספר האיטרציות בלולאה (ARRAY_SIZE / (PAGE_SIZE / sizeof(int))), שהוא למעשה מספר הדפים הכולל במערך.\n\nלסיכום, `Access 1` מנצלת היטב את הלוקליות המרחבית ומייצרת מעט page faults יחסית, בעוד `Access 2` מפרה אותה וגורמת למספר רב של page faults, מה שיוביל לביצועים איטיים יותר עקב הגישה התכופה לדיסק."}, "difficulty_estimation": "Easy", "_source_file": "0557__Virtual_Memory__CodeAnalysis__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:40:59", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Virtual Memory", "Memory Management", "Segmentation Faults", "Pointers"], "content": {"text": "נתונה פיסת קוד C הבאה. בהתחשב בידע שלך על זיכרון וירטואלי במערכות הפעלה, הסבר מה יקרה כאשר קוד זה יבוצע. התייחס להשפעה על התהליך ולמושגים רלוונטיים של זיכרון וירטואלי.", "code_snippet": "#include <stdio.h>\n\nint main() {\n    int *ptr; // Pointer declared but not initialized\n    *ptr = 10; // Attempting to dereference an uninitialized pointer\n    printf(\"Value: %d\\n\", *ptr);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הקוד מנסה לכתוב למיקום זיכרון שאינו מוגדר עבור המצביע `ptr`. כאשר המצביע `ptr` מוכרז, הוא מכיל ערך אקראי (garbage value), מכיוון שלא אותחל לכתובת חוקית. הניסיון לבצע `*ptr = 10;` יגרום למערכת ההפעלה לנסות לגשת לכתובת זיכרון וירטואלית אקראית זו. סביר להניח שכתובת זו אינה ממופה למסגרת עמודים פיזית (physical page frame) בטבלת העמודים של התהליך, או שהיא נמצאת מחוץ לתחום הזיכרון המוקצה לתהליך. כתוצאה מכך, יתרחש 'Page Fault' (כשל עמוד) חומרה. מערכת ההפעלה תזהה שזוהי גישה בלתי חוקית לזיכרון (ולא רק עמוד שצריך להיטען מהדיסק), ותשלח אות `SIGSEGV` (Segmentation Violation) לתהליך. קבלת אות זה תוביל לסיום בלתי צפוי של התהליך (crash) עם הודעת 'Segmentation fault'."}, "difficulty_estimation": "Easy", "_source_file": "0558__Virtual_Memory__CodeAnalysis__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:41:09", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Virtual Memory"], "content": {"text": "נתונה תוכנית C קצרה המקצה מערך של מספרים שלמים. נניח שגודל שלם (int) הוא 4 בתים, וגודל עמוד (page size) במערכת ההפעלה הוא 4KB (כלומר 4096 בתים). המערך ממוקם בכתובת וירטואלית התחלתית 0x10000000. בהתבסס על קוד ה-C המצורף, מהי הכתובת הווירטואלית המדויקת של האיבר arr[250] במערך, ועל איזה מספר עמוד וירטואלי (Virtual Page Number) הוא נופל?", "code_snippet": "#include <stdio.h>\n\nint main() {\n    int arr[1000]; // נניח שהמערך מתחיל בכתובת 0x10000000\n    \n    // פעולות כלשהן על arr...\n    \n    return 0;\n}", "options": null}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "גודל שלם (int) הוא 4 בתים. לכן, האיבר arr[250] נמצא בקיזוז של 250 * 4 = 1000 בתים מהכתובת ההתחלתית של המערך.\n\nהכתובת הווירטואלית של arr[250] היא: 0x10000000 (כתובת התחלתית) + 1000 (קיזוז) = 0x100003E8.\n\nגודל עמוד הוא 4KB, שהם 4096 בתים. המשמעות היא שה-12 ביטים הנמוכים ביותר של הכתובת הווירטואלית (bits 0-11) מייצגים את הקיזוז בתוך העמוד (page offset), והביטים הגבוהים יותר מייצגים את מספר העמוד הווירטואלי (Virtual Page Number - VPN).\n\nכדי למצוא את מספר העמוד הווירטואלי, נחלק את הכתובת הווירטואלית בגודל העמוד:\n0x100003E8 / 4096 = 0x100003E8 / 0x1000.\n\nהכתובת 0x100003E8 נופלת בעמוד שמתחיל בכתובת 0x10000000. מספר העמוד הווירטואלי הוא 0x10000000 / 0x1000 = 0x10000.\nהקיזוז בתוך העמוד הוא 0x3E8 (1000 בתים).\n\nלכן, הכתובת הווירטואלית של arr[250] היא 0x100003E8 והיא נופלת על עמוד וירטואלי מספר 0x10000."}, "difficulty_estimation": "Easy", "_source_file": "0559__Virtual_Memory__CodeAnalysis__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:41:22", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Virtual Memory"], "content": {"text": "נתונה תוכנית C הבאה. נתחו את התוכנית וענו על השאלות הבאות בהתייחס למערכת הפעלה המשתמשת בזיכרון וירטואלי, בהנחה שמערכת ההפעלה משתמשת בדפים בגודל 4KB:\n\n1.  האם הקריאה ל-`malloc` צפויה להיכשל במערכת עם פחות מ-4GB של זיכרון פיזי (RAM)? הסבירו.\n2.  כמה זיכרון פיזי (Resident Set Size - RSS) התוכנית צפויה לצרוך עבור המערך לאחר השורה `large_array[0] = 'A';`? הסבירו.\n3.  כמה זיכרון פיזי (RSS) התוכנית צפויה לצרוך עבור המערך לאחר השורה `large_array[4 * GIGABYTE - 1] = 'Z';`? הסבירו.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h> // For sleep\n\n#define GIGABYTE (1024ULL * 1024 * 1024)\n\nint main() {\n    printf(\"Allocating 4 GB of memory...\\n\");\n    char *large_array = (char *)malloc(4 * GIGABYTE);\n\n    if (large_array == NULL) {\n        perror(\"Failed to allocate memory\");\n        return 1;\n    }\n\n    printf(\"Memory allocated. Writing to the first byte...\\n\");\n    large_array[0] = 'A'; // Accessing the first page\n\n    printf(\"Writing to the last byte...\\n\");\n    large_array[4 * GIGABYTE - 1] = 'Z'; // Accessing the last page\n\n    printf(\"Sleeping for 10 seconds. Check process memory usage.\\n\");\n    sleep(10); // Allows checking memory usage in a separate terminal\n\n    printf(\"Freeing memory...\\n\");\n    free(large_array);\n\n    printf(\"Program finished.\\n\");\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  **כשלון `malloc`**: לא, הקריאה ל-`malloc` לא צפויה להיכשל במערכת עם פחות מ-4GB זיכרון פיזי. `malloc` מקצה מרחב כתובות וירטואלי (virtual address space) ולא זיכרון פיזי מיידית. כל עוד יש מספיק מרחב כתובות וירטואלי זמין (בדרך כלל גדול בהרבה מה-RAM במערכות 64 ביט), ההקצאה תצליח. זיכרון פיזי מוקצה ונכנס לשימוש רק כאשר התוכנית ניגשת בפועל לדפים הווירטואליים הללו (מנגנון Demand Paging).\n\n2.  **RSS לאחר `large_array[0] = 'A';`**: לאחר שורה זו, התוכנית צפויה לצרוך דף פיזי אחד (4KB) עבור המערך. הגישה ל-`large_array[0]` גורמת ל-Page Fault עבור הדף הווירטואלי הראשון של המערך. מערכת ההפעלה תאלץ להקצות דף פיזי ולמפות אותו לדף הווירטואלי הזה. שאר 4GB הווירטואליים עדיין אינם ממופים לזיכרון פיזי.\n\n3.  **RSS לאחר `large_array[4 * GIGABYTE - 1] = 'Z';`**: לאחר שורה זו, התוכנית צפויה לצרוך שני דפים פיזיים (8KB) עבור המערך. הגישה ל-`large_array[4 * GIGABYTE - 1]` גורמת ל-Page Fault עבור הדף הווירטואלי האחרון של המערך (שכמעט בוודאות נמצא בדף וירטואלי שונה מהדף הראשון). מערכת ההפעלה תקצה דף פיזי נוסף ותמפה אותו לדף הווירטואלי הזה. למרות שכל 4GB הווירטואליים של המערך שמורים, רק הדפים שאליהם ניגשו בפועל יקבלו הקצאה של זיכרון פיזי."}, "difficulty_estimation": "Easy", "_source_file": "0560__Virtual_Memory__CodeAnalysis__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:41:44", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Virtual Memory", "Paging", "Copy-on-Write", "Processes"], "content": {"text": "נתונה תוכנית C המשתמשת במערך גלובלי גדול. התוכנית מאתחלת חלק מהמערך, ואז מבצעת fork(). תהליך האב ותהליך הבן משנים כל אחד חלק אחר של המערך. יש להניח שמערכת ההפעלה משתמשת בזיכרון וירטואלי עם מנגנון Copy-on-Write (CoW), וגודל דף הוא 4KB. גודל המערך הכולל הוא 4MB (מערך של int-ים).\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\n#define PAGE_SIZE 4096 // 4KB\n#define ARRAY_SIZE (1024 * 1024) // 4MB total array size (1024 pages of integers)\n\nint global_array[ARRAY_SIZE]; // Array of integers\n\nint main() {\n    // 1. Initialize first part of the array\n    for (int i = 0; i < ARRAY_SIZE / 2; ++i) {\n        global_array[i] = i;\n    }\n\n    pid_t pid = fork();\n\n    if (pid < 0) {\n        perror(\"fork failed\");\n        return 1;\n    } else if (pid == 0) { // Child process\n        // 2. Child modifies the second half of the array\n        for (int i = ARRAY_SIZE / 2; i < ARRAY_SIZE; ++i) {\n            global_array[i] = i * 2;\n        }\n        exit(0);\n    } else { // Parent process\n        // 3. Parent modifies the first half of the array\n        for (int i = 0; i < ARRAY_SIZE / 2; ++i) {\n            global_array[i] = i * 3;\n        }\n        wait(NULL); // Wait for child to finish\n    }\n\n    return 0;\n}\n```\n\nבהתעלם מזיכרון הנדרש לקוד, למחסנית, לערימה או למבני נתונים של מערכת ההפעלה (כגון טבלאות דפים), כמה דפים פיזיים בסך הכל יוקצו על ידי מערכת ההפעלה עבור המערך `global_array` לאחר ששני התהליכים (האב והבן) סיימו את פעולותיהם? הסבירו את חישוביכם לפרטי פרטים.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\n#define PAGE_SIZE 4096 // 4KB\n#define ARRAY_SIZE (1024 * 1024) // 4MB total array size (1024 pages of integers)\n\nint global_array[ARRAY_SIZE]; // Array of integers\n\nint main() {\n    // 1. Initialize first part of the array\n    for (int i = 0; i < ARRAY_SIZE / 2; ++i) {\n        global_array[i] = i;\n    }\n\n    pid_t pid = fork();\n\n    if (pid < 0) {\n        perror(\"fork failed\");\n        return 1;\n    } else if (pid == 0) { // Child process\n        // 2. Child modifies the second half of the array\n        for (int i = ARRAY_SIZE / 2; i < ARRAY_SIZE; ++i) {\n            global_array[i] = i * 2;\n        }\n        exit(0);\n    } else { // Parent process\n        // 3. Parent modifies the first half of the array\n        for (int i = 0; i < ARRAY_SIZE / 2; ++i) {\n            global_array[i] = i * 3;\n        }\n        wait(NULL); // Wait for child to finish\n    }\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסבר:\n1.  **גודל המערך והדפים**:\n    *   גודל המערך `global_array` הוא `1024 * 1024` איברים מסוג `int`. כל `int` הוא 4 בתים.\n    *   גודל המערך הכולל: `4 * 1024 * 1024` בתים = `4MB`.\n    *   גודל דף: `4KB` (`4096` בתים).\n    *   מספר הדפים הכולל הנדרש למערך: `4MB / 4KB` = `1024` דפים.\n\n2.  **שלב 1: אתחול המערך לפני `fork()`**:\n    *   הלולאה הראשונה מאתחלת את החצי הראשון של המערך (`global_array[0]` עד `global_array[ARRAY_SIZE / 2 - 1]`).\n    *   חצי זה של המערך הוא `2MB` (`512` דפים).\n    *   כאשר התהליך כותב לחלק זה של המערך, `512` דפים פיזיים מוקצים עבורו. נניח שדפים אלה מוכנסים לזיכרון פיזי.\n\n3.  **שלב 2: קריאה ל-`fork()` ו-Copy-on-Write (CoW)**:\n    *   כאשר `fork()` נקרא, מרחב הכתובות הוירטואלי של תהליך האב משוכפל עבור תהליך הבן.\n    *   בזכות מנגנון CoW, בתחילה, הן האב והן הבן חולקים את אותם `512` דפים פיזיים שהוקצו בשלב 1. דפים אלה מסומנים כקריאה בלבד (read-only).\n    *   החצי השני של המערך (`global_array[ARRAY_SIZE / 2]` עד `global_array[ARRAY_SIZE - 1]`, שהם `512` דפים נוספים) עדיין לא נגעו בהם. הם ככל הנראה אינם מגובים פיזית או שהם דפי אפס משותפים. במקרה של כתיבה אליהם, יוקצו דפים חדשים בנפרד לכל תהליך.\n\n4.  **שלב 3: שינויים בתהליך הבן**:\n    *   תהליך הבן משנה את החצי השני של המערך (`global_array[ARRAY_SIZE / 2]` עד `global_array[ARRAY_SIZE - 1]`).\n    *   חצי זה של המערך הוא `2MB` (`512` דפים).\n    *   כאשר הבן כותב לדפים אלה לראשונה, מתרחשת תקלת דף (page fault). מכיוון שדפים אלו לא היו בשימוש לפני ה-fork (או היו דפי אפס משותפים), מערכת ההפעלה מקצה `512` דפים פיזיים *חדשים* באופן פרטי עבור הבן.\n\n5.  **שלב 4: שינויים בתהליך האב**:\n    *   תהליך האב משנה את החצי הראשון של המערך (`global_array[0]` עד `global_array[ARRAY_SIZE / 2 - 1]`).\n    *   חצי זה של המערך הוא `2MB` (`512` דפים).\n    *   דפים אלה נגעו בהם בשלב 1, ונחלקו עם הבן במצב read-only לאחר ה-fork.\n    *   כאשר האב מנסה לכתוב לדפים אלה, מתרחשת תקלת דף. מנגנון CoW נכנס לפעולה: מערכת ההפעלה יוצרת עותק של כל דף (מתוך ה-`512` המשותפים) ומקצה `512` דפים פיזיים *חדשים* ופרטיים עבור האב. האב כותב לעותקים הפרטיים שלו.\n\n**חישוב סך הדפים הפיזיים:**\n*   דפים שהוקצו לפני ה-`fork()` (עבור חצי המערך הראשון): `512` דפים.\n*   דפים שהוקצו עבור תהליך הבן (עבור חצי המערך השני): `512` דפים.\n*   דפים שהוקצו עבור תהליך האב (עבור חצי המערך הראשון, בגלל CoW): `512` דפים.\n\n**סך הכל:** `512 + 512 + 512 = 1536` דפים פיזיים."}, "difficulty_estimation": "Medium", "_source_file": "0561__Virtual_Memory__CodeAnalysis__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:42:19", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Virtual Memory", "Paging", "TLB", "Memory Access Patterns", "Performance"], "content": {"text": "נתונה תוכנית C המשתמשת במערך דו-ממדי גדול. גודל המערך הוא 1024x1024 שלמים (integers).\nבמערכת ההפעלה הנתונה:\n- גודל דף הוא 4KB (קילובייט).\n- גודל שלם (int) הוא 4 בתים.\n- ה-TLB (Translation Lookaside Buffer) יכול להכיל 64 כניסות.\n- מדיניות החלפת דפים (Page Replacement Policy) היא LRU (Least Recently Used).\n- מדיניות החלפת כניסות ב-TLB היא LRU.\n- המערכת משתמשת ב-Demand Paging, והזיכרון ההתחלתי (cache/TLB) ריק לחלוטין.\n\nיש לנתח את קטע הקוד ולענות על השאלות הבאות בהקשר של זיכרון וירטואלי:", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define MATRIX_SIZE 1024 // 1024x1024 integers\n#define PAGE_SIZE 4096   // 4KB page size\n#define INT_SIZE 4       // Size of int in bytes\n\nint matrix[MATRIX_SIZE][MATRIX_SIZE];\n\nint main() {\n    // Scenario 1: Row-major access\n    for (int i = 0; i < MATRIX_SIZE; ++i) {\n        for (int j = 0; j < MATRIX_SIZE; ++j) {\n            matrix[i][j] = i * j; // Access (i,j)\n        }\n    }\n\n    // Scenario 2: Column-major access\n    for (int j = 0; j < MATRIX_SIZE; ++j) {\n        for (int i = 0; i < MATRIX_SIZE; ++i) {\n            matrix[i][j] = i * j; // Access (i,j)\n        }\n    }\n\n    return 0;\n}"}, "sub_questions": [{"id": "1.1", "text": "כמה Page Faults יתרחשו במהלך ביצוע \"תרחיש 1: גישה לפי שורה\" (Row-major access)? נמק/י.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "כמה TLB Misses יתרחשו במהלך ביצוע \"תרחיש 1: גישה לפי שורה\" (Row-major access)? נמק/י.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "כמה Page Faults יתרחשו במהלך ביצוע \"תרחיש 2: גישה לפי עמודה\" (Column-major access)? נמק/י.", "code_snippet": null, "options": null}, {"id": "1.4", "text": "כמה TLB Misses יתרחשו במהלך ביצוע \"תרחיש 2: גישה לפי עמודה\" (Column-major access)? נמק/י.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "חישובים כלליים:\n*   גודל המערך: 1024 שורות * 1024 עמודות * 4 בתים/שלם = 4,194,304 בתים = 4MB.\n*   גודל דף: 4096 בתים = 4KB.\n*   מספר השלמים בדף אחד: 4096 בתים / 4 בתים/שלם = 1024 שלמים.\n*   מספר הדפים הכולל הנדרש למערך: 4MB / 4KB = 1024 דפים.\n*   כל שורה במערך מכילה 1024 שלמים, ולכן תופסת 1024 * 4 = 4096 בתים, כלומר בדיוק דף אחד.\n\n1.1. Page Faults בתרחיש 1 (Row-major access):\n*   בגישת Row-major, הלולאה הפנימית (j) עוברת על כל האיברים בשורה הנוכחית (i). ב-C, מערכים דו-ממדיים נשמרים בזיכרון בסדר Row-major, כלומר איברי שורה רציפים בזיכרון.\n*   מאחר שכל שורה תופסת בדיוק דף אחד והגישה היא רציפה בתוך השורה, הגישה הראשונה לאיבר matrix[i][0] תגרום ל-Page Fault (בהנחה שהדף אינו בזיכרון, כפי שצוין). \n*   כל שאר הגישות לאיברים matrix[i][1] עד matrix[i][MATRIX_SIZE-1] יהיו באותו הדף שכבר נטען, ולכן לא יגרמו ל-Page Fault נוסף עבור שורה זו.\n*   מכיוון שיש MATRIX_SIZE = 1024 שורות, וכל שורה גורמת ל-Page Fault אחד, סך הכל יתרחשו 1024 Page Faults.\n*   מספר Page Faults: 1024.\n\n1.2. TLB Misses בתרחיש 1 (Row-major access):\n*   בדומה ל-Page Faults, הגישה הראשונה לכל דף (כלומר, הגישה הראשונה לכל שורה, matrix[i][0]) תגרום ל-TLB Miss, מכיוון שה-TLB ריק בתחילה.\n*   לאחר ה-TLB Miss, ה-PTE (Page Table Entry) של הדף נטען ל-TLB.\n*   כל הגישות הבאות לאיברים באותה השורה (matrix[i][1] עד matrix[i][MATRIX_SIZE-1]) יהיו TLB Hit, מכיוון שה-PTE של הדף כבר נמצא ב-TLB.\n*   מכיוון שיש MATRIX_SIZE = 1024 שורות, וכל שורה גורמת ל-TLB Miss אחד (כדי לטעון את ה-PTE של הדף של אותה שורה), סך הכל יתרחשו 1024 TLB Misses.\n*   ה-TLB מכיל 64 כניסות. כשנגיע לשורה ה-65, ה-PTE של שורה 0 יפלט (LRU). אך מכיוון שהגישה לכל שורה היא חד-פעמית ורציפה, ואין חזרה לדפים קודמים באותו לולאה, כל דף חדש ייצור TLB Miss.\n*   מספר TLB Misses: 1024.\n\n1.3. Page Faults בתרחיש 2 (Column-major access):\n*   בגישת Column-major, הלולאה הפנימית (i) עוברת על איברים בעמודה הנוכחית (j), כלומר matrix[0][j], matrix[1][j], ..., matrix[MATRIX_SIZE-1][j].\n*   כפי שצוין, כל שורה תופסת דף אחד. לכן, הגישה ל-matrix[i][j] עבור i שונה פירושה גישה לדף אחר בזיכרון וירטואלי.\n*   לדוגמה, matrix[0][j] נמצא בדף 0, matrix[1][j] נמצא בדף 1, וכן הלאה, עד matrix[1023][j] שנמצא בדף 1023.\n*   כל גישה לאיבר matrix[i][j] (עבור i משתנה) תגרום ל-Page Fault, מכיוון שאנו ניגשים לדף חדש שאינו בזיכרון (בהנחה שאין מספיק זיכרון פיזי להחזיק את כל הדפים בבת אחת, ודפים קודמים נפלטו).\n*   הלולאה החיצונית (j) רצה 1024 פעמים, והלולאה הפנימית (i) רצה 1024 פעמים. בכל איטרציה של הלולאה הפנימית, אנו ניגשים לדף חדש (שלא נטען לאחרונה).\n*   לכן, מספר ה-Page Faults הכולל יהיה MATRIX_SIZE * MATRIX_SIZE = 1024 * 1024 = 1,048,576.\n*   מספר Page Faults: 1,048,576.\n\n1.4. TLB Misses בתרחיש 2 (Column-major access):\n*   בדומה ל-Page Faults, בגישת Column-major, כל גישה לאיבר matrix[i][j] (כאשר i משתנה) תגרום ל-TLB Miss.\n*   זאת מכיוון שכל גישה לאיבר matrix[i][j] עבור i שונה מובילה לדף וירטואלי שונה.\n*   ה-TLB יכול להכיל רק 64 כניסות. מכיוון שאנו ניגשים ל-1024 דפים שונים ברצף (עבור כל עמודה j), ה-TLB יתמלא ויפלוט כניסות ישנות לפי מדיניות LRU. כלומר, כמעט כל גישה לדף חדש תגרום ל-TLB Miss.\n*   מספר ה-TLB Misses הכולל יהיה MATRIX_SIZE * MATRIX_SIZE = 1024 * 1024 = 1,048,576.\n*   מספר TLB Misses: 1,048,576.", "code_snippet": null}, "difficulty_estimation": "Medium", "_source_file": "0562__Virtual_Memory__CodeAnalysis__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:42:50", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Virtual Memory", "Paging", "Copy-on-Write", "Processes", "fork"], "content": {"text": "נתונה התוכנית הבאה. יש להניח כי גודל דף הוא 4KB (4096 בתים) וכי מערכת ההפעלה מממשת Copy-on-Write (CoW) עבור דפים במרחב הזיכרון של תהליכים שנוצרו באמצעות `fork()`. יש להתעלם מדפים המשמשים עבור קוד התוכנית, מחסנית, ערימה, וטבלאות דפים, ולהתמקד אך ורק בדפים המשמשים את המערך הגלובלי `global_buffer`.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\n#define PAGE_SIZE 4096 // Assume 4KB page size\n#define NUM_PAGES 4    // Total 4 pages for the array\n\nchar global_buffer[PAGE_SIZE * NUM_PAGES]; // Global array\n\nint main() {\n    // Initialize the entire buffer with 'A'\n    for (int i = 0; i < PAGE_SIZE * NUM_PAGES; ++i) {\n        global_buffer[i] = 'A';\n    }\n\n    pid_t pid = fork();\n\n    if (pid < 0) {\n        perror(\"fork failed\");\n        exit(1);\n    } else if (pid == 0) { // Child process\n        printf(\"Child process (PID: %d):\\n\", getpid());\n        // Child modifies the first page\n        for (int i = 0; i < PAGE_SIZE; ++i) {\n            global_buffer[i] = 'C';\n        }\n        // Child modifies a byte in the third page\n        global_buffer[PAGE_SIZE * 2 + 10] = 'X';\n\n        printf(\"Child reads first byte of first page: %c\\n\", global_buffer[0]);\n        printf(\"Child reads first byte of second page: %c\\n\", global_buffer[PAGE_SIZE]);\n        printf(\"Child reads byte from third page: %c\\n\", global_buffer[PAGE_SIZE * 2 + 10]);\n        printf(\"Child reads first byte of fourth page: %c\\n\", global_buffer[PAGE_SIZE * 3]);\n\n    } else { // Parent process\n        printf(\"Parent process (PID: %d):\\n\", getpid());\n        // Parent modifies the second page\n        for (int i = PAGE_SIZE; i < PAGE_SIZE * 2; ++i) {\n            global_buffer[i] = 'P';\n        }\n        // Parent modifies a byte in the fourth page\n        global_buffer[PAGE_SIZE * 3 + 20] = 'Y';\n\n        wait(NULL); // Wait for child to finish\n\n        printf(\"Parent reads first byte of first page: %c\\n\", global_buffer[0]);\n        printf(\"Parent reads first byte of second page: %c\\n\", global_buffer[PAGE_SIZE]);\n        printf(\"Parent reads byte from third page: %c\\n\", global_buffer[PAGE_SIZE * 2 + 10]);\n        printf(\"Parent reads byte from fourth page: %c\\n\", global_buffer[PAGE_SIZE * 3 + 20]);\n    }\n\n    return 0;\n}"}, "sub_questions": [{"id": "1.1", "text": "מה יהיה הפלט המדויק של התוכנית?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "כמה דפים פיזיים של זיכרון (עבור המערך `global_buffer` בלבד) יהיו בשימוש על ידי המערכת ברגעים הבאים? נמק.", "code_snippet": null, "options": null}, {"id": "1.2.a", "text": "מיד לאחר האתחול של המערך `global_buffer` ולפני קריאה ל-`fork()`.", "code_snippet": null, "options": null}, {"id": "1.2.b", "text": "מיד לאחר קריאה ל-`fork()`, ולפני כל שינוי במערך על ידי תהליך הבן או האב.", "code_snippet": null, "options": null}, {"id": "1.2.c", "text": "לאחר שתהליך הבן סיים את כל השינויים וההדפסות שלו, ורגע לפני שתהליך האב מתחיל את ההדפסות שלו (כלומר, לאחר `wait(NULL)`).", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסבר מפורט:\n\n**פתרון ל-1.1: פלט התוכנית**\nהפלט יכלול את ההדפסות של תהליך הבן ולאחר מכן את ההדפסות של תהליך האב, מכיוון שהאב ממתין לבן באמצעות `wait(NULL)`.\nבשל מנגנון Copy-on-Write (CoW), כאשר תהליך (בן או אב) כותב לדף זיכרון ששותף במקור, נוצר עותק פרטי של הדף עבור אותו תהליך. קריאות מאותו דף יחזירו את הערך מהעותק הפרטי שלו (אם קיים) או מהדף המשותף המקורי.\n\n**פלט תהליך הבן:**\n```\nChild process (PID: <PID של הבן>):\nChild reads first byte of first page: C\nChild reads first byte of second page: A\nChild reads byte from third page: X\nChild reads first byte of fourth page: A\n```\n*   `Child reads first byte of first page: C` - תהליך הבן שינה את דף 0 ל-'C', ולכן קריאה ממנו תחזיר 'C'.\n*   `Child reads first byte of second page: A` - תהליך הבן לא שינה את דף 1. הדף נשאר משותף ומכיל את הערך המקורי 'A'.\n*   `Child reads byte from third page: X` - תהליך הבן שינה את דף 2 ל-'X' במיקום מסוים, ולכן קריאה ממנו תחזיר 'X'.\n*   `Child reads first byte of fourth page: A` - תהליך הבן לא שינה את דף 3. הדף נשאר משותף ומכיל את הערך המקורי 'A'.\n\n**פלט תהליך האב (לאחר שהבן סיים):**\n```\nParent process (PID: <PID של האב>):\nParent reads first byte of first page: A\nParent reads first byte of second page: P\nParent reads byte from third page: A\nParent reads byte from fourth page: Y\n```\n*   `Parent reads first byte of first page: A` - תהליך הבן שינה את דף 0, מה שגרם ליצירת עותק עבור הבן. הדף המקורי (של האב) נשאר 'A'.\n*   `Parent reads first byte of second page: P` - תהליך האב שינה את דף 1 ל-'P', ולכן קריאה ממנו תחזיר 'P'.\n*   `Parent reads byte from third page: A` - תהליך הבן שינה את דף 2, מה שגרם ליצירת עותק עבור הבן. הדף המקורי (של האב) נשאר 'A'.\n*   `Parent reads byte from fourth page: Y` - תהליך האב שינה את דף 3 ל-'Y' במיקום מסוים, ולכן קריאה ממנו תחזיר 'Y'.\n\n**פתרון ל-1.2: מספר דפים פיזיים**\n\n**1.2.א: מיד לאחר האתחול של המערך `global_buffer` ולפני קריאה ל-`fork()`**\n*   **מספר דפים פיזיים:** 4\n*   **נימוק:** המערך `global_buffer` מוגדר בגודל של 4 דפים (4 * 4096 בתים). לאחר האתחול בלולאה, כל הדפים של המערך נכתבים בפעם הראשונה, מה שגורם למערכת ההפעלה להקצות להם דפים פיזיים בזיכרון. לכן, 4 דפים פיזיים נכנסים לשימוש.\n\n**1.2.ב: מיד לאחר קריאה ל-`fork()`, ולפני כל שינוי במערך על ידי תהליך הבן או האב**\n*   **מספר דפים פיזיים:** 4\n*   **נימוק:** קריאה ל-`fork()` יוצרת תהליך בן. בשל מנגנון Copy-on-Write (CoW), תהליך הבן מקבל העתק של מרחב הכתובות הוירטואלי של האב, אך בתחילה, דפים פיזיים אינם משוכפלים. במקום זאת, טבלאות הדפים של האב והבן מפנות לאותם דפים פיזיים עם הרשאת קריאה בלבד. שיכפול הדף הפיזי יתרחש רק כאשר אחד התהליכים ינסה לכתוב לדף משותף. מכיוון שעדיין לא בוצעו שינויים, כל 4 הדפים נשארים משותפים.\n\n**1.2.ג: לאחר שתהליך הבן סיים את כל השינויים וההדפסות שלו, ורגע לפני שתהליך האב מתחיל את ההדפסות שלו (כלומר, לאחר `wait(NULL)`)**\n*   **מספר דפים פיזיים:** 8\n*   **נימוק:**\n    *   **דף 0:** הבן משנה את דף 0 (כתיבה ל-`global_buffer[0]` עד `global_buffer[PAGE_SIZE-1]`). מנגנון CoW משכפל את דף 0. כעת יש שני דפים פיזיים עבור דף 0 (אחד לאב, אחד לבן).\n    *   **דף 1:** האב משנה את דף 1 (כתיבה ל-`global_buffer[PAGE_SIZE]` עד `global_buffer[PAGE_SIZE*2-1]`). מנגנון CoW משכפל את דף 1. כעת יש שני דפים פיזיים עבור דף 1.\n    *   **דף 2:** הבן משנה את דף 2 (כתיבה ל-`global_buffer[PAGE_SIZE * 2 + 10]`). מנגנון CoW משכפל את דף 2. כעת יש שני דפים פיזיים עבור דף 2.\n    *   **דף 3:** האב משנה את דף 3 (כתיבה ל-`global_buffer[PAGE_SIZE * 3 + 20]`). מנגנון CoW משכפל את דף 3. כעת יש שני דפים פיזיים עבור דף 3.\n    *   בסה\"כ, כל אחד מ-4 הדפים המקוריים שונה על ידי תהליך כלשהו. לכן, עבור כל אחד מ-4 הדפים הלוגיים, קיימים כעת שני עותקים פיזיים נפרדים בזיכרון (אחד עבור האב ואחד עבור הבן). 4 דפים לוגיים * 2 עותקים = 8 דפים פיזיים בסך הכל."}, "difficulty_estimation": "Medium", "_source_file": "0564__Virtual_Memory__CodeAnalysis__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:44:17", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Virtual Memory", "Paging", "Copy-on-Write", "Page Faults", "fork"], "content": {"text": "נתונה התוכנית הבאה, המבצעת הקצאת זיכרון גדולה, מאתחלת חלקים ממנה, ולאחר מכן מבצעת `fork`. עליך לנתח את הקוד ולהשיב על השאלה.\n\nיש להניח את ההנחות הבאות לגבי המערכת:\n- גודל דף זיכרון (PAGE_SIZE) הוא 4KB.\n- מערכת ההפעלה משתמשת במנגנון זיכרון וירטואלי עם Copy-on-Write (CoW) עבור אזורי זיכרון הניתנים לכתיבה (writable).\n- כל גישה ראשונה לדף זיכרון (קריאה או כתיבה) גורמת ל-page fault. כלומר, דפים מוקצים פיזית רק בעת הגישה הראשונה אליהם (demand paging).\n- הקריאה ל-`malloc` מצליחה ומחזירה מצביע לזיכרון המיושר לגודל דף (page-aligned).\n- קוד התוכנית עצמו, המחסנית, הערימה של המערכת, וטבלאות דפים אינם נכללים בחישוב מספר ה-page faults, אלא רק הגישות למערך `large_array`.\n- פעולות `printf` אינן גורמות ל-page faults על המערך `large_array` עצמו.\n\nכמה page faults מינימליים הקשורים לגישה למערך `large_array` יתרחשו בסך הכל במהלך ריצת התוכנית (כולל תהליך האב והבן), עד לסיום שני התהליכים? נמק את תשובתך.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <string.h> // For memset\n\n#define PAGE_SIZE 4096 // 4KB\n#define ARRAY_SIZE (256 * PAGE_SIZE) // 1MB array, 256 pages\n\nint main() {\n    char *large_array = (char *)malloc(ARRAY_SIZE);\n    if (large_array == NULL) {\n        perror(\"malloc failed\");\n        return 1;\n    }\n\n    // Initialize the first page and the last page\n    memset(large_array, 0, PAGE_SIZE); // Accesses first page\n    memset(large_array + ARRAY_SIZE - PAGE_SIZE, 0, PAGE_SIZE); // Accesses last page\n\n    printf(\"Array allocated and partially initialized. PID: %d\\n\", getpid());\n\n    pid_t pid = fork();\n\n    if (pid < 0) {\n        perror(\"fork failed\");\n        free(large_array);\n        return 1;\n    } else if (pid == 0) { // Child process\n        printf(\"Child process (PID: %d) started.\\n\", getpid());\n        // Child modifies the first page\n        for (int i = 0; i < PAGE_SIZE; ++i) {\n            large_array[i] = 'C';\n        }\n        printf(\"Child modified first page. Exiting.\\n\");\n        _exit(0); // Use _exit to avoid flushing parent's stdio buffer\n    } else { // Parent process\n        printf(\"Parent process (PID: %d) forked child (PID: %d).\\n\", getpid(), pid);\n        // Parent modifies the last page\n        for (int i = 0; i < PAGE_SIZE; ++i) {\n            large_array[ARRAY_SIZE - PAGE_SIZE + i] = 'P';\n        }\n        printf(\"Parent modified last page. Waiting for child.\\n\");\n        wait(NULL);\n        printf(\"Child finished. Parent exiting.\\n\");\n    }\n\n    free(large_array);\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ננתח את מספר ה-page faults שנגרמים עקב גישה למערך `large_array`:\n\n1.  **הקצאת זיכרון (`malloc`):** הקריאה ל-`malloc(ARRAY_SIZE)` מקצה זיכרון וירטואלי בגודל 1MB (256 דפים). בשלב זה, לא מתרחשים page faults מכיוון שהזיכרון הפיזי מוקצה רק בעת הגישה הראשונה אליו (demand paging).\n\n2.  **אתחול הדף הראשון (`memset(large_array, 0, PAGE_SIZE)`):** פעולה זו ניגשת לדף הזיכרון הראשון של המערך. זוהי הגישה הראשונה לדף זה. מכיוון שהדף אינו בזיכרון הפיזי, נגרם **page fault אחד**. הדף מובא לזיכרון הפיזי ונרשם בטבלת הדפים של תהליך האב.\n\n3.  **אתחול הדף האחרון (`memset(large_array + ARRAY_SIZE - PAGE_SIZE, 0, PAGE_SIZE)`):** פעולה זו ניגשת לדף הזיכרון האחרון של המערך. זוהי הגישה הראשונה לדף זה. נגרם **page fault אחד נוסף**. הדף מובא לזיכרון הפיזי ונרשם בטבלת הדפים של תהליך האב.\n    *   סה\"כ page faults עד כה: 2.\n\n4.  **קריאה ל-`fork()`:** כאשר `fork()` נקרא, מרחב הכתובות הווירטואלי של תהליך האב משוכפל עבור תהליך הבן. הודות למנגנון Copy-on-Write (CoW), דפי הזיכרון הניתנים לכתיבה (כמו אלו של `large_array`) משותפים בתחילה בין האב לבן ומסומנים כקריאה בלבד (read-only) בטבלאות הדפים של שניהם. בשלב זה, שני הדפים (הראשון והאחרון) שנגעו בהם כבר נמצאים בזיכרון הפיזי ומשותפים. 254 הדפים הנותרים עדיין לא הוקצו פיזית כלל.\n\n5.  **תהליך הבן (`if (pid == 0)`):**\n    *   **שינוי הדף הראשון (`for (int i = 0; i < PAGE_SIZE; ++i) { large_array[i] = 'C'; }`):** הבן מנסה לשנות את הדף הראשון. מכיוון שדף זה משותף עם האב ומסומן כ-read-only (בשל CoW), הגישה הראשונה לכתיבה על ידי הבן גורמת ל-**page fault של CoW**. מערכת ההפעלה יוצרת עותק פרטי של דף זה עבור תהליך הבן, ומעדכנת את טבלת הדפים של הבן שתצביע על העותק החדש. הדף המקורי נשאר עבור האב (שעדיין לא שינה אותו).\n    *   סה\"כ page faults עד כה: 2 (מהאב) + 1 (מהבן) = 3.\n\n6.  **תהליך האב (`else { // Parent process }`):**\n    *   **שינוי הדף האחרון (`for (int i = 0; i < PAGE_SIZE; ++i) { large_array[ARRAY_SIZE - PAGE_SIZE + i] = 'P'; }`):** האב מנסה לשנות את הדף האחרון. בדומה למקרה של הבן, דף זה משותף עם הבן ומסומן כ-read-only. הגישה הראשונה לכתיבה על ידי האב גורמת ל-**page fault של CoW**. מערכת ההפעלה יוצרת עותק פרטי של דף זה עבור תהליך האב, ומעדכנת את טבלת הדפים של האב שתצביע על העותק החדש. הדף המקורי נשאר עבור הבן (שעדיין לא שינה אותו).\n    *   סה\"כ page faults: 2 (מהאב לפני fork) + 1 (מהבן) + 1 (מהאב אחרי fork) = **4 page faults**.\n\nלסיכום, בסך הכל יתרחשו 4 page faults הקשורים לגישה למערך `large_array`."}, "difficulty_estimation": "Medium", "_source_file": "0565__Virtual_Memory__CodeAnalysis__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:44:47", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Virtual Memory", "Copy-On-Write", "Processes", "Memory Management"], "content": {"text": "נתונה תוכנית C הבאה. יש להניח שמערכת ההפעלה משתמשת בזיכרון וירטואלי עם מנגנון Copy-On-Write (COW) וגודל דף הוא 4KB. המערך הגלובלי `global_array` מתחיל בכתובת מיושרת לדף.\n\nתאר והסבר באופן מפורט:\n1.  מה יהיה הפלט המודפס למסך על ידי תהליך האב ועל ידי תהליך הבן?\n2.  כמה דפים פיזיים לכל היותר יהיו בשימוש עבור המערך `global_array` הכולל של שני התהליכים (אב ובן) לאחר ששניהם סיימו את פעולות הכתיבה שלהם? נמק את תשובתך תוך התייחסות למנגנון ה-COW.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\n#define PAGE_SIZE 4096 // Assume 4KB page size\n#define ARRAY_PAGES 4\n#define ARRAY_SIZE (PAGE_SIZE * ARRAY_PAGES) // Array spanning 4 pages\n\nchar global_array[ARRAY_SIZE]; // This will be in the data segment, initialized to 'A's\n\nint main() {\n    // Initialize the array (this ensures all pages are touched and mapped in parent initially)\n    for (int i = 0; i < ARRAY_SIZE; ++i) {\n        global_array[i] = 'A';\n    }\n\n    printf(\"Initial: global_array[0]=%c, global_array[%d]=%c\\n\", global_array[0], ARRAY_SIZE-1, global_array[ARRAY_SIZE-1]);\n\n    pid_t pid = fork();\n\n    if (pid < 0) {\n        perror(\"fork failed\");\n        exit(1);\n    } else if (pid == 0) { // Child process\n        // Child modifies the first half (pages 0 and 1)\n        for (int i = 0; i < ARRAY_SIZE / 2; ++i) {\n            global_array[i] = 'C';\n        }\n        printf(\"Child (PID: %d): global_array[0]=%c, global_array[%d]=%c\\n\", getpid(), global_array[0], ARRAY_SIZE-1, global_array[ARRAY_SIZE-1]);\n        exit(0);\n    } else { // Parent process\n        // Parent waits to ensure child finishes its modifications\n        wait(NULL);\n        // Parent modifies the second half (pages 2 and 3)\n        for (int i = ARRAY_SIZE / 2; i < ARRAY_SIZE; ++i) {\n            global_array[i] = 'P';\n        }\n        printf(\"Parent (PID: %d): global_array[0]=%c, global_array[%d]=%c\\n\", getpid(), global_array[0], ARRAY_SIZE-1, global_array[ARRAY_SIZE-1]);\n    }\n\n    return 0;\n}"}, "sub_questions": null, "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  **פלט התוכנית:**\n    *   **פלט ראשוני (מהתהליך האב לפני ה-fork):**\n        `Initial: global_array[0]=A, global_array[16383]=A`\n    *   **פלט מתהליך הבן:**\n        תהליך הבן משנה את החצי הראשון של המערך (אינדקסים 0 עד `ARRAY_SIZE/2 - 1`, כלומר דפים 0 ו-1) ל-'C'. את החצי השני (דפים 2 ו-3) הוא אינו משנה. לכן, התו במיקום 0 יהיה 'C', והתו במיקום `ARRAY_SIZE-1` (שהוא 16383) יישאר 'A' (הערך המקורי ששותף עם האב ולא שונה על ידי הבן).\n        `Child (PID: <child_pid>): global_array[0]=C, global_array[16383]=A`\n    *   **פלט מתהליך האב:**\n        תהליך האב ממתין שהבן יסיים את פעולותיו. לאחר מכן, הוא משנה את החצי השני של המערך (אינדקסים `ARRAY_SIZE/2` עד `ARRAY_SIZE - 1`, כלומר דפים 2 ו-3) ל-'P'. את החצי הראשון (דפים 0 ו-1) הוא אינו משנה. בזכות מנגנון ה-COW, הגישה של הבן לדפים 0 ו-1 יצרה עותקים נפרדים עבורו, ולכן השינויים של הבן אינם משפיעים על האב. התו במיקום 0 של האב יישאר 'A'. התו במיקום `ARRAY_SIZE-1` (שהוא 16383) ישתנה ל-'P'.\n        `Parent (PID: <parent_pid>): global_array[0]=A, global_array[16383]=P`\n\n2.  **מספר הדפים הפיזיים בשימוש:**\n    *   **שלב 1: אתחול המערך ע\"י האב:** לפני קריאת ה-`fork()`, תהליך האב מאתחל את כל המערך `global_array`. מכיוון שגודל המערך הוא `4 * PAGE_SIZE`, האב משתמש ב-4 דפים פיזיים. נסמן אותם P0, P1, P2, P3. טבלת הדפים של האב מפנה לדפים אלו.\n    *   **שלב 2: קריאת `fork()`:** כאשר מתבצעת קריאת `fork()`, נוצר תהליך הבן. מערכת ההפעלה, המשתמשת ב-COW, אינה מעתיקה את כל מרחב הזיכרון של האב. במקום זאת, טבלת הדפים של הבן מועתקת, וכל הדפים המכילים נתונים ניתנים לכתיבה (כמו `global_array`) מסומנים כ-read-only הן בטבלת הדפים של האב והן בטבלת הדפים של הבן, ומפנים לאותם דפים פיזיים (P0, P1, P2, P3).\n    *   **שלב 3: כתיבה של תהליך הבן:** תהליך הבן כותב לחצי הראשון של המערך, אשר מכסה את דפים וירטואליים 0 ו-1. כאשר הבן מנסה לכתוב לדף 0, מתרחשת תקלת דף (page fault). מערכת ההפעלה מזהה שהדף מסומן ל-COW, מעתיקה את התוכן של דף פיזי P0 לדף פיזי חדש (נסמן אותו C0), מעדכנת את טבלת הדפים של הבן כך שדף וירטואלי 0 יפנה ל-C0 ויהיה ניתן לכתיבה. דף P0 נשאר כפי שהוא וממשיך להיות ממופה עבור האב. אותו תהליך מתרחש עבור דף 1: P1 מועתק ל-C1, וטבלת הדפים של הבן מתעדכנת. דפים 2 ו-3 אינם משתנים על ידי הבן, ולכן הבן והאב ממשיכים לשתף את P2 ו-P3 (כפי שהיו לאחר ה-fork).\n        בשלב זה ישנם 4 (מקוריים) + 2 (חדשים עבור הבן) = 6 דפים פיזיים בשימוש (P0, P1, P2, P3, C0, C1).\n    *   **שלב 4: כתיבה של תהליך האב:** תהליך האב כותב לחצי השני של המערך, אשר מכסה את דפים וירטואליים 2 ו-3. כאשר האב מנסה לכתוב לדף 2, מתרחשת תקלת דף. מערכת ההפעלה מעתיקה את התוכן של דף פיזי P2 לדף פיזי חדש (נסמן אותו PA2), ומעדכנת את טבלת הדפים של האב. דף P2 נשאר כפי שהוא וממשיך להיות ממופה עבור הבן (שמעולם לא כתב אליו). אותו תהליך מתרחש עבור דף 3: P3 מועתק ל-PA3.\n    *   **סיכום:** בסיום ריצת שני התהליכים, יהיו בשימוש 8 דפים פיזיים בסך הכל עבור המערך `global_array`:\n        *   P0 (ממופה לדף וירטואלי 0 של האב)\n        *   P1 (ממופה לדף וירטואלי 1 של האב)\n        *   PA2 (דף פיזי חדש, ממופה לדף וירטואלי 2 של האב)\n        *   PA3 (דף פיזי חדש, ממופה לדף וירטואלי 3 של האב)\n        *   C0 (דף פיזי חדש, ממופה לדף וירטואלי 0 של הבן)\n        *   C1 (דף פיזי חדש, ממופה לדף וירטואלי 1 של הבן)\n        *   P2 (ממופה לדף וירטואלי 2 של הבן)\n        *   P3 (ממופה לדף וירטואלי 3 של הבן)\n        כל אחד מ-4 הדפים המקוריים (P0, P1, P2, P3) שותף בתחילה, ולאחר מכן מועתק פעם אחת כאשר אחד מהתהליכים (האב או הבן) כותב אליו. לכן, עבור כל דף וירטואלי שהיה קיים במקור, יהיו בסופו של דבר 2 דפים פיזיים (הדף המקורי והעותק שלו), כל אחד ממופה לתהליך אחר. סה\"כ `4 * 2 = 8` דפים פיזיים."}, "difficulty_estimation": "Medium", "_source_file": "0566__Virtual_Memory__CodeAnalysis__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:45:23", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Virtual Memory", "Paging", "Copy-on-Write", "Fork"], "content": {"text": "נתונה תוכנית C המשתמשת בזיכרון וירטואלי ובמנגנון Copy-on-Write (COW).\nנתון:\n*   גודל דף זיכרון (PAGE_SIZE) הוא 4KB.\n*   המערך `arr` בגודל 1MB (ARRAY_SIZE) מוקצה באמצעות `malloc` בתהליך האב.\n*   הלולאה שמאחלת את המערך מבטיחה שכל הדפים של המערך יוקצו פיזית בתהליך האב ויהיו מוכנים ל-COW.\n*   המערכת ההפעלה תומכת באופן מלא ב-Copy-on-Write עבור דפי זיכרון ששונו.\n\nבהתבסס על הקוד הנתון וההנחות, מהו המספר המקסימלי של דפים פיזיים שישמשו את המערך `arr` במקביל על ידי שני התהליכים (האב והילד) בכל שלב של ריצת התוכנית? הסבר את חישובך.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <string.h>\n\n#define PAGE_SIZE 4096 // 4KB\n#define ARRAY_SIZE (256 * PAGE_SIZE) // 1MB array, 256 pages\n\nint main() {\n    int *arr = (int *)malloc(ARRAY_SIZE);\n    if (arr == NULL) {\n        perror(\"malloc failed\");\n        return 1;\n    }\n\n    // Initialize array - this brings all pages into memory for the parent\n    // and prepares them for COW if fork happens later.\n    for (int i = 0; i < ARRAY_SIZE / sizeof(int); ++i) {\n        arr[i] = i;\n    }\n\n    pid_t pid = fork();\n\n    if (pid < 0) {\n        perror(\"fork failed\");\n        free(arr);\n        return 1;\n    } else if (pid == 0) { // Child process\n        // Modify elements at specific locations\n        arr[0] = -1; // Modifies the first page\n        arr[PAGE_SIZE / sizeof(int) + 5] = -2; // Modifies the second page\n        arr[2 * PAGE_SIZE / sizeof(int) + 10] = -3; // Modifies the third page\n        \n        exit(0);\n    } else { // Parent process\n        wait(NULL);\n        free(arr);\n    }\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסבר:\n1.  **אתחול בתהליך האב:** המערך `arr` בגודל 1MB (ARRAY_SIZE) מוקצה באמצעות `malloc`. הלולאה מאחלת את כל האלמנטים במערך. מכיוון ש-`PAGE_SIZE` הוא 4KB, מערך בגודל 1MB דורש `1MB / 4KB = 1024KB / 4KB = 256` דפים פיזיים. בשלב זה, רק תהליך האב קיים, וכל 256 הדפים הללו מוקצים לו.\n2.  **קריאת `fork()`:** כאשר `fork()` נקרא, נוצר תהליך ילד. בזכות מנגנון ה-Copy-on-Write (COW), תהליך הילד אינו מקבל מיד עותק משלו של כל דפי הזיכרון של האב. במקום זאת, שני התהליכים חולקים את אותם 256 דפים פיזיים. דפים אלו מסומנים כקריאה בלבד (read-only) עבור שני התהליכים. בשלב זה, לא מוקצים דפים פיזיים *נוספים* עבור המערך בתהליך הילד.\n3.  **שינויים בתהליך הילד:** תהליך הילד משנה שלושה אלמנטים במערך `arr`:\n    *   `arr[0] = -1;` משנה את האלמנט הראשון, שנמצא בדף הראשון של המערך.\n    *   `arr[PAGE_SIZE / sizeof(int) + 5] = -2;` משנה אלמנט בדף השני של המערך.\n    *   `arr[2 * PAGE_SIZE / sizeof(int) + 10] = -3;` משנה אלמנט בדף השלישי של המערך.\n    כאשר תהליך הילד מנסה לכתוב לדף המסומן כ-read-only, מתרחש \"Copy-on-Write Page Fault\". מערכת ההפעלה מיירטת את הפעולה, יוצרת עותק חדש של הדף עבור תהליך הילד, מעתיקה אליו את התוכן המקורי, משנה את טבלת הדפים של הילד כך שתצביע על הדף החדש, ומשנה את ההרשאות של הדף החדש לכתיבה וקריאה. דף זה נשאר read-only עבור האב.\n    מכיוון שהילד משנה שלושה אלמנטים שנמצאים בשלושה דפים *שונים*, יתרחשו 3 אירועי COW Page Faults, ויוקצו 3 דפים פיזיים חדשים עבור הילד.\n4.  **מספר דפים מקסימלי במקביל:**\n    *   תהליך האב עדיין משתמש ב-256 הדפים המקוריים (כולל שלושת הדפים שהילד עשה להם עותק, שעדיין נגישים לאב בגרסתם המקורית). כלומר, 256 דפים פיזיים מוקצים עבור המערך של האב.\n    *   תהליך הילד משתמש ב-3 דפים פיזיים *חדשים* (שהם עותקים של הדפים המקוריים 1, 2, 3) וב-253 דפים משותפים עם האב (הדפים שלא שונו).\n    *   המספר הכולל של דפים פיזיים הייחודיים לאב או לילד, או משותפים, הוא:\n        256 דפים (של האב) + 3 דפים (נוספים שנוצרו עבור הילד, שהם עותקים של דפים שהיו שייכים לאב והאב עדיין משתמש בהם בגרסתם המקורית) = 259 דפים.\n    נקודת המקסימום היא לאחר שהילד ביצע את כל השינויים לפני שהוא מסיים, כאשר גם האב וגם הילד קיימים וכל הדפים המדוברים נמצאים בזיכרון פיזי.", "code_snippet": null}, "difficulty_estimation": "Medium", "_source_file": "0567__Virtual_Memory__CodeAnalysis__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:45:57", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Virtual Memory", "Copy-on-Write", "Processes", "Memory Management"], "content": {"text": "נתונה תוכנית C המשתמשת בזיכרון ויוצרת תהליך בן באמצעות `fork()`. יש להניח שמערכת ההפעלה מיישמת מנגנון Copy-on-Write (COW) עבור העתקת דפי זיכרון ב-`fork()`.\n\nנתון קטע הקוד הבא:\n\nהריצו את התוכנית, ונתחו את פלטה. הסבירו מדוע הפלט הוא כזה, תוך התייחסות למנגנון הזיכרון הווירטואלי ומנגנון ה-Copy-on-Write.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\n#define BUFFER_SIZE (4 * 1024 * 1024) // 4MB\n\nint main() {\n    int *buffer = (int *)malloc(BUFFER_SIZE);\n    if (buffer == NULL) {\n        perror(\"malloc failed\");\n        return 1;\n    }\n\n    // Initialize buffer\n    for (int i = 0; i < BUFFER_SIZE / sizeof(int); ++i) {\n        buffer[i] = 0; // Initialize all to 0\n    }\n\n    printf(\"Parent: Initial value at buffer[0] = %d\\n\", buffer[0]);\n\n    pid_t pid = fork();\n\n    if (pid < 0) {\n        perror(\"fork failed\");\n        free(buffer);\n        return 1;\n    } else if (pid == 0) { // Child process\n        sleep(1); // Ensure parent prints initial value first\n        printf(\"Child: Modifying buffer[0]...\\n\");\n        buffer[0] = 999; // Modify the first element\n        printf(\"Child: Value at buffer[0] after modification = %d\\n\", buffer[0]);\n        free(buffer); // Child frees its copy\n        exit(0);\n    } else { // Parent process\n        wait(NULL); // Wait for child to finish\n        printf(\"Parent: Value at buffer[0] after child modified it = %d\\n\", buffer[0]);\n        free(buffer); // Parent frees its copy\n    }\n\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכנית מתחילה באלוקציה ואיפוס של חוצץ זיכרון גדול (4MB) על ידי תהליך האב. לאחר מכן, האב מדפיס את הערך ההתחלתי של `buffer[0]`, שהוא 0.\n\nכאשר מתבצעת קריאת המערכת `fork()`, נוצר תהליך בן. מערכת ההפעלה, המשתמשת במנגנון Copy-on-Write (COW), משכפלת את מרחב הכתובות הווירטואלי של האב עבור הבן. אך בתחילה, שני התהליכים (האב והבן) חולקים את אותם דפי זיכרון פיזיים (physical pages) עבור האזור `buffer`. דפים אלו מסומנים כ-read-only בטבלאות הדפים של שני התהליכים.\n\nכאשר תהליך הבן ניגש לשנות את `buffer[0]` (בשורה `buffer[0] = 999;`), מתרחש page fault (כיוון שהדף מסומן כ-read-only). מערכת ההפעלה מזהה שזהו דף COW, ולכן היא יוצרת עותק פרטי חדש של הדף הפיזי המכיל את `buffer[0]` עבור תהליך הבן. הבן כותב את הערך 999 לעותק הפרטי שלו. הערך בזיכרון הפיזי המקורי של האב נשאר 0.\n\nהבן מדפיס את הערך 999 (מהעותק הפרטי שלו) ואז מסיים. האב ממתין לסיום הבן (`wait(NULL)`). לאחר מכן, האב מדפיס שוב את הערך של `buffer[0]` ממרחב הכתובות שלו. כיוון שהאב מעולם לא שינה את הדף בעצמו, והשינוי של הבן בוצע על עותק פרטי, הערך של `buffer[0]` במרחב האב נשאר 0.\n\nלכן, הפלט יהיה:\nParent: Initial value at buffer[0] = 0\nChild: Modifying buffer[0]...\nChild: Value at buffer[0] after modification = 999\nParent: Value at buffer[0] after child modified it = 0"}, "difficulty_estimation": "Medium", "_source_file": "0568__Virtual_Memory__CodeAnalysis__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:46:12", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Virtual Memory", "Paging", "TLB", "Cache Locality"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם גודל עמוד של 4KB. יחידת הניהול זיכרון (MMU) כוללת TLB בגודל 64 כניסות, בעל אסוציאטיביות של 4-way (כלומר, 16 סטים, כל סט מכיל 4 כניסות). נניח שהמערכת משתמשת באלגוריתם החלפת עמודים LRU. המערך הגלובלי מאותחל לאפסים לפני הפעלת הפונקציות.\n\nנתונה תוכנית C המגדירה מערך דו-ממדי גדול מאוד בגודל `SIZE x SIZE` של מספרים שלמים (int). שתי פונקציות, `funcA` ו-`funcB`, מתוכננות לעבד את המערך:\n", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define SIZE 2048 // 2048x2048 matrix\n\nint matrix[SIZE][SIZE]; // Global array, initialized to zeros\n\nvoid funcA() {\n    for (int i = 0; i < SIZE; i++) {\n        for (int j = 0; j < SIZE; j++) {\n            matrix[i][j] = i + j; // Row-major access\n        }\n    }\n}\n\nvoid funcB() {\n    for (int j = 0; j < SIZE; j++) {\n        for (int i = 0; i < SIZE; i++) {\n            matrix[i][j] = i + j; // Column-major access\n        }\n    }\n}\n\nint main() {\n    // Example usage:\n    // funcA();\n    // funcB();\n    return 0;\n}\n", "options": null}, "sub_questions": [{"id": "1.1", "text": "השוו בין `funcA` ל-`funcB` מבחינת מספר ה-Page Faults הצפוי בעת גישה למערך. נמקו את תשובתכם בהתבסס על גודל העמוד הנתון (4KB).", "code_snippet": null, "options": null}, {"id": "1.2", "text": "השוו בין `funcA` ל-`funcB` מבחינת ביצועי ה-TLB (Translation Lookaside Buffer). איזו פונקציה תסבול מפחות TLB misses? נמקו את תשובתכם בהתבסס על גודל ה-TLB הנתון (64 כניסות, 4-way associative).", "code_snippet": null, "options": null}, {"id": "1.3", "text": "כיצד שינוי בגודל העמוד ל-16KB (במקום 4KB) ישפיע על ביצועי שתי הפונקציות ביחס ל-Page Faults? נמקו את תשובתכם.", "code_snippet": null, "options": null}], "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "נתונים: \nגודל המערך: `SIZE x SIZE` = `2048 x 2048` אינטגרים.\nגודל `int`: 4 בתים.\nגודל כולל של המערך: `2048 * 2048 * 4` בתים = `16,777,216` בתים = `16 MB`.\nגודל עמוד: `4 KB` = `4096` בתים.\nמספר אינטגרים בעמוד: `4096 / 4 = 1024` אינטגרים.\nגודל שורה במערך: `2048 * 4` בתים = `8192` בתים = `8 KB`.\nTLB: 64 כניסות, 4-way associative.\n\n**1.1 השוואה בין `funcA` ל-`funcB` מבחינת Page Faults (גודל עמוד 4KB):**\n\n*   **`funcA` (גישה לפי שורות - row-major):**\n    הלולאה הפנימית (`for j`) סורקת את כל האיברים בשורה מסוימת (`matrix[i][0]` עד `matrix[i][SIZE-1]`). שורה אחת היא בגודל `8 KB`. מכיוון שגודל העמוד הוא `4 KB`, כל שורה מתפרסת על פני `8KB / 4KB = 2` עמודים. כאשר `funcA` ניגשת לשורה חדשה `i`, יש צורך לטעון את 2 העמודים המכילים את השורה לזיכרון הפיזי (אם אינם כבר שם). לאחר טעינת העמודים, כל הגישות הבאות לאיברים באותה שורה יהיו Page Hits. \n    מספר ה-Page Faults הצפוי: `SIZE` (מספר שורות) * `2` (עמודים לשורה) = `2048 * 2 = 4096` Page Faults.\n    זהו מספר נמוך יחסית ויעיל, מכיוון שהגישה היא סדרתית (sequential) בתוך העמודים, וניצול ה-Spatial Locality (עקרון המיקום המרחבי) הוא גבוה.\n\n*   **`funcB` (גישה לפי עמודות - column-major):**\n    הלולאה הפנימית (`for i`) סורקת את האיברים לאורך עמודה מסוימת (`matrix[0][j]` עד `matrix[SIZE-1][j]`). כל גישה `matrix[i][j]` ו-`matrix[i+1][j]` מרוחקות בזיכרון ב-`SIZE * sizeof(int)` בתים = `2048 * 4 = 8192` בתים (`8 KB`). מכיוון שגודל העמוד הוא `4 KB`, כל גישה כזו (`matrix[i][j]`) תהיה כמעט בוודאות על עמוד שונה מהגישה הקודמת (`matrix[i-1][j]`). לכן, עבור כל אינטגר שניגשים אליו, סביר מאוד שיתרחש Page Fault. \n    מספר ה-Page Faults הצפוי: `SIZE` (מספר עמודות) * `SIZE` (מספר שורות) = `2048 * 2048 = 4,194,304` Page Faults.\n    זהו מספר גבוה מאוד ולא יעיל, מכיוון שהגישה היא לא סדרתית בתוך העמודים, וניצול ה-Spatial Locality הוא נמוך מאוד. כל גישה גורמת ל-Jump לכתובת רחוקה בזיכרון, מה שמחייב טעינת עמוד חדש כמעט בכל פעם.\n\n**מסקנה:** `funcA` תגרום למספר נמוך בהרבה של Page Faults בהשוואה ל-`funcB`.\n\n**1.2 השוואה בין `funcA` ל-`funcB` מבחינת ביצועי TLB (גודל TLB 64 כניסות, 4-way associative):**\n\n*   **`funcA` (גישה לפי שורות):**\n    כפי שצוין, כל שורה מתפרסת על 2 עמודים, ולכן דורשת 2 כניסות ב-TLB. ה-TLB יכול להכיל 64 כניסות, מה שמספיק ל-`64 / 2 = 32` שורות בו-זמנית. כאשר `funcA` ניגשת לשורה חדשה `i`, תתרחשנה 2 TLB misses עבור 2 העמודים של השורה. לאחר מכן, הגישות לאיברים באותה שורה יהיו TLB hits. לאחר 32 שורות, ה-TLB יתמלא, וכניסות ישנות יוחלפו (לפי LRU). מכיוון שכל שורה נסרקת במלואה, ורק 2 כניסות TLB נדרשות עבורה, רוב הגישות בתוך השורה ייהנו מ-TLB hits. מספר ה-TLB misses יהיה בערך `SIZE * 2 = 4096` (כל פעם ששורה חדשה נטענת ל-TLB בפעם הראשונה).\n    זהו מספר יעיל ומינימלי ביחס למספר העמודים הכולל.\n\n*   **`funcB` (גישה לפי עמודות):**\n    כל גישה ל-`matrix[i][j]` עבור `i` משתנה, ניגשת לעמוד זיכרון שונה. לכן, כמעט כל גישה `matrix[i][j]` תגרום ל-TLB miss. ה-TLB יכול להכיל רק 64 כניסות. הפונקציה ניגשת ל-`SIZE` (`2048`) איברים בעמודה אחת, כאשר כל אחד מהם נמצא בעמוד שונה. זה אומר שלאחר 64 גישות, ה-TLB יהיה מלא וכניסות ישנות יוחלפו. הגישה הבאה תהיה לכתובת שאינה ב-TLB, ותגרום ל-TLB miss נוסף. \n    מספר ה-TLB misses הצפוי: `SIZE * SIZE = 2048 * 2048 = 4,194,304` TLB misses.\n    זהו מספר גבוה מאוד ולא יעיל, בדומה ל-Page Faults, עקב חוסר ניצול ה-Spatial Locality.\n\n**מסקנה:** `funcA` תגרום למספר נמוך בהרבה של TLB misses בהשוואה ל-`funcB`.\n\n**1.3 השפעת שינוי גודל העמוד ל-16KB על Page Faults:**\n\n*   גודל עמוד חדש: `16 KB`.\n    גודל שורה במערך: `8 KB`.\n\n*   **`funcA` (גישה לפי שורות):**\n    כעת, שורה אחת בגודל `8 KB` נכנסת במלואה לעמוד יחיד בגודל `16 KB`. לכן, כאשר `funcA` ניגשת לשורה חדשה `i`, יש צורך לטעון רק עמוד אחד לזיכרון הפיזי (אם אינו כבר שם). \n    מספר ה-Page Faults הצפוי: `SIZE` (מספר שורות) * `1` (עמוד לשורה) = `2048 * 1 = 2048` Page Faults.\n    זהו שיפור משמעותי לעומת 4KB עמודים (4096 Page Faults), מכיוון שהעמודים הגדולים יותר מנצלים טוב יותר את ה-Spatial Locality של הגישה הטורית בשורות.\n\n*   **`funcB` (גישה לפי עמודות):**\n    כל גישה `matrix[i][j]` ו-`matrix[i+1][j]` מרוחקות בזיכרון ב-`8192` בתים (`8 KB`). מכיוון שגודל העמוד החדש הוא `16 KB`, שתי גישות עוקבות אלו (`matrix[i][j]` ו-`matrix[i+1][j]`) יכולות כעת להימצא באותו עמוד פיזי (אם העמוד התחיל בכתובת מתאימה, למשל `matrix[i][j]` ב-offset 0 של העמוד ו-`matrix[i+1][j]` ב-offset `8KB` של אותו עמוד). כלומר, כל שני אינטגרים עוקבים בעמודה (לדוגמה `matrix[0][j]` ו-`matrix[1][j]`) יגרמו יחד ל-Page Fault אחד. \n    מספר ה-Page Faults הצפוי: `(SIZE * SIZE) / 2` = `(2048 * 2048) / 2 = 2,097,152` Page Faults.\n    זהו שיפור לעומת 4KB עמודים (4,194,304 Page Faults), אך עדיין מספר גבוה מאוד ולא יעיל בהשוואה ל-`funcA`. הגדלת גודל העמוד עזרה ל-`funcB` מכיוון שכעת כל עמוד מכיל יותר נתונים, ולכן יש סיכוי טוב יותר שגישות לא רציפות יפלו באותו עמוד.\n\n**מסקנה כוללת:** הגדלת גודל העמוד ל-16KB משפרת את ביצועי שתי הפונקציות מבחינת Page Faults, אך `funcA` ממשיכה להיות יעילה בהרבה מ-`funcB`, והשיפור היחסי ב-`funcA` גדול יותר (חצי מ-Page Faults, בעוד שב-`funcB` גם חצי, אך עדיין מיליונים)."}, "difficulty_estimation": "Hard", "_source_file": "0569__Virtual_Memory__CodeAnalysis__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:46:55", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Virtual Memory", "Memory Management", "Copy-on-Write", "Processes", "mmap", "fork"], "content": {"text": "נתונה תוכנית C המשתמשת בפונקציות `mmap` ו-`fork` ליצירת תהליכים וניהול זיכרון. נתחו את קטע הקוד הבא והסבירו מה יהיו הפלטים המודפסים על ידי תהליך האב ועל ידי תהליך הבן, ובאיזה סדר. התייחסו באופן מפורט למנגנון הזיכרון הווירטואלי, ובפרט למנגנון Copy-on-Write (CoW), והשפעת ה-flags ששימשו בפונקציית `mmap` על התנהגות התוכנית. הסבירו גם מדוע השינויים שכל תהליך מבצע אינם משפיעים על האחר.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <sys/mman.h>\n#include <unistd.h>\n#include <string.h>\n#include <sys/wait.h>\n\n#define MMAP_SIZE 4096 // One page size\n\nint main() {\n    char *shared_mem;\n    pid_t pid;\n\n    // 1. Map a private, anonymous memory region\n    shared_mem = mmap(NULL, MMAP_SIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);\n    if (shared_mem == MAP_FAILED) {\n        perror(\"mmap failed\");\n        return 1;\n    }\n\n    printf(\"Parent: Mapped memory at %p\\n\", shared_mem);\n\n    // 2. Parent writes initial data\n    strcpy(shared_mem, \"Hello from Parent (initial)\");\n    printf(\"Parent: Initial content: '%s'\\n\", shared_mem);\n\n    pid = fork();\n\n    if (pid == -1) {\n        perror(\"fork failed\");\n        munmap(shared_mem, MMAP_SIZE);\n        return 1;\n    } else if (pid == 0) { // Child process\n        sleep(1); // Ensure parent potentially modifies first if scheduler allows\n        printf(\"Child: Before modification, content: '%s'\\n\", shared_mem);\n        strcpy(shared_mem, \"Hello from Child (modified)\");\n        printf(\"Child: After modification, content: '%s'\\n\", shared_mem);\n        _exit(0); // Use _exit to avoid flushing parent's buffers\n    } else { // Parent process\n        // 3. Parent modifies after fork\n        strcpy(shared_mem + 10, \"PARENT_MOD\"); // Modify a part of the string\n        printf(\"Parent: After child forked and parent modified, content: '%s'\\n\", shared_mem);\n        wait(NULL); // Wait for child to finish\n        printf(\"Parent: After child finished, final content: '%s'\\n\", shared_mem);\n    }\n\n    munmap(shared_mem, MMAP_SIZE);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכנית מדגימה את התנהגות זיכרון וירטואלי במערכת הפעלה מודרנית, תוך שימוש ב-`mmap` וב-`fork` עם מנגנון Copy-on-Write (CoW).\n\n**ניתוח שלבי התוכנית והפלטים:**\n\n1.  **`mmap` עם `MAP_PRIVATE | MAP_ANONYMOUS`**: תהליך האב ממפה אזור זיכרון פרטי (private) ואנונימי בגודל עמוד זיכרון אחד (4096 בתים). `MAP_PRIVATE` מציין שהשינויים שיבוצעו לאזור זיכרון זה לא יהיו גלויים לתהליכים אחרים. `MAP_ANONYMOUS` מציין שהזיכרון אינו מגובה בקובץ כלשהו, אלא נוצר על ידי מערכת ההפעלה.\n    *   **פלט ראשון (אב):** `Parent: Mapped memory at 0x...` (כתובת הזיכרון הווירטואלי שהוקצתה). \n    *   **פלט שני (אב):** `Parent: Initial content: 'Hello from Parent (initial)'`\n\n2.  **`strcpy` ראשוני באב**: תהליך האב כותב את המחרוזת \"Hello from Parent (initial)\" לאזור הזיכרון הממופה. בשלב זה, קיים עמוד פיזי יחיד (נניח P1) המכיל את המחרוזת, ותהליך האב מצביע עליו בטבלת הדפים שלו.\n\n3.  **`fork()`**: תהליך האב יוצר תהליך בן. בשלב זה, תהליך הבן מקבל עותק של מרחב הכתובות הווירטואלי של האב. עם זאת, מכיוון שהזיכרון מופה כ-`MAP_PRIVATE`, מערכת ההפעלה לא מעתיקה באופן מיידי את כל העמודים הפיזיים. במקום זאת, היא משתמשת במנגנון **Copy-on-Write (CoW)**. גם האב וגם הבן מצביעים לאותו עמוד פיזי (P1), אך בטבלאות הדפים שלהם העמוד מסומן כ'קריאה בלבד' (read-only).\n\n4.  **שינוי באב לאחר `fork`**: תהליך האב ממשיך ומשנה חלק מהמחרוזת על ידי `strcpy(shared_mem + 10, \"PARENT_MOD\")`. מכיוון שהעמוד P1 מסומן כ'קריאה בלבד' עבור האב, ניסיון הכתיבה מפעיל **page fault**. מערכת ההפעלה יוצרת עמוד פיזי חדש (נניח P2), מעתיקה אליו את התוכן הנוכחי של P1, מעדכנת את טבלת הדפים של האב כך שתצביע על P2 (כעת עם הרשאות קריאה-כתיבה), ומאפשרת לאב להמשיך בכתיבה. כעת P2 מכיל את המחרוזת \"Hello from PARENT_MOD (initial)\". העמוד P1 נשאר ללא שינוי וממשיך להיות משותף (CoW) עם הבן.\n    *   **פלט שלישי (אב):** `Parent: After child forked and parent modified, content: 'Hello from PARENT_MOD (initial)'`\n\n5.  **קריאה בבן לפני שינוי**: תהליך הבן מבצע `sleep(1)` (כדי לאפשר לאב לכתוב לפניו) ואז מדפיס את תוכן הזיכרון. מכיוון שהבן עדיין מצביע על P1 (דרך CoW) ו-P1 מכיל את התוכן המקורי שכתב האב לפני ה-`fork`, הבן יראה את התוכן הראשוני.\n    *   **פלט ראשון (בן):** `Child: Before modification, content: 'Hello from Parent (initial)'`\n\n6.  **שינוי בבן**: תהליך הבן מנסה לכתוב `strcpy(shared_mem, \"Hello from Child (modified)\")`. בדומה לאב, גם כאן מתרחש **page fault** מכיוון שהבן מנסה לכתוב לעמוד P1 המסומן כ'קריאה בלבד' עבורו. מערכת ההפעלה יוצרת עמוד פיזי חדש (נניח P3), מעתיקה אליו את התוכן הנוכחי של P1, מעדכנת את טבלת הדפים של הבן כך שתצביע על P3 (כעת עם הרשאות קריאה-כתיבה), ומאפשרת לבן להמשיך בכתיבה. כעת P3 מכיל את המחרוזת \"Hello from Child (modified)\".\n    *   **פלט שני (בן):** `Child: After modification, content: 'Hello from Child (modified)'`\n\n7.  **סיום הבן וסיום האב**: הבן מסיים את פעולתו (`_exit(0)`). האב ממתין לבן (`wait(NULL)`) ומדפיס שוב את תוכן הזיכרון שלו. הזיכרון של האב עדיין מצביע על P2, ולכן יראה את השינויים שביצע בעצמו.\n    *   **פלט רביעי (אב):** `Parent: After child finished, final content: 'Hello from PARENT_MOD (initial)'`\n\n**סדר הפלטים המשוער (בהתאם ל-`sleep(1)`):**\n1.  `Parent: Mapped memory at 0x...`\n2.  `Parent: Initial content: 'Hello from Parent (initial)'`\n3.  `Parent: After child forked and parent modified, content: 'Hello from PARENT_MOD (initial)'`\n4.  `Child: Before modification, content: 'Hello from Parent (initial)'`\n5.  `Child: After modification, content: 'Hello from Child (modified)'`\n6.  `Parent: After child finished, final content: 'Hello from PARENT_MOD (initial)'`\n\n**מדוע השינויים אינם משפיעים על האחר:**\nמנגנון ה-Copy-on-Write (CoW) בשילוב עם `MAP_PRIVATE` מבטיח שכל תהליך מקבל עותק פרטי משלו של עמוד זיכרון ברגע שהוא מנסה לכתוב אליו. לפני הכתיבה הראשונה, שני התהליכים חולקים את אותו עמוד פיזי וירטואלי (P1). ברגע שאחד מהם מבצע כתיבה (בין אם האב ל-P2 או הבן ל-P3), מערכת ההפעלה משכפלת את העמוד הפיזי, מעדכנת את טבלת הדפים של התהליך הכותב כך שיצביע על העותק החדש, ומאפשרת את הכתיבה. התהליך השני ממשיך להצביע על העמוד המקורי (או על עותק פרטי משלו אם הוא גם כתב). כתוצאה מכך, שינויים שבוצעו על ידי תהליך אחד אינם נראים או משפיעים על תהליך אחר, למרות שהם התחילו עם אותה כתובת וירטואלית ואותו תוכן."}, "difficulty_estimation": "Hard", "_source_file": "0570__Virtual_Memory__CodeAnalysis__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:47:32", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Virtual Memory", "Page Faults", "Copy-on-Write", "Process Management"], "content": {"text": "נתונה תוכנית C המבצעת הקצאת זיכרון גדולה, מאתחלת אותה, מבצעת fork(), ולאחר מכן תהליך הבן משנה חלקים מהזיכרון שהוקצה. עליך לנתח את השימוש בזיכרון הפיזי והווירטואלי ואת מספר תקלות הדף (page faults) שיתרחשו. הקוד הבא יורץ על מערכת לינוקס עם גודל דף של 4096 בתים (PAGE_SIZE) וגודל של int הוא 4 בתים.\n\nנתח את התוכנית וציין:\n1.  כמה זיכרון וירטואלי (VAS) מוקצה למערך large_array בתהליך האב מיד לאחר שלב 1?\n2.  כמה זיכרון פיזי (RAM) נצרך על ידי המערך large_array בתהליך האב מיד לאחר שלב 2 (לפני fork)?\n3.  כמה זיכרון פיזי (RAM) נצרך על ידי המערך large_array *בסה\"כ* עבור שני התהליכים (האב והבן) מיד לאחר שלב 3 (לאחר fork ולפני כל שינוי על ידי הבן)?\n4.  כמה תקלות דף (page faults) יתרחשו *בסה\"כ* כתוצאה מהלולאה בשלב 4 בתהליך הבן?\n5.  כמה זיכרון פיזי (RAM) נצרך על ידי המערך large_array *בסה\"כ* עבור שני התהליכים (האב והבן) לאחר שלב 4 (לאחר שהבן סיים את השינויים)?\n\nבכל סעיף יש לפרט את החישוב ולהסביר את התשובה בהתבסס על מנגנוני זיכרון וירטואלי, כולל העתקה בכתיבה (Copy-on-Write).", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <string.h>\n\n#define GB (1024 * 1024 * 1024)\n#define NUM_INTS (GB / sizeof(int))\n#define PAGE_SIZE 4096 // Common page size\n\nint main() {\n    int *large_array;\n    pid_t pid;\n\n    // שלב 1: הקצאת זיכרון\n    printf(\"Allocating a large array...\\n\");\n    large_array = (int *)malloc(NUM_INTS * sizeof(int));\n    if (large_array == NULL) {\n        perror(\"malloc failed\");\n        return 1;\n    }\n\n    // שלב 2: אתחול המערך\n    // לולאה זו מבטיחה שכל הדפים של המערך יוכנסו לזיכרון הפיזי.\n    printf(\"Initializing array to touch all pages...\\n\");\n    for (long i = 0; i < NUM_INTS; ++i) {\n        large_array[i] = i;\n    }\n    printf(\"Array initialization complete.\\n\");\n\n    // שלב 3: יצירת תהליך בן\n    pid = fork();\n\n    if (pid < 0) {\n        perror(\"fork failed\");\n        return 1;\n    } else if (pid == 0) { // תהליך הבן\n        printf(\"Child process (PID %d) started.\\n\", getpid());\n        // שלב 4: שינוי במערך על ידי הבן\n        // הבן משנה מספר שלם אחד בכל דף, מה שיפעיל CoW עבור כל דף כזה.\n        for (long i = 0; i < NUM_INTS; i += (PAGE_SIZE / sizeof(int))) {\n            large_array[i] = -1; // שינוי כדי להפעיל CoW\n        }\n        printf(\"Child process (PID %d) finished modifications.\\n\", getpid());\n        exit(0);\n    } else { // תהליך האב\n        printf(\"Parent process (PID %d) forked child (PID %d).\\n\", getpid(), pid);\n        printf(\"Parent waiting for child...\\n\");\n        wait(NULL); // המתן שהבן יסיים\n        printf(\"Child finished. Parent exiting.\\n\");\n    }\n\n    free(large_array);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ניתוח התוכנית:\nנתונים:\n*   גודל המערך large_array: 1GB = 1024 * 1024 * 1024 בתים.\n*   גודל int: 4 בתים.\n*   מספר האיברים במערך: NUM_INTS = 1GB / 4B = 256 * 1024 * 1024 איברים.\n*   גודל דף (PAGE_SIZE): 4096 בתים.\n*   מספר הדפים הדרושים למערך: 1GB / 4096B = 262,144 דפים.\n\n1.  **זיכרון וירטואלי (VAS) לאחר שלב 1 (הקצאה)**:\n    מיד לאחר הקצאת הזיכרון באמצעות malloc, מערכת ההפעלה מקצה לתהליך האב מרחב כתובות וירטואלי של 1GB עבור large_array. בשלב זה, לרוב לא מוקצה זיכרון פיזי בפועל, אלא רק מופרש מקום במרחב הכתובות הווירטואלי.\n    **תשובה: 1GB**.\n\n2.  **זיכרון פיזי (RAM) לאחר שלב 2 (אתחול)**:\n    לולאת האתחול for (long i = 0; i < NUM_INTS; ++i) { large_array[i] = i; } גורמת לנגיעה (כתיבה) בכל איבר במערך. כתוצאה מכך, כל דף וירטואלי המכיל חלק מהמערך יקבל תקלת דף (page fault) בפעם הראשונה שייגש אליו. מערכת ההפעלה תאלץ להביא את הדף הזה לזיכרון הפיזי. מכיוון שכל איברי המערך נכתבים, כל הדפים המרכיבים את המערך (262,144 דפים) יובאו לזיכרון הפיזי.\n    **תשובה: 1GB**.\n\n3.  **זיכרון פיזי (RAM) לאחר שלב 3 (fork), לפני שינויים**: \n    כאשר מתבצעת קריאה ל-fork(), תהליך הבן נוצר כמעט כעותק זהה של תהליך האב. אולם, במערכות הפעלה מודרניות (כמו לינוקס) מתבצע שימוש במנגנון העתקה בכתיבה (Copy-on-Write - CoW) עבור דפי זיכרון. משמעות הדבר היא שבתחילה, האב והבן חולקים את אותם דפים פיזיים עבור הזיכרון המשותף (כמו large_array). דפים חדשים יוקצו רק כאשר אחד מהתהליכים ינסה לשנות דף שמשותף לשניהם. לכן, בשלב זה, למרות שיש שני תהליכים, הזיכרון הפיזי הכולל שנצרך על ידי המערך עדיין נשאר זהה.\n    **תשובה: 1GB**.\n\n4.  **תקלות דף (page faults) כתוצאה משלב 4 (שינוי הבן)**:\n    הלולאה בתהליך הבן משנה איבר אחד בכל דף וירטואלי: for (long i = 0; i < NUM_INTS; i += (PAGE_SIZE / sizeof(int))). \n    *   PAGE_SIZE / sizeof(int) = 4096 / 4 = 1024. זהו מספר האיברים בתוך דף בודד.\n    *   הלולאה קופצת ב-1024 איברים בכל איטרציה, כלומר היא נכנסת לדף וירטואלי חדש בכל פעם. \n    *   מספר האיטרציות (ומכאן מספר הדפים שהבן ישנה) הוא: NUM_INTS / (PAGE_SIZE / sizeof(int)) = (256 * 1024 * 1024) / 1024 = 256 * 1024 = 262,144.\n    כל כתיבה לדף וירטואלי שעדיין משותף (במצב CoW) תגרום לתקלת דף. מערכת ההפעלה תייצר עותק פרטי של הדף הפיזי עבור תהליך הבן, תמפה אותו למרחב הכתובות של הבן, והבן יוכל לשנות אותו באופן עצמאי. מכיוון שהבן משנה איבר בכל אחד מ-262,144 הדפים המרכיבים את המערך, כל אחד משינויים אלה יפעיל תקלת דף ויגרום ליצירת עותק פרטי של הדף.\n    **תשובה: 262,144 תקלות דף**.\n\n5.  **זיכרון פיזי (RAM) לאחר שלב 4 (לאחר שינויי הבן)**:\n    לאחר שהבן סיים את השינויים, כל דף שהבן שינה (כלומר, כל 262,144 הדפים) קיבל עותק פיזי נפרד בזיכרון. \n    *   האב ממשיך להשתמש ב-1GB המקורי של הדפים הפיזיים.\n    *   הבן יצר 1GB של עותקים פיזיים משלו (262,144 דפים חדשים). \n    לכן, סך הזיכרון הפיזי שנצרך על ידי המערך עבור שני התהליכים יהיה הסכום של הזיכרון הפיזי של האב והבן.\n    **תשובה: 2GB** (1GB לאב + 1GB לבן)."}, "difficulty_estimation": "Hard", "_source_file": "0571__Virtual_Memory__CodeAnalysis__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:48:06", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Virtual Memory", "Copy-on-Write", "Page Faults", "fork()"], "content": {"text": "נתון קטע קוד ב-C המשתמש במערך גלובלי גדול. הקוד מבצע אתחול של המערך בתהליך האב, ולאחר מכן מבצע `fork()`. גם תהליך האב וגם תהליך הבן ניגשים ומשנים חלקים שונים של המערך.\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <string.h>\n\n#define PAGE_SIZE 4096 // גודל עמוד זיכרון: 4KB\n#define ARRAY_SIZE (PAGE_SIZE * 10) // גודל המערך: 10 עמודים\n\nint global_array[ARRAY_SIZE / sizeof(int)]; // מערך גלובלי של מספרים שלמים\n\nint main() {\n    // אתחול המערך בתהליך האב\n    for (int i = 0; i < ARRAY_SIZE / sizeof(int); ++i) {\n        global_array[i] = i;\n    }\n\n    pid_t pid = fork();\n\n    if (pid < 0) {\n        perror(\"fork failed\");\n        return 1;\n    } else if (pid == 0) { // תהליך הבן\n        printf(\"Child process (PID: %d) modifying memory...\\n\", getpid());\n        // הבן משנה את חציו הראשון של המערך\n        for (int i = 0; i < (ARRAY_SIZE / sizeof(int)) / 2; ++i) {\n            global_array[i] = -i;\n        }\n        printf(\"Child finished modifications.\\n\");\n    } else { // תהליך האב\n        printf(\"Parent process (PID: %d) modifying memory...\\n\", getpid());\n        // האב משנה את חציו השני של המערך\n        for (int i = (ARRAY_SIZE / sizeof(int)) / 2; i < ARRAY_SIZE / sizeof(int); ++i) {\n            global_array[i] = i * 2;\n        }\n        printf(\"Parent finished modifications.\\n\");\n        wait(NULL); // המתן לבן שיסיים\n        printf(\"Child exited. Parent exiting.\\n\");\n    }\n\n    return 0;\n}\n```\n\nבהתבסס על הקוד לעיל ובהנחה שמערכת ההפעלה משתמשת במנגנון זיכרון וירטואלי עם Copy-on-Write (CoW) עבור `fork()`:\n\n1.  כמה עמודי זיכרון פיזיים (physical pages) יוקצו בסך הכל עבור המערך `global_array` על ידי שני התהליכים (האב והבן) לאחר ששניהם סיימו את פעולות השינוי שלהם?\n2.  כמה Page Faults (page faults) יתרחשו בסך הכל כתוצאה מגישה ושינוי המערך `global_array` על ידי שני התהליכים? (התייחסו רק ל-page faults שנובעים מגישה ראשונית לדפים או מ-CoW).\n\nנניח שגודל `int` הוא 4 בתים, ושהמערך `global_array` מתחיל בכתובת המיושרת לגבול עמוד זיכרון.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <string.h>\n\n#define PAGE_SIZE 4096 // גודל עמוד זיכרון: 4KB\n#define ARRAY_SIZE (PAGE_SIZE * 10) // גודל המערך: 10 עמודים\n\nint global_array[ARRAY_SIZE / sizeof(int)]; // מערך גלובלי של מספרים שלמים\n\nint main() {\n    // אתחול המערך בתהליך האב\n    for (int i = 0; i < ARRAY_SIZE / sizeof(int); ++i) {\n        global_array[i] = i;\n    }\n\n    pid_t pid = fork();\n\n    if (pid < 0) {\n        perror(\"fork failed\");\n        return 1;\n    } else if (pid == 0) { // תהליך הבן\n        printf(\"Child process (PID: %d) modifying memory...\\n\", getpid());\n        // הבן משנה את חציו הראשון של המערך\n        for (int i = 0; i < (ARRAY_SIZE / sizeof(int)) / 2; ++i) {\n            global_array[i] = -i;\n        }\n        printf(\"Child finished modifications.\\n\");\n    }\n\n    else { // תהליך האב\n        printf(\"Parent process (PID: %d) modifying memory...\\n\", getpid());\n        // האב משנה את חציו השני של המערך\n        for (int i = (ARRAY_SIZE / sizeof(int)) / 2; i < ARRAY_SIZE / sizeof(int); ++i) {\n            global_array[i] = i * 2;\n        }\n        printf(\"Parent finished modifications.\\n\");\n        wait(NULL); // המתן לבן שיסיים\n        printf(\"Child exited. Parent exiting.\\n\");\n    }\n\n    return 0;\n}\n", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "**הסבר מפורט:**\n\n1.  **אתחול המערך בתהליך האב:**\n    *   הלולאה הראשונה בתהליך האב מאתחלת את כל 10 העמודים של המערך `global_array`.\n    *   כאשר תהליך האב ניגש לראשונה לכל עמוד זיכרון (וירטואלי) בתוך המערך, מתרחש Page Fault. מערכת ההפעלה מקצה עמוד זיכרון פיזי עבור העמוד הוירטואלי הזה, מאתחלת אותו (בדרך כלל מאפסת אותו אם לא הוקצה קודם לכן, ואז התהליך כותב לתוכו), ומעדכנת את טבלת הדפים של האב.\n    *   **מספר עמודים פיזיים שהוקצו בשלב זה:** 10 עמודים.\n    *   **מספר Page Faults בשלב זה:** 10 (אלו Page Faults ראשוניים של גישה).\n\n2.  **קריאה ל-`fork()`:**\n    *   כאשר `fork()` נקרא, תהליך הבן מקבל עותק של מרחב הכתובות הוירטואלי של האב.\n    *   בזכות מנגנון Copy-on-Write (CoW), עמודי הזיכרון הפיזיים שבהם נמצא המערך `global_array` **משותפים** בין האב לבן. טבלאות הדפים של האב והבן מצביעות לאותם עמודים פיזיים, אך הם מסומנים כ\"קריאה בלבד\" (read-only). בשלב זה, **לא מוקצים עמודי זיכרון פיזיים חדשים**.\n    *   **מספר עמודים פיזיים שהוקצו בשלב זה (נוספים):** 0.\n    *   **מספר Page Faults בשלב זה:** 0 (ה-fork עצמו לא גורם ל-page faults על נתוני המשתמש בשל CoW).\n\n3.  **שינוי המערך על ידי תהליך הבן:**\n    *   תהליך הבן משנה את חציו הראשון של המערך (`global_array[0]` עד `global_array[ARRAY_SIZE / (2 * sizeof(int)) - 1]`).\n    *   חצי המערך הזה משתרע על פני 5 עמודים פיזיים (כי `ARRAY_SIZE / 2` בתים חולקו ב-`PAGE_SIZE` בתים לעמוד).\n    *   בכל פעם שהבן מנסה לכתוב לעמוד זיכרון (וירטואלי) שעדיין משותף עם האב ומסומן כ-read-only, מתרחש Page Fault מסוג CoW.\n    *   מערכת ההפעלה מיירטת את ה-Page Fault, מקצה עמוד זיכרון פיזי **חדש** עבור הבן, מעתיקה אליו את התוכן המקורי של העמוד המשותף, מעדכנת את טבלת הדפים של הבן כך שתצביע לעמוד הפיזי החדש, ומסמנת אותו כ-writable עבור הבן. העמוד הפיזי המקורי נשאר עבור האב.\n    *   **מספר עמודים פיזיים שהוקצו בשלב זה (נוספים):** 5 עמודים (אחד עבור כל עמוד בחצי הראשון של המערך).\n    *   **מספר Page Faults בשלב זה:** 5 (אלו CoW Page Faults).\n\n4.  **שינוי המערך על ידי תהליך האב:**\n    *   תהליך האב משנה את חציו השני של המערך (`global_array[ARRAY_SIZE / (2 * sizeof(int))]` עד `global_array[ARRAY_SIZE / sizeof(int) - 1]`).\n    *   גם חצי המערך הזה משתרע על פני 5 עמודים פיזיים.\n    *   בדומה לבן, בכל פעם שהאב מנסה לכתוב לעמוד זיכרון (וירטואלי) שעדיין משותף עם הבן ומסומן כ-read-only, מתרחש Page Fault מסוג CoW.\n    *   מערכת ההפעלה מקצה עמוד זיכרון פיזי **חדש** עבור האב, מעתיקה אליו את התוכן המקורי, מעדכנת את טבלת הדפים של האב, ומסמנת אותו כ-writable. העמוד הפיזי המקורי (שעדיין יכול להיות משותף עם הבן אם הבן לא שינה אותו, אבל במקרה זה הבן שינה את החצי השני אז העמוד המקורי נשאר לאב) נשאר עבור הבן (אם רלוונטי) או משוחרר אם אין לו יותר מצביעים. במקרה זה, העמודים בחצי השני לא שונו על ידי הבן, אז הם עדיין מצביעים לאותם עמודים פיזיים שהאב יצר בהתחלה. לכן, עבור כל אחד מ-5 העמודים הללו, האב יגרום ל-CoW page fault, ויקבל עותק חדש.\n    *   **מספר עמודים פיזיים שהוקצו בשלב זה (נוספים):** 5 עמודים (אחד עבור כל עמוד בחצי השני של המערך).\n    *   **מספר Page Faults בשלב זה:** 5 (אלו CoW Page Faults).\n\n**סיכום:**\n\n*   **סה\"כ עמודי זיכרון פיזיים:**\n    *   10 עמודים מהאתחול הראשוני על ידי האב.\n    *   5 עמודים נוספים עבור הבן (עבור חציו הראשון).\n    *   5 עמודים נוספים עבור האב (עבור חציו השני).\n    *   סה\"כ = 10 + 5 + 5 = **20 עמודי זיכרון פיזיים**.\n    *   בסיום, לכל אחד מהתהליכים (האב והבן) יהיה עותק משלו של המערך `global_array` בזיכרון הפיזי, כאשר כל עותק תופס 10 עמודים.\n\n*   **סה\"כ Page Faults:**\n    *   10 Page Faults במהלך אתחול המערך על ידי האב.\n    *   5 Page Faults מסוג CoW בעת שינוי הבן.\n    *   5 Page Faults מסוג CoW בעת שינוי האב.\n    *   סה\"כ = 10 + 5 + 5 = **20 Page Faults**."}, "difficulty_estimation": "Hard", "_source_file": "0572__Virtual_Memory__CodeAnalysis__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:48:40", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Virtual Memory", "Paging", "TLB", "Locality of Reference", "Performance"], "content": {"text": "נתונה תוכנית C המבצעת גישה למטריצה גדולה בזיכרון. המערכת פועלת עם זיכרון וירטואלי בעל המאפיינים הבאים:\n*   גודל עמוד (Page Size): 4KB (4096 בתים).\n*   גודל TLB (Translation Lookaside Buffer): 4 כניסות (entries). ה-TLB משתמש באסטרטגיית החלפה LRU (Least Recently Used).\n*   גודל הזיכרון הפיזי: גדול מספיק כדי להכיל את כל המטריצה.\n*   גודל int: 4 בתים.\n\nהמטריצה מוגדרת כ- `int matrix[ARRAY_DIM][ARRAY_DIM]` כאשר `ARRAY_DIM` הוא 1024.\nלצורך הניתוח, הניחו כי בתחילת כל לולאת גישה (לפני לולאת ה-for החיצונית הראשונה עבור כל דפוס גישה), ה-TLB ריק וכל דפי המטריצה אינם נמצאים בזיכרון הפיזי.\n\nנתח את קטע הקוד הבא וענה על השאלות:", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define ARRAY_DIM 1024\n#define INT_SIZE 4 // bytes\n\nint main() {\n    int (*matrix)[ARRAY_DIM] = malloc(ARRAY_DIM * ARRAY_DIM * INT_SIZE);\n\n    if (matrix == NULL) {\n        perror(\"malloc failed\");\n        return 1;\n    }\n\n    // Access pattern 1: Row-major\n    printf(\"Accessing in row-major order...\\n\");\n    for (int i = 0; i < ARRAY_DIM; ++i) {\n        for (int j = 0; j < ARRAY_DIM; ++j) {\n            matrix[i][j] = i * ARRAY_DIM + j;\n        }\n    }\n\n    // Access pattern 2: Column-major\n    printf(\"Accessing in column-major order...\\n\");\n    for (int j = 0; j < ARRAY_DIM; ++j) {\n        for (int i = 0; i < ARRAY_DIM; ++i) {\n            matrix[i][j] = i * ARRAY_DIM + j;\n        }\n    }\n\n    free(matrix);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "101.1", "text": "כמה דפים (pages) דורשת המטריצה כולה?", "code_snippet": null, "options": null}, {"id": "101.2", "text": "עבור \"Access pattern 1\" (גישה לפי שורות):\nא. כמה Page Faults יתרחשו בסך הכל?\nב. כמה TLB Misses יתרחשו בסך הכל?", "code_snippet": null, "options": null}, {"id": "101.3", "text": "עבור \"Access pattern 2\" (גישה לפי עמודות):\nא. כמה Page Faults יתרחשו בסך הכל?\nב. כמה TLB Misses יתרחשו בסך הכל?", "code_snippet": null, "options": null}, {"id": "101.4", "text": "הסבר בקצרה מדוע יש הבדל משמעותי במספר ה-Page Faults וה-TLB Misses בין שני דפוסי הגישה, וכיצד ניתן לייעל את הביצועים במקרים כאלה.", "code_snippet": null, "options": null}], "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "**חישובים ופתרונות:**\n\n**1. כמה דפים (pages) דורשת המטריצה כולה?**\n*   גודל המטריצה: `ARRAY_DIM * ARRAY_DIM * INT_SIZE = 1024 * 1024 * 4 בתים = 4,194,304 בתים = 4MB`.\n*   גודל עמוד: `4KB = 4096 בתים`.\n*   מספר הדפים הנדרש: `4,194,304 / 4096 = 1024 דפים`.\n\n**2. עבור \"Access pattern 1\" (גישה לפי שורות):**\n*   כל שורה במטריצה היא בגודל `ARRAY_DIM * INT_SIZE = 1024 * 4 = 4096 בתים`. זהו בדיוק גודל של עמוד אחד.\n*   ישנן 1024 שורות, כלומר 1024 דפים שונים, כאשר כל שורה תופסת דף בודד.\n\nא. **כמה Page Faults יתרחשו בסך הכל?**\n    *   בתחילת כל לולאת `for` חיצונית, כל הדפים אינם בזיכרון הפיזי.\n    *   כאשר ניגשים לאיבר הראשון בכל שורה (`matrix[i][0]`), מתרחש Page Fault מכיוון שהדף של השורה הזו אינו בזיכרון. פעולה זו מכניסה את כל הדף (השורה) לזיכרון הפיזי.\n    *   לאחר מכן, כל הגישות הבאות לאותה שורה (`matrix[i][j]` עבור `j > 0`) יהיו Page Hits, מכיוון שהדף כבר נמצא בזיכרון.\n    *   מכיוון שיש 1024 שורות, וכל שורה נטענת פעם אחת, סך הכל יתרחשו **1024 Page Faults**.\n\nב. **כמה TLB Misses יתרחשו בסך הכל?**\n    *   ה-TLB ריק בתחילה וגודלו 4 כניסות. הוא משתמש באסטרטגיית LRU.\n    *   עבור כל שורה `i`:\n        *   הגישה הראשונה לאיבר בשורה (`matrix[i][0]`) תגרום ל-TLB Miss. המיפוי של דף `i` יוכנס ל-TLB (או יחליף את כניסת ה-LRU אם ה-TLB מלא).\n        *   כל שאר הגישות לאיברי אותה שורה (`matrix[i][j]` עבור `j > 0`) יהיו TLB Hits, מכיוון שהמיפוי של דף `i` נמצא כעת ב-TLB והוא ה-MRU (Most Recently Used).\n    *   מכיוון שיש 1024 שורות, וכל שורה גורמת ל-TLB Miss אחד (כאשר ניגשים אליה לראשונה), סך הכל יתרחשו **1024 TLB Misses**.\n\n**3. עבור \"Access pattern 2\" (גישה לפי עמודות):**\n*   הלולאה החיצונית עוברת על עמודות (`j`), והלולאה הפנימית עוברת על שורות (`i`).\n*   גישה ל-`matrix[i][j]` עבור `j` קבוע ו-`i` משתנה, פירושה גישה לאיברים שנמצאים בדפים שונים לחלוטין. לדוגמה, `matrix[0][0]` נמצא בדף 0, `matrix[1][0]` בדף 1, וכן הלאה, עד `matrix[1023][0]` שנמצא בדף 1023.\n\nא. **כמה Page Faults יתרחשו בסך הכל?**\n    *   בתחילת כל לולאת `for` חיצונית, כל הדפים אינם בזיכרון הפיזי.\n    *   כאשר `j=0` (העמודה הראשונה):\n        *   הגישה ל-`matrix[0][0]` תגרום ל-Page Fault ותטען את דף 0.\n        *   הגישה ל-`matrix[1][0]` תגרום ל-Page Fault ותטען את דף 1.\n        *   ...וכן הלאה, עד הגישה ל-`matrix[1023][0]` שתגרום ל-Page Fault ותטען את דף 1023.\n        *   בסך הכל, עבור העמודה הראשונה, יטענו 1024 דפים שונים, ולכן יתרחשו 1024 Page Faults.\n    *   מכיוון שהזיכרון הפיזי גדול מספיק כדי להכיל את כל המטריצה (כל 1024 הדפים), לאחר העמודה הראשונה, כל דפי המטריצה כבר נמצאים בזיכרון הפיזי.\n    *   לכן, עבור כל העמודות הבאות (`j > 0`), לא יתרחשו Page Faults נוספים.\n    *   סך הכל יתרחשו **1024 Page Faults**.\n\nב. **כמה TLB Misses יתרחשו בסך הכל?**\n    *   ה-TLB ריק בתחילה וגודלו 4 כניסות. הוא משתמש באסטרטגיית LRU.\n    *   עבור `j=0` (העמודה הראשונה):\n        *   הגישה ל-`matrix[0][0]` גורמת ל-TLB Miss (דף 0 נכנס). TLB: {P0}\n        *   הגישה ל-`matrix[1][0]` גורמת ל-TLB Miss (דף 1 נכנס). TLB: {P0, P1}\n        *   הגישה ל-`matrix[2][0]` גורמת ל-TLB Miss (דף 2 נכנס). TLB: {P0, P1, P2}\n        *   הגישה ל-`matrix[3][0]` גורמת ל-TLB Miss (דף 3 נכנס). TLB: {P0, P1, P2, P3}\n        *   הגישה ל-`matrix[4][0]` גורמת ל-TLB Miss (דף 0, שהוא ה-LRU, יוצא; דף 4 נכנס). TLB: {P1, P2, P3, P4}\n        *   כיוון שאנו ניגשים ברצף ל-1024 דפים שונים (`P0, P1, ..., P1023`) וה-TLB יכול להכיל רק 4 כניסות, כל גישה לאיבר תגרום ל-TLB Miss מכיוון שהמיפוי לדף הדרוש לא יהיה ב-TLB (הוא כבר הוחלף).\n        *   לכן, עבור העמודה הראשונה, יתרחשו `1024 TLB Misses`.\n    *   עבור `j=1` (העמודה השנייה):\n        *   שוב, אנו ניגשים ברצף לדפים `P0, P1, ..., P1023`. גם כאן, כל גישה תגרום ל-TLB Miss מאותה הסיבה שה-TLB קטן מדי כדי להכיל את כל המיפויים הרלוונטיים, ומיפויים ישנים יוחלפו לפני שנגיע אליהם שוב.\n        *   לכן, עבור העמודה השנייה, יתרחשו `1024 TLB Misses`.\n    *   דפוס זה חוזר על עצמו עבור כל 1024 העמודות.\n    *   סך הכל יתרחשו `ARRAY_DIM * ARRAY_DIM = 1024 * 1024 = 1,048,576 TLB Misses`.\n\n**4. הסבר בקצרה מדוע יש הבדל משמעותי במספר ה-Page Faults וה-TLB Misses בין שני דפוסי הגישה, וכיצד ניתן לייעל את הביצועים במקרים כאלה.**\n\n**הבדלים עיקריים וסיבותיהם:**\n*   **עקרון המיקום (Locality of Reference):** השוני המשמעותי נובע ממידת הניצול של עקרון המיקום, ובפרט מיקום מרחבי (Spatial Locality).\n    *   **גישה לפי שורות (Row-major):** ב-C, מטריצות מאוחסנות בזיכרון ב\"סדר שורה ראשי\" (row-major order), כלומר איברי שורה רצופים מאוחסנים באופן רציף בזיכרון. כאשר ניגשים לשורה, איברים סמוכים נטענים יחד באותו דף זיכרון. לכן, לאחר ה-Page Fault וה-TLB Miss הראשוני לטעינת דף של שורה, כל הגישות הבאות לאיברים באותה שורה יהיו Page Hits ו-TLB Hits (עד שהדף יוחלף או ה-TLB יתמלא ויחליף את הכניסה). זהו ניצול יעיל של מיקום מרחבי.\n    *   **גישה לפי עמודות (Column-major):** כאשר ניגשים לעמודה, אנו עוברים בין איברים שאינם סמוכים בזיכרון, אלא מרוחקים זה מזה בגודל שורה שלמה (4096 בתים). המשמעות היא שכל גישה לאיבר בתוך אותה עמודה (למעט 4 הגישות הראשונות שייכנסו ל-TLB) תהיה לדף זיכרון אחר, וכמעט תמיד תגרום ל-TLB Miss (מכיוון שה-TLB קטן מאוד ולא יכול להכיל את כל המיפויים הרלוונטיים). למרות שכל הדפים נטענים לזיכרון הפיזי פעם אחת (ב-1024 Page Faults), הגישה החוזרת אליהם דרך ה-TLB היא לא יעילה בגלל חוסר מיקום מרחבי, מה שמוביל למספר עצום של TLB Misses.\n\n**ייעול ביצועים:**\n*   **התאמה למבנה הנתונים:** תמיד עדיף לגשת לנתונים באופן התואם לאופן אחסונם בזיכרון. במקרה של מטריצות ב-C, גישה לפי שורות עדיפה בהרבה על גישה לפי עמודות.\n*   **שיפור מיקום מרחבי וזמני (Spatial and Temporal Locality):** ארגון מחדש של אלגוריתמים ומבני נתונים כך שגישות לזיכרון יהיו קרובות ככל האפשר בזמן ובמרחב.\n*   **טכניקת \"חסימה\" או \"אריחים\" (Blocking/Tiling):** עבור אלגוריתמים (כמו כפל מטריצות) הדורשים גישה שאינה תואמת למיקום בזיכרון, ניתן לחלק את המטריצה ל\"בלוקים\" קטנים (אריחים) ולעבד כל בלוק בנפרד. בלוקים אלה יהיו קטנים מספיק כדי להיכנס כולם לזיכרון המטמון (cache) או ל-TLB, מה שימזער את מספר ה-Page Faults וה-TLB Misses. לדוגמה, במקום לעבד עמודה שלמה, נעבד רק חלק קטן מעמודה שמתאים בגודלו ל-TLB/cache, ואז נעבור לחלק קטן של עמודה הבאה, וכן הלאה, עד שנסיים בלוק שלם."}, "difficulty_estimation": "Hard", "_source_file": "0573__Virtual_Memory__CodeAnalysis__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:49:33", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Virtual Memory", "Paging", "Page Faults", "Memory Access Patterns", "Page Replacement Policies"], "content": {"text": "נתון קוד C המטפל במערך דו-ממדי גדול מאוד. המערך מאותחל ל-0 ונמצא בזיכרון וירטואלי. גודל כל אלמנט במערך הוא 4 בתים (int). נניח כי גודל דף זיכרון הוא 4KB, וכי ישנם 16 פריימים פיזיים פנויים בלבד בזיכרון הפיזי עבור נתוני התוכנית (כלומר, הזיכרון הפיזי קטן משמעותית מגודל המערך). מדיניות החלפת הדפים היא LRU (Least Recently Used).\n\nהמערך מוגדר כ: `int arr[1024][1024];` ופרוס בזיכרון בסדר שורות (row-major order).\n\nכמה כשלים (Page Faults) יתרחשו בסך הכל עבור כל אחד מקטעי הקוד הבאים? נמקו את תשובתכם.\n\n**קטע קוד א':**", "code_snippet": "int arr[1024][1024];\n// ... initialization of arr to 0 (not shown) ...\n\nfor (int i = 0; i < 1024; i++) {\n    for (int j = 0; j < 1024; j++) {\n        arr[i][j]++;\n    }\n}", "options": null}, "sub_questions": [{"id": "101.1", "text": "כמה כשלים (Page Faults) יתרחשו עבור קטע קוד א'?", "code_snippet": null, "options": null}, {"id": "101.2", "text": "כמה כשלים (Page Faults) יתרחשו עבור קטע קוד ב'?", "code_snippet": "int arr[1024][1024];\n// ... initialization of arr to 0 (not shown) ...\n\nfor (int j = 0; j < 1024; j++) {\n    for (int i = 0; i < 1024; i++) {\n        arr[i][j]++;\n    }\n}", "options": null}], "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "נתוני השאלה:\n- גודל מערך: `1024 x 1024` איברים. כל איבר הוא `int` (4 בתים).\n- גודל כולל של המערך: `1024 * 1024 * 4 = 4,194,304` בתים = `4MB`.\n- גודל דף זיכרון: `4KB`.\n- מספר איברים בדף: `4KB / 4B = 1024` איברים.\n- מספר דפים כולל למערך: `4MB / 4KB = 1024` דפים.\n- מספר פריימים פיזיים זמינים: `16` פריימים.\n- מדיניות החלפת דפים: LRU.\n\n**ניתוח קטע קוד א' (גישה לפי שורות - Row-major access):**\n```c\nfor (int i = 0; i < 1024; i++) {\n    for (int j = 0; j < 1024; j++) {\n        arr[i][j]++;\n    }\n}\n```\nהמערך פרוס בזיכרון בסדר שורות (row-major order), כלומר `arr[0][0], arr[0][1], ..., arr[0][1023], arr[1][0], ...`.\nכל שורה במערך (`arr[i]`) מכילה `1024` איברים, אשר תופסים בדיוק `1024 * 4 = 4096` בתים, כלומר שורה שלמה נכנסת לדף זיכרון אחד בדיוק.\n\nבלולאה החיצונית אנו עוברים על השורות (`i`). בכל איטרציה של הלולאה החיצונית (כלומר, עבור כל שורה חדשה `i`), אנו ניגשים לאיבר הראשון בשורה (`arr[i][0]`). מכיוון שכל שורה נמצאת בדף זיכרון נפרד, ובהנחה שדף השורה הקודמת כבר יצא מהזיכרון הפיזי (בגלל מגבלת 16 הפריימים), תתרחש תקלת דף. לאחר שהדף של השורה `i` נטען לזיכרון הפיזי, כל הגישות הבאות לאיברים באותה שורה (`arr[i][1]` עד `arr[i][1023]`) לא יגרמו לתקלות דף נוספות, שכן כולם נמצאים באותו דף שכבר נטען.\n\nמכיוון שיש `1024` שורות, וכל גישה לשורה חדשה (לאחר שתקלה בדף הקודם כבר הוציאה את דף השורה מהזיכרון הפיזי) גורמת לתקלת דף אחת, המספר הכולל של תקלות דף יהיה `1024`.\n\n**תשובה 101.1: 1024 כשלים.**\n\n**ניתוח קטע קוד ב' (גישה לפי עמודות - Column-major access):**\n```c\nfor (int j = 0; j < 1024; j++) {\n    for (int i = 0; i < 1024; i++) {\n        arr[i][j]++;\n    }\n}\n```\nבלולאה החיצונית אנו עוברים על העמודות (`j`). בלולאה הפנימית אנו עוברים על השורות (`i`) עבור עמודה קבועה `j`.\n\nעבור `j=0` (העמודה הראשונה):\n- `arr[0][0]` נגיש. נגרמת תקלת דף עבור הדף המכיל את `arr[0]` (נכנה אותו `P_0`). `P_0` נטען לזיכרון הפיזי.\n- `arr[1][0]` נגיש. נגרמת תקלת דף עבור הדף המכיל את `arr[1]` (`P_1`). `P_1` נטען לזיכרון הפיזי.\n- ...\n- `arr[15][0]` נגיש. נגרמת תקלת דף עבור הדף המכיל את `arr[15]` (`P_15`). `P_15` נטען לזיכרון הפיזי.\nבשלב זה, `16` תקלות דף התרחשו, וכל `16` הפריימים בזיכרון הפיזי מלאים בדפים `P_0` עד `P_15`.\n- `arr[16][0]` נגיש. נגרמת תקלת דף עבור הדף המכיל את `arr[16]` (`P_16`). מכיוון שהזיכרון מלא ויש 16 פריימים בלבד, מדיניות LRU תוציא את הדף הכי פחות בשימוש, שהוא `P_0` (הדף של `arr[0]`). `P_16` נטען במקומו.\n- תהליך זה ממשיך. עבור כל `arr[i][0]` כאשר `i` הוא בין `0` ל-`1023`, תתרחש תקלת דף. בכל פעם, דף חדש נטען ודף ישן יותר (לפי LRU) מוצא. מכיוון שכל האיברים בעמודה שונים ונמצאים בדפים שונים, וקיימים `1024` איברים בעמודה, נקבל `1024` תקלות דף עבור העמודה הראשונה (`j=0`). בסיום עיבוד העמודה הראשונה, כל `1024` הדפים של המערך נטענו לזיכרון הפיזי לפחות פעם אחת, ו-`P_1023` עד `P_1023-15` הם הדפים האחרונים שנטענו ונמצאים בזיכרון הפיזי.\n\nעבור `j=1` (העמודה השנייה):\n- `arr[0][1]` נגיש. דף `P_0` (המכיל את `arr[0]`) הוצא מהזיכרון הפיזי במהלך עיבוד העמודה הראשונה. לכן, תתרחש תקלת דף עבור `P_0` והוא ייטען מחדש.\n- `arr[1][1]` נגיש. דף `P_1` הוצא מהזיכרון הפיזי. תתרחש תקלת דף עבור `P_1` והוא ייטען מחדש.\n- ...\n- דפוס זה חוזר על עצמו. עבור כל איבר `arr[i][j]`, הדף `P_i` המכיל אותו כבר הוצא מהזיכרון הפיזי כתוצאה מגישה לאיברים מאוחרים יותר בעמודה הקודמת. לכן, כל גישה לאיבר `arr[i][j]` תגרום לתקלת דף.\n\nמכיוון שיש `1024` עמודות, וכל עמודה מכילה `1024` איברים שכל אחד מהם נמצא בדף נפרד שיגרום לתקלת דף, המספר הכולל של תקלות דף יהיה: `1024` עמודות * `1024` תקלות דף לעמודה = `1024 * 1024 = 1,048,576` תקלות דף.\n\n**תשובה 101.2: 1,048,576 כשלים.**"}, "difficulty_estimation": "Hard", "_source_file": "0574__Virtual_Memory__CodeAnalysis__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:50:14", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Virtual Memory", "Paging", "TLB", "Cache Locality", "Performance"], "content": {"text": "נתונה תוכנית C המבצעת אתחול של מערך דו-ממדי גדול. התוכנית מממשת שתי פונקציות לאתחול המערך בדרכים שונות:\n1. `init_row_major`: מאתחלת את המערך לפי שורות (גישה עוקבת בזיכרון).\n2. `init_col_major`: מאתחלת את המערך לפי עמודות (גישה לא עוקבת בזיכרון).\n\nהקוד הבא מייצג את הפונקציות הללו:\n\n```c\n#define N 2048\nchar large_array[N][N];\n\nvoid init_row_major() {\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            large_array[i][j] = (char)(i + j);\n        }\n    }\n}\n\nvoid init_col_major() {\n    for (int j = 0; j < N; j++) {\n        for (int i = 0; i < N; i++) {\n            large_array[i][j] = (char)(i + j);\n        }\n    }\n}\n```\n\nבהנחה שגודל דף זיכרון הוא 4KB, ושהמערך `large_array` גדול מספיק כדי לחרוג מגודלי ה-cache השונים (L1, L2, L3) של המעבד, וכן כדי לדרוש מספר רב של דפי זיכרון ורשומות TLB:\n\nא. איזו פונקציה, מבין `init_row_major` ו-`init_col_major`, צפויה להיות מהירה באופן משמעותי יותר? נמקו את תשובתכם בפירוט, תוך התייחסות למנגנוני זיכרון וירטואלי (כגון TLB, Page Faults) ולמנגנוני Cache של המעבד.", "code_snippet": "#define N 2048\nchar large_array[N][N];\n\nvoid init_row_major() {\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            large_array[i][j] = (char)(i + j);\n        }\n    }\n}\n\nvoid init_col_major() {\n    for (int j = 0; j < N; j++) {\n        for (int i = 0; i < N; i++) {\n            large_array[i][j] = (char)(i + j);\n        }\n    }\n}\n", "options": null}, "sub_questions": null, "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפונקציה `init_row_major` צפויה להיות מהירה באופן משמעותי יותר מ-`init_col_major`.\n\nההסבר טמון באופן הגישה לזיכרון והשפעותיו על מנגנוני הזיכרון הווירטואלי (Paging, TLB) ועל זיכרון המטמון (Cache) של המעבד:\n\n**1. `init_row_major` (גישה לפי שורות):**\n   *   **עקרון לוקליות המרחב (Spatial Locality):** מערכי C מאוחסנים בזיכרון בשורה-אחר-שורה (row-major order). כאשר אנו ניגשים ל-`large_array[i][j]`, הגישה הבאה ל-`large_array[i][j+1]` נמצאת מיד אחרי הכתובת הנוכחית בזיכרון פיזי. גישה זו היא עוקבת ובעלת לוקליות מרחבית גבוהה.\n   *   **Page Faults:** כאשר מתרחש Page Fault עבור `large_array[i][j]`, דף הזיכרון המכיל את הכתובת הזו נטען לזיכרון פיזי. מכיוון שהגישה היא עוקבת, הגישות הבאות לאלמנטים כמו `large_array[i][j+1]`, `large_array[i][j+2]` וכו', צפויות להיות באותו דף זיכרון שכבר נטען. זה מוביל למספר נמוך יחסית של Page Faults.\n   *   **TLB (Translation Lookaside Buffer):** ה-TLB הוא מטמון לתרגומי כתובות וירטואליות לפיזיות. כאשר מתרחש TLB Miss, יש צורך לגשת לטבלאות הדפים בזיכרון הראשי. בגישה לפי שורות, לאחר שדף מסוים טופל והרשומה שלו נכנסה ל-TLB, גישות רבות נוספות בתוך אותו דף יגרמו ל-TLB Hit. זה מפחית משמעותית את מספר ה-TLB Misses ואת הצורך בגישה לטבלאות הדפים.\n   *   **Cache:** כאשר נטען אלמנט לזיכרון המטמון (Cache), נטענת יחידה גדולה יותר הנקראת Cache Line. בגישה לפי שורות, האלמנטים הבאים בזיכרון (כגון `large_array[i][j+1]`, `large_array[i][j+2]`) נמצאים באותה Cache Line או ב-Cache Lines סמוכות. זה מוביל לניצול יעיל של המטמון (Cache Hits רבים) ומפחית את הצורך בטעינות מהזיכרון הראשי.\n\n**2. `init_col_major` (גישה לפי עמודות):**\n   *   **עקרון לוקליות המרחב (Spatial Locality):** בגישה זו, לאחר הגישה ל-`large_array[i][j]`, הגישה הבאה היא ל-`large_array[i+1][j]`. בזיכרון, אלמנט זה נמצא במרחק של N בתים (או N כפול גודל טיפוס הנתונים) מהאלמנט הקודם. זוהי גישה לא עוקבת ובעלת לוקליות מרחבית נמוכה מאוד.\n   *   **Page Faults:** כל גישה ל-`large_array[i+1][j]` (כאשר `i` משתנה) צפויה לקפוץ לדף זיכרון שונה (או לפחות לכתובת רחוקה בתוך דף). בהינתן ש-`N` גדול (2048), קפיצה של 2048 בתים (לדוגמה, אם `char` הוא 1 בית) או יותר, ככל הנראה תעבור לדף זיכרון חדש עבור כל איטרציה של הלולאה הפנימית. זה יוביל למספר עצום של Page Faults, מכיוון שכל גישה לאלמנט חדש בעמודה עלולה לדרוש טעינת דף חדש לזיכרון הפיזי, מה שגורם להשהיה משמעותית.\n   *   **TLB (Translation Lookaside Buffer):** עקב הקפיצות התכופות בין דפי זיכרון שונים, ה-TLB יסבול ממספר רב של TLB Misses. כל גישה לאלמנט `large_array[i][j]` כאשר `i` משתנה, תדרוש תרגום כתובת לדף זיכרון חדש, וככל הנראה הרשומה לדף זה לא תהיה ב-TLB. זה יחייב גישה לטבלאות הדפים שוב ושוב, מה שמאט את התהליך באופן דרמטי.\n   *   **Cache:** בגישה לפי עמודות, הנתונים הנטענים ל-Cache Line אינם מנוצלים ביעילות. לאחר טעינת `large_array[i][j]` ל-Cache Line, הגישה הבאה ל-`large_array[i+1][j]` תהיה בכתובת רחוקה מאוד, וסביר להניח שהיא לא תהיה באותה Cache Line. זה מוביל ל-Cache Misses רבים ול-Cache Thrashing (החלפה תכופה של Cache Lines), מה שמחייב טעינה חוזרת ונשנית של נתונים מהזיכרון הראשי.\n\nלסיכום, `init_row_major` מנצלת ביעילות את עקרון לוקליות המרחב, ומביאה למספר נמוך של Page Faults, TLB Misses ו-Cache Misses, מה שהופך אותה למהירה בהרבה. לעומתה, `init_col_major` סובלת מביצועים ירודים עקב הפרה של לוקליות המרחב, מה שגורם למספרים גבוהים של Page Faults, TLB Misses ו-Cache Misses."}, "difficulty_estimation": "Hard", "_source_file": "0576__Virtual_Memory__CodeAnalysis__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:51:30", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Paging", "Memory Management", "Virtual Memory"], "content": {"text": "מהי המטרה העיקרית של שיטת ה-Paging במערכת הפעלה?", "code_snippet": null, "options": ["א. לאפשר לזיכרון וירטואלי גדול יותר מהזיכרון הפיזי ולספק הגנה בין תהליכים.", "ב. להגביר את מהירות הגישה לנתונים בדיסק הקשיח.", "ג. למנוע מצבי קיפאון (deadlocks) בין תהליכים.", "ד. לארגן קבצים במערכת הקבצים באופן היררכי.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "א'. שיטת ה-Paging מאפשרת ניהול זיכרון יעיל, כולל יצירת מרחב כתובות וירטואלי גדול מהזיכרון הפיזי הזמין, והיא גם מספקת מנגנון הגנה חשוב בין תהליכים שונים על ידי בידוד מרחבי הכתובות שלהם."}, "difficulty_estimation": "Easy", "_source_file": "0577__Paging__MultipleChoice__Easy.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:51:39", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Memory Management", "Paging", "Virtual Memory"], "content": {"text": "במערכת דפדוף (paging), לאילו יחידות בגודל קבוע מחולקים הזיכרון הלוגי והזיכרון הפיזי, בהתאמה?", "code_snippet": null, "options": ["א. זיכרון לוגי לדפים (pages), וזיכרון פיזי למסגרות (frames).", "ב. זיכרון לוגי למסגרות (frames), וזיכרון פיזי לדפים (pages).", "ג. זיכרון לוגי לסגמנטים (segments), וזיכרון פיזי לדפים (pages).", "ד. זיכרון לוגי לבלוקים (blocks), וזיכרון פיזי למסגרות (frames).", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "א'. כפי שנלמד, במערכת דפדוף (paging), הזיכרון הלוגי של תהליך מחולק ליחידות בגודל קבוע הנקראות דפים (pages), והזיכרון הפיזי מחולק ליחידות בגודל קבוע הנקראות מסגרות (frames)."}, "difficulty_estimation": "Easy", "_source_file": "0578__Paging__MultipleChoice__Easy.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:51:48", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Paging", "Memory Management", "Virtual Memory"], "content": {"text": "מהי המטרה העיקרית של שיטת ה-Paging בניהול זיכרון?", "code_snippet": null, "options": ["א. למנוע פרגמנטציה חיצונית (external fragmentation).", "ב. להאיץ את ביצועי המעבד.", "ג. לנהל התקני קלט/פלט.", "ד. ליישם החלפת הקשר (context switch).", "ה. אף אחת מהתשובות האחרות אינה נכונה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "א. כפי שנלמד, Paging היא שיטה לניהול זיכרון וירטואלי שמטרתה העיקרית היא למנוע פרגמנטציה חיצונית על ידי חלוקת הזיכרון הפיזי והלוגי לדפים ופריימים בגודל קבוע."}, "difficulty_estimation": "Easy", "_source_file": "0579__Paging__MultipleChoice__Easy.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:51:55", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Paging", "Memory Management", "Virtual Memory"], "content": {"text": "מה מכילה טבלת דפים (Page Table)?", "code_snippet": null, "options": ["א. רשימה של תהליכים פעילים במערכת.", "ב. מיפוי מכתובות וירטואליות לכתובות פיזיות.", "ג. נתונים על קבצים המאוחסנים בדיסק.", "ד. מידע על התקני קלט/פלט מחוברים.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. כפי שנלמד, טבלת דפים (Page Table) היא מבנה נתונים המשמש את מערכת ההפעלה לתרגום כתובות וירטואליות לכתובות פיזיות בזיכרון, ברמת הדפים (pages)."}, "difficulty_estimation": "Easy", "_source_file": "0580__Paging__MultipleChoice__Easy.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:52:03", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Paging", "Memory Management", "Virtual Memory"], "content": {"text": "מהו תפקידה העיקרי של טבלת הדפים (Page Table) במערכת Paging?", "code_snippet": null, "options": ["א. לאחסן את הקוד הבינארי של תהליכים.", "ב. לאחסן את המיפוי בין כתובות וירטואליות לכתובות פיזיות בזיכרון.", "ג. לתזמן את ביצוע התהליכים על ידי המעבד.", "ד. לנהל את קבצי המשתמשים על הדיסק הקשיח.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. כפי שנלמד, טבלת הדפים היא מבנה נתונים קריטי במנגנון ה-Paging, ותפקידה העיקרי הוא לאחסן את המיפוי (mapping) בין דפים וירטואליים (הנראים לתהליך) למסגרות דף פיזיות (היכן שהנתונים נמצאים בפועל בזיכרון הפיזי)."}, "difficulty_estimation": "Easy", "_source_file": "0581__Paging__MultipleChoice__Easy.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:52:10", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Paging", "Virtual Memory", "Memory Management"], "content": {"text": "כיצד מחולקת כתובת וירטואלית במערכת דפדוף (Paging)?", "code_snippet": null, "options": ["א. למספר עמוד (page number) והיסט (offset).", "ב. למספר מקטע (segment number) והיסט (offset).", "ג. לכתובת בסיס (base address) וגודל (limit).", "ד. לכתובת פיזית (physical address) וכתובת וירטואלית (virtual address).", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "א'. כפי שנלמד, במערכת דפדוף, כתובת וירטואלית מחולקת לשני חלקים: מספר העמוד (page number), המציין את העמוד הווירטואלי, והיסט (offset) בתוך העמוד, המציין את המיקום הספציפי בתוך אותו עמוד."}, "difficulty_estimation": "Easy", "_source_file": "0582__Paging__MultipleChoice__Easy.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:52:17", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Paging", "Memory Management", "Virtual Memory"], "content": {"text": "מהי מטרתו העיקרית של טבלת הדפים (Page Table) במערכת הפעלה המשתמשת ב-paging?", "code_snippet": null, "options": ["א. אחסון מיפוי בין כתובות וירטואליות לכתובות פיזיות.", "ב. ניהול תורי התהליכים (process queues) הממתינים לביצוע.", "ג. שמירת תוכן קבצי המשתמש על הדיסק.", "ד. ביצוע החלפת הקשר (context switch) בין תהליכים.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "א'. כפי שנלמד, טבלת הדפים (Page Table) היא מבנה נתונים חיוני ב-paging, ותפקידה העיקרי הוא לאחסן את המיפוי בין כתובות לוגיות (וירטואליות) לכתובות פיזיות בזיכרון, ובכך לאפשר את תרגום הכתובות על ידי ה-MMU."}, "difficulty_estimation": "Easy", "_source_file": "0583__Paging__MultipleChoice__Easy.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:52:26", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Paging", "Memory Management", "Virtual Memory"], "content": {"text": "במערכת הפעלה המשתמשת ב-Paging, מהי 'עמודה' (page)?", "code_snippet": null, "options": ["א. בלוק בגודל קבוע של זיכרון וירטואלי.", "ב. בלוק בגודל קבוע של זיכרון פיזי.", "ג. אזור בדיסק המשמש לאחסון נתונים באופן זמני.", "ד. רשומה בטבלת העמודות (Page Table Entry).", "ה. אף אחת מהתשובות האחרות אינה נכונה."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "א'. כפי שנלמד, במנגנון Paging, הזיכרון הווירטואלי של תהליך מחולק לבלוקים בגודל קבוע הנקראים 'עמודות' (pages). הזיכרון הפיזי מחולק לבלוקים בגודל זהה הנקראים 'מסגרות' (frames)."}, "difficulty_estimation": "Easy", "_source_file": "0584__Paging__MultipleChoice__Easy.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:52:33", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Paging", "Memory Management"], "content": {"text": "במערכת הפעלה המשתמשת ב-Paging, כתובת וירטואלית היא באורך 32 ביטים וגודל עמוד (page size) הוא 4KB.\nמהו מספר הביטים המוקדש למספר העמוד (page number) ומהו מספר הביטים המוקדש לקיזוז בתוך העמוד (page offset)?", "code_snippet": null, "options": ["א. מספר עמוד: 12 ביטים, קיזוז: 20 ביטים.", "ב. מספר עמוד: 20 ביטים, קיזוז: 12 ביטים.", "ג. מספר עמוד: 10 ביטים, קיזוז: 22 ביטים.", "ד. מספר עמוד: 22 ביטים, קיזוז: 10 ביטים."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "גודל העמוד הוא 4KB. מכיוון ש-1KB = 2^10 בתים, ו-4KB = 4 * 1024 בתים = 2^2 * 2^10 בתים = 2^12 בתים. לכן, כדי לייצג כל כתובת בתוך עמוד בגודל 4KB, נדרשים 12 ביטים עבור הקיזוז (offset).\nהכתובת הווירטואלית היא באורך 32 ביטים. אם 12 ביטים מוקדשים לקיזוז, אז מספר הביטים הנותרים למספר העמוד הוא: 32 - 12 = 20 ביטים.\nלכן, מספר העמוד הוא 20 ביטים והקיזוז הוא 12 ביטים."}, "difficulty_estimation": "Medium", "_source_file": "0585__Paging__MultipleChoice__Medium.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:52:42", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Paging", "Memory Management", "Virtual Memory"], "content": {"text": "נתונה מערכת הפעלה המשתמשת במנגנון Paging לניהול זיכרון וירטואלי. גודל דף (page size) הוא 4KB. תהליך מנסה לגשת לכתובת וירטואלית `0xABCD1234`. נניח כי עבור הדף הווירטואלי הרלוונטי, רשומת טבלת הדפים (Page Table Entry - PTE) מצביעה על מספר מסגרת פיזית (Physical Frame Number - PFN) השווה ל-`0x000F`. מהי הכתובת הפיזית (Physical Address) אליה יתורגם הגישה?", "code_snippet": null, "options": ["א. 0xABCD234", "ב. 0x000F1234", "ג. 0x000F234", "ד. 0xABCD000F"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "גודל דף הוא 4KB, כלומר 2 בחזקת 12 בתים. לכן, 12 הביטים הפחות משמעותיים (LSB) של הכתובת הווירטואלית מייצגים את ההיסט בתוך הדף (page offset).\nהכתובת הווירטואלית היא `0xABCD1234`.\nהיסט הדף (page offset) הוא 12 הביטים הימניים ביותר: `0x234` (שכן 12 הביטים האחרונים של 0x1234 הם 0010 0011 0100).\nמספר הדף הווירטואלי (VPN) הוא הביטים הנותרים: `0xABCD1`.\nעל פי הנתון, מספר המסגרת הפיזית (PFN) עבור דף זה הוא `0x000F`.\nכדי לקבל את הכתובת הפיזית, אנו מחברים את מספר המסגרת הפיזית עם ההיסט בתוך הדף.\nהכתובת הפיזית = (PFN << מספר_ביטים_היסט_דף) | היסט_דף\nהכתובת הפיזית = (`0x000F` << 12) | `0x234`\n`0x000F` << 12 = `0xF000` (הזזה של 0x000F ב-12 ביטים שמאלה)\n`0xF000` | `0x234` = `0xF234`.\nלכן, הכתובת הפיזית היא `0x000F234`."}, "difficulty_estimation": "Medium", "_source_file": "0586__Paging__MultipleChoice__Medium.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:52:56", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Paging", "Memory Management", "Virtual Memory"], "content": {"text": "בתרגום כתובת וירטואלית לכתובת פיזית במערכת זיכרון מבוססת דפדוף (paging), מהו הסדר הנכון של הפעולות כאשר ישנו TLB Miss אך ה-page נמצא בזיכרון הפיזי?", "code_snippet": null, "options": ["א. בדיקה ב-TLB -> אם לא נמצא, בדיקה בטבלת הדפים (Page Table) בזיכרון הראשי -> אם נמצא, עדכון TLB -> גישה לזיכרון הפיזי.", "ב. בדיקה בטבלת הדפים (Page Table) בזיכרון הראשי -> אם נמצא, עדכון TLB -> גישה לזיכרון הפיזי.", "ג. בדיקה ב-TLB -> אם לא נמצא, קריאת ה-page מהדיסק לזיכרון הראשי -> עדכון TLB -> גישה לזיכרון הפיזי.", "ד. בדיקה ב-TLB -> אם לא נמצא, בדיקה בטבלת הדפים (Page Table) בזיכרון הראשי -> אם נמצא, גישה לזיכרון הפיזי, ללא עדכון TLB."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "כאשר מתבצע תרגום כתובת וירטואלית, המערכת מנסה תחילה למצוא את המיפוי ב-TLB (Translation Lookaside Buffer) בשל מהירותו. אם הכתובת לא נמצאת ב-TLB (TLB Miss), המערכת פונה לטבלת הדפים (Page Table) שנמצאת בזיכרון הראשי. מכיוון שה-page נמצא בזיכרון הפיזי במקרה זה, המיפוי יימצא בטבלת הדפים. לאחר מכן, המיפוי מועתק ל-TLB כדי לזרז גישות עתידיות לאותו page, ולבסוף מתבצעת הגישה לזיכרון הפיזי."}, "difficulty_estimation": "Medium", "_source_file": "0587__Paging__MultipleChoice__Medium.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:53:06", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Paging", "Memory Management"], "content": {"text": "נתונה מערכת זיכרון וירטואלי המשתמשת ב-paging.\nגודל דף (page size) הוא 4KB.\nכתובת וירטואלית נתונה היא `0x0000A123`.\nבטבלת הדפים (page table) של התהליך, עבור מספר הדף הווירטואלי המתאים לכתובת זו, מספר ה-frame הפיזי הוא `0x000F`.\nמהי הכתובת הפיזית המתאימה לכתובת הווירטואלית הנתונה?", "code_snippet": null, "options": ["א. `0x000F123`", "ב. `0x0000F123`", "ג. `0x000A123`", "ד. `0x000F0A123`"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "גודל דף הוא 4KB, כלומר 2^12 בתים. לכן, 12 הביטים הפחות משמעותיים של הכתובת הווירטואלית מייצגים את ה-offset בתוך הדף.\nהכתובת הווירטואלית הנתונה היא `0x0000A123`.\n*   ה-offset הוא 12 הביטים הנמוכים ביותר: `0x123`.\n*   מספר הדף הווירטואלי (VPN) הוא שאר הביטים: `0x0000A`.\nטבלת הדפים מציינת כי עבור מספר הדף הווירטואלי `0x0000A`, מספר ה-frame הפיזי הוא `0x000F`.\nכדי לבנות את הכתובת הפיזית, אנו מחליפים את ה-VPN במספר ה-frame הפיזי ומשאירים את ה-offset ללא שינוי:\nכתובת פיזית = (Frame Number << 12) | Offset\nכתובת פיזית = (`0x000F` << 12) | `0x123`\n`0x000F` מוסט ב-12 ביטים שמאלה הוא `0x000F000`.\n`0x000F000` + `0x123` = `0x000F123`.\nלכן, התשובה הנכונה היא `א`."}, "difficulty_estimation": "Medium", "_source_file": "0588__Paging__MultipleChoice__Medium.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:53:18", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Paging", "Memory Management"], "content": {"text": "במערכת הפעלה המשתמשת בזיכרון וירטואלי מבוסס Paging, נתון כי מרחב הכתובות הווירטואלי הוא בגודל 32 ביט, גודל עמוד (page size) הוא 4KB, וכל רשומה בטבלת העמודים (PTE) דורשת 4 בתים. בהנחה שמדובר בטבלת עמודים יחידה (single-level page table), כמה רשומות תהיה בטבלה ומה יהיה גודלה המרבי?", "code_snippet": null, "options": ["א. 2^12 רשומות, גודל 16KB", "ב. 2^20 רשומות, גודל 4MB", "ג. 2^32 רשומות, גודל 16GB", "ד. 2^10 רשומות, גודל 4KB"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "מרחב הכתובות הווירטואלי הוא 2^32 בתים. גודל עמוד הוא 4KB, שזה 4 * 1024 בתים, או 2^2 * 2^10 = 2^12 בתים.\nמספר העמודים הווירטואליים הכולל הוא מרחב הכתובות הווירטואלי חלקי גודל עמוד: 2^32 / 2^12 = 2^(32-12) = 2^20 עמודים.\nמכיוון שכל עמוד וירטואלי דורש רשומה אחת בטבלת העמודים, טבלת העמודים תכיל 2^20 רשומות.\nגודל כל רשומה בטבלת העמודים (PTE) הוא 4 בתים.\nלכן, הגודל המרבי של טבלת העמודים יהיה מספר הרשומות כפול גודל רשומה: 2^20 רשומות * 4 בתים/רשומה = 2^20 * 2^2 בתים = 2^22 בתים.\n2^22 בתים שווה ל-4 מגה-בייט (4MB)."}, "difficulty_estimation": "Medium", "_source_file": "0589__Paging__MultipleChoice__Medium.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:53:28", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Paging", "Memory Management"], "content": {"text": "מהי מטרתו העיקרית של ה-Valid/Invalid bit (סיבית תקינות/אי-תקינות) בערך בטבלת דפים (Page Table Entry)?", "code_snippet": null, "options": ["א. לציין אם הדף שונה מאז שהועמס לזיכרון הפיזי.", "ב. לציין אם הדף נמצא כרגע בזיכרון הפיזי או על הדיסק.", "ג. לציין את רמת ההרשאה לדף (קריאה, כתיבה, הרצה).", "ד. לציין אם הדף משותף למספר תהליכים.", "ה. לציין את מספר המסגרת הפיזית (Frame Number) שבה נמצא הדף."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ה-Valid/Invalid bit מציין האם הדף המקביל לערך בטבלת הדפים נמצא כרגע בזיכרון הפיזי (Valid) או לא (Invalid). כאשר הסיבית היא Invalid, ניסיון גישה לדף יגרום ל-Page Fault, שידרוש מהמערכת לטעון את הדף מהדיסק לזיכרון הפיזי. אפשרות א' מתארת את ה-Dirty bit, אפשרות ג' מתארת את סיביות ההגנה, ואפשרות ה' היא חלקו העיקרי של ה-PTE כאשר הדף תקף."}, "difficulty_estimation": "Medium", "_source_file": "0590__Paging__MultipleChoice__Medium.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:53:37", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Paging"], "content": {"text": "במערכת הפעלה המשתמשת במנגנון Paging, איזה מידע *עיקרי* נשמר ב-Page Table Entry (PTE) עבור דף (page) שקיים בזיכרון הפיזי?", "code_snippet": null, "options": ["א. הכתובת הפיזית המלאה של תחילת הדף בזיכרון.", "ב. מספר המסגרת (Frame Number) בזיכרון הפיזי, יחד עם ביטים לבקרה (כגון Valid/Invalid, Dirty, Accessed).", "ג. הכתובת הווירטואלית של תחילת הדף.", "ד. גודל הדף בבתים וזמן הטעינה שלו לזיכרון."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הסבר: Page Table Entry (PTE) מכיל את מספר המסגרת (Frame Number) בזיכרון הפיזי שאליה ממופה הדף הווירטואלי. בנוסף, הוא מכיל ביטי בקרה חשובים כמו:\n*   Valid/Invalid bit: מציין אם הדף נמצא בזיכרון הפיזי או על הדיסק.\n*   Dirty bit: מציין אם הדף השתנה מאז נטען לזיכרון.\n*   Accessed bit: מציין אם הדף שימש לאחרונה.\nביטים אלו חיוניים לניהול זיכרון, במיוחד עבור אלגוריתמי החלפת דפים (Page Replacement Algorithms). הכתובת הפיזית המלאה נוצרת על ידי שילוב מספר המסגרת עם ה-offset מתוך הכתובת הווירטואלית, ולכן המספר המלא אינו נשמר ישירות ב-PTE."}, "difficulty_estimation": "Medium", "_source_file": "0591__Paging__MultipleChoice__Medium.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:53:48", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Paging", "Memory Management"], "content": {"text": "איזה מהבאים אינו מהווה מידע שניתן למצוא בדרך כלל בערך בטבלת עמודים (PTE - Page Table Entry)?", "code_snippet": null, "options": ["א. מספר מסגרת (Frame Number)", "ב. סיבית תקפות (Valid Bit)", "ג. גודל העמוד (Page Size)", "ד. סיביות הגנה (Protection Bits)", "ה. סיבית שינוי (Dirty Bit)"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "ג. גודל העמוד (Page Size) הוא פרמטר כלל-מערכתי (או לכל היותר פר-תהליך, אך נקבע על ידי המערכת) ואינו מאוחסן בתוך כל ערך בטבלת העמודים. טבלת העמודים מכילה מידע ספציפי לכל עמוד וכיצד למפות אותו לזיכרון פיזי, כגון מספר המסגרת הפיזית, סיביות תקפות, הגנה ושינוי."}, "difficulty_estimation": "Medium", "_source_file": "0592__Paging__MultipleChoice__Medium.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:53:56", "_subject": "Virtualization"}, {"id": 6, "type": "MultipleChoice", "topic": ["Paging", "Virtual Memory", "Address Translation", "Multi-level Paging"], "content": {"text": "במערכת הפעלה המשתמשת בזיכרון וירטואלי, כתובות וירטואליות הן בגודל 64 ביטים. גודל דף הוא 4KB, וכל רשומת טבלת דפים (PTE) היא בגודל 8 בתים. טבלאות הדפים ממומשות כטבלאות דפים היררכיות בעלות ארבע רמות (4-level page table). כמה ביטים מוקצים לכל אינדקס בטבלת הדפים ברמה העליונה ביותר (level 1)?", "code_snippet": null, "options": ["א. 8 ביטים", "ב. 9 ביטים", "ג. 12 ביטים", "ד. 13 ביטים", "ה. 16 ביטים"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "התשובה הנכונה היא ב'.\n1.  **חישוב גודל ההיסט (Offset):** גודל הדף הוא 4KB (קילו-בייט), כלומר 2^12 בתים. לכן, 12 ביטים מוקצים להיסט בתוך הדף.\n2.  **חישוב מספר הביטים לכתובת דף וירטואלי (VPN):** הכתובת הוירטואלית כולה היא 64 ביטים. לאחר הפחתת ביטי ההיסט, נשארים 64 - 12 = 52 ביטים עבור ה-Virtual Page Number (VPN).\n3.  **חישוב מספר הרשומות המקסימלי לטבלת דפים:** כל טבלת דפים חייבת להיכנס לדף אחד. גודל דף הוא 4KB, וגודל רשומת טבלת דפים (PTE) הוא 8 בתים. לכן, מספר הרשומות המקסימלי בטבלת דפים אחת הוא: 4096 בתים / 8 בתים/רשומה = 512 רשומות.\n4.  **חישוב מספר הביטים לאינדקס בטבלת דפים:** כדי לאנדקס 512 רשומות, נדרשים log2(512) = 9 ביטים.\nמכיוון שטבלאות הדפים הן היררכיות בעלות 4 רמות, וכל טבלת דפים (בכל רמה) חייבת להיכנס לדף אחד (כלומר, להכיל לכל היותר 512 רשומות), כל אינדקס בכל רמה (כולל הרמה העליונה ביותר) מוקצה לו 9 ביטים. סך הכל, 4 רמות * 9 ביטים/רמה = 36 ביטים מוקצים לאינדקסים בטבלאות הדפים. שאר ה-VPN (52-36=16 ביטים) אינם משמשים לאינדוקס טבלאות דפים, בדומה למנגנון כתובות קנוניות ב-x86-64."}, "difficulty_estimation": "Hard", "_source_file": "0593__Paging__MultipleChoice__Hard.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:54:18", "_subject": "Virtualization"}, {"id": 101, "type": "MultipleChoice", "topic": ["Paging", "Virtual Memory", "Multi-level Paging"], "content": {"text": "נתונה מערכת הפעלה 64 ביט המשתמשת בכתובות וירטואליות קנוניות באורך 48 ביט. המערכת מיישמת דפדוף היררכי בן 4 רמות (4-level hierarchical paging). גודל דף הוא 4KB, וגודל כניסה בטבלת דפים (PTE) הוא 8 בתים. מהו נפח הזיכרון המרבי (ב-GB) שייצרכו טבלאות הדפים של תהליך בודד, אם הוא ממפה באופן מלא את כל מרחב הכתובות הווירטואלי הקנוני שלו?", "code_snippet": null, "options": ["א. 4GB", "ב. 64GB", "ג. 128GB", "ד. 513GB", "ה. 1024GB"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "נפח כתובת וירטואלית קנונית: 48 ביט.\nגודל דף: 4KB = 2^12 בתים, לכן 12 ביטים מוקצים ל-offset.\nמספר ביטים ל-Virtual Page Number (VPN): 48 - 12 = 36 ביטים.\nגודל כניסה בטבלת דפים (PTE): 8 בתים.\nמספר כניסות לכל טבלת דפים (שגודלה כגודל דף אחד): 4KB / 8 בתים = 4096 / 8 = 512 כניסות.\nמספר ביטים לכל אינדקס בטבלת דפים: log2(512) = 9 ביטים.\nמספר רמות טבלאות דפים נדרשות: 36 ביטים (VPN) / 9 ביטים לרמה = 4 רמות. זה תואם את הנתון בשאלה.\n\nכדי למפות באופן מלא את כל מרחב הכתובות הווירטואלי הקנוני (48 ביט), נצטרך את טבלאות הדפים הבאות:\n1.  רמה 4 (PML4): טבלת דפים אחת.\n2.  רמה 3 (PDPT): אם טבלת ה-PML4 מלאה, היא מפנה ל-512 טבלאות דפים ברמה 3.\n3.  רמה 2 (PD): אם כל טבלאות ה-PDPT מלאות, הן מפנות ל-512 * 512 = 512^2 טבלאות דפים ברמה 2.\n4.  רמה 1 (PT): אם כל טבלאות ה-PD מלאות, הן מפנות ל-512 * 512 * 512 = 512^3 טבלאות דפים ברמה 1.\n\nסה\"כ דפים המשמשים לטבלאות דפים:\n1 (PML4) + 512 (PDPTs) + 512^2 (PDs) + 512^3 (PTs)\n= 1 + 512 + 262,144 + 134,217,728\n= 134,480,385 דפים.\n\nנפח זיכרון כולל בבתים: 134,480,385 דפים * 4096 בתים/דף = 550,810,320,000 בתים.\n\nנמיר ל-GB:\n550,810,320,000 בתים / (1024 * 1024 * 1024) בתים/GB ≈ 512.98 GB.\nהתשובה הקרובה ביותר היא 513GB.\n\nהערה: ניתן גם לחשב בקירוב: נפח טבלאות הדפים ברמה הנמוכה ביותר הוא הדומיננטי.\n512^3 דפים * 4KB/דף = (2^9)^3 * 2^12 בתים = 2^27 * 2^12 בתים = 2^39 בתים.\n2^39 בתים / (2^10)^3 בתים/GB = 2^39 / 2^30 GB = 2^9 GB = 512 GB.\nהוספת הדפים מהרמות הגבוהות יותר (כ-1GB נוסף) מביאה ל-513GB."}, "difficulty_estimation": "Hard", "_source_file": "0594__Paging__MultipleChoice__Hard.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:54:40", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Paging", "Virtual Memory", "TLB", "Effective Access Time", "Multi-Level Page Tables"], "content": {"text": "מערכת הפעלה משתמשת בכתובות וירטואליות בנות 32 ביט ובגודל דף של 4KB. מיפוי הכתובות מבוצע באמצעות טבלת דפים דו-שכבתית (Two-Level Page Table). כל ערך בטבלת הדפים (PTE) הוא בגודל 4 בתים. למערכת קיים TLB עם שיעור פגיעה (Hit Rate) של 95%. זמן הגישה ל-TLB הוא 5ns, וזמן הגישה לזיכרון הפיזי (RAM) הוא 50ns.\nמהו זמן הגישה האפקטיבי (Effective Access Time - EAT) לביצוע פעולת קריאת נתונים מהזיכרון?", "code_snippet": null, "options": ["א. 55ns", "ב. 60ns", "ג. 105ns", "ד. 155ns", "ה. 110ns"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "זמן גישה אפקטיבי (EAT) מחושב לפי הנוסחה:\nEAT = (שיעור פגיעה ב-TLB * זמן גישה במקרה של פגיעה) + (שיעור החטאה ב-TLB * זמן גישה במקרה של החטאה)\n\nנחשב את המרכיבים:\n1.  **חלוקת הכתובת הוירטואלית:**\n    *   גודל כתובת וירטואלית: 32 ביט.\n    *   גודל דף: 4KB = 2^12 בתים. לכן, ההיסט בתוך הדף (Page Offset) הוא 12 ביט.\n    *   מספר הדף הוירטואלי (VPN): 32 - 12 = 20 ביט.\n    *   גודל ערך בטבלת דפים (PTE): 4 בתים.\n    *   מספר ערכים בטבלת דפים שיכולים להיכנס לדף אחד: 4KB / 4 בתים = 1024 ערכים.\n    *   מספר ביטים לכל אינדקס בטבלת הדפים: log2(1024) = 10 ביט.\n    *   מכיוון שמדובר בטבלת דפים דו-שכבתית, ה-VPN מתחלק לשני אינדקסים, כל אחד בן 10 ביט (10+10=20 ביט, תואם ל-VPN).\n\n2.  **זמן גישה במקרה של פגיעה ב-TLB (TLB Hit):**\n    *   גישה ל-TLB: 5ns.\n    *   ה-TLB מכיל את הכתובת הפיזית של הדף.\n    *   גישה לזיכרון הפיזי (קריאת נתונים): 50ns.\n    *   סה\"כ זמן במקרה של פגיעה: 5ns + 50ns = 55ns.\n\n3.  **זמן גישה במקרה של החטאה ב-TLB (TLB Miss):**\n    *   גישה ל-TLB: 5ns (מתבצעת תמיד, גם במקרה של החטאה).\n    *   החטאה ב-TLB דורשת מעבר על טבלת הדפים בזיכרון הראשי כדי למצוא את הכתובת הפיזית של הדף.\n    *   טבלת דפים דו-שכבתית דורשת שתי גישות לזיכרון הראשי כדי למצוא את ה-PTE:\n        *   גישה לטבלת הדפים ברמה הראשונה (P1): 50ns.\n        *   גישה לטבלת הדפים ברמה השנייה (P2): 50ns.\n    *   לאחר מציאת הכתובת הפיזית של הדף, יש לגשת לזיכרון הראשי כדי לקרוא את הנתונים: 50ns.\n    *   סה\"כ זמן במקרה של החטאה: 5ns (TLB) + 50ns (P1) + 50ns (P2) + 50ns (Data) = 155ns.\n\n4.  **חישוב EAT:**\n    *   שיעור פגיעה ב-TLB: 95% = 0.95.\n    *   שיעור החטאה ב-TLB: 100% - 95% = 5% = 0.05.\n    *   EAT = (0.95 * 55ns) + (0.05 * 155ns)\n    *   EAT = 52.25ns + 7.75ns\n    *   EAT = 60ns."}, "difficulty_estimation": "Hard", "_source_file": "0595__Paging__MultipleChoice__Hard.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:55:05", "_subject": "Virtualization"}, {"id": 101, "type": "MultipleChoice", "topic": ["Virtual Memory", "Paging", "Copy-on-Write", "Process Management"], "content": {"text": "נתונה מערכת הפעלה המיישמת זיכרון וירטואלי עם דפדוף (paging) בגודל דף של 4KB ותומכת במנגנון Copy-on-Write (COW). תהליך אב P מקצה אזור זיכרון בגודל 4KB בשם buf וכותב למיקום buf[0] את התו 'A'. לאחר מכן, תהליך P מבצע קריאה למערכת fork() ליצירת תהליך בן C. מיד לאחר ה-fork(), תהליך P כותב למיקום buf[0] את התו 'B'. לבסוף, תהליך C קורא את התו ממיקום buf[0]. איזו טענה נכונה בהכרח לגבי מצב הזיכרון הפיזי והערכים הנצפים על ידי התהליכים?", "code_snippet": null, "options": ["א. בסיום הפעולות, אזור buf משתמש בשני דפים פיזיים שונים. תהליך P יקרא 'B' ותהליך C יקרא 'A'.", "ב. בסיום הפעולות, אזור buf משתמש בדף פיזי אחד בלבד. גם תהליך P וגם תהליך C יקראו 'B'.", "ג. בסיום הפעולות, אזור buf משתמש בשני דפים פיזיים שונים. גם תהליך P וגם תהליך C יקראו 'B'.", "ד. בסיום הפעולות, אזור buf משתמש בדף פיזי אחד בלבד. תהליך P יקרא 'B' ותהליך C יקרא 'A'.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "הסבר:\n1.  **לפני fork()**: תהליך P מקצה דף זיכרון וירטואלי עבור buf אשר ממופה לדף פיזי יחיד (נניח PP1). הכתיבה buf[0] = 'A' גורמת ל-PP1 להכיל 'A'.\n2.  **לאחר fork()**: תהליך C נוצר. מכיוון שהמערכת תומכת ב-COW, ה-PTE (Page Table Entry) עבור הדף של buf בשני התהליכים (P ו-C) מצביע כעת על אותו דף פיזי PP1, אך מסומן כ\"קריאה בלבד\" (או \"COW\"). זה אומר שכל ניסיון כתיבה לדף זה יגרום ל-page fault.\n3.  **P כותב 'B'**: כאשר תהליך P מנסה לכתוב ל-buf[0] = 'B', מתרחשת פסיקת דף (page fault) מכיוון שהדף מסומן כ-COW/קריאה בלבד. מערכת ההפעלה מטפלת בפסיקה:\n    *   מקצה דף פיזי חדש (נניח PP2).\n    *   מעתיקה את התוכן של PP1 (שהוא 'A') ל-PP2.\n    *   מעדכנת את ה-PTE של P עבור buf כך שיצביע על PP2 ומסמנת אותו כ\"קריאה-כתיבה\".\n    *   תהליך P ממשיך את פעולת הכתיבה, וכעת PP2 מכיל 'B'.\n    *   ה-PTE של C עדיין מצביע על PP1 (שעדיין מכיל 'A') ומסומן כ-COW.\n4.  **C קורא buf[0]**: תהליך C מבצע קריאה. מכיוון שה-PTE שלו מצביע על PP1 (המכיל 'A') והפעולה היא קריאה, לא מתרחשת פסיקת דף. C קורא את 'A'.\n\nלכן, בסיום הפעולות, קיימים שני דפים פיזיים עבור אזור buf (אחד עבור P ואחד עבור C), תהליך P רואה 'B' ותהליך C רואה 'A'. תשובה א' נכונה."}, "difficulty_estimation": "Hard", "_source_file": "0596__Paging__MultipleChoice__Hard.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:55:29", "_subject": "Virtualization"}, {"id": 101, "type": "MultipleChoice", "topic": ["Paging", "Virtual Memory", "TLB", "Page Faults"], "content": {"text": "במערכת הפעלה המשתמשת בכתובות וירטואליות בגודל 32 ביטים ובגודל דף של 4KB, ממומש מנגנון דפדוף היררכי בעל 3 רמות (3-level page table). קיים גם TLB. תהליך מנסה לגשת לכתובת וירטואלית מסוימת. גישה זו גורמת ל-TLB Miss. לאחר מכן, הליכת טבלאות הדפים (page table walk) מגלה שהדף אינו נמצא בזיכרון הפיזי (P-bit=0), מה שמוביל ל-Page Fault. מערכת ההפעלה מטפלת בהצלחה ב-Page Fault על ידי טעינת הדף מהדיסק לפריימ פנוי ועדכון ה-PTE המתאים בזיכרון הראשי. ה-TLB מעודכן, והפקודה המקורית מופעלת מחדש, ולאחר מכן הגישה לנתונים מתבצעת בהצלחה. מהו המספר המינימלי הכולל של גישות לזיכרון הראשי (RAM, לא כולל I/O לדיסק) הנדרשות מרגע ה-TLB Miss הראשוני ועד שהנתונים נגישים בהצלחה על ידי המעבד? יש להניח שבמהלך טיפול ב-Page Fault, רק עדכון ה-PTE הנחוץ נספר ככתיבה לזיכרון.", "code_snippet": null, "options": ["א. 3", "ב. 4", "ג. 5", "ד. 6", "ה. 7"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "ההסבר:\n1.  **TLB Miss ראשוני:** אין גישה לזיכרון הראשי (RAM) בשלב זה.\n2.  **הליכת טבלאות דפים (Page Table Walk):** מכיוון שמדובר במנגנון דפדוף בעל 3 רמות, נדרשות 3 גישות קריאה לזיכרון הראשי כדי לאתר את ה-PTE (Page Table Entry) הסופי: גישה אחת לכל רמה של טבלת הדפים. (3 גישות קריאה).\n3.  **גילוי Page Fault וטיפול:** ה-PTE שנמצא מצביע על כך שהדף אינו בזיכרון הפיזי. מערכת ההפעלה מטפלת ב-Page Fault:\n    *   טעינת הדף מהדיסק: פעולת I/O לדיסק, אינה נספרת כגישת RAM.\n    *   עדכון ה-PTE בזיכרון הראשי: נדרשת גישת כתיבה אחת לזיכרון הראשי כדי לעדכן את ה-PTE עם מספר הפריימ החדש וסיביות ה-P (Present) המתאימות. (1 גישת כתיבה).\n    *   עדכון ה-TLB: פעולת מטמון של המעבד, אינה נספרת כגישת RAM.\n4.  **הפעלת הפקודה מחדש וגישה לנתונים:**\n    *   הפקודה המקורית מופעלת מחדש. הפעם, ה-TLB יכיל את ה-PTE המעודכן (TLB Hit), ולכן אין גישות RAM נוספות לצורך תרגום הכתובת.\n    *   הגישה בפועל לנתונים/פקודות בזיכרון הפיזי: נדרשת גישת קריאה אחת לזיכרון הראשי כדי להביא את הנתונים המבוקשים. (1 גישת קריאה).\n\n**סך הכל:** 3 גישות קריאה (ל-PTEs) + 1 גישת כתיבה (עדכון PTE) + 1 גישת קריאה (גישה לנתונים) = 5 גישות לזיכרון הראשי."}, "difficulty_estimation": "Hard", "_source_file": "0597__Paging__MultipleChoice__Hard.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:55:53", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Paging", "Virtual Memory", "Multi-level Paging", "Page Table Size"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בכתובות וירטואליות בגודל 64 ביט, ובכתובות פיזיות בגודל 48 ביט. המערכת מיישמת paging רב-שכבתי (multi-level paging) עם 4 רמות, כאשר כל טבלת דפים (page table) היא בגודל 4KB וכל ערך בטבלת דפים (PTE) הוא בגודל 8 בתים.\nתהליך מסוים ממפה באופן רציף 4GB של זיכרון וירטואלי, החל מכתובת 0.\nבהתבסס על ההנחה כי 16 הביטים העליונים של הכתובת הוירטואלית מוזנחים (canonical addressing), איזו מהטענות הבאות נכונה לגבי סך הזיכרון הנדרש לטבלאות הדפים עבור תהליך זה במקרים הבאים?", "code_snippet": null, "options": ["א. כאשר גודל דף הוא 4KB, נדרשים 8MB + 24KB לטבלאות הדפים. כאשר גודל דף הוא 2MB, נדרשים 24KB לטבלאות הדפים.", "ב. כאשר גודל דף הוא 4KB, נדרשים 8MB לטבלאות הדפים. כאשר גודל דף הוא 2MB, נדרשים 16KB לטבלאות הדפים.", "ג. כאשר גודל דף הוא 4KB, נדרשים 2MB + 24KB לטבלאות הדפים. כאשר גודל דף הוא 2MB, נדרשים 24KB לטבלאות הדפים.", "ד. כאשר גודל דף הוא 4KB, נדרשים 8MB + 16KB לטבלאות הדפים. כאשר גודל דף הוא 2MB, נדרשים 16KB לטבלאות הדפים.", "ה. אף אחת מהתשובות אינה נכונה."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "ההסבר מבוסס על חישוב הזיכרון הנדרש לטבלאות דפים עבור כל אחד מהמקרים:\n\n**נתונים:**\n*   כתובת וירטואלית אפקטיבית: 48 ביט (בהתעלם מ-16 הביטים העליונים, כפי שנהוג ב-canonical addressing).\n*   גודל טבלת דפים: 4KB (4096 בתים).\n*   גודל ערך בטבלת דפים (PTE): 8 בתים.\n*   מספר ערכים בטבלת דפים יחידה: 4096 / 8 = 512 ערכים.\n*   כל רמה בטבלת הדפים משתמשת ב- log2(512) = 9 ביטים לאינדוקס.\n*   תהליך ממפה 4GB של זיכרון וירטואלי רציף, החל מ-0 (כלומר 2^32 בתים).\n\n**מקרה א': גודל דף = 4KB**\n*   **Offset:** 12 ביטים (log2(4KB)).\n*   **מספר ביטים לכתובת דף וירטואלי (VPN):** 48 - 12 = 36 ביטים.\n*   מאחר שכל רמה משתמשת ב-9 ביטים, נדרשות 36 / 9 = 4 רמות של טבלאות דפים (בדרך כלל PML4, PDPT, PD, PT).\n*   **מספר דפים וירטואליים בגודל 4KB:** 4GB / 4KB = (2^32) / (2^12) = 2^20 דפים.\n\n1.  **טבלאות דפים (PTs - רמה 1):** כל PT מכיל 512 PTEs וממפה 512 דפים.\n    *   מספר ה-PTs הנדרשים: 2^20 דפים / 512 דפים ל-PT = 2^20 / 2^9 = 2^11 = 2048 PTs.\n    *   זיכרון עבור PTs: 2048 PTs * 4KB/PT = 8MB.\n\n2.  **מדרכי דפים (PDs - רמה 2):** כל PD מכיל 512 PTEs ומצביע על 512 PTs.\n    *   מספר ה-PDs הנדרשים: 2048 PTs / 512 PTs ל-PD = 4 PDs.\n    *   זיכרון עבור PDs: 4 PDs * 4KB/PD = 16KB.\n\n3.  **מדרכי דפים מצביעים (PDPTs - רמה 3):** כל PDPT מכיל 512 PTEs ומצביע על 512 PDs.\n    *   מספר ה-PDPTs הנדרשים: 4 PDs / 512 PDs ל-PDPT = 1 PDPT (כי 4 קטן מ-512).\n    *   זיכרון עבור PDPTs: 1 PDPT * 4KB/PDPT = 4KB.\n\n4.  **טבלת PML4 (רמה 4):** כל PML4 מכיל 512 PTEs ומצביע על 512 PDPTs.\n    *   מספר ה-PML4s הנדרשים: 1 PDPT / 512 PDPTs ל-PML4 = 1 PML4 (כי 1 קטן מ-512).\n    *   זיכרון עבור PML4s: 1 PML4 * 4KB/PML4 = 4KB.\n\n*   **סה\"כ זיכרון לטבלאות דפים במקרה א':** 8MB + 16KB + 4KB + 4KB = 8MB + 24KB.\n\n**מקרה ב': גודל דף = 2MB (דפים גדולים - Huge Pages)**\n*   **Offset:** 21 ביטים (log2(2MB)).\n*   **מספר ביטים לכתובת דף וירטואלי (VPN):** 48 - 21 = 27 ביטים.\n*   מאחר שכל רמה משתמשת ב-9 ביטים, נדרשות 27 / 9 = 3 רמות של טבלאות דפים. במקרה זה, הרמה הנמוכה ביותר (PD) מצביעה ישירות על דפים פיזיים בגודל 2MB.\n*   **מספר דפים וירטואליים בגודל 2MB:** 4GB / 2MB = (2^32) / (2^21) = 2^11 = 2048 דפים.\n\n1.  **מדרכי דפים (PDs - רמה 1, מצביעה על דפים פיזיים):** כל PD מכיל 512 PTEs וממפה 512 דפים בגודל 2MB.\n    *   מספר ה-PDs הנדרשים: 2^11 דפים / 512 דפים ל-PD = 2^11 / 2^9 = 2^2 = 4 PDs.\n    *   זיכרון עבור PDs: 4 PDs * 4KB/PD = 16KB.\n\n2.  **מדרכי דפים מצביעים (PDPTs - רמה 2):** כל PDPT מכיל 512 PTEs ומצביע על 512 PDs.\n    *   מספר ה-PDPTs הנדרשים: 4 PDs / 512 PDs ל-PDPT = 1 PDPT.\n    *   זיכרון עבור PDPTs: 1 PDPT * 4KB/PDPT = 4KB.\n\n3.  **טבלת PML4 (רמה 3):** כל PML4 מכיל 512 PTEs ומצביע על 512 PDPTs.\n    *   מספר ה-PML4s הנדרשים: 1 PDPT / 512 PDPTs ל-PML4 = 1 PML4.\n    *   זיכרון עבור PML4s: 1 PML4 * 4KB/PML4 = 4KB.\n\n*   **סה\"כ זיכרון לטבלאות דפים במקרה ב':** 16KB + 4KB + 4KB = 24KB.\n\nלכן, התשובה הנכונה היא א'."}, "difficulty_estimation": "Hard", "_source_file": "0598__Paging__MultipleChoice__Hard.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:56:25", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Paging", "Virtual Memory", "Multi-level Page Tables"], "content": {"text": "במערכת הפעלה המשתמשת בזיכרון וירטואלי ובטבלאות דפים רב-שכבתיות, נתונים הפרטים הבאים:\n*   גודל כתובת וירטואלית: 64 ביטים.\n*   גודל דף: 4KB.\n*   גודל כניסה בטבלת דפים (PTE): 8 בתים.\n*   כל טבלת דפים (או ספריית דפים) ממלאת דף אחד בדיוק.\n\nכמה גישות לזיכרון פיזי נדרשות, במקרה הגרוע ביותר (TLB miss), כדי לתרגם כתובת וירטואלית ולגשת לנתון בזיכרון, בהנחה שהדף הנדרש כבר נמצא בזיכרון הפיזי (אין page fault)?", "code_snippet": null, "options": ["א. 5", "ב. 6", "ג. 7", "ד. 8", "ה. 9"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "נחשב תחילה את מספר הביטים המוקצים ל-offset ואת מספר הביטים עבור הכתובת הוירטואלית של הדף (VPN):\n*   גודל דף = 4KB = 2^12 בתים. לכן, ה-offset הוא 12 ביטים.\n*   גודל כתובת וירטואלית = 64 ביטים.\n*   מספר ביטים ל-VPN = 64 - 12 = 52 ביטים.\n\nנחשב כמה כניסות (PTEs) יש בכל טבלת דפים וכמה ביטים נדרשים לאינדקס בכל רמה:\n*   גודל טבלת דפים = גודל דף = 4KB.\n*   גודל כניסה בטבלת דפים (PTE) = 8 בתים.\n*   מספר כניסות בטבלת דפים = 4KB / 8 בתים = 4096 / 8 = 512 כניסות.\n*   מספר ביטים לאינדקס בכל רמה = log2(512) = 9 ביטים.\n\nכעת נחשב את מספר הרמות בטבלת הדפים הרב-שכבתית:\n*   יש לנו 52 ביטים עבור ה-VPN.\n*   כל רמה משתמשת ב-9 ביטים.\n*   52 / 9 = 5 עם שארית 7.\n*   לכן, יהיו 5 רמות שכל אחת מהן משתמשת ב-9 ביטים (5 * 9 = 45 ביטים), ורמה נוספת (הרמה הגבוהה ביותר) שתשתמש ב-7 הביטים הנותרים.\n*   סה\"כ 6 רמות של טבלאות דפים.\n\nבמקרה של TLB miss ואין page fault, נדרשות הגישות הבאות:\n1.  גישה לטבלת הדפים ברמה 1 (PD1). (גישת זיכרון אחת)\n2.  גישה לטבלת הדפים ברמה 2 (PD2). (גישת זיכרון אחת)\n3.  גישה לטבלת הדפים ברמה 3 (PD3). (גישת זיכרון אחת)\n4.  גישה לטבלת הדפים ברמה 4 (PD4). (גישת זיכרון אחת)\n5.  גישה לטבלת הדפים ברמה 5 (PD5). (גישת זיכרון אחת)\n6.  גישה לטבלת הדפים ברמה 6 (PT6) כדי למצוא את ה-PTE של דף הנתונים. (גישת זיכרון אחת)\n    עד כה, 6 גישות זיכרון לטבלאות הדפים.\n7.  גישה לנתון עצמו בזיכרון הפיזי. (גישת זיכרון אחת)\n\nסה\"כ גישות לזיכרון פיזי = 6 (לתרגום הכתובת) + 1 (לגישה לנתון) = 7 גישות."}, "difficulty_estimation": "Hard", "_source_file": "0599__Paging__MultipleChoice__Hard.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:56:44", "_subject": "Virtualization"}, {"id": 101, "type": "MultipleChoice", "topic": ["Virtual Memory", "Paging", "Effective Access Time", "TLB", "Multi-level Paging", "Page Faults"], "content": {"text": "מערכת הפעלה משתמשת בזיכרון וירטואלי עם טבלאות דפים דו-שכבתיות (two-level page tables).\n\nנתונים:\n*   זמן גישה ל-TLB: 20ns\n*   זמן גישה לזיכרון הראשי (RAM): 100ns\n*   שיעור פגיעות ב-TLB (Hit Rate): 98%\n*   שיעור כשל דף (Page Fault Rate): 0.01% (מתוך כל הגישות לזיכרון הווירטואלי שאינן TLB hit)\n*   זמן טיפול בכשל דף (כולל קריאה מהדיסק ועדכון טבלאות דפים, לא כולל גישת נתונים סופית): 10 מילי-שניות (ms)\n\nמהו זמן הגישה האפקטיבי הממוצע לזיכרון (Effective Memory Access Time) בננו-שניות (ns)?", "code_snippet": null, "options": ["א. 124 ns", "ב. 142 ns", "ג. 144 ns", "ד. 143.6 ns", "ה. אף אחת מהתשובות אינה נכונה."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "נחשב את זמן הגישה האפקטיבי הממוצע (EAT) באמצעות הנוסחה הבאה:\nEAT = (שיעור פגיעות TLB) * (זמן גישת TLB + זמן גישת זיכרון לנתונים)\n      + (שיעור החמצות TLB) * [\n          זמן גישת TLB + \n          (שיעור כשל דף) * (מספר רמות טבלת דפים * זמן גישת זיכרון + זמן טיפול בכשל דף + זמן גישת זיכרון לנתונים)\n          + (1 - שיעור כשל דף) * (מספר רמות טבלת דפים * זמן גישת זיכרון + זמן גישת זיכרון לנתונים)\n        ]\n\nנתונים:\n*   t_tlb = 20ns\n*   t_mem = 100ns\n*   p_tlb = 0.98\n*   p_pf = 0.0001 (0.01%)\n*   t_pf_service = 10,000,000ns (10ms)\n*   N_levels = 2\n\nשלב 1: חישוב עבור פגיעת TLB (TLB Hit):\nזמן = p_tlb * (t_tlb + t_mem)\nזמן = 0.98 * (20ns + 100ns)\nזמן = 0.98 * 120ns = 117.6ns\n\nשלב 2: חישוב עבור החמצת TLB (TLB Miss):\nשיעור החמצה = 1 - p_tlb = 1 - 0.98 = 0.02\n\nבמקרה של החמצת TLB, עדיין נדרש זמן גישת TLB (t_tlb = 20ns).\nלאחר מכן, נצטרך לגשת לטבלאות הדפים בזיכרון הראשי. מכיוון שמדובר בטבלאות דו-שכבתיות, זה דורש 2 גישות זיכרון (N_levels * t_mem = 2 * 100ns = 200ns).\nבשלב זה, אנו מגלים אם יש כשל דף.\n\n  א. מקרה של כשל דף (Page Fault) לאחר החמצת TLB:\n     ההסתברות לכשל דף במקרה זה היא p_pf = 0.0001.\n     הזמן הכולל = N_levels * t_mem (לטבלאות דפים) + t_pf_service (לטיפול בכשל) + t_mem (לגישת נתונים סופית לאחר הטעינה)\n     זמן = 2 * 100ns + 10,000,000ns + 100ns = 200ns + 10,000,000ns + 100ns = 10,000,300ns\n     תרומה ל-EAT מגישה זו = p_pf * (10,000,300ns) = 0.0001 * 10,000,300ns = 1000.03ns\n\n  ב. מקרה ללא כשל דף (No Page Fault) לאחר החמצת TLB:\n     ההסתברות ללא כשל דף במקרה זה היא (1 - p_pf) = (1 - 0.0001) = 0.9999.\n     הזמן הכולל = N_levels * t_mem (לטבלאות דפים) + t_mem (לגישת נתונים)\n     זמן = 2 * 100ns + 100ns = 200ns + 100ns = 300ns\n     תרומה ל-EAT מגישה זו = (1 - p_pf) * (300ns) = 0.9999 * 300ns = 299.97ns\n\nשלב 3: שילוב כל החלקים לחישוב EAT סופי:\nEAT = (זמן מפגיעת TLB) + (שיעור החמצות TLB) * [זמן גישת TLB + (תרומה מכשל דף) + (תרומה ללא כשל דף)]\nEAT = 117.6ns + 0.02 * [20ns + 1000.03ns + 299.97ns]\nEAT = 117.6ns + 0.02 * [1320.0ns]\nEAT = 117.6ns + 26.4ns\nEAT = 144ns\n\nלכן, התשובה הנכונה היא ג'."}, "difficulty_estimation": "Hard", "_source_file": "0600__Paging__MultipleChoice__Hard.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:57:15", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Paging", "Virtual Memory", "Memory Management"], "content": {"text": "נתונה מערכת זיכרון וירטואלי עם המאפיינים הבאים:\n*   גודל דף: 4KB\n*   גודל כתובת וירטואלית: 32 ביטים\n*   גודל כתובת פיזית: 28 ביטים\n*   טבלת דפים לינארית, כאשר כל כניסה בטבלת הדפים (PTE) מכילה PFN (Physical Frame Number) וביט Present.\n*   הביט Present (P) הוא 1 אם הדף נמצא בזיכרון הפיזי, ו-0 אם לא.\n\nנתון חלק מטבלת הדפים של תהליך מסוים:\n\n| מספר דף וירטואלי (VPN) | PFN | P |\n|-------------------------|-----|---|\n| 0                       | 10  | 1 |\n| 1                       | 25  | 1 |\n| 2                       | 15  | 1 |\n| 3                       | 0   | 0 |\n| 4                       | 30  | 1 |\n\nענה על השאלות הבאות:", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "מה גודל ההיסט (Offset) בכתובת הוירטואלית בביטים?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "מה גודל מספר הדף הוירטואלי (VPN) בביטים?", "code_snippet": null, "options": null}, {"id": "1.3", "text": "תהליך מבקש לגשת לכתובת וירטואלית `0x00003250`.\n    *   מהו מספר הדף הוירטואלי (VPN) ומהו ההיסט (Offset) עבור כתובת זו?\n    *   האם תתרחש פסיקת דף (Page Fault)? נמק.\n    *   אם לא תתרחש פסיקת דף, מהי הכתובת הפיזית אליה יומר הגישה?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\n1.  **גודל ההיסט (Offset) בכתובת הוירטואלית:**\n    גודל דף נתון כ-4KB.\n    4KB = 4 * 1024 בתים = 2^2 * 2^10 בתים = 2^12 בתים.\n    לכן, גודל ההיסט הוא 12 ביטים.\n\n2.  **גודל מספר הדף הוירטואלי (VPN):**\n    גודל כתובת וירטואלית נתון כ-32 ביטים.\n    גודל ההיסט הוא 12 ביטים (מחישוב קודם).\n    לכן, גודל מספר הדף הוירטואלי (VPN) הוא 32 - 12 = 20 ביטים.\n\n3.  **גישה לכתובת וירטואלית `0x00003250`:**\n    *   **מספר הדף הוירטואלי (VPN) וההיסט (Offset):**\n        הכתובת הוירטואלית `0x00003250` בבסיס 16.\n        נמיר את הכתובת לבסיס 10: `0x00003250` = `3 * 4096 + 640` = `12288 + 640` = `12928` בבתים.\n        לחלופין, נשתמש בחישוב ביטים:\n        כתובת וירטואלית: `0000 0000 0000 0000 0011 0010 0101 0000` (32 ביטים)\n        ה-12 ביטים הימניים הם ההיסט: `0010 0101 0000` = `0x250` = 640 בבתים.\n        ה-20 ביטים השמאליים הם מספר הדף הוירטואלי: `0000 0000 0000 0000 0011` = `0x3` = 3 בבתים.\n        לכן, מספר הדף הוירטואלי (VPN) הוא 3, וההיסט (Offset) הוא `0x250` (או 640 בבתים).\n\n    *   **האם תתרחש פסיקת דף (Page Fault)? נמק:**\n        עבור מספר דף וירטואלי 3, נסתכל בטבלת הדפים הנתונה:\n        | מספר דף וירטואלי (VPN) | PFN | P |\n        |-------------------------|-----|---|\n        | 3                       | 0   | 0 |\n        ביט ה-Present (P) עבור דף 3 הוא 0. משמעות הדבר היא שהדף אינו נמצא בזיכרון הפיזי.\n        לכן, **כן, תתרחש פסיקת דף (Page Fault)**.\n\n    *   **אם לא תתרחש פסיקת דף, מהי הכתובת הפיזית אליה יומר הגישה?**\n        מכיוון שמתרחשת פסיקת דף, הגישה לכתובת זו אינה מומרת לכתובת פיזית באופן מיידי. מערכת ההפעלה תטפל בפסיקת הדף (למשל, על ידי טעינת הדף מהדיסק לזיכרון הפיזי)."}, "difficulty_estimation": "Easy", "_source_file": "0601__Paging__Open__Easy.json", "_topic_hint": "Paging", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:57:35", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Paging", "Virtual Memory", "Memory Management"], "content": {"text": "נתונה מערכת זיכרון וירטואלי המשתמשת במנגנון Paging. גודל דף במערכת הוא 4KB. כל כניסה בטבלת הדפים (Page Table Entry - PTE) היא בגודל 32 ביטים ומכילה את שדה ה-PFN (Page Frame Number) ואת ה-Valid bit.\n\nנתון תהליך אשר טבלת הדפים שלו מכילה את הכניסה הבאה עבור דף וירטואלי מספר 5:\n`PTE עבור דף וירטואלי 5: 0x0000A001`\n\nכאשר:\n*   ה-Valid bit הוא הביט הנמוך ביותר (הביט 0).\n*   שדה ה-PFN תופס את הביטים 1 עד 20.\n\nמהי הכתובת הפיזית אליה תתורגם הכתובת הוירטואלית `0x5123`?", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כדי לתרגם כתובת וירטואלית לכתובת פיזית, נבצע את השלבים הבאים:\n\n1.  **חלוקת הכתובת הוירטואלית למספר דף והיסט:**\n    *   גודל הדף הוא 4KB, כלומר 2^12 בתים. לכן, ההיסט (offset) תופס 12 ביטים (ביטים 0-11).\n    *   הכתובת הוירטואלית הנתונה היא `0x5123`.\n    *   ההיסט הוא 12 הביטים הנמוכים ביותר: `0x123`.\n    *   מספר הדף הוירטואלי הוא שאר הביטים: `0x5123` >> 12 = `0x5`. (כלומר, דף וירטואלי מספר 5).\n\n2.  **בדיקת כניסת טבלת הדפים (PTE) עבור דף וירטואלי 5:**\n    *   ה-PTE הנתון עבור דף וירטואלי 5 הוא `0x0000A001`.\n    *   ה-Valid bit הוא הביט הנמוך ביותר (ביט 0). ערכו הוא 1, מה שאומר שהדף נמצא בזיכרון הפיזי וזמין לשימוש.\n    *   שדה ה-PFN תופס את הביטים 1 עד 20. נחלץ את ה-PFN מה-PTE:\n        *   `0x0000A001` בבינארית: `0000 0000 0000 0000 1010 0000 0000 0001`\n        *   ה-PFN (ביטים 1-20) הוא: `0000 0000 0000 1010 0000` בבינארית, שזה `0x0000A0` בבסיס 16 (או 160 בבסיס 10).\n\n3.  **בניית הכתובת הפיזית:**\n    *   הכתובת הפיזית מורכבת מצירוף ה-PFN וההיסט: `Physical Address = (PFN << 12) | Offset`.\n    *   `Physical Address = (0x0000A0 << 12) | 0x123`\n    *   `0x0000A0` מוזז ב-12 ביטים שמאלה הופך ל-`0xA00000`.\n    *   `0xA00000 | 0x123 = 0xA00123`.\n\nלכן, הכתובת הפיזית היא `0xA00123`."}, "difficulty_estimation": "Easy", "_source_file": "0602__Paging__Open__Easy.json", "_topic_hint": "Paging", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:57:52", "_subject": "Virtualization"}, {"id": 8, "type": "Open", "topic": ["Paging", "Memory Management", "Virtual Memory"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם מנגנון Paging. גודל דף הוא 256 בתים. הכתובות הוירטואליות הן בנות 16 ביטים, והכתובות הפיזיות הן בנות 12 ביטים. טבלת הדפים היא לינארית. כל כניסה בטבלת הדפים (PTE) היא בגודל 1 בית, כאשר 4 הביטים הימניים ביותר הם PFN ו-4 הביטים השמאליים ביותר הם ביטויי בקרה. נניח שביטויי הבקרה מסודרים משמאל לימין (הביט המשמעותי ביותר של ה-PTE) באופן הבא: V (Valid), P (Present), D (Dirty), A (Accessed).", "code_snippet": null, "options": null}, "sub_questions": [{"id": "8.1", "text": "כמה ביטים מוקצים ל-Offset וכמה ביטים מוקצים ל-Virtual Page Number (VPN) בכתובת וירטואלית?", "code_snippet": null, "options": null}, {"id": "8.2", "text": "מהו המספר המקסימלי של כניסות בטבלת הדפים? מהו גודלה המקסימלי של טבלת הדפים בבתים?", "code_snippet": null, "options": null}, {"id": "8.3", "text": "תהליך ניגש לכתובת וירטואלית 0x1234. נתון כי הכניסה בטבלת הדפים עבור הדף המתאים היא 0x4B (בבסיס 16). האם תתרחש פסיקת דף (Page Fault)? אם לא, מהי הכתובת הפיזית המתאימה? הסבירו ופרטו את כל החישובים.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\n**סעיף 8.1:**\n*   גודל דף הוא 256 בתים. מכיוון ש-2^8 = 256, מספר הביטים המוקצים ל-Offset הוא 8 ביטים.\n*   הכתובות הוירטואליות הן בנות 16 ביטים. לכן, מספר הביטים המוקצים ל-Virtual Page Number (VPN) הוא 16 - 8 = 8 ביטים.\n\n**סעיף 8.2:**\n*   מספר הביטים של ה-VPN הוא 8, ולכן המספר המקסימלי של דפים וירטואליים הוא 2^8 = 256.\n*   מספר הכניסות בטבלת הדפים שווה למספר הדפים הוירטואליים המקסימלי, כלומר 256 כניסות.\n*   כל כניסה בטבלת הדפים (PTE) היא בגודל 1 בית. לכן, גודלה המקסימלי של טבלת הדפים הוא 256 כניסות * 1 בית/כניסה = 256 בתים.\n\n**סעיף 8.3:**\n*   הכתובת הוירטואלית הנתונה היא 0x1234.\n*   נמיר את הכתובת הוירטואלית לייצוג בינארי: 0x1234 = 0001 0010 0011 0100.\n*   כפי שחישבנו בסעיף 8.1, ה-Offset מורכב מ-8 הביטים הימניים ביותר: 0011 0100 = 0x34.\n*   ה-Virtual Page Number (VPN) מורכב מ-8 הביטים השמאליים ביותר: 0001 0010 = 0x12 (דף וירטואלי מספר 18 בבסיס עשרוני).\n*   נתון כי הכניסה בטבלת הדפים (PTE) עבור דף 0x12 היא 0x4B.\n*   נמיר את ה-PTE לייצוג בינארי: 0x4B = 0100 1011.\n*   לפי הגדרת השאלה, 4 הביטים השמאליים ביותר הם ביטויי הבקרה (V, P, D, A) ו-4 הביטים הימניים ביותר הם ה-PFN.\n    *   ביטויי הבקרה: 0100. לפי הסדר V=0, P=1, D=0, A=0.\n    *   PFN (מספר מסגרת פיזית): 1011 = 0xB (בבסיס 16).\n*   ביט ה-Present (P) הוא 1. מכיוון ש-P=1, הדף נמצא בזיכרון הפיזי, ולכן **לא תתרחש פסיקת דף (Page Fault)**.\n*   הכתובת הפיזית מורכבת מחיבור ה-PFN וה-Offset:\n    *   PFN בבינארי: 1011\n    *   Offset בבינארי: 0011 0100\n    *   הכתובת הפיזית בבינארי: 1011 0011 0100\n    *   נמיר לכתובת פיזית בבסיס 16: 0xB34."}, "difficulty_estimation": "Easy", "_source_file": "0604__Paging__Open__Easy.json", "_topic_hint": "Paging", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:58:28", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Paging", "Virtual Memory", "Memory Management"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם מנגנון Paging. גודל דף במערכת הוא 4KB. הזיכרון הוירטואלי הוא בגודל 32 ביטים. הזיכרון הפיזי הוא בגודל 20 ביטים. לכל תהליך יש טבלת דפים לינארית. כל כניסה בטבלת הדפים (PTE) מכילה את מספר המסגרת הפיזית (PFN) וביט נוכחות (Present bit).\nנתונה טבלת דפים חלקית של תהליך מסוים:\n\n| מספר דף וירטואלי (VPN) | PFN | Present Bit |\n|-------------------------|-----|-------------|\n| 0                       | 10  | 1           |\n| 1                       | 15  | 1           |\n| 2                       | -   | 0           |\n| 3                       | 22  | 1           |\n| 4                       | 12  | 1           |\n\nיש לפרט ולנמק את כל החישובים.\n\nא) מהו מספר הביטים המוקצים למספר הדף הוירטואלי (VPN) ומהו מספר הביטים המוקצים להיסט הדף (Offset) בכתובת וירטואלית?\nב) תהליך ניגש לכתובת וירטואלית `0x3A50`. האם תתרחש פסיקת דף (Page Fault)? אם לא, מהי הכתובת הפיזית המתאימה?", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א) חישוב ביטים ל-VPN ולהיסט:\nגודל דף הוא 4KB, שזה 4 * 1024 בתים = 4096 בתים. מכיוון ש-2^12 = 4096, ההיסט (Offset) בכתובת הוירטואלית דורש 12 ביטים.\nגודל הכתובת הוירטואלית הכולל הוא 32 ביטים.\nמספר הביטים המוקצים למספר הדף הוירטואלי (VPN) הוא סך הביטים בכתובת הוירטואלית פחות ביטי ההיסט: 32 - 12 = 20 ביטים.\n\nב) ניגשים לכתובת וירטואלית `0x3A50`:\nראשית, נפריד את הכתובת הוירטואלית למספר דף וירטואלי (VPN) ולהיסט (Offset):\nהכתובת `0x3A50` בבינארי (עבור 32 ביטים, נתמקד בחלקים הרלוונטיים): `00...0011101001010000`.\nההיסט הוא 12 הביטים הפחות משמעותיים: `0xA50` (הקסדצימלי) או `101001010000` (בינארי).\nמספר הדף הוירטואלי (VPN) הוא הביטים הנותרים: `0x3` (הקסדצימלי) או `0011` (בינארי).\n\nנבדוק את טבלת הדפים עבור VPN = 3:\nבטבלה הנתונה, עבור VPN=3, ה-PFN הוא 22 וביט ה-Present הוא 1. מכיוון שביט ה-Present הוא 1, הדף נמצא בזיכרון הפיזי, ולכן לא תתרחש פסיקת דף (Page Fault).\n\nכעת נחשב את הכתובת הפיזית:\nהכתובת הפיזית נוצרת על ידי שרשור ה-PFN (מספר המסגרת הפיזית) עם ההיסט.\nגודל הזיכרון הפיזי הוא 20 ביטים. ההיסט הוא 12 ביטים, לכן ה-PFN תופס 20 - 12 = 8 ביטים.\nPFN = 22 (עשרוני) = `00010110` (בינארי, 8 ביטים).\nOffset = `0xA50` (הקסדצימלי) = `101001010000` (בינארי, 12 ביטים).\nהכתובת הפיזית בבינארי היא: `00010110` (PFN) `101001010000` (Offset) = `00010110101001010000`.\nהמרת הכתובת הפיזית להקסדצימלית: `0x16A50`."}, "difficulty_estimation": "Easy", "_source_file": "0605__Paging__Open__Easy.json", "_topic_hint": "Paging", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:58:51", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Paging", "Virtual Memory"], "content": {"text": "נתונה מערכת זיכרון וירטואלי עם גודל דף של 4KB. תהליך ניגש לכתובת וירטואלית 0xABCDE. ידוע שרשומת טבלת הדפים (PTE) עבור הדף הוירטואלי המתאים מצביעה על מספר מסגרת פיזית (PFN) 0x123. בהנחה שהדף נמצא בזיכרון (Present bit = 1), מהי הכתובת הפיזית המתקבלת? פרטו את החישובים.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כדי לחשב את הכתובת הפיזית, עלינו לפרק את הכתובת הוירטואלית למספר דף וירטואלי (VPN) ולהיסט בתוך הדף (Offset), ולאחר מכן להחליף את ה-VPN במספר מסגרת פיזית (PFN) שניתן לנו.\n\n1.  **קביעת גודל ההיסט (Offset):**\n    גודל הדף הוא 4KB.\n    4KB = 4 * 1024 בתים = 4096 בתים.\n    מכיוון ש-2^12 = 4096, ההיסט בתוך הדף דורש 12 ביטים.\n\n2.  **פירוק הכתובת הוירטואלית:**\n    הכתובת הוירטואלית הנתונה היא 0xABCDE.\n    נמיר לבינארי (אפשר לחשוב עליה כ-20 ביטים לצורך העניין, למרות שגודל הכתובת הוירטואלית לא נתון במפורש, זה מספיק לחישוב):\n    0xABCDE = 1010 1011 1100 1101 1110 (בינארי)\n\n    *   **היסט (Offset):** 12 הביטים הפחות משמעותיים של הכתובת הוירטואלית.\n        Offset = 0xCDE (הביטים 1100 1101 1110)\n\n    *   **מספר דף וירטואלי (VPN):** הביטים הנותרים (המשמעותיים יותר).\n        VPN = 0xAB (הביטים 1010 1011)\n\n3.  **בניית הכתובת הפיזית:**\n    נתון שמספר המסגרת הפיזית (PFN) המתאים ל-VPN זה הוא 0x123.\n\n    הכתובת הפיזית נוצרת על ידי שילוב ה-PFN עם ההיסט:\n    Physical Address = (PFN << Offset_bits) | Offset\n    Physical Address = (0x123 << 12) | 0xCDE\n\n    נחשב:\n    0x123 << 12 = 0x123000 (מזיזים את 0x123 ב-12 ביטים שמאלה, כלומר מוסיפים 12 אפסים בסוף, שזה שקול לכפל ב-2^12).\n\n    Physical Address = 0x123000 + 0xCDE = 0x123CDE\n\nהכתובת הפיזית המתקבלת היא 0x123CDE."}, "difficulty_estimation": "Easy", "_source_file": "0606__Paging__Open__Easy.json", "_topic_hint": "Paging", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:59:04", "_subject": "Virtualization"}, {"id": 8, "type": "Open", "topic": ["Paging", "Virtual Memory", "Memory Management"], "content": {"text": "נתונה מערכת המשתמשת בזיכרון וירטואלי עם מנגנון Paging. גודל דף במערכת הוא 4KB.\nתהליך מסוים מנסה לגשת לכתובת וירטואלית 0x12345.\nידוע כי הדף הוירטואלי המתאים לכתובת זו ממופה למסגרת פיזית (PFN) מספר 0xABC.\nמהי הכתובת הפיזית אליה יגשת התהליך? פרטו את החישוב.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסבר:\n1.  **גודל ההיסט (Offset):** גודל הדף הוא 4KB, שזה 4096 בתים. כדי לייצג 4096 כתובות בתוך דף, נדרשים 12 ביטים (2^12 = 4096). לכן, 12 הביטים הפחות משמעותיים של הכתובת הוירטואלית מהווים את ההיסט בתוך הדף.\n2.  **פירוק הכתובת הוירטואלית:** הכתובת הוירטואלית הנתונה היא 0x12345.\n    *   ההיסט (Offset) הוא 12 הביטים הימניים: 0x345.\n    *   מספר הדף הוירטואלי (Virtual Page Number - VPN) הוא הביטים הנותרים משמאל: 0x12.\n3.  **חישוב הכתובת הפיזית:** הכתובת הפיזית מורכבת מצירוף של מספר המסגרת הפיזית (Page Frame Number - PFN) וההיסט.\n    *   מספר המסגרת הפיזית הנתון (PFN) הוא 0xABC.\n    *   הכתובת הפיזית המתקבלת היא PFN משולב עם ההיסט. במילים אחרות, PFN מוזז שמאלה במספר ביטים השווה לגודל ההיסט (12 ביטים), ואז מוסיפים לו את ההיסט.\n    *   כתובת פיזית = (PFN << גודל היסט) | היסט\n    *   כתובת פיזית = (0xABC << 12) | 0x345\n    *   כתובת פיזית = 0xABC000 + 0x345 = 0xABC345\n\n**הכתובת הפיזית אליה יגשת התהליך היא 0xABC345.**"}, "difficulty_estimation": "Easy", "_source_file": "0607__Paging__Open__Easy.json", "_topic_hint": "Paging", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:59:16", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Paging", "Virtual Memory", "Memory Management"], "content": {"text": "נתונה מערכת זיכרון וירטואלי המשתמשת במנגנון Paging עם גודל דף של 4KB. כתובת וירטואלית במערכת היא בת 32 ביטים. טבלת הדפים היא לינארית, וכל כניסה בטבלת הדפים (PTE) מכילה את מספר מסגרת הדף הפיזית (PFN) ואת ביט ה-Present (P).\nלהלן חלק מטבלת הדפים של תהליך מסוים:\n\n| מספר דף וירטואלי (VPN) | PFN (הקסדצימלי) | P (Present Bit) |\n|-------------------------|-------------------|-----------------|\n| 0x00000                 | 0x00001           | 1               |\n| 0x00001                 | -                 | 0               |\n| 0x00002                 | 0x00011           | 1               |\n| 0x00003                 | -                 | 0               |\n| 0x00004                 | 0x00015           | 1               |\n\nיש לפרט ולנמק את כל החישובים.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "מהו מספר הביטים המוקצים למספר הדף הוירטואלי (VPN) ומהו מספר הביטים המוקצים להיסט (Offset) בכתובת וירטואלית?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "נתונה הכתובת הוירטואלית `0x0000405A`. מהו מספר הדף הוירטואלי וההיסט עבור כתובת זו?", "code_snippet": null, "options": null}, {"id": "1.3", "text": "תרגם את הכתובת הוירטואלית `0x0000405A` לכתובת פיזית. פרט את שלבי החישוב. האם תתרחש פסיקת דף (Page Fault)?", "code_snippet": null, "options": null}, {"id": "1.4", "text": "תרגם את הכתובת הוירטואלית `0x000030FF` לכתובת פיזית. פרט את שלבי החישוב. האם תתרחש פסיקת דף (Page Fault)?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\n1.1. גודל דף הוא 4KB, כלומר 2^12 בתים. לכן, ההיסט (Offset) דורש 12 ביטים.\nהכתובת הוירטואלית היא בת 32 ביטים. לכן, מספר הדף הוירטואלי (VPN) דורש 32 - 12 = 20 ביטים.\n\n1.2. הכתובת הוירטואלית הנתונה היא `0x0000405A`.\nכדי לחלץ את ה-VPN ואת ההיסט, נפריד את 12 הביטים הפחות משמעותיים עבור ההיסט, ואת 20 הביטים המשמעותיים ביותר עבור ה-VPN.\nהיסט (Offset): 12 הביטים הימניים ביותר של `0x0000405A` הם `0x05A`.\nמספר דף וירטואלי (VPN): 20 הביטים השמאליים ביותר של `0x0000405A` הם `0x00004`.\n\n1.3. נתרגם את הכתובת הוירטואלית `0x0000405A` לכתובת פיזית:\nשלב 1: מצא את ה-VPN ואת ההיסט (כפי שחושב בסעיף 1.2).\n   VPN = `0x00004`\n   Offset = `0x05A`\nשלב 2: חפש את ה-VPN בטבלת הדפים.\n   עבור VPN `0x00004`, טבלת הדפים מראה: PFN = `0x00015`, P = 1.\nשלב 3: בדוק את ביט ה-Present (P).\n   P = 1, כלומר הדף נמצא בזיכרון הפיזי. לכן, לא תתרחש פסיקת דף (Page Fault).\nשלב 4: חשב את הכתובת הפיזית.\n   הכתובת הפיזית מורכבת מ-PFN מוזז שמאלה במספר ביטי ההיסט, בתוספת ההיסט.\n   PFN = `0x00015`.\n   הזזת PFN שמאלה ב-12 ביטים (כגודל ההיסט): `0x00015 << 12` = `0x00015000`.\n   הוסף את ההיסט: `0x00015000 + 0x05A` = `0x0001505A`.\n   הכתובת הפיזית היא `0x0001505A`.\n\n1.4. נתרגם את הכתובת הוירטואלית `0x000030FF` לכתובת פיזית:\nשלב 1: מצא את ה-VPN ואת ההיסט.\n   היסט (Offset): 12 הביטים הימניים ביותר של `0x000030FF` הם `0x0FF`.\n   מספר דף וירטואלי (VPN): 20 הביטים השמאליים ביותר של `0x000030FF` הם `0x00003`.\nשלב 2: חפש את ה-VPN בטבלת הדפים.\n   עבור VPN `0x00003`, טבלת הדפים מראה: P = 0 (ו-PFN לא רלוונטי במקרה זה).\nשלב 3: בדוק את ביט ה-Present (P).\n   P = 0, כלומר הדף אינו נמצא בזיכרון הפיזי. לכן, תתרחש פסיקת דף (Page Fault).\n   לא ניתן לקבוע כתובת פיזית במקרה זה ללא טיפול בפסיקת הדף."}, "difficulty_estimation": "Easy", "_source_file": "0608__Paging__Open__Easy.json", "_topic_hint": "Paging", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:59:45", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Paging", "Virtual Memory", "Memory Management", "Multi-level Paging"], "content": {"text": "נתונה מערכת עם זיכרון וירטואלי של 2GB, גודל דף של 4KB, וזיכרון פיזי של 256MB. המערכת משתמשת בטבלת דפים דו-רמתית (Two-Level Paging). כל כניסה בטבלת הדפים (PTE) מכילה מספר מסגרת פיזית (PFN), ביט Valid, ביט Dirty וביט Accessed. גודל כל טבלת דפים (רמה 1 או רמה 2) הוא דף יחיד.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "10.1", "text": "מהם הגדלים של ה-VPN וה-PFN? (בביטים)\nVPN: ________ ביטים\nPFN: ________ ביטים", "code_snippet": null, "options": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. זיכרון וירטואלי 2GB = 2^31 בתים, לכן כתובת וירטואלית היא 31 ביטים.\n   גודל דף 4KB = 2^12 בתים, לכן ההיסט (offset) הוא 12 ביטים.\n   VPN = 31 - 12 = 19 ביטים.\n2. זיכרון פיזי 256MB = 2^28 בתים, לכן כתובת פיזית היא 28 ביטים.\n   ההיסט זהה – 12 ביטים.\n   PFN = 28 - 12 = 16 ביטים."}}, {"id": "10.2", "text": "כמה ביטים מוקצים לכל אינדקס בטבלת הדפים ברמה הראשונה (P1) וברמה השנייה (P2)?\nP1: ________ ביטים\nP2: ________ ביטים", "code_snippet": null, "options": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. גודל PTE: PFN (16 ביטים) + 3 ביטים (Valid, Dirty, Accessed) = 19 ביטים. כדי ליישר לבית הקרוב (או למילה), מעגלים ל-32 ביטים, כלומר 4 בתים לכל PTE.\n2. מספר כניסות לדף: גודל דף / גודל PTE = 4KB / 4 בתים = 1024 כניסות. כדי לאנדקס 1024 כניסות, נדרשים 10 ביטים (2^10 = 1024).\n3. ה-VPN הוא 19 ביטים (מסעיף קודם). אם P1 משתמש ב-10 ביטים, אז P2 ישתמש ב-19 - 10 = 9 ביטים.\n   P1: 10 ביטים.\n   P2: 9 ביטים."}}, {"id": "10.3", "text": "מהו הגודל הכולל (בבתים) של טבלאות הדפים הנדרשות עבור תהליך המשתמש במלוא מרחב הכתובות הוירטואלי שלו?\nגודל כולל: ________ בתים", "code_snippet": null, "options": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. טבלת דפים ברמה 1 (L1) תופסת דף יחיד, כלומר 4KB.\n2. תהליך המשתמש במלוא מרחב הכתובות הוירטואלי שלו, פירושו שכל כניסה בטבלת L1 מפנה לטבלת L2. מכיוון שטבלת L1 מכילה 1024 כניסות (לפי סעיף קודם), יהיו 1024 טבלאות L2.\n3. כל טבלת L2 תופסת דף יחיד, כלומר 4KB.\n4. סך הזיכרון עבור טבלאות L2 = 1024 * 4KB = 4096KB.\n5. סך הזיכרון הכולל עבור כל טבלאות הדפים = זיכרון L1 + זיכרון L2 = 4KB + 4096KB = 4100KB.\n6. המרה לבתים: 4100KB = 4100 * 1024 בתים = 4,198,400 בתים."}}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": null}, "difficulty_estimation": "Medium", "_source_file": "0609__Paging__Open__Medium.json", "_topic_hint": "Paging", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:00:01", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Paging", "Memory Management", "Virtual Memory", "Multi-level Paging"], "content": {"text": "נתונה מערכת המשתמשת במנגנון ריבוד כפול של טבלאות דפים (two-level paging) עם המאפיינים הבאים:\n- גודל זיכרון וירטואלי: 4GB\n- גודל זיכרון פיזי: 256MB\n- גודל דף: 4KB\n- גודל כל כניסה בטבלת הדפים (PTE): 4 בתים\n\nהמערכת מחלקת את ה-VPN לשני חלקים שווים (P1 ו-P2).\n\nא. מהם הגדלים של ה-VPN וה-PFN בביטים?\nVPN: ____ ביטים, PFN: ____ ביטים\n\nב. כמה רשומות יכולה להכיל כל טבלת דפים (חיצונית ופנימית)?\nמספר רשומות: ____\n\nג. כמה זיכרון פיזי, במינימום, תתפוס טבלת הדפים של תהליך המשתמש ב-100 דפים וירטואליים רציפים החל מכתובת 0?", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. כתובת וירטואלית היא 32 ביטים (זיכרון וירטואלי 4GB). היסט הדף הוא 12 ביטים (גודל דף 4KB = 2^12 בתים). לכן, ה-VPN הוא 32 - 12 = 20 ביטים.\nכתובת פיזית היא 28 ביטים (זיכרון פיזי 256MB = 2^28 בתים). היסט הדף זהה – 12 ביטים. לכן, ה-PFN הוא 28 - 12 = 16 ביטים.\n\nב. גודל דף הוא 4KB. גודל כניסה בטבלת דפים (PTE) הוא 4 בתים. לכן, כל טבלת דפים יכולה להכיל 4KB / 4B = 1024 רשומות.\n\nג. ה-VPN הוא 20 ביטים. מכיוון שהוא מחולק לשני חלקים שווים (P1 ו-P2), כל אחד מהם הוא 10 ביטים. כל 10 ביטים יכולים לייצג 2^10 = 1024 ערכים, וזה תואם למספר הרשומות בכל טבלת דפים (1024).\nתהליך המשתמש ב-100 דפים וירטואליים רציפים החל מכתובת 0 פירושו שרק כניסה אחת בטבלת הדפים החיצונית (עבור P1=0) תהיה בשימוש, והיא תצביע על טבלת דפים פנימית אחת. טבלת הדפים הפנימית הזו תכיל 100 רשומות תקפות (עבור P2 מ-0 עד 99).\nלכן, נדרשת טבלת דפים חיצונית אחת וטבלת דפים פנימית אחת. כל טבלת דפים תופסת דף פיזי אחד (4KB).\nסה\"כ זיכרון פיזי עבור הטבלאות: 1 (טבלה חיצונית) * 4KB + 1 (טבלה פנימית) * 4KB = 8KB."}, "difficulty_estimation": "Medium", "_source_file": "0610__Paging__Open__Medium.json", "_topic_hint": "Paging", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:00:18", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Memory Management", "Virtual Memory", "Paging", "Two-level Paging"], "content": {"text": "נתונה מערכת המשתמשת בזיכרון וירטואלי בגודל 16MB ובזיכרון פיזי בגודל 4MB. גודל דף הוא 4KB. המערכת מיישמת מנגנון דפדוף דו-שכבתי (two-level paging), כאשר כל טבלת דפים (גם השכבה החיצונית וגם הפנימית) מאוחסנת במסגרת דף בודדת. כל כניסה בטבלת הדפים (PTE) מכילה מספר מסגרת פיזית (PFN) ושלושה ביטים לבקרה (Valid, Dirty, Accessed), ומעוגלת לגודל מינימלי בחזקת 2 עבור אחסון.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "10.1", "text": "א. מה גודל כתובת וירטואלית וכתובת פיזית בביטים? מהו גודל ה-Offset, ה-VPN וה-PFN בביטים?\nכתובת וירטואלית: ____ ביטים\nכתובת פיזית: ____ ביטים\nOffset: ____ ביטים\nVPN: ____ ביטים\nPFN: ____ ביטים", "code_snippet": null, "options": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. גודל זיכרון וירטואלי 16MB = 2^24 בתים, לכן כתובת וירטואלית היא 24 ביטים.\nגודל זיכרון פיזי 4MB = 2^22 בתים, לכן כתובת פיזית היא 22 ביטים.\nגודל דף 4KB = 2^12 בתים, לכן ה-Offset הוא 12 ביטים.\nVPN (Virtual Page Number) = כתובת וירטואלית - Offset = 24 - 12 = 12 ביטים.\nPFN (Physical Frame Number) = כתובת פיזית - Offset = 22 - 12 = 10 ביטים."}}, {"id": "10.2", "text": "ב. כמה ביטים מוקצים לכל אינדקס בטבלת הדפים (עבור השכבה החיצונית והפנימית)?\nאינדקס טבלה חיצונית: ____ ביטים\nאינדקס טבלה פנימית: ____ ביטים", "code_snippet": null, "options": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "2. כל כניסה בטבלת הדפים (PTE) מכילה PFN (10 ביטים) ועוד 3 ביטים לבקרה (Valid, Dirty, Accessed), סה\"כ 13 ביטים. המינימום בחזקת 2 לאחסון הוא 16 ביטים, כלומר 2 בתים לכל PTE.\nגודל דף הוא 4KB = 4096 בתים. מכיוון שכל טבלת דפים מאוחסנת במסגרת דף בודדת, טבלת דפים יכולה להכיל לכל היותר 4096 בתים / 2 בתים/כניסה = 2048 כניסות.\nלכן, כל אינדקס בטבלת הדפים (PT1 ו-PT2) יכול להיות בגודל log2(2048) = 11 ביטים.\nמכיוון שה-VPN הוא 12 ביטים, נחלק אותו ל-PT1 ו-PT2. כדי לנצל את גודל הדף ביעילות עבור טבלאות הדפים הפנימיות (שממפות את הדפים הפיזיים בפועל), נבחר ש-PT2 יהיה 11 ביטים. ואז PT1 יהיה 12 - 11 = 1 ביט.\nלכן, אינדקס טבלה חיצונית (PT1) הוא 1 ביט, ואינדקס טבלה פנימית (PT2) הוא 11 ביטים."}}, {"id": "10.3", "text": "ג. כמה זיכרון פיזי תתפוסנה טבלאות הדפים עבור תהליך הממפה את כל המרחב הווירטואלי שלו?\nזיכרון כולל לטבלאות דפים: ____ KB", "code_snippet": null, "options": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "3. טבלת הדפים החיצונית (PT1) דורשת מסגרת דף אחת. היא מכילה 2^1 = 2 כניסות. גודלה בפועל הוא 2 כניסות * 2 בתים/כניסה = 4 בתים, אך היא תופסת מסגרת דף שלמה בזיכרון הפיזי (4KB).\nמכיוון שהתהליך ממפה את כל המרחב הווירטואלי, כל הכניסות ב-PT1 יהיו תקפות (valid) ויצביעו על טבלאות דפים פנימיות.\nכל אחת מ-2 הכניסות ב-PT1 מצביעה על טבלת דפים פנימית (PT2) נפרדת. כל טבלת PT2 תופסת מסגרת דף אחת בזיכרון הפיזי (4KB).\nלכן, סך הזיכרון הפיזי הנדרש עבור טבלאות הדפים הוא: 1 מסגרת דף עבור PT1 + 2 מסגרות דף עבור PT2 (אחת לכל כניסה תקפה ב-PT1) = 4KB + (2 * 4KB) = 4KB + 8KB = 12KB."}}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": null}, "difficulty_estimation": "Medium", "_source_file": "0611__Paging__Open__Medium.json", "_topic_hint": "Paging", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:00:43", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Memory Management", "Paging", "Virtual Memory", "Two-level Paging"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם כתובות באורך 32 ביטים. גודל הזיכרון הפיזי הוא 16MB. גודל הדף במערכת הוא 4KB. המערכת משתמשת במנגנון Paging דו-שלבי, כאשר כל כניסה בטבלת הדפים (PTE) היא בגודל 4 בתים.\n\nענה על השאלות הבאות:\n1. מהו מספר הביטים הנדרש עבור ה-VPN (Virtual Page Number)?\n2. מהו מספר הביטים הנדרש עבור ה-PFN (Physical Frame Number)?\n3. כמה ביטים מוקצים לכל רמה ב-VPN (VPN1 ו-VPN2)?\n4. מהו נפח הזיכרון הפיזי המקסימלי שיידרש עבור טבלאות הדפים של תהליך יחיד, הממפה את כל מרחב הכתובות הוירטואלי שלו?", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "להלן הפתרון המלא:\n\n1.  **חישוב VPN (Virtual Page Number):**\n    *   אורך כתובת וירטואלית: 32 ביטים (נתון).\n    *   גודל דף: 4KB = 2^12 בתים. לכן, ההיסט (offset) בתוך הדף הוא 12 ביטים.\n    *   VPN = אורך כתובת וירטואלית - היסט = 32 ביטים - 12 ביטים = 20 ביטים.\n\n2.  **חישוב PFN (Physical Frame Number):**\n    *   גודל זיכרון פיזי: 16MB = 2^24 בתים. לכן, אורך כתובת פיזית הוא 24 ביטים.\n    *   היסט: 12 ביטים (זהה לגודל הדף).\n    *   PFN = אורך כתובת פיזית - היסט = 24 ביטים - 12 ביטים = 12 ביטים.\n\n3.  **חלוקת ביטים עבור VPN1 ו-VPN2:**\n    *   כל כניסה בטבלת הדפים (PTE) היא בגודל 4 בתים (נתון).\n    *   גודל דף הוא 4KB. מספר הכניסות שיכולות להיכנס לדף אחד הוא: 4KB / 4 בתים/כניסה = 1024 כניסות.\n    *   לכן, כל אינדקס בטבלה (בין אם זה אינדקס למדריך הדפים ברמה 1 או אינדקס לטבלת הדפים ברמה 2) צריך לייצג 1024 ערכים, מה שדורש 10 ביטים (כי 2^10 = 1024).\n    *   VPN1 (אינדקס למדריך הדפים ברמה הראשונה) = 10 ביטים.\n    *   VPN2 (אינדקס לטבלת הדפים ברמה השנייה) = 10 ביטים.\n    *   סך הכל VPN = 10 ביטים (VPN1) + 10 ביטים (VPN2) = 20 ביטים, כפי שחושב בסעיף 1.\n\n4.  **נפח זיכרון פיזי מקסימלי עבור טבלאות הדפים של תהליך יחיד:**\n    *   **מדריך הדפים (Page Directory - רמה 1):**\n        *   מדריך הדפים מכיל 2^VPN1 כניסות = 2^10 = 1024 כניסות.\n        *   גודל מדריך הדפים: 1024 כניסות * 4 בתים/כניסה = 4096 בתים = 4KB. (זה תופס בדיוק דף פיזי אחד).\n    *   **טבלאות הדפים ברמה 2:**\n        *   במקרה הגרוע ביותר, אם התהליך ממפה את כל מרחב הכתובות הוירטואלי שלו, הוא יזדקק לכל טבלאות הדפים ברמה 2 האפשריות. יש 2^VPN1 אפשרויות לטבלאות רמה 2, כלומר 1024 טבלאות כאלה.\n        *   כל טבלת דפים ברמה 2 היא בגודל 4KB (כפי שחושב לעיל, מכילה 1024 כניסות של 4 בתים).\n        *   גודל כולל של טבלאות רמה 2: 1024 טבלאות * 4KB/טבלה = 4MB.\n    *   **סה\"כ זיכרון פיזי מקסימלי עבור טבלאות הדפים:**\n        *   גודל מדריך הדפים + גודל טבלאות רמה 2 = 4KB + 4MB.\n        *   סה\"כ = 4,198,400 בתים (או 4MB + 4KB)."}, "difficulty_estimation": "Medium", "_source_file": "0612__Paging__Open__Medium.json", "_topic_hint": "Paging", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:01:00", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Memory Management", "Virtual Memory", "Paging", "Multi-level Paging"], "content": {"text": "נתונה מערכת עם זיכרון וירטואלי של 4GB, גודל דף של 4KB, וזיכרון פיזי של 1GB.\nמנגנון ניהול הזיכרון הוא Paging דו-שכבתי (Two-level Paging).\nגודל כל רשומה בטבלת הדפים (PTE) ובספריית הדפים (PDE) הוא 4 בתים.\n\nמהם הגדלים של ה-VPN, ה-PFN, כמה ביטים מוקצים לאינדקס הרמה הראשונה (Page Directory Index), וכמה ביטים לאינדקס הרמה השנייה (Page Table Index)? כמה זיכרון פיזי תתפוס לכל היותר טבלת הדפים (כולל ספריית הדפים) של תהליך יחיד, אם הוא ממפה את כל מרחב הכתובות הוירטואלי שלו?\n\nגודל VPN: ____\nגודל PFN: ____\nביטים לאינדקס רמה 1 (PDI): ____\nביטים לאינדקס רמה 2 (PTI): ____\nגודל טבלה מקסימלי: ____", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  **חישוב גודל כתובות וירטואליות ופיזיות, והיסט דף:**\n    *   זיכרון וירטואלי 4GB = 2^32 בתים, לכן כתובת וירטואלית היא 32 ביטים.\n    *   זיכרון פיזי 1GB = 2^30 בתים, לכן כתובת פיזית היא 30 ביטים.\n    *   גודל דף 4KB = 2^12 בתים, לכן ההיסט (offset) בתוך הדף הוא 12 ביטים.\n\n2.  **חישוב VPN ו-PFN:**\n    *   **VPN (Virtual Page Number):** מספר ביטים לכתובת וירטואלית - מספר ביטים להיסט = 32 - 12 = **20 ביטים**.\n    *   **PFN (Physical Frame Number):** מספר ביטים לכתובת פיזית - מספר ביטים להיסט = 30 - 12 = **18 ביטים**.\n\n3.  **חישוב ביטים לאינדקסים במנגנון דו-שכבתי:**\n    *   כל דף (או טבלת דפים/ספריית דפים) הוא בגודל 4KB. גודל כל רשומה (PTE או PDE) הוא 4 בתים.\n    *   מספר הרשומות שניתן לאחסן בדף יחיד = גודל דף / גודל רשומה = 4KB / 4B = 1024 רשומות.\n    *   כדי לייצג 1024 רשומות, נדרשים log2(1024) = 10 ביטים.\n    *   במנגנון Paging דו-שכבתי, ה-VPN מתחלק לשני אינדקסים: אינדקס לספריית הדפים (PDI) ואינדקס לטבלת הדפים (PTI). סכום הביטים של שני האינדקסים צריך להיות שווה ל-VPN.\n    *   לכן, **אינדקס רמה 1 (PDI): 10 ביטים**.\n    *   **אינדקס רמה 2 (PTI): 10 ביטים**.\n    *   (10 + 10 = 20 ביטים, שזה אכן גודל ה-VPN).\n\n4.  **חישוב גודל טבלת דפים מקסימלי:**\n    *   תהליך הממפה את כל מרחב הכתובות הוירטואלי שלו דורש: ספריית דפים אחת (Page Directory) וטבלאות דפים (Page Tables) עבור כל הכניסות בספריית הדפים.\n    *   ספריית הדפים תופסת דף אחד: 4KB.\n    *   ספריית הדפים מכילה 1024 כניסות (PDI של 10 ביטים). אם כל הכניסות תקפות, כל אחת מהן מצביעה לטבלת דפים אחרת.\n    *   לכן, נצטרך 1024 טבלאות דפים.\n    *   כל טבלת דפים תופסת דף אחד: 4KB.\n    *   הזיכרון הפיזי הכולל שיתפוס מבנה טבלת הדפים הוא: (1 * גודל דף עבור ספריית הדפים) + (1024 * גודל דף עבור טבלאות הדפים).\n    *   = 1 * 4KB + 1024 * 4KB\n    *   = 4KB + 4096KB\n    *   = 4KB + 4MB = **4,198,400 בתים**."}, "difficulty_estimation": "Medium", "_source_file": "0613__Paging__Open__Medium.json", "_topic_hint": "Paging", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:01:17", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Memory Management", "Virtual Memory", "Paging"], "content": {"text": "נתונה מערכת עם זיכרון וירטואלי של 256MB, גודל דף של 4KB, וזיכרון פיזי של 128MB.\nכל כניסה בטבלת הדפים (PTE) מכילה את מספר מסגרת הדף הפיזי (PFN) ועוד 3 ביטים עבור דגלים (לדוגמה: valid, dirty, accessed), ומוקצית בגודל מינימלי המעוגל לחזקה הקרובה של 2 בתים.\nמהם הגדלים של ה-VPN, ה-PFN, וכמה זיכרון פיזי תתפוס טבלת דפים (לינארית) של תהליך, במינימום?\nגודל VPN: ________ גודל PFN: ________ גודל טבלה: ________", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כתובת וירטואלית היא 28 ביטים (זיכרון וירטואלי 256MB = 2^28 בתים).\nמתוכם 12 ביטים מייצגים את ההיסט (גודל דף 4KB = 2^12 בתים).\nלכן, מספר הדף הוירטואלי (VPN) הוא 28 - 12 = 16 ביטים.\n\nכתובת פיזית היא 27 ביטים (זיכרון פיזי 128MB = 2^27 בתים).\nההיסט זהה – 12 ביטים.\nלכן, מספר מסגרת הדף הפיזי (PFN) הוא 27 - 12 = 15 ביטים.\n\nכל כניסה בטבלת הדפים (PTE) מכילה את ה-PFN (15 ביטים) ועוד 3 ביטים לדגלים, סך הכל 18 ביטים.\nכאשר מעגלים לגודל מינימלי בחזקת 2 בתים, 18 ביטים דורשים 4 בתים (32 ביטים).\nלכל תהליך יש 2^16 דפים וירטואליים (לפי גודל ה-VPN).\nטבלת הדפים הלינארית שלו תכיל 2^16 רשומות.\nגודל טבלת הדפים הכולל יהיה: 2^16 רשומות * 4 בתים/רשומה = 65,536 * 4 בתים = 262,144 בתים = 256KB."}, "difficulty_estimation": "Medium", "_source_file": "0614__Paging__Open__Medium.json", "_topic_hint": "Paging", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:01:28", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Memory Management", "Paging", "Virtual Memory", "Two-Level Paging"], "content": {"text": "נתונה מערכת המשתמשת בטבלת דפים דו-שכבתית (Two-Level Page Table) לניהול זיכרון וירטואלי.\n*   גודל מרחב הכתובות הוירטואלי (Virtual Address Space) הוא 4GB.\n*   גודל דף הוא 4KB.\n*   גודל הזיכרון הפיזי (Physical Memory) הוא 1GB.\n*   כל כניסה בטבלת דפים (PTE) היא בגודל 4 בתים.\n\nענה על השאלות הבאות:", "code_snippet": null, "options": null}, "sub_questions": [{"id": "10.1", "text": "מהם גודלי החלקים (בביטים) של הכתובת הוירטואלית עבור VPN1, VPN2 וההיסט (Offset)?\nVPN1: _______ ביטים, VPN2: _______ ביטים, Offset: _______ ביטים.", "code_snippet": null, "options": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. גודל מרחב כתובות וירטואלי 4GB = 2^32 בתים, לכן כתובת וירטואלית היא באורך 32 ביטים.\nגודל דף 4KB = 2^12 בתים, לכן ההיסט (Offset) הוא באורך 12 ביטים.\nמספר הביטים עבור ה-VPN הכולל הוא 32 - 12 = 20 ביטים.\nגודל כל כניסה בטבלת דפים (PTE) הוא 4 בתים.\nמספר הכניסות בכל טבלת דפים (שתופסת דף בודד) הוא גודל דף / גודל PTE = 4KB / 4 בתים = 4096 / 4 = 1024 כניסות.\nכדי לאנדקס 1024 כניסות, נדרשים log2(1024) = 10 ביטים.\nמכיוון שמדובר בטבלה דו-שכבתית, אנו מחלקים את 20 ביטי ה-VPN לשני חלקים שווים (כדי למקסם את מספר הכניסות בכל רמה): VPN1 = 10 ביטים, VPN2 = 10 ביטים.\nתשובה: VPN1: 10 ביטים, VPN2: 10 ביטים, Offset: 12 ביטים."}}, {"id": "10.2", "text": "מהו הגודל המרבי של טבלת הדפים מהרמה הראשונה (First-Level Page Table) בבתים?\nגודל טבלה: _______ בתים.", "code_snippet": null, "options": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "2. טבלת הדפים מהרמה הראשונה מכילה 2^VPN1 כניסות. VPN1 הוא 10 ביטים, לכן 2^10 = 1024 כניסות.\nגודל כל כניסה הוא 4 בתים.\nתשובה: 1024 כניסות * 4 בתים/כניסה = 4096 בתים (או 4KB)."}}, {"id": "10.3", "text": "מהו המספר המרבי של טבלאות דפים מהרמה השנייה (Second-Level Page Tables) שתהליך בודד יכול להחזיק?\nמספר טבלאות: _______", "code_snippet": null, "options": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "3. כל כניסה בטבלת הדפים מהרמה הראשונה יכולה להצביע על טבלת דפים מהרמה השנייה.\nמכיוון שיש 1024 כניסות בטבלת הדפים מהרמה הראשונה, תהליך יכול להחזיק לכל היותר 1024 טבלאות דפים מהרמה השנייה.\nתשובה: 1024 טבלאות."}}, {"id": "10.4", "text": "מהו שטח הזיכרון הפיזי המינימלי שתופסות טבלאות הדפים של תהליך (בהנחה שממופה לפחות דף וירטואלי אחד)?\nשטח זיכרון: _______ בתים.", "code_snippet": null, "options": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "4. כדי שתהליך ירוץ, הוא חייב להחזיק לפחות טבלת דפים אחת מהרמה הראשונה. טבלה זו תופסת דף אחד (4KB).\nכדי למפות לפחות דף וירטואלי אחד, חייבת להיות כניסה אחת תקפה בטבלת הדפים מהרמה הראשונה, המצביעה על טבלת דפים מהרמה השנייה.\nלכן, נדרשת גם לפחות טבלת דפים אחת מהרמה השנייה, אשר תופסת גם היא דף אחד (4KB).\nתשובה: דף אחד (רמה 1) + דף אחד (רמה 2) = 4KB + 4KB = 8KB."}}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": null}, "difficulty_estimation": "Medium", "_source_file": "0615__Paging__Open__Medium.json", "_topic_hint": "Paging", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:01:46", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Paging", "Virtual Memory", "Memory Management"], "content": {"text": "נתונה מערכת הפעלה המשתמשת במנגנון זיכרון וירטואלי עם טבלאות דפים דו-שכבתיות.\nגודל מרחב הכתובות הוירטואלי הוא 4GB.\nגודל הזיכרון הפיזי הוא 16MB.\nגודל דף (Page Size) הוא 4KB.\nגודל כניסה בטבלת דפים (PTE) הוא 4 בתים.\n\nא. מהו מספר הביטים עבור VPN (Virtual Page Number)?\nב. מהו מספר הביטים עבור PFN (Physical Frame Number)?\nג. בהנחה שה-VPN מחולק לשני חלקים שווים (VPN1 ו-VPN2), כמה כניסות יש בכל טבלת דפים פנימית?\nד. כמה זיכרון פיזי תתפוס טבלאות הדפים (ברמה החיצונית והפנימיות יחד) של תהליך שממפה את כל מרחב הכתובות הוירטואלי שלו?", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. גודל מרחב הכתובות הוירטואלי הוא 4GB, כלומר 2^32 בתים. לכן כתובת וירטואלית היא באורך 32 ביטים.\nגודל דף הוא 4KB, כלומר 2^12 בתים. לכן ההיסט בתוך הדף הוא באורך 12 ביטים.\nמספר הביטים עבור VPN הוא: 32 (ביטי כתובת וירטואלית) - 12 (ביטי היסט) = 20 ביטים.\n\nב. גודל הזיכרון הפיזי הוא 16MB, כלומר 2^24 בתים. לכן כתובת פיזית היא באורך 24 ביטים.\nמספר הביטים עבור PFN הוא: 24 (ביטי כתובת פיזית) - 12 (ביטי היסט) = 12 ביטים.\n\nג. גודל דף הוא 4KB (4096 בתים). גודל כניסה בטבלת דפים (PTE) הוא 4 בתים.\nמספר הכניסות בכל טבלת דפים (פנימית או חיצונית) הוא: 4096 בתים / 4 בתים/כניסה = 1024 כניסות.\n\nד. כדי למפות את כל מרחב הכתובות הוירטואלי, נצטרך את כל טבלאות הדפים:\n- טבלת הדפים החיצונית (Page Directory) מכילה כניסות עבור כל ה-VPN1 האפשריים. מכיוון שה-VPN הוא 20 ביטים ומחולק לשני חלקים שווים, VPN1 הוא 10 ביטים. לכן יש 2^10 = 1024 כניסות בטבלת הדפים החיצונית.\n- טבלת הדפים החיצונית תופסת 1024 כניסות * 4 בתים/כניסה = 4096 בתים = 4KB (דף פיזי אחד).\n- כל כניסה בטבלת הדפים החיצונית מצביעה על טבלת דפים פנימית. מכיוון שכל מרחב הכתובות ממופה, נצטרך 1024 טבלאות דפים פנימיות.\n- כל טבלת דפים פנימית תופסת דף פיזי אחד, כלומר 4KB.\n- סך הזיכרון הפיזי שתופסות טבלאות הדפים הפנימיות הוא: 1024 טבלאות * 4KB/טבלה = 4096KB = 4MB.\n- סך הזיכרון הפיזי הכולל שתופסות טבלאות הדפים הוא: 4KB (טבלה חיצונית) + 4MB (טבלאות פנימיות) = 4MB + 4KB."}, "difficulty_estimation": "Medium", "_source_file": "0616__Paging__Open__Medium.json", "_topic_hint": "Paging", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:02:00", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Paging", "Virtual Memory", "Memory Management", "TLB", "Shared Memory"], "content": {"text": "נתונה מערכת זיכרון וירטואלי עם המאפיינים הבאים:\n*   כתובת וירטואלית בגודל 48 ביטים.\n*   גודל דף: 4KB.\n*   גודל כניסה בטבלת דפים (PTE): 8 בתים.\n*   טבלת דפים היררכית בעלת 4 רמות. כל טבלת דפים (או תת-טבלה) מכילה 512 כניסות ומוקצית לדף פיזי אחד.\n*   TLB (Translation Lookaside Buffer) בעל 16 כניסות, בשיטת אסוציאטיבית מלאה, עם מדיניות החלפה LRU (Least Recently Used). כל כניסה ב-TLB כוללת מזהה תהליך (ASID).\n*   זמן גישה ל-TLB: 10 ננו-שניות.\n*   זמן גישה לזיכרון פיזי (לקריאת PTE או נתונים): 100 ננו-שניות.\n*   זמן טיפול בפסיקת דף (Page Fault): 10 מילי-שניות (כולל טעינה מהדיסק ועדכון PTE).\n\nבמערכת רצים שני תהליכים, P1 ו-P2. לשניהם יש קטע קוד משותף וקטעי נתונים פרטיים:\n*   **קטע קוד משותף (Shared Code Segment):** משתרע מכתובת וירטואלית `0x0000_1000_0000_0000` עד `0x0000_1000_0000_FFFF`. קטע זה מכיל 16 דפים (64KB).\n*   **קטע נתונים פרטי P1 (P1 Private Data Segment):** משתרע מכתובת וירטואלית `0x0000_2000_0000_0000` עד `0x0000_2000_0000_FFFF`. קטע זה מכיל 16 דפים (64KB).\n*   **קטע נתונים פרטי P2 (P2 Private Data Segment):** משתרע מכתובת וירטואלית `0x0000_3000_0000_0000` עד `0x0000_3000_0000_FFFF`. קטע זה מכיל 16 דפים (64KB).\n\n**מצב התחלתי:**\n*   כל דפי הקוד והנתונים של המשתמש אינם נמצאים בזיכרון הפיזי (כלומר, ה-Present Bit ב-PTE שלהם הוא 0).\n*   מבני טבלאות הדפים הנדרשים עבור קטעי הזיכרון המוקצים לתהליכים (קוד ונתונים) כבר הוקצו בזיכרון הפיזי, אך רק הדפים של טבלאות הדפים עצמן (ולא דפי המשתמש) נמצאים בזיכרון.\n*   ה-TLB ריק.\n\n**רצף גישות לכתובות וירטואליות (לפי הסדר):**\n1.  P1 ניגש לכתובת: `0x0000_1000_0000_1000`\n2.  P1 ניגש לכתובת: `0x0000_1000_0000_2000`\n3.  P1 ניגש לכתובת: `0x0000_2000_0000_1000`\n4.  P2 ניגש לכתובת: `0x0000_1000_0000_1000`\n5.  P2 ניגש לכתובת: `0x0000_3000_0000_1000`\n6.  P1 ניגש לכתובת: `0x0000_1000_0000_1000`\n7.  P1 ניגש לכתובת: `0x0000_2000_0000_2000`\n8.  P2 ניגש לכתובת: `0x0000_1000_0000_2000`\n\n**נדרש:**\nא.  מהו סך הזיכרון הפיזי המינימלי הנדרש להחזיק את כל מבני טבלאות הדפים של שני התהליכים (P1 ו-P2) יחד, בטרם בוצעה כל גישה לדפי קוד/נתונים של המשתמש? פרט את חישוביך.\nב.  עבור כל גישה ברצף הנתון, ציין האם התרחש TLB Hit או TLB Miss, והאם התרחשה פסיקת דף (Page Fault). הסבר בקצרה לכל מקרה.\nג.  מהו זמן הגישה האפקטיבי הכולל (Total Effective Access Time) עבור רצף הגישות כולו? פרט את חישוביך.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "**פתרון:**\n\n**ניתוח מבנה הזיכרון הווירטואלי וטבלאות הדפים:**\n*   כתובת וירטואלית (VA) בגודל 48 ביטים.\n*   גודל דף: 4KB = 2^12 בתים. לכן, ה-Offset הוא 12 ביטים.\n*   מספר דף וירטואלי (VPN) הוא 48 - 12 = 36 ביטים.\n*   גודל כניסה בטבלת דפים (PTE): 8 בתים.\n*   גודל טבלת דפים: 4KB. מספר כניסות בכל טבלה: 4KB / 8 בתים = 512 כניסות.\n*   גודל אינדקס לכל רמה: log2(512) = 9 ביטים.\n*   מערכת בעלת 4 רמות של טבלאות דפים, כאשר כל רמה משתמשת ב-9 ביטים לאינדקס. סה\"כ: 9 * 4 = 36 ביטים, תואם ל-VPN.\n    *   P1 Index: 9 ביטים\n    *   P2 Index: 9 ביטים\n    *   P3 Index: 9 ביטים\n    *   P4 Index: 9 ביטים\n\n**א. חישוב סך הזיכרון הפיזי המינימלי הנדרש למבני טבלאות הדפים:**\nכל טבלת דפים (בכל רמה) תופסת דף פיזי אחד (4KB).\n\nננתח את הצרכים עבור כל קטע זיכרון:\n*   **עבור תהליך P1:**\n    *   **טבלת דפים ראשית (P1 Root Page Table):** 1 דף (4KB). (ייחודית ל-P1)\n    *   **עבור קטע קוד משותף (16 דפים):**\n        *   P1 entry בטבלה הראשית מצביע לטבלת P2. דורש 1 דף P2.\n        *   P2 entry בטבלת P2 מצביע לטבלת P3. דורש 1 דף P3.\n        *   P3 entry בטבלת P3 מצביע לטבלת P4. דורש 1 דף P4.\n        *   סה\"כ 3 דפים עבור מבנה טבלאות הדפים של קטע הקוד של P1 (P2, P3, P4).\n    *   **עבור קטע נתונים פרטי P1 (16 דפים):**\n        *   P1 entry בטבלה הראשית מצביע לטבלת P2. דורש 1 דף P2.\n        *   P2 entry בטבלת P2 מצביע לטבלת P3. דורש 1 דף P3.\n        *   P3 entry בטבלת P3 מצביע לטבלת P4. דורש 1 דף P4.\n        *   סה\"כ 3 דפים עבור מבנה טבלאות הדפים של קטע הנתונים של P1 (P2, P3, P4).\n\n*   **עבור תהליך P2:**\n    *   **טבלת דפים ראשית (P1 Root Page Table):** 1 דף (4KB). (ייחודית ל-P2)\n    *   **עבור קטע קוד משותף (16 דפים):**\n        *   ה-P1 entry של P2 עבור קטע הקוד יצביע לאותה טבלת P2 פיזית שנוצרה עבור P1. לכן, אין צורך בדפים פיזיים נוספים עבור טבלאות P2, P3, P4 של קטע הקוד.\n        *   סה\"כ 0 דפים נוספים.\n    *   **עבור קטע נתונים פרטי P2 (16 דפים):**\n        *   P1 entry בטבלה הראשית מצביע לטבלת P2. דורש 1 דף P2.\n        *   P2 entry בטבלת P2 מצביע לטבלת P3. דורש 1 דף P3.\n        *   P3 entry בטבלת P3 מצביע לטבלת P4. דורש 1 דף P4.\n        *   סה\"כ 3 דפים עבור מבנה טבלאות הדפים של קטע הנתונים של P2 (P2, P3, P4).\n\n**סך הכל דפים פיזיים עבור טבלאות דפים:**\n1 (P1 Root) + 3 (P1 Code P2/P3/P4) + 3 (P1 Data P2/P3/P4) + 1 (P2 Root) + 0 (P2 Code P2/P3/P4) + 3 (P2 Data P2/P3/P4) = 11 דפים.\n\n**סך הזיכרון הפיזי הנדרש:** 11 דפים * 4KB/דף = 44KB.\n\n**ב. ניתוח רצף הגישות וג. חישוב זמן גישה אפקטיבי כולל:**\n\nנשתמש ב: TLB Access = 10ns, Memory Access = 100ns, Page Fault = 10,000,000ns. (עלות גישה במקרה של TLB Miss היא: TLB Access + 4*Memory Access + [Page Fault אם P=0] + Memory Access)\nTLB מכיל 16 כניסות, LRU, ASID-aware (כלומר, כניסה ב-TLB כוללת גם את מזהה התהליך, ASID).\n\n| # | תהליך | כתובת וירטואלית | VPN (לצורך מעקב) | TLB Hit/Miss | Page Fault? | הסבר | עלות (ns) |\n|---|---|---|---|---|---|---|---|\n| 1 | P1 | `0x0000_1000_0000_1000` | `0x1000_0000_0` | Miss | כן | TLB ריק. הליכה בטבלת דפים (4 גישות זיכרון). ה-PTE מצביע על P=0 (דף קוד P1). פסיקת דף וטעינת הדף (ל-F1). PTE מעודכן (P=1, PFN=F1). כניסה ל-TLB: (VPN 0x1000_0000_0, ASID 1) -> F1. | 10 + 4*100 + 10,000,000 + 100 = 10,000,510 |\n| 2 | P1 | `0x0000_1000_0000_2000` | `0x1000_0000_1` | Miss | כן | (P1 Code page 1). TLB Miss. הליכה בטבלת דפים. ה-PTE מצביע על P=0. פסיקת דף (ל-F2). PTE מעודכן (P=1, PFN=F2). כניסה ל-TLB: (VPN 0x1000_0000_1, ASID 1) -> F2. | 10 + 4*100 + 10,000,000 + 100 = 10,000,510 |\n| 3 | P1 | `0x0000_2000_0000_1000` | `0x2000_0000_0` | Miss | כן | (P1 Data page 0). TLB Miss. הליכה בטבלת דפים. ה-PTE מצביע על P=0. פסיקת דף (ל-F3). PTE מעודכן (P=1, PFN=F3). כניסה ל-TLB: (VPN 0x2000_0000_0, ASID 1) -> F3. | 10 + 4*100 + 10,000,000 + 100 = 10,000,510 |\n| 4 | P2 | `0x0000_1000_0000_1000` | `0x1000_0000_0` | Miss | לא | (P2 Code page 0). TLB Miss (ה-ASID שונה מגישה 1). הליכה בטבלת דפים (4 גישות). ה-PTE (המשותף עם P1) מצביע על P=1 (כבר נטען בגישה 1). אין פסיקת דף. כניסה ל-TLB: (VPN 0x1000_0000_0, ASID 2) -> F1. | 10 + 4*100 + 100 = 510 |\n| 5 | P2 | `0x0000_3000_0000_1000` | `0x3000_0000_0` | Miss | כן | (P2 Data page 0). TLB Miss. הליכה בטבלת דפים. ה-PTE מצביע על P=0. פסיקת דף (ל-F4). PTE מעודכן (P=1, PFN=F4). כניסה ל-TLB: (VPN 0x3000_0000_0, ASID 2) -> F4. | 10 + 4*100 + 10,000,000 + 100 = 10,000,510 |\n| 6 | P1 | `0x0000_1000_0000_1000` | `0x1000_0000_0` | Hit | לא | (P1 Code page 0). TLB Hit (כניסה (VPN 0x1000_0000_0, ASID 1) -> F1 קיימת ב-TLB). | 10 + 100 = 110 |\n| 7 | P1 | `0x0000_2000_0000_2000` | `0x2000_0000_1` | Miss | כן | (P1 Data page 1). TLB Miss. הליכה בטבלת דפים. ה-PTE מצביע על P=0. פסיקת דף (ל-F5). PTE מעודכן (P=1, PFN=F5). כניסה ל-TLB: (VPN 0x2000_0000_1, ASID 1) -> F5. | 10 + 4*100 + 10,000,000 + 100 = 10,000,510 |\n| 8 | P2 | `0x0000_1000_0000_2000` | `0x1000_0000_1` | Miss | לא | (P2 Code page 1). TLB Miss (ה-ASID שונה מגישה 2). הליכה בטבלת דפים. ה-PTE (המשותף עם P1) מצביע על P=1 (כבר נטען בגישה 2). אין פסיקת דף. כניסה ל-TLB: (VPN 0x1000_0000_1, ASID 2) -> F2. | 10 + 4*100 + 100 = 510 |\n\n**סיכום:**\n*   סה\"כ TLB Hits: 1\n*   סה\"כ TLB Misses: 7\n*   סה\"כ Page Faults: 5\n\n**חישוב זמן הגישה האפקטיבי הכולל:**\n*   5 גישות עם Page Fault: 5 * 10,000,510 ns = 50,002,550 ns\n*   2 גישות עם TLB Miss ללא Page Fault: 2 * 510 ns = 1,020 ns\n*   1 גישה עם TLB Hit: 1 * 110 ns = 110 ns\n\n**זמן גישה אפקטיבי כולל = 50,002,550 + 1,020 + 110 = 50,003,680 ננו-שניות.**", "difficulty_estimation": "Hard"}, "_source_file": "0617__Paging__Open__Hard.json", "_topic_hint": "Paging", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:03:11", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Paging", "Virtual Memory", "TLB", "Page Faults", "Memory Management"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם טבלאות דפים היררכיות דו-רמתיות (Two-level Paging). פרטי המערכת הם כדלקמן:\n*   **גודל כתובת וירטואלית**: 32 ביטים.\n*   **גודל כתובת פיזית**: 28 ביטים.\n*   **גודל דף**: 4KB.\n*   **גודל כניסה בטבלת דפים (PTE)**: 4 בתים.\n    *   פורמט ה-PTE: `[PFN (16 ביטים)] [V (1)] [P (1)] [D (1)] [A (1)] [שמור (12 ביטים)]`\n    *   `V` (Valid) מציין אם הכניסה חוקית. `P` (Present) מציין אם הדף נמצא בזיכרון הפיזי. `D` (Dirty) מציין אם הדף שונה מאז נטען. `A` (Accessed) מציין אם הדף נקרא או נכתב לאחרונה.\n*   **TLB**: מכיל 4 כניסות, אסוציאטיבי מלא (fully associative), משתמש באלגוריתם LRU להחלפת כניסות.\n    *   פורמט כניסה ב-TLB: `[VPN (20 ביטים)] [PFN (16 ביטים)] [V (1)] [P (1)] [D (1)] [A (1)] [נתוני LRU]`\n\nתהליך מסוים מתחיל עם המצב הבא:\n*   **כתובת בסיס טבלת דפים רמה 1 (P1)**: ממוקמת במסגרת פיזית `0x100`.\n*   **מצב טבלאות דפים (חלקי)**:\n    *   **טבלת P1 (ב-0x100)**:\n        *   `P1[0]` מצביע לטבלת P2 במסגרת `0x200`. (V=1, P=1)\n        *   `P1[1]` מצביע לטבלת P2 במסגרת `0x300`. (V=1, P=1)\n        *   `P1[2]` מצביע לטבלת P2 במסגרת `0x400`. (V=1, P=1)\n        *   `P1[3]` מצביע לטבלת P2 במסגרת `0x500`. (V=1, P=0)\n        *   `P1[4]` (וכל שאר הכניסות ב-P1) הן V=0, P=0.\n    *   **טבלת P2_A (ב-0x200)**:\n        *   `P2_A[0]` ממפה ל-PFN `0x1A`. (V=1, P=1, D=0, A=0)\n        *   `P2_A[1]` ממפה ל-PFN `0x1B`. (V=1, P=1, D=0, A=0)\n        *   `P2_A[2]` ממפה ל-PFN `0x1C`. (V=1, P=1, D=0, A=0)\n        *   (כל שאר הכניסות ב-P2_A הן V=0, P=0)\n    *   **טבלת P2_B (ב-0x300)**:\n        *   `P2_B[0]` ממפה ל-PFN `0x2A`. (V=1, P=1, D=0, A=0)\n        *   `P2_B[1]` ממפה ל-PFN `0x2B`. (V=1, P=0, D=0, A=0)\n        *   (כל שאר הכניסות ב-P2_B הן V=0, P=0)\n    *   **טבלת P2_C (ב-0x400)**:\n        *   `P2_C[0]` ממפה ל-PFN `0x3A`. (V=1, P=1, D=0, A=0)\n        *   (כל שאר הכניסות ב-P2_C הן V=0, P=0)\n*   **מצב TLB התחלתי**:\n    *   כניסה 0: `VPN=0x00000`, `PFN=0x1A`, V=1, P=1, D=0, A=0, LRU=3 (הכי חדש)\n    *   כניסה 1: `VPN=0x00001`, `PFN=0x1B`, V=1, P=1, D=0, A=0, LRU=2\n    *   כניסה 2: `VPN=0x01000`, `PFN=0x2A`, V=1, P=1, D=0, A=0, LRU=1\n    *   כניסה 3: פנויה (או V=0), LRU=0 (הכי ישן)\n\nבצעו את סדרת הגישות הבאה לזיכרון הוירטואלי. עבור כל גישה:\n1.  ציינו אם התרחשה פגיעת TLB (TLB Hit) או החטאה (TLB Miss).\n2.  במקרה של החטאה, תארו את תהליך ה-Page Walk (חיפוש בטבלאות הדפים P1 ו-P2).\n3.  ציינו אם התרחשה תקלת דף (Page Fault). אם כן, הסבירו מדוע.\n4.  אם לא התרחשה תקלת דף, מהי הכתובת הפיזית המתקבלת?\n5.  תארו את שינויי המצב ב-TLB ובטבלאות הדפים (PTEs) כתוצאה מהגישה.\n6.  בסיום כל הגישות, הציגו את המצב הסופי של ה-TLB.\n\n**רשימת גישות (Virtual Address, סוג פעולה):**\n1.  `0x00000010`, קריאה\n2.  `0x00001020`, כתיבה\n3.  `0x01000030`, קריאה\n4.  `0x00002040`, כתיבה\n5.  `0x01001050`, קריאה\n6.  `0x02000060`, קריאה\n7.  `0x03000070`, כתיבה", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "**ניתוח פרמטרי מערכת:**\n*   **גודל כתובת וירטואלית**: 32 ביטים.\n*   **גודל דף**: 4KB = 2^12 בתים. לכן, ההיסט (Offset) הוא 12 ביטים.\n*   **מספר ביטים ל-VPN**: 32 - 12 = 20 ביטים.\n*   **טבלאות דפים דו-רמתיות**: 20 ביטים ל-VPN מתחלקים ל-10 ביטים עבור אינדקס P1 ול-10 ביטים עבור אינדקס P2.\n    *   P1 Index: VA[31:22]\n    *   P2 Index: VA[21:12]\n*   **גודל כתובת פיזית**: 28 ביטים. זיכרון פיזי מקסימלי: 2^28 בתים = 256MB.\n*   **מספר ביטים ל-PFN**: 28 - 12 = 16 ביטים. (תואם את פורמט ה-PTE).\n\n**מצב TLB התחלתי:**\n| כניסה | VPN (0x) | PFN (0x) | V | P | D | A | LRU |\n|---|---|---|---|---|---|---|---|\n| 0 | 00000 | 1A | 1 | 1 | 0 | 0 | 3 |\n| 1 | 00001 | 1B | 1 | 1 | 0 | 0 | 2 |\n| 2 | 01000 | 2A | 1 | 1 | 0 | 0 | 1 |\n| 3 | - (ריק) | - | 0 | 0 | 0 | 0 | 0 |\n\n**מעקב אחר גישות לזיכרון:**\n\n**1. גישה: קריאה ל-`VA 0x00000010`**\n*   **פירוק כתובת**: P1 Index = `0x0`, P2 Index = `0x0`, Offset = `0x010`. VPN = `0x00000`.\n*   **בדיקת TLB**: VPN `0x00000` נמצא בכניסה 0. **TLB Hit!**\n*   **תקלת דף**: לא התרחשה (P=1).\n*   **כתובת פיזית**: `PFN 0x1A` + `Offset 0x010` = `0x1A010`.\n*   **עדכון מצב**: \n    *   **TLB**: כניסה 0 (VPN `0x00000`) מקבלת LRU=3, A=1. שאר הכניסות יורדות ב-LRU (E1:2, E2:1, E3:0).\n    *   **PTE (זיכרון)**: ה-PTE המתאים בטבלת `P2_A[0]` מעודכן ל-A=1.\n\n**מצב TLB לאחר גישה 1:**\n| כניסה | VPN (0x) | PFN (0x) | V | P | D | A | LRU |\n|---|---|---|---|---|---|---|---|\n| 0 | 00000 | 1A | 1 | 1 | 0 | 1 | 3 |\n| 1 | 00001 | 1B | 1 | 1 | 0 | 0 | 2 |\n| 2 | 01000 | 2A | 1 | 1 | 0 | 0 | 1 |\n| 3 | - (ריק) | - | 0 | 0 | 0 | 0 | 0 |\n\n**2. גישה: כתיבה ל-`VA 0x00001020`**\n*   **פירוק כתובת**: P1 Index = `0x0`, P2 Index = `0x1`, Offset = `0x020`. VPN = `0x00001`.\n*   **בדיקת TLB**: VPN `0x00001` נמצא בכניסה 1. **TLB Hit!**\n*   **תקלת דף**: לא התרחשה (P=1).\n*   **כתובת פיזית**: `PFN 0x1B` + `Offset 0x020` = `0x1B020`.\n*   **עדכון מצב**: \n    *   **TLB**: כניסה 1 (VPN `0x00001`) מקבלת LRU=3, A=1, D=1. שאר הכניסות יורדות ב-LRU (E0:2, E2:1, E3:0).\n    *   **PTE (זיכרון)**: ה-PTE המתאים בטבלת `P2_A[1]` מעודכן ל-A=1, D=1.\n\n**מצב TLB לאחר גישה 2:**\n| כניסה | VPN (0x) | PFN (0x) | V | P | D | A | LRU |\n|---|---|---|---|---|---|---|---|\n| 0 | 00000 | 1A | 1 | 1 | 0 | 1 | 2 |\n| 1 | 00001 | 1B | 1 | 1 | 1 | 1 | 3 |\n| 2 | 01000 | 2A | 1 | 1 | 0 | 0 | 1 |\n| 3 | - (ריק) | - | 0 | 0 | 0 | 0 | 0 |\n\n**3. גישה: קריאה ל-`VA 0x01000030`**\n*   **פירוק כתובת**: P1 Index = `0x1`, P2 Index = `0x0`, Offset = `0x030`. VPN = `0x01000`.\n*   **בדיקת TLB**: VPN `0x01000` נמצא בכניסה 2. **TLB Hit!**\n*   **תקלת דף**: לא התרחשה (P=1).\n*   **כתובת פיזית**: `PFN 0x2A` + `Offset 0x030` = `0x2A030`.\n*   **עדכון מצב**: \n    *   **TLB**: כניסה 2 (VPN `0x01000`) מקבלת LRU=3, A=1. שאר הכניסות יורדות ב-LRU (E0:1, E1:2, E3:0).\n    *   **PTE (זיכרון)**: ה-PTE המתאים בטבלת `P2_B[0]` מעודכן ל-A=1.\n\n**מצב TLB לאחר גישה 3:**\n| כניסה | VPN (0x) | PFN (0x) | V | P | D | A | LRU |\n|---|---|---|---|---|---|---|---|\n| 0 | 00000 | 1A | 1 | 1 | 0 | 1 | 1 |\n| 1 | 00001 | 1B | 1 | 1 | 1 | 1 | 2 |\n| 2 | 01000 | 2A | 1 | 1 | 0 | 1 | 3 |\n| 3 | - (ריק) | - | 0 | 0 | 0 | 0 | 0 |\n\n**4. גישה: כתיבה ל-`VA 0x00002040`**\n*   **פירוק כתובת**: P1 Index = `0x0`, P2 Index = `0x2`, Offset = `0x040`. VPN = `0x00002`.\n*   **בדיקת TLB**: VPN `0x00002` **לא** נמצא ב-TLB. **TLB Miss!**\n*   **Page Walk**: \n    1.  קריאת `P1[0]` מטבלת P1 (במסגרת `0x100`). ה-PTE מצביע לטבלת P2 במסגרת `0x200` (V=1, P=1).\n    2.  קריאת `P2_A[2]` מטבלת P2_A (במסגרת `0x200`). ה-PTE ממפה ל-PFN `0x1C` (V=1, P=1, D=0, A=0).\n*   **תקלת דף**: לא התרחשה (P=1).\n*   **כתובת פיזית**: `PFN 0x1C` + `Offset 0x040` = `0x1C040`.\n*   **עדכון מצב**: \n    *   **TLB**: כניסה חדשה עבור VPN `0x00002` נטענת. כניסה 3 (הריקה, LRU=0) נבחרת להחלפה. הכניסה החדשה מקבלת LRU=3, A=1, D=1. שאר הכניסות יורדות ב-LRU (E0:2, E1:1, E2:0).\n    *   **PTE (זיכרון)**: ה-PTE המתאים בטבלת `P2_A[2]` מעודכן ל-A=1, D=1.\n\n**מצב TLB לאחר גישה 4:**\n| כניסה | VPN (0x) | PFN (0x) | V | P | D | A | LRU |\n|---|---|---|---|---|---|---|---|\n| 0 | 00000 | 1A | 1 | 1 | 0 | 1 | 2 |\n| 1 | 00001 | 1B | 1 | 1 | 1 | 1 | 1 |\n| 2 | 01000 | 2A | 1 | 1 | 0 | 1 | 0 |\n| 3 | 00002 | 1C | 1 | 1 | 1 | 1 | 3 |\n\n**5. גישה: קריאה ל-`VA 0x01001050`**\n*   **פירוק כתובת**: P1 Index = `0x1`, P2 Index = `0x1`, Offset = `0x050`. VPN = `0x01001`.\n*   **בדיקת TLB**: VPN `0x01001` **לא** נמצא ב-TLB. **TLB Miss!**\n*   **Page Walk**: \n    1.  קריאת `P1[1]` מטבלת P1 (במסגרת `0x100`). ה-PTE מצביע לטבלת P2 במסגרת `0x300` (V=1, P=1).\n    2.  קריאת `P2_B[1]` מטבלת P2_B (במסגרת `0x300`). ה-PTE ממפה ל-PFN `0x2B` (V=1, P=0, D=0, A=0).\n*   **תקלת דף**: **כן!** ה-PTE של הדף הנדרש (P2_B[1]) מראה P=0 (לא נוכח בזיכרון הפיזי). מערכת ההפעלה תצטרך לטעון את הדף.\n*   **כתובת פיזית**: לא מחושבת עקב תקלת דף.\n*   **עדכון מצב**: \n    *   **TLB**: לא מתווספת כניסה חדשה ל-TLB עד לטיפול בתקלת הדף וטעינת הדף. מצב ה-TLB נשאר ללא שינוי.\n    *   **PTE (זיכרון)**: ה-PTE המתאים בטבלת `P2_B[1]` מעודכן ל-A=1 (על ידי החומרה לפני הפעלת ה-trap).\n\n**מצב TLB לאחר גישה 5:** (ללא שינוי)\n| כניסה | VPN (0x) | PFN (0x) | V | P | D | A | LRU |\n|---|---|---|---|---|---|---|---|\n| 0 | 00000 | 1A | 1 | 1 | 0 | 1 | 2 |\n| 1 | 00001 | 1B | 1 | 1 | 1 | 1 | 1 |\n| 2 | 01000 | 2A | 1 | 1 | 0 | 1 | 0 |\n| 3 | 00002 | 1C | 1 | 1 | 1 | 1 | 3 |\n\n**6. גישה: קריאה ל-`VA 0x02000060`**\n*   **פירוק כתובת**: P1 Index = `0x2`, P2 Index = `0x0`, Offset = `0x060`. VPN = `0x02000`.\n*   **בדיקת TLB**: VPN `0x02000` **לא** נמצא ב-TLB. **TLB Miss!**\n*   **Page Walk**: \n    1.  קריאת `P1[2]` מטבלת P1 (במסגרת `0x100`). ה-PTE מצביע לטבלת P2 במסגרת `0x400` (V=1, P=1).\n    2.  קריאת `P2_C[0]` מטבלת P2_C (במסגרת `0x400`). ה-PTE ממפה ל-PFN `0x3A` (V=1, P=1, D=0, A=0).\n*   **תקלת דף**: לא התרחשה (P=1).\n*   **כתובת פיזית**: `PFN 0x3A` + `Offset 0x060` = `0x3A060`.\n*   **עדכון מצב**: \n    *   **TLB**: כניסה חדשה עבור VPN `0x02000` נטענת. כניסה 2 (LRU=0) נבחרת להחלפה (כי היא ה-LRU ביותר מבין הכניסות התפוסות). הכניסה החדשה מקבלת LRU=3, A=1, D=0. שאר הכניסות יורדות ב-LRU (E0:1, E1:0, E3:2).\n    *   **PTE (זיכרון)**: ה-PTE המתאים בטבלת `P2_C[0]` מעודכן ל-A=1.\n\n**מצב TLB לאחר גישה 6:**\n| כניסה | VPN (0x) | PFN (0x) | V | P | D | A | LRU |\n|---|---|---|---|---|---|---|---|\n| 0 | 00000 | 1A | 1 | 1 | 0 | 1 | 1 |\n| 1 | 00001 | 1B | 1 | 1 | 1 | 1 | 0 |\n| 2 | 02000 | 3A | 1 | 1 | 0 | 1 | 3 |\n| 3 | 00002 | 1C | 1 | 1 | 1 | 1 | 2 |\n\n**7. גישה: כתיבה ל-`VA 0x03000070`**\n*   **פירוק כתובת**: P1 Index = `0x3`, P2 Index = `0x0`, Offset = `0x070`. VPN = `0x03000`.\n*   **בדיקת TLB**: VPN `0x03000` **לא** נמצא ב-TLB. **TLB Miss!**\n*   **Page Walk**: \n    1.  קריאת `P1[3]` מטבלת P1 (במסגרת `0x100`). ה-PTE מצביע לטבלת P2 במסגרת `0x500` (V=1, P=0).\n*   **תקלת דף**: **כן!** ה-PTE של טבלת P2 עצמה (P1[3]) מראה P=0. טבלת הדפים של רמה 2 אינה נוכחת בזיכרון הפיזי. מערכת ההפעלה תצטרך לטעון אותה.\n*   **כתובת פיזית**: לא מחושבת עקב תקלת דף.\n*   **עדכון מצב**: \n    *   **TLB**: לא מתווספת כניסה חדשה ל-TLB. מצב ה-TLB נשאר ללא שינוי.\n    *   **PTE (זיכרון)**: ה-PTE המתאים בטבלת `P1[3]` מעודכן ל-A=1.\n\n**מצב TLB סופי לאחר כל הגישות:**\n| כניסה | VPN (0x) | PFN (0x) | V | P | D | A | LRU |\n|---|---|---|---|---|---|---|---|\n| 0 | 00000 | 1A | 1 | 1 | 0 | 1 | 1 |\n| 1 | 00001 | 1B | 1 | 1 | 1 | 1 | 0 |\n| 2 | 02000 | 3A | 1 | 1 | 0 | 1 | 3 |\n| 3 | 00002 | 1C | 1 | 1 | 1 | 1 | 2 |\n"}, "difficulty_estimation": "Hard", "_source_file": "0621__Paging__Open__Hard.json", "_topic_hint": "Paging", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:08:18", "_subject": "Virtualization"}, {"id": 8, "type": "Open", "topic": ["Paging", "Virtual Memory", "TLB", "Page Replacement"], "content": {"text": "נתונה מערכת זיכרון וירטואלי עם טבלת דפים היררכית בעלת 2 רמות, ו-TLB.\nגודל דף: 4KB.\nגודל כתובת וירטואלית: 32 ביטים.\nגודל כתובת פיזית: 20 ביטים.\nכל כניסה בטבלת הדפים (PTE) היא בגודל 4 בתים (32 ביטים), ומבנה ה-PTE הוא כדלקמן:\n[PFN (8 ביטים)] [V (Valid)] [P (Present)] [D (Dirty)] [A (Accessed)] [R/W (Read/Write)] [שאר 19 ביטים שמורים/לא בשימוש]\nה-TLB הוא בעל 4 כניסות, fully associative, ומשתמש באלגוריתם LRU להחלפה.\nנתון כי למערכת יש 8 מסגרות פיזיות זמינות עבור דפי נתונים של תהליך (לא כולל מסגרות עבור טבלאות דפים עצמן). מסגרות אלו ממוספרות מ-0x20 עד 0x27 (כולל).\n\n**תת-שאלה 1:**\nבהתבסס על הנתונים, פרטו את מבנה הכתובת הוירטואלית (מספר ביטים ל-P1, P2, Offset).\n\n**תת-שאלה 2:**\nנתונה טבלת הדפים הבאה עבור תהליך מסוים (המספרים בבסיס 16):\n**טבלת דפים רמה 1 (P1):**\nP1_Entry[0x0] -> PFN = 0x10, V=1, P=1, D=0, A=0, R/W=1\nP1_Entry[0x1] -> PFN = 0x11, V=1, P=1, D=0, A=0, R/W=1\nP1_Entry[0x2] -> PFN = 0x00, V=0, P=0, D=0, A=0, R/W=0 (לא בשימוש)\n...\n**טבלת דפים רמה 2 (P2) הממוקמת ב-PFN 0x10 (עבור P1_Entry[0x0]):**\nP2_Entry[0x0] -> PFN = 0x20, V=1, P=1, D=0, A=0, R/W=1\nP2_Entry[0x1] -> PFN = 0x21, V=1, P=1, D=0, A=0, R/W=1\nP2_Entry[0x2] -> PFN = 0x22, V=1, P=1, D=0, A=0, R/W=1\nP2_Entry[0x3] -> PFN = 0x23, V=1, P=1, D=0, A=0, R/W=1\n...\n**טבלת דפים רמה 2 (P2) הממוקמת ב-PFN 0x11 (עבור P1_Entry[0x1]):**\nP2_Entry[0x0] -> PFN = 0x24, V=1, P=1, D=0, A=0, R/W=1\nP2_Entry[0x1] -> PFN = 0x25, V=1, P=1, D=0, A=0, R/W=1\nP2_Entry[0x2] -> PFN = 0x00, V=0, P=0, D=0, A=0, R/W=0 (לא בשימוש)\n...\n\nנתונה הכתובת הוירטואלית `0x00101020`. פרטו את כל שלבי התרגום לכתובת פיזית. מהי הכתובת הפיזית הסופית? האם תתרחש פסיקת דף (Page Fault) במהלך הגישה לנתונים? הסבירו.\n\n**תת-שאלה 3:**\nהתהליך מבצע את סדרת הגישות (קריאה) לכתובות הוירטואליות הבאות:\n`0x00000000`, `0x00001000`, `0x00002000`, `0x00003000`, `0x00100000`, `0x00101000`, `0x00000000`, `0x00001000`, `0x00102000`, `0x00004000`\n\nבהנחה שה-TLB ריק בתחילה, וטבלת הדפים ברמות 1 ו-2 (כפי שמוצגות לעיל) כבר טעונות בזיכרון הפיזי. כמו כן, כל דפי הנתונים שאינם מופיעים באופן מפורש בטבלאות הדפים הנתונות (P2_Entry[X]) אינם Present (כלומר ה-P ביט שלהם הוא 0). כאשר מתרחשת פסיקת דף עבור דף נתונים, הוא נטען למסגרת הפנויה הבאה מבין 0x20-0x27 (אם יש) או מחליף את דף הנתונים ה-LRU בזיכרון הפיזי. יש לעדכן את ה-PTE המתאים.\nעקבו אחר סדרת הגישות וחשבו:\nא. כמה TLB Misses יתרחשו?\nב. כמה Page Faults יתרחשו עבור דפי הנתונים?\nג. הציגו את מצב ה-TLB ואת רשימת המסגרות הפיזיות (עבור דפי נתונים בלבד) לאחר כל גישה. יש להציג את ה-TLB ואת המסגרות כרשימות LRU, כאשר האלמנט האחרון הוא ה-MRU (Most Recently Used).", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "**פתרון תת-שאלה 1:**\nגודל דף הוא 4KB, כלומר 2^12 בתים. לכן, ההיסט (Offset) הוא 12 ביטים.\nגודל כתובת וירטואלית הוא 32 ביטים. נותרו 32 - 12 = 20 ביטים עבור מספרי הדפים (P1 ו-P2).\nכל טבלת דפים מכילה 1024 כניסות (4KB / 4 בתים לכניסה). לכן, כל רמה בטבלת הדפים צריכה 10 ביטים (2^10 = 1024).\nמבנה הכתובת הוירטואלית:\n*   P1: 10 ביטים (ביטים 22-31)\n*   P2: 10 ביטים (ביטים 12-21)\n*   Offset: 12 ביטים (ביטים 0-11)\n**מבנה כללי:** [P1 (10 ביטים) | P2 (10 ביטים) | Offset (12 ביטים)]\n\n**פתרון תת-שאלה 2:**\nהכתובת הוירטואלית `0x00101020` בבינארי (32 ביטים): `0000 0000 0001 0000 0001 0000 0010 0000`\nנחלק לפי המבנה:\n*   P1 = `0000000000` (ביטים 22-31) = `0x0`\n*   P2 = `0100000000` (ביטים 12-21) = `0x40`\n*   Offset = `00100000` (ביטים 0-11) = `0x20`\n\n**שלבי התרגום:**\n1.  **גישה לטבלת דפים רמה 1 (P1):** המערכת ניגשת לכניסה מספר `0x0` בטבלת דפים רמה 1.\n    *   לפי הנתון: `P1_Entry[0x0]` מכיל `PFN = 0x10` עם ביטים `V=1, P=1`. ה-PTE תקין ומפנה למסגרת הפיזית `0x10` המכילה את טבלת דפים רמה 2.\n    *   אין Page Fault בשלב זה.\n2.  **גישה לטבלת דפים רמה 2 (P2):** המערכת ניגשת לכניסה מספר `0x40` בטבלת דפים רמה 2, הממוקמת ב-PFN 0x10.\n    *   הכתובת הפיזית של ה-PTE בטבלת דפים רמה 2 תהיה: `(PFN_P1 << 12) + (P2_Index * sizeof(PTE))` = `(0x10 << 12) + (0x40 * 4)` = `0x10000 + 0x100` = `0x10100`.\n    *   הערך של `P2_Entry[0x40]` אינו מופיע באופן מפורש בטבלה הנתונה. לפי ההנחיה בשאלה, כל דפי הנתונים שאינם מופיעים מפורשות הם `P=0` (לא Present).\n    *   **תוצאה:** תתרחש **פסיקת דף (Page Fault)** עבור דף הנתונים, מכיוון שהביט `P` ב-PTE המתאים הוא 0. לא ניתן לחשב כתובת פיזית סופית מכיוון שהדף אינו בזיכרון הפיזי.\n\n**פתרון תת-שאלה 3:**\n**מיפוי כתובות וירטואליות למספרי דפים וירטואליים (VP):**\n*   `0x00000000` -> P1=`0x0`, P2=`0x0` (VP `0x000`) -> PFN `0x20` (P=1)\n*   `0x00001000` -> P1=`0x0`, P2=`0x1` (VP `0x001`) -> PFN `0x21` (P=1)\n*   `0x00002000` -> P1=`0x0`, P2=`0x2` (VP `0x002`) -> PFN `0x22` (P=1)\n*   `0x00003000` -> P1=`0x0`, P2=`0x3` (VP `0x003`) -> PFN `0x23` (P=1)\n*   `0x00100000` -> P1=`0x0`, P2=`0x40` (VP `0x040`) -> P=0 (לא מפורש)\n*   `0x00101000` -> P1=`0x0`, P2=`0x41` (VP `0x041`) -> P=0 (לא מפורש)\n*   `0x00102000` -> P1=`0x0`, P2=`0x42` (VP `0x042`) -> P=0 (לא מפורש)\n*   `0x00004000` -> P1=`0x0`, P2=`0x4` (VP `0x004`) -> P=0 (לא מפורש)\n\n**מעקב אחר גישות (TLB ו-Data Frames כרשימות LRU, האחרון הוא MRU):**\n**מצב התחלתי:**\n*   TLB: `[]`\n*   Data Frames (VP, PFN): `[]` (8 מסגרות זמינות: 0x20-0x27)\n*   TLB Misses: 0, Page Faults: 0\n\n1.  **גישה: `0x00000000` (VP `0x000`)**\n    *   **TLB Miss.** (ריק). Page Walk: P1[0x0]->PFN 0x10, P2[0x0]->PFN 0x20 (P=1).\n    *   אין Page Fault.\n    *   TLB: `[(0x000, 0x20)]`\n    *   Data Frames: `[(0x000, 0x20)]`\n    *   סה\"כ: TLB Misses: 1, Page Faults: 0\n\n2.  **גישה: `0x00001000` (VP `0x001`)**\n    *   **TLB Miss.** Page Walk: P1[0x0]->PFN 0x10, P2[0x1]->PFN 0x21 (P=1).\n    *   אין Page Fault.\n    *   TLB: `[(0x000, 0x20), (0x001, 0x21)]`\n    *   Data Frames: `[(0x000, 0x20), (0x001, 0x21)]`\n    *   סה\"כ: TLB Misses: 2, Page Faults: 0\n\n3.  **גישה: `0x00002000` (VP `0x002`)**\n    *   **TLB Miss.** Page Walk: P1[0x0]->PFN 0x10, P2[0x2]->PFN 0x22 (P=1).\n    *   אין Page Fault.\n    *   TLB: `[(0x000, 0x20), (0x001, 0x21), (0x002, 0x22)]`\n    *   Data Frames: `[(0x000, 0x20), (0x001, 0x21), (0x002, 0x22)]`\n    *   סה\"כ: TLB Misses: 3, Page Faults: 0\n\n4.  **גישה: `0x00003000` (VP `0x003`)**\n    *   **TLB Miss.** Page Walk: P1[0x0]->PFN 0x10, P2[0x3]->PFN 0x23 (P=1).\n    *   אין Page Fault.\n    *   TLB: `[(0x000, 0x20), (0x001, 0x21), (0x002, 0x22), (0x003, 0x23)]`\n    *   Data Frames: `[(0x000, 0x20), (0x001, 0x21), (0x002, 0x22), (0x003, 0x23)]`\n    *   סה\"כ: TLB Misses: 4, Page Faults: 0\n\n5.  **גישה: `0x00100000` (VP `0x040`)**\n    *   **TLB Miss.** Page Walk: P1[0x0]->PFN 0x10, P2[0x40]->P=0.\n    *   **Page Fault!** (PF #1). הקצאת PFN 0x24 ל-VP 0x040. עדכון P2[0x40] ל-PFN 0x24, P=1.\n    *   TLB: פינוי (0x000, 0x20) (LRU). הוספת (0x040, 0x24).\n        `[(0x001, 0x21), (0x002, 0x22), (0x003, 0x23), (0x040, 0x24)]`\n    *   Data Frames: הוספת (0x040, 0x24) כ-MRU. (0x000, 0x20) הופך ל-LRU אך לא מפונה (עדיין יש מקום).\n        `[(0x000, 0x20), (0x001, 0x21), (0x002, 0x22), (0x003, 0x23), (0x040, 0x24)]`\n    *   סה\"כ: TLB Misses: 5, Page Faults: 1\n\n6.  **גישה: `0x00101000` (VP `0x041`)**\n    *   **TLB Miss.** Page Walk: P1[0x0]->PFN 0x10, P2[0x41]->P=0.\n    *   **Page Fault!** (PF #2). הקצאת PFN 0x25 ל-VP 0x041. עדכון P2[0x41] ל-PFN 0x25, P=1.\n    *   TLB: פינוי (0x001, 0x21) (LRU). הוספת (0x041, 0x25).\n        `[(0x002, 0x22), (0x003, 0x23), (0x040, 0x24), (0x041, 0x25)]`\n    *   Data Frames: הוספת (0x041, 0x25).\n        `[(0x000, 0x20), (0x001, 0x21), (0x002, 0x22), (0x003, 0x23), (0x040, 0x24), (0x041, 0x25)]`\n    *   סה\"כ: TLB Misses: 6, Page Faults: 2\n\n7.  **גישה: `0x00000000` (VP `0x000`)**\n    *   **TLB Miss.** Page Walk: P1[0x0]->PFN 0x10, P2[0x0]->PFN 0x20 (P=1).\n    *   אין Page Fault.\n    *   TLB: פינוי (0x002, 0x22) (LRU). הוספת (0x000, 0x20).\n        `[(0x003, 0x23), (0x040, 0x24), (0x041, 0x25), (0x000, 0x20)]`\n    *   Data Frames: (0x000, 0x20) הופך ל-MRU.\n        `[(0x001, 0x21), (0x002, 0x22), (0x003, 0x23), (0x040, 0x24), (0x041, 0x25), (0x000, 0x20)]`\n    *   סה\"כ: TLB Misses: 7, Page Faults: 2\n\n8.  **גישה: `0x00001000` (VP `0x001`)**\n    *   **TLB Miss.** Page Walk: P1[0x0]->PFN 0x10, P2[0x1]->PFN 0x21 (P=1).\n    *   אין Page Fault.\n    *   TLB: פינוי (0x003, 0x23) (LRU). הוספת (0x001, 0x21).\n        `[(0x040, 0x24), (0x041, 0x25), (0x000, 0x20), (0x001, 0x21)]`\n    *   Data Frames: (0x001, 0x21) הופך ל-MRU.\n        `[(0x002, 0x22), (0x003, 0x23), (0x040, 0x24), (0x041, 0x25), (0x000, 0x20), (0x001, 0x21)]`\n    *   סה\"כ: TLB Misses: 8, Page Faults: 2\n\n9.  **גישה: `0x00102000` (VP `0x042`)**\n    *   **TLB Miss.** Page Walk: P1[0x0]->PFN 0x10, P2[0x42]->P=0.\n    *   **Page Fault!** (PF #3). הקצאת PFN 0x26 ל-VP 0x042. עדכון P2[0x42] ל-PFN 0x26, P=1.\n    *   TLB: פינוי (0x040, 0x24) (LRU). הוספת (0x042, 0x26).\n        `[(0x041, 0x25), (0x000, 0x20), (0x001, 0x21), (0x042, 0x26)]`\n    *   Data Frames: הוספת (0x042, 0x26).\n        `[(0x002, 0x22), (0x003, 0x23), (0x040, 0x24), (0x041, 0x25), (0x000, 0x20), (0x001, 0x21), (0x042, 0x26)]`\n    *   סה\"כ: TLB Misses: 9, Page Faults: 3\n\n10. **גישה: `0x00004000` (VP `0x004`)**\n    *   **TLB Miss.** Page Walk: P1[0x0]->PFN 0x10, P2[0x4]->P=0.\n    *   **Page Fault!** (PF #4). הקצאת PFN 0x27 ל-VP 0x004. עדכון P2[0x4] ל-PFN 0x27, P=1.\n    *   TLB: פינוי (0x041, 0x25) (LRU). הוספת (0x004, 0x27).\n        `[(0x000, 0x20), (0x001, 0x21), (0x042, 0x26), (0x004, 0x27)]`\n    *   Data Frames: הוספת (0x004, 0x27).\n        `[(0x002, 0x22), (0x003, 0x23), (0x040, 0x24), (0x041, 0x25), (0x000, 0x20), (0x001, 0x21), (0x042, 0x26), (0x004, 0x27)]`\n    *   סה\"כ: TLB Misses: 10, Page Faults: 4\n\n**סיכום תת-שאלה 3:**\nא. סך הכל TLB Misses: **10**\nב. סך הכל Page Faults עבור דפי נתונים: **4**\nג. מצב ה-TLB ורשימת המסגרות הפיזיות (עבור דפי נתונים בלבד) לאחר כל גישה – מפורט לעיל."}, "difficulty_estimation": "Hard", "_source_file": "0622__Paging__Open__Hard.json", "_topic_hint": "Paging", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:09:28", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Paging", "Virtual Memory", "Memory Management", "Copy-On-Write"], "content": {"text": "נתונה מערכת הפעלה המממשת זיכרון וירטואלי באמצעות דפדוף (Paging).\nמאפייני המערכת הם כדלקמן:\n*   גודל דף (Page Size) הוא 4KB.\n*   כתובות וירטואליות הן בגודל 32 ביטים.\n*   כתובות פיזיות הן בגודל 30 ביטים.\n*   טבלת הדפים היא היררכית, בעלת שתי רמות (Level 1 ו-Level 2).\n*   כל כניסה בטבלת דפים (PTE) היא בגודל 4 בתים (32 ביטים).\n*   פורמט ה-PTE הוא: [מספר מסגרת פיזית (PFN)] [V|P|D|A|COW|Reserved]. כאשר V=Valid, P=Present, D=Dirty, A=Accessed, COW=Copy-On-Write. ביטים Reserved שמורים לשימוש עתידי, יש להתעלם מהם.\n*   ביט ה-COW (Copy-On-Write) ב-PTE מציין האם הדף משותף וצריך להעתיקו לפני כתיבה. כאשר ביט זה דולק (1), כתיבה לדף תגרום לפסיקת דף (COW fault), הקצאת מסגרת פיזית חדשה, העתקת התוכן, עדכון ה-PTE של התהליך הכותב (כיבוי ביט COW והגדרת ביט D), ועדכון ה-PTE של התהליכים האחרים (אם רלוונטי).\n\nנתונים שני תהליכים, P1 ו-P2, המשתמשים בזיכרון.\n*   תהליך P1 משתמש ב-10 דפים פרטיים (Private Pages).\n*   תהליך P2 משתמש ב-5 דפים פרטיים (Private Pages).\n*   שני התהליכים חולקים אזור זיכרון של 8 דפים (Shared Pages) באמצעות מנגנון Copy-On-Write. בתחילה, דפים אלו ממופים לאותן מסגרות פיזיות בזיכרון, וביט ה-COW שלהם דולק בטבלאות הדפים של שני התהליכים.\n\nיש לפרט ולנמק את כל החישובים.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "מבנה הכתובת הוירטואלית:\n*   כמה ביטים מוקצים לכל אחד מהשדות הבאים בכתובת הוירטואלית: Offset, Page Number Level 2 (P2), Page Number Level 1 (P1)?\n*   מהו גודל הזיכרון הוירטואלי המקסימלי במערכת בבתים?\n*   מהו גודל הזיכרון הפיזי המקסימלי במערכת בבתים?\n*   כמה ביטים מוקצים ל-PFN ב-PTE?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "תרגום כתובת וטיפול ב-COW:\n*   תהליך P1 ניגש לכתובת וירטואלית `0x00401050`. נניח שזוהי כתובת בדף משותף (COW page) שטרם נכתב אליו על ידי P1. נניח ש-PTE עבור דף זה ברמה 2 של P1 מכיל: `PFN=0x2F3DE, V=1, P=1, D=0, A=0, COW=1`.\n*   א. אם הגישה היא קריאה (Read), מהי הכתובת הפיזית אליה יתורגם הגישה? אילו ביטים ב-PTE ישונו (אם בכלל)?\n*   ב. אם הגישה היא כתיבה (Write), מה יקרה? תאר את השלבים המלאים, כולל טיפול בפסיקת ה-COW, וציין אילו ביטים ב-PTE ישונו וכיצד. הנח שהמערכת מקצה מסגרת פיזית חדשה `0x3FFFF` עבור ההעתקה.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "ניצול זיכרון:\n*   חשב את סך הזיכרון הפיזי (בבתים) הנדרש עבור טבלאות הדפים (בכל הרמות) של שני התהליכים P1 ו-P2 יחד.\n*   חשב את סך הזיכרון הפיזי (בבתים) הנדרש עבור דפי הנתונים (Private + Shared) של שני התהליכים P1 ו-P2 יחד, *לפני* פעולת הכתיבה בסעיף 1.2ב.\n*   חשב את סך הזיכרון הפיזי (בבתים) הנדרש עבור דפי הנתונים (Private + Shared) של שני התהליכים P1 ו-P2 יחד, *לאחר* פעולת הכתיבה בסעיף 1.2ב.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\n**1.1. מבנה הכתובת הוירטואלית**\n*   **Offset**: גודל דף הוא 4KB = 2^12 בתים. לכן, ההיסט (Offset) הוא 12 ביטים.\n*   **Page Number**: כתובת וירטואלית היא 32 ביטים. אם 12 ביטים הם Offset, נשארים 32 - 12 = 20 ביטים למספר הדף הוירטואלי.\n*   **P1, P2**: טבלת הדפים היררכית עם 2 רמות. כל כניסה בטבלת דפים היא 4 בתים. גודל דף הוא 4KB. לכן, כל טבלת דפים (ברמה 1 או 2) יכולה להכיל 4KB / 4 בתים/כניסה = 1024 כניסות. 1024 = 2^10.\n    *   לכן, כל רמה של טבלת הדפים (P1 ו-P2) דורשת 10 ביטים עבור אינדקס הדף.\n    *   P1 (Level 1 Page Number): 10 ביטים.\n    *   P2 (Level 2 Page Number): 10 ביטים.\n    *   **סיכום חלוקת הביטים**: P1 (10 ביטים) | P2 (10 ביטים) | Offset (12 ביטים).\n\n*   **גודל הזיכרון הוירטואלי המקסימלי**: 2^32 בתים = 4GB. (מכיוון שהכתובת הווירטואלית היא 32 ביטים).\n\n*   **גודל הזיכרון הפיזי המקסימלי**: כתובת פיזית היא 30 ביטים. לכן, גודל הזיכרון הפיזי המקסימלי הוא 2^30 בתים = 1GB.\n\n*   **PFN ב-PTE**: כתובת פיזית היא 30 ביטים. 12 ביטים הם Offset. לכן, מספר מסגרת פיזית (PFN) הוא 30 - 12 = 18 ביטים.\n\n**1.2. תרגום כתובת וטיפול ב-COW**\n\nכתובת וירטואלית `0x00401050`.\nנמיר לבסיס 2 כדי לפרק ל-P1, P2, Offset:\n`0x00401050` = `0000 0000 0100 0000 0001 0000 0101 0000` בבינארי.\n\nלפי החלוקה שחושבה בסעיף 1.1: P1 (10 ביטים) | P2 (10 ביטים) | Offset (12 ביטים).\n*   Offset: `0000 0101 0000` = `0x050` (12 ביטים אחרונים).\n*   P2: `0000 0001 00` = `0x004` (10 ביטים לפני האופסט).\n*   P1: `0000 0000 01` = `0x001` (10 ביטים ראשונים).\n\nPTE עבור דף זה ברמה 2 של P1 מכיל: `PFN=0x2F3DE, V=1, P=1, D=0, A=0, COW=1`.\n\n*   **א. גישת קריאה (Read)**:\n    *   הגישה היא קריאה, וביט ה-COW דולק (1). מכיוון שזו קריאה, אין צורך להפעיל את מנגנון ה-COW.\n    *   **תרגום כתובת פיזית**:\n        *   PFN הוא `0x2F3DE` (18 ביטים).\n        *   הכתובת הפיזית תורכב מ-PFN ועוד Offset.\n        *   PFN (בינארי): `0010 1111 0011 1101 1110`\n        *   Offset (בינארי): `0000 0101 0000`\n        *   הכתובת הפיזית היא צירוף PFN + Offset: `0010 1111 0011 1101 1110 0000 0101 0000` בבינארי.\n        *   בבסיס 16: `0x2F3DE050`.\n    *   **שינוי ביטים ב-PTE**: רק ביט ה-Accessed (A) ישתנה ל-1, כדי לסמן שהדף נקרא.\n        *   PTE לאחר קריאה: `PFN=0x2F3DE, V=1, P=1, D=0, A=1, COW=1`.\n\n*   **ב. גישת כתיבה (Write)**:\n    *   הגישה היא כתיבה, וביט ה-COW דולק (1). זה יגרום ל-COW fault (פסיקת דף מסוג Copy-On-Write).\n    *   **שלבים**:\n        1.  **פסיקת COW**: מערכת ההפעלה (OS) מקבלת את הפסיקה.\n        2.  **הקצאת מסגרת חדשה**: ה-OS מקצה מסגרת פיזית חדשה עבור P1. נתון שהמסגרת החדשה היא `0x3FFFF` (18 ביטים).\n        3.  **העתקת תוכן**: תוכן הדף המקורי (במסגרת `0x2F3DE`) מועתק למסגרת הפיזית החדשה (`0x3FFFF`).\n        4.  **עדכון PTE של P1**: ה-PTE של P1 עבור הדף הספציפי מתעדכן:\n            *   ה-PFN משתנה ל-`0x3FFFF`.\n            *   ביט ה-COW כבה (0), מכיוון שהדף אינו משותף יותר עבור P1.\n            *   ביט ה-Dirty (D) נדלק (1), מכיוון שהדף נכתב.\n            *   ביט ה-Accessed (A) נדלק (1).\n            *   PTE לאחר כתיבה עבור P1: `PFN=0x3FFFF, V=1, P=1, D=1, A=1, COW=0`.\n        5.  **עדכון PTE של P2 (אם רלוונטי)**: ה-PTE של P2 עבור הדף המקורי נשאר ללא שינוי, עם ביט COW דולק, וממשיך להצביע על המסגרת הפיזית `0x2F3DE`. אם P2 ינסה לכתוב לדף זה, גם הוא יבצע COW משלו ויקבל מסגרת חדשה משלו.\n        6.  **המשך פעולה**: פעולת הכתיבה המקורית מתבצעת כעת במסגרת הפיזית החדשה (`0x3FFFF`).\n\n**1.3. ניצול זיכרון**\n\n*   **חישוב סך הזיכרון הפיזי עבור טבלאות הדפים (בכל הרמות) של P1 ו-P2 יחד**:\n    *   גודל דף = 4KB.\n    *   כל טבלת דפים (ברמה 1 או 2) תופסת דף אחד (4KB).\n    *   **תהליך P1**:\n        *   סה\"כ דפים בשימוש על ידי P1 (פרטיים + משותפים): 10 + 8 = 18 דפים.\n        *   בהנחת פיזור מינימלי, כל 18 הדפים ממופים על ידי כניסות בודדות בטבלת רמה 2 אחת. לכן, P1 יזדקק לטבלת רמה 2 אחת.\n        *   כדי להגיע לטבלת רמה 2 זו, נדרשת כניסה אחת בטבלת רמה 1 של P1. לכן, P1 יזדקק לטבלת רמה 1 אחת.\n        *   סה\"כ מסגרות לטבלאות דפים עבור P1: 1 (רמה 1) + 1 (רמה 2) = 2 מסגרות.\n    *   **תהליך P2**:\n        *   סה\"כ דפים בשימוש על ידי P2 (פרטיים + משותפים): 5 + 8 = 13 דפים.\n        *   בהנחת פיזור מינימלי, P2 יזדקק לטבלת רמה 2 אחת.\n        *   כדי להגיע לטבלת רמה 2 זו, נדרשת כניסה אחת בטבלת רמה 1 של P2. לכן, P2 יזדקק לטבלת רמה 1 אחת.\n        *   סה\"כ מסגרות לטבלאות דפים עבור P2: 1 (רמה 1) + 1 (רמה 2) = 2 מסגרות.\n    *   **סה\"כ מסגרות לטבלאות דפים עבור P1 ו-P2 יחד**: 2 (עבור P1) + 2 (עבור P2) = 4 מסגרות.\n    *   **סך זיכרון פיזי לטבלאות דפים**: 4 מסגרות * 4KB/מסגרת = 16KB.\n\n*   **חישוב סך הזיכרון הפיזי עבור דפי הנתונים (Private + Shared) של P1 ו-P2 יחד, *לפני* פעולת הכתיבה בסעיף 1.2ב**:\n    *   דפים פרטיים של P1: 10 דפים = 10 מסגרות פיזיות.\n    *   דפים פרטיים של P2: 5 דפים = 5 מסגרות פיזיות.\n    *   דפים משותפים (COW): 8 דפים. מכיוון שהם משותפים וטרם נכתב אליהם, הם ממופים לאותן מסגרות פיזיות. לכן, הם תופסים 8 מסגרות פיזיות.\n    *   **סה\"כ מסגרות לדפי נתונים לפני COW**: 10 (P1 פרטי) + 5 (P2 פרטי) + 8 (משותף COW) = 23 מסגרות.\n    *   **סך זיכרון פיזי לדפי נתונים לפני COW**: 23 מסגרות * 4KB/מסגרת = 92KB.\n\n*   **חישוב סך הזיכרון הפיזי עבור דפי הנתונים (Private + Shared) של P1 ו-P2 יחד, *לאחר* פעולת הכתיבה בסעיף 1.2ב**:\n    *   תהליך P1 כתב לאחד מהדפים המשותפים, מה שגרם להעתקה (COW).\n    *   דפים פרטיים של P1: 10 דפים = 10 מסגרות פיזיות.\n    *   דפים פרטיים של P2: 5 דפים = 5 מסגרות פיזיות.\n    *   דפים שהיו משותפים (COW) - מצב חדש:\n        *   7 דפים נותרו משותפים בין P1 ל-P2, והם ממופים ל-7 מסגרות פיזיות.\n        *   הדף ה-8 (ש-P1 כתב אליו) קיבל עותק חדש עבור P1, שמופה למסגרת פיזית חדשה (1 מסגרת).\n        *   המסגרת הפיזית המקורית של הדף ה-8 עדיין משמשת את P2 (כדף משותף עם COW). כלומר, היא נחשבת כעת למסגרת בשימוש על ידי P2 (אך לא על ידי P1 עבור דף זה). (1 מסגרת).\n        *   סה\"כ מסגרות עבור הדפים שהיו במקור משותפים: 7 (נותרו משותפים) + 1 (עותק P1) + 1 (מקורי, עדיין בשימוש P2) = 9 מסגרות.\n    *   **סה\"כ מסגרות לדפי נתונים לאחר COW**: 10 (P1 פרטי) + 5 (P2 פרטי) + 9 (דפים שהיו משותפים לאחר COW) = 24 מסגרות.\n    *   **סך זיכרון פיזי לדפי נתונים לאחר COW**: 24 מסגרות * 4KB/מסגרת = 96KB."}, "difficulty_estimation": "Hard", "_source_file": "0623__Paging__Open__Hard.json", "_topic_hint": "Paging", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:10:14", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Paging", "Virtual Memory", "Memory Management", "TLB", "Page Faults"], "content": {"text": "נתונה מערכת זיכרון וירטואלי עם המאפיינים הבאים:\n*   גודל כתובת וירטואלית (VA): 32 ביטים.\n*   גודל כתובת פיזית (PA): 30 ביטים.\n*   גודל דף: 4KB.\n*   טבלת דפים היררכית עם שתי רמות (P1 ו-P2).\n*   גודל כניסה בטבלת הדפים (PTE): 4 בתים.\n*   TLB (Translation Lookaside Buffer): 2 כניסות, אסוציאטיבי מלא, מדיניות החלפה LRU.\n*   פורמט PTE כולל: Present bit (P), Read/Write bit (R/W), Accessed bit (A), Dirty bit (D), וכן PFN (מספר מסגרת פיזית).\n    *   P=1: הדף נמצא בזיכרון פיזי. P=0: הדף אינו נמצא בזיכרון פיזי.\n    *   R/W=1: ניתן לקרוא ולכתוב לדף. R/W=0: ניתן לקרוא בלבד.\n    *   A: מוגדר ל-1 בעת גישה לדף (קריאה או כתיבה).\n    *   D: מוגדר ל-1 בעת כתיבה לדף.\n\n**מצב התחלתי:**\n*   ה-TLB ריק.\n*   מצב טבלאות הדפים (רק כניסות רלוונטיות, שאר הכניסות אינן Valid או אינן בשימוש): \n    *   PTE עבור דף וירטואלי `0x00000` (P1=0, P2=0): PFN=0x100, P=1, R/W=1, A=0, D=0\n    *   PTE עבור דף וירטואלי `0x00001` (P1=0, P2=1): PFN=0x101, P=1, R/W=0, A=0, D=0\n    *   PTE עבור דף וירטואלי `0x00400` (P1=1, P2=0): PFN=0x200, P=0, R/W=1, A=0, D=0\n    *   PTE עבור דף וירטואלי `0x00401` (P1=1, P2=1): PFN=0x201, P=1, R/W=1, A=0, D=0", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "כמה ביטים מוקצים לכל אחד מהשדות הבאים בכתובת הוירטואלית: אינדקס P1, אינדקס P2, והיסט (Offset)? מהו המספר המקסימלי של כניסות בכל רמה של טבלת הדפים? פרט את חישוביך.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "עקוב אחר סדרת הגישות הבאות לכתובות וירטואליות. עבור כל גישה, פרט את השלבים המתרחשים (בדיקת TLB, מעבר בטבלאות דפים), האם מתרחשת פסיקת דף (Page Fault) או שגיאת הגנה (Protection Fault), ואם לא, מהי הכתובת הפיזית המתקבלת. כמו כן, הצג את מצב ה-TLB לאחר כל גישה (אם הוא משתנה) ואת עדכוני ה-PTE הרלוונטיים (A ו-D ביטים).\n(הערה: הגישות הן לפי סדר, ו-LRU מחושב על בסיס הגישות המוצלחות שמעדכנות את ה-TLB).", "code_snippet": "גישה 1: קריאה לכתובת `0x00000010`\nגישה 2: כתיבה לכתובת `0x00001010`\nגישה 3: קריאה לכתובת `0x00400010`\nגישה 4: קריאה לכתובת `0x00000010`\nגישה 5: כתיבה לכתובת `0x00401010`\nגישה 6: קריאה לכתובת `0x00001010`", "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\n**1. חלוקת כתובת וירטואלית:**\n*   **גודל דף**: 4KB = 2^12 בתים. לכן, ההיסט (Offset) הוא 12 ביטים.\n*   **גודל כתובת וירטואלית**: 32 ביטים. מספר הביטים הנותרים למספרי דפים הוא 32 - 12 = 20 ביטים.\n*   **גודל כניסה בטבלת הדפים (PTE)**: 4 בתים.\n*   **מספר הכניסות המקסימלי בכל טבלת דפים** (שגודלה כגודל דף, 4KB): 4KB / 4B = 1024 כניסות.\n*   לכן, כל אינדקס ברמת טבלת הדפים (P1 ו-P2) דורש `log2(1024) = 10` ביטים.\n*   **חלוקת הכתובת הוירטואלית (32 ביטים)**:\n    *   אינדקס P1: 10 ביטים.\n    *   אינדקס P2: 10 ביטים.\n    *   היסט (Offset): 12 ביטים.\n*   **מספר הכניסות המקסימלי בכל רמה של טבלת הדפים**: 1024.\n\n**2. מעקב גישות לזיכרון:**\n\n**מצב התחלתי:**\n*   TLB: ריק. (רשימת LRU: []).\n*   PTEs רלוונטיים:\n    *   דף וירטואלי `0x00000` (P1=0, P2=0): PFN=0x100, P=1, R/W=1, A=0, D=0\n    *   דף וירטואלי `0x00001` (P1=0, P2=1): PFN=0x101, P=1, R/W=0, A=0, D=0\n    *   דף וירטואלי `0x00400` (P1=1, P2=0): PFN=0x200, P=0, R/W=1, A=0, D=0\n    *   דף וירטואלי `0x00401` (P1=1, P2=1): PFN=0x201, P=1, R/W=1, A=0, D=0\n\n**גישה 1: קריאה לכתובת `0x00000010`**\n*   מספר דף וירטואלי: `0x00000` (P1=0, P2=0). היסט: `0x10`.\n*   **בדיקת TLB**: Miss (ריק).\n*   **מעבר בטבלת דפים (Page Table Walk)**:\n    *   גישה ל-P1[0] (נניח תקין ומצביע לטבלת P2).\n    *   גישה ל-P2[0]. PTE שנמצא: PFN=0x100, P=1, R/W=1, A=0, D=0.\n    *   **בדיקת הרשאות**: גישת קריאה מותרת (R/W=1).\n    *   **בדיקת Present bit**: P=1, הדף נמצא בזיכרון. אין Page Fault.\n    *   **עדכון PTE**: A=1. ה-PTE הופך ל: PFN=0x100, P=1, R/W=1, A=1, D=0.\n*   **כתובת פיזית**: PFN `0x100` (18 ביטים) + היסט `0x10` (12 ביטים) = `0x04000010`.\n*   **עדכון TLB**: הוספת (VA Page `0x00000`, PFN `0x100`, R/W=1) ל-TLB.\n    *   מצב TLB: `[(0x00000, 0x100, R/W=1)]` (החדש ביותר מימין).\n*   **תוצאה**: כתובת פיזית `0x04000010`.\n\n**גישה 2: כתיבה לכתובת `0x00001010`**\n*   מספר דף וירטואלי: `0x00001` (P1=0, P2=1). היסט: `0x10`.\n*   **בדיקת TLB**: Miss.\n*   **מעבר בטבלת דפים**: \n    *   גישה ל-P1[0].\n    *   גישה ל-P2[1]. PTE שנמצא: PFN=0x101, P=1, R/W=0, A=0, D=0.\n    *   **בדיקת הרשאות**: ניסיון כתיבה, אך R/W=0 (קריאה בלבד).\n*   **תוצאה**: **שגיאת הגנה (Protection Fault)**. לא נוצרת כתובת פיזית. ה-TLB וה-PTE נשארים ללא שינוי.\n*   מצב TLB: `[(0x00000, 0x100, R/W=1)]`.\n\n**גישה 3: קריאה לכתובת `0x00400010`**\n*   מספר דף וירטואלי: `0x00400` (P1=1, P2=0). היסט: `0x10`.\n*   **בדיקת TLB**: Miss.\n*   **מעבר בטבלת דפים**: \n    *   גישה ל-P1[1].\n    *   גישה ל-P2[0]. PTE שנמצא: PFN=0x200, P=0, R/W=1, A=0, D=0.\n    *   **בדיקת הרשאות**: גישת קריאה מותרת (R/W=1).\n    *   **בדיקת Present bit**: P=0, הדף אינו נמצא בזיכרון.\n*   **תוצאה**: **פסיקת דף (Page Fault)**. לא נוצרת כתובת פיזית. ה-TLB וה-PTE נשארים ללא שינוי.\n*   מצב TLB: `[(0x00000, 0x100, R/W=1)]`.\n\n**גישה 4: קריאה לכתובת `0x00000010`**\n*   מספר דף וירטואלי: `0x00000` (P1=0, P2=0). היסט: `0x10`.\n*   **בדיקת TLB**: Hit עבור (0x00000, 0x100, R/W=1).\n*   **בדיקת הרשאות**: גישת קריאה מותרת (R/W=1).\n*   **עדכון PTE**: A=1 (כבר היה 1). ה-PTE נשאר: PFN=0x100, P=1, R/W=1, A=1, D=0.\n*   **כתובת פיזית**: PFN `0x100` + היסט `0x10` = `0x04000010`.\n*   **עדכון TLB**: הערך (0x00000, 0x100, R/W=1) הופך לשימוש האחרון. \n*   מצב TLB: `[(0x00000, 0x100, R/W=1)]`.\n\n**גישה 5: כתיבה לכתובת `0x00401010`**\n*   מספר דף וירטואלי: `0x00401` (P1=1, P2=1). היסט: `0x10`.\n*   **בדיקת TLB**: Miss.\n*   **מעבר בטבלת דפים**: \n    *   גישה ל-P1[1].\n    *   גישה ל-P2[1]. PTE שנמצא: PFN=0x201, P=1, R/W=1, A=0, D=0.\n    *   **בדיקת הרשאות**: גישת כתיבה מותרת (R/W=1).\n    *   **בדיקת Present bit**: P=1, הדף נמצא בזיכרון. אין Page Fault.\n    *   **עדכון PTE**: A=1, D=1. ה-PTE הופך ל: PFN=0x201, P=1, R/W=1, A=1, D=1.\n*   **כתובת פיזית**: PFN `0x201` + היסט `0x10` = `0x08040010`.\n*   **עדכון TLB**: הוספת (VA Page `0x00401`, PFN `0x201`, R/W=1) ל-TLB. \n    *   מצב TLB: `[(0x00000, 0x100, R/W=1), (0x00401, 0x201, R/W=1)]`. (0x00000 הוא ה-LRU).\n*   **תוצאה**: כתובת פיזית `0x08040010`.\n\n**גישה 6: קריאה לכתובת `0x00001010`**\n*   מספר דף וירטואלי: `0x00001` (P1=0, P2=1). היסט: `0x10`.\n*   **בדיקת TLB**: Miss.\n*   **מעבר בטבלת דפים**: \n    *   גישה ל-P1[0].\n    *   גישה ל-P2[1]. PTE שנמצא: PFN=0x101, P=1, R/W=0, A=0, D=0. (שימו לב: ה-A bit לא עודכן בגישה 2 מכיוון שהייתה תקלת הרשאה).\n    *   **בדיקת הרשאות**: גישת קריאה מותרת (R/W=0 פירושו קריאה בלבד).\n    *   **בדיקת Present bit**: P=1, הדף נמצא בזיכרון. אין Page Fault.\n    *   **עדכון PTE**: A=1. ה-PTE הופך ל: PFN=0x101, P=1, R/W=0, A=1, D=0.\n*   **כתובת פיזית**: PFN `0x101` + היסט `0x10` = `0x04040010`.\n*   **עדכון TLB**: הוספת (VA Page `0x00001`, PFN `0x101`, R/W=0) ל-TLB. ה-TLB מלא (2 כניסות), ולכן יש לפנות את הכניסה שהיא LRU. במקרה זה, (0x00000, 0x100, R/W=1) היא ה-LRU.\n    *   מצב TLB: `[(0x00401, 0x201, R/W=1), (0x00001, 0x101, R/W=0)]`.\n*   **תוצאה**: כתובת פיזית `0x04040010`."}, "difficulty_estimation": "Hard", "_source_file": "0624__Paging__Open__Hard.json", "_topic_hint": "Paging", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:11:11", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Paging", "Virtual Memory", "Address Translation"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם מנגנון דפדוף (paging).\nגודל דף (page size) וגודל מסגרת פיזית (frame size) הוא 4KB (כלומר, 2 בחזקת 12 בתים).\n\nכתוב פונקציית C בשם `translate_address` אשר מקבלת כתובת וירטואלית (32 סיביות) ומצביע לטבלת דפים חד-מפלסית. הפונקציה צריכה להחזיר את הכתובת הפיזית המתאימה.\nיש להניח שכל הדפים נמצאים בזיכרון הפיזי (כלומר, השדה `present` תמיד 1) ושטבלת הדפים תקינה. אין צורך לטפל ב-page faults.\n\nמבנה טבלת הדפים ומבנה כניסה בטבלה מוגדרים כדלהלן:", "code_snippet": "#include <stdio.h>\n\n#define PAGE_SIZE_BYTES 4096 // 4KB\n#define PAGE_SHIFT 12        // log2(4096)\n#define PAGE_MASK 0xFFF      // Mask for the offset (12 bits)\n\n// Structure for a Page Table Entry (PTE)\ntypedef struct {\n    unsigned int physical_frame_number; // The physical frame number\n    unsigned int present : 1;           // 1 if page is in physical memory, 0 otherwise\n} PageTableEntry;\n\n// Function to implement:\nunsigned int translate_address(unsigned int virtual_address, PageTableEntry* page_table) {\n    // Write your code here to translate the virtual_address to a physical address\n    return 0; // Placeholder\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון דורש מיצוי מספר הדף הווירטואלי (VPN) וההיסט (offset) מהכתובת הווירטואלית.\n1. מספר הדף הווירטואלי מתקבל על ידי הזזת הכתובת הווירטואלית ימינה ב-PAGE_SHIFT (12 סיביות).\n2. ההיסט מתקבל על ידי ביצוע פעולת AND לוגית בין הכתובת הווירטואלית לבין PAGE_MASK (שמייצג את 12 הסיביות הפחות משמעותיות).\n3. לאחר מכן, משתמשים במספר הדף הווירטואלי כאינדקס לטבלת הדפים כדי למצוא את כניסת טבלת הדפים (PTE) המתאימה. מכניסה זו אנו שולפים את מספר המסגרת הפיזית (PFN).\n4. לבסוף, הכתובת הפיזית מורכבת על ידי הזזת מספר המסגרת הפיזית שמאלה ב-PAGE_SHIFT ושילובו עם ההיסט באמצעות פעולת OR לוגית.", "code_snippet": "#include <stdio.h>\n\n#define PAGE_SIZE_BYTES 4096 // 4KB\n#define PAGE_SHIFT 12        // log2(4096)\n#define PAGE_MASK 0xFFF      // Mask for the offset (12 bits)\n\n// Structure for a Page Table Entry (PTE)\ntypedef struct {\n    unsigned int physical_frame_number; // The physical frame number\n    unsigned int present : 1;           // 1 if page is in physical memory, 0 otherwise\n} PageTableEntry;\n\n// Function to implement:\nunsigned int translate_address(unsigned int virtual_address, PageTableEntry* page_table) {\n    // 1. Extract virtual page number (VPN)\n    unsigned int virtual_page_number = virtual_address >> PAGE_SHIFT;\n\n    // 2. Extract offset within the page\n    unsigned int offset = virtual_address & PAGE_MASK;\n\n    // 3. Look up the Page Table Entry (PTE) using the VPN\n    //    We assume page_table is an array of PageTableEntry\n    PageTableEntry pte = page_table[virtual_page_number];\n\n    // 4. Combine the physical frame number (PFN) with the offset to get the physical address\n    unsigned int physical_address = (pte.physical_frame_number << PAGE_SHIFT) | offset;\n\n    return physical_address;\n}"}, "difficulty_estimation": "Easy", "_source_file": "0625__Paging__CodeAnalysis__Easy.json", "_topic_hint": "Paging", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:11:31", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Paging", "Virtual Memory", "Page Faults"], "content": {"text": "נתונה תוכנית ה-C הבאה:\n\nבהנחה כי:\n1. המערכת משתמשת ב-Demand Paging.\n2. גודל הדף הוא 4KB (כפי שהוגדר ב-`PAGE_SIZE`).\n3. גודל משתנה `int` הוא 4 בתים.\n4. המערך `arr` מוקצה בכתובת וירטואלית מיושרת לדף (page-aligned).\n5. בתחילת ריצת התוכנית, אף דף של המערך `arr` אינו נמצא בזיכרון הפיזי.\n6. כל גישה לאלמנט בתוך דף שאינו נמצא כרגע בזיכרון גורמת בדיוק לתקלת דף (page fault) אחת.\n7. מערכת ההפעלה טוענת את הדף כולו לזיכרון הפיזי בעקבות תקלת דף.\n\nכמה תקלות דף יתרחשו במהלך ביצוע לולאת ה-`for` בפונקציה `main`?", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define PAGE_SIZE 4096 // גודל דף בבתים\n#define NUM_PAGES 5    // מספר דפים שהמערך משתרע עליהם\n#define ELEMENTS_PER_PAGE (PAGE_SIZE / sizeof(int)) // מספר איברים מסוג int בדף אחד\n#define ARRAY_TOTAL_ELEMENTS (NUM_PAGES * ELEMENTS_PER_PAGE) // סך כל האיברים במערך\n\nint main() {\n    int* arr = (int*)malloc(ARRAY_TOTAL_ELEMENTS * sizeof(int));\n    if (arr == NULL) {\n        perror(\"malloc failed\");\n        return 1;\n    }\n\n    // לולאה הניגשת לכל האיברים במערך באופן סדרתי\n    for (int i = 0; i < ARRAY_TOTAL_ELEMENTS; ++i) {\n        arr[i] = i;\n    }\n\n    free(arr);\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסבר:\n*   `PAGE_SIZE` הוא 4096 בתים.\n*   גודל משתנה `int` הוא 4 בתים.\n*   לכן, `ELEMENTS_PER_PAGE` (מספר האיברים מסוג `int` בדף אחד) הוא 4096 / 4 = 1024.\n*   המערך משתרע על פני `NUM_PAGES` = 5 דפים.\n*   סך כל האיברים במערך הוא `ARRAY_TOTAL_ELEMENTS` = 5 * 1024 = 5120 איברים.\n*   לולאת ה-`for` ניגשת לכל האיברים במערך באופן סדרתי, החל מ-`arr[0]` ועד `arr[5119]`.\n*   כאשר `arr[0]` נגיש לראשונה, הוא נמצא בדף הראשון. מכיוון שדף זה אינו בזיכרון הפיזי, מתרחשת תקלת דף (page fault), וכל הדף הראשון נטען לזיכרון.\n*   גישות עוקבות לאיברים באותו דף (לדוגמה, `arr[1]` עד `arr[1023]`) לא יגרמו לתקלות דף נוספות, מכיוון שהדף שלהם כבר טעון.\n*   כאשר `arr[1024]` נגיש לראשונה, הוא נמצא בדף השני. דף זה אינו בזיכרון, ולכן מתרחשת תקלת דף שנייה, וכל הדף השני נטען.\n*   דפוס זה חוזר על עצמו: בכל פעם שהלולאה עוברת לדף חדש וניגשת לאלמנט הראשון שבו, מתרחשת תקלת דף.\n*   מכיוון שהמערך משתרע על פני 5 דפים, וכל דף נגיש לראשונה באופן סדרתי, תתרחש תקלת דף אחת בדיוק עבור כל אחד מ-5 הדפים.\n*   לכן, יתרחשו סך הכל 5 תקלות דף."}, "difficulty_estimation": "Easy", "_source_file": "0626__Paging__CodeAnalysis__Easy.json", "_topic_hint": "Paging", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:11:47", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Paging"], "content": {"text": "נתונה מערכת זיכרון המשתמשת בטכניקת Paging עם גודל עמוד של 4KB.\nלמען הפשטות, טבלת העמודים (Page Table) מכילה את הערכים הבאים (המספרים הם בבסיס עשרוני):\n\n| Virtual Page Number (VPN) | Physical Frame Number (PFN) |\n| :------------------------ | :-------------------------- |\n| 0                         | 10                          |\n| 1                         | 12                          |\n| 2                         | 8                           |\n| 3                         | 15                          |\n\nנתונה כתובת וירטואלית `0x32A4`.\nמהי הכתובת הפיזית המתאימה לכתובת וירטואלית זו?", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ראשית, נחשב את גודל ההיסט (offset) בכתובת. מכיוון שגודל עמוד הוא 4KB, שהם 2^12 בתים, ההיסט יהיה בן 12 ביטים.\nהכתובת הווירטואלית הנתונה היא `0x32A4`.\nנפריד את הכתובת הווירטואלית למספר העמוד הווירטואלי (VPN) ולהיסט (offset):\nהיסט (12 הביטים הפחות משמעותיים): `0x2A4`\nמספר עמוד וירטואלי (שאר הביטים, כלומר `0x32A4 >> 12`): `0x3` (או 3 בבסיס עשרוני)\n\nכעת, נשתמש בטבלת העמודים כדי למצוא את מספר המסגרת הפיזית (PFN) המתאים ל-VPN 3.\nמטבלת העמודים אנו רואים של-VPN 3 מתאים PFN 15.\n\nלבסוף, נבנה את הכתובת הפיזית על ידי שילוב ה-PFN עם ההיסט:\nכתובת פיזית = `(PFN << מספר ביטים של היסט) | היסט`\nכתובת פיזית = `(15 << 12) | 0x2A4`\n\nבבסיס הקסדצימלי:\n`15` בבסיס עשרוני הוא `F` בבסיס הקסדצימלי.\nהזזה של `F` ב-12 ביטים שמאלה היא `0xF000`.\nשילוב עם ההיסט: `0xF000 | 0x2A4 = 0xF2A4`.\n\nלכן, הכתובת הפיזית המתאימה היא `0xF2A4`."}, "difficulty_estimation": "Easy", "_source_file": "0627__Paging__CodeAnalysis__Easy.json", "_topic_hint": "Paging", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:12:00", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Paging", "Memory Management", "Virtual Memory"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם מנגנון Paging. גודל דף הוא 4KB. נניח שקיימת טבלת דפים ברמה אחת, כפי שמיוצגת בקוד ה-C הבא.\nבהינתן הכתובת הווירטואלית `0x00002345`, מהי הכתובת הפיזית המתאימה?\nיש להתייחס לטבלת הדפים כפי שהיא מוגדרת בקוד.", "code_snippet": "#include <stdint.h>\n\n// גודל דף הוא 4KB (2^12 בתים)\n#define PAGE_SIZE_BYTES 4096\n#define PAGE_OFFSET_BITS 12\n\n// טבלת דפים מפושטת: אינדקס המערך הוא מספר הדף הווירטואלי (VPN),\n// והערך באותו אינדקס הוא מספר המסגרת הפיזית (PFN).\nuint32_t page_table[5] = {\n    0x0000A, // page_table[0] maps to PFN 0xA\n    0x0000C, // page_table[1] maps to PFN 0xC\n    0x0000B, // page_table[2] maps to PFN 0xB\n    0x0000D, // page_table[3] maps to PFN 0xD\n    0x0000E  // page_table[4] maps to PFN 0xE\n};", "options": null}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "גודל דף הוא 4KB, שזה 2^12 בתים. לכן, 12 הביטים הפחות משמעותיים (0-11) של הכתובת הווירטואלית מייצגים את ההיסט בתוך הדף (Page Offset). שאר הביטים (12-31) מייצגים את מספר הדף הווירטואלי (Virtual Page Number - VPN).\n\nהכתובת הווירטואלית הנתונה היא `0x00002345`.\n1.  **חישוב Virtual Page Number (VPN)**:\n    נחלק את הכתובת הווירטואלית בגודל הדף, או ניקח את הביטים 12-31.\n    `VPN = 0x00002345 / 0x1000 = 0x00002` (או `0x00002345 >> 12`).\n\n2.  **חישוב Page Offset (PO)**:\n    ניקח את שארית החלוקה של הכתובת הווירטואלית בגודל הדף, או ניקח את הביטים 0-11.\n    `PO = 0x00002345 % 0x1000 = 0x345` (או `0x00002345 & 0xFFF`).\n\n3.  **איתור Physical Frame Number (PFN)**:\n    נשתמש ב-VPN (שהוא 2) כדי לחפש בטבלת הדפים.\n    לפי הקוד, `page_table[2]` מכיל `0x0000B`. לכן, `PFN = 0x0000B`.\n\n4.  **חישוב הכתובת הפיזית (Physical Address - PA)**:\n    נשלב את ה-PFN עם ה-PO.\n    `PA = (PFN << 12) | PO`\n    `PA = (0x0000B << 12) | 0x345`\n    `PA = 0xB000 | 0x345`\n    `PA = 0xB345`\n\nהכתובת הפיזית המתאימה היא `0xB345`."}, "difficulty_estimation": "Easy", "_source_file": "0628__Paging__CodeAnalysis__Easy.json", "_topic_hint": "Paging", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:12:22", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Paging"], "content": {"text": "נתונה מערכת זיכרון וירטואלי המשתמשת בטבלאות עמודים (Paging). גודל עמוד הוא 4KB (קילו-בתים).\nלהלן מוצגת כניסה מטבלת עמודים חלקית עבור תהליך מסוים:\n\nבהינתן הכתובת הווירטואלית `0x12345`, חשבו את הכתובת הפיזית המתאימה.", "code_snippet": "/*\n * גודל עמוד: 4KB (2^12 בתים)\n *\n * להלן חלק מטבלת העמודים המציג את הכניסה עבור עמוד וירטואלי 0x12:\n * page_table[0x12] = 0x07;\n * כלומר, עמוד וירטואלי 0x12 ממופה למסגרת פיזית 0x07.\n */", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כדי לחשב את הכתובת הפיזית, עלינו קודם כל לפרק את הכתובת הווירטואלית למספר העמוד הווירטואלי (VPN) ולהיסט בתוך העמוד (Page Offset).\nגודל העמוד הוא 4KB, שהם 2^12 בתים. לכן, 12 הביטים הפחות משמעותיים של הכתובת הווירטואלית מייצגים את ההיסט, ושאר הביטים מייצגים את מספר העמוד הווירטואלי.\n\nהכתובת הווירטואלית הנתונה היא `0x12345`.\n\n1.  **חישוב היסט העמוד (Page Offset):**\n    ההיסט הוא 12 הביטים התחתונים של הכתובת הווירטואלית.\n    `0x12345 & 0xFFF = 0x345`.\n\n2.  **חישוב מספר העמוד הווירטואלי (Virtual Page Number - VPN):**\n    מספר העמוד הווירטואלי מתקבל על ידי הזזת הכתובת הווירטואלית 12 ביטים ימינה.\n    `0x12345 >> 12 = 0x12`.\n\n3.  **איתור מספר המסגרת הפיזית (Frame Number - FN) בטבלת העמודים:**\n    על פי הנתון בשאלה, עבור עמוד וירטואלי מספר `0x12`, טבלת העמודים מפנה למסגרת פיזית מספר `0x07`.\n    כלומר, `page_table[0x12] = 0x07`.\n\n4.  **הרכבת הכתובת הפיזית (Physical Address - PA):**\n    הכתובת הפיזית מורכבת ממספר המסגרת הפיזית (FN) שאליו מוצמד ההיסט (PO).\n    `PA = (FN << 12) | PO`\n    `PA = (0x07 << 12) | 0x345`\n    `PA = 0x7000 | 0x345`\n    `PA = 0x7345`\n\nלכן, הכתובת הפיזית המתאימה לכתובת הווירטואלית `0x12345` היא `0x7345`."}, "difficulty_estimation": "Easy", "_source_file": "0629__Paging__CodeAnalysis__Easy.json", "_topic_hint": "Paging", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:12:37", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Paging", "Virtual Memory"], "content": {"text": "נתונה פונקציית C הבאה שמטרתה לנתח כתובת וירטואלית בהינתן גודל עמוד.\n\n```c\n#include <stdio.h>\n\nvoid analyze_virtual_address(unsigned int virtual_address, unsigned int page_size) {\n    unsigned int page_number = virtual_address / page_size;\n    unsigned int offset = virtual_address % page_size;\n\n    printf(\"מספר עמוד וירטואלי (VPN): %u\\n\", page_number);\n    printf(\"היסט בתוך העמוד (Offset): %u\\n\", offset);\n}\n\nint main() {\n    analyze_virtual_address(2050, 4096);\n    return 0;\n}\n```\n\nמה יהיה הפלט של התוכנית כאשר היא מורצת? הסבר את המשמעות של כל רכיב בפלט בהקשר של זיכרון וירטואלי ו-Paging.", "code_snippet": "#include <stdio.h>\n\nvoid analyze_virtual_address(unsigned int virtual_address, unsigned int page_size) {\n    unsigned int page_number = virtual_address / page_size;\n    unsigned int offset = virtual_address % page_size;\n\n    printf(\"מספר עמוד וירטואלי (VPN): %u\\n\", page_number);\n    printf(\"היסט בתוך העמוד (Offset): %u\\n\", offset);\n}\n\nint main() {\n    analyze_virtual_address(2050, 4096);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפלט של התוכנית יהיה:\n```\nמספר עמוד וירטואלי (VPN): 0\nהיסט בתוך העמוד (Offset): 2050\n```\n\n**הסבר:**\nבמערכות הפעלה המשתמשות ב-Paging לניהול זיכרון וירטואלי, כתובת וירטואלית מחולקת לשני חלקים עיקריים:\n1.  **מספר עמוד וירטואלי (Virtual Page Number - VPN)**: חלק זה מזהה את העמוד הוירטואלי שאליו מתייחסת הכתובת. הוא משמש כאינדקס לטבלת העמודים (Page Table) כדי למצוא את העמוד הפיזי המתאים.\n2.  **היסט בתוך העמוד (Offset)**: חלק זה מציין את המיקום הספציפי בתוך העמוד (הוירטואלי והפיזי) שאליו מתייחסת הכתובת.\n\nהפונקציה `analyze_virtual_address` מבצעת את החישובים הבאים:\n*   `page_number = virtual_address / page_size;`\n    כאשר `virtual_address` היא 2050 ו-`page_size` היא 4096:\n    `2050 / 4096 = 0` (חילוק של מספרים שלמים).\n    זה אומר שהכתובת 2050 נמצאת בעמוד הוירטואלי הראשון (עמוד מספר 0).\n*   `offset = virtual_address % page_size;`\n    כאשר `virtual_address` היא 2050 ו-`page_size` היא 4096:\n    `2050 % 4096 = 2050`.\n    זה אומר שהכתובת 2050 נמצאת בהיסט 2050 בתים מתחילת העמוד הוירטואלי.\n\nלכן, הכתובת הוירטואלית 2050, בגודל עמוד של 4096 בתים, מתורגמת לעמוד וירטואלי מספר 0, בהיסט 2050 בתוך עמוד זה."}, "difficulty_estimation": "Easy", "_source_file": "0630__Paging__CodeAnalysis__Easy.json", "_topic_hint": "Paging", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:12:51", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Paging", "Virtual Memory", "Address Translation"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי. גודל עמוד (page size) הוא 4KB (4096 בתים). נתון קטע קוד C המנסה לגשת לכתובת וירטואלית מסוימת. כמו כן, נתונה טבלת העמודים (page table) המפושטת עבור התהליך המריץ את הקוד. כתובת וירטואלית היא באורך 32 ביט.\n\nטבלת עמודים (Page Table) עבור התהליך (חלק רלוונטי):\n| מספר עמוד וירטואלי (VPN) | סיבית תקינות (Valid Bit) | מספר מסגרת עמוד פיזית (PFN) |\n|-------------------------|--------------------------|-------------------------------|\n| 0xABCD0                 | 1                        | 0x100                         |\n| 0xABCD1                 | 1                        | 0x200                         |\n| 0xABCD2                 | 0                        | 0x000                         |\n| 0xABCD3                 | 1                        | 0x300                         |\n\nבהתבסס על הקוד וטבלת העמודים, מהי הכתובת הפיזית אליה תתורגם הכתובת הוירטואלית `0xABCD1234`? הסבירו את הדרך לפתרון.", "code_snippet": "#include <stdio.h>\n\nint main() {\n    // הכתובת הוירטואלית שאליה מנסים לגשת:\n    unsigned long virtual_address = 0xABCD1234; \n    printf(\"Attempting to access virtual address: 0x%lx\\n\", virtual_address);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון מבוסס על תהליך תרגום כתובות וירטואליות לכתובות פיזיות במערכת מבוססת עמודים.\n\n1.  **פירוק הכתובת הוירטואלית**: הכתובת הוירטואלית הנתונה היא `0xABCD1234`. גודל עמוד הוא 4KB, כלומר 2^12 בתים. לכן, 12 הביטים הנמוכים ביותר של הכתובת הוירטואלית מייצגים את ההיסט בתוך העמוד (page offset), ושאר הביטים מייצגים את מספר העמוד הוירטואלי (VPN).\n    -   היסט העמוד (Page Offset): `0x234` (12 הביטים האחרונים).\n    -   מספר העמוד הוירטואלי (VPN): `0xABCD1` (הביטים הנותרים).\n\n2.  **חיפוש בטבלת העמודים**: אנו מחפשים את ה-VPN `0xABCD1` בטבלת העמודים הנתונה.\n    -   עבור VPN `0xABCD1`, אנו מוצאים שסיבית התקינות (Valid Bit) היא 1, מה שאומר שהעמוד נמצא בזיכרון הפיזי. מספר מסגרת העמוד הפיזית (PFN) המתאים הוא `0x200`.\n\n3.  **הרכבת הכתובת הפיזית**: הכתובת הפיזית מורכבת מצירוף ה-PFN וה-Offset.\n    -   כתובת פיזית = (PFN << 12) | Offset\n    -   כתובת פיזית = (`0x200` << 12) | `0x234`\n    -   הזזה שמאלה ב-12 ביטים של `0x200` נותנת `0x200000`.\n    -   חיבור ההיסט: `0x200000` + `0x234` = `0x200234`.\n\nלכן, הכתובת הפיזית היא `0x200234`."}, "difficulty_estimation": "Easy", "_source_file": "0631__Paging__CodeAnalysis__Easy.json", "_topic_hint": "Paging", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:13:13", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Paging"], "content": {"text": "נתונה מערכת זיכרון וירטואלי המשתמשת במנגנון Paging. גודל עמוד הוא 4KB (2^12 בתים). אורך כתובת וירטואלית הוא 32 ביטים. טבלת העמודים של תהליך מסוים נתונה להלן:\n\n| מספר עמוד וירטואלי (VPN) | מספר מסגרת פיזית (PFN) | דגל תקפות (Valid Bit) |\n|-------------------------|-------------------------|-----------------------|\n| 0x00000                 | 0x10000                 | 1                     |\n| 0x00001                 | 0x10001                 | 1                     |\n| 0x00002                 | 0x10002                 | 0                     |\n| 0x00003                 | 0x10003                 | 1                     |\n\nנתונה תוכנית C המנסה לגשת לכתובת וירטואלית מסוימת. מה תהיה הכתובת הפיזית אליה ניגשת התוכנית, או האם תתרחש תקלת עמוד (Page Fault)?\n\n```c\n#include <stdio.h>\n\nint main() {\n    unsigned int virtual_address = 0x00003A50; // הכתובת הווירטואלית לגישה\n    // נניח שהתוכנית מנסה לגשת לזיכרון בכתובת זו\n    // לדוגמה: char* ptr = (char*)virtual_address; char value = *ptr;\n    printf(\"Attempting to access virtual address: 0x%X\\n\", virtual_address);\n    return 0;\n}\n```\n\nמהי הכתובת הפיזית המתאימה, או האם תתרחש תקלת עמוד? נמק.", "code_snippet": "#include <stdio.h>\n\nint main() {\n    unsigned int virtual_address = 0x00003A50; // הכתובת הווירטואלית לגישה\n    // נניח שהתוכנית מנסה לגשת לזיכרון בכתובת זו\n    // לדוגמה: char* ptr = (char*)virtual_address; char value = *ptr;\n    printf(\"Attempting to access virtual address: 0x%X\\n\", virtual_address);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ראשית, נחלץ את מספר העמוד הווירטואלי (VPN) ואת ההיסט בתוך העמוד (offset) מהכתובת הווירטואלית הנתונה, 0x00003A50.\nגודל העמוד הוא 4KB, כלומר 2^12 בתים. לכן, 12 הביטים הפחות משמעותיים של הכתובת מייצגים את ההיסט בתוך העמוד, ושאר הביטים מייצגים את מספר העמוד הווירטואלי.\n\nהכתובת הווירטואלית: 0x00003A50\nהיסט (Offset): 0x00003A50 & 0xFFF = 0xA50 (12 הביטים האחרונים)\nמספר עמוד וירטואלי (VPN): 0x00003A50 >> 12 = 0x00003\n\nלאחר מכן, נבדוק את טבלת העמודים עבור ה-VPN שחישבנו (0x00003):\nבטבלה אנו רואים של-VPN 0x00003 מתאים מספר מסגרת פיזית (PFN) 0x10003, ודגל התקפות (Valid Bit) הוא 1.\nמכיוון שדגל התקפות הוא 1, העמוד נמצא בזיכרון הפיזי ולא תתרחש תקלת עמוד.\n\nלבסוף, נבנה את הכתובת הפיזית על ידי שילוב ה-PFN עם ההיסט:\nכתובת פיזית = (PFN << 12) | Offset\nכתובת פיזית = (0x10003 << 12) | 0xA50\nכתובת פיזית = 0x10003000 | 0xA50\nכתובת פיזית = 0x10003A50\n\nלכן, הכתובת הפיזית אליה ניגשת התוכנית היא 0x10003A50."}, "difficulty_estimation": "Easy", "_source_file": "0632__Paging__CodeAnalysis__Easy.json", "_topic_hint": "Paging", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:13:30", "_subject": "Virtualization"}, {"id": 9, "type": "CodeAnalysis", "topic": ["Paging", "Virtual Memory", "TLB", "Page Faults", "Memory Access Patterns"], "content": {"text": "נתונה התוכנית הבאה בשפת C המבצעת אתחול של מערך דו-ממדי גדול בשתי תבניות גישה שונות. המערכת עליה רצה התוכנית מוגדרת באופן הבא:\n- גודל דף: 4KB.\n- גודל מטמון תרגום כתובות (TLB): 64 כניסות.\n- גודל זיכרון פיזי: קטן מספיק כך שלא כל דפי המערך יכולים להיות בזיכרון הפיזי בו זמנית, מה שמוביל להחלפת דפים תכופה.\n- מדיניות החלפת דפים בזיכרון הפיזי וב-TLB היא LRU (Least Recently Used).\n- גודל int הוא 4 בתים.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define ROWS 1024\n#define COLS 1024\n#define PAGE_SIZE 4096 // 4KB\n\nint main() {\n    int (*matrix)[COLS] = (int (*)[COLS])malloc(ROWS * COLS * sizeof(int));\n    if (matrix == NULL) {\n        perror(\"malloc failed\");\n        return 1;\n    }\n\n    // Access pattern 1: Row-major\n    // אתחול בסדר שורה-עיקרי\n    for (int i = 0; i < ROWS; ++i) {\n        for (int j = 0; j < COLS; ++j) {\n            matrix[i][j] = i * COLS + j;\n        }\n    }\n\n    // Access pattern 2: Column-major\n    // אתחול בסדר עמודה-עיקרי\n    for (int j = 0; j < COLS; ++j) {\n        for (int i = 0; i < ROWS; ++i) {\n            matrix[i][j] = i * COLS + j;\n        }\n    }\n\n    free(matrix);\n    return 0;\n}"}, "sub_questions": [{"id": "9.1", "text": "כמה תקלות דף (page faults) וכמה אי-פגיעות ב-TLB (TLB misses) יתרחשו במהלך לולאת הגישה הראשונה (סדר שורה-עיקרי) למערך? נמקו.", "code_snippet": null, "options": null}, {"id": "9.2", "text": "כמה תקלות דף וכמה אי-פגיעות ב-TLB יתרחשו במהלך לולאת הגישה השנייה (סדר עמודה-עיקרי) למערך? נמקו.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "חישובים מקדימים:\n*   גודל המערך הכולל: ROWS * COLS * sizeof(int) = 1024 * 1024 * 4 בתים = 4MB.\n*   מספר הדפים שהמערך תופס: 4MB / 4KB = 1024 דפים.\n*   מספר איברים מסוג int לדף: 4KB / 4 בתים = 1024 איברים.\n*   כל שורה במערך: COLS * sizeof(int) = 1024 * 4 בתים = 4KB. כלומר, כל שורה תופסת בדיוק דף אחד.\n\nלולאת גישה ראשונה (סדר שורה-עיקרי):\n`for (int i = 0; i < ROWS; ++i) { for (int j = 0; j < COLS; ++j) { matrix[i][j] = ...; } }`\n\n*   תקלות דף (Page Faults):\n    *   הגישה היא סדרתית, שורה-אחר-שורה. כל שורה (4KB) מתאימה בדיוק לדף אחד.\n    *   כאשר ניגשים לאיבר הראשון בשורה (`matrix[i][0]`), נגרמת תקלת דף (אם הדף אינו כבר בזיכרון הפיזי). הדף כולו נטען לזיכרון הפיזי.\n    *   כל שאר הגישות לאיברים באותה שורה (`matrix[i][1]` עד `matrix[i][COLS-1]`) יהיו פגיעות בדף שכבר נטען.\n    *   מכיוון שיש ROWS = 1024 שורות, וכל שורה נמצאת בדף נפרד, ובהנחה שהזיכרון הפיזי אינו יכול להכיל את כל 1024 הדפים בו-זמנית (ומדיניות LRU תגרום להחלפה), כל גישה ראשונה לשורה חדשה תגרום לתקלת דף.\n    *   סה\"כ תקלות דף: ROWS = 1024.\n*   אי-פגיעות ב-TLB (TLB Misses):\n    *   עבור כל שורה i, הגישה הראשונה `matrix[i][0]` גורמת לאי-פגיעה ב-TLB (הכתובת הווירטואלית לדף זה אינה ב-TLB). הערך נטען ל-TLB.\n    *   כל שאר הגישות לאיברים באותה שורה (`matrix[i][1]` עד `matrix[i][COLS-1]`) יהיו פגיעות ב-TLB, מכיוון שהדף כבר נמצא ב-TLB.\n    *   מכיוון שיש ROWS = 1024 שורות, ומספר הדפים הייחודיים (1024) גדול בהרבה מגודל ה-TLB (64), בכל פעם שנעבור לשורה חדשה (דף חדש), הדף הקודם ביותר ב-TLB יוחלף (לפי LRU). לכן, הגישה הראשונה לכל שורה תגרום לאי-פגיעה ב-TLB.\n    *   סה\"כ אי-פגיעות ב-TLB: ROWS = 1024.\n\nלולאת גישה שנייה (סדר עמודה-עיקרי):\n`for (int j = 0; j < COLS; ++j) { for (int i = 0; i < ROWS; ++i) { matrix[i][j] = ...; } }`\n\n*   תקלות דף (Page Faults):\n    *   הגישה היא עמודה-אחר-עמודה. כל גישה `matrix[i][j]` ולאחריה `matrix[i+1][j]` היא גישה לאיברים המרוחקים ב- `COLS * sizeof(int) = 4096 בתים = 1 דף`.\n    *   משמעות הדבר היא שכל גישה לאיבר `matrix[i][j]` (למעט `i=0`) היא לדף שונה מהגישה הקודמת (`matrix[i-1][j]`).\n    *   במהלך הלולאה הפנימית (`for i`), אנו ניגשים ל-ROWS = 1024 דפים שונים ברצף. מכיוון שהזיכרון הפיזי קטן מ-1024 דפים, ובהתאם למדיניות LRU, רוב הדפים ייזרקו מהזיכרון הפיזי לפני שנגיע אליהם שוב בלולאה החיצונית הבאה (`j+1`).\n    *   למעשה, כל גישה לאיבר (`matrix[i][j]`) תהיה ככל הנראה לדף שאינו בזיכרון הפיזי, מכיוון שאנו עוברים בין 1024 דפים שונים עבור כל j, ורק 64 דפים יכולים להיות ב-TLB, ופחות מ-1024 דפים בזיכרון הפיזי. סדר הגישה הטורי (קפיצות של גודל דף) מבטיח שכל גישה כמעט תמיד תהיה לדף חדש או לדף שהוצא מזמן.\n    *   סה\"כ תקלות דף: ROWS * COLS = 1024 * 1024 = 1,048,576.\n*   אי-פגיעות ב-TLB (TLB Misses):\n    *   בדומה לתקלות הדף, כל גישה לאיבר `matrix[i][j]` (למעט `i=0`) היא לדף שונה מהגישה הקודמת.\n    *   במהלך הלולאה הפנימית (`for i`), אנו ניגשים ל-ROWS = 1024 דפים שונים. מכיוון שגודל ה-TLB הוא 64 כניסות בלבד, כל גישה לאיבר (`matrix[i][j]`) תגרום לאי-פגיעה ב-TLB, מכיוון שהדף המתאים יוצא מן ה-TLB לפני שנגיע אליו שוב (אם בכלל).\n    *   סה\"כ אי-פגיעות ב-TLB: ROWS * COLS = 1024 * 1024 = 1,048,576."}, "difficulty_estimation": "Medium", "_source_file": "0633__Paging__CodeAnalysis__Medium.json", "_topic_hint": "Paging", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:14:17", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Paging", "TLB", "Memory Management", "Cache Performance"], "content": {"text": "נתונה תוכנית C הבאה המבצעת איתחול של מטריצה דו-ממדית:\n```c\n#include <stdio.h>\n#include <stdlib.h>\n\n#define MATRIX_SIZE 256 // N x N matrix\n#define INT_SIZE_BYTES 4 // Size of an integer in bytes\n\nint main() {\n    // Allocate a 2D array (MATRIX_SIZE x MATRIX_SIZE) of integers\n    int (*matrix)[MATRIX_SIZE] = (int (*)[MATRIX_SIZE])malloc(sizeof(int) * MATRIX_SIZE * MATRIX_SIZE);\n    if (matrix == NULL) {\n        perror(\"Failed to allocate matrix\");\n        return 1;\n    }\n\n    // Access pattern: Row-major\n    for (int i = 0; i < MATRIX_SIZE; ++i) {\n        for (int j = 0; j < MATRIX_SIZE; ++j) {\n            matrix[i][j] = i * MATRIX_SIZE + j;\n        }\n    }\n\n    free(matrix);\n    return 0;\n}\n```\nהמערכת עליה רצה התוכנית משתמשת בזיכרון וירטואלי עם מנגנון Paging. נתונים הפרטים הבאים:\n*   גודל דף (Page Size) הוא 4KB (4096 בתים).\n*   TLB (Translation Lookaside Buffer) הינו בגודל 16 כניסות (entries) ומשתמש במדיניות החלפה LRU (Least Recently Used).\n*   ההקצאה `malloc` מצליחה ומחזירה בלוק זיכרון רציף במרחב הווירטואלי.\n*   התהליך מקבל מספיק מסגרות פיזיות (physical frames) כדי להכיל את כל המטריצה.\n*   אין TLB hits ראשוניים (כלומר ה-TLB ריק בתחילת הריצה של הלולאות).\n*   התעלמו מגישות לזיכרון שאינן קשורות למטריצה (למשל, קוד התוכנית עצמו, משתנים מקומיים).\n\n**שאלה:**\nכמה TLB Misses יתרחשו במהלך ביצוע הלולאה החיצונית (הלולאה של `i`) בגישה לזיכרון של המטריצה `matrix`? נמקו את תשובתכם בפירוט.", "code_snippet": null, "options": null}, "sub_questions": null, "points": 20, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "הבה ננתח את הפרמטרים והגישה לזיכרון:\n1.  **גודל המטריצה:** `MATRIX_SIZE = 256`. כל איבר הוא `int` (4 בתים).\n    גודל המטריצה הכולל: `256 * 256 * 4 בתים = 262,144 בתים = 256KB`.\n2.  **גודל דף:** `4KB = 4096 בתים`.\n3.  **מספר איברים בדף:** `4096 בתים / 4 בתים/איבר = 1024 איברים`.\n4.  **מספר דפים למטריצה:** `262,144 בתים / 4096 בתים/דף = 64 דפים`.\n5.  **TLB Size:** 16 כניסות.\n6.  **מדיניות החלפה:** LRU (Least Recently Used).\n\n**ניתוח הגישה לזיכרון (Row-major):**\nהלולאה החיצונית עוברת על `i` מ-0 עד `MATRIX_SIZE-1` (כלומר 0 עד 255).\nהלולאה הפנימית עוברת על `j` מ-0 עד `MATRIX_SIZE-1` (כלומר 0 עד 255) עבור כל `i`.\nבכל איטרציה של הלולאה החיצונית (עבור `i` מסוים), אנו ניגשים לכל האיברים בשורה `i` (`matrix[i][0]` עד `matrix[i][255]`).\n\n**כמה שורות נכנסות לדף אחד?**\nאורך שורה אחת: `256 איברים * 4 בתים/איבר = 1024 בתים`.\nמכיוון שגודל דף הוא `4096 בתים`, דף אחד מכיל בדיוק `4096 / 1024 = 4` שורות שלמות.\n\nלכן, הגישה לזיכרון מתרחשת באופן הבא:\n*   שורות `0, 1, 2, 3` נמצאות בדף 0.\n*   שורות `4, 5, 6, 7` נמצאות בדף 1.\n*   ... וכן הלאה, עד שורות `252, 253, 254, 255` שנמצאות בדף 63.\n\n**חישוב TLB Misses:**\nהתוכנית ניגשת לדפים בסדר עוקב: דף 0, לאחר מכן דף 1, לאחר מכן דף 2, וכן הלאה, עד דף 63. כל דף נגיש למשך 4 איטרציות של הלולאה החיצונית (לדוגמה, דף 0 נגיש עבור `i=0,1,2,3`).\n\n*   **עבור `i = 0`:** הגישה הראשונה ל-`matrix[0][0]` היא הגישה הראשונה לדף 0. ה-TLB ריק, ולכן מתרחש TLB Miss. דף 0 נטען ל-TLB. כל שאר הגישות לאיברים בשורה 0 יהיו TLB Hits.\n*   **עבור `i = 1, 2, 3`:** ניגשים לשורות 1, 2, ו-3, שנמצאות כולן בדף 0. דף 0 כבר ב-TLB, ולכן כל הגישות יהיו TLB Hits.\n    (סה\"כ TLB Misses עד כה: 1)\n\n*   **עבור `i = 4`:** הגישה הראשונה ל-`matrix[4][0]` היא הגישה הראשונה לדף 1. דף 1 אינו ב-TLB (הוא חדש). מתרחש TLB Miss. דף 1 נטען ל-TLB.\n*   **עבור `i = 5, 6, 7`:** ניגשים לדף 1. דף 1 כבר ב-TLB, ולכן כל הגישות יהיו TLB Hits.\n    (סה\"כ TLB Misses עד כה: 2)\n\nדפוס זה ממשיך. בכל פעם שהלולאה החיצונית מגיעה ל-`i` שהוא כפולה של 4 (כלומר, `i = 0, 4, 8, ...`), אנו מתחילים לגשת לדף חדש במטריצה. ישנם `256 / 4 = 64` דפים ייחודיים במטריצה.\n\n**השפעת גודל ה-TLB (16 כניסות) ומדיניות LRU:**\nמכיוון שהגישה לדפים היא סדרתית (P0, P1, P2, ..., P63) וגודל ה-TLB הוא 16 כניסות (קטן ממספר הדפים הכולל 64):\n1.  הגישות הראשונות לדפים 0 עד 15 יגרמו ל-16 TLB Misses. ה-TLB יתמלא בדפים אלו. דף 0 יהיה ה-LRU.\n2.  כאשר נגשים לדף 16 (עבור `i = 64`), מתרחש TLB Miss. דף 16 נטען ל-TLB ומחליף את דף 0 (שהוא ה-LRU).\n3.  כאשר נגשים לדף 17 (עבור `i = 68`), מתרחש TLB Miss. דף 17 נטען ל-TLB ומחליף את דף 1 (שהוא ה-LRU החדש).\n4.  דפוס זה חוזר על עצמו. כל גישה לדף חדש, לאחר שה-TLB התמלא, תגרום ל-TLB Miss, שכן הדף הנדרש אינו ב-TLB (הוא הודח בעבר, או שהוא חדש לגמרי) והוא יחליף את הדף ה-LRU.\n\nמכיוון שיש 64 דפים ייחודיים במטריצה, וכל גישה ראשונה לדף חדש תגרום ל-TLB Miss, סך ה-TLB Misses יהיה 64.\n\n**תשובה סופית:** 64 TLB Misses.", "code_snippet": null}, "difficulty_estimation": "Medium", "_source_file": "0634__Paging__CodeAnalysis__Medium.json", "_topic_hint": "Paging", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:15:04", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Paging", "Memory Management", "TLB", "Locality"], "content": {"text": "נתונה תוכנית C המבצעת גישה לזיכרון בשתי דרכים שונות על מערך גדול. גודל דף במערכת הוא 4KB (4096 בתים). ה-TLB (Translation Lookaside Buffer) במערכת מכיל 64 כניסות. יש להתעלם מהשפעות מטמון הנתונים (data cache) ולהתמקד בהתנהגות ה-Paging וה-TLB בלבד.\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n\n#define ARRAY_SIZE (256 * 1024 * 1024) // 256 MB\n#define PAGE_SIZE 4096 // 4 KB\n\nint main() {\n    char *arr = (char *)malloc(ARRAY_SIZE);\n    if (arr == NULL) {\n        perror(\"malloc failed\");\n        return 1;\n    }\n\n    // Ensure all pages are mapped and resident in physical memory.\n    // This loop forces initial page faults for all pages.\n    for (long i = 0; i < ARRAY_SIZE; i += PAGE_SIZE) {\n        arr[i] = 0;\n    }\n\n    // --- Loop 1: Sequential Access ---\n    printf(\"Starting sequential access (Loop 1)...\\n\");\n    for (long i = 0; i < ARRAY_SIZE; ++i) {\n        arr[i] = (char)(i % 256);\n    }\n    printf(\"Sequential access finished.\\n\");\n\n    // --- Loop 2: Strided Access ---\n    // Stride is PAGE_SIZE * 2 to ensure we hit different pages frequently\n    printf(\"Starting strided access (Loop 2)...\\n\");\n    for (long i = 0; i < ARRAY_SIZE; i += (PAGE_SIZE * 2)) {\n        arr[i] = (char)(i % 256);\n    }\n    printf(\"Strided access finished.\\n\");\n\n    free(arr);\n    return 0;\n}\n```\n\n**שאלות:**\n1.  השוו ונתחו את מספר ה-TLB misses הצפוי עבור \"לולאה 1: גישה סדרתית\" לעומת \"לולאה 2: גישה מדלגת\". הסבירו מדוע קיים הבדל.\n2.  האם לולאה כלשהי עלולה לגרום ל-page faults נוספים (מעבר לאלה שנגרמו על ידי אתחול המערך)? הסבירו מדוע.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define ARRAY_SIZE (256 * 1024 * 1024) // 256 MB\n#define PAGE_SIZE 4096 // 4 KB\n\nint main() {\n    char *arr = (char *)malloc(ARRAY_SIZE);\n    if (arr == NULL) {\n        perror(\"malloc failed\");\n        return 1;\n    }\n\n    // Ensure all pages are mapped and resident in physical memory.\n    // This loop forces initial page faults for all pages.\n    for (long i = 0; i < ARRAY_SIZE; i += PAGE_SIZE) {\n        arr[i] = 0;\n    }\n\n    // --- Loop 1: Sequential Access ---\n    printf(\"Starting sequential access (Loop 1)...\\n\");\n    for (long i = 0; i < ARRAY_SIZE; ++i) {\n        arr[i] = (char)(i % 256);\n    }\n    printf(\"Sequential access finished.\\n\");\n\n    // --- Loop 2: Strided Access ---\n    // Stride is PAGE_SIZE * 2 to ensure we hit different pages frequently\n    printf(\"Starting strided access (Loop 2)...\\n\");\n    for (long i = 0; i < ARRAY_SIZE; i += (PAGE_SIZE * 2)) {\n        arr[i] = (char)(i % 256);\n    }\n    printf(\"Strided access finished.\\n\");\n\n    free(arr);\n    return 0;\n}\n", "options": null}, "sub_questions": null, "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  **השוואת TLB misses:**\n    *   **לולאה 1 (גישה סדרתית):** לולאה זו ניגשת לבתים בזיכרון באופן רציף. בכל פעם שהתוכנית ניגשת לדף חדש (כלומר, כתובת זיכרון שעוברת לדף אחר), תתרחש TLB miss אם ה-PTE (Page Table Entry) עבור דף זה אינו נמצא כבר ב-TLB. לאחר שה-PTE נטען ל-TLB, כל הגישות הבאות לבתים בתוך אותו דף יגרמו ל-TLB hit. מאחר וגודל ה-TLB הוא 64 כניסות, הוא יכול להכיל מיפויים עבור 64 דפים, שהם 64 * 4KB = 256KB. המערך כולו גדול בהרבה (256MB). לכן, ה-TLB יתמלא ויתחיל לפנות כניסות ישנות. אך בגלל הגישה הסדרתית, בכל פעם שניגשים לדף חדש, סביר להניח שהדף שפונה הוא הדף שהיה בשימוש לפני זמן רב, והדף החדש הנטען יהיה בשימוש ל-4KB הבאים. לכן, מספר ה-TLB misses יהיה בקירוב מספר הדפים הכולל במערך: `ARRAY_SIZE / PAGE_SIZE = 256MB / 4KB = 65536` TLB misses.\n    *   **לולאה 2 (גישה מדלגת):** לולאה זו ניגשת לזיכרון בקפיצות של `PAGE_SIZE * 2 = 8KB`. כל קפיצה כזו מובילה לכתובת שנמצאת בדף *שונה* מהדף הקודם אליו ניגשנו (למעשה, היא מדלגת על דף אחד ומגיעה לדף הבא אחריו). מאחר וכל גישה היא לדף אחר, וגודל ה-TLB (64 כניסות) קטן בהרבה ממספר הדפים הכולל אליהם ניגשים בלולאה זו (שהוא `ARRAY_SIZE / (PAGE_SIZE * 2) = 256MB / 8KB = 32768` דפים ייחודיים), כמעט כל גישה תגרום ל-TLB miss. בכל פעם שניגשים לדף חדש, ה-PTE שלו יוכנס ל-TLB, אך מכיוון שהגישות אינן סדרתיות וה-TLB קטן יחסית למספר הדפים הייחודיים שאליהם ניגשים, סביר להניח שה-PTE שהוכנס קודם לכן כבר פונה. לכן, מספר ה-TLB misses יהיה גבוה מאוד, בקירוב `ARRAY_SIZE / (PAGE_SIZE * 2) = 32768`.\n    *   **הבדל:** לולאה 2 תגרום למספר TLB misses גבוה בהרבה מלולאה 1. הסיבה לכך היא שלולאה 1 מנצלת את עקרון המקומיות המרחבית (spatial locality) בצורה יעילה, מה שמאפשר ל-TLB למפות אזור זיכרון גדול יחסית (256KB) לפני שהוא נאלץ לפנות כניסות. לעומת זאת, לולאה 2 \"מביסה\" את ה-TLB על ידי דילוג קבוע לדפים חדשים, ובכך כמעט כל גישה גורמת ל-TLB miss.\n\n2.  **Page Faults נוספים:**\n    *   הלולאה הראשונית `for (long i = 0; i < ARRAY_SIZE; i += PAGE_SIZE)` מבצעת גישה לכל דף במערך. פעולה זו גורמת ל-page fault ראשוני עבור כל דף, ומבטיחה שכל הדפים המרכיבים את המערך `arr` יטענו לזיכרון פיזי וימופו על ידי טבלת הדפים של התהליך.\n    *   לאחר לולאת האתחול, כל הדפים של המערך כבר נמצאים בזיכרון פיזי. לכן, הן \"לולאה 1: גישה סדרתית\" והן \"לולאה 2: גישה מדלגת\" ניגשות לכתובות זיכרון שכבר ממופות וממוקמות בזיכרון הפיזי.\n    *   בהנחה שאין לחץ זיכרון משמעותי במערכת שיגרום ל-OS לפנות דפים מהזיכרון הפיזי (השאלה מבקשת להתמקד בהתנהגות ה-Paging וה-TLB בלבד ולהתעלם מהשפעות מטמון נתונים), לא צפויים להתרחש page faults *נוספים* באף אחת מהלולאות, מעבר לאלה שנגרמו על ידי לולאת האתחול.", "code_snippet": null}, "difficulty_estimation": "Medium", "_source_file": "0635__Paging__CodeAnalysis__Medium.json", "_topic_hint": "Paging", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:15:31", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Paging", "Memory Management", "Virtual Memory", "Page Faults"], "content": {"text": "נתונה תוכנית C המבצעת איטרציה על מערך דו-ממדי גדול. התוכנית רצה על מערכת עם זיכרון וירטואלי.\n\nנתונים:\n- גודל דף: 4 קילובייט (KB).\n- גודל משתנה `int`: 4 בתים.\n- זיכרון פיזי זמין לדפי נתונים (user data pages) של התהליך: 128 קילובייט (KB).\n- מדיניות החלפת דפים: LRU (Least Recently Used).\n- ניתן להניח שהמערך `arr` מיושר לגבול דף (page boundary).\n- ניתן להניח שקטעי קוד, מחסנית (stack) וטבלת הדפים של התהליך אינם מתחרים על הזיכרון הפיזי המוקצה לדפי הנתונים.\n\nכמה Page Faults (כשלים בדף) יתרחשו במהלך ריצת הלולאות בתוכנית הנתונה? נמק את תשובתך.", "code_snippet": "int arr[1024][1024];\n\nvoid access_array() {\n    for (int i = 0; i < 1024; ++i) {\n        for (int j = 0; j < 1024; ++j) {\n            arr[i][j] = i + j;\n        }\n    }\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "גודל המערך `arr` הוא `1024 * 1024 * 4` בתים = 4 מגה-בייט (MB).\nגודל דף הוא 4 קילובייט (KB).\nלכן, המערך תופס `4MB / 4KB = 1024` דפים.\nכל שורה במערך `arr[i]` תופסת `1024 * 4 = 4096` בתים, שהם בדיוק גודל של דף אחד. כלומר, שורה `i` של המערך נמצאת כולה בדף `i`.\n\nהזיכרון הפיזי הזמין לדפי נתונים הוא 128 קילובייט (KB).\nמספר מסגרות הזיכרון הפיזי (frames) הזמינות לדפי נתונים הוא `128KB / 4KB = 32` מסגרות.\n\nהלולאה החיצונית עוברת על השורות (`i`), והלולאה הפנימית עוברת על העמודות (`j`).\nכאשר `i=0`, התוכנית ניגשת לאלמנטים `arr[0][0]` עד `arr[0][1023]`. כל אלה נמצאים בדף 0.\n- הגישה הראשונה ל-`arr[0][0]` תגרום ל-Page Fault אחד, מכיוון שדף 0 אינו בזיכרון. דף 0 נטען לאחת המסגרות.\n- כל הגישות הבאות בדף 0 (כלומר `arr[0][1]` עד `arr[0][1023]`) הן Page Hits ולא יגרמו ל-Page Faults נוספים.\nסה\"כ 1 Page Fault עבור `i=0`.\n\nבאופן דומה, עבור `i=1` עד `i=31`:\n- בכל איטרציה של `i`, ניגשים לדף חדש (דף `i`).\n- הגישה הראשונה לדף `i` תגרום ל-Page Fault אחד.\n- לאחר `i=31`, 32 דפים (0 עד 31) נטענו ל-32 המסגרות הפיזיות. כל המסגרות מלאות.\n\nהחל מ-`i=32`:\n- ניגשים לדף 32, והוא אינו בזיכרון. תתרחש Page Fault.\n- מכיוון שמדיניות ההחלפה היא LRU והדף הכי פחות בשימוש הוא דף 0 (שנטען ראשון ולא היה בשימוש מאז), דף 0 יפונה מהזיכרון הפיזי, ודף 32 יטען במקומו.\n- תבנית זו חוזרת על עצמה עבור כל `i` עד `1023`. בכל איטרציה של הלולאה החיצונית (עבור כל שורה), ניגשים לדף חדש שלא נמצא בזיכרון הפיזי (עקב הגבלת מספר המסגרות ושימוש ב-LRU), ולכן תתרחש Page Fault אחת.\n\nסה\"כ מספר ה-Page Faults הוא 1024, אחד עבור כל אחת מ-1024 השורות (דפים) במערך, כאשר כל שורה נטענת לראשונה (או נטענת מחדש לאחר פינוי) במהלך האיטרציה שלה.", "code_snippet": null}, "difficulty_estimation": "Medium", "_source_file": "0636__Paging__CodeAnalysis__Medium.json", "_topic_hint": "Paging", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:15:59", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Paging", "Memory Management", "Spatial Locality", "Page Faults"], "content": {"text": "נתונה פיסת הקוד הבאה:\nהתוכנית מריצה שתי לולאות הניגשות למערך דו-ממדי בגודל 1024x1024 שלמים (integers). כל הגישות הן לכתיבה.\nבמערכת זו נתון גם:\n- גודל דף זיכרון הוא 4KB.\n- גודל שלם (int) הוא 4 בתים.\n- כל הדפים של המערך אינם טעונים לזיכרון הפיזי בתחילת ריצת התוכנית (כלומר, כל גישה לדף בפעם הראשונה תגרום ל-page fault).\n- ה-TLB מספיק גדול כדי להחזיק את כל הערכים הדרושים לדף בודד, ואין צורך להתחשב בביצועי ה-TLB.\n\nשאלה:\nהשוו את מספר ה-page faults שייגרמו על ידי 'לולאה 1' (גישה לפי שורות) לעומת 'לולאה 2' (גישה לפי עמודות). הסבירו מדוע קיים הבדל, אם קיים, וחשבו את מספר ה-page faults עבור כל לולאה בנפרד.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define ROWS 1024\n#define COLS 1024\n\nint main() {\n    int (*arr)[COLS] = (int (*)[COLS])malloc(ROWS * COLS * sizeof(int));\n    if (arr == NULL) {\n        perror(\"malloc failed\");\n        return 1;\n    }\n\n    // Loop 1: Row-major access\n    printf(\"Accessing array in row-major order...\\n\");\n    for (int i = 0; i < ROWS; ++i) {\n        for (int j = 0; j < COLS; ++j) {\n            arr[i][j] = i * COLS + j; // Write access\n        }\n    }\n\n    // Loop 2: Column-major access\n    printf(\"Accessing array in column-major order...\\n\");\n    for (int j = 0; j < COLS; ++j) {\n        for (int i = 0; i < ROWS; ++i) {\n            arr[i][j] = i * COLS + j; // Write access\n        }\n    }\n\n    free(arr);\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "הסבר:\n*   **גודל המערך:** המערך הוא בגודל `1024 * 1024` שלמים. כל שלם הוא 4 בתים. לכן, הגודל הכולל של המערך הוא `1024 * 1024 * 4` בתים = `4,194,304` בתים = `4` מגה-בייט.\n*   **גודל דף:** 4 קילובייט (`4096` בתים).\n*   **מספר שלמים לדף:** `4096` בתים / `4` בתים/שלם = `1024` שלמים.\n*   **מספר הדפים הכולל למערך:** `4` מגה-בייט / `4` קילובייט/דף = `1024` דפים.\n\n**לולאה 1 (גישה לפי שורות - Row-major access):**\n`for (int i = 0; i < ROWS; ++i) { for (int j = 0; j < COLS; ++j) { arr[i][j] = ...; } }`\n*   בלולאה זו, הגישה לאלמנטים מתבצעת בסדר: `arr[0][0], arr[0][1], ..., arr[0][1023], arr[1][0], ...`.\n*   מכיוון שכל שורה מכילה `1024` שלמים, וכל דף זיכרון יכול להכיל בדיוק `1024` שלמים, כל שורה במערך תופסת דף זיכרון אחד בדיוק.\n*   כאשר ניגשים לאלמנט `arr[i][0]` בפעם הראשונה, הדף המכיל את השורה `i` עדיין אינו בזיכרון הפיזי, ולכן תתרחש `page fault`. דף זה ייטען לזיכרון הפיזי.\n*   כל הגישות הבאות לאלמנטים באותה שורה (`arr[i][1]` עד `arr[i][1023]`) יתבצעו לדף שכבר נמצא בזיכרון, ולכן לא יגרמו ל-`page fault` נוסף עבור שורה זו.\n*   דפוס זה חוזר על עצמו עבור כל אחת מ-`ROWS` השורות (1024 שורות).\n*   לכן, תתרחש `page fault` אחת לכל שורה.\n*   **מספר ה-page faults הכולל עבור לולאה 1 = `ROWS` = `1024` page faults.**\n\n**לולאה 2 (גישה לפי עמודות - Column-major access):**\n`for (int j = 0; j < COLS; ++j) { for (int i = 0; i < ROWS; ++i) { arr[i][j] = ...; } }`\n*   בלולאה זו, הגישה לאלמנטים מתבצעת בסדר: `arr[0][0], arr[1][0], ..., arr[1023][0], arr[0][1], ...`.\n*   `arr[0][0]` נמצא בדף 0.\n*   `arr[1][0]` נמצא בדף 1 (שורה 1 היא דף נפרד).\n*   `arr[2][0]` נמצא בדף 2 (שורה 2 היא דף נפרד).\n*   וכך הלאה, עד `arr[1023][0]` שנמצא בדף 1023.\n*   בכל פעם שניגשים ל-`arr[i][j]` (עבור `j` קבוע ו-`i` משתנה), הגישה היא לדף זיכרון שונה מהגישה הקודמת `arr[i-1][j]`, מכיוון שכל שורה היא דף נפרד.\n*   לכן, כמעט כל גישה לאלמנט `arr[i][j]` תגרום ל-`page fault` מכיוון שהדף המכיל אותו לא יהיה טעון בזיכרון הפיזי (אלא אם כן הוא נטען כבר בגישה קודמת לאותה עמודה, אבל במקרה זה, הגישה הראשונה לכל אלמנט תגרום ל-page fault).\n*   מספר הגישות הכולל למערך הוא `ROWS * COLS` = `1024 * 1024`.\n*   **מספר ה-page faults הכולל עבור לולאה 2 = `1024 * 1024` = `1,048,576` page faults.**\n\n**מסקנה:**\nלולאה 1 (גישה לפי שורות) גורמת ל-`1024` page faults מכיוון שהיא מפגינה לוקליות מרחבית (spatial locality) מצוינת. ברגע שדף נטען לזיכרון, כל הגישות הבאות לאותה שורה (שהיא הדף כולו) הן מהירות.\nלולאה 2 (גישה לפי עמודות) גורמת ל-`1,048,576` page faults מכיוון שהיא מפגינה לוקליות מרחבית ירודה מאוד. כל גישה עוקבת קופצת לדף זיכרון חדש, מה שמוביל ל-page fault כמעט עבור כל גישת זיכרון. הבדל דרמטי זה מדגיש את החשיבות של תבניות גישת זיכרון לביצועים במערכות זיכרון מבוססות דפדוף.", "code_snippet": null}, "difficulty_estimation": "Medium", "_source_file": "0637__Paging__CodeAnalysis__Medium.json", "_topic_hint": "Paging", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:16:20", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Paging", "Virtual Memory", "Memory Management", "Locality of Reference"], "content": {"text": "נתונה מערכת הפעלה המנהלת זיכרון וירטואלי עם גודל דף של 4KB. גודל משתנה מסוג `int` הוא 4 בתים. נתונה תוכנית C המשתמשת במערך דו-ממדי סטטי גדול:\n\nהניחו שהמערך `arr` נמצא כולו באזור זיכרון המשתמש (user space) ואינו טעון לזיכרון הפיזי בתחילת ביצוע הפונקציות (כלומר, כל הדפים המכילים את המערך מסומנים כ-invalid בטבלת הדפים).", "code_snippet": "#define ROWS 1024\n#define COLS 1024\nstatic int arr[ROWS][COLS]; // ~4MB total size\n\n// פונקציה 1: גישה בסדר שורות\nvoid access_row_major() {\n    for (int i = 0; i < ROWS; ++i) {\n        for (int j = 0; j < COLS; ++j) {\n            arr[i][j] = i * j;\n        }\n    }\n}\n\n// פונקציה 2: גישה בסדר עמודות\nvoid access_col_major() {\n    for (int j = 0; j < COLS; ++j) {\n        for (int i = 0; i < ROWS; ++i) {\n            arr[i][j] = i * j;\n        }\n    }\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "כמה Page Faults (כשל דף) יתרחשו בסך הכל בעת קריאה לפונקציה `access_row_major()`? נמקו.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "כמה Page Faults (כשל דף) יתרחשו בסך הכל בעת קריאה לפונקציה `access_col_major()`? נמקו.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "הסבירו מדוע יש הבדל (או אין הבדל) במספר ה-Page Faults בין שתי הפונקציות.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "נתונים:\nגודל דף = 4KB = 4096 בתים.\nגודל `int` = 4 בתים.\nמספר `int`ים לדף = 4096 / 4 = 1024 `int`ים.\nגודל המערך `arr` הוא `1024 * 1024 * 4` בתים = `4,194,304` בתים = 4MB.\nמספר הדפים הכולל הנדרש למערך = 4MB / 4KB = 1024 דפים.\n\n**1. ניתוח `access_row_major()`:**\nמערכי C מאוחסנים בזיכרון בסדר שורות (row-major order). כלומר, האלמנטים `arr[i][0]`, `arr[i][1]`, ..., `arr[i][COLS-1]` מאוחסנים בזיכרון באופן רציף. \nבמקרה זה, `COLS = 1024`. מכיוון שדף אחד יכול להכיל 1024 `int`ים, כל שורה במערך `arr` (שגודלה `1024 * 4` בתים = 4KB) תתאים בדיוק לדף אחד בזיכרון. \nכאשר הפונקציה ניגשת לאלמנט הראשון בשורה (`arr[i][0]`), יתרחש Page Fault, והדף המכיל את כל השורה `i` ייטען לזיכרון הפיזי. לאחר מכן, כל הגישות הבאות לאלמנטים באותה שורה (`arr[i][1]` עד `arr[i][1023]`) ימצאו את הנתונים כבר בזיכרון הפיזי ולא יגרמו ל-Page Fault נוסף. \nמכיוון שיש `ROWS = 1024` שורות, וכל שורה גורמת ל-Page Fault אחד (ברגע הגישה הראשונה אליה), המספר הכולל של Page Faults יהיה **1024**. \n\n**2. ניתוח `access_col_major()`:**\nבפונקציה זו, הלולאה הפנימית עוברת על האינדקס `i` (שורות) בעוד האינדקס `j` (עמודות) קבוע. כלומר, סדר הגישה לזיכרון הוא `arr[0][j]`, `arr[1][j]`, `arr[2][j]`, וכן הלאה. \nהאלמנט `arr[i][j]` והאלמנט `arr[i+1][j]` אינם סמוכים בזיכרון. ההפרש בכתובות ביניהם הוא `COLS * sizeof(int)` בתים. במקרה זה, `1024 * 4` בתים = 4096 בתים, שזהו בדיוק גודל של דף אחד. \nמשמעות הדבר היא שכל גישה לאלמנט `arr[i][j]` (עבור `i` שונה) תהיה בדף זיכרון שונה לגמרי. לדוגמה, `arr[0][j]` יהיה בדף P, `arr[1][j]` יהיה בדף P+1, `arr[2][j]` בדף P+2, וכן הלאה. \nלכן, עבור כל עמודה `j`, כאשר הלולאה הפנימית עוברת על `i` מ-0 עד `ROWS-1`, כל גישה ל-`arr[i][j]` תגרום ל-Page Fault חדש, מכיוון שהיא ניגשת לדף שונה שעדיין לא נטען. \nיש `ROWS = 1024` גישות כאלה עבור כל עמודה, וקיימות `COLS = 1024` עמודות. \nלכן, המספר הכולל של Page Faults יהיה `ROWS * COLS = 1024 * 1024 = 1,048,576`. \n\n**3. הסבר ההבדל:**\nההבדל הדרמטי במספר ה-Page Faults נובע מעקרון 'מקומיוּת ההתייחסות' (Locality of Reference), ובפרט 'מקומיוּת מרחבית' (Spatial Locality). \n*   **`access_row_major()`** מפגינה מקומיוּת מרחבית גבוהה: היא ניגשת לזיכרון באופן רציף (אלמנטים סמוכים בזיכרון). כאשר דף נטען לזיכרון הפיזי בעקבות Page Fault, הוא מכיל את כל האלמנטים הבאים שהפונקציה תצטרך באותה שורה. לכן, רוב הגישות ימצאו את הנתונים כבר בזיכרון הפיזי, מה שמפחית משמעותית את מספר ה-Page Faults. \n*   **`access_col_major()`** מפגינה מקומיוּת מרחבית נמוכה מאוד: כל גישה בתוך הלולאה הפנימית (שינוי `i`) קופצת לכתובת זיכרון המרוחקת בדיוק דף אחד מהכתובת הקודמת. משמעות הדבר היא שכל גישה כמעט תמיד תגרום ל-Page Fault חדש, מכיוון שהיא דורשת דף זיכרון שונה שאינו טעון. זה מוביל לטעינה של דפים רבים ושונים שוב ושוב, ובכך מגדיל מאוד את מספר ה-Page Faults.", "code_snippet": null}, "difficulty_estimation": "Medium", "_source_file": "0638__Paging__CodeAnalysis__Medium.json", "_topic_hint": "Paging", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:16:44", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Paging", "Memory Management", "Locality of Reference"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם מנגנון Paging.\nגודל דף הוא 4KB (קילו-בייטים). גודל שלם (int) הוא 4 בייטים.\nנתונה תוכנית C המבצעת הקצאת זיכרון עבור מערך דו-ממדי גדול ולאחר מכן ניגשת אליו בשתי דרכים שונות.\nיש להניח כי המערך מוקצה בזיכרון רציף ומתחיל בכתובת המיושרת לגבול דף (page boundary).\nכמו כן, יש להניח כי טבלת הדפים של התהליך ריקה לחלוטין בתחילת כל איטרציה של לולאת ה-`for` החיצונית של כל קטע קוד (Loop A ו-Loop B). כלומר, אם דף נגיש באיטרציה קודמת, הוא יחשב כ'לא נגיש' באיטרציה הבאה של הלולאה החיצונית.\nהתעלמו מ-TLB ומהשפעותיו, והתמקדו רק ב-page faults.\n\n```c\n#include <stdlib.h>\n\n#define ROWS 1024\n#define COLS 1024\n\nint main() {\n    int* arr = (int*)malloc(ROWS * COLS * sizeof(int)); // Allocate 4MB\n    if (arr == NULL) return 1;\n\n    // Loop A: Row-major access\n    for (int i = 0; i < ROWS; ++i) {\n        for (int j = 0; j < COLS; ++j) {\n            arr[i * COLS + j] = i + j;\n        }\n    }\n\n    // Loop B: Column-major access\n    for (int j = 0; j < COLS; ++j) {\n        for (int i = 0; i < ROWS; ++i) {\n            arr[i * COLS + j] = i - j;\n        }\n    }\n\n    free(arr);\n    return 0;\n}\n```\n\n1. כמה page faults יתרחשו במהלך ביצוע \"Loop A\"? נמקו.\n2. כמה page faults יתרחשו במהלך ביצוע \"Loop B\"? נמקו.", "code_snippet": null, "options": null}, "sub_questions": null, "points": 20, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "נתונים:\n- גודל דף: 4KB = 4096 בייטים.\n- גודל int: 4 בייטים.\n- מספר שלמים לדף: 4096 / 4 = 1024 שלמים.\n- גודל מערך: ROWS * COLS = 1024 * 1024 שלמים.\n- גודל המערך בבייטים: 1024 * 1024 * 4 בייטים = 4MB.\n- מספר הדפים הכולל שהמערך תופס: 4MB / 4KB = 1024 דפים.\n\nההנחה המרכזית היא ש\"טבלת הדפים של התהליך ריקה לחלוטין בתחילת כל איטרציה של לולאת ה-`for` החיצונית של כל קטע קוד (Loop A ו-Loop B)\". המשמעות היא שכל דף שיגש אליו ייחשב כ'לא נגיש' שוב בתחילת האיטרציה הבאה של הלולאה החיצונית, גם אם הוא נגיש באיטרציה הנוכחית. (זהו תרחיש היפותטי שמטרתו לבחון הבנה של דפוסי גישה).\n\n**1. Page Faults במהלך ביצוע \"Loop A\" (גישה לפי שורות):**\n- הלולאה החיצונית (`for (int i = 0; i < ROWS; ++i)`) מבצעת 1024 איטרציות.\n- בכל איטרציה של הלולאה החיצונית (`i` קבוע), הלולאה הפנימית (`for (int j = 0; j < COLS; ++j)`) ניגשת לכל 1024 האלמנטים בשורה הנוכחית: `arr[i * COLS + j]` כאשר `j` משתנה מ-0 ל-1023.\n- מכיוון שכל שורה מכילה 1024 שלמים, ו-1024 שלמים תופסים בדיוק דף אחד (1024 * 4 בייטים = 4096 בייטים), כל שורה נמצאת בדף נפרד.\n- בתחילת כל איטרציה של הלולאה החיצונית (`i`), טבלת הדפים ריקה. לכן, הגישה הראשונה לשורה הנוכחית (למשל, `arr[i * COLS + 0]`) תגרום ל-page fault אחד כדי להביא את הדף המכיל את השורה כולה.\n- לאחר ה-page fault הראשון עבור השורה, כל שאר הגישות לשלמים באותה שורה יהיו בתוך אותו דף שכבר נטען, ולכן לא יגרמו ל-page faults נוספים באותה איטרציה של הלולאה החיצונית.\n- מכיוון שיש `ROWS = 1024` איטרציות בלולאה החיצונית, וכל איטרציה גורמת ל-1 page fault (עבור הדף של השורה הנוכחית), המספר הכולל של page faults ב-\"Loop A\" הוא: `1024 * 1 = 1024` page faults.\n\n**2. Page Faults במהלך ביצוע \"Loop B\" (גישה לפי עמודות):**\n- הלולאה החיצונית (`for (int j = 0; j < COLS; ++j)`) מבצעת 1024 איטרציות.\n- בכל איטרציה של הלולאה החיצונית (`j` קבוע), הלולאה הפנימית (`for (int i = 0; i < ROWS; ++i)`) ניגשת לאלמנטים `arr[i * COLS + j]` כאשר `i` משתנה מ-0 ל-1023.\n- הגישות הללו הן: `arr[j]`, `arr[COLS + j]`, `arr[2 * COLS + j]`, ..., `arr[(ROWS - 1) * COLS + j]`.\n- מכיוון ש-`COLS = 1024` שלמים, והמספר המקסימלי של שלמים בדף הוא 1024, כל גישה `arr[i * COLS + j]` קופצת לדף חדש לחלוטין ביחס לגישה הקודמת `arr[(i-1) * COLS + j]`. לדוגמה:\n  - `arr[j]` נמצא בדף 0.\n  - `arr[COLS + j]` נמצא בדף 1.\n  - `arr[2 * COLS + j]` נמצא בדף 2.\n  - ...\n  - `arr[(ROWS - 1) * COLS + j]` נמצא בדף `ROWS - 1`.\n- כלומר, בכל איטרציה של הלולאה הפנימית (`i`), אנו ניגשים לדף חדש.\n- בתחילת כל איטרציה של הלולאה החיצונית (`j`), טבלת הדפים ריקה. לכן, הלולאה הפנימית תגרום ל-page fault עבור כל גישה לאלמנט, מכיוון שכל גישה היא לדף חדש שטרם נטען (או שהיה נטען באיטרציה קודמת של הלולאה החיצונית אך נחשב כעת כ'לא נגיש').\n- הלולאה הפנימית מבצעת `ROWS = 1024` גישות לדפים שונים, ולכן תגרום ל-1024 page faults.\n- מכיוון שיש `COLS = 1024` איטרציות בלולאה החיצונית, וכל איטרציה גורמת ל-1024 page faults, המספר הכולל של page faults ב-\"Loop B\" הוא: `1024 * 1024 = 1,048,576` page faults."}, "difficulty_estimation": "Medium", "_source_file": "0639__Paging__CodeAnalysis__Medium.json", "_topic_hint": "Paging", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:17:32", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Paging", "Memory Management", "Page Faults", "LRU", "Performance"], "content": {"text": "נתונה תוכנית C המבצעת גישה למערך דו-ממדי גדול. המערכת פועלת עם זיכרון וירטואלי ומשתמשת במנגנון דפדוף (paging).\n\nהניחו את הפרטים הבאים בנוגע למערכת הזיכרון:\n- גודל דף: 4096 בתים (4KB).\n- גודל משתנה `int`: 4 בתים.\n- מספר מסגרות פיזיות זמינות *לנתוני המערך* (arr): 10 מסגרות (frames).\n- מדיניות החלפת דפים: LRU (Least Recently Used).\n- בתחילת ריצת התוכנית, טבלת הדפים של המערך ריקה (כלומר, אף דף של המערך אינו נמצא בזיכרון הפיזי).\n- שאר דפי התהליך (קוד, מחסנית, ערימה) כבר טעונים ואינם נכללים בספירת המסגרות המצוינות לעיל או בספירת כשלי הדף.\n\nכמה כשלי דף (page faults) יתרחשו במהלך ביצוע הלולאה הראשית בתוכנית הנתונה?", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define ROWS 1024\n#define COLS 1024\n\nint arr[ROWS][COLS]; // מערך גלובלי\n\nint main() {\n    // גישה למערך בסדר עמודות-ראשי (column-major access)\n    for (int j = 0; j < COLS; ++j) {\n        for (int i = 0; i < ROWS; ++i) {\n            arr[i][j] = i + j; // גישה ל-arr[i][j]\n        }\n    }\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "נתונים:\n- גודל דף: 4096 בתים (4KB).\n- גודל משתנה `int`: 4 בתים.\n- המערך `arr[1024][1024]` מאוחסן בזיכרון בסדר שורות-ראשי (row-major order). כלומר, `arr[0][0], arr[0][1], ..., arr[0][1023]` סמוכים בזיכרון, ואחריהם `arr[1][0], arr[1][1], ...` וכן הלאה.\n\nחישוב גודל המערך והדפים:\n- כל שורה במערך, `arr[i]`, מכילה `1024 * 4 = 4096` בתים. זהו בדיוק גודל של דף אחד.\n- לכן, כל שורה `arr[i]` שוכנת בדף נפרד. המערך כולו משתרע על פני 1024 דפים שונים (נסמן אותם כ-P0 עבור `arr[0]`, P1 עבור `arr[1]`, ..., P1023 עבור `arr[1023]`).\n\nניתוח לולאות הגישה:\n- הלולאה החיצונית רצה על `j` (עמודות), והלולאה הפנימית רצה על `i` (שורות).\n- בכל איטרציה של הלולאה הפנימית, אנו ניגשים ל-`arr[i][j]`. כאשר `i` משתנה, אנו למעשה קופצים לדף אחר בזיכרון (מדף P`i` לדף P`i+1`).\n\nמספר המסגרות הפיזיות הזמינות לנתוני המערך: 10 מסגרות (frames).\nמדיניות החלפת דפים: LRU (Least Recently Used).\n\nניתוח כמות כשלי דף:\n1.  **לולאה חיצונית `j = 0` (העמודה הראשונה):**\n    - הלולאה הפנימית תגש ל-`arr[0][0], arr[1][0], ..., arr[1023][0]`. רצף הגישות לדפים הוא `P0, P1, ..., P1023`.\n    - גישה ל-`arr[0][0]` (דף P0) תגרום לכשל דף (הדף אינו בזיכרון). P0 נטען למסגרת.\n    - גישה ל-`arr[1][0]` (דף P1) תגרום לכשל דף. P1 נטען למסגרת.\n    - ...\n    - גישה ל-`arr[9][0]` (דף P9) תגרום לכשל דף. P9 נטען למסגרת. כעת כל 10 המסגרות מלאות בדפים P0-P9.\n    - גישה ל-`arr[10][0]` (דף P10) תגרום לכשל דף. מכיוון שהמסגרות מלאות, יש להחליף דף. לפי מדיניות LRU, דף P0 (שהיה בשימוש הכי פחות לאחרונה מבין אלו שבזיכרון) יוחלף על ידי P10.\n    - גישה ל-`arr[11][0]` (דף P11) תגרום לכשל דף. P1 יוחלף על ידי P11. (וכן הלאה, הדף P`i-10` יוחלף על ידי P`i`).\n    - תבנית זו חוזרת על עצמה. כל גישה ל-`arr[i][0]` עבור `i` מ-0 עד 1023 תגרום לכשל דף, שכן הדף `P_i` לא יהיה בזיכרון או יהיה דף חדש שיש לטעון.\n    - סך הכל כשלי דף עבור `j=0`: 1024 כשלי דף.\n\n2.  **לולאות חיצוניות `j = 1` עד `j = 1023`:**\n    - כאשר הלולאה החיצונית עוברת לעמודה הבאה (`j=1`), הלולאה הפנימית שוב ניגשת לדפים `P0, P1, ..., P1023` בסדר זה.\n    - נניח גישה ל-`arr[0][1]` (דף P0). דף P0 הוצא מהזיכרון במהלך הטיפול בעמודה `j=0` (כאשר P10 נטען). לכן, גישה זו תגרום לכשל דף נוסף. דף LRU הנוכחי (למשל, P1014, אם נניח שהדפים האחרונים שנטענו עבור j=0 היו P1014-P1023) יוחלף ב-P0.\n    - באופן דומה, גישה ל-`arr[1][1]` (דף P1) תגרום לכשל דף, מכיוון ש-P1 הוצא מהזיכרון במהלך הטיפול בעמודה `j=0` (כאשר P11 נטען). דף LRU יוחלף ב-P1.\n    - תבנית זו חוזרת על עצמה עבור כל `arr[i][j]` בכל עמודה.\n    - מכיוון שמספר הדפים הכולל של המערך (1024) גדול בהרבה ממספר המסגרות הזמינות (10), כל דף שנטען לזיכרון עבור `j` מסוים, ככל הנראה יוצא מהזיכרון לפני שיידרש שוב בעמודה הבאה (`j+1`). זהו מצב של 'thrashing' (הדפה) בו רוב זמן המעבד מושקע בהחלפת דפים.\n\n**סיכום:**\n- עבור כל אחת מ-`ROWS * COLS = 1024 * 1024` הגישות למערך `arr[i][j]`, יתרחש כשל דף.\n- סך כל כשלי הדף יהיה: `1024 * 1024 = 1,048,576`.\n\n**תשובה:** מספר כשלי הדף הכולל הוא 1,048,576.", "code_snippet": null}, "difficulty_estimation": "Medium", "_source_file": "0640__Paging__CodeAnalysis__Medium.json", "_topic_hint": "Paging", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:18:08", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Paging", "Virtual Memory", "TLB", "Page Faults", "Memory Access Patterns"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם מנגנון Paging דו-שכבתי. הפרטים הטכניים של המערכת הם כדלקמן:\n*   מרחב כתובות וירטואלי: 32 סיביות.\n*   גודל דף: 4KB (2^12 בתים).\n*   מבנה טבלאות הדפים:\n    *   אינדקס לטבלת הדפים העליונה (Page Directory Index - PDI): 10 סיביות (מסיביות 31-22).\n    *   אינדקס לטבלת הדפים התחתונה (Page Table Index - PTI): 10 סיביות (מסיביות 21-12).\n    *   היסט בתוך הדף (Page Offset): 12 סיביות (מסיביות 11-0).\n*   TLB (Translation Lookaside Buffer): מכיל 4 כניסות, אסוציאטיבי מלא (fully associative), ומשתמש במדיניות החלפה LRU (Least Recently Used). ה-TLB ריק בתחילת ריצת התוכנית.\n*   זיכרון פיזי: גדול מספיק להכיל את כל הנתונים הנדרשים.\n*   הנחות:\n    *   הקצאת הזיכרון באמצעות `malloc` מחזירה בלוק רציף של כתובות וירטואליות.\n    *   כל דפי המערך `matrix` אינם נמצאים בזיכרון הפיזי בתחילת הריצה (כל גישה ראשונה לדף תגרום ל-Page Fault).\n    *   טבלאות הדפים (Page Directory ו-Page Tables) תמיד נמצאות בזיכרון הפיזי ואינן גורמות ל-Page Faults.\n    *   TLB Miss גורם לחיפוש בטבלאות הדפים. Page Fault מתרחש כאשר דף אינו בזיכרון הפיזי. לאחר Page Fault, הדף נטען לזיכרון הפיזי, ה-PTE המתאים מתעדכן, וה-TLB מתעדכן עם המיפוי החדש.\n\nנתונה התוכנית הבאה:\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n\n#define ROWS 1024\n#define COLS 1024\n\nint main() {\n    int (*matrix)[COLS] = (int (*)[COLS])malloc(ROWS * COLS * sizeof(int));\n    if (matrix == NULL) {\n        perror(\"malloc failed\");\n        return 1;\n    }\n\n    // Access elements in a specific pattern\n    for (int j = 0; j < COLS; ++j) { // Outer loop iterates through columns\n        for (int i = 0; i < ROWS; ++i) { // Inner loop iterates through rows\n            matrix[i][j] = i + j; // Write access\n        }\n    }\n\n    free(matrix);\n    return 0;\n}\n\n```\n\nחשבו עבור התוכנית הנ\"ל את:\n1.  המספר הכולל של Page Faults שיגרמו במהלך ריצת הלולאות הפנימיות והחיצוניות.\n2.  המספר הכולל של TLB Misses שיגרמו במהלך ריצת הלולאות הפנימיות והחיצוניות.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define ROWS 1024\n#define COLS 1024\n\nint main() {\n    int (*matrix)[COLS] = (int (*)[COLS])malloc(ROWS * COLS * sizeof(int));\n    if (matrix == NULL) {\n        perror(\"malloc failed\");\n        return 1;\n    }\n\n    // Access elements in a specific pattern\n    for (int j = 0; j < COLS; ++j) { // Outer loop iterates through columns\n        for (int i = 0; i < ROWS; ++i) { // Inner loop iterates through rows\n            matrix[i][j] = i + j; // Write access\n        }\n    }\n\n    free(matrix);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "**ניתוח מבנה הזיכרון והגישה:**\n*   גודל דף: 4KB (2^12 בתים).\n*   גודל `int`: 4 בתים.\n*   מספר `int`-ים בדף: 4096 בתים / 4 בתים/`int` = 1024 `int`-ים.\n*   המערך `matrix` בגודל `1024x1024` `int`-ים, מאוחסן בזיכרון בסדר שורות (row-major).\n*   גודל שורה אחת במערך: `1024 * 4` בתים = 4096 בתים = 1 דף.\n*   מכאן, כל שורה במערך תופסת בדיוק דף אחד בזיכרון הווירטואלי, וכל שורה חדשה מתחילה בדף וירטואלי חדש. בהנחה שכתובת הבסיס של המערך מיושרת לדף, הגישה ל-`matrix[i][j]` תמיד תתייחס לדף הווירטואלי המתאים לשורה `i` (כלומר, דף מספר `i`).\n*   הלולאות ניגשות למערך בסדר עמודות-ראשי (column-major): עבור `j` קבוע, `i` עובר מ-0 עד 1023. כלומר, ניגשים ל-`matrix[0][j]`, `matrix[1][j]`, ..., `matrix[1023][j]` (אשר נמצאים בדפים `P0`, `P1`, ..., `P1023` בהתאמה).\n\n**1. מספר Page Faults כולל:**\n*   כאשר `j=0` (הלולאה החיצונית הראשונה), הלולאה הפנימית ניגשת ל-`matrix[0][0]`, `matrix[1][0]`, ..., `matrix[1023][0]`.\n*   גישה ל-`matrix[0][0]` מתייחסת לדף `P0`. מכיוון שכל הדפים אינם בזיכרון הפיזי בתחילה, גישה זו תגרום ל-Page Fault עבור דף `P0`. הדף ייטען לזיכרון הפיזי.\n*   באופן דומה, גישה ל-`matrix[1][0]` מתייחסת לדף `P1` ותגרום ל-Page Fault. הדף ייטען.\n*   תהליך זה יחזור על עצמו עבור כל `i` מ-0 עד 1023. כל גישה ל-`matrix[i][0]` תגרום ל-Page Fault עבור דף `Pi` (מכיוון שזהו הדף `Pi` הראשון שנפגש בתוכנית).\n*   בסך הכל, עבור `j=0`, ניגשים ל-1024 דפים שונים (`P0` עד `P1023`), וכל אחד מהם גורם ל-Page Fault בגישה הראשונה אליו. לכן, יתרחשו `1024` Page Faults.\n*   לאחר סיום הלולאה הפנימית עבור `j=0`, כל 1024 הדפים של המערך (`P0` עד `P1023`) נמצאים כעת בזיכרון הפיזי.\n*   עבור כל איטרציה עוקבת של הלולאה החיצונית (`j=1` עד `j=1023`), הלולאה הפנימית ניגשת שוב לאותם 1024 דפים (`P0` עד `P1023`). מכיוון שכל הדפים כבר נמצאים בזיכרון הפיזי, לא יתרחשו Page Faults נוספים.\n*   **סה\"כ Page Faults:** 1024.\n\n**2. מספר TLB Misses כולל:**\n*   גודל ה-TLB הוא 4 כניסות, ומדיניות ההחלפה היא LRU.\n*   הלולאה הפנימית ניגשת ל-1024 דפים שונים (`P0`, `P1`, ..., `P1023`) באופן סדרתי.\n*   בכל איטרציה של הלולאה הפנימית (עבור `j` קבוע):\n    *   `i=0`: גישה לדף `P0`. ה-TLB ריק (או מכיל כניסות לא רלוונטיות מהאיטרציה הקודמת של `j`). TLB Miss. `P0` מתווסף ל-TLB.\n    *   `i=1`: גישה לדף `P1`. TLB Miss. `P1` מתווסף ל-TLB.\n    *   `i=2`: גישה לדף `P2`. TLB Miss. `P2` מתווסף ל-TLB.\n    *   `i=3`: גישה לדף `P3`. TLB Miss. `P3` מתווסף ל-TLB. כעת ה-TLB מלא: `{P0, P1, P2, P3}` (בסדר שימוש: `P3` הכי חדש, `P0` הכי ישן).\n    *   `i=4`: גישה לדף `P4`. TLB Miss. ה-TLB מלא, `P0` הוא ה-LRU. `P0` מוחלף ב-`P4`. ה-TLB: `{P1, P2, P3, P4}` (בסדר שימוש: `P4` הכי חדש, `P1` הכי ישן).\n    *   `i=5`: גישה לדף `P5`. TLB Miss. `P1` הוא ה-LRU. `P1` מוחלף ב-`P5`. ה-TLB: `{P2, P3, P4, P5}`.\n*   דפוס זה ממשיך: בכל פעם שניגשים לדף חדש (`Pi`), הוא גורם ל-TLB Miss ומחליף את הדף שהיה הכי פחות בשימוש מבין הדפים שהיו ב-TLB. מכיוון שיש לנו 1024 דפים שונים ואנחנו ניגשים אליהם באופן סדרתי, וגודל ה-TLB הוא רק 4, כל גישה לדף תהיה TLB Miss.\n*   לכן, עבור כל איטרציה של הלולאה הפנימית (1024 גישות), יתרחשו 1024 TLB Misses.\n*   הלולאה החיצונית רצה 1024 פעמים (עבור `j` מ-0 עד 1023).\n*   **סה\"כ TLB Misses:** `1024 (ROWS) * 1024 (COLS) = 1,048,576`."}, "difficulty_estimation": "Hard", "_source_file": "0641__Paging__CodeAnalysis__Hard.json", "_topic_hint": "Paging", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:18:49", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Paging", "Virtual Memory", "Memory Management", "Page Faults", "TLB"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם מנגנון Paging דו-שלבי. גודל כתובת וירטואלית הוא 32 סיביות, וגודל דף הוא 4KB. טבלת הדפים מחולקת באופן הבא: 10 סיביות לאינדקס טבלת הדפים ברמה הראשונה (Page Directory Index - PDI), 10 סיביות לאינדקס טבלת הדפים ברמה השנייה (Page Table Index - PTI), ו-12 סיביות ל-Offset בתוך הדף.\n\nנתונים מצבי הרישומים הבאים:\n*   **PDBR (Page Directory Base Register)**: מכיל את הכתובת הפיזית ההתחלתית של טבלת הדפים ברמה הראשונה (Page Directory). נניח PDBR = `0x10000000`.\n*   **TLB (Translation Lookaside Buffer)**: ריק בתחילת הריצה.\n\nנתונות כניסות ספציפיות בטבלאות הדפים (נניח שגודל כניסה בטבלה הוא 4 בתים):\n*   **Page Directory Entry (PDE) בכתובת פיזית `0x10000040`**: (מתאים ל-PDI = 16)\n    *   `Valid = 1`\n    *   `Read/Write = 1`\n    *   `PFN (Physical Frame Number)` מצביע על הכתובת הפיזית ההתחלתית של טבלת הדפים ברמה השנייה: `0x20000000`.\n*   **Page Table Entry (PTE) בכתובת פיזית `0x20000080`**: (מתאים ל-PTI = 32)\n    *   `Valid = 1`\n    *   `Read/Write = 0` (קריאה בלבד)\n    *   `PFN` מצביע על הכתובת הפיזית ההתחלתית של דף הנתונים: `0x30000000`.\n\nנתונה התוכנית הבאה שמנסה לכתוב לכתובת וירטואלית מסוימת:\n", "code_snippet": "#include <stdio.h>\n#include <stdint.h>\n\nint main() {\n    uint32_t *ptr = (uint32_t *)0x00402020; // Attempt to write to virtual address 0x00402020\n    *ptr = 0xDEADBEEF;\n    printf(\"Write successful, value: 0x%X\\n\", *ptr);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "מהי הכתובת הפיזית אליה מנסה התוכנית לכתוב? פרטו את שלבי התרגום.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "האם תתרחש שגיאת דף (Page Fault) במהלך הגישה לכתובת זו? אם כן, מאיזה סוג (לדוגמה: Invalid Page, Permission Violation)? הסבירו מדוע.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "כמה גישות זיכרון (Memory Accesses) בסך הכל יבוצעו על ידי חומרת ה-MMU כדי לתרגם את הכתובת הווירטואלית ולבצע את פעולת הכתיבה (כולל גישה לנתונים עצמם), בהנחה שה-TLB היה ריק בהתחלה? פרטו את הגישות.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\nנפרק את הכתובת הווירטואלית `0x00402020`:\n*   גודל דף: 4KB = 2^12 בתים. לכן ה-Offset הוא 12 סיביות.\n*   כתובת וירטואלית 32 סיביות: PDI (10 סיביות) | PTI (10 סיביות) | Offset (12 סיביות).\n\n`0x00402020` בבינארית: `0000 0000 0100 0000 0010 0000 0010 0000`\n*   **PDI (סיביות 31-22)**: `0000 0100 00` = `0x10` (16 עשרוני)\n*   **PTI (סיביות 21-12)**: `0000 1000 00` = `0x20` (32 עשרוני)\n*   **Offset (סיביות 11-0)**: `0000 0010 0000` = `0x020` (32 עשרוני)\n\n**א. הכתובת הפיזית ושלבי התרגום:**\n1.  **חישוב כתובת ה-PDE:** ה-PDBR מכיל את הבסיס של Page Directory: `0x10000000`. כיוון שה-PDI הוא `0x10` (16), וגודל כניסת PDE הוא 4 בתים, הכתובת הפיזית של ה-PDE היא:\n    `0x10000000 + (0x10 * 4) = 0x10000000 + 0x40 = 0x10000040`.\n2.  **קריאת ה-PDE:** ה-PDE בכתובת `0x10000040` מכיל: `Valid = 1`, `Read/Write = 1`, ו-PFN המצביע על `0x20000000` (הבסיס של טבלת הדפים ברמה השנייה).\n3.  **חישוב כתובת ה-PTE:** בסיס טבלת הדפים ברמה השנייה הוא `0x20000000`. כיוון שה-PTI הוא `0x20` (32), וגודל כניסת PTE הוא 4 בתים, הכתובת הפיזית של ה-PTE היא:\n    `0x20000000 + (0x20 * 4) = 0x20000000 + 0x80 = 0x20000080`.\n4.  **קריאת ה-PTE:** ה-PTE בכתובת `0x20000080` מכיל: `Valid = 1`, `Read/Write = 0` (קריאה בלבד), ו-PFN המצביע על `0x30000000` (הבסיס של דף הנתונים).\n5.  **חישוב הכתובת הפיזית הסופית:** בסיס דף הנתונים הוא `0x30000000`. ה-Offset הוא `0x020`. לכן, הכתובת הפיזית הסופית היא:\n    `0x30000000 + 0x020 = 0x30000020`.\n\n**ב. האם תתרחש שגיאת דף?**\nכן, תתרחש שגיאת דף (Page Fault) מסוג **Permission Violation**.\nהתוכנית מנסה לבצע פעולת כתיבה (`*ptr = 0xDEADBEEF;`) לכתובת הווירטואלית `0x00402020`. לאחר תרגום הכתובת, ה-PTE המתאים (בכתובת הפיזית `0x20000080`) מציין `Read/Write = 0`, כלומר, לדף הנתונים יש הרשאת קריאה בלבד. ניסיון כתיבה לדף עם הרשאת קריאה בלבד מפר את ההרשאות וגורם לשגיאת הגנה (Permission Violation).\n\n**ג. מספר גישות זיכרון:**\nבהנחה שה-TLB ריק בתחילת הריצה, יבוצעו 3 גישות זיכרון:\n1.  **גישה ל-PDE:** ה-MMU ניגש לזיכרון הפיזי בכתובת `0x10000040` כדי לקרוא את ה-PDE. (גישה 1)\n2.  **גישה ל-PTE:** ה-MMU ניגש לזיכרון הפיזי בכתובת `0x20000080` כדי לקרוא את ה-PTE. (גישה 2)\n3.  **גישה לנתונים:** ה-MMU מנסה לגשת לזיכרון הפיזי בכתובת `0x30000020` כדי לבצע את פעולת הכתיבה. גישה זו היא חלק מתהליך התרגום והגישה לזיכרון, גם אם היא נכשלת עקב שגיאת הרשאה. (גישה 3)\n\nלאחר שתי הגישות הראשונות, ה-TLB יתעדכן עם כניסות עבור ה-PDE וה-PTE, כך שגישות עתידיות לאותה כתובת וירטואלית (או כתובות באותו דף/בטווח ה-PDI/PTI המכוסה) יהיו מהירות יותר (TLB hit)."}, "difficulty_estimation": "Hard", "_source_file": "0642__Paging__CodeAnalysis__Hard.json", "_topic_hint": "Paging", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:19:30", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Paging", "Virtual Memory", "TLB", "Page Faults", "Memory Protection"], "content": {"text": "נתונה מערכת הפעלה המנהלת זיכרון וירטואלי באמצעות מנגנון Paging דו-שכבתי.\nגודל עמוד: 4KB (2^12 בתים).\nמרחב כתובות וירטואליות ופיזיות: 32 ביט.\n\n**מבנה טבלת העמודים:**\nכתובת וירטואלית (VA) מחולקת לשלושה חלקים:\n*   אינדקס ספריות עמודים (PDI): ביטים [31-22] (10 ביטים)\n*   אינדקס טבלת עמודים (PTI): ביטים [21-12] (10 ביטים)\n*   היסט בתוך העמוד (Offset): ביטים [11-0] (12 ביטים)\n\n**TLB:**\nה-TLB מכיל 4 כניסות, הוא fully associative, ומשתמש במדיניות החלפה LRU (Least Recently Used). בתחילת הריצה ה-TLB ריק.\n\n**פורמט כניסת טבלת עמודים (PTE) / כניסת ספריית עמודים (PDE):**\n*   ביט 0: Present (P) - 1 אם העמוד/טבלה נמצא בזיכרון הפיזי, 0 אחרת.\n*   ביט 1: Read/Write (R/W) - 1 עבור קריאה/כתיבה, 0 עבור קריאה בלבד.\n*   ביטים [31-12]: Physical Frame Number (PFN) או כתובת פיזית של טבלת העמודים הבאה (מיושר ל-4KB).\n\n**מצב התחלתי של טבלאות העמודים הרלוונטיות:**\nנניח שכתובת ספריית העמודים (Page Directory) היא `0x100000`.\nנניח שכתובת טבלת העמודים (Page Table) עבור PDI=1 היא `0x110000`.\n\n*   **כניסת ספריית עמודים (PDE) עבור PDI = 1:**\n    *   כתובת פיזית של ה-PDE: `0x100004` (בהנחה שגודל PDE הוא 4 בתים)\n    *   ערך ה-PDE: `0x110003` (מצביע לטבלת עמודים ב-`0x110000`, Present=1, R/W=1)\n\n*   **כניסות טבלת העמודים (PTEs) בטבלת העמודים ב-`0x110000`:**\n    *   **PTE עבור PTI = 0 (VA `0x00400000` - `0x00400FFF`):** `0x200003` (PFN `0x200`, Present=1, R/W=1)\n    *   **PTE עבור PTI = 10 (VA `0x0040A000` - `0x0040AFFF`):** `0x20A001` (PFN `0x20A`, Present=1, R/W=0 - **קריאה בלבד!**)\n    *   **PTE עבור PTI = 100 (VA `0x00464000` - `0x00464FFF`):** `0x00000000` (Present=0 - **לא קיים בזיכרון!**)\n    *   כל שאר כניסות ה-PTE בטווח PDI=1 שאינן מוזכרות במפורש נניח שהן Present=1, R/W=1, עם PFNים עוקבים (לדוגמה, PTI `k` ממופה ל-PFN `0x200 + k`).\n\n**טיפול בכשלי עמוד (Page Faults):**\n*   אם ביט Present הוא 0 (P=0): מתרחש Page Fault מסוג \"Not Present\". מערכת ההפעלה מקצה מסגרת פיזית חדשה, טוענת את העמוד לזיכרון, מעדכנת את ה-PTE ל-`new_PFN | 0x3` (P=1, R/W=1), ומאתחלת מחדש את הפקודה שגרמה לכשל.\n*   אם ביט Present הוא 1 (P=1) אך גישת הכתיבה אינה מותרת (R/W=0): מתרחש Page Fault מסוג \"Protection Fault\". מערכת ההפעלה מפסיקה את התוכנית.\n\n**התוכנית הבאה:**\nנתונה התוכנית הבאה בשפת C. נניח ש-`sizeof(int) = 4` בתים.\nהתוכנית ניגשת למערך `arr` שמתחיל בכתובת וירטואלית `0x00400000`.\n", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define PAGE_SIZE 4096 // 4KB\n#define INT_PER_PAGE (PAGE_SIZE / sizeof(int)) // 1024 integers per page\n\nint main() {\n    int* arr = (int*)0x00400000;\n\n    // Access Pattern 1: Access a R/W page (PTI=0)\n    arr[0] = 10; // Write access\n\n    // Access Pattern 2: Attempt to write to a Read-Only page (PTI=10)\n    arr[INT_PER_PAGE * 10] = 20; // Write access\n\n    // Access Pattern 3: Attempt to read from a Not-Present page (PTI=100)\n    int val = arr[INT_PER_PAGE * 100]; // Read access\n\n    // Access Pattern 4: Sequential access to fill TLB and demonstrate LRU\n    for (int i = 0; i < 6; ++i) {\n        arr[INT_PER_PAGE * i + 1] = i; // Write access to second element of each page\n    }\n\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "101.1", "text": "נתחו את ריצת התוכנית. כמה TLB Hits, TLB Misses, Page Faults (Not Present) ו-Page Faults (Protection) יתרחשו עד שהתוכנית תסיים את ריצתה (או תופסק)?\nציינו את המצב הסופי של המונים הללו.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "**ניתוח מפורט של ריצת התוכנית:**\n\n**מצב התחלתי:**\nTLB: ריק (קיבולת 4 כניסות, מדיניות LRU)\nTLB Hits: 0\nTLB Misses: 0\nPage Faults (Not Present): 0\nPage Faults (Protection): 0\nהתוכנית הופסקה: לא\n\n**דפוס גישה 1: `arr[0] = 10;` (VA `0x00400000`)**\n1.  **VA `0x00400000`**:\n    *   הכתובת מתפרשת כ-PDI=1, PTI=0, Offset=0.\n    *   **TLB Miss** (ה-TLB ריק).\n    *   **Page Table Walk**:\n        *   מערכת ההפעלה ניגשת ל-PDE עבור PDI=1 (בכתובת פיזית `0x100004`). ערך ה-PDE הוא `0x110003` (Present=1, R/W=1). זהו זיכרון פיזי שמכיל את טבלת העמודים הבאה.\n        *   מערכת ההפעלה ניגשת ל-PTE עבור PTI=0 (בכתובת פיזית `0x110000`). ערך ה-PTE הוא `0x200003` (Present=1, R/W=1). ה-PFN הוא `0x200`.\n        *   סוג הגישה הוא כתיבה (write). בדיקת הרשאות: R/W=1, לכן הגישה מותרת.\n    *   הוספה ל-TLB: `(0x00400000, 0x200000)`. כעת זו הכניסה הכי לאחרונה בשימוש (LRU=0).\n    *   **TLB Misses: 1**.\n\n**מצב מצטבר לאחר דפוס גישה 1:**\nTLB Hits: 0\nTLB Misses: 1\nPage Faults (Not Present): 0\nPage Faults (Protection): 0\nTLB: `[ (0x00400000, 0x200000, LRU=0) ]` (כאשר 0 מציין הכי לאחרונה בשימוש)\n\n**דפוס גישה 2: `arr[INT_PER_PAGE * 10] = 20;` (VA `0x0040A000`)**\n`INT_PER_PAGE * 10` מצביע לתחילת עמוד מספר 10 (VA `0x0040A000`).\n1.  **VA `0x0040A000`**:\n    *   הכתובת מתפרשת כ-PDI=1, PTI=10, Offset=0.\n    *   **TLB Miss** (הכניסה אינה נמצאת ב-TLB).\n    *   **Page Table Walk**:\n        *   מערכת ההפעלה ניגשת ל-PDE עבור PDI=1 (בכתובת פיזית `0x100004`). ערך ה-PDE הוא `0x110003` (Present=1, R/W=1).\n        *   מערכת ההפעלה ניגשת ל-PTE עבור PTI=10 (בכתובת פיזית `0x110028`). ערך ה-PTE הוא `0x20A001` (Present=1, R/W=0). ה-PFN הוא `0x20A`.\n        *   סוג הגישה הוא כתיבה (write). בדיקת הרשאות: R/W=0 (קריאה בלבד). הגישה אינה מותרת.\n    *   **Protection Fault!** התוכנית מנסה לכתוב לעמוד המוגדר כקריאה בלבד.\n    *   מערכת ההפעלה מפסיקה את התוכנית.\n    *   **Page Faults (Protection): 1**.\n    *   **TLB Misses: 1** (סה\"כ 2).\n\n**מצב סופי של המונים כאשר התוכנית מופסקת:**\n*   **TLB Hits: 0**\n*   **TLB Misses: 2**\n*   **Page Faults (Not Present): 0**\n*   **Page Faults (Protection): 1**\n*   **התוכנית הופסקה: כן**\n\n**הערה:** דפוסי הגישה 3 ו-4 לא יבוצעו כלל, כיוון שהתוכנית מופסקת מיד לאחר כשל ההגנה בדפוס גישה 2."}, "difficulty_estimation": "Hard", "_source_file": "0643__Paging__CodeAnalysis__Hard.json", "_topic_hint": "Paging", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:20:53", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Paging", "Memory Management", "TLB", "Page Faults"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם מנגנון Paging דו-שכבתי. הפרטים הטכניים של המערכת הם כדלקמן:\n-   כתובות וירטואליות: 32 סיביות.\n-   גודל עמוד (Page Size): 4KB (4096 בתים).\n-   טבלת עמודים דו-שכבתית: 10 סיביות למצביע לטבלת עמודים ברמה הראשונה (Page Directory), 10 סיביות למצביע לטבלת עמודים ברמה השנייה (Page Table), ו-12 סיביות לאופסט בתוך העמוד. (כלומר, מבנה כתובת וירטואלית: P1[10] | P2[10] | Offset[12]).\n-   חיץ תרגום כתובות (TLB): מכיל 4 רשומות (entries), והוא אסוציאטיבי מלא (fully associative) עם מנגנון החלפה LRU (Least Recently Used).\n-   מצב התחלתי: ה-TLB ריק לחלוטין. כל עמודי הזיכרון של המערך 'data' נמצאים על הדיסק (לא בזיכרון פיזי, כלומר סיבית ה-Valid ב-PTE שלהם היא 0).\n\nקוד ה-C הבא מופעל על מערכת זו. המערך `data` מיושר לגבול עמוד (page-aligned) וכתובתו הווירטואלית מתחילה ב-0 לצורך פשטות הניתוח.\n\nיש לחשב את המספר הכולל של החטאות TLB (TLB misses) ואת המספר הכולל של תקלות עמוד (page faults) שיתרחשו במהלך כל ריצת הפונקציה `complex_access_pattern`.\n\nהנחות:\n-   כל גישה לזיכרון (קריאה או כתיבה) דורשת תרגום כתובת. אם הכתובת נמצאת ב-TLB, זהו TLB hit. אחרת, זהו TLB miss.\n-   במקרה של TLB miss, מתבצעת הליכה בטבלת העמודים (page table walk) כדי למצוא את ה-PTE המתאים. אם סיבית ה-Valid ב-PTE היא 0, מתרחשת תקלת עמוד (page fault). לאחר מכן, העמוד נטען לזיכרון הפיזי, ה-PTE מתעדכן, והרשומה מוכנסת ל-TLB. (יש לזכור כי במקרה של תקלת עמוד, גם לאחר טעינת העמוד, הרשומה עדיין צריכה להיכנס ל-TLB).\n-   אם סיבית ה-Valid ב-PTE היא 1 (העמוד נמצא בזיכרון פיזי), הרשומה מוכנסת ל-TLB (אם אין מקום, מופעל מנגנון LRU), ואין תקלת עמוד.\n-   כל פעולה על המערך `data` (כלומר, כל השמה בתוך הלולאות) נחשבת לגישה אחת לזיכרון לצורך חישוב TLB misses ו-page faults.\n", "code_snippet": "#include <stdio.h>\n\n#define PAGE_SIZE_BYTES 4096\n#define INT_PER_PAGE (PAGE_SIZE_BYTES / sizeof(int)) // 1024 integers per page\n#define NUM_PAGES_IN_ARRAY 256 // Total 256 pages for the array (1MB)\n#define ARRAY_SIZE (NUM_PAGES_IN_ARRAY * INT_PER_PAGE) // 256 * 1024 = 262144 integers\n\nint data[ARRAY_SIZE]; // Assume this array starts at a page-aligned virtual address\n                       // For simplicity, assume its base virtual address is 0.\n\nvoid complex_access_pattern() {\n    // Phase 1: Access the first element of every 4th page\n    // Pages accessed: 0, 4, 8, ..., 252 (total 64 distinct pages)\n    for (int i = 0; i < NUM_PAGES_IN_ARRAY; i += 4) {\n        data[i * INT_PER_PAGE] = i; // Access to page 'i'\n    }\n\n    // Phase 2: Access the first element of every 2nd page (starting from page 0)\n    // Pages accessed: 0, 2, 4, 6, 8, ..., 254 (total 128 distinct pages)\n    for (int i = 0; i < NUM_PAGES_IN_ARRAY; i += 2) {\n        data[i * INT_PER_PAGE] = i; // Access to page 'i'\n    }\n\n    // Phase 3: Access the first element of every page\n    // Pages accessed: 0, 1, 2, 3, 4, ..., 255 (total 256 distinct pages)\n    for (int i = 0; i < NUM_PAGES_IN_ARRAY; ++i) {\n        data[i * INT_PER_PAGE] = i; // Access to page 'i'\n    }\n}\n\nint main() {\n    complex_access_pattern();\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ניתוח הפתרון:\n\nנתונים:\n-   גודל עמוד: 4KB (2^12 בתים).\n-   TLB: מכיל 4 רשומות, אסוציאטיבי מלא, מנגנון החלפה LRU.\n-   המערך `data` מכיל 256 עמודים (0 עד 255).\n-   TLB ריק בתחילת הפונקציה `complex_access_pattern`.\n-   כל עמודי המערך `data` אינם בזיכרון פיזי בתחילה (Valid bit = 0).\n\nנחשב את החטאות ה-TLB ואת תקלות העמוד עבור כל שלב בנפרד:\n\n**שלב 1: `for (int i = 0; i < NUM_PAGES_IN_ARRAY; i += 4)`**\n-   גישות לעמודים: 0, 4, 8, 12, ..., 252.\n-   מספר גישות כולל: `256 / 4 = 64` גישות.\n-   כל גישה היא לעמוד שלא נגיש אליו קודם בשלב זה (או בכלל, מכיוון שה-TLB היה ריק והעמודים לא היו בזיכרון פיזי). לכן, כל גישה תגרום להחטאת TLB.\n-   **TLB Misses**: 64 (כל 64 הגישות הן החטאות TLB).\n-   **Page Faults**: 64 (כל העמודים האלה נגישים בפעם הראשונה, ולכן יגרמו לתקלת עמוד ולטעינה לזיכרון פיזי).\n-   מצב TLB בסיום שלב 1: ה-TLB יכיל את 4 העמודים האחרונים שנגישו אליהם: 252, 248, 244, 240 (בסדר LRU: 252 הוא ה-MRU, 240 הוא ה-LRU).\n\n**שלב 2: `for (int i = 0; i < NUM_PAGES_IN_ARRAY; i += 2)`**\n-   גישות לעמודים: 0, 2, 4, 6, 8, ..., 254.\n-   מספר גישות כולל: `256 / 2 = 128` גישות.\n-   ננתח את הגישות ל-TLB:\n    -   ה-TLB מכיל את העמודים {252, 248, 244, 240} מסוף שלב 1. אף אחד מהעמודים הראשונים שנגישים אליהם בשלב 2 (0, 2, 4, 6, 8...) לא נמצא ב-TLB. למעשה, מאחר שאנו ניגשים ל-128 עמודים שונים, וגודל ה-TLB הוא 4 בלבד, כל גישה תגרום להחטאת TLB. גם עמודים שנגישו אליהם בשלב 1 (כגון 0, 4, 8) לא יהיו ב-TLB כי הם כבר נפלטו. לדוגמה:\n        -   גישה לעמוד 0: החטאה. 240 (LRU) נפלט. TLB: {0, 252, 248, 244}.\n        -   גישה לעמוד 2: החטאה. 244 (LRU) נפלט. TLB: {2, 0, 252, 248}.\n        -   גישה לעמוד 4: החטאה. 248 (LRU) נפלט. TLB: {4, 2, 0, 252}.\n        -   גישה לעמוד 6: החטאה. 252 (LRU) נפלט. TLB: {6, 4, 2, 0}.\n        -   גישה לעמוד 8: החטאה. 0 (LRU) נפלט. TLB: {8, 6, 4, 2}.\n    -   כל 128 הגישות הן החטאות TLB.\n-   **TLB Misses**: 128.\n-   **Page Faults**: נבדוק אילו עמודים נגישים לראשונה:\n    -   עמודים שנגישו אליהם בשלב 1: 0, 4, 8, ..., 252 (64 עמודים). אלה כבר בזיכרון פיזי, ולא יגרמו לתקלת עמוד נוספת.\n    -   עמודים חדשים שנגישים אליהם לראשונה בשלב 2: 2, 6, 10, ..., 254 (64 עמודים). אלה יגרמו לתקלות עמוד.\n    -   סה\"כ תקלות עמוד בשלב 2: 64.\n-   מצב TLB בסיום שלב 2: יכיל את 4 העמודים האחרונים שנגישו אליהם: 254, 252, 250, 248 (בסדר LRU).\n\n**שלב 3: `for (int i = 0; i < NUM_PAGES_IN_ARRAY; ++i)`**\n-   גישות לעמודים: 0, 1, 2, 3, 4, ..., 255.\n-   מספר גישות כולל: 256 גישות.\n-   ננתח את הגישות ל-TLB:\n    -   ה-TLB מכיל את העמודים {254, 252, 250, 248} מסוף שלב 2. הגישה הראשונה לעמוד 0 תהיה החטאה. הגישה לעמוד 1 תהיה החטאה. וכן הלאה. מכיוון שאנו ניגשים לעמודים ברצף (0, 1, 2, 3, 4, ...), וגודל ה-TLB הוא 4, כל גישה החל מהגישה הרביעית תפלוט את העמוד שהוכנס לפני 4 גישות (על פי LRU). לדוגמה:\n        -   נגישה לעמוד 0: החטאה (248 נפלט). TLB={0, 254, 252, 250}.\n        -   נגישה לעמוד 1: החטאה (250 נפלט). TLB={1, 0, 254, 252}.\n        -   נגישה לעמוד 2: החטאה (252 נפלט). TLB={2, 1, 0, 254}.\n        -   נגישה לעמוד 3: החטאה (254 נפלט). TLB={3, 2, 1, 0}.\n        -   נגישה לעמוד 4: החטאה (0 נפלט). TLB={4, 3, 2, 1}.\n    -   כל 256 הגישות הן החטאות TLB.\n-   **TLB Misses**: 256.\n-   **Page Faults**: נבדוק אילו עמודים נגישים לראשונה:\n    -   עמודים שנגישו אליהם בשלבים קודמים (0, 2, 4, ..., 254) כבר בזיכרון פיזי.\n    -   עמודים חדשים שנגישים אליהם לראשונה בשלב 3: 1, 3, 5, ..., 255 (128 עמודים). אלה יגרמו לתקלות עמוד.\n    -   סה\"כ תקלות עמוד בשלב 3: 128.\n\n**סיכום כולל:**\n-   **סה\"כ TLB Misses**: 64 (שלב 1) + 128 (שלב 2) + 256 (שלב 3) = **448**\n-   **סה\"כ Page Faults**: 64 (שלב 1) + 64 (שלב 2) + 128 (שלב 3) = **256** (כל 256 העמודים של המערך נטענו לזיכרון פיזי בסופו של דבר, מה שצפוי).\n"}, "difficulty_estimation": "Hard", "_source_file": "0644__Paging__CodeAnalysis__Hard.json", "_topic_hint": "Paging", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:21:41", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Paging", "TLB", "Memory Management", "Performance"], "content": {"text": "נתונה התוכנית הבאה ב-C המאתחלת מערך דו-ממדי גדול ומבצעת עליו שתי לולאות גישה שונות: אחת בסדר שורות ואחת בסדר עמודות. יש להתייחס למערכת בעלת המאפיינים הבאים:\n*   גודל עמוד (Page Size): 4KB\n*   גודל טיפוס `int`: 4 בתים\n*   TLB: מכיל 64 כניסות, אסוציאטיבי מלא (Fully Associative), ומשתמש במדיניות החלפה LRU.\n*   הניחו שה-TLB ריק בתחילה ושאף עמוד אינו טעון לזיכרון הפיזי לפני תחילת ביצוע הלולאות.\n*   הניחו שאין תהליכים אחרים רצים במערכת ושכל המערך מוקצה בזיכרון וירטואלי רציף.\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n\n#define DIM 1024\n#define ARRAY_SIZE (DIM * DIM) // 1024 * 1024 integers\n\nint main() {\n    int* arr = (int*)malloc(ARRAY_SIZE * sizeof(int));\n    if (arr == NULL) {\n        perror(\"malloc failed\");\n        return 1;\n    }\n\n    // Access pattern 1: Row-major\n    printf(\"Accessing row-major...\\n\");\n    for (int i = 0; i < DIM; ++i) {\n        for (int j = 0; j < DIM; ++j) {\n            arr[i * DIM + j] = i + j; // Write access\n        }\n    }\n\n    // Access pattern 2: Column-major\n    printf(\"Accessing column-major...\\n\");\n    for (int j = 0; j < DIM; ++j) {\n        for (int i = 0; i < DIM; ++i) {\n            volatile int temp = arr[i * DIM + j]; // Read access, use volatile to prevent optimization\n            // Dummy use to ensure access is not optimized away\n            if (temp < 0) { /* do nothing, just to use temp */ }\n        }\n    }\n\n    free(arr);\n    return 0;\n}\n```\n\nחשבו והסבירו עבור כל אחת מתבניות הגישה (סדר שורות וסדר עמודות):\n1.  כמה כשלי עמודים (Page Faults) יתרחשו?\n2.  כמה החמצות TLB (TLB Misses) יתרחשו?\n\nהסבירו את חישוביכם ונימוקיכם באופן מפורט.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ראשית, נחשב את גודל המערך הכולל ואת מספר העמודים הנדרשים:\n*   גודל המערך: `1024 * 1024 * sizeof(int) = 1024 * 1024 * 4 bytes = 4,194,304 bytes = 4MB`.\n*   גודל עמוד: `4KB = 4096 bytes`.\n*   מספר העמודים הנדרשים למערך כולו: `4MB / 4KB = 1024 עמודים`.\n*   מספר שלמים (int) בעמוד אחד: `4096 bytes / 4 bytes/int = 1024 שלמים`.\n*   מכיוון ש-`DIM = 1024`, כל שורה במערך מכילה `1024` שלמים, כלומר, כל שורה תופסת בדיוק עמוד אחד של זיכרון.\n\n**תבנית גישה 1: סדר שורות (Row-major)**\nהלולאה החיצונית עוברת על השורות (`i`), והפנימית על העמודות (`j`).\n`for (int i = 0; i < DIM; ++i)`\n  `for (int j = 0; j < DIM; ++j)`\n    `arr[i * DIM + j]`\n\n1.  **כשלי עמודים (Page Faults):**\n    *   בכל פעם שהלולאה החיצונית מתחילה איטרציה חדשה (עבור `i` חדש), היא ניגשת לשורה חדשה. מכיוון שכל שורה תופסת עמוד זיכרון שלם, ובהנחה שאף עמוד אינו טעון בתחילה, הגישה הראשונה לכל שורה (לדוגמה, `arr[i * DIM + 0]`) תגרום לכשל עמוד. העמוד כולו ייטען לזיכרון הפיזי.\n    *   הגישות הבאות באותה שורה (`arr[i * DIM + j]` עבור `j > 0`) יהיו כולן בתוך אותו עמוד שכבר נטען, ולכן לא יגרמו כשלי עמודים נוספים.\n    *   ישנן `DIM = 1024` שורות, ולכן יתרחשו `1024` כשלי עמודים בסך הכל (אחד לכל עמוד ייחודי במערך).\n\n2.  **החמצות TLB (TLB Misses):**\n    *   בדומה לכשלי העמודים, הגישה הראשונה לכל שורה חדשה (כלומר, לעמוד חדש) תגרום להחמצת TLB, שכן ה-TLB ריק בתחילה. לאחר מכן, הכתובת הווירטואלית של העמוד תתורגם, והכניסה המתאימה תתווסף ל-TLB.\n    *   כל הגישות הבאות בתוך אותה שורה (אותו עמוד) יהיו פגיעות TLB (TLB Hits), שכן הכניסה לעמוד זה כבר נמצאת ב-TLB.\n    *   ה-TLB מכיל 64 כניסות. אנו ניגשים ל-1024 עמודים ברצף, כאשר כל עמוד נגיש רק פעם אחת במהלך הגישה הראשונית. מכיוון שאנו לא חוזרים לעמודים קודמים לפני שנשלים את כל המערך, גודל ה-TLB לא משפיע על מספר ההחמצות הכולל במעבר יחיד זה. כל גישה לעמוד חדש תגרום להחמצה.\n    *   לכן, יתרחשו `1024` החמצות TLB בסך הכל (אחת לכל עמוד ייחודי במערך).\n\n**תבנית גישה 2: סדר עמודות (Column-major)**\nהלולאה החיצונית עוברת על העמודות (`j`), והפנימית על השורות (`i`).\n`for (int j = 0; j < DIM; ++j)`\n  `for (int i = 0; i < DIM; ++i)`\n    `arr[i * DIM + j]`\n\n1.  **כשלי עמודים (Page Faults):**\n    *   עבור `j` קבוע (כלומר, בעת מעבר על עמודה אחת), הלולאה הפנימית (`i`) ניגשת ל-`arr[0*DIM + j]`, `arr[1*DIM + j]`, `arr[2*DIM + j]`, וכן הלאה, עד `arr[1023*DIM + j]`.\n    *   ההבדל בין `arr[i*DIM + j]` לבין `arr[(i+1)*DIM + j]` הוא `DIM` שלמים, כלומר `1024 * 4 = 4096 bytes`. זהו בדיוק גודל של עמוד אחד.\n    *   משמעות הדבר היא שכל גישה בתוך הלולאה הפנימית (עבור `i` שונה) מתייחסת לעמוד זיכרון *שונה* לחלוטין. לדוגמה, `arr[0*DIM + j]` נמצא בעמוד 0 (בקיזוז `j`), `arr[1*DIM + j]` נמצא בעמוד 1 (בקיזוז `j`), וכן הלאה, עד `arr[1023*DIM + j]` שנמצא בעמוד 1023 (בקיזוז `j`).\n    *   במהלך הגישה לעמודה הראשונה (`j=0`), הלולאה הפנימית תגרום לגישה לכל 1024 העמודים (עמוד 0 עד עמוד 1023) בפעם הראשונה. כל אחת מ-1024 הגישות האלה תגרום לכשל עמוד, שכן העמודים אינם טעונים בתחילה. בסיום מעבר על העמודה הראשונה, כל 1024 העמודים של המערך יהיו טעונים בזיכרון הפיזי.\n    *   במהלך הגישות לעמודות הבאות (`j=1` עד `j=1023`), כל העמודים כבר נמצאים בזיכרון הפיזי. לכן, לא יתרחשו כשלי עמודים נוספים.\n    *   לכן, יתרחשו `1024` כשלי עמודים בסך הכל (אחד לכל עמוד ייחודי במערך, במהלך הגישה הראשונה אליו).\n\n2.  **החמצות TLB (TLB Misses):**\n    *   כאמור, עבור `j` קבוע, הלולאה הפנימית ניגשת ל-1024 עמודים *שונים* ברצף.\n    *   ה-TLB מכיל רק 64 כניסות. כאשר אנו ניגשים ל-64 העמודים הראשונים, ה-TLB מתמלא בהם (כל גישה היא החמצה ומוסיפה כניסה).\n    *   כאשר אנו מנסים לגשת לעמוד ה-65 (עבור `i=64`), ה-TLB כבר מלא. מדיניות ה-LRU תגרום לפינוי הכניסה של העמוד שהיה בשימוש הכי פחות לאחרונה (במקרה זה, העמוד הראשון שנגשנו אליו, עמוד 0). גישה זו תהיה החמצת TLB.\n    *   דפוס זה יחזור על עצמו עבור כל אחת מ-1024 הגישות בלולאה הפנימית: כל גישה לעמוד חדש תגרום להחמצת TLB, מכיוון שה-TLB קטן מכדי להכיל את כל 1024 העמודים שנגישים ברצף כה מהיר.\n    *   לכן, עבור כל איטרציה של הלולאה החיצונית (עבור כל עמודה `j`), יתרחשו `1024` החמצות TLB.\n    *   מכיוון שיש `DIM = 1024` עמודות, מספר ההחמצות הכולל יהיה: `1024 (עמודות) * 1024 (החמצות לעמודה) = 1,048,576 החמצות TLB`."}, "difficulty_estimation": "Hard", "_source_file": "0645__Paging__CodeAnalysis__Hard.json", "_topic_hint": "Paging", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:22:17", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Paging", "Virtual Memory", "TLB", "Page Faults", "Memory Access Time"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם מנגנון Paging. להלן הפרטים הטכניים של המערכת:\n*   גודל עמוד: 4KB (קילו-בתים).\n*   TLB (Translation Lookaside Buffer): מכיל 64 כניסות, בשיטת אסוציאטיבית מלאה (Fully Associative).\n*   מדיניות החלפה ב-TLB: LRU (Least Recently Used).\n*   זמן גישה לזיכרון פיזי: 100ns.\n*   זמן בדיקת TLB: 10ns.\n*   מבנה טבלת עמודים: שני סבבים (Two-level page table). כל סבב דורש גישת זיכרון אחת.\n*   זמן טיפול ב-Page Fault (כולל קריאה מהדיסק): 10ms (מילי-שניות).\n*   מרחב כתובות וירטואלי ופיזי: 32 סיביות.\n\nנתונה התוכנית הבאה בשפת C/C++, המאתחלת מטריצה גדולה. יש להניח שהזיכרון המוקצה למטריצה אינו נמצא בזיכרון הפיזי בתחילת ריצת התוכנית (כלומר, כל גישה ראשונית לעמוד חדש תגרום ל-Page Fault). יש להתייחס רק לגישות הזיכרון הנובעות מגישה לאיברי המטריצה.", "code_snippet": "#define ROWS 2048\n#define COLS 2048\n\nint matrix[ROWS][COLS]; // Global array, allocated in BSS/data segment\n\nvoid initialize_matrix() {\n    for (int i = 0; i < ROWS; ++i) {\n        for (int j = 0; j < COLS; ++j) {\n            matrix[i][j] = i * COLS + j; // Memory access here\n        }\n    }\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "כמה Page Faults סך הכל יתרחשו במהלך ריצת הפונקציה initialize_matrix? נמקו.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "כמה TLB Misses סך הכל יתרחשו במהלך ריצת הפונקציה initialize_matrix? נמקו.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "מהו זמן הגישה האפקטיבי הממוצע (Effective Access Time - EAT) לגישת זיכרון יחידה (עבור גישות לאיברי המטריצה בלבד) במהלך ריצת הפונקציה initialize_matrix? הציגו את החישוב המלא.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\n**סעיף 1.1: חישוב Page Faults**\nגודל המטריצה: `2048 שורות * 2048 עמודות * sizeof(int)`.\nכאשר `sizeof(int) = 4` בתים:\n`2048 * 2048 * 4 = 2^11 * 2^11 * 2^2 = 2^24` בתים = 16 מגה-בתים (MB).\nגודל עמוד: `4KB = 2^12` בתים.\nמספר העמודים הכולל שהמטריצה תופסת: `16MB / 4KB = 2^24 / 2^12 = 2^12 = 4096` עמודים.\nהגישה למטריצה בתוך הלולאות היא סדרתית (row-major), כלומר, `matrix[i][j]` ולאחר מכן `matrix[i][j+1]` תהיה בכתובת רציפה בזיכרון הווירטואלי.\nמכיוון שכל הזיכרון המוקצה למטריצה אינו נמצא בזיכרון הפיזי בתחילת הריצה (cold start), כל גישה ראשונה לעמוד חדש תגרום ל-Page Fault. הפונקציה `initialize_matrix` עוברת על כל איברי המטריצה, ולכן תגרום לגישה לכל `4096` העמודים הייחודיים.\nלפיכך, מספר ה-Page Faults הכולל יהיה: **4096**.\n\n**סעיף 1.2: חישוב TLB Misses**\nמספר גישות הזיכרון הכולל (לצורך גישה לאיברי המטריצה): `N_accesses = 2048 * 2048 = 4,194,304` גישות.\nמספר שלמים (integers) בעמוד: `4KB / sizeof(int) = 4096 / 4 = 1024` שלמים לעמוד.\nכל שורה במטריצה מכילה `2048` שלמים. לכן, כל שורה תתפרס על פני `2048 / 1024 = 2` עמודים.\nבכל איטרציה של הלולאה החיצונית (`for i`), אנו ניגשים לשני עמודים וירטואליים שונים.\nלדוגמה, עבור `i=0`, נגש לעמודים המכילים את `matrix[0][0]` עד `matrix[0][2047]`. אלו יהיו שני עמודים רציפים (נניח עמוד `P_0` ועמוד `P_1`).\n1.  הגישה הראשונה לעמוד `P_0` (לדוגמה `matrix[0][0]`) תגרום ל-TLB Miss, והכניסה עבור `P_0` תוכנס ל-TLB.\n2.  הגישות הבאות ל-`P_0` (עד `1023` פעמים) יהיו TLB Hits.\n3.  הגישה הראשונה לעמוד `P_1` (לדוגמה `matrix[0][1024]`) תגרום ל-TLB Miss, והכניסה עבור `P_1` תוכנס ל-TLB.\n4.  הגישות הבאות ל-`P_1` (עד `1023` פעמים) יהיו TLB Hits.\nלכן, עבור כל שורה (`i`), יתרחשו 2 TLB Misses (אחד לכל עמוד בשורה).\nסה\"כ שורות: `2048`.\nסה\"כ TLB Misses: `2048 שורות * 2 TLB Misses/שורה = 4096`.\n\nמכיוון שגודל ה-TLB הוא `64` כניסות, וכל שורה מכניסה שתי כניסות חדשות, ה-TLB יתמלא לאחר `32` שורות (`64 / 2`). בשלב זה, מדיניות ה-LRU תגרום לכניסות ישנות (מהשורות הראשונות) להיזרק מה-TLB כדי לפנות מקום לכניסות חדשות. מכיוון שמספר העמודים הכולל (`4096`) גדול בהרבה מגודל ה-TLB (`64`), וכניסות ה-TLB לא נשארות ב-TLB לאורך זמן רב מספיק כדי להיות נגישות שוב (הלולאה החיצונית לא חוזרת על עצמה), כל גישה ראשונית לעמוד חדש בכל איטרציה של `i` תגרום ל-TLB Miss.\nלכן, סך הכל יתרחשו: **4096 TLB Misses**.\n\n**סעיף 1.3: חישוב Effective Access Time (EAT)**\nזמן גישה אפקטיבי (EAT) מחושב לפי הנוסחה:\n`EAT = (N_tlb_hit * T_tlb_hit) + (N_tlb_miss * (T_pt_walk + T_pf_service)) / N_accesses`\nכאשר:\n*   מספר גישות זיכרון כולל (`N_accesses`) = `4,194,304` (מגישה לאיברי המטריצה)\n*   מספר TLB Misses (`N_tlb_miss`) = `4096` (מחישוב בסעיף 1.2)\n*   מספר TLB Hits (`N_tlb_hit`) = `N_accesses - N_tlb_miss = 4,194,304 - 4096 = 4,190,208`\n*   זמן TLB Hit (`T_tlb_hit`) = `10ns`\n*   זמן טיול בטבלת עמודים (`T_pt_walk`) = `2 סבבים * 100ns/סבב = 200ns` (כי טבלת עמודים היא דו-שכבתית וכל סבב דורש גישת זיכרון אחת).\n*   זמן טיפול ב-Page Fault (`T_pf_service`) = `10ms = 10,000,000ns`.\n(הערה: כל TLB Miss בפונקציה זו מוביל ל-Page Fault, כפי שחושב בסעיף א', מכיוון שכל גישה היא לעמוד חדש שאינו בזיכרון)\n\nנחשב תחילה את סך כל הזמן שלוקח לביצוע הפונקציה:\n`Total_Time = (N_tlb_hit * T_tlb_hit) + (N_tlb_miss * (T_pt_walk + T_pf_service))`\n`Total_Time = (4,190,208 * 10ns) + (4096 * (200ns + 10,000,000ns))`\n`Total_Time = 41,902,080ns + (4096 * 10,000,200ns)`\n`Total_Time = 41,902,080ns + 40,960,819,200ns`\n`Total_Time = 41,002,721,280ns`\n\nכעת נחשב את זמן הגישה האפקטיבי הממוצע (EAT):\n`EAT = Total_Time / N_accesses`\n`EAT = 41,002,721,280ns / 4,194,304`\n`EAT = 9775.875ns` (בערך)\n\nזמן הגישה האפקטיבי הממוצע הוא: **9775.875ns**."}, "difficulty_estimation": "Hard", "_source_file": "0646__Paging__CodeAnalysis__Hard.json", "_topic_hint": "Paging", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:23:03", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Paging", "Memory Management", "MMU"], "content": {"text": "נתונה תוכנית המדמה חלק ממערכת ניהול זיכרון (MMU) במערכת הפעלה, המשתמשת בזיכרון וירטואלי עם טבלאות עמודים דו-שכבתיות. המערכת פועלת עם כתובות וירטואליות בנות 32 סיביות וגודל עמוד של 4KB. כתובת וירטואלית מורכבת מ-10 סיביות עבור אינדקס טבלת העמודים העליונה (Page Directory Index - PDI), 10 סיביות עבור אינדקס טבלת העמודים השנייה (Page Table Index - PTI), ו-12 סיביות עבור ההיסט בתוך העמוד.\n\nהמבנים `PageTableEntry` ו-`PageDirectoryEntry` מוגדרים כך שה-20 סיביות העליונות מכילות את כתובת ה-Physical Frame Number (PFN) או כתובת טבלת העמודים הבאה (במקרה של PDE), ו-12 הסיביות התחתונות משמשות כדגלים (flags). הסיבית הנמוכה ביותר (bit 0) מייצגת את דגל ה-'Present' (P) - 1 אם העמוד/טבלת העמודים קיימת בזיכרון פיזי, 0 אחרת.\n\nהקוד הבא מנסה לממש פונקציה שמבצעת תרגום מכתובת וירטואלית לכתובת פיזית. הפונקציה מקבלת כתובת וירטואלית ואת תוכן אוגר CR3 (המכיל את הכתובת הפיזית של ה-Page Directory Base Register).\n\nיש לנתח את הקוד ולענות על השאלות הבאות:", "code_snippet": "#include <stdint.h>\n#include <stdio.h>\n\n// Define constants for address translation\n#define PAGE_OFFSET_BITS 12\n#define PTE_INDEX_BITS 10\n#define PDE_INDEX_BITS 10\n\n#define PAGE_SIZE (1 << PAGE_OFFSET_BITS) // 4KB\n\n// Masks for extracting parts of the virtual address\n#define PAGE_OFFSET_MASK ((1 << PAGE_OFFSET_BITS) - 1)\n#define PTE_INDEX_MASK (((1 << PTE_INDEX_BITS) - 1) << PAGE_OFFSET_BITS)\n#define PDE_INDEX_MASK (((1 << PDE_INDEX_BITS) - 1) << (PAGE_OFFSET_BITS + PTE_INDEX_BITS))\n\n// Bit for the 'Present' flag in PTE/PDE\n#define PRESENT_BIT 0x1\n\n// Simplified Page Table Entry structure\ntypedef uint32_t PageTableEntry; // PFN is bits 31-12, flags are 11-0\n\n// Function to simulate reading from physical memory (for page table walk)\n// In a real OS, this would access actual memory. Here, it's a placeholder.\nuint32_t read_physical_memory(uint32_t p_addr) {\n    // For this problem, assume it works and returns a valid 32-bit entry\n    // from the specified physical address, if the address is valid.\n    // In a real simulation, this might involve an array representing physical memory.\n    // For code analysis, we focus on the logic of translate_virtual_to_physical.\n    (void)p_addr; // Suppress unused parameter warning\n    // A real implementation might look like: return simulated_physical_memory[p_addr / sizeof(uint32_t)];\n    // For this problem, assume it returns the correct PageTableEntry/PageDirectoryEntry value.\n    return 0; // Placeholder return\n}\n\n// Function to translate a virtual address to a physical address\n// Returns -1 (or some error code) if a page fault occurs.\nuint32_t translate_virtual_to_physical(uint32_t virtual_address, uint32_t cr3_register) {\n    // 1. Extract PDI, PTI, and Offset\n    uint32_t pdi = (virtual_address & PDE_INDEX_MASK) >> (PAGE_OFFSET_BITS + PTE_INDEX_BITS);\n    uint32_t pti = (virtual_address & PTE_INDEX_MASK) >> PAGE_OFFSET_BITS;\n    uint32_t offset = virtual_address & PAGE_OFFSET_MASK;\n\n    // 2. Get Page Directory Entry (PDE)\n    uint32_t pde_address = (cr3_register & ~PAGE_OFFSET_MASK) + (pdi * sizeof(PageTableEntry));\n    PageTableEntry pde = read_physical_memory(pde_address);\n\n    // Check if PDE is present\n    if (!(pde & PRESENT_BIT)) {\n        return (uint32_t)-1; // Page fault: PDE not present\n    }\n\n    // 3. Get Page Table Entry (PTE)\n    // The physical address of the next page table is in the upper bits of the PDE\n    uint32_t pt_base_physical_address = pde & ~PAGE_OFFSET_MASK; // Extract PFN from PDE\n    uint32_t pte_address = pt_base_physical_address + (pti * sizeof(PageTableEntry));\n    PageTableEntry pte = read_physical_memory(pte_address);\n\n    // Check if PTE is present\n    if (!(pte & PRESENT_BIT)) {\n        return (uint32_t)-1; // Page fault: PTE not present\n    }\n\n    // 4. Calculate Physical Address\n    // The physical address of the page frame is in the upper bits of the PTE\n    uint32_t page_frame_physical_address = pte & ~PAGE_OFFSET_MASK; // Extract PFN from PTE\n    uint32_t physical_address = page_frame_physical_address + offset;\n\n    return physical_address;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "האם ישנה סיטואציה שבה הפונקציה `translate_virtual_to_physical` עלולה להחזיר תוצאה שגויה, או לגרום לבעיה במערכת (בהנחה ש-`read_physical_memory` היא פונקציה שקוראת מזיכרון פיזי אמיתי ועלולה לקרוס בגישה לכתובת לא חוקית), למרות שדגל ה-`Present` מוגדר? נמק והצע תיקון.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "הסבירו בקצרה כיצד שימוש ב-Translation Lookaside Buffer (TLB) משפיע על ביצועי תרגום הכתובות במערכת כזו, ומהן ההשלכות של 'פגיעת' (hit) ו'החטאת' (miss) ב-TLB על ביצועי הפונקציה `translate_virtual_to_physical`.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: כן, קיימת סיטואציה כזו. אם אחת מהרשומות בטבלת העמודים (PDE או PTE) מוגדרת עם דגל ה-`Present` על 1, אך ערך ה-PFN (הכתובת הפיזית של טבלת העמודים הבאה או של ה-Page Frame) הוא 0 (כלומר, כל ה-20 הסיביות העליונות הן 0), הפונקציה תנסה לגשת לכתובת פיזית 0. ברוב מערכות ההפעלה, כתובת פיזית 0 שמורה או אינה ניתנת לשימוש עבור טבלאות עמודים או עמודי נתונים, וניסיון גישה אליה עלול לגרום לקריסה של המערכת או ל-Page Fault נוסף שלא מטופל כראוי במסגרת פונקציה זו. הפונקציה הנוכחית בודקת רק את דגל ה-`Present` אך לא את תקינות הכתובת הפיזית עצמה.\n\n**תיקון מוצע:**\nיש להוסיף בדיקה שערך הכתובת הפיזית שהופק מתוך ה-PDE או ה-PTE אינו 0 (אלא אם כן, במערכת ספציפית, כתובת פיזית 0 היא לגיטימית לשימוש כבסיס לטבלת עמודים או כ-Page Frame). התיקון ייראה כך:\n```c\n// ... inside translate_virtual_to_physical function ...\n\n    // Check if PDE is present AND its physical address is not zero (if 0 is invalid)\n    // (pde & PRESENT_BIT) ensures we only check the address if present is 1\n    if (!(pde & PRESENT_BIT) || ((pde & ~PAGE_OFFSET_MASK) == 0 && (pde & PRESENT_BIT))) {\n        return (uint32_t)-1; // Page fault: PDE not present or points to invalid zero address\n    }\n    uint32_t pt_base_physical_address = pde & ~PAGE_OFFSET_MASK;\n\n    // ...\n    // Check if PTE is present AND its physical address is not zero (if 0 is invalid)\n    if (!(pte & PRESENT_BIT) || ((pte & ~PAGE_OFFSET_MASK) == 0 && (pte & PRESENT_BIT))) {\n        return (uint32_t)-1; // Page fault: PTE not present or points to invalid zero address\n    }\n    uint32_t page_frame_physical_address = pte & ~PAGE_OFFSET_MASK;\n\n// ...\n```\nהערה: בדיקה זו מבוססת על ההנחה שכתובת פיזית 0 אינה מותרת כבסיס לטבלת עמודים או כ-Page Frame. במערכות מסוימות, ייתכן שכתובת 0 היא לגיטימית ויש להתאים את הבדיקה בהתאם.\n\n1.2: ה-TLB (Translation Lookaside Buffer) הוא זיכרון מטמון קטן ומהיר השומר תרגומי כתובות וירטואליות-פיזיות שבוצעו לאחרונה. הוא נועד להאיץ את תהליך תרגום הכתובות על ידי הימנעות מהצורך לבצע 'הליכה' מלאה בטבלאות העמודים שבזיכרון הראשי עבור כל גישה לזיכרון.\n\n*   **פגיעת TLB (TLB Hit):** כאשר תרגום הכתובת הווירטואלית כבר נמצא ב-TLB, המערכת יכולה לקבל את הכתובת הפיזית באופן מיידי מה-TLB, ללא צורך לבצע את הפעולות שמתוארות בפונקציה `translate_virtual_to_physical` (קריאות ל-`read_physical_memory`). זה משפר באופן דרמטי את ביצועי גישת הזיכרון, שכן אין צורך לגשת לזיכרון הראשי (שתי גישות במקרה של טבלה דו-שכבתית) כדי לבצע את התרגום. הפונקציה `translate_virtual_to_physical` לא תופעל כלל במקרה של TLB Hit.\n\n*   **החטאת TLB (TLB Miss):** כאשר תרגום הכתובת הווירטואלית אינו נמצא ב-TLB, המערכת נאלצת לבצע את 'הליכת טבלת העמודים' המלאה (Page Table Walk) באמצעות ה-MMU (או במקרה שלנו, באמצעות הפונקציה `translate_virtual_to_physical`). זה כרוך במספר גישות לזיכרון הראשי (שתי גישות במקרה של טבלה דו-שכבתית: אחת ל-PDE ואחת ל-PTE). לאחר שהתרגום נמצא, הוא נטען ל-TLB עבור גישות עתידיות. החטאת TLB מאטה משמעותית את גישת הזיכרון הראשונית לאותו עמוד, מכיוון שהיא דורשת יותר גישות לזיכרון הראשי מאשר גישה ישירה לנתונים. הפונקציה `translate_virtual_to_physical` מתארת בדיוק את העבודה שמתבצעת בעת TLB Miss."}, "difficulty_estimation": "Hard", "_source_file": "0647__Paging__CodeAnalysis__Hard.json", "_topic_hint": "Paging", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:24:01", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["File Systems"], "content": {"text": "איזה מהבאים אינו מאוחסן ב-inode במערכת קבצים טיפוסית?", "code_snippet": null, "options": ["א. גודל הקובץ.", "ב. הרשאות גישה.", "ג. שם הקובץ.", "ד. זמני יצירה ושינוי.", "ה. מיקומי בלוקי הנתונים."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "ג'. ה-inode מאחסן מטא-דאטה אודות הקובץ, כגון גודל, הרשאות, זמני גישה ושינוי, וכן את מצביעי הבלוקים המכילים את תוכן הקובץ. לעומת זאת, שם הקובץ מאוחסן ברשומת התיקייה (directory entry) המצביעה על ה-inode של הקובץ, ולא בתוך ה-inode עצמו."}, "difficulty_estimation": "Easy", "_source_file": "0649__File_Systems__MultipleChoice__Easy.json", "_topic_hint": "File Systems", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:25:39", "_subject": "File Systems"}, {"id": 5, "type": "MultipleChoice", "topic": ["File Systems"], "content": {"text": "מהי המטרה העיקרית של מערכת קבצים (File System)?", "code_snippet": null, "options": ["א. לאפשר לתהליכים שונים לשתף זיכרון פיזי ביניהם.", "ב. לספק ממשק לניהול קבצים ותיקיות, כולל אחסון, אחזור וארגון נתונים בדיסק.", "ג. לתזמן את סדר הפעולות של המעבד בין תהליכים רצים.", "ד. לתרגם כתובות לוגיות לכתובות פיזיות בזיכרון הראשי.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "המטרה העיקרית של מערכת קבצים היא לספק דרך מאורגנת ויעילה לאחסן, לאחזר ולנהל נתונים בדיסק, תוך הצגתם למשתמש ולתוכניות בצורה של קבצים ותיקיות. שאר האפשרויות מתארות תפקידים של רכיבי מערכת הפעלה אחרים (כמו ניהול זיכרון או תזמון מעבד)."}, "difficulty_estimation": "Easy", "_source_file": "0650__File_Systems__MultipleChoice__Easy.json", "_topic_hint": "File Systems", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:25:47", "_subject": "File Systems"}, {"id": 5, "type": "MultipleChoice", "topic": ["File Systems", "Inodes", "Metadata"], "content": {"text": "איזה מהבאים מאוחסן בדרך כלל ב-inode במערכת קבצים?", "code_snippet": null, "options": ["א. שם הקובץ ותוכן הקובץ.", "ב. הרשאות גישה, מזהה בעלים, גודל הקובץ וכתובות לבלוקי הנתונים.", "ג. הנתיב המלא לקובץ וזמן יצירתו.", "ד. שם הקובץ, מספר הקישורים הקשיחים וזמן הגישה האחרונה.", "ה. אף אחת מהתשובות האחרות אינה נכונה."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. ב-inode מאוחסנים מטא-נתונים אודות הקובץ, כגון הרשאות גישה (permissions), מזהה הבעלים (owner ID), גודל הקובץ (file size), זמני גישה/שינוי/יצירה (timestamps), מספר הקישורים הקשיחים (hard links count), וחשוב מכל - מצביעים (pointers) לבלוקי הנתונים המכילים את תוכן הקובץ. שם הקובץ והנתיב המלא אליו מאוחסנים ברשומות התיקיות (directory entries), ולא ב-inode עצמו."}, "difficulty_estimation": "Easy", "_source_file": "0651__File_Systems__MultipleChoice__Easy.json", "_topic_hint": "File Systems", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:25:55", "_subject": "File Systems"}, {"id": 5, "type": "MultipleChoice", "topic": ["File Systems"], "content": {"text": "מהו תפקידו העיקרי של inode במערכת קבצים?", "code_snippet": null, "options": ["א. לאחסון את שם הקובץ בלבד.", "ב. לאחסון את תוכן הקובץ (הנתונים עצמם).", "ג. לאחסון מטא-נתונים על הקובץ, כולל הרשאות, גודל, תאריכים וכתובות לבלוקי הנתונים.", "ד. לאחסון את רשימת התיקיות שבהן הקובץ נמצא."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "ג'. inode (אינוד) הוא מבנה נתונים במערכת קבצים המכיל את כל המידע (מטא-נתונים) על קובץ או תיקייה, למעט שמו ותוכן הנתונים עצמם. מידע זה כולל הרשאות גישה, בעלות, גודל הקובץ, תאריכים שונים (כגון יצירה, שינוי אחרון), ובעיקר - מצביעים לבלוקי הנתונים הפיזיים על הדיסק המרכיבים את הקובץ. שם הקובץ מאוחסן בתוך רשומת התיקייה המצביעה על ה-inode המתאים."}, "difficulty_estimation": "Easy", "_source_file": "0652__File_Systems__MultipleChoice__Easy.json", "_topic_hint": "File Systems", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:26:04", "_subject": "File Systems"}, {"id": 5, "type": "MultipleChoice", "topic": ["File Systems"], "content": {"text": "איזה מבין הפרטים הבאים אינו מאוחסן בדרך כלל ישירות ב-inode של קובץ?", "code_snippet": null, "options": ["א. גודל הקובץ", "ב. הרשאות הגישה לקובץ", "ג. שם הקובץ", "ד. מזהה הבעלים של הקובץ", "ה. זמן השינוי האחרון של הקובץ"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "ג'. ה-inode מכיל מטא-דאטה אודות הקובץ כגון גודל, הרשאות, מזהה בעלים וזמני גישה ושינוי. שם הקובץ מאוחסן בתוך רשומת התיקייה (directory entry) המצביעה על ה-inode, ולא בתוך ה-inode עצמו."}, "difficulty_estimation": "Easy", "_source_file": "0653__File_Systems__MultipleChoice__Easy.json", "_topic_hint": "File Systems", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:26:11", "_subject": "File Systems"}, {"id": 1, "type": "MultipleChoice", "topic": ["File Systems", "Inodes"], "content": {"text": "איזה סוג מידע נשמר בדרך כלל ב-inode?", "code_snippet": null, "options": ["א. שם הקובץ ותוכן הקובץ.", "ב. שם הקובץ ונתיב התיקייה שלו.", "ג. תוכן הקובץ והרשאות הגישה שלו.", "ד. מטא-נתונים של הקובץ (הרשאות, גודל, בעלים, זמנים) ומצביעים לבלוקי הנתונים.", "ה. רק תוכן הקובץ."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "ד'. ה-inode (אינדקס צומת) הוא מבנה נתונים במערכת קבצים המכיל את כל המידע אודות קובץ (מטא-נתונים) למעט שמו. לדוגמה, הוא מכיל את סוג הקובץ, הרשאות גישה, בעלים, זמני יצירה/גישה/שינוי, גודל הקובץ, ומצביעים לבלוקי הנתונים המכילים את תוכן הקובץ בפועל. שם הקובץ נשמר בתוך רשומת התיקייה המצביעה על ה-inode המתאים."}, "difficulty_estimation": "Easy", "_source_file": "0654__File_Systems__MultipleChoice__Easy.json", "_topic_hint": "File Systems", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:26:19", "_subject": "File Systems"}, {"id": 1, "type": "MultipleChoice", "topic": ["File Systems"], "content": {"text": "במערכת קבצים מסוג UNIX-like, מהו התפקיד העיקרי של ה-inode?", "code_snippet": null, "options": ["א. לאחסן את שם הקובץ ואת הנתיב המלא אליו.", "ב. להצביע על בלוקי הנתונים המכילים את תוכן הקובץ ולשמור מטה-נתונים (metadata) עליו.", "ג. לשמש כטבלת המרה מכתובות לוגיות לכתובות פיזיות בדיסק.", "ד. לארגן את כל התיקיות והקבצים בצורה היררכית."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. ה-inode הוא מבנה נתונים המכיל את כל המידע (מטה-נתונים) אודות קובץ או תיקייה, למעט שמו בפועל ותוכנו. הוא כולל מידע כמו הרשאות, בעלות, זמני שינוי, גודל, ורשימת כתובות של בלוקי הנתונים המכילים את תוכן הקובץ. שם הקובץ מאוחסן בתוך רשומת התיקייה המצביעה על ה-inode המתאים."}, "difficulty_estimation": "Easy", "_source_file": "0655__File_Systems__MultipleChoice__Easy.json", "_topic_hint": "File Systems", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:26:28", "_subject": "File Systems"}, {"id": 5, "type": "MultipleChoice", "topic": ["File Systems"], "content": {"text": "מהי המטרה העיקרית של מערכת קבצים?", "code_snippet": null, "options": ["א. לנהל את תזמון המעבד.", "ב. להקצות זיכרון פיזי לתהליכים.", "ג. לארגן ולנהל קבצים על התקני אחסון.", "ד. לטפל בתקשורת רשת."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "ג'. מערכת קבצים אחראית לארגון, אחסון וניהול קבצים על התקני אחסון כמו דיסקים קשיחים או SSD, ולספק ממשק למשתמשים ותוכניות לגשת אליהם. שאר האפשרויות מתארות תפקידים של רכיבים אחרים במערכת ההפעלה (כמו מתזמן המעבד, מנהל הזיכרון ומנהל הרשת)."}, "difficulty_estimation": "Easy", "_source_file": "0656__File_Systems__MultipleChoice__Easy.json", "_topic_hint": "File Systems", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:26:35", "_subject": "File Systems"}, {"id": 6, "type": "MultipleChoice", "topic": ["File Systems", "System Calls"], "content": {"text": "במערכת קבצים מסוג יוניקס (כמו VSFS), כאשר קובץ נמחק באמצעות קריאת המערכת `unlink()`, איזה מהבאים משוחרר או מסומן כפנוי באופן מיידי *ללא תלות במספר הקישורים הקשיחים (hard links) לקובץ*?", "code_snippet": null, "options": ["א. הבלוקים המכילים את נתוני הקובץ.", "ב. ה-inode של הקובץ.", "ג. רשומת התיקייה (directory entry) המפנה לקובץ.", "ד. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "קריאת המערכת `unlink()` מסירה באופן מיידי את רשומת התיקייה (directory entry) המפנה לקובץ מהתיקייה ההורית. לאחר מכן, היא מפחיתה את מונה הקישורים הקשיחים (link count) ב-inode של הקובץ. רק אם מונה הקישורים מגיע לאפס (ואין תהליכים שעדיין מחזיקים את הקובץ פתוח), אז ה-inode והבלוקים המכילים את נתוני הקובץ מסומנים כפנויים וניתנים לשימוש חוזר. לכן, הפעולה המיידית והבלתי תלויה במספר הקישורים היא הסרת רשומת התיקייה."}, "difficulty_estimation": "Medium", "_source_file": "0657__File_Systems__MultipleChoice__Medium.json", "_topic_hint": "File Systems", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:26:46", "_subject": "File Systems"}, {"id": 6, "type": "MultipleChoice", "topic": ["File Systems", "Disk Management", "Fragmentation"], "content": {"text": "מהי החיסרון העיקרי של שימוש בגודל בלוק גדול יותר במערכת קבצים (לדוגמה, 16KB במקום 4KB)?", "code_snippet": null, "options": ["א. הגדלת ה-internal fragmentation (פיצול פנימי).", "ב. הגדלת ה-external fragmentation (פיצול חיצוני).", "ג. מורכבות רבה יותר בניהול מפתחות (inodes) לקבצים.", "ד. האטה בגישת דיסק עבור קבצים גדולים."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "א. כאשר גודל הבלוק במערכת קבצים גדול יותר, קבצים שגודלם אינו כפולה מדויקת של גודל הבלוק יגרמו לבזבוז שטח בבלוק האחרון שלהם. שטח לא מנוצל זה בתוך בלוק שהוקצה לקובץ נקרא internal fragmentation. בעוד שגודל בלוק גדול יכול להפחית את מספר פעולות ה-I/O הנדרשות לקריאה/כתיבה של קבצים גדולים, החיסרון העיקרי הוא בזבוז שטח דיסק עקב פיצול פנימי, במיוחד אם יש הרבה קבצים קטנים. פיצול חיצוני קשור לפיזור של שטחים פנויים קטנים ולא ישירות לגודל הבלוק. ניהול מפתחות (inodes) לא מושפע ישירות מגודל הבלוק. גישת דיסק עבור קבצים גדולים לרוב תהיה מהירה יותר עם בלוקים גדולים יותר עקב פחות פעולות I/O."}, "difficulty_estimation": "Medium", "_source_file": "0658__File_Systems__MultipleChoice__Medium.json", "_topic_hint": "File Systems", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:26:54", "_subject": "File Systems"}, {"id": 101, "type": "MultipleChoice", "topic": ["File Systems", "Disk Management", "Allocation Methods"], "content": {"text": "במערכת קבצים המשתמשת בשיטת הקצאה רציפה (Contiguous Allocation) עבור קבצים, מהי הבעיה המרכזית בניהול שטח דיסק הנובעת משיטה זו?", "code_snippet": null, "options": ["א. היא סובלת מפיצול פנימי (Internal Fragmentation) משמעותי, שאינו מאפשר ניצול יעיל של בלוקים.", "ב. היא דורשת טבלאות אינדקס גדולות מאוד (FAT או Inode Table) כדי לאתר את בלוקי הקובץ.", "ג. היא מקשה מאוד על גישה אקראית (Random Access) לנתונים בתוך קובץ.", "ד. היא נוטה לסבול מפיצול חיצוני (External Fragmentation) חמור, המקשה על הקצאת קבצים חדשים והגדלת קיימים."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "ד'. שיטת הקצאה רציפה דורשת שכל הבלוקים של קובץ יהיו רציפים על הדיסק. כאשר קבצים נמחקים או משתנים בגודלם, נוצרים חורים (gaps) של שטח פנוי שאינם רציפים. עם הזמן, הדיסק הופך למפוצל חיצונית (External Fragmentation), מה שאומר שיש הרבה שטח פנוי בסך הכל, אך הוא מפוצל לחתיכות קטנות שאינן גדולות מספיק כדי להכיל קובץ חדש גדול או כדי להגדיל קובץ קיים. זוהי הבעיה המרכזית בניהול שטח אחסון בשיטה זו."}, "difficulty_estimation": "Medium", "_source_file": "0659__File_Systems__MultipleChoice__Medium.json", "_topic_hint": "File Systems", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:27:10", "_subject": "File Systems"}, {"id": 2, "type": "MultipleChoice", "topic": ["File Systems", "Inodes", "Hard Links"], "content": {"text": "במערכת קבצים המשתמשת ב-inodes, מה מתרחש כאשר קובץ בעל מספר קישורים קשיחים (hard links) נמחק באמצעות פקודת `rm` על אחד מהקישורים הללו?", "code_snippet": null, "options": ["א. הקובץ נמחק באופן מיידי וה-inode שלו משוחרר.", "ב. ה-inode של הקובץ משוחרר רק כאשר כל הקישורים הקשיחים אליו נמחקים.", "ג. רק הקישור הקשיח הספציפי נמחק, אך הקובץ נשאר נגיש דרך קישוריו האחרים, ללא שינוי במונה הקישורים (link count).", "ד. הקובץ נשאר נגיש דרך קישוריו האחרים, ומונה הקישורים ב-inode שלו קטן ב-1."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "כאשר קישור קשיח נמחק (למשל, באמצעות פקודת `rm`), ערך מונה הקישורים (link count) ב-inode המתאים לקובץ מופחת באחד. הקובץ עצמו וה-inode שלו ימשיכו להתקיים ולהיות נגישים כל עוד מונה הקישורים גדול מאפס. רק כאשר מונה הקישורים מגיע לאפס, ה-inode ובלוקי הנתונים המשויכים אליו משוחררים ומוחזרים למערכת. לכן, הקובץ נשאר נגיש דרך קישוריו האחרים ומונה הקישורים קטן ב-1."}, "difficulty_estimation": "Medium", "_source_file": "0660__File_Systems__MultipleChoice__Medium.json", "_topic_hint": "File Systems", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:27:22", "_subject": "File Systems"}, {"id": 10, "type": "MultipleChoice", "topic": ["File Systems", "Hard Links", "Inodes"], "content": {"text": "במערכת קבצים מסוג VSFS, נניח שקובץ קיים ויש לו שני קישורים קשיחים (hard links) המפנים אליו. מה יקרה לנתוני הקובץ ול-inode שלו כאשר אחד משני הקישורים הקשיחים הללו יימחק?", "code_snippet": null, "options": ["א. נתוני הקובץ יימחקו מיד, וה-inode יסומן כפנוי.", "ב. ה-inode של הקובץ יימחק מיד, ונתוני הקובץ יהפכו לבלתי נגישים.", "ג. מונה הקישורים (link count) ב-inode יופחת באחד. נתוני הקובץ וה-inode יימחקו רק כאשר מונה הקישורים יגיע לאפס.", "ד. הקובץ כולו, כולל הנתונים וה-inode, יישאר זמין באופן מלא, ללא כל שינוי, מכיוון שהקישור הקשיח השני עדיין קיים."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "ג. כאשר קישור קשיח נמחק, ערך מונה הקישורים (link count) ב-inode של הקובץ מופחת באחד. הקובץ (הן הנתונים והן ה-inode) יישאר קיים ונגיש כל עוד מונה הקישורים גדול מאפס. רק כאשר מונה הקישורים מגיע לאפס, מערכת הקבצים תשחרר את ה-inode ואת בלוקי הנתונים שלו. במקרה זה, מכיוון שקיים קישור קשיח נוסף, מונה הקישורים ירד ל-1 ולא יגיע לאפס, ולכן הקובץ יישאר קיים ונגיש דרך הקישור הקשיח הנותר."}, "difficulty_estimation": "Medium", "_source_file": "0661__File_Systems__MultipleChoice__Medium.json", "_topic_hint": "File Systems", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:27:33", "_subject": "File Systems"}, {"id": 10, "type": "MultipleChoice", "topic": ["File Systems", "Hard Links", "File Deletion"], "content": {"text": "במערכת קבצים נפוצה (כמו ext4 או NTFS), מה קורה כאשר מוחקים קובץ שיש לו מספר קישורים קשיחים (hard links) המצביעים עליו?", "code_snippet": null, "options": ["א. הקובץ נמחק מיד, וכל הקישורים הקשיחים הנותרים הופכים לבלתי תקינים (dangling).", "ב. הקובץ (ה-inode ותוכן הנתונים) נמחק רק כאשר כל הקישורים הקשיחים המצביעים עליו נמחקים.", "ג. ה-inode של הקובץ נמחק מיד, אך תוכן הקובץ נשאר עד שכל הקישורים נמחקים.", "ד. מערכת הקבצים מונעת את מחיקת הקובץ כל עוד יש לו יותר מקישור קשיח אחד."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. כאשר מוחקים קישור קשיח לקובץ, מערכת הקבצים מקטינה את מונה הקישורים (link count) השמור ב-inode של הקובץ. הקובץ עצמו (כולל ה-inode ותוכן הנתונים) נמחק פיזית ומשוחרר רק כאשר מונה הקישורים מגיע לאפס. כל עוד יש לפחות קישור קשיח אחד שמצביע על הקובץ, הוא נשאר קיים ונגיש דרך הקישורים האחרים."}, "difficulty_estimation": "Medium", "_source_file": "0662__File_Systems__MultipleChoice__Medium.json", "_topic_hint": "File Systems", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:27:40", "_subject": "File Systems"}, {"id": 10, "type": "MultipleChoice", "topic": ["File Systems", "Directory Structure", "Inodes"], "content": {"text": "מהו המידע שמאוחסן בדרך כלל בתוך רשומת ספרייה (directory entry) במערכת קבצים לינוקס טיפוסית (כמו ext4)?", "code_snippet": null, "options": ["א. שם הקובץ, גודל הקובץ, וזמן השינוי האחרון.", "ב. שם הקובץ, מספר ה-inode, וסוג הקובץ (לדוגמה, קובץ רגיל או ספרייה).", "ג. מספר ה-inode, הרשאות גישה, ובעלות הקובץ.", "ד. גודל הקובץ, הרשאות גישה, וזמן הגישה האחרון.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "רשומת ספרייה (directory entry) מקשרת שם קובץ למספר inode. לכן, היא חייבת להכיל את שם הקובץ ואת מספר ה-inode המתאים. מערכות קבצים רבות, כמו ext4, שומרות גם את סוג הקובץ (לדוגמה, קובץ רגיל, ספרייה, קישור סימבולי) בתוך רשומת הספרייה עצמה כאופטימיזציה, כדי למנוע גישה ל-inode עבור פעולות בסיסיות כמו 'ls -F' או בדיקת סוג הפריט. מידע אחר כמו גודל, זמנים, הרשאות ובעלות מאוחסן ב-inode עצמו."}, "difficulty_estimation": "Medium", "_source_file": "0663__File_Systems__MultipleChoice__Medium.json", "_topic_hint": "File Systems", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:27:50", "_subject": "File Systems"}, {"id": 10, "type": "MultipleChoice", "topic": ["File Systems", "Links", "Inodes"], "content": {"text": "במערכת קבצים מסוג Unix-like (כמו VSFS מההרצאות), מהי ההגדרה הנכונה ביותר של קישור קשיח (Hard Link)?", "code_snippet": null, "options": ["א. קישור קשיח הוא קובץ חדש בעל מספר inode משלו, המכיל את הנתיב לקובץ המקורי.", "ב. קישור קשיח יוצר כניסה חדשה בספרייה (directory entry) המצביעה על ה-inode הקיים של הקובץ המקורי.", "ג. קישור קשיח יכול להצביע על קובץ או ספרייה הנמצאים במערכות קבצים שונות.", "ד. מחיקת הקובץ המקורי לאחר יצירת קישור קשיח אליו תגרום למחיקת כל הקישורים הקשיחים הקשורים אליו."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. קישור קשיח (Hard Link) הוא למעשה כניסה נוספת בספרייה (directory entry) המצביעה על אותו מספר inode כמו הקובץ המקורי. הוא אינו יוצר inode חדש, אלא רק מגדיל את מונה הקישורים (link count) של ה-inode הקיים. כל עוד link count גדול מאפס, הנתונים של הקובץ נשמרים בדיסק. קישורים קשיחים אינם יכולים להצביע על ספריות (ברוב המערכות המודרניות) ואינם יכולים לחצות גבולות של מערכות קבצים שונות."}, "difficulty_estimation": "Medium", "_source_file": "0664__File_Systems__MultipleChoice__Medium.json", "_topic_hint": "File Systems", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:28:01", "_subject": "File Systems"}, {"id": 10, "type": "MultipleChoice", "topic": ["File Systems", "Journaling", "Consistency"], "content": {"text": "במערכת קבצים מתג'ורנלת (Journaling File System) מסוג `data=ordered`, תהליך כותב 4KB של נתונים לקובץ קיים ולאחר מכן מבצע `fsync()` על ה-file descriptor של הקובץ. גודל בלוק במערכת הקבצים הוא 4KB. מהו המספר המינימלי של פעולות כתיבה לדיסק (disk writes) הנדרשות כדי להבטיח שהשינויים יהיו עמידים (durable) לאחר ה-`fsync()`, בהנחה שהקובץ אינו חדש ואין צורך להקצות בלוקים חדשים לנתונים, אך יש צורך לעדכן את גודל הקובץ ב-inode?", "code_snippet": null, "options": ["א. 1", "ב. 2", "ג. 3", "ד. 4", "ה. 5"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "במערכת קבצים מתג'ורנלת מסוג `data=ordered`, הנתונים נכתבים למיקומם הסופי בדיסק *לפני* שהמטא-דאטה (כמו ה-inode המעודכן) נכתבת ליומן (journal). קריאה ל-`fsync()` במצב זה מבטיחה עמידות (durability) של הנתונים והמטא-דאטה. רצף הפעולות המינימלי הוא:\n1. כתיבת בלוק הנתונים (4KB) למיקומו הסופי בדיסק. (פעולת כתיבה אחת)\n2. כתיבת המטא-דאטה המעודכנת (ה-inode עם הגודל החדש) ליומן. (פעולת כתיבה אחת ליומן)\n3. כתיבת בלוק ה-commit ליומן, המסמן את סיום הטרנזקציה. (פעולת כתיבה אחת ליומן)\nסה\"כ שלוש פעולות כתיבה מינימליות לדיסק מבטיחות שאם תתרחש קריסה, הנתונים יהיו על הדיסק, וה-inode המעודכן יוחזר באמצעות ה-replay של היומן במהלך ההתאוששות. לכן התשובה הנכונה היא ג'."}, "difficulty_estimation": "Hard", "_source_file": "0665__File_Systems__MultipleChoice__Hard.json", "_topic_hint": "File Systems", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:28:19", "_subject": "File Systems"}, {"id": 1, "type": "MultipleChoice", "topic": ["File Systems", "Inode Structure", "Disk I/O"], "content": {"text": "נתון מערכת קבצים עם גודל בלוק של 4KB וגודל מצביע לבלוק (block pointer) של 4 בתים. לכל Inode יש 12 מצביעים ישירים (direct pointers), מצביע עקיף יחיד (single indirect), מצביע עקיף כפול (double indirect) ומצביע עקיף משולש (triple indirect).\nמהו המספר המינימלי של פעולות קריאה מהדיסק (disk I/Os) הנדרשות כדי לגשת לבית בודד בתוך קובץ שגודלו 100GB, בהנחה שה-Inode של הקובץ וכל בלוקי המצביעים העקיפים הרלוונטיים אינם נמצאים בזיכרון המטמון (cache)?", "code_snippet": null, "options": ["א. 3", "ב. 4", "ג. 5", "ד. 6", "ה. 7"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הסבר: כדי לגשת לבית בודד בקובץ שגודלו 100GB, נצטרך בוודאות להשתמש במצביע העקיף המשולש (triple indirect pointer), מכיוון שגודל הקובץ (100GB) גדול בהרבה מהיכולת של מצביעים ישירים (12 * 4KB = 48KB), עקיפים בודדים (1 * (4KB/4B) * 4KB = 4MB) או כפולים (1 * (4KB/4B)^2 * 4KB = 4GB).\n\nה-I/Os הנדרשים הם:\n1. קריאת ה-Inode עצמו מהדיסק. (1 I/O)\n2. קריאת בלוק המצביעים העקיף הראשון (ה-single indirect block) שה-Inode מפנה אליו דרך המצביע המשולש. (1 I/O)\n3. קריאת בלוק המצביעים העקיף השני (ה-double indirect block) שהבלוק הקודם מפנה אליו. (1 I/O)\n4. קריאת בלוק המצביעים העקיף השלישי (ה-triple indirect block) שהבלוק הקודם מפנה אליו. (1 I/O)\n5. קריאת בלוק הנתונים (data block) שמכיל את הבית המבוקש, שהבלוק הקודם מפנה אליו. (1 I/O)\n\nסה\"כ 5 פעולות קריאה מהדיסק."}, "difficulty_estimation": "Hard", "_source_file": "0666__File_Systems__MultipleChoice__Hard.json", "_topic_hint": "File Systems", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:28:30", "_subject": "File Systems"}, {"id": 101, "type": "MultipleChoice", "topic": ["File Systems", "Hard Links", "File Lifecycle"], "content": {"text": "נתונה סדרת הפעולות הבאה על מערכת קבצים דמוית יוניקס:\n1.  נוצר קובץ בשם `file_A.txt`.\n2.  נוצר קישור קשיח (hard link) בשם `file_B.txt` ל-`file_A.txt`.\n3.  `file_A.txt` נפתח לכתיבה (O_RDWR).\n4.  `file_A.txt` נמחק באמצעות `unlink`.\n5.  נתונים נכתבים לתיאור הקובץ הפתוח (file descriptor) שנוצר בשלב 3.\n6.  תיאור הקובץ נסגר.\n\nאיזו מהטענות הבאות נכונה לגבי מצב הקובץ והנתונים שלו לאחר סיום כל הפעולות?", "code_snippet": null, "options": ["א. הנתונים שנכתבו בשלב 5 אבדו, ו-`file_B.txt` יכיל את התוכן המקורי של `file_A.txt` (לפני שלב 5).", "ב. הנתונים שנכתבו בשלב 5 נשמרו, ו-`file_B.txt` יכיל את הנתונים החדשים.", "ג. הנתונים שנכתבו בשלב 5 אבדו, ו-`file_B.txt` לא קיים יותר.", "ד. הנתונים שנכתבו בשלב 5 נשמרו, אך הם אינם נגישים דרך `file_B.txt` מכיוון שהקובץ המקורי נמחק.", "ה. לא ניתן לכתוב נתונים לקובץ לאחר שהוא נמחק, גם אם תיאור הקובץ פתוח."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "במערכת קבצים דמוית יוניקס, קישור קשיח (hard link) הוא שם נוסף לאותו קובץ (אותו inode). כאשר `file_B.txt` נוצר כקישור קשיח ל-`file_A.txt`, שניהם מצביעים על אותו inode, ומונה הקישורים (link count) של ה-inode עולה ל-2. כאשר `file_A.txt` נמחק באמצעות `unlink`, רק כניסת התיקייה (directory entry) עבור `file_A.txt` מוסרת, ומונה הקישורים של ה-inode יורד ל-1. מכיוון שמונה הקישורים עדיין גדול מ-0 (בגלל `file_B.txt`), ה-inode ובלוקי הנתונים שלו אינם משוחררים. בנוסף, כל עוד קיים תיאור קובץ (file descriptor) פתוח המצביע על ה-inode, הקובץ \"חי\" וניתן לכתוב או לקרוא ממנו. לכן, כאשר נכתבים נתונים לתיאור הקובץ בשלב 5, הנתונים נכתבים לבלוקים המשויכים ל-inode המשותף. לאחר סגירת תיאור הקובץ, הנתונים החדשים נשארים ב-inode ונגישים דרך `file_B.txt`."}, "difficulty_estimation": "Hard", "_source_file": "0667__File_Systems__MultipleChoice__Hard.json", "_topic_hint": "File Systems", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:28:57", "_subject": "File Systems"}, {"id": 1, "type": "MultipleChoice", "topic": ["File Systems", "Journaling", "Data Integrity"], "content": {"text": "במערכת קבצים מיומנת (journaling file system) כמו ext4, המוגדרת במצב `data=ordered`, תהליך כותב מידע קטן לקובץ קיים. מיד לאחר פעולת הכתיבה ולפני שהתהליך הספיק לבצע קריאה ל-`fsync()`, המערכת קורסת באופן בלתי צפוי. לאחר אתחול מחדש ושחזור מערכת הקבצים, מהו המצב הסביר ביותר של הקובץ?", "code_snippet": null, "options": ["א. הקובץ יכיל את הנתונים החדשים, ומטא-הנתונים (גודל קובץ, זמן שינוי) יעודכנו בהתאם.", "ב. הקובץ יכיל את הנתונים החדשים, אך מטא-הנתונים לא יעודכנו.", "ג. הקובץ ישוחזר למצבו המקורי לפני הכתיבה, ללא הנתונים החדשים.", "ד. הקובץ עלול להכיל נתונים שגויים (corrupted data) או שילוב בלתי עקבי של נתונים ישנים וחדשים."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "במצב `data=ordered` (הגדרת ברירת מחדל ב-ext4), מערכת הקבצים מבטיחה שבלוקי הנתונים ייכתבו לדיסק *לפני* שמטא-הנתונים המתאימים (כמו גודל קובץ או מצביעי בלוקים) יעודכנו ביומן. אם קריסה מתרחשת *לאחר* כתיבת הנתונים לדיסק אך *לפני* שמטא-הנתונים עודכנו ביומן או שהיומן נכתב לדיסק (פעולה ש-`fsync()` מסייעת להבטיח), אז לאחר השחזור, היומן ינוגן אך שינוי מטא-הנתונים לא יופיע בו. כתוצאה מכך, מערכת הקבצים תחזור למצבה העקבי האחרון, והקובץ יופיע כאילו הכתיבה מעולם לא התרחשה, כלומר יכיל את הנתונים המקוריים שלו. הנתונים החדשים, גם אם נכתבו לדיסק, לא יהיו נגישים דרך מערכת הקבצים, מה שמבטיח עקביות של מטא-הנתונים אך לא מבטיח שהנתונים עצמם שרדו ללא קריאה ל-`fsync()`."}, "difficulty_estimation": "Hard", "_source_file": "0668__File_Systems__MultipleChoice__Hard.json", "_topic_hint": "File Systems", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:29:15", "_subject": "File Systems"}, {"id": 10, "type": "MultipleChoice", "topic": ["File Systems", "i-nodes", "Disk I/O", "Performance"], "content": {"text": "נתונה מערכת קבצים המשתמשת במבנה i-node הדומה ל-UNIX, עם גודל בלוק של 4KB וגודל מצביע של 4 בתים. ה-i-node מכיל 12 מצביעים ישירים, מצביע עקיף יחיד, מצביע עקיף כפול, ומצביע עקיף משולש. כמה פעולות קלט/פלט דיסק (לכל הפחות) נדרשות כדי לקרוא בלוק נתונים מקובץ, אם ידוע שהבלוק המבוקש נמצא תחת המצביע העקיף המשולש, בהנחה שה-i-node עצמו כבר נמצא בזיכרון, ושום בלוק אחר (בלוקי אינדקס או נתונים) אינו שמור במטמון?", "code_snippet": null, "options": ["א. 1", "ב. 2", "ג. 3", "ד. 4", "ה. 5"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "כדי לגשת לבלוק נתונים דרך המצביע העקיף המשולש, יש לבצע את השלבים הבאים, כאשר כל שלב דורש קריאת בלוק דיסק (I/O) מכיוון שאין כלום במטמון:\n1. קריאת בלוק המצביעים העקיפים המשולש (הראשון בשרשרת, אליו מצביע ה-i-node).\n2. קריאת בלוק המצביעים העקיפים הכפול (השני בשרשרת, אליו מצביע הבלוק מהשלב הקודם).\n3. קריאת בלוק המצביעים העקיפים היחיד (השלישי בשרשרת, אליו מצביע הבלוק מהשלב הקודם).\n4. קריאת בלוק הנתונים עצמו (אליו מצביע הבלוק מהשלב הקודם).\n\nסך הכל 4 פעולות קלט/פלט דיסק."}, "difficulty_estimation": "Hard", "_source_file": "0669__File_Systems__MultipleChoice__Hard.json", "_topic_hint": "File Systems", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:29:27", "_subject": "File Systems"}, {"id": 101, "type": "MultipleChoice", "topic": ["File Systems", "Journaling", "Performance", "Consistency"], "content": {"text": "במערכת קבצים מסוג Journaling (כגון ext4 במצב 'ordered'), יישום מבצע פעולות כתיבה תכופות וקטנות לקבצים רבים. בהשוואה למערכת קבצים ללא journaling, איזו טענה הבאה מסבירה בצורה הטובה ביותר את ההשפעה של מנגנון ה-journaling על ביצועי הכתיבה והעקביות במצב זה?", "code_snippet": null, "options": ["א. ה-journaling מחייב כתיבה כפולה של כל בלוק נתונים (גם ליומן וגם למיקום הסופי), מה שמכפיל את עומס ה-I/O ומפחית את הביצועים באופן משמעותי, אך מבטיח שלמות נתונים מלאה.", "ב. ה-journaling דורש כתיבות סנכרוניות רבות ליומן (journal) כדי להבטיח את סדר הפעולות ואת עקביות המטא-דאטה, מה שמגדיל את זמן ההשהיה (latency) של כל פעולת כתיבה ויוצר עומס I/O נוסף.", "ג. ה-journaling משפר את ביצועי הכתיבה על ידי איגום (batching) של שינויים במטא-דאטה לפני כתיבתם לדיסק, ובכך מפחית את מספר פעולות ה-I/O הפיזיות.", "ד. ה-journaling גורם לשימוש מוגבר ב-CPU לצורך חישוב checksums של הנתונים, אך אינו משפיע באופן מהותי על פעולות ה-I/O עצמן.", "ה. ה-journaling מונע פרגמנטציה (fragmentation) של הקבצים על ידי הקצאת בלוקים רציפים, ובכך משפר את ביצועי הקריאה והכתיבה."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. במערכות קבצים מסוג Journaling, במיוחד במצב 'ordered' (כמו ב-ext4), מנגנון ה-journaling מבטיח את עקביות המטא-דאטה במקרה של קריסה. כדי להשיג זאת, שינויים במטא-דאטה נרשמים ליומן (journal) לפני שהם מיושמים במיקומם הסופי בדיסק. בנוסף, על מנת להבטיח שהנתונים עצמם יהיו בדיסק לפני עדכון המטא-דאטה ביומן (כדי למנוע מצב של מטא-דאטה המצביע על נתונים לא מעודכנים), מתבצעות פעמים רבות כתיבות סנכרוניות לדיסק או פקודות flush לזיכרון המטמון של הדיסק. ריבוי כתיבות קטנות ופרטניות גורר ריבוי טרנזקציות ביומן וריבוי כתיבות סנכרוניות, מה שמגדיל משמעותית את זמן ההשהיה (latency) של כל פעולת כתיבה ואת עומס ה-I/O הכולל. זהו המחיר עבור עקביות גבוהה יותר ויכולת התאוששות מהירה מקריסות. תשובה א' מתארת מצב של 'data' journaling מלא, שבו כל הנתונים נכתבים פעמיים, ואינו נכון בהכרח למצב 'ordered' בו רק המטא-דאטה עובר ליומן."}, "difficulty_estimation": "Hard", "_source_file": "0670__File_Systems__MultipleChoice__Hard.json", "_topic_hint": "File Systems", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:29:46", "_subject": "File Systems"}, {"id": 6, "type": "MultipleChoice", "topic": ["File Systems", "Journaling", "Data Consistency", "fsync"], "content": {"text": "בהינתן מערכת קבצים מתזמנת (Journaling File System) הפועלת במצב `data=ordered` (כמו ext4/ext3 כברירת מחדל), תהליך מבצע את הפעולות הבאות:\n1.  פותח קובץ חדש (`open`).\n2.  כותב 10KB של נתונים לקובץ (`write`).\n3.  מבצע סנכרון (`fsync`).\n4.  מיד לאחר מכן, המערכת קורסת באופן פתאומי.\n\nלאחר אתחול המערכת מחדש, מהו המצב המובטח של הקובץ והנתונים?", "code_snippet": null, "options": ["א. הנתונים (10KB) מובטחים להימצא בקובץ, וכן כל המטא-דאטה (גודל קובץ, זמן שינוי) תהיה מעודכנת.", "ב. הקובץ עצמו מובטח להימצא, וכן כל המטא-דאטה שלו תהיה מעודכנת, אך אין ערובה שהנתונים (10KB) נכתבו לדיסק.", "ג. הנתונים (10KB) מובטחים להימצא בקובץ, אך המטא-דאטה עשויה להיות לא מעודכנת (לדוגמה, גודל הקובץ עשוי להיות 0).", "ד. הקובץ עשוי לא להימצא כלל, אך אם יימצא, המטא-דאטה שלו תהיה מעודכנת. הנתונים (10KB) אינם מובטחים.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "במערכת קבצים מתזמנת (Journaling File System) במצב `data=ordered`, הסדר שבו נכתבים נתונים ומטא-דאטה לדיסק הוא קריטי. במצב זה, נתוני הקובץ נכתבים לדיסק *לפני* שהמטא-דאטה המתאימה (לדוגמה, גודל הקובץ, מיקומי בלוקים) נרשמת ליומן ונכתבת לדיסק. הקריאה ל-`fsync()` מבטיחה שכל הנתונים והמטא-דאטה המשויכים לקובץ (כולל כל עדכוני היומן) נדחפו בהצלחה לזיכרון יציב (הדיסק) לפני שהפונקציה חוזרת. לכן, אם המערכת קורסת *לאחר* ש-`fsync()` הסתיימה בהצלחה, מובטח שגם 10KB הנתונים וגם כל המטא-דאטה הרלוונטית (גודל קובץ, זמני שינוי, וכו') נשמרו באופן עקבי על הדיסק ויהיו זמינים לאחר התאוששות."}, "difficulty_estimation": "Hard", "_source_file": "0671__File_Systems__MultipleChoice__Hard.json", "_topic_hint": "File Systems", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:30:00", "_subject": "File Systems"}, {"id": 101, "type": "MultipleChoice", "topic": ["File Systems", "Inode Structure", "Block Allocation"], "content": {"text": "נתונה מערכת קבצים המשתמשת במבנה Inode עם 12 מצביעים ישירים (direct pointers), מצביע עקיף יחיד (single indirect pointer), מצביע עקיף כפול (double indirect pointer), ומצביע עקיף משולש (triple indirect pointer). גודל בלוק במערכת הקבצים הוא 4KB, וכל מצביע לבלוק דורש 4 בתים. מהו גודל הקובץ המרבי הנתמך על ידי מערכת קבצים זו?", "code_snippet": null, "options": ["א. 4TB + 4GB + 4MB + 48KB", "ב. 4TB + 4GB + 4MB", "ג. 4TB + 4GB + 1MB + 48KB", "ד. 4TB + 1GB + 4MB + 48KB", "ה. אף תשובה אחרת אינה נכונה."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "הפתרון דורש חישוב של תרומת כל סוג מצביעים לגודל הקובץ המרבי:\n1.  **מצביעים ישירים (Direct Pointers)**: ישנם 12 מצביעים, וכל אחד מצביע לבלוק בגודל 4KB. סך הכל: 12 * 4KB = 48KB.\n2.  **מצביע עקיף יחיד (Single Indirect Pointer)**: בלוק אחד מכיל מצביעים לבלוקי נתונים. מספר המצביעים בבלוק הוא גודל בלוק / גודל מצביע = 4096 בתים / 4 בתים למצביע = 1024 מצביעים. כל אחד מהם מצביע לבלוק נתונים בגודל 4KB. סך הכל: 1024 * 4KB = 4096KB = 4MB.\n3.  **מצביע עקיף כפול (Double Indirect Pointer)**: בלוק אחד מכיל מצביעים לבלוקים עקיפים יחידים. כל אחד מ-1024 המצביעים בבלוק זה מצביע לבלוק עקיף יחיד, אשר בתורו מצביע ל-1024 בלוקי נתונים. סך הכל: 1024 * (1024 * 4KB) = 1024 * 4MB = 4096MB = 4GB.\n4.  **מצביע עקיף משולש (Triple Indirect Pointer)**: בלוק אחד מכיל מצביעים לבלוקים עקיפים כפולים. כל אחד מ-1024 המצביעים בבלוק זה מצביע לבלוק עקיף כפול, אשר בתורו מצביע ל-4GB של נתונים. סך הכל: 1024 * 4GB = 4096GB = 4TB.\n\nגודל הקובץ המרבי הוא סכום כל התרומות: 48KB + 4MB + 4GB + 4TB."}, "difficulty_estimation": "Hard", "_source_file": "0672__File_Systems__MultipleChoice__Hard.json", "_topic_hint": "File Systems", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:30:17", "_subject": "File Systems"}, {"id": 10, "type": "Open", "topic": ["File Systems"], "content": {"text": "מהו inode במערכת קבצים? אילו סוגי מידע הוא מאחסן, ומדוע הוא חשוב לניהול קבצים?", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "Inode הוא מבנה נתונים במערכת קבצים המכיל מידע אודות קובץ או תיקייה (metadata), למעט שמו של הקובץ ותוכן הנתונים שלו. הוא מאחסן מידע כגון:\n- סוג הקובץ (רגיל, תיקייה, קישור סימבולי וכו').\n- הרשאות גישה (permissions).\n- בעלות (UID, GID).\n- זמני יצירה, גישה ושינוי אחרונים.\n- גודל הקובץ.\n- מספר הקישורים הקשיחים (hard links) לקובץ.\n- מצביעים (pointers) לבלוקי הנתונים (data blocks) המכילים את תוכן הקובץ בפועל.\n\nה-inode חשוב לניהול קבצים מכיוון שהוא מפריד את המטא-דאטה של הקובץ מתוכן הנתונים שלו ומשמו. זה מאפשר:\n1. ניהול יעיל: מערכת הקבצים יכולה למצוא את תוכן הקובץ על הדיסק באמצעות המצביעים ב-inode, בלי צורך לחפש אותו לפי שם.\n2. קישורים קשיחים: מספר קבצים יכולים להצביע לאותו inode, מה שמאפשר לקישורים קשיחים לחלוק את אותם נתונים ואותה מטא-דאטה.\n3. עקביות: עדכון מטא-דאטה (כמו הרשאות או זמנים) אינו דורש שינוי במיקום הפיזי של נתוני הקובץ, אלא רק ב-inode עצמו."}, "difficulty_estimation": "Easy", "_source_file": "0673__File_Systems__Open__Easy.json", "_topic_hint": "File Systems", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:30:25", "_subject": "File Systems"}, {"id": 1, "type": "Open", "topic": ["File Systems"], "content": {"text": "הסבר את ההבדל בין קישור קשיח (Hard Link) לקישור סימבולי (Symbolic Link) במערכת קבצים. תאר תרחיש אחד שבו עדיף להשתמש בקישור קשיח, ותרחיש אחר שבו עדיף להשתמש בקישור סימבולי.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסבר ההבדלים:\n\n**קישור קשיח (Hard Link):**\n*   מצביע לאותו מספר inode כמו הקובץ המקורי. כל הקישורים הקשיחים לאותו קובץ חולקים את אותם בלוקי נתונים ואת אותם מטא-נתונים (הרשאות, זמני גישה/שינוי וכו').\n*   הקובץ נמחק פיזית רק כאשר כל הקישורים הקשיחים אליו נמחקים. כל עוד קיים לפחות קישור קשיח אחד, נתוני הקובץ יישארו קיימים.\n*   לא יכול לקשר בין מערכות קבצים שונות (פועל רק בתוך אותה מערכת קבצים).\n*   לא יכול לקשר לתיקיות (בדרך כלל, למניעת לולאות). כלומר, רק לקבצים רגילים.\n*   מבחינת מערכת הקבצים, אין 'מקור' ו'קישור' – כולם הם שמות שווים לאותו קובץ.\n\n**קישור סימבולי (Symbolic Link / Soft Link):**\n*   הוא קובץ מיוחד בפני עצמו, עם inode משלו ובלוק נתונים משלו, המכיל את הנתיב (path) לקובץ או לתיקייה המקוריים.\n*   אם הקובץ המקורי נמחק, הקישור הסימבולי הופך ל'קישור שבור' (dangling pointer) ולא יוכל לגשת לנתונים.\n*   יכול לקשר בין מערכות קבצים שונות.\n*   יכול לקשר גם לתיקיות.\n*   מבחינת מערכת הקבצים, קיים 'מקור' ו'קישור' – הקישור הוא רק הפניה למקור.\n\n**תרחישים מועדפים:**\n\n**עדיפות לקישור קשיח:**\n*   **תרחיש:** נניח שיש לנו קובץ תצורה חשוב (`config.conf`) ואנחנו רוצים שהוא יהיה נגיש משני מיקומים שונים במערכת הקבצים (`/etc/app1/config.conf` וגם `/usr/local/share/app2/config.conf`), אך אנחנו רוצים לוודא שאם אחד מהנתיבים נמחק בטעות, הקובץ עצמו יישאר קיים ונגיש מהנתיב השני. במקרה זה, יצירת קישור קשיח תבטיח ששני הנתיבים מצביעים לאותו קובץ בדיוק, ושהקובץ לא יימחק עד ששניהם יוסרו.\n\n**עדיפות לקישור סימבולי:**\n*   **תרחיש:** נניח שיש לנו תיקייה גדולה עם נתונים חשובים (`/data/logs/application_logs`) ואנחנו רוצים ליצור קיצור דרך נוח אליה מתיקיית הבית שלנו (`~/logs`). בנוסף, ייתכן שהתיקייה המקורית נמצאת במערכת קבצים נפרדת (למשל, כונן רשת ממופה). במקרה זה, קישור סימבולי הוא הפתרון היחיד והמתאים ביותר, מכיוון שקישור קשיח אינו יכול לקשר לתיקיות או בין מערכות קבצים. אם נרצה לשנות את המיקום של `application_logs` בעתיד, נוכל פשוט לעדכן את הקישור הסימבולי מבלי להשפיע על הקובץ המקורי."}, "difficulty_estimation": "Easy", "_source_file": "0674__File_Systems__Open__Easy.json", "_topic_hint": "File Systems", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:30:39", "_subject": "File Systems"}, {"id": 1, "type": "Open", "topic": ["File Systems"], "content": {"text": "מהו inode במערכת קבצים, ואיזה מידע הוא מאחסן בדרך כלל?", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "Inode (index node) הוא מבנה נתונים במערכת קבצים בסגנון יוניקס, המתאר אובייקט במערכת הקבצים כגון קובץ או תיקייה. כל inode מאחסן את התכונות ומיקומי בלוקי הדיסק של נתוני אובייקט מערכת קבצים.\n\nמידע טיפוסי המאוחסן ב-inode כולל:\n*   סוג הקובץ (קובץ רגיל, תיקייה, קישור סימבולי, קובץ התקן וכו').\n*   הרשאות (קריאה, כתיבה, הרצה לבעלים, קבוצה, אחרים).\n*   מזהה בעלים (UID).\n*   מזהה קבוצה (GID).\n*   גודל הקובץ בבתים.\n*   חותמות זמן (גישה אחרונה, שינוי אחרון, שינוי inode אחרון).\n*   מונה קישורים (מספר הקישורים הקשיחים המצביעים ל-inode זה).\n*   מצביעים לבלוקי הנתונים בדיסק המכילים את התוכן בפועל של הקובץ."}, "difficulty_estimation": "Easy", "_source_file": "0675__File_Systems__Open__Easy.json", "_topic_hint": "File Systems", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:30:48", "_subject": "File Systems"}, {"id": 1, "type": "Open", "topic": ["File Systems"], "content": {"text": "הסבר את מטרתו של ה-inode במערכת קבצים דמוית יוניקס. איזה מידע ה-inode מאחסן, ואיזה מידע הוא *אינו* מאחסן? כיצד רשומת ספרייה (directory entry) מקשרת שם קובץ ל-inode המתאים לו?", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ה-inode (קיצור של index node) הוא מבנה נתונים במערכות קבצים דמויות יוניקס המייצג קובץ או ספרייה. מטרתו העיקרית היא לאחסן את כל המטא-דאטה (metadata) אודות הקובץ, למעט שמו ותוכנו בפועל.\n\nה-inode מאחסן מידע כגון:\n1. סוג הקובץ (קובץ רגיל, ספרייה, קישור סימבולי, התקן בלוק, התקן תו וכו').\n2. הרשאות גישה (read, write, execute) לבעלים, לקבוצה ולשאר המשתמשים.\n3. UID של הבעלים ו-GID של הקבוצה.\n4. גודל הקובץ בבתים.\n5. זמני גישה, שינוי ויצירה אחרונים (atime, mtime, ctime).\n6. מספר הקישורים הקשיחים (hard links) המצביעים לקובץ זה.\n7. מצביעים לבלוקי הנתונים (data blocks) שבהם מאוחסן תוכן הקובץ בפועל.\n\nה-inode *אינו* מאחסן את שם הקובץ או את הנתיב המלא אליו, וגם לא את תוכן הקובץ עצמו (הוא רק מצביע לבלוקים המכילים את התוכן).\n\nרשומת ספרייה (directory entry) מקשרת שם קובץ ל-inode המתאים לו באופן הבא: ספרייה היא למעשה קובץ מיוחד המכיל רשימה של רשומות. כל רשומה כזו מורכבת בדרך כלל משם קובץ וממספר ה-inode של הקובץ או הספרייה שאליה הוא מתייחס. כאשר המערכת צריכה למצוא קובץ לפי שמו (לדוגמה, בפקודת `ls` או `open`), היא מחפשת את השם המתאים בתוך רשומות הספרייה הנוכחית. ברגע שנמצא השם, היא משיגה את מספר ה-inode המשויך אליו, ובעזרת מספר זה היא יכולה לאתר את ה-inode המתאים בדיסק ולקרוא ממנו את כל המטא-דאטה הנדרשת כדי לגשת לקובץ."}, "difficulty_estimation": "Easy", "_source_file": "0676__File_Systems__Open__Easy.json", "_topic_hint": "File Systems", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:30:59", "_subject": "File Systems"}, {"id": 10, "type": "Open", "topic": ["File Systems"], "content": {"text": "הסבירו את תפקידו של inode במערכת קבצים דמוית יוניקס. איזה מידע הוא מאחסן, ומדוע מידע זה מופרד מנתוני הקובץ עצמו?", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "inode (index node) הוא מבנה נתונים במערכת קבצים דמוית יוניקס המתאר אובייקט במערכת הקבצים, כגון קובץ או תיקייה. כל inode מאחסן את התכונות ומיקומי בלוקי הדיסק של נתוני האובייקט.\n\nמידע המאוחסן ב-inode כולל בדרך כלל:\n- סוג הקובץ (קובץ רגיל, תיקייה, קישור סימבולי וכו')\n- הרשאות (קריאה, כתיבה, הפעלה עבור בעלים, קבוצה, אחרים)\n- מזהה בעלים ומזהה קבוצה\n- גודל הקובץ\n- חותמות זמן (זמן יצירה, זמן גישה אחרונה, זמן שינוי אחרון)\n- ספירת קישורים (מספר הקישורים הקשיחים המצביעים ל-inode זה)\n- מצביעים לבלוקי הנתונים בדיסק שבהם מאוחסן תוכן הקובץ בפועל.\n\nההפרדה בין מידע ה-inode לבין בלוקי הנתונים של הקובץ מספקת מספר יתרונות:\n1.  **גישה יעילה למטא-דאטה:** כאשר מערכת קבצים צריכה לגשת למטא-דאטה (כמו הרשאות או חותמות זמן), היא צריכה לקרוא רק את ה-inode, ולא את כל תוכן הקובץ. זה מהיר יותר, במיוחד עבור קבצים גדולים.\n2.  **גמישות בגודל הקובץ:** Inodes מאחסנים מצביעים לבלוקי נתונים, מה שמאפשר לקבצים להיות מפוצלים על פני הדיסק מבלי שיהיה צורך לעדכן את המטא-דאטה של הקובץ בכל פעם שנתונים מתווספים או נמחקים מאמצע הקובץ.\n3.  **קישורים קשיחים (Hard Links):** מספר ערכים בתיקייה (שמות קבצים) יכולים להצביע על אותו inode. זה מאפשר קישורים קשיחים, שבהם נתוני קובץ בודד יכולים להיות מופנים על ידי מספר שמות ללא שכפול הנתונים. ספירת הקישורים של ה-inode עוקבת אחר כמה ערכי תיקיות מצביעים אליו. כאשר ספירת הקישורים יורדת לאפס, בלוקי הנתונים של הקובץ ניתנים לשחרור.\n4.  **מבנה תיקיות:** תיקיות מאחסנות מיפויים משמות קבצים למספרי inode. הפרדה זו מאפשרת חיפוש יעיל של קבצים לפי שם ולאחר מכן אחזור התכונות שלהם ומיקומי בלוקי הנתונים באמצעות ה-inode."}, "difficulty_estimation": "Easy", "_source_file": "0678__File_Systems__Open__Easy.json", "_topic_hint": "File Systems", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:31:25", "_subject": "File Systems"}, {"id": 101, "type": "Open", "topic": ["File Systems"], "content": {"text": "הסבר בקצרה את תפקידה העיקרי של מערכת קבצים במערכת הפעלה. ציין שני רכיבים מרכזיים במערכת קבצים ותאר בקצרה את תפקידו של כל אחד מהם.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "תפקידה העיקרי של מערכת קבצים הוא לנהל את אחסון הנתונים הקבוע (persistent storage) על גבי אמצעי אחסון כגון דיסק קשיח. היא מספקת שיטה לארגון קבצים ותיקיות, מאפשרת גישה לנתונים בצורה מופשטת ונוחה למשתמשים וליישומים, ומטפלת בהקצאה ושחרור של מקום בדיסק.\n\nשני רכיבים מרכזיים במערכת קבצים הם:\n1.  **Inode (אינוד)**: מבנה נתונים המכיל את כל המידע (metadata) על קובץ או תיקייה, למעט שמו ותוכנו בפועל. מידע זה כולל הרשאות גישה, בעלות, גודל הקובץ, זמני יצירה ושינוי, ומצביעים לבלוקי הנתונים המכילים את תוכן הקובץ.\n2.  **בלוק נתונים (Data Block)**: יחידת האחסון הבסיסית ביותר בה נשמרים הנתונים בפועל של הקובץ. כל בלוק נתונים מכיל חלק מתוכן הקובץ (או את כולו, אם הקובץ קטן מספיק), והם מקושרים לקובץ באמצעות המצביעים שב-inode שלו."}, "difficulty_estimation": "Easy", "_source_file": "0679__File_Systems__Open__Easy.json", "_topic_hint": "File Systems", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:31:35", "_subject": "File Systems"}, {"id": 10, "type": "Open", "topic": ["File Systems"], "content": {"text": "מהו inode במערכת קבצים? פרטו את המידע העיקרי שמאוחסן ב-inode, והסבירו מדוע הוא חיוני לניהול קבצים במערכת ההפעלה.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "inode (קיצור של index node) הוא מבנה נתונים בסיסי במערכות קבצים, המכיל מטא-דאטה (מידע על מידע) אודות קובץ או תיקייה. ה-inode אינו מכיל את שם הקובץ (שמאוחסן בתיקייה) וגם לא את תוכן הקובץ בפועל (שמאוחסן בבלוקי נתונים).\nהמידע העיקרי המאוחסן ב-inode כולל:\n*   **מספר Inode (Inode number):** מזהה ייחודי עבור ה-inode בתוך מערכת הקבצים.\n*   **סוג הקובץ:** האם זהו קובץ רגיל, תיקייה, קישור סימבולי, התקן בלוקים, התקן תווים, ועוד.\n*   **הרשאות גישה (Permissions):** קובע מי יכול לקרוא, לכתוב או להריץ את הקובץ.\n*   **בעלות (Owner/Group IDs):** מזהי המשתמש והקבוצה הבעלים של הקובץ.\n*   **זמני גישה ושינוי (Timestamps):**\n    *   `atime`: זמן הגישה האחרונה לתוכן הקובץ.\n    *   `mtime`: זמן השינוי האחרון של תוכן הקובץ.\n    *   `ctime`: זמן השינוי האחרון של ה-inode עצמו (לדוגמה, שינוי הרשאות או בעלות).\n*   **מונה קישורים (Link count):** מספר ה-hard links המצביעים ל-inode זה. כאשר מונה זה מגיע ל-0 ואין תהליכים שפתוחים את הקובץ, ה-inode משוחרר והבלוקים שלו ניתנים לשימוש חוזר.\n*   **גודל הקובץ (File size):** גודל הקובץ בבתים.\n*   **מצביעים לבלוקי נתונים (Pointers to data blocks):** רשימת כתובות של בלוקי הנתונים בדיסק המכילים את תוכן הקובץ בפועל.\n\nה-inode חיוני לניהול קבצים מכיוון שהוא מאפשר למערכת ההפעלה:\n1.  **לאתר את תוכן הקובץ:** באמצעות המצביעים לבלוקי הנתונים.\n2.  **לנהל הרשאות ובעלות:** לשלוט בגישה לקובץ.\n3.  **לעקוב אחר סטטוס הקובץ:** לדעת מתי הקובץ נגיש לאחרונה, מתי תוכנו השתנה, או מתי המטא-דאטה שלו השתנה.\n4.  **להפריד בין שם הקובץ לתוכן:** מאפשר למספר שמות קבצים שונים (hard links) להצביע על אותו תוכן פיזי בדיסק, תוך שמירה על עקביות הנתונים."}, "difficulty_estimation": "Easy", "_source_file": "0680__File_Systems__Open__Easy.json", "_topic_hint": "File Systems", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:31:48", "_subject": "File Systems"}, {"id": 10, "type": "Open", "topic": ["File Systems", "Links"], "content": {"text": "נתונה מערכת קבצים מסוג ext4. משתמש יוצר קובץ בשם original.txt עם תוכן כלשהו. לאחר מכן, הוא יוצר קישור קשיח (hard link) בשם hardlink.txt המצביע על original.txt. לבסוף, הוא יוצר קישור רך (soft link / symbolic link) בשם softlink.txt המצביע גם הוא על original.txt.\n\nא. תארו במפורט כיצד מערכת הקבצים מתייחסת לכל אחד מהאובייקטים הללו (original.txt, hardlink.txt, softlink.txt) מבחינת inodes, בלוקי נתונים ורשומות ספריות (directory entries) לאחר כל הפעולות.\nב. לאחר מכן, המשתמש מוחק את הקובץ original.txt. תארו מה קורה למערכת הקבצים (לרבות inodes, בלוקי נתונים, רשומות ספריות) ומה מצבם של hardlink.txt ו-softlink.txt.\nג. לאחר מכן (בהמשך לסעיף ב'), המשתמש מוחק את hardlink.txt. תארו מה קורה למערכת הקבצים ומה מצבו של softlink.txt.\nד. לאחר מכן (בהמשך לסעיף ג'), המשתמש מוחק את softlink.txt. תארו מה קורה למערכת הקבצים.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. לאחר יצירת original.txt:\n    - נוצר inode חדש עבור הקובץ. ה-inode מכיל מטא-דאטה (בעלים, הרשאות, גודל, זמנים) ומצביעים לבלוקי הנתונים של הקובץ.\n    - נוצרים בלוקי נתונים עבור תוכן הקובץ.\n    - נוצרת רשומת ספרייה בתיקייה הנוכחית המקשרת את השם original.txt ל-inode מספר X.\n    - מונה הקישורים (link count) ב-inode X מוגדר ל-1.\n\n    לאחר יצירת hardlink.txt:\n    - לא נוצר inode חדש ולא נוצרים בלוקי נתונים חדשים. קישור קשיח הוא פשוט שם נוסף לאותו inode.\n    - נוצרת רשומת ספרייה חדשה בתיקייה הנוכחית המקשרת את השם hardlink.txt לאותו inode מספר X.\n    - מונה הקישורים (link count) ב-inode X עולה ל-2.\n\n    לאחר יצירת softlink.txt:\n    - נוצר inode חדש (נניח inode Y) עבור הקישור הרך עצמו. ה-inode Y הוא מסוג 'קישור סימבולי'.\n    - נוצר בלוק נתונים אחד (או יותר, תלוי באורך הנתיב) המכיל את הנתיב המלא לקובץ המקורי (original.txt).\n    - נוצרת רשומת ספרייה חדשה בתיקייה הנוכחית המקשרת את השם softlink.txt ל-inode Y.\n    - מונה הקישורים ב-inode Y מוגדר ל-1. מונה הקישורים ב-inode X נשאר 2.\n\nב. מחיקת original.txt:\n    - רשומת הספרייה עבור original.txt נמחקת מהתיקייה.\n    - מונה הקישורים (link count) ב-inode X יורד מ-2 ל-1.\n    - ה-inode X ובלוקי הנתונים שלו לא משוחררים עדיין, מכיוון שמונה הקישורים עדיין גדול מ-0 (בגלל hardlink.txt).\n    - hardlink.txt עדיין קיים ונגיש, ומצביע לאותו inode X. הקובץ ותוכנו עדיין קיימים ונגישים דרך hardlink.txt.\n    - softlink.txt עדיין קיים, אך הוא מצביע על נתיב שכבר לא קיים (original.txt). לכן, הקישור הופך ל'קישור שבור' (dangling link). ניסיון לגשת דרך softlink.txt ייכשל עם שגיאה (למשל, \"No such file or directory\").\n\nג. מחיקת hardlink.txt (לאחר מחיקת original.txt):\n    - רשומת הספרייה עבור hardlink.txt נמחקת מהתיקייה.\n    - מונה הקישורים (link count) ב-inode X יורד מ-1 ל-0.\n    - מכיוון שמונה הקישורים של inode X הגיע ל-0, ה-inode X מסומן כפנוי, ובלוקי הנתונים שהוא הצביע עליהם מסומנים גם הם כפנויים וזמינים לשימוש חוזר.\n    - הקובץ ותוכנו נמחקו סופית ממערכת הקבצים.\n    - softlink.txt עדיין קיים ומצביע על נתיב שכבר לא קיים, והוא נשאר קישור שבור. לא חל שינוי במצבו של softlink.txt כתוצאה ממחיקת hardlink.txt.\n\nד. מחיקת softlink.txt (לאחר מחיקת original.txt ו-hardlink.txt):\n    - רשומת הספרייה עבור softlink.txt נמחקת מהתיקייה.\n    - מונה הקישורים (link count) ב-inode Y (של הקישור הרך) יורד מ-1 ל-0.\n    - מכיוון שמונה הקישורים של inode Y הגיע ל-0, ה-inode Y מסומן כפנוי, ובלוקי הנתונים שהוא הצביע עליהם (שכבר הכילו את הנתיב original.txt) מסומנים גם הם כפנויים וזמינים לשימוש חוזר.\n    - הקישור הרך נמחק סופית ממערכת הקבצים.\n", "difficulty_estimation": "Medium"}, "_source_file": "0681__File_Systems__Open__Medium.json", "_topic_hint": "File Systems", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:32:04", "_subject": "File Systems"}, {"id": 1, "type": "Open", "topic": ["File Systems"], "content": {"text": "נתונה מערכת קבצים חדשה וריקה. גודל בלוק במערכת הקבצים הוא 4KB. משתמש מבצע את הפעולות הבאות בסדר כרונולוגי:\n1. יוצר קובץ בשם `original.txt` המכיל את הטקסט \"Hello Operating Systems!\" (גודל הטקסט הוא 27 בתים).\n2. יוצר קישור קשיח (hard link) בשם `hardlink.txt` המצביע אל `original.txt`.\n3. יוצר קישור רך (soft link / symbolic link) בשם `softlink.txt` המצביע אל `original.txt`.\n4. מוחק את הקובץ `original.txt`.\n\nענה על השאלות הבאות, תוך פירוט ההסבר לכל שלב:\nא. כמה inodes וכמה בלוקי נתונים (data blocks) יהיו בשימוש לאחר סיום פעולה 3? נמק.\nב. תאר מה קורה במערכת הקבצים (ברמת ה-inodes והבלוקים) כאשר מבוצעת פעולה 4. נמק.\nג. מה תהיה התוצאה של ניסיון לקרוא את התוכן של `hardlink.txt` לאחר פעולה 4? נמק.\nד. מה תהיה התוצאה של ניסיון לקרוא את התוכן של `softlink.txt` לאחר פעולה 4? נמק.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. לאחר סיום פעולה 3:\n   - הקובץ `original.txt` דורש inode אחד (לאחסון מטא-דאטה כמו הרשאות, בעלים, זמנים) ובלוק נתונים אחד (4KB) לאחסון התוכן \"Hello Operating Systems!\". גודל התוכן (27 בתים) קטן מבלוק אחד, ולכן נדרש בלוק אחד בלבד.\n   - הקישור הקשיח `hardlink.txt` אינו דורש inode חדש או בלוק נתונים חדש. הוא בסך הכל יוצר כניסה חדשה בספרייה המצביעה לאותו inode של `original.txt`. מונה הקישורים (link count) של ה-inode המקורי גדל ל-2 (כעת גם `original.txt` וגם `hardlink.txt` מצביעים אליו).\n   - הקישור הרך `softlink.txt` דורש inode חדש משלו, מכיוון שהוא קובץ מסוג מיוחד ( symbolic link). בנוסף, הוא דורש בלוק נתונים אחד לאחסון המחרוזת של הנתיב אליו הוא מצביע (\"original.txt\"). אורך המחרוזת הוא 12 בתים, הנכנסים בבלוק נתונים אחד.\n   - סך הכל בשימוש: 2 inodes (אחד עבור הקובץ המקורי/קישור קשיח, ואחד עבור הקישור הרך) ו-2 בלוקי נתונים (אחד עבור תוכן הקובץ, ואחד עבור הנתיב של הקישור הרך).\n\nב. כאשר מבוצעת פעולה 4 (מחיקת `original.txt`):\n   - כניסת הספרייה עבור `original.txt` מוסרת מהספרייה הראשית.\n   - מונה הקישורים (link count) של ה-inode אליו הצביעו `original.txt` וגם `hardlink.txt` מופחת ב-1 (מ-2 ל-1). מונה הקישורים מציין כמה שמות קבצים שונים מצביעים לאותו inode.\n   - ה-inode ובלוק הנתונים המכיל את התוכן \"Hello Operating Systems!\" אינם משוחררים ואינם נמחקים, מכיוון שמונה הקישורים עדיין גדול מ-0 (הוא 1, בגלל `hardlink.txt`). הנתונים עדיין נגישים דרך הקישור הקשיח.\n   - ה-inode ובלוק הנתונים של `softlink.txt` אינם מושפעים כלל, מכיוון שהם קיימים באופן עצמאי.\n\nג. ניסיון לקרוא את התוכן של `hardlink.txt` לאחר פעולה 4:\n   - הקריאה תצליח. `hardlink.txt` עדיין מצביע ל-inode המקורי. מכיוון שמונה הקישורים של ה-inode עדיין 1, ה-inode ובלוק הנתונים שלו נותרו שלמים ונגישים. מערכת הקבצים עדיין רואה את הקובץ כקיים דרך הקישור הקשיח. התוכן \"Hello Operating Systems!\" ייקרא בהצלחה.\n\nד. ניסיון לקרוא את התוכן של `softlink.txt` לאחר פעולה 4:\n   - הקריאה תיכשל. `softlink.txt` מכיל את הנתיב \"original.txt\". כאשר מערכת ההפעלה תנסה לפתור נתיב זה, היא תגלה שהקובץ `original.txt` אינו קיים עוד בספרייה. הקישור הרך הפך ל\"קישור שבור\" (dangling link), ומערכת ההפעלה תחזיר שגיאה (לדוגמה, \"No such file or directory\"). הקישור הרך תלוי בקיומו של קובץ היעד. "}, "difficulty_estimation": "Medium", "_source_file": "0682__File_Systems__Open__Medium.json", "_topic_hint": "File Systems", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:32:23", "_subject": "File Systems"}, {"id": 1, "type": "Open", "topic": ["File Systems", "Journaling", "Consistency"], "content": {"text": "משתמש כותב קובץ גדול (מספר ג'יגה-בייטים) למערכת קבצים מסוג ext3 המוגדרת במצב 'ordered' (ברירת המחדל). במהלך הכתיבה, מתרחשת הפסקת חשמל פתאומית.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "תארו מהו המצב הסביר של הקובץ לאחר הפסקת החשמל והפעלת המערכת מחדש. אילו מנגנונים במערכת הקבצים מבטיחים את שלמות המערכת במצב זה?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "מה היה קורה באותו תרחיש אם מערכת הקבצים הייתה מסוג ext2 (ללא Journaling)? פרטו את ההבדלים והסיכונים.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: במצב 'ordered' של ext3, מערכת הקבצים מבטיחה שבלוקי הנתונים (data blocks) יכתבו לדיסק לפני שבלוקי המטא-דאטה (metadata blocks) המצביעים עליהם יכתבו ליומן (journal) וייעשו קומטינג (commit). לאחר הפסקת חשמל והפעלת המערכת מחדש, ה-ext3 תבצע שחזור מהיומן. מכיוון שרק שינויי מטא-דאטה נרשמים ביומן (ולא הנתונים עצמם במצב ordered), היומן ישמש לשחזור עקבי של המטא-דאטה. המצב הסביר של הקובץ יהיה אחד משניים:\n1. הקובץ יופיע כקובץ תקין, אך הוא יהיה קטום (truncated) לגודלו האחרון לפני הכתיבה שהושלמה במלואה ובוצעה לה התחייבות (commit) ליומן. כלומר, החלקים שנכתבו אך לא הספיקו להתחייב, לא יופיעו בקובץ.\n2. במקרה שבלוקי נתונים נכתבו אך המטא-דאטה לא הספיקה להתעדכן כלל, הבלוקים הללו יהפכו לבלוקים \"אבודים\" (lost blocks) שניתן למצוא אותם בעזרת כלי כמו `fsck` ולשחזר אותם (אם כי לרוב הם לא יהיו שימושיים).\nהמנגנון שמבטיח את שלמות המערכת הוא ה-Journal. הוא מבטיח שכל שינויי המטא-דאטה יבוצעו באופן אטומי: או שכולם יבוצעו או שאף אחד לא יבוצע. במצב 'ordered', הוא גם מבטיח שהנתונים יהיו על הדיסק לפני שהמטא-דאטה תצביע עליהם, ובכך נמנע מצב שבו המטא-דאטה מצביעה על נתונים לא מעודכנים או \"זבל\" (garbage).\n\n1.2: אם מערכת הקבצים הייתה ext2 (ללא Journaling), התרחיש היה שונה באופן מהותי:\n1. **חוסר עקביות במערכת הקבצים:** ללא יומן, אין דרך פשוטה ובטוחה להבטיח אטומיות של שינויים. הפסקת חשמל עלולה להשאיר את המטא-דאטה במצב לא עקבי, לדוגמה: Inode עודכן כדי להצביע על בלוקי נתונים חדשים, אך מפת הבלוקים הפנויים (free block bitmap) לא עודכנה, מה שגורם לבלוקים אלו להיראות גם פנויים וגם בשימוש (in use). Inode לא עודכן, אך בלוקי נתונים נכתבו, מה שגורם לבלוקים להיות \"אבודים\" (לא מקושרים לאף קובץ). מפת הבלוקים הפנויים עודכנה, אך ה-inode לא (או להפך), מה שמוביל לנתונים שגויים או בלוקים דלופים (leaked blocks).\n2. **צורך ב-`fsck`:** לאחר הפסקת חשמל, חובה להריץ את כלי ה-`fsck` (File System Check) כדי לסרוק את כל מערכת הקבצים, לזהות ולתקן אי-עקביויות. תהליך זה יכול להיות ארוך מאוד (תלוי בגודל מערכת הקבצים) ובמהלכו מערכת הקבצים אינה זמינה.\n3. **אובדן נתונים וקורפציה:** קיים סיכון גבוה יותר לאובדן נתונים או לקורפציה של קבצים. ייתכן שהקובץ יהיה פגום, יכיל מידע חלקי או שגוי, או שחלקים ממנו יהפכו לבלוקים אבודים. במקרים חמורים, אי-עקביות עלולה להוביל לקריסת מערכת הקבצים כולה או לחוסר יכולת לעלות (mount) אותה.\nההבדל המרכזי הוא ש-ext3 עם journaling מספקת הבטחה חזקה יותר לעקביות המטא-דאטה וזמן שחזור מהיר לאחר קריסה, בעוד ext2 מסתמכת על סריקה מלאה ופגיעה יותר לאובדן נתונים."}, "difficulty_estimation": "Medium", "_source_file": "0683__File_Systems__Open__Medium.json", "_topic_hint": "File Systems", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:32:42", "_subject": "File Systems"}, {"id": 10, "type": "Open", "topic": ["File Systems"], "content": {"text": "מערכות קבצים מתורגלות (Journaling File Systems) הן מרכיב חיוני במערכות הפעלה מודרניות לשמירה על עקביות הנתונים.\nא. הסבירו מהי מטרת ה-Journaling במערכות קבצים.\nב. תארו את השלבים העיקריים של פעולת כתיבה טיפוסית (לדוגמה, יצירת קובץ חדש וכתיבת נתונים ראשוניים אליו) במערכת קבצים מתורגלת.\nג. השוו בין שלושת מצבי ה-Journaling העיקריים: Writeback, Ordered ו-Data (או Full). התייחסו להבדלים ביניהם מבחינת ביצועים (Performance) ושלמות הנתונים (Data Integrity) במקרה של קריסת מערכת.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. מטרת ה-Journaling היא להבטיח את עקביות מערכת הקבצים במקרה של קריסת מערכת או הפסקת חשמל פתאומית. במקום לבצע בדיקה יקרה וארוכה של כל מערכת הקבצים (כמו fsck), ה-Journal מאפשר לשחזר את מצב מערכת הקבצים למצב עקבי האחרון על ידי שחזור או ביטול עסקאות (Transactions) שלא הושלמו במלואן.\n\nב. שלבי פעולת כתיבה טיפוסית (יצירת קובץ וכתיבת נתונים):\n1.  **יצירת טרנזקציה (Transaction):** מערכת הקבצים יוצרת טרנזקציה חדשה עבור פעולת הכתיבה.\n2.  **רישום ל-Journal (Journaling):** כל השינויים במטא-דאטה (metadata) של מערכת הקבצים (לדוגמה, הקצאת inode חדש, יצירת ערך חדש בתיקייה, הקצאת בלוקי נתונים) נרשמים ל-Journal (יומן) לפני שהם מיושמים למקומם הסופי בדיסק.\n3.  **כתיבת נתונים (Data Write):** הנתונים עצמם נכתבים לבלוקי הנתונים המוקצים בדיסק. מיקום כתיבת הנתונים ביחס ל-Journal תלוי במצב ה-Journaling (ראו סעיף ג').\n4.  **יישום שינויים למערכת הקבצים (Apply Changes):** לאחר שהשינויים נרשמו ב-Journal (ובמצבים מסוימים, גם הנתונים נכתבו), המטא-דאטה מיושם למקומותיו הסופיים במבני מערכת הקבצים על הדיסק (לדוגמה, ה-inode החדש נכתב לטבלת ה-inodes).\n5.  **אישור טרנזקציה (Commit Transaction):** ברגע שכל השינויים הרלוונטיים נרשמו ב-Journal או יושמו למערכת הקבצים (תלוי במצב), הטרנזקציה מסומנת כ\"בוצעה בהצלחה\" (committed) ב-Journal. אם קריסה מתרחשת לפני ה-commit, הטרנזקציה תבוטל או תשוחזר.\n\nג. השוואה בין מצבי Journaling:\n*   **Writeback Journaling:**\n    *   **ביצועים:** הגבוהים ביותר. רק מטא-דאטה נרשם ל-Journal. נתוני הקובץ נכתבים ישירות למקומם הסופי בדיסק, ולרוב אין סדר מסוים בין כתיבת הנתונים לכתיבת המטא-דאטה ל-Journal.\n    *   **שלמות נתונים:** הנמוכה ביותר מבין השלושה. במקרה של קריסה, מערכת הקבצים תהיה עקבית מבחינת המבנה שלה (metadata), אך ייתכן שנתוני הקובץ יהיו לא מעודכנים או יכילו נתונים שגויים (\"stale data\" או \"garbage data\"), מכיוון שהמטא-דאטה יכול להצביע על בלוקים שטרם הכילו את הנתונים החדשים.\n*   **Ordered Journaling:**\n    *   **ביצועים:** בינוניים. נתוני הקובץ נכתבים למקומם הסופי בדיסק *לפני* שהמטא-דאטה המצביע עליהם נרשם ל-Journal. רק מטא-דאטה נרשם ל-Journal.\n    *   **שלמות נתונים:** בינונית. במקרה של קריסה, מובטח שכל הנתונים אליהם מצביע המטא-דאטה יהיו נכונים (או לפחות הנתונים שהיו שם לפני הפעולה). לא יהיה מצב שבו המטא-דאטה מצביע על נתונים שגויים. עם זאת, ייתכן שחלק מהנתונים שטרם נרשמו ל-Journal יאבדו, אך המערכת תישאר עקבית.\n*   **Data (Full) Journaling:**\n    *   **ביצועים:** הנמוכים ביותר. גם מטא-דאטה וגם נתוני הקובץ נרשמים ל-Journal לפני שהם נכתבים למקומם הסופי בדיסק. זה כרוך בכתיבה כפולה של הנתונים (פעם ל-Journal ופעם למקומם הסופי).\n    *   **שלמות נתונים:** הגבוהה ביותר. במקרה של קריסה, מובטח שגם מבנה מערכת הקבצים וגם תוכן הקבצים יהיו עקביים לחלוטין. זה המצב הבטוח ביותר אך גם האיטי ביותר."}, "difficulty_estimation": "Medium", "_source_file": "0684__File_Systems__Open__Medium.json", "_topic_hint": "File Systems", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:32:59", "_subject": "File Systems"}, {"id": 1, "type": "Open", "topic": ["File Systems"], "content": {"text": "משתמש יוצר קובץ חדש במערכת קבצים מסוג ext4. לאחר מכן, הוא יוצר hard link לקובץ זה, ולאחר מכן symbolic link לאותו קובץ. תארו בפירוט מה מתרחש ברמת מערכת הקבצים (inodes, בלוקי נתונים, ספריות) בכל אחד מהשלבים הללו. כמו כן, הסבירו מה יקרה במקרים הבאים (בנפרד, בהתבסס על המצב הסופי לאחר יצירת כל הקישורים): א. המשתמש מוחק את הקובץ המקורי. ב. המשתמש מוחק את ה-hard link. ג. המשתמש מוחק את ה-symbolic link. נמקו את תשובותיכם.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסבר מפורט על השלבים:\n\n1.  **יצירת הקובץ המקורי (לדוגמה, 'original_file.txt'):**\n    *   מערכת הקבצים מקצה inode חדש עבור הקובץ. ה-inode מכיל מטא-דאטה כגון בעלות, הרשאות, גודל, זמני גישה/שינוי, ומצביעים לבלוקי הנתונים. מונים ה-link count (מספר הקישורים לאותו inode) מאותחל ל-1.\n    *   מוקצים בלוקי נתונים מהדיסק לאחסון תוכן הקובץ, והמצביעים ב-inode מתעדכנים.\n    *   נוצרת רשומת ספרייה (directory entry) בספרייה שבה נוצר הקובץ. רשומה זו מקשרת את שם הקובץ ('original_file.txt') למספר ה-inode שלו.\n\n2.  **יצירת Hard Link (לדוגמה, 'hard_link.txt'):**\n    *   נוצרת רשומת ספרייה חדשה בספרייה הנוכחית (או אחרת), המקשרת את השם החדש ('hard_link.txt') *לאותו מספר inode* של הקובץ המקורי. כלומר, שני שמות הקבצים מצביעים על אותו inode.\n    *   מונה ה-link count ב-inode המשותף גדל ל-2.\n    *   לא מוקצים inodes או בלוקי נתונים חדשים עבור ה-hard link עצמו, מכיוון שהוא רק שם נוסף לאותו inode ונתונים קיימים.\n\n3.  **יצירת Symbolic Link (Soft Link) (לדוגמה, 'soft_link.txt'):**\n    *   מערכת הקבצים מקצה inode *חדש* עבור ה-symbolic link. זהו inode שונה לחלוטין מה-inode של הקובץ המקורי.\n    *   מוקצים בלוקי נתונים עבור ה-inode החדש של ה-symbolic link. בלוקי נתונים אלה *אינם* מכילים את תוכן הקובץ המקורי, אלא את ה-*נתיב* (path) לקובץ המקורי ('original_file.txt').\n    *   נוצרת רשומת ספרייה חדשה המקשרת את השם ('soft_link.txt') למספר ה-inode של ה-symbolic link.\n    *   מונה ה-link count של ה-inode של ה-symbolic link מאותחל ל-1. מונה ה-link count של ה-inode של הקובץ המקורי נשאר 2.\n\n**השפעות מחיקה (בהתבסס על המצב הסופי):**\n\nא. **מחיקת הקובץ המקורי ('original_file.txt'):**\n    *   רשומת הספרייה של 'original_file.txt' נמחקת. \n    *   מונה ה-link count של ה-inode המשותף (עבור 'original_file.txt' ו-'hard_link.txt') יורד מ-2 ל-1.\n    *   מכיוון שמונה ה-link count עדיין גדול מ-0 (הוא 1, בגלל ה-hard link), ה-inode ובלוקי הנתונים שלו *לא משוחררים*. הקובץ עדיין נגיש במלואו דרך ה-hard link ('hard_link.txt').\n    *   ה-symbolic link ('soft_link.txt') הופך ל-'קישור תלוי' (dangling link) או 'קישור שבור' (broken link), מכיוון שהוא עדיין מצביע לנתיב 'original_file.txt' שאינו קיים עוד כרשומת ספרייה, ולכן ניסיון גישה דרכו ייכשל (או יצביע על קובץ אחר אם נוצר קובץ חדש באותו נתיב).\n\nב. **מחיקת ה-Hard Link ('hard_link.txt'):**\n    *   רשומת הספרייה של 'hard_link.txt' נמחקת.\n    *   מונה ה-link count של ה-inode המשותף יורד מ-2 ל-1.\n    *   ה-inode ובלוקי הנתונים שלו *לא משוחררים*, מכיוון שהקובץ המקורי ('original_file.txt') עדיין קיים ומונה ה-link count הוא 1. הקובץ עדיין נגיש דרך 'original_file.txt'.\n    *   ה-symbolic link ('soft_link.txt') ממשיך לפעול כרגיל, מכיוון שהוא מצביע לנתיב של הקובץ המקורי שעדיין קיים.\n\nג. **מחיקת ה-Symbolic Link ('soft_link.txt'):**\n    *   רשומת הספרייה של 'soft_link.txt' נמחקת.\n    *   מונה ה-link count של ה-inode של ה-symbolic link יורד מ-1 ל-0.\n    *   ה-inode של ה-symbolic link ובלוקי הנתונים שלו (שמכילים את הנתיב לקובץ המקורי) *משוחררים* בחזרה למערכת הקבצים.\n    *   הקובץ המקורי ('original_file.txt') וה-hard link שלו ('hard_link.txt') *אינם מושפעים כלל* ונותרים שלמים ונגישים, מכיוון שמחיקת symbolic link משפיעה רק על הקישור עצמו ולא על היעד שאליו הוא מצביע."}, "difficulty_estimation": "Medium", "_source_file": "0685__File_Systems__Open__Medium.json", "_topic_hint": "File Systems", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:33:19", "_subject": "File Systems"}, {"id": 10, "type": "Open", "topic": ["File Systems"], "content": {"text": "משתמש חדש מתקין מערכת קבצים חדשה ומתכנן לאחסן בה שני סוגי קבצים עיקריים: אלפי קבצים קטנים מאוד (בגודל של מספר בתים בודדים) וקובץ אחד גדול מאוד (בגודל של מאות ג'יגה-בייט). הניחו שגודל הבלוק במערכת הקבצים הוא 4KB. נתחו והשוו את שיטות הקצאת הבלוקים הבאות (Contiguous, Linked, Indexed) בהתייחס לאופן שבו הן יתמודדו עם אתגרי אחסון אלו. התייחסו לשיקולים הבאים עבור כל שיטה:\n1. ניצול שטח דיסק (פנימי וחיצוני).\n2. ביצועי קריאה/כתיבה סדרתית.\n3. ביצועי קריאה/כתיבה אקראית.\n4. מורכבות ניהול ה-metadata.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "להלן ניתוח והשוואה של שיטות הקצאת הבלוקים השונות בהתייחס לתרחיש הנתון:\n\n**1. הקצאה רציפה (Contiguous Allocation):**\n*   **ניצול שטח דיסק:**\n    *   **קבצים קטנים:** סובלת מפרגמנטציה פנימית גבוהה (כל קובץ, גם אם הוא בגודל בתים בודדים, יתפוס בלוק שלם – 4KB). \n    *   **קובץ גדול:** סובלת קשות מפרגמנטציה חיצונית. קשה מאוד למצוא רצף של מאות ג'יגה-בייט של בלוקים פנויים על הדיסק, במיוחד לאחר שימוש מסוים במערכת הקבצים. אם נמצא רצף כזה, אין פרגמנטציה פנימית למעט הבלוק האחרון אם גודל הקובץ אינו כפולה של גודל הבלוק.\n*   **ביצועי קריאה/כתיבה סדרתית:** מצוינים. הבלוקים רציפים פיזית על הדיסק, ולכן ניתן לקרוא/לכתוב אותם ביעילות עם מינימום תזוזות ראש הקריאה/כתיבה (seek time).\n*   **ביצועי קריאה/כתיבה אקראית:** מצוינים. מיקום כל בלוק ניתן לחישוב ישירות (כתובת התחלה + היסט), מה שמאפשר גישה ישירה ומהירה לכל חלק בקובץ.\n*   **מורכבות ניהול ה-metadata:** פשוטה. נדרשים רק כתובת הבלוק הראשון ואורך הקובץ (בבלוקים).\n\n**2. הקצאה מקושרת (Linked Allocation):**\n*   **ניצול שטח דיסק:**\n    *   **קבצים קטנים וגדולים:** כמעט ללא פרגמנטציה חיצונית. פרגמנטציה פנימית מינימלית (רק בבלוק האחרון). עם זאת, לכל בלוק נדרש מצביע לבלוק הבא (או בתוך הבלוק עצמו או בטבלת FAT נפרדת), מה שמפחית את נפח האחסון הזמין לנתונים בתוך הבלוקים.\n*   **ביצועי קריאה/כתיבה סדרתית:** גרועים. כדי לקרוא את הבלוק הבא, יש לקרוא קודם את המצביע מתוך הבלוק הנוכחי, מה שגורם למספר רב של פעולות I/O ו-seekים עבור קריאת קובץ שלם.\n*   **ביצועי קריאה/כתיבה אקראית:** גרועים מאוד. כדי לגשת לבלוק ה-N בקובץ, יש צורך לעבור על N-1 מצביעים מההתחלה, מה שדורש N פעולות קריאה מהדיסק.\n*   **מורכבות ניהול ה-metadata:** עבור כל קובץ, נדרשים רק מצביע לבלוק הראשון ולבלוק האחרון. אך ניהול המצביעים בתוך הבלוקים או בטבלת FAT מוסיף מורכבות מערכתית.\n\n**3. הקצאה באמצעות אינדקס (Indexed Allocation):**\n*   **ניצול שטח דיסק:**\n    *   **קבצים קטנים:** פרגמנטציה פנימית מינימלית (רק בבלוק האחרון). עם זאת, עבור קבצים קטנים מאוד, שימוש בבלוק אינדקס שלם (4KB) כדי להצביע על בלוק אחד או פחות של נתונים מהווה תקורה משמעותית של שטח דיסק.\n    *   **קובץ גדול:** פרגמנטציה פנימית מינימלית. עבור קבצים גדולים מאוד, בלוק אינדקס יחיד לא יספיק, ויהיה צורך במבני אינדקס מרובי רמות, מה שמוסיף תקורה של שטח דיסק עבור בלוקי האינדקס הנוספים.\n*   **ביצועי קריאה/כתיבה סדרתית:** טובים. בלוק האינדקס נקרא פעם אחת (או חלקים ממנו), ולאחר מכן ניתן לגשת לבלוקי הנתונים ישירות. יעיל בהרבה משיטה מקושרת, וקרוב לביצועים של רציפה אם בלוקי הנתונים קרובים פיזית.\n*   **ביצועי קריאה/כתיבה אקראית:** טובים. קריאת בלוק האינדקס מאפשרת גישה ישירה לכל בלוק נתונים בקובץ, בדרך כלל עם 1-2 פעולות I/O לדיסק (אחת לבלוק האינדקס ואחת לבלוק הנתונים).\n*   **מורכבות ניהול ה-metadata:** מורכבת יותר. דורשת ניהול של בלוקי אינדקס, ופוטנציאלית מבני אינדקס מרובי רמות. האיינוד (inode) בדרך כלל מכיל מצביעים לבלוקי האינדקס.\n\n**סיכום עבור התרחיש הנתון:**\n*   **קבצים קטנים:** הקצאה מקושרת או אינדקסית עדיפות על פני רציפה מבחינת ניצול שטח (למרות תקורת המצביעים/אינדקס), אך אינדקסית עשויה לסבול מתקורה גבוהה מדי של בלוק אינדקס לקובץ קטן. הקצאה רציפה סובלת מפרגמנטציה פנימית גבוהה מאוד.\n*   **קובץ גדול:** הקצאה מקושרת ואינדקסית עדיפות על פני רציפה מבחינת ניצול שטח וגמישות, מכיוון שאינן סובלות מפרגמנטציה חיצונית. מבחינת ביצועים, אינדקסית מציעה איזון טוב בין גישה סדרתית לאקראית, בעוד שמקושרת גרועה לשניהם. רציפה מצוינת בביצועים אך בלתי מעשית לקובץ גדול מאוד על מערכת קבצים פעילה."}, "difficulty_estimation": "Medium", "_source_file": "0686__File_Systems__Open__Medium.json", "_topic_hint": "File Systems", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:33:42", "_subject": "File Systems"}, {"id": 1, "type": "Open", "topic": ["File Systems"], "content": {"text": "נתונה מערכת קבצים המשתמשת במבנה inode הכולל 12 מצביעים ישירים (direct pointers), מצביע עקיף יחיד (single indirect pointer) אחד, ומצביע עקיף כפול (double indirect pointer) אחד. כל מצביע יכול להתייחס לבלוק דיסק. הניחו שגודל הבלוק הוא 4KB (4096 בתים) וגודל של מצביע לבלוק הוא 4 בתים.\n\nא. מהו גודל הקובץ המקסימלי הנתמך על ידי מערכת קבצים זו?\nב. תארו כיצד תתבצע פעולת קריאה לבלוק נתונים הממוקם בקיזוז (offset) גבוה מאוד, לדוגמה, הבלוק ה-100,000 של קובץ. פרטו את מספר גישות הדיסק הנדרשות כדי לאתר את בלוק הנתונים (בהנחה שה-inode כבר בזיכרון).\nג. דון ביתרונות ובחסרונות של מבנה inode זה עבור קבצים בגדלים שונים (קטנים מאוד, בינוניים, גדולים מאוד).", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\nא. גודל הקובץ המקסימלי:\n*   גודל בלוק: 4KB = 4096 בתים.\n*   מספר מצביעים לבלוק בתוך בלוק אחד: 4096 בתים / 4 בתים למצביע = 1024 מצביעים.\n\nחישוב:\n*   מצביעים ישירים (Direct pointers): 12 מצביעים * 4KB לבלוק = 48KB.\n*   מצביע עקיף יחיד (Single indirect pointer): מצביע אחד לבלוק שמכיל 1024 מצביעים לבלוקי נתונים.\n    *   מספר בלוקי נתונים: 1024 בלוקים.\n    *   סה\"כ נתונים: 1024 בלוקים * 4KB לבלוק = 4MB.\n*   מצביע עקיף כפול (Double indirect pointer): מצביע אחד לבלוק שמכיל 1024 מצביעים לבלוקים עקיפים יחידים. כל אחד מהבלוקים העקיפים היחידים מכיל 1024 מצביעים לבלוקי נתונים.\n    *   מספר בלוקי נתונים: 1024 * 1024 בלוקים = 1,048,576 בלוקים.\n    *   סה\"כ נתונים: 1,048,576 בלוקים * 4KB לבלוק = 4GB.\n\nגודל הקובץ המקסימלי הכולל: 48KB + 4MB + 4GB = 4,299,210,752 בתים.\n\nב. פעולת קריאה לבלוק נתונים בקיזוז גבוה (בלוק 100,000):\nהבלוק ה-100,000 נמצא מעבר לטווח המצביעים הישירים (12 בלוקים) ומעבר לטווח המצביע העקיף היחיד (1024 בלוקים). לכן, הוא ימופה באמצעות המצביע העקיף הכפול.\n\nשלבי איתור וקריאת הבלוק (בהנחה שה-inode כבר בזיכרון):\n1.  **גישה לבלוק העקיף הכפול:** קריאת הבלוק שאליו מצביע ה-double indirect pointer ב-inode (גישת דיסק אחת).\n2.  **גישה לבלוק העקיף היחיד:** הבלוק שנקרא בשלב 1 מכיל 1024 מצביעים לבלוקים עקיפים יחידים. נחשב את האינדקס המתאים בתוך בלוק זה כדי למצוא את המצביע לבלוק העקיף היחיד הרצוי, ונבצע קריאה לבלוק זה (גישת דיסק אחת נוספת).\n3.  **גישה לבלוק הנתונים:** הבלוק שנקרא בשלב 2 מכיל 1024 מצביעים לבלוקי נתונים. נחשב את האינדקס המתאים בתוך בלוק זה כדי למצוא את המצביע לבלוק הנתונים הרצוי, ונבצע קריאה לבלוק נתונים זה (גישת דיסק אחת נוספת).\nסה\"כ נדרשות 3 גישות דיסק על מנת לאתר ולקרוא את בלוק הנתונים (בלוק עקיף כפול -> בלוק עקיף יחיד -> בלוק נתונים).\n\nג. יתרונות וחסרונות של מבנה ה-inode עבור קבצים בגדלים שונים:\n\nיתרונות:\n*   **יעילות לקבצים קטנים:** 12 המצביעים הישירים מאפשרים גישה מהירה וישירה לנתונים עבור קבצים קטנים (עד 48KB) עם מינימום גישות דיסק (לרוב רק קריאת ה-inode עצמו). אין צורך בבלוקים נוספים לאחסון מצביעים.\n*   **מדרגיות לקבצים גדולים:** המצביעים העקיפים (יחיד וכפול) מאפשרים לקבצים לגדול לגדלים עצומים (עד 4GB במקרה זה) מבלי לדרוש הקצאה רציפה גדולה מראש על הדיסק, ובכך תומכים בשימוש יעיל בשטח דיסק ובמניעת פיצול פנימי במבנה הקובץ.\n*   **איזון:** המבנה ההיברידי הזה מציע איזון טוב בין ביצועים (לקבצים קטנים) לבין גמישות ומדרגיות (לקבצים גדולים).\n\nחסרונות:\n*   **ביצועים לקבצים גדולים מאוד:** גישה לבלוקי נתונים באמצעות מצביעים עקיפים כפולים (או יותר) דורשת מספר גישות דיסק רק כדי לאתר את בלוק הנתונים עצמו. זה מוביל לביצועי קריאה/כתיבה איטיים יותר עבור קבצים גדולים מאוד בהשוואה למערכת המשתמשת בהקצאה רציפה לחלוטין (אם כי הקצאה רציפה פחות גמישה וסובלת מבעיות פיצול). \n*   **תקורה לקבצים בינוניים:** קובץ שצריך רק בלוק אחד מהמצביע העקיף היחיד, לדוגמה, עדיין דורש בלוק נוסף אחד לאחסון המצביעים, מה שמוסיף תקורה מסוימת.\n*   **מורכבות:** המבנה מורכב יותר ליישום ולניהול בהשוואה לשיטות הקצאה פשוטות יותר."}, "difficulty_estimation": "Medium", "_source_file": "0687__File_Systems__Open__Medium.json", "_topic_hint": "File Systems", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:34:06", "_subject": "File Systems"}, {"id": 10, "type": "Open", "topic": ["File Systems", "Fragmentation", "Disk Allocation"], "content": {"text": "נתונה מערכת קבצים פשוטה המשתמשת בהקצאה רציפה (contiguous allocation) של בלוקים. גודל בלוק הוא 4KB. הדיסק כולל 100 בלוקים זמינים של DATA, ומערכת הקבצים מתחילה כאשר כל הבלוקים פנויים ורצופים (בלוקים 0-99). בוצעו הפעולות הבאות:\n1. נוצר קובץ A בגודל 10KB.\n2. נוצר קובץ B בגודל 5KB.\n3. נוצר קובץ C בגודל 14KB.\n4. קובץ B נמחק.\n5. נוצר קובץ D בגודל 7KB.\n\nא. תאר את מצב בלוקי ה-DATA הפנויים והתפוסים לאחר כל שלב. ציין במפורש את מספרי הבלוקים.\nב. האם נוצרה פרגמנטציה פנימית או חיצונית? אם כן, היכן ומתי? חשב את גודל הפרגמנטציה הפנימית עבור כל קובץ שנוצר.\nג. האם קובץ D הצליח להיווצר? אם כן, היכן הוא ממוקם? אם לא, מדוע?", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "פתרון:\n\nגודל בלוק: 4KB.\nסה\"כ בלוקים: 100 (ממוספרים 0-99).\n\nא. מצב בלוקי ה-DATA לאחר כל שלב:\n\n**מצב התחלתי:**\n*   בלוקים פנויים: 0-99 (100 בלוקים).\n*   בלוקים תפוסים: אין.\n\n**לאחר שלב 1 (קובץ A, גודל 10KB):**\n*   קובץ A דורש ceil(10KB / 4KB) = 3 בלוקים. הוא מקבל את הבלוקים הרצופים הראשונים הזמינים.\n*   בלוקים תפוסים: A תופס את בלוקים 0, 1, 2.\n*   בלוקים פנויים: 3-99 (97 בלוקים).\n\n**לאחר שלב 2 (קובץ B, גודל 5KB):**\n*   קובץ B דורש ceil(5KB / 4KB) = 2 בלוקים.\n*   בלוקים תפוסים: A תופס 0, 1, 2. B תופס 3, 4.\n*   בלוקים פנויים: 5-99 (95 בלוקים).\n\n**לאחר שלב 3 (קובץ C, גודל 14KB):**\n*   קובץ C דורש ceil(14KB / 4KB) = 4 בלוקים.\n*   בלוקים תפוסים: A תופס 0, 1, 2. B תופס 3, 4. C תופס 5, 6, 7, 8.\n*   בלוקים פנויים: 9-99 (91 בלוקים).\n\n**לאחר שלב 4 (קובץ B נמחק):**\n*   הבלוקים של קובץ B (3, 4) משתחררים.\n*   בלוקים תפוסים: A תופס 0, 1, 2. C תופס 5, 6, 7, 8.\n*   בלוקים פנויים: 3, 4 (2 בלוקים) ו-9-99 (91 בלוקים). סה\"כ 93 בלוקים פנויים.\n\n**לאחר שלב 5 (קובץ D, גודל 7KB):**\n*   קובץ D דורש ceil(7KB / 4KB) = 2 בלוקים. מערכת הקבצים תחפש מקום רציף של 2 בלוקים.\n*   היא תמצא את הבלוקים 3, 4 שהתפנו.\n*   בלוקים תפוסים: A תופס 0, 1, 2. D תופס 3, 4. C תופס 5, 6, 7, 8.\n*   בלוקים פנויים: 9-99 (91 בלוקים). סה\"כ 91 בלוקים פנויים.\n\nב. פרגמנטציה:\n\n**פרגמנטציה פנימית (Internal Fragmentation):** נוצרת כאשר גודל הקובץ אינו כפולה מדויקת של גודל הבלוק, ובלוקים מוקצים לקובץ אך לא מנוצלים במלואם.\n*   **קובץ A (10KB):** הוקצו 3 בלוקים (12KB). פרגמנטציה פנימית: 12KB - 10KB = 2KB.\n*   **קובץ B (5KB):** הוקצו 2 בלוקים (8KB). פרגמנטציה פנימית: 8KB - 5KB = 3KB.\n*   **קובץ C (14KB):** הוקצו 4 בלוקים (16KB). פרגמנטציה פנימית: 16KB - 14KB = 2KB.\n*   **קובץ D (7KB):** הוקצו 2 בלוקים (8KB). פרגמנטציה פנימית: 8KB - 7KB = 1KB.\n\n**פרגמנטציה חיצונית (External Fragmentation):** נוצרת כאשר קיימים מספיק בלוקים פנויים בסך הכל כדי לאחסן קובץ, אך הם אינם רצופים (כלומר, קיימים בלוקים תפוסים המפרידים בין בלוקים פנויים), ולכן לא ניתן להקצות מקום לקובץ המצריך מקטע רציף גדול יותר.\n*   פרגמנטציה חיצונית נוצרה **לאחר שלב 4**, כאשר קובץ B נמחק. לפני מחיקת B, כל הבלוקים הפנויים (9-99) היוו מקטע רציף אחד. לאחר מחיקת B, נוצרו שני מקטעים פנויים רצופים נפרדים: (3, 4) ו-(9-99). למרות שסה\"כ יש 93 בלוקים פנויים, הם אינם יוצרים מקטע רציף אחד של 93 בלוקים.\n\nג. יצירת קובץ D:\n\nכן, קובץ D **הצליח להיווצר**.\nקובץ D דורש 2 בלוקים רצופים. לאחר מחיקת קובץ B בשלב 4, הבלוקים 3 ו-4 התפנו ויצרו מקטע רציף של 2 בלוקים. מערכת הקבצים השתמשה במקטע זה כדי לאחסן את קובץ D. לכן, קובץ D ממוקם בבלוקים 3, 4."}, "difficulty_estimation": "Medium", "_source_file": "0688__File_Systems__Open__Medium.json", "_topic_hint": "File Systems", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:34:28", "_subject": "File Systems"}, {"id": 9, "type": "Open", "topic": ["File Systems", "NAND Flash", "SSD", "Wear Leveling", "Garbage Collection"], "content": {"text": "נתונה מערכת קבצים חדשה בשם \"FlashFS\", המתוכננת במיוחד עבור התקני אחסון מסוג NAND Flash (כונני SSD). מטרת המערכת היא למזער את הגברת הכתיבה (write amplification) ולהאריך את חיי ההתקן על ידי יישום אסטרטגיות מתאימות. FlashFS משתמשת בשכבת תרגום פלאש (FTL - Flash Translation Layer) הממפה בלוקים לוגיים לבלוקים פיזיים, ומאפשרת כתיבה מחוץ למקום (out-of-place writes).\n\nנתונים:\n*   גודל עמוד (Page Size): 4KB (יחידת הכתיבה הקטנה ביותר).\n*   גודל בלוק מחיקה (Erase Block Size): 256KB (יחידת המחיקה הקטנה ביותר).\n*   כל בלוק מחיקה מכיל 64 עמודים (256KB / 4KB).\n*   מנגנון ה-FTL מאפשר מיפוי מלא (fully associative mapping) של בלוקים לוגיים לבלוקים פיזיים.\n*   ה-FTL מנהל רשימות של בלוקים ריקים (free blocks), בלוקים פעילים (active blocks) ובלוקים מיושנים (obsolete blocks).\n*   מנגנון איסוף הזבל (Garbage Collection) מופעל כאשר מספר הבלוקים הריקים יורד מתחת לסף מסוים.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "9.1", "text": "FlashFS מיישמת מנגנון איזון בלאי (wear leveling) כדי להאריך את חיי ה-SSD.\nא. הסבירו בקצרה מהו wear leveling, מדוע הוא קריטי ב-NAND Flash, ותארו שני סוגים עיקריים שלו (סטטי ודינמי).\nב. תארו כיצד FlashFS יכולה ליישם wear leveling דינמי יעיל. מהם היתרונות והחסרונות של גישה זו בהקשר של FlashFS?", "code_snippet": null, "options": null}, {"id": "9.2", "text": "משתמש מבצע עדכון לוגי של 4KB נתונים בעמוד קיים בקובץ. העמוד הלוגי ממופה כרגע לעמוד פיזי P1 בבלוק מחיקה B1.\nא. תארו את רצף הפעולות הפיזיות (קריאה, כתיבה, מחיקה) הנדרשות על ידי ה-FTL וה-FlashFS כדי לבצע את העדכון, בהנחה שאין מספיק עמודים ריקים בבלוק הפעיל הנוכחי, ונדרש להפעיל איסוף זבל (Garbage Collection) על בלוק B_GC שנבחר. בלוק B_GC מכיל 50% עמודים תקפים ו-50% עמודים מיושנים.\nב. חשבו את גורם הגברת הכתיבה (Write Amplification Factor - WAF) עבור פעולת העדכון המתוארת בסעיף א'. הראו את החישוב המלא ונמקו. (התעלמו מפעולות קריאה של מטא-דאטה שגרתיות).", "code_snippet": null, "options": null}, {"id": "9.3", "text": "התקני SSD רבים כוללים שטח אחסון נוסף המכונה \"over-provisioning\".\nא. הסבירו מהו over-provisioning וכיצד הוא תורם לשיפור הביצועים ואורך חיי ה-SSD במערכת קבצים כמו FlashFS.\nב. הציעו דוגמה מספרית (באחוזים) של over-provisioning וציינו אילו פרמטרים של מערכת הקבצים או דפוסי השימוש יכולים להשפיע על הבחירה באחוז זה.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון לשאלה 9:\n\n**פתרון לסעיף 9.1.א. (Wear Leveling)**\n*   **מהו Wear Leveling ומדוע הוא קריטי:** NAND Flash הוא התקן בעל אורך חיים מוגבל, כאשר כל בלוק מחיקה יכול לעמוד במספר מוגבל של מחזורי מחיקה/כתיבה (Program/Erase cycles - P/E cycles) לפני שהוא נשחק ונהרס. ללא מנגנון מיוחד, בלוקים מסוימים שבהם נכתבים נתונים בתדירות גבוהה (לדוגמה, בלוקים המכילים מטא-דאטה של מערכת הקבצים או קבצים זמניים) יישחקו מהר יותר מאחרים, ויגרמו לכשל מוקדם של כל ההתקן. Wear leveling הוא מנגנון שמטרתו לפזר את פעולות הכתיבה/מחיקה באופן אחיד על פני כל הבלוקים הפיזיים בהתקן, ובכך להאריך את חיי ה-SSD כולו.\n*   **סוגים עיקריים:**\n    *   **Wear Leveling סטטי (Static Wear Leveling):** מנגנון זה מפקח גם על בלוקים המכילים נתונים \"קרים\" (שאינם משתנים לעיתים קרובות). אם בלוק כזה לא נכתב מחדש במשך זמן רב, ובלוקים אחרים נשחקים במהירות, המערכת תעתיק את הנתונים מהבלוק הקר לבלוק אחר עם ספירת P/E נמוכה יותר, ותשחרר את הבלוק הקר כדי שיוכל לשמש לנתונים \"חמים\" (שמשתנים בתדירות גבוהה). זה מאריך את חיי ה-SSD בצורה הטובה ביותר אך דורש פעולות העתקה נוספות.\n    *   **Wear Leveling דינמי (Dynamic Wear Leveling):** מנגנון זה מתמקד בעיקר בבלוקים המכילים נתונים \"חמים\" (שמשתנים לעיתים קרובות). ה-FTL עוקב אחר ספירת ה-P/E של בלוקים פנויים (או בלוקים שיש בהם נתונים שמשתנים). כאשר נדרשת כתיבה לוגית חדשה, ה-FTL יבחר בלוק פיזי פנוי עם ספירת ה-P/E הנמוכה ביותר מבין הבלוקים הזמינים. גישה זו פשוטה יותר ליישום אך אינה מונעת שחיקה לא אחידה אם חלק מהבלוקים נשארים עם נתונים סטטיים ואינם נכתבים מחדש.\n\n**פתרון לסעיף 9.1.ב. (יישום Wear Leveling דינמי ב-FlashFS)**\n*   **כיצד FlashFS יכולה ליישם:** FlashFS, באמצעות ה-FTL שלה, יכולה לשמור עבור כל בלוק פיזי ספירת P/E (Program/Erase cycles). כאשר FlashFS צריכה לכתוב נתונים חדשים (לדוגמה, כתוצאה מעדכון עמוד לוגי קיים, או כתיבת עמוד לוגי חדש), היא תבקש מה-FTL בלוק פיזי פנוי (או בלוק שיהפוך לפנוי לאחר איסוף זבל). ה-FTL יבחר את הבלוק הפיזי הפנוי (או את הבלוק בעל הנתונים המיושנים ביותר שניתן למחוק) בעל ספירת ה-P/E הנמוכה ביותר. לאחר מחיקה וכתיבה לבלוק זה, ספירת ה-P/E שלו תעודכן. זה מבטיח שבלוקים ששוחררו ונמחקו ישמשו לכתיבות הבאות בצורה מאוזנת.\n*   **יתרונות:**\n    *   **פשטות יחסית:** קל יותר ליישום מ-Static Wear Leveling, מכיוון שאינו דורש מעקב והעתקה של נתונים \"קרים\".\n    *   **יעילות עבור נתונים דינמיים:** מבטיח שבלוקים המעורבים בפעולות כתיבה תכופות ישחקו באופן אחיד.\n    *   **הפחתת Overheads:** אין צורך לבצע העתקות מיותרות של נתונים סטטיים, מה שחוסך משאבי כתיבה.\n*   **חסרונות:**\n    *   **פוטנציאל לשחיקה לא אחידה:** אם ישנם בלוקים המכילים נתונים סטטיים מאוד שאינם משתנים לעולם, הם לא ייכללו במנגנון ה-wear leveling הדינמי, ובלוקים אחרים ימשיכו להישחק. זה עלול להוביל לכשל מוקדם יותר של ההתקן בהשוואה ל-Static Wear Leveling.\n    *   **תלות בדפוסי שימוש:** יעילותו תלויה מאוד בכמות הנתונים הסטטיים מול הדינמיים.\n\n**פתרון לסעיף 9.2.א. (רצף פעולות לעדכון נתונים)**\nעדכון עמוד לוגי של 4KB הממופה לעמוד פיזי P1 בבלוק B1, כאשר נדרש איסוף זבל על בלוק B_GC (50% תקפים, 50% מיושנים):\n\n1.  **קריאת נתונים תקפים מבלוק B_GC:** ה-FTL יבחר בלוק B_GC לצורך איסוף זבל. מכיוון ש-50% מהעמודים בו תקפים (32 עמודים, כלומר 32 * 4KB = 128KB), יש לקרוא אותם.\n2.  **כתיבת הנתונים התקפים מבלוק B_GC לבלוק פיזי פנוי חדש:** ה-FTL יבחר בלוק פיזי פנוי (נניח B_NEW_GC) ויכתוב אליו את 32 העמודים התקפים שנקראו מ-B_GC.\n3.  **מחיקת בלוק B_GC:** לאחר שכל הנתונים התקפים מ-B_GC הועתקו, בלוק B_GC נמחק במלואו (Erase operation). כעת הוא בלוק פנוי וניתן להקצותו מחדש.\n4.  **בחירת עמוד ריק לכתיבת הנתונים המעודכנים:** ה-FTL יבחר עמוד ריק בבלוק הפעיל הנוכחי (או בבלוק B_NEW_GC אם הוא נבחר כבלוק הפעיל), נניח P_NEW.\n5.  **כתיבת הנתונים המעודכנים לעמוד P_NEW:** ה-FTL כותב את 4KB הנתונים המעודכנים לעמוד הפיזי P_NEW.\n6.  **עדכון טבלת המיפוי ב-FTL:** ה-FTL מעדכן את טבלת המיפוי כך שהעמוד הלוגי מצביע כעת על העמוד הפיזי P_NEW. העמוד הפיזי P1 בבלוק B1 מסומן כעת כמיושן (obsolete).\n7.  **עדכון ספירות P/E:** ספירת ה-P/E של בלוק B_GC (שנמחק וכעת פנוי) תעודכן לאחר המחיקה.\n\n**פתרון לסעיף 9.2.ב. (חישוב Write Amplification Factor - WAF)**\n*   **הגדרת WAF:** WAF הוא היחס בין כמות הנתונים הפיזיים שנכתבו בפועל ל-NAND Flash לבין כמות הנתונים הלוגיים שהמארח ביקש לכתוב.\n    WAF = (סה\"כ כתיבות פיזיות) / (סה\"כ כתיבות לוגיות)\n\n*   **חישוב:**\n    *   **כתיבה לוגית:** 4KB (העדכון המקורי).\n    *   **כתיבות פיזיות:**\n        1.  **העתקת נתונים תקפים מ-B_GC:** 32 עמודים * 4KB/עמוד = 128KB. (אלו כתיבות פנימיות של ה-FTL, לא כתיבה ישירה של המארח אך נחשבות ככתיבה פיזית). יש להעתיק אותם לבלוק פיזי חדש.\n        2.  **כתיבת הנתונים המעודכנים:** 4KB. (הנתונים הלוגיים המעודכנים נכתבים לעמוד פיזי חדש).\n    *   סה\"כ כתיבות פיזיות = 128KB (העתקה) + 4KB (נתונים חדשים) = 132KB.\n\n    WAF = 132KB / 4KB = 33.\n\n    **נימוק:** גורם הגברת הכתיבה הוא 33. זאת מכיוון שעל מנת לעדכן 4KB של נתונים לוגיים, ה-FTL נאלץ לבצע איסוף זבל. איסוף הזבל דרש העתקה של 128KB של נתונים תקפים (50% מבלוק ה-GC). בנוסף לכך, נכתבו ה-4KB של הנתונים המעודכנים עצמם. סך הכתיבות הפיזיות הוא 128KB (העתקה) + 4KB (נתונים חדשים) = 132KB. היחס בין 132KB ל-4KB הוא 33.\n\n**פתרון לסעיף 9.3.א. (Over-provisioning)**\n*   **מהו Over-provisioning:** Over-provisioning (OP) הוא שטח אחסון פיזי נוסף ב-SSD שאינו נגיש למערכת ההפעלה או למשתמש. הוא שמור באופן בלעדי לשימוש פנימי של בקר ה-SSD (ה-FTL) לצורך ניהול, כגון איסוף זבל, wear leveling, הקצאת בלוקים פגומים (bad block management) וניהול מטמון. לדוגמה, SSD של 120GB עשוי להיות מבוסס על שבבי פלאש בנפח פיזי של 128GB, כאשר 8GB (כ-7%) שמורים ל-OP.\n*   **תרומה לשיפור ביצועים ואורך חיים ב-FlashFS:**\n    *   **הפחתת WAF ושיפור אורך חיים:** שטח OP מספק ל-FTL יותר בלוקים פנויים לעבודה. ככל שיש יותר בלוקים פנויים, ה-FTL יכול לבחור בלוקים בצורה חכמה יותר עבור איסוף זבל ו-wear leveling. זה מאפשר לו לאסוף זבל בצורה יעילה יותר (לדוגמה, לבחור בלוקים עם אחוז גבוה יותר של עמודים מיושנים), מה שמפחית את הצורך להעתיק נתונים תקפים ומוביל להפחתה ב-WAF. WAF נמוך יותר משמעותו פחות כתיבות פיזיות, מה שמאריך את חיי ה-SSD.\n    *   **שיפור ביצועים (במיוחד בכתיבה):** כמות גדולה יותר של בלוקים פנויים מאפשרת ל-FTL לשמור רשימה ארוכה יותר של בלוקים ריקים, מה שמפחית את התדירות שבה חייבים לבצע איסוף זבל. פעולות איסוף זבל (מחיקה והעתקה) צורכות זמן ומשאבי I/O, ועלולות להאט את ביצועי הכתיבה. עם שטח OP גדול יותר, ה-SSD יכול לשמור על ביצועי כתיבה גבוהים יותר לאורך זמן, גם תחת עומס כתיבה כבד.\n    *   **גמישות ב-Wear Leveling:** שטח OP מאפשר ל-FTL לבצע wear leveling בצורה יעילה יותר על ידי מתן יותר אפשרויות לבלוקים להחלפה.\n\n**פתרון לסעיף 9.3.ב. (דוגמה מספרית והשפעה)**\n*   **דוגמה מספרית:** אחוז OP נפוץ נע בין 7% (לדוגמה, 240GB לוגיים מתוך 256GB פיזיים) ל-28% (לדוגמה, 400GB לוגיים שמשתמשים ב-512GB פיזיים). ב-SSD המיועד ליישומים ארגוניים עם עומס כתיבה גבוה, נראה לעיתים קרובות OP של 28%. ב-SSD לצרכן ביתי, נראה לרוב OP של 7%.\n*   **פרמטרים המשפיעים על הבחירה באחוז ה-OP:**\n    *   **דפוס עומס העבודה (Workload Pattern):** כוננים המיועדים לעומסי כתיבה כבדים ורנדומליים (לדוגמה, שרתי בסיסי נתונים) ייהנו משטח OP גדול יותר כדי להפחית את ה-WAF ולשמור על ביצועים עקביים. כוננים עם עומסי קריאה בעיקר ו/או כתיבות סדרתיות צפויות פחות להזדקק ל-OP גבוה.\n    *   **אורך חיים רצוי (Desired Endurance):** יישומים הדורשים אורך חיים ארוך יותר (יותר P/E cycles) יבחרו ב-OP גבוה יותר כדי למזער את השחיקה.\n    *   **עלות:** שטח OP גבוה יותר משמעותו פחות שטח זמין למשתמש, ולכן עלות גבוהה יותר לכל GB שימושי. יש למצוא איזון בין עלות, ביצועים ואורך חיים.\n    *   **אלגוריתמי ה-FTL ואיסוף הזבל:** אלגוריתמים מתוחכמים יותר של FTL ואיסוף זבל עשויים לדרוש פחות OP כדי להשיג רמות ביצועים ואורך חיים דומות.\n    *   **אחוז הנתונים המיושנים (Stale Data Ratio):** בסביבות שבהן אחוז גבוה של נתונים הופך למיושן במהירות, OP גבוה יותר יכול לסייע ל-FTL לנהל את הבלוקים ביעילות רבה יותר."}, "difficulty_estimation": "Hard", "_source_file": "0689__File_Systems__Open__Hard.json", "_topic_hint": "File Systems", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:35:15", "_subject": "File Systems"}, {"id": 1, "type": "Open", "topic": ["File Systems", "I/O", "Disk Scheduling"], "content": {"text": "נתונה מערכת קבצים חדשה בשם FlexFS. במערכת זו:\n- גודל בלוק (Block Size) הוא 4KB.\n- גודל Inode הוא 256 בתים.\n- קבצים קטנים מאוד (עד 60 בתים) נשמרים ישירות בתוך ה-inode.\n- עבור קבצים גדולים יותר, FlexFS משתמשת באלוקציה מבוססת Extents. Extent הוא רצף רציף של בלוקים פיזיים על הדיסק.\n- כל inode מכיל 10 תיאורי Extent ישירים. כל תיאור Extent הוא בגודל 16 בתים (8 בתים לכתובת הבלוק הפיזי הראשון, 8 בתים למספר הבלוקים ב-Extent).\n- אם קובץ דורש יותר Extents ממה שנכנס ב-inode, המערכת משתמשת בבלוק 'Indirect Extent Block' שיכול להכיל תיאורי Extents נוספים.\n\nנתון דיסק קשיח עם המאפיינים הבאים:\n- מהירות סיבוב (RPM): 10000.\n- זמן Seek ממוצע: 8ms.\n- קצב העברה מקסימלי: 50 MB/s.\n\nקובץ בשם `/home/user/mydata.txt` בגודל 500KB נשמר במערכת FlexFS. עקב פעולות כתיבה קודמות, הקובץ מפוצל כעת לשלושה Extents נפרדים על הדיסק, אשר אינם סמוכים זה לזה:\n- Extent A: מכיל את הנתונים מ-Offset 0KB עד 199KB (סה\"כ 200KB).\n- Extent B: מכיל את הנתונים מ-Offset 200KB עד 399KB (סה\"כ 200KB).\n- Extent C: מכיל את הנתונים מ-Offset 400KB עד 499KB (סה\"כ 100KB).\n\nיש לבצע פעולת קריאה של הנתונים מהקובץ בטווח Offsets שבין 150KB ל-450KB (כולל).\nהניחו שבלוק ה-inode של הקובץ כבר נמצא בזיכרון הראשי (cache). כמו כן, הניחו שכל גישה ל-Extent חדש דורשת פעולת Seek וזמן Latency סיבובי ממוצע, מכיוון שה-Extents מרוחקים זה מזה פיזית על הדיסק.\nפרטו את כל החישובים וההנחות באופן מלא.\n\nמהו הזמן המינימלי שתיקח פעולת הקריאה?", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\nראשית נחשב את הפרמטרים של הדיסק:\n- זמן סיבוב מלא: 60 שניות / 10000 סיבובים לדקה = 0.006 שניות = 6ms.\n- זמן Latency סיבובי ממוצע: חצי מזמן סיבוב מלא = 0.5 * 6ms = 3ms.\n- זמן Seek ממוצע: 8ms (נתון).\n- קצב העברה: 50 MB/s = 50 * 1024 KB/s = 51200 KB/s.\n- גודל בלוק: 4KB.\n\nנדרש לקרוא נתונים מהקובץ בטווח Offsets שבין 150KB ל-450KB. נפרק את הקריאה לפי ה-Extents השונים:\n\n1.  **קריאה מ-Extent A (Offsets 150KB - 199KB):**\n    - ה-Extent A מכיל נתונים מ-0KB עד 199KB. הקריאה מתחילה ב-Offset 150KB בתוך הקובץ.\n    - כמות הנתונים לקריאה מ-Extent A: (199 - 150 + 1)KB = 50KB.\n    - מספר הבלוקים שיש לקרוא מ-Extent A: 50KB / 4KB = 12.5 בלוקים. מאחר שקריאה מתבצעת בבלוקים שלמים, יש לקרוא 13 בלוקים (החל מהבלוק המכיל את 150KB ועד הבלוק המכיל את 199KB).\n    - זמן העברה ל-13 בלוקים: (13 בלוקים * 4KB/בלוק) / 51200 KB/s = 52KB / 51200 KB/s ≈ 0.001015625 שניות = 1.016ms (מעוגל).\n    - זמן גישה ל-Extent A: זמן Seek + זמן Latency סיבובי ממוצע + זמן העברה = 8ms + 3ms + 1.016ms = 12.016ms.\n\n2.  **קריאה מ-Extent B (Offsets 200KB - 399KB):**\n    - ה-Extent B מכיל נתונים מ-200KB עד 399KB. נדרשת קריאה של כל ה-Extent.\n    - כמות הנתונים לקריאה מ-Extent B: (399 - 200 + 1)KB = 200KB.\n    - מספר הבלוקים שיש לקרוא מ-Extent B: 200KB / 4KB = 50 בלוקים.\n    - זמן העברה ל-50 בלוקים: (50 בלוקים * 4KB/בלוק) / 51200 KB/s = 200KB / 51200 KB/s ≈ 0.00390625 שניות = 3.906ms (מעוגל).\n    - זמן גישה ל-Extent B: זמן Seek + זמן Latency סיבובי ממוצע + זמן העברה = 8ms + 3ms + 3.906ms = 14.906ms.\n\n3.  **קריאה מ-Extent C (Offsets 400KB - 450KB):**\n    - ה-Extent C מכיל נתונים מ-400KB עד 499KB. הקריאה מסתיימת ב-Offset 450KB בתוך הקובץ.\n    - כמות הנתונים לקריאה מ-Extent C: (450 - 400 + 1)KB = 51KB.\n    - מספר הבלוקים שיש לקרוא מ-Extent C: 51KB / 4KB = 12.75 בלוקים. מאחר שקריאה מתבצעת בבלוקים שלמים, יש לקרוא 13 בלוקים (החל מהבלוק המכיל את 400KB ועד הבלוק המכיל את 450KB).\n    - זמן העברה ל-13 בלוקים: (13 בלוקים * 4KB/בלוק) / 51200 KB/s = 52KB / 51200 KB/s ≈ 0.001015625 שניות = 1.016ms (מעוגל).\n    - זמן גישה ל-Extent C: זמן Seek + זמן Latency סיבובי ממוצע + זמן העברה = 8ms + 3ms + 1.016ms = 12.016ms.\n\n**סה\"כ זמן מינימלי לקריאה:**\nמאחר שה-Extents מרוחקים זה מזה, כל גישה ל-Extent חדש דורשת פעולת Seek וזמן Latency סיבובי. לכן, נסכום את זמני הגישה לכל Extent:\nסה\"כ זמן = זמן גישה ל-Extent A + זמן גישה ל-Extent B + זמן גישה ל-Extent C\nסה\"כ זמן = 12.016ms + 14.906ms + 12.016ms = 38.938ms.\n\nהזמן המינימלי שתיקח פעולת הקריאה הוא 38.938ms."}, "difficulty_estimation": "Hard", "_source_file": "0690__File_Systems__Open__Hard.json", "_topic_hint": "File Systems", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:35:53", "_subject": "File Systems"}, {"id": 9, "type": "Open", "topic": ["File Systems", "Disk I/O", "Consistency", "Performance"], "content": {"text": "נתונה מערכת קבצים VSFS עם מאפיינים ייחודיים:\n- גודל בלוק הוא 4KB.\n- גודל inode הוא 256 בתים. בכל inode יש 10 מצביעים ישירים, 2 מצביעים עקיפים בודדים, ומצביע עקיף כפול אחד. גודל מצביע הוא 4 בתים.\n- קובץ שגודלו אינו עולה על 128 בתים, נשמר במלואו בתוך הרשומה של התיקייה המכילה אותו (Small File Optimization). במקרה כזה, ה-inode של הקובץ פשוט מציין שהקובץ הוא 'קובץ קטן' (למשל, באמצעות דגל ב-inode) ואינו מכיל מצביעים לנתונים. הנתונים עצמם מאוחסנים ברשומת התיקייה.\n- רשומת תיקייה עבור קובץ קטן מכילה: שם הקובץ (אורך משתנה, עד 250 בתים), גודל הקובץ (2 בתים), ו-128 בתים של נתוני הקובץ. כלומר, סה\"כ אורך שם הקובץ + 2 + 128 בתים.\n- רשומת תיקייה עבור קובץ גדול מכילה: שם הקובץ (אורך משתנה, עד 250 בתים), גודל הקובץ (2 בתים), ומספר ה-inode של הקובץ (4 בתים). כלומר, סה\"כ אורך שם הקובץ + 2 + 4 בתים.\n- ה-inode של תיקיית השורש מאוחסן ב-superblock.\n- מהירות הסיבוב של הדיסק (RPM) היא 7200.\n- זמן ה-seek הממוצע של הדיסק הוא 10ms.\n- קצב ההעברה המקסימלי של הדיסק הוא MB/s 50.\nיש לפרט ולנמק את כל החישובים בכל סעיף.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "9.1", "text": "1. מהו הגודל המקסימלי של קובץ הנתמך במערכת קבצים זו?\n2. מהו המספר המקסימלי של קבצים קטנים (Small Files) שניתן לאחסן בבלוק נתונים יחיד של תיקייה, אם כל שמות הקבצים הם באורך 8 תווים (כולל תו מסיים)?", "code_snippet": null, "options": null}, {"id": "9.2", "text": "משתמש ביצע פעולת קריאה של 10KB מתוך הקובץ `/home/user/data/largefile.txt`. ידוע שקובץ זה נוצר במקור כקובץ קטן בגודל 50 בתים, ולאחר מכן הורחב על ידי הוספת נתונים עד שהגיע לגודל כולל של 1MB. נתון שאף cache אינו מכיל מידע רלוונטי לביצוע הפעולה. כל מרכיבי הנתיב (`home`, `user`, `data`) הם תיקיות. יש להניח שאורך שם קובץ ממוצע בתיקיות הוא 8 תווים. מהו הזמן המינימלי שתיקח פעולה זו? יש לפרט את כל הבלוקים הנקראים ואת סדר הגישה אליהם, ולנמק מדוע זהו הזמן המינימלי.", "code_snippet": null, "options": null}, {"id": "9.3", "text": "תאר תרחיש בו משתמש מוסיף נתונים לקובץ קטן קיים (Small File) כך שגודלו הופך להיות גדול מ-128 בתים, והוא הופך ל'קובץ גדול' (Large File) הדורש בלוקי נתונים ו-inode מלא. הסבר נקודה ספציפית במהלך פעולה זו שבה קריסת מערכת עלולה להוביל למצב לא עקבי במערכת הקבצים, ותאר את חוסר העקביות. הצע פתרון למניעת חוסר עקביות זה, בהנחה שמערכת הקבצים משתמשת ב-metadata journaling (כלומר, בלוקי הנתונים נכתבים ישירות למיקומם הסופי בדיסק ולא ל-journal).", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון שאלה 9:\n\n**סעיף 9.1:**\n1.  **גודל קובץ מקסימלי:**\n    *   גודל בלוק: 4KB = 4096 בתים.\n    *   גודל מצביע: 4 בתים.\n    *   מספר מצביעים בבלוק עקיף: 4096 / 4 = 1024 מצביעים.\n    *   מצביעים ישירים: 10 * 4KB = 40KB.\n    *   מצביעים עקיפים בודדים: 2 * (1024 מצביעים לבלוקי נתונים * 4KB/בלוק) = 2 * 4MB = 8MB.\n    *   מצביע עקיף כפול: 1 * (1024 מצביעים לבלוקי עקיף בודדים * 1024 מצביעים לבלוקי נתונים * 4KB/בלוק) = 1 * 4GB = 4GB.\n    *   סה\"כ גודל קובץ מקסימלי: 40KB + 8MB + 4GB = 4,303,396,864 בתים.\n\n2.  **מספר קבצים קטנים בבלוק תיקייה:**\n    *   גודל בלוק: 4KB = 4096 בתים.\n    *   רשומת תיקייה לקובץ קטן: שם הקובץ (8 תווים = 8 בתים) + גודל הקובץ (2 בתים) + נתוני הקובץ (128 בתים) = 8 + 2 + 128 = 138 בתים.\n    *   מספר רשומות מקסימלי בבלוק יחיד: 4096 בתים / 138 בתים/רשומה = 29.68. כלומר, ניתן לאחסן **29 קבצים קטנים** מלאים בבלוק נתונים יחיד של תיקייה.\n\n**סעיף 9.2:**\nלצורך חישוב הזמן המינימלי, נניח את התרחיש האופטימלי ביותר שבו כל הבלוקים הנדרשים לקריאה ממוקמים ברצף פיזי על הדיסק, ולכן נשלם רק על זמן ההעברה הכולל של הנתונים, ללא זמני seek או rotational latency נוספים מעבר למינימום ההתחלתי (אם בכלל).\n\n**הבלוקים שיש לקרוא, לפי סדר הגישה:**\n1.  **בלוק ה-Superblock:** מכיל את ה-inode של תיקיית השורש. (1 בלוק)\n2.  **בלוק נתונים של תיקיית השורש (`/`):** כדי למצוא את רשומת התיקייה עבור `home` ולקבל את מספר ה-inode שלה. (1 בלוק)\n    *   רשומת תיקייה עבור קובץ גדול (כמו תיקייה): שם (8 בתים) + גודל (2 בתים) + מספר inode (4 בתים) = 14 בתים.\n3.  **בלוק ה-inode של תיקיית `home`:** כדי לקבל את המידע על התיקייה, ובפרט את המצביעים לבלוקי הנתונים שלה. (1 בלוק)\n4.  **בלוק נתונים של תיקיית `home`:** כדי למצוא את רשומת התיקייה עבור `user` ולקבל את מספר ה-inode שלה. (1 בלוק)\n5.  **בלוק ה-inode של תיקיית `user`:** כדי לקבל את המידע על התיקייה. (1 בלוק)\n6.  **בלוק נתונים של תיקיית `user`:** כדי למצוא את רשומת התיקייה עבור `data` ולקבל את מספר ה-inode שלה. (1 בלוק)\n7.  **בלוק ה-inode של תיקיית `data`:** כדי לקבל את המידע על התיקייה. (1 בלוק)\n8.  **בלוק נתונים של תיקיית `data`:** כדי למצוא את רשומת התיקייה עבור `largefile.txt` ולקבל את מספר ה-inode שלה. (1 בלוק)\n9.  **בלוק ה-inode של הקובץ `largefile.txt`:** כדי לקבל את המידע על הקובץ, ובפרט את המצביעים לבלוקי הנתונים שלו. (1 בלוק)\n10. **בלוקי הנתונים של הקובץ `largefile.txt`:** יש לקרוא 10KB. גודל בלוק הוא 4KB. לכן נדרשים 10KB / 4KB/בלוק = 2.5 בלוקים. כלומר, יש לקרוא **3 בלוקים** מלאים (4KB כל אחד). (3 בלוקים)\n\n**סה\"כ בלוקים לקריאה:** 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1 + 3 = **12 בלוקים**.\n\n**חישוב זמן הקריאה המינימלי:**\n*   סה\"כ נתונים להעברה: 12 בלוקים * 4KB/בלוק = 48KB.\n*   קצב העברה מקסימלי: 50 MB/s = 50 * 1024 KB/s.\n*   זמן העברה: 48KB / (50 * 1024 KB/s) = 48 / 51200 שניות = 0.0009375 שניות.\n*   זמן העברה במילישניות: 0.0009375 * 1000 ms = **0.9375ms**.\n\n**נימוק לזמן המינימלי:** ההנחה היא שכל 12 הבלוקים ממוקמים ברצף פיזי על הדיסק, ולכן ניתן לקרוא אותם בפעולת העברה רציפה אחת, לאחר seek ו-rotational latency ראשוניים, אשר זמנם זניח ביחס לזמן ההעברה הכולל או מושמט בתרחישי 'מינימום זמן' כפי שנראה בדוגמאות.\n\n**סעיף 9.3:**\n**תרחיש:**\nמשתמש יוצר קובץ בשם `myfile.txt` בתיקייה `/home/user/data` עם תוכן של 50 בתים. הקובץ מסווג כ'קובץ קטן' (Small File), ונתוניו (50 בתים) נשמרים ישירות בתוך רשומת התיקייה של `myfile.txt` בבלוק הנתונים של `/home/user/data`. ה-inode של `myfile.txt` מסומן כ'קובץ קטן' ואינו מכיל מצביעים לנתונים.\nלאחר מכן, המשתמש מוסיף לקובץ `myfile.txt` עוד 150 בתים של נתונים, כך שגודלו הכולל הופך ל-200 בתים. כעת, הקובץ גדול מ-128 בתים, ולכן הוא צריך להפוך ל'קובץ גדול' (Large File) ונתוניו צריכים לעבור לבלוקי נתונים ייעודיים, ורשומת התיקייה צריכה להכיל את מספר ה-inode שלו במקום את הנתונים.\n\n**נקודת קריסה ואי-עקביות:**\nרצף הפעולות הנדרש למעבר מקובץ קטן לגדול, תחת אילוצי metadata journaling, יכלול בדרך כלל:\n1.  הקצאת בלוק נתונים חדש (או יותר) עבור הקובץ `myfile.txt` (בלוק DATA).\n2.  כתיבת כל התוכן החדש של הקובץ (200 בתים) לבלוק הנתונים החדש שהוקצה. (פעולה זו נחשבת לכתיבת DATA ולכן מתבצעת ישירות למיקומה הסופי בדיסק, מחוץ ל-journal).\n3.  **התחלת טרנזקציה ב-journal (כתיבת TxB).**\n4.  כתיבת המצב החדש של ה-inode של `myfile.txt` (סימון כ'קובץ גדול', עדכון גודל, עדכון מצביעים לבלוק הנתונים החדש) ל-journal.\n5.  כתיבת המצב החדש של רשומת התיקייה של `myfile.txt` בתוך בלוק הנתונים של `/home/user/data` (הסרת 50 הבתים המקוריים, הוספת מספר ה-inode של הקובץ, עדכון גודל) ל-journal.\n6.  עדכון ה-bitmap של הבלוקים ב-journal (סימון הבלוק החדש כבשימוש, ושחרור הבלוק הישן אם היה בשימוש כלשהו ב-inode). (במקרה זה, אין בלוק ישן לשחרר, הנתונים היו בתוך רשומת התיקייה).\n7.  **כתיבת TxE ל-journal.**\n8.  **ביצוע fsync ל-journal** (כדי לוודא שהטרנזקציה נכתבה לדיסק).\n9.  כתיבת ה-inode המעודכן של `myfile.txt` למיקומו הסופי בדיסק.\n10. כתיבת בלוק הנתונים המעודכן של תיקיית `/home/user/data` למיקומו הסופי בדיסק.\n\n**נקודת הקריסה הבעייתית:** אם המערכת קורסת **לאחר שלב 2 (כתיבת נתוני הקובץ החדשים לבלוק הנתונים החדש)** אך **לפני שלב 8 (ביצוע fsync ל-journal)**, כלומר, הנתונים החדשים נכתבו לדיסק, אך המטא-דאטה (ה-inode ורשומת התיקייה) לא עודכנו באופן אטומי ב-journal.\n\n**חוסר העקביות:**\n*   **נתונים אבודים (Lost Data) ודליפת מקום דיסק (Disk Space Leak):** בלוק הנתונים החדש שמכיל את 200 הבתים של הקובץ נכתב לדיסק, אך ה-inode של הקובץ ורשומת התיקייה עדיין לא עודכנו כדי להצביע עליו. כתוצאה מכך, הבלוק החדש מוקצה אך אינו נגיש דרך מערכת הקבצים. הוא הופך ל'בלוק אבוד' ומהווה דליפת מקום דיסק.\n*   **נתונים מיושנים (Stale Data):** רשומת התיקייה עבור `myfile.txt` בבלוק הנתונים של `/home/user/data` עדיין מכילה את ה-50 בתים המקוריים של הקובץ, ומציינת שהקובץ הוא 'קובץ קטן' בגודל 50 בתים. קריאה עתידית של הקובץ תציג את הנתונים הישנים והגודל הישן, למרות שהנתונים החדשים כבר נכתבו במקום אחר על הדיסק.\n*   **חוסר עקביות ב-inode:** ה-inode של הקובץ עדיין מסומן כ'קובץ קטן' ואינו מכיל מצביעים לנתונים, בניגוד למצב הרצוי.\n\n**פתרון למניעת חוסר עקביות (Metadata Journaling):**\nהבעיה נובעת מכך שנתוני הקובץ הקטן נשמרים בתוך המטא-דאטה (רשומת התיקייה). כאשר הקובץ גדל, הוא עובר שינוי מבני הכולל גם העברת נתונים וגם שינוי במטא-דאטה. כדי להבטיח עקביות מלאה תחת metadata journaling, יש לטפל בשינוי רשומת התיקייה ובשינוי ה-inode כפעולה אטומית אחת.\n\n**הפתרון המוצע: גישת Copy-on-Write (CoW) לבלוק התיקייה:**\nבמקום לעדכן את בלוק הנתונים הקיים של התיקייה במקום, ניישם גישת Copy-on-Write לבלוקי תיקיות:\n1.  **הקצאת בלוק נתונים חדש (או יותר)** עבור הקובץ `myfile.txt`.\n2.  **כתיבת כל התוכן החדש של הקובץ** (200 בתים) לבלוק הנתונים החדש שהוקצה. (פעולה זו נכתבת ישירות למיקומה הסופית בדיסק).\n3.  **התחלת טרנזקציה ב-journal (כתיבת TxB).**\n4.  **הקצאת בלוק נתונים *חדש* עבור תיקיית האב** (`/home/user/data`).\n5.  **העתקת כל הרשומות הקיימות** מהבלוק הישן של תיקיית `/home/user/data` לבלוק הנתונים החדש, תוך **דילוג על הרשומה הישנה של `myfile.txt`**.\n6.  **הוספת הרשומה *החדשה* של `myfile.txt`** לבלוק הנתונים החדש של תיקיית `/home/user/data` (רשומה זו תכיל את מספר ה-inode של הקובץ, גודלו החדש, וללא נתונים פנימיים).\n7.  **כתיבת המצב החדש של ה-inode של `myfile.txt`** (סימון כ'קובץ גדול', עדכון גודל, עדכון מצביעים לבלוק הנתונים החדש) ל-journal.\n8.  **כתיבת המצב החדש של ה-inode של תיקיית האב** (`/home/user/data`) ל-journal, כך שיצביע על בלוק הנתונים *החדש* של התיקייה.\n9.  **עדכון ה-bitmap של הבלוקים ב-journal:** סימון הבלוקים החדשים (בלוק הנתונים של הקובץ ובלוק הנתונים החדש של התיקייה) כבשימוש, וסימון הבלוק הישן של התיקייה כפנוי.\n10. **כתיבת TxE ל-journal.**\n11. **ביצוע fsync ל-journal**.\n12. **יישום השינויים למיקומם הסופי בדיסק:** כתיבת ה-inode המעודכן של הקובץ, כתיבת ה-inode המעודכן של תיקיית האב, כתיבת בלוק הנתונים החדש של התיקייה, ועדכון ה-bitmap הראשי.\n13. **שחרור בלוק הנתונים הישן של התיקייה** (הוא כבר סומן כפנוי ב-bitmap כחלק מהטרנזקציה).\n\n**מדוע פתרון זה מטפל בבעיה:**\nאם המערכת קורסת **לפני שלב 11 (טרנזקציה לא בוצעה במלואה)**: הבלוק הישן של תיקיית `/home/user/data` נשאר שלם ועדיין מצביע על `myfile.txt` כקובץ קטן עם 50 בתים של נתונים. הבלוקים החדשים שהוקצו (בלוק נתוני הקובץ ובלוק הנתונים החדש של התיקייה) אינם נגישים ממערכת הקבצים וניתן לשחררם במהלך שחזור או באמצעות כלי fsck.\nאם המערכת קורסת **לאחר שלב 11 (טרנזקציה בוצעה במלואה)**: במהלך שחזור, ה-journal יבוצע מחדש (replay), וכל השינויים במטא-דאטה (ה-inode של הקובץ, ה-inode של התיקייה, ובלוק הנתונים החדש של התיקייה) ייושמו באופן אטומי. מערכת הקבצים תהיה במצב עקבי, כאשר `myfile.txt` מופיע כקובץ גדול עם 200 בתים של נתונים, ובלוק הנתונים הישן של התיקייה פונה.\nפתרון זה מבטיח שאף קריסה לא תגרום לחוסר עקביות במטא-דאטה, שכן כל השינויים הקריטיים (כולל השינוי במבנה רשומת התיקייה) מבוצעים כחלק מטרנזקציה אטומית אחת."}, "difficulty_estimation": "Hard", "_source_file": "0691__File_Systems__Open__Hard.json", "_topic_hint": "File Systems", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:37:11", "_subject": "File Systems"}, {"id": 1, "type": "Open", "topic": ["File Systems", "I/O", "Journaling", "Crash Consistency"], "content": {"text": "נתונה מערכת קבצים VSFS משופרת המשתמשת ב-metadata journaling (בדומה למצב Ordered ב-ext3), ובהתאם לכך, נתוני קבצים נכתבים למיקומם הסופי בדיסק לפני כתיבת ה-metadata המעודכן ל-journal.\nנתונים נוספים על מערכת הקבצים:\n- גודל בלוק: 4KB (4096 בתים).\n- גודל inode: 256 בתים.\n- כל inode מכיל 64 בתים עבור נתוני קבצים קטנים (in-inode data).\n- כל inode מכיל 10 מצביעים ישירים, מצביע עקיף יחיד אחד, ומצביע עקיף כפול אחד. גודל מצביע הוא 4 בתים.\n- רשומות תיקייה: כל רשומה מכילה את שם הקובץ (עד 255 תווים) ומספר ה-inode של הקובץ, המיוצג על ידי 2 בתים בלבד.\n- תיקיות מאורגנות כרשימה מקושרת של בלוקי נתונים, כאשר כל בלוק מכיל מספר רשומות תיקייה. ה-inode של התיקייה מצביע על הבלוק הראשון ברשימה וכן מכיל מצביע לבלוק האחרון.\n\nנתוני דיסק:\n- מהירות סיבוב: 7200 RPM.\n- זמן Seek ממוצע: 10ms.\n- קצב העברה מקסימלי: 2 MB/s.\n\nיש לפרט ולנמק את כל החישובים בכל סעיף.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "משתמש יוצר קובץ חדש וריק בשם `new_file.txt` בתיקייה `home/user/documents/`. ידוע כי התיקייה `documents` מלאה ודורשת הקצאת בלוק נתונים חדש עבור רשומת הקובץ החדש. הקובץ `new_file.txt` הוא קטן ולכן נתוניו נשמרים בתוך ה-inode שלו (in-inode data).\nתארו את רצף הפעולות הקריטיות על הדיסק (כתיבות ועדכונים, כולל ל-journal) הנדרשות לפעולה זו, ובאיזה שלב קריסה עלולה לגרום לחוסר עקביות במערכת הקבצים (File System Corruption), למרות השימוש ב-metadata journaling. הסבירו מדוע, והציעו פתרון לבעיה זו.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "משתמש מבצע פעולת קריאה של 100KB מתוך קובץ גדול (מעל 1MB) שמתחילה ב-offset 0. הקובץ נמצא בנתיב `home/user/big_data/very_important_file.bin`.\nנתון כי כל ה-inodes ובלוקי הנתונים של התיקיות בנתיב (home, user, big_data) נמצאים ב-cache. ה-inode של `very_important_file.bin` אינו ב-cache, ובלוקי הנתונים של הקובץ אינם ב-cache. ניתן להניח כי בלוקי הנתונים של הקובץ מפוזרים באופן אקראי על הדיסק.\nמהו הזמן המינימלי והמקסימלי שתיקח פעולת קריאה זו? יש לפרט את כל החישובים.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "מהו המספר המקסימלי של קבצים שתיקייה בודדת יכולה להכיל במערכת קבצים זו? יש לפרט את כל החישובים וההנחות.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון שאלה 1:\n\nחישובים כלליים:\nזמן סיבוב מלא: 1 / (7200 RPM / 60) = 1 / 120 = 8.333ms.\nזמן סיבוב ממוצע (חצי סיבוב): 8.333ms / 2 = 4.167ms.\nזמן העברת בלוק 4KB: (4KB / 2MB/s) = (4KB / 2048KB/s) = 1/512 s = 1.953ms.\n\n1.1. יצירת קובץ חדש וריק בתיקייה הדורשת בלוק נתונים חדש:\nרצף הפעולות הקריטיות על הדיסק (במצב Ordered journaling, שבו נתוני קבצים נכתבים לדיסק לפני ה-metadata המעודכן ל-journal, ובלוקי תיקייה נחשבים כנתונים):\n1.  הקצאת inode חדש (עדכון inode bitmap בזיכרון).\n2.  הקצאת בלוק נתונים חדש (בלוק תיקייה) (עדכון data bitmap בזיכרון).\n3.  **כתיבת בלוק הנתונים החדש של התיקייה למיקומו הסופי בדיסק.** בלוק זה יכיל את רשומת הקובץ `new_file.txt` ואת המצביע לבלוק הבא ברשימה המקושרת של התיקייה (אם יש).\n4.  כתיבת ה-inode החדש של `new_file.txt` למיקומו הסופי בדיסק (מכיל את נתוני הקובץ הקטנים).\n5.  עדכון בלוק הנתונים ה'אחרון' הקודם של התיקייה בזיכרון, כך שיצביע על בלוק הנתונים החדש שהוקצה (כדי לחבר אותו לרשימה המקושרת).\n6.  עדכון ה-inode של התיקייה `documents` בזיכרון (גודל, זמן שינוי).\n7.  **שלב ה-Journaling (כתיבת טרנזקציה ללוג):**\n    א.  כתיבת `TxB` (Transaction Begin) ל-journal.\n    ב.  כתיבת עדכון ל-`inode bitmap` ל-journal.\n    ג.  כתיבת עדכון ל-`data bitmap` ל-journal.\n    ד.  כתיבת תוכן ה-`new_inode` של `new_file.txt` ל-journal.\n    ה.  כתיבת תוכן בלוק הנתונים ה'אחרון' הקודם (לאחר עדכון המצביע) ל-journal.\n    ו.  כתיבת תוכן ה-`inode` של התיקייה `documents` (לאחר העדכונים) ל-journal.\n    ז.  כתיבת `TxE` (Transaction End) ל-journal.\n8.  ביצוע `fsync` על ה-journal (לוודא שהטרנזקציה כולה נכתבה לדיסק).\n9.  כתיבת ה-metadata המעודכן (ביטמאפים, inode חדש, inode תיקייה, בלוק קודם של תיקייה) למיקומם הסופי בדיסק.\n10. עדכון ה-superblock של ה-journal לציון שהטרנזקציה בוצעה בהצלחה (Commit).\n\n**שלב קריטי ובעיה:**\nקריסה עלולה לגרום לחוסר עקביות במערכת הקבצים אם היא מתרחשת **לאחר שלב 3 (כתיבת בלוק הנתונים החדש של התיקייה למיקומו הסופי בדיסק) אך לפני שלב 8 (סיום כתיבת הטרנזקציה המלאה ל-journal וביצוע fsync)**. במצב זה:\n-   בלוק הנתונים החדש של התיקייה, המכיל את רשומת `new_file.txt`, נכתב לדיסק.\n-   אך הטרנזקציה ב-journal אינה שלמה (או שעדיין לא בוצע לה `fsync`), ולכן מערכת הקבצים לא תדע על הבלוק הזה כחלק מהתיקייה על שחזור המערכת.\n-   על שחזור המערכת, ה-journal יתעלם מהפעולה הלא גמורה (או יחזיר את ה-metadata למצב הקודם). כתוצאה מכך, בלוק הנתונים החדש של התיקייה יהפוך לבלוק יתום (orphaned block) שאינו מקושר לשום תיקייה, ורשומת הקובץ החדש תאבד. זהו חוסר עקביות במערכת הקבצים (File System Corruption) מכיוון שיש בלוק מסומן כתפוס אך לא נגיש.\n\n**פתרון מוצע:**\nכדי למנוע בעיה זו במצב metadata journaling (Ordered mode), יש להבטיח שבלוקי הנתונים של התיקייה (שנחשבים כנתונים במצב זה, אך מכילים metadata-like entries) ייכתבו למיקומם הסופי בדיסק רק *לאחר* שהטרנזקציה המלאה שמתארת את השינויים בתיקייה (כולל קישור לבלוק החדש) נכתבה ל-journal ובוצעה לה `fsync`. כלומר, יש לשנות את סדר הכתיבה לדיסק כך ששלב 3 יתבצע רק *לאחר* שלב 8. לחילופין, ניתן להשתמש במצב journaling מלא (data journaling) שבו גם בלוקי הנתונים נכתבים ל-journal, אך זה פוגע בביצועים.\n\n1.2. זמן קריאת 100KB מקובץ גדול:\n\nנתונים:\nקריאת 100KB = 25 בלוקים (100KB / 4KB/בלוק).\n\n**זמן מינימלי:**\nבתרחיש המינימלי, ה-inode של הקובץ וכל 25 בלוקי הנתונים נמצאים ברצף על הדיסק.\n1.  **קריאת inode הקובץ:**\n    *   זמן Seek: 10ms.\n    *   זמן Rotational Latency ממוצע: 4.167ms.\n    *   זמן העברת בלוק (4KB): 1.953ms.\n    *   סה\"כ לקריאת inode: 10 + 4.167 + 1.953 = 16.120ms.\n2.  **קריאת 25 בלוקי נתונים רציפים:**\n    *   מכיוון שהבלוקים רציפים, נניח Seek ו-Rotational Latency יחידים עבור כלל 25 הבלוקים (הם מיד אחרי ה-inode או במיקום רציף אחר).\n    *   זמן Seek: 10ms.\n    *   זמן Rotational Latency ממוצע: 4.167ms.\n    *   זמן העברת 100KB (25 בלוקים): 100KB / (2MB/s) = 48.828ms.\n    *   סה\"כ לקריאת נתונים: 10 + 4.167 + 48.828 = 62.995ms.\n**סה\"כ זמן מינימלי:** 16.120ms (inode) + 62.995ms (נתונים) = **79.115ms**.\n\n**זמן מקסימלי:**\nבתרחיש המקסימלי, ה-inode של הקובץ וכל 25 בלוקי הנתונים מפוזרים באופן אקראי על הדיסק, כך שכל גישה לבלוק דורשת Seek ו-Rotational Latency ממוצעים חדשים.\n1.  **קריאת inode הקובץ:**\n    *   זמן Seek: 10ms.\n    *   זמן Rotational Latency ממוצע: 4.167ms.\n    *   זמן העברת בלוק (4KB): 1.953ms.\n    *   סה\"כ לקריאת inode: 10 + 4.167 + 1.953 = 16.120ms.\n2.  **קריאת 25 בלוקי נתונים מפוזרים:**\n    *   כל בלוק דורש: Seek + Rotational Latency + זמן העברת בלוק.\n    *   זמן לבלוק יחיד: 10 + 4.167 + 1.953 = 16.120ms.\n    *   סה\"כ ל-25 בלוקים: 25 * 16.120ms = 403.000ms.\n**סה\"כ זמן מקסימלי:** 16.120ms (inode) + 403.000ms (נתונים) = **419.120ms**.\n\n1.3. מספר קבצים מקסימלי בתיקייה בודדת:\n\n**הגבלה על ידי מספר ה-inodes הכולל במערכת:**\nרשומת תיקייה מכילה מספר inode המיוצג על ידי 2 בתים בלבד. משמעות הדבר היא שמספר ה-inodes הכולל שניתן לייצג במערכת הקבצים מוגבל ל-2^16 = 65,536 inodes. לכן, תיקייה בודדת לא יכולה להכיל יותר מ-65,536 קבצים, גם אם מבנה התיקייה מאפשר אחסון של יותר רשומות.\n\n**הגבלה על ידי מבנה התיקייה (רשימה מקושרת של בלוקים):**\n*   **גודל רשומת תיקייה:** שם קובץ (עד 255 בתים) + מספר inode (2 בתים) = 257 בתים לרשומה (בהנחה של שם קובץ מקסימלי).\n*   **מספר רשומות לבלוק נתונים:** גודל בלוק (4096 בתים) / גודל רשומה (257 בתים) = 15.93, כלומר 15 רשומות לבלוק (יש לעגל למטה).\n*   **מספר בלוקי נתונים ש-inode של תיקייה יכול להצביע עליהם:**\n    *   מספר מצביעים בבלוק מצביעים: 4096 בתים / 4 בתים/מצביע = 1024 מצביעים.\n    *   מצביעים ישירים: 10 בלוקים.\n    *   מצביע עקיף יחיד: 1 בלוק מצביעים, שיכול להצביע על 1024 בלוקי נתונים.\n    *   מצביע עקיף כפול: 1 בלוק מצביעים, שיכול להצביע על 1024 בלוקי מצביעים, שכל אחד מהם מצביע על 1024 בלוקי נתונים. סה\"כ 1024 * 1024 = 1,048,576 בלוקי נתונים.\n    *   סה\"כ בלוקי נתונים מקסימליים לתיקייה: 10 (ישיר) + 1024 (עקיף יחיד) + 1,048,576 (עקיף כפול) = 1,049,610 בלוקים.\n*   **מספר קבצים מקסימלי לפי מבנה התיקייה:** 1,049,610 בלוקים * 15 רשומות/בלוק = 15,744,150 קבצים.\n\n**סיכום:**\nהמספר המקסימלי של קבצים שתיקייה בודדת יכולה להכיל במערכת קבצים זו הוא **65,536 קבצים**. הגבלה זו נובעת ממספר ה-inodes הכולל המוגבל על ידי גודל שדה ה-inode number ברשומות התיקייה (2 בתים), שהוא קטן יותר מהמספר המקסימלי של קבצים שמבנה התיקייה יכול להכיל.\n"}, "difficulty_estimation": "Hard", "_source_file": "0692__File_Systems__Open__Hard.json", "_topic_hint": "File Systems", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:38:35", "_subject": "File Systems"}, {"id": 1, "type": "Open", "topic": ["File Systems", "I/O", "Disk Management", "Journaling"], "content": {"text": "נתונה מערכת קבצים VSFS עם מבנה ייחודי: אין טבלת Inode ייעודית. במקום זאת, Inodes מאוחסנים בתוך בלוקי DATA רגילים. כל רשומת תיקייה מכילה את שם הקובץ ואת מיקום ה-Inode שלו, המיוצג כזוג `(מספר_בלוק, היסט_בתוך_הבלוק)`.\nInode הוא בגודל קבוע של 256 בתים. בלוק DATA הוא בגודל 4KB. גודל מצביע הוא 8 בתים.\nכל Inode מכיל:\n- מונה קישורים (reference count) בגודל 4 בתים.\n- סוג קובץ (file type) בגודל 4 בתים.\n- גודל קובץ (file size) בגודל 8 בתים.\n- 10 מצביעים ישירים.\n- 2 מצביעים עקיפים יחידים.\n- מצביע עקיף כפול אחד.\n- שאר המקום ב-Inode שמור לשימוש עתידי (padding).\n\nפרמטרי דיסק:\n- מהירות סיבוב (RPM): 7500.\n- זמן Seek ממוצע: 10ms.\n- קצב העברה מקסימלי: 2 MB/s.\n- תיקיית השורש (root directory) ממוקמת בבלוק DATA מספר 1, וה-Inode שלה ממוקם בבלוק DATA מספר 1 בהיסט 0.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "מהו הגודל המקסימלי של קובץ הנתמך במערכת קבצים זו, וכמה בלוקי DATA הוא יתפוס (כולל בלוקים של מצביעים אך לא בלוק Inode)? פרטו את החישובים.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "משתמש ביצע פעולת קריאה של 20KB מתחילתו של הקובץ `/home/user/documents/report.txt`. נתיב זה מכיל 3 תיקיות (home, user, documents) והקובץ report.txt. ידוע שכל רשומת תיקייה (Directory Entry) תופסת 32 בתים (שם הקובץ + מיקום Inode). כמו כן, ידוע שכל התיקיות בנתיב, וגם הקובץ `report.txt`, קטנים מספיק כך שכל הנתונים שלהם (למעט ה-Inode עצמו) נשמרים בבלוק DATA יחיד. בנוסף, ידוע שכל ה-Inodes בנתיב (כולל Inode הקובץ) נמצאים בבלוקי DATA שונים זה מזה, אך כל Inode ממוקם בתחילת הבלוק (היסט 0).\nנתון שאף cache אינו מכיל מידע רלוונטי לביצוע הפעולה. מהו הזמן המינימלי שתיקח פעולה זו? יש לפרט ולנמק את כל החישובים.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "סטודנט טוען כי עיצוב מערכת קבצים זה (Inodes המוקצים בתוך בלוקי DATA, ורשומות תיקייה המצביעות ל-`(מספר_בלוק, היסט_בתוך_הבלוק)`) מציג אתגרים משמעותיים לניהול יעיל של שטח פנוי ולעקביות מטה-דאטה בעת מחיקת קבצים, גם עם מערכת Journaling חזקה. האם אתם מסכימים? הסבירו את האתגרים הספציפיים וכיצד ניתן למתן אותם, תוך התייחסות הן לקבצים בעלי קישור יחיד והן לקבצים בעלי קישורים קשיחים (hard links). תארו כיצד קריסה בנקודה קריטית במהלך מחיקה עלולה להוביל לאי-עקביות או אובדן נתונים.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון שאלה 1:\n\n1.1. חישוב גודל Inode:\nגודל Inode = 256 בתים.\nמקום למצביעים: 256 - 4 (מונה קישורים) - 4 (סוג קובץ) - 8 (גודל קובץ) = 240 בתים.\nמספר מצביעים שניתן לאחסן ב-Inode: 240 / 8 (גודל מצביע) = 30 מצביעים.\n\nהמצביעים הקיימים:\n- 10 מצביעים ישירים.\n- 2 מצביעים עקיפים יחידים.\n- 1 מצביע עקיף כפול.\nסה\"כ 10 + 2 + 1 = 13 מצביעים מסוגים שונים.\nמכיוון ש-13 < 30, כל המצביעים הללו יכולים להיכנס ב-Inode.\n\nמספר מצביעים בבלוק עקיף:\nבלוק DATA = 4KB = 4096 בתים.\nמספר מצביעים בבלוק עקיף = 4096 / 8 = 512 מצביעים.\n\nחישוב בלוקי נתונים מקסימליים:\n- 10 מצביעים ישירים: 10 בלוקים.\n- 2 מצביעים עקיפים יחידים: 2 * 512 בלוקים = 1024 בלוקים.\n- 1 מצביע עקיף כפול: 1 * 512 * 512 בלוקים = 262144 בלוקים.\nסה\"כ בלוקי DATA = 10 + 1024 + 262144 = 263178 בלוקים.\n\nגודל קובץ מקסימלי:\nגודל קובץ מקסימלי = 263178 בלוקים * 4KB/בלוק = 1,052,712KB = 1,028.039MB ≈ 1GB.\n\n1.2. נפרק את פעולת הקריאה לשלבים:\nחישוב זמן גישה לבלוק בודד (seek + rotational latency + transfer time):\nזמן סיבוב מלא = 60000ms / 7500 RPM = 8ms.\nזמן rotational latency ממוצע = 0.5 * 8ms = 4ms.\nזמן העברת בלוק (4KB) = 4KB / (2MB/s) = 4KB / 2048KB/s = 1/512 s ≈ 1.95ms ≈ 2ms.\nזמן גישה לבלוק בודד = 10ms (seek) + 4ms (rotational) + 2ms (transfer) = 16ms.\n\n1.  **קריאת Inode של תיקיית השורש:** ה-Inode נמצא בבלוק DATA 1. קריאה אחת של בלוק DATA. זמן = 16ms.\n2.  **קריאת בלוק ה-DATA של תיקיית השורש:** נניח שנתוני התיקייה נמצאים בבלוק DATA נוסף. קריאה אחת של בלוק DATA. זמן = 16ms.\n3.  **קריאת Inode של תיקיית `/home`:** מצאנו את `(block_num, offset)` עבור `/home`. נניח שזה בבלוק DATA חדש. קריאה אחת של בלוק DATA. זמן = 16ms.\n4.  **קריאת בלוק ה-DATA של תיקיית `/home`:** נניח שנתוני התיקייה נמצאים בבלוק DATA נוסף. קריאה אחת של בלוק DATA. זמן = 16ms.\n5.  **קריאת Inode של תיקיית `/user`:** מצאנו את `(block_num, offset)` עבור `/user`. נניח שזה בבלוק DATA חדש. קריאה אחת של בלוק DATA. זמן = 16ms.\n6.  **קריאת בלוק ה-DATA של תיקיית `/user`:** נניח שנתוני התיקייה נמצאים בבלוק DATA נוסף. קריאה אחת של בלוק DATA. זמן = 16ms.\n7.  **קריאת Inode של תיקיית `/documents`:** מצאנו את `(block_num, offset)` עבור `/documents`. נניח שזה בבלוק DATA חדש. קריאה אחת של בלוק DATA. זמן = 16ms.\n8.  **קריאת בלוק ה-DATA של תיקיית `/documents`:** נניח שנתוני התיקייה נמצאים בבלוק DATA נוסף. קריאה אחת של בלוק DATA. זמן = 16ms.\n9.  **קריאת Inode של הקובץ `report.txt`:** מצאנו את `(block_num, offset)` עבור `report.txt`. נניח שזה בבלוק DATA חדש. קריאה אחת של בלוק DATA. זמן = 16ms.\n\nסה\"כ פעולות גישה למטה-דאטה (Inodes ותיקיות) = 9 פעולות. זמן כולל למטה-דאטה = 9 * 16ms = 144ms.\n\n10. **קריאת נתוני הקובץ `report.txt`:** יש לקרוא 20KB. גודל בלוק הוא 4KB, לכן יש לקרוא 20KB / 4KB = 5 בלוקים.\n    נניח תרחיש מינימלי שבו 5 הבלוקים הללו רציפים על הדיסק, ומיד לאחר בלוק ה-Inode של הקובץ. במקרה זה, תהיה פעולת Seek אחת לבלוק הראשון של הנתונים, ולאחר מכן קריאה רציפה.\n    זמן קריאת 5 בלוקים רציפים = 10ms (seek) + 4ms (rotational) + (5 * 2ms (transfer)) = 10ms + 4ms + 10ms = 24ms.\n\nסה\"כ זמן מינימלי = 144ms (מטה-דאטה) + 24ms (נתונים) = 168ms.\n\n1.3. **הסכמה עם טענת הסטודנט:** כן, טענת הסטודנט נכונה. עיצוב זה אכן מציג אתגרים משמעותיים.\n\n**אתגרים ספציפיים וכיצד ניתן למתן אותם:**\n\n1.  **ניהול שטח פנוי בתוך בלוקים (Internal Fragmentation):**\n    *   **האתגר:** Inodes מוקצים בתוך בלוקי DATA. כאשר קובץ נמחק (מונה הקישורים שלו מגיע ל-0), רק ה-Inode הספציפי בתוך בלוק ה-DATA מסומן כפנוי. בלוק ה-DATA המכיל אותו לא יכול להיות משוחרר בחזרה לבריכת הבלוקים הפנויים כל עוד יש בו Inodes פעילים אחרים, או אם הבלוק משמש גם לאחסון נתוני קבצים אחרים. זה מוביל לפרגמנטציה פנימית משמעותית בתוך בלוקים, כאשר בלוקי DATA מכילים שילוב של Inodes פעילים, Inode slots פנויים שאינם ניתנים לשימוש עבור נתוני קובץ רגילים, ואולי גם נתוני קבצים רגילים.\n    *   **מיגון:** יש צורך ב-bitmap ייעודי ל-Inode slots בתוך בלוקי DATA, בדומה ל-bitmap של בלוקי DATA. כל ביט ב-bitmap כזה ייצג אם Inode slot מסוים בתוך בלוק DATA פנוי או תפוס. בלוק DATA ישוחרר רק כאשר כל ה-Inode slots בתוכו פנויים, וגם אין בו נתוני קבצים פעילים אחרים (אם הבלוק שימש גם לאחסון נתונים). מנגנון כזה מגדיל את מורכבות ניהול השטח הפנוי.\n    *   **עבור קבצים בעלי קישור יחיד:** כשמונה הקישורים מגיע ל-0, יש לסמן את ה-Inode slot כפנוי ולשחרר את בלוקי הנתונים שלו. אם בלוק ה-DATA שהכיל את ה-Inode כעת ריק מכל Inodes ונתונים, ניתן לשחרר אותו.\n    *   **עבור קבצים בעלי קישורים קשיחים:** מחיקת רשומת תיקייה רק מפחיתה את מונה הקישורים ב-Inode. רק כאשר מונה הקישורים מגיע ל-0, ה-Inode slot מסומן כפנוי ובלוקי הנתונים משוחררים. האתגר זהה לקבצים בעלי קישור יחיד – ניהול שטח פנוי בתוך בלוקים המכילים Inodes, אך במקרה זה, בלוק ה-DATA שמכיל את ה-Inode יישאר תפוס כל עוד מונה הקישורים גדול מ-0.\n\n2.  **מורכבות Journaling ועקביות מטה-דאטה:**\n    *   **האתגר:** במערכת Journaling רגילה, פעולת מחיקת קובץ כוללת: (1) הסרת רשומת התיקייה, (2) הפחתת מונה הקישורים ב-Inode, (3) אם מונה הקישורים מגיע ל-0: שחרור בלוקי הנתונים של הקובץ ושחרור ה-Inode slot בבלוק ה-DATA המכיל אותו. בעיצוב זה, פעולות (2) ו-(3) הן פעולות על בלוק DATA שיכול להכיל Inodes אחרים ו/או נתוני קבצים, מה שמסבך את הטיפול.\n    *   **תרחיש קריסה בעייתי (אי-עקביות/אובדן נתונים):**\n        *   **קריסה לאחר (1) ולפני (2):** רשומת התיקייה נמחקה, אך מונה הקישורים ב-Inode לא עודכן. ה-Inode ובלוקי הנתונים שלו עדיין מסומנים כתפוסים אך אינם נגישים דרך מערכת הקבצים (lost data). ה-Journaling צריך לכלול את עדכון מונה הקישורים כחלק מהטרנזקציה יחד עם מחיקת רשומת התיקייה. אם ה-Journaling לא מטפל בכך במפורש, הנתונים אבודים (לא ניתנים לגישה) אך לא משוחררים, מה שמוביל לדליפת שטח דיסק.\n        *   **קריסה לאחר (2) ולפני (3):** מונה הקישורים ירד ל-0, אך בלוקי הנתונים וה-Inode slot לא שוחררו. זה יוביל לדליפת שטח דיסק (space leak) – הנתונים אינם נגישים ואינם משוחררים. ה-Journaling חייב להבטיח ששחרור המשאבים יתבצע כחלק אינטגרלי מהטרנזקציה.\n        *   **אתגר ייחודי למערכת זו (קריסה בבלוק Inode):** אם בלוק DATA מכיל מספר Inodes, ובלוק זה משוחרר בטעות (למשל, עקב באג או קריסה מורכבת) לפני שכל ה-Inodes הפעילים בו פונו, אזי Inodes חיים עלולים להיפגע או להימחק. כל הקבצים המצביעים אליהם יהפכו לבלתי נגישים, וישנה סכנה לאובדן נתונים חמור. Journaling חייב לוודא ששחרור בלוק DATA המכיל Inodes מבוצע רק לאחר אימות שכל ה-Inode slots בתוכו פנויים, וכי הבלוק אינו מכיל נתוני קבצים פעילים אחרים.\n    *   **מיגון:** Journaling חייב לכלול את כל הפעולות הכרוכות במחיקה כטרנזקציה אטומית אחת: הסרת רשומת התיקייה, עדכון מונה הקישורים, ושחרור ה-Inode slot ובלוקי הנתונים (אם רלוונטי). במקרה של קריסה, ה-Journaling יבטיח שהמערכת תחזור למצב עקבי (לפני המחיקה או אחרי המחיקה המלאה). בנוסף, יש צורך בסריקות רקע תקופתיות (כמו fsck) לאיתור Inodes עם מונה קישורים 0 שבלוקיהם לא שוחררו (space leaks), או Inodes נגישים בבלוקים שסומנו בטעות כפנויים, כדי לתקן אי-עקביויות.\n\nלסיכום, בעוד שהעיצוב חוסך טבלת Inode ייעודית, הוא מעביר את מורכבות ניהול ה-Inodes לתוך בלוקי ה-DATA, מה שמסבך את ניהול שטח פנוי, פרגמנטציה פנימית, ודורש Journaling קפדני ומורכב יותר כדי להבטיח עקביות ושלמות המערכת."}, "difficulty_estimation": "Hard", "_source_file": "0693__File_Systems__Open__Hard.json", "_topic_hint": "File Systems", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:39:24", "_subject": "File Systems"}, {"id": 1, "type": "Open", "topic": ["File Systems", "I/O", "Disk Scheduling", "Journaling"], "content": {"text": "נתונה מערכת קבצים VSFS עם מבנה inode ייחודי ואלוקציית בלוקים מבוססת extents. במערכת זו:\n- גודל בלוק הוא 4KB (4096 בתים).\n- גודל inode הוא 256 בתים. מתוכם, 128 הבתים הראשונים מוקצים לאחסון נתוני קובץ ישירות ב-inode (עבור קבצים קטנים מאוד). רק כאשר גודל הקובץ חורג מ-128 בתים, נעשה שימוש במצביעי extents.\n- כל מצביע extent הוא בגודל 8 בתים ומכיל (start_block_id, num_blocks), כאשר num_blocks הוא שדה בגודל 1 בית (כלומר, עד 255 בלוקים רציפים לכל extent).\n- בכל inode יש 8 מצביעי extents ישירים.\n- בנוסף, קיים מצביע עקיף אחד לבלוק extents עקיף יחיד. בלוק זה מכיל מצביעי extents נוספים.\n- מבנה רשומת תיקייה (directory entry) מכיל שם קובץ ומספר inode בלבד.\n\nנתוני דיסק:\n- מהירות הסיבוב של הדיסק (RPM) היא 10000.\n- זמן ה-seek הממוצע של הדיסק הוא 8ms.\n- קצב ההעברה המקסימלי של הדיסק הוא 100 MB/s.\n\nמערכת הקבצים משתמשת ב-metadata journaling. פירוש הדבר שרק עדכוני metadata (כמו inodes, superblocks) נרשמים ל-journal לפני כתיבתם למיקומם הסופי. בלוקי נתונים (כולל בלוקי נתונים של תיקיות) נכתבים ישירות למיקומם הסופי על הדיסק ברגע שהטרנזקציה מוכנה, לפני שה-TxE נכתב ל-journal. יש לפרט ולנמק את כל החישובים בכל סעיף.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "מהו הגודל המקסימלי של קובץ הנתמך במערכת הקבצים הנתונה? כמה בלוקי DATA (בלוקים המכילים נתוני קובץ בפועל) וכמה בלוקים נוספים (בלוקי metadata כגון בלוקי extents עקיפים) יידרשו עבור קובץ בגודל זה?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "משתמש ביצע פעולת קריאה של 500KB מתוך הקובץ: `/home/user/project/data.txt`.\nידוע שהקובץ `data.txt` הוא בגודל 1MB. הנתונים שלו מאוחסנים באמצעות extents, כאשר ה-128 בתים הראשונים נמצאים ב-inode, והשאר בשני extents ישירים רציפים (ה-extent הראשון מכיל 255 בלוקים, והשני מכיל את הבלוק הנותר). פעולת הקריאה היא מתחילת הקובץ (offset 0).\nנתון שאף cache אינו מכיל מידע רלוונטי לביצוע הפעולה.\nמה הזמן המינימלי שתיקח פעולה זו? יש לפרט את כל הבלוקים שנקראים, את גודלם הכולל, ואת חישוב הזמן.\nניתן להניח כל תרחיש שיוביל לזמן הקצר ביותר, כל עוד הוא עומד בנתונים ובמגבלות שצוינו.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "משתמש יוצר קובץ חדש וריק בשם `newfile.txt` בתיקייה קיימת (`/home/user/project/`). נתון שבלוק הנתונים של התיקייה (`project`) מכיל מספיק מקום פנוי לרשומת התיקייה החדשה. המערכת משתמשת ב-metadata journaling כמתואר לעיל. תארו רצף פעולות קצר על הדיסק (לפחות 3 פעולות כתיבה) עבור יצירת הקובץ, וציינו באיזה שלב קריסה עלולה לגרום לבעיה במערכת הקבצים. יש להסביר מדוע הקריסה בעייתית וכיצד היא מתבטאת. לאחר מכן, הציעו פתרון לבעיה, תוך שמירה על עקרונות ה-metadata journaling (כלומר, אין לכתוב את תוכן בלוק הנתונים של הקובץ ל-journal).", "code_snippet": null, "options": null}], "points": 5, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון שאלה 1:\n\n**סעיף 1.1: גודל קובץ מקסימלי ומספר בלוקים**\n\n*   **נתונים ב-inode**: 128 בתים.\n*   **מצביעי extents ישירים**: 8 מצביעים. כל מצביע יכול להפנות ל-255 בלוקים רציפים. כל בלוק הוא 4KB.\n    *   סה\"כ נתונים ממצביעים ישירים: `8 * 255 בלוקים * 4KB/בלוק = 8 * 1020KB = 8160KB`.\n*   **מצביע extent עקיף**: 1 מצביע לבלוק extents עקיף. בלוק זה (4KB) יכול להכיל `4096 בתים / 8 בתים/מצביע = 512 מצביעי extents`.\n    *   סה\"כ נתונים ממצביעים עקיפים: `512 מצביעים * 255 בלוקים/מצביע * 4KB/בלוק = 512 * 1020KB = 522240KB = 510MB`.\n\n*   **גודל קובץ מקסימלי**: `128 בתים + 8160KB + 522240KB = 530400KB + 128 בתים`.\n    *   `530400KB = 530400 * 1024 בתים = 543129600 בתים`. \n    *   סה\"כ: `543129600 + 128 = 543129728 בתים` (כ-518MB).\n\n*   **מספר בלוקי DATA נדרשים**: זהו סך הבלוקים המכילים את נתוני הקובץ בפועל.\n    *   ממצביעים ישירים: `8 * 255 = 2040 בלוקים`.\n    *   ממצביעים עקיפים: `512 * 255 = 130560 בלוקים`.\n    *   סה\"כ בלוקי DATA: `2040 + 130560 = 132600 בלוקים`.\n\n*   **מספר בלוקים נוספים (metadata)**:\n    *   בלוק אחד עבור בלוק ה-extents העקיף.\n\n**סעיף 1.2: זמן קריאת 500KB מהקובץ**\n\n**חישוב בלוקים לקריאה:**\n\n1.  **Superblock**: בלוק בודד לקריאת פרטי מערכת הקבצים (כולל מיקום inode השורש). (1 בלוק)\n2.  **מעבר בנתיב `/home/user/project/data.txt`**: לכל רכיב בנתיב נצטרך לקרוא את בלוק ה-inode שלו ואת בלוק הנתונים של התיקייה המכילה אותו כדי למצוא את ה-inode הבא.\n    *   **root**: קריאת inode של root (1 בלוק), קריאת בלוק הנתונים של root (כדי למצוא `home` - 1 בלוק).\n    *   **home**: קריאת inode של `home` (1 בלוק), קריאת בלוק הנתונים של `home` (כדי למצוא `user` - 1 בלוק).\n    *   **user**: קריאת inode של `user` (1 בלוק), קריאת בלוק הנתונים של `user` (כדי למצוא `project` - 1 בלוק).\n    *   **project**: קריאת inode של `project` (1 בלוק), קריאת בלוק הנתונים של `project` (כדי למצוא `data.txt` - 1 בלוק).\n    *   **data.txt**: קריאת inode של `data.txt` (1 בלוק).\n    *   סה\"כ בלוקי metadata עבור מעבר בנתיב: `1 (superblock) + 4 * (1 inode block + 1 directory data block) + 1 (data.txt inode block) = 1 + 8 + 1 = 10 בלוקים`.\n\n3.  **נתוני הקובץ**: נדרש לקרוא 500KB החל מאופסט 0.\n    *   ה-128 בתים הראשונים נמצאים ב-inode של `data.txt` (כבר נקרא בשלב הקודם).\n    *   היתרה לקריאה: `500KB - 128 בתים = 512000 - 128 = 511872 בתים`.\n    *   מספר בלוקי DATA הנדרשים: `511872 בתים / 4096 בתים/בלוק = 124.99...` כלומר 125 בלוקים.\n\n*   **סה\"כ בלוקים לקריאה**: `10 (metadata) + 125 (data) = 135 בלוקים`.\n*   **גודל כולל לקריאה**: `135 בלוקים * 4KB/בלוק = 540KB`.\n\n**חישוב זמן מינימלי:**\nכדי למזער את הזמן, נניח את התרחיש המיטבי:\n*   כל 10 בלוקי ה-metadata הנדרשים (superblock, inodes, directory data) נמצאים ברצף על הדיסק.\n*   כל 125 בלוקי ה-data של הקובץ נמצאים ברצף על הדיסק, ומיד לאחר בלוקי ה-metadata.\n*   הדיסק מתחיל לסובב בדיוק בנקודה שבה הנתונים נדרשים.\n\n*   **זמן Seek**: נניח seek אחד בלבד עבור כל הקריאה הרציפה: `8ms`.\n*   **זמן השהייה סיבובית ממוצעת (Rotational Latency)**: `0.5 סיבוב / (10000 סיבובים/דקה / 60 שניות/דקה) = 0.5 / 166.67 סיבובים/שניה = 0.003 שניות = 3ms`.\n*   **זמן העברה (Transfer Time)**: `540KB / 100MB/s = 0.54MB / 100MB/s = 0.0054 שניות = 5.4ms`.\n\n*   **זמן כולל מינימלי**: `8ms (seek) + 3ms (rotational latency) + 5.4ms (transfer) = 16.4ms`.\n\n**סעיף 1.3: בעיית Journaling ביצירת קובץ ופתרון**\n\n**רצף פעולות לדוגמה עבור `touch /home/user/project/newfile.txt`:**\n\n1.  **קריאת inode של התיקייה `project`**: קריאה מבלוק ה-inode המתאים.\n2.  **קריאת בלוק הנתונים של התיקייה `project`**: קריאה מבלוק ה-DATA המתאים.\n3.  **הקצאת inode חדש עבור `newfile.txt`**: הקצאת בלוק inode וכתיבת ה-inode החדש לבלוק זה.\n4.  **כתיבת TxB ל-journal**: רישום תחילת טרנזקציה עם פרטי עדכון ה-inode של `project` ושל `newfile.txt` (שניהם נחשבים metadata).\n5.  **עדכון בלוק הנתונים של התיקייה `project`**: הוספת רשומת `newfile.txt` לבלוק הנתונים של התיקייה `project` וכתיבתו למיקומו הסופי על הדיסק. (פעולת DATA).\n6.  **`fsync`**: הבטחת כתיבת בלוק הנתונים של `project` לדיסק.\n7.  **כתיבת TxE ל-journal**: סיום הטרנזקציה ב-journal.\n8.  **`fsync`**: הבטחת כתיבת ה-TxE לדיסק.\n9.  **עדכון inode של `project`**: כתיבת ה-inode המעודכן (זמן שינוי, גודל) למיקומו הסופי על הדיסק.\n10. **עדכון inode של `newfile.txt`**: כתיבת ה-inode המעודכן (זמן יצירה, גודל) למיקומו הסופי על הדיסק.\n\n**שלב בעייתי וכיצד קריסה מתבטאת:**\nקריסה **לאחר שלב 6 (fsync של בלוק הנתונים של התיקייה) ולפני שלב 7 (כתיבת TxE ל-journal)** תגרום לבעיה.\n*   **הסבר**: בשלב זה, בלוק הנתונים של התיקייה `project` כבר עודכן ונכתב לדיסק (עם רשומת `newfile.txt`), והכתיבה אושרה על ידי `fsync`. עם זאת, הטרנזקציה עדיין אינה מחויבת ב-journal (כי TxE טרם נכתב). כאשר המערכת תעלה מחדש, ה-recovery process יראה טרנזקציה פתוחה ב-journal. מכיוון שמערכת הקבצים משתמשת ב-metadata journaling בלבד, בלוק הנתונים של התיקייה `project` נחשב לבלוק נתונים רגיל, ולכן השינוי בו לא נרשם במלואו ל-journal (רק ה-inode של התיקייה נרשם כ-metadata). תהליך ה-recovery עלול לגלגל אחורה רק את השינויים שרשומים ב-journal (כלומר, את עדכוני ה-inode של `project` ושל `newfile.txt` אם נכתבו), אך לא יבטל את השינוי בבלוק הנתונים של התיקייה. התוצאה היא מצב לא עקבי: התיקייה `project` על הדיסק מכילה רשומה עבור `newfile.txt`, אך ה-inode של `project` עלול לא להיות מעודכן (לדוגמה, מספר הקישורים או זמן השינוי שלו), וה-inode של `newfile.txt` עלול להיות מוקצה אך לא מקושר כראוי, או להיחשב כבלוק שאינו בשימוש (אם הטרנזקציה גולגלה לאחור חלקית). הדבר יכול להוביל ל\"קובץ יתום\" (orphan file) או לרשומת תיקייה המפנה ל-inode לא תקין או לא קיים, מה שפוגע בעקביות מערכת הקבצים.\n\n**פתרון מוצע (שומר על עקרונות metadata journaling):**\nהפתרון הוא ליישם את עקרון **Copy-on-Write (CoW)** עבור בלוקי נתונים של תיקיות כאשר הם משתנים כחלק מטרנזקציה. \n\n1.  במקום לעדכן את בלוק הנתונים הקיים של התיקייה (`project`) במקום (שלב 5 לעיל), נקצה בלוק נתונים חדש לחלוטין.\n2.  נעתיק את התוכן של בלוק הנתונים הישן לבלוק החדש.\n3.  נוסיף את רשומת `newfile.txt` לבלוק הנתונים החדש.\n4.  הטרנזקציה ב-journal תכלול כעת לא רק את עדכוני ה-inode של `project` ושל `newfile.txt`, אלא גם את הפעולות של **הקצאת הבלוק החדש ושחרור הבלוק הישן** עבור נתוני התיקייה.\n5.  כתיבת בלוק הנתונים החדש תתבצע למיקומו הסופי.\n6.  לאחר מכן, ה-TxE יירשם ל-journal.\n7.  רק לאחר שהטרנזקציה ממומשת (TxE נכתב לדיסק), ה-inode של `project` יועדכן כך שיצביע על בלוק הנתונים החדש.\n\n*   **הסבר מדוע הפתרון מטפל בבעיה**: בגישה זו, אם המערכת קורסת לפני שהטרנזקציה מחויבת (כלומר, לפני כתיבת TxE ל-journal), בלוק הנתונים המקורי של התיקייה (`project`) נשאר ללא שינוי על הדיסק. בלוק הנתונים החדש (שעודכן) עלול להיות קיים על הדיסק, אך הוא אינו מקושר לאף inode, ולכן הוא ייחשב כבלוק שאינו בשימוש ויוכל להימחק בתהליך ניקוי עתידי (או שייכלל בלוג כבלוק שצריך לשחרר). תהליך ה-recovery יבטל את כל הפעולות הלא מחויבות, כולל הקצאת הבלוק החדש, ושחרור הבלוק הישן לא יתרחש. כך, גם אם קריסה תתרחש בכל שלב, מערכת הקבצים תישאר במצב עקבי: התיקייה `project` תישאר ללא השינוי, והקובץ `newfile.txt` לא יווצר, ללא שאריות או הפניות שגויות."}, "difficulty_estimation": "Hard", "_source_file": "0695__File_Systems__Open__Hard.json", "_topic_hint": "File Systems", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:41:39", "_subject": "File Systems"}, {"id": 100, "type": "CodeAnalysis", "topic": ["File Systems", "System Calls", "File I/O"], "content": {"text": "נתונה תוכנית ה-C הבאה המבצעת פעולות על קובץ. מה יהיה הפלט של התוכנית לפלט הסטנדרטי (stdout)?", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <fcntl.h>\n#include <string.h>\n\nint main() {\n    int fd;\n    char buffer[10]; // Buffer for 9 chars + null terminator\n    char *filename = \"test_file.txt\";\n    ssize_t bytes_read; // To store the return value of read\n\n    // Open file, create if not exists, truncate if exists, read/write permissions\n    fd = open(filename, O_CREAT | O_TRUNC | O_RDWR, 0644);\n    if (fd == -1) {\n        perror(\"open\");\n        exit(EXIT_FAILURE);\n    }\n\n    // Write \"HELLO\"\n    write(fd, \"HELLO\", 5); \n\n    // Seek to offset 2 from the beginning\n    lseek(fd, 2, SEEK_SET);\n\n    // Write \"WORLD\"\n    write(fd, \"WORLD\", 5);\n\n    // Seek to the beginning for reading\n    lseek(fd, 0, SEEK_SET);\n\n    // Clear buffer before reading to ensure clean output\n    memset(buffer, 0, sizeof(buffer));\n\n    // Read up to 9 bytes into buffer (leaving space for null terminator)\n    bytes_read = read(fd, buffer, sizeof(buffer) - 1); \n    if (bytes_read == -1) {\n        perror(\"read\");\n        close(fd);\n        unlink(filename);\n        exit(EXIT_FAILURE);\n    }\n\n    // Null-terminate the buffer at the exact end of read data\n    buffer[bytes_read] = '\\0';\n\n    printf(\"File content after operations: %s\\n\", buffer);\n\n    close(fd);\n    unlink(filename); // Clean up the file\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכנית פותחת קובץ בשם \"test_file.txt\" ומבצעת עליו מספר פעולות:\n1.  `fd = open(filename, O_CREAT | O_TRUNC | O_RDWR, 0644);`: הקובץ \"test_file.txt\" נוצר (או נמחק תוכנו אם קיים), ונפתח לקריאה וכתיבה. מצביע הקובץ (file offset) מאותחל לאופסט 0.\n2.  `write(fd, \"HELLO\", 5);`: המחרוזת \"HELLO\" נכתבת לקובץ. תוכן הקובץ כעת הוא `HELLO`. מצביע הקובץ מתקדם לאופסט 5.\n3.  `lseek(fd, 2, SEEK_SET);`: מצביע הקובץ מוזז לאופסט 2 מתחילת הקובץ.\n4.  `write(fd, \"WORLD\", 5);`: המחרוזת \"WORLD\" נכתבת החל מאופסט 2. היא דורסת את התווים \"LLO\" שהיו שם. תוכן הקובץ כעת הוא `HEWORLD`. מצביע הקובץ מתקדם לאופסט 2 + 5 = 7.\n5.  `lseek(fd, 0, SEEK_SET);`: מצביע הקובץ מוזז שוב לתחילת הקובץ (אופסט 0).\n6.  `memset(buffer, 0, sizeof(buffer));`: המאגר `buffer` מאופס (ממולא בתווי null).\n7.  `bytes_read = read(fd, buffer, sizeof(buffer) - 1);`: התוכנית מנסה לקרוא עד 9 בתים מהקובץ לתוך המאגר `buffer`. מכיוון שגודל הקובץ הוא 7 בתים בלבד (`HEWORLD`), רק 7 בתים אלה נקראים. המשתנה `bytes_read` יכיל את הערך 7. המאגר `buffer` יכיל כעת את המחרוזת `HEWORLD` ב-7 הבתים הראשונים, ואחריהם תווי null מה-`memset`.\n8.  `buffer[bytes_read] = '\\0';`: שורה זו מבטיחה שהמחרוזת במאגר תהיה מסתיימת ב-null בדיוק במיקום הנכון (לאחר 7 התווים שנקראו). במקרה זה, `buffer[7]` מקבל את התו null, מה שהופך את `buffer` למחרוזת C תקנית `\"HEWORLD\"`.\n9.  `printf(\"File content after operations: %s\\n\", buffer);`: הפלט יהיה המחרוזת שנקראה, `HEWORLD`, ולאחריה ירידת שורה.\n\nלכן, הפלט הסופי של התוכנית הוא:\n`File content after operations: HEWORLD`", "code_snippet": null}, "difficulty_estimation": "Easy", "_source_file": "0697__File_Systems__CodeAnalysis__Easy.json", "_topic_hint": "File Systems", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:42:57", "_subject": "File Systems"}, {"id": 101, "type": "CodeAnalysis", "topic": ["File Systems", "System Calls", "File I/O", "lseek"], "content": {"text": "נתונה תוכנית ה-C הבאה, המבצעת פעולות כתיבה ומיקום (seek) על קובץ. מה יהיה התוכן הסופי של הקובץ 'testfile.txt' לאחר הרצת התוכנית? הסבר את תשובתך.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <fcntl.h>\n#include <unistd.h>\n#include <string.h>\n\nint main() {\n    int fd;\n    char buffer1[] = \"Hello\";\n    char buffer2[] = \"World\";\n    char filename[] = \"testfile.txt\";\n\n    fd = open(filename, O_CREAT | O_TRUNC | O_RDWR, 0644);\n    if (fd == -1) {\n        perror(\"open\");\n        return 1;\n    }\n\n    write(fd, buffer1, strlen(buffer1));\n    lseek(fd, 2, SEEK_SET);\n    write(fd, buffer2, strlen(buffer2));\n\n    close(fd);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכנית פותחת את הקובץ 'testfile.txt' במצב יצירה, קיטום (trunc) וכתיבה/קריאה (RDWR). מצביע הקובץ (file offset) מאותחל ל-0.\n\n1.  הקריאה הראשונה ל-`write` כותבת את המחרוזת \"Hello\" (5 בתים) החל ממיקום 0 בקובץ. תוכן הקובץ: \"Hello\". מצביע הקובץ מתקדם למיקום 5.\n2.  הקריאה ל-`lseek(fd, 2, SEEK_SET)` מעבירה את מצביע הקובץ למיקום 2 מההתחלה.\n3.  הקריאה השנייה ל-`write` כותבת את המחרוזת \"World\" (5 בתים) החל ממיקום 2. פעולה זו דורסת חלק מהתוכן הקיים:\n    *   התווים 'H' ו-'e' במיקומים 0 ו-1 נשארים ללא שינוי.\n    *   התווים 'l', 'l', 'o' במיקומים 2, 3, 4 נדרסים על ידי 'W', 'o', 'r' בהתאמה.\n    *   התווים 'l', 'd' מהמחרוזת \"World\" נכתבים במיקומים 5 ו-6, ומרחיבים את הקובץ מעבר לגודלו המקורי של 5 בתים.\n\nלכן, התוכן הסופי של הקובץ יהיה \"HeWorld\".", "code_snippet": null}, "difficulty_estimation": "Easy", "_source_file": "0698__File_Systems__CodeAnalysis__Easy.json", "_topic_hint": "File Systems", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:43:11", "_subject": "File Systems"}, {"id": 101, "type": "CodeAnalysis", "topic": ["File Systems", "System Calls", "File I/O"], "content": {"text": "נתונה תוכנית ה-C הבאה המבצעת פעולות קבצים בסיסיות. נתחו את הקוד וציינו מה יהיה הפלט המודפס למסך בסיום ריצת התוכנית.", "code_snippet": "#include <stdio.h>\n#include <fcntl.h> // For open flags\n#include <unistd.h> // For read, write, close, lseek\n\nint main() {\n    int fd;\n    char buffer[20];\n    const char *data1 = \"Hello\";\n    const char *data2 = \"World\";\n\n    // Open a file named \"test.txt\" for writing, create if not exists, truncate if exists\n    fd = open(\"test.txt\", O_WRONLY | O_CREAT | O_TRUNC, 0644);\n    if (fd == -1) {\n        perror(\"open\");\n        return 1;\n    }\n\n    // Write \"Hello\"\n    write(fd, data1, 5);\n\n    // Write \"World\"\n    write(fd, data2, 5);\n\n    // Close the file\n    close(fd);\n\n    // Reopen the file for reading\n    fd = open(\"test.txt\", O_RDONLY);\n    if (fd == -1) {\n        perror(\"open\");\n        return 1;\n    }\n\n    // Read 10 bytes from the file\n    read(fd, buffer, 10);\n    buffer[10] = '\\0'; // Null-terminate for printing\n\n    printf(\"Content read: %s\\n\", buffer);\n\n    close(fd);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכנית פותחת את הקובץ 'test.txt' במצב כתיבה עם מחיקת תוכן קיים (O_TRUNC). לאחר מכן היא כותבת את המחרוזת 'Hello' (5 בתים) ואחריה מיד את המחרוזת 'World' (5 בתים). סך הכל נכתבו 10 בתים והקובץ יכיל את הטקסט 'HelloWorld'.\nלאחר מכן, הקובץ נסגר ונפתח מחדש במצב קריאה בלבד. פתיחה מחדש של קובץ מאפסת את מצביע הקובץ לתחילת הקובץ (offset 0).\nקריאה של 10 בתים מהקובץ תקרא את כל התוכן 'HelloWorld'. המחרוזת מוכנסת למאגר `buffer` ולאחר מכן מודפסת למסך באמצעות `printf`. שימו לב שהתו `\\n` בסוף ה-`printf` גורם לירידת שורה.\nלכן, הפלט יהיה:\nContent read: HelloWorld", "code_snippet": null}, "difficulty_estimation": "Easy", "_source_file": "0700__File_Systems__CodeAnalysis__Easy.json", "_topic_hint": "File Systems", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:43:39", "_subject": "File Systems"}, {"id": 1, "type": "CodeAnalysis", "topic": ["File Systems"], "content": {"text": "נתונה תוכנית ה-C הבאה. מה יהיה התוכן הסופי של הקובץ `test_file.txt` לאחר הרצת התוכנית?", "code_snippet": "#include <stdio.h>\n#include <fcntl.h> // For open flags\n#include <unistd.h> // For write, read, close, lseek\n\nint main() {\n    int fd;\n\n    // Open a file for writing, create if not exists, truncate if exists\n    fd = open(\"test_file.txt\", O_WRONLY | O_CREAT | O_TRUNC, 0644);\n    if (fd == -1) {\n        perror(\"open\");\n        return 1;\n    }\n\n    // Write \"Hello\"\n    write(fd, \"Hello\", 5);\n\n    // Seek to offset 10 from the beginning of the file\n    lseek(fd, 10, SEEK_SET);\n\n    // Write \"World\"\n    write(fd, \"World\", 5);\n\n    close(fd);\n\n    // For verification, not part of the core question logic\n    // char buffer[20];\n    // fd = open(\"test_file.txt\", O_RDONLY);\n    // read(fd, buffer, 20);\n    // buffer[15] = '\\0'; // Null-terminate to print reliably\n    // printf(\"File content: '%s'\\n\", buffer);\n    // close(fd);\n    // unlink(\"test_file.txt\"); // Clean up\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכנית פותחת את הקובץ `test_file.txt` לכתיבה, יוצרת אותו אם אינו קיים וחותכת אותו אם הוא קיים (O_TRUNC). ראשית, נכתבת המחרוזת \"Hello\" לקובץ, מה שגורם לגודל הקובץ להיות 5 בתים. לאחר מכן, הפונקציה `lseek` מזיזה את מצביע הקובץ למיקום 10 (SEEK_SET). מכיוון שהמיקום הנוכחי הוא 5, פעולת ה-seek יוצרת 'חור' של 5 בתים (ממיקום 5 עד 9) שיתמלאו בתווי אפס (null bytes) כאשר תתבצע כתיבה למיקום 10. לבסוף, נכתבת המחרוזת \"World\" החל ממיקום 10. לכן, התוכן הסופי של הקובץ יהיה: \"Hello\" ואחריו 5 תווי אפס, ואז \"World\"."}, "difficulty_estimation": "Easy", "_source_file": "0701__File_Systems__CodeAnalysis__Easy.json", "_topic_hint": "File Systems", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:43:51", "_subject": "File Systems"}, {"id": 101, "type": "CodeAnalysis", "topic": ["File Systems", "System Calls", "I/O"], "content": {"text": "נתונה תוכנית ה-C הבאה המבצעת פעולות על קובץ. מה יהיה הפלט הסופי של התוכנית על המסך? יש להניח שכל קריאות המערכת מצליחות.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <fcntl.h>\n#include <string.h>\n\nint main() {\n    char *filename = \"my_file.txt\";\n    char write_data[] = \"ABCDEFGHIJ\"; // 10 characters\n    char read_buffer[6]; // To read up to 5 characters + null terminator\n    int fd;\n    ssize_t bytes_read;\n\n    // 1. Open file for writing, create if not exists, truncate if exists\n    fd = open(filename, O_CREAT | O_WRONLY | O_TRUNC, 0644);\n    if (fd == -1) {\n        perror(\"Error opening file for write\");\n        return 1;\n    }\n\n    // 2. Write data to the file\n    write(fd, write_data, strlen(write_data));\n    close(fd); // Close the file\n\n    // 3. Open the file for reading\n    fd = open(filename, O_RDONLY);\n    if (fd == -1) {\n        perror(\"Error opening file for read\");\n        return 1;\n    }\n\n    // 4. Seek to offset 2 from the beginning\n    lseek(fd, 2, SEEK_SET);\n\n    // 5. Read 3 bytes\n    bytes_read = read(fd, read_buffer, 3);\n    if (bytes_read == -1) {\n        perror(\"Error reading from file\");\n        return 1;\n    }\n    read_buffer[bytes_read] = '\\0'; // Null-terminate the string\n    printf(\"%s\", read_buffer);\n\n    // 6. Seek to offset 2 from the current position\n    lseek(fd, 2, SEEK_CUR);\n\n    // 7. Read 2 bytes\n    bytes_read = read(fd, read_buffer, 2);\n    if (bytes_read == -1) {\n        perror(\"Error reading from file\");\n        return 1;\n    }\n    read_buffer[bytes_read] = '\\0'; // Null-terminate the string\n    printf(\"%s\", read_buffer);\n\n    close(fd);\n    unlink(filename); // Clean up the file\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכנית יוצרת קובץ בשם 'my_file.txt' וכותבת אליו את המחרוזת 'ABCDEFGHIJ'. לאחר מכן, היא פותחת את הקובץ לקריאה.\nהקריאה הראשונה:\n- הפקודה `lseek(fd, 2, SEEK_SET)` מזיזה את מצביע הקובץ למיקום 2 מההתחלה (התו השלישי, 'C').\n- הפקודה `read(fd, read_buffer, 3)` קוראת 3 בתים מהמיקום הנוכחי, כלומר 'C', 'D', 'E'. הפלט הראשון יהיה \"CDE\". מצביע הקובץ מתקדם למיקום 5.\nהקריאה השנייה:\n- הפקודה `lseek(fd, 2, SEEK_CUR)` מזיזה את מצביע הקובץ 2 בתים קדימה מהמיקום הנוכחי (שהוא 5). לכן, המצביע יעבור למיקום 5 + 2 = 7 (התו השמיני, 'H').\n- הפקודה `read(fd, read_buffer, 2)` קוראת 2 בתים מהמיקום הנוכחי, כלומר 'H', 'I'. הפלט השני יהיה \"HI\".\nהפלט הסופי המודפס למסך הוא שילוב של שתי ההדפסות: \"CDEHI\"."}, "difficulty_estimation": "Easy", "_source_file": "0702__File_Systems__CodeAnalysis__Easy.json", "_topic_hint": "File Systems", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:44:08", "_subject": "File Systems"}, {"id": 10, "type": "CodeAnalysis", "topic": ["File Systems", "System Calls", "I/O", "lseek"], "content": {"text": "נתונה תוכנית C הבאה שיוצרת קובץ וכותבת אליו. מה יהיה הפלט הסופי של התוכנית לפלט הסטנדרטי? יש להניח שכל קריאות המערכת מצליחות.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <fcntl.h> // For open\n#include <unistd.h> // For write, read, close, lseek\n\nint main() {\n    int fd;\n    char buffer[20];\n    char write_data1[] = \"Hello World\"; \n    char write_data2[] = \"OS\";          \n\n    // 1. Open a file named \"test_file.txt\". Create if not exists, truncate if exists, read/write permissions.\n    fd = open(\"test_file.txt\", O_CREAT | O_RDWR | O_TRUNC, 0644);\n    if (fd == -1) {\n        perror(\"open\");\n        return 1;\n    }\n\n    // 2. Write \"Hello World\" to the file.\n    write(fd, write_data1, sizeof(write_data1) - 1); \n\n    // 3. Move the file pointer to position 6 from the beginning.\n    lseek(fd, 6, SEEK_SET);\n\n    // 4. Write \"OS\" to the file starting from the current file pointer position.\n    write(fd, write_data2, sizeof(write_data2) - 1); \n\n    // 5. Move the file pointer back to the beginning of the file.\n    lseek(fd, 0, SEEK_SET);\n\n    // 6. Read up to 20 bytes from the file into the buffer.\n    read(fd, buffer, 20);\n\n    // 7. Print the content of the buffer (up to 20 characters).\n    printf(\"File content after operations: %.*s\\n\", 20, buffer); \n\n    // 8. Close the file.\n    close(fd);\n\n    return 0;\n}"}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכנית פותחת את הקובץ 'test_file.txt' במצב כתיבה וקריאה, ומוחקת את תוכנו אם קיים (O_TRUNC).\n1. בתחילה נכתבת המחרוזת \"Hello World\" (11 תווים) לקובץ. מצביע הקובץ נמצא כעת במיקום 11. תוכן הקובץ: \"Hello World\".\n2. לאחר מכן, קריאת `lseek(fd, 6, SEEK_SET)` מזיזה את מצביע הקובץ למיקום 6 (התו השביעי).\n3. הקריאה `write(fd, \"OS\", 2)` כותבת את המחרוזת \"OS\" (2 תווים) החל ממיקום 6. זה גורם לדריסה של התווים 'W' ו-'o' מהמחרוזת המקורית \"World\". התוכן הופך ל: \"Hello OSrld\". מצביע הקובץ נמצא כעת במיקום `6 + 2 = 8`.\n4. קריאת `lseek(fd, 0, SEEK_SET)` מזיזה את מצביע הקובץ חזרה למיקום 0 (תחילת הקובץ).\n5. קריאת `read(fd, buffer, 20)` קוראת את 11 התווים מהקובץ (שהם \"Hello OSrld\") לתוך המערך `buffer`. שאר המערך `buffer` יישאר ללא שינוי (או יכיל ערכים אקראיים אם לא אותחל).\n6. לבסוף, `printf` מדפיס את התוכן של `buffer` עד 20 תווים. מכיוון שנקראו 11 תווים שהם \"Hello OSrld\", זה מה שיודפס.\nלכן, הפלט הסופי יהיה: Hello OSrld"}, "difficulty_estimation": "Easy", "_source_file": "0703__File_Systems__CodeAnalysis__Easy.json", "_topic_hint": "File Systems", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:44:22", "_subject": "File Systems"}, {"id": 1, "type": "CodeAnalysis", "topic": ["File Systems", "System Calls", "lseek", "write", "File Descriptors"], "content": {"text": "נתונה תוכנית ה-C הבאה. מה יהיה התוכן הסופי של הקובץ `testfile.txt` לאחר הרצת התוכנית? יש להניח שכל קריאות המערכת מצליחות.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <fcntl.h> // For open flags\n#include <unistd.h> // For open, write, close, lseek\n\nint main() {\n    int fd;\n    char buffer1[] = \"Hello\";\n    char buffer2[] = \"World\";\n\n    // Open file, create if not exists, truncate if exists, read/write mode\n    fd = open(\"testfile.txt\", O_RDWR | O_CREAT | O_TRUNC, 0644);\n    if (fd == -1) {\n        perror(\"open\");\n        return 1;\n    }\n\n    write(fd, buffer1, 5); // Write \"Hello\"\n\n    lseek(fd, 2, SEEK_SET); // Move 2 bytes from the beginning\n\n    write(fd, buffer2, 5); // Write \"World\"\n\n    close(fd);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכנית פותחת את הקובץ 'testfile.txt' במצב קריאה/כתיבה. הדגל O_TRUNC מבטיח שהקובץ יהיה ריק לחלוטין בתחילת התוכנית, וסמן הקובץ (file pointer) ממוקם בתחילתו (אופסט 0).\n\n1.  `write(fd, buffer1, 5);`:\n    התוכנית כותבת את המחרוזת \"Hello\" לקובץ. תוכן הקובץ כרגע: \"Hello\". סמן הקובץ מתקדם למיקום 5.\n\n2.  `lseek(fd, 2, SEEK_SET);`:\n    התוכנית מזיזה את סמן הקובץ למיקום 2 מהתחלה (SEEK_SET). סמן הקובץ נמצא כעת במיקום 2.\n\n3.  `write(fd, buffer2, 5);`:\n    התוכנית כותבת את המחרוזת \"World\" החל מהמיקום הנוכחי של סמן הקובץ, שהוא 2.\n    התוכן המקורי \"Hello\" יראה כך: H e l l o\n    הכתיבה של \"World\" מתחילה במיקום 2, ותחליף את התווים הקיימים:\n    מיקום: 0 1 2 3 4 5 6\n    תוכן:   H e W o r l d\n    (התווים 'l', 'l', 'o' מ-'Hello' מוחלפים על ידי 'W', 'o', 'r' מ-'World', והתווים 'l', 'd' נוספים אחרי ה-'o').\n    התוכן הסופי של הקובץ יהיה \"HeWorld\". סמן הקובץ מתקדם למיקום 2 + 5 = 7.\n\n4.  `close(fd);`:\n    הקובץ נסגר והתוכן \"HeWorld\" נשמר."}, "difficulty_estimation": "Easy", "_source_file": "0704__File_Systems__CodeAnalysis__Easy.json", "_topic_hint": "File Systems", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:44:37", "_subject": "File Systems"}, {"id": 101, "type": "CodeAnalysis", "topic": ["File Systems", "Processes", "System Calls", "Concurrency"], "content": {"text": "נתונה תוכנית ה-C הבאה המבצעת פעולות קבצים באמצעות קריאות מערכת. התוכנית יוצרת קובץ בשם `output.txt`, כותבת אליו נתונים, מבצעת `fork`, ולאחר מכן גם תהליך האב וגם תהליך הבן כותבים לאותו קובץ. נתחו את הקוד וציינו מה יהיה התוכן הסופי של הקובץ `output.txt` לאחר סיום ריצת התוכנית. הסבירו את הנימוק לתוכן הסופי.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <fcntl.h>\n#include <sys/wait.h>\n#include <string.h>\n\nint main() {\n    int fd;\n    char *filename = \"output.txt\";\n\n    // 1. Open file\n    fd = open(filename, O_WRONLY | O_CREAT | O_TRUNC, 0644);\n    if (fd == -1) {\n        perror(\"open\");\n        exit(1);\n    }\n\n    // 2. Parent writes \"PARENT1\"\n    write(fd, \"PARENT1\", 7);\n\n    // 3. Fork\n    pid_t pid = fork();\n\n    if (pid == -1) {\n        perror(\"fork\");\n        exit(1);\n    }\n\n    if (pid == 0) { // Child process\n        // Child writes \"CHILD\"\n        write(fd, \"CHILD\", 5);\n        close(fd);\n        exit(0);\n    } else { // Parent process\n        // Parent waits for child\n        wait(NULL);\n        // Parent writes \"PARENT2\"\n        write(fd, \"PARENT2\", 7);\n        close(fd);\n    }\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון דורש הבנה כיצד מתבצע שיתוף של מתארי קבצים (file descriptors) בין תהליך אב לבן לאחר קריאת המערכת `fork()`. \n\n1.  **פתיחת הקובץ וכתיבה ראשונית**: תהליך האב פותח את הקובץ `output.txt` במצב כתיבה (`O_WRONLY | O_CREAT | O_TRUNC`). בשלב זה, מתאר הקובץ `fd` מצביע על קובץ חדש וריק, ומצביע הכתיבה (file offset) נמצא בתחילת הקובץ (offset 0). לאחר מכן, האב כותב את המחרוזת \"PARENT1\". הקובץ מכיל כעת \"PARENT1\", ומצביע הכתיבה מתקדם ל-offset 7.\n\n2.  **קריאת `fork()`**: כאשר מתבצעת קריאת `fork()`, נוצר תהליך בן. מתארי הקבצים (file descriptors) של תהליך האב משוכפלים לתהליך הבן. חשוב לציין ששני מתארי הקבצים (האחד באב והאחד בבן) מצביעים כעת על *אותה כניסה בטבלת הקבצים הגלובלית* של מערכת ההפעלה. כניסה זו מכילה, בין היתר, את מצביע הכתיבה הנוכחי של הקובץ. לכן, מצביע הכתיבה משותף בין האב לבן. בשלב זה, מצביע הכתיבה המשותף הוא 7.\n\n3.  **כתיבת הבן**: תהליך הבן רץ וכותב את המחרוזת \"CHILD\". הכתיבה מתחילה מה-offset המשותף הנוכחי, שהוא 7. הקובץ מכיל כעת \"PARENT1CHILD\", ומצביע הכתיבה המשותף מתקדם ל-offset 7 + 5 = 12.\n\n4.  **המתנת האב וכתיבה נוספת**: תהליך האב ממתין לסיום הבן באמצעות `wait(NULL)`. רק לאחר שהבן מסיים את כתיבתו ויוצא, האב ממשיך. כעת, האב כותב את המחרוזת \"PARENT2\". הכתיבה מתחילה מה-offset המשותף הנוכחי, שהוא 12 (כפי שקודם על ידי הבן). הקובץ מכיל כעת \"PARENT1CHILDPARENT2\", ומצביע הכתיבה המשותף מתקדם ל-offset 12 + 7 = 19.\n\n5.  **סגירת הקבצים**: שני התהליכים סוגרים את מתאר הקובץ `fd`.\n\nלכן, התוכן הסופי של הקובץ `output.txt` יהיה \"PARENT1CHILDPARENT2\"."}, "difficulty_estimation": "Medium", "_source_file": "0705__File_Systems__CodeAnalysis__Medium.json", "_topic_hint": "File Systems", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:44:57", "_subject": "File Systems"}, {"id": 10, "type": "CodeAnalysis", "topic": ["File Systems", "Hard Links", "Inodes", "System Calls"], "content": {"text": "נתונה תוכנית ה-C הבאה המבצעת פעולות על מערכת קבצים. יש לנתח את הקוד ולענות על השאלה: מה יהיה הפלט המדויק של התוכנית? הסבירו כל שורה בפלט.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/stat.h> // For stat and struct stat\n#include <fcntl.h>    // For open flags\n#include <string.h>   // For strlen, memset\n\nint main() {\n    const char *file_name = \"data.txt\";\n    const char *link_name = \"data_link.txt\";\n    const char *initial_content = \"OS Exam Question\";\n    int fd;\n    struct stat file_stat;\n\n    // 1. Create a file and write some content\n    fd = open(file_name, O_CREAT | O_WRONLY | O_TRUNC, 0644);\n    if (fd == -1) { perror(\"open file_name\"); return 1; }\n    write(fd, initial_content, strlen(initial_content));\n    close(fd);\n    printf(\"Step 1: File '%s' created and content written.\\n\", file_name);\n\n    // 2. Create a hard link to the file\n    if (link(file_name, link_name) == -1) { perror(\"link\"); return 1; }\n    printf(\"Step 2: Hard link '%s' created for '%s'.\\n\", link_name, file_name);\n\n    // 3. Get and print the link count for the original file\n    if (stat(file_name, &file_stat) == -1) { perror(\"stat file_name\"); return 1; }\n    printf(\"Step 3: Link count for '%s': %ld\\n\", file_name, file_stat.st_nlink);\n\n    // 4. Unlink the original file name\n    if (unlink(file_name) == -1) { perror(\"unlink file_name\"); return 1; }\n    printf(\"Step 4: '%s' unlinked.\\n\", file_name);\n\n    // 5. Try to open the original file name (should fail)\n    fd = open(file_name, O_RDONLY);\n    if (fd == -1) {\n        printf(\"Step 5: Cannot open '%s' (as expected).\\n\", file_name);\n    } else {\n        printf(\"Step 5: Successfully opened '%s' (unexpected).\\n\", file_name);\n        close(fd);\n    }\n\n    // 6. Get and print the link count for the hard link\n    if (stat(link_name, &file_stat) == -1) { perror(\"stat link_name\"); return 1; }\n    printf(\"Step 6: Link count for '%s': %ld\\n\", link_name, file_stat.st_nlink);\n\n    // 7. Read content using the hard link\n    char read_buffer[100];\n    memset(read_buffer, 0, sizeof(read_buffer));\n    fd = open(link_name, O_RDONLY);\n    if (fd == -1) { perror(\"open link_name\"); return 1; }\n    read(fd, read_buffer, sizeof(read_buffer) - 1);\n    close(fd);\n    printf(\"Step 7: Content read from '%s': '%s'\\n\", link_name, read_buffer);\n\n    // Cleanup: Remove the hard link as well\n    unlink(link_name);\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון מנתח את התוכנית שלב אחר שלב:\n\n*   **Step 1:** הקובץ `data.txt` נוצר ונכתב לתוכו התוכן \"OS Exam Question\". בשלב זה, לקובץ יש רק שם אחד במערכת הקבצים, ולכן מונה הקישורים (link count) שלו הוא 1.\n    *   **פלט:** `Step 1: File 'data.txt' created and content written.`\n\n*   **Step 2:** הפונקציה `link()` יוצרת קישור קשיח (hard link) בשם `data_link.txt` המצביע לאותו inode של `data.txt`. כעת, לשם `data.txt` ולשם `data_link.txt` יש שניהם ערך בטבלת התיקיות שמצביע לאותו בלוק inode דיסק. מונה הקישורים של ה-inode המשותף עולה ל-2.\n    *   **פלט:** `Step 2: Hard link 'data_link.txt' created for 'data.txt'.`\n\n*   **Step 3:** קריאה ל-`stat(file_name, &file_stat)` מאחזרת את המידע על ה-inode של `data.txt` (שהוא אותו inode כמו של `data_link.txt`). המשתנה `file_stat.st_nlink` יכיל את מספר הקישורים הקשיחים לאותו inode, שהוא 2.\n    *   **פלט:** `Step 3: Link count for 'data.txt': 2`\n\n*   **Step 4:** הפונקציה `unlink(file_name)` מסירה את הערך של `data.txt` מטבלת התיקיות ומקטינה את מונה הקישורים של ה-inode באחד. הקובץ עצמו (הנתונים בבלוקי הדיסק) עדיין קיים מכיוון שמונה הקישורים לא הגיע ל-0 (הוא כעת 1, בגלל `data_link.txt`).\n    *   **פלט:** `Step 4: 'data.txt' unlinked.`\n\n*   **Step 5:** ניסיון לפתוח את `data.txt` נכשל מכיוון ששם הקובץ `data.txt` כבר לא קיים במערכת הקבצים. למרות שהנתונים עדיין קיימים על הדיסק, אין דרך לגשת אליהם ישירות דרך השם `data.txt`.\n    *   **פלט:** `Step 5: Cannot open 'data.txt' (as expected).`\n\n*   **Step 6:** קריאה ל-`stat(link_name, &file_stat)` מאחזרת את המידע על ה-inode, אשר מונה הקישורים שלו כעת הוא 1 (הוא ירד מ-2 ל-1 לאחר ה-`unlink` של `data.txt`).\n    *   **פלט:** `Step 6: Link count for 'data_link.txt': 1`\n\n*   **Step 7:** פתיחה וקריאה מתוך `data_link.txt` מצליחה מכיוון שהקישור הקשיח עדיין קיים ומצביע ל-inode עם הנתונים. התוכן המקורי \"OS Exam Question\" יקרא ויוצג.\n    *   **פלט:** `Step 7: Content read from 'data_link.txt': 'OS Exam Question'`\n\n*   **Cleanup:** ה-`unlink(link_name)` האחרון יסיר את הקישור האחרון ל-inode, ובכך יקטין את מונה הקישורים ל-0. רק אז, הנתונים הפיזיים על הדיסק ישוחררו ויהפכו לזמינים לשימוש חוזר."}, "difficulty_estimation": "Medium", "_source_file": "0706__File_Systems__CodeAnalysis__Medium.json", "_topic_hint": "File Systems", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:45:23", "_subject": "File Systems"}, {"id": 8, "type": "CodeAnalysis", "topic": ["File Systems", "Inodes", "Disk Management", "Block Allocation"], "content": {"text": "קובץ במערכת הפעלה מיוצג על ידי Inode המכיל מידע על הקובץ, כולל מצביעים לבלוקי הנתונים שלו על הדיסק. נתונה מערכת קבצים בה גודל בלוק הוא 4096 בתים. מבנה ה-Inode כולל 12 מצביעים ישירים, מצביע עקיף יחיד (Single Indirect), ומצביע עקיף כפול (Double Indirect). מצביע עקיף יחיד מצביע לבלוק המכיל מצביעים לבלוקי נתונים. מצביע עקיף כפול מצביע לבלוק המכיל מצביעים לבלוקים של מצביעים, אשר בתורם מצביעים לבלוקי נתונים.\nמספר המצביעים בבלוק אחד הוא `BLOCK_SIZE / sizeof(int)`.\n\nנתונה הגדרת המבנה `inode_t` וחתימת הפונקציה `getBlockAddress`. עליכם להשלים את מימוש הפונקציה `getBlockAddress` כך שהיא תחזיר את הכתובת הפיזית של בלוק הנתונים המתאים למספר הבלוק הלוגי הנתון `logical_block_num`. אם הבלוק הלוגי אינו קיים (כלומר, הוא מחוץ לטווח הגודל המקסימלי הנתמך על ידי מבנה ה-inode, או שמצביע ביניים כלשהו אינו חוקי), הפונקציה צריכה להחזיר -1.\n\nיש להניח שקיימת פונקציית עזר `read_block_pointers(int block_address, int* buffer)` אשר קוראת בלוק שלם מהדיסק (המכיל מצביעים) אל תוך המערך `buffer` ומחזירה 0 בהצלחה, או -1 בכשל (למשל, כתובת בלוק לא חוקית). במקרה של כשל בקריאת בלוק מצביעים, יש להחזיר -1 מהפונקציה `getBlockAddress`.\n\n**שימו לב:** יש להתייחס רק למצביעים הישירים, העקיפים היחידים והעקיפים הכפולים כפי שהוגדרו. אין צורך להתייחס למצביעים עקיפים משולשים או יותר.", "code_snippet": "#include <stdio.h>\n\n#define BLOCK_SIZE 4096 // 4KB\n#define POINTERS_PER_BLOCK (BLOCK_SIZE / sizeof(int)) // Assuming int is 4 bytes, so 1024 pointers\n#define NUM_DIRECT_BLOCKS 12\n\ntypedef struct {\n    int direct_blocks[NUM_DIRECT_BLOCKS];\n    int single_indirect_block;            // Pointer to a block of pointers\n    int double_indirect_block;            // Pointer to a block of pointers to blocks of pointers\n    // For simplicity, assume these are initialized to 0 if not pointing to a valid block\n    // A real system would use a special value like -1 or 0 to indicate an unallocated block\n} inode_t;\n\n// Helper function signature (assume it's implemented elsewhere).\n// Reads a block of pointers from disk into 'buffer'.\n// Returns 0 on success, -1 on failure (e.g., invalid block_address).\n// For the purpose of this problem, assume 'buffer' is pre-allocated by the caller\n// to BLOCK_SIZE bytes and can hold POINTERS_PER_BLOCK integers.\nint read_block_pointers(int block_address, int* buffer);\n\n// Complete this function\nint getBlockAddress(inode_t* inode, int logical_block_num) {\n    // Your implementation here\n    return -1; // Placeholder\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון מחשב את הכתובת הפיזית של בלוק נתונים על בסיס מספר הבלוק הלוגי (logical_block_num) על ידי בחינת שלושה מקרים עיקריים:\n\n1.  **בלוקים ישירים (Direct Blocks):**\n    אם `logical_block_num` קטן מ-`NUM_DIRECT_BLOCKS` (במקרה זה 12), הבלוק הוא בלוק ישיר. הכתובת הפיזית נמצאת ישירות במערך `direct_blocks` של ה-inode. במקרה זה, הפונקציה `getBlockAddress` אינה דורשת גישות דיסק נוספות (בהנחה שה-inode כבר נטען לזיכרון).\n\n2.  **בלוקים עקיפים יחידים (Single Indirect Blocks):**\n    אם `logical_block_num` נמצא בטווח הבלוקים המכוסים על ידי המצביע העקיף היחיד (כלומר, אחרי הבלוקים הישירים ועד `POINTERS_PER_BLOCK` בלוקים נוספים), יש לגשת לבלוק המצביעים העקיף.\n    ראשית, נבדוק אם `inode->single_indirect_block` מצביע לבלוק חוקי (לא 0 או שלילי). אם לא, נחזיר -1.\n    לאחר מכן, נקצה זיכרון לחוצץ (`ptr_block`) בגודל של בלוק אחד (כדי להכיל את המצביעים) ונקרא את הבלוק הזה מהדיסק באמצעות `read_block_pointers` אל תוך החוצץ. אם הקריאה נכשלת או ההקצאה נכשלת, נחזיר -1.\n    ההיסט בתוך בלוק המצביעים מחושב על ידי `logical_block_num - NUM_DIRECT_BLOCKS`. הכתובת הפיזית של בלוק הנתונים היא הערך במיקום זה בחוצץ. במקרה זה, נדרשת גישת דיסק אחת לפונקציה `getBlockAddress` (כדי לקרוא את בלוק המצביעים העקיף).\n\n3.  **בלוקים עקיפים כפולים (Double Indirect Blocks):**\n    אם `logical_block_num` נמצא בטווח הבלוקים המכוסים על ידי המצביע העקיף הכפול (כלומר, אחרי הבלוקים העקיפים היחידים ועד `POINTERS_PER_BLOCK * POINTERS_PER_BLOCK` בלוקים נוספים), יש לגשת לשתי רמות של בלוקי מצביעים.\n    ראשית, נבדוק אם `inode->double_indirect_block` מצביע לבלוק חוקי. אם לא, נחזיר -1.\n    נקצה זיכרון לחוצץ `ptr_block_lvl1` ונקרא את בלוק המצביעים ברמה הראשונה (Level 1) מהדיסק. אם הקריאה או ההקצאה נכשלות, נחזיר -1.\n    נחשב את האינדקסים `idx1` ו-`idx2`. `idx1` הוא האינדקס בבלוק המצביעים ברמה הראשונה, ו-`idx2` הוא האינדקס בבלוק המצביעים ברמה השנייה אליו מצביע `ptr_block_lvl1[idx1]`.\n    נבדוק אם `ptr_block_lvl1[idx1]` מצביע לבלוק חוקי. אם לא, נשחרר זיכרון ונחזיר -1.\n    נקצה זיכרון לחוצץ `ptr_block_lvl2` ונקרא את בלוק המצביעים ברמה השנייה (Level 2) מהדיסק. אם הקריאה או ההקצאה נכשלות, נשחרר זיכרון ונחזיר -1.\n    הכתובת הפיזית של בלוק הנתונים היא הערך במיקום `idx2` בחוצץ של בלוק המצביעים ברמה השנייה. במקרה זה, נדרשות שתי גישות דיסק לפונקציה `getBlockAddress` (אחת לבלוק המצביעים ברמה הראשונה, ואחת לבלוק המצביעים ברמה השנייה).\n\nבכל המקרים, אם `logical_block_num` חורג מהטווח המקסימלי הנתמך על ידי מבנה ה-inode, או אם מצביע ביניים כלשהו אינו חוקי (למשל, 0 או שלילי), הפונקציה תחזיר -1. יש שימוש ב-`malloc` כדי להקצות זיכרון לחוצצי המצביעים באופן זמני, וב-`free` כדי לשחררם לאחר השימוש בהם.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h> // For malloc, free\n\n#define BLOCK_SIZE 4096 // 4KB\n#define POINTERS_PER_BLOCK (BLOCK_SIZE / sizeof(int)) // Assuming int is 4 bytes, so 1024 pointers\n#define NUM_DIRECT_BLOCKS 12\n\ntypedef struct {\n    int direct_blocks[NUM_DIRECT_BLOCKS];\n    int single_indirect_block;            // Pointer to a block of pointers\n    int double_indirect_block;            // Pointer to a block of pointers to blocks of pointers\n} inode_t;\n\n// Mock helper function for demonstration. In a real scenario, this would interact with disk.\n// For the purpose of the exam question, it's just a signature.\n// For the solution, we assume it exists and works as described.\nint read_block_pointers(int block_address, int* buffer) {\n    // In a real system, this would read from disk into the buffer.\n    // For this problem, we just need to know it provides the array of pointers.\n    // We'll return 0 for success, and -1 for an invalid address or read error.\n    if (block_address <= 0) { // Assuming block addresses are positive integers\n        return -1; \n    }\n    // Simulate populating buffer with some values if necessary for testing,\n    // but for the logic of getBlockAddress, we just need the function signature.\n    return 0; // Success\n}\n\nint getBlockAddress(inode_t* inode, int logical_block_num) {\n    // 1. Direct blocks\n    if (logical_block_num < NUM_DIRECT_BLOCKS) {\n        // Ensure the direct block pointer is valid (not 0 or -1, assuming 0 is invalid)\n        if (inode->direct_blocks[logical_block_num] <= 0) {\n            return -1;\n        }\n        return inode->direct_blocks[logical_block_num];\n    }\n\n    // 2. Single Indirect blocks\n    int single_indirect_start = NUM_DIRECT_BLOCKS;\n    int single_indirect_end = single_indirect_start + POINTERS_PER_BLOCK;\n    if (logical_block_num >= single_indirect_start && logical_block_num < single_indirect_end) {\n        // Check if the single indirect block pointer itself is valid\n        if (inode->single_indirect_block <= 0) {\n            return -1;\n        }\n\n        int* ptr_block = (int*)malloc(BLOCK_SIZE);\n        if (ptr_block == NULL) {\n            return -1; // Memory allocation failed\n        }\n\n        // Read the single indirect block from disk\n        if (read_block_pointers(inode->single_indirect_block, ptr_block) == -1) {\n            free(ptr_block);\n            return -1; // Failed to read indirect block\n        }\n        \n        int offset_in_indirect_block = logical_block_num - single_indirect_start;\n        // Ensure the pointer within the indirect block is valid\n        if (ptr_block[offset_in_indirect_block] <= 0) {\n            free(ptr_block);\n            return -1;\n        }\n\n        int block_address = ptr_block[offset_in_indirect_block];\n        free(ptr_block);\n        return block_address;\n    }\n\n    // 3. Double Indirect blocks\n    int double_indirect_start = single_indirect_end;\n    int double_indirect_end = double_indirect_start + (POINTERS_PER_BLOCK * POINTERS_PER_BLOCK);\n    if (logical_block_num >= double_indirect_start && logical_block_num < double_indirect_end) {\n        // Check if the double indirect block pointer itself is valid\n        if (inode->double_indirect_block <= 0) {\n            return -1;\n        }\n\n        int* ptr_block_lvl1 = (int*)malloc(BLOCK_SIZE);\n        if (ptr_block_lvl1 == NULL) {\n            return -1; // Memory allocation failed\n        }\n\n        // Read the first level indirect block (which contains pointers to other indirect blocks)\n        if (read_block_pointers(inode->double_indirect_block, ptr_block_lvl1) == -1) {\n            free(ptr_block_lvl1);\n            return -1; // Failed to read first level indirect block\n        }\n\n        int offset_from_double_indirect_start = logical_block_num - double_indirect_start;\n        int idx1 = offset_from_double_indirect_start / POINTERS_PER_BLOCK; // Index in the first level indirect block\n        int idx2 = offset_from_double_indirect_start % POINTERS_PER_BLOCK; // Index in the second level indirect block\n\n        // Check if the pointer at idx1 in the first level indirect block is valid\n        if (idx1 >= POINTERS_PER_BLOCK || ptr_block_lvl1[idx1] <= 0) {\n            free(ptr_block_lvl1);\n            return -1;\n        }\n\n        int* ptr_block_lvl2 = (int*)malloc(BLOCK_SIZE);\n        if (ptr_block_lvl2 == NULL) {\n            free(ptr_block_lvl1); // Clean up previously allocated memory\n            return -1; // Memory allocation failed\n        }\n\n        // Read the second level indirect block (which contains pointers to data blocks)\n        if (read_block_pointers(ptr_block_lvl1[idx1], ptr_block_lvl2) == -1) {\n            free(ptr_block_lvl1);\n            free(ptr_block_lvl2);\n            return -1; // Failed to read second level indirect block\n        }\n\n        // Ensure the pointer within the second level indirect block is valid\n        if (ptr_block_lvl2[idx2] <= 0) {\n            free(ptr_block_lvl1);\n            free(ptr_block_lvl2);\n            return -1;\n        }\n\n        int block_address = ptr_block_lvl2[idx2];\n        free(ptr_block_lvl1);\n        free(ptr_block_lvl2);\n        return block_address;\n    }\n\n    // Logical block number is out of the range supported by this inode structure\n    return -1;\n}"}, "difficulty_estimation": "Medium", "_source_file": "0707__File_Systems__CodeAnalysis__Medium.json", "_topic_hint": "File Systems", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:46:00", "_subject": "File Systems"}, {"id": 10, "type": "CodeAnalysis", "topic": ["File Systems", "Inodes", "Disk Allocation"], "content": {"text": "נתונה מערכת קבצים פשוטה המממשת את מבנה ה-inode הבא:\n```c\n#define N_DIRECT 10 // מספר מצביעים ישירים\n#define BLOCK_SIZE 4096 // גודל בלוק בבתים\n// מספר בלוקים שניתן להפנות אליהם מבלוק עקיף יחיד\n#define BLOCKS_PER_INDIRECT (BLOCK_SIZE / sizeof(int)) \n\ntypedef struct {\n    int is_used; // 1 אם ה-inode בשימוש, 0 אחרת\n    int type;    // 0 עבור קובץ, 1 עבור תיקיה\n    int size;    // גודל הקובץ בבתים\n    int direct_blocks[N_DIRECT]; // מצביעים לבלוקי נתונים ישירים\n    int indirect_block; // מצביע לבלוק נתונים המכיל מערך של מספרי בלוקים\n} inode_t;\n\n// מערך ה-inodes הגלובלי\ninode_t inodes[100]; \n\n// מערך המדמה את בלוקי הנתונים בדיסק. \n// בפועל, בלוקים אלה מכילים נתונים, אך לצורך שאלה זו, \n// בלוקים עקיפים מכילים מספרי בלוקים. כאשר בלוק הוא בלוק עקיף (indirect block),\n// data_blocks_content[block_num][idx] יכיל את מספר הבלוק הפיזי הבא.\nint data_blocks_content[1000][BLOCK_SIZE / sizeof(int)]; // מדמה את תוכן הבלוקים\n```\n\nכתבו את הפונקציה `get_data_block_num` אשר מקבלת מספר inode ומספר בלוק לוגי בתוך הקובץ (logical_block_index), ומחזירה את מספר הבלוק הפיזי בדיסק המתאים לבלוק הלוגי הנתון.\nיש להניח שה-inode הנתון `inode_num` תמיד בשימוש ותמיד מייצג קובץ.\nאם ה-logical_block_index חורג מהגודל המותר עבור הקובץ, הפונקציה צריכה להחזיר -1.", "code_snippet": "int get_data_block_num(int inode_num, int logical_block_index) {\n    // השלימו את הפונקציה כאן\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפונקציה `get_data_block_num` מקבלת מספר inode ומספר בלוק לוגי בתוך הקובץ. המטרה היא למצוא את מספר הבלוק הפיזי המתאים.\n\nראשית, אנו מאחזרים את מבנה ה-inode המתאים ממערך ה-`inodes` הגלובלי. מכיוון שהונח שה-inode תמיד בשימוש ומייצג קובץ, אין צורך בבדיקות נוספות.\n\nשנית, אנו מבצעים בדיקת תקינות כדי לוודא שמספר הבלוק הלוגי אינו חורג מגודל הקובץ. גודל הקובץ נתון בבתים (`inode.size`), ולכן אנו מחשבים את מספר הבלוקים הכולל שהקובץ תופס על ידי חלוקה בגודל הבלוק (`BLOCK_SIZE`) תוך עיגול למעלה (באמצעות `+ BLOCK_SIZE - 1`). אם ה-`logical_block_index` קטן מ-0 או גדול או שווה למספר הבלוקים הכולל, זהו אינדקס לא חוקי, והפונקציה מחזירה -1.\n\nלאחר מכן, אנו בודקים אם הבלוק הלוגי נמצא בטווח המצביעים הישירים (`N_DIRECT`). אם כן, אנו פשוט מחזירים את מספר הבלוק המאוחסן במערך `direct_blocks` של ה-inode.\n\nאם הבלוק הלוגי אינו בטווח המצביעים הישירים, אנו בודקים אם הוא נמצא בטווח המצביעים העקיפים. אנו מחשבים את האינדקס בתוך הבלוק העקיף על ידי הפחתת `N_DIRECT` מה-`logical_block_index`. אם אינדקס זה חוקי (כלומר, קטן מ-`BLOCKS_PER_INDIRECT`), אנו ניגשים לבלוק העקיף (שמספרו מאוחסן ב-`inode.indirect_block`) ומשם מאחזרים את מספר הבלוק הפיזי מהמערך `data_blocks_content` באותו אינדקס. מספר בלוק פיזי זה מוחזר.\n\nאם ה-`logical_block_index` חורג גם מהטווח הישיר וגם מהטווח העקיף (מצב שאמור להיות מכוסה כבר על ידי בדיקת הגודל הראשונית), הפונקציה תחזיר -1.\n\n```c\n#define N_DIRECT 10 // מספר מצביעים ישירים\n#define BLOCK_SIZE 4096 // גודל בלוק בבתים\n#define BLOCKS_PER_INDIRECT (BLOCK_SIZE / sizeof(int)) \n\ntypedef struct {\n    int is_used; \n    int type;    \n    int size;    \n    int direct_blocks[N_DIRECT]; \n    int indirect_block; \n} inode_t;\n\ninode_t inodes[100]; \nint data_blocks_content[1000][BLOCK_SIZE / sizeof(int)]; \n\nint get_data_block_num(int inode_num, int logical_block_index) {\n    inode_t current_inode = inodes[inode_num];\n\n    // חישוב מספר הבלוקים הכולל שהקובץ תופס\n    int total_blocks_in_file = (current_inode.size + BLOCK_SIZE - 1) / BLOCK_SIZE;\n\n    // בדיקה אם האינדקס הלוגי חורג מגודל הקובץ או שלילי\n    if (logical_block_index < 0 || logical_block_index >= total_blocks_in_file) {\n        return -1; // אינדקס בלוק לא חוקי\n    }\n\n    // בדיקה אם הבלוק נמצא במצביעים הישירים\n    if (logical_block_index < N_DIRECT) {\n        return current_inode.direct_blocks[logical_block_index];\n    }\n\n    // בדיקה אם הבלוק נמצא במצביע העקיף היחיד\n    // הונח ש-indirect_block מצביע לבלוק חוקי אם הוא נדרש\n    int indirect_offset = logical_block_index - N_DIRECT;\n    if (indirect_offset < BLOCKS_PER_INDIRECT) {\n        return data_blocks_content[current_inode.indirect_block][indirect_offset];\n    }\n\n    // מצב זה אמור להיות מכוסה ע\"י בדיקת ה-total_blocks_in_file,\n    // אך מוחזר -1 למען בטיחות במקרה של אי-התאמה בנתונים.\n    return -1;\n}\n```", "difficulty_estimation": "Medium"}, "_source_file": "0708__File_Systems__CodeAnalysis__Medium.json", "_topic_hint": "File Systems", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:46:27", "_subject": "File Systems"}, {"id": 8, "type": "CodeAnalysis", "topic": ["File Systems", "Processes", "Concurrency", "System Calls"], "content": {"text": "נתונה תוכנית C הבאה המשתמשת במנגנוני מערכת קבצים ותהליכים. יש לנתח את הקוד ולציין את כל הפלטים האפשריים של התוכנית לשטף הפלט הסטנדרטי (stdout), תוך התמקדות בתוכן הסופי של הקובץ כפי שמודפס על ידי תהליך האב. הסבירו מדוע כל פלט אפשרי, ופרטו את מצב קובץ הנתונים ואיך ה-offset המשותף משתנה בכל אחד מהתרחישים.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <fcntl.h>\n#include <sys/wait.h>\n#include <string.h>\n\nint main() {\n    int fd;\n    char *filename = \"test_file.txt\";\n    char buffer_parent[] = \"AAAAA\"; // 5 'A's\n    char buffer_child[] = \"BBBBB\";  // 5 'B's\n\n    // Create and open the file, truncating if it exists\n    fd = open(filename, O_CREAT | O_TRUNC | O_RDWR, 0644);\n    if (fd == -1) {\n        perror(\"open failed\");\n        exit(1);\n    }\n\n    // Write some initial data\n    write(fd, \"123\", 3); // File: \"123\", current shared offset: 3\n\n    pid_t pid = fork();\n\n    if (pid < 0) {\n        perror(\"fork failed\");\n        exit(1);\n    } else if (pid == 0) { // Child process\n        printf(\"Child: Writing...\\n\");\n        // Child's file offset is inherited from parent (3)\n        lseek(fd, 1, SEEK_CUR); // Move offset by 1 relative to current shared offset\n        write(fd, buffer_child, strlen(buffer_child)); // Write 5 'B's\n        printf(\"Child: Finished writing.\\n\");\n        close(fd);\n        exit(0);\n    } else { // Parent process\n        printf(\"Parent: Writing...\\n\");\n        // Parent's file offset is also inherited from parent (3)\n        // No lseek here, writes from current shared offset\n        write(fd, buffer_parent, strlen(buffer_parent)); // Write 5 'A's\n        printf(\"Parent: Finished writing.\\n\");\n        wait(NULL); // Wait for child to finish\n        close(fd);\n\n        // Re-open the file to read its final content\n        fd = open(filename, O_RDONLY);\n        if (fd == -1) {\n            perror(\"re-open failed\");\n            exit(1);\n        }\n        char read_buf[20]; // Buffer to read content into\n        ssize_t bytes_read = read(fd, read_buf, sizeof(read_buf) - 1);\n        if (bytes_read == -1) {\n            perror(\"read failed\");\n            exit(1);\n        }\n        read_buf[bytes_read] = '\\0'; // Null-terminate the string\n        printf(\"Final file content: %s\\n\", read_buf);\n        close(fd);\n    }\n\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כדי לפתור את השאלה, יש להבין כיצד מתנהגים מתארי קבצים (file descriptors) במקרה של יצירת תהליך חדש (fork) וכיצד פעולות כתיבה (write) ושינוי מיקום (lseek) משפיעות על קובץ משותף. כאשר תהליך אב מבצע fork, תהליך הבן מקבל עותק של כל מתארי הקבצים של האב. עם זאת, מתארי קבצים אלו מצביעים לאותה טבלת קבצים (file table entry) בקרנל. המשמעות היא שהם חולקים את אותו מצביע קריאה/כתיבה (file offset) עבור הקובץ.\n\nנתחיל בניתוח הקוד:\n1.  הקובץ \"test_file.txt\" נוצר/נפתח במצב קריאה וכתיבה (O_RDWR) ונמחק תוכנו הקודם (O_TRUNC). מצביע הקובץ ההתחלתי הוא 0.\n2.  האב כותב \"123\" לקובץ. הקובץ מכיל כעת \"123\", ומצביע הקובץ המשותף מתקדם ל-3.\n3.  מתבצעת קריאת fork(). הן תהליך האב והן תהליך הבן יורשים את מתאר הקובץ `fd`, ושניהם חולקים את אותו מצביע קובץ משותף, שערכו כרגע הוא 3.\n\nקיימים שני תרחישים עיקריים לסדר הפעולות של הכתיבה, עקב אי-דטרמיניסטיות של תזמון תהליכים:\n\n**תרחיש 1: תהליך האב כותב לפני תהליך הבן**\n*   **האב:** מבצע `write(fd, buffer_parent, strlen(buffer_parent))`. הוא כותב \"AAAAA\" החל מה-offset המשותף הנוכחי (3). הקובץ הופך להיות: \"123AAAAA\". מצביע הקובץ המשותף מתקדם ל-3 + 5 = 8.\n*   **הבן:** מבצע `lseek(fd, 1, SEEK_CUR)`. ה-offset המשותף הנוכחי הוא 8 (לאחר כתיבת האב). ה-lseek מזיז את המצביע ב-1 קדימה, כך שהוא הופך ל-8 + 1 = 9.\n*   **הבן:** מבצע `write(fd, buffer_child, strlen(buffer_child))`. הוא כותב \"BBBBB\" החל מה-offset המשותף הנוכחי (9). הקובץ הופך להיות: \"123AAAAABBBBB\". מצביע הקובץ המשותף מתקדם ל-9 + 5 = 14.\n*   האב ממתין לבן (`wait(NULL)`), סוגר את הקובץ, פותח אותו מחדש לקריאה, קורא את התוכן ומדפיס.\n*   **פלט סופי אפשרי:** `Final file content: 123AAAAABBBBB`\n\n**תרחיש 2: תהליך הבן כותב לפני תהליך האב**\n*   **הבן:** מבצע `lseek(fd, 1, SEEK_CUR)`. ה-offset המשותף הנוכחי הוא 3 (לאחר כתיבת האב לפני ה-fork). ה-lseek מזיז את המצביע ב-1 קדימה, כך שהוא הופך ל-3 + 1 = 4.\n*   **הבן:** מבצע `write(fd, buffer_child, strlen(buffer_child))`. הוא כותב \"BBBBB\" החל מה-offset המשותף הנוכחי (4). הקובץ הופך להיות: \"123BBBBB\" (התו '3' בקובץ נדרס על ידי 'B' הראשון). מצביע הקובץ המשותף מתקדם ל-4 + 5 = 9.\n*   **האב:** מבצע `write(fd, buffer_parent, strlen(buffer_parent))`. הוא כותב \"AAAAA\" החל מה-offset המשותף הנוכחי (9). הקובץ הופך להיות: \"123BBBBBAAAAA\". מצביע הקובץ המשותף מתקדם ל-9 + 5 = 14.\n*   האב ממתין לבן (`wait(NULL)`), סוגר את הקובץ, פותח אותו מחדש לקריאה, קורא את התוכן ומדפיס.\n*   **פלט סופי אפשרי:** `Final file content: 123BBBBBAAAAA`\n\n**לגבי פלטי ה-printf הנוספים:**\nהשורות `\"Child: Writing...\"`, `\"Child: Finished writing.\"` ו-`\"Parent: Writing...\"`, `\"Parent: Finished writing.\"` יכולות להופיע בכל סדר אפשרי לפני שורת הפלט הסופית `\"Final file content: ...\"`, בהתאם לתזמון המדויק של מערכת ההפעלה. עם זאת, השורה `\"Final file content: ...\"` תמיד תופיע אחרונה מכיוון שתהליך האב ממתין לתהליך הבן לפני שהוא קורא את תוכן הקובץ ומדפיס אותו. לכן, ישנם שני פלטים סופיים אפשריים עבור תוכן הקובץ, וכל אחד מהם יכול להשתלב עם סדר שונה של הודעות ה-`printf` מהאב והבן."}, "difficulty_estimation": "Medium", "_source_file": "0709__File_Systems__CodeAnalysis__Medium.json", "_topic_hint": "File Systems", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:47:04", "_subject": "File Systems"}, {"id": 101, "type": "CodeAnalysis", "topic": ["File Systems", "System Calls", "I/O", "lseek", "unlink"], "content": {"text": "נתונה תוכנית ה-C הבאה המבצעת פעולות על מערכת קבצים. יש לנתח את הקוד ולציין מה יהיה הפלט המודפס למסך, וכן מה יהיה תוכן הקובץ test_file.txt לאחר סיום ריצת התוכנית (או האם הקובץ ימחק).", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <fcntl.h>\n#include <string.h>\n\nint main() {\n    int fd;\n    char buffer[20];\n    const char *filename = \"test_file.txt\";\n    const char *data1 = \"Hello\";\n    const char *data2 = \"World\";\n\n    // 1. Create and open the file\n    fd = open(filename, O_CREAT | O_RDWR | O_TRUNC, 0644);\n    if (fd == -1) {\n        perror(\"open\");\n        return 1;\n    }\n    printf(\"1. File '%s' opened with fd %d\\n\", filename, fd);\n\n    // 2. Write \"Hello\"\n    write(fd, data1, strlen(data1));\n    printf(\"2. Wrote '%s'. Current offset: %ld\\n\", data1, lseek(fd, 0, SEEK_CUR));\n\n    // 3. Seek to offset 10\n    lseek(fd, 10, SEEK_SET);\n    printf(\"3. Seeked to offset 10. Current offset: %ld\\n\", lseek(fd, 0, SEEK_CUR));\n\n    // 4. Write \"World\"\n    write(fd, data2, strlen(data2));\n    printf(\"4. Wrote '%s'. Current offset: %ld\\n\", data2, lseek(fd, 0, SEEK_CUR));\n\n    // 5. Unlink the file\n    unlink(filename);\n    printf(\"5. Unlinked file '%s'.\\n\", filename);\n\n    // 6. Seek back to beginning\n    lseek(fd, 0, SEEK_SET);\n    printf(\"6. Seeked to beginning. Current offset: %ld\\n\", lseek(fd, 0, SEEK_CUR));\n\n    // 7. Read content\n    memset(buffer, 0, sizeof(buffer)); // Clear buffer\n    ssize_t bytes_read = read(fd, buffer, sizeof(buffer) - 1);\n    buffer[bytes_read] = '\\0'; // Null-terminate\n    printf(\"7. Read %zd bytes: '%s'\\n\", bytes_read, buffer);\n\n    // 8. Close the file descriptor\n    close(fd);\n    printf(\"8. File descriptor %d closed.\\n\", fd);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון מתאר את הפלט של התוכנית ואת מצב מערכת הקבצים לאחר סיום הריצה.\n\n**ניתוח שלבי התוכנית:**\n1.  **פתיחת הקובץ:** הפעולה `open` יוצרת או פותחת את הקובץ `test_file.txt` עם הרשאות קריאה וכתיבה. דגל `O_TRUNC` גורם לכך שאם הקובץ כבר קיים, תוכנו נמחק וגודלו מתאפס. ה-file descriptor `fd` יקבל ערך (לרוב 3, כיוון ש-0, 1, 2 תפוסים ע\"י stdin, stdout, stderr). פלט: `1. File 'test_file.txt' opened with fd 3`.\n2.  **כתיבת \"Hello\":** הפעולה `write` כותבת את המחרוזת \"Hello\" (5 בתים) לקובץ. מצביע הקובץ (file offset) מתקדם למיקום 5. גודל הקובץ מתעדכן ל-5 בתים. פלט: `2. Wrote 'Hello'. Current offset: 5`.\n3.  **מעבר למיקום 10:** הפעולה `lseek` מזיזה את מצביע הקובץ למיקום 10 (SEEK_SET פירושו מראשית הקובץ). שימו לב שפעולה זו אינה משנה את גודל הקובץ עדיין. פלט: `3. Seeked to offset 10. Current offset: 10`.\n4.  **כתיבת \"World\":** הפעולה `write` כותבת את המחרוזת \"World\" (5 בתים) החל ממיקום 10. מכיוון שהמצביע היה במיקום 10 וגודל הקובץ היה 5, נוצר \"חור\" (hole) בין מיקום 5 למיקום 10. חור זה מתמלא באפסים (null bytes, `\\0`). לכן, תוכן הקובץ יהיה \"Hello\" ואחריו 5 אפסים, ואז \"World\". מצביע הקובץ מתקדם למיקום 15 (10 + 5). גודל הקובץ מתעדכן ל-15 בתים. פלט: `4. Wrote 'World'. Current offset: 15`.\n5.  **מחיקת הקישור (unlink):** הפעולה `unlink` מסירה את הקישור לשם הקובץ `test_file.txt` מהספרייה. עם זאת, הקובץ עצמו (ה-inode והבלוקים שלו) לא נמחק באופן מיידי מכיוון שעדיין קיים לו file descriptor פתוח (`fd`). הקובץ יימחק פיזית רק כאשר כל ה-file descriptors הפתוחים אליו ייסגרו. פלט: `5. Unlinked file 'test_file.txt'.`\n6.  **מעבר לתחילת הקובץ:** הפעולה `lseek` מזיזה את מצביע הקובץ חזרה למיקום 0. פלט: `6. Seeked to beginning. Current offset: 0`.\n7.  **קריאת תוכן:** הפעולה `read` קוראת 15 בתים מתחילת הקובץ לתוך המאגר `buffer`. למרות שהקובץ נמחק (שמו הוסר), ה-file descriptor `fd` עדיין תקף ומאפשר גישה לתוכן הקובץ. התוכן שייקרא לתוך `buffer` הוא \"Hello\" ואחריו 5 אפסים, ואז \"World\". כלומר, `buffer` יכיל: `{'H', 'e', 'l', 'l', 'o', '\\0', '\\0', '\\0', '\\0', '\\0', 'W', 'o', 'r', 'l', 'd', '\\0', ...}` (התו האחרון הוא ה-NULL שנוסף ידנית). שימו לב ש-`printf` עם פורמט `%s` מפסיקה להדפיס כאשר היא נתקלת בתו ה-NULL הראשון. לכן, הפלט המודפס עבור שורה זו יהיה רק `Hello`. פלט: `7. Read 15 bytes: 'Hello'`.\n8.  **סגירת הקובץ:** הפעולה `close` סוגרת את ה-file descriptor `fd`. כעת, מכיוון שזהו ה-file descriptor הפתוח האחרון לקובץ ששמו נמחק, הקובץ (ה-inode והבלוקים שלו) נמחק באופן סופי ממערכת הקבצים. פלט: `8. File descriptor 3 closed.`\n\n**פלט התוכנית המלא:**\n```\n1. File 'test_file.txt' opened with fd 3\n2. Wrote 'Hello'. Current offset: 5\n3. Seeked to offset 10. Current offset: 10\n4. Wrote 'World'. Current offset: 15\n5. Unlinked file 'test_file.txt'.\n6. Seeked to beginning. Current offset: 0\n7. Read 15 bytes: 'Hello'\n8. File descriptor 3 closed.\n```\n\n**תוכן הקובץ `test_file.txt` לאחר סיום ריצת התוכנית:**\nהקובץ `test_file.txt` לא יתקיים במערכת הקבצים לאחר סיום ריצת התוכנית. הוא נמחק עקב קריאת `unlink` וסגירת ה-file descriptor האחרון (`close(fd)`), מה שמשחרר את ה-inode והבלוקים שלו.", "code_snippet": null}, "difficulty_estimation": "Medium", "_source_file": "0710__File_Systems__CodeAnalysis__Medium.json", "_topic_hint": "File Systems", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:47:37", "_subject": "File Systems"}, {"id": 1, "type": "CodeAnalysis", "topic": ["File Systems", "Processes", "System Calls", "File Descriptors"], "content": {"text": "נתונה תוכנית ה-C הבאה המבצעת פעולות על קובץ באמצעות קריאות מערכת. יש לנתח את התוכנית ולהסביר מה יהיה התוכן הסופי של הקובץ `test_file.txt` לאחר סיום ריצת התוכנית.\n\nיש להסביר את השלבים המובילים לתוצאה הסופית, תוך התייחסות לאופן שבו מזהי קבצים (file descriptors) ו-offsets משותפים או מופרדים בין תהליכים שונים.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <fcntl.h>\n#include <sys/wait.h>\n#include <string.h>\n\nint main() {\n    int fd;\n    char *filename = \"test_file.txt\";\n\n    // 1. Create and open the file\n    fd = open(filename, O_CREAT | O_TRUNC | O_RDWR, 0644);\n    if (fd == -1) {\n        perror(\"open\");\n        exit(EXIT_FAILURE);\n    }\n\n    // 2. Parent writes \"HELLO\"\n    write(fd, \"HELLO\", 5);\n\n    // 3. Parent forks\n    pid_t pid = fork();\n\n    if (pid == -1) {\n        perror(\"fork\");\n        exit(EXIT_FAILURE);\n    }\n\n    if (pid == 0) { // Child process\n        // 4. Child writes \"WORLD\"\n        write(fd, \"WORLD\", 5);\n        // 5. Child seeks to beginning\n        lseek(fd, 0, SEEK_SET);\n        // 6. Child writes \"OS\"\n        write(fd, \"OS\", 2);\n        close(fd);\n        exit(EXIT_SUCCESS);\n    } else { // Parent process\n        // 7. Parent waits for child to finish\n        wait(NULL);\n        // 8. Parent seeks to offset 5\n        lseek(fd, 5, SEEK_SET);\n        // 9. Parent writes \"SYS\"\n        write(fd, \"SYS\", 3);\n        close(fd);\n    }\n\n    // Clean up: Delete the file (not part of the question's analyzed behavior)\n    unlink(filename);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכן הסופי של הקובץ `test_file.txt` יהיה: \"OSLLO SYSWORLD\"\n\nההסבר המפורט הוא כדלקמן:\n1.  **פתיחת הקובץ ופעולות תהליך ההורה הראשוניות:**\n    *   התוכנית פותחת את הקובץ `test_file.txt` במצב יצירה, מחיקה (אם קיים) וקריאה/כתיבה. ה-offset ההתחלתי של הקובץ הוא 0.\n    *   התהליך ההורה כותב \"HELLO\" לקובץ. תוכן הקובץ: `\"HELLO\"`. ה-offset של הקובץ מתקדם ל-5.\n\n2.  **יצירת תהליך הבן (`fork`):**\n    *   לאחר קריאת ה-`fork()`, נוצר תהליך בן. חשוב להבין שמזהי קבצים (file descriptors) משוכפלים בתהליך ה-`fork`, כלומר גם להורה וגם לבן יש מזהה קובץ `fd` שמצביע על אותה 'תיאור קובץ פתוח' (open file description) בטבלת הקבצים של המערכת. המשמעות היא שה-offset של הקובץ משותף בין ההורה לבן. כל שינוי ב-offset על ידי אחד מהתהליכים משפיע על שניהם.\n    *   בשלב זה, ה-offset המשותף הוא 5.\n\n3.  **פעולות תהליך הבן:**\n    *   הבן כותב \"WORLD\" לקובץ. הכתיבה מתחילה מה-offset הנוכחי, שהוא 5. תוכן הקובץ הופך להיות: `\"HELLOWORLD\"`. ה-offset המשותף מתקדם ל-10.\n    *   הבן מבצע `lseek(fd, 0, SEEK_SET)`, שמזיז את ה-offset המשותף לתחילת הקובץ (0).\n    *   הבן כותב \"OS\" לקובץ. הכתיבה מתחילה מה-offset 0, ולכן דורסת את שני התווים הראשונים. תוכן הקובץ הופך להיות: `\"OSLLOWORLD\"`. ה-offset המשותף מתקדם ל-2.\n    *   הבן סוגר את מזהה הקובץ שלו ויוצא.\n\n4.  **פעולות תהליך ההורה:**\n    *   ההורה ממתין שהבן יסיים באמצעות `wait(NULL)`. לאחר שהבן מסיים, ההורה ממשיך לפעול.\n    *   ה-offset המשותף של הקובץ נשאר 2 (הוא הוגדר כך בפעולה האחרונה של הבן).\n    *   ההורה מבצע `lseek(fd, 5, SEEK_SET)`, שמזיז את ה-offset המשותף ל-5.\n    *   ההורה כותב \"SYS\" לקובץ. הכתיבה מתחילה מה-offset 5, ודורסת חלק מהתווים הקיימים. תוכן הקובץ הופך להיות: `\"OSLLO SYSWORLD\"`.\n    *   ההורה סוגר את מזהה הקובץ שלו. (השורה `unlink(filename);` בסוף התוכנית מוחקת את הקובץ לאחר קבלת התוצאה, ואינה משפיעה על התוכן הסופי ברגע שהתוכנית מסיימת את פעולות הכתיבה)."}, "difficulty_estimation": "Medium", "_source_file": "0711__File_Systems__CodeAnalysis__Medium.json", "_topic_hint": "File Systems", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:47:59", "_subject": "File Systems"}, {"id": 101, "type": "CodeAnalysis", "topic": ["File Systems", "Links", "System Calls", "Inode"], "content": {"text": "נתונה תוכנית ה-C הבאה. התוכנית מופעלת בספרייה ריקה. יש להניח שכל קריאות המערכת מצליחות.\n\nלאחר הרצת התוכנית, מה יהיה התוכן של הקובץ `hardlink.txt` ומה יקרה בניסיון לקרוא מהקובץ `softlink.txt`?", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <fcntl.h>\n#include <sys/stat.h> // For S_IRUSR, etc.\n\nint main() {\n    const char *file_orig = \"original.txt\";\n    const char *hard_link_name = \"hardlink.txt\";\n    const char *soft_link_name = \"softlink.txt\";\n    int fd;\n\n    // 1. Create original.txt and write \"First line.\"\n    fd = open(file_orig, O_CREAT | O_WRONLY | O_TRUNC, 0644);\n    if (fd == -1) { perror(\"open original.txt\"); return 1; }\n    write(fd, \"First line.\\n\", 12);\n    close(fd);\n\n    // 2. Create a hard link to original.txt\n    if (link(file_orig, hard_link_name) == -1) { perror(\"link hardlink.txt\"); return 1; }\n\n    // 3. Create a symbolic link to original.txt\n    if (symlink(file_orig, soft_link_name) == -1) { perror(\"symlink softlink.txt\"); return 1; }\n\n    // 4. Append \"Second line.\" via the hard link\n    fd = open(hard_link_name, O_WRONLY | O_APPEND);\n    if (fd == -1) { perror(\"open hardlink.txt for append\"); return 1; }\n    write(fd, \"Second line.\\n\", 13);\n    close(fd);\n\n    // 5. Unlink the original file\n    if (unlink(file_orig) == -1) { perror(\"unlink original.txt\"); return 1; }\n\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסבר:\n\n**תוכן הקובץ `hardlink.txt`:**\nהתוכן יהיה:\n```\nFirst line.\nSecond line.\n```\n\n**נימוק:** קישור קשיח (hard link) הוא שם נוסף לאותו קובץ (אותו inode) במערכת הקבצים. כאשר כותבים לקובץ `original.txt` (דרך הפתיחה הראשונית) או ל-`hardlink.txt` (דרך הפתיחה השנייה), בפועל כותבים לאותו מקום אחסון בדיסק. לכן, הוספת הטקסט 'Second line.' דרך `hardlink.txt` משנה את התוכן של ה-inode המשותף. הפעולה `unlink(file_orig)` מסירה רק את השם `original.txt` מהספרייה ומקטינה את מונה הקישורים (link count) של ה-inode. כיוון ש-`hardlink.txt` עדיין מצביע על אותו inode, הקובץ והתוכן שלו נשארים זמינים דרך `hardlink.txt`.\n\n**ניסיון לקרוא מהקובץ `softlink.txt`:**\nהניסיון לקרוא מהקובץ `softlink.txt` ייכשל עם שגיאה כגון `ENOENT` (No such file or directory).\n\n**נימוק:** קישור סימבולי (symbolic link או soft link) הוא קובץ מיוחד המכיל את הנתיב (path) לקובץ יעד אחר. במקרה זה, `softlink.txt` מכיל את הנתיב `original.txt`. כאשר `original.txt` נמחק (באמצעות `unlink`), השם `original.txt` כבר אינו קיים בספרייה. לכן, כאשר מנסים לגשת ל-`softlink.txt`, מערכת ההפעלה מנסה לפתור את הנתיב הפנימי `original.txt`, אך כיוון שקובץ בשם זה כבר לא קיים, הגישה נכשלת והשגיאה `ENOENT` מוחזרת. הקישור הסימבולי הופך ל'קישור שבור' (dangling link)."}, "difficulty_estimation": "Medium", "_source_file": "0712__File_Systems__CodeAnalysis__Medium.json", "_topic_hint": "File Systems", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:48:19", "_subject": "File Systems"}, {"id": 1, "type": "CodeAnalysis", "topic": ["File Systems", "Sparse Files", "System Calls", "lseek", "write"], "content": {"text": "נתונה תוכנית ה-C הבאה המבצעת פעולות על קובץ במערכת קבצים מסוג ext4 (או כל מערכת קבצים נפוצה אחרת התומכת בקבצים דלילים - sparse files). יש להניח שגודל הבלוק במערכת הקבצים הוא 4096 בתים (4KB). התוכנית רצה בסביבה שבה היא יכולה ליצור קבצים ולכתוב אליהם בהצלחה.\n\nלאחר שהתוכנית מסיימת את ריצתה, ענו על השאלות הבאות:\n1. מה יהיה גודלו הלוגי של הקובץ `sparse_file_test.bin` כפי שיוצג על ידי פקודת `ls -l` (השדה שמציין את מספר הבתים בקובץ)? נמקו.\n2. כמה בלוקים פיזיים (מגודל 4KB כל אחד) יוקצו בפועל על הדיסק עבור הקובץ `sparse_file_test.bin`? נמקו.\n3. אם נקרא את תוכן הקובץ מתחילתו ועד סופו (באופן לוגי) באמצעות קריאות `read` רצופות, מה יהיו 10 הבתים הראשונים שנקראו? ומה יהיה הבייט האחרון שנקרא (במיקום `seek_offset` + 1 - 1)? נמקו.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <fcntl.h>\n#include <string.h>\n#include <sys/stat.h>\n\n#define FILENAME \"sparse_file_test.bin\"\n\nint main() {\n    int fd;\n    char initial_data[] = \"START\"; // 5 bytes\n    char final_data = 'E';         // 1 byte\n    off_t seek_offset = 100 * 1024 * 1024; // 100 MB\n\n    // Open the file for writing, create if it doesn't exist, truncate if it does\n    fd = open(FILENAME, O_CREAT | O_TRUNC | O_WRONLY, 0644);\n    if (fd == -1) {\n        perror(\"Error opening file\");\n        return 1;\n    }\n\n    // Write initial data\n    if (write(fd, initial_data, strlen(initial_data)) == -1) {\n        perror(\"Error writing initial data\");\n        close(fd);\n        return 1;\n    }\n\n    // Seek to a large offset\n    if (lseek(fd, seek_offset, SEEK_SET) == (off_t)-1) {\n        perror(\"Error seeking\");\n        close(fd);\n        return 1;\n    }\n\n    // Write a single byte at the new offset\n    if (write(fd, &final_data, 1) == -1) {\n        perror(\"Error writing final data\");\n        close(fd);\n        return 1;\n    }\n\n    // Close the file\n    close(fd);\n\n    // The program ends here.\n    return 0;\n}"}, "sub_questions": null, "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. **גודל לוגי של הקובץ:**\n   הגודל הלוגי של הקובץ נקבע על ידי המיקום הגבוה ביותר אליו נכתב בייט כלשהו, בתוספת מספר הבתים שנכתבו באותה פעולה. בתחילה נכתבים 5 בתים (\"START\"), מה שקובע את גודל הקובץ ל-5 בתים. לאחר מכן, מתבצעת קריאת `lseek` למיקום `100 * 1024 * 1024` בתים (שהם 104,857,600 בתים). קריאת `lseek` לבדה אינה משנה את גודל הקובץ. רק פעולת כתיבה (write) במיקום זה או מעבר לו תגדיל את גודל הקובץ. לבסוף, נכתב בייט יחיד ('E') במיקום זה. לכן, הגודל הלוגי של הקובץ יהיה `104,857,600 + 1 = 104,857,601` בתים. פקודת `ls -l` תציג גודל זה.\n\n2. **בלוקים פיזיים שיוקצו על הדיסק:**\n   מערכות קבצים מודרניות רבות (כמו ext4) תומכות בקבצים דלילים (sparse files). המשמעות היא שפערים גדולים בקובץ שנוצרו על ידי `lseek` מעבר ל-EOF ואז כתיבה, אינם גורמים להקצאת בלוקים פיזיים על הדיסק עבור הפער. בלוקים מוקצים רק כאשר נתונים נכתבים בפועל לתוכם. במקרה זה:\n   *   הכתיבה הראשונית של \"START\" (5 בתים) תדרוש בלוק פיזי אחד (כי 5 בתים קטנים מ-4096 בתים, אך עדיין תופסים בלוק שלם).\n   *   קריאת ה-`lseek` לא תקצה בלוקים עבור הפער של כמעט 100MB.\n   *   הכתיבה של הבייט היחיד 'E' במיקום `104,857,600` תדרוש הקצאת בלוק פיזי נוסף (הבלוק המכיל את המיקום הזה).\n   לכן, סך הכל יוקצו 2 בלוקים פיזיים על הדיסק עבור הקובץ (1 בלוק לנתונים הראשונים, 1 בלוק לנתון האחרון). הגודל הפיזי שיתפוס הקובץ על הדיסק יהיה `2 * 4096 = 8192` בתים.\n\n3. **תוכן הקובץ בקריאה:**\n   *   **10 הבתים הראשונים:** הקובץ מתחיל עם הנתונים \"START\" (5 בתים). הפער שנוצר בין סוף הכתיבה הראשונית (בייט 5) ועד לתחילת הכתיבה במיקום `104,857,600` (בייט 104,857,600) יכיל מבחינה לוגית בתים עם ערך אפס (null bytes, '\\0'). לכן, 10 הבתים הראשונים שנקראו יהיו: `'S', 'T', 'A', 'R', 'T', '\\0', '\\0', '\\0', '\\0', '\\0'` (כלומר, \"START\" ואחריו 5 אפסים).\n   *   **הבייט האחרון שנקרא (במיקום `seek_offset` + 1 - 1):** הבייט האחרון שנקרא באופן לוגי הוא הבייט שהוצב במיקום `seek_offset`, שהוא 'E'. כלומר, הבייט במיקום `104,857,600` יכיל את התו 'E'."}, "difficulty_estimation": "Hard", "_source_file": "0713__File_Systems__CodeAnalysis__Hard.json", "_topic_hint": "File Systems", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:48:47", "_subject": "File Systems"}, {"id": 101, "type": "CodeAnalysis", "topic": ["File Systems", "Hard Links", "Processes", "System Calls"], "content": {"text": "נתונה תוכנית C הבאה המדגימה יצירת קובץ, קישורים קשיחים (hard links), פעולות מחיקה (unlink) וגישה לקובץ מתהליכים שונים.\nקראו את הקוד בעיון וענו על השאלות הבאות.\nיש להניח שכל קריאות המערכת מצליחות, ואין שגיאות I/O.\nיש להתייחס למערכת הפעלה מבוססת POSIX.\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <fcntl.h>\n#include <sys/stat.h>\n#include <string.h>\n#include <sys/wait.h>\n\n#define FILENAME_ORIG \"exam_file_orig.txt\"\n#define FILENAME_LINK \"exam_file_link.txt\"\n#define BUF_SIZE 10\n\nint main() {\n    int fd_parent;\n    char buffer[BUF_SIZE];\n    pid_t pid;\n\n    // 1. Create a file and write initial content\n    fd_parent = open(FILENAME_ORIG, O_CREAT | O_TRUNC | O_RDWR, 0644);\n    if (fd_parent == -1) {\n        perror(\"open FILENAME_ORIG\");\n        return EXIT_FAILURE;\n    }\n    write(fd_parent, \"AAAABBBBCC\", BUF_SIZE); // Write 10 bytes\n    printf(\"Parent[%d]: Wrote 'AAAABBBBCC' to %s, fd_parent = %d\\n\", getpid(), FILENAME_ORIG, fd_parent);\n    fflush(stdout);\n\n    // 2. Create a hard link\n    if (link(FILENAME_ORIG, FILENAME_LINK) == -1) {\n        perror(\"link\");\n        close(fd_parent);\n        unlink(FILENAME_ORIG); // Clean up if link fails\n        return EXIT_FAILURE;\n    }\n    printf(\"Parent[%d]: Created hard link %s to %s\\n\", getpid(), FILENAME_LINK, FILENAME_ORIG);\n    fflush(stdout);\n\n    // 3. Unlink the original path name\n    if (unlink(FILENAME_ORIG) == -1) {\n        perror(\"unlink FILENAME_ORIG\");\n        close(fd_parent);\n        unlink(FILENAME_LINK); // Clean up\n        return EXIT_FAILURE;\n    }\n    printf(\"Parent[%d]: Unlinked original file path %s\\n\", getpid(), FILENAME_ORIG);\n    fflush(stdout);\n    // At this point, the file's link count is 1 (due to FILENAME_LINK)\n    // and it's still open via fd_parent.\n\n    // 4. Fork a child process\n    pid = fork();\n\n    if (pid == -1) {\n        perror(\"fork\");\n        close(fd_parent);\n        unlink(FILENAME_LINK); // Clean up\n        return EXIT_FAILURE;\n    }\n\n    if (pid == 0) { // Child process\n        int fd_child;\n        printf(\"Child[%d]: Starting.\\n\", getpid());\n        fflush(stdout);\n\n        // Child closes its inherited fd_parent to ensure it opens a new one\n        close(fd_parent);\n\n        // Child opens the file via the hard link path\n        fd_child = open(FILENAME_LINK, O_RDWR);\n        if (fd_child == -1) {\n            perror(\"Child: open FILENAME_LINK\");\n            exit(EXIT_FAILURE);\n        }\n        printf(\"Child[%d]: Opened %s, fd_child = %d\\n\", getpid(), FILENAME_LINK, fd_child);\n        fflush(stdout);\n\n        // Child seeks and writes\n        lseek(fd_child, 0, SEEK_SET); // Seek to beginning\n        write(fd_child, \"XXXX\", 4);   // Overwrite first 4 bytes\n        printf(\"Child[%d]: Wrote 'XXXX' to file via fd_child\\n\", getpid());\n        fflush(stdout);\n\n        lseek(fd_child, 8, SEEK_SET); // Seek to offset 8\n        write(fd_child, \"YY\", 2);     // Overwrite bytes at offset 8, 9\n        printf(\"Child[%d]: Wrote 'YY' to file via fd_child\\n\", getpid());\n        fflush(stdout);\n\n        close(fd_child);\n        printf(\"Child[%d]: Closed fd_child.\\n\", getpid());\n        fflush(stdout);\n        exit(EXIT_SUCCESS);\n\n    } else { // Parent process\n        printf(\"Parent[%d]: Forked child with PID = %d\\n\", getpid(), pid);\n        fflush(stdout);\n\n        // Parent waits for child to finish\n        wait(NULL);\n        printf(\"Parent[%d]: Child finished.\\n\", getpid());\n        fflush(stdout);\n\n        // Parent writes to the file *after* child is done\n        // Parent's fd_parent still points to the file. Its offset is still at BUF_SIZE (10).\n        lseek(fd_parent, 4, SEEK_SET); // Seek to offset 4\n        write(fd_parent, \"ZZZ\", 3);    // Overwrite bytes at offset 4, 5, 6\n        printf(\"Parent[%d]: Wrote 'ZZZ' to file via fd_parent\\n\", getpid());\n        fflush(stdout);\n\n        // Parent reads the final content of the file\n        lseek(fd_parent, 0, SEEK_SET); // Seek to beginning to read\n        ssize_t bytes_read = read(fd_parent, buffer, BUF_SIZE);\n        if (bytes_read == -1) {\n            perror(\"Parent: read final content\");\n        } else {\n            buffer[bytes_read] = '\\0';\n            printf(\"Parent[%d]: Final content of the file: '%s'\\n\", getpid(), buffer);\n            fflush(stdout);\n        }\n\n        // 5. Unlink the hard link path\n        if (unlink(FILENAME_LINK) == -1) {\n            perror(\"unlink FILENAME_LINK\");\n        }\n        printf(\"Parent[%d]: Unlinked hard link path %s.\\n\", getpid(), FILENAME_LINK);\n        fflush(stdout);\n        // Now link count is 0. File data will be deallocated upon closing all FDs.\n\n        // 6. Close the parent's file descriptor\n        close(fd_parent);\n        printf(\"Parent[%d]: Closed fd_parent. File data should now be deallocated.\\n\", getpid());\n        fflush(stdout);\n\n        // Try to open the file paths to confirm they are gone\n        if (open(FILENAME_ORIG, O_RDONLY) == -1) {\n            printf(\"Parent[%d]: Confirmed %s is gone.\\n\", getpid(), FILENAME_ORIG);\n            fflush(stdout);\n        }\n        if (open(FILENAME_LINK, O_RDONLY) == -1) {\n            printf(\"Parent[%d]: Confirmed %s is gone.\\n\", getpid(), FILENAME_LINK);\n            fflush(stdout);\n        }\n    }\n\n    return EXIT_SUCCESS;\n}\n```\n\n**שאלות:**\n1.  מה יהיה התוכן הסופי של הקובץ כפי שייקרא על ידי תהליך האב בסוף הריצה (שורות 68-75)?\n2.  באיזה שלב, אם בכלל, נתוני הקובץ יפונו מהדיסק? הסבירו מדוע.", "code_snippet": null, "options": null}, "sub_questions": null, "points": 20, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "1.  **תוכן הקובץ הסופי:**\n    התוכן הסופי של הקובץ יהיה \"XXXXZZZBYY\".\n    \n    **הסבר מפורט:**\n    *   **אתחול (שורה 21):** הקובץ נוצר עם התוכן \"AAAABBBBCC\".\n        מצב הקובץ: `AAAABBBBCC`\n    *   **תהליך בן (Child process):**\n        *   הבן סוגר את `fd_parent` שירש ופותח מחדש את הקובץ דרך הקישור הקשיח `FILENAME_LINK` ומקבל `fd_child` (שורות 40-47). לכן, ל-`fd_parent` של האב ול-`fd_child` של הבן יש מצבי היסט קריאה/כתיבה (file offset) בלתי תלויים, למרות שהם מצביעים על אותו קובץ פיזי (אותו inode).\n        *   הבן מבצע `lseek(fd_child, 0, SEEK_SET)` וממקם את ההיסט בתחילת הקובץ. לאחר מכן כותב `\"XXXX\"` (שורה 50).\n            מצב הקובץ: `XXXXBBBBCC`\n        *   הבן מבצע `lseek(fd_child, 8, SEEK_SET)` וממקם את ההיסט במיקום 8. לאחר מכן כותב `\"YY\"` (שורה 54).\n            מצב הקובץ: `XXXXBBBBYY` (תווים 'C','C' נדרסים על ידי 'Y','Y').\n        *   הבן סוגר את `fd_child` ויוצא.\n    *   **תהליך אב (Parent process):**\n        *   האב ממתין שהבן יסיים (שורה 62).\n        *   האב מבצע `lseek(fd_parent, 4, SEEK_SET)` וממקם את ההיסט במיקום 4 (ההיסט של `fd_parent` נשאר 10 מהכתיבה הראשונית). לאחר מכן כותב `\"ZZZ\"` (שורה 66).\n            מצב הקובץ: `XXXXZZZBYY` (תווים 'B','B','B' נדרסים על ידי 'Z','Z','Z').\n        *   האב קורא את התוכן הסופי (שורות 68-75).\n\n2.  **פינוי נתוני הקובץ מהדיסק:**\n    נתוני הקובץ יפונו מהדיסק רק כאשר שני התנאים הבאים מתקיימים:\n    א.  מונה הקישורים (link count) של הקובץ מגיע ל-0.\n    ב.  אין יותר file descriptors פתוחים המצביעים על הקובץ.\n    \n    **ניתוח שלבי הפינוי בקוד:**\n    *   **שורה 32 (`unlink(FILENAME_ORIG)`):** קריאה זו מסירה את השם המקורי של הקובץ מספריית הקבצים. מונה הקישורים של הקובץ יורד מ-2 ל-1 (כי עדיין קיים הקישור הקשיח `FILENAME_LINK`). הקובץ עדיין נגיש דרך `FILENAME_LINK` ודרך `fd_parent` הפתוח.\n    *   **שורה 80 (`unlink(FILENAME_LINK)`):** קריאה זו מסירה גם את הקישור הקשיח `FILENAME_LINK` מספריית הקבצים. כעת, מונה הקישורים של הקובץ מגיע ל-0. אולם, נתוני הקובץ **עדיין לא מפוּנים מהדיסק** מכיוון ש-`fd_parent` עדיין פתוח בתהליך האב.\n    *   **שורה 86 (`close(fd_parent)`):** קריאה זו סוגרת את ה-file descriptor הפתוח האחרון המצביע על הקובץ. ברגע זה, מכיוון שגם מונה הקישורים הוא 0 וגם אין file descriptors פתוחים, מערכת ההפעלה תפנה את ה-inode ואת בלוקי הנתונים של הקובץ מהדיסק. כלומר, הקובץ מפונה רק בשלב זה."}, "difficulty_estimation": "Hard", "_source_file": "0714__File_Systems__CodeAnalysis__Hard.json", "_topic_hint": "File Systems", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:49:33", "_subject": "File Systems"}, {"id": 101, "type": "CodeAnalysis", "topic": ["File Systems", "Hard Links", "System Calls", "Inode Management"], "content": {"text": "נתונה תוכנית C הבאה המבצעת פעולות שונות על קבצים וקישורים קשיחים (hard links). נתחו את הקוד וציינו מה יהיה הפלט המדויק של התוכנית. הסבירו כל שורת פלט בפירוט, תוך התייחסות למצב הקובץ (מספר הקישורים הקשיחים אליו, גודלו ותוכנו הפנימי) לאחר כל פעולת מערכת משמעותית.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <fcntl.h>\n#include <sys/stat.h>\n#include <string.h>\n\nint main() {\n    const char* file_name = \"data.txt\";\n    const char* link_name = \"link_to_data.txt\";\n    int fd;\n    struct stat sb;\n\n    // 1. Create file and write initial content\n    fd = open(file_name, O_CREAT | O_WRONLY | O_TRUNC, 0644);\n    if (fd == -1) { perror(\"open\"); return 1; }\n    write(fd, \"Original\", 8);\n    close(fd);\n\n    // 2. Create a hard link\n    if (link(file_name, link_name) == -1) { perror(\"link\"); return 1; }\n\n    // 3. Open the original file name again, then unlink it\n    fd = open(file_name, O_WRONLY | O_APPEND);\n    if (fd == -1) { perror(\"open again\"); return 1; }\n    \n    if (unlink(file_name) == -1) { perror(\"unlink original\"); return 1; }\n\n    // 4. Write more content through the open file descriptor\n    write(fd, \" Appended\", 9);\n\n    // 5. Check status of the link name before closing the fd\n    if (stat(link_name, &sb) == -1) { perror(\"stat link_name (before close)\"); return 1; }\n    printf(\"A: Inode: %ld, Links: %ld, Size: %lld\\n\", (long)sb.st_ino, (long)sb.st_nlink, (long long)sb.st_size);\n\n    // 6. Close the file descriptor\n    close(fd);\n\n    // 7. Check status of the link name after closing the fd\n    if (stat(link_name, &sb) == -1) { perror(\"stat link_name (after close)\"); return 1; }\n    printf(\"B: Inode: %ld, Links: %ld, Size: %lld\\n\", (long)sb.st_ino, (long)sb.st_nlink, (long long)sb.st_size);\n\n    // 8. Unlink the hard link\n    if (unlink(link_name) == -1) { perror(\"unlink link\"); return 1; }\n\n    // 9. Try to stat the link name one last time\n    if (stat(link_name, &sb) == -1) {\n        printf(\"C: %s does not exist.\\n\", link_name);\n    } else {\n        printf(\"C: Error: %s still exists.\\n\", link_name);\n    }\n\n    return 0;\n}"}, "sub_questions": null, "points": 20, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "הפלט המדויק של התוכנית יהיה (מספר ה-Inode יהיה תלוי במערכת): \n```\nA: Inode: <inode_number>, Links: 1, Size: 17\nB: Inode: <inode_number>, Links: 1, Size: 17\nC: link_to_data.txt does not exist.\n```\n\nלהלן פירוט הפעולות וההסבר:\n\n**שלב 1: יצירת קובץ וכתיבה אליו (`open`, `write`, `close`)**\n- התוכנית יוצרת קובץ בשם `data.txt` עם הרשאות 0644. נכתב לתוכו התוכן \"Original\" (8 בתים).\n- לאחר ה-`close(fd)`, ה-inode של הקובץ `data.txt` קיים במערכת הקבצים. יש לו קישור קשיח אחד (link count = 1) ושמו `data.txt` מצביע אליו. גודלו 8 בתים.\n\n**שלב 2: יצירת קישור קשיח (`link`)**\n- נוצר קישור קשיח בשם `link_to_data.txt` המצביע לאותו inode כמו `data.txt`. \n- כעת, ל-inode יש 2 קישורים קשיחים (link count = 2). גם `data.txt` וגם `link_to_data.txt` הם שמות חוקיים לאותו קובץ בדיוק. גודל הקובץ נשאר 8 בתים והתוכן \"Original\".\n\n**שלב 3: פתיחת הקובץ המקורי ומחיקתו (`open`, `unlink`)**\n- הקובץ `data.txt` נפתח שוב (`fd` חדש) במצב הוספה (`O_APPEND`). פעולה זו יוצרת התייחסות נוספת ל-inode בקרנל (לא משפיע על ה-link count).\n- מיד לאחר מכן, `unlink(file_name)` מבוצע. פעולה זו מסירה את הערך `data.txt` מספריית הקבצים. כתוצאה מכך, ה-link count של ה-inode יורד ל-1 (כי `link_to_data.txt` עדיין קיים). \n- חשוב לציין שה-inode עצמו *אינו נמחק* בשלב זה, מכיוון ש:\n    1. ה-link count עדיין אינו 0 (הוא 1, בגלל `link_to_data.txt`).\n    2. קיים file descriptor פתוח (ה-`fd` החדש) שמחזיק התייחסות ל-inode.\n- לכן, הקובץ עדיין נגיש דרך `link_to_data.txt` ודרך ה-`fd` הפתוח.\n\n**שלב 4: כתיבה נוספת דרך ה-file descriptor הפתוח (`write`)**\n- נכתב התוכן \" Appended\" (9 בתים) דרך ה-`fd` הפתוח (שנפתח עם `O_APPEND`).\n- תוכן הקובץ הופך ל-\"Original Appended\". גודל הקובץ גדל ל-8 + 9 = 17 בתים. \n- שימו לב: הכתיבה מתבצעת בהצלחה למרות ששמו המקורי של הקובץ (`data.txt`) נמחק, כי ה-file descriptor עדיין מצביע ל-inode התקין.\n\n**שלב 5: בדיקת מצב הקישור הקשיח לפני סגירת ה-fd (`stat`)**\n- `stat(link_name)` מבוצע על `link_to_data.txt`. \n- **פלט A**: \n    - `Inode`: יהיה מספר ה-inode המקורי (זהה לאורך כל הריצה). \n    - `Links`: יהיה 1, מכיוון ש-`data.txt` נמחק ב-`unlink` בשלב 3.\n    - `Size`: יהיה 17, מכיוון שהתוכן \" Appended\" נכתב בשלב 4.\n\n**שלב 6: סגירת ה-file descriptor (`close`)**\n- `close(fd)` מבוצע. פעולה זו משחררת את התייחסות ה-kernel ל-inode דרך ה-file descriptor. \n- ה-link count של ה-inode נשאר 1. ה-inode עדיין לא נמחק כי ה-link count אינו 0.\n\n**שלב 7: בדיקת מצב הקישור הקשיח לאחר סגירת ה-fd (`stat`)**\n- `stat(link_name)` מבוצע שוב. \n- **פלט B**: \n    - `Inode`: יהיה אותו מספר inode. \n    - `Links`: יהיה 1 (לא השתנה מ-`close`).\n    - `Size`: יהיה 17 (לא השתנה מ-`close`).\n\n**שלב 8: מחיקת הקישור הקשיח (`unlink`)**\n- `unlink(link_name)` מבוצע. פעולה זו מסירה את הערך `link_to_data.txt` מספריית הקבצים. \n- כעת, ה-link count של ה-inode יורד ל-0. מכיוון שאין יותר קישורים קשיחים ל-inode ואין יותר file descriptors פתוחים המצביעים אליו (ה-`fd` נסגר בשלב 6), ה-inode נמחק סופית ממערכת הקבצים.\n\n**שלב 9: ניסיון אחרון לבדוק את מצב הקישור הקשיח (`stat`)**\n- `stat(link_name)` מבוצע שוב. מכיוון שה-inode נמחק בשלב 8, הקובץ `link_to_data.txt` כבר אינו קיים במערכת הקבצים. \n- `stat` יחזיר -1 ויציג הודעת שגיאה (כמו \"No such file or directory\").\n- **פלט C**: התוכנית תדפיס: `C: link_to_data.txt does not exist.`"}, "difficulty_estimation": "Hard", "_source_file": "0715__File_Systems__CodeAnalysis__Hard.json", "_topic_hint": "File Systems", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:50:08", "_subject": "File Systems"}, {"id": 10, "type": "CodeAnalysis", "topic": ["File Systems", "System Calls", "Processes", "Links"], "content": {"text": "נתונה התוכנית הבאה, המדגימה פעולות על מערכת קבצים בסביבת יוניקס. יש להניח שכל קריאות המערכת מצליחות, ואין שגיאות I/O למעט אלו שעשויות להיות צפויות מלוגיקת התוכנית עצמה.\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <fcntl.h>\n#include <sys/stat.h>\n#include <string.h>\n#include <sys/wait.h>\n#include <errno.h>\n\nint main() {\n    const char *original_file = \"data.txt\";\n    const char *hard_link = \"hlink.txt\";\n    const char *sym_link = \"slink.txt\";\n    char buffer[50];\n    int fd;\n\n    // 1. יצירת קובץ מקורי וכתיבת תוכן אליו\n    fd = open(original_file, O_CREAT | O_WRONLY | O_TRUNC, 0644);\n    write(fd, \"Hello World\", strlen(\"Hello World\"));\n    close(fd);\n\n    // 2. יצירת קישור קשיח (hard link) לקובץ המקורי\n    link(original_file, hard_link);\n\n    // 3. יצירת קישור סימלי (symbolic link) לקובץ המקורי\n    symlink(original_file, sym_link);\n\n    pid_t pid = fork();\n    if (pid == -1) { perror(\"fork\"); return 1; }\n\n    if (pid == 0) { // תהליך הבן\n        // 4. הבן מוחק את הקובץ המקורי (מבטל את הקישור בספרייה)\n        unlink(original_file);\n\n        // 5. הבן מנסה לפתוח/ליצור מחדש את הקובץ המקורי עם דגל O_CREAT | O_EXCL\n        fd = open(original_file, O_CREAT | O_EXCL | O_WRONLY, 0600);\n        if (fd != -1) { // בהנחה שהפעולה מצליחה\n            write(fd, \"Child's new data\", strlen(\"Child's new data\"));\n            close(fd);\n        }\n        exit(0);\n    } else { // תהליך האב\n        wait(NULL); // ממתין שהבן יסיים\n\n        // 6. האב קורא מתוך הקישור הקשיח\n        fd = open(hard_link, O_RDONLY);\n        if (fd != -1) {\n            memset(buffer, 0, sizeof(buffer));\n            ssize_t bytes_read = read(fd, buffer, sizeof(buffer) - 1);\n            if (bytes_read > 0) buffer[bytes_read] = '\\0';\n            printf(\"Content of '%s': '%s'\\n\", hard_link, buffer);\n            close(fd);\n        }\n\n        // 7. האב קורא מתוך הקישור הסימלי\n        fd = open(sym_link, O_RDONLY);\n        if (fd != -1) {\n            memset(buffer, 0, sizeof(buffer));\n            ssize_t bytes_read = read(fd, buffer, sizeof(buffer) - 1);\n            if (bytes_read > 0) buffer[bytes_read] = '\\0';\n            printf(\"Content of '%s': '%s'\\n\", sym_link, buffer);\n            close(fd);\n        }\n        \n        // 8. האב קורא מתוך הקובץ המקורי (שייתכן שהבן יצר מחדש)\n        fd = open(original_file, O_RDONLY);\n        if (fd != -1) {\n            memset(buffer, 0, sizeof(buffer));\n            ssize_t bytes_read = read(fd, buffer, sizeof(buffer) - 1);\n            if (bytes_read > 0) buffer[bytes_read] = '\\0';\n            printf(\"Content of '%s': '%s'\\n\", original_file, buffer);\n            close(fd);\n        }\n\n        // ניקוי קבצים (לא חלק מהפלט המבוקש)\n        unlink(hard_link);\n        unlink(sym_link);\n        unlink(original_file);\n    }\n    return 0;\n}\n```\n\nהסבירו מה יהיה הפלט המודפס למסך על ידי תהליך האב (Parent) עבור שלבי הקריאה (6, 7 ו-8). פרטו את ההסבר לכל שלב, כולל שינויים במבנה מערכת הקבצים (כגון מונים של קישורים (link count) ואינודים (inodes)) כתוצאה מפעולות התוכנית.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כדי להבין את הפלט, נתח את שינויי מערכת הקבצים לאורך ריצת התוכנית:\n\n**מצב התחלתי (לפני ה-fork):**\n1.  **`open(original_file, O_CREAT | O_WRONLY | O_TRUNC, 0644)` ו-`write(\"Hello World\")`:**\n    *   נוצר קובץ בשם `data.txt`. מערכת הקבצים מקצה לו אינוד חדש (נניח **אינוד X**). תוכן הקובץ הוא \"Hello World\". מונה הקישורים (link count) של אינוד X הוא 1.\n2.  **`link(original_file, hard_link)`:**\n    *   נוצר קישור קשיח בשם `hlink.txt` המצביע גם הוא לאינוד X. מונה הקישורים של אינוד X עולה ל-2.\n3.  **`symlink(original_file, sym_link)`:**\n    *   נוצר קישור סימלי בשם `slink.txt`. זהו קובץ חדש בפני עצמו, המקבל אינוד משלו (נניח **אינוד Y**). תוכן אינוד Y הוא המחרוזת \"data.txt\". מונה הקישורים של אינוד Y הוא 1. אינוד X נשאר עם מונה קישורים של 2.\n\n**לאחר ה-fork (בתהליך הבן):**\n4.  **תהליך הבן: `unlink(original_file)`:**\n    *   הכניסה `data.txt` נמחקת מהספרייה. מונה הקישורים של אינוד X יורד ל-1 (בגלל ש-`hlink.txt` עדיין מצביע עליו). נתוני הקובץ באינוד X **אינם נמחקים** מהדיסק כל עוד מונה הקישורים גדול מ-0 (או שיש קבצים פתוחים המצביעים על האינוד).\n5.  **תהליך הבן: `open(original_file, O_CREAT | O_EXCL | O_WRONLY, 0600)` ו-`write(\"Child's new data\")`:**\n    *   מכיוון ש-`data.txt` נמחק בשלב הקודם (כלומר, אין כניסה כזו בספרייה), קריאת `open` עם `O_CREAT | O_EXCL` **מצליחה** ליצור קובץ *חדש* בשם `data.txt`. קובץ זה יקבל אינוד חדש משלו (נניח **אינוד Z**). תוכן הקובץ החדש הוא \"Child's new data\". מונה הקישורים של אינוד Z הוא 1.\n    *   **חשוב**: אינוד X (המכיל \"Hello World\") עדיין קיים ומצביע עליו `hlink.txt`. אינוד Y (הקישור הסימלי) עדיין מצביע על השם `data.txt`.\n\n**לאחר שהבן מסיים (בתהליך האב):**\nתהליך האב ממתין לבן באמצעות `wait(NULL)`.\n\n6.  **תהליך האב: `open(hard_link, O_RDONLY)` ו-`printf(\"Content of '%s': '%s'\\n\", hard_link, buffer)`:**\n    *   האב פותח את `hlink.txt`. קישור קשיח מצביע ישירות על האינוד המקורי. `hlink.txt` עדיין מצביע על **אינוד X**, שהכיל את הנתונים המקוריים \"Hello World\".\n    *   **פלט:** `Content of 'hlink.txt': 'Hello World'`\n\n7.  **תהליך האב: `open(sym_link, O_RDONLY)` ו-`printf(\"Content of '%s': '%s'\\n\", sym_link, buffer)`:**\n    *   האב פותח את `slink.txt`. קישור סימלי מכיל שם של קובץ (במקרה זה, \"data.txt\"). מערכת ההפעלה פותרת (resolves) את הנתיב `data.txt`. מכיוון שהבן יצר קובץ *חדש* בשם `data.txt` (המצביע על אינוד Z), הקישור הסימלי יצביע כעת לקובץ החדש הזה.\n    *   **פלט:** `Content of 'slink.txt': 'Child's new data'`\n\n8.  **תהליך האב: `open(original_file, O_RDONLY)` ו-`printf(\"Content of '%s': '%s'\\n\", original_file, buffer)`:**\n    *   האב פותח את `data.txt`. מכיוון שהבן יצר קובץ *חדש* בשם `data.txt` (המצביע על אינוד Z), האב יפתח את הקובץ החדש הזה.\n    *   **פלט:** `Content of 'data.txt': 'Child's new data'`\n\n**סיכום הפלט המודפס על ידי תהליך האב:**\n```\nContent of 'hlink.txt': 'Hello World'\nContent of 'slink.txt': 'Child's new data'\nContent of 'data.txt': 'Child's new data'\n```"}, "difficulty_estimation": "Hard", "_source_file": "0716__File_Systems__CodeAnalysis__Hard.json", "_topic_hint": "File Systems", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:50:47", "_subject": "File Systems"}, {"id": 10, "type": "CodeAnalysis", "topic": ["File Systems", "Links", "Inodes", "Processes", "System Calls"], "content": {"text": "נתונה תוכנית C המבצעת סדרת פעולות על קבצים וקישורים (links) במערכת הקבצים, תוך שימוש בתהליכי אב ובן. מטרת השאלה היא לנתח את מצב מערכת הקבצים והפלט של התוכנית לאחר ביצוע כל הפעולות.\n\nיש להניח כי כל קריאות המערכת מצליחות, וכי התוכנית רצה בסביבה נקייה בה הקבצים `fileA.txt`, `linkH.txt`, ו-`linkS.txt` אינם קיימים לפני הרצת התוכנית.\n\nנתחו את הקוד וציינו במדויק מה יהיה הפלט המודפס למסך, ומה יהיה מצב מערכת הקבצים הסופי עבור כל אחד מהנתיבים `fileA.txt`, `linkH.txt`, ו-`linkS.txt` (האם קיים, אם כן, מה מספר ה-inode שלו, כמה קישורים קשיחים מצביעים אליו, ואם הוא קישור סימבולי, למי הוא מצביע. כמו כן, מה תהיה תכולת הקובץ המקורי אם ניתן יהיה לגשת אליו דרך קישור כלשהו).", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/types.h>\n#include <sys/stat.h>\n#include <fcntl.h>\n#include <string.h>\n#include <errno.h>\n\n// פונקציית עזר להדפסת מידע על קובץ/קישור\nvoid print_file_info(const char* path, const char* label) {\n    struct stat st;\n    printf(\"--- %s (%s) ---\\n\", label, path);\n    if (lstat(path, &st) == -1) { // שימוש ב-lstat כדי להבחין בין קישור סימבולי למטרה שלו\n        if (errno == ENOENT) {\n            printf(\"File/Link '%s' does not exist.\\n\", path);\n        } else {\n            perror(\"lstat error\");\n        }\n        return;\n    }\n    printf(\"Inode: %ld\\n\", (long)st.st_ino);\n    printf(\"Links: %ld\\n\", (long)st.st_nlink);\n    if (S_ISLNK(st.st_mode)) {\n        char buf[256];\n        ssize_t len = readlink(path, buf, sizeof(buf) - 1);\n        if (len != -1) {\n            buf[len] = '\\0';\n            printf(\"Symlink points to: %s\\n\", buf);\n        } else {\n            perror(\"readlink error\");\n        }\n    }\n    // מדפיס תוכן אם זה קובץ רגיל או קישור סימבולי תקין לקובץ רגיל\n    // stat(path, &st) עוקב אחר קישורים סימבוליים. אם הוא נכשל, זה אומר שהיעד לא קיים.\n    if (S_ISREG(st.st_mode) || (S_ISLNK(st.st_mode) && stat(path, &st) != -1 && S_ISREG(st.st_mode))) {\n        FILE* f = fopen(path, \"r\");\n        if (f) {\n            printf(\"Content: \\\"\");\n            int c;\n            while ((c = fgetc(f)) != EOF) {\n                putchar(c);\n            }\n            printf(\"\\\"\\n\");\n            fclose(f);\n        } else {\n            perror(\"fopen for content read error\");\n        }\n    }\n}\n\nint main() {\n    const char* fileA = \"fileA.txt\";\n    const char* linkH = \"linkH.txt\";\n    const char* linkS = \"linkS.txt\";\n\n    // ניקוי ריצות קודמות\n    unlink(fileA);\n    unlink(linkH);\n    unlink(linkS);\n\n    // 1. יצירת fileA.txt וכתיבת \"Hello\" אליו\n    FILE* f_a = fopen(fileA, \"w\");\n    if (!f_a) { perror(\"fopen fileA\"); return 1; }\n    fprintf(f_a, \"Hello\");\n    fclose(f_a);\n\n    printf(\"Initial state:\\n\");\n    print_file_info(fileA, \"fileA\");\n\n    // 2. יצירת קישור קשיח linkH.txt ל-fileA.txt\n    if (link(fileA, linkH) == -1) { perror(\"link hard\"); return 1; }\n\n    // 3. יצירת קישור סימבולי linkS.txt המצביע על fileA.txt\n    if (symlink(fileA, linkS) == -1) { perror(\"symlink soft\"); return 1; }\n\n    printf(\"\\nAfter creating links:\\n\");\n    print_file_info(fileA, \"fileA\");\n    print_file_info(linkH, \"linkH\");\n    print_file_info(linkS, \"linkS\");\n\n    pid_t pid = fork();\n\n    if (pid == -1) {\n        perror(\"fork error\");\n        return 1;\n    } else if (pid == 0) { // תהליך הבן\n        printf(\"\\n--- Child Process (%d) ---\\n\", getpid());\n        // פתיחת fileA.txt לכתיבה, כתיבת \" child\"\n        f_a = fopen(fileA, \"a\"); // הוספה לתוכן קיים\n        if (!f_a) { perror(\"child fopen fileA\"); exit(1); }\n        fprintf(f_a, \" child\");\n        fclose(f_a);\n        printf(\"Child wrote to %s.\\n\", fileA);\n\n        // מחיקת linkH.txt\n        if (unlink(linkH) == -1) { perror(\"child unlink linkH\"); exit(1); }\n        printf(\"Child unlinked %s.\\n\", linkH);\n\n        exit(0);\n    } else { // תהליך האב\n        printf(\"\\n--- Parent Process (%d) ---\\n\", getpid());\n        int status;\n        wait(&status); // המתנה שהבן יסיים\n        printf(\"Parent finished waiting for child.\\n\");\n\n        // פתיחת linkS.txt לכתיבה, כתיבת \" parent\"\n        f_a = fopen(linkS, \"a\"); // הוספה לתוכן קיים, עוקב אחר הקישור הסימבולי\n        if (!f_a) { perror(\"parent fopen linkS\"); return 1; }\n        fprintf(f_a, \" parent\");\n        fclose(f_a);\n        printf(\"Parent wrote to %s (via symlink).\\n\", linkS);\n\n        // מחיקת fileA.txt\n        if (unlink(fileA) == -1) { perror(\"parent unlink fileA\"); return 1; }\n        printf(\"Parent unlinked %s.\\n\", fileA);\n\n        printf(\"\\nFinal state (from parent):\\n\");\n        print_file_info(fileA, \"fileA (after unlink)\");\n        print_file_info(linkH, \"linkH (after child unlink)\");\n        print_file_info(linkS, \"linkS\");\n    }\n\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכנית מבצעת את הפעולות הבאות:\n\n1.  **אתחול:**\n    *   התוכנית מוחקת קבצים קודמים בשמות `fileA.txt`, `linkH.txt`, `linkS.txt` אם קיימים.\n    *   יוצרת את `fileA.txt` וכותבת לתוכו \"Hello\".\n    *   **מצב ראשוני (לפני יצירת קישורים):**\n        *   `fileA.txt`: קיים. Inode: X (מספר כלשהו), קישורים קשיחים: 1, תוכן: \"Hello\".\n\n2.  **יצירת קישורים:**\n    *   `link(\"fileA.txt\", \"linkH.txt\")`: יוצר קישור קשיח (`linkH.txt`) ל-`fileA.txt`. כעת שני השמות מצביעים לאותו Inode X.\n    *   `symlink(\"fileA.txt\", \"linkS.txt\")`: יוצר קישור סימבולי (`linkS.txt`) המצביע על המחרוזת \"fileA.txt\". ל-`linkS.txt` יש Inode משלו (נניח Y), והוא מכיל את הנתיב \"fileA.txt\".\n    *   **מצב לאחר יצירת קישורים:**\n        *   `fileA.txt`: קיים. Inode: X, קישורים קשיחים: 2, תוכן: \"Hello\".\n        *   `linkH.txt`: קיים. Inode: X, קישורים קשיחים: 2, תוכן: \"Hello\".\n        *   `linkS.txt`: קיים. Inode: Y, קישורים קשיחים: 1 (עבור הקישור הסימבולי עצמו), מצביע ל-`fileA.txt`. תוכן (דרך המעקב אחר הקישור): \"Hello\".\n\n3.  **פיצול תהליכים (fork):**\n    *   התוכנית מתפצלת לתהליך אב ותהליך בן.\n\n4.  **תהליך הבן:**\n    *   פותח את `fileA.txt` במצב הוספה (`\"a\"`). זה פותח את Inode X.\n    *   כותב \" child\" לתוך הקובץ. תוכן Inode X הופך ל-\"Hello child\".\n    *   סוגר את הקובץ.\n    *   `unlink(\"linkH.txt\")`: מוחק את הערך `linkH.txt` מהתיקייה. מונה הקישורים הקשיחים של Inode X יורד מ-2 ל-1. הקובץ עצמו (ה-Inode) עדיין קיים ונגיש דרך `fileA.txt` (או `linkS.txt`).\n    *   הבן מסיים את פעולתו ויוצא.\n\n5.  **תהליך האב (לאחר שהבן סיים):**\n    *   ממתין שהבן יסיים (`wait`).\n    *   פותח את `linkS.txt` במצב הוספה (`\"a\"`). כיוון ש-`linkS.txt` הוא קישור סימבולי ל-`fileA.txt`, ו-`fileA.txt` עדיין קיים (כי מונה הקישורים של Inode X הוא 1), הקריאה `fopen` עוקבת אחר הקישור ופותחת את Inode X.\n    *   כותב \" parent\" לתוך הקובץ. תוכן Inode X הופך ל-\"Hello child parent\".\n    *   סוגר את הקובץ.\n    *   `unlink(\"fileA.txt\")`: מוחק את הערך `fileA.txt` מהתיקייה. מונה הקישורים הקשיחים של Inode X יורד מ-1 ל-0.\n    *   **מכיוון שמונה הקישורים הקשיחים של Inode X הגיע ל-0, ואין יותר file descriptors פתוחים המצביעים אליו (כי תהליך האב סגר את הקובץ לאחר הכתיבה), הקובץ (ה-Inode והנתונים שלו) נמחק בפועל ממערכת הקבצים.**\n\n**פלט התוכנית (מספרי ה-Inode וה-PID ישתנו בין הרצות):**\n\n```\nInitial state:\n--- fileA (fileA.txt) ---\nInode: <מספר Inode X>\nLinks: 1\nContent: \"Hello\"\n\nAfter creating links:\n--- fileA (fileA.txt) ---\nInode: <מספר Inode X>\nLinks: 2\nContent: \"Hello\"\n--- linkH (linkH.txt) ---\nInode: <מספר Inode X>\nLinks: 2\nContent: \"Hello\"\n--- linkS (linkS.txt) ---\nInode: <מספר Inode Y>\nLinks: 1\nSymlink points to: fileA.txt\nContent: \"Hello\"\n\n--- Child Process (<PID של הבן>) ---\nChild wrote to fileA.txt.\nChild unlinked linkH.txt.\n\n--- Parent Process (<PID של האב>) ---\nParent finished waiting for child.\nParent wrote to linkS (via symlink).\nParent unlinked fileA.txt.\n\nFinal state (from parent):\n--- fileA (fileA.txt (after unlink)) ---\nFile/Link 'fileA.txt' does not exist.\n--- linkH (linkH.txt (after child unlink)) ---\nFile/Link 'linkH.txt' does not exist.\n--- linkS (linkS.txt) ---\nInode: <מספר Inode Y>\nLinks: 1\nSymlink points to: fileA.txt\nfopen for content read error: No such file or directory\n```\n\n**מצב מערכת הקבצים הסופי:**\n\n*   **`fileA.txt`**: אינו קיים במערכת הקבצים. נמחק על ידי תהליך האב (כי מונה הקישורים שלו ירד ל-0).\n*   **`linkH.txt`**: אינו קיים במערכת הקבצים. נמחק על ידי תהליך הבן.\n*   **`linkS.txt`**: קיים במערכת הקבצים. זהו קישור סימבולי.\n    *   Inode: Y (ה-Inode המקורי של הקישור הסימבולי עצמו).\n    *   קישורים קשיחים: 1 (רק הקישור הסימבולי עצמו).\n    *   מצביע ל-\"fileA.txt\".\n    *   **הערה**: כיוון ש-`fileA.txt` נמחק, `linkS.txt` הוא כעת קישור סימבולי \"תלוי\" (dangling symlink) המצביע לנתיב שאינו קיים. ניסיון לגשת לתוכן דרך `linkS.txt` ייכשל (לדוגמה, `cat linkS.txt` יחזיר שגיאה \"No such file or directory\" או דומה)."}, "difficulty_estimation": "Hard", "_source_file": "0717__File_Systems__CodeAnalysis__Hard.json", "_topic_hint": "File Systems", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:51:25", "_subject": "File Systems"}, {"id": 1, "type": "CodeAnalysis", "topic": ["File Systems", "Disk Management", "Inodes", "Block Allocation"], "content": {"text": "במערכת הפעלה, ניהול קבצים דורש הבנה כיצד קבצים מאוחסנים פיזית על הדיסק. נתונה מערכת קבצים היפותטית המשתמשת במבנה Inode סטנדרטי, הכולל מצביעים ישירים (direct pointers), מצביע עקיף יחיד (single indirect pointer), ומצביע עקיף כפול (double indirect pointer). כל מצביע מצביע לבלוק אחד. הבלוקים העקיפים מכילים מצביעים לבלוקים אחרים (נתונים או עקיפים נוספים). המטרה היא לחשב את מספר הבלוקים הפיזיים הכולל על הדיסק שקובץ מסוים תופס, בהתחשב בגודלו הלוגי ובמבנה ה-Inode. מספר הבלוקים הכולל צריך לכלול גם את בלוקי הנתונים וגם את הבלוקים המשמשים לאחסון המצביעים העקיפים.\n\nיש לממש את הפונקציה `calculate_total_blocks` המקבלת מצביע למבנה `inode_t` ומחזירה את מספר הבלוקים הפיזיים הכולל. יש להשתמש בקבועים ובמבנה הנתונים המוגדרים מטה. שימו לב לטיפול נכון במקרים של קבצים קטנים וגדולים מאוד, ולוודא חישוב מדויק עבור בלוקי המצביעים העקיפים.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h> \n\n#define BLOCK_SIZE 4096       // גודל בלוק בבתים\n#define NUM_DIRECT_PTRS 12    // מספר מצביעים ישירים ב-inode\n#define PTRS_PER_BLOCK (BLOCK_SIZE / sizeof(int)) // מספר מצביעים בבלוק עקיף (בהנחה שמצביע הוא int)\n\n// מבנה Inode פשוט\ntypedef struct inode {\n    long i_size; // גודל הקובץ בבתים\n    // לצורך שאלה זו, אין צורך במימוש בפועל של המצביעים,\n    // אלא רק בהבנת המבנה הלוגי וחישוב המקום\n} inode_t;\n\n// יש לממש פונקציה זו\nint calculate_total_blocks(inode_t *inode) {\n    // Implement your solution here\n    return 0; // Placeholder\n}", "options": null}, "sub_questions": null, "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון דורש חישוב מדורג של הבלוקים הנדרשים בכל רמה של מצביעים (ישירים, עקיפים יחידים, עקיפים כפולים). יש לזכור שבלוקים עקיפים (single/double indirect blocks) עצמם תופסים מקום על הדיסק וצריך לספור אותם בנוסף לבלוקי הנתונים.\n\n1.  **חישוב בלוקי נתונים:** תחילה, נחשב כמה בלוקי נתונים נדרשים עבור הקובץ. אם גודל הקובץ הוא 0, אין צורך בבלוקי נתונים. אחרת, נשתמש בחישוב תקרה: `(i_size + BLOCK_SIZE - 1) / BLOCK_SIZE`.\n2.  **מצביעים ישירים:** עד `NUM_DIRECT_PTRS` בלוקים מטופלים על ידי מצביעים ישירים. בלוקים אלו אינם דורשים בלוקים נוספים עבור המצביעים עצמם.\n3.  **מצביעים עקיפים יחידים:** אם מספר בלוקי הנתונים גדול מ-`NUM_DIRECT_PTRS`, נצטרך להשתמש במצביע העקיף היחיד. בלוק זה יכול להכיל `PTRS_PER_BLOCK` מצביעים. אם יש צורך בבלוק זה (כלומר, אם ישנם בלוקי נתונים שחורגים מיכולת הכיסוי של המצביעים הישירים), הוא עצמו תופס בלוק פיזי אחד על הדיסק.\n4.  **מצביעים עקיפים כפולים:** אם מספר בלוקי הנתונים גדול ממה שיכולים לכסות המצביעים הישירים והעקיפים היחידים יחד (`NUM_DIRECT_PTRS + PTRS_PER_BLOCK`), נצטרך להשתמש במצביע העקיף הכפול. בלוק זה מכיל מצביעים לבלוקים עקיפים יחידים. הוא עצמו תופס בלוק פיזי אחד על הדיסק. בנוסף, כל אחד מבלוקי המצביעים העקיפים היחידים שהוא מצביע אליהם תופס גם הוא בלוק פיזי אחד. יש לחשב כמה בלוקים עקיפים יחידים כאלה נדרשים.\n\n**מימוש:**\n```c\n#include <stdio.h>\n#include <stdlib.h> \n\n#define BLOCK_SIZE 4096       // גודל בלוק בבתים\n#define NUM_DIRECT_PTRS 12    // מספר מצביעים ישירים ב-inode\n#define PTRS_PER_BLOCK (BLOCK_SIZE / sizeof(int)) // מספר מצביעים בבלוק עקיף (בהנחה שמצביע הוא int)\n\n// מבנה Inode פשוט\ntypedef struct inode {\n    long i_size; // גודל הקובץ בבתים\n    // לצורך שאלה זו, אין צורך במימוש בפועל של המצביעים,\n    // אלא רק בהבנת המבנה הלוגי וחישוב המקום\n} inode_t;\n\nint calculate_total_blocks(inode_t *inode) {\n    if (inode->i_size == 0) {\n        return 0;\n    }\n\n    // מספר בלוקי הנתונים הנדרשים עבור הקובץ\n    long num_data_blocks = (inode->i_size + BLOCK_SIZE - 1) / BLOCK_SIZE;\n    long total_physical_blocks = num_data_blocks; // מתחילים עם בלוקי הנתונים עצמם\n\n    // בדיקה עבור בלוק מצביעים עקיפים יחידים\n    // אם יש יותר בלוקי נתונים מאשר המצביעים הישירים יכולים לכסות\n    if (num_data_blocks > NUM_DIRECT_PTRS) {\n        total_physical_blocks += 1; // מוסיפים בלוק אחד עבור בלוק המצביעים העקיפים היחידים עצמו\n    }\n\n    // בדיקה עבור בלוק מצביעים עקיפים כפולים\n    // ויש גם לחשב את בלוקי המצביעים העקיפים היחידים שמתחתיו\n    // היכולת הכוללת של מצביעים ישירים ועקיפים יחידים\n    long covered_by_direct_and_single_indirect = NUM_DIRECT_PTRS + PTRS_PER_BLOCK;\n\n    if (num_data_blocks > covered_by_direct_and_single_indirect) {\n        total_physical_blocks += 1; // מוסיפים בלוק אחד עבור בלוק המצביעים העקיפים הכפולים עצמו\n\n        // נחשב כמה בלוקי מצביעים עקיפים יחידים נדרשים תחת הבלוק העקיף הכפול\n        // אלו הבלוקים שחורגים מיכולת הכיסוי של המצביעים הישירים והעקיפים היחידים\n        long remaining_data_blocks_for_double = num_data_blocks - covered_by_direct_and_single_indirect;\n        // חישוב תקרה של כמה בלוקי מצביעים עקיפים יחידים נדרשים כדי להצביע ל-remaining_data_blocks_for_double\n        long num_single_indirect_blocks_under_double = (remaining_data_blocks_for_double + PTRS_PER_BLOCK - 1) / PTRS_PER_BLOCK;\n        total_physical_blocks += num_single_indirect_blocks_under_double; // מוסיפים את בלוקי המצביעים העקיפים היחידים האלה\n    }\n\n    return (int)total_physical_blocks;\n}\n```\n", "difficulty_estimation": "Hard"}, "_source_file": "0718__File_Systems__CodeAnalysis__Hard.json", "_topic_hint": "File Systems", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:52:00", "_subject": "File Systems"}, {"id": 1, "type": "CodeAnalysis", "topic": ["File Systems", "Links", "System Calls", "Inode"], "content": {"text": "נתונה תוכנית C הבאה, המבצעת סדרת פעולות על מערכת הקבצים. נתחו את הקוד וציינו את הפלט המדויק של התוכנית, כולל הודעות שגיאה מ-`perror` במקרה של כשל. יש להניח שהתיקייה הנוכחית ריקה לפני הרצת התוכנית וכל קריאות המערכת מצליחות אלא אם כן צוין אחרת.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/stat.h>\n#include <fcntl.h>\n#include <string.h>\n#include <errno.h> // For errno\n\nint main() {\n    // 1. Create a file and write some content\n    int fd = open(\"original.txt\", O_CREAT | O_WRONLY | O_TRUNC, 0644);\n    if (fd == -1) { perror(\"open original.txt\"); return 1; }\n    write(fd, \"Hello World\\n\", 12);\n    close(fd);\n    printf(\"1. Created original.txt\\n\");\n\n    // 2. Create a hard link to original.txt\n    if (link(\"original.txt\", \"hardlink.txt\") == -1) { perror(\"link hardlink.txt\"); return 1; }\n    printf(\"2. Created hardlink.txt pointing to original.txt\\n\");\n\n    // 3. Create a symbolic link to original.txt\n    if (symlink(\"original.txt\", \"symlink.txt\") == -1) { perror(\"symlink symlink.txt\"); return 1; }\n    printf(\"3. Created symlink.txt pointing to original.txt\\n\");\n\n    // 4. Rename original.txt to new_name.txt\n    if (rename(\"original.txt\", \"new_name.txt\") == -1) { perror(\"rename original.txt\"); return 1; }\n    printf(\"4. Renamed original.txt to new_name.txt\\n\");\n\n    // 5. Try to read from hardlink.txt\n    char buffer[100];\n    int bytes_read;\n    fd = open(\"hardlink.txt\", O_RDONLY);\n    if (fd == -1) { perror(\"5. open hardlink.txt (after rename)\"); }\n    else {\n        bytes_read = read(fd, buffer, sizeof(buffer) - 1);\n        if (bytes_read > 0) {\n            buffer[bytes_read] = '\\0';\n            printf(\"5. Read from hardlink.txt: %s\", buffer);\n        }\n        close(fd);\n    }\n\n    // 6. Try to read from symlink.txt\n    fd = open(\"symlink.txt\", O_RDONLY);\n    if (fd == -1) { perror(\"6. open symlink.txt (after rename)\"); } // This will fail\n    else {\n        bytes_read = read(fd, buffer, sizeof(buffer) - 1);\n        if (bytes_read > 0) {\n            buffer[bytes_read] = '\\0';\n            printf(\"6. Read from symlink.txt: %s\", buffer);\n        }\n        close(fd);\n    }\n    \n    // 7. Unlink hardlink.txt\n    if (unlink(\"hardlink.txt\") == -1) { perror(\"7. unlink hardlink.txt\"); return 1; }\n    printf(\"7. Unlinked hardlink.txt\\n\");\n\n    // 8. Try to read from new_name.txt\n    fd = open(\"new_name.txt\", O_RDONLY);\n    if (fd == -1) { perror(\"8. open new_name.txt (after unlink hardlink)\"); }\n    else {\n        bytes_read = read(fd, buffer, sizeof(buffer) - 1);\n        if (bytes_read > 0) {\n            buffer[bytes_read] = '\\0';\n            printf(\"8. Read from new_name.txt: %s\", buffer);\n        }\n        close(fd);\n    }\n\n    // 9. Unlink new_name.txt\n    if (unlink(\"new_name.txt\") == -1) { perror(\"9. unlink new_name.txt\"); return 1; }\n    printf(\"9. Unlinked new_name.txt\\n\");\n\n    // 10. Try to read from symlink.txt\n    fd = open(\"symlink.txt\", O_RDONLY);\n    if (fd == -1) { perror(\"10. open symlink.txt (after unlink new_name)\"); } // This will also fail\n    else {\n        bytes_read = read(fd, buffer, sizeof(buffer) - 1);\n        if (bytes_read > 0) {\n            buffer[bytes_read] = '\\0';\n            printf(\"10. Read from symlink.txt: %s\", buffer);\n        }\n        close(fd);\n    }\n\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ניתוח התוכנית צעד אחר צעד:\n\n1.  **`open(\"original.txt\", ...)` וכתיבה:**\n    *   נוצר קובץ בשם `original.txt` עם התוכן \"Hello World\\n\".\n    *   פלט: `1. Created original.txt`\n2.  **`link(\"original.txt\", \"hardlink.txt\")`:**\n    *   נוצר קישור קשיח (hard link) בשם `hardlink.txt` המצביע לאותו Inode של `original.txt`. כעת, לשני השמות יש Inode משותף ומונה הקישורים (link count) של ה-Inode הוא 2.\n    *   פלט: `2. Created hardlink.txt pointing to original.txt`\n3.  **`symlink(\"original.txt\", \"symlink.txt\")`:**\n    *   נוצר קישור סימבולי (symbolic link) בשם `symlink.txt`. קובץ זה מכיל את המחרוזת \"original.txt\" ולא מצביע ישירות ל-Inode של הקובץ המקורי.\n    *   פלט: `3. Created symlink.txt pointing to original.txt`\n4.  **`rename(\"original.txt\", \"new_name.txt\")`:**\n    *   הקובץ `original.txt` משנה את שמו ל-`new_name.txt`. פעולה זו משנה את שם הרשומה בספרייה, אך ה-Inode נשאר זהה. מונה הקישורים של ה-Inode אינו משתנה.\n    *   פלט: `4. Renamed original.txt to new_name.txt`\n5.  **`open(\"hardlink.txt\", O_RDONLY)` וקריאה:**\n    *   `hardlink.txt` עדיין מצביע ל-Inode המשותף (שכעת מקושר גם ל-`new_name.txt`). לכן, הפתיחה תצליח והתוכן ייקרא.\n    *   פלט: `5. Read from hardlink.txt: Hello World\\n`\n6.  **`open(\"symlink.txt\", O_RDONLY)` וקריאה:**\n    *   `symlink.txt` מצביע למחרוזת \"original.txt\". מכיוון ש-`original.txt` כבר לא קיים (שמו שונה ל-`new_name.txt`), הקישור הסימבולי הפך לקישור תלוי (dangling symlink). ניסיון פתיחתו יכשל עם שגיאת \"No such file or directory\" (ENOENT).\n    *   פלט: `6. open symlink.txt (after rename): No such file or directory`\n7.  **`unlink(\"hardlink.txt\")`:**\n    *   הקישור הקשיח `hardlink.txt` נמחק. מונה הקישורים של ה-Inode המשותף יורד מ-2 ל-1. מכיוון שמונה הקישורים עדיין לא אפס, נתוני הקובץ לא נמחקים.\n    *   פלט: `7. Unlinked hardlink.txt`\n8.  **`open(\"new_name.txt\", O_RDONLY)` וקריאה:**\n    *   `new_name.txt` הוא כעת הקישור היחיד ל-Inode. פתיחתו תצליח והתוכן ייקרא.\n    *   פלט: `8. Read from new_name.txt: Hello World\\n`\n9.  **`unlink(\"new_name.txt\")`:**\n    *   הקובץ `new_name.txt` נמחק. מונה הקישורים של ה-Inode יורד מ-1 ל-0. מכיוון שמונה הקישורים הגיע לאפס, נתוני הקובץ (הבלוקים) ישוחררו.\n    *   פלט: `9. Unlinked new_name.txt`\n10. **`open(\"symlink.txt\", O_RDONLY)` וקריאה:**\n    *   `symlink.txt` עדיין מצביע למחרוזת \"original.txt\". מכיוון שגם `original.txt` (או `new_name.txt`) כבר לא קיימים, הקישור הסימבולי נשאר תלוי ופתיחתו תיכשל שוב עם אותה שגיאה.\n    *   פלט: `10. open symlink.txt (after unlink new_name): No such file or directory`\n\n**פלט סופי משוער (כולל הודעות perror):**\n```\n1. Created original.txt\n2. Created hardlink.txt pointing to original.txt\n3. Created symlink.txt pointing to original.txt\n4. Renamed original.txt to new_name.txt\n5. Read from hardlink.txt: Hello World\n6. open symlink.txt (after rename): No such file or directory\n7. Unlinked hardlink.txt\n8. Read from new_name.txt: Hello World\n9. Unlinked new_name.txt\n10. open symlink.txt (after unlink new_name): No such file or directory\n```"}, "difficulty_estimation": "Hard", "_source_file": "0719__File_Systems__CodeAnalysis__Hard.json", "_topic_hint": "File Systems", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:52:31", "_subject": "File Systems"}, {"id": 101, "type": "CodeAnalysis", "topic": ["File Systems", "Processes", "Concurrency", "System Calls", "Race Conditions"], "content": {"text": "נתונה תוכנית C הבאה המשתמשת בקריאות מערכת לטיפול בקבצים ויוצרת תהליכים חדשים באמצעות `fork`. יש להניח שכל קריאות המערכת מצליחות, ושהמערכת מאפשרת ריצה מקבילה של תהליכים עם מנגנון תזמון שרירותי (כלומר, כל סדר ריצה אפשרי, כולל החלפות הקשר בין קריאות מערכת שונות). כל התהליכים מחכים לסיום ילדיהם לפני שהם מסיימים את דרכם.\n\nיש לציין את כל הפלטים האפשריים של תוכן הקובץ הסופי `output.txt` ולהסביר כל פלט בפירוט, תוך התייחסות למצבי מרוץ אפשריים בין התהליכים.\n\nתוכן הקובץ ההתחלתי הוא 12 תווים 'X'.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <fcntl.h>\n#include <sys/wait.h>\n#include <string.h>\n\n#define FILENAME \"output.txt\"\n#define NUM_CHILDREN 2\n#define CHUNK_SIZE 4 // Each process writes 4 bytes\n#define FILE_LENGTH (CHUNK_SIZE * (NUM_CHILDREN + 1)) // Total length of 12 bytes\n\nint main() {\n    int fd;\n    pid_t pid;\n    int i;\n    char buffer[CHUNK_SIZE + 1];\n\n    fd = open(FILENAME, O_CREAT | O_RDWR | O_TRUNC, 0644);\n    if (fd == -1) {\n        perror(\"open\");\n        exit(EXIT_FAILURE);\n    }\n\n    // Initialize file with 'X' characters up to FILE_LENGTH\n    for (i = 0; i < FILE_LENGTH; ++i) {\n        if (write(fd, \"X\", 1) == -1) {\n            perror(\"initial write\");\n            exit(EXIT_FAILURE);\n        }\n    }\n    lseek(fd, 0, SEEK_SET); // Reset offset to beginning for subsequent writes\n\n    // Fork children\n    for (i = 0; i < NUM_CHILDREN; ++i) {\n        pid = fork();\n        if (pid == -1) {\n            perror(\"fork\");\n            exit(EXIT_FAILURE);\n        }\n\n        if (pid == 0) { // Child process\n            char child_char = '0' + i; // '0' for child 0, '1' for child 1\n            memset(buffer, child_char, CHUNK_SIZE);\n            buffer[CHUNK_SIZE] = '\\0';\n\n            // Child 0 targets offset 0, Child 1 targets offset 2\n            off_t target_offset = (off_t)(i * (CHUNK_SIZE / 2)); \n            \n            // Critical section: lseek + write\n            lseek(fd, target_offset, SEEK_SET); \n            usleep(10000); // Small delay to increase chance of interleaving\n            write(fd, buffer, CHUNK_SIZE);\n            \n            close(fd); // Child closes its copy of the file descriptor\n            exit(EXIT_SUCCESS);\n        }\n    }\n\n    // Parent also writes\n    char parent_char = 'P';\n    memset(buffer, parent_char, CHUNK_SIZE);\n    buffer[CHUNK_SIZE] = '\\0';\n    \n    // Parent targets offset 4\n    off_t parent_target_offset = (off_t)(NUM_CHILDREN * (CHUNK_SIZE / 2)); \n    \n    // Critical section: lseek + write\n    lseek(fd, parent_target_offset, SEEK_SET); \n    usleep(10000); // Small delay to increase chance of interleaving\n    write(fd, buffer, CHUNK_SIZE);\n\n    // Parent waits for children to finish\n    for (i = 0; i < NUM_CHILDREN; ++i) {\n        wait(NULL);\n    }\n\n    close(fd); // Parent closes its copy of the file descriptor\n\n    // Read and print final file content\n    fd = open(FILENAME, O_RDONLY);\n    if (fd == -1) {\n        perror(\"open for read\");\n        exit(EXIT_FAILURE);\n    }\n\n    char final_content[FILE_LENGTH + 1];\n    ssize_t bytes_read = read(fd, final_content, FILE_LENGTH);\n    if (bytes_read == -1) {\n        perror(\"read final\");\n        exit(EXIT_FAILURE);\n    }\n    final_content[bytes_read] = '\\0'; // Null-terminate\n\n    printf(\"Final file content: '%s'\\n\", final_content);\n\n    close(fd);\n    unlink(FILENAME); // Clean up the file\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון דורש הבנה עמוקה של אופן פעולת מתארי קבצים (file descriptors) לאחר קריאת `fork`, וכיצד פעולות `lseek` ו-`write` משפיעות על מיקום הכתיבה המשותף. כאשר תהליך אב מבצע `fork`, מתאר הקובץ `fd` משוכפל לילד. מתארים משוכפלים אלה (באב ובילדים) מצביעים כולם על אותה כניסה בטבלת הקבצים הפתוחים (open file table entry) של מערכת ההפעלה. המשמעות היא שהם חולקים את אותו מצביע קריאה/כתיבה (file offset).\n\nקריאת `lseek(fd, offset, SEEK_SET)` משנה את המצביע המשותף עבור כל התהליכים החולקים את אותה כניסה בטבלת הקבצים הפתוחים. קריאת `write` כותבת החל מהמצביע הנוכחי ומקדמת אותו במספר הבתים שנכתבו. מכיוון שקריאות `lseek` ו-`write` אינן אטומיות יחד, וקיים `usleep` ביניהן, ייתכנו מצבי מרוץ רבים שבהם סדר ביצוע הפעולות משפיע על התוצאה הסופית.\n\nהתוכנית יוצרת שני תהליכי בן (Child 0, Child 1) ותהליך אב (Parent). כל אחד מהם מנסה לכתוב מחרוזת בת 4 בתים לקובץ:\n- Child 0: כותב \"0000\", מטרתו לכתוב ב-offset 0.\n- Child 1: כותב \"1111\", מטרתו לכתוב ב-offset 2.\n- Parent: כותב \"PPPP\", מטרתו לכתוב ב-offset 4.\n\nהקובץ מאותחל ל-`XXXXXXXXXXXX` (12 תווי 'X').\n\nלהלן דוגמאות לפלטים אפשריים והסבר כיצד הם מתקבלים:\n\n**פלט אפשרי 1: `0011PPPPXXXX`**\n**תיאור סדר פעולות:** סדר הפעולות הוא (L=lseek, W=write):\n1.  **C0_L**: Child 0 קורא ל-`lseek(fd, 0, SEEK_SET)`. מצביע הקובץ המשותף (S) הופך ל-0.\n2.  **C0_W**: Child 0 קורא ל-`write(\"0000\", 4)`. כותב \"0000\" החל מ-S=0. הקובץ: `0000XXXXXXXX`. S הופך ל-4.\n3.  **C1_L**: Child 1 קורא ל-`lseek(fd, 2, SEEK_SET)`. S הופך ל-2.\n4.  **C1_W**: Child 1 קורא ל-`write(\"1111\", 4)`. כותב \"1111\" החל מ-S=2. הקובץ: `001111XXXXXX`. S הופך ל-6.\n5.  **P_L**: Parent קורא ל-`lseek(fd, 4, SEEK_SET)`. S הופך ל-4.\n6.  **P_W**: Parent קורא ל-`write(\"PPPP\", 4)`. כותב \"PPPP\" החל מ-S=4. הקובץ: `0011PPPPXXXX`. S הופך ל-8.\n\n**פלט אפשרי 2: `00001111PPPP`**\n**תיאור סדר פעולות:** כל פעולות ה-`lseek` מתבצעות לפני כל פעולות ה-`write`, בסדר מסוים:\n1.  **P_L**: Parent קורא ל-`lseek(fd, 4, SEEK_SET)`. S הופך ל-4.\n2.  **C1_L**: Child 1 קורא ל-`lseek(fd, 2, SEEK_SET)`. S הופך ל-2.\n3.  **C0_L**: Child 0 קורא ל-`lseek(fd, 0, SEEK_SET)`. S הופך ל-0.\n    (בשלב זה, כל קריאות ה-lseek הסתיימו, ו-S עומד על 0). \n4.  **C0_W**: Child 0 קורא ל-`write(\"0000\", 4)`. כותב \"0000\" החל מ-S=0. הקובץ: `0000XXXXXXXX`. S הופך ל-4.\n5.  **C1_W**: Child 1 קורא ל-`write(\"1111\", 4)`. כותב \"1111\" החל מ-S=4. הקובץ: `00001111XXXX`. S הופך ל-8.\n6.  **P_W**: Parent קורא ל-`write(\"PPPP\", 4)`. כותב \"PPPP\" החל מ-S=8. הקובץ: `00001111PPPP`. S הופך ל-12.\n\n**פלט אפשרי 3: `XX00001111PP`**\n**תיאור סדר פעולות:** דוגמה נוספת לסדר פעולות שונה:\n1.  **C0_L**: Child 0 קורא ל-`lseek(fd, 0, SEEK_SET)`. S הופך ל-0.\n2.  **P_L**: Parent קורא ל-`lseek(fd, 4, SEEK_SET)`. S הופך ל-4.\n3.  **C1_L**: Child 1 קורא ל-`lseek(fd, 2, SEEK_SET)`. S הופך ל-2.\n    (בשלב זה, כל קריאות ה-lseek הסתיימו, ו-S עומד על 2). \n4.  **C0_W**: Child 0 קורא ל-`write(\"0000\", 4)`. כותב \"0000\" החל מ-S=2. הקובץ: `XX0000XXXXXX`. S הופך ל-6.\n5.  **C1_W**: Child 1 קורא ל-`write(\"1111\", 4)`. כותב \"1111\" החל מ-S=6. הקובץ: `XX00001111XX`. S הופך ל-10.\n6.  **P_W**: Parent קורא ל-`write(\"PPPP\", 4)`. כותב \"PPPP\" החל מ-S=10. הקובץ: `XX00001111PP`. S הופך ל-14.\n    (הקריאה האחרונה של `read` תקרא רק 12 בתים, ולכן הפלט יהיה `XX00001111PP`).\n\n**פלט אפשרי 4: `1111PPPP0000`**\n**תיאור סדר פעולות:** דוגמה לסדר פעולות שבו ה-`write` של C0 מתרחש אחרון, וקריאת `lseek` של C1 היא האחרונה לפני ה-`write` הראשון:\n1.  **C0_L**: Child 0 קורא ל-`lseek(fd, 0, SEEK_SET)`. S הופך ל-0.\n2.  **P_L**: Parent קורא ל-`lseek(fd, 4, SEEK_SET)`. S הופך ל-4.\n3.  **C1_L**: Child 1 קורא ל-`lseek(fd, 2, SEEK_SET)`. S הופך ל-2.\n4.  **C1_W**: Child 1 קורא ל-`write(\"1111\", 4)`. כותב \"1111\" החל מ-S=2. הקובץ: `XX1111XXXXXX`. S הופך ל-6.\n5.  **P_W**: Parent קורא ל-`write(\"PPPP\", 4)`. כותב \"PPPP\" החל מ-S=6. הקובץ: `XX1111PPPPXX`. S הופך ל-10.\n6.  **C0_W**: Child 0 קורא ל-`write(\"0000\", 4)`. כותב \"0000\" החל מ-S=10. הקובץ: `XX1111PPPP00`. S הופך ל-14.\n    (הקריאה האחרונה של `read` תקרא רק 12 בתים, ולכן הפלט יהיה `XX1111PPPP00`).\n\nישנם פלטים אפשריים נוספים הנובעים משילובים שונים של סדרי הריצה, אך אלה ארבע דוגמאות הממחישות את מגוון התוצאות האפשריות עקב מצבי המרוץ על מצביע הקובץ המשותף."}, "difficulty_estimation": "Hard", "_source_file": "0720__File_Systems__CodeAnalysis__Hard.json", "_topic_hint": "File Systems", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:53:58", "_subject": "File Systems"}, {"id": 6, "type": "MultipleChoice", "topic": ["CPU Scheduling"], "content": {"text": "מהי המטרה העיקרית של מתזמן (scheduler) במערכת הפעלה?", "code_snippet": null, "options": ["א. לנהל את הזיכרון הפיזי של המערכת.", "ב. להחליט איזה תהליך יקבל את המעבד ויתבצע הלאה.", "ג. לטפל בפעולות קלט/פלט של התקנים.", "ד. לסנכרן גישה למשאבים משותפים בין תהליכים."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. המטרה העיקרית של מתזמן המעבד היא לבחור מבין התהליכים המוכנים לביצוע, איזה תהליך יקבל את המעבד ויתבצע. שאר התשובות מתארות תפקידים אחרים של מערכת ההפעלה או מנגנוניה (ניהול זיכרון, טיפול בקלט/פלט, סינכרון)."}, "difficulty_estimation": "Easy", "_source_file": "0721__CPU_Scheduling__MultipleChoice__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:54:05", "_subject": "Virtualization"}, {"id": 6, "type": "MultipleChoice", "topic": ["CPU Scheduling"], "content": {"text": "מהי המטרה העיקרית של תזמון מעבד (CPU Scheduling) במערכת הפעלה?", "code_snippet": null, "options": ["א. להבטיח שכל התהליכים יקבלו זמן מעבד שווה.", "ב. למקסם את ניצול המעבד ולספק זמני תגובה הולמים.", "ג. למנוע מצב של קיפאון (deadlock) בין תהליכים.", "ד. לנהל את הקצאת הזיכרון לתהליכים שונים.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. המטרה העיקרית של תזמון מעבד היא למקסם את ניצול המעבד, לספק זמני תגובה הולמים למשתמשים, להבטיח הוגנות בין תהליכים ולמקסם את התפוקה של המערכת. אפשרות ב' מכסה היבטים מרכזיים אלו."}, "difficulty_estimation": "Easy", "_source_file": "0722__CPU_Scheduling__MultipleChoice__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:54:13", "_subject": "Virtualization"}, {"id": 6, "type": "MultipleChoice", "topic": ["CPU Scheduling"], "content": {"text": "מהי המטרה העיקרית של תזמון מעבד (CPU Scheduling) במערכת הפעלה?", "code_snippet": null, "options": ["א. למנוע מצבי קיפאון (deadlocks) בין תהליכים.", "ב. לקבוע איזה תהליך יקבל את המעבד ומתי.", "ג. לנהל את הזיכרון הווירטואלי של המערכת.", "ד. לסנכרן גישה למשאבים משותפים בין חוטי חישוב (threads).", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. תזמון מעבד הוא מנגנון במערכת ההפעלה האחראי לבחור איזה תהליך (או חוט חישוב) מבין אלה המוכנים לריצה יוקצה למעבד, ומתי. מטרותיו כוללות מקסום ניצול המעבד, מזעור זמן תגובה, ומקסום תפוקה. האפשרויות האחרות מתייחסות לנושאים אחרים במערכות הפעלה כמו מניעת קיפאון, ניהול זיכרון וסנכרון."}, "difficulty_estimation": "Easy", "_source_file": "0723__CPU_Scheduling__MultipleChoice__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:54:20", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["CPU Scheduling"], "content": {"text": "מהי המטרה העיקרית של מתזמן המעבד (CPU Scheduler) במערכת הפעלה?", "code_snippet": null, "options": ["א. לנהל את הזיכרון הפיזי של המערכת.", "ב. להחליט איזה תהליך ירוץ על המעבד ומתי.", "ג. לטפל בפסיקות חומרה וקריאות מערכת.", "ד. לאבטח את המערכת מפני גישה לא מורשית.", "ה. אף אחת מהתשובות האחרות אינה נכונה."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. מתזמן המעבד אחראי לבחור מבין התהליכים המוכנים להרצה, איזה מהם יוקצה למעבד ובאיזו עת. מטרותיו כוללות מקסום ניצול המעבד, מתן זמני תגובה הולמים, והבטחת הגינות בין התהליכים. ניהול זיכרון, טיפול בפסיקות, ואבטחה הם תפקידים אחרים של מערכת ההפעלה."}, "difficulty_estimation": "Easy", "_source_file": "0724__CPU_Scheduling__MultipleChoice__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:54:27", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["CPU Scheduling"], "content": {"text": "איזה מבין אלגוריתמי תזמון המעבד הבאים הוא אלגוריתם מונע (preemptive)?", "code_snippet": null, "options": ["א. FCFS (First-Come, First-Served)", "ב. SJF (Shortest Job First)", "ג. Round Robin", "ד. Priority Scheduling (תזמון לפי עדיפות)", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "אלגוריתם Round Robin הוא אלגוריתם מונע (preemptive) מעצם הגדרתו, שכן הוא משתמש בפסיקת שעון (time slice) כדי להחליף תהליכים לאחר פרק זמן קבוע. אלגוריתמים כמו FCFS הם אינם מונעים. SJF ותזמון לפי עדיפות יכולים להיות מונעים או לא מונעים, תלוי במימוש, אך Round Robin הוא תמיד מונע."}, "difficulty_estimation": "Easy", "_source_file": "0725__CPU_Scheduling__MultipleChoice__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:54:36", "_subject": "Virtualization"}, {"id": 6, "type": "MultipleChoice", "topic": ["CPU Scheduling"], "content": {"text": "מהי המטרה העיקרית של תזמון מעבד (CPU Scheduling) במערכת הפעלה?", "code_snippet": null, "options": ["א. להבטיח שכל התהליכים יקבלו את אותו זמן מעבד.", "ב. למנוע מצב של קיפאון (deadlock) בין תהליכים.", "ג. למקסם את ניצול המעבד ולספק זמני תגובה הולמים למשתמשים.", "ד. לאפשר תקשורת בין תהליכים שונים.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "ג'. המטרה העיקרית של תזמון מעבד היא למקסם את ניצול המעבד על ידי שמירה על תור העבודה מלא ככל האפשר, ובו זמנית לספק זמני תגובה מהירים למשתמשים עבור יישומים אינטראקטיביים, ובסך הכל לייעל את ביצועי המערכת."}, "difficulty_estimation": "Easy", "_source_file": "0726__CPU_Scheduling__MultipleChoice__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:54:43", "_subject": "Virtualization"}, {"id": 6, "type": "MultipleChoice", "topic": ["CPU Scheduling"], "content": {"text": "מהי המטרה העיקרית של מתזמן מעבד (CPU scheduler) במערכת הפעלה?", "code_snippet": null, "options": ["א. לנהל את הקצאת הזיכרון לתהליכים שונים.", "ב. למנוע מצב של קיפאון (deadlock) בין תהליכים מתחרים.", "ג. למקסם את ניצול המעבד תוך מתן מענה הוגן וזמני תגובה סבירים לתהליכים.", "ד. לטפל בפסיקות (interrupts) חומרה ותוכנה.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "ג. המטרה העיקרית של מתזמן המעבד היא להחליט איזה תהליך יקבל את המעבד, מתי ולכמה זמן, במטרה למקסם את ניצול המעבד (לשמור על המעבד עסוק ככל האפשר), להבטיח זמני תגובה טובים לתהליכים אינטראקטיביים ולספק הוגנות בין תהליכים שונים."}, "difficulty_estimation": "Easy", "_source_file": "0727__CPU_Scheduling__MultipleChoice__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:54:53", "_subject": "Virtualization"}, {"id": 6, "type": "MultipleChoice", "topic": ["CPU Scheduling"], "content": {"text": "מהי המטרה העיקרית של תזמון מעבד (CPU Scheduling) במערכת הפעלה?", "code_snippet": null, "options": ["א. להבטיח שכל התהליכים יקבלו זמן מעבד שווה.", "ב. למנוע מצבי קיפאון (deadlocks) בין תהליכים.", "ג. להחליט איזה תהליך יקבל את המעבד ומתי.", "ד. לנהל את זיכרון המערכת בין תהליכים שונים.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "ג'. תזמון מעבד (CPU Scheduling) עוסק בקביעה איזה תהליך מבין התהליכים המוכנים לריצה יקבל את המעבד ומתי. מטרתו היא למקסם את ניצול המעבד, למזער זמני המתנה ולספק הוגנות, אך הפעולה היסודית היא הקצאת המעבד."}, "difficulty_estimation": "Easy", "_source_file": "0728__CPU_Scheduling__MultipleChoice__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 23:55:00", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["CPU Scheduling", "Scheduling", "Priority Scheduling", "Round Robin", "Starvation"], "content": {"text": "נתונה מערכת עם אלגוריתם תזמון RR סטנדרטי, עם שינוי אחד: כאשר תהליך מסיים את הקוונטה שלו, אם ישנם תהליכים בעלי עדיפות גבוהה (High Priority) בתור המוכנים, התהליך בעל העדיפות הגבוהה ביותר (אם יש כמה, אז זה שהגיע ראשון מביניהם) יקבל את המעבד מיד. אם אין תהליכים בעלי עדיפות גבוהה, האלגוריתם פועל כ-RR סטנדרטי (התהליך שסיים חוזר לסוף התור, והתהליך הבא בתור רץ). איזו טענה בהכרח נכונה?", "code_snippet": null, "options": ["א. זמן התגובה (Response Time) של תהליכים בעלי עדיפות גבוהה תמיד יהיה אופטימלי.", "ב. זמן המחזור (Turnaround Time) של תהליכים בעלי עדיפות נמוכה תמיד יהיה עדיף או שווה לזה של RR סטנדרטי.", "ג. קיימת אפשרות להרעבה (Starvation) של תהליכים בעלי עדיפות נמוכה.", "ד. אין אפשרות להרעבה של אף תהליך במערכת.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג. קיימת אפשרות להרעבה (Starvation) של תהליכים בעלי עדיפות נמוכה.", "explanation": "התשובה הנכונה היא ג'. באלגוריתם תזמון זה, תהליכים בעלי עדיפות נמוכה עלולים לסבול מהרעבה. אם תהליכים בעלי עדיפות גבוהה ממשיכים להגיע לתור המוכנים, או אם יש תמיד תהליכים בעלי עדיפות גבוהה הממתינים לריצה, תהליכים בעלי עדיפות נמוכה לעולם לא יקבלו הזדמנות לרוץ. הם ימתינו בתור בעוד שהמעבד מוקצה שוב ושוב לתהליכים בעלי עדיפות גבוהה. בניגוד ל-RR סטנדרטי, שבו כל תהליך מקבל הזדמנות לרוץ בזמן מוגבל, כאן העדיפות הגבוהה יכולה לדחוק באופן קבוע את התהליכים בעלי העדיפות הנמוכה."}, "difficulty_estimation": "Medium", "_source_file": "0729__CPU_Scheduling__MultipleChoice__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:55:14", "_subject": "Virtualization"}, {"id": 6, "type": "MultipleChoice", "topic": ["CPU Scheduling", "Round Robin", "Starvation", "Aging"], "content": {"text": "נתונה מערכת עם אלגוריתם תזמון מבוסס RR. משימה שסיימה את הקוונטה שלה חוזרת לסוף התור. משימה חדשה מתווספת לסוף התור. עם זאת, אם משימה המתינה בתור יותר מ-X קוונטות (ללא ריצה), היא מקבלת קדימות ועוברת לתחילת התור ברגע שמתפנה המעבד (לאחר סיום הקוונטה הנוכחית של המשימה הרצה). נניח ש-X הוא מספר שלם חיובי. איזו טענה בהכרח נכונה?", "code_snippet": null, "options": ["א. זמן התגובה הממוצע של האלגוריתם תמיד עדיף על זה של RR סטנדרטי.", "ב. זמן המחזור הממוצע של האלגוריתם תמיד עדיף על זה של RR סטנדרטי.", "ג. האלגוריתם מבטיח שאין הרעבה.", "ד. האלגוריתם עלול לגרום לבעיית היפוך קדימויות (priority inversion).", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג. האלגוריתם מבטיח שאין הרעבה.", "explanation": "הסבר:\nא. לא נכון. מנגנון ה'הזדקנות' (aging) אכן מבטיח הוגנות ומונע הרעבה, אך העברות תכופות לתחילת התור עלולות להגדיל את מספר החלפות ההקשר (context switches) או לשבש את סדר הריצה, ובכך לא בהכרח לשפר את זמן התגובה הממוצע לעומת RR סטנדרטי, ובמקרים מסוימים אף להרע אותו.\nב. לא נכון. מאותן סיבות כמו בסעיף א', מנגנון זה אינו מבטיח שיפור בזמן המחזור הממוצע.\nג. נכון. מנגנון ה'הזדקנות' (aging) שבו משימה שעברה את סף ההמתנה (X קוונטות) מקודמת לתחילת התור, מבטיח שכל משימה תקבל לבסוף את המעבד. בכך, הוא מונע באופן מוחלט מצב של הרעבה (starvation) בו משימה לעולם אינה זוכה לרוץ.\nד. לא נכון. בעיית היפוך קדימויות קשורה למשאבים משותפים ומנגנוני סנכרון (כגון מנעולים), ולא נובעת ישירות ממנגנון תזמון המעבד המתואר כאן."}, "difficulty_estimation": "Medium", "_source_file": "0730__CPU_Scheduling__MultipleChoice__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:55:28", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["CPU Scheduling", "Priority Scheduling", "Round Robin"], "content": {"text": "נתונה מערכת הפעלה המשתמשת באלגוריתם תזמון מבוסס עדיפויות (Priority Scheduling) עם דחיקה (Preemptive). למשימות ניתנת עדיפות מספרית, כאשר מספר נמוך יותר מציין עדיפות גבוהה יותר. במידה ולשתי משימות יש אותה עדיפות, הן מתזומנות בשיטת Round Robin עם קוונטה של 20ms. משימה חדשה מתווספת לתור העדיפות המתאים.\nאיזו מהטענות הבאות נכונה לגבי מערכת זו?", "code_snippet": null, "options": ["א. תזמון משימות בעלות עדיפות נמוכה יותר מובטח תוך זמן סופי, ללא קשר למספר המשימות בעלות עדיפות גבוהה שמגיעות.", "ב. זמן התגובה (Response Time) עבור משימות בעלות עדיפות גבוהה הוא תמיד אופטימלי.", "ג. משימה בעלת עדיפות גבוהה יותר תמיד תדחה (preempt) משימה בעלת עדיפות נמוכה יותר ותתחיל לרוץ באופן מיידי.", "ד. גודל הקוונטה (20ms) משפיע רק על זמן המחזור (Turnaround Time) של משימות, ולא על זמן התגובה (Response Time) שלהן."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג. משימה בעלת עדיפות גבוהה יותר תמיד תדחה (preempt) משימה בעלת עדיפות נמוכה יותר ותתחיל לרוץ באופן מיידי.", "explanation": "התשובה הנכונה היא ג'. לפי הגדרת אלגוריתם תזמון מבוסס עדיפויות עם דחיקה, משימה בעלת עדיפות גבוהה יותר שתגיע תמיד תדחה משימה בעלת עדיפות נמוכה יותר שכבר רצה, ותקבל את המעבד מיד.\nא' אינה נכונה: ייתכן מצב של הרעבה (starvation) עבור משימות בעלות עדיפות נמוכה אם מגיעות ברציפות משימות בעלות עדיפות גבוהה יותר, ובכך מונעות ממשימות בעדיפות נמוכה לרוץ.\nב' אינה נכונה: זמן התגובה אומנם טוב למשימות בעדיפות גבוהה, אך הוא אינו בהכרח אופטימלי, במיוחד כאשר ישנן מספר משימות באותה רמת עדיפות המשתמשות ב-Round Robin, מה שגורם להן להמתין לתורן.\nד' אינה נכונה: גודל הקוונטה משפיע הן על זמן המחזור והן על זמן התגובה של משימות באותה רמת עדיפות המתוזמנות ב-Round Robin. קוונטה קטנה מדי מגבירה החלפות הקשר ומשפרת תגובתיות, בעוד שקוונטה גדולה מדי גורמת להתנהגות דומה ל-FCFS בתוך קבוצת עדיפות."}, "difficulty_estimation": "Medium", "_source_file": "0731__CPU_Scheduling__MultipleChoice__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:55:44", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["CPU Scheduling", "Priority Scheduling", "Starvation"], "content": {"text": "נתונה מערכת הפעלה המשתמשת באלגוריתם תזמון מבוסס עדיפויות עם דחיקה (preemptive priority scheduling). כאשר תהליך חדש מגיע למערכת, אם העדיפות שלו גבוהה יותר מהתהליך הרץ כעת, הוא דוחק אותו ומתחיל לרוץ מיד. אם עדיפותו נמוכה או שווה, הוא מתווסף לתור ההמתנה בהתאם לעדיפותו. בהינתן שקיימת זרימה קבועה של תהליכים בעלי עדיפות גבוהה שמגיעים למערכת, איזו טענה נכונה בהכרח?", "code_snippet": null, "options": ["א. זמן התגובה של תהליכים בעלי עדיפות גבוהה הוא תמיד אופטימלי.", "ב. תהליכים בעלי עדיפות נמוכה עלולים לסבול מהרעבה (starvation).", "ג. האלגוריתם מבטיח שזמן המחזור הממוצע של כל התהליכים יהיה המינימלי האפשרי.", "ד. האלגוריתם מבטיח הוגנות (fairness) מוחלטת בין כל התהליכים.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "באופן מובנה, אלגוריתם תזמון מבוסס עדיפויות ללא מנגנון 'הזדקנות' (aging) עלול לגרום להרעבה. אם תהליכים בעלי עדיפות גבוהה ממשיכים להגיע למערכת באופן עקבי, הם ידחקו שוב ושוב את התהליכים בעלי העדיפות הנמוכה יותר, ובכך ימנעו מהם מלקבל זמן מעבד. לכן, תהליכים בעלי עדיפות נמוכה עלולים לעולם לא לרוץ ולסבול מהרעבה."}, "difficulty_estimation": "Medium", "_source_file": "0732__CPU_Scheduling__MultipleChoice__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:55:53", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["CPU Scheduling", "Round Robin", "Starvation", "Performance Metrics"], "content": {"text": "נתונה מערכת המשתמשת באלגוריתם תזמון Round Robin (RR) עם קוונטה בגודל q. עם זאת, אם זמן הריצה הנותר של תהליך (burst time) קטן או שווה ל-q, התהליך מורשה לרוץ עד לסיום ללא הפרעה (preemption). איזו טענה בהכרח נכונה לגבי שינוי זה?", "code_snippet": null, "options": ["א. זמן המחזור הממוצע (Average Turnaround Time) של המערכת ישתפר משמעותית עבור כל התהליכים.", "ב. תפוקת המעבד (CPU Utilization) תפחת עקב החלטות תזמון מורכבות יותר.", "ג. קיימת סכנה מוגברת להרעבה (starvation) עבור תהליכים ארוכים יותר.", "ד. זמן התגובה (Response Time) של כל התהליכים בהכרח ישתפר.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג. קיימת סכנה מוגברת להרעבה (starvation) עבור תהליכים ארוכים יותר.", "explanation": "השינוי המוצע באלגוריתם RR מעניק עדיפות לתהליכים קצרים (אלו שזמן הריצה הנותר שלהם קטן או שווה לקוונטה), ומאפשר להם לרוץ עד לסיום ללא הפרעה. בעוד שזה יכול לשפר את זמן המחזור הממוצע הכולל (במיוחד עבור תהליכים קצרים) ולהפחית את מספר החלפות ההקשר עבורם, החיסרון המשמעותי הוא הסיכון להרעבה. אם יגיעו למערכת באופן רציף תהליכים קצרים חדשים העומדים בקריטריון זה, הם יקבלו עדיפות על פני תהליכים ארוכים שכבר נמצאים בתור, וימנעו מהם לרוץ או ידחו את ריצתם לזמן בלתי מוגבל. לכן, תהליכים ארוכים עשויים להמתין לזמן בלתי מוגבל או לזמן ארוך מאוד."}, "difficulty_estimation": "Medium", "_source_file": "0733__CPU_Scheduling__MultipleChoice__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:56:06", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["CPU Scheduling", "Scheduling Algorithms", "Performance Metrics"], "content": {"text": "נתונות המשימות הבאות המגיעות למערכת:\n* P1: זמן הגעה 0, זמן ריצה 8 יחידות\n* P2: זמן הגעה 1, זמן ריצה 4 יחידות\n* P3: זמן הגעה 2, זמן ריצה 9 יחידות\n* P4: זמן הגעה 3, זמן ריצה 5 יחידות\n\nאיזה אלגוריתם תזמון ישיג את זמן ההמתנה הממוצע הנמוך ביותר עבור משימות אלו?\nהניחו כי עבור Round Robin, קוונטת הזמן היא 3 יחידות.", "code_snippet": null, "options": ["א. FCFS (First-Come, First-Served)", "ב. SJF לא מונע (Non-Preemptive SJF)", "ג. SJF מונע (Preemptive SJF / SRTF)", "ד. Round Robin (RR)"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג. SJF מונע (Preemptive SJF / SRTF)", "explanation": "נחשב את זמן ההמתנה הממוצע עבור כל אלגוריתם:\n\n**1. FCFS (First-Come, First-Served):**\n* P1: מגיעה ב-0, מתחילה ב-0, מסיימת ב-8. זמן המתנה = 0.\n* P2: מגיעה ב-1, מתחילה ב-8, מסיימת ב-12. זמן המתנה = 8 - 1 = 7.\n* P3: מגיעה ב-2, מתחילה ב-12, מסיימת ב-21. זמן המתנה = 12 - 2 = 10.\n* P4: מגיעה ב-3, מתחילה ב-21, מסיימת ב-26. זמן המתנה = 21 - 3 = 18.\nסה\"כ זמן המתנה = 0 + 7 + 10 + 18 = 35.\nזמן המתנה ממוצע = 35 / 4 = 8.75.\n\n**2. SJF לא מונע (Non-Preemptive SJF):**\n* ב-0: P1 מגיעה ורצה (burst 8). P1 רצה עד 8.\n* ב-8: P1 מסיימת. בתור מוכנים: P2 (burst 4), P3 (burst 9), P4 (burst 5). P2 נבחרת (הקצרה ביותר).\n* P2 רצה (8-12).\n* ב-12: P2 מסיימת. בתור מוכנים: P3 (burst 9), P4 (burst 5). P4 נבחרת.\n* P4 רצה (12-17).\n* ב-17: P4 מסיימת. בתור מוכנים: P3 (burst 9). P3 רצה.\n* P3 רצה (17-26).\nזמני סיום: P1=8, P2=12, P4=17, P3=26.\n* P1: זמן המתנה = 0.\n* P2: זמן המתנה = 8 - 1 = 7.\n* P3: זמן המתנה = 17 - 2 = 15.\n* P4: זמן המתנה = 12 - 3 = 9.\nסה\"כ זמן המתנה = 0 + 7 + 15 + 9 = 31.\nזמן המתנה ממוצע = 31 / 4 = 7.75.\n\n**3. SJF מונע (Preemptive SJF / SRTF - Shortest Remaining Time First):**\n* ב-0: P1 מגיעה ורצה (P1_rem=8).\n* ב-1: P2 מגיעה (burst 4). P2 (rem=4) קצרה מ-P1 (rem=7). P2 מתחילה לרוץ.\n* ב-2: P3 מגיעה (burst 9). P2 (rem=3) עדיין קצרה ביותר. P2 ממשיכה.\n* ב-3: P4 מגיעה (burst 5). P2 (rem=2) עדיין קצרה ביותר. P2 ממשיכה.\n* ב-5: P2 מסיימת. בתור מוכנים: P1 (rem=7), P3 (rem=9), P4 (rem=5). P4 קצרה ביותר. P4 מתחילה לרוץ.\n* ב-10: P4 מסיימת. בתור מוכנים: P1 (rem=7), P3 (rem=9). P1 קצרה ביותר. P1 מתחילה לרוץ.\n* ב-17: P1 מסיימת. בתור מוכנים: P3 (rem=9). P3 מתחילה לרוץ.\n* ב-26: P3 מסיימת.\n\nזמני סיום: P2=5, P4=10, P1=17, P3=26.\n* P1: זמן המתנה = (1-0) + (10-1) = 9. (P1 רצה 0-1, חיכתה 1-10, רצה 10-17)\n* P2: זמן המתנה = 1 - 1 = 0.\n* P3: זמן המתנה = 17 - 2 = 15.\n* P4: זמן המתנה = 5 - 3 = 2.\nסה\"כ זמן המתנה = 9 + 0 + 15 + 2 = 26.\nזמן המתנה ממוצע = 26 / 4 = 6.5.\n\n**4. Round Robin (RR) עם קוונטה = 3:**\n* P1: (0-3), נותר 5.\n* P2: (3-6), נותר 1.\n* P3: (6-9), נותר 6.\n* P4: (9-12), נותר 2.\n* P1: (12-15), נותר 2.\n* P2: (15-16), נותר 0. P2 מסיימת.\n* P3: (16-19), נותר 3.\n* P4: (19-21), נותר 0. P4 מסיימת.\n* P1: (21-23), נותר 0. P1 מסיימת.\n* P3: (23-26), נותר 0. P3 מסיימת.\n\nזמני סיום: P1=23, P2=16, P3=26, P4=21.\n* P1: זמן המתנה = זמן סיום - זמן הגעה - זמן ריצה = 23 - 0 - 8 = 15.\n* P2: זמן המתנה = 16 - 1 - 4 = 11.\n* P3: זמן המתנה = 26 - 2 - 9 = 15.\n* P4: זמן המתנה = 21 - 3 - 5 = 13.\nסה\"כ זמן המתנה = 15 + 11 + 15 + 13 = 54.\nזמן המתנה ממוצע = 54 / 4 = 13.5.\n\n**סיכום זמני המתנה ממוצעים:**\n* FCFS: 8.75\n* SJF לא מונע: 7.75\n* SJF מונע (SRTF): 6.5\n* Round Robin (RR): 13.5\n\nהאלגוריתם שמשיג את זמן ההמתנה הממוצע הנמוך ביותר הוא SJF מונע (SRTF)."}, "difficulty_estimation": "Medium", "_source_file": "0734__CPU_Scheduling__MultipleChoice__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:56:34", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["CPU Scheduling", "Round Robin", "Starvation"], "content": {"text": "נתונה מערכת המשתמשת באלגוריתם תזמון Round Robin (RR). אולם, כאשר תהליך מסיים את הקוונטה שלו, הוא אינו מוחזר לסוף התור, אלא ממוקם בתחילת התור הממתין. תהליכים חדשים שנוצרים מתווספים לסוף התור. הניחו כי לא נוצרים שני תהליכים חדשים בו-זמנית.\nאיזו טענה בהכרח נכונה?", "code_snippet": null, "options": ["א. זמן התגובה של תהליכים חדשים תמיד יהיה עדיף על זה של RR סטנדרטי.", "ב. זמן המחזור הממוצע של המערכת תמיד ישתפר לעומת RR סטנדרטי.", "ג. לכל מספר תהליכים N > 1, אם מספר התהליכים הפעילים בתור בכל רגע נתון הוא בדיוק N, לא תיתכן הרעבה.", "ד. אם ישנם תהליכים קיימים שאינם מסתיימים, תהליך חדש שנוצר עלול לסבול מהרעבה.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ד. אם ישנם תהליכים קיימים שאינם מסתיימים, תהליך חדש שנוצר עלול לסבול מהרעבה.", "explanation": "האלגוריתם המתואר מעניק עדיפות גבוהה לתהליכים קיימים: לאחר שסיימו את הקוונטה שלהם, הם מוחזרים לתחילת התור במקום לסופו. אם ישנם מספר תהליכים קיימים שאינם מסתיימים (לדוגמה, תהליכי לולאה אינסופית), הם ייכנסו למחזור קבוע של הרצה וחזרה לתחילת התור. תהליך חדש, שנוצר ומתווסף לסוף התור, לעולם לא יגיע לראש התור כדי לרוץ כל עוד התהליכים הקיימים ממשיכים להתחלף ביניהם ולחזור לתחילת התור. לכן, תהליך חדש עלול לסבול מהרעבה ולא לזכות בזמן מעבד."}, "difficulty_estimation": "Medium", "_source_file": "0735__CPU_Scheduling__MultipleChoice__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:56:50", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["CPU Scheduling", "Round Robin", "Scheduling Algorithms"], "content": {"text": "באלגוריתם תזמון Round Robin (RR), מה קורה כאשר גודל הקוונטה (time quantum) שואף לאינסוף?", "code_snippet": null, "options": ["א. האלגוריתם הופך להיות שקול ל-Shortest Job First (SJF).", "ב. האלגוריתם הופך להיות שקול ל-First-Come, First-Served (FCFS).", "ג. האלגוריתם הופך להיות שקול ל-Priority Scheduling עם עדיפות קבועה.", "ד. האלגוריתם מפסיק להיות אלגוריתם תזמון יעיל וגורם להרבה החלפות הקשר.", "ה. זמן התגובה הממוצע שואף לאפס."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב. האלגוריתם הופך להיות שקול ל-First-Come, First-Served (FCFS).", "explanation": "כאשר גודל הקוונטה באלגוריתם Round Robin שואף לאינסוף, כל תהליך מקבל את ה-CPU ורץ עד להשלמתו המלאה ללא הפרעה, אלא אם כן תהליך אחר מגיע לפניו. זהו בדיוק המאפיין של אלגוריתם First-Come, First-Served (FCFS), שבו התהליכים מבוצעים לפי סדר הגעתם ורצים עד לסיום ה-burst שלהם."}, "difficulty_estimation": "Medium", "_source_file": "0736__CPU_Scheduling__MultipleChoice__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 23:56:59", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["CPU Scheduling", "Preemptive Priority", "I/O Blocking", "Context Switch"], "content": {"text": "מערכת הפעלה משתמשת באלגוריתם תזמון קדימויות דורסני (Preemptive Priority), כאשר ערך מספרי נמוך יותר מציין קדימות גבוהה יותר. עבור תהליכים בעלי אותה קדימות, המערכת משתמשת בגישת FCFS (First-Come, First-Served) בתוך רמת הקדימות. עלות החלפת הקשר (Context Switch) היא 1ms.\n\nנתונים התהליכים הבאים:\nP1: קדימות 1, זמן ריצה CPU כולל 10ms. מגיע בזמן 0ms. מבצע פעולת קלט/פלט (I/O) לאחר 4ms של ריצת CPU. פעולת ה-I/O אורכת 6ms.\nP2: קדימות 2, זמן ריצה CPU כולל 8ms. מגיע בזמן 0ms.\nP3: קדימות 1, זמן ריצה CPU כולל 7ms. מגיע בזמן 2ms.\n\nמהו הזמן הכולל שחלף מתחילת פעולת המערכת ועד שכל התהליכים סיימו את ריצת ה-CPU שלהם?", "code_snippet": null, "options": ["א. 23ms", "ב. 24ms", "ג. 25ms", "ד. 26ms", "ה. אף תשובה אחרת אינה נכונה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ה", "explanation": "נבצע מעקב אחר ביצוע התהליכים:\n\n*   **זמן 0**: P1 (קדימות 1, CPU=10) ו-P2 (קדימות 2, CPU=8) מגיעים. P1 נבחר לריצה מכיוון שיש לו את הקדימות הגבוהה ביותר.\n*   **זמן 0-4**: P1 רץ (4ms). נותר ל-P1: 6ms CPU.\n*   **זמן 2**: P3 (קדימות 1, CPU=7) מגיע. P1 ממשיך לרוץ מכיוון של-P3 אותה קדימות (ולא קדימות גבוהה יותר), ו-P1 התחיל לפני P3. P3 מצטרף לתור ההמתנה של קדימות 1.\n*   **זמן 4**: P1 השלים 4ms ריצה ומתחיל פעולת I/O (תימשך 6ms, כלומר P1 יסיים I/O בזמן 4+6=10). P1 נחסם.\n    *   התהליך בעל הקדימות הגבוהה ביותר ומוכן לריצה הוא P3 (קדימות 1).\n    *   מתבצעת החלפת קשר מ-P1 ל-P3: 1ms.\n*   **זמן 4-5**: החלפת קשר.\n*   **זמן 5**: P3 מתחיל לרוץ (CPU=7).\n*   **זמן 5-10**: P3 רץ (5ms). נותר ל-P3: 2ms CPU.\n*   **זמן 10**: P1 מסיים I/O והופך למוכן. P3 עדיין רץ (קדימות 1). P1 (קדימות 1) מצטרף לתור ההמתנה של קדימות 1 אחרי P3 (כי P3 התחיל לרוץ לפני ש-P1 חזר מ-I/O).\n*   **זמן 10-12**: P3 רץ (2ms). P3 מסיים (סה\"כ 7ms CPU).\n*   **זמן 12**: P3 מסיים.\n    *   התהליך בעל הקדימות הגבוהה ביותר ומוכן לריצה הוא P1 (קדימות 1).\n    *   מתבצעת החלפת קשר מ-P3 ל-P1: 1ms.\n*   **זמן 12-13**: החלפת קשר.\n*   **זמן 13**: P1 מתחיל לרוץ (נותרו לו 6ms CPU).\n*   **זמן 13-19**: P1 רץ (6ms). P1 מסיים (סה\"כ 10ms CPU).\n*   **זמן 19**: P1 מסיים.\n    *   התהליך בעל הקדימות הגבוהה ביותר ומוכן לריצה הוא P2 (קדימות 2).\n    *   מתבצעת החלפת קשר מ-P1 ל-P2: 1ms.\n*   **זמן 19-20**: החלפת קשר.\n*   **זמן 20**: P2 מתחיל לרוץ (CPU=8).\n*   **זמן 20-28**: P2 רץ (8ms). P2 מסיים (סה\"כ 8ms CPU).\n*   **זמן 28**: P2 מסיים. כל התהליכים סיימו.\n\nהזמן הכולל שחלף מתחילת פעולת המערכת ועד שכל התהליכים סיימו את ריצת ה-CPU שלהם הוא 28ms.\nלכן, התשובה הנכונה היא ה'."}, "difficulty_estimation": "Hard", "_source_file": "0737__CPU_Scheduling__MultipleChoice__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:57:35", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["CPU Scheduling", "Preemptive Priority Scheduling", "Process States"], "content": {"text": "שקול מערכת המשתמשת באלגוריתם תזמון עדיפויות מונע (preemptive priority scheduling), כאשר מספר עדיפות נמוך יותר מציין עדיפות גבוהה יותר. כל התהליכים מגיעים לתור המוכנים בזמני ההגעה שצוינו. המתזמן תמיד בוחר את התהליך בעל העדיפות הגבוהה ביותר מבין אלו שמוכנים. אם למספר תהליכים יש אותה עדיפות, נעשה שימוש ב-Round Robin עם קוונטום של 1ms (אך ייתכן שזה לא יידרש לשאלה זו בהינתן עדיפויות שונות). תקורה של החלפת הקשר (context switch) ניתנת להזנחה.\n\nהתהליכים הבאים נתונים:\nP1: זמן הגעה = 0ms, עדיפות = 1, פרץ מעבד = 4ms, פרץ I/O = 6ms, פרץ מעבד = 2ms.\nP2: זמן הגעה = 1ms, עדיפות = 2, פרץ מעבד = 8ms.\nP3: זמן הגעה = 2ms, עדיפות = 3, פרץ מעבד = 10ms.\n\nמהו מצבו של תהליך P2 בזמן T=10ms?", "code_snippet": null, "options": ["א. P2 רץ.", "ב. P2 חסום ב-I/O.", "ג. P2 מוכן ובעל 2ms זמן מעבד נותר.", "ד. P2 מוכן ובעל 4ms זמן מעבד נותר.", "ה. P2 סיים את ריצתו."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "בזמן T=0: P1 מגיע ומתחיל לרוץ (עדיפות 1).\nבזמן T=1: P2 מגיע (עדיפות 2). P1 ממשיך לרוץ.\nבזמן T=2: P3 מגיע (עדיפות 3). P1 ממשיך לרוץ.\nבזמן T=4: P1 מסיים את פרץ המעבד הראשון (4ms). P1 עובר למצב חסום (I/O) למשך 6ms (ישתחרר ב-T=10). זמן המעבד הנותר ל-P1 הוא 2ms.\nבתור המוכנים יש כעת את P2 ו-P3. P2 (עדיפות 2) נבחר לרוץ.\nמ-T=4 עד T=10: P2 רץ למשך 6ms.\nבזמן T=10: P1 מסיים את פעולת ה-I/O שלו וחוזר למצב מוכן. P1 (עדיפות 1) עדיף על P2 (עדיפות 2) שרץ כעת. לכן, המתזמן מבצע דריסה (preemption) ל-P2. P2 עובר ממצב ריצה למצב מוכן.\nמצבו של P2 בזמן T=10ms הוא מוכן, מכיוון שנדרס. זמן המעבד הנותר ל-P2 הוא 8ms (סה\"כ) - 6ms (שבוצעו) = 2ms.\nלכן, התשובה הנכונה היא ג'."}, "difficulty_estimation": "Hard", "_source_file": "0738__CPU_Scheduling__MultipleChoice__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:57:56", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["CPU Scheduling", "Multilevel Feedback Queue"], "content": {"text": "נתונה מערכת הפעלה המשתמשת במתזמן CPU מסוג Multilevel Feedback Queue (MLFQ) עם שלוש רמות תור:\n*   **Q0:** Round Robin עם קוונטום זמן של 2 יחידות.\n*   **Q1:** Round Robin עם קוונטום זמן של 4 יחידות.\n*   **Q2:** First Come, First Served (FCFS).\n\nכל התהליכים מתחילים בתור Q0.\n*   אם תהליך מנצל את כל קוונטום הזמן שלו (ונשאר לו זמן ריצה נוסף), הוא עובר לתור הבא בעדיפות נמוכה יותר.\n*   אם תהליך מסיים את ריצתו או מפנה את המעבד (לדוגמה, עבור I/O) לפני תום קוונטום הזמן שלו, הוא נשאר באותו תור (וממוקם בסופו).\n*   תורים בעלי עדיפות גבוהה יותר (Q0 > Q1 > Q2) מוגשים תמיד ראשונים.\n\nנתונים ארבעה תהליכים:\n| תהליך | זמן הגעה | זמן ריצה (Burst Time) |\n|---|---|---|\n| P1 | 0 | 7 |\n| P2 | 1 | 3 |\n| P3 | 2 | 2 |\n| P4 | 3 | 8 |\n\nמהו זמן ההמתנה הממוצע (Average Waiting Time) של כל התהליכים במערכת?", "code_snippet": null, "options": ["א. 5.75", "ב. 6.00", "ג. 6.25", "ד. 6.50", "ה. אף אחת מהתשובות אינה נכונה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ה", "explanation": "נשרטט את תרשים גאנט ונחשב את זמני ההמתנה בהתאם לכללים:\n\n**כלל מעבר בין תורים:** אם תהליך מנצל את כל קוונטום הזמן שלו (ויש לו עדיין זמן ריצה נוסף), הוא עובר לתור הבא בעדיפות נמוכה יותר. אם הוא מסיים את ריצתו או מפנה את המעבד לפני תום הקוונטום, הוא נשאר באותו תור.\n\n**מעקב אחר ריצת התהליכים:**\n\n1.  **זמן 0-2 (Q0, P1):**\n    *   P1 מתחיל (Burst=7). רץ למשך 2 יחידות (קוונטום Q0).\n    *   Burst P1 נשאר 5. P1 ניצל את כל הקוונטום ויש לו עוד עבודה, לכן עובר ל-Q1.\n    *   מצב תורים: Q0: [], Q1: [P1(5)]\n\n2.  **זמן 2-4 (Q0, P2):**\n    *   P2 מגיע בזמן 1. P3 מגיע בזמן 2.\n    *   Q0: [P2(3), P3(2)]. מתזמן בוחר את P2 (הגיע קודם ל-Q0).\n    *   P2 רץ למשך 2 יחידות (קוונטום Q0).\n    *   Burst P2 נשאר 1. P2 ניצל את כל הקוונטום ויש לו עוד עבודה, לכן עובר ל-Q1.\n    *   מצב תורים: Q0: [P3(2)], Q1: [P1(5), P2(1)] (P1 הגיע ל-Q1 ב-2, P2 הגיע ל-Q1 ב-4)\n\n3.  **זמן 4-6 (Q0, P3):**\n    *   P4 מגיע בזמן 3.\n    *   Q0: [P3(2), P4(8)]. מתזמן בוחר את P3.\n    *   P3 רץ למשך 2 יחידות (קוונטום Q0).\n    *   Burst P3 נשאר 0. P3 סיים את ריצתו. הוא לא עובר תור.\n    *   **P3 Completion Time = 6.**\n    *   מצב תורים: Q0: [P4(8)], Q1: [P1(5), P2(1)]\n\n4.  **זמן 6-8 (Q0, P4):**\n    *   Q0: [P4(8)]. מתזמן בוחר את P4.\n    *   P4 רץ למשך 2 יחידות (קוונטום Q0).\n    *   Burst P4 נשאר 6. P4 ניצל את כל הקוונטום ויש לו עוד עבודה, לכן עובר ל-Q1.\n    *   מצב תורים: Q0: [], Q1: [P1(5), P2(1), P4(6)] (P4 הגיע ל-Q1 ב-8)\n\n5.  **זמן 8-12 (Q1, P1):**\n    *   Q0 ריק. מתזמן בוחר מ-Q1.\n    *   Q1: [P1(5), P2(1), P4(6)]. מתזמן בוחר את P1 (הגיע ראשון ל-Q1).\n    *   P1 רץ למשך 4 יחידות (קוונטום Q1).\n    *   Burst P1 נשאר 1. P1 ניצל את כל הקוונטום ויש לו עוד עבודה, לכן עובר ל-Q2.\n    *   מצב תורים: Q0: [], Q1: [P2(1), P4(6)], Q2: [P1(1)]\n\n6.  **זמן 12-13 (Q1, P2):**\n    *   Q0 ריק. מתזמן בוחר מ-Q1.\n    *   Q1: [P2(1), P4(6)]. מתזמן בוחר את P2.\n    *   P2 רץ למשך 1 יחידה (פחות מקוונטום Q1).\n    *   Burst P2 נשאר 0. P2 סיים את ריצתו. הוא לא עובר תור.\n    *   **P2 Completion Time = 13.**\n    *   מצב תורים: Q0: [], Q1: [P4(6)], Q2: [P1(1)]\n\n7.  **זמן 13-17 (Q1, P4):**\n    *   Q0 ריק. מתזמן בוחר מ-Q1.\n    *   Q1: [P4(6)]. מתזמן בוחר את P4.\n    *   P4 רץ למשך 4 יחידות (קוונטום Q1).\n    *   Burst P4 נשאר 2. P4 ניצל את כל הקוונטום ויש לו עוד עבודה, לכן עובר ל-Q2.\n    *   מצב תורים: Q0: [], Q1: [], Q2: [P1(1), P4(2)] (P4 הגיע ל-Q2 ב-17)\n\n8.  **זמן 17-18 (Q2, P1):**\n    *   Q0, Q1 ריקים. מתזמן בוחר מ-Q2.\n    *   Q2: [P1(1), P4(2)]. מתזמן בוחר את P1 (FCFS).\n    *   P1 רץ למשך 1 יחידה (FCFS עד הסוף).\n    *   Burst P1 נשאר 0. P1 סיים את ריצתו.\n    *   **P1 Completion Time = 18.**\n    *   מצב תורים: Q0: [], Q1: [], Q2: [P4(2)]\n\n9.  **זמן 18-20 (Q2, P4):**\n    *   Q0, Q1 ריקים. מתזמן בוחר מ-Q2.\n    *   Q2: [P4(2)]. מתזמן בוחר את P4.\n    *   P4 רץ למשך 2 יחידות (FCFS עד הסוף).\n    *   Burst P4 נשאר 0. P4 סיים את ריצתו.\n    *   **P4 Completion Time = 20.**\n\n**סיכום זמני השלמה, זמן מחזור וזמן המתנה:**\n\n| תהליך | זמן הגעה | זמן ריצה | זמן השלמה | זמן מחזור (Completion - Arrival) | זמן המתנה (Turnaround - Burst) |\n|---|---|---|---|---|---|\n| P1 | 0 | 7 | 18 | 18 - 0 = 18 | 18 - 7 = 11 |\n| P2 | 1 | 3 | 13 | 13 - 1 = 12 | 12 - 3 = 9 |\n| P3 | 2 | 2 | 6 | 6 - 2 = 4 | 4 - 2 = 2 |\n| P4 | 3 | 8 | 20 | 20 - 3 = 17 | 17 - 8 = 9 |\n\n**זמן ההמתנה הממוצע** = (11 + 9 + 2 + 9) / 4 = 31 / 4 = 7.75\n\nלכן, התשובה הנכונה היא ה'."}, "difficulty_estimation": "Hard", "_source_file": "0739__CPU_Scheduling__MultipleChoice__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 23:58:42", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["CPU Scheduling", "SRTF", "Round Robin", "Process Management"], "content": {"text": "נתונה מערכת הפעלה עם מעבד יחיד (single core CPU) המשתמשת באחד משני אלגוריתמי תזמון: Preemptive SJF (Shortest Remaining Time First) או Round Robin עם קוואנטום זמן של 2ms. הנח כי אין overhead של החלפת הקשר. נתונים התהליכים הבאים:\n\n| תהליך | זמן הגעה (ms) | פרץ מעבד 1 (ms) | פרץ קלט/פלט (ms) | פרץ מעבד 2 (ms) |\n| :------ | :---------------- | :--------------- | :------------- | :--------------- |\n| P1      | 0                 | 5                | 10             | 3                |\n| P2      | 1                 | 4                | -              | -                |\n| P3      | 3                 | 2                | 5              | 2                |\n\nאיזו מהטענות הבאות נכונה לגבי זמני ההשלמה (completion times) של התהליכים?", "code_snippet": null, "options": ["א. תהליך P1 מסתיים מוקדם יותר באלגוריתם Round Robin מאשר באלגוריתם Preemptive SJF, בעוד שתהליכים P2 ו-P3 מסתיימים מוקדם יותר באלגוריתם Preemptive SJF.", "ב. תהליך P2 מסתיים מוקדם יותר באלגוריתם Round Robin מאשר באלגוריתם Preemptive SJF.", "ג. תהליך P3 מסתיים מוקדם יותר באלגוריתם Round Robin מאשר באלגוריתם Preemptive SJF.", "ד. כל התהליכים מסתיימים מוקדם יותר באלגוריתם Round Robin.", "ה. אף אחת מהטענות האחרות אינה נכונה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "נחשב את זמני ההשלמה עבור כל אלגוריתם:\n\n**תהליכים נתונים:**\nP1: זמן הגעה=0, פרץ מעבד 1=5, פרץ ק/פ=10, פרץ מעבד 2=3 (סה\"כ CPU = 8ms)\nP2: זמן הגעה=1, פרץ מעבד 1=4 (סה\"כ CPU = 4ms)\nP3: זמן הגעה=3, פרץ מעבד 1=2, פרץ ק/פ=5, פרץ מעבד 2=2 (סה\"כ CPU = 4ms)\n\n**1. אלגוריתם Preemptive SJF (SRTF):**\n*   **t=0:** P1 מגיע ומתחיל לרוץ (נותרו 8ms). \n*   **t=1:** P2 מגיע (נותרו 4ms). ל-P1 נותרו 7ms. P2 קצר יותר (4 < 7), לכן P1 נקטע, P2 מתחיל לרוץ.\n*   **t=3:** P3 מגיע (נותרו 4ms). ל-P2 נותרו 2ms. P3 (4) ארוך יותר מ-P2 (2), לכן P2 ממשיך לרוץ.\n*   **t=5:** P2 מסיים. **זמן השלמה P2 = 5ms**. \n    *   בתור: P1 (נותרו 7ms), P3 (נותרו 4ms). P3 הוא הקצר ביותר. P3 מתחיל לרוץ.\n*   **t=7:** P3 מסיים את פרץ המעבד הראשון (2ms). ל-P3 נותרו 2ms. P3 עובר לק/פ למשך 5ms, יהיה מוכן שוב ב-t=7+5=12.\n    *   בתור: P1 (נותרו 7ms). P1 מתחיל לרוץ.\n*   **t=12:** P1 מסיים את פרץ המעבד הראשון (5ms). ל-P1 נותרו 3ms. P1 עובר לק/פ למשך 10ms, יהיה מוכן שוב ב-t=12+10=22.\n    *   בדיוק ב-t=12, P3 מסיים את הק/פ והופך למוכן (נותרו 2ms). P3 הוא התהליך היחיד בתור. P3 מתחיל לרוץ.\n*   **t=14:** P3 מסיים את פרץ המעבד השני (2ms). **זמן השלמה P3 = 14ms**.\n    *   המעבד לא פעיל עד ש-P1 חוזר.\n*   **t=22:** P1 מסיים את הק/פ. ל-P1 נותרו 3ms. P1 מתחיל לרוץ.\n*   **t=25:** P1 מסיים את פרץ המעבד השני (3ms). **זמן השלמה P1 = 25ms**.\n\n**זמני השלמה SRTF:** P1=25, P2=5, P3=14\n\n**2. אלגוריתם Round Robin (קוואנטום=2ms):**\n*   **t=0:** P1 מגיע. P1 מתחיל לרוץ (נותרו 8ms).\n*   **t=1:** P2 מגיע. תור מוכנים: [P2].\n*   **t=2:** P1 קוואנטום נגמר. ל-P1 נותרו 6ms. P1 עובר לסוף התור. תור מוכנים: [P2, P1]. P2 מתחיל לרוץ.\n*   **t=3:** P3 מגיע. תור מוכנים: [P1, P3].\n*   **t=4:** P2 קוואנטום נגמר. ל-P2 נותרו 2ms. P2 עובר לסוף התור. תור מוכנים: [P1, P3, P2]. P1 מתחיל לרוץ.\n*   **t=6:** P1 קוואנטום נגמר. ל-P1 נותרו 4ms. P1 עובר לסוף התור. תור מוכנים: [P3, P2, P1]. P3 מתחיל לרוץ.\n*   **t=8:** P3 קוואנטום נגמר. ל-P3 נותרו 2ms. P3 עובר לסוף התור. תור מוכנים: [P2, P1, P3]. P2 מתחיל לרוץ.\n*   **t=10:** P2 קוואנטום נגמר. ל-P2 נותרו 0ms. P2 מסיים. **זמן השלמה P2 = 10ms**. \n    *   תור מוכנים: [P1, P3]. P1 מתחיל לרוץ.\n*   **t=11:** P1 מסיים את פרץ המעבד הראשון (1ms מהקוואנטום הנוכחי, סה\"כ 5ms). ל-P1 נותרו 3ms. P1 עובר לק/פ למשך 10ms, יהיה מוכן שוב ב-t=11+10=21.\n    *   תור מוכנים: [P3]. P3 מתחיל לרוץ.\n*   **t=13:** P3 מסיים את פרץ המעבד הראשון (2ms, הקוואנטום שלו). ל-P3 נותרו 2ms. P3 עובר לק/פ למשך 5ms, יהיה מוכן שוב ב-t=13+5=18.\n    *   המעבד לא פעיל.\n*   **t=18:** P3 מסיים את הק/פ. ל-P3 נותרו 2ms. P3 מתחיל לרוץ.\n*   **t=20:** P3 מסיים את פרץ המעבד השני (2ms, הקוואנטום שלו). ל-P3 נותרו 0ms. P3 מסיים. **זמן השלמה P3 = 20ms**.\n    *   המעבד לא פעיל.\n*   **t=21:** P1 מסיים את הק/פ. ל-P1 נותרו 3ms. P1 מתחיל לרוץ.\n*   **t=23:** P1 קוואנטום נגמר. ל-P1 נותרו 1ms. P1 עובר לסוף התור. תור מוכנים: [P1]. P1 מתחיל לרוץ.\n*   **t=24:** P1 מסיים את פרץ המעבד השני (1ms). ל-P1 נותרו 0ms. P1 מסיים. **זמן השלמה P1 = 24ms**.\n\n**זמני השלמה Round Robin:** P1=24, P2=10, P3=20\n\n**השוואת זמני השלמה:**\n*   **P1:** Round Robin = 24ms, SRTF = 25ms. (P1 מסתיים מוקדם יותר ב-Round Robin)\n*   **P2:** Round Robin = 10ms, SRTF = 5ms. (P2 מסתיים מוקדם יותר ב-SRTF)\n*   **P3:** Round Robin = 20ms, SRTF = 14ms. (P3 מסתיים מוקדם יותר ב-SRTF)\n\nלפי ההשוואה, טענה א' היא הנכונה: תהליך P1 מסתיים מוקדם יותר באלגוריתם Round Robin מאשר באלגוריתם Preemptive SJF, בעוד שתהליכים P2 ו-P3 מסתיימים מוקדם יותר באלגוריתם Preemptive SJF.\n\n"}, "difficulty_estimation": "Hard", "_source_file": "0740__CPU_Scheduling__MultipleChoice__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:00:06", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["CPU Scheduling", "Preemptive Priority"], "content": {"text": "נתונות 4 משימות (תהליכים) במערכת הפעלה המשתמשת באלגוריתם תזמון עדיפויות מונע (Preemptive Priority Scheduling). מספר עדיפות נמוך יותר מציין עדיפות גבוהה יותר. במקרה של שוויון בעדיפות, המשימה שהגיעה ראשונה (FCFS) תקבל את המעבד.\nלהלן פרטי המשימות:\n- P1: זמן הגעה = 0, זמן ריצה (CPU burst) = 5, עדיפות = 3\n- P2: זמן הגעה = 1, זמן ריצה (CPU burst) = 2, עדיפות = 1\n- P3: זמן הגעה = 2, זמן ריצה (CPU burst) = 3, עדיפות = 4\n- P4: זמן הגעה = 4, זמן ריצה (CPU burst) = 4, עדיפות = 2\n\nמהו זמן ההמתנה הממוצע (Average Waiting Time) של כל המשימות?", "code_snippet": null, "options": ["א. 3.0", "ב. 3.25", "ג. 3.5", "ד. 3.75", "ה. אף אחת מהתשובות אינה נכונה"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "נבצע מעקב אחר ביצוע המשימות:\nזמן 0: P1 מגיע (עדיפות 3, זמן ריצה 5). P1 מתחיל לרוץ.\nזמן 1: P2 מגיע (עדיפות 1, זמן ריצה 2). P2 בעל עדיפות גבוהה מ-P1. P1 נקטע (נותרו 4 יחידות). P2 מתחיל לרוץ.\nזמן 2: P3 מגיע (עדיפות 4, זמן ריצה 3). P2 ממשיך לרוץ (עדיפות 1).\nזמן 3: P2 מסיים ריצה (זמן ריצה 2 הושלם). המעבד פנוי.\n   משימות מוכנות: P1 (עדיפות 3, נותרו 4), P3 (עדיפות 4, נותרו 3).\n   P1 בעל עדיפות גבוהה יותר מ-P3. P1 ממשיך לרוץ.\nזמן 4: P4 מגיע (עדיפות 2, זמן ריצה 4). P1 רץ (עדיפות 3). P4 בעל עדיפות גבוהה מ-P1. P1 נקטע (נותרו 3 יחידות). P4 מתחיל לרוץ.\nזמן 8: P4 מסיים ריצה (זמן ריצה 4 הושלם). המעבד פנוי.\n   משימות מוכנות: P1 (עדיפות 3, נותרו 3), P3 (עדיפות 4, נותרו 3).\n   P1 בעל עדיפות גבוהה יותר מ-P3. P1 ממשיך לרוץ.\nזמן 11: P1 מסיים ריצה (זמן ריצה 3 הושלם, סה\"כ 5). המעבד פנוי.\n   משימות מוכנות: P3 (עדיפות 4, נותרו 3).\n   P3 מתחיל לרוץ.\nזמן 14: P3 מסיים ריצה (זמן ריצה 3 הושלם).\n\nזמני סיום:\nP2: 3\nP4: 8\nP1: 11\nP3: 14\n\nזמני מחזור (Turnaround Time = זמן סיום - זמן הגעה):\nP1: 11 - 0 = 11\nP2: 3 - 1 = 2\nP3: 14 - 2 = 12\nP4: 8 - 4 = 4\n\nזמני המתנה (Waiting Time = זמן מחזור - זמן ריצה):\nP1: 11 - 5 = 6\nP2: 2 - 2 = 0\nP3: 12 - 3 = 9\nP4: 4 - 4 = 0\n\nזמן ההמתנה הממוצע = (6 + 0 + 9 + 0) / 4 = 15 / 4 = 3.75.\nלכן, התשובה הנכונה היא ד'."}, "difficulty_estimation": "Hard", "_source_file": "0741__CPU_Scheduling__MultipleChoice__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:00:26", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["CPU Scheduling", "Preemptive Priority", "Round Robin"], "content": {"text": "נתונה מערכת הפעלה המשתמשת באלגוריתם תזמון מעבדים (CPU Scheduling) מונע (Preemptive Priority).\nכלל התזמון הוא כדלקמן:\n1.  תהליכים בעלי עדיפות נמוכה יותר (מספר נמוך יותר) יקבלו את המעבד לפני תהליכים בעלי עדיפות גבוהה יותר.\n2.  אם שני תהליכים או יותר בעלי אותה עדיפות נמצאים במצב Ready, הם יתוזמנו בשיטת Round Robin עם קוונטום (Quantum) של 2 מילישניות.\n3.  אין התחשבות בזמן החלפת קשר (Context Switch Overhead).\n\nנתונים שלושה תהליכים: P1, P2, P3.\n*   **P1:** מגיע בזמן 0. עדיפות: 2. דורש 4 מילישניות CPU, לאחר מכן מבצע פעולת I/O שאורכת 3 מילישניות, ולאחר מכן דורש 2 מילישניות CPU נוספות.\n*   **P2:** מגיע בזמן 0. עדיפות: 1. דורש 6 מילישניות CPU.\n*   **P3:** מגיע בזמן 1. עדיפות: 2. דורש 3 מילישניות CPU.\n\nלהלן קטע קוד המייצג את התנהגותו של תהליך P1:\n```c\n// מבנה קוד כללי של תהליך P1\nvoid process_P1_task() {\n    // פרץ CPU ראשון\n    for (long i = 0; i < 400000000; ++i) { /* ביצוע עבודה של המעבד */ } \n\n    // פעולת קלט/פלט\n    perform_io_operation(3); // מדמה פעולת I/O באורך 3 מילישניות\n\n    // פרץ CPU שני\n    for (long i = 0; i < 200000000; ++i) { /* ביצוע עבודה של המעבד */ }\n}\n```\n\nמהו זמן המחזור (Turnaround Time) של תהליך P1?", "code_snippet": "// מבנה קוד כללי של תהליך P1\nvoid process_P1_task() {\n    // פרץ CPU ראשון\n    for (long i = 0; i < 400000000; ++i) { /* ביצוע עבודה של המעבד */ } \n\n    // פעולת קלט/פלט\n    perform_io_operation(3); // מדמה פעולת I/O באורך 3 מילישניות\n\n    // פרץ CPU שני\n    for (long i = 0; i < 200000000; ++i) { /* ביצוע עבודה של המעבד */ }\n}", "options": ["א. 12 מילישניות", "ב. 15 מילישניות", "ג. 17 מילישניות", "ד. 18 מילישניות", "ה. 19 מילישניות"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "נבצע מעקב אחר ביצוע התהליכים:\n\n*   **זמן 0:**\n    *   P1 מגיע (עדיפות 2, דורש 4ms CPU).\n    *   P2 מגיע (עדיפות 1, דורש 6ms CPU).\n    *   P2 בעל העדיפות הגבוהה ביותר (1), ולכן מתחיל לרוץ.\n*   **זמן 0 - 6:**\n    *   P2 רץ. \n    *   בזמן 1: P3 מגיע (עדיפות 2, דורש 3ms CPU). P2 עדיין בעל העדיפות הגבוהה ביותר.\n    *   P2 מסיים את פרץ ה-CPU שלו בזמן 6.\n*   **זמן 6:**\n    *   P1 מוכן (עדיפות 2, נותרו 4ms CPU).\n    *   P3 מוכן (עדיפות 2, נותרו 3ms CPU).\n    *   ל-P1 ול-P3 יש אותה עדיפות (2). הם יתוזמנו ב-Round Robin עם קוונטום 2ms. P1 הגיע ראשון מבין השניים (בזמן 0), ולכן P1 יתחיל לרוץ.\n*   **זמן 6 - 8:**\n    *   P1 רץ למשך 2ms (קוונטום). ל-P1 נותרו 2ms CPU.\n    *   בזמן 8, P1 נדחה על ידי RR. P3 מקבל את תורו.\n*   **זמן 8 - 10:**\n    *   P3 רץ למשך 2ms (קוונטום). ל-P3 נותר 1ms CPU.\n    *   בזמן 10, P3 נדחה על ידי RR. P1 מקבל את תורו.\n*   **זמן 10 - 12:**\n    *   P1 רץ למשך 2ms. P1 מסיים את פרץ ה-CPU הראשון שלו.\n    *   בזמן 12, P1 עובר למצב I/O למשך 3ms.\n*   **זמן 12:**\n    *   P3 הוא התהליך היחיד שמוכן (עדיפות 2, נותר 1ms CPU). P3 מתחיל לרוץ.\n*   **זמן 12 - 13:**\n    *   P3 רץ למשך 1ms. P3 מסיים את פרץ ה-CPU שלו.\n*   **זמן 13 - 15:**\n    *   המעבד אינו פעיל (Idle) בזמן זה, מכיוון שאין תהליכים מוכנים.\n*   **זמן 15:**\n    *   P1 מסיים את פעולת ה-I/O שלו וחוזר למצב Ready (עדיפות 2, נותרו 2ms CPU).\n    *   P1 הוא התהליך היחיד שמוכן. P1 מתחיל לרוץ.\n*   **זמן 15 - 17:**\n    *   P1 רץ למשך 2ms. P1 מסיים את פרץ ה-CPU השני שלו. P1 מסתיים.\n\nזמן הסיום של P1 הוא 17.\nזמן ההגעה של P1 הוא 0.\nזמן המחזור (Turnaround Time) של P1 = זמן סיום - זמן הגעה = 17 - 0 = 17 מילישניות.\nלכן, התשובה הנכונה היא ג'."}, "difficulty_estimation": "Hard", "_source_file": "0742__CPU_Scheduling__MultipleChoice__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:00:52", "_subject": "Virtualization"}, {"id": 101, "type": "MultipleChoice", "topic": ["CPU Scheduling", "Round Robin", "Quantum", "Performance", "Fairness"], "content": {"text": "נתבונן במערכת המשתמשת באלגוריתם תזמון מעבד מסוג Round Robin (RR). הקוונטום (Q) נקבע להיות *מעט גדול יותר* ממשך פרץ המעבד הטיפוסי של תהליכים מוגבלי-קלט/פלט (I/O-bound), אך *קטן משמעותית* ממשך פרץ המעבד הטיפוסי של תהליכים מוגבלי-מעבד (CPU-bound). איזו מהטענות הבאות היא *הסבירה ביותר להיות נכונה* לגבי התנהגות המערכת?", "code_snippet": null, "options": ["א. תהליכים מוגבלי-קלט/פלט יחוו זמני השלמה (turnaround times) נמוכים מאוד ותפוקה גבוהה, וינצלו באופן יעיל את המעבד כשהם מוכנים לביצוע.", "ב. תהליכים מוגבלי-מעבד יסבלו מרעב (starvation) משמעותי מכיוון שתהליכים מוגבלי-קלט/פלט תמיד ישלימו את פרצי המעבד שלהם בתוך הקוונטום ויחזרו במהירות לתור המוכנים.", "ג. המערכת תשיג איזון טוב בין היענות (responsiveness) עבור תהליכים מוגבלי-קלט/פלט לבין התקדמות סבירה עבור תהליכים מוגבלי-מעבד, תוך מזעור תקורת החלפת ההקשר (context switch overhead) עבור משימות מוגבלות-קלט/פלט.", "ד. ניצול המעבד הכולל יהיה נמוך מאוד עקב החלפות ההקשר התכופות הנגרמות על ידי שני סוגי התהליכים.", "ה. המערכת תתנוון להתנהגות מסוג First-Come, First-Served (FCFS) עבור תהליכים מוגבלי-מעבד, מכיוון שהם יידחקו רק לאחר שיפוג הקוונטום שלהם, ותהליכים מוגבלי-קלט/פלט לא יפריעו באופן משמעותי."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "ג. בחירה של קוונטום שמעט גדול מפרץ המעבד הטיפוסי של תהליכי I/O-bound מאפשרת לתהליכים אלו להשלים את פרץ המעבד הקצר שלהם ולעבור לביצוע פעולת קלט/פלט מבלי להידחק (preempted). זה משפר את היענות המערכת עבורם וממזער את תקורת החלפת ההקשר עבורם, שכן הם יוצאים מהמעבד באופן וולונטרי. במקביל, תהליכים מוגבלי-מעבד עדיין מקבלים נתחי זמן קוונטום קבועים, מה שמבטיח התקדמות סבירה ומונע רעב, גם אם קצב התקדמותם איטי יותר מאשר בקוונטום גדול מאוד. לכן, זוהי אסטרטגיה נפוצה לאיזון בין סוגי התהליכים."}, "difficulty_estimation": "Hard", "_source_file": "0743__CPU_Scheduling__MultipleChoice__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:01:12", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["CPU Scheduling", "SRTF", "Round Robin"], "content": {"text": "נתונים ארבעה תהליכים (P1, P2, P3, P4) עם זמני הגעה (Arrival Time) וזמני ריצה (Burst Time) כדלקמן:\n\nP1: AT=0, BT=10\nP2: AT=1, BT=1\nP3: AT=2, BT=2\nP4: AT=3, BT=10\n\nהשווה בין ממוצע זמן ההמתנה (Average Waiting Time) של כל התהליכים בשיטות התזמון הבאות:\n1. SRTF (Shortest Remaining Time First)\n2. Round Robin (RR) עם קוונטום (Quantum) בגודל 3 יחידות זמן.\n\nאיזו מהטענות הבאות נכונה?", "code_snippet": null, "options": ["א. ממוצע זמן ההמתנה ב-SRTF גבוה יותר מאשר ב-RR.", "ב. ממוצע זמן ההמתנה ב-SRTF נמוך יותר מאשר ב-RR.", "ג. ממוצע זמן ההמתנה זהה בשתי השיטות.", "ד. לא ניתן לקבוע ללא מידע נוסף על עומס המערכת."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "נבצע מעקב (trace) עבור כל אחת משיטות התזמון:\n\n**1. SRTF (Shortest Remaining Time First):**\n-   **t=0**: P1 מגיע (BT=10). P1 רץ.\n-   **t=1**: P2 מגיע (BT=1). זמן הריצה הנותר של P2 (1) קצר מזה של P1 (9). P1 נקטע (preempted). P2 רץ.\n-   **t=2**: P2 מסתיים. P3 מגיע (BT=2). זמן הריצה הנותר של P3 (2) קצר מזה של P1 (9). P3 רץ.\n-   **t=4**: P3 מסתיים. P4 מגיע (BT=10). זמן הריצה הנותר של P1 (9) קצר מזה של P4 (10). P1 רץ.\n-   **t=13**: P1 מסתיים. P4 רץ.\n-   **t=23**: P4 מסתיים.\n\n**זמני סיום (Completion Time - CT):**\nP2: 2\nP3: 4\nP1: 13\nP4: 23\n\n**זמני מחזור (Turnaround Time - TAT = CT - AT):**\nP2: 2 - 1 = 1\nP3: 4 - 2 = 2\nP1: 13 - 0 = 13\nP4: 23 - 3 = 20\n\n**זמני המתנה (Waiting Time - WT = TAT - BT):**\nP2: 1 - 1 = 0\nP3: 2 - 2 = 0\nP1: 13 - 10 = 3\nP4: 20 - 10 = 10\n\n**ממוצע זמן המתנה ב-SRTF:** (0 + 0 + 3 + 10) / 4 = 13 / 4 = 3.25\n\n**2. Round Robin (RR) עם קוונטום (Quantum) בגודל 3:**\n-   **t=0**: P1 מגיע (BT=10). P1 רץ.\n-   **t=1**: P2 מגיע. (P1 ממשיך לרוץ כי הקוונטום שלו לא תם).\n-   **t=2**: P3 מגיע. (P1 ממשיך לרוץ).\n-   **t=3**: P1 מסיים קוונטום. P1 (נותרו 7) עובר לסוף התור. תור: P2, P3, P4, P1(7). P2 רץ (BT=1).\n-   **t=4**: P2 מסתיים. תור: P3, P4, P1(7). P3 רץ (BT=2).\n-   **t=6**: P3 מסתיים. תור: P4, P1(7). P4 רץ (BT=10).\n-   **t=9**: P4 מסיים קוונטום. P4 (נותרו 7) עובר לסוף התור. תור: P1(7), P4(7). P1 רץ (נותרו 7).\n-   **t=12**: P1 מסיים קוונטום. P1 (נותרו 4) עובר לסוף התור. תור: P4(7), P1(4). P4 רץ (נותרו 7).\n-   **t=15**: P4 מסיים קוונטום. P4 (נותרו 4) עובר לסוף התור. תור: P1(4), P4(4). P1 רץ (נותרו 4).\n-   **t=18**: P1 מסתיים. תור: P4(4). P4 רץ (נותרו 4).\n-   **t=22**: P4 מסתיים.\n\n**זמני סיום (Completion Time - CT):**\nP2: 4\nP3: 6\nP1: 18\nP4: 22\n\n**זמני מחזור (Turnaround Time - TAT = CT - AT):**\nP2: 4 - 1 = 3\nP3: 6 - 2 = 4\nP1: 18 - 0 = 18\nP4: 22 - 3 = 19\n\n**זמני המתנה (Waiting Time - WT = TAT - BT):**\nP2: 3 - 1 = 2\nP3: 4 - 2 = 2\nP1: 18 - 10 = 8\nP4: 19 - 10 = 9\n\n**ממוצע זמן המתנה ב-RR:** (2 + 2 + 8 + 9) / 4 = 21 / 4 = 5.25\n\n**השוואה:**\nממוצע זמן ההמתנה ב-SRTF הוא 3.25.\nממוצע זמן ההמתנה ב-RR הוא 5.25.\n\nלכן, ממוצע זמן ההמתנה ב-SRTF נמוך יותר מאשר ב-RR."}, "difficulty_estimation": "Hard", "_source_file": "0744__CPU_Scheduling__MultipleChoice__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:01:40", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["CPU Scheduling", "Scheduling Algorithms"], "content": {"text": "תאר את אלגוריתם תזמון המעבד First-Come, First-Served (FCFS). ציין יתרון וחיסרון עיקריים של אלגוריתם זה.", "code_snippet": null, "options": null}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "תיאור: אלגוריתם FCFS (First-Come, First-Served) מתזמן תהליכים לפי סדר הגעתם לתור המוכנים (ready queue). התהליך הראשון שמגיע מקבל את המעבד, ורץ עד לסיומו או עד שהוא נכנס למצב המתנה (לדוגמה, פעולת קלט/פלט). זהו אלגוריתם לא מונע (non-preemptive).\nיתרון עיקרי: פשוט מאוד ליישום ולהבנה. קל להבטיח הוגנות בסיסית בכך ש\"הראשון שהגיע הוא הראשון שמקבל שירות\".\nחיסרון עיקרי: יכול לגרום לזמני המתנה וזמני מחזור (turnaround time) ארוכים מאוד עבור תהליכים קצרים, במיוחד אם תהליך ארוך מגיע ראשון. תופעה זו מכונה 'אפקט השיירה' (convoy effect), והיא עלולה להוביל לניצול נמוך של המעבד אם תהליכים ארוכים גורמים לתהליכי I/O-bound קצרים לחכות זמן רב."}, "difficulty_estimation": "Easy", "_source_file": "0745__CPU_Scheduling__Open__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:01:47", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["CPU Scheduling", "Round Robin"], "content": {"text": "הסבירו את עקרון הפעולה של אלגוריתם תזמון Round Robin (RR). ציינו יתרון וחיסרון אחד של אלגוריתם זה, והסבירו בקצרה כל אחד מהם.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "אלגוריתם Round Robin הוא אלגוריתם תזמון פרמפטיבי (preemptive) שנועד להבטיח הוגנות בין תהליכים. כל תהליך מקבל יחידת זמן קבועה לביצוע (quantum). כאשר הקוואנטום של תהליך מסתיים, אם התהליך עדיין לא סיים את ריצתו, הוא מועבר לסוף תור התהליכים המוכנים (ready queue) והמעבד עובר לתהליך הבא בתור. תהליך שסיים את ריצתו לפני תום הקוואנטום משחרר את המעבד ויוצא מתור התהליכים.\n\nיתרון: הוגנות (Fairness) - כל תהליך מקבל הזדמנות שווה לרוץ ואין תהליך שסובל מרעב (starvation). הוא מתאים למערכות אינטראקטיביות שבהן חשוב שכל המשתמשים יקבלו זמן תגובה סביר.\n\nחיסרון: תקורה (Overhead) - עם כל החלפת קונטקסט (context switch) נדרש זמן לעבודה ניהולית של מערכת ההפעלה (שמירת מצב תהליך נוכחי וטעינת מצב תהליך חדש). אם הקוואנטום קצר מדי, התקורה של החלפות הקונטקסט עלולה להיות משמעותית ולפגוע בביצועים הכוללים של המערכת."}, "difficulty_estimation": "Easy", "_source_file": "0746__CPU_Scheduling__Open__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:01:59", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["CPU Scheduling", "Scheduling Algorithms", "FCFS"], "content": {"text": "הסבירו בקצרה את אלגוריתם תזמון המעבד First-Come, First-Served (FCFS). ציינו יתרון וחיסרון אחד של אלגוריתם זה.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "אלגוריתם FCFS (First-Come, First-Served) הוא אלגוריתם תזמון מעבד לא-פולשני (non-preemptive) שבו התהליכים מבוצעים לפי סדר הגעתם לתור המוכנים. התהליך הראשון שמגיע לתור המוכנים הוא הראשון שמקבל את המעבד, והוא ממשיך לרוץ עד לסיום פעולתו או עד שהוא נכנס למצב המתנה (למשל, עבור קלט/פלט).\n\nיתרון: פשוט מאוד ליישום והבנה. הוא נחשב הוגן במובן שתהליכים מקבלים את המעבד לפי סדר הגעתם.\n\nחיסרון: עלול לסבול מ'אפקט השיירה' (convoy effect) – תהליך ארוך אחד יכול לגרום לתהליכים קצרים רבים להמתין זמן רב, מה שמוביל לזמן המתנה ממוצע גבוה וזמן מחזור (turnaround time) ממוצע גבוה עבור המערכת כולה."}, "difficulty_estimation": "Easy", "_source_file": "0747__CPU_Scheduling__Open__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:02:07", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["CPU Scheduling", "FCFS"], "content": {"text": "תארו את אלגוריתם תזמון המעבד First-Come, First-Served (FCFS). מהו היתרון העיקרי שלו, ומהו חיסרון משמעותי אחד שיכול להיות לו במערכת מרובת תהליכים?", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "תיאור: אלגוריתם FCFS (First-Come, First-Served) מתזמן תהליכים לפי סדר הגעתם לתור המוכנים (ready queue). התהליך הראשון שמגיע מקבל את המעבד ורץ עד לסיום פעולתו, או עד שהוא נכנס למצב המתנה (למשל, עבור קלט/פלט), והוא אינו נקטע (non-preemptive).\n\nיתרון עיקרי: היתרון הבולט ביותר של FCFS הוא פשטותו הרבה ליישום והבנה. הוא אינו דורש חישובים מורכבים או מעקב אחרי זמנים, מה שהופך אותו לקל מאוד למימוש במערכות הפעלה.\n\nחיסרון משמעותי: החיסרון המרכזי של FCFS הוא שהוא עלול לסבול מ\"אפקט השיירה\" (convoy effect). מצב זה מתרחש כאשר תהליך ארוך מאוד (בעל זמן ביצוע ארוך) מגיע ראשון ומשתלט על המעבד, וגורם לכל התהליכים הקצרים יותר שהגיעו אחריו להמתין זמן רב באופן לא יעיל. זה יכול להוביל לזמני המתנה וזמני מחזור (turnaround time) ממוצעים גבוהים מאוד עבור כלל המערכת, ולפגיעה בביצועים הכוללים."}, "difficulty_estimation": "Easy", "_source_file": "0748__CPU_Scheduling__Open__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:02:16", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["CPU Scheduling", "FCFS", "SJF"], "content": {"text": "הסבירו בקצרה את ההבדל העיקרי בין אלגוריתמי תזמון המעבד First-Come, First-Served (FCFS) ו-Shortest-Job-First (SJF) (לא פרמפטיבי). תארו חיסרון אחד לכל אחד מהאלגוריתמים.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הבדל עיקרי:\n*   **FCFS (First-Come, First-Served)**: תהליכים מתוזמנים לפי סדר הגעתם לתור. התהליך הראשון שמגיע, הוא הראשון שמקבל את המעבד, ורץ עד לסיום או לחסימה.\n*   **SJF (Shortest-Job-First) (לא פרמפטיבי)**: מבין כל התהליכים הממתינים בתור, האלגוריתם בוחר את התהליך בעל זמן הריצה (burst time) הקצר ביותר. תהליך שנבחר רץ עד לסיום או לחסימה.\n\nחיסרון של FCFS:\n*   **אפקט השיירה (Convoy Effect)**: תהליך ארוך שמגיע ראשון יכול לגרום לתהליכים קצרים רבים שהגיעו אחריו להמתין זמן רב, ובכך להעלות את זמן ההמתנה הממוצע ואת זמן המחזור הממוצע באופן משמעותי.\n\nחיסרון של SJF (לא פרמפטיבי):\n*   **קושי במימוש**: SJF דורש ידע מוקדם על זמן הריצה (burst time) של כל תהליך, מידע שבדרך כלל אינו זמין במערכת הפעלה אמיתית. במציאות, יש צורך להעריך את זמני הריצה, מה שמוסיף מורכבות ואי-דיוק."}, "difficulty_estimation": "Easy", "_source_file": "0749__CPU_Scheduling__Open__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:02:35", "_subject": "Virtualization"}, {"id": 5, "type": "Open", "topic": ["CPU Scheduling", "Round Robin"], "content": {"text": "הסבירו בקצרה את עקרון הפעולה של אלגוריתם תזמון Round Robin. מהו הפרמטר המרכזי באלגוריתם זה, וכיצד בחירתו משפיעה על ביצועי המערכת (זמן תגובה וזמן מחזור)?", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "אלגוריתם תזמון Round Robin (RR) פועל על בסיס חלוקת זמן CPU בין התהליכים בשיטה של זמן קוונטום (time quantum).\nעקרון הפעולה: כל תהליך מקבל נתח קטן של זמן CPU, הנקרא 'קוונטום זמן'. אם התהליך לא מסיים את ריצתו בתוך הקוונטום שהוקצה לו, הוא נקטע (preempted) ומועבר לסוף תור התהליכים המוכנים (ready queue). לאחר מכן, התהליך הבא בתור מקבל את זמנו. פעולה זו מבטיחה שוויון יחסי ומונעת מצב שבו תהליך אחד משתלט על ה-CPU לאורך זמן.\n\nהפרמטר המרכזי באלגוריתם זה הוא **זמן הקוונטום (Time Quantum)**.\n\nהשפעת בחירת זמן הקוונטום על ביצועי המערכת:\n*   **קוונטום זמן קטן:**\n    *   **יתרונות:** זמן תגובה (response time) טוב יותר, מכיוון שכל תהליך מקבל גישה ל-CPU לעיתים קרובות. זה אידיאלי למערכות אינטראקטיביות.\n    *   **חסרונות:** מוביל ליותר החלפות הקשר (context switches), מה שמגדיל את התקורה (overhead) של המערכת ומוריד את התפוקה (throughput) הכוללת, כיוון שיש יותר זמן מבוזבז על החלפת תהליכים במקום על ביצוע עבודה שימושית.\n\n*   **קוונטום זמן גדול:**\n    *   **יתרונות:** פחות החלפות הקשר, מה שמפחית את התקורה ומשפר את התפוקה. במקרה קיצוני, כאשר הקוונטום גדול מאוד (ארוך יותר מרוב זמני הריצה של התהליכים), האלגוריתם יתנהג באופן דומה ל-First Come First Served (FCFS).\n    *   **חסרונות:** זמן תגובה גרוע יותר, במיוחד עבור תהליכים אינטראקטיביים קצרים, שעלולים להמתין זמן רב יחסית עד שיקבלו את תורם, גם אם הם דורשים רק מעט זמן CPU. זמן המחזור (turnaround time) יכול להיות גבוה יותר עבור תהליכים קצרים."}, "difficulty_estimation": "Easy", "_source_file": "0750__CPU_Scheduling__Open__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:02:51", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["CPU Scheduling", "Scheduling Algorithms", "FCFS"], "content": {"text": "הסבירו את המטרה העיקרית של תזמון מעבד (CPU scheduling), וציינו יתרון אחד וחיסרון אחד של אלגוריתם התזמון FCFS (First Come First Served).", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "המטרה העיקרית של תזמון מעבד היא לנהל את הקצאת המעבד (CPU) בין התהליכים השונים במערכת ההפעלה, במטרה לייעל את ביצועי המערכת הכוללים. מטרות נפוצות כוללות הגדלת ניצולת המעבד, מזעור זמן התגובה (response time) וזמן ההשלמה (turnaround time), והבטחת הוגנות בהקצאת המשאבים.\n\nיתרון של אלגוריתם FCFS:\n*   פשטות: קל מאוד ליישום והבנה. תהליכים מבוצעים לפי סדר הגעתם לתור.\n\nחיסרון של אלגוריתם FCFS:\n*   אפקט השיירה (Convoy Effect): תהליך ארוך שמגיע מוקדם יכול לגרום לזמני המתנה ארוכים מאוד עבור כל התהליכים הקצרים יותר שמגיעים אחריו, ובכך לפגוע ביעילות ובזמן התגובה הכולל של המערכת."}, "difficulty_estimation": "Easy", "_source_file": "0751__CPU_Scheduling__Open__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:03:00", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["CPU Scheduling", "FCFS"], "content": {"text": "הסבירו את אלגוריתם תזמון המעבד First-Come, First-Served (FCFS). מהו החיסרון המרכזי שלו, ומדוע הוא נחשב לפשוט ליישום?", "code_snippet": null, "options": null}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "אלגוריתם FCFS (First-Come, First-Served) הוא אלגוריתם תזמון מעבד פשוט שבו תהליכים מבוצעים לפי סדר הגעתם לתור המוכנים. התהליך שמגיע ראשון מבוצע ראשון, ולאחר מכן התהליך שהגיע שני, וכן הלאה, עד שכל תהליך מסיים את זמן הריצה שלו.\n\nהחיסרון המרכזי של FCFS הוא 'אפקט השיירה' (Convoy Effect). אם תהליך ארוך מגיע ראשון, כל התהליכים הקצרים יותר שמגיעים אחריו יצטרכו להמתין עד שהתהליך הארוך יסיים את ריצתו. זה יכול להוביל לזמני המתנה וזמני מחזור ממוצעים גבוהים מאוד עבור התהליכים הקצרים, ובכך ליעילות נמוכה של המערכת.\n\nהאלגוריתם נחשב לפשוט ליישום מכיוון שהוא דורש רק תור FIFO (First-In, First-Out) פשוט. אין צורך בלוגיקה מורכבת לקביעת עדיפויות, חישוב זמני ריצה שנותרו, או הקצאת פרוסות זמן. התהליך המגיע לתור פשוט מתווסף לסופו, והתהליך שבראש התור מקבל את המעבד."}, "difficulty_estimation": "Easy", "_source_file": "0752__CPU_Scheduling__Open__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:03:09", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["CPU Scheduling", "Scheduling", "Priority Scheduling", "Starvation"], "content": {"text": "מערכת הפעלה משתמשת באלגוריתם תזמון מעבד מבוסס עדיפויות (Preemptive Priority Scheduling) כאשר העדיפויות סטטיות (נקבעות פעם אחת ולא משתנות במהלך חיי התהליך).\n\n1. תארו תרחיש ספציפי שבו אלגוריתם תזמון זה יוביל לביצועים ירודים או לחוסר הוגנות משמעותי. נמקו את תשובתכם.\n2. הציעו שינוי או הרחבה לאלגוריתם התזמון הנתון על מנת להתמודד עם הבעיה שתיארתם בסעיף 1. אין להפוך את האלגוריתם ל-Multi-Level Feedback Queue. תארו כיצד השינוי עובד והסבירו מדוע הוא פותר את הבעיה.\n3. ציינו חיסרון פוטנציאלי אחד לשינוי שהצעתם בסעיף 2.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. תרחיש לביצועים ירודים/חוסר הוגנות:\n   תרחיש: ישנם תהליכים בעלי עדיפות גבוהה שמגיעים למערכת באופן תדיר. תהליך בעל עדיפות נמוכה יותר מגיע ומוכן לריצה. עם זאת, בגלל ההגעה המתמדת של תהליכים בעלי עדיפות גבוהה, התהליך בעל העדיפות הנמוכה לעולם אינו מקבל זמן מעבד (או מקבל מעט מאוד) ונשאר במצב \"רעב\" (starvation).\n   נימוק: האלגוריתם הוא פריאמטיבי, כלומר תהליך בעל עדיפות גבוהה יותר יכול להפסיק תהליך בעל עדיפות נמוכה יותר. כאשר העדיפויות סטטיות, אין מנגנון לשפר את עדיפותו של תהליך שממתין זמן רב, ולכן תהליכים בעלי עדיפות נמוכה יכולים להיתקע באינסוף המתנה אם תהליכים בעלי עדיפות גבוהה ממשיכים להגיע.\n\n2. שינוי מוצע לפתרון הבעיה:\n   הצעה: מנגנון \"הזדקנות\" (Aging). במקום עדיפות סטטית, עדיפות של תהליך תשתנה באופן דינמי.\n   תיאור ופתרון: כל פרק זמן קבוע (לדוגמה, כל שנייה) או לאחר מספר מסוים של החלפות קונטקסט, עדיפותם של כל התהליכים שממתינים בתור ה-Ready (ולא רצים כרגע) תוגדל בערך קבוע כלשהו (לדוגמה, עדיפותם תפחת מספרית אם 0 היא העדיפות הגבוהה ביותר, או תגדל אם מספרים גבוהים יותר מציינים עדיפות גבוהה יותר). ברגע שתהליך מקבל זמן מעבד, עדיפותו מאופסת לערך ההתחלתי שלו. מנגנון זה מבטיח שגם תהליכים בעלי עדיפות התחלתית נמוכה יצברו מספיק עדיפות עם הזמן כדי לקבל בסופו של דבר זמן מעבד, ובכך נמנעת תופעת הרעב. זהו עדיין אלגוריתם מבוסס עדיפויות, רק שהעדיפויות דינמיות. זה לא הופך אותו ל-MLFQ, שכן אין מספר תורים נפרדים עם כללי מעבר מורכבים.\n\n3. חיסרון פוטנציאלי:\n   חיסרון: מנגנון ה-Aging מוסיף תקורה (overhead) למערכת. יש צורך לבדוק ולעדכן באופן שוטף את העדיפויות של התהליכים הממתינים. פעולה זו דורשת זמן מעבד ומשאבי זיכרון נוספים, ועלולה להשפיע על יעילות התזמון הכוללת, במיוחד במערכות עם מספר רב של תהליכים או עם תקופת עדכון קצרה מאוד. בנוסף, קביעת קצב ה\"הזדקנות\" והערך המקסימלי לעדיפות דורשת כוונון עדין כדי לא לפגוע בעדיפותם המקורית של תהליכים קריטיים."}, "difficulty_estimation": "Medium", "_source_file": "0754__CPU_Scheduling__Open__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:03:44", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["CPU Scheduling", "Round Robin", "Mixed Workload"], "content": {"text": "מערכת הפעלה מריצה שני סוגים של תהליכים: תהליכים אינטראקטיביים (Interactive processes) הדורשים זמני תגובה נמוכים, ותהליכי אצווה (Batch processes) שיכולים לסבול זמני תגובה גבוהים יותר אך חשובה להם יעילות הריצה הכוללת (throughput). המערכת משתמשת באלגוריתם תזמון Round Robin סטנדרטי עם קוואנטום זמן קבוע ובתור מוכנים יחיד.\nהציעו שינוי לאלגוריתם ה-Round Robin הקיים, תוך שמירה על תור מוכנים יחיד (מבלי להשתמש במספר תורים נפרדים), שישפר את הביצועים עבור שני סוגי התהליכים. יש לפרט את השינוי, להסביר כיצד הוא מטפל בדרישות השונות של התהליכים, ולנמק מדוע הוא יביא לשיפור ביצועים.", "code_snippet": null, "options": null}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון המוצע הוא שינוי דינמי של קוואנטום הזמן (time quantum) המוקצה לתהליך, בהתבסס על סוג התהליך (אינטראקטיבי או אצווה).\n1.  **השינוי המוצע**:\n    *   יש להגדיר שני ערכים שונים לקוואנטום זמן: Q_interactive עבור תהליכים אינטראקטיביים ו-Q_batch עבור תהליכי אצווה, כאשר Q_interactive < Q_batch.\n    *   כאשר המתזמן בוחר את התהליך הבא לריצה מראש התור המוכנים היחיד, הוא יבדוק את סוג התהליך (מידע זה צריך להיות מאוחסן ב-PCB של התהליך).\n    *   בהתאם לסוג התהליך, יוקצה לו קוואנטום הזמן המתאים (או Q_interactive או Q_batch).\n    *   התהליך ירוץ למשך הקוואנטום שהוקצה לו, או עד שיחסום/יסיים, ולאחר מכן יחזור לסוף התור המוכנים, כבאלגוריתם Round Robin רגיל.\n2.  **הסבר ונימוק לשיפור ביצועים**:\n    *   **עבור תהליכים אינטראקטיביים**: הקוואנטום הקצר יותר (Q_interactive) מבטיח שתהליכים אלו יקבלו את המעבד לעיתים קרובות יותר. מכיוון שתהליכים אינטראקטיביים הם לרוב קצרי-CPU-burst ומונעי-קלט/פלט, הם יסיימו את משימתם הקצרה או יחסמו מהר יותר, מה שיביא לזמני תגובה נמוכים משמעותית. ריבוי החלפות ההקשר עבורם פחות קריטי, שכן הם ממילא חוסמים לעיתים קרובות.\n    *   **עבור תהליכי אצווה**: הקוואנטום הארוך יותר (Q_batch) מאפשר לתהליכים אלו לרוץ לפרקי זמן ארוכים יותר ללא הפרעה. זה מפחית באופן משמעותי את תקורת החלפות ההקשר (context switches) עבורם. תהליכי אצווה הם לרוב עתירי מעבד (CPU-bound), ולכן הפחתת החלפות ההקשר משפרת את התפוקה הכוללת של המערכת (throughput) על ידי הקטנת הזמן המבוזבז על ניהול.\n    *   **שמירה על תור יחיד**: השינוי עומד בדרישה לשמור על תור מוכנים יחיד, ובכך נמנעת המורכבות של ניהול מספר תורים, סדרי עדיפויות ביניהם, או העברות בין תורים, כפי שקורה באלגוריתמים כמו MLFQ. זהו שיפור ל-Round Robin סטנדרטי תוך שמירה על פשטות יחסית.\n    *   **הוגנות (Fairness)**: למרות הקוואנטומים השונים, עקרון ה-Round Robin נשמר – כל תהליך יקבל בסופו של דבר זמן מעבד, והמערכת תתאים את התזמון לצרכים המהותיים של כל סוג תהליך."}, "difficulty_estimation": "Medium", "_source_file": "0755__CPU_Scheduling__Open__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:04:04", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["CPU Scheduling", "Scheduling Algorithms", "Process Management", "Starvation"], "content": {"text": "נתונה מערכת חד-מעבדתית המשתמשת באלגוריתם תזמון קדימויות (Priority Scheduling). להלן רשימת תהליכים עם זמני הגעה, זמני ריצת מעבד (CPU burst) וקדימויות. מספר קדימות נמוך יותר מציין קדימות גבוהה יותר.\n\n| תהליך | זמן הגעה | זמן ריצת מעבד | קדימות |\n|---|---|---|---|\n| P1 | 0 | 10 | 3 |\n| P2 | 1 | 5 | 1 |\n| P3 | 2 | 2 | 2 |\n| P4 | 3 | 3 | 1 |\n\nהניחו שכל התהליכים הם CPU-bound ואינם מבצעים פעולות קלט/פלט במהלך ריצתם. במקרה של קדימויות שוות, יש להשתמש ב-FCFS (First-Come, First-Served) כקריטריון שובר שוויון.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "a", "text": "ציירו את דיאגרמת גאנט (Gantt Chart) עבור תזמון FCFS (First-Come, First-Served) וחשבו את זמן ההמתנה הממוצע (Average Waiting Time) ואת זמן המחזור הממוצע (Average Turnaround Time).", "code_snippet": null, "options": null}, {"id": "b", "text": "ציירו את דיאגרמת גאנט עבור תזמון קדימויות עם דריסה (Preemptive Priority) וחשבו את זמן ההמתנה הממוצע ואת זמן המחזור הממוצע.", "code_snippet": null, "options": null}, {"id": "c", "text": "הסבירו מהי בעיית 'הרעבה' (Starvation) בהקשר של תזמון קדימויות. האם תהליך כלשהו ברשימה הנתונה עלול לסבול מהרעבה תחת תזמון קדימויות עם דריסה? אם כן, איזה תהליך ומדוע? הציעו פתרון לבעיה זו.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. דיאגרמת גאנט עבור FCFS:\n[P1 (0-10)] [P2 (10-15)] [P3 (15-17)] [P4 (17-20)]\n\nחישובים:\n- P1: זמן המתנה = 0, זמן מחזור = 10 - 0 = 10\n- P2: זמן המתנה = 10 - 1 = 9, זמן מחזור = 15 - 1 = 14\n- P3: זמן המתנה = 15 - 2 = 13, זמן מחזור = 17 - 2 = 15\n- P4: זמן המתנה = 17 - 3 = 14, זמן מחזור = 20 - 3 = 17\n\nזמן המתנה ממוצע = (0 + 9 + 13 + 14) / 4 = 36 / 4 = 9\nזמן מחזור ממוצע = (10 + 14 + 15 + 17) / 4 = 56 / 4 = 14\n\nב. דיאגרמת גאנט עבור Preemptive Priority:\n[P1 (0-1)] [P2 (1-6)] [P4 (6-9)] [P3 (9-11)] [P1 (11-20)]\n\nחישובים:\n- P1: זמן הגעה = 0, זמן ריצה כולל = 10. רץ 0-1, ממתין 1-11, רץ 11-20. זמן המתנה = (1-0) + (11-1) = 1+10 = 10. זמן מחזור = 20 - 0 = 20.\n- P2: זמן הגעה = 1, זמן ריצה = 5. רץ 1-6. זמן המתנה = 1 - 1 = 0. זמן מחזור = 6 - 1 = 5.\n- P3: זמן הגעה = 2, זמן ריצה = 2. רץ 9-11. זמן המתנה = 9 - 2 = 7. זמן מחזור = 11 - 2 = 9.\n- P4: זמן הגעה = 3, זמן ריצה = 3. רץ 6-9. זמן המתנה = 6 - 3 = 3. זמן מחזור = 9 - 3 = 6.\n\nזמן המתנה ממוצע = (10 + 0 + 7 + 3) / 4 = 20 / 4 = 5\nזמן מחזור ממוצע = (20 + 5 + 9 + 6) / 4 = 40 / 4 = 10\n\nג. **הרעבה (Starvation)** היא מצב שבו תהליך בעל קדימות נמוכה עשוי שלא לקבל זמן מעבד לעולם, או לקבל זמן מעבד לעיתים רחוקות מאוד, בגלל שתהליכים בעלי קדימות גבוהה יותר מגיעים באופן קבוע או רצים במשך זמן רב.\n\nבתרחיש הנתון, **תהליך P1 עלול לסבול מהרעבה**. קדימותו היא 3, שהיא הנמוכה ביותר. כפי שניתן לראות מדיאגרמת גאנט של Preemptive Priority, P1 רץ רק ליחידת זמן אחת בתחילה, ולאחר מכן נדחה לטובת P2, P4, ו-P3. הוא מסיים לרוץ רק לאחר שכל שאר התהליכים בעלי הקדימות הגבוהה יותר סיימו. אם תהליכים חדשים בעלי קדימות גבוהה יותר היו ממשיכים להגיע למערכת באופן קבוע, P1 היה נדחה שוב ושוב ולא היה מקבל הזדמנות לסיים את ריצתו.\n\n**פתרון** לבעיית ההרעבה הוא מנגנון ה**'הזדקנות' (Aging)**. מנגנון זה מגדיל בהדרגה את הקדימות של תהליכים שממתינים זמן רב בתור, כך שקדימותם עולה עם הזמן (כלומר, ערך הקדימות שלהם יורד, אם ערך נמוך מציין קדימות גבוהה). בסופו של דבר, קדימותם תהיה גבוהה מספיק כדי שיוכלו לקבל זמן מעבד ולבצע את עבודתם, ובכך למנוע מהם להישאר במצב הרעבה לנצח."}, "difficulty_estimation": "Medium", "_source_file": "0758__CPU_Scheduling__Open__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:05:53", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["CPU Scheduling", "Scheduling Algorithms", "Performance Metrics"], "content": {"text": "נתונים שלושה תהליכים P1, P2, P3 עם זמני הגעה (Arrival Time), זמני ריצה (Burst Time) ועדיפויות (Priority) כפי שמוצג בטבלה הבאה. יש להניח שמספר עדיפות נמוך יותר מציין עדיפות גבוהה יותר. עבור כל אחד מאלגוריתמי התזמון הבאים, חשבו את זמן ההמתנה הממוצע (Average Waiting Time) ואת זמן המחזור הממוצע (Average Turnaround Time). לאחר מכן, השוו ובחרו את האלגוריתם הטוב ביותר עבור סט תהליכים זה ונמקו את בחירתכם.\n\n| תהליך | זמן הגעה | זמן ריצה (Burst Time) | עדיפות (Priority) |\n|---|---|---|---|\n| P1 | 0 | 5 | 2 |\n| P2 | 1 | 3 | 1 |\n| P3 | 2 | 2 | 3 |", "code_snippet": null, "options": null}, "sub_questions": [{"id": "7.1", "text": "אלגוריתם FCFS (First Come First Served)", "code_snippet": null, "options": null}, {"id": "7.2", "text": "אלגוריתם תזמון עדיפויות עם דריסה (Preemptive Priority Scheduling)", "code_snippet": null, "options": null}, {"id": "7.3", "text": "אלגוריתם Round Robin עם קוונטום זמן של 2 יחידות (Quantum = 2)", "code_snippet": null, "options": null}, {"id": "7.4", "text": "איזה אלגוריתם ביצע את הביצועים הטובים ביותר עבור סט תהליכים זה ומדוע?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון מלא:\n\n**7.1. אלגוריתם FCFS (First Come First Served):**\n*   סדר הריצה נקבע לפי זמן ההגעה: P1, P2, P3.\n*   תרשים גאנט:\n    | P1 (5) | P2 (3) | P3 (2) |\n    | 0      5        8      10 |\n*   **P1:** זמן סיום = 5. זמן מחזור = 5 (5-0). זמן המתנה = 0 (0-0).\n*   **P2:** זמן סיום = 8. זמן מחזור = 7 (8-1). זמן המתנה = 4 (5-1).\n*   **P3:** זמן סיום = 10. זמן מחזור = 8 (10-2). זמן המתנה = 6 (8-2).\n*   **זמן מחזור ממוצע:** (5 + 7 + 8) / 3 = 20 / 3 = 6.67 יחידות זמן.\n*   **זמן המתנה ממוצע:** (0 + 4 + 6) / 3 = 10 / 3 = 3.33 יחידות זמן.\n\n**7.2. אלגוריתם תזמון עדיפויות עם דריסה (Preemptive Priority Scheduling):**\n*   עדיפויות: P2 (1) > P1 (2) > P3 (3).\n*   תרשים גאנט:\n    | P1 (1) | P2 (3) | P1 (4) | P3 (2) |\n    | 0      1        4        8      10 |\n*   **הסבר:**\n    *   **זמן 0:** P1 מגיע ומתחיל לרוץ (עדיפות 2).\n    *   **זמן 1:** P2 מגיע (עדיפות 1). P2 דורס את P1 ומתחיל לרוץ. P1 נשאר עם 4 יחידות ריצה.\n    *   **זמן 2:** P3 מגיע (עדיפות 3). P2 עדיין בעל העדיפות הגבוהה ביותר וממשיך לרוץ.\n    *   **זמן 4:** P2 מסיים את ריצתו. P1 (נותרו 4 יחידות) ו-P3 (נותרו 2 יחידות) ממתינים. P1 בעל עדיפות גבוהה יותר (2 מול 3) ומתחיל לרוץ.\n    *   **זמן 8:** P1 מסיים את ריצתו. P3 ממתין ומתחיל לרוץ.\n    *   **זמן 10:** P3 מסיים את ריצתו.\n*   **P1:** זמן סיום = 8. זמן מחזור = 8 (8-0). זמן המתנה = 3 (P1 רץ 0-1, ממתין 1-4, רץ 4-8. כלומר, המתנה בין 1 ל-4 = 3).\n*   **P2:** זמן סיום = 4. זמן מחזור = 3 (4-1). זמן המתנה = 0 (1-1).\n*   **P3:** זמן סיום = 10. זמן מחזור = 8 (10-2). זמן המתנה = 6 (8-2).\n*   **זמן מחזור ממוצע:** (8 + 3 + 8) / 3 = 19 / 3 = 6.33 יחידות זמן.\n*   **זמן המתנה ממוצע:** (3 + 0 + 6) / 3 = 9 / 3 = 3.00 יחידות זמן.\n\n**7.3. אלגוריתם Round Robin עם קוונטום זמן של 2 יחידות (Quantum = 2):**\n*   תרשים גאנט:\n    | P1 (2) | P2 (2) | P3 (2) | P1 (2) | P2 (1) | P1 (1) |\n    | 0      2        4        6        8        9      10 |\n*   **הסבר:**\n    *   **זמן 0-2:** P1 רץ (נותרו 3). P2 מגיע בזמן 1. P3 מגיע בזמן 2.\n    *   **תור בזמן 2:** [P2, P3, P1]\n    *   **זמן 2-4:** P2 רץ (נותרה 1). P3 מגיע בזמן 2.\n    *   **תור בזמן 4:** [P3, P1, P2]\n    *   **זמן 4-6:** P3 רץ (נותרו 0). P3 מסיים.\n    *   **תור בזמן 6:** [P1, P2]\n    *   **זמן 6-8:** P1 רץ (נותרה 1).\n    *   **תור בזמן 8:** [P2, P1]\n    *   **זמן 8-9:** P2 רץ (נותרו 0). P2 מסיים.\n    *   **תור בזמן 9:** [P1]\n    *   **זמן 9-10:** P1 רץ (נותרו 0). P1 מסיים.\n*   **P1:** זמן סיום = 10. זמן מחזור = 10 (10-0). זמן המתנה = 5 (רץ 0-2, ממתין 2-6, רץ 6-8, ממתין 8-9, רץ 9-10. המתנה = (6-2)+(9-8) = 4+1=5).\n*   **P2:** זמן סיום = 9. זמן מחזור = 8 (9-1). זמן המתנה = 5 (רץ 2-4, ממתין 4-8, רץ 8-9. המתנה = (2-1)+(8-4) = 1+4=5).\n*   **P3:** זמן סיום = 6. זמן מחזור = 4 (6-2). זמן המתנה = 2 (רץ 4-6. המתנה = (4-2)=2).\n*   **זמן מחזור ממוצע:** (10 + 8 + 4) / 3 = 22 / 3 = 7.33 יחידות זמן.\n*   **זמן המתנה ממוצע:** (5 + 5 + 2) / 3 = 12 / 3 = 4.00 יחידות זמן.\n\n**7.4. השוואת ביצועים:**\n*   **FCFS:** זמן מחזור ממוצע = 6.67, זמן המתנה ממוצע = 3.33\n*   **Preemptive Priority:** זמן מחזור ממוצע = 6.33, זמן המתנה ממוצע = 3.00\n*   **Round Robin (Q=2):** זמן מחזור ממוצע = 7.33, זמן המתנה ממוצע = 4.00\n\n**מסקנה ונימוק:**\nאלגוריתם **תזמון עדיפויות עם דריסה** השיג את הביצועים הטובים ביותר עבור סט תהליכים זה, עם זמן מחזור ממוצע וזמן המתנה ממוצע הנמוכים ביותר.\n\n**נימוק:**\nהסיבה לכך היא שתהליך P2, בעל העדיפות הגבוהה ביותר (1), קיבל גישה למעבד מיד עם הגעתו (בדריסה), מה שהפחית משמעותית את זמן ההמתנה וזמן המחזור שלו לאפס. למרות שתהליך P1 נדרס, הוא עדיין הושלם לפני P3 בעל העדיפות הנמוכה יותר, מה ששמר על זמני המתנה וזמני מחזור סבירים עבורו. התעדוף היעיל של תהליכים בעלי חשיבות גבוהה (או זמני ריצה קצרים יותר במקרה של SJF) הוא היתרון המרכזי כאן.\n\nאלגוריתם FCFS הציג ביצועים טובים יחסית אך פחות טובים מעדיפויות, בעיקר בגלל ש-P1, שהגיע ראשון, תפס את המעבד לכל זמן הריצה שלו (5 יחידות) בזמן ש-P2 בעל העדיפות הגבוהה יותר המתין, למרות ש-P2 היה תהליך קצר יותר.\n\nRound Robin הציג את הביצועים הגרועים ביותר עבור סט תהליכים זה, עם זמני מחזור והמתנה הגבוהים ביותר. הדבר נובע מהעלויות התקורה של החלפות ההקשר התכופות (context switches) והעובדה שהקוונטום (2 יחידות) לא תמיד התאים באופן אופטימלי לזמני הריצה של התהליכים, במיוחד עבור P1 הארוך יותר, שחולק למספר רב של מקטעי ריצה והמתנה."}, "difficulty_estimation": "Medium", "_source_file": "0759__CPU_Scheduling__Open__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:06:21", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["CPU Scheduling", "Scheduling Algorithms", "Performance Analysis"], "content": {"text": "נתונים ארבעה תהליכים (P1, P2, P3, P4) עם זמני הגעה, זמני ריצה (burst time) ורמות עדיפות, כפי שמוצג בטבלה הבאה. יש להניח שרמת עדיפות נמוכה יותר מצביעה על עדיפות גבוהה יותר (לדוגמה, עדיפות 1 גבוהה מעדיפות 2). בנוסף, כל תהליך דורש גישה למשאב משותף (למשל, קטע קריטי) למשך כל זמן הריצה שלו, ורק תהליך אחד יכול לגשת למשאב זה בכל רגע נתון.\n\n| תהליך | זמן הגעה | זמן ריצה | עדיפות |\n|--------|----------|----------|--------|\n| P1     | 0        | 8        | 3      |\n| P2     | 1        | 4        | 1      |\n| P3     | 2        | 9        | 4      |\n| P4     | 3        | 5        | 2      |\n\n1. חשבו את זמן ההמתנה הממוצע (Average Waiting Time) ואת זמן המחזור הממוצע (Average Turnaround Time) עבור התהליכים באמצעות אלגוריתם תזמון Priority Preemptive (עדיפות עם דריסה).\n2. חשבו את זמן ההמתנה הממוצע ואת זמן המחזור הממוצע עבור התהליכים באמצעות אלגוריתם תזמון Round Robin (RR) עם קוונטום זמן של 2 יחידות.\n3. בהתחשב בתוצאות שחישבתם, ובמגבלת המשאב המשותף, נתחו איזה אלגוריתם עשוי להיות עדיף במערכת עם תקורה גבוהה של החלפת הקשר (context switch overhead). נמקו את תשובתכם.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\n**1. אלגוריתם Priority Preemptive (עדיפות עם דריסה):**\n\n*   **זמן 0:** P1 מגיע (זמן ריצה=8, עדיפות=3). P1 מתחיל לרוץ.\n*   **זמן 1:** P2 מגיע (זמן ריצה=4, עדיפות=1). P2 בעל עדיפות גבוהה יותר מ-P1. P1 נדרס (רץ יחידת זמן אחת). P2 מתחיל לרוץ.\n*   **זמן 1-5:** P2 רץ את כל זמן הריצה שלו (4 יחידות). P2 מסיים בזמן 5.\n    *   P2: זמן מחזור = 5 - 1 = 4. זמן המתנה = 4 - 4 = 0.\n*   **זמן 2:** P3 מגיע (זמן ריצה=9, עדיפות=4).\n*   **זמן 3:** P4 מגיע (זמן ריצה=5, עדיפות=2).\n*   **זמן 5:** P2 מסיים. תהליכים מוכנים: P4 (עדיפות=2), P1 (עדיפות=3), P3 (עדיפות=4). P4 בעל העדיפות הגבוהה ביותר. P4 מתחיל לרוץ.\n*   **זמן 5-10:** P4 רץ את כל זמן הריצה שלו (5 יחידות). P4 מסיים בזמן 10.\n    *   P4: זמן מחזור = 10 - 3 = 7. זמן המתנה = 7 - 5 = 2.\n*   **זמן 10:** P4 מסיים. תהליכים מוכנים: P1 (עדיפות=3), P3 (עדיפות=4). P1 בעל העדיפות הגבוהה ביותר. P1 מתחיל לרוץ.\n*   **זמן 10-17:** P1 רץ את יתרת זמן הריצה שלו (7 יחידות, לאחר שרץ יחידה אחת בזמן 0-1). P1 מסיים בזמן 17.\n    *   P1: זמן מחזור = 17 - 0 = 17. זמן המתנה = 17 - 8 = 9.\n*   **זמן 17:** P1 מסיים. תהליכים מוכנים: P3 (עדיפות=4). P3 מתחיל לרוץ.\n*   **זמן 17-26:** P3 רץ את כל זמן הריצה שלו (9 יחידות). P3 מסיים בזמן 26.\n    *   P3: זמן מחזור = 26 - 2 = 24. זמן המתנה = 24 - 9 = 15.\n\n**סיכום Priority Preemptive:**\n*   P1: זמן המתנה = 9, זמן מחזור = 17\n*   P2: זמן המתנה = 0, זמן מחזור = 4\n*   P3: זמן המתנה = 15, זמן מחזור = 24\n*   P4: זמן המתנה = 2, זמן מחזור = 7\n\n**זמן המתנה ממוצע:** (9 + 0 + 15 + 2) / 4 = 26 / 4 = 6.5\n**זמן מחזור ממוצע:** (17 + 4 + 24 + 7) / 4 = 52 / 4 = 13\n\n**2. אלגוריתם Round Robin (RR) עם קוונטום זמן של 2 יחידות:**\n\n**תרשים גאנט:**\n0-2: P1 (נותר=6)\n2-4: P2 (נותר=2)\n4-6: P3 (נותר=7)\n6-8: P1 (נותר=4)\n8-10: P4 (נותר=3)\n10-12: P2 (נותר=0) -> P2 מסיים בזמן 12.\n    *   P2: זמן מחזור = 12 - 1 = 11. זמן המתנה = 11 - 4 = 7.\n12-14: P3 (נותר=5)\n14-16: P1 (נותר=2)\n16-18: P4 (נותר=1)\n18-20: P3 (נותר=3)\n20-22: P1 (נותר=0) -> P1 מסיים בזמן 22.\n    *   P1: זמן מחזור = 22 - 0 = 22. זמן המתנה = 22 - 8 = 14.\n22-23: P4 (נותר=0) -> P4 מסיים בזמן 23 (רץ יחידת זמן אחת).\n    *   P4: זמן מחזור = 23 - 3 = 20. זמן המתנה = 20 - 5 = 15.\n23-26: P3 (נותר=0) -> P3 מסיים בזמן 26 (רץ 3 יחידות זמן).\n    *   P3: זמן מחזור = 26 - 2 = 24. זמן המתנה = 24 - 9 = 15.\n\n**סיכום Round Robin:**\n*   P1: זמן המתנה = 14, זמן מחזור = 22\n*   P2: זמן המתנה = 7, זמן מחזור = 11\n*   P3: זמן המתנה = 15, זמן מחזור = 24\n*   P4: זמן המתנה = 15, זמן מחזור = 20\n\n**זמן המתנה ממוצע:** (14 + 7 + 15 + 15) / 4 = 51 / 4 = 12.75\n**זמן מחזור ממוצע:** (22 + 11 + 24 + 20) / 4 = 77 / 4 = 19.25\n\n**3. ניתוח והשוואה בהתחשב בתקורה של החלפת הקשר:**\n\nאלגוריתם Priority Preemptive הניב זמני המתנה ומחזור ממוצעים טובים יותר בדוגמה זו (6.5 ו-13 בהתאמה, לעומת 12.75 ו-19.25 ב-RR). במערכת עם תקורה גבוהה של החלפת הקשר (context switch overhead), אלגוריתם Priority Preemptive עשוי להיות עדיף.\n\nהסיבה לכך היא ש-Priority Preemptive מבצע החלפות הקשר רק כאשר מתקיים אחד משני תנאים עיקריים:\n1.  תהליך בעל עדיפות גבוהה יותר מגיע למערכת.\n2.  התהליך הנוכחי מסיים את ריצתו.\n\nלעומת זאת, Round Robin מבצע החלפת הקשר באופן מחזורי בתום כל קוונטום זמן, גם אם אין תהליך בעל עדיפות גבוהה יותר או תהליך אחר שדורש את המעבד. במקרה של קוונטום קטן (כמו 2 יחידות בדוגמה זו), מספר החלפות הקשר ב-Round Robin יהיה גבוה משמעותית. כל החלפת הקשר כרוכה בתקורה (זמן CPU מבוזבז על שמירת וטעינת הקשר של תהליכים), וכאשר התקורה גבוהה, מספר רב של החלפות קשר יגרום לבזבוז משאבי CPU משמעותי ויפגע בביצועים הכוללים של המערכת.\n\nלגבי מגבלת המשאב המשותף: באלגוריתם Priority Preemptive, קיימת סכנה למצב של היפוך עדיפויות (priority inversion) אם תהליך בעל עדיפות נמוכה מחזיק במשאב קריטי שתהליך בעל עדיפות גבוהה יותר ממתין לו, ולא קיימים מנגנונים מתאימים (כמו priority inheritance או priority ceiling protocol) לפתור זאת. במקרה כזה, היתרון בעדיפות נפגע. עם זאת, בהתייחס לשאלת תקורת החלפת הקשר בלבד, Priority Preemptive עדיין מבצע פחות החלפות קשר מבחינה תכנונית מאשר Round Robin עם קוונטום קטן, ולכן עשוי להיות עדיף במערכות רגישות לתקורה זו."}, "difficulty_estimation": "Medium", "_source_file": "0760__CPU_Scheduling__Open__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:06:52", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["CPU Scheduling", "Preemptive Priority", "Process Management"], "content": {"text": "נתונה מערכת הפעלה המשתמשת באלגוריתם תזמון מעבד מסוג Preemptive Priority (עדיפות נמוכה יותר = עדיפות גבוהה יותר) עם תקורה של החלפת הקשר (Context Switch) של 1ms. במקרה של שוויון עדיפויות, התהליך בעל מזהה נמוך יותר (PID) יקבל קדימות. להלן רשימת תהליכים עם זמני הגעה, עדיפויות ורצפי פעולות (CPU burst, I/O burst):\n\n*   P1: (זמן הגעה 0ms, עדיפות 3, רצף: CPU 5ms, I/O 3ms, CPU 3ms)\n*   P2: (זמן הגעה 2ms, עדיפות 1, רצף: CPU 4ms, I/O 2ms, CPU 2ms)\n*   P3: (זמן הגעה 4ms, עדיפות 2, רצף: CPU 6ms)\n*   P4: (זמן הגעה 6ms, עדיפות 4, רצף: CPU 2ms, I/O 1ms, CPU 1ms)\n\nיש להניח כי תהליך שסיים פעולת I/O חוזר לתור המוכנים (Ready Queue) עם אותה עדיפות מקורית. נדרש לחשב ולפרט את כל השלבים והחישובים:\n\n1.  זמן ההמתנה הממוצע (Average Waiting Time) של התהליכים.\n2.  זמן המחזור הממוצע (Average Turnaround Time) של התהליכים.\n3.  ניצולת המעבד (CPU Utilization) הכוללת.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "נבצע סימולציה מפורטת של תזמון המעבד:\n\n**נתונים:**\n*   P1: הגעה 0, עדיפות 3, CPU [5], I/O [3], CPU [3]\n*   P2: הגעה 2, עדיפות 1, CPU [4], I/O [2], CPU [2]\n*   P3: הגעה 4, עדיפות 2, CPU [6]\n*   P4: הגעה 6, עדיפות 4, CPU [2], I/O [1], CPU [1]\n*   תקורה החלפת קשר (CS): 1ms\n*   עדיפות נמוכה יותר = גבוהה יותר (1=הכי גבוה).\n*   שוויון עדיפויות: PID נמוך יותר קודם.\n\n**מעקב אחר מצב המערכת (גאנט צ'ארט מפורט):**\n\n*   **זמן 0:** P1 מגיע. P1 מתחיל לרוץ.\n    *   CPU: P1 (5ms) (נותר: 5)\n*   **זמן 2:** P2 מגיע (עדיפות 1). P2 גבוה יותר מ-P1 (עדיפות 3).\n    *   P1 נקטע (רץ 2ms). P1 נותר: 3ms.\n    *   CS (P1 -> P2): 1ms.\n*   **זמן 3:** P2 מתחיל לרוץ.\n    *   CPU: P2 (4ms) (נותר: 4)\n*   **זמן 4:** P3 מגיע (עדיפות 2). P2 ממשיך לרוץ (עדיפות 1).\n*   **זמן 6:** P4 מגיע (עדיפות 4). P2 ממשיך לרוץ (עדיפות 1).\n*   **זמן 7:** P2 מסיים CPU burst ראשון (4ms). P2 עובר ל-I/O (2ms). יסיים I/O ב-7+2=9ms. P2 נותר CPU: 2ms.\n    *   CS (P2 -> P3): 1ms (P3 בעדיפות הגבוהה ביותר בתור המוכנים).\n*   **זמן 8:** P3 מתחיל לרוץ.\n    *   CPU: P3 (6ms) (נותר: 6)\n*   **זמן 9:** P2 מסיים I/O וחוזר לתור המוכנים (עדיפות 1). P2 גבוה מ-P3 (עדיפות 2).\n    *   P3 נקטע (רץ 1ms). P3 נותר: 5ms.\n    *   CS (P3 -> P2): 1ms.\n*   **זמן 10:** P2 מתחיל לרוץ (CPU burst שני).\n    *   CPU: P2 (2ms) (נותר: 2)\n*   **זמן 12:** P2 מסיים CPU burst שני. P2 מסיים.\n    *   CS (P2 -> P3): 1ms (P3 בעדיפות הגבוהה ביותר בתור המוכנים).\n*   **זמן 13:** P3 ממשיך לרוץ.\n    *   CPU: P3 (5ms) (נותר: 5)\n*   **זמן 18:** P3 מסיים CPU burst. P3 מסיים.\n    *   CS (P3 -> P1): 1ms (P1 בעדיפות הגבוהה ביותר בתור המוכנים, P=3. P4 הוא P=4).\n*   **זמן 19:** P1 ממשיך לרוץ (CPU burst ראשון).\n    *   CPU: P1 (3ms) (נותר: 3)\n*   **זמן 22:** P1 מסיים CPU burst ראשון (סה\"כ 5ms). P1 עובר ל-I/O (3ms). יסיים I/O ב-22+3=25ms. P1 נותר CPU: 3ms.\n    *   CS (P1 -> P4): 1ms (P4 בעדיפות הגבוהה ביותר בתור המוכנים).\n*   **זמן 23:** P4 מתחיל לרוץ (CPU burst ראשון).\n    *   CPU: P4 (2ms) (נותר: 2)\n*   **זמן 25:** P1 מסיים I/O וחוזר לתור המוכנים (עדיפות 3). P1 גבוה מ-P4 (עדיפות 4).\n    *   P4 נקטע (רץ 2ms). P4 עובר ל-I/O (1ms). יסיים I/O ב-25+1=26ms. P4 נותר CPU: 1ms.\n    *   CS (P4 -> P1): 1ms.\n*   **זמן 26:** P1 מתחיל לרוץ (CPU burst שני).\n    *   CPU: P1 (3ms) (נותר: 3)\n*   **זמן 27:** P4 מסיים I/O וחוזר לתור המוכנים (עדיפות 4). P1 ממשיך לרוץ (עדיפות 3).\n*   **זמן 29:** P1 מסיים CPU burst שני. P1 מסיים.\n    *   CS (P1 -> P4): 1ms.\n*   **זמן 30:** P4 מתחיל לרוץ (CPU burst שני).\n    *   CPU: P4 (1ms) (נותר: 1)\n*   **זמן 31:** P4 מסיים CPU burst שני. P4 מסיים.\n\n**חישוב מדדים:**\n\n**P1:**\n*   זמן הגעה (AT): 0\n*   זמן סיום (CT): 29\n*   זמן CPU כולל: 5 + 3 = 8ms\n*   זמן המתנה (WT) = (2-2) + (19-2) + (25-26) = 0 + 17 + 1 = 18ms\n*   זמן מחזור (TAT) = CT - AT = 29 - 0 = 29ms\n\n**P2:**\n*   זמן הגעה (AT): 2\n*   זמן סיום (CT): 12\n*   זמן CPU כולל: 4 + 2 = 6ms\n*   זמן המתנה (WT) = (3-2) + (10-9) = 1 + 1 = 2ms\n*   זמן מחזור (TAT) = CT - AT = 12 - 2 = 10ms\n\n**P3:**\n*   זמן הגעה (AT): 4\n*   זמן סיום (CT): 18\n*   זמן CPU כולל: 1 + 5 = 6ms\n*   זמן המתנה (WT) = (8-4) + (13-9) = 4 + 4 = 8ms\n*   זמן מחזור (TAT) = CT - AT = 18 - 4 = 14ms\n\n**P4:**\n*   זמן הגעה (AT): 6\n*   זמן סיום (CT): 31\n*   זמן CPU כולל: 2 + 1 = 3ms\n*   זמן המתנה (WT) = (23-6) + (30-26) = 17 + 4 = 21ms\n*   זמן מחזור (TAT) = CT - AT = 31 - 6 = 25ms\n\n**סיכום מדדים:**\n\n1.  **זמן ההמתנה הממוצע (Average Waiting Time):**\n    (18 + 2 + 8 + 21) / 4 = 49 / 4 = **12.25ms**\n\n2.  **זמן המחזור הממוצע (Average Turnaround Time):**\n    (29 + 10 + 14 + 25) / 4 = 78 / 4 = **19.5ms**\n\n3.  **ניצולת המעבד (CPU Utilization):**\n    *   זמן ריצת CPU כולל (ללא CS): 8 (P1) + 6 (P2) + 6 (P3) + 3 (P4) = 23ms\n    *   זמן החלפות קשר (CS) כולל: 8 החלפות * 1ms/החלפה = 8ms\n    *   זמן סיום סימולציה כולל: 31ms\n    *   זמן סרק (Idle Time): 0ms (המעבד היה תמיד עסוק בתהליך או ב-CS מרגע הגעת התהליך הראשון ועד סיום האחרון).\n    *   ניצולת מעבד = (זמן ריצת CPU כולל) / (זמן סיום סימולציה כולל) = 23 / 31 = **74.19%**"}, "difficulty_estimation": "Hard", "_source_file": "0761__CPU_Scheduling__Open__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:07:45", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["CPU Scheduling", "Multi-level Feedback Queue", "Process Management"], "content": {"text": "נתונה מערכת הפעלה המשתמשת באלגוריתם תזמון מורכב הכולל שתי תורים:\n1.  **תור עדיפות גבוהה (HP - High Priority)**: ממומש כ-Round Robin עם קוונטום זמן של 5ms. תהליכים חדשים נכנסים לתור זה. תהליכים שתם זמנם בתור זה (השתמשו בכל הקוונטום שלהם) ועוד לא סיימו את פעולת ה-CPU הנוכחית, עוברים לתור LP.\n2.  **תור עדיפות נמוכה (LP - Low Priority)**: ממומש כ-FCFS. תהליכים בתור זה ירוצו רק כאשר תור HP ריק.\n3.  **טיפול ב-I/O**: כאשר תהליך מבצע פעולת I/O, הוא עוזב את תור התזמון. בסיום פעולת ה-I/O, התהליך חוזר לתור HP.\n4.  **זמן החלפת קשר (Context Switch)**: 1ms.\n5.  **הנחות**:\n    *   אם מספר תהליכים מגיעים בו-זמנית או חוזרים מ-I/O בו-זמנית, הסדר ביניהם הוא לפי ה-PID הנמוך ביותר.\n    *   הזמן הנדרש ל-I/O אינו נכלל בקוונטום ה-CPU ואינו מושפע מזמן החלפת קשר.\n    *   חישובי ה-CPU burst הם נטו, ללא זמן החלפת קשר.\n    *   התהליכים מוכנים לריצה מיד עם הגעתם (arrival time).\n\nנתונים שלושה תהליכים:\n\n| תהליך (PID) | זמן הגעה (Arrival Time) | רצף פעולות (CPU/IO Bursts) |\n| :---------- | :--------------------- | :------------------------- |\n| P1          | 0ms                    | CPU(10ms), I/O(20ms), CPU(5ms) |\n| P2          | 2ms                    | CPU(8ms), I/O(10ms), CPU(2ms) |\n| P3          | 3ms                    | CPU(6ms)                  |\n\nחשב את זמן הסיום (Completion Time) וזמן ההמתנה (Waiting Time) עבור כל אחד מהתהליכים. הצג את מהלך התזמון באופן מפורט.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "נבצע סימולציה מפורטת של מהלך התזמון:\n\n**מצב התחלתי:**\nזמן = 0ms\nתור HP: ריק\nתור LP: ריק\nתהליכי I/O: ריק\nתהליך רץ: אף אחד\n\n**שלבי הסימולציה:**\n\n*   **זמן 0ms:**\n    *   P1 מגיע (זמן הגעה 0ms) ונכנס לתור HP. \n    *   P1 מתחיל לרוץ.\n    *   P1 CPU Burst 1 נשאר: 10ms.\n\n*   **זמן 2ms:**\n    *   P2 מגיע (זמן הגעה 2ms) ונכנס לתור HP. \n    *   HP: [P2]\n    *   P2 CPU Burst 1 נשאר: 8ms.\n\n*   **זמן 3ms:**\n    *   P3 מגיע (זמן הגעה 3ms) ונכנס לתור HP. \n    *   HP: [P2, P3]\n    *   P3 CPU Burst 1 נשאר: 6ms.\n\n*   **זמן 5ms:**\n    *   הקוונטום של P1 מסתיים (רץ 5ms).\n    *   P1 CPU Burst 1 נשאר: 5ms.\n    *   P1 עובר לתור LP (כי לא סיים את ה-CPU Burst).\n    *   HP: [P2, P3]\n    *   LP: [P1]\n    *   החלפת קשר (Context Switch) של 1ms.\n    *   זמן נוכחי: 5ms + 1ms = 6ms.\n\n*   **זמן 6ms:**\n    *   P2 (מה-HP) מתחיל לרוץ.\n\n*   **זמן 11ms:**\n    *   הקוונטום של P2 מסתיים (רץ 5ms).\n    *   P2 CPU Burst 1 נשאר: 3ms.\n    *   P2 עובר לתור LP.\n    *   HP: [P3]\n    *   LP: [P1, P2]\n    *   החלפת קשר של 1ms.\n    *   זמן נוכחי: 11ms + 1ms = 12ms.\n\n*   **זמן 12ms:**\n    *   P3 (מה-HP) מתחיל לרוץ.\n\n*   **זמן 17ms:**\n    *   הקוונטום של P3 מסתיים (רץ 5ms).\n    *   P3 CPU Burst 1 נשאר: 1ms.\n    *   P3 עובר לתור LP.\n    *   HP: []\n    *   LP: [P1, P2, P3]\n    *   החלפת קשר של 1ms.\n    *   זמן נוכחי: 17ms + 1ms = 18ms.\n\n*   **זמן 18ms:**\n    *   תור HP ריק. P1 (מה-LP, FCFS) מתחיל לרוץ. P1 CPU Burst 1 נשאר: 5ms.\n\n*   **זמן 23ms:**\n    *   P1 מסיים את ה-CPU Burst הראשון (רץ 5ms). \n    *   P1 מתחיל פעולת I/O (20ms). P1 עוזב את תורי התזמון.\n    *   P1 יחזור מ-I/O בזמן 23ms + 20ms = 43ms.\n    *   החלפת קשר של 1ms.\n    *   זמן נוכחי: 23ms + 1ms = 24ms.\n\n*   **זמן 24ms:**\n    *   תור HP ריק. P2 (מה-LP, FCFS) מתחיל לרוץ. P2 CPU Burst 1 נשאר: 3ms.\n\n*   **זמן 27ms:**\n    *   P2 מסיים את ה-CPU Burst הראשון (רץ 3ms).\n    *   P2 מתחיל פעולת I/O (10ms). P2 עוזב את תורי התזמון.\n    *   P2 יחזור מ-I/O בזמן 27ms + 10ms = 37ms.\n    *   החלפת קשר של 1ms.\n    *   זמן נוכחי: 27ms + 1ms = 28ms.\n\n*   **זמן 28ms:**\n    *   תור HP ריק. P3 (מה-LP, FCFS) מתחיל לרוץ. P3 CPU Burst 1 נשאר: 1ms.\n\n*   **זמן 29ms:**\n    *   P3 מסיים את ה-CPU Burst הראשון (רץ 1ms). P3 מסיים את כל פעולות ה-CPU שלו.\n    *   **P3 סיום (Completion Time): 29ms.**\n    *   החלפת קשר של 1ms.\n    *   זמן נוכחי: 29ms + 1ms = 30ms.\n\n*   **זמן 30ms - 37ms:**\n    *   ה-CPU אינו פעיל (Idle). אין תהליכים בתורים.\n\n*   **זמן 37ms:**\n    *   P2 מסיים פעולת I/O וחוזר לתור HP. \n    *   P2 מתחיל לרוץ (ה-CPU היה פנוי).\n    *   P2 CPU Burst 2 נשאר: 2ms.\n\n*   **זמן 39ms:**\n    *   P2 מסיים את ה-CPU Burst השני (רץ 2ms). P2 מסיים את כל פעולות ה-CPU שלו.\n    *   **P2 סיום (Completion Time): 39ms.**\n    *   החלפת קשר של 1ms.\n    *   זמן נוכחי: 39ms + 1ms = 40ms.\n\n*   **זמן 40ms - 43ms:**\n    *   ה-CPU אינו פעיל (Idle). אין תהליכים בתורים.\n\n*   **זמן 43ms:**\n    *   P1 מסיים פעולת I/O וחוזר לתור HP. \n    *   P1 מתחיל לרוץ (ה-CPU היה פנוי).\n    *   P1 CPU Burst 2 נשאר: 5ms.\n\n*   **זמן 48ms:**\n    *   P1 מסיים את ה-CPU Burst השני (רץ 5ms). P1 מסיים את כל פעולות ה-CPU שלו.\n    *   **P1 סיום (Completion Time): 48ms.**\n\n\n**חישוב זמני המתנה (Waiting Time):**\nזמן המתנה = זמן סיום - זמן הגעה - סך כל זמן CPU Burst - סך כל זמן I/O.\n\n*   **P1:**\n    *   זמן סיום: 48ms\n    *   זמן הגעה: 0ms\n    *   סך כל זמן CPU Burst: 10ms + 5ms = 15ms\n    *   סך כל זמן I/O: 20ms\n    *   **זמן המתנה ל-P1 = 48 - 0 - 15 - 20 = 13ms.**\n\n*   **P2:**\n    *   זמן סיום: 39ms\n    *   זמן הגעה: 2ms\n    *   סך כל זמן CPU Burst: 8ms + 2ms = 10ms\n    *   סך כל זמן I/O: 10ms\n    *   **זמן המתנה ל-P2 = 39 - 2 - 10 - 10 = 17ms.**\n\n*   **P3:**\n    *   זמן סיום: 29ms\n    *   זמן הגעה: 3ms\n    *   סך כל זמן CPU Burst: 6ms\n    *   סך כל זמן I/O: 0ms\n    *   **זמן המתנה ל-P3 = 29 - 3 - 6 - 0 = 20ms.**", "difficulty_estimation": "Hard"}, "_source_file": "0762__CPU_Scheduling__Open__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:08:22", "_subject": "Virtualization"}, {"id": 101, "type": "Open", "topic": ["CPU Scheduling", "Priority Scheduling", "Round Robin", "Context Switching", "I/O"], "content": {"text": "נתונה מערכת הפעלה המשתמשת במתזמן CPU היברידי עם עדיפויות ו-Round Robin (PPRR). המתזמן פועל על פי הכללים הבאים:\n1.  **עדיפויות**: לכל תהליך יש עדיפות סטטית (מספר נמוך יותר מציין עדיפות גבוהה יותר). תהליכים בעלי עדיפות זהה יטופלו לפי סדר הגעה (FCFS) בתוך תור ה-Round Robin.\n2.  **קדימה (Preemption)**: תהליך בעל עדיפות גבוהה יותר שמגיע למערכת או הופך למוכן (לאחר סיום I/O) יקבל את המעבד מיד ויקדים תהליך בעל עדיפות נמוכה יותר שרץ כרגע.\n3.  **בתוך אותה עדיפות**: תהליכים בעלי אותה עדיפות יטופלו באמצעות אלגוריתם Round Robin עם קואנטום זמן קבוע.\n4.  **טיפול ב-I/O**: כאשר תהליך מתחיל פעולת I/O, הוא מפנה את המעבד. כאשר פעולת I/O מסתיימת, התהליך הופך למוכן וממוקם בתור ההרצה בהתאם לעדיפותו. אם עדיפותו גבוהה יותר מהתהליך הרץ, הוא מקדים אותו.\n5.  **זמן החלפת הקשר (Context Switch)**: לכל החלפת קשר נדרשת יחידת זמן אחת (1ms). זמן זה נחשב כזמן שהמעבד עסוק בפעולת מערכת ואינו נכלל בזמן הריצה של התהליכים, אך נכלל בזמן ההמתנה הכולל של התהליכים הממתינים ל-CPU.\n\nנתונים התהליכים הבאים:\n\n| תהליך | זמן הגעה | עדיפות | פרץ CPU ראשון | פרץ I/O | פרץ CPU שני |\n| :---- | :-------- | :----- | :------------ | :-------- | :------------ |\n| P1    | 0ms       | 2      | 5ms           | 10ms      | 3ms           |\n| P2    | 1ms       | 1      | 6ms           | (אין)    | (אין)        |\n| P3    | 2ms       | 2      | 4ms           | 8ms       | 2ms           |\n\nקואנטום הזמן (Quantum) עבור Round Robin הוא 2ms.\n\nחשבו את זמן ההמתנה הממוצע (Average Waiting Time) ואת זמן המחזור הממוצע (Average Turnaround Time) עבור כל התהליכים. הציגו את כל שלבי החישוב והסבירו את התפתחות התזמון לאורך ציר הזמן.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "נבצע סימולציה מפורטת של התזמון לאורך ציר הזמן:\n\n**נתונים:**\n*   קואנטום (Q) = 2ms\n*   זמן החלפת קשר (CS) = 1ms\n\n**תהליכים:**\n*   P1: הגעה=0, עדיפות=2, CPU1=5ms, I/O=10ms, CPU2=3ms (סה\"כ CPU=8ms)\n*   P2: הגעה=1, עדיפות=1, CPU1=6ms (סה\"כ CPU=6ms)\n*   P3: הגעה=2, עדיפות=2, CPU1=4ms, I/O=8ms, CPU2=2ms (סה\"כ CPU=6ms)\n\n**ציר זמן (Gantt Chart Simulation):**\n\n*   **זמן 0:**\n    *   P1 מגיע. תור מוכנים: [P1(2,5)].\n    *   P1 מתחיל לרוץ.\n    *   **0-1:** P1 רץ (נותר CPU=4ms).\n\n*   **זמן 1:**\n    *   P2 מגיע. עדיפות P2 (1) גבוהה יותר מ-P1 (2). P2 מקדים את P1.\n    *   **1-2:** החלפת קשר (CS) מ-P1 ל-P2. (P1 נכנס לתור המוכנים).\n\n*   **זמן 2:**\n    *   P3 מגיע. עדיפות P3 (2) נמוכה מ-P2 (1). P2 ממשיך לרוץ.\n    *   **2-4:** P2 רץ (Q=2ms). (נותר CPU=4ms). הקואנטום של P2 הסתיים, אך אין תהליכים בעדיפות גבוהה יותר והוא התהליך היחיד בעדיפות 1, לכן ממשיך לרוץ ללא החלפת קשר.\n    *   **4-6:** P2 רץ (Q=2ms). (נותר CPU=2ms).\n    *   **6-8:** P2 רץ (Q=2ms). (נותר CPU=0ms). P2 מסיים ריצת CPU.\n    *   **8-9:** החלפת קשר (CS) מ-P2 לתהליך הבא. תור מוכנים: [P1(2,4), P3(2,4)]. P1 ו-P3 בעלי אותה עדיפות, P1 הגיע ראשון לתור המוכנים (בזמן 1). P1 ירוץ.\n\n*   **זמן 9:**\n    *   P1 מתחיל לרוץ.\n    *   **9-11:** P1 רץ (Q=2ms). (נותר CPU=2ms). הקואנטום של P1 הסתיים.\n    *   **11-12:** החלפת קשר (CS) מ-P1 ל-P3. (P1 חוזר לסוף תור המוכנים של עדיפות 2).\n\n*   **זמן 12:**\n    *   P3 מתחיל לרוץ.\n    *   **12-14:** P3 רץ (Q=2ms). (נותר CPU=2ms). הקואנטום של P3 הסתיים.\n    *   **14-15:** החלפת קשר (CS) מ-P3 ל-P1. (P3 חוזר לסוף תור המוכנים של עדיפות 2).\n\n*   **זמן 15:**\n    *   P1 מתחיל לרוץ.\n    *   **15-17:** P1 רץ (Q=2ms). (נותר CPU=0ms לפרץ הראשון). P1 מסיים את פרץ ה-CPU הראשון ועובר ל-I/O.\n    *   P1 יסיים I/O בזמן 17 + 10 = 27.\n    *   **17-18:** החלפת קשר (CS) מ-P1 ל-P3. (P3 הוא התהליך היחיד בתור המוכנים כרגע).\n\n*   **זמן 18:**\n    *   P3 מתחיל לרוץ.\n    *   **18-20:** P3 רץ (Q=2ms). (נותר CPU=0ms לפרץ הראשון). P3 מסיים את פרץ ה-CPU הראשון ועובר ל-I/O.\n    *   P3 יסיים I/O בזמן 20 + 8 = 28.\n\n*   **זמן 20-27:**\n    *   CPU פנוי (Idle). אין תהליכים מוכנים.\n\n*   **זמן 27:**\n    *   P1 מסיים I/O והופך למוכן (נותר CPU=3ms).\n    *   **27-28:** החלפת קשר (CS) מ-Idle ל-P1.\n\n*   **זמן 28:**\n    *   P1 מתחיל לרוץ.\n    *   P3 מסיים I/O והופך למוכן (נותר CPU=2ms). עדיפות P3 (2) שווה לעדיפות P1 (2). P1 רץ, P3 נכנס לתור המוכנים אחרי P1.\n    *   **28-30:** P1 רץ (Q=2ms). (נותר CPU=1ms). הקואנטום של P1 הסתיים, אך הוא עדיין התהליך היחיד בעדיפות 2 שהגיע בזמן 27, לכן ממשיך לרוץ ללא החלפת קשר.\n    *   **30-31:** P1 רץ (נותר CPU=0ms). P1 מסיים את כל פרצי ה-CPU שלו. P1 מסתיים.\n    *   **31-32:** החלפת קשר (CS) מ-P1 ל-P3. (P3 הוא התהליך היחיד המוכן).\n\n*   **זמן 32:**\n    *   P3 מתחיל לרוץ.\n    *   **32-34:** P3 רץ (Q=2ms). (נותר CPU=0ms). P3 מסיים את כל פרצי ה-CPU שלו. P3 מסתיים.\n\n**סיכום זמנים:**\n\n| תהליך | זמן הגעה | זמן CPU כולל | זמן I/O כולל | זמן סיום | זמן מחזור (Turnaround Time) | זמן המתנה (Waiting Time) |\n| :---- | :-------- | :----------- | :----------- | :------- | :-------------------------- | :----------------------- |\n| P1    | 0         | 8            | 10           | 31       | 31 - 0 = 31                 | 31 - 8 - 10 = 13         |\n| P2    | 1         | 6            | 0            | 8        | 8 - 1 = 7                   | 7 - 6 = 1                |\n| P3    | 2         | 6            | 8            | 34       | 34 - 2 = 32                 | 32 - 6 - 8 = 18          |\n\n**חישוב זמני המתנה (אימות מפורט):**\n*   **P1:**\n    *   המתנה בזמן CS (P1->P2): 1ms (1-2)\n    *   המתנה בזמן ריצת P2: 6ms (2-8)\n    *   המתנה בזמן CS (P2->P1): 1ms (8-9)\n    *   המתנה בזמן CS (P1->P3): 1ms (11-12)\n    *   המתנה בזמן ריצת P3: 2ms (12-14)\n    *   המתנה בזמן CS (P3->P1): 1ms (14-15)\n    *   המתנה בזמן CS (Idle->P1): 1ms (27-28)\n    *   סה\"כ המתנה P1 = 1+6+1+1+2+1+1 = 13ms. (תואם לחישוב בטבלה)\n\n*   **P2:**\n    *   המתנה בזמן CS (P1->P2): 1ms (1-2)\n    *   סה\"כ המתנה P2 = 1ms. (תואם לחישוב בטבלה)\n\n*   **P3:**\n    *   המתנה בזמן ריצת P2: 6ms (2-8)\n    *   המתנה בזמן CS (P2->P1): 1ms (8-9)\n    *   המתנה בזמן ריצת P1: 2ms (9-11)\n    *   המתנה בזמן CS (P1->P3): 1ms (11-12)\n    *   המתנה בזמן CS (P3->P1): 1ms (14-15)\n    *   המתנה בזמן ריצת P1: 2ms (15-17)\n    *   המתנה בזמן CS (P1->P3): 1ms (17-18)\n    *   המתנה בזמן ריצת P1 (אחרי I/O): 3ms (28-31)\n    *   המתנה בזמן CS (P1->P3): 1ms (31-32)\n    *   סה\"כ המתנה P3 = 6+1+2+1+1+2+1+3+1 = 18ms. (תואם לחישוב בטבלה)\n\n**חישוב ממוצעים:**\n*   **זמן המתנה ממוצע (Average Waiting Time):**\n    *   (13 + 1 + 18) / 3 = 32 / 3 = 10.67ms\n\n*   **זמן מחזור ממוצע (Average Turnaround Time):**\n    *   (31 + 7 + 32) / 3 = 70 / 3 = 23.33ms", "difficulty_estimation": "Hard"}, "_source_file": "0763__CPU_Scheduling__Open__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:09:10", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["CPU Scheduling", "Scheduling Algorithms", "Round Robin", "Priority Scheduling"], "content": {"text": "נתונה מערכת הפעלה המשתמשת במתזמן מעבדים היברידי בעל שתי רמות עדיפות, המשלב עדיפות דינמית עם Round Robin. המתזמן פועל לפי הכללים הבאים:\n1. קיימים שני תורים: תור עדיפות גבוהה (High-Priority Queue - HPQ) ותור עדיפות נמוכה (Low-Priority Queue - LPQ).\n2. תהליכים חדשים מגיעים תחילה ל-LPQ.\n3. תהליכים ב-HPQ מקבלים קוואנטום זמן של `Q_HP = 2ms` ומופעלים במנגנון Round Robin.\n4. תהליכים ב-LPQ מקבלים קוואנטום זמן של `Q_LP = 4ms` ומופעלים במנגנון Round Robin, אך רק כאשר ה-HPQ ריק.\n5. תהליך שסיים פעולת קלט/פלט (I/O) עובר אוטומטית ל-HPQ.\n6. אם תהליך ב-LPQ רץ והגיע תהליך חדש ל-HPQ (או תהליך עבר ל-HPQ), התהליך הרץ מה-LPQ נדחק (preempted) מיד ועובר לסוף ה-LPQ.\n7. זמן החלפת קשר (Context Switch Time) הוא `1ms` בכל פעם שהמעבד עובר מתהליך אחד לאחר (כולל בין תהליכים באותו תור או בין תורים).\n8. פעולות I/O אינן דורשות מהמעבד, ומתבצעות במקביל לעבודת המעבד אם יש תהליכים אחרים זמינים. תהליך שמבצע I/O אינו נמצא בתור ה-Ready ואינו יכול לרוץ על המעבד עד לסיום ה-I/O.\n\nנתונים התהליכים הבאים:\n*   **P1**: זמן הגעה `0ms`. רצף פעולות: `CPU (5ms) -> I/O (3ms) -> CPU (3ms)`\n*   **P2**: זמן הגעה `1ms`. רצף פעולות: `CPU (4ms) -> I/O (2ms) -> CPU (2ms)`\n*   **P3**: זמן הגעה `2ms`. רצף פעולות: `CPU (6ms) -> I/O (4ms) -> CPU (1ms)`\n\nיש לשרטט את גאנט צ'ארט (Gantt Chart) המלא של ביצוע התהליכים, ולחשב עבור כל תהליך את זמן ההמתנה (Waiting Time) ואת זמן המחזור (Turnaround Time). יש להציג את כל החישובים וההנחות בפירוט.", "code_snippet": null, "options": null}, "sub_questions": null, "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "נתונים:\n*   זמן החלפת קשר (CS) = 1ms\n*   קוואנטום לתור עדיפות גבוהה (Q_HP) = 2ms\n*   קוואנטום לתור עדיפות נמוכה (Q_LP) = 4ms\n\nמעקב צעד אחר צעד:\n*   **t=0**: P1 מגיע. LPQ = [P1]. HPQ = [].\n*   **t=0-1**: CPU מבצע החלפת קשר (CS) ל-P1.\n*   **t=1**: P1 מתחיל לרוץ (P1 פרץ CPU ראשון: 5ms). זמן ריצה עד כה: 0ms.\n*   **t=1**: P2 מגיע. LPQ = [P1, P2].\n*   **t=2**: P3 מגיע. LPQ = [P1, P2, P3].\n*   **t=5**: P1 השלים 4ms (קוואנטום LPQ). נשאר ל-P1 (CPU:1ms). P1 עובר לסוף LPQ. LPQ = [P2, P3, P1].\n*   **t=5-6**: CPU מבצע החלפת קשר (CS).\n*   **t=6-7**: CPU מבצע החלפת קשר (CS) ל-P2.\n*   **t=7**: P2 מתחיל לרוץ (P2 פרץ CPU ראשון: 4ms). זמן ריצה עד כה: 0ms.\n*   **t=11**: P2 השלים 4ms (קוואנטום LPQ). נשאר ל-P2 (CPU:0ms). P2 מסיים פרץ CPU ראשון ומתחיל I/O (2ms). P2 יסיים I/O ב-t=11+2=13ms.\n*   **t=11-12**: CPU מבצע החלפת קשר (CS).\n*   **t=12-13**: CPU מבצע החלפת קשר (CS) ל-P3.\n*   **t=13**: P3 מתחיל לרוץ (P3 פרץ CPU ראשון: 6ms). זמן ריצה עד כה: 0ms.\n*   **t=13**: P2 מסיים I/O. P2 עובר ל-HPQ. HPQ = [P2].\n*   **t=13**: P3 (מתור LPQ) נדחק ע\"י P2 (מתור HPQ). נשאר ל-P3 (CPU:6ms). P3 עובר לסוף LPQ. LPQ = [P1, P3].\n*   **t=13-14**: CPU מבצע החלפת קשר (CS).\n*   **t=14-15**: CPU מבצע החלפת קשר (CS) ל-P2.\n*   **t=15**: P2 מתחיל לרוץ (P2 פרץ CPU שני: 2ms). זמן ריצה עד כה: 0ms.\n*   **t=17**: P2 השלים 2ms (קוואנטום HPQ). נשאר ל-P2 (CPU:0ms). P2 מסיים את כל פרצי ה-CPU שלו. P2 מסתיים. זמן סיום P2 = 17ms.\n*   **t=17-18**: CPU מבצע החלפת קשר (CS).\n*   **t=18-19**: CPU מבצע החלפת קשר (CS) ל-P1.\n*   **t=19**: P1 מתחיל לרוץ (P1 פרץ CPU ראשון: 1ms נותר). זמן ריצה עד כה: 0ms.\n*   **t=20**: P1 השלים 1ms. נשאר ל-P1 (CPU:0ms). P1 מסיים פרץ CPU ראשון ומתחיל I/O (3ms). P1 יסיים I/O ב-t=20+3=23ms.\n*   **t=20-21**: CPU מבצע החלפת קשר (CS).\n*   **t=21-22**: CPU מבצע החלפת קשר (CS) ל-P3.\n*   **t=22**: P3 מתחיל לרוץ (P3 פרץ CPU ראשון: 6ms נותר). זמן ריצה עד כה: 0ms.\n*   **t=26**: P3 השלים 4ms (קוואנטום LPQ). נשאר ל-P3 (CPU:2ms). P3 עובר לסוף LPQ. LPQ = [P3].\n*   **t=26-27**: CPU מבצע החלפת קשר (CS).\n*   **t=27-28**: CPU מבצע החלפת קשר (CS) ל-P3.\n*   **t=28**: P3 מתחיל לרוץ (P3 פרץ CPU ראשון: 2ms נותר). זמן ריצה עד כה: 0ms.\n*   **t=30**: P3 השלים 2ms. נשאר ל-P3 (CPU:0ms). P3 מסיים פרץ CPU ראשון ומתחיל I/O (4ms). P3 יסיים I/O ב-t=30+4=34ms.\n*   **t=30-31**: CPU מבצע החלפת קשר (CS).\n*   **t=31-33**: CPU לא פעיל (Idle) - אין תהליכים בתורים.\n*   **t=33**: P1 מסיים I/O. P1 עובר ל-HPQ. HPQ = [P1].\n*   **t=33-34**: CPU מבצע החלפת קשר (CS) ל-P1.\n*   **t=34**: P1 מתחיל לרוץ (P1 פרץ CPU שני: 3ms). זמן ריצה עד כה: 0ms.\n*   **t=34**: P3 מסיים I/O. P3 עובר ל-HPQ. HPQ = [P1, P3].\n*   **t=36**: P1 השלים 2ms (קוואנטום HPQ). נשאר ל-P1 (CPU:1ms). P1 עובר לסוף HPQ. HPQ = [P3, P1].\n*   **t=36-37**: CPU מבצע החלפת קשר (CS).\n*   **t=37-38**: CPU מבצע החלפת קשר (CS) ל-P3.\n*   **t=38**: P3 מתחיל לרוץ (P3 פרץ CPU שני: 1ms). זמן ריצה עד כה: 0ms.\n*   **t=39**: P3 השלים 1ms. נשאר ל-P3 (CPU:0ms). P3 מסיים את כל פרצי ה-CPU שלו. P3 מסתיים. זמן סיום P3 = 39ms.\n*   **t=39-40**: CPU מבצע החלפת קשר (CS).\n*   **t=40-41**: CPU מבצע החלפת קשר (CS) ל-P1.\n*   **t=41**: P1 מתחיל לרוץ (P1 פרץ CPU שני: 1ms נותר). זמן ריצה עד כה: 0ms.\n*   **t=42**: P1 השלים 1ms. נשאר ל-P1 (CPU:0ms). P1 מסיים את כל פרצי ה-CPU שלו. P1 מסתיים. זמן סיום P1 = 42ms.\n*   **t=42-43**: CPU מבצע החלפת קשר (CS).\n*   **t=43**: כל התהליכים הסתיימו.\n\n**גאנט צ'ארט (Gantt Chart):**\n| 0-1 (CS) | 1-5 (P1) | 5-6 (CS) | 6-7 (CS) | 7-11 (P2) | 11-12 (CS) | 12-13 (CS) | 13-14 (CS) | 14-15 (CS) | 15-17 (P2) | 17-18 (CS) | 18-19 (CS) | 19-20 (P1) | 20-21 (CS) | 21-22 (CS) | 22-26 (P3) | 26-27 (CS) | 27-28 (CS) | 28-30 (P3) | 30-31 (CS) | 31-33 (Idle) | 33-34 (CS) | 34-36 (P1) | 36-37 (CS) | 37-38 (CS) | 38-39 (P3) | 39-40 (CS) | 40-41 (CS) | 41-42 (P1) | 42-43 (CS) |\n\n**חישובים:**\n*   **P1**:\n    *   זמן הגעה: 0ms\n    *   זמן סיום: 42ms\n    *   זמן CPU כולל: 5ms + 3ms = 8ms\n    *   זמן מחזור (Turnaround Time) = זמן סיום - זמן הגעה = 42 - 0 = **42ms**\n    *   זמן המתנה (Waiting Time) = סך הזמן שבילה P1 בתור ה-Ready:\n        *   [0,1] (מהגעה ועד ריצה ראשונה) = 1ms\n        *   [5,19] (לאחר קוואנטום ראשון ועד ריצה שנייה) = 14ms\n        *   [23,34] (לאחר סיום I/O ועד ריצה שלישית) = 11ms\n        *   [36,41] (לאחר קוואנטום שלישי ועד ריצה רביעית) = 5ms\n        *   סה\"כ זמן המתנה = 1 + 14 + 11 + 5 = **31ms**\n\n*   **P2**:\n    *   זמן הגעה: 1ms\n    *   זמן סיום: 17ms\n    *   זמן CPU כולל: 4ms + 2ms = 6ms\n    *   זמן מחזור (Turnaround Time) = זמן סיום - זמן הגעה = 17 - 1 = **16ms**\n    *   זמן המתנה (Waiting Time) = סך הזמן שבילה P2 בתור ה-Ready:\n        *   [1,7] (מהגעה ועד ריצה ראשונה) = 6ms\n        *   [13,15] (לאחר סיום I/O ועד ריצה שנייה) = 2ms\n        *   סה\"כ זמן המתנה = 6 + 2 = **8ms**\n\n*   **P3**:\n    *   זמן הגעה: 2ms\n    *   זמן סיום: 39ms\n    *   זמן CPU כולל: 6ms + 1ms = 7ms\n    *   זמן מחזור (Turnaround Time) = זמן סיום - זמן הגעה = 39 - 2 = **37ms**\n    *   זמן המתנה (Waiting Time) = סך הזמן שבילה P3 בתור ה-Ready:\n        *   [2,13] (מהגעה ועד ריצה ראשונה) = 11ms\n        *   [13,22] (לאחר דחיקה ועד ריצה שנייה) = 9ms\n        *   [26,28] (לאחר קוואנטום שני ועד ריצה שלישית) = 2ms\n        *   [34,38] (לאחר סיום I/O ועד ריצה רביעית) = 4ms\n        *   סה\"כ זמן המתנה = 11 + 9 + 2 + 4 = **26ms**\n"}, "difficulty_estimation": "Hard", "_source_file": "0764__CPU_Scheduling__Open__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:10:31", "_subject": "Virtualization"}, {"id": 101, "type": "Open", "topic": ["CPU Scheduling"], "content": {"text": "נתונה מערכת מרובת מעבדים עם 2 מעבדים זהים (CPU1 ו-CPU2).\nהמתזמן משתמש באלגוריתם תעדוף מונע (preemptive priority scheduling), כאשר מספר נמוך יותר מציין עדיפות גבוהה יותר (לדוגמה, 0 היא העדיפות הגבוהה ביותר).\nבין תהליכים בעלי אותה רמת עדיפות, המתזמן משתמש ב-FCFS (First-Come, First-Served).\nזמן החלפת הקשר (Context Switch) הוא 1ms.\n\n**כלל מיוחד לשיפור ביצועים:**\nכאשר תהליך מסיים פעולת קלט/פלט (I/O) והופך למוכן (ready), העדיפות שלו מוגברת באופן זמני לעדיפות הגבוהה ביותר האפשרית (עדיפות 0) עבור פרץ ה-CPU הבא שלו *בלבד*. לאחר שפרץ CPU זה מסתיים, העדיפות המקורית של התהליך משוחזרת. הגברה זו מתרחשת גם אם התהליך כבר בעל עדיפות גבוהה. אם תהליך בעל עדיפות 0 (מוגברת) נדחק על ידי תהליך אחר בעל עדיפות 0 (לדוגמה, אם תהליך אחר בעל עדיפות 0 הופך למוכן), הוא חוזר לתור המוכנים עם עדיפות 0 וממשיך כשהמעבד מתפנה.\n\nלהלן רשימת התהליכים ופרטי הביצוע שלהם:\n*   **P1:** מגיע ב-0ms, עדיפות מקורית 2. פרצי ביצוע: CPU 8ms, I/O 10ms, CPU 4ms.\n*   **P2:** מגיע ב-0ms, עדיפות מקורית 1. פרצי ביצוע: CPU 6ms, I/O 8ms, CPU 3ms.\n*   **P3:** מגיע ב-2ms, עדיפות מקורית 2. פרצי ביצוע: CPU 5ms, I/O 5ms, CPU 2ms.\n\nמהו הזמן הכולל עד לסיום כל התהליכים במערכת (Total Completion Time)?\nפרט את כל השלבים והחישובים.", "code_snippet": null, "options": null}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "נבצע מעקב אחר ביצוע התהליכים על פני ציר הזמן.\n**נתונים:**\n*   2 מעבדים זהים (CPU1, CPU2).\n*   תעדוף מונע (Preemptive Priority), מספר נמוך = עדיפות גבוהה.\n*   אותה עדיפות = FCFS.\n*   זמן החלפת קשר (CS) = 1ms.\n*   **כלל Boost:** לאחר I/O, פרץ ה-CPU הבא מקבל עדיפות 0 (הגבוהה ביותר) עבור פרץ זה בלבד.\n\n**תהליכים:**\n*   P1: A=0, Prio 2. Bursts: C8, I10, C4\n*   P2: A=0, Prio 1. Bursts: C6, I8, C3\n*   P3: A=2, Prio 2. Bursts: C5, I5, C2\n\n---\n**מעקב:**\n\n**T=0:**\n*   **Ready Queue (RQ):** [P2(P1, C6), P1(P2, C8)] (P2 בעדיפות גבוהה מ-P1)\n*   **CPU1:** P2 מתחיל. (CS=1ms)\n*   **CPU2:** P1 מתחיל. (CS=1ms)\n*   **זמן מערכת = 1ms.**\n*   CPU1 state: P2(P1, C5)\n*   CPU2 state: P1(P2, C7)\n\n**T=1:**\n*   P2 רץ ב-CPU1 (C_rem=4). P1 רץ ב-CPU2 (C_rem=6).\n\n**T=2 (P3 מגיע):**\n*   **RQ:** [P3(P2, C5)] (P2 ו-P1 רצים)\n*   P2 (P1) > P1 (P2) > P3 (P2). אין דחיקה. התהליכים הרצים ממשיכים.\n*   P2 רץ ב-CPU1 (C_rem=3). P1 רץ ב-CPU2 (C_rem=5).\n\n**T=3:**\n*   P2 רץ ב-CPU1 (C_rem=2). P1 רץ ב-CPU2 (C_rem=4).\n\n**T=4:**\n*   P2 רץ ב-CPU1 (C_rem=1). P1 רץ ב-CPU2 (C_rem=3).\n\n**T=5:**\n*   P2 רץ ב-CPU1 (C_rem=0). P2 מסיים את פרץ ה-CPU הראשון שלו (סה\"כ 6ms). \n*   P2 עובר ל-I/O (8ms). יהיה מוכן שוב ב-`5 + 8 = 13ms`.\n*   CPU1 מתפנה. (CS=1ms עבור התהליך הבא).\n*   P1 רץ ב-CPU2 (C_rem=2).\n*   **RQ:** [P1(P2, C2), P3(P2, C5)] (P1 עדיין רץ ב-CPU2. P1 ו-P3 באותה עדיפות, P1 קדם ל-P3 ב-FCFS).\n*   **CPU1:** P1 כבר רץ ב-CPU2, לכן P3 מתחיל ב-CPU1. (CS=1ms).\n*   **זמן מערכת = 6ms.**\n*   CPU1 state: P3(P2, C4)\n*   CPU2 state: P1(P2, C1) (P1 רץ ב-CPU2 מ-T=5 עד T=6).\n\n**T=6:**\n*   P3 רץ ב-CPU1 (C_rem=4). P1 רץ ב-CPU2 (C_rem=1).\n\n**T=7 (P1 מסיים את פרץ ה-CPU הראשון שלו):**\n*   P1 סיים את פרץ ה-CPU הראשון שלו (סה\"כ 8ms). \n*   P1 עובר ל-I/O (10ms). יהיה מוכן שוב ב-`7 + 10 = 17ms`.\n*   CPU2 מתפנה. (CS=1ms עבור התהליך הבא).\n*   P3 רץ ב-CPU1 (C_rem=3).\n*   **RQ:** [P3(P2, C3)] (P3 כבר רץ ב-CPU1).\n*   אין תהליכים נוספים בתור המוכנים. CPU2 עובר למצב סרק (idle) לאחר CS של 1ms.\n*   **זמן מערכת = 8ms.**\n*   CPU1 state: P3(P2, C2)\n*   CPU2 state: Idle\n\n**T=8:**\n*   P3 רץ ב-CPU1 (C_rem=2). CPU2: Idle.\n\n**T=9:**\n*   P3 רץ ב-CPU1 (C_rem=1). CPU2: Idle.\n\n**T=10:**\n*   P3 רץ ב-CPU1 (C_rem=0). P3 מסיים את פרץ ה-CPU הראשון שלו (סה\"כ 5ms). \n*   P3 עובר ל-I/O (5ms). יהיה מוכן שוב ב-`10 + 5 = 15ms`.\n*   CPU1 מתפנה. (CS=1ms עבור התהליך הבא).\n*   **RQ:** [] (P2 מוכן ב-13ms, P1 מוכן ב-17ms, P3 מוכן ב-15ms).\n*   שני המעבדים עוברים למצב סרק עד T=13.\n*   **זמן מערכת = 11ms.**\n\n**T=11, T=12:**\n*   שני המעבדים במצב סרק.\n\n**T=13 (P2 מסיים I/O):**\n*   P2 הופך למוכן. **כלל ה-Boost חל:** פרץ ה-CPU הבא של P2 (C3) מקבל עדיפות 0.\n*   **RQ:** [P2(P0, C3)]\n*   **CPU1:** P2 מתחיל. (CS=1ms)\n*   **CPU2:** עדיין סרק.\n*   **זמן מערכת = 14ms.**\n*   CPU1 state: P2(P0, C2)\n\n**T=14:**\n*   P2 רץ ב-CPU1 (C_rem=2). CPU2: Idle.\n\n**T=15 (P3 מסיים I/O):**\n*   P3 הופך למוכן. **כלל ה-Boost חל:** פרץ ה-CPU הבא של P3 (C2) מקבל עדיפות 0.\n*   **RQ:** [P2(P0, C1), P3(P0, C2)] (P2 עדיין רץ ב-CPU1. P2 ו-P3 באותה עדיפות (0), P2 קדם ל-P3 ב-FCFS).\n*   **CPU2:** P3 מתחיל. (CS=1ms)\n*   **זמן מערכת = 16ms.**\n*   CPU1 state: P2(P0, C0) (P2 רץ ב-CPU1 מ-T=15 עד T=16).\n*   CPU2 state: P3(P0, C1)\n\n**T=16 (P2 מסיים את פרץ ה-CPU המוגבר):**\n*   P2 סיים את פרץ ה-CPU שלו (סה\"כ 3ms). P2 סיים את כל ביצועיו.\n*   P2 הופך ל\"סיים\" (Done).\n*   CPU1 מתפנה. (CS=1ms עבור התהליך הבא).\n*   P3 רץ ב-CPU2 (C_rem=1).\n*   **RQ:** [P3(P0, C1)] (P3 כבר רץ ב-CPU2).\n*   **זמן מערכת = 17ms.**\n*   CPU1 state: Idle\n*   CPU2 state: P3(P0, C0)\n\n**T=17 (P1 מסיים I/O):**\n*   P1 הופך למוכן. **כלל ה-Boost חל:** פרץ ה-CPU הבא של P1 (C4) מקבל עדיפות 0.\n*   **CPU2:** P3 סיים את פרץ ה-CPU שלו (סה\"כ 2ms). P3 סיים את כל ביצועיו.\n*   P3 הופך ל\"סיים\" (Done).\n*   CPU2 מתפנה. (CS=1ms עבור התהליך הבא).\n*   **RQ:** [P1(P0, C4)]\n*   **CPU1:** P1 מתחיל. (CS=1ms)\n*   **זמן מערכת = 18ms.**\n*   CPU1 state: P1(P0, C3)\n*   CPU2 state: Idle\n\n**T=18:**\n*   P1 רץ ב-CPU1 (C_rem=3). CPU2: Idle.\n\n**T=19:**\n*   P1 רץ ב-CPU1 (C_rem=2). CPU2: Idle.\n\n**T=20:**\n*   P1 רץ ב-CPU1 (C_rem=1). CPU2: Idle.\n\n**T=21 (P1 מסיים את פרץ ה-CPU המוגבר):**\n*   P1 סיים את פרץ ה-CPU שלו (סה\"כ 4ms). P1 סיים את כל ביצועיו.\n*   P1 הופך ל\"סיים\" (Done).\n*   CPU1 מתפנה. (CS=1ms עבור התהליך הבא).\n*   **זמן מערכת = 22ms.**\n\n**כל התהליכים הסתיימו ב-T=22ms.**\nהזמן הכולל עד לסיום כל התהליכים הוא 22ms.", "difficulty_estimation": "Hard"}, "_source_file": "0765__CPU_Scheduling__Open__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:11:36", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["CPU Scheduling"], "content": {"text": "נתונה מערכת הפעלה המשתמשת באלגוריתם תזמון מעבד מסוג \"עדיפויות עם דריסה\" (Preemptive Priority).\nנתונים שלושה תהליכים:\n*   P1: זמן הגעה = 0, פרץ מעבד ראשון = 5 יחידות זמן, פרץ קלט/פלט = 10 יחידות זמן, פרץ מעבד שני = 3 יחידות זמן, עדיפות = 2.\n*   P2: זמן הגעה = 2, פרץ מעבד ראשון = 4 יחידות זמן, פרץ קלט/פלט = 8 יחידות זמן, פרץ מעבד שני = 2 יחידות זמן, עדיפות = 1.\n*   P3: זמן הגעה = 4, פרץ מעבד ראשון = 6 יחידות זמן, פרץ קלט/פלט = 12 יחידות זמן, פרץ מעבד שני = 4 יחידות זמן, עדיפות = 3.\n\nהנחות נוספות:\n1.  מספר עדיפות נמוך יותר מציין עדיפות גבוהה יותר (לדוגמה, עדיפות 1 גבוהה יותר מעדיפות 2).\n2.  תקורה של החלפת הקשר (Context Switch Overhead) היא יחידת זמן אחת.\n3.  פעולות קלט/פלט אינן ניתנות לדריסה (non-preemptible) – מרגע שתהליך מתחיל I/O, הוא משלים אותו וחוזר למצב \"מוכן\" (Ready).\n4.  אין תקורה על הכנסת תהליך למצב Ready.\n\nיש לשרטט את תרשים גאנט (Gantt Chart) המלא של ביצוע התהליכים, ולחשב את זמן ההמתנה הממוצע (Average Waiting Time) ואת זמן המחזור הממוצע (Average Turnaround Time) עבור כל התהליכים. יש לפרט את כל החישובים וההנחות.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "תרשים גאנט:\n[P1(0-2)] [CS(2-3)] [P2(3-7)] [CS(7-8)] [P1(8-11)] [CS(11-12)] [P3(12-15)] [CS(15-16)] [P2(16-18)] [CS(18-19)] [P3(19-21)] [CS(21-22)] [P1(22-25)] [CS(25-26)] [P3(26-31)]\n\nפירוט ביצוע וחישוב זמנים:\n\n*   **זמן 0:** P1 מגיע (עדיפות 2). המעבד פנוי, P1 מתחיל לרוץ.\n*   **זמן 2:** P2 מגיע (עדיפות 1). עדיפות P2 גבוהה מ-P1, לכן P1 נדרס. P1 נשאר עם 3 יחידות מעבד. מתבצעת החלפת קשר (CS) מ-P1 ל-P2 (יחידה אחת).\n*   **זמן 3:** P2 מתחיל לרוץ (4 יחידות מעבד).\n*   **זמן 4:** P3 מגיע (עדיפות 3). עדיפות P3 נמוכה מ-P2, P2 ממשיך לרוץ.\n*   **זמן 7:** P2 מסיים את פרץ המעבד הראשון שלו (4 יחידות). P2 נכנס ל-I/O (8 יחידות). P2 יהיה מוכן שוב בזמן 7 + 8 = 15. המעבד פנוי. P1 (עם 3 יחידות מעבד ועדיפות 2) ו-P3 (עם 6 יחידות מעבד ועדיפות 3) נמצאים בתור המוכנים. P1 בעל עדיפות גבוהה יותר. מתבצעת החלפת קשר (CS) מ-P2 ל-P1 (יחידה אחת).\n*   **זמן 8:** P1 ממשיך לרוץ (3 יחידות מעבד).\n*   **זמן 11:** P1 מסיים את פרץ המעבד הראשון שלו (3 יחידות). P1 נכנס ל-I/O (10 יחידות). P1 יהיה מוכן שוב בזמן 11 + 10 = 21. המעבד פנוי. P3 (עם 6 יחידות מעבד ועדיפות 3) הוא התהליך היחיד בתור המוכנים. מתבצעת החלפת קשר (CS) מ-P1 ל-P3 (יחידה אחת).\n*   **זמן 12:** P3 מתחיל לרוץ (6 יחידות מעבד).\n*   **זמן 15:** P2 מסיים את פעולת ה-I/O שלו וחוזר למצב מוכן (עם 2 יחידות מעבד ועדיפות 1). P3 (עם עדיפות 3) רץ. עדיפות P2 גבוהה מ-P3, לכן P3 נדרס. P3 נשאר עם 6 - (15-12) = 3 יחידות מעבד. מתבצעת החלפת קשר (CS) מ-P3 ל-P2 (יחידה אחת).\n*   **זמן 16:** P2 מתחיל לרוץ (2 יחידות מעבד).\n*   **זמן 18:** P2 מסיים את פרץ המעבד השני שלו. P2 מסיים את ביצועו. המעבד פנוי. P3 (עם 3 יחידות מעבד ועדיפות 3) הוא התהליך היחיד בתור המוכנים. מתבצעת החלפת קשר (CS) מ-P2 ל-P3 (יחידה אחת).\n*   **זמן 19:** P3 ממשיך לרוץ (3 יחידות מעבד).\n*   **זמן 21:** P1 מסיים את פעולת ה-I/O שלו וחוזר למצב מוכן (עם 3 יחידות מעבד ועדיפות 2). P3 (עם עדיפות 3) רץ. עדיפות P1 גבוהה מ-P3, לכן P3 נדרס. P3 נשאר עם 3 - (21-19) = 1 יחידת מעבד. מתבצעת החלפת קשר (CS) מ-P3 ל-P1 (יחידה אחת).\n*   **זמן 22:** P1 מתחיל לרוץ (3 יחידות מעבד).\n*   **זמן 25:** P1 מסיים את פרץ המעבד השני שלו. P1 מסיים את ביצועו. המעבד פנוי. P3 (עם 1 יחידת מעבד ועדיפות 3) הוא התהליך היחיד בתור המוכנים. מתבצעת החלפת קשר (CS) מ-P1 ל-P3 (יחידה אחת).\n*   **זמן 26:** P3 ממשיך לרוץ (5 יחידות מעבד, משלים את ה-1 שנותר + 4 מהפרץ השני).\n*   **זמן 31:** P3 מסיים את פרץ המעבד השני שלו. P3 מסיים את ביצועו. כל התהליכים הסתיימו.\n\nחישוב זמני מחזור והמתנה:\n\n*   **זמן מחזור (Turnaround Time - TAT):** זמן סיום - זמן הגעה.\n*   **זמן המתנה (Waiting Time - WT):** זמן מחזור - סך זמן מעבד - סך זמן קלט/פלט. (נוסחה זו כוללת בתוכה את התקורה של החלפות הקשר כחלק מזמן ההמתנה הכולל של התהליך).\n\n**תהליך P1:**\n*   סך זמן מעבד: 5 + 3 = 8\n*   סך זמן קלט/פלט: 10\n*   זמן סיום: 25\n*   זמן הגעה: 0\n*   TAT(P1) = 25 - 0 = 25\n*   WT(P1) = 25 - 8 - 10 = 7\n\n**תהליך P2:**\n*   סך זמן מעבד: 4 + 2 = 6\n*   סך זמן קלט/פלט: 8\n*   זמן סיום: 18\n*   זמן הגעה: 2\n*   TAT(P2) = 18 - 2 = 16\n*   WT(P2) = 16 - 6 - 8 = 2\n\n**תהליך P3:**\n*   סך זמן מעבד: 6 + 4 = 10\n*   סך זמן קלט/פלט: 12\n*   זמן סיום: 31\n*   זמן הגעה: 4\n*   TAT(P3) = 31 - 4 = 27\n*   WT(P3) = 27 - 10 - 12 = 5\n\n**סיכום ממוצעים:**\n*   **זמן המתנה ממוצע:** (7 + 2 + 5) / 3 = 14 / 3 ≈ 4.67 יחידות זמן\n*   **זמן מחזור ממוצע:** (25 + 16 + 27) / 3 = 68 / 3 ≈ 22.67 יחידות זמן"}, "difficulty_estimation": "Hard", "_source_file": "0766__CPU_Scheduling__Open__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:12:23", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["CPU Scheduling", "Multi-level Feedback Queue"], "content": {"text": "נתונה מערכת הפעלה המשתמשת במתזמן מעבד מסוג תור משוב רב-שכבתי (Multi-level feedback queue) עם 3 רמות עדיפות:\n- תור 0 (Q0): עדיפות עליונה, מבוסס Round Robin, קוונטום = 2ms.\n- תור 1 (Q1): עדיפות בינונית, מבוסס Round Robin, קוונטום = 4ms.\n- תור 2 (Q2): עדיפות נמוכה, מבוסס FCFS (First-Come, First-Served).\n\nכללי המעבר בין התורים והטיפול בתהליכים:\n1.  תהליכים חדשים מגיעים לתור 0.\n2.  תהליך שמשתמש בקוונטום המלא שלו בתור Q0 עובר לתור Q1.\n3.  תהליך שמשתמש בקוונטום המלא שלו בתור Q1 עובר לתור Q2.\n4.  תהליך שמבצע פעולת קלט/פלט (I/O) ומושלם, חוזר לתור 0 (Q0) עם סיום פעולת ה-I/O שלו.\n5.  תקורת החלפת הקשר (Context Switch Overhead) היא 1ms. תקורה זו חלה בכל מעבר בין תהליכים, ובנוסף בעת סיום תהליך (כאשר המעבד מתפנה).\n\nלהלן רשימת התהליכים שיש לטפל בהם:\n- P1: זמן הגעה 0ms, זמן מעבד כולל 10ms (ללא I/O).\n- P2: זמן הגעה 1ms, זמן מעבד כולל 8ms (ללא I/O).\n- P3: זמן הגעה 2ms, זמן מעבד כולל 12ms. התהליך מבצע פעולת I/O לאחר 3ms של זמן מעבד. פעולת ה-I/O אורכת 5ms. לאחר סיום ה-I/O, נותרו לו 9ms של זמן מעבד.\n- P4: זמן הגעה 3ms, זמן מעבד כולל 6ms (ללא I/O).\n\nחשב את זמן הסיום (Completion Time) של כל תהליך ואת זמן ההמתנה הממוצע (Average Waiting Time) של כל התהליכים במערכת. פרט את שלבי החישוב באופן ברור.", "code_snippet": null, "options": null}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "נבצע מעקב מפורט אחר ביצוע התהליכים על ציר הזמן:\n\n**מצב התחלתי:** כל התורים ריקים. זמן = 0ms.\n\n**0ms:** P1 מגיע. Q0: [P1]. המתזמן בוחר ב-P1. מתבצעת החלפת הקשר ל-P1 (1ms). P1 רץ 2ms (קוונטום).\n- זמן: 0 + 1 (CS) + 2 = 3ms.\n- P1 השתמש בקוונטום מלא, עובר ל-Q1. זמן מעבד נותר ל-P1: 8ms.\n- Q0: [], Q1: [P1], Q2: []\n\n**1ms:** P2 מגיע. Q0: [P2].\n**2ms:** P3 מגיע. Q0: [P2, P3].\n**3ms:** P4 מגיע. Q0: [P2, P3, P4].\n\n**3ms:** P1 סיים את הקוונטום. המתזמן בוחר ב-P2 (הראשון ב-Q0). החלפת קשר ל-P2 (1ms). P2 רץ 2ms (קוונטום).\n- זמן: 3 + 1 (CS) + 2 = 6ms.\n- P2 השתמש בקוונטום מלא, עובר ל-Q1. זמן מעבד נותר ל-P2: 6ms.\n- Q0: [P3, P4], Q1: [P1, P2], Q2: []\n\n**6ms:** המתזמן בוחר ב-P3 (הראשון ב-Q0). החלפת קשר ל-P3 (1ms). P3 רץ 2ms (קוונטום).\n- זמן: 6 + 1 (CS) + 2 = 9ms.\n- P3 השתמש בקוונטום מלא. P3 עדיין זקוק ל-1ms נוסף לפני ה-I/O. עובר ל-Q1. זמן מעבד נותר ל-P3: 10ms (1ms לפני I/O, 9ms אחרי I/O).\n- Q0: [P4], Q1: [P1, P2, P3], Q2: []\n\n**9ms:** המתזמן בוחר ב-P4 (הראשון ב-Q0). החלפת קשר ל-P4 (1ms). P4 רץ 2ms (קוונטום).\n- זמן: 9 + 1 (CS) + 2 = 12ms.\n- P4 השתמש בקוונטום מלא, עובר ל-Q1. זמן מעבד נותר ל-P4: 4ms.\n- Q0: [], Q1: [P1, P2, P3, P4], Q2: []\n\n**12ms:** Q0 ריק. המתזמן בוחר ב-P1 (הראשון ב-Q1). החלפת קשר ל-P1 (1ms). P1 רץ 4ms (קוונטום).\n- זמן: 12 + 1 (CS) + 4 = 17ms.\n- P1 השתמש בקוונטום מלא, עובר ל-Q2. זמן מעבד נותר ל-P1: 4ms.\n- Q0: [], Q1: [P2, P3, P4], Q2: [P1]\n\n**17ms:** המתזמן בוחר ב-P2 (הראשון ב-Q1). החלפת קשר ל-P2 (1ms). P2 רץ 4ms (קוונטום).\n- זמן: 17 + 1 (CS) + 4 = 22ms.\n- P2 השתמש בקוונטום מלא, עובר ל-Q2. זמן מעבד נותר ל-P2: 2ms.\n- Q0: [], Q1: [P3, P4], Q2: [P1, P2]\n\n**22ms:** המתזמן בוחר ב-P3 (הראשון ב-Q1). החלפת קשר ל-P3 (1ms). P3 זקוק ל-1ms נוסף לפני ה-I/O. P3 רץ 1ms.\n- זמן: 22 + 1 (CS) + 1 (P3 CPU) = 24ms.\n- P3 מסיים את פרץ המעבד הראשון שלו ויוזם פעולת I/O. זמן ה-I/O הוא 5ms. P3 עובר למצב חסום (Blocked).\n- זמן סיום I/O עבור P3: 24 + 5 = 29ms.\n- Q0: [], Q1: [P4], Q2: [P1, P2]\n\n**24ms:** P3 חסום. המתזמן בוחר ב-P4 (הראשון ב-Q1). החלפת קשר ל-P4 (1ms). P4 רץ 4ms (קוונטום).\n- זמן: 24 + 1 (CS) + 4 = 29ms.\n- P4 השתמש בקוונטום מלא. זמן מעבד נותר ל-P4: 0ms. P4 סיים את ריצתו. מתבצעת תקורה לסיום תהליך (1ms).\n- **זמן סיום P4: 29ms.**\n- Q0: [], Q1: [], Q2: [P1, P2]\n\n**29ms:** P4 סיים. **באותו רגע בדיוק**, I/O של P3 מסתיים. P3 חוזר לתור Q0. זמן מעבד נותר ל-P3: 9ms.\n- Q0: [P3], Q1: [], Q2: [P1, P2]\n\n**29ms:** המתזמן בוחר ב-P3 (הראשון ב-Q0). החלפת קשר ל-P3 (1ms). P3 רץ 2ms (קוונטום).\n- זמן: 29 + 1 (CS) + 2 = 32ms.\n- P3 השתמש בקוונטום מלא, עובר ל-Q1. זמן מעבד נותר ל-P3: 7ms.\n- Q0: [], Q1: [P3], Q2: [P1, P2]\n\n**32ms:** Q0 ריק. המתזמן בוחר ב-P1 (הראשון ב-Q2). החלפת קשר ל-P1 (1ms). P1 נמצא בתור FCFS, רץ עד לסיום. זמן מעבד נותר: 4ms.\n- זמן: 32 + 1 (CS) + 4 = 37ms.\n- P1 סיים את ריצתו. מתבצעת תקורה לסיום תהליך (1ms).\n- **זמן סיום P1: 37ms.**\n- Q0: [], Q1: [P3], Q2: [P2]\n\n**37ms:** P1 סיים. המתזמן בוחר ב-P2 (הראשון ב-Q2). החלפת קשר ל-P2 (1ms). P2 נמצא בתור FCFS, רץ עד לסיום. זמן מעבד נותר: 2ms.\n- זמן: 37 + 1 (CS) + 2 = 40ms.\n- P2 סיים את ריצתו. מתבצעת תקורה לסיום תהליך (1ms).\n- **זמן סיום P2: 40ms.**\n- Q0: [], Q1: [P3], Q2: []\n\n**40ms:** P2 סיים. המתזמן בוחר ב-P3 (הראשון ב-Q1). החלפת קשר ל-P3 (1ms). P3 רץ 4ms (קוונטום).\n- זמן: 40 + 1 (CS) + 4 = 45ms.\n- P3 השתמש בקוונטום מלא, עובר ל-Q2. זמן מעבד נותר ל-P3: 3ms.\n- Q0: [], Q1: [], Q2: [P3]\n\n**45ms:** Q1 ריק. המתזמן בוחר ב-P3 (הראשון ב-Q2). החלפת קשר ל-P3 (1ms). P3 נמצא בתור FCFS, רץ עד לסיום. זמן מעבד נותר: 3ms.\n- זמן: 45 + 1 (CS) + 3 = 49ms.\n- P3 סיים את ריצתו. מתבצעת תקורה לסיום תהליך (1ms).\n- **זמן סיום P3: 49ms.**\n- Q0: [], Q1: [], Q2: []\n\n**סיכום זמני סיום:**\n- P1: 37ms\n- P2: 40ms\n- P3: 49ms\n- P4: 29ms\n\n**חישוב זמן המתנה (Waiting Time = Completion Time - Arrival Time - Total CPU Burst - Total I/O Time):**\n- P1: זמן מעבד 10ms. זמן המתנה = 37 - 0 - 10 = 27ms.\n- P2: זמן מעבד 8ms. זמן המתנה = 40 - 1 - 8 = 31ms.\n- P3: זמן מעבד 12ms, זמן I/O 5ms. זמן המתנה = 49 - 2 - 12 - 5 = 30ms.\n- P4: זמן מעבד 6ms. זמן המתנה = 29 - 3 - 6 = 20ms.\n\n**זמן המתנה ממוצע:**\n(27 + 31 + 30 + 20) / 4 = 108 / 4 = 27ms."}, "difficulty_estimation": "Hard", "_source_file": "0767__CPU_Scheduling__Open__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:13:01", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["CPU Scheduling", "Multilevel Feedback Queue"], "content": {"text": "נתונה מערכת הפעלה המשתמשת במתזמן (scheduler) מסוג Multilevel Feedback Queue (MLFQ) עם 3 תורים:\n-   **תור 0 (עדיפות עליונה):** Round Robin עם קוונטום זמן של 4 מילישניות.\n-   **תור 1 (עדיפות בינונית):** Round Robin עם קוונטום זמן של 8 מילישניות.\n-   **תור 2 (עדיפות נמוכה):** First-Come, First-Served (FCFS).\n\n**כללי המעבר בין התורים:**\n1.  תהליכים חדשים נכנסים לתור 0.\n2.  אם תהליך מנצל את כל קוונטום הזמן שלו בתור 0, הוא עובר לתור 1.\n3.  אם תהליך מנצל את כל קוונטום הזמן שלו בתור 1, הוא עובר לתור 2.\n4.  אם תהליך מבצע פעולת קלט/פלט (I/O), הוא נחסם. עם סיום פעולת ה-I/O, התהליך חוזר לתור 0 (עדיפות עליונה).\n5.  אם תהליך מסיים CPU burst לפני תום הקוונטום, הוא נשאר באותו התור. אם הוא יוצא ל-I/O, הוא עובר למצב חסום ועם חזרתו יכנס לתור 0.\n6.  תורים בעדיפות גבוהה יותר תמיד מבצעים פריימפשן (preemption) לתהליכים בתורים בעדיפות נמוכה יותר. בתוך אותו תור, מתבצעת הפעולה לפי כללי התור (RR או FCFS).\n\nלהלן רשימת תהליכים עם זמני הגעה (Arrival Time) ורצפי פעולות (CPU burst, I/O burst):\n\n| תהליך | זמן הגעה | רצף פעולות (זמנים במילישניות) |\n|---|---|---|\n| P1 | 0 | CPU (5), I/O (10), CPU (5) |\n| P2 | 0 | CPU (15) |\n| P3 | 5 | CPU (6), I/O (5), CPU (4) |\n\nהתעלמו מזמני החלפת הקשר (context switch overhead). יש לחשב ולפרט את זמן הסיום של כל תהליך, ואת הזמן הכולל עד לסיום כל התהליכים במערכת.", "code_snippet": null, "options": null}, "sub_questions": null, "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון ידרוש מעקב צמוד אחר מצב התהליכים והתורים לאורך זמן:\n\n**זמן 0:**\n*   P1 ו-P2 מגיעים ונכנסים לתור 0.\n*   תור 0: [P1, P2]. P1 מתחיל לרוץ.\n\n**זמן 0-4:**\n*   P1 רץ 4ms (מתוך 5ms). נשאר לו 1ms. P1 מנצל את כל הקוונטום בתור 0, ולכן עובר לתור 1.\n*   תור 0: [P2]. P2 מתחיל לרוץ.\n\n**זמן 4-5:**\n*   P2 רץ 1ms (מתוך קוונטום של 4ms). נשאר לו 14ms ל-CPU.\n\n**זמן 5:**\n*   P3 מגיע ונכנס לתור 0.\n*   תור 0: [P2, P3] (P3 נוסף לסוף התור, כיוון ש-P2 כבר רץ ו-P3 מגיע לאותו תור). P2 ממשיך לרוץ בתור 0 (טרם סיים את הקוונטום שלו).\n\n**זמן 5-8:**\n*   P2 רץ 3ms נוספים (משלים 4ms סה\"כ לקוונטום הנוכחי). נשאר לו 11ms ל-CPU. P2 מנצל את כל הקוונטום בתור 0, ולכן עובר לתור 1.\n*   תור 0: [P3]. P3 מתחיל לרוץ.\n\n**זמן 8-12:**\n*   P3 רץ 4ms (מתוך 6ms). נשאר לו 2ms. P3 מנצל את כל הקוונטום בתור 0, ולכן עובר לתור 1.\n*   תור 0: ריק. תור 1: [P1, P2, P3]. P1 מתחיל לרוץ (התהליך הראשון בתור 1).\n\n**זמן 12-13:**\n*   P1 רץ 1ms (השלמה של ה-CPU burst הראשון). נשאר לו 0ms ל-CPU burst זה. P1 מבצע I/O.\n*   P1 נחסם למשך 10ms (עד זמן 23). עם סיום ה-I/O יחזור לתור 0.\n*   תור 1: [P2, P3]. P2 מתחיל לרוץ.\n\n**זמן 13-21:**\n*   P2 רץ 8ms (מתוך 11ms). נשאר לו 3ms ל-CPU. P2 מנצל את כל הקוונטום בתור 1, ולכן עובר לתור 2.\n*   תור 1: [P3]. P3 מתחיל לרוץ.\n\n**זמן 21-23:**\n*   P3 רץ 2ms (השלמה של ה-CPU burst הראשון). נשאר לו 0ms ל-CPU burst זה. P3 מבצע I/O.\n*   P3 נחסם למשך 5ms (עד זמן 28). עם סיום ה-I/O יחזור לתור 0.\n*   תור 1: ריק. תור 2: [P2]. P2 מתחיל לרוץ (כי תור 0 ו-1 ריקים).\n\n**זמן 23:**\n*   P1 מסיים I/O. חוזר לתור 0.\n*   תור 0: [P1]. P1 מבצע פריימפשן ל-P2 (כי P1 בתור 0 ו-P2 בתור 2).\n*   P1 מתחיל לרוץ (יש לו 5ms ל-CPU burst השני).\n\n**זמן 23-27:**\n*   P1 רץ 4ms (מתוך 5ms). נשאר לו 1ms. P1 מנצל את כל הקוונטום בתור 0, ולכן עובר לתור 1.\n*   תור 0: ריק. תור 1: [P1]. P1 מתחיל לרוץ (כי תור 0 ריק ו-P1 בראש תור 1).\n\n**זמן 27-28:**\n*   P1 רץ 1ms (השלמה של ה-CPU burst השני). נשאר לו 0ms ל-CPU burst זה. P1 מסיים את פעילותו.\n*   תור 1: ריק. תור 2: [P2]. P2 מתחיל לרוץ (כי תור 0 ו-1 ריקים).\n\n**זמן 28:**\n*   P3 מסיים I/O. חוזר לתור 0.\n*   תור 0: [P3]. P3 מבצע פריימפשן ל-P2 (כי P3 בתור 0 ו-P2 בתור 2).\n*   P3 מתחיל לרוץ (יש לו 4ms ל-CPU burst השני).\n\n**זמן 28-32:**\n*   P3 רץ 4ms (השלמה של ה-CPU burst השני). נשאר לו 0ms ל-CPU burst זה. P3 מסיים את פעילותו.\n*   תור 0: ריק. תור 1: ריק. תור 2: [P2]. P2 מתחיל לרוץ.\n\n**זמן 32-35:**\n*   P2 רץ 3ms (השלמה של ה-CPU burst היחיד). נשאר לו 0ms ל-CPU burst זה. P2 מסיים את פעילותו.\n\n**זמני סיום:**\n*   P1: 28ms\n*   P2: 35ms\n*   P3: 32ms\n\n**הזמן הכולל עד לסיום כל התהליכים במערכת הוא 35 מילישניות.**", "difficulty_estimation": "Hard"}, "_source_file": "0768__CPU_Scheduling__Open__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:13:49", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["CPU Scheduling", "Processes", "Concurrency"], "content": {"text": "נתונה התוכנית הבאה:\nהניחו כי המערכת פועלת על מעבד יחיד (single CPU) ומשתמשת באלגוריתם תזמון מונע (preemptive scheduler) שאינו מבטיח סדר ריצה ספציפי בין תהליכים מוכנים לריצה. כל קריאות המערכת מצליחות.\nכתבו את כל הפלטים האפשריים של התוכנית.", "code_snippet": "#include <stdio.h>\n#include <unistd.h> // For fork\n\nint main() {\n    printf(\"1. Parent starts\\n\");\n    fflush(stdout);\n\n    pid_t pid = fork();\n\n    if (pid == 0) { // Child process\n        printf(\"3. Child executes\\n\");\n        fflush(stdout);\n        printf(\"4. Child finishes\\n\");\n        fflush(stdout);\n    } else if (pid > 0) { // Parent process\n        printf(\"2. Parent continues\\n\");\n        fflush(stdout);\n        printf(\"5. Parent finishes\\n\");\n        fflush(stdout);\n    }\n\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסבר:\nהשורה הראשונה \"1. Parent starts\" מודפסת תמיד ראשונה, מכיוון שהיא מתבצעת על ידי תהליך האב לפני קריאת ה-fork. קריאת ה-fflush(stdout) מבטיחה שההדפסה תצא מיד לפלט.\n\nלאחר קריאת ה-fork, נוצרים שני תהליכים: תהליך אב ותהליך בן. שניהם מוכנים לריצה על המעבד. המתזמן המונע יכול לבחור להריץ כל אחד מהם.\n\n*   **תהליך האב** ימשיך להדפיס: \"2. Parent continues\" ולאחר מכן \"5. Parent finishes\".\n*   **תהליך הבן** ימשיך להדפיס: \"3. Child executes\" ולאחר מכן \"4. Child finishes\".\n\nמכיוון שהמתזמן הוא מונע ואינו מבטיח סדר ריצה ספציפי, ישנן שתי אפשרויות עיקריות לסדר ההדפסות של קטעי הקוד לאחר ה-fork, בהתחשב בכך שכל רצף הדפסות בתוך תהליך בודד הוא קצר מאוד וסביר שיתבצע ברצף:\n\n**פלט אפשרי 1: תהליך האב רץ ומסיים את הדפסותיו לפני שהמתזמן מעביר את השליטה לבן.**\n1. Parent starts\n2. Parent continues\n3. Parent finishes\n3. Child executes\n4. Child finishes\n\n**פלט אפשרי 2: תהליך הבן רץ ומסיים את הדפסותיו לפני שהמתזמן מעביר את השליטה לאב.**\n1. Parent starts\n3. Child executes\n4. Child finishes\n2. Parent continues\n5. Parent finishes\n\nבכל אחד מהמקרים, סדר ההדפסות בתוך כל תהליך נשמר (לדוגמה, \"2\" תמיד יבוא לפני \"5\" באב, ו\"3\" תמיד יבוא לפני \"4\" בבן)."}, "difficulty_estimation": "Easy", "_source_file": "0769__CPU_Scheduling__CodeAnalysis__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:14:10", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["CPU Scheduling", "Processes", "System Calls"], "content": {"text": "נתונה התוכנית הבאה, המשתמשת ב-fork ליצירת תהליכים בנים. יש להניח שהמערכת מריצה תהליכים על מעבד יחיד (single CPU) ומשתמשת באלגוריתם תזמון מסוג FCFS (First Come, First Served). כמו כן, יש להניח שכל קריאות המערכת מצליחות, ושתהליך האב יוצר את כל התהליכים הבנים לפני שהם מתחילים לרוץ. הפלט הסטנדרטי אינו מבוּפָר (unbuffered).\n\nמה יהיה הפלט המדויק של התוכנית?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\n#define NUM_CHILDREN 3\n#define PRINT_COUNT 2\n\nint main() {\n    setbuf(stdout, NULL); // Disable buffering for immediate output\n    char chars[NUM_CHILDREN] = {'A', 'B', 'C'};\n\n    for (int i = 0; i < NUM_CHILDREN; ++i) {\n        pid_t pid = fork();\n        if (pid == -1) {\n            perror(\"fork failed\");\n            exit(1);\n        }\n        if (pid == 0) { // Child process\n            for (int j = 0; j < PRINT_COUNT; ++j) {\n                printf(\"%c\", chars[i]);\n            }\n            exit(0);\n        }\n    }\n\n    // Parent waits for all children to complete\n    for (int i = 0; i < NUM_CHILDREN; ++i) {\n        wait(NULL);\n    }\n\n    printf(\"\\nParent finished.\\n\");\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכנית יוצרת 3 תהליכי בנים בלולאה. תהליך האב יוצר את הבנים בסדר: הראשון מדפיס 'A', השני מדפיס 'B', והשלישי מדפיס 'C'. לאחר יצירת כל הבנים, תהליך האב נכנס למצב המתנה (wait) עבורם.\n\nמכיוון שאלגוריתם התזמון הוא FCFS (First Come, First Served) ומוגדר במפורש שתהליך האב יוצר את כל התהליכים הבנים לפני שהם מתחילים לרוץ, התהליכים הבנים יבוצעו על ידי המעבד לפי סדר יצירתם. לכן, תהליך הבן הראשון (שמדפיס 'A') ירוץ עד לסיומו, ואז תהליך הבן השני (שמדפיס 'B') ירוץ עד לסיומו, וכן הלאה. כל תהליך בן מדפיס את התו שלו פעמיים.\n\nלבסוף, לאחר שכל הבנים סיימו את ריצתם, תהליך האב יתעורר מה-wait וידפיס את הודעת הסיום. \n\nהפלט המדויק יהיה:\nAABBCC\nParent finished.\n"}, "difficulty_estimation": "Easy", "_source_file": "0770__CPU_Scheduling__CodeAnalysis__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:14:28", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["CPU Scheduling", "Processes", "Concurrency"], "content": {"text": "נתונה התוכנית הבאה:\nהניחו את ההנחות הבאות:\n1.  המערכת משתמשת באלגוריתם תזמון Round Robin (RR) עם קוונטום (quantum) של 20 מילישניות.\n2.  כל קריאות המערכת (fork, usleep) מצליחות.\n3.  אין תקורה (overhead) למעבר הקשר (context switch).\n4.  כל תהליך, לאחר קריאת `printf` ו-`usleep`, מבצע עבודה שמשך זמןה הכולל הוא 10 מילישניות. זמן זה קצר מהקוונטום.\n5.  התהליך הראשי (parent) ותהליכי הבן (children) מוכנים לריצה מיד לאחר יצירתם, והם מתזומנים בסדר הבא: Parent, Child 1, Child 2. סדר זה נשמר לאורך כל הריצה כל עוד התהליכים מוכנים.\n6.  הפלט הסטנדרטי אינו מחוצץ (unbuffered).", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    setbuf(stdout, NULL);\n    printf(\"Start\\n\");\n\n    pid_t pid1 = fork();\n    if (pid1 == 0) { // Child 1\n        for (int i = 0; i < 3; ++i) {\n            printf(\"A\");\n            usleep(10000); // 10ms\n        }\n        _exit(0);\n    }\n\n    pid_t pid2 = fork();\n    if (pid2 == 0) { // Child 2 (forked by original parent)\n        for (int i = 0; i < 3; ++i) {\n            printf(\"B\");\n            usleep(10000); // 10ms\n        }\n        _exit(0);\n    }\n\n    // Parent continues\n    for (int i = 0; i < 3; ++i) {\n        printf(\"P\");\n        usleep(10000); // 10ms\n    }\n\n    // Wait for children to finish\n    waitpid(pid1, NULL, 0);\n    waitpid(pid2, NULL, 0);\n\n    printf(\"\\nEnd\\n\");\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכנית מתחילה בהדפסת \"Start\\n\".\nלאחר מכן, התהליך הראשי (P) יוצר שני תהליכי בנים. נניח ש-`pid1` הוא עבור Child 1 (C1) ו-`pid2` עבור Child 2 (C2).\nבהתאם להנחות, תזמון התהליכים הוא Round Robin בסדר P, C1, C2. סדר זה נשמר לאורך כל הריצה כל עוד התהליכים מוכנים.\nכל תהליך מבצע לולאה של 3 איטרציות, ובכל איטרציה הוא מדפיס תו (P, A, או B) וממתין 10 מילישניות. זמן ההמתנה הזה קצר מהקוונטום (20 מילישניות).\nלכן, בכל פעם שתהליך מקבל את המעבד, הוא יסיים את פעולתו (הדפסה + שינה) בתוך הקוונטום שלו, וייתן למתזמן להעביר את המעבד לתהליך הבא בתור ברשימת התהליכים המוכנים (P -> C1 -> C2 -> P -> ...).\n\nהפלט יתנהל כך:\n1.  התהליך הראשי מדפיס: `Start\\n`\n2.  התהליך הראשי (P) רץ ראשון, מדפיס: `P`\n3.  Child 1 (C1) רץ שני, מדפיס: `A`\n4.  Child 2 (C2) רץ שלישי, מדפיס: `B`\n5.  התהליך הראשי (P) רץ שוב, מדפיס: `P`\n6.  Child 1 (C1) רץ שוב, מדפיס: `A`\n7.  Child 2 (C2) רץ שוב, מדפיס: `B`\n8.  התהליך הראשי (P) רץ בפעם האחרונה, מדפיס: `P`\n9.  Child 1 (C1) רץ בפעם האחרונה, מדפיס: `A`\n10. Child 2 (C2) רץ בפעם האחרונה, מדפיס: `B`\n\nבנקודה זו, כל שלושת התהליכים סיימו את הלולאות שלהם. תהליכי הבן יצאו (`_exit(0)`). התהליך הראשי ימתין לסיום הבנים באמצעות `waitpid`, ולאחר מכן ידפיס את שורת הסיום.\n\nלכן, הפלט הכולל יהיה:\n```\nStart\nPABPABPAB\nEnd\n```"}, "difficulty_estimation": "Easy", "_source_file": "0771__CPU_Scheduling__CodeAnalysis__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:14:51", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["CPU Scheduling", "Processes", "System Calls"], "content": {"text": "נתונה התוכנית הבאה:\nהניחו כי המערכת בעלת מעבד יחיד (single CPU) וכי אלגוריתם תזמון המעבד הוא FCFS (First Come, First Served).\nהניחו שכל קריאות המערכת (system calls) מצליחות.\nהפלט הסטנדרטי אינו מבוּפר (unbuffered).\nמהו הפלט הסופי של התוכנית?", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nvoid child_task(char c, int count) {\n    for (int i = 0; i < count; ++i) {\n        printf(\"%c\", c);\n    }\n    exit(0);\n}\n\nint main() {\n    pid_t pid1, pid2;\n\n    setbuf(stdout, NULL); // Unbuffered output\n\n    printf(\"P\"); \n\n    pid1 = fork();\n    if (pid1 == 0) { // Child 1\n        child_task('A', 3);\n    }\n\n    if (pid1 > 0) { // Parent continues after first fork\n        printf(\"M\"); \n        pid2 = fork();\n        if (pid2 == 0) { // Child 2\n            child_task('B', 2);\n        }\n    }\n\n    if (pid1 > 0 && pid2 > 0) { // Only parent after both forks\n        printf(\"F\"); \n        wait(NULL); \n        wait(NULL); \n        printf(\"E\\n\"); \n    }\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התהליך הראשי מתחיל ומדפיס 'P'.\nלאחר מכן הוא קורא ל-`fork()` ויוצר את תהליך הבן הראשון (Child 1).\nעל פי אלגוריתם FCFS, התהליך הראשי ממשיך לרוץ מכיוון שהוא היה על המעבד והוא לא נחסם (קריאת ה-`fork` הסתיימה).\nהתהליך הראשי מדפיס 'M'.\nלאחר מכן הוא קורא שוב ל-`fork()` ויוצר את תהליך הבן השני (Child 2).\nהתהליך הראשי ממשיך לרוץ (שוב, FCFS והוא לא נחסם), מדפיס 'F'.\nלאחר מכן התהליך הראשי קורא ל-`wait(NULL)` ונחסם, ממתין לתהליכי בנים שיסתיימו.\nבנקודה זו, תהליך הבן הראשון (Child 1) ותהליך הבן השני (Child 2) נמצאים שניהם בתור התורים של המעבד.\nמכיוון ש-Child 1 נוצר לפני Child 2 (והוכנס לתור לפניו), על פי FCFS הוא יקבל את המעבד ראשון.\nChild 1 ירוץ וידפיס את התו 'A' שלוש פעמים (AAA). לאחר מכן הוא יסיים את פעולתו באמצעות `exit(0)`.\nכאשר Child 1 מסיים, התהליך הראשי שהמתין לתהליכים בנים הופך להיות מוכן שוב (מכיוון שאחד מילדיו סיים).\nכעת, בתור התורים יש את Child 2 ואת התהליך הראשי (שתהליך הבן הראשון סיים, והוא נכנס לתור מאוחר יותר מ-Child 2).\nעל פי FCFS, Child 2 יקבל את המעבד.\nChild 2 ירוץ וידפיס את התו 'B' פעמיים (BB). לאחר מכן הוא יסיים את פעולתו.\nכאשר Child 2 מסיים, התהליך הראשי (שכבר היה מוכן) מקבל את המעבד.\nהתהליך הראשי ימשיך מנקודת הקריאה ל-`wait(NULL)` הראשונה (שכבר חזרה עבור Child 1) ויבצע את הקריאה השנייה ל-`wait(NULL)` (שכבר חזרה עבור Child 2). כלומר, הוא יצא ממצב חסימה.\nלאחר מכן הוא ידפיס 'E' וירד שורה, ויסיים את פעולתו.\nלכן, הפלט הסופי של התוכנית יהיה: PMFAAABBE\n"}, "difficulty_estimation": "Easy", "_source_file": "0772__CPU_Scheduling__CodeAnalysis__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:15:17", "_subject": "Virtualization"}, {"id": 7, "type": "CodeAnalysis", "topic": ["CPU Scheduling", "Processes", "System Calls"], "content": {"text": "נתונה התוכנית הבאה. הניחו שיש מעבד יחיד ואלגוריתם התזמון הוא FCFS (First-Come, First-Served). כמו כן, הניחו שכל קריאות המערכת מצליחות, ושתהליך המריץ קטע קוד אינו נקטע עד לסיום קטע זה או עד שהוא נחסם (לדוגמה, בקריאה ל-waitpid).", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nvoid worker(char c, int count) {\n    for (int i = 0; i < count; ++i) {\n        printf(\"%c\", c);\n        fflush(stdout); // Ensure immediate output\n    }\n}\n\nint main() {\n    setbuf(stdout, NULL); // Disable stdout buffering\n\n    pid_t pid1, pid2;\n\n    printf(\"Start\\n\");\n\n    pid1 = fork();\n    if (pid1 == 0) { // Child process 1\n        worker('A', 3);\n        return 0;\n    }\n\n    pid2 = fork();\n    if (pid2 == 0) { // Child process 2\n        worker('B', 3);\n        return 0;\n    }\n\n    // Parent process\n    worker('C', 3);\n\n    waitpid(pid1, NULL, 0);\n    waitpid(pid2, NULL, 0);\n\n    printf(\"\\nEnd\\n\");\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "כתבו את הפלט המדויק של התוכנית.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התהליך הראשי (main) מתחיל ומדפיס 'Start\\n'.\nלאחר מכן, התהליך הראשי מבצע שתי קריאות fork(). קריאה אחת יוצרת את תהליך הבן A, והשנייה יוצרת את תהליך הבן B. שני תהליכי הבן מתווספים לתור המוכנים (Ready Queue).\nמכיוון שאלגוריתם התזמון הוא FCFS, והתהליך הראשי עדיין רץ ולא נחסם, הוא ממשיך לבצע את עבודתו עד לסיום הקטע הנוכחי. הוא קורא לפונקציה `worker('C', 3)` ומדפיס 'CCC'.\nלאחר מכן, התהליך הראשי מגיע לקריאות ל-`waitpid` ונחסם בהמתנה לסיום תהליכי הבן שלו.\nכעת, המעבד פנוי, והמערכת בוחרת את התהליך הבא מתור המוכנים לפי סדר הגעתו. נניח שתהליך A הגיע ראשון לתור המוכנים (מכיוון שקריאת ה-fork שלו קדמה לקריאת ה-fork של B). תהליך A רץ, קורא לפונקציה `worker('A', 3)` ומדפיס 'AAA'.\nתהליך A מסיים את ריצתו ויוצא.\nלאחר מכן, המערכת בוחרת את תהליך B. תהליך B רץ, קורא לפונקציה `worker('B', 3)` ומדפיס 'BBB'.\nתהליך B מסיים את ריצתו ויוצא.\nעם סיום שני תהליכי הבן, התהליך הראשי (main), שהיה חסום ב-`waitpid`, הופך למוכן שוב. הוא נבחר לרוץ וממשיך את ביצועו, מדפיס '\\nEnd\\n' ויוצא.\n\nלכן, הפלט הסופי יהיה:\nStart\nCCC\nAAA\nBBB\nEnd"}, "difficulty_estimation": "Easy", "_source_file": "0773__CPU_Scheduling__CodeAnalysis__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:15:39", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["CPU Scheduling", "Processes", "Concurrency"], "content": {"text": "נתונה התוכנית הבאה. הניחו כי המערכת פועלת על מעבד יחיד (single CPU) ומשתמשת באלגוריתם תזמון Round Robin (RR) עם קוונטום זמן (time quantum) של 1 יחידת זמן.\nכל קריאת `printf` נחשבת לפעולה שלוקחת בדיוק 1 יחידת זמן CPU. זמן יצירת תהליך (`fork`) וזמן החלפת הקשר (context switch) זניחים (0 יחידות זמן).\nלאחר קריאת ה-`fork`, שני התהליכים (האב והבן) מועברים לתור המוכנים. נניח שהתהליך האב ממשיך לרוץ את שארית הקוונטום שלו (אם נותרה), ולאחר מכן מתבצעת החלפת קשר. אם לשניהם יש קוונטום מלא, האב ירוץ, ואז הבן, וחוזר חלילה.\nמהו פלט אפשרי אחד של התוכנית? נמקו את תשובתכם בפירוט.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h> // For fork, getpid\n#include <sys/wait.h> // For wait\n\nint main() {\n    setbuf(stdout, NULL); // Disable buffering for immediate output\n    printf(\"Start\\n\");\n    pid_t pid = fork();\n\n    if (pid == -1) {\n        perror(\"fork failed\");\n        exit(1);\n    }\n\n    if (pid == 0) { // Child process\n        for (int i = 0; i < 3; ++i) {\n            printf(\"Child: %d\\n\", i);\n        }\n        printf(\"Child Done\\n\");\n        exit(0); // Child exits cleanly\n    } else { // Parent process\n        for (int i = 0; i < 2; ++i) {\n            printf(\"Parent: %d\\n\", i);\n        }\n        wait(NULL); // Parent waits for child\n        printf(\"Parent Done\\n\");\n    }\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכנית מתחילה בהדפסת 'Start' ולאחר מכן יוצרת תהליך בן באמצעות `fork()`. קריאת `setbuf(stdout, NULL)` מבטיחה שהפלט יודפס מיד וללא בופר.\n\nלאחר ה-`fork`, שני התהליכים (האב והבן) נמצאים בתור המוכנים. על פי כלל התזמון הנתון (Round Robin עם קוונטום של יחידת זמן אחת, כאשר כל `printf` לוקח יחידת זמן אחת), התהליכים יבצעו פעולה אחת בתורם.\n\nשלבי הריצה:\n1.  התהליך הראשי (האב) מתחיל. מדפיס \"Start\".\n2.  האב מבצע `fork()`. נוצר תהליך בן. שני התהליכים (האב והבן) מוכנים לריצה.\n3.  נניח שהאב מקבל את המעבד ראשון (על פי ההנחה שהאב ממשיך לרוץ או מקבל את התור ראשון). \n4.  **אב**: מדפיס \"Parent: 0\". (מנצל יחידת זמן אחת). הקוונטום נגמר, מתבצעת החלפת קשר, והאב עובר לסוף תור המוכנים.\n5.  **בן**: מקבל את המעבד. מדפיס \"Child: 0\". (מנצל יחידת זמן אחת). הקוונטום נגמר, מתבצעת החלפת קשר, והבן עובר לסוף תור המוכנים.\n6.  **אב**: מקבל את המעבד. מדפיס \"Parent: 1\". (מנצל יחידת זמן אחת). הקוונטום נגמר, מתבצעת החלפת קשר, והאב עובר לסוף תור המוכנים.\n7.  **בן**: מקבל את המעבד. מדפיס \"Child: 1\". (מנצל יחידת זמן אחת). הקוונטום נגמר, מתבצעת החלפת קשר, והבן עובר לסוף תור המוכנים.\n8.  **אב**: מקבל את המעבד. הלולאה שלו מסתיימת. קורא ל-`wait(NULL)` ונכנס למצב חסימה (Blocked) עד שהבן יסיים את פעולתו.\n9.  **בן**: מקבל את המעבד. מדפיס \"Child: 2\". (מנצל יחידת זמן אחת). הקוונטום נגמר, מתבצעת החלפת קשר, והבן עובר לסוף תור המוכנים.\n10. **בן**: מקבל את המעבד. מדפיס \"Child Done\". (מנצל יחידת זמן אחת). הקוונטום נגמר, הבן קורא ל-`exit(0)` ומסיים את פעולתו (Terminated).\n11. **אב**: הבן סיים, מה שגורם לשחרור האב ממצב חסימה. האב עובר לתור המוכנים.\n12. **אב**: מקבל את המעבד. מדפיס \"Parent Done\".\n13. **אב**: מסיים את פעולתו (Terminated).\n\nלכן, פלט אפשרי אחד של התוכנית יהיה:\n```\nStart\nParent: 0\nChild: 0\nParent: 1\nChild: 1\nChild: 2\nChild Done\nParent Done\n```"}, "difficulty_estimation": "Easy", "_source_file": "0774__CPU_Scheduling__CodeAnalysis__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:16:07", "_subject": "Virtualization"}, {"id": 7, "type": "CodeAnalysis", "topic": ["CPU Scheduling", "Processes", "System Calls"], "content": {"text": "נתונה התוכנית הבאה:\nיש להניח שקיימת יחידת עיבוד מרכזית (מעבד) אחת בלבד, ואלגוריתם התזמון הוא FIFO (First-In, First-Out).\nכל קריאות המערכת מצליחות, ואין חציצה לפלט הסטנדרטי (stdout).\nכתבו את הפלט המדויק של התוכנית.", "code_snippet": "#include <stdio.h>\n#include <unistd.h> // for fork, getpid\n#include <sys/wait.h> // for wait\n\nint main() {\n    setbuf(stdout, NULL); // Disable buffering for immediate output\n\n    printf(\"Parent process started.\\n\");\n\n    pid_t pid1 = fork();\n    if (pid1 == 0) { // Child 1\n        printf(\"Child 1 created.\\n\");\n        return 0;\n    }\n\n    pid_t pid2 = fork();\n    if (pid2 == 0) { // Child 2\n        printf(\"Child 2 created.\\n\");\n        return 0;\n    }\n\n    // Parent waits for both children to finish\n    wait(NULL); // Waits for one child\n    wait(NULL); // Waits for the other child\n\n    printf(\"Parent process finished.\\n\");\n\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפלט המדויק של התוכנית יהיה:\nParent process started.\nChild 1 created.\nChild 2 created.\nParent process finished.\n\nהסבר:\n1. התהליך הראשי (Parent) מתחיל ומדפיס \"Parent process started.\".\n2. התהליך הראשי מבצע `fork()` ויוצר את Child 1. Child 1 מתווסף לתור התהליכים המוכנים לריצה (Ready Queue).\n3. התהליך הראשי ממשיך מיד (מבלי שהילדים ירוצו בינתיים, מכיוון שקריאת `fork` היא מהירה והתהליך הראשי לא מסיים את רצף הפעולות שלו) ומבצע `fork()` נוסף, ויוצר את Child 2. Child 2 מתווסף לתור התהליכים המוכנים לריצה, אחרי Child 1. כעת, התהליך הראשי רץ, ותור ה-Ready הוא: `[Child 1, Child 2]`.\n4. התהליך הראשי קורא ל-`wait(NULL)` הראשון. קריאה זו חוסמת את התהליך הראשי, והוא עובר למצב חסום (Blocked).\n5. כעת, המעבד פנוי. אלגוריתם התזמון FIFO בוחר את התהליך הראשון בתור ה-Ready, שהוא Child 1. Child 1 רץ.\n6. Child 1 מדפיס \"Child 1 created.\" ויוצא. עם יציאתו, התהליך הראשי (שהיה חסום ב-`wait(NULL)` הראשון) משתחרר ועובר למצב מוכן לריצה. הוא מתווסף לסוף תור ה-Ready. כעת תור ה-Ready הוא: `[Child 2, Parent]`.\n7. המעבד פנוי שוב. אלגוריתם התזמון FIFO בוחר את התהליך הראשון בתור ה-Ready, שהוא Child 2. Child 2 רץ.\n8. Child 2 מדפיס \"Child 2 created.\" ויוצא. כעת, Child 2 הסתיים.\n9. המעבד פנוי שוב. אלגוריתם התזמון FIFO בוחר את התהליך הראשון בתור ה-Ready, שהוא התהליך הראשי. התהליך הראשי רץ.\n10. התהליך הראשי מבצע את ה-`wait(NULL)` השני. מכיוון ש-Child 2 כבר סיים את ריצתו (והוא 'זומבי'), קריאת `wait(NULL)` זו חוזרת מיד, מבלי לחסום את התהליך הראשי.\n11. התהליך הראשי ממשיך, מדפיס \"Parent process finished.\" ויוצא."}, "difficulty_estimation": "Easy", "_source_file": "0775__CPU_Scheduling__CodeAnalysis__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:16:42", "_subject": "Virtualization"}, {"id": 7, "type": "CodeAnalysis", "topic": ["CPU Scheduling", "Processes", "System Calls"], "content": {"text": "נתונה התוכנית הבאה. התוכנית יוצרת מספר תהליכי בן המדמים עבודה על ידי הדפסת הודעות. נתון שהמערכת משתמשת באלגוריתם תזמון FCFS (First-Come, First-Served) ושיש מעבד יחיד. יש להניח שכל קריאות המערכת מצליחות באופן מיידי ושתהליכי הבן נכנסים לתור ה-Ready לפי סדר יצירתם. מה יהיה פלט התוכנית?", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\n// פונקציה שמדמה עבודת תהליך בן\nvoid child_work(int id, int burst_time) {\n    for (int i = 0; i < burst_time; ++i) {\n        printf(\"Process %d - burst %d\\n\", id, i + 1);\n    }\n    exit(0);\n}\n\nint main() {\n    pid_t pids[3]; // מערך לשמירת מזהי תהליכי הבן\n    int burst_times[] = {3, 2, 4}; // זמני ריצה (burst times) עבור תהליכים 1, 2, 3 בהתאמה\n\n    printf(\"Parent process started (PID: %d)\\n\", getpid());\n\n    // יצירת שלושה תהליכי בן\n    for (int i = 0; i < 3; ++i) {\n        pids[i] = fork();\n        if (pids[i] == -1) {\n            perror(\"fork failed\");\n            exit(1);\n        } else if (pids[i] == 0) {\n            // קוד שמבוצע על ידי תהליך הבן\n            child_work(i + 1, burst_times[i]); // תהליך 1, 2, 3\n        }\n    }\n\n    // התהליך האב ממתין לסיום כל תהליכי הבן\n    for (int i = 0; i < 3; ++i) {\n        wait(NULL);\n    }\n\n    printf(\"Parent process finished\\n\");\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון:\nהפלט הצפוי של התוכנית יהיה (ה-PID של התהליך האב ישתנה בין הרצות):\n```\nParent process started (PID: <pid_של_התהליך_האב>)\nProcess 1 - burst 1\nProcess 1 - burst 2\nProcess 1 - burst 3\nProcess 2 - burst 1\nProcess 2 - burst 2\nProcess 3 - burst 1\nProcess 3 - burst 2\nProcess 3 - burst 3\nProcess 3 - burst 4\nParent process finished\n```\nהסבר:\nהתוכנית יוצרת שלושה תהליכי בן בסדר עוקב באמצעות לולאת `for`. תהליך בן 1 נוצר ראשון, אחריו תהליך בן 2, ואז תהליך בן 3.\nבהתאם לנתון, אלגוריתם התזמון הוא FCFS (First-Come, First-Served), וכי תהליכי הבן נכנסים לתור ה-Ready לפי סדר יצירתם. מכיוון שיש מעבד יחיד, כל תהליך יקבל את המעבד ויבצע את כל עבודתו (burst שלו) ברציפות, עד לסיומו, לפני שהמעבד יעבור לתהליך הבא בתור.\n\n1.  **תהליך בן 1 (id=1)** נוצר ראשון עם זמן ריצה של 3 יחידות (הדפסות). הוא ירוץ במלואו וידפיס את 3 ההודעות שלו: \"Process 1 - burst 1\", \"Process 1 - burst 2\", \"Process 1 - burst 3\".\n2.  **תהליך בן 2 (id=2)** נוצר שני עם זמן ריצה של 2 יחידות. הוא ירוץ במלואו לאחר שתהליך 1 סיים, וידפיס את 2 ההודעות שלו: \"Process 2 - burst 1\", \"Process 2 - burst 2\".\n3.  **תהליך בן 3 (id=3)** נוצר שלישי עם זמן ריצה של 4 יחידות. הוא ירוץ במלואו לאחר שתהליך 2 סיים, וידפיס את 4 ההודעות שלו: \"Process 3 - burst 1\", \"Process 3 - burst 2\", \"Process 3 - burst 3\", \"Process 3 - burst 4\".\n\nלאחר שכל תהליכי הבן סיימו את ריצתם, התהליך האב, שהמתין להם באמצעות `wait(NULL)`, ימשיך את ריצתו וידפיס את ההודעה הסופית שלו: \"Parent process finished\". ההודעה הראשונית של האב \"Parent process started (PID: <pid>)\" תודפס מיד עם תחילת ריצת התוכנית."}, "difficulty_estimation": "Easy", "_source_file": "0776__CPU_Scheduling__CodeAnalysis__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:17:01", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["CPU Scheduling", "Threads", "Concurrency"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בחוטים (threads).\nהניחו כי המערכת משתמשת במתזמן (CPU Scheduler) מסוג Round Robin עם קוונטום זמן של 3 יחידות עבודה.\nכל קריאת `printf` בתוכנית מייצגת יחידת עבודה אחת, אלא אם צוין אחרת, ואינה גורמת לחסימה ארוכה.\nזמן יצירת החוטים והכנסתם לתור המוכנים (Ready Queue) הוא כדלקמן:\n- חוט T1 נוצר ראשון. כל איטרציה בלולאה שלו (כולל ה-printf) דורשת יחידת עבודה אחת. סה\"כ 5 איטרציות.\n- חוט T2 נוצר שני. כל איטרציה בלולאה שלו (כולל ה-printf) דורשת 2 יחידות עבודה. סה\"כ 3 איטרציות.\n- חוט T3 נוצר שלישי. כל איטרציה בלולאה שלו (כולל ה-printf) דורשת יחידת עבודה אחת. סה\"כ 4 איטרציות.\nהניחו כי אין תקורה (overhead) למעבר הקשר (context switch).\nכתבו את הפלט המדויק של התוכנית.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nvoid* thread_func_T1(void* arg) {\n    for (int i = 0; i < 5; ++i) {\n        printf(\"T1: %d\\n\", i + 1);\n        // סימולציה של יחידת עבודה אחת\n    }\n    return NULL;\n}\n\nvoid* thread_func_T2(void* arg) {\n    for (int i = 0; i < 3; ++i) {\n        printf(\"T2: %d\\n\", i + 1);\n        // סימולציה של 2 יחידות עבודה\n    }\n    return NULL;\n}\n\nvoid* thread_func_T3(void* arg) {\n    for (int i = 0; i < 4; ++i) {\n        printf(\"T3: %d\\n\", i + 1);\n        // סימולציה של יחידת עבודה אחת\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid[3];\n\n    // יצירת חוטים. נניח שהם נכנסים לתור המוכנים בסדר זה: T1, T2, T3\n    pthread_create(&tid[0], NULL, thread_func_T1, NULL);\n    pthread_create(&tid[1], NULL, thread_func_T2, NULL);\n    pthread_create(&tid[2], NULL, thread_func_T3, NULL);\n\n    pthread_join(tid[0], NULL);\n    pthread_join(tid[1], NULL);\n    pthread_join(tid[2], NULL);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון מבוסס על מעקב אחר ביצוע החוטים לפי מתזמן Round Robin עם קוונטום של 3 יחידות עבודה. סדר הכניסה לתור המוכנים הוא T1, T2, T3.\n\n*   **שלב 1 (זמן 0):** T1 מקבל את המעבד.\n    *   T1 מבצע איטרציה 1 (1 יחידה) - מדפיס \"T1: 1\".\n    *   T1 מבצע איטרציה 2 (1 יחידה) - מדפיס \"T1: 2\".\n    *   T1 מבצע איטרציה 3 (1 יחידה) - מדפיס \"T1: 3\".\n    *   קוונטום T1 נגמר (3 יחידות). T1 עובר לסוף תור המוכנים. תור: [T2, T3, T1].\n\n*   **שלב 2 (זמן 3):** T2 מקבל את המעבד.\n    *   T2 מבצע איטרציה 1 (2 יחידות) - מדפיס \"T2: 1\".\n    *   T2 השתמש ב-2 יחידות מתוך הקוונטום שלו. נותרה לו יחידה אחת בקוונטום הנוכחי.\n    *   קוונטום T2 נגמר (3 יחידות). T2 עובר לסוף תור המוכנים. תור: [T3, T1, T2].\n\n*   **שלב 3 (זמן 6):** T3 מקבל את המעבד.\n    *   T3 מבצע איטרציה 1 (1 יחידה) - מדפיס \"T3: 1\".\n    *   T3 מבצע איטרציה 2 (1 יחידה) - מדפיס \"T3: 2\".\n    *   T3 מבצע איטרציה 3 (1 יחידה) - מדפיס \"T3: 3\".\n    *   קוונטום T3 נגמר (3 יחידות). T3 עובר לסוף תור המוכנים. תור: [T1, T2, T3].\n\n*   **שלב 4 (זמן 9):** T1 מקבל את המעבד.\n    *   T1 מבצע איטרציה 4 (1 יחידה) - מדפיס \"T1: 4\".\n    *   T1 מבצע איטרציה 5 (1 יחידה) - מדפיס \"T1: 5\".\n    *   T1 מסיים את עבודתו (סה\"כ 2 יחידות בקוונטום זה). T1 יוצא מהמערכת. תור: [T2, T3].\n\n*   **שלב 5 (זמן 11):** T2 מקבל את המעבד.\n    *   T2 מבצע איטרציה 2 (2 יחידות) - מדפיס \"T2: 2\".\n    *   T2 השתמש ב-2 יחידות מתוך הקוונטום שלו. נותרה לו יחידה אחת בקוונטום הנוכחי.\n    *   קוונטום T2 נגמר (3 יחידות). T2 עובר לסוף תור המוכנים. תור: [T3, T2].\n\n*   **שלב 6 (זמן 14):** T3 מקבל את המעבד.\n    *   T3 מבצע איטרציה 4 (1 יחידה) - מדפיס \"T3: 4\".\n    *   T3 מסיים את עבודתו (סה\"כ 1 יחידה בקוונטום זה). T3 יוצא מהמערכת. תור: [T2].\n\n*   **שלב 7 (זמן 15):** T2 מקבל את המעבד.\n    *   T2 מבצע איטרציה 3 (2 יחידות) - מדפיס \"T2: 3\".\n    *   T2 מסיים את עבודתו (סה\"כ 2 יחידות בקוונטום זה). T2 יוצא מהמערכת. תור: [].\n\n**פלט סופי:**\nT1: 1\nT1: 2\nT1: 3\nT2: 1\nT3: 1\nT3: 2\nT3: 3\nT1: 4\nT1: 5\nT2: 2\nT3: 4\nT2: 3"}, "difficulty_estimation": "Medium", "_source_file": "0777__CPU_Scheduling__CodeAnalysis__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:17:33", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["CPU Scheduling", "Round Robin"], "content": {"text": "נתונה התוכנית הבאה, המדמה יצירה של שלושה תהליכים (חוטים) המבצעים עבודת מעבד. יש להניח כי כל התהליכים מגיעים למצב Ready בו-זמנית (בזמן 0) וממוקמים בתור ה-Ready לפי סדר יצירתם (A, B, C). זמני הריצה (burst times) של התהליכים הם כדלקמן:\n- תהליך A: 20 יחידות זמן\n- תהליך B: 10 יחידות זמן\n- תהליך C: 30 יחידות זמן\n\nהמערכת משתמשת באלגוריתם תזמון Round Robin עם קוואנטום (quantum) של 10 יחידות זמן. יש להניח שאין תקורה (overhead) על החלפת הקשר (context switch).\n\nמה יהיה סדר ההדפסה של הודעות ה-\"finished\" עבור התהליכים A, B, ו-C? יש לפרט את מצב תור ה-Ready ואת לוח הזמנים של המעבד לאורך הריצה.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n\n// Simulate CPU work\nvoid cpu_burst(int iterations) {\n    volatile int x = 0; // volatile to prevent compiler optimizations\n    for (int i = 0; i < iterations; ++i) {\n        x++;\n    }\n}\n\n// Thread function for Process A\nvoid* process_A(void* arg) {\n    printf(\"Process A started\\n\");\n    cpu_burst(200000000); // Represents ~20 units of time\n    printf(\"Process A finished\\n\");\n    return NULL;\n}\n\n// Thread function for Process B\nvoid* process_B(void* arg) {\n    printf(\"Process B started\\n\");\n    cpu_burst(100000000); // Represents ~10 units of time\n    printf(\"Process B finished\\n\");\n    return NULL;\n}\n\n// Thread function for Process C\nvoid* process_C(void* arg) {\n    printf(\"Process C started\\n\");\n    cpu_burst(300000000); // Represents ~30 units of time\n    printf(\"Process C finished\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid_A, tid_B, tid_C;\n\n    // Create threads (assume they become ready almost simultaneously)\n    pthread_create(&tid_A, NULL, process_A, NULL);\n    pthread_create(&tid_B, NULL, process_B, NULL);\n    pthread_create(&tid_C, NULL, process_C, NULL);\n\n    // Wait for threads to finish\n    pthread_join(tid_A, NULL);\n    pthread_join(tid_B, NULL);\n    pthread_join(tid_C, NULL);\n\n    printf(\"Main finished\\n\");\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "האלגוריתם Round Robin מבצע ריצה של כל תהליך בתור ה-Ready למשך יחידות זמן של הקוואנטום (10 יחידות), או עד לסיום ה-burst שלו, המוקדם מביניהם. תהליכים שלא סיימו חוזרים לסוף תור ה-Ready.\n\nנתונים:\n- תהליך A: 20 יחידות זמן\n- תהליך B: 10 יחידות זמן\n- תהליך C: 30 יחידות זמן\n- קוואנטום: 10 יחידות זמן\n- הגעה: כל התהליכים בזמן 0.\n- תור Ready ראשוני: [A, B, C]\n\nמעקב אחר הריצה:\n1.  **זמן 0-10:** תהליך A רץ.\n    -   A נותר: 10 יחידות.\n    -   תור Ready: [B, C, A] (A עובר לסוף התור)\n2.  **זמן 10-20:** תהליך B רץ (מסיים את ה-burst שלו, שהוא 10 יחידות).\n    -   B נותר: 0 יחידות. **B מסיים.**\n    -   **פלט:** \"Process B finished\"\n    -   תור Ready: [C, A]\n3.  **זמן 20-30:** תהליך C רץ.\n    -   C נותר: 20 יחידות.\n    -   תור Ready: [A, C] (C עובר לסוף התור)\n4.  **זמן 30-40:** תהליך A רץ (מסיים את ה-burst שלו, שהוא 10 יחידות).\n    -   A נותר: 0 יחידות. **A מסיים.**\n    -   **פלט:** \"Process A finished\"\n    -   תור Ready: [C]\n5.  **זמן 40-50:** תהליך C רץ.\n    -   C נותר: 10 יחידות.\n    -   תור Ready: [C] (C עובר לסוף התור)\n6.  **זמן 50-60:** תהליך C רץ (מסיים את ה-burst שלו, שהוא 10 יחידות).\n    -   C נותר: 0 יחידות. **C מסיים.**\n    -   **פלט:** \"Process C finished\"\n    -   תור Ready: []\n\nסדר ההדפסה הסופי של הודעות ה-\"finished\" יהיה: B, A, C."}, "difficulty_estimation": "Medium", "_source_file": "0778__CPU_Scheduling__CodeAnalysis__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:17:54", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["CPU Scheduling", "Round Robin", "Context Switching"], "content": {"text": "נתונה קבוצת תהליכים שיש לבצע על מעבד בודד, ומוצגת להלן. המעבד משתמש באלגוריתם תזמון Round Robin (RR) עם קוונטום זמן (time quantum) של 2 יחידות זמן. עלות החלפת קשר (context switch) היא 1 יחידת זמן.\nבהנחה שהתהליכים מתווספים לתור המוכנים (Ready Queue) לפי סדר הגעתם ובמקרה של הגעה בו-זמנית, לפי סדר הופעתם במערך (A, B, C). המעבד תמיד בוחר את התהליך הבא מחזית התור המוכנים. תהליך שהופסק בגלל תום הקוונטום מועבר לסוף התור המוכנים.\nמהו סדר הרצת התהליכים על המעבד (ללא ציון זמני החלפת קשר) עד להשלמת כל התהליכים?", "code_snippet": "typedef struct Process {\n    char id;\n    int arrival_time;\n    int burst_time;\n} Process;\n\nProcess processes[] = {\n    {'A', 0, 5},\n    {'B', 1, 3},\n    {'C', 3, 4}\n};\nint num_processes = sizeof(processes) / sizeof(Process);", "options": ["א. A, A, B, C, A, B, C", "ב. A, B, C, A, B, C, A", "ג. A, B, A, C, B, A, C", "ד. A, B, C, A, C, B, A"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "נבצע מעקב אחר הרצת התהליכים צעד אחר צעד:\n- **זמן 0:** תהליך A מגיע (זמן הגעה 0, זמן ריצה 5). תור המוכנים: [A]. A מתחיל לרוץ.\n- **זמן 0-2:** A רץ (2 יחידות זמן, קוונטום ראשון). ל-A נותרו 3 יחידות זמן.\n- **זמן 2:** קוונטום של A הסתיים. A מועבר לסוף תור המוכנים: [A]. מתבצעת החלפת קשר (עלות 1 יחידת זמן).\n- **זמן 2-3:** המעבד במצב סרק (החלפת קשר).\n- **זמן 3:** תהליכים B (זמן הגעה 1, זמן ריצה 3) ו-C (זמן הגעה 3, זמן ריצה 4) מגיעים. B ו-C מתווספים לתור המוכנים לפי סדר הגעתם. תור המוכנים: [A, B, C]. המעבד בוחר את A (מראש התור). A מתחיל לרוץ.\n- **זמן 3-5:** A רץ (2 יחידות זמן, קוונטום שני). ל-A נותרה 1 יחידת זמן.\n- **זמן 5:** קוונטום של A הסתיים. A מועבר לסוף תור המוכנים: [B, C, A]. מתבצעת החלפת קשר.\n- **זמן 5-6:** המעבד במצב סרק (החלפת קשר).\n- **זמן 6:** המעבד בוחר את B (מראש התור). B מתחיל לרוץ.\n- **זמן 6-8:** B רץ (2 יחידות זמן, קוונטום ראשון). ל-B נותרה 1 יחידת זמן.\n- **זמן 8:** קוונטום של B הסתיים. B מועבר לסוף תור המוכנים: [C, A, B]. מתבצעת החלפת קשר.\n- **זמן 8-9:** המעבד במצב סרק (החלפת קשר).\n- **זמן 9:** המעבד בוחר את C (מראש התור). C מתחיל לרוץ.\n- **זמן 9-11:** C רץ (2 יחידות זמן, קוונטום ראשון). ל-C נותרו 2 יחידות זמן.\n- **זמן 11:** קוונטום של C הסתיים. C מועבר לסוף תור המוכנים: [A, B, C]. מתבצעת החלפת קשר.\n- **זמן 11-12:** המעבד במצב סרק (החלפת קשר).\n- **זמן 12:** המעבד בוחר את A (מראש התור). A מתחיל לרוץ.\n- **זמן 12-13:** A רץ (1 יחידת זמן, זמן ריצה שנותר). A מסתיים.\n- **זמן 13:** A הסתיים. מתבצעת החלפת קשר. תור המוכנים: [B, C].\n- **זמן 13-14:** המעבד במצב סרק (החלפת קשר).\n- **זמן 14:** המעבד בוחר את B (מראש התור). B מתחיל לרוץ.\n- **זמן 14-15:** B רץ (1 יחידת זמן, זמן ריצה שנותר). B מסתיים.\n- **זמן 15:** B הסתיים. מתבצעת החלפת קשר. תור המוכנים: [C].\n- **זמן 15-16:** המעבד במצב סרק (החלפת קשר).\n- **זמן 16:** המעבד בוחר את C (מראש התור). C מתחיל לרוץ.\n- **זמן 16-18:** C רץ (2 יחידות זמן, זמן ריצה שנותר). C מסתיים.\n- **זמן 18:** C הסתיים. כל התהליכים הסתיימו.\n\nסדר הרצת התהליכים על המעבד (ללא זמני החלפת קשר): A, A, B, C, A, B, C.\nלכן, התשובה הנכונה היא א'."}, "difficulty_estimation": "Medium", "_source_file": "0779__CPU_Scheduling__CodeAnalysis__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:18:33", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["CPU Scheduling"], "content": {"text": "נתונה התוכנית הבאה, המדמה פעולת מתזמן מעבד (CPU Scheduler) פשוט. המתזמן פועל בשיטת תעדוף מונעת (Preemptive Priority), כאשר מספר גבוה יותר מציין עדיפות גבוהה יותר. במקרה של שוויון בעדיפות, המתזמן יבחר בתהליך בעל ה-PID הנמוך יותר (First Come, First Served - FCFS, אם כי במקרה זה ה-PID הוא קריטריון שבירת שוויון קבוע). כל יחידת זמן (time unit) מייצגת ריצה של יחידת זמן אחת עבור התהליך הנבחר. יש להניח שכל התהליכים מגיעים בזמן 0.\n\nכמה החלפות הקשר (context switches) יתרחשו במהלך ריצת התוכנית, מרגע התחלת הריצה ועד שכל התהליכים יסיימו?", "code_snippet": "#include <stdio.h>\n#include <stdbool.h>\n\n// Represents a simplified Process Control Block (PCB)\ntypedef struct {\n    int pid;\n    int burst_time;\n    int priority; // Higher number = higher priority\n    int remaining_time;\n} PCB;\n\n// Global variables simulating current running process state\nint current_running_pid = -1;\nint context_switches_count = 0;\n\n// Simulates a scheduler's decision for one time unit\n// Assumes all processes arrive at time 0.\nvoid schedule_and_run_unit(PCB processes[], int num_processes) {\n    int chosen_idx = -1;\n    int highest_priority_found = -1;\n\n    // Find the highest priority ready process\n    for (int i = 0; i < num_processes; ++i) {\n        if (processes[i].remaining_time > 0) { // Process is not finished\n            if (chosen_idx == -1 || // First ready process found\n                processes[i].priority > highest_priority_found ||\n                (processes[i].priority == highest_priority_found && processes[i].pid < processes[chosen_idx].pid)) { // Tie-breaking: lower PID\n                \nhighest_priority_found = processes[i].priority;\n                chosen_idx = i;\n            }\n        }\n    }\n\n    if (chosen_idx != -1) {\n        if (processes[chosen_idx].pid != current_running_pid) {\n            // Context switch occurred\n            if (current_running_pid != -1) { // Only count if there was a previous process running\n                context_switches_count++;\n            }\n            current_running_pid = processes[chosen_idx].pid;\n        }\n        processes[chosen_idx].remaining_time--; // Run for one unit\n    }\n}\n\nint main() {\n    PCB processes[3] = {\n        {.pid = 1, .burst_time = 5, .priority = 2, .remaining_time = 5}, \n        {.pid = 2, .burst_time = 3, .priority = 3, .remaining_time = 3},\n        {.pid = 3, .burst_time = 4, .priority = 1, .remaining_time = 4}\n    };\n    int num_processes = 3;\n\n    int total_finished_processes = 0;\n    while (total_finished_processes < num_processes) {\n        schedule_and_run_unit(processes, num_processes);\n\n        total_finished_processes = 0;\n        for (int i = 0; i < num_processes; ++i) {\n            if (processes[i].remaining_time == 0) {\n                total_finished_processes++;\n            }\n        }\n    }\n    return 0;\n}", "options": ["א. 0", "ב. 1", "ג. 2", "ד. 3", "ה. 4"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "במהלך ריצת התוכנית, המתזמן בוחר תמיד בתהליך עם העדיפות הגבוהה ביותר מבין התהליכים שטרם סיימו. במקרה של שוויון בעדיפות, נבחר תהליך בעל ה-PID הנמוך יותר. אנו סופרים החלפת הקשר כאשר ה-PID של התהליך הנבחר לריצה שונה מה-PID של התהליך שרץ ביחידת הזמן הקודמת, למעט הבחירה הראשונה של תהליך (ממצב של אף תהליך לא רץ).\n\nלהלן מעקב אחר הריצה:\n- תהליכים: P1 (PID=1, Burst=5, Priority=2), P2 (PID=2, Burst=3, Priority=3), P3 (PID=3, Burst=4, Priority=1).\n- מצב התחלתי: current_running_pid = -1, context_switches_count = 0.\n\n1.  **יחידות זמן 1-3:** P2 בעל העדיפות הגבוהה ביותר (3).\n    *   ביחידת זמן 1, P2 נבחר. current_running_pid משתנה מ-1 ל-2. זו הבחירה הראשונה, לא נספרת כהחלפת קשר.\n    *   ביחידות זמן 2-3, P2 ממשיך לרוץ. אין החלפת קשר. P2 מסיים ביחידת זמן 3.\n    *   בסיום: P2 סיים. current_running_pid = 2, context_switches_count = 0.\n\n2.  **יחידות זמן 4-8:** P1 (Priority=2) ו-P3 (Priority=1) נותרו. P1 בעל העדיפות הגבוהה יותר.\n    *   ביחידת זמן 4, P1 נבחר. current_running_pid משתנה מ-2 ל-1. **נספרת החלפת הקשר הראשונה (1).**\n    *   ביחידות זמן 5-8, P1 ממשיך לרוץ. אין החלפת קשר. P1 מסיים ביחידת זמן 8.\n    *   בסיום: P1 סיים. current_running_pid = 1, context_switches_count = 1.\n\n3.  **יחידות זמן 9-12:** P3 (Priority=1) נותר.\n    *   ביחידת זמן 9, P3 נבחר. current_running_pid משתנה מ-1 ל-3. **נספרת החלפת הקשר השנייה (2).**\n    *   ביחידות זמן 10-12, P3 ממשיך לרוץ. אין החלפת קשר. P3 מסיים ביחידת זמן 12.\n    *   בסיום: P3 סיים. current_running_pid = 3, context_switches_count = 2.\n\nסה\"כ החלפות הקשר: 2."}, "difficulty_estimation": "Medium", "_source_file": "0780__CPU_Scheduling__CodeAnalysis__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:19:13", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["CPU Scheduling", "Threads", "Concurrency"], "content": {"text": "נתונה תוכנית C הבאה המשתמשת בחוטים (threads). התוכנית רצה על מערכת הפעלה המשתמשת במתזמן (scheduler) מסוג Round Robin עם קוואנטום זמן קבוע וקטן יחסית (כלומר, חוט יכול להיקטע במהלך ביצוע לולאת העבודה הפנימית). הניחו שקריאות printf מתבצעות אטומית (כלומר, הדפסת שורה שלמה לא תיקטע), אך המתזמן יכול להחליף חוטים בכל נקודה אחרת. כתבו את כל הפלטים האפשריים של התוכנית. נמקו את תשובתכם.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n\nvoid *thread_func(void *arg) {\n    int id = *(int*)arg;\n    for (int i = 0; i < 3; ++i) {\n        printf(\"Thread %d executing iteration %d\\n\", id, i);\n        // Simulate work (busy-wait)\n        for (long j = 0; j < 10000000; ++j);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n    int id1 = 1;\n    int id2 = 2;\n\n    pthread_create(&tid1, NULL, thread_func, &id1);\n    pthread_create(&tid2, NULL, thread_func, &id2);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "המתזמן מסוג Round Robin הוא מתזמן פרמפטיבי (preemptive), כלומר, הוא יכול להחליף חוטים בכל עת לאחר שפג קוואנטום הזמן שלהם, או אם חוט נחסם (במקרה זה, החוטים מבצעים עבודה בלולאה ארוכה, כך שסביר שיוחלפו עקב פקיעת קוואנטום). כתוצאה מכך, סדר ההדפסה בין החוטים יכול להשתנות באופן משמעותי. עם זאת, בתוך כל חוט, סדר ההדפסות נשמר: חוט 1 תמיד ידפיס 'Thread 1 executing iteration 0', ואז 'Thread 1 executing iteration 1', ואז 'Thread 1 executing iteration 2'. וכך גם עבור חוט 2. מכיוון שקריאות printf אטומיות, כל שורת פלט תודפס בשלמותה. לכן, כל פלט אפשרי יהיה מורכב משש שורות, כאשר שלוש מהן שייכות לחוט 1 בסדר עולה של איטרציות, ושלוש שייכות לחוט 2 בסדר עולה של איטרציות, וסדר הופעת השורות משני החוטים יכול להיות משולב בכל צורה אפשרית. לדוגמה, פלטים אפשריים:\n1.\nThread 1 executing iteration 0\nThread 1 executing iteration 1\nThread 1 executing iteration 2\nThread 2 executing iteration 0\nThread 2 executing iteration 1\nThread 2 executing iteration 2\n2.\nThread 2 executing iteration 0\nThread 2 executing iteration 1\nThread 2 executing iteration 2\nThread 1 executing iteration 0\nThread 1 executing iteration 1\nThread 1 executing iteration 2\n3.\nThread 1 executing iteration 0\nThread 2 executing iteration 0\nThread 1 executing iteration 1\nThread 2 executing iteration 1\nThread 1 executing iteration 2\nThread 2 executing iteration 2\nועוד שילובים רבים אחרים, כל עוד הסדר הפנימי של ההדפסות לכל חוט נשמר."}, "difficulty_estimation": "Medium", "_source_file": "0781__CPU_Scheduling__CodeAnalysis__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:19:28", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["CPU Scheduling", "Concurrency", "Threads"], "content": {"text": "נתונה התוכנית הבאה. הניחו שהתוכנית רצה על מעבד יחיד (single-core CPU) ומשתמשת במתזמן (scheduler) מונע-פקודות (preemptive) מסוג Round Robin עם קוונטום זמן קצר. כל קריאות ה-`printf` נדפסות מיידית.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For usleep or sleep\n\nvolatile int shared_flag = 0; // Shared flag\n\nvoid* thread_A_func(void* arg) {\n    printf(\"Thread A: Starting heavy computation...\\n\");\n    for (long i = 0; i < 500000000; ++i) { // Simulate heavy computation\n        // Busy loop\n    }\n    shared_flag = 1; // Signal that A has finished its main work\n    printf(\"Thread A: Computation finished, flag set.\\n\");\n    return NULL;\n}\n\nvoid* thread_B_func(void* arg) {\n    printf(\"Thread B: Waiting for flag from A...\\n\");\n    while (shared_flag == 0) {\n        // Busy-wait loop\n        // This loop consumes CPU cycles\n    }\n    printf(\"Thread B: Flag detected, proceeding.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid_A, tid_B;\n\n    printf(\"Main: Creating threads...\\n\");\n    pthread_create(&tid_B, NULL, thread_B_func, NULL); // Create B first\n    pthread_create(&tid_A, NULL, thread_A_func, NULL); // Then A\n\n    pthread_join(tid_A, NULL);\n    pthread_join(tid_B, NULL);\n\n    printf(\"Main: All threads finished.\\n\");\n    return 0;\n}"}, "sub_questions": [{"id": "8.1", "text": "תארו את סדר ההדפסות האפשרי של התוכנית. הסבירו מדוע ייתכנו סדרי הדפסה שונים, וציינו לפחות שני סדרים אפשריים.", "code_snippet": null, "options": null}, {"id": "8.2", "text": "הסבירו מדוע השימוש בלולאת ה-`while (shared_flag == 0)` ב-`thread_B_func` אינו יעיל מבחינת ניצול מעבד, וכיצד הוא משפיע על זמן הריצה הכולל של התוכנית. הציעו דרך יעילה יותר לממש את ההמתנה ב-`thread_B_func`.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "פתרון לשאלה 8.1:\nקריאות ה-`printf` שאינן תלויות ב-`shared_flag` יתרחשו בדרך כלל בהתחלה ובסוף. סדר יצירת ה-threads משפיע על הסדר שבו הם נכנסים ל-ready queue, אך המתזמן יכול להחליט לתזמן כל אחד מהם. לכן: \n1. `Main: Creating threads...` תמיד יודפס ראשון.\n2. `Thread B: Waiting for flag from A...` ו-`Thread A: Starting heavy computation...` יכולים להופיע בסדרים שונים, תלוי בתזמון הראשוני של A ו-B. מכיוון ש-B נוצר ראשון, ייתכן שיתחיל ראשון וידפיס את הודעת ההמתנה שלו. אך אם A מתחיל מיד אחריו, הוא ידפיס את ההודעה שלו. \n3. לאחר ש-A יסיים את החישוב הכבד ויקבע את `shared_flag` ל-1, ורק לאחר מכן, `Thread A: Computation finished, flag set.` יודפס.\n4. לבסוף, כאשר B יתזמן שוב ויגלה ש-`shared_flag` הוא 1, הוא ידפיס `Thread B: Flag detected, proceeding.`. סדר ההדפסה של הודעה זו ביחס להדפסה הסופית של A תלוי שוב בתזמון. יש לציין ש-A קובע את הדגל *לפני* שהוא מדפיס את הודעת הסיום שלו. לכן, B יכול להתחיל את ההדפסה שלו *לאחר* שהדגל נקבע, אך *לפני* ש-A מדפיס את הודעת הסיום שלו, אם המתזמן מחליט לתת ל-B לרוץ בדיוק אחרי ש-A קבע את הדגל ולפני ש-A קרא ל-printf.\n5. `Main: All threads finished.` יודפס אחרון, רק לאחר ששני ה-threads סיימו וה-`main` ביצע `pthread_join` עבור שניהם.\n\nדוגמאות לסדרי הדפסה אפשריים:\nא. `Main: Creating threads...`\n   `Thread B: Waiting for flag from A...`\n   `Thread A: Starting heavy computation...`\n   (המתזמן מעביר בין A ל-B במשך החישוב של A)\n   `Thread A: Computation finished, flag set.`\n   `Thread B: Flag detected, proceeding.`\n   `Main: All threads finished.`\n\nב. `Main: Creating threads...`\n   `Thread A: Starting heavy computation...`\n   `Thread B: Waiting for flag from A...`\n   (המתזמן מעביר בין A ל-B במשך החישוב של A)\n   `Thread A: Computation finished, flag set.`\n   `Thread B: Flag detected, proceeding.`\n   `Main: All threads finished.`\n\nפתרון לשאלה 8.2:\nהשימוש בלולאת ה-`while (shared_flag == 0)` ב-`thread_B_func` הוא דוגמה ל-\"busy-waiting\" (המתנה פעילה). הוא אינו יעיל מכיוון ש-`thread_B` צורך זמן מעבד יקר (CPU cycles) על ידי בדיקה חוזרת ונשנית של המשתנה `shared_flag` בלולאה, במקום להיכנס למצב המתנה (blocked state) ולפנות את המעבד ל-`thread_A` או ל-threads אחרים. במערכת חד-מעבדית (single-core), זה אומר ש-`thread_B` למעשה גונב זמן מעבד מ-`thread_A`, מה שמאריך את הזמן שלוקח ל-`thread_A` לסיים את החישוב הכבד שלו ולקבוע את הדגל. כתוצאה מכך, זמן הריצה הכולל של התוכנית יהיה ארוך יותר באופן משמעותי מאשר אם `thread_B` היה ממתין באופן חוסם. למעשה, במצב של busy-waiting, שני ה-threads מתחרים על המעבד, כאשר אחד (B) לא מבצע עבודה שימושית.\n\nדרך יעילה יותר לממש את ההמתנה ב-`thread_B_func` היא באמצעות מנגנוני סנכרון חוסמים, כגון mutex ו-condition variable. לדוגמה:\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n\npthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;\npthread_cond_t cond = PTHREAD_COND_INITIALIZER;\nvolatile int shared_flag = 0;\n\nvoid* thread_A_func(void* arg) {\n    printf(\"Thread A: Starting heavy computation...\\n\");\n    for (long i = 0; i < 500000000; ++i) {\n        // Busy loop\n    }\n    \n    pthread_mutex_lock(&mutex);\n    shared_flag = 1; // Signal that A has finished its main work\n    pthread_cond_signal(&cond); // Wake up waiting threads\n    pthread_mutex_unlock(&mutex);\n    \n    printf(\"Thread A: Computation finished, flag set.\\n\");\n    return NULL;\n}\n\nvoid* thread_B_func(void* arg) {\n    printf(\"Thread B: Waiting for flag from A...\\n\");\n    \n    pthread_mutex_lock(&mutex);\n    while (shared_flag == 0) {\n        pthread_cond_wait(&cond, &mutex); // Wait efficiently\n    }\n    pthread_mutex_unlock(&mutex);\n    \n    printf(\"Thread B: Flag detected, proceeding.\\n\");\n    return NULL;\n}\n\n// main function remains largely the same\n```\n\nבפתרון זה, `thread_B` נכנס למצב המתנה (blocked) כאשר הוא קורא ל-`pthread_cond_wait`, ובכך מפנה את המעבד ל-`thread_A` (או ל-threads אחרים). `thread_A` מעיר את `thread_B` רק כאשר הוא מסיים את עבודתו וקובע את הדגל, באמצעות `pthread_cond_signal`. זה מאפשר ניצול יעיל יותר של המעבד וקיצור זמן הריצה הכולל של התוכנית."}, "difficulty_estimation": "Medium", "_source_file": "0782__CPU_Scheduling__CodeAnalysis__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:20:07", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["CPU Scheduling", "Round Robin", "Concurrency"], "content": {"text": "נתונה התוכנית הבאה בשפת C++ המשתמשת בחוטים (threads). התוכנית יוצרת שלושה חוטים, כאשר כל חוט מבצע לולאת busy-wait המדמה עבודה של מעבד, ולאחר מכן מגדיל מונה גלובלי משותף ומדפיס את מזהה החוט ואת ערך המונה. המערכת מריצה את התוכנית באמצעות מתזמן מעבד מסוג **Round Robin (RR)** עם **קוואנטום (quantum) של 4 יחידות זמן**. יש להניח כי כל 100,000 איטרציות בלולאת ה-busy-wait שוות ליחידת זמן אחת. כל החוטים נוצרים ומוכנים לריצה בזמן 0, והמתזמן יבחר אותם בסדר יצירתם (tA, tB, tC) בפעם הראשונה. פעולת ההדפסה `std::cout` נחשבת כפעולה מהירה שאינה צורכת זמן מעבד משמעותי ואינה גורמת להחלפת הקשר (context switch) נוספת.\n\nמהו הפלט המדויק של התוכנית ל-`std::cout` (כולל הודעת ה-`Main`) ומהו הערך הסופי של המונה הגלובלי `global_counter`?\nיש להסביר את שלבי הריצה המלאים של המתזמן.", "code_snippet": "#include <iostream>\n#include <thread>\n#include <vector>\n#include <chrono> \n\n// Global shared counter\nint global_counter = 0;\n\n// Busy-wait function to simulate CPU burst\nvoid busy_wait(int iterations) {\n    volatile int dummy = 0; // volatile to prevent optimization\n    for (int i = 0; i < iterations; ++i) {\n        dummy++;\n    }\n}\n\n// Thread function for A (10 units of work)\nvoid thread_func_A() {\n    busy_wait(1000000); \n    global_counter++;\n    std::cout << \"A: \" << global_counter << std::endl;\n}\n\n// Thread function for B (5 units of work)\nvoid thread_func_B() {\n    busy_wait(500000); \n    global_counter++;\n    std::cout << \"B: \" << global_counter << std::endl;\n}\n\n// Thread function for C (15 units of work)\nvoid thread_func_C() {\n    busy_wait(1500000); \n    global_counter++;\n    std::cout << \"C: \" << global_counter << std::endl;\n}\n\nint main() {\n    std::cout << \"Main: Starting threads...\" << std::endl;\n    std::thread tA(thread_func_A);\n    std::thread tB(thread_func_B);\n    std::thread tC(thread_func_C);\n\n    tA.join();\n    tB.join();\n    tC.join();\n\n    std::cout << \"Main: Final counter value: \" << global_counter << std::endl;\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון דורש מעקב אחר מצב המתזמן (Round Robin) וזמני הריצה של כל חוט.\n\n**נתונים:**\n*   זמן עבודה של חוט A: 1000000 איטרציות = 10 יחידות זמן.\n*   זמן עבודה של חוט B: 500000 איטרציות = 5 יחידות זמן.\n*   זמן עבודה של חוט C: 1500000 איטרציות = 15 יחידות זמן.\n*   קוואנטום (Q) = 4 יחידות זמן.\n*   תור מוכנים התחלתי (על פי סדר יצירה): [A, B, C]\n\n**שלבי הריצה:**\n1.  **זמן 0:** המתזמן בוחר את **A**. A רץ למשך 4 יחידות זמן.\n    *   A נשאר: 10 - 4 = 6 יחידות.\n    *   תור מוכנים: [B, C, A]\n2.  המתזמן בוחר את **B**. B רץ למשך 4 יחידות זמן.\n    *   B נשאר: 5 - 4 = 1 יחידה.\n    *   תור מוכנים: [C, A, B]\n3.  המתזמן בוחר את **C**. C רץ למשך 4 יחידות זמן.\n    *   C נשאר: 15 - 4 = 11 יחידות.\n    *   תור מוכנים: [A, B, C]\n4.  המתזמן בוחר את **A**. A רץ למשך 4 יחידות זמן.\n    *   A נשאר: 6 - 4 = 2 יחידות.\n    *   תור מוכנים: [B, C, A]\n5.  המתזמן בוחר את **B**. B רץ למשך יחידה אחת (עד השלמה).\n    *   B נשאר: 1 - 1 = 0 יחידות. **B מסיים.**\n    *   `global_counter` הופך ל-1. **פלט:** `B: 1`\n    *   תור מוכנים: [C, A]\n6.  המתזמן בוחר את **C**. C רץ למשך 4 יחידות זמן.\n    *   C נשאר: 11 - 4 = 7 יחידות.\n    *   תור מוכנים: [A, C]\n7.  המתזמן בוחר את **A**. A רץ למשך 2 יחידות זמן (עד השלמה).\n    *   A נשאר: 2 - 2 = 0 יחידות. **A מסיים.**\n    *   `global_counter` הופך ל-2. **פלט:** `A: 2`\n    *   תור מוכנים: [C]\n8.  המתזמן בוחר את **C**. C רץ למשך 4 יחידות זמן.\n    *   C נשאר: 7 - 4 = 3 יחידות.\n    *   תור מוכנים: [C] (C חוזר לסוף התור, אך הוא היחיד)\n9.  המתזמן בוחר את **C**. C רץ למשך 3 יחידות זמן (עד השלמה).\n    *   C נשאר: 3 - 3 = 0 יחידות. **C מסיים.**\n    *   `global_counter` הופך ל-3. **פלט:** `C: 3`\n    *   תור מוכנים: []\n\n**פלט מלא:**\nMain: Starting threads...\nB: 1\nA: 2\nC: 3\nMain: Final counter value: 3", "code_snippet": null}, "difficulty_estimation": "Medium", "_source_file": "0783__CPU_Scheduling__CodeAnalysis__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:20:38", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["CPU Scheduling", "Processes", "System Calls"], "content": {"text": "נתונה התוכנית הבאה, המורצת על מערכת הפעלה מבוססת לינוקס המשתמשת בתזמון מעבד מונע-עדיפויות (preemptive priority-based scheduling). ערך `nice` נמוך יותר מציין עדיפות גבוהה יותר (כאשר ערך ברירת המחדל הוא 0). יש להניח כי המערכת תמיד מעדיפה תהליכים בעלי עדיפות גבוהה יותר, וכי קריאות המערכת `usleep` מאפשרות החלפת הקשרים (context switches) באופן מיידי.\nמהו הפלט הסביר ביותר של התוכנית? נמק את תשובתך באופן מפורט.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <sys/resource.h> // For nice() and getpriority()\n\nint main() {\n    pid_t pid1, pid2;\n\n    printf(\"Parent (PID: %d) starts.\\n\", getpid());\n\n    pid1 = fork();\n    if (pid1 == 0) { // Child 1\n        // Child 1 inherits parent's nice (0) initially\n        nice(10); // Set lower priority for Child 1\n        printf(\"Child 1 (PID: %d, nice: %d) created, parent PID: %d.\\n\", getpid(), getpriority(PRIO_PROCESS, 0), getppid());\n        for (int i = 0; i < 2; ++i) {\n            printf(\"Child 1 (PID: %d) working %d.\\n\", getpid(), i);\n            usleep(50000); // Simulate some work\n        }\n        printf(\"Child 1 (PID: %d) exits.\\n\", getpid());\n        return 0;\n    }\n\n    // Parent continues after forking Child 1\n    pid2 = fork();\n    if (pid2 == 0) { // Child 2\n        // Child 2 inherits parent's nice (0) initially\n        nice(-5); // Set higher priority for Child 2\n        printf(\"Child 2 (PID: %d, nice: %d) created, parent PID: %d.\\n\", getpid(), getpriority(PRIO_PROCESS, 0), getppid());\n        for (int i = 0; i < 2; ++i) {\n            printf(\"Child 2 (PID: %d) working %d.\\n\", getpid(), i);\n            usleep(50000); // Simulate some work\n        }\n        printf(\"Child 2 (PID: %d) exits.\\n\", getpid());\n        return 0;\n    }\n\n    // Parent continues after forking Child 2\n    printf(\"Parent (PID: %d, nice: %d) processing.\\n\", getpid(), getpriority(PRIO_PROCESS, 0));\n    for (int i = 0; i < 1; ++i) { // Parent does less work\n        printf(\"Parent (PID: %d) working %d.\\n\", getpid(), i);\n        usleep(50000); // Simulate some work\n    }\n\n    waitpid(pid1, NULL, 0); // Wait for Child 1\n    waitpid(pid2, NULL, 0); // Wait for Child 2\n    printf(\"Parent (PID: %d) exits.\\n\", getpid());\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכנית יוצרת שלושה תהליכים: תהליך אב ושני תהליכי בנים (בן 1 ובן 2).\n1.  **תהליך האב (Parent)**: מתחיל עם עדיפות ברירת מחדל (nice 0). הוא יוצר את בן 1 ואז את בן 2. לאחר מכן, הוא מבצע מעט עבודה (לולאה אחת) ולבסוף ממתין לשני בניו לפני שהוא מסיים.\n2.  **תהליך בן 1 (Child 1)**: נוצר עם עדיפות ברירת מחדל (nice 0), אך מיד משנה את עדיפותו ל-nice 10. זוהי העדיפות הנמוכה ביותר מבין שלושת התהליכים.\n3.  **תהליך בן 2 (Child 2)**: נוצר גם הוא עם עדיפות ברירת מחדל (nice 0), אך מיד משנה את עדיפותו ל-nice -5. זוהי העדיפות הגבוהה ביותר מבין שלושת התהליכים.\n\nמכיוון שמערכת ההפעלה משתמשת בתזמון מונע-עדיפויות (preemptive priority-based scheduling), תהליכים בעלי ערך `nice` נמוך יותר (כלומר עדיפות גבוהה יותר) יקבלו את המעבד. קריאות `usleep` גורמות לתהליכים לוותר על המעבד, מה שמאפשר למתזמן להפעיל תהליכים בעלי עדיפות גבוהה יותר.\n\nהסדר הצפוי של קבלת המעבד וסיום העבודה הוא:\n1.  **Child 2 (nice -5)**: יקבל את המעבד ראשון וישלים את עבודתו (שתי איטרציות).\n2.  **Parent (nice 0)**: יקבל את המעבד לאחר ש-Child 2 יסיים את עבודתו, וישלים את עבודתו שלו (איטרציה אחת).\n3.  **Child 1 (nice 10)**: יקבל את המעבד רק לאחר ש-Child 2 וה-Parent יסיימו את עבודתם, ויסיים אחרון.\n\nהפלט הסביר ביותר של התוכנית (מספרי ה-PID ישתנו בכל הרצה):\n```\nParent (PID: X) starts.\nChild 1 (PID: Y, nice: 10) created, parent PID: X.\nChild 2 (PID: Z, nice: -5) created, parent PID: X.\nParent (PID: X, nice: 0) processing.\nChild 2 (PID: Z) working 0.\nChild 2 (PID: Z) working 1.\nChild 2 (PID: Z) exits.\nParent (PID: X) working 0.\nParent (PID: X) exits.\nChild 1 (PID: Y) working 0.\nChild 1 (PID: Y) working 1.\nChild 1 (PID: Y) exits.\n```\n\n**נימוק לסדר הפלט:**\n*   הודעות ה-'starts', 'created' ו-'processing' הראשוניות יכולות להופיע בסדר מעט שונה, מכיוון שהן מבוצעות מיד לאחר ה-fork, לפני שקריאות ה-`nice()` משפיעות באופן מלא על התזמון. עם זאת, ברגע שהעדיפויות נקבעו, המתזמן יעדיף באופן עקבי את Child 2.\n*   Child 2, עם העדיפות הגבוהה ביותר (nice -5), יבצע את שתי איטרציות העבודה שלו ויסיים ראשון, ולכן הודעת ה-'Child 2 exits' תופיע לפני הודעות ה-'exits' של האחרים.\n*   ה-Parent, עם עדיפות בינונית (nice 0), יבצע את איטרציית העבודה שלו לאחר ש-Child 2 יסיים את מרבית עבודתו. הוא ימתין לבניו באמצעות `waitpid`, אך מכיוון ש-Child 2 מסיים ראשון, ה-Parent יתחיל להמתין בעיקר ל-Child 1. הודעת ה-'Parent exits' תופיע לאחר סיום עבודת ה-Parent ולפני סיום עבודת Child 1.\n*   Child 1, עם העדיפות הנמוכה ביותר (nice 10), יקבל את המעבד רק לאחר שהתהליכים בעלי העדיפות הגבוהה יותר (Child 2 וה-Parent) יסיימו את מרבית עבודתם. לכן, הודעת ה-'Child 1 exits' תופיע אחרונה."}, "difficulty_estimation": "Medium", "_source_file": "0784__CPU_Scheduling__CodeAnalysis__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:21:06", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["CPU Scheduling", "Processes", "System Calls", "Concurrency"], "content": {"text": "נתונה התוכנית הבאה, המריצה מספר תהליכי ילד:\nיש להניח שהמערכת פועלת על מעבד יחיד (single CPU). קריאות המערכת `fork()` מצליחות תמיד, ואין עיכובים משמעותיים ביצירת תהליכים מעבר לזמן הריצה של `fork` עצמו. זמן החלפת קשר (context switch) זניח. כל פעולת `printf` מהירה ואינה צורכת זמן מעבד או קלט/פלט משמעותי. הפונקציה `cpu_intensive_work(duration_ms)` מבצעת עבודה תובענית במעבד שצורכת בדיוק `duration_ms` מילישניות של זמן מעבד, ואינה חוסמת את התהליך. קריאת `usleep(ms)` חוסמת את התהליך למשך `ms` מילישניות.\n", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\n#define NUM_PROCESSES 3 // מספר תהליכי ילד\n\n// פונקציית עזר לביצוע עבודה תובענית במעבד\n// מדמה עבודה של 'duration_ms' מילישניות\nvoid cpu_intensive_work(int duration_ms) {\n    // לצורך השאלה, נניח שפעולה זו צורכת בדיוק את זמן המעבד הנתון\n    // ואינה חוסמת את התהליך.\n}\n\nvoid child_task(int id, int cpu_burst_ms, int io_sleep_ms) {\n    printf(\"Child %d (PID %d): Starting CPU burst (%dms)\\n\", id, getpid(), cpu_burst_ms);\n    cpu_intensive_work(cpu_burst_ms); // מדמה עבודה תובענית במעבד\n    printf(\"Child %d (PID %d): Finished CPU burst, going to sleep (%dms)\\n\", id, getpid(), io_sleep_ms);\n    usleep(io_sleep_ms * 1000); // מדמה פעולת קלט/פלט או חסימה\n    printf(\"Child %d (PID %d): Woke up, finishing.\\n\", id, getpid());\n    exit(0);\n}\n\nint main() {\n    setbuf(stdout, NULL); // ודא פלט מיידי ללא בופר\n\n    pid_t pids[NUM_PROCESSES];\n    int i;\n\n    // יוצרים את תהליכי הילד\n    for (i = 0; i < NUM_PROCESSES; ++i) {\n        pids[i] = fork();\n        if (pids[i] == -1) {\n            perror(\"fork failed\");\n            exit(EXIT_FAILURE);\n        }\n        if (pids[i] == 0) { // תהליך ילד\n            // לילד i: צריכת מעבד של (i+1)*20ms, שינה של 100ms\n            child_task(i, (i + 1) * 20, 100);\n        }\n    }\n\n    printf(\"Parent (PID %d): Forked all children. Waiting for them to finish...\\n\", getpid());\n\n    // האב ממתין לכל הילדים\n    for (i = 0; i < NUM_PROCESSES; ++i) {\n        wait(NULL);\n    }\n\n    printf(\"Parent (PID %d): All children finished. Exiting.\\n\", getpid());\n    return 0;\n}\n", "options": null}, "sub_questions": [{"id": "1.1", "text": "תארו את הפלט האפשרי היחיד של התוכנית תחת אלגוריתם תזמון FCFS (First-Come, First-Served). יש להסביר את סדר הפעולות המוביל לפלט זה.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "תארו את הפלט האפשרי היחיד של התוכנית תחת אלגוריתם תזמון Round Robin (RR) עם קוונטום זמן של 30ms. יש להסביר את סדר הפעולות המוביל לפלט זה. (התייחסו לרשימת התהליכים המוכנים כ-P0, P1, P2 בסדר יצירתם, וההורה נכנס למצב המתנה רק לאחר שכל הילדים נוצרו והוא סיים את פעולותיו הראשוניות).", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "ניתוח התהליכים וזמניהם:\n- תהליך ילד 0 (P0): דורש 20ms זמן מעבד, ואז נכנס לשינה של 100ms.\n- תהליך ילד 1 (P1): דורש 40ms זמן מעבד, ואז נכנס לשינה של 100ms.\n- תהליך ילד 2 (P2): דורש 60ms זמן מעבד, ואז נכנס לשינה של 100ms.\nהתהליך ההורה (Parent) יוצר את שלושת הילדים (P0, P1, P2). לאחר מכן, הוא מדפיס הודעה ונכנס למצב המתנה (wait) עבור הילדים. נניח שההורה מסיים את הלולאה וקריאת ה-printf שלו לפני שמתחיל תזמון משמעותי של הילדים.\n\n**1.1 פלט תחת FCFS:**\nבאופן ראשוני, ההורה יוצר את P0, P1, P2. הם נכנסים לתור המוכנים בסדר זה. ההורה מסיים את פעולותיו הראשוניות, מדפיס הודעה, ומיד נחסם בקריאה הראשונה ל-`wait(NULL)` מכיוון שאף ילד עדיין לא סיים.\n\nסדר הפעולות:\n1.  **זמן T=0**: ההורה יוצר את P0, P1, P2. הם נכנסים לתור המוכנים (P0, P1, P2). ההורה ממשיך, מדפיס: `Parent (PID X): Forked all children. Waiting for them to finish...` ומיד נחסם ב-`wait()`.\n2.  **P0 מקבל מעבד**: מדפיס `Child 0 (PID Y): Starting CPU burst (20ms)`. מבצע 20ms עבודת מעבד. מדפיס `Child 0 (PID Y): Finished CPU burst, going to sleep (100ms)`. נכנס לשינה של 100ms. (P0 יתעורר ב-T = 20 + 100 = 120ms).\n3.  **P1 מקבל מעבד** (לאחר ש-P0 נחסם, ב-T=20ms): מדפיס `Child 1 (PID Z): Starting CPU burst (40ms)`. מבצע 40ms עבודת מעבד. מדפיס `Child 1 (PID Z): Finished CPU burst, going to sleep (100ms)`. נכנס לשינה של 100ms. (P1 יתעורר ב-T = 20 + 40 + 100 = 160ms).\n4.  **P2 מקבל מעבד** (לאחר ש-P1 נחסם, ב-T=20+40=60ms): מדפיס `Child 2 (PID W): Starting CPU burst (60ms)`. מבצע 60ms עבודת מעבד. מדפיס `Child 2 (PID W): Finished CPU burst, going to sleep (100ms)`. נכנס לשינה של 100ms. (P2 יתעורר ב-T = 60 + 60 + 100 = 220ms).\n5.  **T=120ms**: P0 מתעורר מהשינה, נכנס לתור המוכנים ומקבל מעבד (הוא התהליך הראשון שמוכן). מדפיס `Child 0 (PID Y): Woke up, finishing.`. P0 יוצא.\n6.  ההורה מתעורר לרגע (מ-`wait`), מעבד את יציאת P0, ומיד נחסם שוב ב-`wait()` עבור הילדים הנותרים.\n7.  **T=160ms**: P1 מתעורר מהשינה, נכנס לתור המוכנים ומקבל מעבד. מדפיס `Child 1 (PID Z): Woke up, finishing.`. P1 יוצא.\n8.  ההורה מתעורר לרגע, מעבד את יציאת P1, ומיד נחסם שוב ב-`wait()`.\n9.  **T=220ms**: P2 מתעורר מהשינה, נכנס לתור המוכנים ומקבל מעבד. מדפיס `Child 2 (PID W): Woke up, finishing.`. P2 יוצא.\n10. ההורה מתעורר, מעבד את יציאת P2, מסיים את לולאת ה-`wait`, ומדפיס `Parent (PID X): All children finished. Exiting.`\n\n**פלט אפשרי יחיד תחת FCFS:**\n```\nParent (PID X): Forked all children. Waiting for them to finish...\nChild 0 (PID Y): Starting CPU burst (20ms)\nChild 0 (PID Y): Finished CPU burst, going to sleep (100ms)\nChild 1 (PID Z): Starting CPU burst (40ms)\nChild 1 (PID Z): Finished CPU burst, going to sleep (100ms)\nChild 2 (PID W): Starting CPU burst (60ms)\nChild 2 (PID W): Finished CPU burst, going to sleep (100ms)\nChild 0 (PID Y): Woke up, finishing.\nChild 1 (PID Z): Woke up, finishing.\nChild 2 (PID W): Woke up, finishing.\nParent (PID X): All children finished. Exiting.\n```\n(הערה: X, Y, Z, W מייצגים מזהי PID שונים וספציפיים לריצה).\n\n**1.2 פלט תחת Round Robin (RR) עם קוונטום 30ms:**\nבאופן ראשוני, ההורה יוצר את P0, P1, P2. הם נכנסים לתור המוכנים (P0, P1, P2). ההורה מסיים את פעולותיו הראשוניות, מדפיס הודעה, ומיד נחסם בקריאה הראשונה ל-`wait(NULL)` מכיוון שאף ילד עדיין לא סיים.\n\nסדר הפעולות:\n1.  **זמן T=0**: ההורה יוצר את P0, P1, P2. הם נכנסים לתור המוכנים (P0, P1, P2). ההורה ממשיך, מדפיס: `Parent (PID X): Forked all children. Waiting for them to finish...` ומיד נחסם ב-`wait()`.\n2.  **T=0ms: P0 מקבל מעבד**.\n    *   מדפיס `Child 0 (PID Y): Starting CPU burst (20ms)`.\n    *   מבצע 20ms עבודת מעבד (P0 דורש 20ms, שזה פחות מהקוונטום 30ms).\n    *   **T=20ms**: P0 מסיים את עבודת המעבד. מדפיס `Child 0 (PID Y): Finished CPU burst, going to sleep (100ms)`.\n    *   **T=20ms**: P0 נכנס לשינה של 100ms. (P0 יתעורר ב-T = 20 + 100 = 120ms).\n    *   P0 נחסם. המעבד מתפנה.\n3.  **T=20ms: P1 מקבל מעבד** (הראשון בתור המוכנים לאחר P0).\n    *   מדפיס `Child 1 (PID Z): Starting CPU burst (40ms)`.\n    *   מבצע 30ms עבודת מעבד (קוונטום מלא).\n    *   **T=50ms**: הקוונטום של P1 מסתיים. P1 מופסק (preempted) ונכנס לסוף תור המוכנים. (P1 עדיין זקוק ל-10ms מעבד).\n4.  **T=50ms: P2 מקבל מעבד** (הראשון בתור המוכנים לאחר P1).\n    *   מדפיס `Child 2 (PID W): Starting CPU burst (60ms)`.\n    *   מבצע 30ms עבודת מעבד (קוונטום מלא).\n    *   **T=80ms**: הקוונטום של P2 מסתיים. P2 מופסק ונכנס לסוף תור המוכנים. (P2 עדיין זקוק ל-30ms מעבד).\n5.  **T=80ms: P1 מקבל מעבד** (הראשון בתור המוכנים).\n    *   מבצע 10ms עבודת מעבד (הזמן הנותר עבור P1).\n    *   **T=90ms**: P1 מסיים את עבודת המעבד. מדפיס `Child 1 (PID Z): Finished CPU burst, going to sleep (100ms)`.\n    *   **T=90ms**: P1 נכנס לשינה של 100ms. (P1 יתעורר ב-T = 90 + 100 = 190ms).\n    *   P1 נחסם. המעבד מתפנה.\n6.  **T=90ms: P2 מקבל מעבד** (הראשון בתור המוכנים).\n    *   מבצע 30ms עבודת מעבד (הזמן הנותר עבור P2).\n    *   **T=120ms**: P2 מסיים את עבודת המעבד. מדפיס `Child 2 (PID W): Finished CPU burst, going to sleep (100ms)`.\n    *   **T=120ms**: P2 נכנס לשינה של 100ms. (P2 יתעורר ב-T = 120 + 100 = 220ms).\n    *   P2 נחסם. המעבד מתפנה.\n7.  **T=120ms**: P0 מתעורר מהשינה, נכנס לתור המוכנים ומקבל מעבד (הוא התהליך היחיד שמוכן). מדפיס `Child 0 (PID Y): Woke up, finishing.`. P0 יוצא.\n8.  ההורה מתעורר לרגע (מ-`wait`), מעבד את יציאת P0, ומיד נחסם שוב ב-`wait()` עבור הילדים הנותרים.\n9.  **T=190ms**: P1 מתעורר מהשינה, נכנס לתור המוכנים ומקבל מעבד. מדפיס `Child 1 (PID Z): Woke up, finishing.`. P1 יוצא.\n10. ההורה מתעורר לרגע, מעבד את יציאת P1, ומיד נחסם שוב ב-`wait()`.\n11. **T=220ms**: P2 מתעורר מהשינה, נכנס לתור המוכנים ומקבל מעבד. מדפיס `Child 2 (PID W): Woke up, finishing.`. P2 יוצא.\n12. ההורה מתעורר, מעבד את יציאת P2, מסיים את לולאת ה-`wait`, ומדפיס `Parent (PID X): All children finished. Exiting.`\n\n**פלט אפשרי יחיד תחת RR (קוונטום 30ms):**\n```\nParent (PID X): Forked all children. Waiting for them to finish...\nChild 0 (PID Y): Starting CPU burst (20ms)\nChild 0 (PID Y): Finished CPU burst, going to sleep (100ms)\nChild 1 (PID Z): Starting CPU burst (40ms)\nChild 2 (PID W): Starting CPU burst (60ms)\nChild 1 (PID Z): Finished CPU burst, going to sleep (100ms)\nChild 2 (PID W): Finished CPU burst, going to sleep (100ms)\nChild 0 (PID Y): Woke up, finishing.\nChild 1 (PID Z): Woke up, finishing.\nChild 2 (PID W): Woke up, finishing.\nParent (PID X): All children finished. Exiting.\n```\n(הערה: X, Y, Z, W מייצגים מזהי PID שונים וספציפיים לריצה).\n"}, "difficulty_estimation": "Hard", "_source_file": "0785__CPU_Scheduling__CodeAnalysis__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:22:09", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["CPU Scheduling", "Processes", "System Calls", "Priorities"], "content": {"text": "נתונה התוכנית הבאה המשתמשת במערכת קריאות `fork` ו-`nice` ליצירת תהליכים בעלי עדיפויות שונות. התוכנית מיועדת לרוץ על מעבד יחיד. יש להניח שכל קריאות המערכת מצליחות.\n\n`nice` values: ערך נמוך יותר מציין עדיפות גבוהה יותר. ערך ברירת מחדל הוא 0.\n`setbuf(stdout, NULL)` מבטיח הדפסה מיידית ללא חיץ.\n\nנתון כי מערכת ההפעלה משתמשת באלגוריתם תזמון מונע (preemptive) מבוסס עדיפויות, כאשר תהליכים בעלי עדיפות גבוהה יותר יקבלו את המעבד לפני תהליכים בעלי עדיפות נמוכה יותר. בין תהליכים בעלי אותה עדיפות, התזמון הוא Round Robin. תהליך יקבל את המעבד ויבצע כמה איטרציות בלולאה לפני שיוחלף (context switch) רק אם יש תהליך בעל עדיפות גבוהה יותר שמוכן לריצה, או לאחר שמיצה את קוואנטום הזמן שלו (אם יש תהליכים אחרים באותה רמת עדיפות). לצורך הניתוח, נניח שכל הדפסה של תו נחשבת ל\"יחידת עבודה\" קטנה מאוד, ושזמן הקוואנטום מספיק לביצוע מספר קטן של הדפסות, אך קצר מ-`ITERATIONS`.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <sys/types.h>\n#include <errno.h>\n\n#define NUM_CHILDREN 3\n#define ITERATIONS   10\n\nvoid child_task(char id_char, int nice_value) {\n    if (nice_value != 0) {\n        if (nice(nice_value) == -1 && errno != 0) {\n            perror(\"nice\");\n            exit(1);\n        }\n    }\n    for (int i = 0; i < ITERATIONS; ++i) {\n        printf(\"%c\", id_char);\n        fflush(stdout);\n    }\n    exit(0);\n}\n\nint main() {\n    pid_t pids[NUM_CHILDREN];\n    char id_chars[NUM_CHILDREN] = {'A', 'B', 'C'};\n    int nice_values[NUM_CHILDREN] = {0, 5, -5}; // A: default, B: lower priority, C: higher priority\n\n    setbuf(stdout, NULL);\n\n    for (int i = 0; i < NUM_CHILDREN; ++i) {\n        pids[i] = fork();\n        if (pids[i] == -1) {\n            perror(\"fork\");\n            exit(1);\n        } else if (pids[i] == 0) { // Child process\n            child_task(id_chars[i], nice_values[i]);\n        }\n    }\n\n    for (int i = 0; i < NUM_CHILDREN; ++i) {\n        wait(NULL);\n    }\n\n    printf(\"\\nParent finished.\\n\");\n    return 0;\n}"}, "sub_questions": [{"id": "101.1", "text": "תארו פלט אפשרי אחד של התוכנית. הסבירו מדוע פלט זה אפשרי, תוך התייחסות לעדיפויות התהליכים וכיצד אלגוריתם התזמון ישפיע על סדר ההדפסות.", "code_snippet": null, "options": null}, {"id": "101.2", "text": "אם נשנה את המערך `nice_values` לשורה `int nice_values[NUM_CHILDREN] = {5, 0, -5};` (כלומר תהליך A מקבל עדיפות נמוכה יותר, B ברירת מחדל, C נשאר הגבוה ביותר), כיצד ישתנה הפלט בהשוואה למקרה המקורי? התייחסו למאפיינים הכלליים של הפלט (למשל, מי יסיים קודם, האם סדר ההדפסות יהיה מעורב יותר או פחות).", "code_snippet": null, "options": null}, {"id": "101.3", "text": "אם אלגוריתם התזמון היה FIFO לא מונע (non-preemptive), ובהנחה שכל תהליך ירוץ עד סיום הלולאה שלו ברגע שקיבל את המעבד, תארו את כל הפלטים האפשריים. הסבירו את ההבדל המהותי מהמקרה המקורי.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\n**סעיף 101.1: פלט אפשרי במקרה המקורי**\nהפלט הסביר ביותר הוא:\n`CCCCCCCCCCAAAAAAAAAABBBBBBBBBB\nParent finished.\n`\n**הסבר:**\n1.  **קביעת עדיפויות:**\n    *   תהליך C נוצר עם `nice -5`, זוהי העדיפות הגבוהה ביותר.\n    *   תהליך A נוצר עם `nice 0`, זוהי עדיפות בינונית.\n    *   תהליך B נוצר עם `nice 5`, זוהי העדיפות הנמוכה ביותר.\n2.  **תזמון מונע מבוסס עדיפויות:** מאחר ותהליך C בעל העדיפות הגבוהה ביותר, הוא יקבל את המעבד מיד כשהוא מוכן לריצה. מכיוון שאין תהליכים אחרים בעלי עדיפות גבוהה יותר או שווה לו שמתחרים איתו על המעבד, והוא לא חסום, הוא ירוץ ברציפות עד שיסיים את כל 10 ההדפסות שלו ('C').\n3.  **לאחר סיום C:** לאחר שתהליך C מסיים ויוצא, המעבד יהיה פנוי לתהליכים A ו-B. תהליך A (עדיפות 0) גבוה יותר מתהליך B (עדיפות 5), ולכן תהליך A יקבל את המעבד וירוץ ברציפות עד שיסיים את כל 10 ההדפסות שלו ('A').\n4.  **לאחר סיום A:** לבסוף, תהליך B יקבל את המעבד ויסיים את 10 ההדפסות שלו ('B').\n5.  **תהליך אב:** תהליך האב ימתין לכל התהליכים הבנים שיסיימו לפני שידפיס את הודעת הסיום שלו.\n\n**סעיף 101.2: שינוי במערך `nice_values` ל-`{5, 0, -5}`**\nהפלט הסביר ביותר יהיה:\n`CCCCCCCCCCBBBBBBBBBBAAAAAAAAAA\nParent finished.\n`\n**הסבר לשינוי:**\n1.  **קביעת עדיפויות חדשה:**\n    *   תהליך C נשאר עם `nice -5` (העדיפות הגבוהה ביותר).\n    *   תהליך B מקבל כעת `nice 0` (עדיפות בינונית).\n    *   תהליך A מקבל כעת `nice 5` (העדיפות הנמוכה ביותר).\n2.  **השפעה על הפלט:** העיקרון של תזמון מבוסס עדיפויות נשאר זהה. תהליך C בעל העדיפות הגבוהה ביותר עדיין ירוץ ויסיים ראשון, וידפיס את כל ה-'C'ים שלו. לאחר מכן, מבין תהליכים A ו-B, תהליך B (עם `nice 0`) הוא בעל עדיפות גבוהה יותר מתהליך A (עם `nice 5`). לכן, B ירוץ ויסיים את הדפסותיו לפני A, ולאחר מכן A ירוץ ויסיים. השינוי הוא שבלוק ההדפסות של 'B' יופיע לפני בלוק ההדפסות של 'A', במקום להיפך כמו במקרה המקורי.\n\n**סעיף 101.3: אלגוריתם תזמון FIFO לא מונע**\nבמצב של FIFO לא מונע, ברגע שתהליך מקבל את המעבד, הוא ירוץ עד לסיום משימתו (כלומר, עד שיצא מהלולאה ב-`child_task`) מבלי להיקטע. סדר ההדפסות יהיה תלוי בסדר שבו התהליכים הבנים נוצרו והוכנסו לתור המוכנים לריצה.\n\n**פלטים אפשריים:**\nהפלט היחיד האפשרי הוא:\n`AAAAAAAAAABBBBBBBBBBCCCCCCCCCC\nParent finished.\n`\n\n**הסבר:**\n1.  **סדר יצירת תהליכים:** בלולאה ב-`main`, התהליכים נוצרים בסדר הבא: A (עבור `i=0`), B (עבור `i=1`), ואז C (עבור `i=2`).\n2.  **הוספה לתור מוכנים (Ready Queue):** באופן טיפוסי, תהליכים חדשים שנוצרו (ילדים) מתווספים לסוף תור המוכנים. לכן, A יתווסף ראשון, ואחריו B, ואחריו C.\n3.  **תזמון FIFO לא מונע:** כאשר המעבד מתפנה (למשל, לאחר שתהליך האב מסיים את לולאת ה-`fork` שלו), הוא יבחר את התהליך הראשון בתור המוכנים. זה יהיה A. A ירוץ וישלים את כל 10 הדפסותיו ('A') ברצף. לאחר ש-A מסיים, המעבד יבחר את התהליך הבא בתור, שהוא B. B ירוץ וישלים את כל 10 הדפסותיו ('B') ברצף. לבסוף, C ירוץ וישלים את כל 10 הדפסותיו ('C') ברצף.\n4.  **הבדל מהותי:** במקרה המקורי, אלגוריתם התזמון היה מונע ומבוסס עדיפויות, ולכן העדיפויות קבעו את סדר ההרצה והשלמת המשימות. במקרה של FIFO לא מונע, העדיפויות שהוגדרו באמצעות `nice` אינן רלוונטיות כלל. סדר ההרצה נקבע אך ורק על פי סדר ההגעה לתור המוכנים (First-Come, First-Served), וברגע שתהליך מתחיל לרוץ הוא אינו נקטע (non-preemptive).", "difficulty_estimation": "Hard"}, "_source_file": "0786__CPU_Scheduling__CodeAnalysis__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:22:49", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["CPU Scheduling", "Processes", "Concurrency", "System Calls"], "content": {"text": "נתונה התוכנית הבאה, המדמה שלושה תהליכי בן (Child processes) המבצעים עבודת מעבד (CPU-bound) ועבודת קלט/פלט (I/O-bound) לסירוגין:\n\nהניחו את ההנחות הבאות לגבי המערכת והתזמון:\n1.  **מעבד:** המערכת כוללת מעבד יחיד.\n2.  **אלגוריתם תזמון:** Round Robin (RR).\n3.  **קוונטום (Quantum):** 10 מילישניות (ms).\n4.  **זמן החלפת קשר (Context Switch Overhead):** זניח (0ms).\n5.  **קריאות מערכת:** `fork()` ו-`printf()` לוקחות זמן זניח.\n6.  **`usleep(X)`:** חוסמת את התהליך למשך X מיקרושניות.\n7.  **`cpu_work(iterations)`:** הפונקציה צורכת בדיוק `iterations / 1,000,000` מילישניות של זמן מעבד (כלומר, `ITER_PER_MS` אחד שווה ל-1 מילישנייה של CPU).\n8.  **סדר יצירה והרצה:** תהליכים חדשים מתווספים לתור ההרצה (Ready Queue) בסדר יצירתם (Child 1, Child 2, Child 3). תהליך האב מסיים את פעולות ה-`fork` באופן מיידי ועובר למצב המתנה (wait) לילדיו, ואינו צורך זמן מעבד נוסף לאחר ה-forking.\n9.  **פלט:** `setbuf(stdout, NULL)` מבטיח הדפסה מיידית לפלט.\n\nכתבו את הפלט המדויק של התוכנית. יש להסביר בפירוט את כל שלבי הריצה, כולל זמני כניסה ויציאה של תהליכים מהמעבד וממצב חסימה.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <sys/types.h>\n\n// Assuming 10^6 iterations take 1ms of CPU time\n#define ITER_PER_MS 1000000\n\nvoid cpu_work(long long iterations, int child_id, int stage) {\n    volatile long long sum = 0;\n    for (volatile long long j = 0; j < iterations; ++j) {\n        sum += j; // Simulate CPU work\n    }\n    printf(\"Child %d: CPU done (stage %d)\\n\", child_id, stage);\n}\n\nvoid io_sleep(useconds_t us, int child_id, int stage) {\n    usleep(us);\n    printf(\"Child %d: I/O done (stage %d)\\n\", child_id, stage);\n}\n\nint main() {\n    setbuf(stdout, NULL); // Unbuffer stdout\n    pid_t pids[3];\n    int child_num;\n\n    printf(\"Parent: Starting\\n\");\n\n    for (int i = 0; i < 3; ++i) {\n        pids[i] = fork();\n        if (pids[i] == -1) {\n            perror(\"fork failed\");\n            exit(1);\n        } else if (pids[i] == 0) {\n            // Child process\n            child_num = i + 1;\n            printf(\"Child %d: Forked (PID %d)\\n\", child_num, getpid());\n\n            if (child_num == 1) { // Child 1: (10ms CPU, 30ms IO) x 2\n                cpu_work(10 * ITER_PER_MS, child_num, 1);\n                io_sleep(30 * 1000, child_num, 1);\n                cpu_work(10 * ITER_PER_MS, child_num, 2);\n                io_sleep(30 * 1000, child_num, 2);\n            } else if (child_num == 2) { // Child 2: (20ms CPU, 10ms IO) x 2\n                cpu_work(20 * ITER_PER_MS, child_num, 1);\n                io_sleep(10 * 1000, child_num, 1);\n                cpu_work(20 * ITER_PER_MS, child_num, 2);\n                io_sleep(10 * 1000, child_num, 2);\n            } else { // Child 3: (10ms CPU, 10ms IO) x 2\n                cpu_work(10 * ITER_PER_MS, child_num, 1);\n                io_sleep(10 * 1000, child_num, 1);\n                cpu_work(10 * ITER_PER_MS, child_num, 2);\n                io_sleep(10 * 1000, child_num, 2);\n            }\n            printf(\"Child %d: Exiting\\n\", child_num);\n            exit(0);\n        }\n    }\n\n    // Parent waits for children\n    for (int i = 0; i < 3; ++i) {\n        wait(NULL);\n    }\n\n    printf(\"Parent: Exiting\\n\");\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "נבצע סימולציה מפורטת של ריצת התוכנית, תוך מעקב אחר מצבי התהליכים (מוכן, רץ, חסום) ותורות ההרצה והחסימה. הקוונטום הוא 10ms.\n\n**מאפייני התהליכים:**\n*   **P1 (Child 1):** צורך 10ms CPU, נחסם ל-30ms I/O, צורך 10ms CPU, נחסם ל-30ms I/O -> יציאה.\n*   **P2 (Child 2):** צורך 20ms CPU, נחסם ל-10ms I/O, צורך 20ms CPU, נחסם ל-10ms I/O -> יציאה.\n*   **P3 (Child 3):** צורך 10ms CPU, נחסם ל-10ms I/O, צורך 10ms CPU, נחסם ל-10ms I/O -> יציאה.\n\n**תור ההרצה ההתחלתי (Ready Queue):** [P1, P2, P3] (לפי סדר יצירתם).\n\n**טבלת מעקב:**\n\n| זמן (ms) | אירוע | תהליך רץ | תור הרצה (Ready Queue) | תור חסומים (Blocked Queue) | פלט |\n|---|---|---|---|---|---|\n| 0 | התחלת המערכת, יצירת תהליכים | - | [P1, P2, P3] | [] | Parent: Starting<br>Child 1: Forked (PID ...)<br>Child 2: Forked (PID ...)<br>Child 3: Forked (PID ...) |\n| 0 | מתזמן בוחר את P1 | P1 | [P2, P3] | [] | |\n| 0-10 | P1 רץ (מבצע 10ms מתוך CPU1) | P1 | [P2, P3] | [] | |\n| 10 | P1 מסיים CPU1 | P1 | [P2, P3] | [] | Child 1: CPU done (stage 1) |\n| 10 | P1 נחסם (I/O1: 30ms, ישתחרר ב-40ms) | - | [P2, P3] | [P1(unblock@40)] | |\n| 10 | מתזמן בוחר את P2 | P2 | [P3] | [P1(unblock@40)] | |\n| 10-20 | P2 רץ (מבצע 10ms מתוך CPU1, נותרו 10ms) | P2 | [P3] | [P1(unblock@40)] | |\n| 20 | הקוונטום של P2 נגמר. P2 עובר לסוף תור ההרצה. | - | [P3, P2] | [P1(unblock@40)] | |\n| 20 | מתזמן בוחר את P3 | P3 | [P2] | [P1(unblock@40)] | |\n| 20-30 | P3 רץ (מבצע 10ms מתוך CPU1) | P3 | [P2] | [P1(unblock@40)] | |\n| 30 | P3 מסיים CPU1 | P3 | [P2] | [P1(unblock@40)] | Child 3: CPU done (stage 1) |\n| 30 | P3 נחסם (I/O1: 10ms, ישתחרר ב-40ms) | - | [P2] | [P1(unblock@40), P3(unblock@40)] | |\n| 30 | מתזמן בוחר את P2 | P2 | [] | [P1(unblock@40), P3(unblock@40)] | |\n| 30-40 | P2 רץ (מבצע 10ms הנותרים מ-CPU1) | P2 | [] | [P1(unblock@40), P3(unblock@40)] | |\n| 40 | P2 מסיים CPU1 (סה\"כ 20ms) | P2 | [] | [P1(unblock@40), P3(unblock@40)] | Child 2: CPU done (stage 1) |\n| 40 | P1 משתחרר מחסימה (I/O1 הסתיים). עובר לסוף תור ההרצה. | - | [P1] | [P3(unblock@40)] | Child 1: I/O done (stage 1) |\n| 40 | P3 משתחרר מחסימה (I/O1 הסתיים). עובר לסוף תור ההרצה. | - | [P1, P3] | [] | Child 3: I/O done (stage 1) |\n| 40 | P2 נחסם (I/O1: 10ms, ישתחרר ב-50ms) | - | [P1, P3] | [P2(unblock@50)] | |\n| 40 | מתזמן בוחר את P1 | P1 | [P3] | [P2(unblock@50)] | |\n| 40-50 | P1 רץ (מבצע 10ms מתוך CPU2) | P1 | [P3] | [P2(unblock@50)] | |\n| 50 | P1 מסיים CPU2 | P1 | [P3] | [P2(unblock@50)] | Child 1: CPU done (stage 2) |\n| 50 | P2 משתחרר מחסימה (I/O1 הסתיים). עובר לסוף תור ההרצה. | - | [P3, P2] | [] | Child 2: I/O done (stage 1) |\n| 50 | P1 נחסם (I/O2: 30ms, ישתחרר ב-80ms) | - | [P3, P2] | [P1(unblock@80)] | |\n| 50 | מתזמן בוחר את P3 | P3 | [P2] | [P1(unblock@80)] | |\n| 50-60 | P3 רץ (מבצע 10ms מתוך CPU2) | P3 | [P2] | [P1(unblock@80)] | |\n| 60 | P3 מסיים CPU2 | P3 | [P2] | [P1(unblock@80)] | Child 3: CPU done (stage 2) |\n| 60 | P3 נחסם (I/O2: 10ms, ישתחרר ב-70ms) | - | [P2] | [P1(unblock@80), P3(unblock@70)] | |\n| 60 | מתזמן בוחר את P2 | P2 | [] | [P1(unblock@80), P3(unblock@70)] | |\n| 60-70 | P2 רץ (מבצע 10ms מתוך CPU2, נותרו 10ms) | P2 | [] | [P1(unblock@80), P3(unblock@70)] | |\n| 70 | P3 משתחרר מחסימה (I/O2 הסתיים). עובר לסוף תור ההרצה. | - | [P3] | [P1(unblock@80)] | Child 3: I/O done (stage 2) |\n| 70 | הקוונטום של P2 נגמר. P2 עובר לסוף תור ההרצה. | - | [P3, P2] | [P1(unblock@80)] | |\n| 70 | מתזמן בוחר את P3 | P3 | [P2] | [P1(unblock@80)] | |\n| 70 | P3 מסיים את כל עבודתו ויוצא. | - | [P2] | [P1(unblock@80)] | Child 3: Exiting |\n| 70 | מתזמן בוחר את P2 | P2 | [] | [P1(unblock@80)] | |\n| 70-80 | P2 רץ (מבצע 10ms הנותרים מ-CPU2) | P2 | [] | [P1(unblock@80)] | |\n| 80 | P1 משתחרר מחסימה (I/O2 הסתיים). עובר לסוף תור ההרצה. | - | [P1] | [] | Child 1: I/O done (stage 2) |\n| 80 | P2 מסיים CPU2 (סה\"כ 20ms) | P2 | [P1] | [] | Child 2: CPU done (stage 2) |\n| 80 | P2 נחסם (I/O2: 10ms, ישתחרר ב-90ms) | - | [P1] | [P2(unblock@90)] | |\n| 80 | מתזמן בוחר את P1 | P1 | [] | [P2(unblock@90)] | |\n| 80 | P1 מסיים את כל עבודתו ויוצא. | - | [] | [P2(unblock@90)] | Child 1: Exiting |\n| 80-90 | המעבד מובטל (אין תהליכים מוכנים, P2 חסום) | - | [] | [P2(unblock@90)] | |\n| 90 | P2 משתחרר מחסימה (I/O2 הסתיים). עובר לסוף תור ההרצה. | - | [P2] | [] | Child 2: I/O done (stage 2) |\n| 90 | מתזמן בוחר את P2 | P2 | [] | [] | |\n| 90 | P2 מסיים את כל עבודתו ויוצא. | - | [] | [] | Child 2: Exiting |\n| 90 | כל תהליכי הבן הסתיימו. תהליך האב מסיים. | - | [] | [] | Parent: Exiting |\n\n**הפלט הסופי יהיה (סדר ה-PID יכול להשתנות):**\nParent: Starting\nChild 1: Forked (PID ...)\nChild 2: Forked (PID ...)\nChild 3: Forked (PID ...)\nChild 1: CPU done (stage 1)\nChild 3: CPU done (stage 1)\nChild 2: CPU done (stage 1)\nChild 1: I/O done (stage 1)\nChild 3: I/O done (stage 1)\nChild 1: CPU done (stage 2)\nChild 2: I/O done (stage 1)\nChild 3: CPU done (stage 2)\nChild 3: I/O done (stage 2)\nChild 3: Exiting\nChild 2: CPU done (stage 2)\nChild 1: I/O done (stage 2)\nChild 1: Exiting\nChild 2: I/O done (stage 2)\nChild 2: Exiting\nParent: Exiting"}, "difficulty_estimation": "Hard", "_source_file": "0787__CPU_Scheduling__CodeAnalysis__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:23:57", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["CPU Scheduling", "Processes", "Concurrency", "System Calls"], "content": {"text": "נתונה התוכנית הבאה, המריצה מספר תהליכי בן במקביל. יש להניח שהמערכת כוללת מעבד יחיד (single CPU) וכל קריאות המערכת מצליחות.\n`fflush(stdout)` מבוצע לאחר כל הדפסה כדי להבטיח שהפלט נכתב מיד.\n`CPU_BURST_ITERATIONS` מייצג לולאה שלוקחת כ-200 מילישניות, ו-`IO_BURST_US` הוא 50 מילישניות.\n", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\n#define N 3 // Number of children\n#define CPU_BURST_ITERATIONS 100000000 // A significant CPU load (approx 200ms)\n#define IO_BURST_US 50000 // 50 milliseconds\n\nvoid child_task(int id) {\n    pid_t pid = getpid();\n    printf(\"Child %d (PID %d): Start\\n\", id, pid);\n    fflush(stdout);\n\n    if (id % 2 == 0) { // Even ID: CPU-bound\n        for (long k = 0; k < CPU_BURST_ITERATIONS; k++);\n        printf(\"Child %d (PID %d): CPU Work Done\\n\", id, pid);\n        fflush(stdout);\n    } else { // Odd ID: I/O-bound (sleep)\n        usleep(IO_BURST_US);\n        printf(\"Child %d (PID %d): Sleep Done\\n\", id, pid);\n        fflush(stdout);\n    }\n\n    printf(\"Child %d (PID %d): End\\n\", id, pid);\n    fflush(stdout);\n    exit(0);\n}\n\nint main() {\n    printf(\"Parent (PID %d): Initializing\\n\", getpid());\n    fflush(stdout);\n\n    pid_t pids[N];\n    for (int i = 0; i < N; ++i) {\n        pids[i] = fork();\n        if (pids[i] == -1) {\n            perror(\"fork failed\");\n            exit(1);\n        } else if (pids[i] == 0) {\n            child_task(i);\n        }\n    }\n\n    printf(\"Parent (PID %d): All children forked\\n\", getpid());\n    fflush(stdout);\n\n    for (int i = 0; i < N; ++i) {\n        int status;\n        pid_t child_pid = wait(&status);\n        printf(\"Parent (PID %d): Child %d terminated\\n\", getpid(), child_pid);\n        fflush(stdout);\n    }\n\n    printf(\"Parent (PID %d): Finalizing\\n\", getpid());\n    fflush(stdout);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "8.1", "text": "תארו פלט אפשרי אחד של התוכנית תחת אלגוריתם תזמון FIFO (First-In, First-Out). הסבירו את סדר האירועים המוביל לפלט זה.", "code_snippet": null, "options": null}, {"id": "8.2", "text": "תארו פלט אפשרי אחד של התוכנית תחת אלגוריתם תזמון Round Robin עם קוואנטום של 10 מילישניות. הסבירו את ההבדלים המרכזיים בפלט בהשוואה לאלגוריתם FIFO, וכיצד הם נובעים מההתנהגות של Round Robin.", "code_snippet": null, "options": null}, {"id": "8.3", "text": "האם סדר הפלטים של תהליכי הבן (הודעות ה-'Start', 'CPU Work Done'/'Sleep Done', ו-'End') יהיה דטרמיניסטי לחלוטין תחת אלגוריתם Round Robin? נמקו.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסבר כללי:\nהתוכנית יוצרת שלושה תהליכי בן (C0, C1, C2) מהתהליך הראשי (P). תהליכים C0 ו-C2 מבצעים עבודה עתירת מעבד (כ-200ms), בעוד שתהליך C1 מבצע פעולת I/O (שינה למשך 50ms). התהליך האב ממתין לכל הבנים.\n\n8.1. פלט אפשרי תחת אלגוריתם FIFO (First-In, First-Out):\nב-FIFO, תהליכים רצים ללא הפסקה מרגע שהם נבחרים ועד שהם מסיימים או נחסמים. בהנחה שתהליכי הבן נכנסים לתור המוכנים בסדר יצירתם (C0, C1, C2):\n\n**סדר אירועים:**\n1.  **P מתחיל:** מדפיס \"Parent (PID X): Initializing\" ואז \"Parent (PID X): All children forked\".\n2.  **P נחסם:** קורא `wait()` וממתין לילדים.\n3.  **C0 רץ (CPU-bound):** נבחר ראשון. מדפיס \"Child 0 (PID Y): Start\". מבצע את לולאת המעבד כ-200ms ללא הפרעה. מדפיס \"Child 0 (PID Y): CPU Work Done\" ו-\"Child 0 (PID Y): End\". C0 מסיים.\n4.  **P מתעורר:** מקבל הודעה על סיום C0. מדפיס \"Parent (PID X): Child Y terminated\".\n5.  **P נחסם שוב:** קורא `wait()` וממתין לילדים הבאים.\n6.  **C1 רץ (I/O-bound):** נבחר שני. מדפיס \"Child 1 (PID Z): Start\". קורא `usleep(50000)` ונחסם למשך 50ms.\n7.  **C2 רץ (CPU-bound):** מכיוון ש-C1 חסום, C2 נבחר. מדפיס \"Child 2 (PID W): Start\". מבצע את לולאת המעבד כ-200ms ללא הפרעה. מדפיס \"Child 2 (PID W): CPU Work Done\" ו-\"Child 2 (PID W): End\". C2 מסיים.\n8.  **P מתעורר:** מקבל הודעה על סיום C2. מדפיס \"Parent (PID X): Child W terminated\".\n9.  **P נחסם שוב:** קורא `wait()` וממתין לילדים הבאים.\n10. **C1 מתעורר:** לאחר 50ms (שעברו בזמן ש-C0 ו-C2 רצו). C1 הופך למוכן.\n11. **C1 רץ:** מדפיס \"Child 1 (PID Z): Sleep Done\" ו-\"Child 1 (PID Z): End\". C1 מסיים.\n12. **P מתעורר:** מקבל הודעה על סיום C1. מדפיס \"Parent (PID X): Child Z terminated\".\n13. **P מסיים:** מדפיס \"Parent (PID X): Finalizing\".\n\n**פלט אפשרי:**\nParent (PID X): Initializing\nParent (PID X): All children forked\nChild 0 (PID Y): Start\nChild 0 (PID Y): CPU Work Done\nChild 0 (PID Y): End\nParent (PID X): Child Y terminated\nChild 1 (PID Z): Start\nChild 2 (PID W): Start\nChild 2 (PID W): CPU Work Done\nChild 2 (PID W): End\nParent (PID X): Child W terminated\nChild 1 (PID Z): Sleep Done\nChild 1 (PID Z): End\nParent (PID X): Child Z terminated\nParent (PID X): Finalizing\n\n8.2. פלט אפשרי תחת אלגוריתם Round Robin (קוואנטום 10ms):\nב-Round Robin, תהליכים מופסקים מראש (preempted) לאחר זמן קוואנטום, וניתנת להם הזדמנות נוספת לפי תור. תהליך שנחסם (למשל, בגלל I/O) מוסר מהתור ומוחזר אליו כשהוא מוכן שוב.\n\n**סדר אירועים (מקוצר):**\n1.  **P מתחיל:** מדפיס \"Parent (PID X): Initializing\" ואז \"Parent (PID X): All children forked\".\n2.  **P נחסם:** קורא `wait()`.\n3.  **C0 רץ (10ms):** מדפיס \"Child 0 (PID Y): Start\". מבצע חלק מעבודת המעבד. מופסק.\n4.  **C1 רץ (10ms):** מדפיס \"Child 1 (PID Z): Start\". קורא `usleep(50000)` ונחסם.\n5.  **C2 רץ (10ms):** מדפיס \"Child 2 (PID W): Start\". מבצע חלק מעבודת המעבד. מופסק.\n6.  **C0 ו-C2 מתחלפים:** ממשיכים לרוץ 10ms כל אחד, מתקדמים בעבודת המעבד שלהם.\n7.  **C1 מתעורר (לאחר 50ms):** מתווסף חזרה לתור המוכנים. מכיוון שהוא תהליך I/O-bound, הוא יקבל את המעבד יחסית במהירות לאחר שהתעורר.\n8.  **C1 רץ (10ms):** מדפיס \"Child 1 (PID Z): Sleep Done\" ו-\"Child 1 (PID Z): End\". C1 מסיים.\n9.  **P מתעורר:** מקבל הודעה על סיום C1. מדפיס \"Parent (PID X): Child Z terminated\".\n10. **P נחסם שוב:** קורא `wait()`.\n11. **C0 ו-C2 ממשיכים:** מתחלפים בקבלת המעבד עד שכל אחד מסיים את 200ms המעבד שלו.\n12. **C0 מסיים:** מדפיס \"Child 0 (PID Y): CPU Work Done\" ו-\"Child 0 (PID Y): End\".\n13. **P מתעורר:** מדפיס \"Parent (PID X): Child Y terminated\".\n14. **P נחסם שוב:** קורא `wait()`.\n15. **C2 מסיים:** מדפיס \"Child 2 (PID W): CPU Work Done\" ו-\"Child 2 (PID W): End\".\n16. **P מתעורר:** מדפיס \"Parent (PID X): Child W terminated\".\n17. **P מסיים:** מדפיס \"Parent (PID X): Finalizing\".\n\n**פלט אפשרי (מסודר יותר):**\nParent (PID X): Initializing\nParent (PID X): All children forked\nChild 0 (PID Y): Start\nChild 1 (PID Z): Start\nChild 2 (PID W): Start\nChild 1 (PID Z): Sleep Done\nChild 1 (PID Z): End\nParent (PID X): Child Z terminated\nChild 0 (PID Y): CPU Work Done\nChild 0 (PID Y): End\nParent (PID X): Child Y terminated\nChild 2 (PID W): CPU Work Done\nChild 2 (PID W): End\nParent (PID X): Child W terminated\nParent (PID X): Finalizing\n\n**הבדלים מרכזיים בהשוואה ל-FIFO:**\n*   **סדר הודעות ה-`Start`:** ב-Round Robin, הודעות ה-`Start` של כל הילדים יופיעו בהתחלה בזו אחר זו (או לסירוגין) במהירות, מכיוון שכל ילד מקבל קוואנטום קצר כדי להתחיל. ב-FIFO, הודעת `Start` של ילד אחד תופיע, ואז הוא יסיים את פעולתו לפני שילד אחר יתחיל.\n*   **סיום תהליכי I/O-bound:** ב-Round Robin, תהליך C1 (I/O-bound) יסיים את פעולתו ויודפסו הודעות ה-`Sleep Done` וה-`End` שלו הרבה לפני שתהליכי C0 ו-C2 (CPU-bound) יסיימו את עבודת המעבד שלהם. כתוצאה מכך, הודעת ה-`Parent: Child Z terminated` (עבור C1) תופיע מוקדם יותר בפלט. ב-FIFO, תהליכי ה-CPU-bound סיימו ראשונים כי הם לא הופסקו.\n*   **אינטרליבינג (Interleaving):** באופן כללי, תהיה יותר אינטרליבינג (ערבוב) בין הפלטים של תהליכי ה-CPU-bound (C0 ו-C2) ב-Round Robin, מכיוון שהם מתחלפים על המעבד. ב-FIFO, הם רצים ברצף.\n\n8.3. האם סדר הפלטים של תהליכי הבן יהיה דטרמיניסטי לחלוטין תחת אלגוריתם Round Robin? נמקו.\n**לא, סדר הפלטים של תהליכי הבן לא יהיה דטרמיניסטי לחלוטין תחת אלגוריתם Round Robin.**\n\n**נימוק:**\nאף על פי שאלגוריתם Round Robin הוא אלגוריתם תזמון מוגדר, ישנם מספר גורמים שיכולים להשפיע על הסדר המדויק של הפלטים ולהפוך אותו ללא דטרמיניסטי:\n1.  **סדר הכנסת תהליכים לתור המוכנים:** כאשר תהליכים הופכים למוכנים (למשל, לאחר `fork` או לאחר סיום `usleep`), הסדר המדויק שבו הם מתווספים לתור המוכנים של המערכת יכול להשתנות מעט בין הרצות שונות, בהתאם למיקרו-תזמונים של קריאות מערכת או אירועי קלט/פלט.\n2.  **הבדלים זעירים בזמני ביצוע:** זמני הריצה של לולאות CPU או השהיות I/O אינם מדויקים לחלוטין ויכולים להשתנות במילישניות בודדות בין הרצות שונות עקב עומס מערכת, הפרעות, קאש, וכו'. שינויים אלו יכולים להשפיע על מתי בדיוק תהליך CPU-bound מסיים את הקוואנטום שלו או מתי תהליך I/O-bound מתעורר, ובכך לשנות את סדר התור.\n3.  **מדיניות תזמון פנימית:** מערכות הפעלה מודרניות מורכבות, וגם אם הליבה משתמשת ב-Round Robin בבסיסה, ייתכנו תת-מערכות תזמון נוספות (למשל, לטיפול באירועי מערכת, מנגנוני I/O) שיכולות להכניס אי-דטרמיניסטיות לסדר הקוואנטומים המוקצים בפועל. לדוגמה, אם שני תהליכים הופכים למוכנים בדיוק באותו רגע, הסדר שבו הם יתווספו לתור המוכנים יכול להיות תלוי בפרטים מימושיים של מערכת ההפעלה.\n\nלכן, בעוד שהדפוס הכללי של Round Robin (אינטרליבינג, תהליכי I/O מסיימים מוקדם יותר) יישמר, הסדר המדויק של כל שורת פלט בודדת, במיוחד בין תהליכים בעלי אופי דומה (C0 ו-C2), יכול להשתנות בין הרצות שונות."}, "difficulty_estimation": "Hard", "_source_file": "0788__CPU_Scheduling__CodeAnalysis__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:24:52", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["CPU Scheduling", "Processes", "Concurrency", "System Calls"], "content": {"text": "נתונה התוכנית הבאה, המדמה עומס עבודה של תהליכים:\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <sys/types.h>\n\n#define N_CHILDREN 3     // מספר תהליכי הבן\n#define WORK_ITERATIONS_FACTOR 10000000 // פקטור עבודה CPU\n#define SLEEP_MICROSECONDS 100000 // 100 מיקרושניות שינה (I/O)\n#define REPEAT_COUNT 2   // מספר חזרות לכל תהליך בן\n\nvoid child_task(int child_idx) {\n    pid_t my_pid = getpid();\n    for (int i = 0; i < REPEAT_COUNT; ++i) {\n        printf(\"Child %d (PID %d) starting work iteration %d\\n\", child_idx, my_pid, i + 1);\n        // Simulate CPU-bound work\n        for (long long j = 0; j < WORK_ITERATIONS_FACTOR * 5; ++j) {\n            // Do nothing, just consume CPU\n        }\n        printf(\"Child %d (PID %d) finished work iteration %d, now sleeping\\n\", child_idx, my_pid, i + 1);\n        usleep(SLEEP_MICROSECONDS); // Simulate I/O or waiting\n    }\n    printf(\"Child %d (PID %d) finished all tasks.\\n\", child_idx, my_pid);\n    exit(0);\n}\n\nint main() {\n    printf(\"Parent (PID %d) starting.\\n\", getpid());\n\n    for (int i = 0; i < N_CHILDREN; ++i) {\n        pid_t pid = fork();\n        if (pid < 0) {\n            perror(\"fork failed\");\n            exit(1);\n        } else if (pid == 0) {\n            // Child process\n            child_task(i + 1);\n        }\n    }\n\n    // Parent waits for all children\n    for (int i = 0; i < N_CHILDREN; ++i) {\n        wait(NULL);\n    }\n\n    printf(\"Parent (PID %d) finished, all children done.\\n\", getpid());\n    return 0;\n}\n```\n\n**הנחות:**\n*   המערכת כוללת מעבד יחיד.\n*   אלגוריתם התזמון הוא Round Robin (RR) עם קוונטום (quantum) של `Q = 20ms`.\n*   זמן העבודה של לולאת ה-CPU הפנימית: `for (long long j = 0; j < WORK_ITERATIONS_FACTOR * 5; ++j)` צורך בדיוק `50ms` של זמן מעבד בכל פעם שהיא מבוצעת (לפני קריאה ל-`usleep`).\n*   קריאה ל-`usleep(X)` גורמת לתהליך להיחסם (blocked) בדיוק למשך `X` מיקרושניות.\n*   זמן החלפת הקשר (context switch overhead) הוא `CS_OVERHEAD_MS = 1ms`. זמן זה נכלל בחישוב הזמן הכולל ומתרחש בכל פעם שהמעבד עובר מתהליך אחד לאחר (כולל בין תהליך האב לתהליכי הבן, ובין תהליכי הבן לבין עצמם, וגם כאשר המעבד עובר ממצב סרק לתהליך או מתהליך למצב סרק).\n*   התהליכים מוכנים לריצה מיד לאחר קריאת ה-`fork`.\n*   קריאות `printf` הן מיידיות ואינן צורכות זמן מעבד משמעותי או גורמות לחסימה.\n*   תהליכי הבן נוצרים בסדר עוקב, כך ש-Child 1 נוצר ראשון, Child 2 שני, ו-Child 3 שלישי. כתוצאה מכך, הם גם יכנסו לתור ה-ready בסדר זה.\n\n**שאלה:**\nחשבו את זמן הריצה הכולל המינימלי של התוכנית מרגע תחילת ריצתה ועד להדפסת ההודעה \"Parent (PID X) finished, all children done.\", תוך פירוט שלבי התזמון, עבודת המעבד והמתנות I/O. ציינו את כל הדפסות הפלט האפשריות ואת סדר הופעתן. יש להחליף את ה-PIDs האמיתיים בתווים X, Y1, Y2, Y3 כפי שמופיע בדוגמאות הפלט.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "**ניתוח וחישוב זמן הריצה הכולל:**\n\n**הגדרות וקבועים:**\n*   `N_CHILDREN = 3` (מספר תהליכי הבן)\n*   `CPU_WORK_TIME_MS = 50ms` (זמן עבודת מעבד לכל איטרציה של לולאה פנימית)\n*   `IO_WAIT_TIME_MS = 100ms` (זמן המתנת I/O בקריאה ל-`usleep`)\n*   `REPEAT_COUNT = 2` (מספר איטרציות עבודה+שינה לכל תהליך בן)\n*   `Q = 20ms` (קוונטום Round Robin)\n*   `CS_OVERHEAD_MS = 1ms` (זמן החלפת הקשר)\n\n**סה\"כ עבודת מעבד לכל תהליך בן:** `REPEAT_COUNT * CPU_WORK_TIME_MS = 2 * 50ms = 100ms`\n**סה\"כ המתנת I/O לכל תהליך בן:** `REPEAT_COUNT * IO_WAIT_TIME_MS = 2 * 100ms = 200ms`\n\n**שלבי התזמון המפורטים (ציר זמן):**\n\n*   **t=0ms:** תהליך האב (P) מתחיל, מדפיס \"Parent (PID X) starting.\".\n    *   P יוצר את C1, C2, C3. סדר יצירה: C1, C2, C3.\n    *   P נכנס ללולאת `wait` ונחסם.\n    *   תור מוכנים (Ready Queue - RQ): `[C1, C2, C3]`.\n    *   **החלפת קשר:** P -> C1 (`1ms`).\n*   **t=1ms:** C1 מתחיל לרוץ (איטרציה 1). מדפיס \"Child 1 (PID Y1) starting work iteration 1\".\n*   **t=1ms + 20ms = 21ms:** קוונטום של C1 נגמר. נותרו ל-C1 `30ms` עבודת מעבד לאיטרציה זו.\n    *   RQ: `[C2, C3, C1]`.\n    *   **החלפת קשר:** C1 -> C2 (`1ms`).\n*   **t=22ms:** C2 מתחיל לרוץ (איטרציה 1). מדפיס \"Child 2 (PID Y2) starting work iteration 1\".\n*   **t=22ms + 20ms = 42ms:** קוונטום של C2 נגמר. נותרו ל-C2 `30ms` עבודת מעבד לאיטרציה זו.\n    *   RQ: `[C3, C1, C2]`.\n    *   **החלפת קשר:** C2 -> C3 (`1ms`).\n*   **t=43ms:** C3 מתחיל לרוץ (איטרציה 1). מדפיס \"Child 3 (PID Y3) starting work iteration 1\".\n*   **t=43ms + 20ms = 63ms:** קוונטום של C3 נגמר. נותרו ל-C3 `30ms` עבודת מעבד לאיטרציה זו.\n    *   RQ: `[C1, C2, C3]`.\n    *   **החלפת קשר:** C3 -> C1 (`1ms`).\n*   **t=64ms:** C1 ממשיך לרוץ.\n*   **t=64ms + 20ms = 84ms:** קוונטום של C1 נגמר. נותרו ל-C1 `10ms` עבודת מעבד לאיטרציה זו.\n    *   RQ: `[C2, C3, C1]`.\n    *   **החלפת קשר:** C1 -> C2 (`1ms`).\n*   **t=85ms:** C2 ממשיך לרוץ.\n*   **t=85ms + 20ms = 105ms:** קוונטום של C2 נגמר. נותרו ל-C2 `10ms` עבודת מעבד לאיטרציה זו.\n    *   RQ: `[C3, C1, C2]`.\n    *   **החלפת קשר:** C2 -> C3 (`1ms`).\n*   **t=106ms:** C3 ממשיך לרוץ.\n*   **t=106ms + 20ms = 126ms:** קוונטום של C3 נגמר. נותרו ל-C3 `10ms` עבודת מעבד לאיטרציה זו.\n    *   RQ: `[C1, C2, C3]`.\n    *   **החלפת קשר:** C3 -> C1 (`1ms`).\n*   **t=127ms:** C1 ממשיך לרוץ. מסיים את `10ms` הנותרים של עבודת המעבד.\n*   **t=127ms + 10ms = 137ms:** C1 מסיים עבודת מעבד לאיטרציה 1. מדפיס \"Child 1 (PID Y1) finished work iteration 1, now sleeping\".\n    *   C1 נחסם (blocked) למשך `100ms`. יתעורר ב-`137ms + 100ms = 237ms`.\n    *   RQ: `[C2, C3]`.\n    *   **החלפת קשר:** C1 -> C2 (`1ms`).\n*   **t=138ms:** C2 ממשיך לרוץ. מסיים את `10ms` הנותרים של עבודת המעבד.\n*   **t=138ms + 10ms = 148ms:** C2 מסיים עבודת מעבד לאיטרציה 1. מדפיס \"Child 2 (PID Y2) finished work iteration 1, now sleeping\".\n    *   C2 נחסם למשך `100ms`. יתעורר ב-`148ms + 100ms = 248ms`.\n    *   RQ: `[C3]`.\n    *   **החלפת קשר:** C2 -> C3 (`1ms`).\n*   **t=149ms:** C3 ממשיך לרוץ. מסיים את `10ms` הנותרים של עבודת המעבד.\n*   **t=149ms + 10ms = 159ms:** C3 מסיים עבודת מעבד לאיטרציה 1. מדפיס \"Child 3 (PID Y3) finished work iteration 1, now sleeping\".\n    *   C3 נחסם למשך `100ms`. יתעורר ב-`159ms + 100ms = 259ms`.\n    *   RQ: `[]` (המעבד עובר למצב סרק).\n    *   **החלפת קשר:** C3 -> Idle (`1ms`).\n*   **t=160ms - t=237ms:** המעבד במצב סרק.\n\n*   **t=237ms:** C1 מתעורר ומוכן לריצה. RQ: `[C1]`.\n    *   **החלפת קשר:** Idle -> C1 (`1ms`).\n*   **t=238ms:** C1 מתחיל לרוץ (איטרציה 2). מדפיס \"Child 1 (PID Y1) starting work iteration 2\".\n*   **t=248ms:** C2 מתעורר ומוכן לריצה. RQ: `[C1, C2]`.\n*   **t=238ms + 20ms = 258ms:** קוונטום של C1 נגמר. נותרו ל-C1 `30ms` עבודת מעבד לאיטרציה זו.\n    *   RQ: `[C2, C1]`.\n    *   **החלפת קשר:** C1 -> C2 (`1ms`).\n*   **t=259ms:** C2 מתחיל לרוץ (איטרציה 2). מדפיס \"Child 2 (PID Y2) starting work iteration 2\".\n*   **t=259ms:** C3 מתעורר ומוכן לריצה. RQ: `[C1, C3]` (C2 רץ).\n*   **t=259ms + 20ms = 279ms:** קוונטום של C2 נגמר. נותרו ל-C2 `30ms` עבודת מעבד לאיטרציה זו.\n    *   RQ: `[C1, C3, C2]`.\n    *   **החלפת קשר:** C2 -> C1 (`1ms`).\n*   **t=280ms:** C1 ממשיך לרוץ.\n*   **t=280ms + 20ms = 300ms:** קוונטום של C1 נגמר. נותרו ל-C1 `10ms` עבודת מעבד לאיטרציה זו.\n    *   RQ: `[C3, C2, C1]`.\n    *   **החלפת קשר:** C1 -> C3 (`1ms`).\n*   **t=301ms:** C3 מתחיל לרוץ (איטרציה 2). מדפיס \"Child 3 (PID Y3) starting work iteration 2\".\n*   **t=301ms + 20ms = 321ms:** קוונטום של C3 נגמר. נותרו ל-C3 `30ms` עבודת מעבד לאיטרציה זו.\n    *   RQ: `[C2, C1, C3]`.\n    *   **החלפת קשר:** C3 -> C2 (`1ms`).\n*   **t=322ms:** C2 ממשיך לרוץ.\n*   **t=322ms + 20ms = 342ms:** קוונטום של C2 נגמר. נותרו ל-C2 `10ms` עבודת מעבד לאיטרציה זו.\n    *   RQ: `[C1, C3, C2]`.\n    *   **החלפת קשר:** C2 -> C1 (`1ms`).\n*   **t=343ms:** C1 ממשיך לרוץ. מסיים את `10ms` הנותרים של עבודת המעבד.\n*   **t=343ms + 10ms = 353ms:** C1 מסיים עבודת מעבד לאיטרציה 2. מדפיס \"Child 1 (PID Y1) finished work iteration 2, now sleeping\".\n    *   C1 נחסם למשך `100ms`. יתעורר ב-`353ms + 100ms = 453ms`.\n    *   RQ: `[C3, C2]`.\n    *   **החלפת קשר:** C1 -> C3 (`1ms`).\n*   **t=354ms:** C3 ממשיך לרוץ.\n*   **t=354ms + 20ms = 374ms:** קוונטום של C3 נגמר. נותרו ל-C3 `10ms` עבודת מעבד לאיטרציה זו.\n    *   RQ: `[C2, C3]`.\n    *   **החלפת קשר:** C3 -> C2 (`1ms`).\n*   **t=375ms:** C2 ממשיך לרוץ. מסיים את `10ms` הנותרים של עבודת המעבד.\n*   **t=375ms + 10ms = 385ms:** C2 מסיים עבודת מעבד לאיטרציה 2. מדפיס \"Child 2 (PID Y2) finished work iteration 2, now sleeping\".\n    *   C2 נחסם למשך `100ms`. יתעורר ב-`385ms + 100ms = 485ms`.\n    *   RQ: `[C3]`.\n    *   **החלפת קשר:** C2 -> C3 (`1ms`).\n*   **t=386ms:** C3 ממשיך לרוץ. מסיים את `10ms` הנותרים של עבודת המעבד.\n*   **t=386ms + 10ms = 396ms:** C3 מסיים עבודת מעבד לאיטרציה 2. מדפיס \"Child 3 (PID Y3) finished work iteration 2, now sleeping\".\n    *   C3 נחסם למשך `100ms`. יתעורר ב-`396ms + 100ms = 496ms`.\n    *   RQ: `[]` (המעבד עובר למצב סרק).\n    *   **החלפת קשר:** C3 -> Idle (`1ms`).\n*   **t=397ms - t=453ms:** המעבד במצב סרק.\n\n*   **t=453ms:** C1 מתעורר ומוכן לריצה. RQ: `[C1]`.\n    *   **החלפת קשר:** Idle -> C1 (`1ms`).\n*   **t=454ms:** C1 רץ. מדפיס \"Child 1 (PID Y1) finished all tasks.\". C1 מסיים ויוצא.\n    *   P מקבל הודעה על יציאת C1, אך עדיין ממתין ל-C2 ו-C3.\n    *   RQ: `[]` (המעבד עובר למצב סרק).\n    *   **החלפת קשר:** C1 -> Idle (`1ms`).\n*   **t=455ms - t=485ms:** המעבד במצב סרק.\n\n*   **t=485ms:** C2 מתעורר ומוכן לריצה. RQ: `[C2]`.\n    *   **החלפת קשר:** Idle -> C2 (`1ms`).\n*   **t=486ms:** C2 רץ. מדפיס \"Child 2 (PID Y2) finished all tasks.\". C2 מסיים ויוצא.\n    *   P מקבל הודעה על יציאת C2, אך עדיין ממתין ל-C3.\n    *   RQ: `[]` (המעבד עובר למצב סרק).\n    *   **החלפת קשר:** C2 -> Idle (`1ms`).\n*   **t=487ms - t=496ms:** המעבד במצב סרק.\n\n*   **t=496ms:** C3 מתעורר ומוכן לריצה. RQ: `[C3]`.\n    *   **החלפת קשר:** Idle -> C3 (`1ms`).\n*   **t=497ms:** C3 רץ. מדפיס \"Child 3 (PID Y3) finished all tasks.\". C3 מסיים ויוצא.\n    *   P מקבל הודעה על יציאת C3. P סיים להמתין ומוכן לריצה. RQ: `[P]`.\n    *   **החלפת קשר:** C3 -> P (`1ms`).\n*   **t=498ms:** P רץ. מדפיס \"Parent (PID X) finished, all children done.\". P מסיים ויוצא.\n\n**זמן הריצה הכולל המינימלי של התוכנית:** `498ms`.\n\n**סה\"כ החלפות קשר:** 24 החלפות קשר (כולל החלפות מ/אל מצב סרק). `24 * 1ms = 24ms` זמן תקורה.\n\n**סדר הדפסות הפלט האפשרי (כולל זמנים משוערים):**\n\n1.  `t=0ms: Parent (PID X) starting.`\n2.  `t=1ms: Child 1 (PID Y1) starting work iteration 1`\n3.  `t=22ms: Child 2 (PID Y2) starting work iteration 1`\n4.  `t=43ms: Child 3 (PID Y3) starting work iteration 1`\n5.  `t=137ms: Child 1 (PID Y1) finished work iteration 1, now sleeping`\n6.  `t=148ms: Child 2 (PID Y2) finished work iteration 1, now sleeping`\n7.  `t=159ms: Child 3 (PID Y3) finished work iteration 1, now sleeping`\n8.  `t=238ms: Child 1 (PID Y1) starting work iteration 2`\n9.  `t=259ms: Child 2 (PID Y2) starting work iteration 2`\n10. `t=301ms: Child 3 (PID Y3) starting work iteration 2`\n11. `t=353ms: Child 1 (PID Y1) finished work iteration 2, now sleeping`\n12. `t=385ms: Child 2 (PID Y2) finished work iteration 2, now sleeping`\n13. `t=396ms: Child 3 (PID Y3) finished work iteration 2, now sleeping`\n14. `t=454ms: Child 1 (PID Y1) finished all tasks.`\n15. `t=486ms: Child 2 (PID Y2) finished all tasks.`\n16. `t=497ms: Child 3 (PID Y3) finished all tasks.`\n17. `t=498ms: Parent (PID X) finished, all children done.`\n"}, "difficulty_estimation": "Hard", "_source_file": "0789__CPU_Scheduling__CodeAnalysis__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:26:19", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["CPU Scheduling", "Processes", "System Calls", "Priorities"], "content": {"text": "נתונה התוכנית הבאה, המריצה מספר תהליכי בן המבצעים עבודה עתירת מעבד (CPU-bound) וקובעים לעצמם ערכי nice שונים. יש להניח שהתוכנית רצה על מערכת לינוקס עם מעבד יחיד (Single CPU) המשתמש באלגוריתם תזמון CFS (Completely Fair Scheduler), אשר מתחשב באופן משמעותי בערכי nice של תהליכים. פלט התוכנית אינו מבוּפר (unbuffered), וכל קריאות המערכת מצליחות כצפוי.\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <sys/types.h>\n#include <errno.h>\n#include <sys/resource.h> // For setpriority() and getpriority()\n\n#define NUM_CHILDREN 3\n#define WORK_ITERATIONS 1000000000LL // Use LL for long long literal\n\nvoid child_work(int child_id, int nice_val) {\n    printf(\"Child %d (PID: %d, nice: %d) starting work...\\n\", child_id, getpid(), nice_val);\n    long long sum = 0;\n    for (long long i = 0; i < WORK_ITERATIONS; ++i) {\n        sum += i; // Simple CPU-bound operation\n    }\n    // To prevent compiler optimizing sum away if not used\n    volatile long long dummy_sum = sum; \n    (void)dummy_sum; // Suppress unused variable warning\n\n    printf(\"Child %d (PID: %d, nice: %d) finished work.\\n\", child_id, getpid(), nice_val);\n    exit(0);\n}\n\nint main() {\n    setbuf(stdout, NULL); // Unbuffered output\n\n    int nice_values[NUM_CHILDREN] = {0, 10, -5}; // Desired nice values\n    pid_t pids[NUM_CHILDREN];\n    int i;\n\n    printf(\"Parent (PID: %d) starting.\\n\", getpid());\n\n    for (i = 0; i < NUM_CHILDREN; ++i) {\n        pids[i] = fork();\n\n        if (pids[i] < 0) {\n            perror(\"fork failed\");\n            exit(1);\n        } else if (pids[i] == 0) { // Child process\n            int ret = setpriority(PRIO_PROCESS, 0, nice_values[i]); // 0 means current process\n            if (ret == -1) {\n                // If setpriority fails, it usually means permissions. For exam, assume success.\n                perror(\"setpriority failed\"); \n            }\n            child_work(i, nice_values[i]); // Pass the set nice value\n        }\n    }\n\n    // Parent waits for all children to finish\n    for (i = 0; i < NUM_CHILDREN; ++i) {\n        wait(NULL);\n    }\n\n    printf(\"Parent (PID: %d) finished.\\n\", getpid());\n    return 0;\n}\n```\n\n**שאלה:**\nתארו את הפלט הסביר ביותר של התוכנית. הסבירו מדוע פלט זה מתקבל, וכיצד אלגוריתם התזמון CFS משתמש בערכי ה-`nice` כדי לקבוע את סדר וקצב ריצת התהליכים. התייחסו במיוחד לסדר סיום העבודה של תהליכי הבן.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפלט הסביר ביותר של התוכנית יראה בערך כך (ערכי ה-PID יהיו שונים בכל ריצה):\n```\nParent (PID: XXXX) starting.\nChild 0 (PID: YYYY, nice: 0) starting work...\nChild 1 (PID: ZZZZ, nice: 10) starting work...\nChild 2 (PID: AAAA, nice: -5) starting work...\nChild 2 (PID: AAAA, nice: -5) finished work.\nChild 0 (PID: YYYY, nice: 0) finished work.\nChild 1 (PID: ZZZZ, nice: 10) finished work.\nParent (PID: XXXX) finished.\n```\n\n**הסבר:**\nאלגוריתם התזמון CFS (Completely Fair Scheduler) בלינוקס שואף להעניק לכל תהליך חלק \"הוגן\" מזמן המעבד. הוא עושה זאת על ידי מעקב אחר \"זמן הריצה הווירטואלי\" (vruntime) של כל תהליך. תהליכים בעלי vruntime נמוך יותר מקבלים עדיפות בריצה.\n\nערכי ה-`nice` משפיעים על האופן שבו ה-vruntime של תהליך מתקדם. ערך `nice` נמוך (כלומר, עדיפות גבוהה יותר) גורם ל-vruntime של התהליך להתקדם לאט יותר, מה שאומר שהוא יקבל יותר זמן מעבד יחסית לתהליכים עם ערכי `nice` גבוהים יותר. לעומת זאת, ערך `nice` גבוה (עדיפות נמוכה יותר) גורם ל-vruntime להתקדם מהר יותר, והתהליך יקבל פחות זמן מעבד.\n\nבתוכנית הנתונה:\n*   **תהליך בן 0** מקבל `nice = 0` (ערך ברירת מחדל). ה-vruntime שלו יתקדם בקצב רגיל.\n*   **תהליך בן 1** מקבל `nice = 10` (עדיפות נמוכה). ה-vruntime שלו יתקדם מהר יותר, ולכן הוא יקבל פחות זמן מעבד.\n*   **תהליך בן 2** מקבל `nice = -5` (עדיפות גבוהה). ה-vruntime שלו יתקדם לאט יותר, ולכן הוא יקבל יותר זמן מעבד.\n\nמכיוון שהתהליכים כולם CPU-bound ומבצעים עבודה זהה (אותו מספר איטרציות בלולאה), סדר סיום העבודה שלהם ייקבע ישירות על ידי העדיפות שקיבלו מהמתזמן:\n1.  **תהליך בן 2 (`nice = -5`)** יסיים ראשון, מכיוון שיש לו את העדיפות הגבוהה ביותר ויקבל את מרבית זמן המעבד.\n2.  **תהליך בן 0 (`nice = 0`)** יסיים שני, מכיוון שיש לו עדיפות בינונית.\n3.  **תהליך בן 1 (`nice = 10`)** יסיים אחרון, מכיוון שיש לו את העדיפות הנמוכה ביותר ויקבל את מעט זמן המעבד מבין השלושה.\n\nהודעות ה\"starting work\" עשויות להופיע בסדר שונה, בהתאם לסדר שבו מערכת ההפעלה מתזמנת את יצירת התהליכים והגדרת ה-`nice` שלהם, אך סדר הודעות ה\"finished work\" יהיה עקבי כפי שתואר לעיל עקב השפעת ה-`nice` על הקצאת זמן המעבד."}, "difficulty_estimation": "Hard", "_source_file": "0791__CPU_Scheduling__CodeAnalysis__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:28:13", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["CPU Scheduling", "Concurrency", "Processes", "System Calls"], "content": {"text": "נתונה התוכנית הבאה:\n\nהניחו את ההנחות הבאות לגבי סביבת הריצה והתזמון:\n1.  **מעבד יחיד**: המערכת כוללת מעבד יחיד.\n2.  **אלגוריתם תזמון**: Round Robin (RR).\n3.  **קוואנטום זמן**: קוואנטום הזמן (Q) הוא 2 יחידות זמן.\n4.  **עלות פעולות**: \n    *   כל קריאה ל-`printf(\"...\")` צורכת בדיוק יחידת זמן אחת. `fflush(stdout)` מיידית וזניחה.\n    *   קריאות מערכת כמו `fork()`, `wait()`, `exit()` צורכות זמן זניח.\n    *   החלפת הקשר (Context Switch) צורכת זמן זניח.\n5.  **`usleep`**: קריאה ל-`usleep(1000 * 100)` גורמת לתהליך להיחסם למשך 100 יחידות זמן. לאחר מכן הוא חוזר לתור המוכנים (ready queue).\n6.  **סדר תהליכים ראשוני**: התהליך הראשי (P0) מתחיל. לאחר שתי קריאות ה-`fork` הראשוניות, תור המוכנים מכיל את P0, P1, P2 בסדר זה.\n7.  **תור המוכנים**: תהליכים חדשים שמוכנים להרצה מתווספים לסוף תור המוכנים. תהליך שסיים את הקוואנטום שלו או נחסם מועבר לסוף תור המוכנים (אם הוא עדיין מוכן).\n\nציירו את סדר ההרצה של התהליכים וכתבו את הפלט המלא והמדויק של התוכנית. הסבירו שלב אחר שלב כיצד הגעתם לפלט זה, תוך התייחסות למצב תור המוכנים בכל נקודת החלטת תזמון.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\n// Function for CPU-intensive child\nvoid child_cpu_intensive(int id) {\n    for (int i = 1; i <= 5; ++i) {\n        printf(\"P%d-%d \", id, i);\n        fflush(stdout); // Ensures immediate output\n    }\n    exit(0);\n}\n\n// Function for mixed CPU/IO child\nvoid child_mixed(int id) {\n    printf(\"P%d-A \", id);\n    fflush(stdout);\n    usleep(1000 * 100); // Simulate I/O or block for 100 time units\n    printf(\"P%d-B \", id);\n    fflush(stdout);\n    exit(0);\n}\n\nint main() {\n    pid_t pid1, pid2;\n\n    printf(\"Parent Start \");\n    fflush(stdout);\n\n    pid1 = fork();\n    if (pid1 == 0) { // Child 1\n        child_cpu_intensive(1);\n    }\n\n    pid2 = fork();\n    if (pid2 == 0) { // Child 2\n        child_mixed(2);\n    }\n\n    // Parent waits for children to finish\n    wait(NULL);\n    wait(NULL);\n\n    printf(\"Parent End\\n\");\n    fflush(stdout);\n\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "נבצע מעקב מפורט אחר מצב תור המוכנים (Ready Queue - RQ) והפלט של התוכנית:\n\n**מצב התחלתי (זמן 0):**\n*   P0 (התהליך הראשי) מתחיל. הוא מדפיס \"Parent Start \". (צורך יחידת זמן 1).\n*   P0 מבצע `fork()` ליצירת P1. P1 נוסף ל-RQ.\n*   P0 מבצע `fork()` ליצירת P2. P2 נוסף ל-RQ.\n*   **RQ**: [P0, P1, P2]\n*   **פלט**: \"Parent Start \"\n\n**זמן 1 (P0 מתחיל ריצה):**\n*   P0 מוקצה למעבד. הוא רץ למשך הקוואנטום שלו (2 יחידות זמן).\n*   P0 מבצע `wait(NULL)` (צורך זמן זניח). P0 נחסם כיוון שילדיו עדיין לא סיימו.\n*   **RQ**: [P1, P2]\n*   **Blocked Queue (BQ)**: [P0 (ממתין לילדים)]\n*   **פלט**: \"Parent Start \"\n\n**זמן 3 (P1 מתחיל ריצה):**\n*   P1 מוקצה למעבד. הוא רץ למשך הקוואנטום שלו (2 יחידות זמן).\n*   P1 מדפיס \"P1-1 \" (יחידת זמן 1).\n*   P1 מדפיס \"P1-2 \" (יחידת זמן 1).\n*   הקוואנטום של P1 מסתיים. P1 מועבר לסוף ה-RQ.\n*   **RQ**: [P2, P1]\n*   **BQ**: [P0]\n*   **פלט**: \"Parent Start P1-1 P1-2 \"\n\n**זמן 5 (P2 מתחיל ריצה):**\n*   P2 מוקצה למעבד. הוא רץ למשך הקוואנטום שלו (2 יחידות זמן).\n*   P2 מדפיס \"P2-A \" (יחידת זמן 1).\n*   P2 מבצע `usleep(1000 * 100)`. P2 נחסם למשך 100 יחידות זמן (עד זמן 5 + 100 = זמן 105).\n*   **RQ**: [P1]\n*   **BQ**: [P0, P2 (ישן עד זמן 105)]\n*   **פלט**: \"Parent Start P1-1 P1-2 P2-A \"\n\n**זמן 6 (P1 מתחיל ריצה):**\n*   P1 מוקצה למעבד. הוא רץ למשך הקוואנטום שלו (2 יחידות זמן).\n*   P1 מדפיס \"P1-3 \" (יחידת זמן 1).\n*   P1 מדפיס \"P1-4 \" (יחידת זמן 1).\n*   הקוואנטום של P1 מסתיים. P1 מועבר לסוף ה-RQ.\n*   **RQ**: [P1]\n*   **BQ**: [P0, P2 (ישן עד זמן 105)]\n*   **פלט**: \"Parent Start P1-1 P1-2 P2-A P1-3 P1-4 \"\n\n**זמן 8 (P1 מתחיל ריצה):**\n*   P1 מוקצה למעבד. הוא רץ (נותרה לו יחידת הדפסה אחת).\n*   P1 מדפיס \"P1-5 \" (יחידת זמן 1).\n*   P1 מסיים את הלולאה שלו ומבצע `exit(0)`. P1 מסיים.\n*   P0 מקבל הודעה ש-P1 סיים, אך עדיין ממתין ל-P2. P0 נשאר חסום.\n*   **RQ**: [] (אין תהליכים מוכנים)\n*   **BQ**: [P0, P2 (ישן עד זמן 105)]\n*   **פלט**: \"Parent Start P1-1 P1-2 P2-A P1-3 P1-4 P1-5 \"\n\n**זמן 9 עד זמן 105:**\n*   המעבד נותר סרק (Idle) כיוון שאין תהליכים מוכנים.\n*   בזמן 105: P2 מסיים את ה-`usleep` שלו. P2 עובר למצב מוכן ונוסף ל-RQ.\n*   **RQ**: [P2]\n*   **BQ**: [P0]\n\n**זמן 105 (P2 מתחיל ריצה):**\n*   P2 מוקצה למעבד. הוא רץ (נותרה לו יחידת הדפסה אחת).\n*   P2 מדפיס \"P2-B \" (יחידת זמן 1).\n*   P2 מסיים ומבצע `exit(0)`. P2 מסיים.\n*   P0 מקבל הודעה ש-P2 סיים. כיוון ש-P0 המתין לשני ילדיו וכעת שניהם סיימו, P0 משתחרר מהחסימה ונוסף ל-RQ.\n*   **RQ**: [P0]\n*   **BQ**: []\n*   **פלט**: \"Parent Start P1-1 P1-2 P2-A P1-3 P1-4 P1-5 P2-B \"\n\n**זמן 106 (P0 מתחיל ריצה):**\n*   P0 מוקצה למעבד. הוא רץ (נותרה לו יחידת הדפסה אחת).\n*   P0 מדפיס \"Parent End\\n\" (יחידת זמן 1).\n*   P0 מסיים את פעולתו ומבצע `return 0`. P0 מסיים.\n*   **RQ**: []\n*   **BQ**: []\n*   **פלט סופי**: \"Parent Start P1-1 P1-2 P2-A P1-3 P1-4 P1-5 P2-B Parent End\\n\""}, "difficulty_estimation": "Hard", "_source_file": "0792__CPU_Scheduling__CodeAnalysis__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:28:49", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Concurrency", "Synchronization", "Threads"], "content": {"text": "מהי המטרה העיקרית של שימוש במנגנוני סנכרון (כמו מנעולים או סמפורים) בתוכנית מרובת חוטים?", "code_snippet": null, "options": ["א. להאיץ את ביצוע התוכנית על ידי חלוקת עבודה.", "ב. למנוע מצבי מרוץ (race conditions) ולוודא עקביות נתונים.", "ג. לאפשר לחוטים לרוץ באופן עצמאי לחלוטין ללא תלות הדדית.", "ד. להקצות זיכרון נפרד לכל חוט במערכת ההפעלה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. מנגנוני סנכרון (כמו מנעולים וסמפורים) נועדו לוודא שגישה למשאבים משותפים נעשית באופן מבוקר, למנוע מצבי מרוץ ובכך לשמור על עקביות הנתונים בתוכנית מרובת חוטים. הם לא בהכרח מאיצים את הביצוע (ולעיתים אף מאטים), ואינם קשורים להקצאת זיכרון נפרדת או לריצה עצמאית לחלוטין."}, "difficulty_estimation": "Easy", "_source_file": "0793__Concurrency__MultipleChoice__Easy.json", "_topic_hint": "Concurrency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:28:57", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Concurrency", "Synchronization", "Mutual Exclusion", "Race Condition"], "content": {"text": "מהי המטרה העיקרית של שימוש במנגנוני סנכרון (כמו מנעולים או סמפורים) בקטע קריטי?", "code_snippet": null, "options": ["א. להבטיח שחוטים יתבצעו לפי סדר מסוים.", "ב. למנוע מצב מרוץ על משאבים משותפים.", "ג. לשפר את ביצועי התוכנית על ידי הפחתת זמן ההמתנה.", "ד. לאפשר לחוטים שונים לגשת למשאבים פרטיים."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. המטרה העיקרית של שימוש במנגנוני סנכרון בקטע קריטי היא להבטיח מניעה הדדית (mutual exclusion), ובכך למנוע מצבי מרוץ ולוודא שרק חוט אחד ניגש למשאב משותף בכל רגע נתון."}, "difficulty_estimation": "Easy", "_source_file": "0794__Concurrency__MultipleChoice__Easy.json", "_topic_hint": "Concurrency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:29:04", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Concurrency", "Synchronization", "Mutex"], "content": {"text": "מהי המטרה העיקרית של מנעול (mutex) בהקשר של תכנות מקבילי?", "code_snippet": null, "options": ["א. לאפשר לכמה חוטים לגשת למשאב משותף בו-זמנית.", "ב. להבטיח שרק חוט אחד יוכל לגשת לקטע קריטי בכל רגע נתון.", "ג. לתזמן את סדר הריצה של חוטים על המעבד.", "ד. למנוע קיפאון (deadlock) באופן מוחלט."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. המטרה העיקרית של מנעול (mutex) היא להבטיח מניעה הדדית (mutual exclusion), כלומר שרק חוט אחד יוכל להיכנס לקטע קריטי ולגשת למשאב משותף בכל רגע נתון, ובכך למנוע מצבי מרוץ (race conditions) ולוודא עקביות נתונים."}, "difficulty_estimation": "Easy", "_source_file": "0795__Concurrency__MultipleChoice__Easy.json", "_topic_hint": "Concurrency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:29:11", "_subject": "Concurrency"}, {"id": 4, "type": "MultipleChoice", "topic": ["Concurrency", "Synchronization", "Mutex"], "content": {"text": "מהי המטרה העיקרית של שימוש במנעול (mutex) בתכנות מקבילי?", "code_snippet": null, "options": ["א. לאפשר לחוטים שונים לרוץ מהר יותר.", "ב. לוודא שרק חוט אחד ייגש לקטע קריטי בכל רגע נתון.", "ג. לסנכרן את קריאת הנתונים מכל הדיסקים במערכת.", "ד. למנוע מצב של רעב (starvation) של חוטים."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. מנעול (mutex) משמש להבטחת מניעה הדדית (mutual exclusion) בקטע קריטי. מטרתו העיקרית היא לוודא שרק חוט אחד יוכל לגשת למשאב משותף או לבצע קוד מסוים (הקטע הקריטי) בכל רגע נתון, ובכך למנוע מצבי מרוץ (race conditions) ולוודא את נכונות התוצאה."}, "difficulty_estimation": "Easy", "_source_file": "0796__Concurrency__MultipleChoice__Easy.json", "_topic_hint": "Concurrency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:29:19", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Concurrency", "Synchronization", "Mutex"], "content": {"text": "מהי המטרה העיקרית של שימוש במנעול (mutex) בתכנות מקבילי?", "code_snippet": null, "options": ["א. להבטיח מניעה הדדית (mutual exclusion) על משאבים משותפים.", "ב. לאפשר לחוטים לשתף נתונים בקלות רבה יותר.", "ג. להגדיר את סדר הביצוע של חוטים שונים.", "ד. למנוע קיפאון (deadlock) במערכת."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "א. המטרה העיקרית של מנעול (mutex) היא להבטיח מניעה הדדית (mutual exclusion), כלומר, שרק חוט אחד יוכל לגשת לקטע קוד קריטי או למשאב משותף בכל רגע נתון. זה מונע מצבי מרוץ (race conditions) ושומר על עקביות הנתונים."}, "difficulty_estimation": "Easy", "_source_file": "0797__Concurrency__MultipleChoice__Easy.json", "_topic_hint": "Concurrency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:29:27", "_subject": "Concurrency"}, {"id": 4, "type": "MultipleChoice", "topic": ["Concurrency", "Synchronization", "Mutex"], "content": {"text": "מהי המטרה העיקרית של שימוש במנעול (mutex) בתכנות מקבילי?", "code_snippet": null, "options": ["א. למנוע מצבי מרוץ (race conditions) על ידי הבטחת גישה בלעדית למשאב משותף.", "ב. לאפשר לחוטים שונים לרוץ בו זמנית על מעבדים שונים.", "ג. להגדיל את מהירות הביצוע הכוללת של התוכנית.", "ד. לנהל את זיכרון המערכת בין חוטים שונים.", "ה. לאפשר תקשורת ישירה בין תהליכים נפרדים."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "א'. מנעול (mutex) משמש להגנה על קטעים קריטיים בקוד, על ידי הבטחת שרק חוט אחד יוכל לגשת למשאב משותף מסוים (כמו משתנה גלובלי או קובץ) בכל רגע נתון. זה מונע מצבי מרוץ ותוצאות בלתי צפויות."}, "difficulty_estimation": "Easy", "_source_file": "0798__Concurrency__MultipleChoice__Easy.json", "_topic_hint": "Concurrency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:29:35", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Concurrency", "Synchronization", "Mutual Exclusion"], "content": {"text": "מהי מטרתו העיקרית של מנעול (mutex) בתכנות מקבילי?", "code_snippet": null, "options": ["א. לאפשר לחוטים שונים לשתף נתונים.", "ב. להבטיח שרק חוט אחד יבצע קטע קוד קריטי בכל רגע נתון.", "ג. למנוע מצב מרוץ (race condition) על ידי הקפאת חוטים.", "ד. לסנכרן את סדר ההרצה של חוטים שונים.", "ה. להגדיל את מהירות הביצוע של תוכנית מקבילית."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. מטרתו העיקרית של מנעול (mutex) היא לאכוף מניעה הדדית (mutual exclusion), כלומר להבטיח שרק חוט אחד יוכל להיכנס לקטע קריטי ולגשת למשאב משותף בזמן נתון, ובכך למנוע מצבי מרוץ ואי-עקביות בנתונים."}, "difficulty_estimation": "Easy", "_source_file": "0799__Concurrency__MultipleChoice__Easy.json", "_topic_hint": "Concurrency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:29:43", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Concurrency", "Synchronization", "Mutual Exclusion"], "content": {"text": "מהי המטרה העיקרית של שימוש במנעול (mutex) בתכנות מקבילי?", "code_snippet": null, "options": ["א. למנוע מצב של קיפאון (deadlock) בכל מקרה.", "ב. להבטיח שרק חוט אחד ייגש למשאב משותף בקטע קריטי בכל רגע נתון.", "ג. לשפר את ביצועי התוכנית על ידי הפחתת זמן המתנה של חוטים.", "ד. לאפשר לחוטים שונים לשתף מידע ביעילות ללא צורך בסנכרון."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. מנעול (mutex) משמש להבטחת מניעה הדדית (mutual exclusion), כלומר, להבטיח שרק חוט אחד יוכל לגשת לקטע קריטי המשתמש במשאב משותף בכל רגע נתון, ובכך למנוע מצבי מרוץ (race conditions)."}, "difficulty_estimation": "Easy", "_source_file": "0800__Concurrency__MultipleChoice__Easy.json", "_topic_hint": "Concurrency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:29:49", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Concurrency", "Race Condition", "Shared Memory"], "content": {"text": "נתון קטע הקוד הבא המציג שני תהליכונים (threads) המנסים להגדיל מונה משותף. מהו הערך הסופי האפשרי הנמוך ביותר של המשתנה `counter` לאחר ששני התהליכונים סיימו את ריצתם, בהנחה שכל תהליכון מבצע 1000 הגדלות וללא כל מנגנון סנכרון?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0;\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < 1000; ++i) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n    pthread_create(&tid1, NULL, increment_counter, NULL);\n    pthread_create(&tid2, NULL, increment_counter, NULL);\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n    printf(\"Final counter value: %d\\n\", counter);\n    return 0;\n}", "options": ["0", "1", "1000", "כל ערך בין 1 ל-2000 (כולל)"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "כל ערך בין 1 ל-2000 (כולל)", "explanation": "קיימת כאן בעיית תחרות (Race Condition) בגלל שפעולת ההגדלה (`counter++`) אינה אטומית. היא מורכבת משלושה שלבים: קריאת הערך, הגדלתו, וכתיבת הערך החדש. ללא מנגנון סנכרון (כמו Mutex), ייתכן מצב שבו שני תהליכונים קוראים את אותו ערך של `counter`, שניהם מגדילים אותו, ושניהם כותבים בחזרה את הערך שלהם. במקרה כזה, אחת ההגדלות \"נאבדת\".\n\nהערך המקסימלי האפשרי הוא 2000 (כאשר אין איבוד של הגדלות, לדוגמה אם התהליכונים רצים בטור או על מעבד יחיד ללא החלפת הקשר).\n\nהערך המינימלי האפשרי הוא 1. לדוגמה, אם תהליכון A קורא את `counter` (שהוא 0), ואז מופסק. תהליכון B מבצע את כל 1000 ההגדלות שלו בהצלחה, כך ש`counter` מגיע ל-1000. לאחר מכן, תהליכון A ממשיך ומבצע את פעולת הכתיבה שלו (כותב 1, שכן הוא הגדיל את ה-0 שקרא בהתחלה). במקרה זה, הערך הסופי יהיה 1.\n\nלכן, כל ערך בין 1 ל-2000 (כולל) אפשרי."}, "difficulty_estimation": "Medium", "_source_file": "0801__Concurrency__MultipleChoice__Medium.json", "_topic_hint": "Concurrency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:30:01", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Concurrency", "Synchronization", "Race Conditions"], "content": {"text": "אם כל הגישה למשתנה גלובלי משותף (shared global variable) מוגנת על ידי אותו mutex, אז מובטח שלא תתרחש race condition על משתנה זה.", "code_snippet": null, "options": ["נכון", "לא נכון"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "נכון", "explanation": "נכון. race condition מתרחשת כאשר מספר תהליכים או תהליכונים ניגשים למשאב משותף בו-זמנית, ולפחות אחד מהם מבצע שינוי, כאשר סדר הגישה משפיע על התוצאה הסופית. אם כל הגישות למשתנה ספציפי מוגנות על ידי אותו mutex, אז רק תהליך או תהליכון אחד יכול לגשת למשתנה בכל רגע נתון (כי ה-mutex יאפשר כניסה רק לתהליך אחד בכל פעם), ובכך נמנעת race condition על אותו משתנה. חשוב לציין שזה לא מבטיח שהתוכנית כולה תהיה נכונה, או שאין race conditions על משתנים אחרים, אלא רק על המשתנה המדובר."}, "difficulty_estimation": "Medium", "_source_file": "0802__Concurrency__MultipleChoice__Medium.json", "_topic_hint": "Concurrency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:30:10", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Concurrency", "Synchronization", "Mutexes"], "content": {"text": "בהינתן mutex מסוג POSIX (pthreads) סטנדרטי, מהי התוצאה הסבירה ביותר כאשר תהליך מנסה לבצע unlock על mutex שאינו נעול על ידו?", "code_snippet": null, "options": ["הפעולה מצליחה, וה-mutex הופך ללא נעול.", "התהליך נכנס למצב deadlock.", "הפעולה גורמת לשגיאת זמן ריצה (runtime error) או התנהגות בלתי מוגדרת (undefined behavior).", "התהליך ממתין עד שה-mutex יהיה זמין."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "הפעולה גורמת לשגיאת זמן ריצה (runtime error) או התנהגות בלתי מוגדרת (undefined behavior).", "explanation": "בתקן POSIX, ניסיון לשחרר mutex באמצעות `pthread_mutex_unlock` על ידי תהליך שאינו מחזיק בו מוביל להתנהגות בלתי מוגדרת (undefined behavior). בפועל, הדבר עלול להתבטא בקריסת התוכנית, שחיתות נתונים (זיכרון), או מצב שבו ה-mutex נראה כפנוי למרות שתהליך אחר עדיין עשוי להחזיק בו באופן לוגי, מה שמוביל ל-race conditions או deadlocks עתידיים. על כן, יש לוודא תמיד שתהליך משחרר רק mutex שהוא עצמו נעל."}, "difficulty_estimation": "Medium", "_source_file": "0803__Concurrency__MultipleChoice__Medium.json", "_topic_hint": "Concurrency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:30:18", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Concurrency", "Race Conditions", "Threads"], "content": {"text": "נתונה תוכנית C המשתמשת ב-pthreads כמתואר מטה. מהו ערכו הסופי האפשרי של המשתנה הגלובלי `counter` לאחר הרצת התוכנית?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0; // Shared variable\n\nvoid *increment(void *arg) {\n    for (int i = 0; i < 100000; i++) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_create(&tid1, NULL, increment, NULL);\n    pthread_create(&tid2, NULL, increment, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    printf(\"Final counter: %d\\n\", counter);\n    return 0;\n}", "options": ["200000", "100000", "ערך לא דטרמיניסטי שקטן או שווה ל-200000", "ערך לא דטרמיניסטי שגדול מ-200000"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ערך לא דטרמיניסטי שקטן או שווה ל-200000", "explanation": "התוכנית סובלת מתנאי מירוץ (race condition) על המשתנה המשותף `counter`. הפעולה `counter++` אינה אטומית; היא מורכבת מקריאה (read) של הערך הנוכחי, הגדלה (increment) שלו, וכתיבה (write) של הערך החדש. כאשר שני תהליכונים (threads) מנסים לבצע פעולה זו בו-זמנית ללא סנכרון (לדוגמה, באמצעות mutex), ייתכן שאחד התהליכונים יקרא את הערך, תהליכון אחר יקרא את אותו ערך, שניהם יגדילו אותו, ושניהם יכתבו את הערך המוגדל, ובכך תאבד אחת ההגדלות. לכן, הערך הסופי של `counter` יהיה לא דטרמיניסטי ותמיד יהיה קטן או שווה ל-200000. האפשרות הנפוצה ביותר היא שהערך יהיה קטן מ-200000, אך תיאורטית, אם לוח הזמנים יתמזל באופן קיצוני ותהליכון אחד יסיים את כל הלולאה שלו לפני שהשני מבצע ולו הגדלה אחת, הוא יכול להגיע ל-200000. לכן, התשובה המדויקת ביותר היא ערך לא דטרמיניסטי שקטן או שווה ל-200000."}, "difficulty_estimation": "Medium", "_source_file": "0804__Concurrency__MultipleChoice__Medium.json", "_topic_hint": "Concurrency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:30:33", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Concurrency", "Race Conditions", "Synchronization"], "content": {"text": "בהינתן קטע הקוד הבא, שבו מספר תהליכונים (threads) מריצים את הפונקציה `increment_function` במקביל ומנסים להגדיל את המונה הגלובלי `global_counter`:\n\nהאם המונה הגלובלי `global_counter` יגיע תמיד לערך המצופה (מספר התהליכונים * 10000) בסיום ריצת כל התהליכונים, גם ללא שימוש במנגנוני סנכרון?", "code_snippet": "int global_counter = 0;\n\nvoid increment_function() {\n    for (int i = 0; i < 10000; ++i) {\n        global_counter++; // פעולה לא אטומית\n    }\n}", "options": ["נכון", "לא נכון"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "לא נכון", "explanation": "לא נכון. הפעולה `global_counter++` אינה אטומית. היא מורכבת ממספר שלבים (קריאת הערך הנוכחי, הגדלה, וכתיבת הערך החדש). כאשר מספר תהליכונים מנסים לבצע פעולה זו במקביל ללא מנגנון סנכרון (כמו mutex), עלולה להתרחש תחרות (race condition). במצב כזה, ייתכן שתהליכון אחד יקרא ערך, יתבצע מיתוג הקשר (context switch) לתהליכון אחר שיקרא את אותו ערך, ושניהם יגדילו ויכתבו בחזרה את הערך המוגדל, מה שיגרום לאיבוד עדכונים. כתוצאה מכך, הערך הסופי של `global_counter` יהיה לרוב נמוך מהערך המצופה."}, "difficulty_estimation": "Medium", "_source_file": "0805__Concurrency__MultipleChoice__Medium.json", "_topic_hint": "Concurrency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:30:44", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Concurrency", "Deadlock"], "content": {"text": "קיום של תנאי No Preemption הכרחי על מנת שיתרחש Deadlock.\nנכון / לא נכון", "code_snippet": null, "options": ["נכון", "לא נכון"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "נכון", "explanation": "נכון. ארבעת התנאים ההכרחיים (Conditions for Deadlock) על מנת שיתרחש Deadlock הם: Mutual Exclusion, Hold and Wait, No Preemption ו-Circular Wait. אם אחד מהתנאים הללו לא מתקיים, לא יכול להיווצר Deadlock. לפיכך, קיומו של No Preemption הוא אכן הכרחי."}, "difficulty_estimation": "Medium", "_source_file": "0806__Concurrency__MultipleChoice__Medium.json", "_topic_hint": "Concurrency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:30:51", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Concurrency", "Mutexes", "Deadlocks"], "content": {"text": "שימוש במנעול (mutex) לבדו מבטיח שלא יתרחשו מצבי קיפאון (deadlocks) במערכת.\nנכון / לא נכון", "code_snippet": null, "options": ["נכון", "לא נכון"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "לא נכון", "explanation": "לא נכון. מנעול (mutex) נועד להבטיח בלעדיות לגישה למשאב משותף ובכך למנוע תנאי מרוץ (race conditions) בתוך קטע קריטי. עם זאת, הוא אינו מונע מצבי קיפאון (deadlocks) בפני עצמו. למשל, אם שני תהליכים דורשים שני משאבים שונים (A ו-B), כאשר תהליך 1 מחזיק את A ומנסה לנעול את B, ותהליך 2 מחזיק את B ומנסה לנעול את A, ייווצר מצב קיפאון. מנעולים הם תנאי הכרחי למניעת תנאי מרוץ, אך לא מספיקים למניעת קיפאון, אשר דורש אסטרטגיות נוספות כמו סדר נעילה קבוע, זיהוי ושחזור, או מניעת אחד מארבעת התנאים של הולד (Hold and Wait, No Preemption, Mutual Exclusion, Circular Wait)."}, "difficulty_estimation": "Medium", "_source_file": "0807__Concurrency__MultipleChoice__Medium.json", "_topic_hint": "Concurrency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:30:59", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Concurrency", "Deadlock"], "content": {"text": "איזה מהתנאים הבאים אינו הכרחי להתרחשות Deadlock במערכת?", "code_snippet": null, "options": ["מניעה הדדית (Mutual Exclusion)", "החזקה והמתנה (Hold and Wait)", "המתנה מעגלית (Circular Wait)", "שחרור משאבים (Resource Release)"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "שחרור משאבים (Resource Release)", "explanation": "ארבעת התנאים ההכרחיים להתרחשות Deadlock הם: מניעה הדדית (Mutual Exclusion), החזקה והמתנה (Hold and Wait), אי-פקיעה (No Preemption), והמתנה מעגלית (Circular Wait). 'שחרור משאבים' אינו תנאי הכרחי ל-Deadlock; להיפך, היכולת לכפות שחרור משאבים (Preemption) היא אסטרטגיה למניעת Deadlock."}, "difficulty_estimation": "Medium", "_source_file": "0808__Concurrency__MultipleChoice__Medium.json", "_topic_hint": "Concurrency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:31:06", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Concurrency", "Synchronization", "Condition Variables"], "content": {"text": "נתון קטע הקוד הבא המשתמש במשתנה תנאי (condition variable) לתיאום בין תהליך יצרן (producer) לתהליך צרכן (consumer). מהי הבעיה העיקרית שיכולה להתרחש בתוכנית זו?", "code_snippet": "#include <iostream>\n#include <thread>\n#include <mutex>\n#include <condition_variable>\n#include <chrono>\n\nstd::mutex m;\nstd::condition_variable cv;\nbool data_available = false; // דגל המציין שהנתונים מוכנים\nint shared_data = 0;\n\nvoid producer_thread() {\n    std::this_thread::sleep_for(std::chrono::milliseconds(100)); // מדמה עבודה כלשהי\n    {\n        std::lock_guard<std::mutex> lk(m);\n        shared_data = 42;\n        data_available = true; // הנתונים מוכנים\n        std::cout << \"Producer: Flag set to true, data = \" << shared_data << std::endl;\n    } // המנעול משוחרר כאן\n    cv.notify_one(); // שליחת איתות לאחר שחרור המנעול\n    std::cout << \"Producer: Notified.\" << std::endl;\n}\n\nvoid consumer_thread() {\n    std::this_thread::sleep_for(std::chrono::milliseconds(10)); // מדמה עבודה קצרה\n    std::unique_lock<std::mutex> lk(m); // תפוס מנעול\n\n    // *נקודה קריטית*: בדיקת flag ללא לולאה או פרדיקט\n    if (!data_available) { \n        std::cout << \"Consumer: Data not available, waiting...\" << std::endl;\n        cv.wait(lk); // המתנה ללא לולאה/פרדיקט\n    }\n    std::cout << \"Consumer: Consumed data: \" << shared_data << std::endl;\n}\n\n// הערה: פונקציית main לא הוצגה אך היא תיצור ותריץ את שני התהליכים.", "options": ["א. התוכנית עלולה להיכנס למצב של Deadlock.", "ב. תהליך הצרכן עלול להחמיץ איתות (missed signal) מהיצרן ולהמתין ללא סוף.", "ג. תהליך הצרכן עלול להתעורר באופן שקרי (spurious wakeup) ולצרוך נתונים לא תקינים או לא מעודכנים.", "ד. תהליך הצרכן עלול לצרוך את הנתונים לפני שהיצרן סיים להכין אותם (race condition על הנתונים).", "ה. אין בעיה בקוד, והתוכנית תמיד תעבוד כראוי."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הבעיה העיקרית בקוד היא שתהליך הצרכן משתמש ב-`cv.wait(lk)` ללא לולאה (או פרדיקט) כדי לבדוק מחדש את התנאי (`data_available`). משתני תנאי עלולים לגרום להתעוררויות שקריות (spurious wakeups), כלומר, תהליך הצרכן עשוי להתעורר מ-`wait` גם אם לא נשלח איתות (`notify_one`/`notify_all`) או אם התנאי עדיין לא מתקיים. במקרה כזה, הצרכן ימשיך לבצע את פעולת הצריכה (`std::cout << \"Consumer: Consumed data: \" << shared_data << std::endl;`) כאשר `data_available` עדיין שקר ו-`shared_data` מכיל ערך ברירת מחדל (0) או ערך שגוי אחר, במקום 42. הפתרון הנכון הוא להשתמש בלולאת `while` סביב ה-`wait` (לדוגמה: `while (!data_available) { cv.wait(lk); }`) או בגרסת ה-`wait` שמקבלת פרדיקט (`cv.wait(lk, []{ return data_available; });`)."}, "difficulty_estimation": "Hard", "_source_file": "0809__Concurrency__MultipleChoice__Hard.json", "_topic_hint": "Concurrency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:31:59", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Concurrency", "Synchronization", "Condition Variables", "Starvation"], "content": {"text": "נתון קטע הקוד הבא המשתמש ב-pthreads לצורך סנכרון בין מספר תהליכים. תהליכי `incrementer` מגדילים מונה משותף `shared_counter` עד לערך `MAX_VAL`. תהליך `watcher` ממתין שהמונה יגיע ל-`MAX_VAL`, מאפס אותו, ומאותת לתהליכי ה-`incrementer` להמשיך. מהי התוצאה הסבירה ביותר בשימוש ב-`pthread_cond_signal(&cond_empty)` במקום `pthread_cond_broadcast(&cond_empty)` בתוך ה-`watcher` thread?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n\n#define MAX_VAL 5\n\nint shared_counter = 0;\npthread_mutex_t mtx;\npthread_cond_t cond_full;   // Condition for counter reaching MAX_VAL\npthread_cond_t cond_empty;  // Condition for counter being reset\n\n// Thread type 1: Increments shared_counter\nvoid* incrementer(void* arg) {\n    for (int i = 0; i < 3; ++i) { // Each incrementer tries 3 times\n        pthread_mutex_lock(&mtx);\n        while (shared_counter == MAX_VAL) { // Wait if counter is full\n            pthread_cond_wait(&cond_empty, &mtx);\n        }\n        shared_counter++;\n        printf(\"Incrementer: shared_counter = %d\\n\", shared_counter);\n        if (shared_counter == MAX_VAL) { // If counter is full, signal the watcher\n            pthread_cond_signal(&cond_full);\n        }\n        pthread_mutex_unlock(&mtx);\n        // Simulate some work outside mutex\n        usleep(50000);\n    }\n    return NULL;\n}\n\n// Thread type 2: Watches for counter to be full, then resets it\nvoid* watcher(void* arg) {\n    for (int i = 0; i < 2; ++i) { // Watcher resets twice\n        pthread_mutex_lock(&mtx);\n        while (shared_counter < MAX_VAL) { // Wait until counter is full\n            pthread_cond_wait(&cond_full, &mtx);\n        }\n        printf(\"Watcher: Resetting shared_counter from %d to 0\\n\", shared_counter);\n        shared_counter = 0;\n        // This is the critical line for the question:\n        pthread_cond_signal(&cond_empty); // Signalling only one waiting incrementer\n        pthread_mutex_unlock(&mtx);\n        // Simulate some work outside mutex\n        usleep(100000);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t inc_threads[3]; // 3 incrementer threads\n    pthread_t w_thread;       // 1 watcher thread\n\n    pthread_mutex_init(&mtx, NULL);\n    pthread_cond_init(&cond_full, NULL);\n    pthread_cond_init(&cond_empty, NULL);\n\n    for (int i = 0; i < 3; ++i) {\n        pthread_create(&inc_threads[i], NULL, incrementer, NULL);\n    }\n    pthread_create(&w_thread, NULL, watcher, NULL);\n\n    for (int i = 0; i < 3; ++i) {\n        pthread_join(inc_threads[i], NULL);\n    }\n    pthread_join(w_thread, NULL);\n\n    pthread_mutex_destroy(&mtx);\n    pthread_cond_destroy(&cond_full);\n    pthread_cond_destroy(&cond_empty);\n\n    return 0;\n}", "options": ["א. התוכנית תיתקע ב-Deadlock באופן ודאי.", "ב. התוכנית תעבוד באופן תקין, אך תהיה פחות יעילה באופן משמעותי.", "ג. ייתכן מצב של Starvation (הרעבה) עבור חלק מתהליכי ה-incrementer, אשר ימתינו ללא הגבלת זמן.", "ד. ה-watcher thread יבצע את פעולתו יותר מפעם אחת עבור כל פעם שהמונה מגיע ל-MAX_VAL.", "ה. אף אחת מהתשובות אינה נכונה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התשובה הנכונה היא ג'. כאשר ה-`watcher` מאפס את `shared_counter` ומאותת באמצעות `pthread_cond_signal(&cond_empty)`, רק אחד מתהליכי ה-`incrementer` הרבים שעשויים להמתין על `cond_empty` יתעורר. תהליך זה יתפוס את המנעול וימשיך להגדיל את המונה. שאר תהליכי ה-`incrementer` יישארו בהמתנה, למרות שהתנאי שלהם (shared_counter == MAX_VAL) כבר אינו מתקיים (כי המונה אופס). מכיוון שרק ה-`watcher` מאותת על `cond_empty`, ואם הוא יאותת רק לאחד, ייתכן שתהליכים אחרים לעולם לא יתעוררו, מה שמוביל למצב של Starvation עבורם. שימוש ב-`pthread_cond_broadcast` היה מעיר את כל התהליכים הממתינים ומאפשר להם להתחרות על המנעול."}, "difficulty_estimation": "Hard", "_source_file": "0810__Concurrency__MultipleChoice__Hard.json", "_topic_hint": "Concurrency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:32:25", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Concurrency", "Deadlock", "Livelock", "Mutexes", "Synchronization"], "content": {"text": "נתון קטע הקוד הבא המשתמש בשני מנעולים (mutex_A, mutex_B) ובשני תהליכונים (thread_func_1, thread_func_2) המנסים לגשת למשאבים משותפים:\n\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <stdbool.h>\n\npthread_mutex_t mutex_A = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_t mutex_B = PTHREAD_MUTEX_INITIALIZER;\n\nvoid* thread_func_1(void* arg) {\n    while (true) {\n        pthread_mutex_lock(&mutex_A);\n        printf(\"Thread 1: Locked A. Trying B...\\n\");\n        if (pthread_mutex_trylock(&mutex_B) == 0) { // Successfully locked B\n            printf(\"Thread 1: Locked B. Doing work...\\n\");\n            // Critical section\n            sleep(1); // Simulate work\n            pthread_mutex_unlock(&mutex_B);\n            pthread_mutex_unlock(&mutex_A);\n            break; // Done with this iteration\n        } else {\n            printf(\"Thread 1: Could not lock B. Unlocking A and retrying...\\n\");\n            pthread_mutex_unlock(&mutex_A);\n            sleep(1); // Backoff\n        }\n    }\n    return NULL;\n}\n\nvoid* thread_func_2(void* arg) {\n    while (true) {\n        pthread_mutex_lock(&mutex_B);\n        printf(\"Thread 2: Locked B. Trying A...\\n\");\n        if (pthread_mutex_trylock(&mutex_A) == 0) { // Successfully locked A\n            printf(\"Thread 2: Locked A. Doing work...\\n\");\n            // Critical section\n            sleep(1); // Simulate work\n            pthread_mutex_unlock(&mutex_A);\n            pthread_mutex_unlock(&mutex_B);\n            break; // Done with this iteration\n        } else {\n            printf(\"Thread 2: Could not lock A. Unlocking B and retrying...\\n\");\n            pthread_mutex_unlock(&mutex_B);\n            sleep(1); // Backoff\n        }\n    }\n    return NULL;\n}\n\n// הערה: פונקציית main יוצרת את שני התהליכונים וממתינה להם.\n// int main() {\n//     pthread_t t1, t2;\n//     pthread_create(&t1, NULL, thread_func_1, NULL);\n//     pthread_create(&t2, NULL, thread_func_2, NULL);\n//     pthread_join(t1, NULL);\n//     pthread_join(t2, NULL);\n//     printf(\"Both threads finished.\\n\");\n//     return 0;\n// }\n```\n\nאיזו טענה נכונה לגבי התנהגות התוכנית כאשר שני התהליכונים רצים במקביל?", "code_snippet": null, "options": ["א. התוכנית תמיד תבצע deadlock.", "ב. התוכנית תמיד תרוץ ללא deadlock ותסיים בהצלחה.", "ג. התוכנית עלולה להיכנס למצב של livelock, בו התהליכונים מבזבזים זמן מעבד מבלי להתקדם.", "ד. התוכנית עלולה להיכנס למצב של deadlock, אך לעולם לא למצב של livelock.", "ה. התוכנית עלולה להיתקל ב-race condition המוביל לנתונים שגויים."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התוכנית מנסה למנוע deadlock על ידי שחרור המנעול הראשון (mutex_A או mutex_B) אם המנעול השני לא נתפס בהצלחה באמצעות `pthread_mutex_trylock`. אסטרטגיה זו אכן מונעת deadlock קלאסי, שכן אף תהליכון לא יחזיק במנעול אחד וימתין באופן אינסופי למנעול אחר שתפוס. עם זאת, ייתכן מצב שבו שני התהליכונים יתפסו בו-זמנית את המנעול הראשון שלהם (thread_func_1 את mutex_A ו-thread_func_2 את mutex_B), ינסו לתפוס את המנעול השני, ייכשלו, ישחררו את המנעול שתפוס אצלם, ימתינו (sleep(1)) ויחזרו על התהליך. מצב זה, שבו תהליכונים מבזבזים משאבי מעבד על ניסיונות חוזרים ונשנים ללא התקדמות, נקרא livelock. לכן, התוכנית עלולה להיכנס למצב של livelock. אין כאן deadlock כי אף תהליכון לא ממתין לעד למנעול כשהוא מחזיק מנעול אחר. כמו כן, השימוש במנעולים מונע race conditions על הנתונים המשותפים (שאינם מופיעים בקוד, אך המנעולים מיועדים להגן עליהם)."}, "difficulty_estimation": "Hard", "_source_file": "0811__Concurrency__MultipleChoice__Hard.json", "_topic_hint": "Concurrency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:32:48", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Concurrency", "Synchronization", "Race Conditions"], "content": {"text": "נתונה פיסת קוד בשפת C המשתמשת ב-pthreads. מספר תהליכונים (threads) מנסים להגדיל מונה משותף (`shared_counter`) באופן חוזר.\n\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#define NUM_THREADS 4\n#define INCREMENTS_PER_THREAD 100000\n\nint shared_counter = 0;\npthread_mutex_t mutex;\n\nvoid* incrementer_thread(void* arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        int current_value;\n        pthread_mutex_lock(&mutex);\n        current_value = shared_counter;\n        pthread_mutex_unlock(&mutex);\n\n        // נקודת מעבר הקשר אפשרית (context switch point)\n\n        pthread_mutex_lock(&mutex);\n        shared_counter = current_value + 1;\n        pthread_mutex_unlock(&mutex);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    pthread_mutex_init(&mutex, NULL);\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, incrementer_thread, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", shared_counter);\n    pthread_mutex_destroy(&mutex);\n    return 0;\n}\n```\nמה יהיה הערך הסופי של `shared_counter` כשהתוכנית תסיים את ריצתה?", "code_snippet": null, "options": ["א. בדיוק 400000 (ארבע מאות אלף).", "ב. פחות מ-400000 אך גדול מ-0.", "ג. בדיוק 0 (אפס) עקב deadlock.", "ד. ערך שאינו ניתן לחיזוי מראש עקב התנהגות בלתי מוגדרת (Undefined Behavior)."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ההסבר: הקוד מכיל תנאי מרוץ (race condition) עקב שימוש שגוי במנגנון המנעול (mutex). פעולת ההגדלה של המונה (`shared_counter++`) אינה אטומית ומורכבת משלושה שלבים: קריאת הערך הנוכחי, הגדלת הערך, וכתיבת הערך החדש. בקוד הנתון, המנעול נתפס ומשוחרר בין שלב הקריאה לשלב הכתיבה:\n1.  `pthread_mutex_lock(&mutex);`\n2.  `current_value = shared_counter;` (קריאת הערך)\n3.  `pthread_mutex_unlock(&mutex);` (שחרור המנעול)\n\nלאחר שחרור המנעול, תהליכון אחר יכול להיכנס לקטע קריטי, לקרוא את אותו `shared_counter` (שעדיין לא עודכן על ידי התהליכון הראשון), להגדיל אותו ולכתוב אותו בחזרה. כאשר התהליכון הראשון ימשיך את פעולתו:\n4.  `pthread_mutex_lock(&mutex);`\n5.  `shared_counter = current_value + 1;` (כתיבת הערך, כאשר `current_value` מבוסס על ערך \"ישן\" של `shared_counter`)\n6.  `pthread_mutex_unlock(&mutex);`\n\nבמקרה כזה, הגדלה אחת לפחות אבדה. מכיוון שתנאי מרוץ זה יתרחש לעיתים קרובות, הערך הסופי של `shared_counter` יהיה בהכרח נמוך מהערך המצופה (`NUM_THREADS * INCREMENTS_PER_THREAD = 4 * 100000 = 400000`), אך לא אפס (המונה כן יוגדל חלקית). אין כאן deadlock כי המנעולים משוחררים תמיד. לכן, התשובה הנכונה היא ב'."}, "difficulty_estimation": "Hard", "_source_file": "0812__Concurrency__MultipleChoice__Hard.json", "_topic_hint": "Concurrency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:33:09", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Concurrency", "Synchronization", "Deadlock", "Condition Variables"], "content": {"text": "נתון קטע קוד המממש תבנית \"יצרן-צרכן\" (Producer-Consumer). היצרן (ה-main thread) מוסיף פריטים לתור משותף, מסמן לצרכן, ולאחר מכן ממתין שכל הפריטים יעובדו ושהוא עצמו יצהיר שסיים להוסיף פריטים. הצרכן מעבד פריטים מהתור. הצרכן מסמן ליצרן שכל הפריטים עובדו רק אם היצרן כבר הצהיר שסיים להוסיף. רק לאחר יציאה מלולאת ההמתנה הראשונה, היצרן אמור להצהיר על סיום הוספת פריטים ולסמן לצרכן. בהתחשב בארגון זה של הקוד, איזו טענה נכונה?", "code_snippet": "```c\n#include <queue>\n#include <pthread.h>\n\nstd::queue<int> shared_queue;\npthread_mutex_t mutex;\npthread_cond_t producer_wait_cond; // היצרן ממתין כאן לסיום עיבוד כל הפריטים והצהרה על סיום הוספה\npthread_cond_t consumer_wait_cond; // הצרכן ממתין כאן לפריטים\n\nint items_added = 0; // סך הפריטים שהיצרן הוסיף\nint items_processed = 0; // סך הפריטים שהצרכן עיבד\nbool producer_done_adding = false; // דגל המציין שהיצרן סיים להוסיף פריטים\n\nvoid* consumer_thread_func(void* arg) {\n    pthread_mutex_lock(&mutex);\n    while (true) {\n        // הצרכן ממתין אם התור ריק והיצרן עדיין עשוי להוסיף פריטים\n        while (shared_queue.empty() && !producer_done_adding) {\n            pthread_cond_wait(&consumer_wait_cond, &mutex);\n        }\n\n        // תנאי יציאה לצרכן: התור ריק והיצרן סיים להוסיף פריטים\n        if (shared_queue.empty() && producer_done_adding) {\n            pthread_mutex_unlock(&mutex);\n            return NULL; // הצרכן יוצא\n        }\n\n        // עיבוד פריט\n        shared_queue.pop();\n        items_processed++;\n\n        // הצרכן מסמן ליצרן רק אם כל הפריטים עובדו *וגם* היצרן סיים להוסיף.\n        // זו נקודת הכשל: אם items_processed == items_added מתקיים לפני ש-producer_done_adding הופך ל-true,\n        // הסימון ליצרן יוחמץ. היצרן עלול להיתקע בהמתנה.\n        if (items_processed == items_added && producer_done_adding) {\n            pthread_cond_signal(&producer_wait_cond);\n        }\n    }\n}\n\n/*\n// קטע קוד לדוגמה של ה-main thread (היצרן)\nint main() {\n    pthread_mutex_init(&mutex, NULL);\n    pthread_cond_init(&producer_wait_cond, NULL);\n    pthread_cond_init(&consumer_wait_cond, NULL);\n\n    pthread_t consumer_tid;\n    pthread_create(&consumer_tid, NULL, consumer_thread_func, NULL);\n\n    // שלב 1: היצרן מוסיף פריטים\n    pthread_mutex_lock(&mutex);\n    for (int i = 0; i < 5; ++i) { \n        shared_queue.push(i);\n        items_added++;\n    }\n    pthread_cond_signal(&consumer_wait_cond); // מעיר את הצרכן שיש פריטים\n    pthread_mutex_unlock(&mutex);\n\n    // שלב 2: היצרן ממתין שכל הפריטים יעובדו *ושהוא עצמו יסמן שסיים להוסיף*.\n    // זהו תנאי המתנה שיוביל לדדלוק.\n    pthread_mutex_lock(&mutex);\n    while (items_processed < items_added || !producer_done_adding) {\n        pthread_cond_wait(&producer_wait_cond, &mutex);\n    }\n    pthread_mutex_unlock(&mutex);\n\n    // שלב 3: רק לאחר שסיים להמתין, היצרן מסמן שהוא סיים להוסיף פריטים ונותן לצרכן הזדמנות לסיים.\n    // שלב זה לעולם לא יגיע אם היצרן נתקע בשלב 2.\n    pthread_mutex_lock(&mutex);\n    producer_done_adding = true;\n    pthread_cond_signal(&consumer_wait_cond); // כדי להעיר את הצרכן לבדוק תנאי יציאה\n    pthread_mutex_unlock(&mutex);\n\n    // std::cout << \"Main: All items processed and producer is done.\" << std::endl;\n\n    pthread_join(consumer_tid, NULL);\n    pthread_mutex_destroy(&mutex);\n    pthread_cond_destroy(&producer_wait_cond);\n    pthread_cond_destroy(&consumer_wait_cond);\n    return 0;\n}\n```", "options": ["א. הקוד נכון ויתפקד כמצופה ללא בעיות.", "ב. הקוד עלול לגרום למצב של Race Condition אך לא ל-Deadlock.", "ג. הקוד עלול לגרום ל-Deadlock של היצרן (ה-main thread) בלבד.", "ד. הקוד עלול לגרום ל-Deadlock של הצרכן (ה-consumer thread) בלבד.", "ה. הקוד עלול לגרום ל-Deadlock של שני התהליכים (היצרן והצרכן)."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ה", "explanation": "היצרן (ה-main thread) ממתין בתנאי `while (items_processed < items_added || !producer_done_adding)`. היצרן יקרא ל-`pthread_cond_wait(&producer_wait_cond, &mutex)` אם תנאי זה מתקיים.\nהצרכן מסמן ל-`producer_wait_cond` רק אם `items_processed == items_added` וגם `producer_done_adding` שניהם נכונים.\nהצרכן ממתין בתנאי `while (shared_queue.empty() && !producer_done_adding)` ויקרא ל-`pthread_cond_wait(&consumer_wait_cond, &mutex)` אם תנאי זה מתקיים.\n\nנתאר תרחיש לדדלוק:\n1.  היצרן מוסיף `N` פריטים לתור (`items_added = N`).\n2.  היצרן משחרר את המנעול ומסמן ל-`consumer_wait_cond` (כדי להעיר את הצרכן).\n3.  הצרכן מתעורר ומעבד את כל `N` הפריטים. כעת `items_processed = N`.\n    בשלב זה, `items_processed == items_added` נכון, אך `producer_done_adding` עדיין `false` (היצרן טרם הגיע לשלב שבו הוא מגדיר דגל זה).\n    לכן, התנאי `if (items_processed == items_added && producer_done_adding)` בצרכן הוא `false`, והצרכן *אינו* מסמן ל-`producer_wait_cond`.\n4.  הצרכן ממשיך את הלולאה. כעת `shared_queue` ריק, ו-`producer_done_adding` הוא `false`.\n    הצרכן יקרא ל-`pthread_cond_wait(&consumer_wait_cond, &mutex)` וייחסם.\n5.  היצרן מגיע ללולאת ההמתנה שלו: `while (items_processed < items_added || !producer_done_adding)`.\n    בשלב זה: `items_processed = N`, `items_added = N`, ו-`producer_done_adding = false`.\n    לכן, התנאי הוא `(N < N || !false)` שזה `(false || true)`, כלומר `true`.\n    היצרן יקרא ל-`pthread_cond_wait(&producer_wait_cond, &mutex)` וייחסם.\n\nכעת, גם היצרן וגם הצרכן חסומים. היצרן ממתין לסיגנל על `producer_wait_cond` שיישלח רק אם `producer_done_adding` יהיה `true`, אך היצרן עצמו חסום לפני שהוא יכול להגדיר את `producer_done_adding` ל-`true`. הצרכן חסום וממתין לסיגנל על `consumer_wait_cond` שיישלח על ידי היצרן, אך היצרן חסום. זהו מצב של דדלוק הדדי (deadlock)."}, "difficulty_estimation": "Hard", "_source_file": "0813__Concurrency__MultipleChoice__Hard.json", "_topic_hint": "Concurrency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:34:33", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Concurrency", "Synchronization", "Deadlock"], "content": {"text": "נתון קטע קוד בשפת C++ המשתמש בשני מנעולים (mutexes) ובשני תהליכונים (threads) המנסים לגשת למשאבים מוגנים על ידי מנעולים אלו. מהי הטענה הנכונה ביותר לגבי התנהגות הקוד תחת הרצה מקבילית?", "code_snippet": "#include <mutex>\n#include <thread>\n#include <iostream>\n#include <vector>\n#include <chrono>\n\nstd::mutex m1;\nstd::mutex m2;\n\nvoid thread_func_A() {\n    std::cout << \"Thread A: Trying to lock m1...\\n\";\n    m1.lock();\n    std::cout << \"Thread A: Locked m1, trying to lock m2...\\n\";\n    std::this_thread::sleep_for(std::chrono::milliseconds(10)); // Potential context switch\n    m2.lock();\n    std::cout << \"Thread A: Locked m2.\\n\";\n    // ... critical section ...\n    m2.unlock();\n    m1.unlock();\n    std::cout << \"Thread A: Unlocked m1 and m2.\\n\";\n}\n\nvoid thread_func_B() {\n    std::cout << \"Thread B: Trying to lock m2...\\n\";\n    m2.lock();\n    std::cout << \"Thread B: Locked m2, trying to lock m1...\\n\";\n    std::this_thread::sleep_for(std::chrono::milliseconds(10)); // Potential context switch\n    m1.lock();\n    std::cout << \"Thread B: Locked m1.\\n\";\n    // ... critical section ...\n    m1.unlock();\n    m2.unlock();\n    std::cout << \"Thread B: Unlocked m1 and m2.\\n\";\n}\n\n// Usage example:\n// int main() {\n//     std::thread t1(thread_func_A);\n//     std::thread t2(thread_func_B);\n//     t1.join();\n//     t2.join();\n//     return 0;\n// }", "options": ["א. הקוד ירוץ תמיד ללא בעיות ויסיים את פעולתו בהצלחה.", "ב. הקוד יגרום בהכרח למצב של קיפאון (Deadlock).", "ג. הקוד עלול להיכנס למצב של קיפאון (Deadlock), אך אינו מובטח.", "ד. הקוד עלול לגרום למצב של תחרות (Race Condition) בגישה למנעולים, אך לא לקיפאון.", "ה. הקוד יגרום לשגיאת קומפילציה עקב שימוש לא נכון במנעולים."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הקוד מדגים מצב קלאסי של פוטנציאל לקיפאון (Deadlock). תהליכון A מנסה לתפוס את מנעול m1 ואז את m2, בעוד שתהליכון B מנסה לתפוס את מנעול m2 ואז את m1. אם יתרחש תזמון מסוים שבו תהליכון A יתפוס את m1 ותהליכון B יתפוס את m2 (לפני שכל אחד מהם יצליח לתפוס את המנעול השני), שניהם ימתינו זה לזה לשחרור המנעול שהשני מחזיק, וכתוצאה מכך תיווצר חסימה הדדית – קיפאון. עם זאת, קיפאון אינו מובטח. ייתכן שתהליכון אחד יצליח לתפוס את שני המנעולים ולשחרר אותם לפני שהתהליכון השני יגיע לניסיון תפיסת המנעול השני שלו. לכן, הטענה הנכונה ביותר היא שהקוד עלול להיכנס למצב של קיפאון, אך זה אינו מובטח."}, "difficulty_estimation": "Hard", "_source_file": "0814__Concurrency__MultipleChoice__Hard.json", "_topic_hint": "Concurrency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:34:51", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Concurrency", "Synchronization", "Deadlock"], "content": {"text": "נתון הקוד הבא המשתמש בספריות pthread ליצירת שני תהליכונים ושני מנעולים (mutexes):\n\nבהנחה ששני התהליכונים רצים במקביל על מעבדים שונים או באותו מעבד עם מיתוג הקשר (context switching) כלשהו, מהי הטענה הנכונה ביותר לגבי הרצת הקוד?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutexA = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_t mutexB = PTHREAD_MUTEX_INITIALIZER;\n\nvoid* thread_func1(void* arg) {\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 1 acquired mutex A\\n\");\n    sleep(1); // Simulate work or delay\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 1 acquired mutex B\\n\");\n    // ... critical section ...\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 2 acquired mutex B\\n\");\n    sleep(1); // Simulate work or delay\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 2 acquired mutex A\\n\");\n    // ... critical section ...\n    pthread_mutex_unlock(&mutexA);\n    pthread_mutex_unlock(&mutexB);\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, thread_func1, NULL);\n    pthread_create(&t2, NULL, thread_func2, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"Main finished\\n\");\n    return 0;\n}", "options": ["א. הקוד ירוץ תמיד בהצלחה ויסיים את פעולתו ללא בעיות.", "ב. הקוד עלול להיכנס למצב של קיפאון (deadlock).", "ג. הקוד עלול לגרום לתנאי מרוץ (race condition) על נתונים משותפים שאינם מוגנים כראוי.", "ד. הקוד יגרום לשגיאת הרצה (runtime error) עקב ניסיון לשחרר מנעול שאינו נעול."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. הקוד מדגים מצב קלאסי של קיפאון (deadlock). קיפאון יכול להתרחש כאשר מתקיימים ארבעה תנאים: מניעה הדדית (mutual exclusion), אחיזה והמתנה (hold and wait), אי-נתיקות (no preemption), והמתנה מעגלית (circular wait). במקרה זה, שני התהליכונים מנסים לרכוש את אותם שני מנעולים (mutexA ו-mutexB) אך בסדר הפוך. תהליכון 1 רוכש את mutexA ולאחר מכן מנסה לרכוש את mutexB. תהליכון 2 רוכש את mutexB ולאחר מכן מנסה לרכוש את mutexA. אם תהליכון 1 ירכוש את mutexA ותהליכון 2 ירכוש את mutexB בערך באותו זמן, שניהם ימתינו אינסופית למנעול שהשני מחזיק בו. זוהי דוגמה מובהקת למצב של המתנה מעגלית המובילה לקיפאון. תנאי מרוץ (race condition) מתייחס לגישה לא מוגנת למשאב משותף, אך כאן הבעיה העיקרית היא בסדר רכישת המנעולים שמוביל לחסימה הדדית, ולא בגישה לנתונים בתוך האזור הקריטי עצמו (שבמקרה זה מוגן על ידי שני המנעולים)."}, "difficulty_estimation": "Hard", "_source_file": "0815__Concurrency__MultipleChoice__Hard.json", "_topic_hint": "Concurrency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:35:06", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Concurrency", "Synchronization", "Condition Variables", "Race Conditions"], "content": {"text": "נתון קטע קוד בשפת C המשתמש ב-pthreads לתיאום בין שני תהליכונים (threads): יצרן (producer) וצרכן (consumer). היצרן מייצר נתונים וקובע דגל `ready_flag`, ולאחר מכן מאותת לצרכן. הצרכן ממתין לדגל זה כדי להתחיל לעבד נתונים.\n\nהקוד של הפונקציה `producer` נראה כך:\n```c\nvoid* producer(void* arg) {\n    sleep(1); // מדמה עבודה כלשהי\n    pthread_mutex_lock(&mtx);\n    ready_flag = 1;\n    pthread_mutex_unlock(&mtx);\n    pthread_cond_signal(&cond);\n    return NULL;\n}\n```\n\nהקוד של הפונקציה `consumer` נראה כך:\n```c\nvoid* consumer(void* arg) {\n    pthread_mutex_lock(&mtx);\n    while (ready_flag == 0) {\n        pthread_cond_wait(&cond, &mtx);\n    }\n    // ... עיבוד הנתונים ...\n    pthread_mutex_unlock(&mtx);\n    return NULL;\n}\n```\n(ההצהרות על `mtx`, `cond`, ו-`ready_flag` כגלובליות עם אתחול מתאים מובנות).\n\nמהי הבעיה הפוטנציאלית החמורה ביותר ביישום פונקציית ה-`producer` כפי שהיא מוצגת?", "code_snippet": null, "options": ["א. קיים מצב של Deadlock (קיפאון) בין התהליכונים.", "ב. קיים תנאי מירוץ (race condition) שעלול להוביל לאיבוד איתות (missed wakeup) ולכך שהצרכן ימתין ללא סוף.", "ג. קיימת תקורה ביצועית גבוהה עקב ריבוי החלפות הקשר (context switches) מיותרות.", "ד. התהליכון `producer` עלול לסיים את פעולתו לפני שהספיק לאותת, ולהשאיר את הצרכן תקוע."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הבעיה העיקרית היא תנאי מירוץ שעלול לגרום ל-missed wakeup (איבוד איתות). נניח שהתהליכון `consumer` בודק את `ready_flag` ומוצא אותו 0, ואז מתזמן החוצה (preempted) רגע לפני שהוא קורא ל-`pthread_cond_wait`. כעת, התהליכון `producer` מתזמן, קובע את `ready_flag` ל-1, משחרר את המנעול, וקורא ל-`pthread_cond_signal`. מכיוון שה-`consumer` עדיין לא נכנס למצב המתנה (wait state) כאשר האות נשלח, האות נשלח אך לא נתפס על ידי אף אחד והוא \"הולך לאיבוד\". כאשר ה-`consumer` מתזמן בחזרה ומגיע לקריאה ל-`pthread_cond_wait`, הוא ייכנס למצב המתנה, אך האות שהיה אמור להעיר אותו כבר נשלח ואבד. כתוצאה מכך, ה-`consumer` ימתין ללא סוף, למרות שהתנאי (`ready_flag == 1`) כבר התקיים. התיקון הנכון הוא לבצע את הקריאה ל-`pthread_cond_signal` כאשר המנעול עדיין תפוס."}, "difficulty_estimation": "Hard", "_source_file": "0816__Concurrency__MultipleChoice__Hard.json", "_topic_hint": "Concurrency", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:35:35", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Concurrency", "Race Conditions", "Critical Section"], "content": {"text": "מהו Race Condition (מצב מרוץ) וכיצד הוא נוצר? תאר/י דוגמה פשוטה למצב של Race Condition. כיצד ניתן למנוע Race Condition באמצעות שימוש בקטע קריטי (Critical Section)?", "code_snippet": "int counter = 0; // משתנה גלובלי משותף\n\nvoid increment() {\n  counter++; // פעולה זו אינה אטומית ועלולה לגרום ל-Race Condition\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "Race Condition (מצב מרוץ) מתרחש כאשר שני תהליכים (או תהליכונים) או יותר ניגשים לאותו משאב משותף (כמו משתנה גלובלי) ומנסים לשנות אותו בו-זמנית, והתוצאה הסופית תלויה בסדר הלא-דטרמיניסטי שבו הפעולות מתבצעות. מצב זה עלול להוביל לתוצאות שגויות או בלתי צפויות, מכיוון שסדר הגישה למשאב המשותף אינו מובטח.\n\n**דוגמה פשוטה:**\nנניח שיש לנו משתנה גלובלי `int counter = 0;` ושני תהליכונים קוראים לפונקציה `increment()`:\n```c\nint counter = 0;\n\nvoid increment() {\n  counter++; // פעולה זו אינה אטומית! היא מורכבת מקריאה של counter, הגדלה של הערך, וכתיבה בחזרה ל-counter.\n}\n```\nאם שני תהליכונים קוראים לפונקציה `increment` כמעט בו-זמנית, ייתכן ששניהם יקראו את הערך 0 של `counter`. לאחר מכן, שניהם יגדילו את הערך שקראו ל-1, ושניהם יכתבו 1 בחזרה ל-`counter`. במצב זה, למרות ששני תהליכונים ביצעו הגדלה, הערך הסופי של `counter` יהיה 1 במקום 2, וזוהי תוצאה שגויה.\n\n**מניעה באמצעות קטע קריטי (Critical Section):**\nכדי למנוע Race Condition, יש להגן על הקוד הניגש למשאב המשותף באמצעות קטע קריטי. קטע קריטי הוא חלק בקוד שבו רק תהליך אחד מורשה להיכנס ולבצע פעולות בכל רגע נתון. כאשר תהליך נכנס לקטע הקריטי, כל תהליך אחר שינסה להיכנס לאותו קטע קריטי ייחסם וימתין עד שהתהליך הנוכחי יסיים ויצא מהקטע הקריטי. מנגנון זה מבטיח בלעדיות הדדית (Mutual Exclusion) בגישה למשאב המשותף.\n\nאחת הדרכים הנפוצות לממש קטע קריטי היא באמצעות מנעולים (mutexes). לדוגמה, נוכל להשתמש ב-mutex כדי להגן על המשתנה `counter`:\n```c\n#include <pthread.h>\n\nint counter = 0;\npthread_mutex_t mutex; // הצהרה על מנעול\n\nvoid init_mutex() {\n  pthread_mutex_init(&mutex, NULL); // אתחול המנעול\n}\n\nvoid increment_safe() {\n  pthread_mutex_lock(&mutex);   // נכנסים לקטע הקריטי: נועלים את המנעול\n  counter++;                     // פעולה בטוחה בתוך הקטע הקריטי\n  pthread_mutex_unlock(&mutex); // יוצאים מהקטע הקריטי: משחררים את המנעול\n}\n```\nבצורה זו, רק תהליך אחד יכול להחזיק את המנעול ולבצע את פעולת ההגדלה על `counter` בכל פעם. אם תהליך אחר ינסה לקרוא ל-`pthread_mutex_lock` כשהמנעול תפוס, הוא ייחסם עד שהמנעול ישוחרר. כך נמנע Race Condition ומובטחת נכונות הנתונים המשותפים."}, "difficulty_estimation": "Easy", "_source_file": "0817__Concurrency__Open__Easy.json", "_topic_hint": "Concurrency", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:35:47", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Concurrency", "Race Conditions"], "content": {"text": "מהו Race Condition (תנאי מירוץ) בהקשר של מערכות הפעלה? תאר כיצד הוא נוצר ותן דוגמה פשוטה.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "Race Condition (תנאי מירוץ) מתרחש כאשר שני תהליכים או יותר (חוטים/תהליכים) ניגשים למשאב משותף (כמו משתנה, קובץ, או מבנה נתונים) ומנסים לשנות אותו בו זמנית, כאשר סדר הגישה והשינוי אינו מוגדר מראש. כתוצאה מכך, התוצאה הסופית של הפעולות תלויה בסדר הספציפי שבו החוטים/תהליכים מריצים את הקוד שלהם, ויכולה להיות בלתי צפויה או שגויה.\n\nכיצד הוא נוצר:\nRace Condition נוצר כאשר פעולות על משאבים משותפים אינן אטומיות (כלומר, אינן מבוצעות כיחידה אחת בלתי ניתנת להפרעה) ואין מנגנון סנכרון מתאים (כמו מנעולים - mutexes, סמפורים וכו') כדי להבטיח גישה בלעדית למשאב בזמן השינוי. לדוגמה, פעולה כמו 'מונה++' נראית אטומית, אך בפועל היא מורכבת משלוש פעולות: קריאת ערך המונה, הגדלתו באחד, וכתיבת הערך החדש בחזרה לזיכרון. אם שני חוטים מנסים לבצע פעולה זו במקביל ללא סנכרון, הם עלולים לקרוא את אותו ערך, להגדיל אותו בנפרד, ולכתוב בחזרה רק אחת מההגדלות, מה שיוביל לאובדן עדכון.\n\nדוגמה פשוטה:\nנניח שיש לנו משתנה גלובלי משותף `int counter = 0;` ושני חוטים (Thread A ו-Thread B) שכל אחד מהם מנסה להגדיל את המונה ב-1. כל חוט מבצע את הפעולה `counter++;`.\n\nללא סנכרון, רצף אירועים אפשרי יכול להיות כזה:\n1.  Thread A קורא את `counter` (ערך 0).\n2.  Thread B קורא את `counter` (ערך 0).\n3.  Thread A מגדיל את הערך שקרא ל-1.\n4.  Thread B מגדיל את הערך שקרא ל-1.\n5.  Thread A כותב את 1 בחזרה ל-`counter`.\n6.  Thread B כותב את 1 בחזרה ל-`counter`.\n\nבמקרה זה, למרות ששני החוטים ביצעו הגדלה, הערך הסופי של `counter` יהיה 1 במקום 2. זהו Race Condition."}, "difficulty_estimation": "Easy", "_source_file": "0818__Concurrency__Open__Easy.json", "_topic_hint": "Concurrency", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:35:58", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Concurrency", "Race Conditions", "Synchronization"], "content": {"text": "מהו תנאי מרוץ (Race Condition) בהקשר של תכנות מקבילי (Concurrency)? הסבר מדוע הוא מהווה בעיה והצע פתרון פשוט למניעתו, תוך התייחסות לדוגמת הקוד הבאה:", "code_snippet": "```c\n#include <stdio.h>\n#include <pthread.h>\n\nint shared_counter = 0; // משתנה משותף\n\nvoid* increment_function(void* arg) {\n    for (int i = 0; i < 100000; i++) {\n        shared_counter++; // פעולה על המשתנה המשותף\n    }\n    return NULL;\n}\n\n// קוד main ליצירת מספר תהליכונים שיקראו ל-increment_function\n// ...\n```", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "### הסבר תנאי מרוץ (Race Condition):\nתנאי מרוץ מתרחש במערכת מקבילית (Multi-threaded או Multi-process) כאשר מספר תהליכונים/תהליכים ניגשים ומשנים נתונים משותפים במקביל, והתוצאה הסופית תלויה בסדר הלא-דטרמיניסטי של ביצוע הפעולות. במילים אחרות, מי מגיע ראשון, ואיך הפעולות שלהם משתלבות.\n\n### מדוע זו בעיה:\nפעולות כמו `shared_counter++` אינן אטומיות (Atomic) ברמת המעבד. הן מתורגמות בדרך כלל לשלוש הוראות מכונה:\n1.  קרא את הערך של `shared_counter` לרג'יסטר.\n2.  הגדל את הערך ברג'יסטר ב-1.\n3.  כתוב את הערך מהרג'יסטר חזרה ל-`shared_counter`.\n\nאם שני תהליכונים מבצעים את הפעולה הזו במקביל, ייתכן שתהליכון אחד יקרא את הערך, ותהליכון שני יקרא *את אותו ערך* לפני שהראשון יספיק לכתוב את הערך המוגדל חזרה. במקרה כזה, שתי הגדלות יתורגמו בפועל להגדלה אחת בלבד, וערכים ילכו לאיבוד. זה מוביל לתוצאות שגויות ובלתי צפויות. לדוגמה, אם `shared_counter` הוא 0, תהליכון A קורא 0, תהליכון B קורא 0, תהליכון A מגדיל ל-1 וכותב 1, ותהליכון B מגדיל ל-1 וכותב 1. במקום 2, המונה נשאר על 1.\n\n### פתרון פשוט למניעה:\nהדרך הנפוצה והפשוטה ביותר למנוע תנאי מרוץ היא באמצעות מנגנוני סנכרון כמו מנעולים (Mutexes). מנעול מבטיח שרק תהליכון אחד יוכל להיכנס לקטע קריטי (Critical Section) - קטע קוד שבו ניגשים לנתונים משותפים - בכל רגע נתון.\n\n#### דוגמת קוד עם Mutex (פתרון):\n```c\n#include <stdio.h>\n#include <pthread.h>\n\nint shared_counter = 0;\npthread_mutex_t counter_mutex; // מנעול להגנת המונה המשותף\n\nvoid* increment_function_safe(void* arg) {\n    for (int i = 0; i < 100000; i++) {\n        pthread_mutex_lock(&counter_mutex);   // נעל את המנעול לפני הגישה לקטע הקריטי\n        shared_counter++;                     // קטע קריטי - פעולה על המשתנה המשותף\n        pthread_mutex_unlock(&counter_mutex); // שחרר את המנעול לאחר סיום הגישה\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n    pthread_mutex_init(&counter_mutex, NULL); // אתחול המנעול\n\n    pthread_create(&tid1, NULL, increment_function_safe, NULL);\n    pthread_create(&tid2, NULL, increment_function_safe, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    printf(\"Final counter value: %d\\n\", shared_counter); // צפוי להיות 200000\n\n    pthread_mutex_destroy(&counter_mutex); // השמדת המנעול\n    return 0;\n}\n```\nהוספת `pthread_mutex_lock` ו-`pthread_mutex_unlock` מבטיחה בלעדיות (Mutual Exclusion) בקטע הקריטי, ובכך מונעת את תנאי המרוץ ומבטיחה שהמונה יגיע לערך הנכון (במקרה זה, 200000 אם שני תהליכונים רצים 100000 פעמים כל אחד)."}, "difficulty_estimation": "Easy", "_source_file": "0819__Concurrency__Open__Easy.json", "_topic_hint": "Concurrency", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:36:14", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Concurrency", "Race Conditions", "Synchronization", "Mutex"], "content": {"text": "מהו מצב מירוץ (race condition) בקונקרנטיות? תאר/י מצב כזה והסבר/י כיצד ניתן למנוע אותו באמצעות שימוש ב-mutex.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "מצב מירוץ (race condition) מתרחש כאשר שני תהליכים או יותר ניגשים למשאב משותף בו-זמנית, ולפחות אחד מהם משנה את המשאב, כאשר סדר הגישה יכול להשפיע על התוצאה הסופית. לדוגמה, שני חוטים (threads) מנסים להגדיל מונה גלובלי. אם חוט אחד קורא את הערך (למשל, 5), השני קורא את אותו הערך (5), שניהם מגדילים אותו ל-6, ושניהם כותבים 6 בחזרה, המונה הסופי יהיה 6 במקום 7 (הוגדל רק באחד במקום בשניים). הסיבה לכך היא שהפעולות 'קריאה', 'הגדלה', 'כתיבה' אינן אטומיות. \n\nניתן למנוע מצב מירוץ באמצעות שימוש במנגנוני סנכרון כמו mutex (מנעול הדדי). Mutex מבטיח שרק תהליך אחד יכול להיכנס לקטע קריטי (critical section) בו נמצא המשאב המשותף בכל רגע נתון. \n\nכדי להשתמש ב-mutex:\n1. לפני הגישה למשאב המשותף, התהליך מנסה לנעול את ה-mutex (למשל, באמצעות `pthread_mutex_lock` ב-C/C++). \n2. אם ה-mutex זמין, התהליך נועל אותו וממשיך לבצע את הפעולות על המשאב המשותף. \n3. אם ה-mutex כבר נעול על ידי תהליך אחר, התהליך הנוכחי נחסם וממתין עד שה-mutex ישוחרר. \n4. לאחר סיום הפעולות על המשאב המשותף, התהליך משחרר את ה-mutex (למשל, באמצעות `pthread_mutex_unlock`), ובכך מאפשר לתהליכים אחרים לגשת למשאב. פעולה זו מבטיחה בלעדיות (mutual exclusion) על הקטע הקריטי ומונעת מצבי מירוץ."}, "difficulty_estimation": "Easy", "_source_file": "0820__Concurrency__Open__Easy.json", "_topic_hint": "Concurrency", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:36:22", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Concurrency", "Race Conditions", "Synchronization"], "content": {"text": "הסבירו מהו מצב מרוץ (Race Condition) בתכנות מקבילי, ותנו דוגמת קוד פשוטה ב-C/C++ המדגימה מצב מרוץ פוטנציאלי כאשר מספר תהליכונים (threads) מנסים לעדכן משתנה משותף ללא סנכרון.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\n// משתנה משותף\nint counter = 0;\n\n// פונקציה שתופעל על ידי כל תהליכון\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < 100000; i++) {\n        counter++; // קטע קריטי ללא הגנה\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid[2];\n\n    // יצירת שני תהליכונים\n    pthread_create(&tid[0], NULL, increment_counter, NULL);\n    pthread_create(&tid[1], NULL, increment_counter, NULL);\n\n    // המתנה לסיום שני התהליכונים\n    pthread_join(tid[0], NULL);\n    pthread_join(tid[1], NULL);\n\n    // הדפסת הערך הסופי של המונה\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "מצב מרוץ (Race Condition) מתרחש כאשר מספר תהליכונים ניגשים לנתון משותף בו-זמנית, ולפחות אחד מהם משנה את הנתון, מה שמוביל לתוצאות בלתי צפויות ולא עקביות. התוצאה הסופית תלויה בסדר הספציפי שבו פעולות התהליכונים מתבצעות.\n\nבדוגמת הקוד, הפעולה `counter++` אינה אטומית. היא מורכבת משלושה שלבים ברמת המעבד:\n1. קריאת הערך הנוכחי של `counter` לתוך אוגר.\n2. הגדלת הערך באוגר.\n3. כתיבת הערך המעודכן מהאוגר בחזרה ל-`counter` בזיכרון.\n\nאם שני תהליכונים מבצעים את הפעולה הזו במקביל ללא סנכרון, ייתכן ששלביהם יתערבבו כך שעדכונים מסוימים ילכו לאיבוד. לדוגמה, אם `counter` הוא 0:\n*   תהליכון A קורא את `counter` (ערך 0) לאוגר שלו.\n*   המתזמן מחליף לתהליכון B.\n*   תהליכון B קורא את `counter` (ערך 0) לאוגר שלו.\n*   תהליכון B מגדיל את הערך באוגר שלו ל-1 וכותב אותו בחזרה ל-`counter`. כעת `counter` שווה 1.\n*   המתזמן מחליף בחזרה לתהליכון A.\n*   תהליכון A מגדיל את הערך באוגר שלו (שעדיין מכיל 0) ל-1 וכותב אותו בחזרה ל-`counter`. כעת `counter` שווה 1.\n\nבמקום ש-`counter` יהיה 2 (כפי שהיינו מצפים לאחר שתי הגדלות), הוא נשאר 1, כי ההגדלה של תהליכון B נדרסה על ידי הכתיבה של תהליכון A. מכיוון שכל תהליכון מבצע את הלולאה 100,000 פעמים, הערך הסופי הצפוי הוא 200,000, אך בפועל, ברוב ההרצות, נקבל ערך נמוך יותר עקב מצבי מרוץ. הפתרון הוא להגן על הקטע הקריטי (critical section) באמצעות מנגנוני סנכרון כמו מנעולים (mutexes) כדי להבטיח בלעדיות הדדית (mutual exclusion) כאשר ניגשים למשתנה המשותף."}, "difficulty_estimation": "Easy", "_source_file": "0821__Concurrency__Open__Easy.json", "_topic_hint": "Concurrency", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:36:33", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Concurrency"], "content": {"text": "מהו מצב מירוץ (Race Condition)? הסבירו מדוע הוא מהווה בעיה בתכנות מקבילי (Concurrent Programming) וכיצד הוא יכול להוביל לתוצאות שגויות.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "מצב מירוץ (Race Condition) מתרחש כאשר מספר תהליכים או תהליכונים (threads) ניגשים לנתונים משותפים בו-זמנית, ולפחות אחד מהם משנה את הנתונים. התוצאה הסופית של הגישה והשינויים תלויה בסדר הביצוע הלא-דטרמיניסטי של הפעולות.\n\nהוא מהווה בעיה קריטית מכיוון שהתוצאה הסופית אינה צפויה ומשתנה מריצה לריצה, בהתאם לתזמון המדויק של הפעולות. זה מוביל להתנהגות לא-דטרמיניסטית, מה שמקשה מאוד על איתור ותיקון באגים (debugging) ויכול לגרום למצב תוכנה שגוי או לתוצאות לא נכונות.\n\nלדוגמה, נניח שיש לנו משתנה מונה משותף (counter) שמתחיל ב-0, ושני תהליכונים מנסים להגדיל אותו ב-1. כל תהליכון מבצע שלוש פעולות: קריאת ערך המונה, הגדלתו ב-1, וכתיבת הערך החדש בחזרה. אם הפעולות מתבצעות בסדר הבא:\n1.  תהליכון 1 קורא: counter = 0\n2.  תהליכון 2 קורא: counter = 0\n3.  תהליכון 1 מגדיל: temp = 0 + 1 = 1\n4.  תהליכון 2 מגדיל: temp = 0 + 1 = 1\n5.  תהליכון 1 כותב: counter = 1\n6.  תהליכון 2 כותב: counter = 1\nבסיום, ערך המונה הוא 1, אף על פי ששני תהליכונים הגדילו אותו. התוצאה הנכונה הייתה צריכה להיות 2. זה מראה כיצד מצב מירוץ יכול להוביל לנתונים שגויים."}, "difficulty_estimation": "Easy", "_source_file": "0822__Concurrency__Open__Easy.json", "_topic_hint": "Concurrency", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:36:44", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Concurrency", "Race Conditions", "Synchronization"], "content": {"text": "מהו מצב מרוץ (Race Condition)? תנו דוגמה והסבירו כיצד ניתן למנוע אותו.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "מצב מרוץ (Race Condition) מתרחש כאשר מספר תהליכים או תהליכונים ניגשים לנתונים משותפים בו-זמנית, והתוצאה הסופית של הגישה תלויה בסדר הביצוע הלא-דטרמיניסטי שלהם.\n\nדוגמה: נניח שקיימת משתנה גלובלי `counter` המאותחל ל-0. שני תהליכונים מנסים להגדיל את `counter` ב-1. ללא סנכרון מתאים, ייתכן ששניהם יקראו את הערך 0, שניהם יגדילו אותו ל-1, ושניהם יכתבו 1 בחזרה ל-`counter`. במקרה כזה, הערך הסופי של `counter` יהיה 1 במקום 2 (הערך הצפוי).\n\nמניעה: ניתן למנוע מצבי מרוץ על ידי שימוש במנגנוני סנכרון כגון מנעולים (mutexes) או סמפורים (semaphores) כדי להבטיח בלעדיות הדדית (mutual exclusion) על הקטעים הקריטיים (critical sections) של הקוד הניגשים לנתונים המשותפים. בצורה זו, רק תהליכון אחד יכול לגשת לנתונים המשותפים בזמן נתון, ובכך מובטח שהפעולות על הנתונים המשותפים יתבצעו בצורה אטומית ומסודרת."}, "difficulty_estimation": "Easy", "_source_file": "0823__Concurrency__Open__Easy.json", "_topic_hint": "Concurrency", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:36:57", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Concurrency", "Synchronization", "Race Conditions"], "content": {"text": "נתונה תוכנית שבה מספר תהליכונים (threads) מעדכנים מונה משותף (shared counter) ללא שימוש במנגנוני סנכרון. הסבירו איזו בעיה עלולה להתרחש וכיצד ניתן לפתור אותה באמצעות מנגנון סנכרון מתאים.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הבעיה שעלולה להתרחש היא 'מצב מירוץ' (Race Condition). מצב מירוץ מתרחש כאשר מספר תהליכונים ניגשים לנתון משותף (כמו המונה במקרה זה) ומשנים אותו בו-זמנית, והתוצאה הסופית תלויה בסדר הלא-דטרמיניסטי שבו פעולות התהליכונים מתבצעות. לדוגמה, פעולת הקידום של המונה (קריאה, שינוי, כתיבה) אינה אטומית. תהליכון אחד עלול לקרוא את ערך המונה, ואז לפני שהוא מספיק לכתוב את הערך המעודכן, תהליכון אחר קורא את אותו ערך ישן, משנה אותו וכותב אותו בחזרה. כאשר התהליכון הראשון ימשיך לכתוב את ערכו המעודכן, הוא ידרוס את השינוי של השני, וכך קידום אחד 'יאבד'.\nכדי לפתור בעיה זו, יש להגן על הגישה למונה המשותף באמצעות מנגנון סנכרון, לדוגמה מנעול (mutex). מנעול מבטיח שרק תהליכון אחד יוכל להיכנס לקטע קריטי (Critical Section) – הקטע בתוכנית שבו הנתון המשותף מעודכן – בכל רגע נתון. תהליכון המבקש להיכנס לקטע קריטי בזמן שהמנעול תפוס על ידי תהליכון אחר, ייחסם עד שהמנעול ישוחרר. באופן זה, פעולת העדכון של המונה הופכת לאטומית, והתוצאה הסופית תהיה נכונה."}, "difficulty_estimation": "Easy", "_source_file": "0824__Concurrency__Open__Easy.json", "_topic_hint": "Concurrency", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:37:09", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Concurrency", "Synchronization", "Semaphores"], "content": {"text": "סמפור ספירה (counting semaphore) הוא אובייקט סנכרון המאפשר שליטה בגישה למשאב משותף על ידי מספר מוגבל של תהליכונים. בהינתן המבנה הבא והפונקציות `semaphore_init`, `semaphore_wait`, `semaphore_signal` ו-`semaphore_destroy`, השלם את מימוש הסמפור הסופר, תוך שימוש במנעולים (mutexes) ומשתני תנאי (condition variables) בלבד.\nפעולת `semaphore_wait()` (או P) מקטינה את מונה הסמפור. אם המונה הופך שלילי, התהליכון הקורא נחסם עד שמונה הסמפור יגדל מספיק.\nפעולת `semaphore_signal()` (או V) מגדילה את מונה הסמפור. אם יש תהליכונים חסומים הממתינים על הסמפור, אחד מהם משוחרר.\nיש להניח כי `pthread_mutex_t` ו-`pthread_cond_t` זמינים לשימוש. השלם את המימוש ע\"י כתיבת הקוד של הפעולות `semaphore_init`, `semaphore_wait`, `semaphore_signal` ו-`semaphore_destroy`.", "code_snippet": "#include <pthread.h>\n#include <stdlib.h>\n\ntypedef struct {\n    int count;\n    pthread_mutex_t mutex;\n    pthread_cond_t cond;\n} Semaphore;\n\nvoid semaphore_init(Semaphore *sem, int initial_count) {\n    // Implement initialization\n}\n\nvoid semaphore_wait(Semaphore *sem) {\n    // Implement P operation\n}\n\nvoid semaphore_signal(Semaphore *sem) {\n    // Implement V operation\n}\n\nvoid semaphore_destroy(Semaphore *sem) {\n    // Implement destruction\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "מימוש סמפור ספירה באמצעות מנעול ומשתנה תנאי:\n\n```c\n#include <pthread.h>\n#include <stdlib.h>\n\ntypedef struct {\n    int count;\n    pthread_mutex_t mutex;\n    pthread_cond_t cond;\n} Semaphore;\n\nvoid semaphore_init(Semaphore *sem, int initial_count) {\n    sem->count = initial_count;\n    pthread_mutex_init(&sem->mutex, NULL);\n    pthread_cond_init(&sem->cond, NULL);\n}\n\nvoid semaphore_wait(Semaphore *sem) {\n    pthread_mutex_lock(&sem->mutex);\n    sem->count--;\n    while (sem->count < 0) {\n        pthread_cond_wait(&sem->cond, &sem->mutex);\n    }\n    pthread_mutex_unlock(&sem->mutex);\n}\n\nvoid semaphore_signal(Semaphore *sem) {\n    pthread_mutex_lock(&sem->mutex);\n    sem->count++;\n    if (sem->count <= 0) {\n        pthread_cond_signal(&sem->cond);\n    }\n    pthread_mutex_unlock(&sem->mutex);\n}\n\nvoid semaphore_destroy(Semaphore *sem) {\n    pthread_mutex_destroy(&sem->mutex);\n    pthread_cond_destroy(&sem->cond);\n}\n```\n\n**הסבר:**\n\nבפונקציה `semaphore_init`:\n- מאתחלים את `count` לערך `initial_count` שנקבע בעת יצירת הסמפור.\n- מאתחלים את המוטקס (`sem->mutex`) באמצעות `pthread_mutex_init`.\n- מאתחלים את משתנה התנאי (`sem->cond`) באמצעות `pthread_cond_init`.\n\nבפונקציה `semaphore_wait` (פעולת P):\n- נועלים את המוטקס (`pthread_mutex_lock`) כדי להגן על הגישה למונה ולמשתנה התנאי.\n- מקטינים את `count` באחד. אם `count` הופך שלילי, זה מצביע על כך שאין מספיק משאבים זמינים ויש תהליכון שצריך להמתין.\n- כל עוד `count` שלילי, קוראים ל-`pthread_cond_wait` על משתנה התנאי. `pthread_cond_wait` משחררת באופן אטומי את המוטקס וגורמת לחוט להמתין. כאשר החוט מתעורר, היא רוכשת מחדש את המוטקס. שימוש בלולאת `while` הכרחי כדי להתמודד עם התעוררות כוזבת (spurious wakeups) ולוודא שהתנאי אכן מתקיים לפני היציאה מההמתנה.\n- משחררים את המוטקס (`pthread_mutex_unlock`) לאחר שהחוט יצא מההמתנה והתקדם.\n\nבפונקציה `semaphore_signal` (פעולת V):\n- נועלים את המוטקס (`pthread_mutex_lock`) כדי להגן על הגישה למונה ולמשתנה התנאי.\n- מגדילים את `count` באחד. פעולה זו משחררת למעשה משאב או מאפשרת לתהליכון נוסף להמשיך.\n- אם `count` קטן או שווה לאפס לאחר ההגדלה (כלומר, לפני ההגדלה היו תהליכונים חסומים או ש-`count` היה 0), יש להעיר חוט אחד חסום (אם קיים) באמצעות `pthread_cond_signal`. `pthread_cond_signal` מעירה לכל היותר חוט אחד מבין אלה הממתינים על משתנה התנאי. זה מבטיח שאחד מהתהליכונים הממתינים יתעורר וינסה לרכוש מחדש את המוטקס.\n- משחררים את המוטקס (`pthread_mutex_unlock`).\n\nבפונקציה `semaphore_destroy`:\n- משמידים את המוטקס באמצעות `pthread_mutex_destroy`.\n- משמידים את משתנה התנאי באמצעות `pthread_cond_destroy`.\n\n**דגשים:**\n- המשתנה `count` יכול להיות שלילי. ערך חיובי של `count` מציין את מספר המשאבים הזמינים. ערך שלילי של `count` מציין את מספר התהליכונים הממתינים על הסמפור.\n- השימוש בלולאת `while` ב-`semaphore_wait` הוא קריטי כדי להבטיח נכונות במקרה של התעוררות כוזבת או כאשר מספר תהליכונים מתעוררים אך רק אחד יכול להמשיך."}, "difficulty_estimation": "Medium", "_source_file": "0825__Concurrency__Open__Medium.json", "_topic_hint": "Concurrency", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:37:37", "_subject": "Concurrency"}, {"id": 101, "type": "Open", "topic": ["Concurrency", "Synchronization", "Semaphores", "Mutexes", "Producer-Consumer"], "content": {"text": "בעיית המפיק-צרכן היא בעיית סנכרון קלאסית במערכות הפעלה. תארו את הבעיה בקצרה, והציגו מימוש של מאגר חסום (Bounded Buffer) עבורה באמצעות סמפורים (semaphores) ומנעול (mutex) ב-C/C++. יש להסביר את תפקידו של כל סמפור ושל המנעול בפתרון המוצע.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "תיאור בעיית המפיק-צרכן:\nבעיית המפיק-צרכן היא בעיית סנכרון קלאסית שבה ישנם שני סוגים של תהליכים (או ת'רדים): מפיקים (producers) וצרכנים (consumers). המפיקים מייצרים פריטים ומכניסים אותם למאגר משותף, בעוד הצרכנים מוציאים פריטים מהמאגר וצורכים אותם. המאגר הוא בדרך כלל בגודל סופי (מאגר חסום - Bounded Buffer). האתגר הוא להבטיח סנכרון נכון:\n1.  מפיק לא ינסה להוסיף פריט למאגר מלא.\n2.  צרכן לא ינסה להוציא פריט ממאגר ריק.\n3.  גישה למאגר המשותף תהיה מוגנת מפני תנאי מירוץ (race conditions).\n\nמימוש באמצעות סמפורים ומנעול:\nהפתרון משתמש בשני סמפורים ובמנעול אחד:\n*   `empty`: סמפור זה סופר את מספר התאים הריקים במאגר. הוא מאותחל לגודל המאגר (`BUFFER_SIZE`). המפיקים מבצעים עליו `sem_wait` (מפחיתים את מספר התאים הריקים), והצרכנים מבצעים עליו `sem_post` (מגדילים את מספר התאים הריקים). תפקידו למנוע ממפיק להכניס פריט למאגר מלא.\n*   `full`: סמפור זה סופר את מספר התאים המלאים במאגר. הוא מאותחל ל-0. המפיקים מבצעים עליו `sem_post` (מגדילים את מספר התאים המלאים), והצרכנים מבצעים עליו `sem_wait` (מפחיתים את מספר התאים המלאים). תפקידו למנוע מצרכן להוציא פריט ממאגר ריק.\n*   `mutex`: מנעול זה (pthread_mutex_t) משמש להבטחת גישה הדדית בלעדית (mutual exclusion) למאגר המשותף (המערך `buffer` והאינדקסים `in`, `out`). הוא מגן מפני תנאי מירוץ כאשר מספר תהליכים מנסים לגשת למאגר בו זמנית, ובכך מבטיח שהשינויים במאגר יהיו אטומיים ועקביים.\n\nקוד מימוש:\n```c\n#include <semaphore.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h> // For malloc, free, exit\n\n#define BUFFER_SIZE 10\n\ntypedef struct {\n    int buffer[BUFFER_SIZE];\n    int in;  // Next write position\n    int out; // Next read position\n    sem_t empty;   // Counts empty slots, initialized to BUFFER_SIZE\n    sem_t full;    // Counts full slots, initialized to 0\n    pthread_mutex_t mutex; // Protects buffer access (in, out, buffer[])\n} BoundedBuffer;\n\n// Initializes the bounded buffer\nvoid init_buffer(BoundedBuffer *buf) {\n    buf->in = 0;\n    buf->out = 0;\n    sem_init(&buf->empty, 0, BUFFER_SIZE); // Initial empty slots = BUFFER_SIZE\n    sem_init(&buf->full, 0, 0);            // Initial full slots = 0\n    pthread_mutex_init(&buf->mutex, NULL);\n}\n\n// Destroys the bounded buffer's synchronization primitives\nvoid destroy_buffer(BoundedBuffer *buf) {\n    sem_destroy(&buf->empty);\n    sem_destroy(&buf->full);\n    pthread_mutex_destroy(&buf->mutex);\n}\n\n// Producer function: puts an item into the buffer\nvoid put(BoundedBuffer *buf, int item) {\n    sem_wait(&buf->empty); // Decrement empty count, wait if buffer is full\n    pthread_mutex_lock(&buf->mutex); // Acquire mutex for critical section\n    \n    buf->buffer[buf->in] = item;\n    buf->in = (buf->in + 1) % BUFFER_SIZE;\n    // printf(\"Producer produced: %d\\n\", item); // For demonstration\n\n    pthread_mutex_unlock(&buf->mutex); // Release mutex\n    sem_post(&buf->full);  // Increment full count, signal consumer\n}\n\n// Consumer function: gets an item from the buffer\nint get(BoundedBuffer *buf) {\n    sem_wait(&buf->full); // Decrement full count, wait if buffer is empty\n    pthread_mutex_lock(&buf->mutex); // Acquire mutex for critical section\n    \n    int item = buf->buffer[buf->out];\n    buf->out = (buf->out + 1) % BUFFER_SIZE;\n    // printf(\"Consumer consumed: %d\\n\", item); // For demonstration\n\n    pthread_mutex_unlock(&buf->mutex); // Release mutex\n    sem_post(&buf->empty); // Increment empty count, signal producer\n    \n    return item;\n}\n```"}, "difficulty_estimation": "Medium", "_source_file": "0826__Concurrency__Open__Medium.json", "_topic_hint": "Concurrency", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:37:56", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Concurrency", "Synchronization", "Semaphores", "Mutexes", "Producer-Consumer"], "content": {"text": "בעיית יצרן-צרכן עם חוצץ חסום\n\nנתון חוצץ חסום (Bounded Buffer) בגודל קבוע (BUFFER_SIZE), המשמש לתקשורת בין מספר יצרנים (Producers) למספר צרכנים (Consumers). היצרנים מוסיפים פריטים לחוצץ והצרכנים מוציאים פריטים ממנו. יש לממש את פונקציות הוספת הפריט (produce) והוצאת הפריט (consume) באופן בטוח מבחינת סנכרון, תוך שימוש במנעול (pthread_mutex_t) ושני סמפורים (sem_t): אחד עבור מקומות פנויים (empty) ואחד עבור מקומות תפוסים (full). יש להניח שהחוצץ עצמו הוא מערך וכי הפונקציות buffer_add ו-buffer_remove (שאינן מסונכרנות) כבר קיימות כפי שמוצג בקוד.", "code_snippet": "#include <pthread.h>\n#include <semaphore.h>\n#include <stdlib.h> // For malloc, free\n\n#define BUFFER_SIZE 10 // Example size\n\ntypedef struct {\n    int *buffer;\n    int head;\n    int tail;\n    int count; // Current number of items in buffer\n    pthread_mutex_t mutex;\n    sem_t empty; // Number of empty slots\n    sem_t full;  // Number of full slots\n} BoundedBuffer;\n\n// Assume these functions manage the buffer array directly,\n// and are NOT thread-safe themselves. Synchronization is\n// expected in produce/consume.\nvoid buffer_add(BoundedBuffer *bb, int item) {\n    bb->buffer[bb->tail] = item;\n    bb->tail = (bb->tail + 1) % BUFFER_SIZE;\n    bb->count++;\n}\n\nint buffer_remove(BoundedBuffer *bb) {\n    int item = bb->buffer[bb->head];\n    bb->head = (bb->head + 1) % BUFFER_SIZE;\n    bb->count--;\n    return item;\n}\n\n// Function to initialize the buffer (provided for context)\nvoid bb_init(BoundedBuffer *bb) {\n    bb->buffer = (int*)malloc(sizeof(int) * BUFFER_SIZE);\n    bb->head = 0;\n    bb->tail = 0;\n    bb->count = 0;\n    pthread_mutex_init(&bb->mutex, NULL);\n    sem_init(&bb->empty, 0, BUFFER_SIZE); // Initially BUFFER_SIZE empty slots\n    sem_init(&bb->full, 0, 0);            // Initially 0 full slots\n}\n\n// Function to destroy the buffer resources (provided for context)\nvoid bb_destroy(BoundedBuffer *bb) {\n    free(bb->buffer);\n    pthread_mutex_destroy(&bb->mutex);\n    sem_destroy(&bb->empty);\n    sem_destroy(&bb->full);\n}\n\n// TODO: Implement these functions\nvoid produce(BoundedBuffer *bb, int item) {\n    // Your code here\n}\n\nint consume(BoundedBuffer *bb) {\n    // Your code here\n    return -1; // Placeholder\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון דורש שימוש בשילוב של סמפורים ומנעול (mutex) כדי להבטיח סנכרון נכון, למנוע תנאי מירוץ (race conditions) ולנהל חסימה יעילה של חוטים.\nלהלן המימוש של הפונקציות produce ו-consume:\n\n```c\nvoid produce(BoundedBuffer *bb, int item) {\n    sem_wait(&bb->empty);              // 1. המתן למקום פנוי בחוצץ\n    pthread_mutex_lock(&bb->mutex);    // 2. נעל את המנעול לגישה לחוצץ\n    buffer_add(bb, item);              // 3. הוסף את הפריט לחוצץ\n    pthread_mutex_unlock(&bb->mutex);  // 4. שחרר את המנעול\n    sem_post(&bb->full);               // 5. אותת שיש כעת פריט תפוס\n}\n\nint consume(BoundedBuffer *bb) {\n    sem_wait(&bb->full);              // 1. המתן לפריט תפוס בחוצץ\n    pthread_mutex_lock(&bb->mutex);    // 2. נעל את המנעול לגישה לחוצץ\n    int item = buffer_remove(bb);      // 3. הסר את הפריט מהחוצץ\n    pthread_mutex_unlock(&bb->mutex);  // 4. שחרר את המנעול\n    sem_post(&bb->empty);              // 5. אותת שיש כעת מקום פנוי\n    return item;\n}\n```\n\n**הסבר:**\n*   **סמפור `empty`**: מאותחל ל-`BUFFER_SIZE`. הוא משמש כדי לשלוט על מספר המקומות הפנויים בחוצץ. כאשר יצרן קורא ל-`sem_wait(&bb->empty)`, הוא נחסם אם אין מקומות פנויים. כאשר צרכן קורא ל-`sem_post(&bb->empty)`, הוא מאותת ששחרר מקום פנוי.\n*   **סמפור `full`**: מאותחל ל-0. הוא משמש כדי לשלוט על מספר הפריטים התפוסים בחוצץ. כאשר צרכן קורא ל-`sem_wait(&bb->full)`, הוא נחסם אם אין פריטים זמינים. כאשר יצרן קורא ל-`sem_post(&bb->full)`, הוא מאותת שהוסיף פריט תפוס.\n*   **מנעול (`pthread_mutex_t mutex`)**: משמש להבטחת גישה הדדית בלעדית (mutual exclusion) לחוצץ המשותף (המשתנים `head`, `tail`, `count` ומערך `buffer` עצמו). הוא מונע משני חוטים (יצרנים או צרכנים) לגשת ולשנות את מצב החuצץ בו-זמנית, ובכך מונע תנאי מירוץ.\n\n**סדר הפעולות קריטי:**\n1.  **קריאה ל-`sem_wait` לפני נעילת המנעול**: סמפורים אלו משמשים לחסימה יעילה של יצרנים/צרכנים כאשר אין מקום/פריטים. אם היינו נועלים את המנעול לפני ה-`sem_wait`, ייתכן שחוט ינעל את המנעול, ינסה לבצע `sem_wait` וייחסם כשהוא מחזיק את המנעול. זה היה מוביל לקיפאון (deadlock), שכן שום חוט אחר לא יוכל לשחרר את המשאב שהחוט החסום ממתין לו (כי הוא לא יכול לגשת לחוצץ כדי להוסיף/להסיר פריטים).\n2.  **שחרור המנעול לפני קריאה ל-`sem_post`**: המנעול מגן רק על הגישה לנתונים המשותפים בחוצץ. לאחר שהפעולה על החוצץ הסתיימה, יש לשחרר את המנעול כדי לאפשר לחוטים אחרים לגשת אליו. קריאת `sem_post` יכולה להעיר חוט חסום אחר, ורצוי שהחוט שיתעורר יוכל מיד לנסות לנעול את המנעול.\n\nסדר פעולות זה מבטיח את נכונות הסנכרון, מונע תנאי מירוץ ומאפשר לחוטים לחכות ביעילות מבלי לגרום לקיפאונות."}, "difficulty_estimation": "Medium", "_source_file": "0827__Concurrency__Open__Medium.json", "_topic_hint": "Concurrency", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:38:22", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Concurrency", "Synchronization", "Semaphores"], "content": {"text": "הסבירו מהו סמפור (Semaphore) ומהן שתי הפעולות העיקריות שלו. לאחר מכן, כתבו מימוש של סמפור באמצעות mutex ו-condition variables (שימוש ב-pthread). המימוש צריך לכלול את פונקציות האתחול (`semaphore_init`), ההשמדה (`semaphore_destroy`), ה-`wait` (או `P`) וה-`signal` (או `V`). הסבירו בקצרה מדוע השימוש ב-mutex ו-condition variables הכרחי למניעת מצבי מירוץ (race conditions) וכיצד הם תורמים לנכונות המימוש.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "סמפור (Semaphore) הוא אובייקט סנכרון המאפשר שליטה בגישה למשאבים משותפים או תיאום בין תהליכים/חוטים. יש לו ערך שלם (מונה) ושתי פעולות עיקריות:\n1.  `wait` (או `P`): מקטינה את ערך הסמפור. אם הערך הופך שלילי (או אפס, תלוי בהגדרה), החוט הקורא נחסם עד שערך הסמפור יהיה חיובי.\n2.  `signal` (או `V`): מגדילה את ערך הסמפור. אם ישנם חוטים חסומים שממתינים על הסמפור, אחד מהם (או יותר, תלוי במימוש) משוחרר.\n\nמימוש הסמפור באמצעות mutex ו-condition variables:\n\n```c\n#include <pthread.h>\n#include <stdlib.h> // For malloc/free\n\n// Semaphore structure\ntypedef struct {\n    int value;\n    pthread_mutex_t mutex;\n    pthread_cond_t cond;\n} Semaphore;\n\n// Initialize semaphore\nvoid semaphore_init(Semaphore *sem, int initial_value) {\n    sem->value = initial_value;\n    pthread_mutex_init(&sem->mutex, NULL);\n    pthread_cond_init(&sem->cond, NULL);\n}\n\n// Destroy semaphore\nvoid semaphore_destroy(Semaphore *sem) {\n    pthread_mutex_destroy(&sem->mutex);\n    pthread_cond_destroy(&sem->cond);\n}\n\n// Wait (P) operation\nvoid semaphore_wait(Semaphore *sem) {\n    pthread_mutex_lock(&sem->mutex);\n    while (sem->value <= 0) {\n        pthread_cond_wait(&sem->cond, &sem->mutex);\n    }\n    sem->value--;\n    pthread_mutex_unlock(&sem->mutex);\n}\n\n// Signal (V) operation\nvoid semaphore_signal(Semaphore *sem) {\n    pthread_mutex_lock(&sem->mutex);\n    sem->value++;\n    pthread_cond_signal(&sem->cond); // או pthread_cond_broadcast אם יש צורך להעיר מספר ממתינים\n    pthread_mutex_unlock(&sem->mutex);\n}\n```\n\nהשימוש ב-mutex ו-condition variables הוא הכרחי למניעת מצבי מירוץ (race conditions) ולהבטחת נכונות המימוש:\n*   **Mutex**: ה-mutex (מנעול) מבטיח שרק חוט אחד יוכל לגשת ולשנות את ערך ה-`value` של הסמפור בכל רגע נתון. ללא ה-mutex, מספר חוטים יכלו לנסות להקטין או להגדיל את `value` בו-זמנית, מה שעלול להוביל לערך שגוי של המונה (למשל, שני חוטים מבצעים `wait`, שניהם רואים `value=1`, שניהם מקטינים ל-`0` במקום שחוט אחד יקטין ל-`0` והשני יחסם). ה-mutex גם מגן על הגישה למשתנה התנאי עצמו.\n*   **Condition Variable**: ה-condition variable (משתנה תנאי) מאפשר לחוטים להמתין באופן יעיל כאשר הסמפור אינו זמין (כלומר, `value <= 0` בפעולת `wait`). במקום לבצע `busy-waiting` (לולאה שבודקת שוב ושוב את התנאי ומבזבזת זמן מעבד), החוט נכנס למצב שינה ומתעורר רק כאשר חוט אחר מבצע `signal` ומסמן שהתנאי אולי השתנה. זה חוסך משאבי מעבד ומאפשר ניהול תורים מסודר של חוטים ממתינים. ה-mutex נחוץ גם עם ה-condition variable כדי להבטיח שהבדיקה של התנאי (sem->value <= 0) והכניסה למצב שינה יהיו פעולה אטומית, וכדי למנוע מצב שבו `signal` נקרא לפני ש-`wait` נכנס למצב שינה, וכך ה-`signal` יאבד.\n\nבקיצור, ה-mutex מגן על המצב הפנימי של הסמפור, וה-condition variable מאפשר לחוטים להמתין באופן יעיל לתנאים מסוימים תוך כדי שחרור המנעול זמנית."}, "difficulty_estimation": "Medium", "_source_file": "0828__Concurrency__Open__Medium.json", "_topic_hint": "Concurrency", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:38:44", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Concurrency", "Synchronization", "Semaphores", "Producer-Consumer"], "content": {"text": "בעיית היצרן-צרכן היא בעיית סנכרון קלאסית במערכות הפעלה. בבעיה זו, ישנם תהליכים (או ת'רדים) יצרנים אשר מייצרים פריטים ומכניסים אותם לחוצץ משותף, ותהליכים צרכנים אשר מוציאים פריטים מהחוצץ וצורכים אותם. החuצץ הוא בעל גודל קבוע. נתון קוד C/C++ חלקי המגדיר את המבנים הדרושים לפתרון בעיית היצרן-צרכן באמצעות סמפורים ו-mutex. השלם את פונקציות ה-`producer` וה-`consumer` כך שיטפלו בסנכרון הגישה לחוצץ באופן נכון, ימנעו תנאי מרוץ, קיפאון ורעב. הסבר בקצרה את תפקידו של כל סמפור ו-mutex בפתרון.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n#include <semaphore.h>\n\n#define BUFFER_SIZE 10\n\ntypedef struct {\n    int buffer[BUFFER_SIZE];\n    int in; // next empty slot\n    int out; // first full slot\n    sem_t full; // counts number of full slots\n    sem_t empty; // counts number of empty slots\n    pthread_mutex_t mutex; // protects access to buffer, in, out\n} SharedBuffer;\n\nSharedBuffer shared_buffer;\n\nvoid init_shared_buffer() {\n    shared_buffer.in = 0;\n    shared_buffer.out = 0;\n    sem_init(&shared_buffer.full, 0, 0); // Initially 0 full slots\n    sem_init(&shared_buffer.empty, 0, BUFFER_SIZE); // Initially BUFFER_SIZE empty slots\n    pthread_mutex_init(&shared_buffer.mutex, NULL);\n}\n\nvoid *producer(void *arg) {\n    int item;\n    while (1) {\n        // Produce an item\n        item = rand() % 100; // Example: produce a random number\n\n        // TODO: Add synchronization logic here to put item into buffer\n        // ...\n\n        printf(\"Producer produced: %d\\n\", item);\n        // sleep(1); // Simulate work\n    }\n    return NULL;\n}\n\nvoid *consumer(void *arg) {\n    int item;\n    while (1) {\n        // TODO: Add synchronization logic here to get item from buffer\n        // ...\n\n        printf(\"Consumer consumed: %d\\n\", item);\n        // sleep(1); // Simulate work\n    }\n    return NULL;\n}\n", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון בעיית היצרן-צרכן באמצעות סמפורים ו-mutex:\n\n**השלמת פונקציית `producer`:**\n```c\nvoid *producer(void *arg) {\n    int item;\n    while (1) {\n        item = rand() % 100; // Produce an item\n\n        sem_wait(&shared_buffer.empty); // המתן למקום ריק בחוצץ\n        pthread_mutex_lock(&shared_buffer.mutex); // נעל את ה-mutex לגישה לחוצץ\n\n        shared_buffer.buffer[shared_buffer.in] = item;\n        shared_buffer.in = (shared_buffer.in + 1) % BUFFER_SIZE;\n\n        pthread_mutex_unlock(&shared_buffer.mutex); // שחרר את ה-mutex\n        sem_post(&shared_buffer.full); // סמן שמקום התמלא בחוצץ\n\n        printf(\"Producer produced: %d\\n\", item);\n        // sleep(1);\n    }\n    return NULL;\n}\n```\n\n**השלמת פונקציית `consumer`:**\n```c\nvoid *consumer(void *arg) {\n    int item;\n    while (1) {\n        sem_wait(&shared_buffer.full); // המתן לפריט מלא בחוצץ\n        pthread_mutex_lock(&shared_buffer.mutex); // נעל את ה-mutex לגישה לחוצץ\n\n        item = shared_buffer.buffer[shared_buffer.out];\n        shared_buffer.out = (shared_buffer.out + 1) % BUFFER_SIZE;\n\n        pthread_mutex_unlock(&shared_buffer.mutex); // שחרר את ה-mutex\n        sem_post(&shared_buffer.empty); // סמן שמקום התפנה בחוצץ\n\n        printf(\"Consumer consumed: %d\\n\", item);\n        // sleep(1);\n    }\n    return NULL;\n}\n```\n\n**הסבר על תפקיד אובייקטי הסנכרון:**\n\n*   **`sem_t empty`**: סמפור זה (אתחל ל-`BUFFER_SIZE`) סופר את מספר המקומות הריקים הזמינים בחוצץ. היצרן מבצע `sem_wait` עליו לפני הכנסת פריט כדי לוודא שיש מקום פנוי. אם אין מקום פנוי, היצרן ייחסם. הצרכן מבצע `sem_post` עליו לאחר הוצאת פריט כדי לסמן שמקום התפנה וכעת הוא זמין ליצרן.\n\n*   **`sem_t full`**: סמפור זה (אתחל ל-0) סופר את מספר הפריטים המלאים הקיימים בחוצץ. הצרכן מבצע `sem_wait` עליו לפני הוצאת פריט כדי לוודא שיש פריט לצרוך. אם אין פריטים, הצרכן ייחסם. היצרן מבצע `sem_post` עליו לאחר הכנסת פריט כדי לסמן שפריט נוסף וכעת הוא זמין לצרכן.\n\n*   **`pthread_mutex_t mutex`**: ה-mutex (אתחל ל-unlocked) משמש להגנה על הקטע הקריטי, כלומר הגישה המשותפת למערך `buffer` ולמשתנים `in` ו-`out`. הוא מבטיח שרק תהליך אחד (יצרן או צרכן) יוכל לגשת ולשנות את הנתונים המשותפים בו-זמנית. זה מונע תנאי מרוץ (race conditions) ודואג לעדכון עקבי של מצב החוצץ."}, "difficulty_estimation": "Medium", "_source_file": "0830__Concurrency__Open__Medium.json", "_topic_hint": "Concurrency", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:39:29", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Concurrency", "Synchronization", "Producer-Consumer"], "content": {"text": "בבעיית היצרן-צרכן הקלאסית, יצרנים מייצרים פריטים וצרכנים צורכים אותם באמצעות חיץ (buffer) משותף בגודל קבוע. נתון חיץ חסום (bounded buffer) בגודל `BUFFER_SIZE`. עליכם לממש את הפונקציות `produce_item` (להוספת פריט לחיץ) ו-`consume_item` (להוצאת פריט מהחיץ) תוך שימוש בסמפורים וב-mutex כדי להבטיח סנכרון נכון ולמנוע תנאי מירוץ (race conditions) וקיפאונות (deadlocks). התייחסו למקרים של חיץ מלא וחיץ ריק. אין צורך לממש את לוגיקת הוספה/הוצאה בפועל של הנתונים, אלא רק את מנגנוני הסנכרון.", "code_snippet": "#include <semaphore.h>\n#include <pthread.h>\n#include <stdlib.h>\n\n#define BUFFER_SIZE 10\n\ntypedef struct {\n    int buffer[BUFFER_SIZE];\n    int in;  // Next producer slot\n    int out; // Next consumer slot\n    sem_t empty; // Counts empty slots\n    sem_t full;  // Counts full slots\n    pthread_mutex_t mutex; // Protects buffer access\n} BoundedBuffer;\n\n// Initialize the buffer and synchronization primitives\nvoid init_buffer(BoundedBuffer *bb) {\n    bb->in = 0;\n    bb->out = 0;\n    sem_init(&bb->empty, 0, BUFFER_SIZE); // All slots initially empty\n    sem_init(&bb->full, 0, 0);            // No slots initially full\n    pthread_mutex_init(&bb->mutex, NULL);\n}\n\n// Destroy the synchronization primitives\nvoid destroy_buffer(BoundedBuffer *bb) {\n    sem_destroy(&bb->empty);\n    sem_destroy(&bb->full);\n    pthread_mutex_destroy(&bb->mutex);\n}\n\n// Function to produce an item\nvoid produce_item(BoundedBuffer *bb, int item) {\n    // TODO: Implement synchronization and item addition\n}\n\n// Function to consume an item\nint consume_item(BoundedBuffer *bb) {\n    // TODO: Implement synchronization and item removal\n    return -1; // Placeholder\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון לבעיית היצרן-צרכן עם חיץ חסום דורש שימוש בשני סמפורים וב-mutex. ה-mutex (`bb->mutex`) משמש להבטחת גישה בלעדית לחיץ עצמו (המשאב המשותף), כדי למנוע תנאי מירוץ בעת עדכון המצביעים `in` ו-`out` או הכנסה/הוצאה של פריטים. הסמפור `bb->empty` (אתחול ל-`BUFFER_SIZE`) עוקב אחר מספר המקומות הריקים בחיץ. יצרן מבצע `sem_wait` על `empty` לפני הוספת פריט, ומבצע `sem_post` על `full` לאחר הוספתו. הסמפור `bb->full` (אתחול ל-0) עוקב אחר מספר המקומות המלאים בחיץ. צרכן מבצע `sem_wait` על `full` לפני הוצאת פריט, ומבצע `sem_post` על `empty` לאחר הוצאתו.\n\n**מימוש פונקציית `produce_item`:**\n```c\nvoid produce_item(BoundedBuffer *bb, int item) {\n    sem_wait(&bb->empty); // Wait if buffer is full (no empty slots)\n    pthread_mutex_lock(&bb->mutex); // Acquire mutex for exclusive buffer access\n\n    // Critical section: Add item to buffer\n    bb->buffer[bb->in] = item;\n    bb->in = (bb->in + 1) % BUFFER_SIZE;\n\n    pthread_mutex_unlock(&bb->mutex); // Release mutex\n    sem_post(&bb->full); // Signal that a slot is now full\n}\n```\n\n**מימוש פונקציית `consume_item`:**\n```c\nint consume_item(BoundedBuffer *bb) {\n    int item;\n    sem_wait(&bb->full); // Wait if buffer is empty (no full slots)\n    pthread_mutex_lock(&bb->mutex); // Acquire mutex for exclusive buffer access\n\n    // Critical section: Remove item from buffer\n    item = bb->buffer[bb->out];\n    bb->out = (bb->out + 1) % BUFFER_SIZE;\n\n    pthread_mutex_unlock(&bb->mutex); // Release mutex\n    sem_post(&bb->empty); // Signal that a slot is now empty\n\n    return item;\n}\n```\n\n**הסבר:**\n1.  **`sem_wait(&bb->empty)` / `sem_wait(&bb->full)`:** פעולות אלו מבטיחות שהיצרן ימתין אם אין מקום פנוי (החיץ מלא), והצרכן ימתין אם אין פריטים זמינים (החיץ ריק). זה מונע גלישה (overflow) ותת-גלישה (underflow) של החיץ.\n2.  **`pthread_mutex_lock(&bb->mutex)` / `pthread_mutex_unlock(&bb->mutex)`:** ה-mutex משמש להגנה על הקטע הקריטי (critical section) שבו מתבצעת הגישה בפועל לחיץ (הוספה/הוצאה של פריט ועדכון המצביעים `in` ו-`out`). זה מבטיח שרק חוט אחד יגש לחיץ בכל רגע נתון, ובכך מונע תנאי מירוץ.\n3.  **`sem_post(&bb->full)` / `sem_post(&bb->empty)`:** לאחר שהיצרן מוסיף פריט, הוא מאותת שהתמלא מקום (`full`). לאחר שהצרכן מוציא פריט, הוא מאותת שהתפנה מקום (`empty`). אותות אלו מעירים חוטים אחרים שממתינים על הסמפורים המתאימים."}, "difficulty_estimation": "Medium", "_source_file": "0831__Concurrency__Open__Medium.json", "_topic_hint": "Concurrency", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:39:46", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Concurrency", "Synchronization", "Producer-Consumer"], "content": {"text": "באופן כללי, מערכת הפעלה מספקת אובייקטי סנכרון כגון Mutexes ו-Condition Variables כדי לאפשר לחוטים לתאם את פעולותיהם.\nבשאלה זו נתבקש לממש Bounded Buffer (מחסנית חסומה), שהוא מבנה נתונים נפוץ המאפשר לחוטים יצרנים (Producers) להכניס נתונים ולחוטים צרכנים (Consumers) להוציא נתונים באופן בטוח ומסונכרן.\nה-Bounded Buffer הוא בעל גודל קבוע (CAPACITY) ויש לממש אותו כבאפר מעגלי.\nפעולת `put` מוסיפה פריט ל-buffer. אם ה-buffer מלא, החוט הקורא ל-`put` צריך לחכות עד שיתפנה מקום.\nפעולת `get` מסירה פריט מה-buffer. אם ה-buffer ריק, החוט הקורא ל-`get` צריך לחכות עד שפריט יהיה זמין.\nיש להבטיח גישה הדדית בלעדית (mutual exclusion) ל-buffer עצמו.\nממשו את הפונקציות `put` ו-`get` תוך שימוש ב-Mutexes ו-Condition Variables בלבד (ניתן להשתמש בספריית `pthread`). אין צורך לממש את `init` ו-`destroy`.", "code_snippet": "#include <pthread.h>\n#include <stdlib.h> // For malloc/free\n\n#define CAPACITY 10 // Example capacity\n\ntypedef struct {\n    int *buffer;\n    int head;\n    int tail;\n    int count;\n    pthread_mutex_t mutex;\n    pthread_cond_t not_full;\n    pthread_cond_t not_empty;\n} BoundedBuffer;\n\n// Provided functions (no need to implement)\nvoid init_buffer(BoundedBuffer *bb) {\n    bb->buffer = (int *)malloc(sizeof(int) * CAPACITY);\n    bb->head = 0;\n    bb->tail = 0;\n    bb->count = 0;\n    pthread_mutex_init(&bb->mutex, NULL);\n    pthread_cond_init(&bb->not_full, NULL);\n    pthread_cond_init(&bb->not_empty, NULL);\n}\n\nvoid destroy_buffer(BoundedBuffer *bb) {\n    free(bb->buffer);\n    pthread_mutex_destroy(&bb->mutex);\n    pthread_cond_destroy(&bb->not_full);\n    pthread_cond_destroy(&bb->not_empty);\n}\n\n// Functions to implement\nvoid put(BoundedBuffer *bb, int item) {\n    // Your implementation here\n}\n\nint get(BoundedBuffer *bb) {\n    // Your implementation here\n    return -1; // Placeholder\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון דורש שימוש ב-Mutex אחד כדי להבטיח Mutual Exclusion (גישה בלעדית) למבנה הנתונים של ה-Bounded Buffer (ה-buffer עצמו, head, tail, ו-count). בנוסף, יש צורך בשני Condition Variables:\n1.  `not_full`: משמש לאותת לחוטים יצרנים (Producers) כאשר יש מקום פנוי ב-buffer (כלומר, ה-buffer אינו מלא). יצרן ימתין על משתנה תנאי זה אם ה-buffer מלא.\n2.  `not_empty`: משמש לאותת לחוטים צרכנים (Consumers) כאשר יש פריטים זמינים ב-buffer (כלומר, ה-buffer אינו ריק). צרכן ימתין על משתנה תנאי זה אם ה-buffer ריק.\n\n**מימוש פונקציית `put`:**\n```c\nvoid put(BoundedBuffer *bb, int item) {\n    pthread_mutex_lock(&bb->mutex);\n    while (bb->count == CAPACITY) { // Buffer is full, wait\n        pthread_cond_wait(&bb->not_full, &bb->mutex);\n    }\n    bb->buffer[bb->tail] = item;\n    bb->tail = (bb->tail + 1) % CAPACITY;\n    bb->count++;\n    pthread_cond_signal(&bb->not_empty); // Signal that buffer is no longer empty\n    pthread_mutex_unlock(&bb->mutex);\n}\n```\n1.  נועלת את ה-mutex כדי להגן על הגישה ל-buffer.\n2.  בודקת בלולאת `while` האם ה-buffer מלא (`bb->count == CAPACITY`). אם כן, החוט קורא ל-`pthread_cond_wait(&bb->not_full, &bb->mutex)`. פעולה זו משחררת את ה-mutex באופן אטומי ומכניסה את החוט למצב המתנה על `not_full`. כאשר החוט יתעורר, ה-mutex יינעל מחדש. חשוב להשתמש בלולאת `while` ולא ב-`if` מכיוון שחוטים יכולים להתעורר מסיבות שונות (spurious wakeup) או שחוט אחר תפס את המקום לפני שהחוט הנוכחי הספיק לפעול.\n3.  כאשר יש מקום, הפריט מוכנס ל-buffer במיקום `bb->tail`.\n4.  `bb->tail` מקודם (בצורה מעגלית).\n5.  `bb->count` מקודם.\n6.  החוט מאותת ל-`not_empty` (`pthread_cond_signal`) כדי להודיע לכל צרכן שממתין שיש כעת פריט זמין.\n7.  משחרר את ה-mutex.\n\n**מימוש פונקציית `get`:**\n```c\nint get(BoundedBuffer *bb) {\n    pthread_mutex_lock(&bb->mutex);\n    while (bb->count == 0) { // Buffer is empty, wait\n        pthread_cond_wait(&bb->not_empty, &bb->mutex);\n    }\n    int item = bb->buffer[bb->head];\n    bb->head = (bb->head + 1) % CAPACITY;\n    bb->count--;\n    pthread_cond_signal(&bb->not_full); // Signal that buffer is no longer full\n    pthread_mutex_unlock(&bb->mutex);\n    return item;\n}\n```\n1.  נועלת את ה-mutex כדי להגן על הגישה ל-buffer.\n2.  בודקת בלולאת `while` האם ה-buffer ריק (`bb->count == 0`). אם כן, החוט קורא ל-`pthread_cond_wait(&bb->not_empty, &bb->mutex)`. פעולה זו משחררת את ה-mutex באופן אטומי ומכניסה את החוט למצב המתנה על `not_empty`. כאשר החוט יתעורר, ה-mutex יינעל מחדש. גם כאן, שימוש בלולאת `while` הוא קריטי.\n3.  כאשר יש פריט, הפריט מוצא מה-buffer במיקום `bb->head`.\n4.  `bb->head` מקודם (בצורה מעגלית).\n5.  `bb->count` מקודם.\n6.  החוט מאותת ל-`not_full` (`pthread_cond_signal`) כדי להודיע לכל יצרן שממתין שיש כעת מקום פנוי.\n7.  משחרר את ה-mutex.\n\nחשוב לציין ששימוש ב-`pthread_cond_signal` מספיק במקרה זה מכיוון שרק חוט אחד (יצרן או צרכן) יכול להמשיך לאחר כל פעולת `put` או `get` בהתאמה. אם היינו רוצים להעיר את כל החוטים הממתינים (למשל, במקרים מורכבים יותר או אם יש מספר מקומות/פריטים שנוספו/הוסרו), היינו משתמשים ב-`pthread_cond_broadcast`."}, "difficulty_estimation": "Medium", "_source_file": "0832__Concurrency__Open__Medium.json", "_topic_hint": "Concurrency", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-08 00:40:07", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Concurrency", "Synchronization", "Threads", "Resource Management", "Priority"], "content": {"text": "עליכם לממש אובייקט סנכרון בשם `ResourcePool` המנהל מאגר של `N` משאבים זהים. במערכת קיימים שני סוגי חוטים: חוטים בעלי עדיפות גבוהה (High-Priority) וחוטים בעלי עדיפות נמוכה (Low-Priority).\n\nהאובייקט `ResourcePool` צריך לספק את הפעולות הבאות:\n- `acquire_resource(PriorityType priority)`: חוט קורא לפעולה זו כדי לרכוש משאב. `PriorityType` יכול להיות `HIGH_PRIORITY` או `LOW_PRIORITY`.\n- `release_resource()`: חוט קורא לפעולה זו כדי לשחרר משאב שברשותו.\n\nיש לממש את האובייקט והפעולות תוך הקפדה על הכללים הבאים:\n1.  ישנם `N` משאבים זהים זמינים במאגר.\n2.  חוט בעל עדיפות גבוהה שמבקש לרכוש משאב יקבל אותו באופן מיידי אם יש משאב זמין.\n3.  חוט בעל עדיפות גבוהה שמבקש לרכוש משאב כאשר אין משאבים זמינים, ימתין עד שיתפנה משאב.\n4.  חוט בעל עדיפות נמוכה שמבקש לרכוש משאב יקבל אותו באופן מיידי רק אם יש משאב זמין ואין חוטים בעלי עדיפות גבוהה שממתינים למשאב.\n5.  חוט בעל עדיפות נמוכה שמבקש לרכוש משאב כאשר אין משאבים זמינים, או כאשר יש חוטים בעלי עדיפות גבוהה שממתינים, ימתין.\n6.  כאשר משאב משוחרר, יש לתת עדיפות לחוטים בעלי עדיפות גבוהה שממתינים. רק אם אין חוטים בעלי עדיפות גבוהה שממתינים, יש לתת משאב לאחד מהחוטים בעלי עדיפות נמוכה שממתינים.\n\nיש להשתמש בפרימיטיבים סנכרון סטנדרטיים (mutexes, semaphores, condition variables) ולמנוע מצב של Deadlock או Starvation (לחוטים בעלי עדיפות גבוהה). יש לדאוג שהמימוש יהיה נכון ובטוח מבחינת תחרותיות.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\ntypedef enum {\n    LOW_PRIORITY,\n    HIGH_PRIORITY\n} PriorityType;\n\ntypedef struct {\n    int N; // Total number of resources\n    int available_resources;\n\n    pthread_mutex_t lock;\n    pthread_cond_t high_priority_cond;\n    pthread_cond_t low_priority_cond;\n\n    int high_priority_waiting; // Count of high-priority threads waiting\n    int low_priority_waiting;  // Count of low-priority threads waiting\n\n} ResourcePool;\n\nvoid init_resource_pool(ResourcePool* pool, int N) {\n    pool->N = N;\n    pool->available_resources = N;\n    pthread_mutex_init(&pool->lock, NULL);\n    pthread_cond_init(&pool->high_priority_cond, NULL);\n    pthread_cond_init(&pool->low_priority_cond, NULL);\n    pool->high_priority_waiting = 0;\n    pool->low_priority_waiting = 0;\n}\n\nvoid destroy_resource_pool(ResourcePool* pool) {\n    pthread_mutex_destroy(&pool->lock);\n    pthread_cond_destroy(&pool->high_priority_cond);\n    pthread_cond_destroy(&pool->low_priority_cond);\n}\n\nvoid acquire_resource(ResourcePool* pool, PriorityType priority) {\n    pthread_mutex_lock(&pool->lock);\n\n    if (priority == HIGH_PRIORITY) {\n        pool->high_priority_waiting++;\n        while (pool->available_resources == 0) {\n            pthread_cond_wait(&pool->high_priority_cond, &pool->lock);\n        }\n        pool->high_priority_waiting--;\n        pool->available_resources--;\n    } else { // LOW_PRIORITY\n        pool->low_priority_waiting++;\n        while (pool->available_resources == 0 || pool->high_priority_waiting > 0) {\n            pthread_cond_wait(&pool->low_priority_cond, &pool->lock);\n        }\n        pool->low_priority_waiting--;\n        pool->available_resources--;\n    }\n\n    pthread_mutex_unlock(&pool->lock);\n}\n\nvoid release_resource(ResourcePool* pool) {\n    pthread_mutex_lock(&pool->lock);\n\n    pool->available_resources++;\n\n    if (pool->high_priority_waiting > 0) {\n        pthread_cond_signal(&pool->high_priority_cond);\n    } else if (pool->low_priority_waiting > 0) {\n        pthread_cond_signal(&pool->low_priority_cond);\n    }\n\n    pthread_mutex_unlock(&pool->lock);\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "לשם מימוש `ResourcePool` נשתמש ב-mutex יחיד (`lock`) כדי להגן על המשתנים המשותפים: `available_resources` (מספר המשאבים הזמינים), `high_priority_waiting` (מספר החוטים בעלי עדיפות גבוהה הממתינים), ו-`low_priority_waiting` (מספר החוטים בעלי עדיפות נמוכה הממתינים).\n\nבנוסף, נשתמש בשני משתני תנאי (condition variables):\n- `high_priority_cond`: עבור חוטים בעלי עדיפות גבוהה הממתינים למשאב.\n- `low_priority_cond`: עבור חוטים בעלי עדיפות נמוכה הממתינים למשאב.\n\n**פונקציית `acquire_resource(PriorityType priority)`:**\n1.  החוט נועל את ה-mutex.\n2.  אם החוט הוא בעל עדיפות גבוהה (`HIGH_PRIORITY`):\n    *   הוא מגדיל את המונה `high_priority_waiting`.\n    *   החוט נכנס ללולאת המתנה (`while`) כל עוד אין משאבים זמינים (`available_resources == 0`). בתוך הלולאה, הוא קורא ל-`pthread_cond_wait` על `high_priority_cond`, מה שמשחרר את ה-mutex ומכניס את החוט למצב שינה. כשהוא מתעורר, הוא נועל מחדש את ה-mutex ובודק שוב את התנאי.\n    *   לאחר יציאה מהלולאה (כלומר, משאב זמין), הוא מקטין את `high_priority_waiting` ומקטין את `available_resources` (כי הוא לקח משאב).\n3.  אם החוט הוא בעל עדיפות נמוכה (`LOW_PRIORITY`):\n    *   הוא מגדיל את המונה `low_priority_waiting`.\n    *   החוט נכנס ללולאת המתנה (`while`) כל עוד אין משאבים זמינים (`available_resources == 0`) **או** שיש חוטים בעלי עדיפות גבוהה שממתינים (`high_priority_waiting > 0`). בתוך הלולאה, הוא קורא ל-`pthread_cond_wait` על `low_priority_cond`.\n    *   לאחר יציאה מהלולאה, הוא מקטין את `low_priority_waiting` ומקטין את `available_resources`.\n4.  בסיום, החוט משחרר את ה-mutex.\n\n**פונקציית `release_resource()`:**\n1.  החוט נועל את ה-mutex.\n2.  הוא מגדיל את `available_resources` (כי משאב שוחרר).\n3.  הוא בודק אם יש חוטים בעלי עדיפות גבוהה שממתינים (`high_priority_waiting > 0`). אם כן, הוא קורא ל-`pthread_cond_signal` על `high_priority_cond` כדי להעיר אחד מהם. העדפה זו מבטיחה שחוטים בעלי עדיפות גבוהה יקבלו משאב קודם.\n4.  אם אין חוטים בעלי עדיפות גבוהה שממתינים, הוא בודק אם יש חוטים בעלי עדיפות נמוכה שממתינים (`low_priority_waiting > 0`). אם כן, הוא קורא ל-`pthread_cond_signal` על `low_priority_cond` כדי להעיר אחד מהם.\n5.  בסיום, החוט משחרר את ה-mutex.\n\n**מניעת Deadlock ו-Starvation:**\n-   השימוש ב-mutex יחיד ובסדר קבוע של נעילה ושחרור (תמיד נועלים לפני גישה למשתנים משותפים ומשחררים אחרי) מונע Deadlock הנובע מסדר נעילה שונה.\n-   חוטים בעלי עדיפות גבוהה לא יסבלו מ-Starvation מכיוון שתמיד תינתן להם עדיפות ברכישת משאב זמין, וחוטים בעלי עדיפות נמוכה לא יוכלו לרכוש משאב אם חוט בעל עדיפות גבוהה ממתין. כאשר משאב משוחרר, ה-`signal` יועבר קודם כל לחוט בעל עדיפות גבוהה אם כזה ממתין. חוטים בעלי עדיפות נמוכה עשויים להמתין זמן רב אם יש זרם קבוע של חוטים בעלי עדיפות גבוהה, אך זהו מאפיין מובנה של מערכות מבוססות עדיפויות ואינו נחשב ל-Starvation קלאסי במובן של חוסר יכולת לקבל משאב כשהוא זמין ואין מתחרים בעדיפות גבוהה יותר."}, "difficulty_estimation": "Hard", "_source_file": "0833__Concurrency__Open__Hard.json", "_topic_hint": "Concurrency", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:40:44", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Concurrency", "Synchronization", "Readers-Writers Problem", "Prioritization", "Starvation Prevention", "Threads"], "content": {"text": "נתון משאב משותף אליו ניגשים שני סוגי חוטים: קוראים (Readers) וכותבים (Writers). יש לממש מנגנון סנכרון המאפשר גישה למשאב בהתאם לכללים הבאים:\n1.  מספר קוראים יכולים לגשת למשאב בו-זמנית.\n2.  רק כותב אחד יכול לגשת למשאב בכל רגע נתון.\n3.  כותבים אינם יכולים לגשת למשאב כאשר קוראים פעילים.\n4.  קוראים אינם יכולים לגשת למשאב כאשר כותב פעיל.\n\nבנוסף לכללים אלו, יש להבטיח את העדיפויות הבאות:\n5.  **עדיפות לכותבים**: אם ישנם כותבים הממתינים לגישה למשאב, אין לאפשר לקוראים חדשים להיכנס. קוראים קיימים יסיימו את עבודתם, ולאחר מכן הכותבים יקבלו גישה.\n6.  **מניעת הרעבה לכותבים**: כותבים יקבלו גישה למשאב בסדר הגעתם (FIFO).\n7.  **מניעת הרעבה לקוראים**: קוראים לא יורעבו באופן מוחלט (כלומר, הם יקבלו גישה בסופו של דבר, אם אין כותבים ממתינים או פעילים).\n\nיש לממש את הפונקציות הבאות באמצעות מוטקסים (mutexes) ומשתני תנאי (condition variables) מתוך ספריית pthreads:\n`void reader_acquire();`\n`void reader_release();`\n`void writer_acquire();`\n`void writer_release();`\n\nאין צורך לממש את הגישה בפועל למשאב, אלא רק את מנגנון הסנכרון. יש לכלול גם פונקציות אתחול וסיום למנגנון הסנכרון (לדוגמה: `init_rw_lock()`, `destroy_rw_lock()`).", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון מבוסס על שימוש במנעול הדדי (mutex) אחד להגנה על משתני מצב משותפים, ושני משתני תנאי (condition variables) - אחד לקוראים ואחד לכותבים. בנוסף, אנו משתמשים במונים כדי לעקוב אחר מספר הקוראים הפעילים, הכותבים הפעילים, והכותבים הממתינים, ובמנגנון תור (FIFO) לכותבים באמצעות מזהי תור.\n\n**קוד מימוש:**\n```c\n#include <pthread.h>\n\n// Global state variables for synchronization\npthread_mutex_t rw_lock;\npthread_cond_t reader_cond;\npthread_cond_t writer_cond;\n\nint readers_active = 0;   // Number of readers currently in critical section\nint writers_active = 0;   // Number of writers currently in critical section (0 or 1)\nint writers_waiting = 0;  // Number of writers waiting to enter\n\n// For FIFO writer prioritization\nunsigned long next_writer_id = 0; // Next ID to be assigned to a waiting writer\nunsigned long current_writer_id = 0; // ID of the writer whose turn it is\n\nvoid init_rw_lock() {\n    pthread_mutex_init(&rw_lock, NULL);\n    pthread_cond_init(&reader_cond, NULL);\n    pthread_cond_init(&writer_cond, NULL);\n    readers_active = 0;\n    writers_active = 0;\n    writers_waiting = 0;\n    next_writer_id = 0;\n    current_writer_id = 0;\n}\n\nvoid destroy_rw_lock() {\n    pthread_mutex_destroy(&rw_lock);\n    pthread_cond_destroy(&reader_cond);\n    pthread_cond_destroy(&writer_cond);\n}\n\nvoid reader_acquire() {\n    pthread_mutex_lock(&rw_lock);\n    // Readers wait if there's an active writer OR if there are writers waiting (prioritization)\n    while (writers_active > 0 || writers_waiting > 0) {\n        pthread_cond_wait(&reader_cond, &rw_lock);\n    }\n    readers_active++;\n    pthread_mutex_unlock(&rw_lock);\n}\n\nvoid reader_release() {\n    pthread_mutex_lock(&rw_lock);\n    readers_active--;\n    // If this was the last reader and there are writers waiting, signal a writer\n    if (readers_active == 0 && writers_waiting > 0) {\n        pthread_cond_signal(&writer_cond); // Wake up the next writer in line\n    }\n    pthread_mutex_unlock(&rw_lock);\n}\n\nvoid writer_acquire() {\n    pthread_mutex_lock(&rw_lock);\n    writers_waiting++; // Increment count of waiting writers\n    unsigned long my_writer_id = next_writer_id++; // Assign unique ID for FIFO\n\n    // Writers wait if there are active readers, an active writer, OR if it's not their turn\n    while (readers_active > 0 || writers_active > 0 || my_writer_id != current_writer_id) {\n        pthread_cond_wait(&writer_cond, &rw_lock);\n    }\n    \n    writers_waiting--; // Decrement count of waiting writers\n    writers_active++;  // Enter critical section\n    pthread_mutex_unlock(&rw_lock);\n}\n\nvoid writer_release() {\n    pthread_mutex_lock(&rw_lock);\n    writers_active--; // Exit critical section\n    current_writer_id++; // Advance the turn to the next writer\n\n    // If there are writers still waiting, signal the next writer in line\n    if (writers_waiting > 0) {\n        pthread_cond_signal(&writer_cond);\n    } else {\n        // If no writers are waiting, allow readers to proceed\n        pthread_cond_broadcast(&reader_cond);\n    }\n    pthread_mutex_unlock(&rw_lock);\n}\n```\n\n**הסבר מפורט:**\n\n**משתני מצב גלובליים:**\n*   `rw_lock`: מוטקס המגן על כל המשתנים הגלובליים הללו כדי למנוע תנאי מירוץ בגישה אליהם.\n*   `reader_cond`: משתנה תנאי עליו ממתינים קוראים כאשר הם אינם יכולים להיכנס למקטע הקריטי.\n*   `writer_cond`: משתנה תנאי עליו ממתינים כותבים כאשר הם אינם יכולים להיכנס למקטע הקריטי.\n*   `readers_active`: מונה את מספר הקוראים שנמצאים כרגע במקטע הקריטי. כאשר ערכו אפס, אין קוראים פעילים.\n*   `writers_active`: מונה את מספר הכותבים שנמצאים כרגע במקטע הקריטי. ערכו יכול להיות 0 או 1, שכן רק כותב אחד יכול להיות פעיל בכל עת.\n*   `writers_waiting`: מונה את מספר הכותבים שממתינים בתור להיכנס למקטע הקריטי. מונה זה משמש לאכיפת עדיפות לכותבים.\n*   `next_writer_id`: מונה עולה שמשמש להקצאת מזהה ייחודי לכל כותב שמגיע ומבקש גישה. זהו למעשה מספר הסידורי של הכותב בתור הכותבים.\n*   `current_writer_id`: המזהה של הכותב שכרגע תורו להיכנס למקטע הכתיבה. כותבים ממתינים עד שמזהה זה ישתווה למזהה שלהם.\n\n**היגיון הפעולה של הפונקציות:**\n\n1.  **`writer_acquire()`**: \n    *   הכותב נועל את המוטקס (`rw_lock`) כדי לגשת בבטחה למשתני המצב הגלובליים.\n    *   הוא מגדיל את `writers_waiting` כדי לסמן שיש כותב ממתין (זה ימנע מקוראים חדשים להיכנס).\n    *   הוא מקבל מזהה תור ייחודי (`my_writer_id`) על ידי הגדלת `next_writer_id`. מזהה זה ישמש לאכיפת סדר FIFO.\n    *   הכותב נכנס ללולאת המתנה (באמצעות `pthread_cond_wait`) על `writer_cond` אם מתקיים אחד מהתנאים הבאים:\n        *   `readers_active > 0`: ישנם קוראים פעילים במשאב.\n        *   `writers_active > 0`: יש כותב אחר שכרגע פעיל במשאב.\n        *   `my_writer_id != current_writer_id`: זה לא תורו של הכותב הנוכחי להיכנס. תנאי זה, יחד עם קידום `current_writer_id` ב`writer_release`, מבטיח שכותבים ייכנסו בסדר הגעתם (FIFO).\n    *   לאחר שהתנאים מתקיימים (אין קוראים/כותבים פעילים וזה תורו של הכותב), הכותב מקטין את `writers_waiting` (כבר אינו ממתין) ומגדיל את `writers_active` (נכנס למקטע הכתיבה).\n    *   הוא משחרר את המוטקס.\n\n2.  **`writer_release()`**: \n    *   הכותב נועל את המוטקס.\n    *   הוא מקטין את `writers_active` כדי לסמן שיצא ממקטע הכתיבה.\n    *   הוא מקדם את `current_writer_id`. פעולה זו מסמנת שהכותב הבא בתור יכול כעת להיכנס (אם אין קוראים פעילים).\n    *   אם ישנם כותבים נוספים שממתינים (`writers_waiting > 0`), הוא מאותת לכותב הבא בתור על `writer_cond` (באמצעות `pthread_cond_signal`). `signal` ולא `broadcast` משמש כדי להעיר כותב יחיד, שהוא הכותב הבא בתור לפי `current_writer_id`.\n    *   אחרת (אין כותבים ממתינים), הוא מאותת לכל הקוראים הממתינים על `reader_cond` (באמצעות `pthread_cond_broadcast`) כדי לאפשר להם להיכנס, שכן אין יותר כותבים שממתינים או פעילים.\n    *   הוא משחרר את המוטקס.\n\n3.  **`reader_acquire()`**: \n    *   הקורא נועל את המוטקס.\n    *   הוא נכנס ללולאת המתנה על `reader_cond` אם מתקיים אחד מהתנאים הבאים:\n        *   `writers_active > 0`: יש כותב פעיל במשאב.\n        *   `writers_waiting > 0`: ישנם כותבים שממתינים לגישה למשאב. תנאי זה מבטיח את עדיפות הכותבים - קוראים חדשים לא ייכנסו אם יש כותבים שמחכים, גם אם אין כותב פעיל כרגע.\n    *   לאחר שהתנאים מתקיימים (אין כותבים פעילים או ממתינים), הקורא מגדיל את `readers_active` (נכנס למקטע הקריאה).\n    *   הוא משחרר את המוטקס.\n\n4.  **`reader_release()`**: \n    *   הקורא נועל את המוטקס.\n    *   הוא מקטין את `readers_active` כדי לסמן שיצא ממקטע הקריאה.\n    *   אם הוא הקורא האחרון שעזב את המקטע הקריטי (`readers_active == 0`) וישנם כותבים ממתינים (`writers_waiting > 0`), הוא מאותת לכותב הבא בתור על `writer_cond` (באמצעות `pthread_cond_signal`). פעולה זו חשובה כדי לשחרר כותבים כאשר כל הקוראים סיימו את עבודתם.\n    *   הוא משחרר את המוטקס.\n\n**הבטחת הדרישות:**\n*   **מספר קוראים בו-זמנית**: מושג מכיוון ש`readers_active` גדל ללא הגבלה כאשר אין כותבים פעילים או ממתינים. אין הגבלה על מספר הקוראים הפעילים.\n*   **כותב יחיד**: מושג על ידי התנאי `writers_active > 0` בלולאת ההמתנה של הכותבים, אשר מבטיח שרק כותב אחד יכול להיות פעיל בכל עת.\n*   **כותבים לא מפריעים לקוראים/קוראים לא מפריעים לכותבים**: מובטח על ידי תנאי ההמתנה בשני סוגי ה-acquire, המונעים גישה בו-זמנית של קוראים וכותבים.\n*   **עדיפות לכותבים**: התנאי `writers_waiting > 0` בלולאת ההמתנה של `reader_acquire()` מונע כניסת קוראים חדשים כאשר ישנם כותבים הממתינים, ובכך נותן עדיפות לכותבים.\n*   **FIFO לכותבים**: השימוש במזהי תור (`next_writer_id`, `current_writer_id`) ובתנאי `my_writer_id != current_writer_id` בלולאת ההמתנה של הכותבים, יחד עם שימוש ב-`pthread_cond_signal` עבור `writer_cond`, מבטיח שכותבים ייכנסו בסדר הגעתם.\n*   **מניעת הרעבה לקוראים**: קוראים יכולים להיכנס אם אין כותבים פעילים או ממתינים. כאשר כותב מסיים את עבודתו ואין כותבים נוספים בתור, הוא מאותת לכל הקוראים הממתינים באמצעות `pthread_cond_broadcast`, ובכך מונע את הרעבתם."}, "difficulty_estimation": "Hard", "_source_file": "0834__Concurrency__Open__Hard.json", "_topic_hint": "Concurrency", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:41:19", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Concurrency", "Synchronization", "Cache", "LRU", "Mutex"], "content": {"text": "עליכם לממש מטמון (cache) מוגבל בגודל בעל קיבולת קבועה `C`, התומך בפעולות הבאות באופן בטוח לחוטים (thread-safe): `put(key, value)`, `get(key)`. המטמון צריך להשתמש במדיניות פינוי LRU (Least Recently Used) כאשר הקיבולת מלאה, וגם לעדכן את סדר ה-LRU בכל גישה (גם בקריאה).\nשימו לב לדרישות הבאות:\n1.  **Thread-Safety**: כל הפעולות חייבות להיות בטוחות לחוטים.\n2.  **LRU Eviction**: כאשר `put` נקרא והמטמון מלא, יש לפנות את הפריט שהיה בשימוש אחרון (LRU) לפני הוספת הפריט החדש.\n3.  **LRU Update**: כל גישה לפריט (באמצעות `get` או `put`) צריכה לעדכן את מיקומו ברשימת ה-LRU כך שיהפוך לפריט שהיה בשימוש אחרון ביותר (MRU - Most Recently Used).\n4.  **No Deadlocks/Starvation**: המימוש חייב להיות חופשי מקיפאון (deadlock) ומהרעבה (starvation).\n\nממשו את המבנה `LRUCache` ואת הפעולות `put` ו-`get` תוך שימוש באובייקטי סנכרון מתאימים (כגון mutexes, condition variables). אין צורך לממש את `key` ו-`value` אלא להניח שהם טיפוסים גנריים או פשוט `int`.", "code_snippet": "#include <iostream>\n#include <list>\n#include <unordered_map>\n#include <mutex>\n\ntemplate <typename Key, typename Value>\nclass LRUCache {\nprivate:\n    int capacity;\n    std::list<std::pair<Key, Value>> lru_list; // Stores (key, value) pairs, front is MRU, back is LRU\n    std::unordered_map<Key, typename std::list<std::pair<Key, Value>>::iterator> cache_map; // Maps key to iterator in lru_list\n\n    // Synchronization primitives\n    std::mutex mtx;\n\n    // Helper to move an item to the front (MRU)\n    // Assumes mtx is already locked\n    void touch(typename std::list<std::pair<Key, Value>>::iterator it) {\n        // Implementation for touch\n    }\n\npublic:\n    LRUCache(int cap) : capacity(cap) {\n        if (capacity <= 0) {\n            this->capacity = 1; // Default to 1 for safety\n        }\n    }\n\n    // Returns true if key found, false otherwise. If found, value is copied to 'out_value'.\n    bool get(const Key& key, Value& out_value) {\n        // TODO: Implement thread-safe get\n        return false;\n    }\n\n    void put(const Key& key, const Value& value) {\n        // TODO: Implement thread-safe put\n    }\n};", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון מתבסס על הגנה על כל המבנים הפנימיים של המטמון (רשימת ה-LRU והמפה) באמצעות mutex יחיד. מכיוון שגם פעולת `get` וגם פעולת `put` משנות את סדר ה-LRU (על ידי העברת פריט לראש הרשימה), שתיהן דורשות גישה בלעדית למבנים אלו, ולכן mutex יחיד מספק את הרמה הנדרשת של סנכרון.\n\n**הסבר למימוש:**\n\n*   **מבנה הנתונים (private members):**\n    *   `capacity`: גודל המטמון המקסימלי.\n    *   `lru_list`: `std::list` המכילה זוגות (key, value). חזית הרשימה (front) מייצגת את הפריט שהיה בשימוש אחרון ביותר (MRU), וקצה הרשימה (back) מייצג את הפריט שהיה בשימוש פחות מכל (LRU).\n    *   `cache_map`: `std::unordered_map` הממפה מפתח (key) לאיטרטור בתוך `lru_list`. זה מאפשר גישה מהירה O(1) לפריט ברשימה לפי מפתח, וכן עדכון מהיר של מיקומו ברשימה.\n    *   `mtx`: `std::mutex` המשמש להגנה על `lru_list` ו-`cache_map` מפני תנאי מירוץ.\n    *   `touch(iterator it)`: פונקציית עזר (פרטית) המקבלת איטרטור לפריט ברשימת ה-LRU ומעבירה אותו לחזית הרשימה (MRU). פונקציה זו מניחה שה-mutex כבר ננעל.\n\n*   **פעולת `get(const Key& key, Value& out_value)`:**\n    1.  ננעל את ה-mutex באמצעות `std::lock_guard` כדי להבטיח גישה בטוחה למבני הנתונים המשותפים.\n    2.  נחפש את המפתח במפת ה-`cache_map`.\n    3.  אם המפתח לא נמצא (`it == cache_map.end()`), נשחרר את ה-mutex (באופן אוטומטי על ידי `lock_guard`) ונחזיר `false`.\n    4.  אם המפתח נמצא: נעדכן את ה-LRU על ידי קריאה ל-`touch(it->second)` כדי להעביר את הפריט לחזית הרשימה. לאחר מכן, נעתיק את ערך הפריט ל-`out_value`. נשחרר את ה-mutex ונחזיר `true`.\n\n*   **פעולת `put(const Key& key, const Value& value)`:**\n    1.  ננעל את ה-mutex באמצעות `std::lock_guard`.\n    2.  נחפש את המפתח במפת ה-`cache_map`.\n    3.  אם המפתח כבר קיים (`it != cache_map.end()`):\n        *   נעדכן את הערך של הפריט הקיים ברשימה (`it->second->second = value`).\n        *   נעדכן את ה-LRU על ידי קריאה ל-`touch(it->second)`.\n        *   נשחרר את ה-mutex.\n    4.  אם המפתח אינו קיים:\n        *   נבדוק אם המטמון מלא (`cache_map.size() >= capacity`).\n        *   אם המטמון מלא, נפנה את פריט ה-LRU: נוציא את הפריט האחרון מ-`lru_list` ונמחק את המפתח המתאים מ-`cache_map`.\n        *   נוסיף את הפריט החדש לחזית רשימת ה-`lru_list` (`push_front`).\n        *   נוסיף את המפתח החדש ואת האיטרטור לפריט החדש ב-`lru_list` ל-`cache_map`.\n        *   נשחרר את ה-mutex.\n\n**מניעת Deadlocks ו-Starvation:**\n*   **Deadlocks**: נמנעים מ-deadlocks מכיוון שמשתמשים רק ב-mutex יחיד, והוא ננעל ומשוחרר באופן עקבי בתוך כל פעולה. אין סדר נעילה מורכב שיכול להוביל למבוי סתום.\n*   **Starvation**: אין מנגנון המתנה מורכב שעלול להרעיב חוטים מסוימים. חוטים פשוט מנסים לנעול את ה-mutex; ברגע שהם מצליחים, הם מבצעים את פעולתם ומשחררים אותו. אין עדיפויות או תורים מיוחדים שיכולים לגרום לחוט מסוים להמתין ללא הגבלת זמן.\n\n```c++\n#include <iostream>\n#include <list>\n#include <unordered_map>\n#include <mutex>\n#include <string> // For example usage in tests\n#include <utility> // For std::pair\n\ntemplate <typename Key, typename Value>\nclass LRUCache {\nprivate:\n    int capacity;\n    std::list<std::pair<Key, Value>> lru_list; // Stores (key, value) pairs, front is MRU, back is LRU\n    std::unordered_map<Key, typename std::list<std::pair<Key, Value>>::iterator> cache_map; // Maps key to iterator in lru_list\n\n    std::mutex mtx; // Mutex to protect access to lru_list and cache_map\n\n    // Helper to move an item to the front (MRU)\n    // Assumes mtx is already locked\n    void touch(typename std::list<std::pair<Key, Value>>::iterator it) {\n        lru_list.splice(lru_list.begin(), lru_list, it);\n    }\n\npublic:\n    LRUCache(int cap) : capacity(cap) {\n        if (capacity <= 0) {\n            this->capacity = 1; // Default to 1 for safety\n        }\n    }\n\n    // Returns true if key found, false otherwise. If found, value is copied to 'out_value'.\n    bool get(const Key& key, Value& out_value) {\n        std::lock_guard<std::mutex> lock(mtx); // Acquire mutex\n\n        auto it = cache_map.find(key);\n        if (it == cache_map.end()) {\n            return false; // Key not found\n        }\n\n        // Key found, update LRU status and return value\n        touch(it->second); // Move to front (MRU)\n        out_value = it->second->second; // Copy the value\n        return true;\n    }\n\n    void put(const Key& key, const Value& value) {\n        std::lock_guard<std::mutex> lock(mtx); // Acquire mutex\n\n        auto it = cache_map.find(key);\n        if (it != cache_map.end()) {\n            // Key already exists, update value and LRU status\n            it->second->second = value; // Update value\n            touch(it->second); // Move to front (MRU)\n        } else {\n            // Key does not exist\n            if (cache_map.size() >= capacity) {\n                // Cache is full, evict LRU item (from back of list)\n                Key lru_key = lru_list.back().first;\n                lru_list.pop_back();\n                cache_map.erase(lru_key);\n            }\n            // Add new item to front of list and map\n            lru_list.push_front({key, value});\n            cache_map[key] = lru_list.begin();\n        }\n    }\n};\n```", "difficulty_estimation": "Hard"}, "_source_file": "0835__Concurrency__Open__Hard.json", "_topic_hint": "Concurrency", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:41:52", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Concurrency", "Synchronization", "Threads", "Producer-Consumer", "Condition Variables", "Mutexes"], "content": {"text": "מערכת מנהלת תור הודעות משותף בעל קיבולת סופית (MessageQueue), אליו כותבים מספר חוטי 'יצרן' (Producer Threads) וממנו קוראים מספר חוטי 'צרכן' (Consumer Threads). בנוסף, קיים חוט 'מנתח' (Analyzer Thread) שתפקידו לנטר את התור.\n\nאם חוט המנתח מזהה (באופן עקיף, דרך מונה) שישנן הודעות 'קריטיות' (CRITICAL) בתור, עליו להשהות באופן מיידי את כל חוטי היצרן. חוטי היצרן יישארו מושהים עד שכל ההודעות הקריטיות בתור יצרכו על ידי חוטי הצרכן. לאחר שכל ההודעות הקריטיות נצרכו, וחוט המנתח זיהה זאת, חוטי היצרן יכולים לחזור לפעולתם הרגילה. יש לזכור שהודעות קריטיות יכולות להתווסף לתור בכל עת, וחוט המנתח צריך להגיב בהתאם.\n\nיש לממש את מבנה הנתונים של תור ההודעות (MessageQueue) ואת הפעולות הנדרשות (`init_queue`, `destroy_queue`, `put_message`, `get_message`), וכן את לוגיקת חוט המנתח (`analyzer_thread_func`), תוך שימוש באובייקטי סנכרון (כגון mutexes ו-condition variables) כדי למנוע תנאי מירוץ וקיפאונות. יש להקפיד על סדר נעילה נכון של mutexes.\n\nהשתמשו במבנה Message הבא:\n```c\nenum MessageType {\n    REGULAR,\n    CRITICAL\n};\n\nstruct Message {\n    int id;\n    MessageType type;\n};\n```", "code_snippet": "/* מבנה הנתונים והפונקציות הנדרשות */\n#include <pthread.h>\n#include <queue> // שימוש ב-STL queue לפשטות, ניתן להחליף בתור מבוסס מערך ב-C\n#include <iostream>\n#include <unistd.h> // עבור sleep\n\n// הגדרת הודעה\nenum MessageType {\n    REGULAR,\n    CRITICAL\n};\n\nstruct Message {\n    int id;\n    MessageType type;\n};\n\n// מבנה תור ההודעות\ntypedef struct {\n    std::queue<Message> q;\n    int capacity;\n    pthread_mutex_t queue_mutex;\n    pthread_cond_t not_full_cv;       // יצרנים ממתינים כאן אם התור מלא\n    pthread_cond_t not_empty_cv;      // צרכנים ממתינים כאן אם התור ריק\n    pthread_cond_t producers_resume_cv; // יצרנים ממתינים כאן אם הושעו על ידי המנתח\n\n    int critical_messages_count; // מונה הודעות קריטיות בתור\n    bool producers_halted;       // דגל המציין אם היצרנים מושעים\n} MessageQueue;\n\n// אתחול התור\nvoid init_queue(MessageQueue *mq, int capacity) {\n    mq->capacity = capacity;\n    pthread_mutex_init(&mq->queue_mutex, NULL);\n    pthread_cond_init(&mq->not_full_cv, NULL);\n    pthread_cond_init(&mq->not_empty_cv, NULL);\n    pthread_cond_init(&mq->producers_resume_cv, NULL);\n    mq->critical_messages_count = 0;\n    mq->producers_halted = false;\n}\n\n// שחרור משאבי התור\nvoid destroy_queue(MessageQueue *mq) {\n    pthread_mutex_destroy(&mq->queue_mutex);\n    pthread_cond_destroy(&mq->not_full_cv);\n    pthread_cond_destroy(&mq->not_empty_cv);\n    pthread_cond_destroy(&mq->producers_resume_cv);\n}\n\n// הכנסת הודעה לתור (על ידי יצרן)\nvoid put_message(MessageQueue *mq, Message msg) {\n    pthread_mutex_lock(&mq->queue_mutex);\n\n    // המתן אם התור מלא\n    while (mq->q.size() == mq->capacity) {\n        pthread_cond_wait(&mq->not_full_cv, &mq->queue_mutex);\n    }\n    // המתן אם היצרנים הושעו על ידי המנתח\n    while (mq->producers_halted) {\n        pthread_cond_wait(&mq->producers_resume_cv, &mq->queue_mutex);\n    }\n\n    mq->q.push(msg);\n    if (msg.type == CRITICAL) {\n        mq->critical_messages_count++;\n    }\n\n    pthread_cond_signal(&mq->not_empty_cv); // איתות לצרכנים שיש הודעה חדשה\n    pthread_mutex_unlock(&mq->queue_mutex);\n}\n\n// הוצאת הודעה מהתור (על ידי צרכן)\nMessage get_message(MessageQueue *mq) {\n    pthread_mutex_lock(&mq->queue_mutex);\n\n    // המתן אם התור ריק\n    while (mq->q.empty()) {\n        pthread_cond_wait(&mq->not_empty_cv, &mq->queue_mutex);\n    }\n\n    Message msg = mq->q.front();\n    mq->q.pop();\n\n    if (msg.type == CRITICAL) {\n        mq->critical_messages_count--;\n        // אם כל ההודעות הקריטיות נצרכו והיצרנים היו מושעים, יש להמשיך אותם\n        if (mq->critical_messages_count == 0 && mq->producers_halted) {\n            mq->producers_halted = false;\n            pthread_cond_broadcast(&mq->producers_resume_cv); // הער את כל היצרנים הממתינים\n        }\n    }\n\n    pthread_cond_signal(&mq->not_full_cv); // איתות ליצרנים שהתור אינו מלא יותר\n    pthread_mutex_unlock(&mq->queue_mutex);\n    return msg;\n}\n\n// פונקציית חוט המנתח\nvoid *analyzer_thread_func(void *arg) {\n    MessageQueue *mq = (MessageQueue *)arg;\n    while (true) {\n        sleep(2); // נתח כל 2 שניות\n\n        pthread_mutex_lock(&mq->queue_mutex);\n\n        if (mq->critical_messages_count > 0 && !mq->producers_halted) {\n            mq->producers_halted = true;\n            // אין צורך לאותת, יצרנים יבדקו את הדגל 'producers_halted' בניסיונם הבא להכניס הודעה\n            // או כאשר יוערו על ידי not_full_cv ואז יפלו להמתנה על producers_resume_cv.\n        } else if (mq->critical_messages_count == 0 && mq->producers_halted) {\n            mq->producers_halted = false;\n            pthread_cond_broadcast(&mq->producers_resume_cv); // המשך יצרנים\n        }\n\n        pthread_mutex_unlock(&mq->queue_mutex);\n    }\n    return NULL;\n}\n"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון משתמש במנגנון Producer-Consumer סטנדרטי עם הרחבה לשליטה על ידי חוט מנתח. כל המצב המשותף (התור עצמו, קיבולת, מונה הודעות קריטיות, ודגל השעיית יצרנים) מוגן על ידי מנעול יחיד (`queue_mutex`). גישה למשתנים אלו תמיד מתבצעת תחת נעילה של `queue_mutex`.\n\n**מבנה `MessageQueue`:**\n- `q`: תור ה-STL המשמש לאחסון ההודעות.\n- `capacity`: הקיבולת המקסימלית של התור.\n- `queue_mutex`: מנעול שמגן על כל המצב המשותף של התור, כולל המונה של ההודעות הקריטיות ודגל השעיית היצרנים. שימוש במנעול יחיד לכל המצב המשותף מונע בעיות של סדר נעילה וקיפאונות בין פעולות שונות.\n- `not_full_cv`: משתנה תנאי עליו ממתינים חוטי יצרן כאשר התור מלא. הוא מאותת כאשר מתפנה מקום בתור.\n- `not_empty_cv`: משתנה תנאי עליו ממתינים חוטי צרכן כאשר התור ריק. הוא מאותת כאשר מתווספת הודעה לתור.\n- `producers_resume_cv`: משתנה תנאי ספציפי עליו ממתינים חוטי יצרן כאשר הם מושעים על ידי חוט המנתח.\n- `critical_messages_count`: מונה את מספר ההודעות הקריטיות הנוכחי בתור.\n- `producers_halted`: דגל בוליאני המציין אם חוטי היצרן מושעים (true) או רשאים להמשיך לייצר (false).\n\n**פעולת `put_message` (יצרן):**\n1.  החוט נועל את `queue_mutex`.\n2.  הוא בודק בשתי לולאות `while` נפרדות את שני תנאי ההמתנה: אם התור מלא (`q.size() == mq->capacity`) או אם היצרנים מושעים (`mq->producers_halted`).\n    -   אם התור מלא, הוא ממתין על `not_full_cv`. כאשר הוא מתעורר, הוא בודק מחדש את התנאי.\n    -   אם היצרנים מושעים, הוא ממתין על `producers_resume_cv`. כאשר הוא מתעורר, הוא בודק מחדש את התנאי.\n    -   שימו לב: גם אם התעורר מ-`not_full_cv`, הוא עדיין צריך לבדוק אם `producers_halted` הוא `true` ולהיכנס להמתנה על `producers_resume_cv` אם צריך.\n3.  לאחר שעבר את שני תנאי ההמתנה, הוא מוסיף את ההודעה לתור.\n4.  אם ההודעה קריטית, הוא מגדיל את `critical_messages_count`.\n5.  הוא מאותת ל-`not_empty_cv` כדי להעיר צרכנים פוטנציאליים.\n6.  הוא משחרר את `queue_mutex`.\n\n**פעולת `get_message` (צרכן):**\n1.  החוט נועל את `queue_mutex`.\n2.  הוא ממתין בלולאת `while` על `not_empty_cv` אם התור ריק.\n3.  לאחר שהתור אינו ריק, הוא מוציא את ההודעה מהתור.\n4.  אם ההודעה הייתה קריטית, הוא מקטין את `critical_messages_count`.\n5.  **לוגיקת השחרור של היצרנים:** אם `critical_messages_count` הגיע ל-0 **וגם** `producers_halted` היה `true`, זה אומר שכל ההודעות הקריטיות נצרכו. במקרה זה, הצרכן משנה את `producers_halted` ל-`false` ומאותת באמצעות `pthread_cond_broadcast` לכל חוטי היצרן הממתינים על `producers_resume_cv` כדי שימשיכו לפעול.\n6.  הוא מאותת ל-`not_full_cv` כדי להעיר יצרנים פוטנציאליים (כי התפנה מקום בתור).\n7.  הוא משחרר את `queue_mutex` ומחזיר את ההודעה.\n\n**פונקציית `analyzer_thread_func` (מנתח):**\n1.  החוט רץ בלולאה אינסופית ומבצע `sleep` תקופתי (לדוגמה, כל 2 שניות).\n2.  הוא נועל את `queue_mutex` כדי לגשת למצב המשותף.\n3.  **לוגיקת השעיית היצרנים:**\n    -   אם `critical_messages_count` גדול מ-0 **וגם** `producers_halted` הוא `false`, המנתח מזהה שיש הודעות קריטיות והיצרנים אינם מושעים. הוא משנה את `producers_halted` ל-`true`.\n    -   במקרה זה, אין צורך לאותת ל-`producers_resume_cv`. חוטי יצרן שינסו להכניס הודעה יבדקו את הדגל `producers_halted` וייכנסו למצב המתנה בעצמם. יצרנים שכבר ממתינים על `not_full_cv` יתעוררו, יבדקו את `producers_halted` וייכנסו להמתנה על `producers_resume_cv`.\n4.  **לוגיקת המשך פעולת היצרנים:**\n    -   אם `critical_messages_count` שווה ל-0 **וגם** `producers_halted` הוא `true`, המנתח מזהה שכל ההודעות הקריטיות נצרכו אך היצרנים עדיין מושעים (ייתכן וצרכן בודד עשה זאת, אך המנתח מוודא את המצב). הוא משנה את `producers_halted` ל-`false` ומאותת באמצעות `pthread_cond_broadcast` לכל חוטי היצרן הממתינים על `producers_resume_cv` כדי שימשיכו לפעול.\n5.  הוא משחרר את `queue_mutex`.\n\n**יתרונות הפתרון:**\n-   שימוש במנעול יחיד לכל המצב המשותף מונע קיפאונות הנובעים מסדר נעילה שונה.\n-   שימוש נכון במשתני תנאי מבטיח שחוטים ממתינים ביעילות ולא מבצעים busy-waiting.\n-   הפרדה ברורה בין תנאי ההמתנה של התור המלא/ריק לבין תנאי ההמתנה של השעיית היצרנים מסייעת בהבנת הלוגיקה.\n-   ה-`broadcast` ב-`producers_resume_cv` מבטיח שכל היצרנים המושעים יתעוררו כאשר התנאי משתנה."}, "difficulty_estimation": "Hard", "_source_file": "0836__Concurrency__Open__Hard.json", "_topic_hint": "Concurrency", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:42:48", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Concurrency", "Synchronization", "Reader-Writer Lock", "Mutex", "Condition Variables", "Fairness"], "content": {"text": "ממשו מנעול קוראים-כותבים (Reader-Writer Lock) הוגן (Fair). מנעול זה צריך לקיים את התכונות הבאות:\n1.  מספר קוראים רשאים לגשת למשאב בו-זמנית.\n2.  רק כותב אחד רשאי לגשת למשאב בכל רגע נתון.\n3.  קוראים וכותבים אינם רשאים לגשת למשאב בו-זמנית.\n4.  **הגינות**:\n    *   אם כותב ממתין לתפוס את המנעול, אין לאפשר לקוראים חדשים להיכנס למצב קריאה.\n    *   כותבים ממתינים צריכים להיכנס לפי סדר הגעתם (FIFO).\n    *   קוראים ממתינים יורשו להיכנס רק כאשר אין כותבים ממתינים או כותבים פעילים.", "code_snippet": "/* מבנה הנתונים של מנעול קוראים-כותבים הוגן */\ntypedef struct {\n    pthread_mutex_t lock;\n    pthread_cond_t readers_cv;\n    pthread_cond_t writers_cv;\n    int readers_active;     // מספר הקוראים הפעילים כרגע\n    int writers_active;     // 0 או 1 (רק כותב אחד בו-זמנית)\n    int writers_waiting;    // מספר הכותבים הממתינים לתפוס את המנעול\n    long writer_ticket_counter; // מונה גלובלי להקצאת 'כרטיסים' לכותבים\n    long writer_serving_ticket; // מספר 'הכרטיס' של הכותב הבא בתור לשרת\n} FairRWLock;\n\n/* אתחול המנעול */\nvoid init(FairRWLock *rwl) {\n    pthread_mutex_init(&rwl->lock, NULL);\n    pthread_cond_init(&rwl->readers_cv, NULL);\n    pthread_cond_init(&rwl->writers_cv, NULL);\n    rwl->readers_active = 0;\n    rwl->writers_active = 0;\n    rwl->writers_waiting = 0;\n    rwl->writer_ticket_counter = 0;\n    rwl->writer_serving_ticket = 0;\n}\n\n/* ניסיון לתפוס את המנעול לקריאה */\nvoid read_lock(FairRWLock *rwl) {\n    pthread_mutex_lock(&rwl->lock);\n    // קורא ממתין אם יש כותב פעיל או כותבים שממתינים (עדיפות לכותבים)\n    while (rwl->writers_active > 0 || rwl->writers_waiting > 0) {\n        pthread_cond_wait(&rwl->readers_cv, &rwl->lock);\n    }\n    rwl->readers_active++;\n    pthread_mutex_unlock(&rwl->lock);\n}\n\n/* שחרור המנעול מקריאה */\nvoid read_unlock(FairRWLock *rwl) {\n    pthread_mutex_lock(&rwl->lock);\n    rwl->readers_active--;\n    // אם זה הקורא האחרון וקיימים כותבים ממתינים, יש לאותת לכותבים\n    if (rwl->readers_active == 0 && rwl->writers_waiting > 0) {\n        pthread_cond_signal(&rwl->writers_cv);\n    }\n    pthread_mutex_unlock(&rwl->lock);\n}\n\n/* ניסיון לתפוס את המנעול לכתיבה */\nvoid write_lock(FairRWLock *rwl) {\n    pthread_mutex_lock(&rwl->lock);\n    long my_ticket = rwl->writer_ticket_counter++; // מקבל 'כרטיס' לפי סדר הגעה\n    rwl->writers_waiting++; // מגדיל את מונה הכותבים הממתינים\n    // כותב ממתין אם יש קוראים פעילים, כותב פעיל, או אם זה לא תורו (FIFO)\n    while (rwl->readers_active > 0 || rwl->writers_active > 0 || my_ticket != rwl->writer_serving_ticket) {\n        pthread_cond_wait(&rwl->writers_cv, &rwl->lock);\n    }\n    rwl->writers_waiting--; // סיים להמתין, עכשיו הוא פעיל\n    rwl->writers_active = 1;\n    pthread_mutex_unlock(&rwl->lock);\n}\n\n/* שחרור המנעול מכתיבה */\nvoid write_unlock(FairRWLock *rwl) {\n    pthread_mutex_lock(&rwl->lock);\n    rwl->writers_active = 0;\n    rwl->writer_serving_ticket++; // מקדם את התור לכותב הבא\n    // אם קיימים כותבים ממתינים, יש לאותת לכותב הבא בתור\n    if (rwl->writers_waiting > 0) {\n        pthread_cond_signal(&rwl->writers_cv);\n    } \n    // אחרת, אם אין כותבים ממתינים, יש לאותת לכל הקוראים הממתינים\n    else {\n        pthread_cond_broadcast(&rwl->readers_cv);\n    }\n    pthread_mutex_unlock(&rwl->lock);\n}\n\n/* השמדת המנעול */\nvoid destroy(FairRWLock *rwl) {\n    pthread_mutex_destroy(&rwl->lock);\n    pthread_cond_destroy(&rwl->readers_cv);\n    pthread_cond_destroy(&rwl->writers_cv);\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון דורש שימוש ב-mutex אחד לשמירה על שלמות הנתונים המשותפים של המנעול, ושני Condition Variables: אחד לקוראים (readers_cv) ואחד לכותבים (writers_cv).\n\nכדי להבטיח את עקרון ה-FIFO עבור כותבים ואת העדיפות שלהם על פני קוראים חדשים, נשתמש בשני מונים נוספים עבור הכותבים:\n*   `writer_ticket_counter`: מונה גלובלי המוקצה לכל כותב שמגיע ומבקש את המנעול, ומבטיח את סדר ההגעה.\n*   `writer_serving_ticket`: מונה גלובלי המצביע על הכותב הבא בתור שמותר לו להיכנס.\n\n**מנגנון הגינות ו-FIFO:**\n*   כאשר כותב מגיע (`write_lock`), הוא מקבל 'כרטיס' (ticket) ייחודי (`my_ticket`) מהמונה `writer_ticket_counter` ומגדיל את המונה `writers_waiting`. הוא ממתין על `writers_cv` אם יש קוראים פעילים (`readers_active > 0`), כותב פעיל (`writers_active > 0`), או אם זה לא תורו (כלומר, `my_ticket` שונה מ-`writer_serving_ticket`).\n*   כאשר קורא מגיע (`read_lock`), הוא ממתין על `readers_cv` אם יש כותב פעיל (`writers_active > 0`) או אם יש כותבים ממתינים (`writers_waiting > 0`). תנאי זה מבטיח שקוראים חדשים לא יתחילו לקרוא אם יש כותב שממתין, ובכך נותן עדיפות לכותבים. \n*   כאשר כותב מסיים (`write_unlock`), הוא מאפס את `writers_active`, מגדיל את `writer_serving_ticket` כדי לאפשר לכותב הבא בתור להיכנס. אם יש כותבים ממתינים (`writers_waiting > 0`), הוא מאותת לאחד מהם (`pthread_cond_signal`) כדי שיבדוק את תנאי הכניסה שלו. אם אין כותבים ממתינים, הוא מאותת לכל הקוראים הממתינים (`pthread_cond_broadcast`) כדי שיוכלו לנסות להיכנס.\n*   כאשר קורא מסיים (`read_unlock`), הוא מקטין את `readers_active`. אם הוא הקורא האחרון (`readers_active == 0`) וקיימים כותבים שממתינים (`writers_waiting > 0`), הוא מאותת לכותב הבא בתור (`pthread_cond_signal`).\n\n**מצבי המתנה (Conditions for Waiting):**\n*   **`read_lock`**: קורא ממתין על `readers_cv` אם יש כותב פעיל (`writers_active > 0`) או כותבים ממתינים (`writers_waiting > 0`).\n*   **`write_lock`**: כותב ממתין על `writers_cv` אם יש קוראים פעילים (`readers_active > 0`), כותב פעיל (`writers_active > 0`), או אם זה לא תורו (`my_ticket != rwl->writer_serving_ticket`).\n\n**מצבי שחרור (Signaling):**\n*   **`read_unlock`**: אם זה הקורא האחרון וקיימים כותבים ממתינים, מאותת לכותב הבא בתור (`pthread_cond_signal` על `writers_cv`).\n*   **`write_unlock`**: מגדיל את `writer_serving_ticket`. אם קיימים כותבים ממתינים, מאותת לכותב הבא בתור (`pthread_cond_signal` על `writers_cv`). אחרת, מאותת לכל הקוראים הממתינים (`pthread_cond_broadcast` על `readers_cv`)."}, "difficulty_estimation": "Hard", "_source_file": "0838__Concurrency__Open__Hard.json", "_topic_hint": "Concurrency", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:44:15", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Concurrency", "Synchronization", "Deadlock Prevention", "Resource Management", "Mutexes", "Condition Variables"], "content": {"text": "מערכת הפעלה מודרנית דורשת ניהול יעיל של משאבים משותפים. נתונות K סוגי משאבים שונים (לדוגמה: מעבדים גרפיים, כרטיסי רשת מיוחדים, בלוקי זיכרון ייעודיים). כל סוג משאב `i` מכיל כמות התחלתית `initial_counts[i]` יחידות זמינות. תהליכים או תהליכונים במערכת צריכים לבקש סט של משאבים באופן אטומי: אם כל המשאבים הנדרשים זמינים, הם יוקצו לתהליך; אחרת, התהליך ימתין עד שכל המשאבים יהיו זמינים. תהליך שסיים להשתמש במשאבים מחזיר אותם למנהל.\n\nיש לממש את מבנה הנתונים `ResourceManager` ואת הפונקציות `init_resource_manager`, `destroy_resource_manager`, `acquire_resources`, ו-`release_resources`.\nהמימוש חייב להיות:\n1.  **נכון מבחינת סנכרון**: למנוע מצבי מרוץ (race conditions).\n2.  **ללא קיפאון (deadlock-free)**: להבטיח שלא ייווצר מצב שבו תהליכים ממתינים זה לזה באופן בלתי הפיך.\n3.  **ללא המתנה פעילה (busy-waiting)**: תהליכים צריכים לחכות ביעילות ולא לבזבז זמן מעבד.", "code_snippet": "```c\n#include <pthread.h>\n#include <stdlib.h> // For malloc, free\n#include <stdio.h>  // For printf (optional, for debugging)\n\n// Represents a request for resources.\n// resource_id_to_count[i] specifies the number of units required for resource type i.\ntypedef struct {\n    int K; // Number of resource types\n    int *resource_id_to_count; // Array of size K\n} ResourceRequest;\n\n// The resource manager structure - COMPLETE THIS STRUCTURE\ntypedef struct {\n    int K; // Number of resource types\n    // Add necessary synchronization primitives and resource state here\n    // For example:\n    // int *available_counts;\n    // pthread_mutex_t manager_mutex;\n    // pthread_cond_t resources_available_cond;\n} ResourceManager;\n\n// Initializes the resource manager\nvoid init_resource_manager(ResourceManager *manager, int K, const int *initial_counts);\n\n// Destroys the resource manager\nvoid destroy_resource_manager(ResourceManager *manager);\n\n// Acquires all resources specified in the request atomically.\n// If not all resources are available, the calling thread waits.\nvoid acquire_resources(ResourceManager *manager, const ResourceRequest *request);\n\n// Releases all resources specified in the request.\nvoid release_resources(ResourceManager *manager, const ResourceRequest *request);\n\n// Helper functions (optional, for testing/completeness)\nResourceRequest* create_request(int K, const int *counts);\nvoid destroy_request(ResourceRequest *request);\n```", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסבר:\nהמימוש יעשה שימוש ב-`pthread_mutex_t` ו-`pthread_cond_t` כדי להבטיח סנכרון נכון ולמנוע המתנה פעילה.\n*   **`manager_mutex`**: מנעול יחיד זה ישמש להגנה על מבנה הנתונים של `ResourceManager`, ובעיקר על המערך `available_counts`. כל גישה או שינוי של `available_counts` תהיה מוגנת על ידי מנעול זה. זה מבטיח אטומיות בבדיקת זמינות ובהקצאת משאבים.\n*   **`resources_available_cond`**: משתנה תנאי זה ישמש כדי לגרום לתהליכים להמתין ביעילות. כאשר תהליך מנסה לרכוש משאבים ומוצא שהם אינם זמינים, הוא ישחרר את ה-`manager_mutex` וימתין על משתנה התנאי. כאשר תהליך אחר משחרר משאבים, הוא יודיע לכל התהליכים הממתינים על ידי קריאה ל-`pthread_cond_broadcast`, מה שיעיר אותם כדי שיבדקו שוב את זמינות המשאבים.\n\n**מניעת מצבי מרוץ וקיפאון:**\n*   **מצבי מרוץ**: המנעול `manager_mutex` מונע מצבי מרוץ על ידי הבטחה שרק תהליך אחד יכול לבדוק ולשנות את `available_counts` בכל רגע נתון.\n*   **קיפאון (Deadlock)**: בפתרון זה, קיפאון נמנע מכיוון שתהליך לעולם אינו מחזיק במשאבים חלקיים וגם ממתין למשאבים אחרים. תהליך רוכש את המנעול `manager_mutex`, בודק אם *כל* המשאבים הנדרשים זמינים.\n    *   אם כן, הוא מקצה אותם (מפחית מהמונה), משחרר את המנעול וממשיך.\n    *   אם לא, הוא משחרר את המנעול ומיד נכנס למצב המתנה על `resources_available_cond`. הוא לא מחזיק באף משאב (רק במנעול `manager_mutex` לזמן קצר מאוד לבדיקה), ובכך מונע מצב שבו הוא יחסום תהליכים אחרים מלהתקדם.\n    *   סדר הרכישה של משאבים בתוך `acquire_resources` אינו משנה לבעיית הקיפאון, מכיוון שהבדיקה וההקצאה נעשות כולן תחת מנעול יחיד, ובאופן אטומי. אם לא ניתן להקצות את כולם, אף אחד לא מוקצה.\n\n**הימנעות מהמתנה פעילה:**\nהשימוש ב-`pthread_cond_wait` מבטיח שתהליכים הממתינים למשאבים לא יבזבזו זמן מעבד על סריקה חוזרת ונשנית (spinning) אלא ייכנסו למצב שינה עד שיאותתו להם על ידי `pthread_cond_broadcast`.\n\n```c\n#include <pthread.h>\n#include <stdlib.h> // For malloc, free\n#include <stdio.h>  // For printf (optional, for debugging)\n#include <string.h> // For memcpy\n\n// Represents a request for resources.\n// resource_id_to_count[i] specifies the number of units required for resource type i.\ntypedef struct {\n    int K; // Number of resource types\n    int *resource_id_to_count; // Array of size K\n} ResourceRequest;\n\n// The resource manager structure\ntypedef struct {\n    int K; // Number of resource types\n    int *available_counts; // Array of size K, current available units for each type\n    pthread_mutex_t manager_mutex;\n    pthread_cond_t resources_available_cond;\n} ResourceManager;\n\n// Initializes the resource manager\nvoid init_resource_manager(ResourceManager *manager, int K, const int *initial_counts) {\n    manager->K = K;\n    manager->available_counts = (int*) malloc(sizeof(int) * K);\n    if (manager->available_counts == NULL) {\n        perror(\"malloc failed for available_counts\");\n        exit(EXIT_FAILURE);\n    }\n    memcpy(manager->available_counts, initial_counts, sizeof(int) * K);\n\n    pthread_mutex_init(&manager->manager_mutex, NULL);\n    pthread_cond_init(&manager->resources_available_cond, NULL);\n}\n\n// Destroys the resource manager\nvoid destroy_resource_manager(ResourceManager *manager) {\n    free(manager->available_counts);\n    pthread_mutex_destroy(&manager->manager_mutex);\n    pthread_cond_destroy(&manager->resources_available_cond);\n}\n\n// Helper function to check if all resources in a request are available\nstatic int check_availability(ResourceManager *manager, const ResourceRequest *request) {\n    for (int i = 0; i < manager->K; ++i) {\n        if (request->resource_id_to_count[i] > 0 && \n            manager->available_counts[i] < request->resource_id_to_count[i]) {\n            return 0; // Not all resources are available\n        }\n    }\n    return 1; // All resources are available\n}\n\n// Acquires all resources specified in the request atomically.\n// If not all resources are available, the calling thread waits.\nvoid acquire_resources(ResourceManager *manager, const ResourceRequest *request) {\n    pthread_mutex_lock(&manager->manager_mutex);\n\n    while (!check_availability(manager, request)) {\n        // Resources not available, wait for a signal\n        pthread_cond_wait(&manager->resources_available_cond, &manager->manager_mutex);\n    }\n\n    // Resources are available, acquire them\n    for (int i = 0; i < manager->K; ++i) {\n        if (request->resource_id_to_count[i] > 0) {\n            manager->available_counts[i] -= request->resource_id_to_count[i];\n        }\n    }\n\n    pthread_mutex_unlock(&manager->manager_mutex);\n}\n\n// Releases all resources specified in the request.\nvoid release_resources(ResourceManager *manager, const ResourceRequest *request) {\n    pthread_mutex_lock(&manager->manager_mutex);\n\n    // Release resources\n    for (int i = 0; i < manager->K; ++i) {\n        if (request->resource_id_to_count[i] > 0) {\n            manager->available_counts[i] += request->resource_id_to_count[i];\n        }\n    }\n\n    // Notify all waiting threads that resources might now be available\n    pthread_cond_broadcast(&manager->resources_available_cond);\n\n    pthread_mutex_unlock(&manager->manager_mutex);\n}\n\n// Helper function to create a ResourceRequest (optional, for testing)\nResourceRequest* create_request(int K, const int *counts) {\n    ResourceRequest *req = (ResourceRequest*) malloc(sizeof(ResourceRequest));\n    if (req == NULL) {\n        perror(\"malloc failed for ResourceRequest\");\n        exit(EXIT_FAILURE);\n    }\n    req->K = K;\n    req->resource_id_to_count = (int*) malloc(sizeof(int) * K);\n    if (req->resource_id_to_count == NULL) {\n        perror(\"malloc failed for resource_id_to_count in request\");\n        free(req);\n        exit(EXIT_FAILURE);\n    }\n    memcpy(req->resource_id_to_count, counts, sizeof(int) * K);\n    return req;\n}\n\n// Helper function to destroy a ResourceRequest (optional, for testing)\nvoid destroy_request(ResourceRequest *request) {\n    free(request->resource_id_to_count);\n    free(request);\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0839__Concurrency__Open__Hard.json", "_topic_hint": "Concurrency", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:44:56", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Concurrency", "Synchronization", "Mutexes", "Fairness", "Threads", "Condition Variables"], "content": {"text": "במערכות הפעלה, מנעולי הדדיות (mutexes) משמשים להגנה על משאבים משותפים מפני גישה במקביל. עם זאת, מימוש סטנדרטי של mutex (כמו `pthread_mutex_t`) אינו מבטיח הוגנות; כלומר, אין ערובה שחוט שממתין למנעול זמן רב יותר יקבל אותו לפני חוטים אחרים שהגיעו מאוחר יותר. מצב זה עלול להוביל להרעבה (starvation) של חוטים מסוימים.\n\nמטרת שאלה זו היא לממש מנעול הדדי הוגן (`FairMutex`) המבטיח שחוטים ירכשו את המנעול בסדר שבו ביקשו אותו (FIFO - ראשון נכנס, ראשון יוצא). יש להתעלם מבעיות של מספרים שלמים (overflow) או טיפול בשגיאות.\n\nממשו את המבנה `FairMutex` ואת הפעולות `init`, `destroy`, `lock`, ו-`unlock` בהתאם לדרישות ההוגנות. ניתן להשתמש ב-`pthread_mutex_t` וב-`pthread_cond_t`.", "code_snippet": "typedef struct __FairMutex {\n    // השלימו את המבנה\n} FairMutex;\n\nvoid fair_mutex_init(FairMutex *fm);\nvoid fair_mutex_destroy(FairMutex *fm);\nvoid fair_mutex_lock(FairMutex *fm);\nvoid fair_mutex_unlock(FairMutex *fm);", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "לשם מימוש מנעול הוגן, נשתמש בגישת ה\"כרטיסים\" (tickets). כל חוט שמבקש לרכוש את המנעול מקבל מספר כרטיס ייחודי, והחוטים רוכשים את המנעול לפי הסדר העולה של מספרי הכרטיסים שלהם. נשתמש בשני מונים: `next_ticket` שיקצה את הכרטיס הבא לחוט שמבקש את המנעול, ו-`current_serving_ticket` שיציין איזה כרטיס תורו להיכנס למקטע הקריטי.\n\nהמבנה `FairMutex` יכלול:\n*   `pthread_mutex_t guard_mutex`: מנעול פנימי שיגן על הגישה למונים (`next_ticket`, `current_serving_ticket`) ולמשתנה התנאי. זהו מנעול קצר-טווח שנועד להבטיח אטומיות בגישה למשתני המצב של המנעול ההוגן עצמו.\n*   `pthread_cond_t cond_var`: משתנה תנאי שעליו ימתינו חוטים שתורם עדיין לא הגיע.\n*   `int next_ticket`: מונה עולה שמקצה כרטיסים לחוטים המבקשים את המנעול.\n*   `int current_serving_ticket`: מונה עולה שמציין את מספר הכרטיס של החוט שתורו להיכנס למקטע הקריטי או של החוט שמחזיק כרגע את המנעול.\n\n**פעולת `fair_mutex_init`:**\nמאתחלת את המנעולים והמונים לערכי ההתחלה שלהם.\n\n**פעולת `fair_mutex_destroy`:**\nמשחררת את המשאבים של המנעולים והמשתנים התנאיים.\n\n**פעולת `fair_mutex_lock`:**\n1.  החוט רוכש את ה-`guard_mutex` כדי לגשת בבטחה למשתני המצב של המנעול ההוגן.\n2.  הוא מקבל כרטיס ייחודי על ידי העתקת הערך הנוכחי של `next_ticket` והגדלתו (`my_ticket = fm->next_ticket++;`).\n3.  החוט נכנס ללולאת המתנה: כל עוד מספר הכרטיס שלו (`my_ticket`) אינו שווה ל-`current_serving_ticket`, הוא ממתין על `cond_var`. המתנה זו משחררת אוטומטית את `guard_mutex` ומחזירה אותו כשהחוט מתעורר.\n4.  כאשר `my_ticket == fm->current_serving_ticket`, החוט יודע שתורו הגיע, והוא \"רוכש\" את המנעול ההוגן. הוא יוצא מלולאת ההמתנה.\n5.  החוט משחרר את ה-`guard_mutex` וממשיך בביצוע המקטע הקריטי.\n\n**פעולת `fair_mutex_unlock`:**\n1.  החוט רוכש את ה-`guard_mutex`.\n2.  הוא מגדיל את `current_serving_ticket` ב-1. פעולה זו למעשה מעבירה את ה\"תור\" לחוט הבא בתור.\n3.  הוא מאותת לחוט אחד שממתין על `cond_var` (`pthread_cond_signal`). חוט זה (אם קיים) יתעורר, יבדוק את התנאי (`my_ticket == fm->current_serving_ticket`), יגלה שתורו הגיע, וירכוש את המנעול.\n4.  החוט משחרר את ה-`guard_mutex`.\n\n```c\n#include <pthread.h>\n#include <stdlib.h> // For malloc/free\n\ntypedef struct __FairMutex {\n    pthread_mutex_t guard_mutex;\n    pthread_cond_t  cond_var;\n    int             next_ticket;\n    int             current_serving_ticket;\n} FairMutex;\n\nvoid fair_mutex_init(FairMutex *fm) {\n    pthread_mutex_init(&fm->guard_mutex, NULL);\n    pthread_cond_init(&fm->cond_var, NULL);\n    fm->next_ticket = 0;\n    fm->current_serving_ticket = 0;\n}\n\nvoid fair_mutex_destroy(FairMutex *fm) {\n    pthread_mutex_destroy(&fm->guard_mutex);\n    pthread_cond_destroy(&fm->cond_var);\n}\n\nvoid fair_mutex_lock(FairMutex *fm) {\n    pthread_mutex_lock(&fm->guard_mutex);\n    int my_ticket = fm->next_ticket++;\n    while (my_ticket != fm->current_serving_ticket) {\n        pthread_cond_wait(&fm->cond_var, &fm->guard_mutex);\n    }\n    pthread_mutex_unlock(&fm->guard_mutex);\n}\n\nvoid fair_mutex_unlock(FairMutex *fm) {\n    pthread_mutex_lock(&fm->guard_mutex);\n    fm->current_serving_ticket++;\n    pthread_cond_signal(&fm->cond_var); // Signal one waiting thread\n    pthread_mutex_unlock(&fm->guard_mutex);\n}\n```", "difficulty_estimation": "Hard"}, "_source_file": "0840__Concurrency__Open__Hard.json", "_topic_hint": "Concurrency", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-08 00:45:21", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Concurrency", "Race Conditions", "Threads"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בחוטים (threads) לקידום מונה משותף `counter`. כל חוט מבצע מספר קבוע של קידומים. קרא את הקוד וענה על השאלה. מהו הערך המינימלי האפשרי של המונה `counter` שיודפס בסיום ריצת התוכנית? הסבר בקצרה מדוע.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\n#define NUM_THREADS 2\n#define INCREMENTS_PER_THREAD 5\n\nint counter = 0;\n\nvoid* thread_func(void* arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הערך המינימלי האפשרי הוא `INCREMENTS_PER_THREAD` (כלומר 5). מצב זה יכול להתרחש כתוצאה מתנאי מירוץ (race condition) על המשתנה המשותף `counter`. פעולת הקידום `counter++` אינה אטומית ומורכבת משלושה שלבים: קריאת הערך הנוכחי, הגדלתו, וכתיבת הערך החדש. לדוגמה, אם שני החוטים מריצים את הפעולה כמעט במקביל:\n1. חוט 1 קורא את `counter` (נניח 0).\n2. חוט 2 קורא גם הוא את `counter` (גם הוא קורא 0).\n3. חוט 1 מגדיל את הערך שקרא (0+1=1) וכותב אותו חזרה ל-`counter` (כעת `counter`=1).\n4. חוט 2 מגדיל את הערך שקרא (0+1=1) וכותב אותו חזרה ל-`counter` (כעת `counter` עדיין 1, הקידום של חוט 1 \"נדרס\").\n\nאם תרחיש זה של \"דריסה\" חוזר על עצמו באופן עקבי עבור כל פעולת קידום, כך שכל זוג פעולות קידום משני חוטים למעשה נראית כמו קידום אחד בלבד, אז בסיום הריצה, המונה יכיל רק את מספר הקידומים שבוצעו על ידי חוט אחד בלבד, כלומר `INCREMENTS_PER_THREAD`."}, "difficulty_estimation": "Easy", "_source_file": "0841__Concurrency__CodeAnalysis__Easy.json", "_topic_hint": "Concurrency", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:45:39", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Concurrency", "Race Conditions", "Threads", "Shared Memory"], "content": {"text": "נתונה תוכנית C המשתמשת בחוטים (threads) לקידום מונה גלובלי משותף. שני חוטים מריצים את אותה פונקציה שמקדמת את המונה מספר קבוע של פעמים. אין שימוש במנגנוני סנכרון. מהו טווח הערכים האפשרי (מינימלי ומקסימלי) עבור המונה הגלובלי `counter` לאחר ששני החוטים סיימו את ריצתם? נניח ש-`N_INCREMENTS` הוא 100.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\n#define N_INCREMENTS 100 // כל חוט יקדם את המונה מספר זה של פעמים\n#define NUM_THREADS 2    // מספר החוטים\n\nint counter = 0;\n\nvoid* thread_func(void* arg) {\n    for (int i = 0; i < N_INCREMENTS; ++i) {\n        counter++; // פעולה לא אטומית\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הערך המקסימלי האפשרי עבור `counter` הוא 200. זה מתרחש כאשר אין הפרעה בין פעולות הקידום של החוטים, וכל אחד מהם מבצע את 100 הקידומים שלו באופן רציף וללא איבוד נתונים. בסך הכל מתבצעים 2 * 100 = 200 קידומים בהצלחה.\n\nהערך המינימלי האפשרי עבור `counter` הוא 100. זה מתרחש עקב תנאי מירוץ (race condition) בפעולת `counter++`. פעולה זו אינה אטומית ומורכבת משלושה שלבים: קריאת הערך הנוכחי של `counter` לתוך אוגר, הגדלת הערך באוגר, וכתיבת הערך החדש מהאוגר בחזרה ל-`counter`. תרחיש לדוגמה שמוביל לערך מינימלי הוא:\n1. חוט 1 קורא את הערך הנוכחי של `counter` (שהוא 0) ומאחסן אותו באוגר פרטי שלו. (reg_T1 = 0)\n2. מתרחש מעבר הקשר (context switch) לחוט 2.\n3. חוט 2 מריץ את כל 100 הקידומים שלו בהצלחה, ללא הפרעה. `counter` מגיע ל-100.\n4. מתרחש מעבר הקשר בחזרה לחוט 1.\n5. חוט 1 ממשיך את פעולת הקידום שלו: הוא מגדיל את הערך שקרא בתחילה (0) ל-1, וכותב 1 ל-`counter`. כעת, `counter` מוגדר ל-1, למרות שחוט 2 כבר קידם אותו ל-100, ובכך הוא דרס את כל הקידומים של חוט 2.\n6. חוט 1 ממשיך את יתרת הקידומים שלו (99 פעמים נוספות), כאשר בכל פעם הוא קורא את הערך הנוכחי של `counter` (שמתחיל מ-1) ומקדמו. בסיום, `counter` יגיע ל-100.\nבמקרה זה, כל הקידומים של חוט 2 (למעט אולי האחרון שחוט 1 דרס) אבדו עקב פעולת הדריסה של חוט 1, ורק הקידומים של חוט 1 נשמרו, כך שהמונה הסופי הוא 100."}, "difficulty_estimation": "Easy", "_source_file": "0842__Concurrency__CodeAnalysis__Easy.json", "_topic_hint": "Concurrency", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:46:02", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Concurrency", "Race Conditions", "Threads", "Shared Memory"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בשני חוטים (threads) לשינוי משתנה גלובלי משותף `counter`. חוט אחד מגדיל את המונה `N` פעמים, והחוט השני מקטין את המונה `N` פעמים. ערך `N` הוא גדול מספיק (לדוגמה, 100,000) כדי להבטיח קיום תנאי מרוץ (race conditions). המונה מאותחל ל-0.\n\nמהו טווח הערכים האפשריים עבור `counter` בסיום ריצת התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\n#define N 100000 // Number of operations per thread\n\nint counter = 0;\n\nvoid* increment_thread(void* arg) {\n    for (int i = 0; i < N; ++i) {\n        counter++;\n    }\n    return NULL;\n}\n\nvoid* decrement_thread(void* arg) {\n    for (int i = 0; i < N; ++i) {\n        counter--;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_create(&tid1, NULL, increment_thread, NULL);\n    pthread_create(&tid2, NULL, decrement_thread, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכנית סובלת מתנאי מרוץ (race condition) על המשתנה הגלובלי המשותף `counter`. פעולות כמו `counter++` ו-`counter--` אינן אטומיות והן מורכבות משלושה שלבים עיקריים: קריאה (read) של הערך הנוכחי, שינוי (modify) הערך, וכתיבה (write) של הערך החדש.\n\nבגלל תזמוני ריצה שונים של החוטים, אחד השינויים עלול ללכת לאיבוד. לדוגמה:\nנניח `counter = 0`.\n1. חוט 1 (מגדיל) קורא את `counter` (ערך 0) ושומר אותו ברגיסטר.\n2. חוט 2 (מקטין) קורא את `counter` (ערך 0) ושומר אותו ברגיסטר משלו.\n3. חוט 1 מגדיל את הערך שברגיסטר שלו ל-1.\n4. חוט 2 מקטין את הערך שברגיסטר שלו ל-1-.\n5. חוט 1 כותב את הערך 1 ל-`counter`. כעת `counter = 1`.\n6. חוט 2 כותב את הערך 1- ל-`counter`. כעת `counter = -1`.\nבתרחיש זה, ההגדלה של חוט 1 אבדה.\n\nבאופן סימטרי, יכול להתרחש תרחיש שבו ההקטנה של חוט 2 אובדת, מה שיוביל לערך גבוה יותר.\nכתוצאה מכך, הערך הסופי של `counter` יכול להיות כל מספר שלם בין `N-` ל-`N` (כולל).\n*   הערך המינימלי האפשרי הוא `N-`. זה קורה אם כל `N` ההגדלות של חוט 1 \"נבלעות\" על ידי פעולות ההקטנה של חוט 2 (כלומר, בכל פעם שחוט 1 מסיים את פעולת ה-`write` שלו, חוט 2 כותב ערך נמוך יותר מיד לאחר מכן, או שחוט 1 קורא ערך, חוט 2 מסיים את כל פעולותיו, ואז חוט 1 כותב ערך מיושן).\n*   הערך המקסימלי האפשרי הוא `N`. זה קורה אם כל `N` ההקטנות של חוט 2 \"נבלעות\" על ידי פעולות ההגדלה של חוט 1.\n*   הערך המצופה (ללא תנאי מרוץ) הוא 0, והוא גם אפשרי אם אין איבוד של פעולות.\n\nלכן, טווח הערכים האפשריים הוא `[N-, N]`."}, "difficulty_estimation": "Easy", "_source_file": "0843__Concurrency__CodeAnalysis__Easy.json", "_topic_hint": "Concurrency", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-08 00:46:27", "_subject": "Concurrency"}]