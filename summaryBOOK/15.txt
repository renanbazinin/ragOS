מערכות הפעלה – שיעור 15

בשיעור הקודם דיברנו על באגים של מקביליות. היום נראה מקרים של deadlocks.
שימוש במנעול שלא מקיים deadlock freedom עלול להוביל ל-deadlock במערכת.
מנעול שכן מקיים זאת, מבטיח שלא יכול להיות deadlock בשימוש בו, אבל זה נכון רק עבור שימוש במנעול יחיד.
ל-deadlock אין תכונת הרכבה. כלומר אם ניקח שני מנעולים שבשניהם אין deadlocks ונשתמש בשניהם, זה לא מבטיח
שלא יהיו לנו deadlocks. כל מנעול בפני עצמו יגרום שבשימוש שלו ספציפית לא יהיו deadlocks, אבל השילוב שלהם כן יכול
לגרום ל-deadlock. וזה ה-deadlocks שנדבר עליהם השיעור.

Deadlock (קיפאון)- מצב בו המערכת לא יכולה להתקדם. כל החוטים במערכת תקועים, למרות שכל המשאבים הדרושים
לזמינים להם. לדוגמא, יש לנו תור וכל החוטים רוצים להוציא איבר מהתור. יש איבר בתור אבל אף חוט לא מתקדם.

הדוגמא הקלאסית ביותר ל-deadlock: נניח שיש לנו שני מנעולים: L1, L2 (לא משנה אילו מנעולים, איזה סוג שנבחר)
ויש שני חוטים שמנסים לתפוס את המנעול. אם שני החוטים ינסו לתפוס את שני המנעולים בצורה הזו ייתכן deadlock:
אנחנו רוצים לבצע פעולה כלשהי ולשם ביצועה, אנחנו זקוקים לשני מנעולים.
אנחנו רוצים להוציא איבר מהתור ולהכניס אותו למחסנית, אז נתפוס את המנעול של התור ואז את המנעול של המחסנית
ונעביר את האיבר. אם לא נהיה זהירים, עלול לקרות מצב בו החוט הראשון יתפוס את L1 ואז את L2 והחוט השני יתפוס
את L2 ואז את L1 וזה יצור deadlock.

//Thread 2::
pthread_mutex_lock(&L2);
pthread_mutex_lock(&L1);

//Thread 1::
pthread_mutex_lock(&L1);
pthread_mutex_lock(&L2);

מה שעלול לקרות במצב זה נקרא "תלות מעגלית"- אם כל חוט מחזיק את השורה הראשונה של הקוד שלו, המערכת תיכנס ל-
deadlock, כי כל חוט מחכה לחוט השני שיסיים עם המנעול שנדרש לו. חוט 1 לא יתקדם עד שחוט 2 לא ישחרר את L2
ואילו חוט 2 לא יתקדם עד שחוט 1 ישחרר את L1.

L1
Thread 1 Holds
Wanted by
Thread 2 Holds
Wanted by
L2

כך המערכת לא תתקדם אף פעם, למרות שלכאורה המשאבים הנדרשים זמינים.
אם היינו שולטים בהרצה, היינו יכולים למנוע את שני המנעולים לאותן החוט ולנעול
להתקדם. האופן בו הקוד נכתב ורץ, הוא זה שגרם ל-deadlock.

מדוע deadlocks קורים?
כשאנחנו כותבים הרבה קוד, הקוד הופך להיות מסובך ואנחנו לא יודעים בדיוק בכל נקודה בקוד איך הגענו אליה.
אנקפסולציה וחלוקה לחלקים קטנים של קוד וכו' לא עובדים טוב עם מנעולים.
אם אנחנו קוראים לפעולה של אובייקט, כתכנות מונחה עצמים אנחנו רואים את הפעולה כקופסא שחורה.
אבל אם הפעולה הזו תופסת מנעול והיא קוראת לפעולות נוספות, עלול להיגרם מצב של קיפאון כי אין לנו שליטה מי תופס את
המנעול, מתי ובאיזה סדר.
כל העניין של סנכרון, מקביליות וקיפאון- לא עובד טוב עם העקרונות של תכנות נכון (אנקפסולציה, קופסא שחורה וכו'..).

נרצה אופציה להריץ את המערכת שלנו בקיפאון וגם להימנע מקיפאון.
בשביל שניהם אנחנו נסתכל על ארבעת התנאים לקיומו של deadlock :
*בשביל שיקרה קיפאון, אז כל ארבעת התנאים להתקיים.
*בשביל למנוע קיפאון, מספיק למנוע תנאי אחד מבין הארבעה (כלומר כל אחד מארבעת התנאי הללו שלא יתקיים, יכול
למנוע קיפאון).

1. circular wait (המתנה מעגלית)- מצב בו חוטים שונים תופסים משאבים בסדר הפוך.
כמו בדוגמא שראינו מקודם בה חוט 1 תפס את L1 ואז רצה לתפוס את
L2 ואילו חוט 2 תפס את L2 ולאחר מכן רצה את L1 – במקרה הזה
יכול לקרות קיפאון כי לאחר תפיסת המנעול הראשון, כל חוט מחכה לחוט
הקודם שישחרר את המנעול, אבל זה אף פעם לא יקרה.
* המתנה מעגלית יכולה לקרות על כל מספר של משאבים/מנעולים.

//Thread 1::
lock(&L1);
lock(&L2);

//Thread 2::
lock(&L2);
lock(&L1);

פתרון לבעיית המתנה המעגלית:
נקבע סדר אחיד כך שכל חוט יתפוס את המשאבים לפי הסדר הרצוי, וכך נמנע מקיפאון.
לדוגמא עבור מנעולים- אם תמיד נתפוס מנעולים בסדר קבוע בקוד שלנו, וכל מי
שרוצה לתפוס יותר ממנעול אחד תמיד יתפוס אותם בסדר הזה, אז לא יוכל לקרות
קיפאון.

//Thread 1::
lock(&L1);
lock(&L2);

//Thread 2::
lock(&L1);
lock(&L2);

הפתרון הזה מאוד קל אבל לא תמיד אפשרי ולא תמיד נוח.
אם יש לנו אנקפסולציה למשל וכו', לא תמיד נוכל להגדיר סדר בין מנעולים.

2. hold and wait – מצב בו חוט מסוים תפס משאב, הוא מחזיק בו ומחכה למשאב אחר.

//Thread 1::
lock(&L1);   Hold L1
lock(&L2);   Wait for L2

//Thread 2::
lock(&L2);   Hold L2
lock(&L1);   Wait for L1

פתרון לבעיה זו:
נרצה למנוע את ההמתנה למשאבים התפוסים, ולא את ההחזקה של המשאבים.
לשם כך, נגדיר מנעול גלובלי שיהווה מנעול לתפיסת משאבים.
כאשר חוט תופס מנעול ראשון ולאחר מכן ממתין למנעול שני שיפונה- אם יהיה מנעול על תפיסת המשאבים, נוכל להבטיח שבכל
פעם שחוט תופס מנעול מסוים, גם המנעול השני יהיה פנוי עבורו.
נגדיר מנעול מיוחד, מנעול master, שמי שתופס אותו יכול לתפוס את כל המנעולים הנדרשים עבורו ללא הפרעות.
ברגע שחוט תפס את המנעול ה-master, לא יכול לקרות מצב בו הוא תופס את מנעול 1 וחוט אחר תופס את מנעול 2.
כך גם מובטחת חשיבות לסדר תפיסת המנעולים.

//Thread 1::
lock(&master); // begin acquisition
lock(&L1);
lock(&L2);
unlock(&master); // end

//Thread 2::
lock(&master); // begin acquisition
lock(&L2);
lock(&L1);
unlock(&master); // end

*לכן בכל פעם שמנסים לתפוס יותר ממשאב אחד בו זמנית, נצטרך את מנעול המסטר.

3. No preemption- מצב בו חוט מסוים תפס משאב ולא משחרר אותו עד שהוא מסיים.
למשל כמו בדוגמא שלנו בה חוט 1 תפס
את L1 ולא משחרר אותו עד שהוא לא מסיים.
כך גם חוט 2 וכל אחד מהם מחכה
למשאב שלא יגיע.

L1 can't be taken from T1
L2 can't be taken from T2

פתרון לבעיה זו:
לפני שחוט ינסה לתפוס מנעול, הוא יבדוק אותו (ולאו דווקא יחכה לו במידה והוא לא זמין). לשם כך נשתמש ב-()trylock.
()trylock מנסה לתפוס פעם אחת / לזמן מסוים. אם אין הצלחה, הפונקציה חוזרת מיד ומודיעה שהמנעול לא פנוי.
אם חוט ניסה לתפוס מנעול ולא הצליחה, הוא ישחרר את המנעול הראשון שהוא תפס (או הקודמים אם מדובר על כמה) וכך לא
תהיה החזקה של מנעולים שאינם בשימוש באמת.

//Thread 1::
while (1) {
    lock(&L1);
    if (!trylock(&L2))
        unlock(&L1);
}

//Thread 2::
while (1) {
    lock(&L2);
    if (!trylock(&L1))
        unlock(&L2);
}

באופן הזה הפתרון הזה פותר את ה-deadlock אבל
נוצרת בעיה חדשה שנקראת livelock.

livelock- בעיה בה החוטים פעילים (מריצים קוד, מתקדמים) אבל המערכת לא מתקדמת (מבחינה לוגית אנחנו לא
מתקדמים). למשל במצב בו חוט 1 תפס את L1, חוט 2 תפס את L2, ואז שניהם ינסו להתקדם ויתקלו.
לאחר מכן, שני החוטים ינסו שוב (באותן התנאים), ייכשלו וימשיכו כך עד אינסוף.
ככל שיהיו לנו יותר ויותר מנעולים שאנחנו מנסים לתפוס, סביר יותר שהמצב הזה יקרה.
כלומר, מצב בו אנחנו מריצים קוד לכאורה, אבל שום דבר לא באמת קורה.

פתרון לבעיה זו:
בכל מקום בו אנחנו תופסים מנעול בקוד, נוסיף exponential backoff- זמן בו אם החוט לא הצליח לתפוס את המנעול,
הוא יחכה וישן זמן אקראי כלשהו לפני שינסה שוב, ואז ההסתברות מאוד גבוהה לא נקבל livelock.

//Thread 1::
while (1) {
    lock(&L1);
    if (!trylock(&L2)) {
        unlock(&L1);
        sleep(rand() % X);
    }
}

//Thread 2::
while (1) {
    lock(&L2);
    if (!trylock(&L1)) {
        unlock(&L2);
        sleep(rand() % X);
    }
}

X הוא קבוע כלשהו שאנחנו מחליטים (זה הזמן
המקסימלי כביכול).

4. Mutual exclusion (מניעה הדדית)- מצב בו חוטים דורשים שליטה בלעדית על משאב.
פתרון לבעיה זו:
ניתן לכתוב מבני נתונים שיהיו lock free, wait free –כלומר מבני נתונים שהם
ללא שימוש במנעולים וללא שימוש בחסימה של חוטים. כל קוד ניתן למימוש ללא מנעולים, כך
שיעבוד בצורה נכונה וסנכרונית.
החיסרון פה הוא שקוד כזה לא תמיד יותר יעיל.
ברגע שאנחנו לא משתמשים במנעולים, לא יכול להיות קיפאון, כי לא יכול להיות מצב בו כולם ממתינים אחד לשני.
כן יכול לקרות livelock.

דוגמא לביטול של מניעה הדדית:
להו קוד שמוסיף איבר לראש רשימה מקושרת.
מלבד הקריאות ל-lock, זהו קוד סטנדרטי שאמור להקצות איבר
חדש, ולהוסיף את הערך שבחרנו לעדכן את ראש הרשימה.
בשביל לעשות תהליך זה באופן תקין עם מקביליות, מוסיפים מנעול
של הרשימה (הרשימה כולה תהיה נעולה), נתפוס את המנעול לפני
שנוסיף איבר לרשימה, נבצע את הקוד הרלוונטי ונשחרר את המנעול
בסיום. כך לא יוכלו להפריע לנו באמצע.

void insert(int value) {
    node_t* n = malloc(sizeof(node_t));
    n->value = value;
    pthread_mutex_lock(&listlock);
    n->next = head;
    head = n;
    pthread_mutex_unlock(&listlock);
}

כאן יש מניעה הדדית. כלומר, יכול לקרות כאן קיפאון. לא בקוד הזה ספציפית, אבל אם נפעיל את הקוד הזה בקוד נוסף
שתופס מנעול וקורא ל-insert ונשחרר מנעול (עניין כלשהו יותר מורכב) עלול לגרום לקיפאון.

המטרה שלנו היא למנוע את התנאי לקיפאון שהוא מניעה הדדית.
למצון של פקודות אטומיות שונות וביניהן (CAS(compare and swap- שמקבלת 3 מצבי (כתובת כלשהי בזיכרון, ערך
expected וערך new. הפקודה הזו: בודקת האם הערך בכתובת שהעברנו כפרמטר שווה ל-expected, אם כן
היא מעדכנת את הערך להיות new, ומחזירה 1. אם הערך בכתובת שהעברנו כפרמטר לא שווה ל-expected, היא
מחזירה 0 ולא משנה אותן. (כמובן שהכל קורה בצורה אטומית).

כדי להוסיף איבר V לרשימה מקושרת אך ללא שימוש במנעול, נוכל להשתמש ב-CAS.
הבעיה שלנו: אנחנו מוסיפים את האיבר V בשני שלבים:
1. מעדכנים את ה-next של האיבר החדש V להיות ה-head הישן.
2. מעדכנים את ה-head להיות האיבר החדש V.

* הבעיה נוצרת במצב בו מישהו נוסף במקביל אלינו גם ירצה להוסיף איבר V2 לרשימה.
נניח וביצענו את השלב הראשון, כלומר עדכון את ה-next של V להיות ה-head הישן.
עכשיו מגיע מישהו שרוצה להוסיף את V2 לראש הרשימה והוא אכן מעדכן את ה-next של V2 להיות ה-head.
ומעדכן את ה-head שיצביע ל-V2. כלומר הוא הוסיף את V2 לראש הרשימה (ביצע את 2 הפעולות הנדרשות לכך).
עכשיו אנחנו ממשיכים כי אנחנו לא יודעים שקרו דברים בזמן הזה, ואנחנו מעדכנים את ה-head להיות V.
ברגע שעשינו זאת, שינינו את ה-head ובעצם נמחק את V2 מהרשימה.

בשביל לפתור את הבעיה הזו במקור, השתמשנו במנעול (כך ששני השלבים יתבצעו בלי שאף חוט אחר יפריע באמצע).

איך נפתור את הבעיה ללא שימוש במנעול?
ננסה את כל השלבים אותן דבר, אבל במקום לעדכן את ה-head ישירות במידה ואנחנו רוצים להוסיף, נשתמש ב-CAS:

void insert(int value) {
    node_t* n = malloc(sizeof(node_t));
    n->value = value;
    do {
        n->next = head;
    } while (!CompareAndSwap(&head, n->next, n));
}

נבדוק האם הערך של ה-head הנוכחי (הישן, לפני
העדכון) זהה ל-next של V, אם כן אז זה אומר
שאף אחד לא התערב לנו באמצע ולכן נעדכן את הערך
של head להיות V (האיבר החדש).
אם מישהו התערב לנו באמצע, אז ה-head לא
יהיה זהה ל-next של V. לכן במקרה זה, נבין
שהתערבו לנו באמצע ולכן נקרא מחדש את הערך של ה-head, נשים אותו כ-next של V ונבצע שוב CAS.
ננסה זאת בלולאה עד שנצליח להגיע למצב שלא התערבו לנו באמצע.

עכשיו כל החוטים יכולים להתקדם במקביל, אף אחד לא יפריע לאף אחד.
- בצורה הזו לא יכול להיות deadlock כי אין פעולת המתנה של חוטים.
- בקוד הספציפי הזה אין livelock כיוון שכאשר חוט כלשהו נכשל ב-CAS, אנחנו מבינים שחוט אחר הצליח לבצע
הוספה של איבר לרשימה המקושרת.
- יכולה לקרות הרעבה. כלומר ייתכן שאנחנו לא נצליח להוסיף איבר לרשימה, אבל המערכת כולה כן מתקדמת.
- תמיד חוט כלשהו יצליח להוסיף איבר לרשימה, לא ייתכן שכולם כל הזמן יפריעו אחד לשני.
** המימוש הנ"ל נקרא lock-free.

נושא אחרון במקביליות: תזמון מקבילי
דיברנו על תזמון תהליכים, אבל כשדיברנו על כך, התייחסנו לניצול של תהליך אחד בכל רגע נתון (היה לנו סט של תהליכים
והתנהלנו במר בכל רגע נתון נתנו רק תהליך אחד בלבד שירוץ).
תזמון של תהליך יחיד כבר לא נפוץ, כי יש לנו הרבה תהליכים והרבה מעבדים, אנחנו רוצים להריץ כמה מהם במקביל.
נדבר על תזמון מקבילי ועל איך עובד תזמון שצריך לבחור כמה תהליכים במקביל (כל מעבד צריך לבחור תהליך).

תזכורת לגבי איך עובד מעבד ארוכה ליבת:
במעבד יש cache) L1) – זיכרון קטן ומהיר שמוכל להותק של מידע מהזיכרון הראשי (ה-ram).
השאיפה היא שהעותקים יהיו של מידע שאנחנו ניגשים אליו בתדירות גבוהה.
ברגע שאנחנו משתמשים ב-cache, הזיכרון של התוכנית שלנו נראה מהיר.
אם כל פעם שהיינו קוראים מהזיכרון, המעבד באמת היה ניגש לזיכרון, הביצועים שלנו היו גרועים (באופן יחסי למה שאנחנו
רגילים אליו).
כאשר יש לנו מעבד מרובה ליבות כלומר מספר מעבדים- לכל מעבד יש cache פרטי משל עצמו שבו הוא משתמש.
תוכן המטמון של כל מעבד כזה נקבע לפי לוקאליות (מקומיות). יש אלגוריתם שבוחן אילו נתונים יהיו במטמון בכל רגע
נתון והוא עובד לפי 2 עקרונות:
1. temporal locality: אם ניגשנו לפרט מידע כלשהו, סביר שניגש אליו שוב בהמשך.
2. spatial locality: אם ניגשנו לכתובת כלשהי בזיכרון, סביר שנרצה לגשת לכתובות הקרובות אליה גם כן.

אבל עכשיו יש לנו בעיית סינכרון בין התכנים של כל המעבדים.
אם יש לנו כמה מעבדים שכל אחד יש לו cache משל עצמו, ברגע שמעבד מספר 1 למשל קורא את עניין a מה-ram, הוא מסביר
את זה למטמון שלו. כעת הוא יכול לקרוא את העניין הזה באופן חופשי ולהשתמש בו באופן חופשי מבלי לגשת ל-ram בכל
פעם. אם הוא משנה את ערכו, זה משתנה במטמון המקומי והזיכרון הראשי עדיין לא מעודכן, אבל אם לא נעדכן חזרה את
הזיכרון, אם מעבד אחר ירצה לקרוא את ערכו של a הוא יקבל ערך לא תקין.
- מצד אחד, אם לא נעדכן את הזיכרון, לא נהיה מתואמים עם שאר המעבדים.
- מצד שני, אם כן נעדכן את הזיכרון על כל שינוי, זה יהיה מאוד איטי.

בעיה זו נקראת cache coherence – הדאגה לכך שכל המעבדים יהיו מעודכנים כל הזמן עם הערכים הנכונים.
בשביל לפתור את הבעיה (או אחד הביצועים מצד שני עקרונית) נדבר בקיצור.
הרעיון הוא ש-bus מעביר הודעות מהמטמון למעבדים, וכולם כל הזמן מאזינים ל-bus (זה נקרא snooping bus).
כאשר אחד המעבדים מעדכן אצלו ערך של כתובת כלשהי a, הדבר הראשון שיקרה: תישלח הודעה על גבי ה-bus שתודעי
לכל המעבדים לזרוק או לעדכן את הערך הישן של a שהם מחזיקים. כלומר הוא מוודא שהוא נמצא העותק היחידי של a.
במידה ומעבד כלשהו יבקש עותק של a, אזי המעבד שבידו העותק המעודכן ישלח את הבקשה גם (כי הוא מאזין ל-bus)
ובמקרה זה הוא ייעל לו את הערך המעודכן (כי הערך בזיכרון הראשי לא מעודכן).

- ככל שהמעבדים שלנו מריצים יותר תוכניות, הם צוברים cache affinity.
כלומר המטמון צבר הרבה נתונים שקשורים לתוכנית (חוט מסוים). נניח והמערכת ההפעלה תפסיק את ריצת החוט, נשים אותו
בצד. אם בהמשך היא תרצה להריץ שוב את אותו החוט, הרבה יותר יהיה יעיל במקרה הזה לבחור במעבד הקודם שהריץ אותו.
אם נביא למעבד חדש להריץ את החוט הזה, הוא יצטרך לקרוא מחדש את כל הערכים של החוט הזה ולמלא את המטמון שלו,
כאשר סביר להניח שהמעבד הקודם שהריץ את החוט הזה עדיין מכיל את הנתונים הללו, או חלק מהם.
לכן בתזמון אנחנו שואפים להשיג cache affinity- אם משהו רץ על מעבד מסוים, נשתדל להריץ אותו על אותו מעבד, בשביל
לנצל את מה שכבר נטען וקיים ב-cache באופן טוב.

אלגוריתמים:
1. Single-queue multiprocessor scheduling (SQMS) : נחזיק תור של ג'ובים, וכל פעם שמעבד צריך
לבחור ג'וב (נאמרה הקוואנטה של מה שרץ עליו כרגע), הוא הולך לתור המשותף של הג'ובים ולוקח ממנו את הג'וב הבא.
האלגוריתם הזה פשוט.
חסרונות:
1. חייבים להשתמש בנעילה (משהו שאנחנו מנסים להימנע ממנו)- בגלל שיש תור משותף שכמה מעבדים ניגשים אליו במקביל ויש
צורך בסנכרון.
2. אין cache affinity- מעבדים לוקחים ג'ובים באופן אקראי מהתור, לכן אין שימור של אותם ג'ובים על מעבדים קודמים
שהריצו אותם.

Queue -> A -> B -> C -> D -> E -> NULL

דוגמא לאלגוריתם: נניח ויש לנו תור עם 5 ג'ובים ו-4 מעבדים.
נניח שהקוואנטה (כמה זמן כל ג'וב רץ) זהה וכל הג'ובים רצים הרבה זמן.

פה רואים את הבעייתיות בתזמון:
כל מעבד לוקח ג'וב מהתור ולכן בהתחלה זה לפי הסדר. כל שאר הג'ובים חוזרים לסוף התור.
ואז יצא שהזמן שהוא נראה מבחינת cache affinity- כל קוואנטה אנחנו מעבירים ג'וב אחד לאחר לגמרי על
כל מעבד.

CPU1: A E D C B
CPU2: B A E D C
CPU3: C B A E D
CPU4: D C B A E

אידיאלית, היינו רוצים תזמון כזה ששומר על cache affinity (כלומר שתהליך ירוץ על
המעבד הראשון שהריץ אותו).
נשים לב שג'ובים A עד D תזמונן תמיד על המעבד הראשון שהריץ אותם, ורק E נע בין כולם.
כל אחד מהג'ובים קיבל 4 קוואנטות (כל 4 פעמים) בכל אחד מהתזמונים, אבל בתזמון הזה, יש cache affinity הרבה
יותר טוב.
כלומר, SQMS לא עושה דבר כזה, ה-cache affinity אצלו גרוע.

* With cache affinity:
CPU1: A E A A A
CPU2: B B E B B
CPU3: C C C E C
CPU4: D D D D E

2. Multi-queue multiprocessor scheduling :
ניתן תור לכל מעבד. ברגע שיגיע ג'וב, נבחר את אחד התורים לשים בו את הג'וב ואותו מעבד יריץ אותו.
בדרך הזו טיפלנו אוטומטית בכל הבעיות שהיו לנו מקודם:
-לא נדרשות כאן נעילות כיוון שכל מעבד יש תור משלו ואין תור משותף שנדרש מנעול (מדי פעם כשמוסיפים באופן מקבילי
ייתכן שיידרש מנעול).
- יש cache affinity באופן טבעי: ברגע שג'וב מסוים מגיע, הוא מקבל תור, משויך למעבד ותמיד הוא יורץ על אותו
המעבד.

Q0 -> A -> C
Q1 -> B -> D

דוגמא:
במעבד הראשון מתוזמנים ג'ובים A,C ובמעבד השני B,D
כך ה-cache affinity מצוין.

CPU0: A C C A A C C A A C C A A C C
CPU1: B B D D B B D D B B D D B B D D

הבעיה בתזמון כזה:
אין הוגנות זה לא ניצול יעיל של המעבד.
ג'וב A רץ כפול מג'ובים B,D והוא לא בהכרח בעדיפות גבוהה יותר,
הוא פשוט תזומן למעבד מסוים וכך קרה.
זה יכול לקרות גם במציאות.

* Load imbalance:
Q0 -> A
Q1 -> B -> D

CPU0: A A A A A A A A A A A A A A A
CPU1: B B D D B B D D B B D D B B D D

כמו כן, ייתכן גם מצב בו כל התהליכים במעבד מסוים הסתיימו ואז לא מדובר כבר על חוסר הוגנות אלא על בעיית ביצועים,
יש תהליכים שמחכים לתזמון ויש מעבד פנוי שלא מריץ אותם. זה גורם לבזבוז של מעבד.

פתרון לכך: Migration
ניקח ג'וב ממעבד אחד למעבד אחר. זה דורש אימון סנכרון אבל לא נעשה זאת יותר מדי אלא מעט.
במצב בו יש מעבד פנוי, ניקח ג'וב ונרכיר אותו לתור הפנוי.
כל זמן מסוים נבדוק את המצב ואם צריך נניד ג'ובים מתור לתור.
נהיה מוכנים לשלם את המחיר שלא יהיה cache affinity תמורת הניצול של עוד מעבד. לרוב אנחנו נרוויח מכך באופן
משמעותי.

במצב בו יש מעבד שסיים ג'וב יחיד ומעבד נוסף שמריץ שני ג'ובים: נבצע Continuous migration כלומר נעביר כל
הזמן איכשהו ג'וב בין התורים (נחלק כל הזמן בין הג'ובים שעוברים בין התורים).
אם נעשה זאת בצורה חכמה ושם לב שכולם יקבלו את אותן זמן מעבד.

Q0 -> A
Q1 -> B -> D

CPU0: A A A A B A B A B B B B
CPU1: B D B D D D D D A D A D

-work stealing כיצד מחליטים מתי לעשות migration, את מי להעביר בין התורים וכו'.
כאשר מעבד מסוים רואה שאין לו הרבה ג'ובים בתור, או שהוא מעדיף בתור של מעבד אחר, בודק אם יש שם הרבה ג'ובים
ואם כן הוא לוקח לו כמה ג'ובים משם. לא נדרש כאן אילון מושלם.
כל פרק זמן מסוים עושים זאת.
החלק העדין- כוונון הפרמטר של כל כמה זמן מסתכלים? אם מעבדים יסתכלו יותר מדי על תורים של מעבדים אחרים, נצטרך
לעשות הרבה סנכרון וזה ייקח הרבה זמן. אם לא נסתכל מספיק, יהיה לנו חוסר איזון.
צריכים למצוא את הסד העדין.

המתזמנים שיש לנו בלינוקס:
1. (O(1 – מתזמן לפי עדיפויות (דומה ל-MLFQ).
הוא מנסה להיות הוגן תוך כדי התזמון. יש לו מערך עדיפויות וברגע שג'וב מסוים סיים לרוץ, מוציאים אותן ממערך הג'ובים
ומעבירים אותן למערך אחר. רק אחרי שהוצאנו את כל הג'ובים, מחליפים מערך ומתחילים להריץ ממנו ג'ובים.
המערך שפועל כרגע נקרא מערך ה-active, והמערך שאותן מעבירים אליו נקרא מערך ה-expired.
בשיטה הזו, המתזמן גם משיג לנו תזמון לפי עדיפויות וגם הוגנות (כל תהליך יקבל את זמן המעבד שלו).
הוא מתזמן תמיד ביעילות של (1)o. זה היתרון העיקרי שלו (מאוד קל לבחור את הג'וב הבא לתזמון, פשוט בוחרים מה
המתזמן).

2. Completely Fair Scheduler (CFS) - המתזמן הזה החליף את (1)o.
לא עובד עם מערכים אלא עם עצים.
הוא מתזמן קצת יותר איטי מבחינת זמן ההחלטה שלו (ברגע שצריכים לבחור תהליך לתזמון)- היעילות היא (O(log N
במקום (1)o כי הוא בוחר מעץ אדום-שחור (לפי עדיפויות, מהר מאוד אפשר לקחת את הערך הקטן/גדול ביותר
מהעץ).
כל ג'וב מיוצג ע"י זמנה בעץ והמספר שמייצג אותן זה כמה זמן הג'וב הזה רץ עד עכשיו.
אז כל פעם אנחנו לוקחים את הג'וב שרץ הכי מעט זמן ונותנים לו לרוץ.
החיסרון העיקרי של המתזמן הזה: כשיש ג'וב חדש – הוא מגיע עם זמן 0.
ברגע שג'וב סיים לרוץ באופן סופי, מוציאים אותו מהעץ.
אחרת, לאחר הרצה שלו, מכניסים אותו מחדש לעץ עם הערך החדש של זמן הריצה שלו.
המתזמן הזה הוגן מאוד יעיל ומהיר ולכן משתמשים בו.

3. BF Scheduler-
עובד עם תור אחד. תומך ב-cache affinity, מהיר יחסית.
אין work stealing.

