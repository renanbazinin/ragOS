מערכות הפעלה – שיעור 22

השיעור נדבר על קריאה – איך נמצא את הנתונים שכתבנו?
כשאנחנו כותבים בלוק כלשהו של מידע, אנחנו כותבים את הדאטה שהשתנה, את ה-inode שהשתנה וכל החלקים שהשתנו.
אם אנחנו רוצים למצוא למשל את ה-inode העדכני: inode-ים מסוימים יכולים להיות כמה גרסאות על הדיסק ואין שום מיקום קבוע.
בכדי למצוא את ה-inode העדכני אנחנו עושים עוד כתיבה, של משהו שנקרא
**inode map (imap)** – לזה מבנה נתונים קטן שמתווסף בסוף סגמנט (בכל סגמנט שדה רלוונטי עבורו, שדה בערך כל
סגמנט). מבנה הנתונים הזה מכיל מצביעים ל-inodes לפי מספר, כלומר הוא מכיל את הכתובת בדיסק של הגרסה האחרונה
של כל inode. אנחנו זוכרים את הדברים האלה בזיכרון, ויחד עם כל סגמנט כותבים את הגרסה המעודכנת של כל inode.

[Diagram: Existing data, D1, Inode blk[0]: A0, Map[k]: A1 imap, A0, A1, A2]

למשל כאן ה-imap מצביע על הגרסה העדכנית של inode k (שבדוגמא זה בלוק
A1) והבלוק A1 מצביע חזרה לדיסק.

ה-imap יכול להיות בכל מיני גדלים (זה תלוי בכמות ה-inodes שיש לנו במערכת) אז אנחנו מפרקים אותו לחלקים וכותבים את
החלק הרלוונטי המעודכן. יכול להיות חלק של imap של inodes 1 – 100 או imap של inodes 101-200 וכו' (איזו חלוקה
שאנחנו מחליטים לעשות) וכל סגמנט שאנחנו מעדכנים – כותבים את החלק/החלקים הרלוונטיים שהתעדכנו ב-imap.
כלומר מדובר על imap אחד שמחולק לחלקים.

עכשיו אם נרצה למצוא inode מסוים, נצטרך להסתכל ב-imap העדכני (המיפוי העדכני) והוא יגיד לנו איפה הגרסה הכי
עדכנית של אותו inode ומשם נוכל להגיע לנתון הרצוי.

אז צמצמנו את הבעיה: אם אנחנו מחפשים למשל את inode מספר 9, נסתכל ב-imap.
בעיה חדשה אך קטנה יותר: איך אנחנו מוצאים את ה-imap? כי הוא גם כל הזמן מתעדכן ומשתנה.
בזמן ריצה יש לנו תמיד את ה-imap בזיכרון, אנחנו זוכרים אותו ואין בעיה.
נוסף חלק קטן למערכת הקבצים Lfs בהתחלה במחרוזת הכיוון נוסיף מצביע שנקרא
**CR (checkpoint region)** שיתפקידו להצביע לגרסה העדכנית ביותר של ה-imap. אם יש כמה חלקים ל-imap
אז יהיו בו מצביעים לגרסה העדכנית של כל חלק (אנחנו גם יודעים אילו inodes ממופים לאיזה חלק של ה-imap).

[Diagram: CR imap[k...]: A2, Existing data, D1, Inode blk[0]: A0, Map[k]: A1 imap, A0, A1, A2]

ה-cr לא זז, הוא כל הזמן במיקום קבוע, אנחנו לא צריכים לשנות אותו כל פעם וגם
לא כדאי לעדכן אותו כל פעם כי לאז נכתוב כל הזמן. זה במידה מסוימת היה יכול להרוס לנו את
הביצועים, לכן מעדכנים אותו לעיתים רחוקות (נניח כל 30 דקה).
אנחנו זוכרים אצלנו בזיכרון את ה-imap השלם ואת כל הנתונים, ומדי פעם גם כותבים אל ה-cr את הנתון המעודכן.
אם נסגור את המחשב ונדליק אותו מחדש, אין בעיה, נקרא את ה-cr, הוא יצביע לכל החלקים של ה-imap, נקרא גם אותם
וכך נוכל לשחזר את ה-imap ולעבוד כרגיל.

**קריאת קובץ:**
בכדי לקרוא קובץ באופן מלא, אנחנו צריכים ללכת ל-cr, לקרוא אותו ולמצוא איפה ה-imap העדכני ביותר נמצא, לאחר מכן ניגש
לגרסה העדכנית ביותר של ה-inode ונקרא אותה, וב-inode יהיה לנו מצביע לדאטה שלנו ונקרא אותו.
אנחנו מניחים שרוב הנתונים הללו ישבו לנו כבר בזיכרון (ה-imap וה-inode המעודכן למשל).

כל קובץ נמצא בתיקייה (אחת או יותר). ונוח ויצרון קובץ חדש עכשיו. בסופו של דבר, אנחנו צריכים לכתוב לסגמנט לדיסק) לא רק
את הנתונים של הקובץ ואת ה-inode המעודכן, עכשיו גם שינינו את התיקייה שהוא נמצא בה (יצרנו קובץ חדש, בתיקייה ששם
את הקובץ השתנו הנתונים, כי נוספה קובץ וצריך לעדכן אותה גם).
בגלל ששינינו את הדאטה של התיקייה, יש צורך לשנות את ה-inode של התיקייה, שגם יצביע על הדאטה החדש, ובסופו של דבר
לשנות גם את ה-imap כי השתנו שני inodes (ה-inode של התיקייה ו-inode של הקובץ החדש שיצרנו).

דבר נוסף נוח מאוד ב-imap שחוסך לנו עבודה: ברגע ששינינו את השינוי הזה, אנחנו לא צריכים להמשיך ולעלות בהיררכיית
הקבצים. הוספנו קובץ לתיקייה אל התיקייה השתנתה. ברגע שהתיקייה השתנתה, טכנית גם התיקייה שהיא נמצאת בתוכה
עברה שינוי כלשהו.
אם לא היינו משתמשים ב-inode map, היינו צריכים לעדכן את כל היררכיית הקבצים. ה-inode map חוסך לנו את זה כי
אם קובץ כלשהו משנה מיקום, אנחנו מעדכנים את ה-inode map והוא מצביע ל-inode העדכני של ה-inode ולא וכל
מערכת הקבצים תחזור להיות תקינה.

**גישה לקובץ שנמצא בתיקייה:**
נניח שאנחנו רוצים לגשת לקובץ foo ומספר ה-inode שלו הוא k ומצאו k בתיקייה dir כלומר הנתיב הוא dir/foo/
בהנחה שאנחנו מתחילים עם cache ריק כלומר זו הפעם הראשונה שאנחנו ניגשים למערכת הקבצים (ובהנחה שאנחנו יודעים
מהו מספר ה-inode של התיקייה dir)
1. נקרא את ה-cr, כדי למצוא את ה-imap העדכני ביותר (שמכיל את ה-inode הכי מעודכן של dir).
2. נקרא את ה-imap העדכני ביותר כדי למצוא את ה-inode העדכני ביותר שמצביע על dir (נניח מצאנו את ה-inode
הוא A3).
3. נלך ל-inode A3 ונחפש ונחשב את ה-data של התיקייה (נניח מצאנו והוא ה-inode A2 הוא).
4. נלך ל-inode A2 ונקרא את ה-data כדי למצוא מבין כל הרשומות בתיקייה איפה הקובץ foo שאנחנו מחפשים
(inode k)
5. נחזור ל-imap כדי לקרוא את המיקום של inode k (נניח שהוא במיקום A1 בדיסק).
6. נקרא את הכתובת A1 שהיא ה-inode של foo, בכדי למצוא את ה-data של הקובץ (נניח שהוא במיקום A0 בדיסק).
7. ניגש ל-data של foo (ניגש לקרוא את A0).

** אותנו התהליך נתפס, אבל בפועל אנחנו מניחים שה-CR, imap, inodes שמורים במטמון.
לכן פה שלבים 1,2,5 היו איטיים כי היינו קוראים ישירות מהאחסון ולא מהדיסק.
גם שלבים 3,6 יהיו אצלנו במטמון (רוב הסיכויים שכן, אבל ייתכן גם שלא).
מה שמעניין לקרוא בוודאות זה את הדאטה.

---

**Garbage Collection**
אם כתבנו data כלשהו ל-inode, כתבנו נתונים לקובץ, אז אנחנו כותבים למערכת הקבצים את ה-data שלנו, את ה-inode
המעודכן וה-imap המעודכן שמצביע ל-inode.
נניח ועכשיו ברצוננו לעדכן שוב את אותה ה-data, אז אנחנו שוב כותבים את ה-data המעודכן, את ה-inode המעודכן ואת ה-
imap המעודכן שמצביע ל-inode.
המשמעות היא שכרגע יש לנו שתי גרסאות של הקובץ, שתי גרסאות של ה-inode, שתי גרסאות של הדאטה, ומה שנשאר מאחורה
זה קבצים זבל, זה לא רלוונטי כי הגרסה החדשה החליפה את הגרסה הישנה.
באופן דומה עבור הוספת נתונים לקובץ. נניח ורק הוספנו נתון לסוף קובץ. אז עכשיו יהיה לנו בלוק חדש D2, ויהיה לנו inode
חדש שמצביע גם ל-D1 וגם ל-D2, וגם imap-1 חדש שיגיד לנו איפה ה-inode המעודכן.
אז גם עכשיו השארנו זבל מאחורה, אותה קצת פחות אבל עדיין זבל.
כל הזמן בעת שכתיבת נתונים, עדכון, אנחנו משאירים מאחורינו זבל.

פתרון ראשון - **versioning file system:** מערכת קבצים ששומרת גרסאות.
אנחנו יכולים לקחת קובץ ולשחזר אותו כמה גרסאות אחורה, זה בעיקר בשרותי ענן.
כלומר נשאיר את כל ה"זבל" מאחור ונשמור אותו למקרה ונרצה לשחזר.

פתרון שני – **garbage collection:** ב-Lfs כל זמן תהליך רקע של זמן מפנה סגמנטים מיותרים (בלוקים מיותרים).
התהליך הזה דואג שישארו לנו רק הגרסאות הכי עדכניות של כל קובץ, של כל inode וכו' והוא זורק את הגרסאות הישנות.

נניח ויש לנו סגמנט שמורכב מכל מיני בלוקים של מידע (כל מיני בלוקים של דאטה, בלוק של inode ובלוק של imap),
כשאנחנו עכשיו באים להפעיל **garbage collection**, אנחנו לא רוצים לפנות בלוקים בודדים.
זה לא טוב לנו. הרעיון הבסיסי של Lfs הוא שאנחנו רוצים לכתוב סגמנט שלם. בעתיד אנחנו רוצים לבוא ולכתוב את כל גודל
הסגמנט, אבל חלק מהסגמנט נקבל וחלק לא, אנחנו לא רוצים לפנות בלוקים בודדים, זה לא יעזור לנו נרצה לפנות את כל הסגמנט.
אבל לא בטוח שיש סגמנט שכולו ירוקון, ייתכן ויהיה בו בלוק שישאר תקף ולא זבל שכתבנו אותו.

אז ה-**Lfs Cleaner** עובר על הדיסק וקורא סגמנטים ישנים ובוחן את הבלוקים בהם שעדיין תקפים.
הוא זוכר את כל הבלוקים שהוא מצא תקפים בהם שהם רלוונטיים ומחפש עוד בלוקים רלוונטיים בסגמנטים הבאים.
כאשר מספר הבלוקים התקפים שהוא מצא מספיקים כדי למלא סגמנט, הוא עוזר. ברגע שהוא מצא מספיק בלוקים, הוא כותב
סגמנט חדש בהמשך הדיסק, שיש בו רק את הבלוקים האלה שהוא מצא. עכשיו הוא יכול למחוק את הסגמנטים שמהם הוא אסף
את הבלוקים התקפים.
התהליך הזה כל הזמן רץ באמצע ועושה את הפעולה הזו של ניסיון לצמצם סגמנטים.

עולה השאלה: איך ה-cleaner יודע איזה בלוקים רלוונטיים ואיזה לא?
הרי כשאנחנו קוראים נתונים- הולכים מה-cr ל-inode ולדאטה.
אבל אין לנו את הכיוון ההפוך, אם אנחנו מסתכלים על בלוק מסוים, אנחנו לא יודעים אם הוא רלוונטי או לא.

לשם כך, לכל סגמנט אנחנו מוסיפים משהו שנקרא **segment summery** – זהו Go של נתונים בתחילת כל סגמנט, אשר מתאר
מה יש בסגמנט. למשל: בבלוק הראשון בסגמנט יש דאטה של inode מסוים, בבלוק הבא יש את ה-inode וכו' למשל
(inode 9, בלוק דאטה 5) וכו' הלאה. כלומר ב-segment summery block יהיה תיאור של כל מה שהולך להופיע בסגמנט הזה.

עכשיו אנחנו יכולים להבין מה יש בסגמנט ומה רלוונטי: אם בסגמנט כלשהו אנחנו יודעים שיש דאטה של inode x, נלך ל-imap
ונסתכל על הגרסה הכי עדכנית של inode x ונבדוק אם המיקום שנשמר ב-imap לזה למיקום שבסגמנט שאנחנו עכשיו
מסתכלים עליו, אם כן, אז הדאטה הזה תקף ועכשיון, אם לא, אז שינו אותו והדאטה שיש בסגמנט הזה כבר לא רלוונטי.
כנ"ל לגבי inode, וגם לגבי ה-imap, נסתכל האם ה-imap עדיין נמצא במיקום שמצוין לנו ב-cr.
ככה נוכל לעבור על כל הבלוקים בסגמנט ולבדוק מי מהם רלוונטי ומי מהם לא.

דרך קצת יותר קלה ויעילה לעשות את הבחינה קוד: **ספירת מספר גרסה** – אם בכל inode נשמור את מספר הגרסה הכי
עדכני שלו ובדאטה גם, ואז אם נסתכל על ה-inode ונראה שכתובה גרסה שהיא שונה מהגרסה העדכנית ביותר שכתובה
ב-imap, נדע שהוא לא רלוונטי.

ה-cleaner רץ כל הזמן ברקע, אבל את הפעולות שלו הוא מבצע בכל פעם שאנחנו לא משתמשים בדיסק, כשאנחנו לא מבצעים
פעולות או כשהדיסק מנומנם. כאשר הדיסק מנומנם, ה-cleaner חייב לרוץ למרות שהוא יפגע לנו בביצועים.

שיקול נוסף שה-cleaner לוקח הוא סיווג בלוקים לפי "חם" ו"קר".
בסגמנט יש המון בלוקים. יכול להיות סגמנט שהוא לא משתנה, חלק מהבלוקים בו רלוונטיים וחלקם לא, זה לא משנה, אבל הסגמנט
לא משתנה. המצב של הסגמנט הזה יחסית סטטי. לסגמנט כזה נקרא **"סגמנט קר" – לא משכתבים את הנתונים שקיימים בו.**
בסגמנט כזה לא נהיה לנו בעיה לגעת, כי זה אומר שהנתונים בו הם דיי יציבים ולא משתנים, לכן האידיאל שלנו הוא לקחת כמה
סגמנטים קרים, לאחד אותם לסגמנט אחד גדול ויהיו בסגמנט הזה הרבה נתונים שלא משתנים ולא נצטרך להתייחס אליהם.

לעומת זאת, יכול להיות סגמנט שתוך כדי ריצה אנחנו מזהים שהבלוקים בו כל הזמן משתנים, בתדירות גבוהה.
לסגמנט כזה נקרא **"סגמנט חם" – סגמנט בו משכתבים את הנתונים לעיתים קרובות.**
בסגמנט כזה עדיף לא לגעת (אם יש לנו ברירה, נחכה כמה שאפשר). ככל שנחכה, יהיו בו פחות בלוקים שנצטרך לכתוב
מחדש. כלומר, אם נחכה עוד קצת, ייתכן ועוד בלוקים יהפכו ללא רלוונטיים, וכך נחסוך כתיבות.

---

**SSD (Solid State Drive)**
כונני SSD הם כונני אחסון ששונים מהאהורד דיסקים שדיברנו עליהם עד כה, והם מאוד מהירים (באופן יחסי).
הרעיון בכונני ssd הוא שאין בהם חלקים נעים, וזה אומר שהביצועים שלנו בפעולות הקריאה והפעולות הסדרתיות הם כמעט
זהים (יש הבדל אבל הוא הרבה פחות משמעותי ואנחנו נראה את זה).

כונן ssd עובד עם חלקי זיכרון שנקראים **Flash (NAND-based flash)**. זכרונות flash עובדים בצורה מסוימת ודי
בעייתית. המטרה היא להבין איך כונן ssd מתמודד עם הבעיות של זיכרון flash, שיש לו לא מעט בעיות אך מצד שני הוא מהיר.

**מבנה לזיכרון flash:** זיכרון flash בנוי מהרבה **banks (בנקים)** שהם מקטעי זיכרון מאוד גדול, כאשר בכל בנק יש
מספר כלשהו של בלוקים. המושג בלוק פה שונה מהמושג בלוק שדיברנו עליו עד עכשיו.
כל בלוק מחולק לדפים.
בתמונה ניתן לראות שיש בנק אחד עם 3 בלוקים, כאשר בכל בלוק יש 4 דפים.
כל בלוק הוא בגודל בין **128kb – 4mb**.
כל קובייה בתמונה היא דף, וגודל כל דף הוא בין **2kb – 4kb**.

[Diagram: Block 0 (Page 0, 1, 2, 3), Block 1 (Page 4, 5, 6, 7), Block 2 (Page 8, 9, 10, 11)]

הבעיה של זיכרון flash- אם ניקח בלוק אחד שיש בו 4 דפים, אנחנו לא יכולים לקרוא ולכתוב באופן חופשי לזיכרון flash.
**- אנחנו יכולים לקרוא דף.** איזה דף שאנחנו רוצים. זה לוקח כמה עשרות של מיקרו שניות (מאוד מהיר יחסית לדיסק), ולא משנה
איפה. פה אין seek time, positioning וכו'.
**- אנחנו יכולים למחוק בלוק שלם.** מה שמחיקה עושה – היא משנה את כל הביטים בכל הדפים של הבלוק ל-1.
מחיקה כזו לוקחת כמה מילישניות (זו פעולה מאוד איטית יחסית לשאר הפעולות שאנחנו עושים על ssd).
**- אנחנו יכולים לכתוב דף** אך עם הנתון שאנחנו רוצים, אבל אנחנו יכולים לכתוב רק לדף שהוא מחוק. אנחנו לא יכולים לכתוב לדף
אם הוא לא מחוק. לכל דף על פני כל הזיכרון שלנו יש **state**, מצב.

מצב של דף יכול להיות:
**I = invalid** (מה שיש בדף הוא לא רלוונטי, לא משתמשים בו עד שנמחוק אותו),
**E = erased** (הדף מחוק. כאשר אנחנו מוחקים בלוק שלם, כל הדפים בו משתנים ל-E),
**V = valid**.

פעולת קריאה אנחנו יכולים לעשות רק על דפים שהם **valid**.
פעולת כתיבה ניתן לעשות רק לדפים שהם במצב **erased**.
פעולת הכתיבה לדף נקראת **program page** והיא לוקחת כמה מאות של מיקרו שניות.

**דוגמא:**
נניח שיש לנו בלוק שכל הדפים בו הם **invalid**, כרגע אנחנו לא יכולים לעשות כלום חוץ מלמחוק את הבלוק.
ברגע שעשינו פעולת מחיקה, כל הבלוק נמחק. כל הדפים הופכים להיות **erased** בבלוק.
עכשיו אנחנו יכולים לעשות **program** לדף 0. כתבנו לדף מספר 0 וה-
state שלו השתנה ל-**valid**, כל השאר נשארו מחוקים.
אנחנו עדיין יכולים לכתוב אליהם כל עוד הם מחוקים.
אם ננסה שוב לכתוב לדף 0, נקבל שגיאה, כי אי אפשר לכתוב לדף אלא אם
הוא במצב erased. אבל למשל לדף 1 כן ניתן לעשות program.
אם לאחר מכן נרצה לכתוב שוב אל דף 0 או 1, נצטרך שוב למחוק את
כל הבלוק ואז לכתוב. כי אי אפשר למחוק דף יחיד, אלא את כל הבלוק בלבד.

[Table:
iiii | Initial: block pages invalid
EEEE | Erase() | Pages in block are erased
VEEE | Program(0) | Page program 0: state valid
error | Program(0) | Cannot re-program page
VVEE | Program(1) | Program page 1
EEEE | Erase() | Block contents erased]

---

**דוגמא נוספת:**
[Diagram: Example 2: Initially
Page 0: 00011000, Page 1: 11001110, Page 2: 00000001, Page 3: 00111111 (all VALID)
Write to page 0: Erase block
Page 0: 11111111, Page 1: 11111111, Page 2: 11111111, Page 3: 11111111 (all ERASED)
Write to page 0: Program page 0
Page 0: 00000011, Page 1: 11111111, Page 2: 11111111, Page 3: 11111111
VALID ERASED ERASED ERASED
Contents of pages 1-3 are gone]

יש לנו פה בלוק שכבר כתבנו אליו נתונים. נניח שכל דף הוא בגודל בית (8 ביטים).
אם אנחנו רוצים לכתוב נתונים חדשים במקום דף מספר 0, אנחנו חייבים קודם כל למחוק את
כל הבלוק ורק אז נוכל לעשות **program** ולכתוב את הנתונים החדשים אל דף מספר 0.

**ההרכב הפנימי של כונן ssd:**
בזכרונות flash, הזיכרון מורכב מתאים. התאים הללו מורכבים מחלקים שנקראים **SLC, MLC, TLC, QLC.**
כלומר כל דף מורכב מתאים כאלה. העדכון בביצועים:
**slc** הוא הקטן ביותר בנפח שלו, אך הוא יותר מהיר.
כשאנחנו קונים כונן ssd הוא בדרך כלל מורכב מ-**MLC,TLC,QLC**
כלומר מהפחות טובים (slc הוא הכי מהיר וגם יקר).

[Table:
Device | Read (μs) | Write (μs) | Erase (μs)
SLC | 25 | 200-300 | 1500-2000
MLC | 50 | 600-900 | ~3000
TLC | ~75 | ~900-1350 | ~4500
* SLC: single level cell, MLC: multiple level cell, TLC: triple level cell
* SLC achieves higher performance (but more expensive)]

יש שתי בעיות לתאים הללו:
1. **התאים האלה נשחקים** – ככל שאנחנו כותבים אליהם, הם נשחקים, ועם הזמן הם נהרסים. אנחנו לא יודעים מתי הם
יכולים להרס. אנחנו רק יכולים לצפות שהם נהרסו. זה אומר שכמות הכתיבות שאנחנו יכולים לעשות לזיכרון היא לא אינסופית
כמו שאנחנו יכולים לעשות בהארד דיסק, אנחנו לא יכולים לכתוב כמה שאנחנו רוצים.
-לכל תא יש מספר **cycles** סופי, כאשר cycle הוא מחיקה וכתיבה. ברגע ששיחקנו כמות פעמים מסוימת, הדף
הזיכרון. ב-SLC מדובר על בערך **100,000 cycles**, ב-MLC בערך **10,000 cycles**. היום המספרים האלה קצת
יותר טובים בזכרונות flash חדישים, אבל עדיין, לא מדהים.
אם הדיסק שלנו מוגבל למספר כה של כתיבות (100,000 או מיליון כתיבות), זה לא דבר שהוא תקין.
** לא מדובר על 100,000 כתיבות לדיסק אלא 100,000 לכל בית בדיסק.
אם יש לנו קובץ שאנחנו כותבים אליו שוב ושוב, בשלב מסוים הוא פשוט יהרס, הנתון שלו יהרס.
** לאורך זמן, הזיכרון של כונן ssd הולך וקטן (אחרי כמה שנים). כי דברים מתחילים להתקלקל והוא מזהה את זה ולא
פשוט מפעיל את התאים האלה ולא משתמש בהם.

2. **קריאה או כתיבה מדיי כלשהו הרבה פעמים (באותו מקום הרבה פעמים), יש הפרעות מגנטיות.**
הפעולות שאנחנו עושים על דף מסוים, עלולות לגרום לשיבוש ביטים בדפים סמוכים.
זה לא רק בדף, זה פה גם. כשאנחנו קוראים או כותבים יותר מדי פעמים, זה גורם להפרעה ושינוי של ביטים בתאים
סמוכים. זה נקרא **Read disturbs or program disturbs.**
זאת אומרת שלא רק שאנחנו לא יכולים לכתוב לאותו תא כי הוא יישחק, אנחנו גם לא יכולים לכתוב הרבה לאותו תא כי זה
ישנה לנו את הנתונים בתאים הקרובים, ואנחנו לא יכולים לקרוא הרבה מאותו תא כי זה ישנה לנו את הנתונים.
כלומר, אם החזקנו איזשהו ענף של קובץ שאנחנו קוראים כל הזמן, אנחנו הולכים להשפיע ולשנות את הנתונים של הדיסק.

**פתרון לכך יד: יצרו כונן ssd, שנקרא flash – based ssd.**
בכונן ssd יש המון זכרונות flash והוא משתמש בהם במקביל (כדי לשפר את הביצועים).
על גבי סט זכרונות ה-flash, יש לו זיכרון משל עצמו (כמו רוב ההתקנים במחשב שלנו), יש לו **RAM** משלו (זיכרון מהיר)
ויש לו בקר (כמו מעבד פשוט של הכונן עצמו) ושכבת ממשק (מה שאנחנו מדברים איתה).
המשתמש, הדרייבר ומערכת ההפעלה מדברים עם הממשק הזה. ואז הבקר של ה-flash מתרגם את הפעולות שעשינו
מקריאה וכתיבה לפקודות פיזיות בזיכרון.

---

זה דומה קצת להארד דיסק, ששם אנחנו רוצים לכתוב לסקטור 40 ואז הוא מבין באיזו צלחת הסקטור הזה, לאן להזיז את
הראש קורא כותב וכו'.
השכבה של הממשק נקראת גם ה-**Flash translation layer (FTL)**, הרעיון שלה הוא לקחת את הפקודות שלנו לתרגם
אותן לפקודות על הזיכרון הפיזי (האמיתי), בצורה כזו שנוכל לנהל כמה שיותר זכרונות במקביל ולוריד את כמות פעולות
הכתיבה שאנחנו עושים.

**write amplification**- כמה פעמים אנחנו עושים פעולות כתיבה יותר ממה שצריך (נניח המשתמש עשה פעולת כתיבה לדף
ואנחנו תרגמנו את זה לכתיבה ל-4 דפים). אנחנו רוצים לצמצם את המספר הזה ככל שאפשר וגם לפזר את הכתיבות ואת
הפעולות באופן שווה, כדי למנוע שחיקה, שלא יהיו הפרעות בין הזכרונות וכו'.

עבורנו כמשתמשים, גם ברמת ה-kernel, הכונן נראה כרצף גדול של דפים. זה דומה מאוד להארד דיסק שעבורנו נראה
כמערך גדול של סקטורים, אנחנו לא מודעים למבנה הפנימי של ה-טרקים והצלחות וכו'. אנחנו פשוט אומרים שאנחנו רוצים לפנות
לסקטור 40 וההארד דיסק כבר יודע איפה הוא נמצא.
כונן ה-flash נראה עבורנו בצורה דומה, לנו הוא נראה כמערך מאוד גדול של דפים ואנחנו מבקשים לקרוא/לכתוב לדף מסוים.
אין לנו **program, read, erase**, החומרה עושה את זה. אנחנו רק מציינים את פעולת הכתיבה או קריאה לדף
מסוים.

עכשיו צריך לדאוג למיפוי. אם אנו ביקשנו לקרוא מדף 2, מה עושים בפועל בזיכרון?
מבחינת הכונן שלנו, קודם כל לוקחים את כל הזכרונות ויוצרים מהם כאילו זיכרון אחד גדול (דומה קצת ל-raid, נשרשר לוגית את
כולם ונקבל התקן מאוד גדול).

**שיטה ראשונה אפשרית למיפוי – מיפוי ישיר (היא אינה טובה):** לעשות מיפוי ישיר. נניח מספר דף פיזי, ואם המשתמש רוצה
לקרוא מ-2 אז נקרא מ-2. הבעיה בגישה הזו והסיבה שהיא לא קיימת ולא הגיונית: אם אנחנו קוראים הרבה מאותו מקום, אז לא
טפלנו בשום בעיה. קריאה מרובה מאותו מקום תגרום להפרעות.
כמו כן, אם נרצה לכתוב לדף מספר 2, זה יתרגם לכתיבה לדף מספר 2, אבל בשביל לכתוב לדף מספר 2 צריך לקרוא את כל
הבלוק שיש בו את 2, לשמור אותו בצד, למחוק אותו ואז לכתוב את כל הבלוק מחדש עם הנתונים העדכניים שלנו.
הרי אי אפשר לכתוב לדף מספר 2 כמות שהוא, הוא צריך קודם כל להיות מחוק ולשם כך צריך למחוק את כל הדפים בבלוק ובשלב
לא לאבד נתונים צריך לשמור אותם בצד.
אז עשינו המון פעולות בשביל כתיבה, וזה מה שנקרא **write amplification**, המשתמש ביצע כתיבה לדף אחד ואנחנו
הפכנו את זה ל-3 קריאות, מחיקה ו-4 כתיבות.
- אל השיטה הזו לא סבירה. היא לא תביא לנו תוצאות טובות בכלל מבחינת הטיפול בדיסק.

**ראינו שימוש ב-LFS- ו Lfs הוא רעיון שעובד מעולה עבור ssd.** לא כמערכת קבצים, אנחנו מדברים כרגע על הכונן
עצמו. הרעיון הזה של לפזר את הכתיבות לאורך הדיסק וכל פעם להוסיף עוד ועוד נתונים, זה רעיון שעובד מעולה עבור ssd.
איך הרעיון הזה יעבוד? נניח שאנחנו מיישמים בדיסק שלנו בתוך ה-**log**, בתוך **journal**.
נניח והמשתמש רוצה לכתוב לדף מספר 100 את הנתון **a1**. אז אנחנו לא מייחסים את הנתון ל-100 הזה עדיין, אנחנו פשוט כותבים למקום
הראשון הפנוי (נניח שזה בדף מספר 0, ולדאטן הבלוק, נמחק את כולו ואז נכתוב למקום המתאים את **a1**).
בצד, נזכור שכתובת 100 הלוגית (מה שהמשתמש חושב שזה 100), אנחנו שמרנו אותה לדף פיזי בדף מספר 0.
ונמשיך. עכשיו המשתמש רוצה לדף מספר 101 את הנתון **a2** אז אנחנו נכתוב אותו לדף מספר 1. וכן הלאה.

[Diagrams:
* Initial state: Block 0, 1, 2, 3 pages 0-15 (all i)
* Write(100): a1 written to physical block 0, first erase block
* Program: Block 0, Page 0: a1, 1: i, 2: i, 3: i
* After all writes:
  100->0
  101->1
  2000->2
  2001->3
  Block 0: 0(a1), 1(a2), 2(b1), 3(b2)
* Record location: 100 -> 0

Example:
* Write(100) with a1
* Write(101) with a2
* Write(2000) with b1
* Write(2001) with b2]

---

אם המשתמש עכשיו רוצה לדרוס, הוא כותב ל-100 את **c1**. נמחוק את בלוק מספר 1, ונכתוב את **c1** בדף 4 (הדף הראשון בבלוק 1).
כבר לא נצביע לדף מספר 0 אלא לדף מספר 4. המיפוי של 100 הוא כרגע ל-**c1**. את דף 0, ה-FTL יודע שהוא כבר לא בשימוש, נסתכל
בהיפויים שלנו, נבין שזה זבל ונקרא.
כל המיפויים הללו ביניינים שמורים בחומרה, בכונן עצמו, בזיכרון שלו. זה זיכרון נדיף. ברגע שנכבה את המחשב לא יהיה חשמל
והוא יימחק אולי הכל יאבד לנו. כל עוד זה שמור לו בזיכרון, אל בלהן רצוי וזה הוא יכול למצוא כל בלוק, לא משנה לאן כתבנו.
אין אופציה להוסיף נתון לדיסק, זה רק לשנות ולכתוב את הדף כולו.
עכשיו את המיפויים הללו צריכים לשמור גם לא בזיכרון. אם אנחנו מכבים את המחשב והמיפויים מחדש, אנחנו צריכים דרך לדעת
מהם המיפויים העדכניים שלנו.
בכל דף שאנחנו שומרים קצת מקום עבור מיפויים. בעצם בכל דף שנשמר בו נתון, למשל בדף מספר 1 נכתוב שהוא שומר את
כתובת 100 לוגית ודף 2 את כתובת 101 לוגית וכן הלאה, ובדף 4 שבו נכתב הנתון המעודכן c1 נרשום שהוא המיפוי של 100.
זה עוזר ברמה הלוגית. ברגע שנטען את המחשב נוכל לחזור ולקרוא את כל הדיסק ולשחזר את המיפויים. זה לא ככה יפה. אם
יש לנו דיסק גדול, להתחיל לשחזר את כל המיפויים שלו יכול לקחת המון זמן. זו הסיבה שבהרבה אתרים איתיים (כוננים איטיים)
שמשתמשים בעיקרון דומה למה שדיברנו ב-LFS. נכתוב גם פה איזה שיטת שנקרא **checkpoint region** ומדי פעם ניקח דף
ונשמור בו את כל המיפויים שלנו (100 מוביל ל-4, 101 מוביל ל-5...), ואותו דבר כמו ה-imap, כל כמה זמן נכתוב איפוי מעודכן,
נצדכן את המיפויים.
עכשיו אם נדליק את המחשב מחדש, אנחנו רק צריכים למצוא איפה המיפוי הכי עדכני ואולי לקרוא קצת הלאה.

**שיטה הזו יש הרבה יתרונות טובים שלומדים להן ב-ssd:**
1. אנחנו לא כותבים פעמיים לאותו מקום עד שכתבנו את כל הדיסק (זה זיקוי, כמו **Lfs** ו-**journal**), כשנגיע לסוף נחזור
מההתחלה. זאת אומרת שפיזרנו את הכתיבות מעולה על פני הדיסק. אנחנו לא נכתוב הרבה לאותו איזור בזיכרון ולא נשחק תאים
מסוימים.
2. המחיקה הן רדית- אם מחקנו בלוק כלשהו, זה אומר שהתחלנו לכתוב אליו. פעם הבאה שנמחק את הבלוק הזה, זה רק
אחרי שנעשה סיבוב שלם. אז גם לא נמחוק זה ודי.
3. האיזון של הכתיבות הוא אוטומטי- סך הכל התאים שלנו יישחקו פחות או יותר באותו זמן.

**שיטה הזו יש שני חסרונות:**
1. השיטה "מכפילה ללכד- בדוגמא שלנו **a1** ו-**a2** שנכתבו מחדש הם זבל (הגרסה הישנה היא זבל).
מצד שני, אם נעשה פעולת **garbage collection** כל הזמן כמו ב-Lfs, כלומר אם נלך כל הזמן ו-cleaner שינקה לנו ברקע את
הדפים המיותרים, אנחנו נוסיף עוד כתיבות. נשחק את הדיסק שלנו עוד יותר. ולכן אי אפשר להריץ מנקה כזה כל הזמן ברקע.
2. טבלת המיפויים עלולה להיות ענקית.

אל ה-**garbage collection** יעבוד בדומה ל-**Lfs**, פשוט בתדירות נמוכה יותר.
נניח שזה המצב שלנו כרגע: כתבנו את **a1** ו-**c1** ואנחנו רוצים לנקות את הבלבן. במקרה הזה יש לנו רק בלוק אחד לנקות (100
ו-101 נכתבו שוב). הדרך היחידה/הדרך הטובה ביותר היא למחוק את כל הבלוק ולכתוב בחזרה את הנתונים המעודכנים. אבל אנחנו רוצים
להימנע משחיקה וכתיבות רבות באותו מקום. אז מה שנעשה: ניקח את הנתונים בבלוק שעדיין רלוונטיים (במקרה הזה **b1, b2**)
ונכתוב אותם מחדש הלאה בהמשך (כמו Lfs) ואז נמחוק את כל הבלוק. פיינו בלוק חדש ואנחנו ממשיכים עם ה-log שלנו קדימה,
אנחנו לא רוצים לחזור אחורה ולא לכתוב ולעשות פעולות על אותם הבלוקים שכבר עברנו, רק להתקדם בשביל שהפעולות שלנו
יתקבלו על פני כל הדיסק.
את הבלוקים שעדיין רלוונטיים נכתוב מחדש, ועדכן את המיפויים (בשביל שיצביעו על הדפים הנכונים) ואת הבלוק שפינינו נמחק.
דוגמא בתמונה בדף הבא.

---

[Diagrams:
* Write 100 and 101 again: 100->4, 101->5, 2000->2, 2001->3.
  Block 0: a1, a2, b1, b2. Block 1: c1, c2, _, _.
* Pages 0 and 1: garbage
* Read live pages from block and write to log (same as LFS):
  100->4, 101->5, 2000->6, 2001->7.
  Block 1: c1, c2, b1, b2.
* Reclaim entire block: Block 0: E, E, E, E.]

התהליך הזה הוא יקר מבחינתנו. גם מבחינת זמן וגם מבחינת
שחיקה. לכן אנחנו נרוץ על ה-**Garbage collector**
מעט. הוא ירוץ בתדירות נמוכה יותר מאשר ב-Lfs, כדי
נציל אותו כל הזמן. הוא ינסה כמה שאפשר למצוא בלוקים
שהם כולם לא רלוונטיים.
אם גם **b1,b2** היו לא רלוונטיים, זה חוסך לנו המון. כי אנחנו
לא צריכים לקרוא שום דבר ולא צריכים לכתוב שום דבר. אם
מצאנו בלוק שכל הנתונים בו הם זבל בלבד, אפשר למחוק את כולו. פקודת מחיקה אחת וסיימנו.
אם מצאנו בלוק שיש בו אפילו דף אחד שהוא רלוונטי, אנחנו צריכים לקרוא את הדף, לכתוב מחדש למקום אחר ורק אז למחוק את
כל הבלוק.
האידיאל מבחינתנו הוא למצוא בלוק שכולו זווים או עם כמה שפחות נתונים רלוונטיים.

טבלת המיפויים שמנה פה דף (**per page**). אם ניקח דף בגודל 4kb והאורד דיסק בגודל 1T, ונחשב כמה מקום בדלתנו,
נגלה שבלבד 1G רק עבור המיפויים. שזה ממש יותר מדי. גם להחזיק ג'יגה של זיכרון בבקר ריצה זה לא ניראלי.
בשביל להתמודד עם זה, יש שיטה אחרת של מיפוי:
**מיפוי פר בלוק:** לא נמפה דף לדף, אלא נחלק את הדיסק הלוגי שלנו (חלוקה שהמשתמש רואה ולא המשתמש) גם לאותם חלקים כמו
שאנחנו מחלקים את הבלוקים לדפים (כל ארבעה דפים זה בלוק), אז כאן כל 4 דפים יקראו **chunk**.
כלומר, בלוק ו-chunk זה אותו דבר. זה הווירטואלי ו- בלוק זה הפיזי.
אז בציור דפים 0,1,2,3 הם **chunk 0**, דפים 4,5,6,7 הם **chunk 1** וכן הלאה.

[Diagram: 500->4. Block 1: a, b, c, d. chunk 1 covers page 500.]

אנחנו עדיין עובדים כמו **log**, אבל נניח שהמשתמש עכשיו כותב לכתובת 2000.
הוא כותב נתון כלשהו. הוא הולך לכתוב לכתובת 2000 את **b1**. אנחנו נצא ל-log שלנו, נמצא בלוק פנוי (לא דף) ונכתוב אליו את
הנתון הזה. עכשיו אנחנו ממפים chunk 3 אל בלוק, לא לדף.
כתובת 2000 נמצאת בצ'אנק 500 (כי יש 4 דפים לכל בלוק), אז אנחנו נשמור ב-צד מיפוי לכל ה-צ'אנק.
צ'אנק 500 נמצא אל בלוק 0. המיפוי פה הוא צ'אנק לדף.
עכשיו נניח שהמשתמש כתב ל-2002 את הנתון **b3**. אנחנו רואים שכבר יש מיפוי, זה גם בצ'אנק 500, לכן נלך לדף המתאים
בבלוק 0 ונכתוב בו את הנתון של 2002 (שזה דף 2). כלומר הולכים לפי ההיסט של ה-דף ב-צ'אנק וכותבים אותו באותו היסט
בצ'אנק 0.
עכשיו חסכנו המון. בפועל יש בערך 1000 דפים בכל בלוק, ובמקום להחזיק מיפוי לכל דף אנחנו מחזיקים מיפוי לכל בלוק, וקיצצנו
בחלקי 1000 את הגודל של המיפויים. לכן במקום 1G מיפויים יהיה לנו 1M מיפויים. זה הרבה יותר טוב. אין לנו בעיה לשמור
1M של מיפויים בזיכרון.

נניח ועכשיו המשתמש הולך ורוצה לעדכן את 2002. נניח וכתבנו את כולם (2000-2003).
עכשיו אנחנו לא יכולים למחוק ל-2002 מבלי למחוק את כל הבלוק. אבל כדי לשמור על ה-log שלנו, כדי לא לשחוק את אותו האזור,
נקרא את כל הבלוק ונכתוב הכל מחדש בבלוק הבא שפנוי. ועדכן את המיפוי שעכשיו 500 לא מנוהל ב-0 אלא מנוהל ב-4.
אין לנו ברירה אם אנחנו רוצים לשמור על האזור.
אל חסרון פה למצב שכתובות הן לא עולות כל כתיבה לדף צריכה לכתוב מחדש את כל הבלוק. זה הרבה מאוד דפים שאנחנו
צריכים לכתוב מחדש עבור כל שינוי.
אל מה שעושים בשביל להתמודד עם זה: **פתרון היברידי.** נשתמש גם ככה וגם ככה.
אנחנו הולכים להחזיק את הזיכרון שלנו לעשות מיפוי פר צ'אנק. צ'אנק לבלוק. כמו שעשינו עד עכשיו.
אבל לפני שאנחנו עושים את זה, נהיה לנו כמו שכבה אלו שבה יהיה מיפוי פר דף.
השכבה הזו אצלו תיקרא ה-**log blocks**. אנחנו ניקח חלק מהבלוקים בדיסק (סוגדיר, היסט כלשהו של בלוקים בדיסק)

---

הבלוקים האלה שקיבלנו מהדיסק הם יהיו ה-**log blocks**. כלומר הבלוקים האלה אנחנו כותבים כרגיל כמו השיטה הישנה.
דף אחרי דף. מה שמגיע כותבים.
כל שאר הבלוקים שהם לא ה-**log blocks**, ייקראו ה-**data blocks**. הם עובדים כמו שאמרנו עד עכשיו: מיפוי מצ'אנק
לבלוק.
ה-**log blocks** כל הזמן יכולים להתרחב. אנחנו לא בוחרים בלוקים ספציפיים. המיקום שלהם על פני הדיסק יכול להשתנות.

עכשיו ניקח את המצב שהיה מקודם:
בלוק מספר 1 כפי שצוין אצלו בצ'אנק 3 אצל מספר 500.
אל יש לנו מיפוי מ-500 אל בלוק מספר 4.

[Diagram: 500->4. Block 1: a, b, c, d. Page 4: a, 5: b, 6: c, 7: d.]

עכשיו המשתמש רוצה לכתוב לכתובת 2002 את **c2** (נתון אחר, חדש).
במקום לקחת את כל הבלוק הזה ולכתוב אותו מחדש, אנחנו נכתוב אותו בלוג.
ה-log יהיה לנו. אז ניקח את כל הבלוק, עם **c2** במקום **c**, ונכתוב לתוך בלוק 3 ונכתוב שמיפוי 2002 נמצא דף 12, זהו מיפוי פר דף
והוא נקרא ה-**log table**.
עכשיו אם המשתמש ירצה לקרוא את 2002, קודם כל נסתכל על המיפוי החזש יותר של 12.
אם הוא ירצה לקרוא את 2001, נסתכל ב-**log table**, לא המיפוי הישן, נשים לב שהוא לא נמצא שם ואז ניגש למיפוי הכללי שהוא
כן קיים. נחזיר לו את המיפוי הזה.

ה-ssd מחזיק לנו את המיפויים. עכשיו יש לנו 2 רמות של מיפויים, גם מפוי פר דף וגם מיפוי פר צ'אנק.
**• Data table: maps blocks**
הוא קודם קודם במיפוי פר דף. כי שם יש את הנתונים היותר עדכניים. זה log, איטי יותר מאשר באחסון מלאים. ברגע שאנחנו רוצים
לקרוא משהו, קודם כל נבדוק באיזור הזמני שלנו, האם זה שם. אם זה לא אל אלוה. אחרת נלך לאיזור הרגיל שלנו ונבדוק האם
זה שם. ואז נוכל להחזיר את הנתונים משם.
- היתרון: עכשיו כדי לשנות דף אחד, אנחנו לא צריכים לשנות את כל הבלוק מחדש.

השלב השני של ה-log שלנו: כל פרק זמן מסוים אנחנו נלחץ ב-log דברים רצופים. מחפשים נתונים שסוגרים בלוקים שלמים
כ-צ'אנק. נניח יש לנו במיקום מסוים את כתובת 2002 ובהמשך המשתמש כתב את 2003 ואת 2000 (זה לא חייב להיות באותו
איזור). אז ניקח את שלושתם ונוחוב אותם לבלוק חדש.
ברגע שהצטברו לנו מספיק שינויים שהם לאותו צ'אנק, נעשה כמו השיטה השנייה, ויקח את כל הנתונים האלה מה-log ונכתוב
אותם לבלוק משלהם.
אז ה-log מנמלא עוד ועוד וכל זמן מה – נרוקן אותו.
בלוקים כל הזמן בין ה-log.
האלגוריתם הזה אסתטי על כך שהעדכון יבוא זמן מסוים לאחר הכתיבה, כי אם לא, אז לה לא עזר לנו כלום.
במקרה הכי גרוע, נהיה גרעין כמו השיטה הקודמת ששינתה צ'אנקים.

השלוב של שתי השיטות הללו יספק לנו **wear leveling**, אותנו כותבים באופן יחסי אחיד לכל הדיסק.
אין פה תא מסוים / דף / בלוק שאנחנו כותבים אליו המון והוא מקבל את רוב הכתיבות, אנחנו מפזרים הכל על פני הדיסק.
אפילו אם יש קובץ שכותבים אליו כל הזמן ואותן מקום, אם התוכנית שלנו כל הזמן כותבת לדף מספר 3, זה יתפזר על פני כל
הדיסק עם השיטות הללו ולא ישחק לנו את הדף הזה.

הבעיה שלנו מגיעה עם בלוקים לא משתנים. אם יש נתונים כשהם שאנחנו לא ניגשים בהם, כתבנו אותם פעם ואנחנו לא משנים
אותם, אז יש לנו בעיה. נניח ברמה קיצונית שיש לנו הארד דיסק של 1T. חצי מהנתונים שלנו לא משתנים. בחצי ג'יגה אנחנו לא
ניגשים. זה אומר שכל הרעיון של ה-log עובד רק על חצי מהדיסק. כלומר יש חצי ג'יגה שכל הזמן כותבים אליהם, ויש חצי
ג'יגה שאף אחד לא ניגש בהם. אז אלה שכותבים אליהם – נשחקים פי שתיים יותר מהר. יש לנו חצי דיסק שלא משתתף בעומס
הכתיבה.

---

מה ש-ssd עושה: מוסיף עוד קצת שחיקה (מוחק עוד קצת את התאים). ה-ssd כל הזמן ברקע לוקח ענפים שיושבים הרבה
זמן ומפזר אותם מחדש סתם (קורא בלוק וכותב אותו הלאה מחדש). כל זה רק בשביל לאזן את השחיקה.
שלא יקרה לנו מצב בו חצי דיסק מתקלקל וחצי דיסק לא נעוץ. מנסים לאזן. שיקלקל פחות או יותר באותו זמן.

פה נוכל לראות השוואות ביצועים של כמה כונני ssd עם הארד דיסק.
האורד דיסק שלנו דווקא האורד דיסק מאוד טוב (יחסית לתקופה שבה נעשתה ההשוואה).
ניתן לראות שבניגוד להארד דיסקים, שהפער בין פעולות אקראיות לסדרתיות הוא בערך פי 100 ואותנו גם ראינו הארד דיסקים
שבהם זה פי 300, אל בכונני ssd זה בערך פי 10 במקרה הגרוע, פי 4 בכוננים יותר טובים.
כלומר, צמצמנו משמעותית את הפער בין פעולות סדרתיות לאקראיות.
בפעולות אקראיות ב-ssd אנחנו מגיעים לביצועים של פעולות סדרתיות בהארד דיסק.
אל כונן ssd מספק לנו ביצועים מאוד טובים.
כמו כן נשים לב שכתיבות אקראיות יותר טובות מקריאות (זה בגלל ה-log, זה יהיה נכון גם ב-Lfs).
לביצוע כתיבה אקראית זה מאוד מהיר כי זה כמעט כמו לבצע כתיבה אקראית, אנחנו כותבים אותן בדפים במיקומים שונים אבל
זה מתורגם לכתיבה אחת סדרתית על פני הדיסק. לכן בסופו של דבר בפועל זה כמו סדרתי.
הביצועים האלה מאוד טובים וזו הסיבה שעוברים ל-ssd למרות המחיר (כונן ssd עולה בערך פי 30 מהארד דיסק רגיל).

[Table:
Device | Rand Reads (MB/S) | Rand Writes (MB/S) | Seq. Reads (MB/S) | Seq. Write (MB/S)
Samsung 840 Pro SSD | 103 | 287 | 421 | 384
Seagate 600 SSD | 84 | 252 | 424 | 374
Intel SSD 335 SSD | 39 | 222 | 344 | 354
Seagate Savvio 15K.3 HDD | 2 | 2 | 223 | 223]

