מערכות הפעלה - שיעור 10

עד כה דיברנו על וירטואליזציה - איך מערכת ההפעלה נותנת לנו את האשליה כאילו כל תהליך רץ בעולם משלו (יש לו זיכרון משלו, מעבד משלו). היום נדבר על נושא המקביליות – איך אנחנו מנצלים את המעבד שיש לנו במחשב כדי להפעיל כמה דברים בבת אחת (ולו רק אחד).

המעבדים שיש לנו היום במחשב, עובדים באיזשהי מהירות מסוימת והם מכילים בתוכם חלקיים טרנזיסטורים שעוזרים להם לפעול. יש אמירה של אדם בשם Moore שנקראת Moore's law ופיה: בערך כל שנתיים כמות הטרנזיסטורים במעבד מכפילה את עצמה. זה אומר שאנחנו יכולים להכניס עוד ועוד חלקים למעבד עוד ועוד אנת מה שקורה בתוך המעבד ולהוסיף עוד שערים ועוד חלקים.

35 YEARS OF MICROPROCESSOR TREND DATA
10^7 Transistors (thousands)
10^6
10^5 Single-thread Performance (SpecINT)
10^4 Frequency (MHz)
10^3 Typical Power (Watts)
10^2
10^1 Number of Cores
10^0
1975 1980 1985 1990 1995 2000 2005 2010 2015
Original data collected and plotted by M. Horowitz, F. Labonte, O. Shacham, K. Olukotun, L. Hammond and C. Batten
Dotted line extrapolations by C. Moore

אם נסתכל על הגרף הזה - הקו העליון אומר כמה טרנזיסטורים יש במעבד לאורך השנים וזה באמת מכפיל את עצמו פחות או יותר כל שנתיים. וזה ממשיך ככה בערך עד ימינו. לעומת זאת, מהירות המעבד נעצרה. אם פעם יכולנו לשים יותר טרנזיסטורים במעבד וזה היה גורם לו להיות יותר מהיר (הנקודות הכחולות), אז בין 2005-2010 הגענו למקסימום. לא יודעים לעשות מעבדים מהירים יותר לפחות לא כלי שהם יבנו בטכנולוגיות אחרות מכיוונים אחרים.

יש לנו מעבדים שיודעים להריץ X פקודות בשנייה, ולא יותר, וכל המהנדסים (של אינטל וכו') נתקלו בבעיה כי אנחנו יודעים להכניס יותר חלקים למעבד אבל לא יכולים לעשות אותו מהיר יותר. אז שמים יותר מעבדים – ניקח את השטח שהיה לנו פעם, נכניס עוד שבבים כאלה, עוד מעבדים בתוך שבב אחד וזה מה שנקרא מעבד מרובה ליבות (multicore processor) – במקום שיהיה לנו במחשב מעבד אחד שיודע להריץ פקודה אחת בכל זמן נתון ועושה את זה מאוד מהר, יהיה לנו שבב עם כמה מעבדים או כמה ליבות, שכל אחת מהן רצה באופן יחסי בנפרד, ואז דברים באמת יוכלו לרוץ במקביל. בכל מעבד שיש לנו היום (10-15 שנים אחרונות) הוא מעבד מרובה ליבות והיום יש 12 ליבות ומעלה...

מה שזה אומר - אם אנחנו רוצים שהקוד שלנו יעבוד מהר יותר, נרצה לנצל את הריבוי. פעם היינו כותבים קוד, המחשב שלנו היה מתעדכן, היינו קונים מחשב חדש יותר, מחליפים מעבד והכל היה רץ מהר יותר. היום זה לא ככה, אם נכתוב קוד וירץ אותו על מעבד יותר חדש, הוא לא ילבד יותר מהר.

בשביל שזה לא יקרה, נרצה לנצל את המעבדים ע"י כתיבת קוד מתאים לכך, כך שכשיש היו יותר מעבדים, הקוד ינצל אותם בצורה טובה.

מה שלמדנו עד היום זה תהליכים, אם יש לנו כמה מעבדים, מערכת ההפעלה יודעת להפעיל את התהליכים האלה במקביל, כל תהליך יעבוד על מעבד אחר, בכל מעבד נעשה context switch, נחליף בין תהליכים וירוצו לנו כמה תהליכים במקביל. אם אנחנו רוצים לייעל את הקוד שלנו, אז להשתמש בתהליכים זה קצת מעיק.

נניח שאנחנו כותבים תוכנה ואנחנו רוצים שהיא תעבוד יותר מהר ע"י שימוש בתהליכים מרובים, זה אפשרי אבל מעיק. גוגל כרום עושה את זה, ותוכנות נוספות. כל כרטיסייה בכרום הוא תהליך, ואז כל כרטיסייה עובדת בתהליך משלו. אבל כך התקשורת נעשית כבדה. תהליכים לא יכולים לתקשר אחד עם השני בצורה יעילה ונוחה. הם דורשים גם הרבה זיכרון. כל פעם שאנחנו עושים ()fork זה משכפל את הזיכרון, context switch לתהליכים זה לא הדבר הכי זול (זו פעולה יחסית יקרה).

במקום כל זה, הוסיפו לנו אבסטרקציה חדשה שנקראת "חוט". הרעיון של חוט - להיות כמו תהליך קטן, הוא נקרא גם light weight process, כלומר להיות תהליך קל יותר, ואנחנו נוכל ליצור חוטי ריצה שאינם נעשה דברים במקביל. חוט הוא סביבת ריצה, הוא מכיל קטע קוד מההתחלה ועד הסוף, ואנחנו יכולים לייצר חוטים שיריצו קטעי קוד והחוטים הללו ירוצו במקביל (לזה תדאג מערכת ההפעלה).

תוכנית מרובת חוטים היא תוכנית שיש לה יותר מנקודת ריצה אחת. עד היום כתבנו תוכנית שהן single threaded (התוכנית שלנו היו חוטים אבל היה חוט יחיד, החוט שמריץ את קוד ה-main שלנו). כלומר, אנחנו מריצים תהליך והמיין שלנו רץ מההתחלה ועד הסוף, זה נקרא חוט. הדרך שלנו לנצל יותר מעבדים ולדאוג שהתוכנית שלנו ירוצו יותר טוב זה תוכנית מרובת חוטים, שחוץ מה-main line של מההתחלה ועד הסוף, יהיו לנו עוד קטעי קוד שירוצו במקביל אליו (בצורה דומה לתהליכים אבל יותר יעילה).

אז מה ההבדל בין ה-main שלנו לזה חוט, אז מהו בעצם תהליך? עד עכשיו אמרנו שתהליך מריץ קוד, אבל האמת היא שתהליך לא מריץ קוד. תהליך הוא מיכל (container) שמכיל מידע (יש לו שרק מכיל עניינים ושירותים אחרים, והוא לא אריזה קוד בפני עצמה). לכל תהליך יש מזהה (pid) ואת התהליכים אליהם הוא קשור (האב שלו בעץ התהליכים), את הזיכרון הוירטואלי שלו, המחסנית והערימה, וכן לכל תהליך יש את סט הקבצים הפתוחים שלו.

הדבר החדש שיש לכל תהליך - לכל תהליך יש חוט אחד או כמה חוטים (לפחות חוט אחד לכל תהליך). החוטים מריצים קוד. אם לתהליך יש 3 חוטים: זה אומר שהוא שואף להריץ 3 דברים במקביל (תלוי במערכת ההפעלה, במנתן ובכמות המעבדים).
לכל חוט בתהליך יש: מזהה (thread id) TID וגם מערך רשימה של כל הרגיסטרים של החוט (ה-context שלו). עד היום אמרנו שמערכת ההפעלה מנהלת תהליכים, אבל בפועל היא לא מנהלת תהליכים אלא מנהלת חוטים של תהליכים. כל חוט מריץ קוד (יש לו רגיסטרים שהוא משתמש בהם תוך כדי ריצה, ושומר לו ה-context). כאשר החוט נעצר כי עושים לו context switch, מערכת ההפעלה שומרת את המצב שלו בצד וטוענת את המצב של חוט אחר. המהות של חוט הוא ייחודי באותו תהליך (ייתכן שיש חוטים עם מזהים דומים בתהליכים שונים), והמחסנית של חוט בניגוד למחלקה של תהליך – היא לא בהכרח מספר (זה תלוי מערכת ההפעלה). הנתונים של חוט שמורים בתוך משהו שנקרא (TCB (Thread control block (בתהליך זה pcb).

קצת context switch: מה שקורה בהחלפת הקשר - מערכת ההפעלה בוחרת חוט מסוים שרץ כרגע, עוצרת אותו, שומרת את המצב שלו בצד (בתוך ה-TCB שלו) וטוענת חוט אחר כלשהו (זה לא חייב להיות חוט של אותו תהליך), טוענת את מצב הרגיסטרים שלו משמור בצד אל המעבד, ואז נותנת לו לעבוד.

אחד היתרונות של חוטים – אם עושים החלפה של שני חוטים באותו תהליך, הם מסתכלים על אותו אזור בזיכרון וחולקים אותו כשיש לנו מעבד ויותר שני תהליכים - אז מערכת ההפעלה לא מנצלת את התהליך, אין דבר כזה לנצל תהליך, אלא מנצלת חוט של התהליך. הזיכרון של החוט שהיא מנהלת הוא הזיכרון של התהליך שהחוט שייך אליו. כשאנחנו עושים החלפה בין חוטים (context switch) זו החלפה בין חוטים ולא בין תהליכים, ואם החוט החדש שייך לאותו תהליך, אז לא צריכים להחליף את הזיכרון (כל הרגיסטרים וכל העניינים שמתייחסים לזיכרון הוירטואלי נשארים ליהם).

אז למה להשתמש בחוטים? יש לנו שתי מטרות עיקריות:
1. מקבילי (Parallelism) – אנחנו רוצים לקחת את התוכנית שלנו ולהריץ אותה בחלקים. מה שעשינו עד היום – תוכנית סדרתית, זה לא יותר מהיר. נרצה שזה יהיה יותר מהיר אז נרצה לחלק את התוכנית שלנו לחלקים קטנים נפרדים ולהריץ הכל בבת אחת. אם יש לנו למשל מערך גדול מאליארד, ונרצה לעבור על כל איבר ולבדוק האם הוא גדול מ-0, אז בתוכנית רגילה נצטרך לעשות לולאת פור על כל המערך וענין שזה לוקח 10 שניות, אבל אם יש לנו 10 מעבדים, נוכל לעשות זאת בשנייה אחת (נוכל ליצור 10 חוטים, לתת לכל חוט לרוץ על עשירית מהמערך, ואז הם יעשו את זה במקביל). עכשיו מעודכן שבוקחה 10 שניות יש לנו תוכנית שבוקחה שניה והתוצאה זהה. כלומר, במקביל אנחנו רוצים לקחת את העבודה שהיינו עושים בחוט יחיד ולפרק אותה לחלקים כדי לנצל את המעבד מרובה הליבות שלנו ולעשות הכל בבת אחת בו זמנית.

2. חפיפה (overlap)- יש תוכנית שקוראות קלט מהמשתמש, כשאנחנו בתוכנית רגילה עושים scanf, התוכנית תקועה. עד שלא מגיע הקלט אנחנו לא יכולים לעשות שום דבר. עם חפיפה, עם חוטים, נוכל ליצור חוט אחד שיקרא ל-scanf ואז בזמן שהחוט הזה חסום ומחכה לקלט מהמשתמש, חוט אחר יעשה משהו אחר באותו זמן. כלומר, אנחנו לא צריכים לחכות להיות תקועים. כשאנחנו עושים קריאה חסומה blocking אנחנו נתקעים עד שקורה אינשהו אירוע, היא בעצם חוסמת את החוט, ונוכל ליצור חוטים נוספים שירוצו במקביל ויוכלו לעשות דברים אחרים במקום שכל התוכנית תינתקע ותמתין.

מה צריך בשביל שחוטים ילכו? לכל הזיכרון שהכרנו עד היום: הזיכרון הוירטואלי של התהליך (text/data, heap, stack). המחסנית מכילה משתנים מקומיים, קריאות לפונקציות וכו'. אם כל חוט מריץ קוד בנפרד, אז עכשיו כל חוט צריך מחסנית משלו. בזיכרון שלנו, יש מחסנית נפרדת לכל חוט. ככה כל חוט יודע איפה הוא נמצא. אז כל פעם שיוצרים חוט, מערכת ההפעלה יוצרת עבורו מחסנית בזיכרון באופן אוטומטי. כשהחוט מסיים, המחסנית הזו משתחררת. המחסנית הזו משויכת לחוט בזמן שהוא משתמש בה, אבל היא לא בלעדית אליו. הזיכרון של התהליך עדיין משותף לכולם. אם חוט אחר רוצה לגשת או לעשות שימוש במחסנית של חוט אחר (לקרוא/לכתוב), הוא יכול.

Text / Data
Heap
Stack
Stack (3)
Stack (2)
Stack (1)

איך חוטים ממומשים?
יש כמה דרכים לממש חוטים:
1. User threads - גישה שהייתה נהוגה יותר בעבר ופחות קיימת כיום. לפי גישה זו: מערכת ההפעלה לא מכירה חוטים, אלא רק תהליכים והיא מנהלת תהליכים (כלומר כל מה שדיברנו עליו עד השיעור היום, עדיין תקף). ב-user threads יש לנו איזושהי ספריית קוד שאינה אנחנו יכולים לייצר חוטים וכל פעם שהתהליך שלנו מקבל זמן מעבד, בספרייה הזו יוחלט איזה חוט מבין חוטים אילה ירוץ כרגע. הכל נעשה בחסות הספרייה, ב-user mode. מבחינת מערכת ההפעלה – אין דבר כזה חוטים, יש תהליך שמריץ דבר אחד בכל רגע נתון, אבל אנחנו בקוד שלנו מחליפים כל פעם בין חוטים בשביל נוחות.
ספריית הקוד נותנת לנו את האשליה כאילו כמה דברים רצים במקביל. זה טוב בעיקר ל-overlap: אם אנחנו רוצים שבזמן שיש פעולה שהיא blocking לא נהיה חסומים או נעשה כמה דברים שזה ייראה כאילו דברים רצים במקביל, אבל זה לא טוב. החיסרון בגישה הזו: דברים לא באמת ירוצו במקביל. גם אם יש לנו כמה מעבדים, מערכת ההפעלה לא תריץ את הקוד שלנו על גבי כמה מעבדים, אלא היא מכירה תהליך אחד והיא יודעת להריץ רק דבר אחד, ולא כמה תוך כדי, וההחלפות ייראו רק למראית עין. כלומר החיסרון העיקרי בשיטה זו הוא שאין מקביליות אמיתית.

2. Kernel Threads – השיטה שיש היום כמעט בכלון במחשב. מערכת ההפעלה מכירה את כל החוטים שיוצרנו והיא בוחרת איזה חוט למתן כל חוט וחוט, מתי להחליף ביניהם ועל איזה מעבד ירוץ כל חוט. ואז אנחנו מקבלים מקביליות אמיתית. החיסרון היחידי ב-kernel threads: חוטים הופכים להיות טיפה יותר יקרים. כי יצירה של חוט זו קריאת מערכת, החלפה בין חוטים עוברת דרך ה-kernel (כי זה context switch) עם פסיקת שעון (או פסיקה כלשהי) אבל קיבלנו מקביליות אמיתית. מערכת ההפעלה יכולה להכיר את כל החוטים שיש לנו להריץ אותם על ליבות שונות במעבד ולדאוג שבאמת ירוצו במקביל.

שילוב: מבחינת מערכת ההפעלה יש תהליך, ואנחנו נגדיר למערכת ההפעלה כמה חוטים יש לנו. נניח נגדיר שיש לנו 4 חוטים. בדרך כלל נגדיר את זה לפי כמות המעבדים במחשב (מספר חוטים כמספר מעבדים). מערכת ההפעלה מכירה את ארבעת החוטים האלה ועושה ביניהם החלפו הקשר (context switch) אבל המשתמש (אנחנו) נחליט לזה כאילו יש יותר. אנחנו יכולים להגדיר חוטים שמערכת ההפעלה לא מכירה (נניח במקרה זה 7 חוטים כאלה) ועכשיו, כשישיהו חוט מקבל זמן מעבד, הוא בוחר מה למתן מבין החוטים הלוגיים שלנו, והוא יכול לעשות context switch ביניהם. אז מערכת ההפעלה מכירה 4 חוטים כשבפועל לקחנו יותר חוטים. אנחנו מקבלים את האשליה ש-7 דברים רצים במקביל, כשבפועל רק 4 מהם באמת רצים במקביל. זה טוב בגלל הנוחות – אם יש לי עבודה שיותר נוח לי לפרק ל-50 חלקים, אז נפרק אותן ל-50 חלקים, אבל במקום ליצור 50 חוטים, אני אצור רק כמה חוטים שצריך. אם יש לי 4 מעבדים, אין טעם ליצור 50 חוטים, זה לא יעזור, ניצור 4 חוטים כי גם ככה לא ירוצו יותר מ-4 דברים במקביל. בשפות חדישות זה שקוף לנו לגמרי. לחלוטין, יש לנו ספריות שאנחנו נותנים להם את כל העבודה שאנחנו רוצים לבצע והן כבר עושות את עבודת התזמון ובוחרות איזה מעבד יבצע מה בכל זמן נתון. זו נקראת הגישה ההיברידית.

ב-Linux:
כל תהליך בלינוקס שהכרנו עד היום, מתחיל עם חוט אחד (תמיד), והוא נקרא גם החוט הראשי (ה-main thread) בסיקר אחר והוא מריץ את פונקציית ה-main שלנו. כמו שאמרנו לפני כן, תהליך לא מריץ קוד בפני עצמו, הוא רק container שמכיל דברים אחרים, בין השאר מכיל חוטים וכשאנחנו מריצים תוכנית - נוצר תהליך ובתוך התהליך הזה נוצר חוט אחד שמריץ את פונקציית ה-main שלנו. החוט הזה יכול ליצור עוד חוטים נוספים, וגם הם בעצם יכולים ליצור עוד חוטים נוספים. בחוטים אין אב, אין יחסים של אב ובן (שלא כמו תהליכים). כל החוטים שווים.

הדבר היחיד שמיחד את החוט הראשי הוא: כשהחוט הראשי מסיים לרוץ, כל התהליך מסתיים. כלומר, כשפונקציית ה-main מסתיימת, כל התהליך מסתיים ולא משנה מה מצבם של החוטים האחרים.

יצירת חוט: נעשית ע"י הקריאה pthread_create. זו קריאת מערכת שיוצרת חוט. כל קריאות המערכת של חוטים מתחילות ב-pthread שזה השם של הספרייה. כל קריאות המערכת של חוטים נבדקות וקוראות מערכת רגילות, בזה שהן מחזירות 0 כשהן מצליחות וכל תוצאה שונה מ-0 היא שגיאה שקרתה. אז כל תוצאה שונה מ-0 מעידה על כישלון.

int pthread_create(
    pthread_t *thread,
    pthread_attr_t *attr,
    void* (*start_routine)(void*),
    void *arg)

• thread id of new thread
• attr config attributes (we pass NULL)
• start_routine routine for thread to run
• arg argument passed to routine

דוגמא לקטע קוד:
חוט מריץ פונקציה בקוד שלנו. הפונקציה שחוט מריץ חייבת להיראות מהחתימה הבאה של: מקבלת *void ומחזירה *void (יודע לקבל כל דבר ולהחזיר כל דבר). כרגע שיצרנו פונקציה כזאת בקוד שלנו, אנחנו יכולים ליצור חוט שיריץ את הפונקציה הזו. אז כרגע יש לנו פונקציה רגילה שנקראת mythread שמקבלת מחרוזת כארגומנט, ומדפיסה אותה למסך ומחזירה NULL.

void* mythread(void *arg)
{
    printf("%s\n", (char*) arg);
    return NULL;
}

- אם אנחנו רוצים להריץ את הפונקציה הזו, אנחנו יכולים לקרוא ל-pthread_create שלו פונקציה שמקבלת כמה ארגומנטים:
1. מצביע לטיפוס מסוג pthread_t שזה ה-id של חוט (TID) הוא לא חייב להיות מספר.
2. פרמטרים ליצירת חוט – תמיד נעביר NULL.
3. שם הפונקציה שהחוט יריץ.
4. מה הארגומנט שהפונקציה הזו תקבל.

בקריאה הראשונה ל-pthread_create: זו כמו קריאה ל-mythread עם הארגומנט - מחרוזת שמכילה "A". לאחר מכן אנחנו יוצרים עוד חוט, וזה כמו קריאה לפונקציה mythread עם הארגומנט - מחרוזת שמכילה "B".

int main(int argc, char *argv[])
{
    pthread_t t1, t2;
    pthread_create(&t1, NULL, mythread, "A");
    pthread_create(&t2, NULL, mythread, "B");
}

כשאנחנו עושים pthread_create: אנחנו קוראים לפונקציה במקביל. אנחנו בעצם יוצרים חוט שהולך להריץ את הקוד שכתוב בפונקציה ואותו הליך ממשיכים הלאה, לא מחכים שהפונקציה תסתיים. כלומר אנחנו מיד ממשיכים לשורה הבאה, ובעצם מריצים משהו במקביל.

כשאנחנו נפעיל את הקוד הזה ונירי – יהיה לנו תהליך שהדבר הראשון שייוצר בו הוא החוט הראשי (ה-main). ברגע שנגיע את השורה הראשונה, ניצר לנו חוט חדש, נקרא לו A (חוט שמקבל כארגומנט A). החוט הזה מריץ את הפונקציה mythread עם הארגומנט A.
הוא רץ במקביל לחוט הראשי (כשמערכת המחשב שני חוטים ושני קטעי הקוד האלה רצים במקביל). הם רצים באותו תהליך (זה אינו תהליך של פעמיים, יש לו שני קטעי קוד שרצים בו זמנית במקביל) ברגע שהחוט הראשי שלנו ממשיך וקורא ל-pthread_create השני, הוא יוצר עוד חוט (ונקרא לו B) ושוב הפונקציה mythread נקראת והיא רצה עכשיו פעמיים – פעם אחת ע"י כל חוט. ברגע שהפונקציה מסתיימת, החוט הרלוונטי מסתיים.

ריצה של הקוד לדוגמא:
יש לנו את החוט הראשי (המיין שלנו), הוא רץ ומבצע את השורה הראשונה -> נוצר לנו החוט הראשון עם הארגומנט A. עכשיו החוט A רץ במקביל אלינו. במקרה הזה הוא מדפיס A. החוט הראשי שלנו ממשיך במקביל אליו. ומייצר עוד חוט, חוט B שנדפיס בסוף B ומסיים. בסופו של דבר גם החוט הראשי שלנו מסתיים.
אז עשינו הרצה וקיבלנו שהפלט הוא: A B.
פה נוכל שיכול להיתקל – ברגע שחוט נוצר הוא רץ במקביל אלינו אבל אנחנו לא יודעים את סדר הריצה, איזה יתומן מתי, מי יקבל page fault וכו'.
יכול לקרות מצב שהחוט הראשי שלנו ייצור את החוט A ואז את החוט B לפני ש-A הספיק לרוץ ואז B ירוץ ראשון ורק לאחר מכן A ירוץ. אז הפלט יהיה: B A.

כמו כן יכול גם לקרות מצב שהחוט הראשי שלנו ייצור את חוט A, ואז את חוט B ירוץ (או לא, זה לא משנה) וידפיס את הפלט שלו, ועכשיו החוט הראשי סיים, ברגע שהחוט הראשי מסתיים, כל התהליך נעצר, מה שלא הספיק לרוץ לא הספיק. במקרה הזה הפלט יכול להיות רק A או רק B (אם רק A או A הספיק לרוץ ו-B לא).

כמו כן, יכול להיות גם מצב שלא יהיה פלט בכלל. ייתכן שהחוט הראשי יצור את חוט B ואז יסיים (החוט הראשי ירוץ הכי מהר והוא הראשון שיסיים). ברגע שהוא מסיים, כל החוטים מפסיקים לרוץ ואז שום דבר לא יודפס.
כל הפלטים היו אפשריים, כתלות במזלנו שלנו.

---------------------------------------------------------------------------------------------------------------------------------------

נראה איך אנחנו מונעים את המקרים הנ"ל – יש לנו את הקריאה pthread_join שהיא המקבילה של wait בתהליכים. pthread_join מחכה שתהליך בן יסיים, wait, wait_pid מחכה שחוט כלשהו יסיים (רק בתוך אותו תהליך). אנחנו מסבירים את המזהה של החוט וכרגע הקריאה ל-join, שביצע את הקריאה (אותו חוט שביצע את הקריאה) הופך להיות blocked כלומר הוא נחסם והוא מחכה.

• Wait to thread to end:
int pthread_join(
    pthread_t th,
    void **thread_return)

• th id of thread to wait for
• thread_return get pointer to thread’s return value
• Any thread can join any thread within the process

אנחנו נמשיך לשורה הבאה, והחוט שהעברנו את המזהה שלו – ממשיך הלאה. הארגומנט השני ב-pthread_join זו הדרך שנו לקבל את ערך ההחזר של החוט. כל חוט מחזיר מהפונקציה שלו משהו (void*), אנחנו לא יכולים להניח לסדר כביכול של חוט כי הוא לא מחזיר שום דבר, אבל ב-join אנחנו יכולים, נניח נגדיר void* ret ונוכל לקרוא ל-pthread join עם t1 ועם ret t1-ה יסיים ורק אחרי שהוא יסיים, נמשיך לשורה הבאה. ואם נרצה נוכל להעביר את הכתובת של ret ועכשיו בתוך המשתנה ret יהיה לנו את ערך ההחזר (מה שהחוט t1 החזיר) והשורה הבאה נוכל להתייחס אליו.
**** כל חוט יכול לעשות join לכל חוט אחר באותו תהליך, ולא צריך יחסי אב וילדים.

קוד נוסף – גם פה אנחנו יוצרים שני חוטים וכל אחד מהם קורא ל-mythread עם הפרמטר שלו, אבל הפעם עושים join, כשאנחנו מעבירים null ל-join, זה אומר שלא מעניין אותנו ערך ההחזר. אנחנו מעוניינים לערך ההחזר, פשוט מחכים שהחוט יסיים. יש לנו מיין (חוט ראשי) שיוצר כמה חוטים שרצים במקביל, והמיין מחכה להם שיסיימו ואז מסיים בעצמו.

int main(int argc, char *argv[])
{
    pthread_t t1, t2;
    pthread_create(&t1, NULL, mythread, "A");
    pthread_create(&t2, NULL, mythread, "B");
    pthread_join(t1, NULL);
    pthread_join(t2, NULL);
}

ברגע שהחוט הראשי מגיע ל-join, הוא הופך להיות blocked, כלומר הוא חסום עד שהחוט הראשון והשני יסיימו. הפלטים האפשריים לקוד הזה: כשאנחנו יוצרים את חוט A ואז את חוט B, עכשיו החוט הראשי מחכה לחוט A שיסיים. אבל זה שהוא מחכה ל-A לא אומר ש-A ירוץ ראשון. אנחנו לא יודעים מה הסדר בין חוט A לחוט B, כל אחד מהם יכול להדפיס ראשון, אבל בהכרח יהיו פלטים וחדר והחוט הראשי והשני החוטים הללו יסיימו ורק אז נמשיך.

קוד נוסף – פלטים אפשריים:
1. 10
2. שום דבר (ללא פלט בכלל)
3. ערך זבל
4. שגיאה
0.5

void* PrintVar(void* arg) {
    int* a = (int*) arg;
    printf("%d\n", *a);
}
void foo() {
    int a = 10;
    pthread_t thr;
    pthread_create(&thr, NULL, PrintVar, &a);
}

הסבר: אנחנו מייצרים חוט, הוא הולך להריץ את הפונקציה printvar שמקבלת בתור ארגומנט את הכתובת של a, אבל a הוא משתנה שמוגדר במחסנית ברגע שהפונקציה foo מסתיימת, ה-a נמחק. ברגע ש-a נמחק, ההתנהגות לא צפויה. יכול להיות שהחוט ירוץ מספיק מהר וידפיס 10, ואז הכל תקין. יכול להיות שהתהליך-foo או שהחוט הראשי מסתיים, ואז לא יודפס לנו כלום (כי החוט הראשי יסיים לפני ש-printvar הספיק לרוץ).

יכול להיות מצב שהקוד ימשיך, הפונקציה foo תסתיים וערך לתוך a כלומר הערך יהיה מזבל או כל דבר שאנחנו לא יודעים מה הוא. יכול להיות שנקבל שגיאה (ניגשנו לזיכרון לא תקין, ברגע שיצאנו מהפונקציה, a יצא מהמחסנית ושוחרר, ולגשת אליו יכול לגרום לשגיאה) ולכן מדובר על התנהגות בלתי צפויה. אנחנו לא יודעים מה יודפס, אם בכלל, ואנחנו לא יודעים אם קטע הקוד הנ"ל ירוץ באופן תקין ולא יקרוס.

תיקון פשוט לקטע הקוד הזה: לבצע join.
נחכה שהחוט שיצרנו יסיים ורק לאחר מכן נמשיך הלאה, ברגע שעשינו join אנחנו יודעים בוודאות ש-a עדיין תקין ולכן אנחנו יכולים להתקדם.
דבר יותר נכון לעשות: לא להעביר כתובת של משתנה שמוגדר במחסנית. אם אנחנו קוראים לפונקציה ומייצרים חוט, אנחנו צריכים לוודא שכל הארגומנטים שאנחנו מעבירים לחוט הם תקינים. או או שנקצה את a דינאמית (ונצטרך מצביע שמוגדר ב-heap ונדאג גם לשחרר בסיום, או שנגדיר משתנה גלובלי (כי משתנה גלובלי לא חי חיי התוכנית), או נמצא כל פתרון אחר שלא מערב שליחה של כתובת משתנה שמוגדר במחסנית.

אותו דבר נכון גם לגבי החוט עצמו. כשאנחנו כותבים פונקציה של חוט, השימוש בה הוא כמו בפונקציה של שפת C לא מעניין אותנו שזה פונקציה של חוט, אם הגדרנו משתנה מקומי והחזרנו מצביע אליו, זה לא טוב. אנחנו מחזירים כתובת של משתנה שהוגדר במחסנית וזה לא נכון. זו התנהגות לא צפויה ולא מישהו הולך להתייחס לערך ההחזר הזה.

---------------------------------------------------------------------------------------------------------------------------------------

קריאות נוספות של חוטים:
1. ()pthread_self - מחזירה את ה-id של החוט הנוכחי

• pthread_t pthread_self()
• Returns current thread’s id

2. (Pthread_cancel (pthread_t th - עוצר חוט אחר שהמזהה שלו הועבר כפרמטר. ייתכן שיש תהליך שעשה join ומחכה לערך ההחזר עבור החוט שעוצרים אותו. אז יש קבוע שמוגדר בלינוקס שנקרא pthread cancel- אם וסתכל על ערך ההחזר של אותו חוט שנעצר, אנחנו נקבל את הקבוע הזה.

• int pthread_cancel(pthread_t th)
• Stops another thread
• th - id of thread to cancel

3. (pthread_exit (void* retval - יוצא מהחוט הנוכחי. החוט שביצע את הקריאה הזו, עוצר מיידית וערך ההחזר של החוט זה מה שהוא יעביר כפרמטר לקריאה.

• void pthread_exit(void *retval)
• Calling thread will exit and return retval
• Called by main thread – waits for all threads to finish!
• Note - exit() on any thread will exit all threads!

מקרה אחד מיוחד: כשהחוט הראשי קורא ל-()pthread_exit, כלומר כאשר החוט הראשי מסתיים ע"י הקריאה הזו, הוא לא מסיים את התהליך. מערכת ההפעלה מחכה עד שכל החוטים בתהליך הזה יסיימו ורק אז התהליך יסתיים. כלומר, כאשר החוט הראשי קורא לקריאה זו, הוא מסיים מבלי לסיים את התהליך.

כסטנדרט, כשאנחנו כותבים קוד חוטים נכתוב בסוף המיין ()pthread_exit (אפשר להעביר ערך 0 כארגומנט לקריאה). ככה אנחנו יודעים בוודאות שכשהחוט הראשי יסתיים, הוא לא יסיים את כל התהליך, וכך כל חוט ירוץ מההתחלה ועד הסוף. כמו כן, כאשר נבצע ()exit (הקריאה ששייכת לתהליכים), כל לו קריאה של תהליכים. לא משנה איזה חוט ביצע את הקריאה הזו, זה עוצר את כל התהליך, כל החוטים עוצרים איפה שהם והתהליך מסתיים.

האמירה הכללית היא לא לשלב בין קריאות מערכת של חוטים לבין קריאות מערכת של תהליכים.
אם כן נשלב:
מקרה 1: יש לנו תהליך ובו יש סט של חוטים, לכל תהליך יש זיכרון משלו. אם נזכר בפעולה של exec – היא בין השאר מוחקת את הזיכרון ומשכתבת אותו עם דף זיכרון של תוכנית חדשה. ברגע שאחד החוטים קורא ל-()exec, בגלל עניין מקביליות (שדברים רצים במקביל), התהליך שלנו עלול לקרוס. הסבר: מערכת ההפעלה מתחילה לשכתב את הזיכרון, לסגור דברים שהתהליך מחזיק ועוד.. אבל ייתכן שעדיין חוטים אחרים רצים במקביל, אז חוט אחר עלול לנסות לגשת לאותו זיכרון שנמחק וזה יכול לגרום לכך שהתהליך יקרוס. לכן בתוכנית עם יותר מחוט אחד, לא נקרא ל-()exec.

מקרה 2: ל-()fork בדרך כלל לא קוראים (אפשר לקרוא אבל לא נוח). נניח והחוט הראשי קורא ל-()fork. ()fork יוצרת תהליך בן חדש שהוא שכפול (גם הזיכרון וגם הכל), אבל ()fork לא משכפלת את החוטים. למעשה החוט היחיד שיהיה בתהליך החדש זה אותו חוט שקרא ל-()fork, ולא רק שהוא יהיה החוט היחיד שייוצר, הוא גם יהפוך להיות החוט הראשי בתהליך החדש (כשהוא יסיים להריץ את הפונקציה שהוא מריץ, כל התהליך יסתיים). למה לא משכפלים את שאר החוטים? אם היינו משכפלים את החוט הלאה, אחד הדברים שאנחנו רוצים ב-()fork זה את היכולת להבין מי האב ומי הבן. כשאנחנו קוראים ל-()fork אנחנו יכולים להבדיל לפי ערך ההחזר שלה. אבל בחוט שכל כרגע לא נקרא לו ע"י הקוד החדש מי האב ומי הבן. ברגע שחוט קורא ל-()fork הוא היחיד שמשוכפל ונתייחס אליו כמו החוט הראשי בתהליך החדש.

SHARED DATA:
בפונקציה mythread: הלולאה רצה 10,000,000 פעמים ומקדמת את המונה (שהוא משתנה גלובלי שמשותף ל-0). כל החוטים מסתכלים על אותו המונה. הפונקציה הראשית (המיין) מייצרת שני חוטים ועושה join לשניהם. בסוף אנחנו מדפיסים את הערך של המונה. כל אחד מהחוטים מריץ את הפונקציה mythread עם פרמטרים שונים. אחרי ששניהם סיימו, אנחנו מדפיסים את הערך של המונה.

int counter = 0; // global (shared) variable
void* mythread(void *arg) {
    for (int i = 0; i < 10000000; ++i) {
        ++counter;
    }
    return NULL;
}
int main(int argc, char *argv[]) {
    pthread_t p1, p2;
    pthread_create(&p1, NULL, mythread, "A");
    pthread_create(&p2, NULL, mythread, "B");
    pthread_join(p1, NULL);
    pthread_join(p2, NULL);
    printf("counter = %d\n", counter);
}

** כל פעם שאנחנו רוצים לקמפל קטע קוד שקשור לקריאות מערכת של חוטים, אנחנו צריכים להוסיף את הדגל הבא:
prompt$ gcc pthread2.c -Wall -o p2 -pthread
prompt$ ./p2

אם נפעיל ונריץ את הקוד, אלו התוצאות שנקבל. במקום לקבל 10,000,000 נקבל מספר אחר, ואם נריץ עוד פעם נקבל מספר אחר.

prompt$ gcc pthread2.c -Wall -o p2 -pthread
prompt$ ./p2
counter = 10363017
prompt$ ./p2
counter = 10734008
prompt$ ./p2
counter = 10647771

הסבר למה שקורה פה: אנחנו כתבנו בקוד שלנו counter++, ובמחינתנו בשפת C זו פקודה אחת, אבל המעבד שלנו לא מכיר פקודה כזו של קידום משתנה, הוא מכיר קריאה וכתיבה מהזיכרון. קידום חיסור וכו' אנחנו יודעים לעשות רק על הרגיסטרים במעבד ולא ישירות על הזיכרון. זה אומר ששם המימוש של counter++ אנחנו צריכים להריץ 3 פקודות – קריאת המונה לתוך רגיסטר, קידום הרגיסטר ב-1 ואז כתיבה שלו חזרה לזיכרון. ברגע שמשהו מתבצע בכמה פקודות ולא בפקודה אחת זה כבר לא בטוח.
אז נראה מה קרה בקידום יחיד של המונה. יש לנו מספר אחד וחוט מספר שניים. כל אחד מהם מריץ בדיוק את אותו הקוד אם נריץ את זה:

ריצה אפשרית אחת: חוט מספר 2 יקרא את המונה לתוך הרגיסטר שלו, ובמקביל אליו חוט מספר 1 יקרא גם. שניהם יקדמו את המונה ויכתבו בחזרה לרגיסטר שלו. הם לא יודעים אחד לשני, קידמנו את המונה פעמיים.

ריצה אפשרית שנייה: חוט מספר 1 יקרא את המונה לתוך הרגיסטר ויאזן עם הקידום שלו. בינתיים חוט מספר 2 מקדם את המונה כמה פעמים. אז עכשיו לא רק שלא קידמנו את המונה נכון, אלא חוט 1 עומד להחזיר אותנו לתוצאה קודמת. יש לנו פה מה שנקרא "מצב ריצה" - מצב שהתוצאה שלי תלויה בתזמון. אם המנתן יהיה ידידותי ויעבוד כפי שציפינו, אז נקבל מה שרצינו. קטע הקוד שגורם למצב הריצה הזה לה על ה-counter++.

זה נקרא קטע קריטי - קטע קוד שנגיע למשאב משותף, ואנחנו לא רוצים שהוא יבוצע במקביל לריצה של קטע קוד אחר. אנחנו רוצים ששלושת הפקודות הללו יתבצעו בבת אחת ולא שכמה חוטים יתערבבו במקביל. אנחנו מנסים להגיע למצב של מניעה הדדית. כלומר היינו רוצים לגרום לכך שרק חוט אחד יוכל לבצע את הפקודה בכל רגע נתון. כלומר שאם חוט א' מבצע עליו פעולה, חוט ב' לא יכול לגעת בו. וכשחוט א' יסיים אז חוט ב' יוכל לגעת בו. כלומר אנחנו רוצים שהפעולה הזו תהיה אטומית (נקרה בבת אחת בלי שתפריע לה במאצע), או לפחות האשליה של אטומיות. זה לפעמים נקרא טרנזקציה.

בשביל זה נצטרך עזרה של מערכת ההפעלה והמעבד שלנו.

