מערכות הפעלה – שיעור 21

השיעור נדבר על התמודדות עם קריסות.
זיכרון על כך שהדיסק הוא רכיב איטי מאוד של בלוקים. במערכת קבצים סטנדרטית אנחנו מחלקים את הבלוקים הללו כך
שחלקם data blocks (בלוקים שבהם אנחנו שומרים את הנתונים של הקבצים), לפניהם יש את הבלוקים של ה-inode
(מכילים את ה-metadata על כל קובץ) ובבלוקים האלו כל בלוק מכיל מספר כלשהו של inodes, לפני כמה שנכנס, גודל
הבלוק וגודל ה-inode. לפניהם יש שני בלוקים (לפחות, יכולים להיות גם יותר) של bitmap, כשכדי שנוכל למצוא איפה יש לנו
inodes פנויים (בלוק אחד או יותר, inode bitmap / data bitmap). הבלוק הראשון הוא ה-superblock (אחרון
שלפעמים יהיה בלוק לפניו שזה ה-boot).
חשוב לנו שכל הנתונים בהארד דיסק יהיו עקביים. אם נתון כלשהו לא תקין, אזי מערכת הקבצים שלנו בבעיה.
הכוונה בנתון לא תקין – נניח ויש לנו inode כלשהו שאחד המצביעים שלו מצביע על בלוק של data. אם בבלוק שהוא מצביע על
בלוק הדאטה הזה קורה מצב שב-bitmap כתוב שהבלוק הזה פנוי, אנחנו בבעיה. אי אפשר להגיע למצב שאנחנו מצביעים
לבלוק דאטה, משתמשים בו ובו זמנית ה-bitmap אומר שהוא פנוי. כי יכול לקרות מצב שמישהו יבוא, יראה שהבלוק הזה פנוי ויכתוב אליו
נתונים. כך שיכתב שיש לנו שני קבצים שמשתמשים באותו בלוק דאטה. וזה לא תקין.
גם מצב הפוך הוא לא תקין: נניח שיש לנו בלוק דאטה מסוים שלא בשימוש, הוא פנוי, אבל ב-bitmap הוא מסומן כתפוס.
אז אולי מערכת הקבצים לא קרסה, היא יכולה להמשיך לעבוד, אך היא לא במצב תקין. כי יש לנו פה ליג' (זליגת זיכרון).
יש בלוק שהוקצה, אף אחד לא מייחס אליו ובחיים לא נשתמש בו.
זה נכון גם לגבי ה-inodes. יש לנו inodes מסוימים שאנחנו משתמשים בו ויש ויקייה שאוכלת אותן ומפנה למספר שלו אבל ב-
inode bitmap הוא מסומן כפנוי. או הפוך – שאנחנו לא משתמשים בו אבל הוא מסומן כתפוס וכו'..
אלו כל מיני בעיות שאנחנו יכולים להגיע אליהן, ותכף נראה איך.
אנחנו רוצים שמערכת הקבצים שלנו תמיד תהיה במצב תקין, על פני כל הדיסק.
בזמן פקודה ועדכונים, השינויים והעדכונים קורים בחלקים ולא נכתבים בבת אחת לדיסק, כל פעם כותבים ענין אחד לדיסק, ואם
קרסנו באמצע – מערכת הקבצים שלנו עלולה להגיע לאחד המצבים שדיברנו עליהם.
ואז נצטרך להתמודד עם הבעיה. הבעיה הזו נקראת **Crash Consistency** – איך אנחנו מתמודדים עם קריסות
בלי להשאיר את מערכת הקבצים שלנו במצב לא תקין, למרות שקריסה יכולה להתרחש בכל רגע (אנחנו לא יכולים לדעת מתי קריסה
תתרחש).

נזכיר כעת על אותה המערכת שדיברנו עליה בשיעור הקודם (הלוא ה-superblock כהנחתה) ונניח שאנחנו עושים פעולה של
append – נכתוב 4kb לקובץ כלשהו שקיים כבר. אנחנו פותחים את הקובץ, עושים ()lseek לסוף שלו, כותבים 4kb בסוף
שלו וסוגרים.
לפי ה-inode bitmap בציור, יש שם 8 ביטים ולכן יש 8 inodes במערכת הקבצים שלנו בסך הכל.
הקובץ שאנחנו כותבים אליו זה ה-i[v1] בציור. כרגע ה-inode שהוא תפוס והנתונים שלו הם ב-data blocks כ-Da.
כלומר התחלנו במצב תקין של מערכת
הקבצים, שבו יש לנו כרגע קובץ אחד.
בתוך ה-inode במצביעים שלו הוא
מצביע לבלוק Da של הדאטה.

| inode Bmap | Data Bmap | inodes | Data Blocks |
| :--- | :--- | :--- | :--- |
| [ ][ ][ ][ ][ ][ ][ ][ ] | [ ][ ][ ][ ][ ][ ][ ][ ] | [i[v1]] | [Da] |

אנחנו משתמשים בתוכנה שהולכת לפתוח את הקובץ הזה ולכתוב לו עוד 4kb. כלומר, לכתוב עוד בלוק של דאטה (כל בלוק הוא
בגודל 4kb). בשביל לספק את הפעולה הזו למשתמש, במערכת הקבצים אנחנו צריכים לכתוב בפועל 3 בלוקים (כי אנחנו
צריכים לעדכן שלושה בלוקים של נתונים). אנחנו נתעלם כרגע מפעולות קריאה, נתייחס אליהן בהמשך, כרגע מעניין אותנו עדכון.

הדבר הראשון מבין השלושה שאנחנו צריכים לעשות (הסדר לא משנה), זה לעדכן את ה-data bitmap.
אנחנו צריכים למצוא בלוק פנוי ולסמן אותו כתפוס (בלוק Db). לאחר שנעשה זאת, נוכל להשתמש באותו בלוק ל-
data שלנו.
דבר שני שאנחנו צריכים לעשות זה לעדכן את ה-inode. כרגע הוא מצביע ל-Da שהיה הדאטה הראשון שלו, אנחנו צריכים
לעדכן ולהוסיף לו הצבעה לאותו בלוק דאטה-לסוף שהמשך הנתונים הוא שם.
דבר שלישי שאנחנו צריכים לעשות זה לכתוב את הבלוק של הדאטה עצמו. זה העדכון של הוספת בלוק נתונים לסוף של קובץ.

כעת, ננסה מצב בו המערכת קורסת.
אנחנו לא יכולים לדעת מה יקרה, אם פתאום קורס החשמל
או ננתק המחשב וכו', ואז יכול לקרות מצב שלא הספקנו
לעשות את כל שלושת השינויים הללו. נסתכל על מצב בו קרסנו באמצע, ומה קורה למערכת הקבצים שלנו עם הדיסק שלנו:

| inode Bmap | Data Bmap | inodes | Data Blocks |
| :--- | :--- | :--- | :--- |
| [ ][ ][ ][ ][ ][ ][ ][ ] | [ ][ ][ ][ ][ ][ ][ ][ ] | [i[v2]] | [Da] [Db] |

**1. נניח וקרסנו לאחר כתיבה אחת:**
אנחנו עושים בסך הכל שלוש פעולות (הסדר שלהן לא חשוב, ויתבצעו באין בכל סדר שנבחר) ואחרי אחת הפעולות קרסנו.
**(i) נניח וקרסנו לאחר עדכון ה-data bitmap** – כלומר, מתוך שלושת העדכונים, הכתיבה הראשונה שביצענו הייתה עדכון
ה-data bitmap ומיד לאחר מכן קרסנו.
הגענו למצב שהוא סוג של ליג' בזיכרון. סימנו ב-data bitmap שהבלוק הספציפי הזה תפוס, אבל לא עדכנו אף אחד
להשתמש בבלוק הזה. כלומר, אין אף inode שמשתמש בבלוק הזה. אז יש פה ליג' בזיכרון- זה בלוק מבוזבז שמסומן כתפוס
ואף אחד לא משתמש בו. כשנעלה את המחשב מחדש, לא נדע שקרסנו באמצע הפעולה, אין לנו דרך לדעת זאת, והגענו למצב לא
תקין של מערכת הקבצים שלנו.
– המסקנה: הפעולה הראשונה שלנו לא יכולה להיות כתיבה ל-data bitmap, כי אם נעשה זאת ואז נקרוס, נהיה במצב
לא תקין. אסור לנו להתחיל בפעולה הזו.

**(ii) נניח וקרסנו לאחר עדכון ה-inode** – כלומר, הפעולה הראשונה שלנו היא עדכון ה-inode לגירסה המעודכנת שלו, ולאחר
מכן נקרוס. כעת נוצרה לנו בעיה חמורה יותר. עדכנו את ה-inode כלומר עדכון itxt שיצביע על הבלוק של הדאטה, אבל לא
כתבנו כלום לדאטה וגם לא כתבנו שהדאטה תפוס בכלל. כלומר ה-inode מצביע לדאטה כלשהו שהוא זבל.
כשהמחשב יעלה מחדש, אם מישהו יבוא וינסה לקרוא את הקובץ הוא יחשוב שהכל תקין, כשבפועל יהיו בו נתונים אחרים.
כמו כן, מישהו אחר יכול לבוא ולתפוס את ה-data block הזה כי לא מעודכן שהוא תפוס, ויהיו לנו שני inodes שמצביעים
לאותו data block וזו בעיה.
– המסקנה: הפעולה הראשונה שלנו לא יכולה להיות כתיבה ל-inode, כי אם נעשה זאת ואז נקרוס, נהיה במצב לא תקין.
אל גם אסור לנו להתחיל בפעולה הזו.

**(iii) נניח וקרסנו לאחר עדכון ה-data block** – כלומר, הפעולה הראשונה תהיה כתיבה ל-data block.
באופן כללי נשים לב שבמקרה זה שאין בעיה. נניח וכתבנו את הדאטה לבלוק, וקרסנו. אנחנו מצפים שהנתונים יאבדו, אבל מערכת
הקבצים שלנו נשארה קונסיסטנטית – איבוד הנתונים יקרה בכל מקרה. מה שנכתב הוא חסר משמעות, זה כאילו לא ביצענו את
הפעולה. כשהמחשב יעלה מחדש, אף אחד לא מצביע לדאטה הזה, הדאטה הזה עדיין מסומן כפנוי, מערכת הקבצים שלנו עדיין
במצב תקין.
– המסקנה: מבין שלושת הכתיבות, ניתן להסיק כי הפעולה הראשונה שאנחנו חייבים לבצע (פיזית על הדיסק) היא כתיבה של
הדאטה. כשאנחנו עושים כמה פעולות על הדיסק, הן נשלחות אליו כסט פעולות והוא יכול לסדר אותן מחדש ואנחנו לא יכולים לשלוט
בסדר. פה הרעיון הוא שאנחנו חייבים לשלוט בסדר ולוודא שפיזית קודם כל ייכתב הדאטה ואז שאר הנתונים.

פה קרסנו לאחר פעולה אחת מה יקרה אם נקרוס לאחר שתי פעולות?
**2. נניח וקרסנו לאחר שתי כתיבות:**
**(i) נניח וקרסנו לאחר עדכון ה-data bitmap ועדכון ה-inode** – עדכנו את ה-bitmap לכך שהבלוק תפוס, ואת
ה-inode שיצביע על הבלוק של הדאטה. מערכת הקבצים אמנם נראית תקינה, אך יש לנו הצבעה לערך מזובל. אבל אנחנו לא
יודעים שהנתונים מזובלים. כשהמחשב יעלה מחדש, אם מישהו יקרא את הנתון הוא יחשוב שזה התוכן של הקובץ.
– המסקנה: שתי הפעולות הראשונות שלנו לא יכולות להיות כתיבה ל-data bitmap ועדכון ה-inode כי אם נעשה זאת
ואז נקרוס, נהיה במצב לא תקין. אסור לנו להתחיל בשתי הפעולות הללו.

**(ii) נניח וקרסנו לאחר עדכון ה-inode וה-data block** – הבעיה כאן שה-data bitmap עדיין מסמן שהבלוק הזה
פנוי ומישהו אחר יכול להשתמש בו בהמשך וקורה מצב שבו inode שלנו מצביע לבלוק שלא מסומן כתפוס ב-bitmap, וזו בעיה
במערכת הקבצים. המסקנה: שתי הפעולות הראשונות שלנו לא יכולות להיות אלו.

**(iii) נניח וקרסנו לאחר עדכון ה-data block וה-data bitmap** – הבעיה שתהיה כאן היא ליג' זיכרון.
כלומר יש בלוק דאטה עם נתונים, שמעודכן שהוא תפוס, אך אף אחד לא מצביע אליו.

- מה שניתן לראות פה, זה שלא משנה באיזה סדר נעשה את הפעולות, אנחנו בבעיה.
אנחנו יכולים לקרוס אחרי פעולה אחת של כתיבת הדאטה, אבל אם קרסנו אחרי שתי פעולות – אין שום סדר שבו נוכל לבצע את
הכתיבות כך שמערכת הקבצים תישאר במצב תקין.
------------------------------------------------------------------------------------------------------------------
אז יש לנו פה בעיה שנקראת **crash consistency** ואנחנו רוצים להתמודד עם קריסה.
המטרה שלנו היא לקחת את מערכת הקבצים ולהעביר אותה ממצב תקין אחד למצב תקין אחר באופן אטומי.
מה שמעניין אותנו היום זה לא רק העניין שיש פגמים, לא מעניין אותנו אם אבדו נתונים, מעניינת אותנו אך ורק התקינות של מערכת
הקבצים. אם משתמש איבד את הנתונים זה לא מעניין אותנו, אנחנו לא יכולים למנוע שהם יאבדו אם הנתונים לא נכתבו. אנחנו רוצים למנוע
מצב בו למשל inode מצביע לנתונים מזובלים, שיהיה bitmap שיהיה מצומן בצורה לא נכונה וכו'.

אבל, אנחנו לא יכולים לכתוב יותר מבלוק אחד בו זמנית, ועדיין רוצים שהפעולה שלנו תתבצע באופן אטומי.
יש לנו 2 פתרונות:
**1. File system checker (fsck)** – תוכנית שקיימת בלינוקס (גם בווינדוס). הגישה: ניתן לבעיות לקרות ונתקן אותן אחר-כך.
אנחנו לא יכולים לעשות כמה כתיבות במקביל, אז נעשה אחרי זה סריקה ונבדוק אם קרו בעיות.
הכלי הזה בלינוקס: אם הייתה קריסה, אז בעליית המחשב הוא יעבור על הדיסק ויבדוק את המצב של הדיסק. לא כל בעיה
אפשר לבדוק, אבל הרבה פעמים הוא יכול לתקן. אך אם מערכת הקבצים שלנו נראית תקינה ויש בעיה, הוא לא יוכל לתקן אותה.
למשל: נניח ויש לנו inode שמצביע ל-דאטה כלשהו, בלי data block שנכתב לשם, וב-bitmap הדאטה הזה מסומן כתפוס.
כלומר מצב מערכת הקבצים נראה תקין, אף לא כתבנו את הדאטה לדאטה בלוק בפועל. יש שם זבל.
את המצב הזה הכלי הנ"ל לא יכול לגלות.
אבל אם inode מצביע לדאטה כלשהו והדאטה הזה לא מסומן כתפוס, את זה הוא יכול לגלות.
כלומר המטרה של הכלי הזה היא לבדוק שה-metadata שלנו תקין. כלומר שאם אנחנו מסתכלים על מערכת הקבצים באופן מנותק-
אין דברים לא עקביים. כל בעיה אחרת, נצטרך לפתור בצורה אחרת (לדוגמא – לכתוב קודם כל את הדאטה, לוודא שנכתב תקין
ואז לעדכן את כל ה-metadata). ניתן לפתור את כל הבעיה ע"י כתיבת הדאטה קודם, ואז שימוש בכלי זה, אך זה יהיה
מאוד יקר.

**הפעולות ש-file system checker יכול לבצע:**
1. הוא יכול לבדוק בלוקים פנויים. נניח הוא עובר על כל ה-data bitmap ובודק אם כל בלוק שמסומן כתפוס, יש inode
שמצביע אליו. אם אין, אז אל פנוי והוא מסומן כפנוי (אם במקרה סימנו תפוס וקרסנו לפני שעדכנו inode להצביע אליו).

2. הוא יכול את מצב ה-inodes באופן כללי. נניח וקרסנו בזמן כתיבה ל-inode ויש נתונים לא תקינים, אז הוא יכול לבצע
בדיקות שפיות (לראות שהספר בלוק כתוב נכון ושכל ה-inodes כתובים בסדר וכן כל הנתונים שלהם.
לדוגמא, אם עבר על כל מערכת הקבצים ובדיקה שבכל inode כתוב מספר הלינקים הנכון (כמות השמות שיש לו. למשל שלא יקרה
מצב בו כתוב שיש לו 5 שמות אבל הוא מופיע רק 4 פעמים, או להיפך) ואז יתבצע מעבר על כל התיקיות וכל ה-inodes וכל
ההיררכיה וגם על ה-inode bitmap).

3. הוא יכול לבדוק האם יש שכפולים (duplicates) – בדיקה האם יש שני inodes שמצביעים לאותו דאטה בלוק.
אם כן, אז יש שתי אפשרויות לפתרון: או שנשכפל את הבלוק וכל אחד יצביע לדאטה משלו, או שאפשר למחוק את הבלוק ולהגיד
אותו משני ה-inodes. שני המצבים לא אידיאליים אבל אנחנו צריכים לקבל החלטה.

הוא עושה עוד כל מיני בדיקות על ה-metadata.
יש שתי בעיות עם הפתרון הזה: 1. אנחנו צריכים להכיר את מערכת הקבצים לעומק. זה לא פתרון גנרי. לכל מערכת קבצים
שעובדת באופן שונה מזו שדיברנו עליה, נצטרך לכתוב כלי חדש שעובד אחרת לגמרי. לכל מערכת קבצים תהיה פעולה שונה.
2. זה נורא איטי. אם פעולה אחת נכשלה, אנחנו צריכים לסרוק את כל מערכת הקבצים ולתקן את כולה. מעבר על כל התיקיות
שנתן בדיסקים של היום זו פעולה שלוקחת כמה שעות. זה לא דבר שנרצה שיקרה כל פעם שהמחשב קורס. כי אולי יש בעיה
ובדרך כלל הבעיה היא נקודתית (ביט אחד שהוא לא נכון וכו') ובגללו אנחנו צריכים לעבור על כל מערכת הקבצים).
– הפתרון הזה עובד, אך לא אידיאלי.

פתרון שהוא קצת יותר אידיאלי:
**2. Journaling (write-ahead logging)** – אם יש לנו בעיה עם קריסה באמצע ואנחנו רוצים שזה יהיה אטומי, בואו
נפתור את זה מראש. נוסיף עוד עבודה קטנה לכל פעולה בשביל שהשחזור יהיה יותר קל.
הרעיון: ניקח שטח בדיסק, שהוא חלק מהדיסק עצמו, ונכתוב אליו את תיאור הפעולה שלנו (את הפעולה שאנחנו רוצים לעשות – לאיזה
inode אנחנו רוצים לעדכן, לאיזה דאטה בלוק אנחנו הולכים לכתוב את הדאטה וכו').
כל זה נכתב ליומן שלנו שנקרא ה-journal ומה שנכתב נקרא ה-note.
רק לאחר שכתבנו את ה-note, נלך למערכת הקבצים עצמה ונבצע את הפעולה בפועל.

למה זה טוב? כי אם קרסנו בזמן שכתבנו ל-journal, זה לא נורא, לא קרה כלום ולא שינינו כלום במערכת הקבצים, היא
נשארה כפי שהייתה לפני כן, נשארה תקינה.
לעומת זאת, אם סיימנו לכתוב, כלומר ה-note שלנו נכתב בהצלחה ואז קרסנו בזמן הכתיבה לדיסק (את התוכן למערכת
הקבצים), אז בשחזור כל מה שנצטרך לעשות זה להסתכל על ה-journal ולראות מה כתוב בו למשל: רצינו לכתוב ל-inode
מספר 4.. ואז נלך ונבצע את הפעולה מחדש, כלומר נעדכן רק את הפעולה הזו ולא נצטרך לסרוק את כל הדיסק.

ה-journal שלנו הוא חלק מהדיסק (כמו כלשהו ששמור לנו את הנתונים) ואנחנו זוכרים לאן משתמשים (נמצאים אותנו לפי הסדר,
כל פעם שאנחנו מוסיפים עוד- אנחנו כותבים אותו איפה שנעצרנו בפעם האחרונה). הוא כמו מערך שאנחנו ממלאים אותו לפי
הסדר מהאובייקט הראשון לאחרון.
נניח ואנחנו רוצים לכתוב את הנתונים שלנו, מה שאנחנו כותבים ל-journal נקרא טרנזקציה.
אנחנו כותבים טרנזקציה ששומרת את הפעולה שאנחנו רוצים לעשות. כדי להבדיל בין טרנזקציה ב-journal אנחנו כותבים
כמה ביטים מיוחדים שנקראים Txb ומציינים את תחילתו של note חדש (תיאור פעולה חדשה). לאחר מכן אנחנו מתחילים

לכתוב את כל הנתונים הרלוונטיים לפעולה (ה-metadata, ה-inode החדש, ה-bitmap החדש) ואז את ה-data ואז
(מה שאנחנו רוצים לכתוב לבלוק) ואז בסוף עוד סט של ביטים מיוחדים שנקראים Txe שמסמנים את סיום הטרנזקציה.

Journal
| Txb | metadata | Data | Txe | Txb | metadata | Data | Txe |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| Tx1 | Tx2 |

זה ה-note שלנו. ואם אנחנו מוסיפים עוד פעולה אז נוסיף עוד note.
אם נקרס ונחזור לקרוא את ה-journal, אנחנו מחפשים טרנזקציות שלמה.
אם לא מצאנו את ה-Txe, זה אומר שקרסנו בזמן כתיבת הטרנזקציה.
אז אין מה לשחזר אותה, כל הנתונים הלכו וזה כאילו הפעולה לא בוצעה בכלל. אבל אם כן מצאנו, אז הפעולה בוצעה כי אנחנו
יודעים לשחזר אותה באופן מלא.

ניקח את הדוגמא שלנו עם ה-journal:
אנחנו רוצים לעשות טרנזקציה כלשהי לקובץ. אז מה שנעשה ראשית – נגדיר **checkpoint**: זו נקודת הזמן שבה אנחנו יודעים
בוודאות שהטרנזקציה שלנו נמצאת ב-journal. אנחנו לא יכולים פשוט לכתוב ולהו, אנחנו צריכים לקרוא ל-fsync לוודא
לסנכרון (כתבנו נתונים, נחכה שהם ייכתבו ורק אז נמשיך).
אנחנו כותבים ל-journal את כל הטרנזקציה (זה נקרא journal write) ומחכים עכשיו שזה ייכתב בפועל
(fsync), מחכים לדיסק שהוא יאמר באמת שנכתב את הנתונים פיזית לדיסק.
ברגע שהנתונים נכתבו, אנחנו קוראים לזה checkpoint. זו הנקודה שבה אנחנו יודעים שהטרנזקציה שלנו נכתבה.
עכשיו שאנחנו יודעים שה-note שומר את הפעולה נכתב, אנחנו יכולים לכתוב לדיסק את הנתונים.
כי עכשיו אנחנו יודעים שאם נעדכן דברים בדיסק ונקרוס, זה לא נורא, הטרנזקציה כבר באופן מלא ב-journal, כאשר נעלה
מחדש פשוט נקרא אותה משם ונוכל לבצע אותה.

נניח ושנינו זאת. עדיין יש בעיה. מה אם אנחנו קורסים בזמן הכתיבה ל-journal: כתבנו את כל הטרנזקציה והנתון שהוא תיכתב
לדיסק בפועל. אבל נזכור שכשאנחנו כותבים נתונים לדיסק, הם לא בהכרח נכתבים בסדר שאנחנו בחרנו. אנחנו כותבים דברים
והדיסק משנה את הסדר לפי העדיפויות שלו.
יכול לקרות מצב בו ה-Txb ייכתב, ה-inode ייכתב וכן גם הדאטה, ה-Txe ייכתב ונקרוס בלי שנכתב ה-bitmap.
מה שנעשה כדי לטפל בבעיה הזו: כשאנחנו כותבים ל-journal, נכתוב את כל הנתונים שלנו ללא ה-Txe ונחכה (כל השאר
כמו פוגעת לנו בביצועים אך אין ברירה). ברגע שנכתב הכל, נעשה fsync ונחכה שהפעולות באמת ייכתבו לדיסק.
רק לאחר שכל הנתונים האלו נכתבו לדיסק נכתוב ב-journal באופן תקין, נכתב את ה-Txe. ורק אז נוכל להמשיך.
עכשיו זה לא משנה לנו אם ההארד דיסק ישנה את הסדר של הכתיבות.

כעת יש לנו שלושה שלבים לכל פעולה שאנחנו עושים בדיסק:
1. כתיבה של כל הנתונים ל-journal (Txb, metadata, data) והמתנה.
2. לאחר שהנתונים נכתבו וסיימנו להמתין, אנחנו עושים commit (מוודאים את הטרנזקציה, כותבים את ה-Txe).
3. לאחר שלב 2 אנחנו שוב מחכים. אחרי שחיכינו מעט וכל הנתונים נכתבו, אנחנו יודעים שהטרנזקציה היא committed
כלומר הגענו לנקודת ה-checkpoint. כל הנתונים נמצאים באופן תקין ב-journal ואז אפשר ללכת לעדכן את הטרנזקציה לכתוב
את הנתונים לדיסק, וקריסות פחות מעניינות אותנו כי אנחנו תמיד יכולים לשחזר את הפעולה גם אם נקרוס.
- אם קרסנו בזמן כתיבת ה-note, כלומר יש note שאין לו Txe, אז מבחינתנו זה כאילו ה-note הזה לא קיים.
- אם קרסנו אחרי שה-Txe נכתב לומר בשלב ה-commit אז אין בעיה כי הטרנזקציה שלנו כבר committed, היא
נמצאת ב-log, כל הנתונים הדרושים לביצוע הפעולה נמצאים ב-journal וסימן שגמור שהמחשב יעלה אנחנו רק צריכים לעבור
על ה-journal ולשחזר את מה שכתוב שם. זה נקרא גם **redo logging**, אנחנו כותבים מן היסטוריה של פעולות וכאשר
המחשב קורס אנחנו פשוט עוברים על ההיסטוריה הזו ועוברים על הפעולות אחת אחרי השנייה ומבצעים אותן בשביל לתקן את
מערכת הקבצים.

ה-journal הוא סופי, לא יכול להיות אינסופי בגלל זיכרון. הבעיה היא שככל שה-journal שלנו גדול יותר, ייקח לנו יותר זמן
להתאושש מקריסה. אם המחשב קרס, אנחנו עוברים על ה-log, אנחנו צריכים לעבור על כל הפעולות.
אם ה-log מאוד גדול זה ייקח המון זמן.
מצד שני אם ה-log מאוד קטן אז הוא הוא יתמלא מהר.
אנחנו רוצים במערכת journal תקינה – נניח וכתבנו מספר פעולות- journal וגמרנו המקום. אם הפעולה הראשונה שכתבנו
(תחילת ה-journal) התבצעה בהצלחה, אנחנו רוצים למחוק אותה ומהיום והלאה לשים במקומה note חדש, כי אנחנו לא צריכים
אותה. כלומר נחזור באופן ציקלי.
לשם כך עלינו להוסיף מבנה קטן ל-journal שנקרא **journal superblock**. הוא מכיל שני מצביעים:
האחד- מצביע להתחלה, איפה הטרנזקציה הראשונה שצריך להתייחס אליה (טרנזקציה שלא בוצעה בהצלחה ולא נכתבה
לדיסק). השני- מצביע לסוף היומן (המצביע השני לא כל-כך רלוונטי, הכי חשוב זה המצביע הראשון שאומר לנו מה ההתחלה).
אם הוספנו טרנזקציה, נעדכן את המצביע האחרון.
אם טרנזקציה מספר 1 הסתיימה בהצלחה (כל הנתונים
בדיסק עודכנו וסיימנו) הפעולה התבצעה במערכת הקבצים
בהצלחה), אז המצביע הראשון של ה-superblock יהיה ל-
Tx2.

Journal
| Journal Super | Tx1 | Tx2 | Tx3 | Tx4 | Tx5 | Tx6 |
| :--- | :--- | :--- | :--- | :---: | :---: | :---: | :---: |
| | ✓ | ✓ | | | | |
| | | | ↑ | | | |

אם סיימנו טרנזקציה מסוימת, נעדכן את המצביע הראשון שיצביע לטרנזקציה הבאה. כך כנהליך השחזור, אם המחשב יקרוס
ויעלה שוב, הוא לא יצטרך להתחיל מההתחלה ולעדכן את הכל, הוא יוכל להתחיל ישר מ-3. כלומר, הוא יקרא את ה-
superblock וידע מאיפה להתחיל.
כל שנוסיף טרנזקציות, ברגע שייגמר לנו המקום פשוט נחזור להתחלה ונכתוב שם, באופן ציקלי.
בביטול הגענו ל-journal אינסופי, הוא יכול להתמלא לחלוטין אבל ברגע שנסיים פעולות ננקה אותן ונוכל להוסיף נתונים חדשים.

אנחנו צריכים כעת לעדכן את המצביעים של הטרנזקציות, אבל זה לא דחוף.
אם למשל המצביע של ה-superblock מצביע על Tx1 למרות שהוא כבר בוצעה – במצב זה, אם המחשב יקרוס פשוט
נצטרך לשחזר טיפה יותר כשהמחשב יעלה, וזה לא נורא.
ברגע שסיימנו פעולה וטרנזקציה מסוימת נכתבה כבר, גם אם נחכה דקה עם עדכון המצביע של הסופר בלוק- זה לא נורא.
הכי גרוע זה שנשלם קצת יותר כשהמחשב יעלה מחדש. ניתן לעשות זאת במועד קצת יותר מאוחר, כשההארד דיסק פחות עמוס.
זה יפגע מעט בביצועים שלנו.
פעולת שחרור הטרנזקציה נקראת Free. זה השלב הרביעי בפרוטוקול שלנו.

1. Journal write
2. Journal commit
3. Checkpoint
4. Free

עכשיו נשארה לנו בעיית ביצועים קטנה. אם נשים לב- אנחנו כותבים כל data פעמיים.
אם אנחנו רוצים לבצע עכשיו כתיבה גדולה של 50mb, אנחנו הולכים ל-journal וכותבים אליו את הנתונים.
ה-metadata שלנו נורא קטן בדרך כלל (כמה בתים, 2-3 בלוקים). אבל אנחנו כותבים דאטה מאוד גדול ליורן, מחכים שהוא
ייכתב ואז כותבים אותו עוד פעם לדיסק, מחכים שהוא ייכתב לדיסק ואז הולכים וכותבים את הכל לדיסק.
יוצא מצב שכתבנו את הדאטה המאוד גדול פעמיים לדיסק. אבל אם נזכור, בהתחלה אמרנו שאין בעיה להתחיל מפעולת הכתיבה
של הדאטה לדיסק, כי אם המחשב קורס לאחר ביצוע הפעולה הזו בלבד, לא קרה כלום.
אז אנחנו יכולים לכתוב את הדאטה שלנו להארד דיסק בנפרד, ולא יקרה כלום אם המחשב יקרוס.
כך נוכל לעשות את הרבה יותר פשוט: לא נכתוב אליו כל את הדאטה שלנו, אלא רק את ה-metadata (ללא ה-Txe).
זה נקרא **metadata journaling**. נכתוב ביומן רק את השינויים שאנחנו עושים במערכת הקבצים עצמה, ואת הדאטה
נכתוב ישירות לדיסק (זה גם נקרא ordered journaling).
ברגע שסיימנו את הכתיבה של ה-metadata והדאטה, נכתוב את ה-Txe. ברגע שזה התבצע, יש לנו את כל העדכונים של

ה-metadata וגם הדאטה נמצא בוודאות בדיסק. אם קרסנו לפני כתיבת ה-Txe, אולי לא נורא, לא פגענו בתקינות של מערכת
הקבצים, כי מותר לנו לכתוב את הדאטה. אם קרסנו אחרי, אז עדיין הכל תקין, ה-inode ועדכון ה-bitmap שלנו שנמצאים ב-journal
וכתובים במדויק. הדיסק כבר יהיה אמין כבר לכל בדיסק ואחר כך נעדכן אותן בהדרגה.
*** נשים לב שכשאנחנו עושים זאת אנחנו חייבים קודם כל לכתוב לדיסק את הדאטה ובו זמנית לכתוב את
ה-metadata ליומן, ונתונים שהכל נכתב ורק אחר כך לכתוב את ה-Txe.

* Final protocol:
1. Data write
  * Write data to final location, wait for completion
2. Journal write
  * Write transaction contents (TxB and metadata), wait for completion
3. Journal commit
  * Write transaction commit block (Txe)
  * Wait for write to complete → transaction is **committed**
4. Checkpoint
  * Write metadata to final locations
5. Free
  * Later, mark transaction as free in journal superblock

זהו הפרוטוקול הסופי שלנו. הסדר בין 1 ל-2 הוא לא משנה.
קודם כותבים את הדאטה לאן שצריך (למיקום שלו בדיסק) ולאחר מכן
כותבים את התוכן של הטרנזקציה.
ב-1,2 שניהם כתוב שאנחנו מחכים לסיום אבל בפועל אנחנו מחכים
רק פעם אחת, ששניהם ייכתבו בסדר כלשהו לא חייבים לחכות אחרי
כל פעולה בנפרד).
לאחר מכן Step 3: כה הסתיים, אנחנו עושים commit כלומר
כותבים Txe ומחכים שזה יסתיים.
ברגע שזה קרה, הפעולה התבצעה.
בעצם כבר בשלב 3, אנחנו יכולים לחזור למשתמש. מבחינת תוכנית המשתמש, הפעולה התבצעה. אנחנו יכולים להודיע לו
שהכתיבה התבצעה בהצלחה והוא יכול להמשיך לרוץ (באופן רגיל). כלומר הפעולה שהוא רצה לבצע, בטוח תהיה בדיסק.
גם אם נקרוס, אנחנו נשחזר את הפעולה והיא בטוח תהיה על הדיסק.
השלב הרביעי: כתיבת כל הנתונים בפועל לדיסק (השלב הרביעי בפרוטוקול הסופי הוא קצת יותר קטן, כי צריך לכתוב רק את
ה-metadata לדיסק, שכן הדאטה כבר כתוב בו).
בשלב החמישי – משחררים את הטרנזקציה מהיומן ומעדכנים את הסופר בלוק.

------------------------------------------------------------------------------------------------------------------
**LFS( Log-structured File System)**:
עכשיו כשיש לנו את זה, נסתכל על מערכת קבצים קצת שונה ממה שדיברנו עליה עד עכשיו.
מערכת הקבצים הזו נקראת LFS. הרעיון שלה: הזיכרונות שלנו הולכים וגדלים. רוב הפעולות שאנחנו מבצעים את הכתיבות על
הדיסק הן פעולות כתיבה. כי כשאנחנו קוראים נתונים, אזי יש לנו cache ה-inodes, bitmaps, data הרבה
פעמים נשארים כבר בזיכרון. זה הופך את פעולות הקריאה להרבה יותר קלות ולכן פעולות הכתיבה הן הבעיה העיקרית שלנו.
כשאנחנו רוצים לשפר את הכתיבות ניתן לאמר כנתון אולי עדיין יש צורך בכתיבות. זמני פעולות קריאה שאנחנו יכולים לקרוא
בפעם אחת מיליון inodes מהזיכרון ולהו, להחזיק אותם.
בעיה נוספת במערכת הקבצים היא שמערכת הקבצים בכלל לא בנויה בצורה שתואמת את מה שדיברנו על דיסקים.
אנחנו הולכים לקרוא/לכתוב עכשיו קובץ באופן סדרתי, אף זה לא בהכרח אומר שזה יבוצע סדרתית על הדיסק.
אפילו אם יש נסח של 100 טרנזיט, בכל פעם שאנחנו כותבים קובץ – לכתוב את הדאטה שלו ולחזור לעדכן את ה-inode ואת
ה-data bitmap עוד. אפילו פעולה שהיא יחסית סדרתית על הדיסק, הופכת להיות אקראית כי אנחנו מבצעים קפיצות וגם
מערכת הקבצים שלנו איטית יותר, הן לא עושות שום דבר שיעזור ל-raid להיות אופטימלית ועל (שכן raid עוזר
בכתיבות סדרתיות).

LFS מציעה לקחת את הרעיון של היומן, וזו תהיה מערכת הקבצים שלנו. כלומר, נוותר על כל השאר. נשתמש רק ביומן.
כל פעם שאנחנו עושים פעולה, פשוט נכתוב אותה. לא צריך inode bitmap וכו', פשוט נכתוב נתונים עוד ועוד..
למה זה טוב? אם נסתכל על הדיסק שלנו כזמן אחד ארוך, כאשר אנחנו מבצעים זוגות של append, כאשר המשתמש ירצה לבצע
פעולה, לא נכתוב את הפעולה ישר לדיסק, אלא נחזיק משהו שנקרא segment (זה יהיה בזיכרון, ב-RAM). זה כמו מערך
בזיכרון. כל פעם שהמשתמש יעשה פעולה, נשמור את הפעולה ב-RAM, ונחכה אותה לסגמנט שלנו.
כך נכתוב את כל הפעולות שמשתמש מבצע לתוך הסגמנט. ברגע שהסגמנט יתמלא, נכתוב את כולו לדיסק באופן רציף.

ואז ככל שהסגמנט שלנו יותר גדול, אנחנו עושים פעולות סדרתיות על הדיסק.
לא סתם נכתוב את כל הפעולות בבת אחת אלא גם כל פעולה תהיה באופן רציף. אלו אותן פעולות כתיבה גדולות של נתונים, שאת
כולן אנחנו נבצע באופן רציף. ואז אנחנו מנצלים את התכונות של הדיסק שדיברנו עליהן (שפעולות רציפות הן הרבה יותר קלות).
אחד היתרונות הכי גדולים של LFS (או כל מערכת קבצים שמשתמשת ברעיון הזה) הוא שגם כתיבות אקראיות הופכות להיות
סדרתיות. בקצב בו המשתמש הולך לקובץ וכותב את הבית הראשון ואז את הבית ה-500 וכן הלאה, לנו זה
לא משנה כי כל הנתונים נכתבים ל-סגמנט ואז אכפת לנו מסדר. אנחנו פשוט כותבים את כל הפעולות שהוא ביצע ואז כותבים את
זה לדיסק במקום אחד.
הפכנו פעולות אקראיות לסדרתיות, שיפרנו את הביצועים באופן משמעותי.

דוגמא: נניח ואנחנו רוצים לבצע עדכון פשוט לשני קבצים מסוימים. כדי לעדכן את הנתונים שלו אנחנו צריכים לעדכן את ה-
inode ואת ה-data block שלו. עכשיו נסתכל על הדיסק וכמו הישן שלנו- נראה מה יש בו.
הענין הוא שלא משנה איזה משתמש עכשיו ולא משנה מה הוא כותב ל-data, אנחנו כותבים את זה לסדרתי.
תמיד נכתוב את הנתונים תוך כדי (דאטה וגבי ה-מהויה שלהם.
בתור התחלה נניח שהדיסק הוא אינסופי.
בשלב הפעולה שלנו, אנחנו פשוט רושמים את ה-data ואת ה-inode המעודכנים לדיסק ברצף.
כל עדכון ייכתב אחד אחרי השני לפי הסדר.

| In-memory Segment |
| :---: |
| [data1] [inode1] [data2] [inode2] |

| Disk |
| :--- |
| Existing data | [data1] [inode1] [data2] [inode2] |

זה לא ילך עדיין, אף אם נסחור על הדיסק מההתחלה ועד הסוף ונקרא את כולו, נוכל לדעת מה התוכן של כל הקבצים בו.
יש לנו log של שינויים.
זה הרעיון הבסיסי. אבל זה לא יהיה לא יעיל עדיין דיברנו על סגמנט. אם הדיסק כל הזמן מסתובב וכל לכתוב בלוק יחיד זה לא
יעיל.
ב-lfs משתמשים במה שנקרא **write buffering**, סגמנט בזיכרון ב-RAM שמתאים אותנו. כל פעם שהמשתמש עושה
פעולה על מערכת הקבצים אנחנו לא מבצעים את הפעולה על הדיסק אלא שומרים אותה בזיכרון.
ברגע שהסגמנט התמלא, נכתוב את כולו בכתיבה אחת סדרתית לדיסק. כל זה זו פעולה אחת לדיסק.
אם הסגמנט שלנו גדול אז זו פעולה סדרתית שאנחנו כותבים לדיסק ולכן היא מאוד יעילה.
לא משנה איזה פעולות המשתמש עשה, אנחנו עושים את הכתיבה סדרתית לחלוטין והופכים את הפעולות האלו להיות יעילות.

אין פה בלוק ייעודי ל-inode bitmap או data bitmap, כל פעם עוברים על הדיסק וכתובים את הנתונים משמאל לימין.
בעיה שנוצרת אינה בהמשך: השארנו מאחורה לכל. כשעשינו את הכתיבה הראשונה כתבנו את ה-inode הראשון, ועכשיו
שכתבנו את הגרסה המעודכנת שלו, אל הכתיבה הראשונה שכתבנו היא לא רלוונטית כי אלו נתונים ישנים. מתבצעת הוספה של
בלוק חדש והמידע הישן נשאר. אל אנחנו משאירים מאחורינו לכל, שינויים לכל, שפשוט אינם בהמשך.

עולה השאלה – כמה buffering לעשות? מה צריך להיות גודל הסגמנט שלנו?
ככל שנגדיל את הסגמנט ונשמור יותר נתונים בזיכרון ורק אז נכתוב לדיסק, הביצועים שלנו יהיו יותר טובים.
אם נשמור ג'יגה בכל פעם ואז נכתוב לדיסק, זה יהיה הרבה יותר טוב מאשר אם נעשה זאת כל 1kb.
כך נקבל ביצועים סדרתיים יותר טובים.
מצד שני, ככל שהסגמנט שלנו יותר גדול, ייקח לנו יותר זמן עד שעדכון דברים. המשתמש יכול לכתוב נתונים ואז המחשב יקרוס
והכל ייאבד.
אנחנו צריכים לנהל את גודל הסגמנט הזה בצורה יעילה.

נעשה טיפה חישובים כדי להבין מה גודל הסגמנט הרצוי:
יש לנו דיסק שעובד במהירות של 100 MB/SEC
(זו המהירות המקסימלית שלו. זמן העברת הנתונים שלו, זה נקרא גם transfer rate, peak rate).
עשינו כבר חישובים על דיסקים בעבר וראינו שאנחנו מוסיפים את ה-seek וה-rotation, מקבלים קצב הרבה יותר נמוך.
כשאנחנו באים למערכת הקבצים הזו של Lfs, אחד השיקולים שלנו זה איזה קצב אנחנו רוצים לקבל.
הקצב האידיאלי של הדיסק הוא 100, MB/SEC הוא יכול לכתוב 100 MB/SEC באידיאל, אבל אי אפשר להגיע לאידיאל,
אל אנחנו צריכים להגיד איזה קצב אנחנו רוצים.
אם נדע מה גודל הסגמנט, נוכל לחשב את הקצב האפקטיבי, הקצב האמיתי:
למשל, אם נגיד שגודל הסגמנט הוא 50MB, זה אומר שבכל פעם אנחנו ממלאים נתונים של 50MB בזיכרון, שוב ושוב.
אנחנו עושים הרבה פעולות של 50MB. עשינו כבר חישובים כאלו, של מה קורה אם אנחנו עושים הרבה פעולות של קריאות
וכתיבות עבור גודל מסוים.
פה זה אותו דבר, המהירות שנקבל – תלויה בגודל הסגמנט.
אפשר לקחת את הגודל הזה של 50MB ולחשב לפי הנוסחה שלנו לפי ה-seek, rotation, transfer.

אבל כשאנחנו מסתכלים על מערכת הקבצים של Lfs, אנחנו מסתכלים על אותו חישוב אך מהכיוון השני:
נגיד הפוך: אנחנו רוצים ביצועים של 90MB/SEC, כלומר 90% מהקצב האידיאלי, אז מה צריך להיות גודל הסגמנט שלנו?

זמן ה-positioning (שהוא seek + rotation) הוא 10ms (נתון).
עכשיו אמרנו, נחשב מה צריך להיות גודל הסגמנט עבור ביצועים רצויים של 90mb/sec.

נגיד שהסגמנט שלנו הוא בגודל x (הוא הנעלם שלנו כי אנחנו רוצים למצוא את גודלו).
כמה זמן ייקח לנו לכתוב x מגה בייט?
לפי הנוסחאות שכבר ראינו, הזמן לכתוב x מגה בייט הוא ה-seek (בשניות) + 100/x (לכתוב x מגה בייט בקצב של
100 מגה בייט לשנייה).
$T_{I/O} = T_{seek} + T_{rotation} + T_{transfer}$
$I/O Rate: R_{I/O} = \frac{Size_{transfer}}{T_{I/O}}$

אנחנו רוצים להגיע לקצב של 90mb/sec והנוסחה של קצב זה גודל חלקי זמן .
אם נכתוב x מגה בייט ב-Tx שניות אז הקצב הוא Tx / x.
ולנו מה שאנחנו רוצים שיהיה שווה ל-90.
x הוא ביחידות של מגה בייט, Tx הוא בשניות ולכן x / Tx זה ביחידות של מגה בייט לשנייה, ואם נשווה ל-90 זה יהיה 90
מגה בייט לשנייה (כשילוב של היחידות).

לאחר חישוב נקבל **x = 9 MB**.
לכן אם אנחנו רוצים להגיע לקצב של 90 MB/SEC גודל הסגמנט
צריך להיות לפחות 9MB עבור הנתונים הללו של הדיסק.
כלומר המשתמש עושה פעולות של 9MB.

** בדרך כלל אנחנו לא מחזיקים רק סגמנט אחד, אם נחזיק רק סגמנט
אחד הוא יתמלא ובזמן הכתיבה שלו לדיסק אנחנו צריכים לחכות, אי
אפשר לבצע עוד פעולות, אז בדרך כלל יש משהו שנקרא
**double buffering** – נחזיק שני סגמנטים באותו הגודל, וכאשר אחד מהם ברגע שהוא התמלא וכתוב אותו לדיסק ובינתיים
נמלא את השני, ברגע שהשני התמלא נכתוב אותו לדיסק וכן הלאה. כל פעם רצף החלופות ביניהם.
כלומר אף פעם אנחנו לא מחכים במצב שהדיסק לא עושה כלום. תמיד יש לנו סגמנט מוכן לכתיבה לדיסק.

* Disk transfer rate: 100 MB/s
* Positioning time: 10ms
* Wish to achieve 90 MB/s **effective** rate
* Time to write $X$ MB: $T_X = 0.01 + \frac{X}{100}$ (in seconds)
* **Effective** rate: $R_{effective} = \frac{X}{T_X} = 90$
* $X = \frac{0.9}{0.1} = 9MB$
* Segment size should be at least **9MB**

