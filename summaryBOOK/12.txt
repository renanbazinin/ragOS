מערכות הפעלה – שיעור 12
היום נמשיך לדבר על מנעולים, נבחן אותם קצת יותר לעומק.
כל המנעולים שראינו עד עכשיו, מימשו את כל העקרונות הרצויים של: מניעה הדדית, deadlock freedom והוגנות.
הדבר היחידי שבעייתי במנעולים הללו: בעיית ביצועים. כשהחוט לא תופס את המנעול, הוא נשאר בתוך לולאה ועושה
"spinning" ועקב כך אנחנו מבזבזים זמן מעבד.

```c
int myturn = FetchAndAdd(&ticket);
while (turn != myturn)
    ; // spin-wait

// critical section

turn = turn + 1;
```

נניח וחוט A נמצא בקטע הקריטי, בשלב מסוים כשהוא יקבל context switch וירוץ חוט אחר במקומו, אם יש עוד חוטים שמנסים לתפוס את המנעול ולהיכנס לקטע הקריטי, הם כמובן לא יכולים.
המנעול כרגע נמצא אצל חוט A. אבל החוטים הללו לא יודעים לכך, ולכן הם ממשיכים בלולאה ומנסים לתפוס את המנעול. אבל שום דבר לא ישתנה. הם מבזבזים הרבה מאוד זמן מעבד.

[תרשים: ציר זמן של CPU עם החלפות הקשר (context switches) וזמן מעבד מבוזבז עקב "Spinning on lock"]

בשביל להתמודד עם הבעיה הזו, נוצר במערכת ההפעלה פתרון בצורת קריאת מערכת.

קריאת מערכת שימושית במקרה הזה: yield: קריאת המערכת הזו מוותרת על זמן המעבד שניתן לנו.

```c
while (...)
    yield();
```

כלומר כאשר נקרא ל-yield אנחנו בעצם אומרים למערכת ההפעלה שאנחנו לא מעוניינים בכל הקוואנטה שלנו כרגע, ושנחזור אלינו פעם הבאה. החוט הזה יחזור לתור ויונתן בהמשך.
כלומר הוא הופך מ-running ל-ready.
ואז אם כל פעם נראה שהמנעול תפוס (בתוך לולאת ה-while, בכל אחד מהמנעולים שדיברנו עליהם), במקום לנסות מיד עוד פעם, נקרא ל-yield ונקבל שיפור משמעותי בביצועים.
ברגע שהמנעול תפוס, אנחנו מוותרים על זמן המעבד שלנו ובינתיים מערכת ההפעלה יכולה לתת לחוט אחר לחזור לחוט שנמצא בקטע הקריטי, ולהריץ אותו מהר יותר (הוא יקבל אחוז יותר גבוה מזמן המעבד) ולסיים מהר יותר ולשחרר את המנעול.

קריאת המערכת הזו משפרת את המצב באופן משמעותי, אך זה עדיין לא המצב האידיאלי.
הזמן הזה שרצים כל שאר החוטים שלא מחזיקים את המנעול, הוא זמן מבוזבז.
אם יש לנו 100 חוטים שמשתמשים במנעול ומנסים לתפוס אותו, עדיין ברגע שחוט ראשון מקבל context switch – זה עובר לחוט השני, והוא רואה שהמנעול תפוס אז הוא עושה yield כלומר קריאת מערכת, ואז שוב יש context switch לחוט השלישי שרואה שהמנעול תפוס ועושה yield וכן הלאה.. כלומר יהיו לנו 99 פעמים context switch בקריאת מערכת עד שנחזור חזרה ל-A.
ואז נחזור ל-A, ירוץ, ינצל את הקוואנטה שלו ואז שוב נעשה 99 פעמים context switch עד שנוכל להריץ את החוט הבא, וכן הלאה. אז שיפרנו את הבעיה אבל לא שיפרנו אותה מספיק.

לשם כך יש מנגנון נוסף של מערכת ההפעלה: Futex:
במקום (או בנוסף) לקרוא ל-yield (שהוא פתרון זמני, רואים שהמנעול תפוס, מוותרים על זמן המעבד ויחזרו אליי בהמשך), אם ראינו שהמנעול תפוס, אולי אני פשוט אבקש ממערכת ההפעלה שתודיע לי כשהמנעול מתפנה.
זה לא מנגנון ייחודי למנעולים, זה מנגנון כללי שבעזרתו חוט מסוים "הולך לישון" ומבקש שלא יחלצו אותו עד שקורה משהו שהוא ביקש.

:Futex_wait
קריאת המערכת הזו מקבלת כתובת וערך, בכתובת הזו אנחנו יכולים לדאוג להעביר את הדגל של המנעול, ובערך expected.

```
* futex_wait(address, expected)
* Puts calling thread to sleep if address is equal to expected
```

אנחנו מעבירים את הערך שבעיניינו, כלומר את הערך שאנחנו לא יכולים להתקדם. למשל במקרה הזה נוכל להעביר שם 1 (כי אם יש 1 המנעול תפוס ואנחנו לא יכולים להתקדם).
אם בתוך הכתובת שציינו (בדגל) יש באמת את הערך 1, אז החוט שלנו ילך לישון.
למעשה, זו קריאת מערכת שעושה את הבדיקה הזו באופן אטומי - היא בודקת האם בכתובת שציינו יש את הערך expected, אם כן- החוט שלנו הולך לישון, הוא הופך להיות blocked, הוא לא יקבל זמן מעבד והתזמן לא יתחשב בו עכשיו.

:Futex_wake

```
* futex_wake(address)
* Wakes one thread waiting on address
```

קריאת המערכת הזו יכולה לעזור לנו בעת שחרור המנעול.
היא מקבלת כתובת למשל את הכתובת של הדגל, המנעול שלנו ומעירה חוט אחד שהלך לישון. החוט הזה יתעורר וינסה לתפוס את המנעול (יכול להיות שחוט אחר יקדים אותו).
זה עוזר לנו להעיר חוטים בודדים ולא לתזמן בכלל חוטים כאשר המנעול תפוס.

המנעולים שאנחנו בדר"כ משתמשים בהם הם מנעולים היברידיים:
אמרנו ש-spinning זה לא טוב, אבל זה לא תמיד לא טוב. אם הקטע הקריטי מאוד קצר (מישהו תופס את המנעול ולאחר 2 פעולות משחרר אותו), אז יכול להיות שעד שנזמן spinning, נחכה קצת ועוד רגע הוא יסיים. במיוחד אם יש לנו מערכת עם מספר מעבדים ואז הוא יוכל לרוץ במקביל אלינו בזמן שנעשה spinning. אין טעם במקרה כזה להשתמש במנגנון של Futex וכו', כי זה יהיה יותר בזבזני מאשר לעשות עוד קצת spinning עד קבלת המנעול.
לכן הגישה ההיברידית למנעולים אומרת: כאשר חוט מסוים מנסה לתפוס את המנעול, במימוש שלו נעשה spinning לזמן קצר (נניח 50 פעמים, 100 אלף שניות) ואם לאחר מכן לא הצלחנו, אז נלך לישון ונחכה שיעירו אותנו כאשר המנעול יהיה פנוי.

:Coarse-grained Locking
גישה בשימוש במנעולים שאומרת שיש לנו מנעול אחד גדול, שבכל פעם שנעשים משאבים מסוים- נתפוס את המנעול.
אבל הגישה הזו לרוב לא טובה. אם נקבל אותה לדוגמא של הצומת, אולי זה שקול לצומת שבה יש רק רמזור אחד, רק נתיב אחד שמקבל ירוק וכל השאר אדומים. אבל לאו כל המכוניות בעולם ככה, לפעמים יש אופציות טובות יותר. אולי יש לנו נתיב שרק פונה ימינה ואין טעם לחסום את כל הנתיבים?
בדומה, ייתכן שחוט אחד רוצה להוסיף איבר לראש הרשימה וחוט אחר לסוף הרשימה, הם לא מפריעים אחד לשני ולא משפיעים אחד על השני, אז אולי לא הכי טוב להשתמש במנעול.

:Fine-grained Locking
גישה אחרת ששפיה אפשר לנעול כמה ענפים בנפרד כל עוד הם לא מתנגשים. נבחן את הקוד שלנו בזכוכית מגדלת ונבדוק מה אפשר ומה אי אפשר להריץ ביחד. לא ננעל משאב בכל פעם שעושים עליו פעולה, אלא נתייחס לפעולות שנעשות עליו ולהיפך נבדוק מתי צריכים לנעול. כך נוכל לנעול כמה חוטים לרוץ ביחד כל עוד הם לא מתנגשים.
למשל, נוכל ליצור מנעול לתחילת הרשימה ומנעול לסוף הרשימה וכך שני חוטים יוכלו לרוץ במקביל כי הם לא מפריעים אחד לשני.

:Mutex API
לינוקס מספקת לנו מנעול שמקיים את כל התכונות: מניעה הדדית, deadlock freedom והוגנות.
המנעול הזה נמצא בספריית pthread (הספרייה שאנחנו משתמשים בה עבור חוטים) ובשביל להשתמש במנעול של לינוקס אנחנו מגדירים משתנה מסוג pthread_mutex_t (משתנה מסוג מנעול).

```c
pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;
...
pthread_mutex_lock(&lock); // may fail!
// critical section
pthread_mutex_unlock(&lock);
```

כעת נוכל לקרוא לקריאת המערכת pthread_mutex_lock בשביל לתפוס את המנעול ו-pthread_mutex_unlock כדי לשחרר. ובין לבין נשים את הקטע הקריטי.

נשים לב: קריאות המערכת pthread_mutex_lock ו-pthread_mutex_unlock יכולות להיכשל ולכן יש צורך לבדוק את ערך ההחזר שלהן. כעת נוכל להשתמש במנעול הזה במקומות המתאימים בקוד.

- אתחול מנעול: כדי להשתמש במנעול יש צורך לאתחל אותו ראשית.
נעשה זאת פעם אחת עבור כל מנעול בעת יצירתו, הפונקציה מקבלת את כתובת המנעול כארגומנט ואופציות לגבי המנעול (נעביר NULL כערך ברירת מחדל).

```
* Creation:
int pthread_mutex_init(
    pthread_mutex_t *mutex,
    const pthread_mutexattr_t *mutexattr);
```

- סיום שימוש במנעול: כאשר נסיים להשתמש במנעול, נשתמש בפעולה הבאה:
שמקבלת כתובת של מנעול והורסת אותו (מוחקת אותו), ומערכת ההפעלה משחררת את כל המשאבים שקשורים למנעול.

```
* Destruction:
int pthread_mutex_destroy(
    pthread_mutex_t *mutex);
```

-----------------------------------------------------------------------

בין אתחול המנעול להריסתו, נוכל להשתמש בקריאה הבאה לנעילה:

```
* Lock:
int pthread_mutex_lock(pthread_mutex_t *mutex);
* Acquire lock, block until acquired
```

הקריאה הראשונה מקבלת מנעול והיא לא חוזרת עד שהמנעול לא שלנו. הקריאה תחזיר 0 אם הכל עבד תקין או ערך אחר אם קריאת המערכת נכשלה.

ובקריאה הבאה לשחרור:

```
* Unlock:
int pthread_mutex_unlock(pthread_mutex_t *mutex);
* Release locked mutex
```

אם אנחנו מחזיקים במנעול, נוכל לקרוא לקריאה הזו והיא תשחרר את המנעול. תחזיר 0 אם הצליח, וערך אחר אם הקריאה נכשלה.

-----------------------------------------------------------------------

חוץ משתי הקריאות של נעילה ושחרור, לינוקס מספקת לנו עוד 2 קריאות לשימוש במנעול:

1. הקריאה הראשונה (trylock) היא קריאה שלא חוסמת את החוט.
כשאנו קוראים לקריאה הזו, המימוש של הקריאה הזו מנסה לתפוס את המנעול פעם אחת. אם המנעול פנוי אזי הוא יתפוס ויודיע, אחרת יכשל בתפיסת המנעול אף נחזור מיד (אין המתנה עד שהמנעול שלנו).
לפי ערך ההחזר נדע אם הצלחנו: 0 להצלחה ומספר אחר לכך שלא הצלחנו לתפוס את המנעול.

```c
int pthread_mutex_trylock(pthread_mutex_t *mutex);
* Acquire lock once, fail if already locked

int pthread_mutex_timedlock(pthread_mutex_t *mutex,
        struct timespec *abs_timeout);
* Acquire lock or return after timeout
```

2. Timedlock - מנסה לתפוס את המנעול אבל לא לזמן בלתי מוגבל, אלא הוא מקבל פרמטר struct timespec שאומר לאיזה פרק של זמן יש לנסות לתפוס את המנעול (למשל למשך חצי שנייה, ואז נחזור או כשתפסנו או כשהסתיים הזמן). לפי ערך ההחזר נדע אם הצלחנו: 0 להצלחה ומספר אחר לכך שלא הצלחנו לתפוס את המנעול.

-----------------------------------------------------------------------

להלן הקוד שראינו בשבוע שעבר, שקידם מונה משותף, רק שעכשיו הוא מתוקן באמצעות מנעולים.
הקטע הקריטי פה הוא קידום המונה ולכן לפניו יש תפיסת מנעול ואחריו שחרור מנעול.
לשם הפשטות אין כאן בדיקות של הצלחת קריאה, אבל יש בהן צורך.
כעת הקוד שלנו יעבוד באופן תקין.

```c
void* mythread(void *arg)
{
    for (int i = 0; i < 1e7; ++i) {
        
        pthread_mutex_lock(&lock);
        counter = counter + 1;
        pthread_mutex_unlock(&lock);
    }
    return NULL;
}

int main(int argc, char *argv[])
{
    pthread_mutex_init(&lock, NULL);
    
    pthread_t p1, p2;
    pthread_create(&p1, NULL, mythread, "A");
    pthread_create(&p2, NULL, mythread, "B");
    pthread_join(p1, NULL);
    pthread_join(p2, NULL);
    printf("main: end (counter = %d)\n", counter);
    
    pthread_mutex_destroy(&lock);
}
```

חשוב לזכור שמנעול הוא אובייקט, קונספט לוגי. הוא לא מגן על הקוד בפני עצמו, הוא לא דואג לסנכרון, כל מה שהוא עושה זה כאשר אנחנו קוראים ל-lock, הקריאה תחזור כשאנחנו מחזיקים במנעול ואף אחד אחר לא. כלומר כשאנחנו מחזיקים במנעול, מובטח לנו שאף חוט אחר לא מחזיק את המנעול גם במקביל אלינו. זה לא מבטיח יותר מכך.
אם אנחנו רוצים לסנכרן את הקוד שלנו, אנחנו צריכים לדאוג לכתוב את הקוד שלנו באופן תקין.
לדוגמא: הקוד שהצגנו לעיל, בקטע הקריטי שהקפנו במנעול, מובטח לנו שלא יהיה יותר מחוט אחד בקטע הזה. אבל אם יש פונקציה אחרת בקוד שמתעסקת עם המונה הזה, היא לא מוגנת. כלומר, המנעול לא מגן על משאב, אלא על קטע הקוד בין נעילת המנעול לבין שחרורו.

:ביצועים:
כיום כשהמעבדים שלנו מרובי ליבות, נרצה למקסם את היכולות של המחשב.
אבל ראינו שזה לא ככה כך, ראינו שכאשר רוצים לעשות זאת, יש עלות כבדה של סנכרון, ואנחנו צריכים לדאוג לשים נעילות.
אבל ברגע ששמנו נעילות, אנחנו מגבילים את המקביליות, וכך אנחנו בעצם פוגעים בביצועים.

חוק אמדאל – Amdahl's law: נוסחה המחשבת: בהינתן הקוד שלנו, אם נריץ אותו על כמות מעבדים מסוימת – מה השיפור בביצועים שאנחנו צפויים לקבל (speedup).
למשל אם ה-speedup שלנו הוא 2, זה אומר שהקוד שלנו ירוץ פי 2 יותר מהר, כלומר בחצי מהזמן.

משתני הנוסחה:
p: כמה מהקוד שלנו באמת מקבילי. כשאנחנו מסתכלים על הקוד ומריצים אותו, כמה אחוזים מהריצה של הקוד שלנו היא מקבילית.
למשל, אם הקוד שלנו הוא 80% מקבילי, אז p=0.8.

[נוסחת Speedup: Speedup = 1 / ( (1-p) + p/n )]
תוויות: Sequential fraction (מצביע על 1-p), Parallel fraction (מצביע על p), Number of threads (מצביע על n).

1-p: החלק הסדרתי. אם 80% מהקוד שלנו הוא מקבילי, אז 20% מהזמן הוא סדרתי.

n: מספר החוטים/מספר המעבדים. ההנחה בנוסחה היא שאנחנו מריצים את הקוד על הרבה חוטים, וכמות החוטים היא כמות המעבדים שזמינה לנו. אם יש לנו 30 מעבדים אז נריץ את זה על 30 חוטים ונראה מה השיפור בביצועים שאנחנו יכולים לקבל מזה שכל חוט רץ על מעבד משלו, כלומר רץ באופן מקבילי, חוץ מאשר כשהוא תופס מנעול וכו'.

דוגמא לשימוש בנוסחה:
נניח שיש לנו 10 מעבדים, לאחר ניתוח של הקוד גילינו ש- 60% ממנו מקבילי ו-40% ממנו סדרתי.
נציב את זה בחוק אמדאל בצורה הבאה: p=0.6, n=10 ונקבל:

[חישוב: Speedup = 1 / ( 1 - 0.6 + 0.6/10 ) = 2.17]

המשמעות היא שכשנריץ את הקוד שלנו על 10 מעבדים, נקבל שיפור של בערך פי 2.
זה לא טוב, ציפינו לקבל משהו באזור של פי 10 (זאת השאיפה שלנו), אבל יותר מדי מהקוד שלנו רץ באופן סדרתי ולא מקבילי ולכן זו התוצאה.

- אם נחשב עם 10 מעבדים נראה את היחסים בין אחוזי הקוד המקבילי ואחוזי הקוד הסדרתי:
* 80% concurrent, 20% sequential -> 3.57
* 90% concurrent, 10% sequential -> 5.26
* 99% concurrent, 01% sequential -> 9.17

ניתן לשים לב שהשיפור המקסימלי יושג רק ע"י אחוזים גבוהים מאוד של קוד מקבילי. כלומר אנחנו צריכים לחשוב טוב לפני שאנחנו הופכים קטע קוד לסדרתי, כי זה משפיע רבות על הביצועים.

כמו כן, לפעמים משתלם לנו יותר לכתוב קוד פחות יעיל אבל שהוא יותר מקבילי.

ראשית, חשוב לנו לשפר את הביצועים של המנעול שאנחנו משתמשים בו, כי אם המנעול שלנו לא טוב והביצועים שלו לא טובים, אולי לא משנה כמה נשפר את הקוד שלנו, ברגע שהוא ישתמש במנעול זה יהרוס הכל.

חילקנו את המנעולים לשני סוגים: כאלה שעושים spinning וכאלה שלא.
נדבר עכשיו רק על מנעולים שעושים spinning (לא כי הם טובים יותר, הם דווקא לרוב טובים פחות, פשוט יהיה לנו קל יותר להדגים עליהם את הבעיות).

המנעול הראשון שראינו (כשיטה): Test-and-set Lock (spinning):

```c
void lock() {
    while (testAndSet(state, true)) {}
}

void unlock() {
    state = false;
}
```

המנעול כתוב כאן טיפה אחרת אבל מדובר על אותו עיקרון.
state הוא משתנה בוליאני, כאשר הוא true זה אומר שהמנעול שלנו תפוס וכאשר הוא false הוא פנוי.
בשביל לתפוס את המנעול, אנחנו מחכים בלולאה, קוראים ל-testAndSet ובודקים עד שהמנעול פנוי.
בשביל לשחרר את המנעול אנחנו שמים false ב-state.

[ליד הקוד: Keep trying until lock acquired]

ניקח את המנעול הפשוט הזה ונבדוק את הביצועים שלו:
ניקח n חוטים, כאשר n יהיה משתנה (בכל פעם נשים בו ערך אחר) ובכל פעם נריץ תוכנית שלוקחת מונה (משתנה גלובלי) ומקדמת אותו מיליון פעמים (הקידום של המיליון פעמים יהיה סך הכל על ידי כל החוטים, למשל אם נריץ את התוכנית על ידי חוט אחד, הוא יקדם את המונה מיליון פעם, ואם נריץ על 2 חוטים אז כל אחד מהם יקדם 500,000 פעם וכו'..).
- קידום המונה ייעשה ע"י שימוש בפעולת הקטע הקריטי, כלומר נקרא ל-lock, נעשה counter++ ואז נקרא ל-unlock (אפילו כשיש רק חוט אחד, כי אנחנו רוצים לבדוק את הביצועים של המנעול).

נניח ועם חוט אחד הניסוי הזה לקח שניה אחת.
היינו מצפים שאם יש חוטים רבים במקביל, אז זה ייקח פחות זמן. אך למעשה, עם שני חוטים- זה עדיין ייקח שניה.
הסיבה היא שבעקבות השימוש במנעול, החוטים לא יכולים לרוץ במקביל, הקוד מתבצע באופן סדרתי ולא מקבילי (100% סדרתי). כל חוט ממתין לאחר בכל פעם. לכן הכי טוב שאנחנו יכולים לצפות לו במקרה הזה: שנייה אחת.
אותו דבר עם 4 מעבדים וכו'. נזכור שהניסוי הזה באמת מתבצע על מחשב עם כמות מעבדים רצויה, למשל כשיש שני חוטים אז יהיו שני מעבדים כאשר כל חוט רץ על מעבד אחר.

אם נשים את זה על מערכת צירים:
ציר ה-X הוא מספר החוטים, ציר ה-Y הוא כמות הזמן שלוקחת הרצת הקוד:
האידיאלי הוא שזה ייקח אותו זמן לכל החוטים, לא משנה כמה חוטים נשים, גם אם נשים 100 חוטים, עדיין 100 חוטים מקדמים את המונה – כל פעם רק חוט אחד יכול לקדם את המונה בכל רגע נתון ולכן סך הכל אנחנו מקדמים את המונה 1,000,000 פעמים- זה אמור לקחת אותו זמן, בין אם מדובר על חוט אחד או 100 חוטים. זה נקרא צוואר בקבוק סדרתי- כל מה שאנחנו עושים בתוכנית משתמש במנעול ולכן כל החוטים כל הזמן מחכים אחד לשני.

[תרשים: גרף זמן מול מספר חוטים המציג קו "ideal" אופקי וקו "no speedup because of sequential bottleneck"]

אם נריץ את הקוד עם מנעול test-and-set נקבל את התוצאה הבאה:
לא רק שלא קיבלנו את הביצועים שציפינו להם, אלא ככל שאנחנו מוסיפים יותר ויותר חוטים, הביצועים יותר ויותר גרועים, כלומר הזמן גדל באופן משמעותי.
אנחנו פוגעים בביצועים ככל שאנחנו מוסיפים חוטים. אז משהו כאן לא עובד כמו שהיינו מצפים.
* נענה על התעלומה הזו בהמשך.

[תרשים "Mystery #1": גרף ביצועים של TAS lock המציג עליה חדה בזמן לעומת הקו האידיאלי]

:Test-and-test-and-set (TTAS) Lock
מנעול נוסף שדומה ל-test-and-set בלולאה, אלא הוא קודם כל קורא את המנעול. יש לולאה חיצונית אינסופית ובפנים לולאה פנימית.
הלולאה הפנימית קוראת את המצב המעודכן של המנעול הזה, ורצה בלולאה עד שהמנעול פנוי. ברגע שהמנעול נראה פנוי, אנחנו קוראים ל-testAndSet ומנסים לתפוס אותו.
המנעול הזה (TTAS) דומה ל-TAS, מלבד הלולאה הפנימית (שעלולה להיראות מיותרת).

```c
void lock()
{
    while (true) {
        while (state) {}
        if (!testAndSet(state, true))
            return;
    }
}
```

אם נשים את זה על מערכת צירים:
נוכל לראות שהביצועים של מנעול ה-TTAS הרבה יותר טובים באופן משמעותי מ-TAS.
מנעול TTAS עדיין לא אידיאלי, אבל הרבה יותר טוב מהמנעול הקודם.
תעלומה 2: מבחינתנו המנעולים TTAS ו-TAS עושים את אותו הדבר, אז למה יש ביניהם הבדל כלכך משמעותי בביצועים? כנראה משהו בדרך שבה אנחנו מסתכלים על הקוד שלנו- לא נכון.
כלומר, משהו במודל שלנו (בצורה בה אנחנו מנתחים את הסיבוכיות של הקוד) לא נכון.
זה היה נכון בעולם שבו יש לנו חוט יחיד, והסתכלנו על הקוד כסדרתי, שכל מה שמתבצע ועד הסוף, אבל פתאום כשהקוד שלנו מקבילי, הדברים שפעם היו נכונים (עבור ריצה של חוט יחיד) כבר לא נכונים עכשיו.
אז נצטרך מודל מדויק יותר שידע להסביר את ההבדלים בשביל להסביר את התופעה.

[תרשים "Mystery #2": גרף ביצועים המראה את TTAS lock בין TAS lock לבין הקו האידיאלי]

כדי להסביר את המנעולים, נשים אותם רגע בצד, ונסביר כיצד מחשב מרובה מעבדים עובד (את הארכיטקטורה שלו):

[תרשים: Bus-Based Architectures המציג מעבדים עם זיכרונות מטמון פרטיים המחוברים דרך BUS משותף לזיכרון ראשי]

במחשב שלנו יש לנו כמה מעבדים (מדובר על מחשב מרובה מעבדים), וכל המעבדים האלו מחוברים לזיכרון המהיר שלנו (ה-RAM, הזיכרון הראשי) והזיכרון הזה הוא לא כ"כ מהיר, על אף השם שלו. כל גישה לזיכרון היא כמה עשרות מחזורי שעון (שקול לכמה עשרות פקודות של המעבד), כלומר גישה לזיכרון נחשבת איטית במושגים של מעבדים.
בשביל לגשת לזיכרון שהוא רכיב חומרה נפרד, יש לנו ערוץ תקשורת שנקרא BUS שמחבר בין המעבדים שלנו לזיכרון, ובעזרתו אנחנו נגשים לזיכרון.
ה-BUS הוא רכיב חומרה שמשדר הודעות (עוברות עליו הודעות), כולם יכולים לשדר עליו הודעות, גם רכיב הזיכרון וגם המעבדים. זה רכיב חומרה, המאפשר להעביר רק הודעה אחת בכל רגע נתון.
כלומר, אם רוצים לשדר כמה הודעות, ה-BUS ישרת אותן אחת אחת, אי אפשר להעביר כמה הודעות בו זמנית על ה-BUS. כל המעבדים שיש לנו במחשב וגם הזיכרון שלנו - ברמת החומרה: "מאזינים" ל-BUS, כלומר הם שומעים את כל ההודעות שעוברות על ה-BUS כל הזמן, ומגיבים בהתאם.

ה-Cache: המזמון. לכל מעבד במחשב שלנו יש מזמון משלו. המזמון הוא לא כמו האוגרים של המעבד, אלא זה זיכרון מאוד קטן ומהיר ששייך למעבד, ושם הוא שומר עותקים מהזיכרון הראשי. כלומר, במקום לגשת כל פעם לזיכרון הראשי, שזו פעולה איטית, המעבדים שלנו שומרים עותקים במזמון הפרטי שלהם וברגע שהנתון שם, אנחנו יכולים לגשת אליו מאוד מהר ללא הזיכרון הראשי שלנו שהוא מאוד איטי.
עכשיו כל פעם כשחוט בתוכנית שלנו ניגש לזיכרון, המעבד בודק האם הנתון שרוצים לגשת אליו – קיים אצלנו במזמון. אם כן, לזה נקרא cache hit, ואפשר לגשת לאותו נתון מאוד מהר.
אחרת, אם הנתון לא קיים אזי לזה נקרא cache miss ועכשיו צריך ללכת את כל הדרך לזיכרון, להביא את הנתון משם וזו תהיה פעולה איטית.

איך ה-Cache עובד? נניח שהמעבד השמאלי ביותר רוצה לגשת לאיזשהו נתון בזיכרון (הרצת קוד שיש בו שורה שניגשת למשתנה כלשהו, עם הכתובת x).
בשביל לגשת לכתובת x שלא נמצאת כרגע במזמון של המעבד, המעבד משדר הודעה על ה-Bus (הוא משדר הודעת read x ומעביר את הכתובת), ההודעה היא: load x (קריאת זיכרון נקראת load). ברגע שהמעבד משדר את ההודעה הזו על גבי ה-Bus, הזיכרון הראשי שומע את ההודעה (כל המעבדים והזיכרון הראשי תמיד מאזינים למה שעובר על ה-Bus). הזיכרון מחזיר את הנתון המבוקש כתגובה דרך ה-Bus (ומחזיר את הנתון שנמצא בכתובת x). כל זה קורה על גבי החומרה (ביטים ואותות חשמליים).

[תרשים: מעבד המפיץ בקשת טעינה עבור 'x', שולח 'load x' ב-Bus ומקבל 'data' מהזיכרון]

נניח והמעבד האמצעי רוצה את אותו הנתון, הוא ישלח את ההודעה load x, אבל הפעם לא צריך ללכת עד הזיכרון, כלומר לא צריך לחכות עד שההודעה תגיע לזיכרון וכו', כי גם המעבדים שלנו מאזינים ל-Bus, אז המעבד השמאלי שומע את ההודעה שעברה על ה-Bus ומבקשת את x, והוא יודע שיש לו את x במזמון שלו ולכן הוא מוציא את ערכו של x על ה-Bus, במקום לחכות לזיכרון. כלומר המעבדים שלנו קרובים זה לזה ויכולים להגיב מהר יותר במקום שיחכו לזיכרון.

עכשיו גם למעבד השמאלי וגם למעבד האמצעי יש את x במזמון שלהם. הכל עובד מצוין. עד שאחד מהם רוצה לשנות את ערכו של x. נניח והמעבד האמצעי רוצה לשנות את הנתון הזה, אנחנו נתקלים בבעיה. כי הוא לא יכול לשנות רק אצלו את הנתון, אנחנו רוצים שמעבדים אחרים יראו את השינוי גם כן. כי אם מישהו משנה ערך של משתנה, הוא צריך להיות מעודכן אצל כולם.

שיטה 1: Write-Through cache = "נפרסם לכולם": ברגע שמעבד אחד שינה את הזיכרון, אז נפרסם על ה-BUS וכל מי שמאזין יוכל לעדכן את הערך שאצלו (כולל הזיכרון והמעבדים שמחזיקים את הערך הזה במזמון שלהם). הגישה הזו מאוד טובה מבחינת נכונות - היא מבטיחה לנו שכל המעבדים רואים את אותו המצב כל הזמן, והזיכרון הראשי שלנו תמיד מעודכן.
הבעיה בגישה הזו: יש עומס על ה-Bus. רוב פעולות הכתיבה שלנו הן על משתנים מקומיים/זמניים, שאנחנו לא משתפים עם מעבדים אחרים. אבל מצד שני, אנחנו לא יודעים מה משותף ומה לא, אז כל כתיבה כזו אנחנו צריכים לפרסם לכולם. וכמעט כל הכתיבות הללו לא מעניינות אף אחד. יוצא מצב שאנחנו מעמיסים את ה-Bus בהודעות מיותרות שגורמות לעומס. כל המחשב נהיה איטי יותר. הגישה הזו אמנם נכונה ונוחה אבל גורמת לכך שהמחשב והזיכרון שלנו יעבדו לאט.

שיטה 2: Write Back Cache = "נשמור אצלי את השינויים": לא נפרסם לכולם כל שינוי קטן שנעשה, ונדבר על השינויים אצלי ואז בסוף אני אפרסם לכולם את השינויים. ברגע שנפנה את המזמון (נאמר המקום נגמר וכו'..), רק אז נודיע לאחרים. הגישה הזו עובדת יותר טוב, כי זה אומר שאני יכול לעבוד מול המזמון שלי ולעדכן את כולם רק בסוף.
אבל אז אנחנו חוזרים לבעיה שהייתה מקודם: אם אני שיניתי ערך, אחרים לא יודעים על השינוי. זה יגרום לכאוס וטעויות. לא תהיה משמעות לזה שהזיכרון משותף.

כדי לפתור זאת - יש לנו מנגנון שנקרא invalidate (אינוולידציה):
המנגנון הזה אומר שלפני שמעבד רוצה לכתוב לכתובת מסוימת, הוא יפרסם הודעה על ה-Bus שהוא משנה את הערך של הכתובת הזו (לא יפרסם את הערך וכו'). ההודעה הזו נקראת invalidate. ברגע שההודעה הזו מפורסמת על גבי ה-BUS, כל מי ששומע את ההודעה ויש לו את הכתובת הזו שהמעבד הולך לשנות, זורק את הערך שלה מהמזמון שלו (זו הודעה רק למעבדים, היא לא מגיעה לזיכרון).
עכשיו ברגע שהודענו לכולם, המעבד שמשנה את הערך של הכתובת הזו, יכול לדעת בוודאות שרק לו יש את הערך המעודכן של הכתובת הזו. עכשיו הוא יכול לשנות את הכתובת הזו כמה שהוא רוצה, כי אין לו חוסר תאימות עם שאר המעבדים. בכך, המעבד ששינה את הכתובת הרוויח ראשוניות כתיבה על הערך הזה, ואילו שאר המעבדים איבדו את הרשאות הקריאה שלהם עליו, כי המזמון שלהם לא עדכני. את הזיכרון הראשי לא עדכנו, הוא עדיין מכיל את הערך הישן והוא לא יודע על השינויים שנעשו בו, אבל זה לא נורא כי אם מישהו ירצה לקרוא את הכתובת הזו, המעבד ששינה – ישלח את הערך המעודכן למי שביקש, כי זה יותר מהר מגישה לזיכרון. את הזיכרון נעדכן בהמשך, זו פעולה איטית.

כעת אם יש מעבד שרוצה לגשת לערך ששונה, הוא רואה שזה לא נמצא אצלו במזמון בגלל הודעת ה-invalidate, אז הוא מפרסם הודעה ב-BUS שהוא רוצה את הערך העדכני ביותר והמעבד שהחזיק בערך העדכני ביותר ישלח את הערך על ה-BUS כי הוא האזין ל-BUS גם כן. בנוסף, המעבד שמחזיק את הערך העדכני ביותר יודע שעכשיו הערך הזה כבר לא שלו בלבד, עוד מישהו ביקש לקרוא את הערך הזה והוא שלח עכשיו וגם הוא לא יוכל לכתוב אליו יותר בלי אישור. הוא יוכל לקרוא את הערך המעודכן שלו אבל בפעם הבאה שהוא ירצה לכתוב אליו שוב, הוא יצטרך שוב לשלוח הודעת invalidate, להגיד לכולם לזרוק את הערך הישן מהמזמון שלהם ורק אז יוכל לכתוב אליו.

*אז כל פעם לפני שאנחנו כותבים - שולחים הודעת invalidate ומוודאים שלאף אחד אין את זה במזמון.

אם בגישה הקודמת (Write Through cache) כשכתבנו 100 פעמים משתנה, היינו צריכים 100 פעמים להפיץ הודעות ב-BUS, בגישה הזו נצטרך להפיץ הודעה אחת ב-BUS (ה-invalidate).

-----------------------------------------------------------------------

נקשר את כל המידע הזה חזרה למנעולים:
כשעשינו את המנעול הראשון - TAS LOCK, הבעיה הייתה שהוא פשוט גרוע.
כל פעם שהיינו קוראים ל-test-and-set, היינו כותבים ערך לזיכרון. זה אומר שכל החוטים שעשו spinning וחיכו למנעול, הם כל הזמן עשו spinning ושלחו invalidate ורשמו ל-BUS.
אם יש לנו 100 חוטים, חוט אחד הצליח לתפוס את המנעול, וכל 99 החוטים האחרים כל פעם עושים invalidate לכולם ואז כותבים את הערך (אם המנעול תפוס), וכך נוצר עומס על ה-BUS ולהעביר הודעה על גביו הופך להיות הרבה יותר איטי, כי צריך לחכות בתור, והביצועים נהיים נורא איטיים.

אחד הדברים הכי גרועים שיוצאים מכך - כשחוט בא לשחרר את המנעול, היינו רוצים שזה יקרה כמה שיותר מהר, כדי שהחוט הבא יוכל להיכנס לקטע הקריטי גם. אבל מה שקורה בפועל זה שהחוט הזה נאלץ לחכות בתור ב-BUS אחרי הרבה חוטים שמנסים לתפוס את המנעול.
זה מה שגורם לביצועים האיטיים שראינו קודם.

אם כך, אז למה המנעול TTAS LOCK יעיל יותר? מכיוון שבהתחלה, כשאנחנו רק בודקים אם המנעול פנוי, אנחנו רק קוראים. החוטים שרק עושים spinning לא מחזיקים במנעול, בעצם לא שולחים invalidate ולא מפריעים, הם עושים spinning על עותק מקומי במזמון שלהם. ברגע שהוא קרא וראה שהמנעול פנוי, הוא מנסה לתפוס אותו.
הפגיעה בביצועים קורית ברגע שמשחררים את המנעול ואז קורה Invalidation storm:

[תרשים Invalidation storm: מעבדים עם זיכרונות מטמון 'invalid', אחד משחרר את המנעול לסטטוס 'free'. ה-Bus מוצג בין המעבדים לזיכרון.]

נניח והחוט הירוק החזיק במנעול ואז שחרר אותו, אז הוא שולח invalidate לכולם וכותב שהמנעול פנוי. עכשיו לכל שאר החוטים אין את הערך של ה-flag במזמון שלהם. עד עכשיו הם קראו ערך מהמזמון שלהם והוא לא השתנה, אבל ברגע שנשלחה הודעת invalidate, הנתון במזמון שלהם כבר לא רלוונטי, אז הם קיבלו cache miss בניסיון לקרוא את הערך הזה, ועכשיו כל החוטים האלה מנסים לקרוא את הערך הזה – יקבלו cache miss כמעט בו זמנית, וכל החוטים האלה יתנפלו ביחד על ה-BUS כדי לקרוא את הערך החדש. ואז הם רואים שהמנעול פנוי וכולם מנסים לעשות test-and-set ושוב כל אחד עושה invalidate בתורו, מנסה לתפוס את המנעול. אם הוא הצליח הוא נכנס לקטע הקריטי, החוט הבא עושה invalidate ונכשל אז חוזר ל-spinning המקומי וכן הלאה.. כך יקרו המון invalidates עד ששוב יהיה שקט. כלומר לאחר שחרור המנעול קורה invalidation storm - כולם בבת אחת עושים invalidate עד שכולם ידעו מחדש שהמנעול תפוס ויחזרו ל-spinning על הערך המקומי של המנעול.
- זה מסביר למה המנעול TAS LOCK כלכך גרוע, ולמה המנעול ה-TTAS LOCK משמעותית יותר טוב אבל עדיין גרוע ולא מפגין ביצועים טובים כמו שהיינו רוצים.
- השלב הבא יהיה מימוש של מנעול טוב, שיעזור לנו להשתמש בכל המנגנונים החומרתיים מבלי כל החסרונות מסביבם.

