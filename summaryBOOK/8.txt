מערכות הפעלה - שיעור 8

בשיעור הקודם דיברנו על זה שטבלת הדפים גדולה מדי, וכל תהליך יש טבלת דפים ואם נשמור את הטבלאות של כל התהליכים בזיכרון זה יתפוס יותר מדי זיכרון, ובשביל זה אנחנו מעדיפים לחלק את טבלת הדפים לחלקים בגודל שווה, כאשר כל חלק הוא בגודל דף.

אם קודם ה-mmu (רכיב החומרה שמתרגם מכתובת וירטואלית לכתובת פיזית) היה צריך לקבל את כתובת תחילת הטבלה ובעזרתה הוא יכול היה למצוא כל רשומה בטבלה, אז עכשיו הוא לא יכול, כי חילקנו את טבלת הדפים לחלקים ופזרנו אותם בזיכרון. לשם כך אנחנו מוסיפים את ה-page directory שזו עוד טבלה שמכילה רשומה של כל חלק.

אם במקרה יש לנו חלק שבו כל ה-valid bit הם 0, כלומר התהליך לא משתמש באף אחד מהדפים שמופיעים באותו חלק - במקום לשמור את החלק הזה של טבלת הדפים בזיכרון, נרשום ב-directory שה-valid bit הוא 0 ויש לנו רשומה אחת שחסכה לנו.

המחשבה על כך נובעת מההנחה שתהליך לא משתמש בכל הדפים שלו, ויהיו הרבה חלקים בטבלת הדפים שלא יהיו בשימוש ונוכל לחסוך.

אך גם ה-directory יכול להיות גדול מדי, וכשזה קורה אנחנו נפצל את אותה הלוגיקה על ה-page directory עצמו. כלומר, נחלק את ה-page directory לחלקים שווים, הגודל של כל חלק יהיה דף ונעשה directory ל-directory.
אותו דבר אם יש לנו חלק שלם שבו כל ה-valid bit הם 0 (שכל הרשומות ב-page directory הם 0), אז נכתוב ב-page directory 0.. וכן הלאה.

כשהתהליך ניגש לזיכרון הווירטואלי, ה-mmu יודע איפה נמצאת הרמה הראשונה בטבלה ואז בעזרת האינדקס הוא מגיע למקום המתאים ברמה הבאה וכן הלאה, עד שהוא מוצא את ה-pte הרצוי.

כל התהליך הזה גורר הרבה מאוד גישות לזיכרון, ולכן כדי להתמודד עם בעיית הביצועים, הוספנו את ה-tlb שהוא רכיב חומרה שמכיל מיפויים לזיכרון (נתמון שמכיל גישות לזיכרון).

ASID - מספר מזהה שאומר לאיזה תהליך שייך המיפוי הספציפי.
הזיכרון שהעידן של דפים עוזר לתהליכים לחלוק ביניהם דפים פיזיים, אז ה-ASID גם עוזר לחלוק מסגרות.

---------------------------------------------------------

הקוד הבא: קורא פרמטר len מהמשתמש ומקצה מערך בגודל זה.
כל איבר במערך הוא מטיפוס mytype.
בהמשך הקוד רץ 1000 פעמים כאשר בכל פעם הוא עובר על כל המערך וניגש לאיזהשהו איבר במערך.
מתבצעת מדידת זמן של קטע הקוד והדפסה של תוצאת המדידה.
clock היא קריאת מערכת שמודדת זמן והיא תמדוד לנו כמה זמן עבר מהקריאה הראשונה שלה עד האחרונה (וזה יבדוק לנו כמה זמן התוכנית רצה).

-------------------------------------------
נריץ את הקוד פעמיים ונמדוד.
בפעם הראשונה הרצנו את הקוד כאשר הטיפוס mytype הוא int כלומר כל איבר במערך הוא 4 בתים, ובפעם השנייה הטיפוס mytype הוא מערך של 100 שלמים, כלומר [100]int, ולכן גודל כל איבר במערך הוא 400 בתים.

```c
// loop.c
int main(int argc, char *argv[])
{
  int len = atoi(argv[1]);
  mytype *arr = (mytype*) malloc(sizeof(mytype) * len);

  clock_t start = clock();
  for (int t = 0; t < 1000; ++t) {
    for (int i = 0; i < len; ++i) {
      arr[i].data += 1;
    }
  }
  clock_t end = clock(); // Measure elapsed time

  free(arr);
  printf("Time passed: %ld\n", (end-start));
  return 0;
}
```

Output:
mytype=int
prompt$ ./loop 1000
Time passed: 2
prompt$ ./loop 10000
Time passed: 18
prompt$ ./loop 100000
Time passed: 172
prompt$ ./loop 1000000
Time passed: 1732

mytype=int[100]
prompt$ ./loop 1000
Time passed: 2
prompt$ ./loop 10000
Time passed: 18
prompt$ ./loop 100000
Time passed: 686 // huh??
prompt$ ./loop 1000000
Time passed: 9449 // what the??

* Ten times the operations, way more runtime
* ...but complexity says it should be ~10 times the runtime!

בתמונה ניתן לראות את הפרמטר len שהועבר בכל אחת מהריצות.
הריצה הראשונה לקחה 2 אלפי שניות, בשני המקרים וזה מספר הגיוני.
הריצה השנייה לקחה 18 אלפי שניות בשני המקרים.
ניתן לראות בריצות השנייה והשלישית שב-int הריצה גדלה בערך פי 10 וב-int[100] ימין גדל כמעט פי 30 ומשם.
מה שקרה כאן - חוסר העקביות קשורה לזיכרון הווירטואלי ואיך שהוא עובד.

אם נסתכל על הזיכרון של תהליך, אמרנו שלכל תהליך יש מרחב כתובות של 4GB.
10 תהליכים לוקחים 40GB וראינו שבמערכת שלנו יש יותר מ-300 תהליכים. אין לנו מספיק זיכרון לכל זה.
כמו כן, אמרנו שתהליכים לא מחזיקים דפים שהם לא משתמשים בהם, אבל גם אם תהליך משתמש רק ב-200 או 300MB, כשמדובר על 300 תהליכים, עדיין אין לנו מספיק זיכרון לכך.
כלומר אנחנו צריכים עוד רמה בהיררכיה של הזיכרון שלנו, כלומר עוד מקום לאחסן את הזיכרון של התוכניות שרצות לנו במחשב. הרמה הזו היא הדיסק (ההארד דיסק שלנו).
יש מנגנון שנקרא swapping (החלפה) שעובד מול ההארד דיסק.

---------------------------------------------------------

היררכיית הזיכרון:
פירמידה שבה החלק העליון הוא הזיכרון הכי מהיר שיש לנו - רגיסטרים נמצאים על המעבד, הם זיכרון מאוד מהיר אבל זה מאוד יקר אז אין לנו הרבה מהם.
לאחר מכן יש את ה-cache שנדבר עליו בהמשך.
מתחת ל-cache יש את הזיכרון המהיר שלנו ה-RAM (שבפועל הוא לא כזה מהיר אבל הוא יותר מהיר מהדיסקים הקשיחים).
הדיסקים הקשיחים נקראים הזיכרון המשני.
היתרון של הזיכרון המשני - הוא מאוד זול, יכול להיות לנו הרבה ממנו, מבחינת מערכת ההפעלה מדובר על מספר אינסופי. אז יש לנו זיכרון עצום שיכול להכיל את כל התהליכים שלנו ונשתמש בו.
הוא מאוד גדול ומאוד זול אבל מאוד איטי. כל גישה להארד דיסק היא מאוד איטית.

איך זה עובד?
יש לנו את הזיכרון הווירטואלי של כל תהליך ואמרנו שהדפים ממופים למסגרות בזיכרון הפיזי.
חלק מהדפים בכלל לא בשימוש אז בטבלת הדפים הם 0 valid ולא משתמשים בהם.
חלק מהדפים נחזיק בדיסק.
יש שטח מיוחד בדיסק ששמור עבור זיכרון של תהליכים והוא נקרא swap space.
למעשה כל הזיכרון של כל תהליך נמצא במקום כלשהו בדיסק, באיזושהי צורה.
הזיכרון המהיר שלנו הוא כמו cache של השטח הזה. אנחנו טוענים את הזיכרון של תהליכים אל ה-RAM ומשתמשים בו ב-RAM, וכאשר ה-RAM מתמלא, מבצעים החלפות.
נטען ל-RAM רק את הדברים שמשתמשים בהם יותר. בדפים שפחות משתמשים, נשאיר בדיסק.
ככה אנחנו יכולים להחזיק כמות מאוד גדולה של תהליכים שמשתמשים בהרבה מאוד זיכרון, למרות שאין לנו את כמות הזיכרון הזו בפועל.

Present bit - זהו ביט שנמצא ב-pte. הוא אומר האם הדף שאנחנו מחפשים נמצא ככלל בזיכרון הפיזי, או שהוא נמצא בדיסק וצריך לטעון אותו מהדיסק ואז pfn לא רלוונטי כי הדף נמצא בדיסק.
עכשיו תהליך הגישה לזיכרון קיבל עוד שלב. ה-mmu מקבל כתובת וירטואלית וניגש ל-tlb בשביל לתרגם אותה לכתובת פיזית. אם זה נמצא ב-tlb וקיבלנו tlb hit אז הכל בסדר.
ה-tlb מחזיק רק רשומות שה-present bit שלהן הוא 1, כלומר רשומות שנמצאות בזיכרון המהיר, ב-RAM.
לעומת זאת אם קיבלנו tlb miss זה אומר שהמיפוי לא נמצא ב-tlb ואז ה-mmu ניגש לטבלת הדפים ומחפש את המיפוי שם, ובודק את ה-present bit:
אם ה-present bit הוא 1: אז אין בעיה, מתרגמים את הכתובת ומעדכנים את ה-tlb.
אחרת, אם הוא 0: זו "בעיה". זה אומר שהדף הזה בכלל לא נמצא בזיכרון המהיר שלנו, לא נמצא ב-ram.
ה-mmu יוצר trap למערכת ההפעלה (מעלה אירוע, מודיע על כך למערכת ההפעלה).
האירוע הזה נקרא page fault. מערכת ההפעלה צריכה לטפל באירוע הזה ולטעון את הדף מהדיסק כדי שנוכל לקרוא ממנו. התהליך של page fault הוא מאוד ארוך ואיטי.
(אנחנו לא פועלים מול הדיסק, מערכת ההפעלה עושה זאת).

---------------------------------------------------------

התהליך המלא:
* גישה לזיכרון תמיד מתחילה בכך שתהליך מסוים מבצע פקודת גישה לזיכרון (קריאה או כתיבה) לאיזושהי כתובת בזיכרון הווירטואלי.
* כעת ה-mmu צריך לתרגם את הכתובת הווירטואלית למסגרת פיזית לכתובת פיזית לפני שהוא מבצע את הפקודה, כדי שהיא תתבצע על הכתובת הנכונה.
* הדבר הראשון שה-mmu עושה זה להיכנס ל-tlb ולבדוק אם יש שם את המיפוי הרצוי.
- אם מצאנו אז הכל בסדר ואפשר להמשיך (ה-mmu מתרגם את זה לכתובת פיזית והפקודה מתבצעת).
* אם לא מצאנו, כלומר אם היה לנו tlb miss, ה-mmu עכשיו צריך ללכת ולחפש את הרשומה בטבלת הדפים, זה עלול לגרור כמה פעולות בזיכרון אכן בפועל (בטבלת הדפים הרשומה בטוח נמצאת).
* כאשר מצאנו את הרשומה, נבדוק את ה-present bit שלה.
- אם הוא 1: הדף נמצא בזיכרון המהיר ורק צריך לעדכן את ה-tlb ולבצע את הפקודה.
* אם הוא 0: אנחנו מעלים אירוע של מערכת ההפעלה page fault.
בשלב הזה, הסתיים התפקיד של החומרה, החומרה עשתה מה שהיא יכולה והטיפול עובר לידי ה-kernel להריץ קוד של מערכת ההפעלה להתמודדות עם המצב שתהליך ניגש לדף שלא נמצא בזיכרון המהיר, אלא נמצא בדיסק.
* מערכת ההפעלה קודם כל צריכה לבדוק האם יש מקום בזיכרון המהיר (כי אנחנו רוצים לטעון דף מהדיסק אל ה-RAM ולשם כך נדרש מקום פנוי בזיכרון המהיר). אם אין מקום פנוי בזיכרון המהיר, מערכת ההפעלה מוצאת מסגרת ב-ram ומפנה אותה ע"י כך שהיא כותבת אותה חזרה לדיסק.
אחרי שפינינו מקום בזיכרון המהיר (או שלא נעשה), עכשיו מערכת ההפעלה יכולה לקרוא את הדף שרצינו מהדיסק ולכתוב אותו למסגרת פנויה בזיכרון. תהליך זה של טעינה מהדיסק נקרא page in ואילו תהליך של לקיחת דף מהזיכרון ואחסונו בדיסק נקרא page out.
* אחרי שטענו את הדף שאותו תהליך ביקש אל ה-ram, עכשיו צריך לעדכן טבלת דפים ואת נתוני הדף בה (את ה-present bit שלו, מספר המסגרת בטבלת הדפים וכו'..). לאחר מכן צריכים לעדכן את ה-tlb ורק אחרי כל זה אפשר לחזור על כל התהליך. הדף נמצא בזיכרון המהיר ואפשר להמשיך.
* אז כל התהליך הזה, מהרגע שקרה page fault ועד הרגע שחוזרים לתהליך המקורי שיבצע את הפקודה כדי שיבצע אותה עוד פעם - נעשה בתוכנה. זה תהליך מאוד איטי כי הוא כולל גם גישות לדיסק וזה לוקח זמן.
בזמן הזה, התהליך המקורי הוא blocked, הוא לא יכול לקבל יותר זמן מעבד כי הוא חייב להמתין שהפקודה תתבצע (שהזיכרון שהוא רצה יהיה זמין). הוא יישאר במצב blocked עד שיסיים ויהיה זמין להמשיך.

---------------------------------------------------------

זו אחת מהסיבות שאמרנו שלא יכולים להסתמך על תזמון תהליכים. כלומר אנחנו לא יכולים להניח שדברים ירוצו באותו קצב. כי יכול להיות שיש לנו שני תהליכים שרצים, ואחד מהם במקרה ניגש לזיכרון וקיבל page fault, אז עכשיו עד שהוא יבצע את הפקודה הבאה, תהליך אחר יכול להריץ המון פקודות בזמן הזה.
בגדול כל המנגנון הזה של page fault הוא מאוד איטי ונרצה שהוא יקרה כמה שפחות.

מה שדיברנו עליו עד עכשיו זה המנגנון של page fault (שמירת דפים בדיסק או טעינת דפים מהדיסק).
חלק נוסף הוא המדיניות: איך מחליטים איזה דף לפנות מה-ram אם הוא מלא ואנו רוצים את ה-tlb miss (זה לא אותה עסק!).
ההחלטה הזו יש השפעה על הביצועים של המערכת שלנו (אם נעשה את זה לא נכון, נקבל הרבה הרבה faults).

אלגוריתמים של מטמון (באופן כללי) - האלגוריתם גם נקלט ל-tlb וגם ל-ram (ה-tlb הוא cache של טבלת הדפים, וכשיש לנו swap, ניתן להסתכל על ה-ram כ-cache).
קודם כל לא מערכת ההפעלה לא מחכה לרגע האחרון כדי לפנות, אם נחכה עד שאין לנו מסגרת פנויה, זה יהיה יקר. במקום זה, מערכת ההפעלה מריצה תהליך רקע שנקרא swap daemon - זה תהליך שרץ בעדיפות נמוכה והוא כל הזמן דואג לפנות דפים, כלומר הוא תמיד דואג שיהיו קצת מסגרות פנויות, הוא לא נותן לזיכרון להתמלא עד הסוף.
התהליך הזה עובד עם שני ערכים:
1. low water mark - איפה הנקודה שבה חייבים להתחיל לפנות את הזיכרון (למשל תהיה כמות המסגרות הפנויות צריכה להיות 10 ומעלה, וכל פעם שמתקרבים ל-10 הוא יפנה).
2. high water mark - צריך גבול יותר גבוה שאומר "עד איפה אנחנו מפנים".
כלומר זה הגבול העליון שאומר מה המספר המקסימלי שעד אליו נפנה.
נניח שהערך הזה הוא 20, אז ברגע שיש פחות מ-10 מסגרות פנויות, ה-swap daemon מתחיל לפנות מסגרות עד שיש יותר מ-20. ככה אנחנו מפנים כמה בבת אחת ויש לנו קצת מרווח וכן הלאה, ואלו דברים יכולים לפעול מבלי לחכות שיהיה לנו מקום פנוי.

איך בוחרים מה לפנות?
אלגוריתם אופטימלי יודע - מנסים לנחש לאיזה דפים התהליך ירצה לגשת ומנסים לפנות דפים בצורה אופטימלית.
אבל כמובן שלא יודעים לאיזה דפים התהליך ירצה בעתיד לגשת, אז נסתכל על האלגוריתמים האופטימליים התיאורטיים כנקודת השוואה תיאורטית:
1. סט גישות - נניח שיש לנו תהליך שיש לו 4 דפים. סדר הגישות מפורט בתמונה ->
ה-cache שלנו בגודל 3 איברים. ברגע שנכנס איבר רביעי, אנחנו מתחילים לפנות. ה-cache בתור התחלה מתחיל ריק. יש לנו miss או hit בהתאם למה שנמצא ב-cache. התוכנית שלנו רצתה 10 פעמים ונעשתה דפים בסדר הזה.
ברגע שהגענו ל-miss בשורה ה-6, הגענו לדף שלא נמצא במטמון אבל גם אנחנו צריכים להוסיף אותו ואין לנו מקום. אנחנו צריכים לבחור מה להוציא.

| Access | Hit/Miss | Evict | Cache |
| :---: | :---: | :---: | :---: |
| 0 | Miss | | 0 |
| 1 | Miss | | 0,1 |
| 2 | Miss | | 0,1,2 |
| 0 | Hit | | 0,1,2 |
| 1 | Hit | | 0,1,2 |
| 3 | Miss | 2 | 0,1,3 |
| 0 | Hit | | 0,1,3 |
| 3 | Hit | | 0,1,3 |
| 1 | Hit | | 0,1,3 |
| 2 | Miss | 3 | 0,1,2 |
| 1 | Hit | | 0,1,2 |

האלגוריתם האופטימלי אומר שאנחנו צריכים להסתכל לעתיד. מה תהיה הגישה הבאה לכל אחד מהדפים הללו, ונפנה את זה שהגישה הבאה אליו היא הכי רחוקה. זה המצב האופטימלי.
הגישה הבאה לדף מספר 2 היא הכי רחוקה, אז זה הדף שנבחר לפנות.
נמשיך ונקבל hit על פני שגיעות דף מספר 2 שלא נמצא במטמון. נבדוק עכשיו את 0,1 או 3, מה לא נעשה את אי מי מהם.
עכשיו ניתן לחשב את ה-hit rate - כמה פעמים מצאנו בתוך המטמון לעומת כמה פעמים הוא חוץ מן ה-miss. בסט הגישות הזה, האלגוריתם האופטימלי הגיע ל-54.5%.
נזכור שזה האלגוריתם שמנצח לא יכול להיות יותר ממנו, זה המקסימום המצופה הספציפי הזה בזיכרון הזה בגודל הזה.

* Hit rate: 6/5+6 = 54.5%
* Without cold-start: 85.7%

---------------------------------------------------------

- על שלושת הגישות הראשונות בטבלה ניתן להגיד שהן תמיד יהיו miss, כי המטמון מתחיל ריק.
כלומר הגישה הראשונה לכל דף תמיד תהיה miss. לא יכול להיות שהדף הזה כבר במטמון אם אף פעם לא ניגשנו אליו. זה לא משנה באיזה אלגוריתם נשתמש, זה תמיד יהיה ככה. זה נקרא cold start - הגישות הראשוניות לכל תהליך. וכשמחשבים את ה-hit rate, אנחנו מעדיפים לחשב אותו בלי ה-cold start.
נחשב את האחוזים בלעדיהן ונקבל 85.7% של hit rate.

FIFO - אלגוריתם נוסף לפינוי מקום במטמון.
כל פעם שיש לפנות דף מהמטמון, נשים אותו בתור. הדף הראשון שנטען הוא גם הדף הראשון שייצא.
אלו שלושת הגישות הראשונות יהיו miss, וכל השאר יעבדו לפי התור.
האלגוריתם הזה קל מאוד למימוש וקל מאוד להבנה ואולי.

| Access | Hit/Miss | Evict | Cache |
| :---: | :---: | :---: | :---: |
| 0 | Miss | | 0 |
| 1 | Miss | | 0,1 |
| 2 | Miss | | 0,1,2 |
| 0 | Hit | | 0,1,2 |
| 1 | Hit | | 0,1,2 |
| 3 | Miss | 2 | 0,1,3 |
| 0 | Hit | | 0,1,3 |
| 3 | Hit | | 0,1,3 |
| 1 | Hit | | 0,1,3 |
| 2 | Miss | 3 | 0,1,2 |
| 1 | Hit | | 0,1,2 |

* Hit rate: 7/5+6 = 36.4% (or 57.1%)

שני האלגוריתמים הבאים מבצעים שימוש בהיסטוריה של תהליך כדי לנסות לחזות מה יהיה בעתיד שלו:
LFU (least frequently used) - נסתכל לעבר ונפנה את הדף שנעשה אליו הכי פחות (בתדירות הנמוכה ביותר).
LRU (least recently used) - נסתכל לפי זמן. מי שנעשה אליו גישה הכי רחוק בעבר, כנראה לא ייגשו אליו בקרוב, ומי שנעשה אליו לאחרונה - כנראה ייגשו אליו שוב.
בדוגמא: הגישה הרחוקה ביותר הייתה ל-2 ולכן אותו נפנה.

כל פעם שניגשים לדף מסוים אנחנו שמים אותו בסוף התור, ואז כשצריך לפנות דף אנחנו לוקחים את הראשון בתור ואז זה בעצם ייצא הדף שנעשה אליו הכי רחוק בעבר.
ההנחה היא שהדף שנהיה אליו הכי רחוק בעבר, אנחנו גם נעשה אליו הכי רחוק בעתיד.

| Access | Hit/Miss | Evict | Cache |
| :---: | :---: | :---: | :---: |
| 0 | Miss | | 0 |
| 1 | Miss | | 0,1 |
| 2 | Miss | | 0,1,2 |
| 0 | Hit | | 1,2,0 |
| 1 | Hit | | 2,0,1 |
| 3 | Miss | 2 | 0,1,3 |
| 0 | Hit | | 1,3,0 |
| 3 | Hit | | 1,0,3 |
| 1 | Hit | | 0,3,1 |
| 2 | Miss | 0 | 3,1,2 |
| 1 | Hit | | 3,2,1 |

---------------------------------------------------------

אלגוריתם Random - הבחירה להוצאה נעשית באופן אקראי.

Belady's anomaly - נניח שיש לנו מטמון בגודל 3. היינו מצפים שאם נגדיל את המטמון, הביצועים ישתפרו, או לפחות לא ייפגעו. אבל לא לכל האלגוריתמים זה נכון. לאלגוריתם כמו LRU יש תכונה שנקראת stack property שאומרת שאם הדף נמצא במטמון בגודל 3, אז כשנגדיל אותו למטמון בגודל גדול יותר, אפילו 4, הוא רק יכול יותר דברים ממה שהיה קודם, כלומר הביצועים לא ייפגעו (כי הוא מכיל את הנתונים שהיו לפני כן ועוד, אז לא ייתכן שיהיה לנו miss שלא היה לפני כן).

אבל ב-FIFO אין את התכונה הזו וזה עלול להוביל לבעיות וזה נקרא "האנומליה של בלדי".

נסתכל על סט הגישות בתמונה התחתונה - בעמודה הימנית.
תהליך זה עם דפים 1-5 והמטמון הוא בגודל 3.
בסט הגישות הזה אנחנו מקבלים hit rate של 25%.

| Access | Hit/Miss | Evict | Cache |
| :---: | :---: | :---: | :---: |
| 1 | Miss | | 1 |
| 2 | Miss | | 1,2 |
| 3 | Miss | | 1,2,3 |
| 4 | Miss | 1 | 2,3,4 |
| 1 | Miss | 2 | 3,4,1 |
| 2 | Miss | 3 | 4,1,2 |
| 5 | Miss | 4 | 1,2,5 |
| 1 | Hit | | 1,2,5 |
| 2 | Hit | | 1,2,5 |
| 3 | Miss | 1 | 2,5,3 |
| 4 | Miss | 2 | 5,3,4 |
| 5 | Hit | | 5,2,3 |

* Hit rate: 3/12 = 25%

לעומת זאת בתמונה התחתונה משמאל, נוכל לראות סט הגישות זהה לפני כן רק שכאן הגדלנו את המטמון לגודל 4 ו-hit rate ירד ל-16.7%.

| Access | Hit/Miss | Evict | Cache |
| :---: | :---: | :---: | :---: |
| 1 | Miss | | 1 |
| 2 | Miss | | 1,2 |
| 3 | Miss | | 1,2,3 |
| 4 | Miss | | 1,2,3,4 |
| 1 | Hit | | 1,2,3,4 |
| 2 | Hit | | 1,2,3,4 |
| 5 | Miss | 1 | 2,3,4,5 |
| 1 | Miss | 2 | 3,4,5,1 |
| 2 | Miss | 3 | 4,5,1,2 |
| 3 | Miss | 4 | 5,1,2,3 |
| 4 | Miss | 5 | 1,2,3,4 |
| 5 | Miss | 1 | 2,3,4,5 |

* Hit rate: 2/12 = 16.7%

אז הגדלנו את ה-cache וקיבלנו ביצועים פחות טובים בגלל המימוש של FIFO כי אין לו את התכונה stack property.
-------------------------------------------
ניקח את כל האלגוריתמים ונשווה ביניהם:
השוואה ראשונה: ניקח תוכנית שמשתמשת ב-100 דפים של זיכרון והיא עושה 10,000 גישות אקראיות (עוברים בלולאה 10,000 פעמים ובכל איטרציה מוגרל דף שאליו ניגשים).
נפעיל כל אלגוריתם ונראה את הביצועים שלו על פני הגרף.
ציר ה-x הוא גודל המטמון וציר ה-y הוא ה-hit rate.
כשגודל המטמון הוא 1, אז ב-FIFO ה-hit rate הוא כמעט 0%, יש רק מקום אחד במטמון וכל פעם צריך להחליף אותו בגישה הבאה.
כשגודל המטמון הוא 100, אז כל הדפים במטמון וה-hit rate הוא 100%. זה נכון לכל השיטות.

---------------------------------------------------------

ניתן לשים לב שהאלגוריתם האופטימלי לא מייחס חשיבות לכך שהגישות נעשות באופן אקראי, הוא מסתכל לעתיד ומבחינתו אין דבר כזה אקראי.
אבל LRU מתנהג אותו דבר כמו FIFO שמתנהג אותו דבר כמו האלגוריתם האקראי. בעצם אין מה ללמוד, רצף הגישות שנעשה הרבה גישות אקראיות לזיכרון, אין שום חוקיות ולכן ה-LRU לא מרוויח כלום מזה שהוא מסתכל על העבר ומנחש דברים לגבי העתיד, כי העבר לא אומר כלום לגבי העתיד.

למרבה המזל, התוכניות שלנו לרוב לא מתנהגות ככה (כלומר הן לא ניגשות באופן אקראי לזיכרון).
לרוב התוכניות שלנו בדרך כלל יש התנהגות דומה ל-workload הבא שנקרא 80-20:

נשתמש באותו רעיון: 100 דפים, 10,000 גישות אבל הפעם 80% מהגישות יתבצעו ל-20% מהדפים.
נבחר 20 דפים מתוך ה-100 וניגש בעיקר אליהם.
זה כבר יותר מייצג תוכנית אמיתית שבה יש משתנים או קטעי קוד שאנחנו ניגשים אליהם יותר וכו'.
עכשיו ניתן לראות שה-LRU עכשיו יותר טוב, כי יש מה ללמוד.
כמובן שהאלגוריתם האופטימלי הוא הכי טוב, ויותר מה-LRU, אבל עדיין ה-LRU יותר טוב מה-FIFO והאלגוריתם האקראי, כי יש מה ללמוד (כי הדף כן יכול לנחש, אפילו בצורה חלקית את הדפים שייגשו אליהם יותר).
-------------------------------------------
עכשיו נעשה עוד השוואה:
תוכנית שמשתמשת ב-50 דפים אבל בלולאה, כלומר היא ניגשת לכל אחד מהם (1,2,3..50).
ניתן לראות שהאלגוריתם האופטימלי עובד טוב.
ברגע שהמטמון בגודל 50 - כל האלגוריתמים על 100% hit rate כי כל הדפים במטמון.
אבל ניתן לראות שכשמטמון בגודל 49, גם ה-FIFO וגם ה-LRU עומדים על hit rate של 0%, כלומר בכל פקודה יש cache miss ו-page fault.
הסיבה היא שהאלגוריתם האקראי עובד טוב, פתאום הרווחנו מהאקראיות והאלגוריתמים החכמים שלנו כבר לא כאלה חכמים.

נזכיר למה:
נניח שיש לנו מערך בגודל 3, אנחנו ניגשים לדפים 1,2,3 וחוזר חלילה.
עכשיו נניח שהמטמון שלנו הוא בגודל 2. כשהתוכנית שלנו רצה, יש לנו misses ראשונים וטוענים למטמון 1, 2.
עכשיו כשתגש ל-3, מחפשים את מי להוציא מהמטמון, נסתכל לאחור - למה ניגשנו הכי רחוק בעבר וזה 1, אז נוציא את 1 ונכתוב במקומו 3. אבל כשאנחנו בלולאה, הדף הבא שאנחנו ניגשים אליו זה 1.

---------------------------------------------------------

כלומר ה-LRU פעל הפוך ממה שהוא היה צריך. הוצאנו את מה שייגשו אליו הכי רחוק בעבר אבל זה הכי קרוב שייגש אליו בעתיד. ואנחנו נמשיך ככה כל פעם. כך זה יעבוד גם במטמון בגודל 49.

- כשהמערך היה קטן, הוא תפס כמות כלשהי של דפים ויכולנו לעבור עליה. אבל ככל שהגדלנו את המערך, הוא תפס יותר ויותר זיכרון, עד שהוא חרג מגודל המטמון שלנו.
האלגוריתמים שעובדים מצוין במחשב הזה או אלגוריתם שדומה מאוד ל-LRU - כשמדובר על המערך שוב ושוב בלולאה, ברגע שהוא מגיע לגודל מסוים אנחנו חורגים מגודל המטמון וכל הזמן מקבלים miss והתוכנית יישמה שיטת גישה מאוד לא יעילה לזיכרון.

הפתרון של מערכת ההפעלה לבעיה הזו זה לא לפתור אותה.
אנחנו צריכים להכיר את הבעיה ופשוט לדעת להתמודד איתה בתכנות.
יש כל מיני דרכים להתמודד איתה כמו לעשות גישות ריקות למערך או לא לעשות לולאות כאלה על ערכים מאוד גדולים.
זה ה-LRU שעליו אנחנו צריכים להכיר את הבעיה ולהבין למה הביצועים שלנו הם כאלה.
-------------------------------------------
יש הרבה רמות cache בקוד שלנו ומה שזה הראה זה ששאלת הרמות הייתה בעיה.

חוץ מהתופעה הזו, LRU עובד טוב, הבעיה היא שאי אפשר לממש אותו. למה? כי אי אפשר לכתוב אלגוריתם כזה, אלא כי הוא מאוד לא יעיל. כל פעם שניגשים לזיכרון אנחנו צריכים להפעיל לוגיקה שהיא לא טריוויאלית.
כל פעם שאנחנו ניגשים למשהו, אנחנו צריכים משהו שיעדכן לנו את נתוני הגישה אליו.
כל פעם שאנחנו צריכים למצוא את זה שפחות ניגשנו אליו מכל ה-מיליון דפים שיש לנו במטמון ולפנות אחד מהם, זה לוקח המון זמן (כל הסריקה הזו וכל העדכונים).
לא משנה כמה טוב יהיה האלגוריתם הזה וכמה הוא מתקרב לאופטימלי, המימוש של ה-LRU יהרוס לנו את כל הביצועים שהרווחנו.

אז הגישה שנוקטים בה - האם אנחנו באמת צריכים את הדף הכי ישן (שניגשו אליו הכי הרבה בעבר) או שמספיק לקחת פשוט דף ישן (שהוא לא בהכרח הכי ישן כלומר כזה שלא ניגשו אליו זמן מה, ואותו נוציא).
זה ייתן לנו קירוב די טוב ל-LRU, זה נקרא אלגוריתם השעון (CLOCK ALGORITHM).

בחלק מהביטים שקיימים ב-pte, קיים ביט שנקרא reference bit שאומר האם ניגשו לדף לאחרונה (הביט הזה נקרא using). כל פעם שניגשים לדף כלשהו (קריאה/כתיבה), הביט נדלק.
אלגוריתם השעון משתמש בביט הזה ומחכה זמן בשביל להוריד אותו ולבדוק לאחרונה.

למשל: נניח שיש לנו מטמון עם 4 מקומות.
כרגע אנחנו מצביעים (נמצאים) על הדף השני במטמון (B). כשמתבצעת גישה ויהיה צורך לפנות דף, המצביע הזה יתקדם על הרשימה עד שהוא ימצא דף שבו הביט הוא 0, ואותו נפנה (זה כנראה מישהו שלא ניגשו אליו לאחרונה).
אבל, תוך כדי שאנחנו עוברים, כל דף שאנחנו פוגשים בדרך, אנחנו הופכים את ה-used bit ל-0.
כי אם נעשה סיבוב שלם ונחזור ל-B והוא עדיין 0, זה אומר שלא ניגשו אליו. אם כן היו ניגשים אליו הוא היה הופך ל-1.

Approximating LRU
Access E
Access C
Access A
Access F

---------------------------------------------------------

ניקח את הגרף שלנו של ה-80-20:
רואים שהנקודות השחורות (של השעון) מתקרבות מאוד ל-LRU. אז אלגוריתם השעון עובד דיי טוב, זה מה שיש לנו במחשבים בפועל.

שיפור נוסף: היה עוד ביט שנקרא Dirty bit - כל פעם שאנחנו משנים דף, הביט הזה נדלק ל-1.
בפעם הראשונה שאנחנו טוענים דף מה-swap לזיכרון, הביט הזה הוא 0, מה שזה אומר שהדף הזה הוא clean, נקי, כלומר מה שיש לנו בדיסק זהה למה שיש לנו ב-RAM.
ברגע ששינינו ערך בדף הזה, הביט יידלק והמשמעות שהדף שונה וזה לא זהה לערך שיש בדיסק.

היתרון בדפים שהם clean הוא שניתן לפנות אותם בקלות. אם יש לנו את ה-swap, טענו דף אל ה-RAM ולא שינינו אותו, הוא נקי (ניגשו אליו הרבה לצורך קריאה) אז לא צריך לכתוב אותו חזרה לדיסק, כי מה שיש בדיסק עדיין תקף. זה קל וזול לפנות את הדף הזה.
זה חיסכון של פעולה שלמה של כתיבה לדיסק, שזו פעולה איטית.
אז אלגוריתם השעון שלנו משופר בכך שהוא לא מחפש רק דפים שה-used bit שלהם הוא 0, אלא מחפש גם דפים שהם clean, שה-dirty bit שלהם הוא 0.
אם אחרי זמן מה הוא לא מצא דף כזה, אז הוא יתחיל לחפש רק used (מבלי להתייחס ל-dirty bits).

הדבר האחרון שקורה - אם ניגשנו לדף מסוים (זה נכון במיוחד לקוד של תהליך) כנראה שניגש לדף שאחריו (בזיכרון הווירטואלי). אם ניגשנו לדף מספר 2, כנראה שנרצה לגשת לדף מספר 3 גם.

prefetching - מנגנון שאומר - אם כבר הגשנו swap ואנחנו טוענים דפים מהדיסק אל ה-RAM, לא נעשה את זה בשביל דף אחד, נטען גם את הדף הבא/הבאים ונטען אותם בבת אחת.
זה מנצל את התכונה של הדיסק שלעשות פעולה אחת גדולה זה הרבה יותר מהיר מאשר כמה פעולות קטנות.

clustering - פעולה נוספת שקורית היא קיבוץ של כתיבות. כתיבה לדיסק היא פעולה יקרה, אם ניתן לקחת כמה פעולות כתיבה ולעשות אותן ביחד במקום לכתוב כל פעם דף יחיד, נעשה זאת.
ומה שקורה זה שהאלגוריתם של ה-page fault שלנו שומר דפים שהשתנו (בדיסק), הוא לא כותב אותם מיד לדיסק, וברגע שהצטברו מספיק שינויים הוא לוקח את כולם בבת אחת וכותב לדיסק.

סיימנו את החלק הראשון של הקורס - וירטואליזציה.

