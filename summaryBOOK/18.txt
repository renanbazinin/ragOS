מערכות הפעלה - שיעור 18

אנחנו נדון בבדיקה של סקטור אחד. עכשיו: יש לנו 2 הארד דיסקים לדוגמא, שנקראים צ'יטה וברקודה, ואנחנו רוצים לבחון את הביצועים שלהם ולהשוות ביניהם.

בכדי לבחון את הביצועים שלהם אנחנו לא בודקים קריאה של סקטור בבודד, אלא ניקח תרחיש כלשהו שאמור לדמות תוכנית. ניקח תרחיש אקראי ותרחיש סדרתי (אנחנו רוצים להשוות בין פעולות שמתבצעות בכל פעם במיקום אחר בדיסק, כלומר באופן אקראי, לבין פעולות שמתרחשות באופן סדרתי ולראות את הפער בביצועים).

התרחיש האקראי: תוכנית שעוברת על הדיסק וכל פעם קוראת מנקודה אחרת במיקום אקראי בדיסק.
ניקח לדוגמא- תוכנית שעושה קריאות בגודל 4KB, כל פעם קוראים 8 סקטורים ממקום כלשהו בדיסק, ואז הולכים למיקום אקראי אחר וקוראים ממנו עוד 4KB וכן הלאה.
נרצה לדעת מה קצב ההעברה שנקבל בתוכנית שלנו בגישות הללו לדיסק.

התרחיש הסדרתי: ניקח מקרה סדרתי בו אנחנו ניגשים למקום כלשהו בדיסק וקוראים המון מידע ברצף.
בדוגמא שלנו נקרא 100MB.

| | Cheetah | Barracuda |
| :--- | :--- | :--- |
| RPM | 15,000 | 7,200 |
| Average Seek | 4 ms | 9 ms |
| Max Transfer | 125 MB/s | 105 MB/s |

- הנתונים שמעניינים אותנו: זמן ה-seek, זמן ה-rotation, וזמן ה-transfer.
בעזרת נתונים אלו, נוכל לחשב את הקצב האמיתי (כי מה שנתנו לנו זה המקסימלי להעברה, שהוא במקרה האופטימלי בו לא מזיזים את הזרוע אף פעם, כלומר זה קצב ההעברה בהנחה שהזרוע נמצאת במיקום המתאים לתחילת הקריאה).
ה-average seek נתון לנו. זמן הסיבוב תלוי במהירות הסיבוב. אנחנו שחישבנו שעם קצב RPM של 7,200, אנחנו מקבלים זמן סיבוב של 8.33ms (של הצ'יטה).
בצ'יטה יש לנו 15,000 סיבובים לדקה. אנחנו רוצים לחשב כמה זמן לוקח סיבוב אחד.
הזמן של סיבוב זה 1/15,000 דקה. אבל דקות זה לא היחידה שאנחנו רוצים, אז נמיר את זה לשניות: 60/15,000 שניות לוקח סיבוב אחד. נמיר את זה למילישניות, אז 60 שניות זה 60,000 מילישניות – אז מדובר על 60,000/15,000 מילישניות לסיבוב אחד. שזה 4 מילישניות לסיבוב יחיד של הצלחת. הממוצע שלנו זה חצי סיבוב, אז נחלק ב-2 ולכן הזמן הממוצע בו אנחנו מחכים לסיבוב הוא 2 מילישניות.
כעת כשיש לנו את הזמן הממוצע לסיבוב עבור כל דיסק, ואת זמן ה-seek הממוצע של שניהם, נוכל לחשב את זמן ההעברה.
- אמרנו שבמקרה האקראי אנחנו עושים הרבה קריאות של 4KB בכל מיני מקומות אקראיים.
זמן ההעברה הוא הזמן שייקח לנו להעביר 4KB. אם נסתכל על הדיסק, נראה שאנחנו מעבירים 125MB/SEC, מה שאנחנו רוצים למצוא זה- כמה מילישניות ייקח לנו להעביר את כל הנתונים שלנו (4KB).
ראשית, נרצה לחשב כמה מילישניות לוקח להעביר kb בודד, ואז נכפול את זה ב-4.
125MB/SEC אומר שלוקח לנו 1/125 שניות להעביר מגה בייט יחיד. נסביר את זה למילישניות – זה 1000/125 מילישניות להעביר מגה בייט יחיד. כעת נרצה לעבור ממגה בייט לקילו בייט ולכן נכפול את המכנה ב-1024 ונקבל 1000/(125*1024) מילישניות להעביר קילו בייט יחיד. נכפול את מה שקיבלנו ב-4, וזה הזמן שלוקח לנו להעביר 4000/(125*1024) :4KB.
זה יוצא 30 מיקרו שניות.

- בדיסק השני: קצב ההעברה הוא 105MB/SEC.
ייקח לנו 1/105 שניות להעביר מגה בייט יחיד. כלומר: 1000/105 מילישניות להעביר מגה בייט יחיד.
נעבור ליחידות של קילו בייט (נכפול את המכנה ב-1024): 1000/(105*1024) מילישניות להעביר קילו בייט יחיד.
זה יוצא 38 מיקרו שניות.

- אם נרצה לחשב את ההעברה הסדרתית, שאמרנו שהיא 100MB:
חישבנו לפני כן כמה זמן ייקח לנו להעביר מגה בייט יחיד, אז נכפול ב-100 את שתי התוצאות שיצאו לנו (נחזור לכל דיסק) ונוכל.

המספרים הסופיים שהגענו אליהם:

| | Cheetah | Barracuda |
| :--- | :--- | :--- |
| T_seek | 4ms | 9ms |
| T_rotation | 2ms | 4.2ms |
| Random T_transfer | 30μs | 38μs |
| Sequential T_transfer | 800ms | 950ms |

בהעברה הסדרתית, אנחנו עושים seek, rotation, big transfer. (פעם אחת מכל אחד).
באקראי, אנחנו עושים בכל קריאה - seek, rotation, transfer, ככה מספר פעמים.

כעת נרצה לחשב את הקצב. קצב ניתן לחשב או משנה מה גודל ההעברה.
נחשב את המהירות הממוצעת בכל אחד מהתרחישים.
נסכום את הזמנים (זמן ה-seek + זמן ה-rotation + זמן ה-transfer).

המהירות הממוצעת במקרה האקראי:
ה-transfer זניח במקרה האקראי ולכן לא נתייחס אליו.
צ'יטה: הזמן שקיבלנו הוא 2ms + 4ms = 6ms.
המשמעות היא שכל פעולה כזו של 4KB לוקחת 6ms.
נרצה לחשב את הקצב (המהירות הממוצעת, ביחידות של MB/SEC): הקצב של הדיסק שניתן לנו הוא הקצב האופטימלי, אבל אנחנו רוצים להגיע לקצב האופטימי (כמה מהירות נקבל בפועל).
כל פעולה לוקחת 6 MS ו- 4KB. אז נרצה להעביר מ-4KB ב-6 מילישניות ל-X מגה בייט לשנייה (נכפול את המונה ב-1000 ונקבל 4000/(1024*6) MB/SEC, שזה 0.66 MB/SEC.

ברקודה: חישוב דומה רק שנולי את הזמן ב-13.2ms. יוצא 0.31 MB/SEC.

- זה הקצב שיש אליו בביצוע פעולת קריאה של 4000 בתים בכל אחד מהדיסקים.

המהירות הממוצעת במקרה הסדרתי:
צ'יטה: הסכום הוא 806 ms. לכן לוקח לנו 806 ms להעביר 100MB. לכן זה 100MB/0.8 SEC.
ברקודה: חישוב דומה רק שנולי את הזמן ב-960 ms ונקבל 100MB/0.96 SEC.

- זה כמעט הזמן האופטימלי. ניתן לראות את הפער המשמעותי בין הקריאה הסדרתית לקריאה אקראית.
- לכן אם נקרא נתונים ממקום אחד באופן סדרתי (על ידי אפילו לשנות את הקוד שלנו לקוד פחות יעיל, אם הוא יכול לעשות קריאות באופן סדרתי).
- מערכות הקבצים שלנו בנויות בהסתמך על זה (ניסיון לפעולות סדרתיות כמה שניתן).

נחזור לדבר על המבנה של הדיסק, שיפורים שעשו בדיסק:
נחשוב על מצב בו מישהו מבצע קריאה של סקטורים רצופים.
נזכור שבעבור מערכת ההפעלה, הדיסק הוא מערך אחד גדול של סקטורים. מערכת ההפעלה לא מכירה את המבנה הפנימי של הדיסק. היא רק מעבירה את האינדקסים שהיא רוצה לקרוא.
נניח ומערכת ההפעלה רוצה לקרוא את אינדקסים 15-20. אם ננסה קריאה של 20, 15, הראש קורא כותב יקרא את סקטור 15 ואז יצטרך לצאת החוצה. ברגע שהראש קורא וכותב יצא החוצה, הוא מפספס את סקטור 16 (כי עד שהוא יצא, הדיסק ממשיך להסתובב ו-16 "בורח" ועד שהוא יחזור נצטרך לחכות כמעט סיבוב שלם עד ש-16 יחזור מתחת לראש קורא כותב ונוכל להמשיך את הקריאה באופן סדרתי).
זה יהיה מאוד לא יעיל והארד דיסקים לא בנויים ככה.
לכן קיים בהארד דיסק: Track skew - כאשר אנחנו יוצאים מ-track מסוים ל-track הבא, הסקטורים בו יהיו בק-shift, קצת קדימה יותר, בהתחשבות מדויקת בזמן של ה-seek. כאשר הראש קורא/כותב יסיים לקרוא את 15 ויוצא ל-16, הוא יסיים בערך בסקטור 23. כך הוא יוכל לעשות את הקריאה הסדרתית ברצף ובצורה יעילה.

Multi-zoned disk drives - דבר נוסף שקורה בדיסק- ככל שמתרחקים ממרכז הדיסק (בגלל שדיסק הוא עגול), יש לנו יותר שטח. סקטורים כבר לא יכולים להיות ביותר גודל. לכן מחלקים את הדיסק לאזורים (zones). ככל שמתרחקים ממרכז הדיסק, האזורים (ה-tracks) מחולקים ליותר סקטורים.

cache & read ahead - כשהראש הקורא/כותב עובר על סקטורים. בזמן שהוא ממתין (מחכה לסיבוב), הוא לא מחכה ומקבל את הזמן, אלא הוא כבר מבצע קריאה של כל מה שעובר מתחתיו, ושם ב-cache של הדיסק עצמו (של החומרה). אם יבקשו אותם לאחר מכן, הם יהיו זמינים. גם מערכת ההפעלה עושה את זה. כשאנחנו רוצים לקרוא 10 בתים מקובץ, מערכת ההפעלה לא הולכת וקוראת רק 10 בתים מהדיסק, אלא קוראת 1000 בתים למשל, ושומרת ב-cache.
אם המשתמש ימשיך לקרוא מהקובץ, יש לנו כבר את הנתונים זמינים. אחרת, לא נורא, זה לא בזבז הרבה ביצועים כי זו הייתה קריאה סדרתית.

write-through cache - ברגע שאנחנו עושים פעולה, אנחנו כותבים אותה ישר. אבל אמרנו שזה לא יעיל, וזה גם לא יעיל בדיסק. לכן נשתמש ב-Writeback cache: נאגור כתיבות, ואז נכתוב את כולן בבת אחת. זה גם יותר יעיל וגם אולי נוכל להפוך משהו אקראי לסדרתי. הסיכון העיקרי בגישה הזו הוא שאם תובטח לנו סדר ולכן עלולה להיות בעיית עקביות, ועלול להיות אובדן מידע במקרה של מחשב שנכבה.

בתוך ההארד דיסק שלנו יש מנגנון (בדיוק כמו שלנו יש מנגנון נהליכים שמחליט מה ירוץ בכל רגע נתון). אם קיבלנו פקודה לכתוב לסקטור 10 ואז ל-11 ואז ל-12 ואז ל-8, הדיסק לא בהכרח יטפל בהם בסדר הזה. הוא יודע לעבור בקשות (גם קריאה וגם כתיבה) ולטפל בהם בסדר שהוא רוצה. במצב אידיאלי, ההארד דיסק יטפל קודם ב-8 (למרות שהגיעה אחרונה) ואז ב-10,11,12 כדי לשמור על פעולה סדרתית.
ההארד דיסק יכול לדעת כמה זמן כל פעולה תיקח, למרות שנהליכים שונים היינו יכולים לדעת כמה זמן דברים ייקחו- היינו יכולים לעשות אלגוריתם אופטימלי. בגלל שאנחנו לא יודעים, השתמשנו במנגנונים שאנחנו עושים. ההארד דיסק אנחנו לא יודע מה יגיע בעתיד, אבל הוא יודע בדיוק כמה זמן כל פעולה תיקח ולכן הוא יכול לחשב.

First come, First served (FCFS): נטפל בבקשות לפי הסדר. אם למשל ה-seek+rotation=10 ms.
כמה זמן נחכה על תעודה בדיסק לפי תזמון כזה?
• 300001, 700001, 300002, 700002, 300003, 700003
~60ms

• 300001, 300002, 300003, 700001, 700002, 700003
~20ms

Shortest Positioning Time First (SPTF): נטפל בבקשה לפי זה שייקח לנו הכי פחות זמן לטפל בה.
הבעיה בגישה הזו: לא כ"כ אפשרי בתוך OS אלא במערכת ההפעלה. מערכת ההפעלה לא מודעת למבנה של הדיסק, לכן יכול לקרוא מצב בו מערכת ההפעלה תעשה תזמון שגוי. לכן האלגוריתם הזה מבוצע בתוך הדיסק.
הדיסק לוקח תמיד סט של בקשות, מטפל בהן ועובר לסט הבקשות הבא.
הדרך הזו מבטיחה לנו שהדיסק יטפל בכל הבקשות בצורה נכונה וחכמה, ובנוסף, לא ייתכן הרעבה (אם כל הזמן יגיעו בקשות קרובות למיקום של הראש קורא/כותב באותה עת, בקשות רחוקות יותר לא יטופלו) כי הדיסק מטפל תמיד בסט של בקשות מסויים ואין לו מעבר לבאות.

Shortest Seek Time First (SSTF): אלגוריתם שמערכת ההפעלה כן יכולה להשתמש בו.
לקחת הסקטור הכי קרוב (איפה שאנחנו עכשיו במערך) ונטפל בהם לפי הסדר, כמה שניתן.

*לכל האלגוריתמים שדיברנו עד עכשיו, יש את הבעיה העיקרית של הרעבה (למרות שאמרנו שהדיסק בעצם קורא סט של בקשות בכל פעם).
האלגוריתם שפתר את בעיית ההרעבה ומערכת ההפעלה עצמה משתמשת בו: אלגוריתם המעלית.
אלגוריתם המעלית אומר- נטפל בבקשות לפי הסדר האידיאלי, אבל נטפל בבקשות לפי סדר עולה של סקטורים.
זו כמו מעלית שעולה בקומה, אם אנחנו בקומה 5 ועולים למעלה, ומגיעה בקשה מקומה 2, לא נטפל בה. אנחנו עולים למעלה, מטפלים בבקשות בכיוון אחד. כאשר נגיע לבקשה המקסימלית ואין יותר לאן להמשיך, נחזור למטה.
זה לא אלגוריתם אידיאלי. מערכת ההפעלה שולחת את הבקשות לפי סדר המספרים במערך. למשל אם מגיעה אליה בקשה לסקטור קטן יותר ממה שאנחנו עליו כרגע, היא לא תשלח את הבקשה הזו.
בגלל שאנחנו שולחים כמה בקשות בבת אחת לדיסק, הוא עדיין יכול לעשות סידור פנימי של עצמו. בכל מקרה מערכת ההפעלה שולחת בקשות רק בסדר עולה.
בדיוק כמו מעלית, אנחנו מטפלים רק במי שקרא לנו. כלומר, עולים למעלה כל עוד יש בקשות להגיע אליהן, וברגע שאין עוד בקשות מלמעלה- יורדים חזרה למטה.
** הרעיון של האלגוריתם הזה הוא למנוע הרעבות מצד אחד, ומצד שני "להפיל" על הדיסק את האחריות לאופטימיזציה.
אנחנו נשלח לו את כל הבקשות לפי הסדר, והוא יעשה את ההתאמות שלו.

- כל מעבר כזה על הדיסק נקרא sweep (עושים sweep למעלה, sweep למטה) וככה מטפלים בבקשות.

- שני שדרוגים לאלגוריתם הזה:
F-SCAN: נעד למנוע מצב שהוא כביכול הרעבה. נניח שאנחנו בדיסק שיש בו מיליון סקטורים, אנחנו בסקטור 2 וקיבלנו בקשה לסקטור מיליון. אנחנו עולים למעלה, ואז מגיעה בקשה ל-3, ואז בקשה ל-4 ו-5. אז ייקח זמן לטפל בהם, והבקשה בסקטור מיליון תעוכב. הבקשות הנמוכות יותר הגיעו אחרי הבקשה לסקטור מיליון.
השדרוג הזה אומר: אחרי שהתחלנו לנוע בכיוון מסוים, אנחנו לא מתייחסים לבקשות חדשות. נשים אותן בצד.
אחרי שהגענו למעלה, נרד למטה ובדרך למטה נטפל בכל מי שממתין בצד. וכן הלאה. אנחנו בעצם מקפיאים את התור. כל בקשה שמגיעה, הולכת לתור החדש, ולא מטפלים בה, וכאשר מסיימים את ה-sweep הנוכחי, עוברים ל-sweep הבא ומטפלים בכל הבקשות שהיו בתור החדש. כך נמנעת הרעבה (סיבוב ארוך מאוד) של בקשות רחוקות שתמיד נדע עליהן.

C-SCAN: אם נשים לב, בשיטה שלנו יש חוסר הוגנות. בקשה שהיא באמצע, תטופל יותר מהר.
השדרוג הזה אומר: נטפל בכל הבקשות במהלך ה-sweep למטה, ואז נרד מבלי לטפל בשום בקשה ונעלה שוב.
כלומר מהסקטור האחרון יורדים ישר לסקטור הראשון ומתחילים רק בכיוון אחד (מלמטה למעלה או מלמעלה למטה).
כך כולם מטופלים באופן שווה.

נניח שהראש קורא/כותב נמצא עכשיו על סקטור 30, והתקבלו בקשות ל-16 ול-8.
איך נחליט מה יותר טוב לטפל בו? אולי בתוך מערכת ההפעלה, אין לנו שום מושג. יכול להיות שהראש קורא/כותב יהיה מספיק מהיר (זמן ה-seek יהיה מספיק מהיר) כך שיפספס את 8 אבל יספיק את 16. ואז הוא מספיק מהיר, עדיף לנו לטפל ב-8 (אם ה-rotation delay < seek time). אחרת ייטען שעד שנעבור מ-30 לחלק החיצוני, כבר ניאלץ לעבור סיבוב ולחכות סיבוב שלם, אולי עדיף לטפל במקרה הזה ב-16. אלה שיקולים שמערכת ההפעלה לא יכולה לקבל, אבל הדיסק שלנו יודע בדיוק מה טוב, ולכן הוא אוצר בקשות. הוא מקבל סטים של בקשות והוא יחליט את הסדר הפנימי שלו.

בדיסקים מודרניים, ה-seek time וה-rotation הם יחסית שקולים.
ההארד דיסק שלנו לעיתים מתזמן בקשות וגם מערכת ההפעלה לעיתים מתזמנת בקשות ומשנה את הסדר וכו'.
אם למשל מגיעה בקשה לסקטור 33 למערכת ההפעלה, היא לא ישר שולחת את זה לדיסק. היא מחכה קצת למקרה ויגיעו בקשות נוספות. אם למשל יגיעו בקשות ל-33,8,34: מערכת ההפעלה תשלח את 33-34 כבקשה אחת וההארד דיסק יודע לקבל בקשה של קריאת מסקטור 33 עד סקטור 34. ההבדל הוא קטן, אבל זה מוריד את כמות הבקשות וגם הופך בקשה אחת לסדרתית.
זה קורה גם בקריאות וגם בכתיבות.
ייתכן שנקבל אישור על כתיבה שהתבצעה כשבפועל היא לא התקבלה ומערכת ההפעלה שומרת את הבקשה ב-cache ומחכה לבקשות נוספות יותר טובות.
לשם כך יש קריאות כמו flash, שמבקשות ממערכת ההפעלה לבצע מיידית את מה שיש ביוון.
- עם כל השיפורים הללו, הדיסק עדיין איטי. גם דיסק שהמהירות האופטימלית שלו היא 125MB/sec, זה עדיין איטי, ונדיר גם שנגיע לזה.

- בעיה נוספת בדיסקים: הם לא אמינים. אם נשתמש הרבה בהארד דיסק, הוא יתקלקל. מה נעשה עם כל הנתונים שנמצאים עליו?
- לשם כך יש לנו מנגנון שנקרא raid. זהו מנגנון תוכנה (אפשר גם בחומרה), שמשתמש את הארד דיסקים שלנו (שיהיו יותר מהירים ויותר אמינים). ניתן לעשות raid גם במחשב האישי שלנו אבל זה יותר נפוץ בשרתים ובחברות.

יש לנו הרבה נתונים ואנחנו רוצים לשמור אותם, אבל אנחנו רוצים גם ביצועים טובים יותר וגם אמינות טובה יותר.
פתרון /: JBOD (just a bunch of disks): שנשתמש בכמה הארד דיסקים.
בכל כונן קשיח כזה תהיה מערכת קבצים ונתונים משלו, והתוכנית שלנו תנהל קבצים בכמה מקומות שונים (אולי נשמור גיבויים וכו').
זו הגישה שאנחנו מכירים אליה, אבל הבעיה בגישה הזו: זה מסורבל לכתוב כל תוכנית שתתייחס לכך בצורה מיוחדת ותפצל את המידע שלה. את המנגנון של raid בא לנהל לנו את זה באופן שקוף.

מערכת raid: Raid(redundant array of independent disks): נחשב דיסק מדומה.
בדומה לזיכרון וירטואלי, נצפה בדיסק מדומה, דיסק לוגי. כשהתוכנית עובדת היא תכתוב את כל הנתונים שלה למקום אחד (רכיב חומרה- הארד דיסק לוגי), וגם מערכת ההפעלה לא תדע שמדובר בדיסק מדומה. מבחינתנו יש הארד דיסק אחד.
יש רכיב חומרה (יכול להיות קוד) שמתפעל את הנתונים שלנו. הוא מכיר את כל ההארד דיסקים שחיברנו (כמה כוננים שונים שיש לנו במחשב) והוא יפצל את הנתונים (וגם אם צריך, יכפל קבצים וכו'..) ויביא לנו את הביצועים באופן שקוף.
התוכנית שלנו יכולה להמשיך לעבוד רגיל ולשמור איך שהיא רוצה, ומנגנון ה-raid יפצל אותם באופן כזה.

מערכת ההפעלה והתוכנית שלנו רואות משהו בלו בלוקים/סקטורים (בדוגמא הזו הארד דיסק המוחלק ל-8 בלוקים/סקטורים). אבל ההארד דיסק הזה הוא לוגי והוא לא באמת קיים. מה שבאמת קיים זה 4 דיסקים פיזיים שמחוברים למחשב ובכל אחד יש 2 בלוקים.
כל סט של בלוקים מופיע במיקום אחר.
כאשר אנחנו ניגשים לבלוק 2, יש מיפוי (כמו זיכרון וירטואלי) של הדיסק פיזי.
למשל בדיסק 2 בבלוק 1, תמוהה בלוק 7 של ההארד דיסק לוגי.
אנחנו רואים דיסק אחד כבפועל יכולה להיות כל כמות של דיסקים מאחורי הקלעים.
raid שקוף לחלוטין עבור מערכת ההפעלה, כי היא בטוחה שהיא שולחת אליו רק סקטור אחד.
בפועל כל מאחורי הקלעים רכיב חומרה/קוד שמנהל את שאר הדיסקים ועושה את החלוקה.
- בטבלה ניתן לראות את המיפוי של איזה בלוקים לוגיים מכל כל דיסק פיזי.

יתרונות של ה-raid:
1. שימוש במספר דיסקים במקביל, מהירות: ברגע שחילקנו את הנתונים שלנו לכמה מקומות, אם עכשיו מישהו קורא את סקטור 0 מנהליך אחד ורוצה לקרוא את סקטור 3 – במצב רגיל היינו צריכים לקרוא אחד אחד, אבל עכשיו עם הדיסק הווירטואלי, לא חייבים לקרוא אחד אחד, כי אם הסקטורים הללו נמצאים בדיסקים פיזיים שונים, ניתן לקרוא אותם מהדיסקים שלהם במקביל.
גם אם עשינו פעולה רצופה, אם רצינו לקרוא את סקטורים 0 עד 3 – במצב רגיל היינו צריכים לחכות 4 קריאות, ועכשיו נצטרך לחכות רק 2 קריאות (כי הוא יקרא את 0,1 מהדיסק הפיזי שלהם ואת 3,4 מדיסק פיזי שונה).

2. שטח אחסון: אנחנו יכולים מהרבה דיסקים קטנים, לייצר דיסק מדומה אחד גדול.
אם יש לנו 10 דיסקים של 1T, במקום לחלק בעצמינו את הנתונים, יש לנו עכשיו דיסק אחד גדול של 10T, והקוד עצמו ידע לחלק ביניהם את הנתונים.

3. אמינות: אם נשמור נתונים בכמה דיסקים, אם דיסק אחד יתקלקל, נוכל להביא את הנתונים מדיסק אחר.

- השימוש העיקרי של raid הוא בדומה לזיכרון וירטואלי, שזה יהיה שקוף לחלוטין.
אנחנו משתמשים בו כאילו זה הארד דיסק רגיל.

- raid מגיע בכל מיני רמות יש סוגים של raid.
Raid-0: רמת raid שמשתמשת בטכניקה של striping. הטכניקה הללו נועדה לשפר את הביצועים.
striping- נחלק את הסקטורים השונים בין הדיסקים לסירוגין, פעם לדיסק אחד, פעם לדיסק אחר.
נניח שיש לנו דיסק וירטואלי אחד ו-2 דיסקים פיזיים, אז נשים את הסקטורים לסירוגין בין הדיסקים.
הרעיון מאחורי הפיזור לסירוגין: רוב הפעולות שנרצה לעשות על הדיסק, יהיו סדרתיות, ואם עכשיו מישהו ירצה לקרוא שני סקטורים, נוכל לנצל אותם במקביל. זה גורם להגברת הביצועים בכמעט פי 2.
- אנחנו לא חייבים לעשות striping כל סקטור. יש דבר שנקרא chunk size – כמה בלוקים אנחנו שמים בכל דיסק, לפני שאנחנו עוברים לדיסק הבא. אז מה שדיברנו עליו עד עכשיו היה chunk size = 1 וניתן גם לראות בדוגמא העליונה משמאל ←
אם נבחר למשל chunk size = 2, זה ייראה כך ←

אותו עיקרון רק עם 4 דיסקים. בטבלה העליונה מדובר על chunk size = 1 ובתחתונה chunk size = 2.
סט אחד של בלוקים על פני כל הדיסקים אנחנו קוראים stripe (מהרגע שהתחלנו לכתוב לדיסק הראשון ועד שחזרנו אליו, אחרי שכתבנו סט אחד של בלוקים). למשל בדוגמא העליונה (בטבלה העליונה), stripe יהיה למשל בלוקים 0,1,2,3. כאשר ה-chunk size = 2, כל שני שורות יהיו stripe.

* ככל שנעשה chunks קטנים יותר, המקביליות שלנו תגדל. יש יותר סיכוי שפעולות שונות יהיו על בלוקים שונים. מה שאנחנו פוגשים בו בעיקר זה ה-positioning time- אם אנחנו רוצים לעשות קריאה כלשהי, כל הדיסקים צריכים להתמקם למיקום המתאים.

* ככל שנעשה chunks גדולים יותר, אנחנו מורידים את ה-positioning time כי פחות דיסקים יצטרכו לבצע את ההתמקמות (זה ייקח פחות זמן במקרה הממוצע). אבל, זה מוריד לנו את המקביליות בפעולה ספציפית. בקריאה רציפה מסוימת, יש יותר סיכוי שבלוקים יתפרסו על פחות דיסקים (יהיו על אותו דיסק). אבל עבור תהליכים שונים שקוראים קבצים שונים, זה עדיין יהיה בסדר.

* הנתון המקובל בדרך כלל chunk size-הוא 64KB (או 128 סקטורים של הדיסק). כלומר כל 64KB אנחנו עוברים לכתוב לדיסק אחר.

* איך אנחנו נמדוד כמה raid טוב? יש לנו 3 מדדים:
1. כמה מקום אחסון יש לנו (כי raid יכול לפגוע בכך). אם יש לנו 10T דיסקים, ייתכן שבגלל החלוקה הפנימית נראה שהדיסק הווירטואלי שלנו הוא רק 5T.
2. אמינות- אם דיסק מתקלקל, כמה מידע אובד לנו? (או- כמה דיסקים יכולים להתקלקל מבלי שנאבד מידע?)
3. ביצועים.

נמדוד כמה raid-0 הוא טוב:
1. הוא לא פוגע לנו בשטח האחסון. אם נשים שני דיסקים של 1T כל אחד, נקבל דיסק וירטואלי של 2T. לא איבדנו שטח אחסון.
זה שטח אחסון הכי טוב שניתן לקבל. אם יש לנו N דיסקים ו-B בלוקים, מה שהמשתמש יראה בדיסק הווירטואלי שלו זה N*B.
2. האמינות שלו מאוד גרועה. ב-raid-0, לא משנה איזה דיסק התקלקל, איבדנו מידע. אין לנו פה שום טיפול בגיבויים (שב-raids אחרים שנראה בהמשך, כן יש). פה רק מחלקים את המידע לשם ביצועים.
3. הביצועים שלו מעולים. ברגע שאנחנו משתמשים בכל הדיסקים, אנחנו יכולים להשתמש בהם לרוב במקביל, ולשפר את הביצועים באופן משמעותי.

הביצועים של raid-0 בתרחיש סדרתי ובתרחיש אקראי:
- נניח שבקריאה סדרתית, קריאה מהדיסק לוקחת S mb/sec
- נניח שבקריאה אקראית, קריאה מהדיסק לוקחת R mb/sec
אנחנו יודעים ש-S>R.

- כאשר אנחנו מקבלים קריאה סדרתית ב-raid-0, אנחנו יכולים לחלק אותה בין כל הדיסקים.
אם יש לנו שני דיסקים ואנחנו מחלקים את הקריאה בין הדיסקים, אנחנו יכולים להגיע לביצועים של 2S.
כלומר N*S mb/sec.

- כנ"ל גם לגבי קריאה אקראית. אם מגיעות לנו קריאות כל הזמן למקומות שונים בדיסק, שני הדיסקים שלנו עובדים.
מדובר על N*S mb/sec. אם מקודם ידענו לקרוא 0.3 mb/sec, עכשיו נוכל לקרוא 0.6 mb/sec.

כלומר, ה-raid-0 משפר לנו משמעותית את הביצועים (כפול N למעשה).
אנחנו מנצלים את כל הדיסקים ומשפרים את הביצועים באופן משמעותי.

