[{"id": 1, "type": "MultipleChoice", "topic": ["Processes", "Process States"], "content": {"text": "מה קורה למצב התהליך (Process State) כאשר הוא מבצע קריאת מערכת הממתינה לפעולת קלט/פלט (I/O), כגון קריאה מדיסק או המתנה לקלט מהמקלדת?", "code_snippet": null, "options": ["א. התהליך עובר למצב Ready כדי שיוכל להמשיך לרוץ מיד.", "ב. התהליך נשאר במצב Running ומבצע Busy Waiting עד שהמידע מגיע.", "ג. התהליך עובר למצב Blocked (או Waiting) עד לסיום פעולת הקלט/פלט.", "ד. התהליך מסיים את ריצתו (Terminated) ומערכת ההפעלה מוחקת אותו."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "כאשר תהליך מבצע פעולת I/O, הוא אינו יכול להמשיך בביצוע פקודות עד שהמידע יהיה זמין. כדי לא לבזבז זמן מעבד יקר, מערכת ההפעלה מעבירה אותו למצב Blocked (חסום) ומקצה את המעבד לתהליך אחר שנמצא במצב Ready. רק לאחר סיום פעולת ה-I/O, התהליך יחזור למצב Ready."}, "difficulty_estimation": "Easy", "_source_file": "0001__Processes__MultipleChoice__Easy.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:02:44", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "Process States"], "content": {"text": "כאשר תהליך מבצע קריאת מערכת הממתינה לקלט מהמשתמש (כמו קריאה מהמקלדת), לאיזה מצב (State) הוא יעבור בדרך כלל?", "code_snippet": null, "options": ["א. Running", "ב. Ready", "ג. Blocked / Waiting", "ד. Terminated"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "כאשר תהליך נדרש להמתין לאירוע חיצוני (כמו קלט/פלט), הוא אינו יכול להמשיך בביצוע הפקודות שלו על המעבד. לכן, מערכת ההפעלה מעבירה אותו למצב Blocked (חום/המתנה) ומשחררת את המעבד לטובת תהליכים אחרים. רק לאחר שהקלט יתקבל, התהליך יחזור למצב Ready."}, "difficulty_estimation": "Easy", "_source_file": "0002__Processes__MultipleChoice__Easy.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:02:52", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Processes"], "content": {"text": "כאשר תהליך מבצע קריאת מערכת לביצוע פעולת קלט/פלט (I/O) וממתין לסיומה, לאיזה מצב (State) הוא יעבור?", "code_snippet": null, "options": ["א. Ready (מוכן)", "ב. Blocked / Waiting (חסום / ממתין)", "ג. Running (רץ)", "ד. Terminated (סיים)"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "כאשר תהליך מבצע פעולה הדורשת המתנה לאירוע חיצוני (כמו קלט/פלט), הוא אינו יכול לנצל את המעבד ולכן עובר למצב Blocked (חסום). לאחר סיום הפעולה והגעת הנתונים, הוא יעבור למצב Ready כדי להמתין לתורו לרוץ שוב על המעבד."}, "difficulty_estimation": "Easy", "_source_file": "0003__Processes__MultipleChoice__Easy.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:03:07", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Processes"], "content": {"text": "מה קורה למצב התהליך (Process State) כאשר הוא מבצע קריאת מערכת חוסמת (Blocking I/O), כמו קריאה מקובץ מהדיסק שטרם נטען?", "code_snippet": null, "options": ["א. התהליך עובר למצב Ready ומחכה בתור למעבד.", "ב. התהליך נשאר במצב Running ומבצע Busy Waiting עד שהנתונים מגיעים.", "ג. התהליך עובר למצב Blocked (או Waiting) עד לסיום פעולת ה-I/O.", "ד. התהליך עובר למצב Terminated ומערכת ההפעלה סוגרת אותו עקב שגיאה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "כאשר תהליך מבצע פעולת I/O חוסמת, הוא אינו יכול להמשיך בביצוע הקוד שלו עד שהנתונים מוכנים. כדי לא לבזבז זמן מעבד יקר, מערכת ההפעלה מעבירה את התהליך למצב Blocked ומוציאה אותו מהמעבד. רק כאשר פעולת ה-I/O מסתיימת, התהליך יועבר חזרה למצב Ready."}, "difficulty_estimation": "Easy", "_source_file": "0004__Processes__MultipleChoice__Easy.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:03:25", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Processes", "System Calls"], "content": {"text": "מה קורה לתהליך אב הקורא למערכת הקריאה wait() כאשר תהליך הבן שלו עדיין פעיל?", "code_snippet": null, "options": ["א. תהליך האב ממשיך בביצוע הקוד שלו כרגיל ובמקביל לבן.", "ב. תהליך האב עובר למצב 'חסום' (Blocked/Waiting) עד אשר אחד מצאצאיו יסיים את ריצתו.", "ג. תהליך האב נמחק מהטבלה של מערכת ההפעלה.", "ד. תהליך הבן הופך להיות תהליך יתום (Orphan)."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "מערכת הקריאה wait() נועדה לסנכרון בין תהליכים. כאשר תהליך אב קורא לה, הוא מושהה על ידי מערכת ההפעלה (עובר למצב Blocked) עד שאחד מתהליכי הבן שלו מסיים את ריצתו (מבצע exit), ורק אז האב חוזר למצב Ready."}, "difficulty_estimation": "Easy", "_source_file": "0005__Processes__MultipleChoice__Easy.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:09:11", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "System Calls"], "content": {"text": "מה יהיה הפלט של הקוד הבא, בהנחה שכל קריאות המערכת מצליחות?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 10;\n    if (fork() == 0) {\n        x += 5;\n        printf(\"%d \", x);\n    } else {\n        wait(NULL);\n        x -= 5;\n        printf(\"%d \", x);\n    }\n    return 0;\n}", "options": ["א. 15 5", "ב. 15 15", "ג. 5 5", "ד. 5 15", "ה. הפלט אינו דטרמיניסטי ותלוי בתזמון המעבד."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א. 15 5", "explanation": "לאחר הקריאה ל-fork, נוצר תהליך בן המקבל עותק נפרד של מרחב הכתובות. בתהליך הבן, fork מחזירה 0, לכן הוא נכנס לבלוק ה-if, מעדכן את ה-x המקומי שלו ל-15 ומדפיס אותו. בתהליך האב, fork מחזירה את ה-PID של הבן (ערך חיובי), ולכן הוא עובר לבלוק ה-else. האב מבצע wait(NULL) ולכן ממתין לסיום הבן לפני שהוא ממשיך בביצוע. לאחר שהבן מסיים, האב מפחית 5 מה-x שלו (שנשאר בערך 10 במקור כי הזיכרון נפרד) ומדפיס 5. לכן הפלט יהיה 15 ולאחר מכן 5."}, "difficulty_estimation": "Medium", "_source_file": "0005__Processes__MultipleChoice__Medium.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:03:40", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "System Calls"], "content": {"text": "מהו הערך המוחזר מהקריאה למערכת fork() בתהליך האב (parent process), בהנחה שהפעולה הצליחה?", "code_snippet": null, "options": ["א. 0", "ב. ה-PID (מזהה התהליך) של תהליך הבן שנוצר", "ג. ה-PID של תהליך האב עצמו", "ד. ערך בוליאני true (1)", "ה. הקריאה אינה מחזירה ערך בתהליך האב"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "לאחר קריאה מוצלחת ל-fork(), המערכת מחזירה את ה-PID של הבן החדש לתהליך האב, ומחזירה 0 לתהליך הבן. ערך שלילי מוחזר רק במקרה של שגיאה."}, "difficulty_estimation": "Easy", "_source_file": "0006__Processes__MultipleChoice__Easy.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:09:20", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Processes", "System Calls"], "content": {"text": "מה קורה כאשר תהליך קורא לקריאת המערכת fork() במערכת הפעלה מסוג Unix/Linux?", "code_snippet": null, "options": ["א. נוצר תהליך חדש (תהליך בן) שהוא עותק כמעט זהה של תהליך האב.", "ב. התהליך הנוכחי נעצר ומתחלף בקוד של תוכנית חדשה לגמרי.", "ג. נוצר חוט (Thread) חדש בתוך אותו מרחב כתובות של התהליך הקיים.", "ד. המערכת מבצעת מעבר למצב המתנה (Waiting) עד לסיום כל תהליכי הרקע."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "קריאת המערכת fork() יוצרת תהליך חדש על ידי שכפול התהליך הקורא. התהליך החדש (הבן) מקבל עותק של מרחב הכתובות, משתנים וקובצי הקלט/פלט של האב, אך הוא פועל כתהליך נפרד עם מזהה תהליך (PID) ייחודי."}, "difficulty_estimation": "Easy", "_source_file": "0007__Processes__MultipleChoice__Easy.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:09:28", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "Process States"], "content": {"text": "מהו המצב (State) של תהליך שממתין לסיום פעולת קלט/פלט (I/O) לפני שיוכל להמשיך בריצתו?", "code_snippet": null, "options": ["א. Running (ריצה)", "ב. Ready (מוכן)", "ג. Blocked/Waiting (חסום/ממתין)", "ד. Terminated (סיום)", "ה. Zombie (זומבי)"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "כאשר תהליך מבצע קריאת מערכת לקלט/פלט, הוא אינו יכול להמשיך בביצועו עד שהנתונים מוכנים או הפעולה הושלמה. לכן, מערכת ההפעלה מעבירה אותו למצב חסום (Blocked) ומוציאה אותו מתור הריצה כדי לאפשר לתהליכים אחרים להשתמש במעבד. רק לאחר קבלת פסיקה מהחומרה שהפעולה הסתיימה, התהליך יעבור למצב Ready ויוכל להיבחר שוב על ידי ה-Scheduler."}, "difficulty_estimation": "Easy", "_source_file": "0008__Processes__MultipleChoice__Easy.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:09:39", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "System Calls"], "content": {"text": "כמה פעמים תודפס המחרוזת \"Hello\" כתוצאה מהרצת הקוד הבא? הנח שכל הקריאות ל-fork מצליחות.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    if (fork() == 0) {\n        fork();\n        printf(\"Hello\\n\");\n    } else {\n        wait(NULL);\n    }\n    return 0;\n}", "options": ["1", "2", "3", "4", "0"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "2", "explanation": "התהליך המקורי (האב) מבצע fork. תהליך האב מקבל ערך חיובי (PID של הבן) ונכנס לבלוק ה-else, שם הוא מבצע wait וממתין לסיום בנו. תהליך הבן מקבל 0 ונכנס לבלוק ה-if. בתוך ה-if, תהליך הבן מבצע fork נוסף, מה שיוצר תהליך נכד. גם הבן וגם הנכד ממשיכים לשורת ה-printf ומדפיסים \"Hello\". סה\"כ ההדפסה מתבצעת פעמיים."}, "difficulty_estimation": "Medium", "_source_file": "0009__Processes__MultipleChoice__Medium.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:09:47", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "System Calls", "Memory Management"], "content": {"text": "נתון קטע הקוד הבא בשפת C. מהו הפלט הצפוי של התוכנית בהנחה שכל קריאות המערכת מצליחות?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 10;\n    if (fork() == 0) {\n        x += 5;\n        printf(\"%d \", x);\n    } else {\n        wait(NULL);\n        x -= 3;\n        printf(\"%d \", x);\n    }\n    return 0;\n}", "options": ["א. 15 12", "ב. 15 7", "ג. 7 15", "ד. 12 15", "ה. הפלט אינו קבוע ותלוי בתזמון המעבד."]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ב. 15 7", "explanation": "לאחר קריאת המערכת fork, נוצר תהליך בן המקבל עותק נפרד של מרחב הכתובות של האב, כולל המשתנה x. בתהליך הבן (שבו fork מחזיר 0), הערך של x הופך ל-15 והוא מודפס. בתהליך האב, נעשה שימוש ב-wait(NULL) שממתין לסיום הבן. לאחר מכן האב מחסיר 3 מהערך המקורי של x (שהיה 10 במרחב הכתובות שלו) ומדפיס 7. מכיוון שהאב מחכה לבן, הפלט תמיד יהיה 15 ולאחר מכן 7."}, "difficulty_estimation": "Medium", "_source_file": "0010__Processes__MultipleChoice__Medium.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:09:57", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Processes", "System Calls"], "content": {"text": "נתון קטע הקוד הבא בשפת C. נניח שכל קריאות המערכת מצליחות. מה נכון לומר לגבי ה-PID (Process Identifier) ומרחב הכתובות (Address Space) של התהליך המריץ את התוכנית \"ls\", בהשוואה לתהליך הבן שנוצר על ידי קריאת ה-fork המופיעה בקוד?", "code_snippet": "pid_t pid = fork();\nif (pid == 0) {\n    char *args[] = {\"ls\", \"-l\", NULL};\n    execvp(args[0], args);\n    exit(0);\n} else {\n    wait(NULL);\n}", "options": ["א. ה-PID משתנה ומרחב הכתובות משתנה.", "ב. ה-PID נשאר זהה ומרחב הכתובות נשאר זהה.", "ג. ה-PID משתנה אך מרחב הכתובות נשאר זהה.", "ד. ה-PID נשאר זהה אך מרחב הכתובות מוחלף בתוכנית החדשה.", "ה. לא ניתן לדעת, הדבר תלוי במתזמן (Scheduler)."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ד. ה-PID נשאר זהה אך מרחב הכתובות מוחלף בתוכנית החדשה.", "explanation": "הקריאה למשפחת פונקציות exec (כמו execvp) מחליפה את מרחב הכתובות של התהליך הנוכחי (קוד, נתונים, מחסנית) בתוכנית חדשה. עם זאת, התהליך עצמו נשאר אותו תהליך במערכת ההפעלה, ולכן הוא שומר על ה-PID המקורי שלו שניתן לו בעת ה-fork."}, "difficulty_estimation": "Medium", "_source_file": "0011__Processes__MultipleChoice__Medium.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:10:11", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "System Calls"], "content": {"text": "נתון קטע הקוד הבא בשפת C. מה יהיה הפלט הצפוי של התוכנית בהנחה שכל קריאות המערכת מצליחות?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    if (fork() == 0) {\n        execlp(\"/bin/echo\", \"echo\", \"Hello\", NULL);\n        printf(\"World\\n\");\n    } else {\n        wait(NULL);\n        printf(\"Goodbye\\n\");\n    }\n    return 0;\n}", "options": ["א. Hello ולאחר מכן World ולאחר מכן Goodbye", "ב. Hello ולאחר מכן Goodbye", "ג. World ולאחר מכן Goodbye", "ד. Goodbye ולאחר מכן Hello", "ה. Hello בלבד"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ב. Hello ולאחר מכן Goodbye", "explanation": "קריאת המערכת execlp מחליפה את דמות התהליך (Process Image) בתוכנית חדשה. לכן, הקוד שמופיע לאחר הקריאה ל-execlp בתהליך הבן לא יבוצע לעולם (אלא אם הקריאה נכשלה). תהליך האב ממתין לסיום הבן בעזרת wait ולכן ידפיס Goodbye רק לאחר שהבן סיים להדפיס Hello."}, "difficulty_estimation": "Medium", "_source_file": "0012__Processes__MultipleChoice__Medium.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:10:32", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "System Calls", "Fork"], "content": {"text": "מה יהיה הפלט של הקוד הבא (בהנחה שכל קריאות המערכת מצליחות והפלט מודפס למסך באופן מיידי)?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 10;\n    if (fork() == 0) {\n        x += 5;\n        if (fork() == 0) {\n            printf(\"%d \", x);\n        } else {\n            wait(NULL);\n            printf(\"%d \", x);\n        }\n    } else {\n        wait(NULL);\n        printf(\"%d \", x);\n    }\n    return 0;\n}", "options": ["א. 10 15 15", "ב. 15 15 10", "ג. 15 20 10", "ד. 15 10 10", "ה. 15 15 15"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב. 15 15 10", "explanation": "התהליך הראשי מתחיל עם x=10. הוא מבצע fork. בתהליך הבן, x הופך ל-15. הבן מבצע fork נוסף ליצירת נכד. הנכד יורש את x=15 ומדפיס אותו. הבן מחכה לנכד (wait) ואז מדפיס את ה-x שלו (שהוא 15). לבסוף, תהליך האב המקורי, שחיכה לסיום הבן, מדפיס את ה-x שלו. מכיוון ש-fork יוצר העתק נפרד של מרחב הכתובות, השינויים בבן ובנכד לא השפיעו על ה-x של האב, ולכן הוא מדפיס 10."}, "difficulty_estimation": "Medium", "_source_file": "0013__Processes__MultipleChoice__Medium.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:10:47", "_subject": "Virtualization"}, {"id": 101, "type": "MultipleChoice", "topic": ["Processes", "System Calls", "Memory Management"], "content": {"text": "לפניך קטע קוד בשפת C המשתמש בקריאת המערכת fork. מה יהיה הפלט של התוכנית (בהנחה שכל הקריאות ל-fork ו-wait מצליחות)?", "code_snippet": "int main() {\n    int x = 10;\n    if (fork() == 0) {\n        x += 5;\n        if (fork() == 0) {\n            x += 5;\n            printf(\"%d\", x);\n        } else {\n            wait(NULL);\n        }\n    } else {\n        wait(NULL);\n        x -= 5;\n        printf(\"%d\", x);\n    }\n    return 0;\n}", "options": ["א. 205", "ב. 2015", "ג. 1510", "ד. 2010", "ה. 155"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "א. 205", "explanation": "לאחר ביצוע fork, נוצר עותק של התהליך עם מרחב כתובות נפרד (Copy-on-Write). בתהליך הבן הראשון, x הופך ל-15. לאחר מכן הוא מבצע fork נוסף, ובתהליך הנכד x הופך ל-20 ומודפס. בתהליך האב המקורי, x נשאר 10 (כי הוא לא מושפע מהשינויים בבנים), ולאחר ה-wait הוא מופחת ב-5 ומודפס הערך 5. כיוון שהאב והבן ממתינים לסיום הצאצאים שלהם, ההדפסה של ה-20 תתבצע לפני ה-5."}, "difficulty_estimation": "Medium", "_source_file": "0014__Processes__MultipleChoice__Medium.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:10:58", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "System Calls", "Memory Management"], "content": {"text": "מה יהיה הפלט של תוכנית ה-C הבאה? הניחו שכל קריאות המערכת מצליחות.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint x = 10;\n\nint main() {\n    pid_t pid = fork();\n    if (pid == 0) {\n        x += 5;\n        return 0;\n    } else {\n        wait(NULL);\n        x -= 2;\n        printf(\"%d\", x);\n    }\n    return 0;\n}", "options": ["א. 8", "ב. 13", "ג. 10", "ד. 15", "ה. אף אחת מהתשובות אינה נכונה"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "א. 8", "explanation": "קריאת המערכת fork יוצרת תהליך חדש עם מרחב כתובות נפרד (Copy-on-Write). למרות שהתהליך הבן משנה את ערכו של x (מעלה ל-15), השינוי מתבצע על העתק מקומי בזיכרון של הבן ואינו משפיע על המשתנה x בתהליך האב. תהליך האב ממתין לסיום הבן באמצעות wait, ולאחר מכן מבצע x -= 2 על הערך המקורי שנותר אצלו (10). לכן הפלט יהיה 8."}, "difficulty_estimation": "Medium", "_source_file": "0015__Processes__MultipleChoice__Medium.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:11:21", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "System Calls", "Memory Management"], "content": {"text": "מה יהיה הפלט של הקוד הבא (בהנחה שכל קריאות המערכת מצליחות)?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 10;\n    if (fork() == 0) {\n        x += 5;\n        printf(\"%d \", x);\n    } else {\n        wait(NULL);\n        x -= 3;\n        printf(\"%d \", x);\n    }\n    return 0;\n}", "options": ["א. 15 12", "ב. 15 7", "ג. 7 15", "ד. 12 15", "ה. התוצאה אינה דטרמיניסטית ותלויה במתזמן."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב. 15 7", "explanation": "לאחר הקריאה ל-fork, נוצרים שני תהליכים נפרדים עם מרחבי כתובות נפרדים. שינוי משתנה בתהליך הבן אינו משפיע על המשתנה בתהליך האב. תהליך הבן מעדכן את x ל-15 ומדפיס. תהליך האב מחכה לסיום הבן באמצעות wait, ולכן הבן תמיד ידפיס ראשון. לאחר מכן האב מעדכן את ה-x המקומי שלו (שערכו נותר 10) ל-7 ומדפיס."}, "difficulty_estimation": "Medium", "_source_file": "0016__Processes__MultipleChoice__Medium.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:11:30", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "fork", "wait", "Copy-on-Write"], "content": {"text": "נתון קוד ה-C הבא. בהנחה שכל הקריאות ל-fork() מצליחות ושהמערכת מדפיסה את הפלט למסך, מהם הערכים שיודפסו על ידי כל התהליכים שנוצרו (בסדר כלשהו)?", "code_snippet": "int main() {\n    int x = 0;\n    for (int i = 0; i < 3; i++) {\n        if (fork() == 0) {\n            x++;\n        } else {\n            x--;\n            wait(NULL);\n            break;\n        }\n    }\n    printf(\"%d \", x);\n    return 0;\n}", "options": ["-1 0 1 3", "0 1 2 3", "-1 -1 -1 3", "-1 0 1 2", "אף אחת מהתשובות אינה נכונה"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "-1 0 1 3", "explanation": "הקוד מבצע לולאה שבה בכל שלב נוצר תהליך ילד חדש. האב (התהליך שקיבל ערך חיובי מ-fork) מחסיר 1 מהמשתנה המקומי x שלו, ממתין לסיום הילד שלו (wait), ויוצא מהלולאה (break). הילד (שקיבל 0 מ-fork) מוסיף 1 ל-x שלו וממשיך לאיטרציה הבאה של הלולאה.\n1. תהליך מקורי P0 (עם x=0): ב-i=0 יוצר את P1. ב-P0 ה-x הופך ל-1-, הוא עוצר ומדפיס 1-.\n2. תהליך P1 (הילד של P0, התחיל עם x=1): ב-i=1 יוצר את P2. ב-P1 ה-x הופך ל-0 (פחות 1), הוא עוצר ומדפיס 0.\n3. תהליך P2 (הילד של P1, התחיל עם x=2): ב-i=2 יוצר את P3. ב-P2 ה-x הופך ל-1 (פחות 1), הוא עוצר ומדפיס 1.\n4. תהליך P3 (הילד של P2, התחיל עם x=3): מסיים את הלולאה (i=3) ומדפיס 3.\nהערכים המודפסים הם 1-, 0, 1, 3. בשל ה-wait, הסדר יהיה הפוך (3, 1, 0, 1-) אך השאלה ביקשה את הערכים בסדר כלשהו."}, "difficulty_estimation": "Hard", "_source_file": "0017__Processes__MultipleChoice__Hard.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:11:57", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "fork", "waitpid", "Memory Management"], "content": {"text": "בהנחה שכל הקריאות למערכת (fork, waitpid) מצליחות, מה יהיה הפלט של קוד ה-C הבא?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    int x = 10;\n    pid_t pid = fork();\n    if (pid == 0) {\n        x += 5;\n        pid_t pid2 = fork();\n        if (pid2 == 0) {\n            x += 5;\n            exit(x);\n        }\n        int status;\n        waitpid(pid2, &status, 0);\n        if (WIFEXITED(status)) {\n            x += WEXITSTATUS(status);\n        }\n        printf(\"%d\", x);\n    } else {\n        wait(NULL);\n    }\n    return 0;\n}", "options": ["א. 15", "ב. 20", "ג. 30", "ד. 35", "ה. 40"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "הסבר: 1. האב המקורי יוצר תהליך בן (C1). לכל אחד מהם מרחב זיכרון נפרד. 2. בתוך C1, המשתנה x מעודכן ל-15. 3. C1 יוצר תהליך נכד (G1). ל-G1 עותק נפרד של הזיכרון שבו x הוא 15. 4. G1 מעדכן את x ל-20 ומסיים עם exit(20). 5. C1 ממתין ל-G1 ובעזרת המאקרו WEXITSTATUS שולף את קוד החזרה (20). 6. C1 מוסיף את הערך שחזר (20) ל-x המקומי שלו (15), ולכן x ב-C1 הופך ל-35. 7. C1 מדפיס את הערך 35. האב המקורי רק מבצע wait ולכן לא מדפיס דבר."}, "difficulty_estimation": "Hard", "_source_file": "0018__Processes__MultipleChoice__Hard.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:12:18", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "fork", "exec", "Process Image"], "content": {"text": "נתון קוד ה-C הבא. בהנחה שכל הקריאות למערכת מצליחות וכל הקבצים קיימים, מה יהיה הפלט של התוכנית?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    printf(\"1\\n\");\n    if (fork() == 0) {\n        printf(\"2\\n\");\n        execlp(\"/bin/echo\", \"echo\", \"3\", NULL);\n        printf(\"4\\n\");\n    } else {\n        wait(NULL);\n        printf(\"5\\n\");\n    }\n    return 0;\n}", "options": ["1, 2, 3, 4, 5", "1, 2, 3, 5", "1, 2, 4, 5", "1, 3, 2, 5", "הקוד יגרום לשגיאת זמן ריצה (Runtime Error)"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "1, 2, 3, 5", "explanation": "התהליך הראשי מתחיל ומדפיס '1'. לאחר מכן מתבצע fork. בתהליך הבן, מודפס '2' ואז מתבצעת הקריאה ל-execlp. פקודה זו מחליפה את תמונת הזיכרון של התהליך הנוכחי בתוכנית החדשה (echo). לכן, הקוד שמופיע לאחר ה-exec (הדפסת '4') לעולם לא יתבצע אם ה-exec הצליח. התוכנית echo מדפיסה '3' ומסתיימת. תהליך האב ממתין לסיום הבן באמצעות wait, ורק לאחר מכן מדפיס '5'. לכן הפלט יהיה 1, 2, 3, 5."}, "difficulty_estimation": "Hard", "_source_file": "0019__Processes__MultipleChoice__Hard.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:12:41", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Processes", "fork", "wait", "Zombie Processes", "Orphan Processes"], "content": {"text": "נתון קטע הקוד הבא בשפת C המורץ על מערכת Linux. נניח שכל הקריאות ל-fork מצליחות, ה-PID של התהליך המקורי הוא 100, וה-PID של תהליך ה-init במערכת הוא 1. מה יודפס על ידי ה-Grandchild (הנכד), ומה יהיה מצבו של תהליך הבן (Child 1) ברגע שה-Grandchild מדפיס את הפלט?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    pid_t pid = fork();\n    if (pid == 0) { // Child 1\n        if (fork() == 0) { // Grandchild\n            sleep(2);\n            printf(\"%d\", getppid());\n            exit(0);\n        }\n        exit(0);\n    }\n    wait(NULL);\n    sleep(5);\n    return 0;\n}", "options": ["א. יודפס 100, ותהליך Child 1 יהיה במצב Zombie.", "ב. יודפס 1, ותהליך Child 1 יהיה במצב Zombie.", "ג. יודפס 1, ותהליך Child 1 לא יהיה קיים במערכת (נוקה).", "ד. יודפס 100, ותהליך Child 1 לא יהיה קיים במערכת (נוקה).", "ה. יודפס ה-PID של ה-Grandchild, ו-Child 1 יהיה במצב Running."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "כאשר Child 1 מבצע exit, הוא הופך ל-Zombie. התהליך המקורי (Parent) קורא ל-wait(NULL), פעולה זו 'אוספת' את הסטטוס של Child 1 ומנקה אותו מטבלת התהליכים (Reaping), לכן הוא אינו קיים יותר במערכת. ה-Grandchild הופך ליתום (Orphan) כיוון שאביו (Child 1) סיים את ריצתו. במערכות Linux, תהליך יתום מאומץ על ידי תהליך ה-init (או subreaper), שכתובתו היא 1. לכן, getppid() יחזיר 1."}, "difficulty_estimation": "Hard", "_source_file": "0020__Processes__MultipleChoice__Hard.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:12:58", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "fork", "Zombie Processes", "Orphan Processes"], "content": {"text": "נתון קטע הקוד הבא בשפת C. נניח שכל הקריאות ל-fork מצליחות, ושהמערכת משתמשת בתהליך ה-init (PID 1) כמאמץ ברירת מחדל לתהליכים יתומים. מה יהיה מצב התהליכים במערכת כעבור 5 שניות מתחילת ריצת התוכנית?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/types.h>\n#include <stdlib.h>\n\nint main() {\n    pid_t pid = fork();\n    if (pid == 0) {\n        // Child process\n        if (fork() > 0) {\n            // Child creates a Grandchild and exits immediately\n            _exit(0);\n        }\n        // Grandchild process continues\n        sleep(100);\n    } else {\n        // Parent process\n        // Parent does not call wait() yet\n        sleep(100);\n    }\n    return 0;\n}", "options": ["א. התהליך הנכד (Grandchild) יהיה במצב Zombie והתהליך הבן (Child) יהיה במצב Running.", "ב. התהליך הבן (Child) יהיה במצב Zombie והתהליך הנכד (Grandchild) יאומץ על ידי ה-init (או reaper process).", "ג. התהליך הבן (Child) ינוקה מהמערכת באופן מיידי כי הוא קרא ל-_exit, והנכד ימשיך לרוץ תחת האב המקורי.", "ד. כל התהליכים יסיימו את ריצתם כיוון שהבן (שהוא ההורה של הנכד) סיים את ריצתו."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "לאחר ה-fork הראשון נוצר תהליך הבן. הבן מבצע fork נוסף ויוצר את הנכד, ואז קורא מיד ל-_exit ומסיים. מכיוון שהאב המקורי עדיין רץ (ב-sleep) ולא קרא ל-wait(), הבן הופך ל-Zombie (תהליך שסיים אך רשומתו נשארת בטבלת התהליכים). הנכד הופך ליתום (Orphan) כי אביו (הבן) מת, ולכן הוא מאומץ על ידי ה-init process."}, "difficulty_estimation": "Hard", "_source_file": "0021__Processes__MultipleChoice__Hard.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:13:14", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "fork", "Address Space", "wait"], "content": {"text": "נתון קטע הקוד הבא בשפת C. מה יהיה סכום כל המספרים שיודפסו למסך (Standard Output) בהנחה שכל הקריאות ל-fork ו-wait מצליחות ואין בעיות זיכרון?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 2;\n    if (fork() == 0) {\n        x = x * 2;\n        if (fork() == 0) {\n            x = x + 1;\n            printf(\"%d\\n\", x);\n        } else {\n            wait(NULL);\n            x = x - 1;\n            printf(\"%d\\n\", x);\n        }\n    } else {\n        wait(NULL);\n        x = x + 2;\n        printf(\"%d\\n\", x);\n    }\n    return 0;\n}", "options": ["12", "10", "14", "9", "התוצאה אינה דטרמיניסטית ותלויה בסדר התזמון של המעבד"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "12", "explanation": "במערכת הפעלה, פקודת fork יוצרת תהליך בן עם מרחב כתובות נפרד המהווה העתק של תהליך האב. ננתח את זרימת התוכנית: 1. תהליך האב המקורי (P) מתחיל עם x=2. 2. P יוצר את C1. בתוך C1, המשתנה x מוכפל ב-2 (x=4). 3. C1 יוצר את GC (הנכד). בתוך GC, המשתנה x (שהועתק מ-C1 כ-4) גדל ב-1 (x=5) ומודפס המספר 5. 4. C1 ממתין לסיום GC, ואז מחסיר 1 מה-x שלו (4-1=3) ומדפיס 3. 5. P ממתין לסיום C1, ואז מוסיף 2 ל-x שלו (2+2=4) ומדפיס 4. סכום כל ההדפסות: 5+3+4=12. כיוון שמרחבי הכתובות מופרדים (Copy-on-Write), השינויים ב-x בכל תהליך אינם משפיעים על האחרים."}, "difficulty_estimation": "Hard", "_source_file": "0022__Processes__MultipleChoice__Hard.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:13:46", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Processes", "Fork", "Memory Space", "Wait"], "content": {"text": "מה יהיה הפלט של הקוד הבא בשפת C, בהנחה שכל הקריאות למערכת מצליחות ושסדר ההדפסה נקבע על פי ה-wait (כלומר, תהליך אב תמיד ידפיס אחרי שתהליך הבן שלו סיים)?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int val = 5;\n    if (fork() == 0) {\n        val += 10;\n        if (fork() == 0) {\n            val *= 2;\n            printf(\"%d \", val);\n        } else {\n            wait(NULL);\n            val -= 5;\n            printf(\"%d \", val);\n        }\n    } else {\n        wait(NULL);\n        val += 1;\n        printf(\"%d \", val);\n    }\n    return 0;\n}", "options": ["א. 30 10 6", "ב. 30 25 6", "ג. 15 10 6", "ד. 30 10 16", "ה. אף אחת מהתשובות אינה נכונה."]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "בתהליך המקורי (P1) המשתנה val שווה 5. לאחר ה-fork הראשון, נוצר תהליך בן (P2) שמקבל עותק של val עם הערך 5. P2 מעדכן את val שלו ל-15 (5+10). לאחר מכן P2 מבצע fork נוסף ויוצר את P3. P3 מקבל עותק של val מ-P2, כלומר 15, מכפיל ב-2 ומדפיס 30. P2 ממתין ל-P3, לאחר מכן מחסיר 5 מה-val שלו (שהיה 15) ומדפיס 10. לבסוף, P1 שהמתין ל-P2, מעדכן את ה-val המקורי שלו (5) ב-1 ומדפיס 6. כיוון שכל תהליך פועל במרחב כתובות נפרד, השינויים במשתנה val אינם משותפים בין התהליכים."}, "difficulty_estimation": "Hard", "_source_file": "0023__Processes__MultipleChoice__Hard.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:14:03", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Processes", "System Calls", "File Descriptors"], "content": {"text": "נתון קטע הקוד הבא המבוצע במערכת הפעלה Unix. נניח שכל קריאות המערכת מצליחות והקובץ test.txt נפתח כקובץ ריק (גודל 0). מה יהיה תוכן הקובץ בסיום ריצת התוכנית?", "code_snippet": "#include <fcntl.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    int fd = open(\"test.txt\", O_RDWR | O_CREAT | O_TRUNC, 0644);\n    write(fd, \"OS\", 2);\n    if (fork() == 0) {\n        write(fd, \"IS\", 2);\n        exit(0);\n    } else {\n        wait(NULL);\n        write(fd, \"FUN\", 3);\n    }\n    close(fd);\n    return 0;\n}", "options": ["א. OSISFUN", "ב. OSIS", "ג. OSFUN", "ד. OS"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "לאחר ביצוע קריאת המערכת fork(), תהליך הבן מקבל עותק של טבלת מתארי הקבצים (File Descriptor Table) של האב. עם זאת, מתארי הקבצים בשני התהליכים מצביעים לאותה כניסה בטבלת הקבצים הפתוחים של מערכת ההפעלה (System-wide Open File Table). כניסה זו מנהלת את ה-File Offset עבור הקובץ הפתוח. כיוון שהאופסט משותף, כאשר הבן כותב את המחרוזת 'IS', הוא מקדם את האופסט מ-2 ל-4. כיוון שהאב ממתין לסיום הבן (בעזרת wait), הוא יבצע את הכתיבה של 'FUN' רק לאחר מכן, והיא תתחיל מהאופסט המעודכן (4). לכן התוצאה היא OSISFUN."}, "difficulty_estimation": "Hard", "_source_file": "0024__Processes__MultipleChoice__Hard.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:14:38", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Processes"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בקריאות מערכת מסוג fork. כמה פעמים תודפס המחרוזת \"Hello\" במהלך הרצה תקינה של התוכנית? הסבירו את תשובתכם על ידי מעקב אחר יצירת התהליכים.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n\nint main() {\n    fork();\n    if (fork() == 0) {\n        fork();\n    }\n    printf(\"Hello\\n\");\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "המחרוזת \"Hello\" תודפס 6 פעמים. \nמעקב אחר יצירת התהליכים:\n1. התוכנית מתחילה עם תהליך אב יחיד (P1).\n2. לאחר ה-fork() הראשון, נוצר תהליך בן (P2). כעת ישנם 2 תהליכים במערכת.\n3. שני התהליכים (P1 ו-P2) מגיעים לשורת ה-if ומבצעים fork() נוסף. נוצרים שני תהליכים חדשים: P3 (הבן של P1) ו-P4 (הבן של P2). כעת ישנם 4 תהליכים במערכת.\n4. תנאי ה-if בודק האם הערך המוחזר מפעולת ה-fork הוא 0. תנאי זה מתקיים אך ורק עבור תהליכי הבן שזה עתה נוצרו (P3 ו-P4).\n5. בתוך בלוק ה-if, התהליכים P3 ו-P4 מבצעים fork() נוסף, מה שיוצר שני תהליכים חדשים נוספים (P5 ו-P6). כעת ישנם סה\"כ 6 תהליכים במערכת.\n6. כל 6 התהליכים הקיימים (P1, P2, P3, P4, P5, P6) ממשיכים בביצוע הקוד ומגיעים לשורת ה-printf. לכן, המחרוזת תודפס 6 פעמים."}, "difficulty_estimation": "Easy", "_source_file": "0025__Processes__Open__Easy.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:14:55", "_subject": "Virtualization"}, {"id": 8, "type": "Open", "topic": ["Processes", "fork"], "content": {"text": "כמה תהליכים נוצרים בסך הכל (כולל תהליך האב המקורי) במהלך הרצת הקוד הבא? יש לפרט את שלבי ההיווצרות של התהליכים.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/types.h>\n\nint main() {\n    fork();\n    pid_t pid = fork();\n    if (pid > 0) {\n        fork();\n    }\n    printf(\"Process\\n\");\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "להלן שלבי היווצרות התהליכים:\n1. בתחילה קיים תהליך אחד (נסמנו P1).\n2. לאחר פקודת ה-fork() הראשונה, נוצר תהליך בן (P2). כעת יש במערכת 2 תהליכים.\n3. לאחר פקודת ה-fork() השנייה, כל אחד משני התהליכים הקיימים (P1 ו-P2) מתפצל פעם נוספת. נוצרים שני תהליכים חדשים (P3 ו-P4). כעת יש במערכת 4 תהליכים.\n4. המשתנה pid מכיל את ערך ההחזר של ה-fork השני. בתהליכי האב של הפיצול השני (P1 ו-P2) הערך יהיה גדול מ-0 (ה-PID של הבן), ובתהליכי הבן החדשים (P3 ו-P4) הערך יהיה 0.\n5. פקודת ה-if מתבצעת רק עבור תהליכים בהם pid > 0, כלומר רק P1 ו-P2 מבצעים את ה-fork() השלישי.\n6. ה-fork השלישי יוצר עוד שני תהליכים (P5 ו-P6).\n7. לסיכום: 1 (התחלתי) + 1 (ב-fork הראשון) + 2 (ב-fork השני) + 2 (ב-fork השלישי בתוך ה-if) = 6 תהליכים סך הכל."}, "difficulty_estimation": "Easy", "_source_file": "0026__Processes__Open__Easy.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:15:08", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Processes", "fork"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בקריאת המערכת fork(). כמה תהליכים בסך הכל (כולל תהליך האב המקורי) ייווצרו במהלך ריצת התוכנית? הניחו שכל הקריאות ל-fork() מצליחות. יש להסביר את שלבי ההיווצרות.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n\nint main() {\n    fork();\n    if (fork() == 0) {\n        fork();\n    }\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "במהלך ריצת התוכנית ייווצרו בסך הכל 6 תהליכים (כולל האב המקורי). להלן הפירוט:\n1. התוכנית מתחילה עם תהליך אחד (P1).\n2. הקריאה הראשונה ל-fork() יוצרת תהליך בן (P2). כעת ישנם 2 תהליכים.\n3. לאחר מכן, שני התהליכים (P1 ו-P2) מגיעים לשורת ה-if ומבצעים fork() נוסף. \n   - P1 יוצר את P3 (עבור P3 הערך המוחזר הוא 0, עבור P1 הערך הוא ה-PID של P3).\n   - P2 יוצר את P4 (עבור P4 הערך המוחזר הוא 0, עבור P2 הערך הוא ה-PID של P4).\n   כעת ישנם 4 תהליכים.\n4. תנאי ה-if בודק האם הערך המוחזר מ-fork הוא 0. תנאי זה מתקיים רק עבור תהליכי הבן החדשים שנוצרו בשלב הקודם (P3 ו-P4).\n5. בתוך בלוק ה-if, שני התהליכים הללו (P3 ו-P4) קוראים ל-fork() פעם שלישית:\n   - P3 יוצר את P5.\n   - P4 יוצר את P6.\n6. סך כל התהליכים במערכת: P1, P2, P3, P4, P5, P6 (סה\"כ 6)."}, "difficulty_estimation": "Easy", "_source_file": "0027__Processes__Open__Easy.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:15:23", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Processes", "Memory Management", "Fork"], "content": {"text": "נתון קוד ה-C הבא המשתמש בקריאת המערכת fork. מה יהיה הפלט של התוכנית (הניחו שכל קריאות המערכת מצליחות)? הסבירו האם השינוי במשתנה x בתהליך הבן משפיע על ערכו בתהליך האב.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 10;\n    pid_t pid = fork();\n\n    if (pid == 0) {\n        // תהליך הבן\n        x = x + 5;\n        printf(\"Child: x = %d\\n\", x);\n    } else {\n        // תהליך האב\n        wait(NULL);\n        x = x - 5;\n        printf(\"Parent: x = %d\\n\", x);\n    }\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפלט של התוכנית יהיה:\nChild: x = 15\nParent: x = 5\n\nהסבר: קריאת המערכת fork יוצרת תהליך חדש (בן) המהווה העתק של תהליך האב. למרות שהבן יורש את ערכי המשתנים של האב ברגע הפיצול, לכל תהליך יש מרחב כתובות (Address Space) נפרד ומבודד בזיכרון. לכן, כל שינוי שמבצע תהליך הבן במשתנה x מתבצע בזיכרון הפרטי שלו ואינו משפיע על ערכו של x במרחב הזיכרון של תהליך האב. תהליך האב ממתין לסיום הבן באמצעות wait, ולאחר מכן מדפיס את ערכו של x המקורי (10) פחות 5."}, "difficulty_estimation": "Easy", "_source_file": "0028__Processes__Open__Easy.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:15:41", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Processes", "fork"], "content": {"text": "לפניך קטע קוד בשפת C המשתמש בקריאת המערכת fork(). הנח שכל הקריאות ל-fork() מצליחות ושאין שגיאות בזמן הריצה.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n\nint main() {\n    fork();\n    if (fork() == 0) {\n        fork();\n    }\n    printf(\"Done\\n\");\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "כמה תהליכים סך הכל ייווצרו במהלך ריצת התוכנית (כולל התהליך הראשי)?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "כמה פעמים תודפס המחרוזת \"Done\" למסך? נמק את תשובתך.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: סך הכל ייווצרו 6 תהליכים.\nניתוח שלבי היצירה:\n1. ה-fork() הראשון מפצל את התהליך המקורי (P) לשני תהליכים: P ו-C1.\n2. ה-fork() השני מתבצע על ידי שני התהליכים הקיימים (P ו-C1). P יוצר את C2, ו-C1 יוצר את C3. כעת ישנם 4 תהליכים במערכת.\n3. התנאי (fork() == 0) מתקיים רק עבור הילדים שנוצרו ב-fork השני (C2 ו-C3). לכן רק הם נכנסים לתוך בלוק ה-if.\n4. בתוך ה-if, התהליך C2 מבצע fork() ויוצר את C4. התהליך C3 מבצע fork() ויוצר את C5.\n5. סך התהליכים: P, C1, C2, C3, C4, C5 - סה\"כ 6 תהליכים.\n\n1.2: המחרוזת תודפס 6 פעמים.\nהסבר: כל תהליך שנוצר במהלך ריצת התוכנית ממשיך בביצוע הקוד עד סוף פונקציית ה-main. מכיוון שפקודת ה-printf נמצאת מחוץ לבלוק ה-if (אחריו), כל אחד מ-6 התהליכים שנוצרו יגיע לשורה זו וידפיס את המחרוזת פעם אחת."}, "difficulty_estimation": "Easy", "_source_file": "0029__Processes__Open__Easy.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:16:00", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Processes", "fork"], "content": {"text": "כמה תהליכים ייווצרו בסך הכל (כולל התהליך הראשי) כתוצאה מהרצת הקוד הבא? פרטו את החישוב והסבירו בקצרה כיצד הגעתם לתוצאה.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n\nint main() {\n    fork();\n    fork();\n    fork();\n    printf(\"Hello\\n\");\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "בכל קריאה לפקודת fork(), כל תהליך קיים במערכת שמריץ את השורה הזו מתפצל לשני תהליכים: תהליך האב המקורי ותהליך בן חדש. שני התהליכים ממשיכים את הריצה מאותה נקודה בקוד. \nהחישוב הוא כדלקמן:\n1. התחלה: תהליך 1 (הראשי).\n2. לאחר ה-fork הראשון: התהליך הראשי יוצר בן, סה\"כ 2 תהליכים.\n3. לאחר ה-fork השני: כל אחד מ-2 התהליכים הקיימים יוצר בן, סה\"כ 4 תהליכים.\n4. לאחר ה-fork השלישי: כל אחד מ-4 התהליכים הקיימים יוצר בן, סה\"כ 8 תהליכים.\nבאופן כללי, עבור n קריאות עוקבות ל-fork(), מספר התהליכים הכולל יהיה 2 בחזקת n. במקרה זה 2^3 = 8."}, "difficulty_estimation": "Easy", "_source_file": "0030__Processes__Open__Easy.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:16:09", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Processes", "fork"], "content": {"text": "כמה תהליכים נוצרים בסך הכל (כולל תהליך האב המקורי) במהלך ריצת הקוד הבא? הסבירו את תשובתכם.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n\nint main() {\n    fork();\n    fork();\n    fork();\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כל קריאה לפקודת fork() יוצרת תהליך בן חדש שהוא העתק של התהליך הקורא. \n1. בתחילה קיים תהליך אחד (האב).\n2. לאחר ה-fork הראשון, ישנם 2 תהליכים (האב והבן הראשון).\n3. לאחר ה-fork השני, כל אחד מ-2 התהליכים הקיימים מבצע fork, ולכן נוצרים 2 תהליכים נוספים, סה\"כ 4 תהליכים.\n4. לאחר ה-fork השלישי, כל אחד מ-4 התהליכים הקיימים מבצע fork, ולכן נוצרים 4 תהליכים נוספים, סה\"כ 8 תהליכים.\nבאופן כללי, עבור n קריאות עוקבות ל-fork, מספר התהליכים יהיה 2 בחזקת n."}, "difficulty_estimation": "Easy", "_source_file": "0031__Processes__Open__Easy.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:16:17", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Processes"], "content": {"text": "נתון קטע הקוד הבא בשפת C. בהנחה שכל הקריאות למערכת מצליחות, כמה תהליכים סה\"כ ירוצו במהלך ביצוע התוכנית (כולל תהליך האב המקורי)? יש לפרט את שלבי היצירה של התהליכים.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n\nint main() {\n    fork();\n    if (fork() == 0) {\n        fork();\n    }\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "שלבי יצירת התהליכים הם כדלקמן:\n1. בתחילה קיים תהליך אחד (נסמנו P1).\n2. לאחר ביצוע ה-fork() הראשון בשורה 5, נוצר תהליך בן (P2). כעת ישנם 2 תהליכים במערכת.\n3. בשורה 6, שני התהליכים (P1 ו-P2) מבצעים את הקריאה fork() בתוך תנאי ה-if:\n   - P1 יוצר תהליך בן חדש (P3). עבור P3 הפונקציה מחזירה 0, ולכן הוא נכנס לבלוק ה-if.\n   - P2 יוצר תהליך בן חדש (P4). עבור P4 הפונקציה מחזירה 0, ולכן הוא נכנס לבלוק ה-if.\n   - עבור P1 ו-P2, הפונקציה מחזירה ערך שונה מ-0 (ה-PID של הבנים שלהם), ולכן הם אינם נכנסים לבלוק ה-if.\n4. בתוך בלוק ה-if (שורה 7), התהליכים P3 ו-P4 מבצעים fork() נוסף:\n   - P3 יוצר תהליך בן חדש (P5).\n   - P4 יוצר תהליך בן חדש (P6).\n5. לסיכום, התהליכים שהורצו הם: P1 (המקורי), P2 (נוצר ב-fork הראשון), P3 ו-P4 (נוצרו ב-fork השני), P5 ו-P6 (נוצרו ב-fork השלישי).\nסה\"כ: 6 תהליכים."}, "difficulty_estimation": "Easy", "_source_file": "0032__Processes__Open__Easy.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:16:39", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Processes", "fork", "Memory Isolation"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בקריאה למערכת fork. הניחו שכל הקריאות למערכת מצליחות ושאין תהליכי זומבי הממתינים במערכת.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/types.h>\n\nint main() {\n    int x = 5;\n    if (fork() == 0) {\n        x += 10;\n        if (fork() == 0) {\n            x += 10;\n        }\n    } else {\n        x -= 5;\n        fork();\n    }\n    printf(\"%d\\n\", x);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "כמה תהליכים נוצרו סך הכל במהלך ריצת התוכנית (כולל התהליך הראשי)? הציגו את עץ התהליכים שנוצר.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "מהם הערכים השונים שיודפסו למסך? הסבירו עבור כל ערך איזה תהליך מדפיס אותו וכיצד הגיע לערך זה.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "האם שינוי הערך של x בתהליך אחד משפיע על הערך של x בתהליך אחר? הסבירו מדוע, תוך התייחסות למנגנון ניהול הזיכרון של תהליכים במערכת ההפעלה.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: סך הכל נוצרו 4 תהליכים. התהליך הראשי (P0) יוצר תהליך בן (P1). P1 יוצר תהליך נכד (P2). לאחר מכן, התהליך הראשי (P0) יוצר תהליך בן נוסף (P3). עץ התהליכים: P0 הוא השורש, בניו הם P1 ו-P3, ו-P2 הוא הבן של P1.\n\n1.2: הערכים שיודפסו הם 25, 15, 0, 0 (הסדר עשוי להשתנות בהתאם לתזמון):\n- תהליך P2 (הנכד): נכנס לבלוק ה-if הראשון של אביו (x=15) ולבלוק ה-if השני שלו עצמו (x=25) ומדפיס 25.\n- תהליך P1 (הבן הראשון): נכנס לבלוק ה-if הראשון (x=15), מסיים את ה-if הפנימי ומדפיס 15.\n- תהליך P0 (האב): נכנס לבלוק ה-else, מעדכן ל-x=0, מבצע fork ומדפיס 0.\n- תהליך P3 (הבן השני): נוצר בתוך ה-else של P0, יורש את הערך x=0 ומדפיס 0.\n\n1.3: לא, שינוי הערך אינו משפיע. לכל תהליך יש מרחב כתובות וירטואלי נפרד (Address Space). בעת ביצוע fork, מערכת ההפעלה יוצרת העתק של מרחב הכתובות עבור הבן. למרות שהתהליכים משתמשים באותה כתובת וירטואלית עבור x, הן ממופות למסגרות שונות בזיכרון הפיזי (או משוכפלות בעת כתיבה במנגנון Copy-on-Write), ולכן השינויים מבודדים."}, "difficulty_estimation": "Medium", "_source_file": "0033__Processes__Open__Medium.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:17:00", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Processes", "fork", "Memory Isolation"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בקריאת המערכת fork. הניחו שכל הקריאות ל-fork מצליחות ושהפלט מודפס למסך באופן מיידי. הניחו כי פקודת ה-wait(NULL) גורמת לתהליך האב להמתין לסיום ביצועו של תהליך הבן הישיר שלו.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 10;\n    if (fork() == 0) {\n        x += 5;\n        if (fork() == 0) {\n            x += 5;\n            printf(\"%d\\n\", x);\n        } else {\n            wait(NULL);\n            x -= 2;\n            printf(\"%d\\n\", x);\n        }\n    } else {\n        wait(NULL);\n        x -= 5;\n        printf(\"%d\\n\", x);\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "כמה תהליכים נוצרו בסך הכל במהלך ריצת התוכנית (כולל התהליך הראשי)?", "code_snippet": null, "options": null}, {"id": "7.2", "text": "מה יהיו הערכים שיודפסו למסך ובאיזה סדר? נמקו את תשובתכם.", "code_snippet": null, "options": null}, {"id": "7.3", "text": "האם שינוי המשתנה x בתהליך הבן משפיע על ערכו של x בתהליך האב? הסבירו מדוע על סמך מנגנוני ניהול זיכרון בסיסיים של תהליכים.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1: נוצרו 3 תהליכים בסך הכל. התהליך הראשי (P1) קרא ל-fork ויצר את P2. תהליך P2 קרא ל-fork פנימי ויצר את P3.\n\n7.2: הערכים שיודפסו הם 20, לאחר מכן 13, ולבסוף 5. \nהסבר: \n- תהליך P3 (הנכד) מקבל x=15 מ-P2, מוסיף 5 ומדפיס 20.\n- תהליך P2 (הבן) ממתין ל-P3, לאחר מכן מחסיר 2 מה-x שלו (שהיה 15) ומדפיס 13.\n- תהליך P1 (האב) ממתין ל-P2, לאחר מכן מחסיר 5 מה-x שלו (שהיה 10) ומדפיס 5.\nהסדר מובטח בזכות קריאות ה-wait.\n\n7.3: לא, השינוי אינו משפיע. בעת ביצוע fork, מערכת ההפעלה יוצרת העתק של מרחב הכתובות של האב עבור הבן. למרות שבתחילה הנתונים זהים, לכל תהליך יש זיכרון וירטואלי נפרד. בזכות מנגנון Copy-on-Write, ברגע שתהליך מנסה לשנות משתנה, נוצר עותק פיזי נפרד עבורו, ולכן שינויים בתהליך אחד אינם נראים בתהליך אחר."}, "difficulty_estimation": "Medium", "_source_file": "0034__Processes__Open__Medium.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:17:15", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Processes", "Process Creation", "fork"], "content": {"text": "לפניכם קוד בשפת C המשתמש בקריאות המערכת fork ו-wait. הניחו שכל קריאות המערכת מצליחות ושהתהליכים מתזמנים בצורה כזו שכל תהליך אב ממתין לסיום ילדיו לפני הדפסה.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 10;\n    pid_t pid1, pid2;\n\n    pid1 = fork();\n    if (pid1 == 0) {\n        x += 5;\n        pid2 = fork();\n        if (pid2 == 0) {\n            x += 5;\n            printf(\"C2: x=%d\\n\", x);\n        } else {\n            wait(NULL);\n            printf(\"C1: x=%d\\n\", x);\n        }\n    } else {\n        wait(NULL);\n        printf(\"P: x=%d\\n\", x);\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "כמה תהליכים נוצרו בסך הכל במהלך ריצת התוכנית, כולל התהליך הראשי?", "code_snippet": null, "options": null}, {"id": "7.2", "text": "מה יהיה הפלט של התוכנית? יש לכתוב את השורות לפי סדר הדפסתן.", "code_snippet": null, "options": null}, {"id": "7.3", "text": "הסבירו מדוע השינויים במשתנה x בתהליכי הבנים אינם משתקפים בערכו של x בתהליך האב (P).", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1: נוצרו 3 תהליכים בסך הכל. התהליך הראשי (P) מבצע fork ויוצר את C1. התהליך C1 מבצע fork נוסף ויוצר את C2.\n\n7.2: הפלט יהיה:\nC2: x=20\nC1: x=15\nP: x=10\nהסבר: C2 יורש מ-C1 את x=15 ומוסיף 5. C1 מוסיף 5 ל-10 המקורי. האב P נשאר עם 10. בגלל קריאות ה-wait, הסדר מובטח מהנכד לסבא.\n\n7.3: כאשר מתבצע fork, נוצר עותק של מרחב הכתובות של תהליך האב עבור הבן. למרות שהם חולקים קוד, לכל תהליך יש מחסנית (stack) וסגמנט נתונים (data segment) נפרדים משלו. מנגנון Copy-on-Write מוודא שברגע שתהליך מנסה לשנות משתנה, נוצר עותק פיזי נפרד בזיכרון, ולכן שינוי ב-x בתהליך אחד לא ישפיע על האחרים."}, "difficulty_estimation": "Medium", "_source_file": "0035__Processes__Open__Medium.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:17:26", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Processes", "fork", "Process Lifecycle"], "content": {"text": "נתון קוד בשפת C המשתמש בקריאת המערכת fork. הניחו שכל הקריאות ל-fork מצליחות.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 10;\n    if (fork() == 0) {\n        x += 5;\n        if (fork() == 0) {\n            x += 5;\n            printf(\"C2: x = %d\\n\", x);\n        } else {\n            wait(NULL);\n            printf(\"C1: x = %d\\n\", x);\n        }\n    } else {\n        wait(NULL);\n        x -= 5;\n        printf(\"P: x = %d\\n\", x);\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "כמה תהליכים נוצרים סה\"כ במהלך ריצת התוכנית (כולל התהליך הראשי)? תארו את עץ התהליכים שנוצר.", "code_snippet": null, "options": null}, {"id": "7.2", "text": "מה יהיה הפלט של התוכנית? הסבירו מדוע השינויים במשתנה x בכל תהליך אינם משפיעים על ערכו בתהליכים האחרים.", "code_snippet": null, "options": null}, {"id": "7.3", "text": "הגדירו מהו תהליך \"זומבי\" (Zombie Process). האם במהלך ריצת קוד זה (כפי שהוא כתוב) אחד התהליכים הופך לזומבי לפרק זמן מסוים? הסבירו.", "code_snippet": null, "options": null}, {"id": "7.4", "text": "מה יקרה אם נסיר את כל קריאות ה-wait מהקוד? התייחסו בפרט למושג \"תהליך יתום\" (Orphan Process).", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1: נוצרים 3 תהליכים בסך הכל. התהליך הראשי (P) קורא ל-fork ויוצר את תהליך הבן הראשון (C1). תהליך C1 קורא ל-fork ויוצר את תהליך הנכד (C2). המבנה הוא שרשרת: P -> C1 -> C2.\n\n7.2: הפלט יהיה:\nC2: x = 20\nC1: x = 15\nP: x = 5\nהסבר: כאשר מתבצע fork, נוצר עותק של מרחב הכתובות של תהליך האב עבור הבן. למרות שבתחילה הם חולקים דפים פיזיים (Copy-on-Write), לוגית לכל תהליך יש משתנה x משלו בכתובת וירטואלית זהה אך בזיכרון פיזי נפרד. לכן, שינוי של x ב-C2 לא משפיע על C1, ושינוי ב-C1 לא משפיע על P.\n\n7.3: תהליך זומבי הוא תהליך שסיים את ביצועו (קרא ל-exit) אך עדיין קיימת עבורו רשומה בטבלת התהליכים של מערכת ההפעלה, כיוון שהאב טרם קרא ל-wait כדי לאסוף את סטטוס הסיום שלו. בקוד זה, C2 יהיה זומבי מרגע סיומו ועד ש-C1 יסיים את ה-wait, וכנ\"ל לגבי C1 מול P.\n\n7.4: ללא wait, תהליכי הבנים עלולים להפוך ליתומים אם האב יסיים לפניהם. תהליך יתום הוא תהליך שאביו הסתיים, ובמצב זה מערכת ההפעלה מאמצת אותו (בדרך כלל ע\"י תהליך ה-init/systemd ש-PID שלו הוא 1) כדי להבטיח שמישהו יבצע עליו wait בסיום."}, "difficulty_estimation": "Medium", "_source_file": "0036__Processes__Open__Medium.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:17:40", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Processes", "System Calls", "fork"], "content": {"text": "לפניכם קוד בשפת C המשתמש בקריאות המערכת fork ו-wait. הניחו שכל קריאות המערכת מצליחות.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    for (int i = 0; i < 3; i++) {\n        pid_t pid = fork();\n        if (pid == 0) {\n            printf(\"Child %d\\n\", i);\n            if (i % 2 == 0) {\n                fork();\n            }\n            _exit(0);\n        }\n    }\n    while(wait(NULL) > 0);\n    printf(\"Parent done\\n\");\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "כמה תהליכים בסך הכל ייווצרו במהלך ריצת התוכנית (כולל התהליך הראשי)? הסבירו את החישוב.", "code_snippet": null, "options": null}, {"id": "7.2", "text": "מה יקרה אם נחליף את הקריאה ל-`_exit(0)` בפקודת `break`? כיצד זה ישפיע על מספר התהליכים הנוצרים?", "code_snippet": null, "options": null}, {"id": "7.3", "text": "הסבירו בקצרה את ההבדל בין `exit()` לבין `_exit()`. מדוע בקוד זה נעשה שימוש ב-`_exit()` בתוך תהליך הבן?", "code_snippet": null, "options": null}, {"id": "7.4", "text": "אם נסיר את שורת הקוד `while(wait(NULL) > 0);`, מה עלול לקרות לתהליכי הבן בסיום ריצתם כל עוד התהליך האב עדיין רץ? הגדירו את המושג המתאים.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1: סך הכל ייווצרו 6 תהליכים. פירוט: התהליך הראשי (1) מריץ לולאה 3 פעמים. באיטרציה i=0 הוא יוצר בן (C1), והבן יוצר נכד (C1_1) כי 0 זוגי. באיטרציה i=1 הוא יוצר בן (C2), והוא לא יוצר נכד כי 1 אינו זוגי. באיטרציה i=2 הוא יוצר בן (C3), והוא יוצר נכד (C3_1) כי 2 זוגי. סה\"כ: 1 (אב) + 3 (בנים) + 2 (נכדים) = 6.\n\n7.2: אם נחליף ב-break, תהליכי הבנים והנכדים לא יסיימו את ריצתם מיד אלא יצאו מהלולאה וימשיכו לשורת ה-wait. במקרה זה, מספר התהליכים שייווצרו לא ישתנה (עדיין 6), מכיוון שכל תהליך שנוצר יוצא מהלולאה ולא ממשיך לאיטרציות הבאות של האב.\n\n7.3: הפונקציה exit() היא פונקציית ספרייה המבצעת ניקוי (cleanup) הכולל ריקון חוצצים (buffers) של stdio לפני סיום התהליך, בעוד _exit() היא קריאת מערכת שמסיימת את התהליך מיד ללא ניקוי חוצצים. בבנים משתמשים לעיתים ב-_exit כדי למנוע מצב שבו חוצצים שהועתקו מהאב ירוקנו פעמיים (גם ע\"י הבן וגם ע\"י האב), מה שעלול להוביל לכפילות בפלט.\n\n7.4: ללא ה-wait, תהליכי הבן יהפכו לתהליכי 'זומבי' (Zombie Processes). זהו מצב שבו התהליך סיים את ביצועו אך עדיין קיימת רשומה עבורו בטבלת התהליכים של מערכת ההפעלה, כדי לאפשר לאב לקרוא את קוד היציאה שלו."}, "difficulty_estimation": "Medium", "_source_file": "0037__Processes__Open__Medium.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:17:57", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Processes", "System Calls", "Memory Management"], "content": {"text": "נתון קוד בשפת C המשתמש בקריאות המערכת fork ו-wait. הנח שכל קריאות המערכת מצליחות ומתבצעות ללא שגיאות. ענו על הסעיפים הבאים בהסתמך על הקוד.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 10;\n    if (fork() == 0) {\n        x += 5;\n        if (fork() == 0) {\n            x += 5;\n            printf(\"%d\\n\", x);\n        } else {\n            wait(NULL);\n            x -= 2;\n            printf(\"%d\\n\", x);\n        }\n    } else {\n        wait(NULL);\n        printf(\"%d\\n\", x);\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "כמה תהליכים נוצרו בסך הכל במהלך הרצת התוכנית (כולל תהליך האב המקורי)?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "מה יהיה הפלט של התוכנית? יש לציין את הערכים המודפסים לפי סדר הדפסתם ולהסביר את החישוב עבור כל אחד.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "האם המשתנה x משותף בין התהליכים השונים? הסבירו כיצד מנגנון ה-Copy-on-Write (CoW) בא לידי ביטוי במקרה זה.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: נוצרו 3 תהליכים בסך הכל. תהליך האב המקורי (P1), תהליך הבן הראשון (P2) שנוצר ב-fork הראשון, ותהליך הנכד (P3) שנוצר ב-fork השני בתוך הבלוק של הבן.\n\n1.2: הפלט יהיה:\n20\n13\n10\nהסבר: \n- P3 (הנכד): יורש x=15 מ-P2, מוסיף 5 ומדפיס 20.\n- P2 (הבן): מחכה ל-P3 שיסיים, לאחר מכן מחסיר 2 מה-x שלו (שהיה 15) ומדפיס 13.\n- P1 (האב): מחכה ל-P2 שיסיים, מדפיס את ה-x שלו שנשאר 10 ללא שינוי.\nהסדר מובטח עקב קריאות ה-wait.\n\n1.3: לא, המשתנה אינו משותף. כל תהליך מקבל מרחב כתובות וירטואלי נפרד. מנגנון Copy-on-Write גורם לכך שכל עוד התהליכים רק קוראים מהזיכרון, הם חולקים את אותם דפים פיזיים. ברגע שתהליך מבצע כתיבה (כמו x += 5), מערכת ההפעלה יוצרת עותק פיזי נפרד של הדף עבור אותו תהליך, כך שהשינוי אינו משפיע על תהליך האב או תהליכים מקבילים אחרים."}, "difficulty_estimation": "Medium", "_source_file": "0038__Processes__Open__Medium.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:18:11", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Processes", "Fork", "Address Space"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בקריאת המערכת fork(). הניחו כי כל הקריאות למערכת מצליחות וכי הפלט נכתב למסך באופן מיידי (ללא buffering).", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 10;\n    pid_t pid1 = fork();\n\n    if (pid1 == 0) {\n        x += 5;\n        pid_t pid2 = fork();\n        if (pid2 == 0) {\n            x *= 2;\n            printf(\"A: x=%d\\n\", x);\n        } else {\n            wait(NULL);\n            x -= 2;\n            printf(\"B: x=%d\\n\", x);\n        }\n    } else {\n        wait(NULL);\n        x += 1;\n        printf(\"C: x=%d\\n\", x);\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "כמה תהליכים נוצרו בסך הכל במהלך ריצת התוכנית (כולל התהליך הראשי)? ציירו את עץ התהליכים.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "מה יהיה הפלט של התוכנית? האם סדר ההדפסות מובטח? הסבירו.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "האם שינוי המשתנה x בתהליך אחד משפיע על ערכו בתהליך אחר? הסבירו מדוע על סמך מנגנון הזיכרון של תהליכים.", "code_snippet": null, "options": null}, {"id": "1.4", "text": "מה יקרה אם נסיר את כל קריאות ה-wait(NULL) מהקוד? האם ערכי ה-x המודפסים ישתנו? האם סדר ההדפסה ישתנה?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: נוצרו 3 תהליכים בסך הכל. התהליך הראשי (P1) יוצר בן (P2), והבן (P2) יוצר נכד (P3). עץ התהליכים הוא ליניארי: P1 -> P2 -> P3.\n\n1.2: הפלט יהיה:\nA: x=30\nB: x=13\nC: x=11\nסדר ההדפסות מובטח בגלל קריאות ה-wait. תהליך P2 מחכה ל-P3 (לכן A לפני B), ותהליך P1 מחכה ל-P2 (לכן B לפני C).\n\n1.3: לא. בעת ביצוע fork, התהליך הבן מקבל העתק של מרחב הכתובות של האב (Copy-on-Write). לכן, לכל תהליך יש עותק פרטי משלו של המשתנה x בזיכרון שלו, ושינויים בו אינם משפיעים על תהליכים אחרים.\n\n1.4: ערכי ה-x המודפסים לא ישתנו, כי המרחבים עדיין מופרדים. עם זאת, סדר ההדפסה לא יהיה מובטח יותר ויהיה תלוי במתזמן (Scheduler), שכן התהליכים ירוצו במקביל ללא סנכרון."}, "difficulty_estimation": "Medium", "_source_file": "0039__Processes__Open__Medium.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:18:27", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Processes", "Fork", "Address Space"], "content": {"text": "נתונה תוכנית בשפת C המשתמשת בקריאת המערכת fork. הניחו כי כל הקריאות למערכת מצליחות וכי התהליכים מסתיימים כסדרם (אין תהליכי זומבי או יתומים במהלך הריצה שימנעו את ההדפסות).", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 10;\n    pid_t p1 = fork();\n    if (p1 == 0) {\n        x += 5;\n        pid_t p2 = fork();\n        if (p2 == 0) {\n            x += 5;\n            printf(\"Child-Child: x = %d\\n\", x);\n        } else {\n            wait(NULL);\n            printf(\"Child: x = %d\\n\", x);\n        }\n    } else {\n        wait(NULL);\n        x -= 5;\n        printf(\"Parent: x = %d\\n\", x);\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "מה יהיה פלט התוכנית? יש להסביר את סדר ההדפסות ואת הערך של x בכל הדפסה.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "כמה תהליכים נוצרו בסך הכל במהלך ריצת התוכנית (כולל התהליך הראשי)?", "code_snippet": null, "options": null}, {"id": "1.3", "text": "האם שינוי הערך של x בתהליך הבן משפיע על ערכו של x בתהליך האב? הסבר מדוע בהתבסס על ניהול הזיכרון של תהליכים.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: פלט התוכנית יהיה:\nChild-Child: x = 20\nChild: x = 15\nParent: x = 5\nהסבר: התהליך הראשי (P1) מפצל את P2. ב-P2 המשתנה x הופך ל-15. P2 מפצל את P3. ב-P3 המשתנה x הופך ל-20 ומודפס. בגלל פקודות ה-wait, P3 מסיים ומדפיס ראשון, אחריו P2 מדפיס (x=15) ואז P1 מבצע x-=5 (מתוך ה-10 המקורי שלו) ומדפיס (x=5).\n\n1.2: נוצרו 3 תהליכים בסך הכל: התהליך המקורי (P1), הבן שלו (P2), והנכד (P3 - הבן של P2).\n\n1.3: לא, השינוי אינו משפיע. בעת ביצוע fork(), מערכת ההפעלה יוצרת עותק של מרחב הכתובות (Address Space) של תהליך האב עבור תהליך הבן. למרות שהם משתמשים באותן כתובות וירטואליות, הן ממופות למסגרות פיזיות שונות בזיכרון (או משתמשות במנגנון Copy-on-Write שיוצר עותק פיזי רק בעת כתיבה). לכן, לכל תהליך יש עותק פרטי משלו של המשתנה x."}, "difficulty_estimation": "Medium", "_source_file": "0040__Processes__Open__Medium.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:18:46", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Processes", "Fork", "Short-circuit evaluation", "Process Tree", "Synchronization"], "content": {"text": "נתון קוד ה-C הבא המשתמש בקריאות מערכת לניהול תהליכים. הניחו שכל הקריאות ל-fork מצליחות, שהמערכת אינה מוגבלת במשאבים, ושאין אופטימיזציות קומפילציה המשנות את לוגיקת הקריאות. ענו על הסעיפים הבאים תוך פירוט מלא של עץ התהליכים והלוגיקה.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <sys/types.h>\n\nint main() {\n    pid_t pid;\n    if (fork() == 0) {\n        // Child block\n        if (fork() || fork()) {\n            fork();\n        }\n    } else {\n        // Parent block\n        wait(NULL);\n        printf(\"Parent Done\\n\");\n    }\n    printf(\"Process %d exiting\\n\", getpid());\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "כמה תהליכים נוצרים בסך הכל במהלך הרצת התוכנית (כולל התהליך המקורי)? פרטו את שלבי היצירה.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "כמה פעמים תודפס המחרוזת 'Process %d exiting' (כאשר %d הוא ה-PID) וכמה פעמים תודפס המחרוזת 'Parent Done'?", "code_snippet": null, "options": null}, {"id": "10.3", "text": "האם מובטח שההדפסה 'Parent Done' תהיה האחרונה שתופיע על המסך? נמקו את תשובתכם על בסיס מנגנון ה-wait.", "code_snippet": null, "options": null}], "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: ניתוח עץ התהליכים:\n- התהליך המקורי (P0) מבצע fork ראשון. נוצר P1 (הבן של P0).\n- P0 נכנס לבלוק ה-else ומבצע wait.\n- P1 נכנס לבלוק ה-if הראשון ומבצע fork (השני בתוכנית). נוצר P2 (הבן של P1).\n- בתוך ה-if הפנימי (fork() || fork()):\n  א. עבור P1: ה-fork מחזיר ערך חיובי (ה-PID של P2), ולכן בשל short-circuit evaluation של אופרטור ה-OR (||), ה-fork השני בביטוי לא מתבצע. P1 נכנס לתוך ה-if ומבצע fork נוסף (יצירת P4).\n  ב. עבור P2: ה-fork מחזיר 0, ולכן הוא חייב לבצע את החלק השני של ה-OR. הוא מבצע fork (השלישי בתוכנית) ויוצר את P3. עבור P2, תוצאת ה-OR היא אמת (0 || PID_P3), ולכן הוא נכנס לתוך ה-if ומבצע fork נוסף (יצירת P5).\n  ג. עבור P3: הוא נוצר מה-fork השני בביטוי ה-OR. הוא מקבל 0. תוצאת ה-OR עבורו היא (0 || 0) כלומר שקר, ולכן הוא לא נכנס לתוך ה-if.\nסך התהליכים: P0, P1, P2, P3, P4, P5 - סה\"כ 6 תהליכים.\n\n10.2: \n- המחרוזת 'Process %d exiting' מודפסת על ידי כל תהליך שמסיים את הריצה שלו מחוץ למבנה ה-if/else. מכיוון שיש 6 תהליכים וכולם מגיעים לשורה זו, היא תודפס 6 פעמים.\n- המחרוזת 'Parent Done' מודפסת רק בבלוק ה-else של ה-fork הראשון. רק תהליך P0 (האב המקורי) נכנס לבלוק זה, ולכן היא תודפס פעם אחת בלבד.\n\n10.3: \nלא, זה לא מובטח. הקריאה wait(NULL) ב-P0 גורמת לו להמתין לסיום של *אחד* מילדיו הישירים. ל-P0 יש רק ילד ישיר אחד והוא P1. ברגע ש-P1 מסיים (exit), P0 משתחרר מה-wait וממשיך להדפסה. עם זאת, P1 עצמו לא קורא ל-wait עבור הילדים שלו (P2, P4). לכן, ייתכן ש-P1 יסיים את ריצתו והדפסתו בזמן שילדיו (ונכדיו P3, P5) עדיין רצים. במצב כזה, P0 ידפיס 'Parent Done' ו-'Process P0 exiting' בזמן שתהליכים אחרים עדיין פעילים ברקע (תהליכים אלו יהפכו ליתומים - orphans)."}, "difficulty_estimation": "Hard", "_source_file": "0041__Processes__Open__Hard.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:19:18", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Processes", "Fork", "Process Tree"], "content": {"text": "נתון הקוד הבא בשפת C. הניחו כי כל קריאות המערכת מצליחות, וכי הפלט מודפס לטרמינל ללא השהיות (buffering) משמעותיות שמשנות את סדר הלוגיקה (פרט לסדר הסטנדרטי של תזמון תהליכים).", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    int i;\n    for (i = 0; i < 3; i++) {\n        if (fork() == 0) {\n            if (i % 2 == 0) {\n                fork();\n                printf(\"A\\n\");\n            } else {\n                printf(\"B\\n\");\n                exit(0);\n            }\n        }\n    }\n    while(wait(NULL) > 0);\n    printf(\"C\\n\");\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "כמה פעמים יודפס התו 'A' במהלך ריצת התוכנית? פרטו את החישוב.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "כמה פעמים יודפס התו 'B' במהלך ריצת התוכנית? פרטו את החישוב.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "כמה פעמים יודפס התו 'C' במהלך ריצת התוכנית? פרטו את החישוב.", "code_snippet": null, "options": null}, {"id": "10.4", "text": "מהו מספר התהליכים הכולל שנוצרו במערכת (כולל תהליך האב המקורי)?", "code_snippet": null, "options": null}], "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ננתח את הלולאה לפי איטרציות:\n1. איטרציה i=0:\n- תהליך האב (P) יוצר בן (C1).\n- C1 נכנס לתנאי (i%2 == 0), מבצע fork נוסף ויוצר את C1a.\n- גם C1 וגם C1a מדפיסים 'A' וממשיכים לאיטרציה הבאה (i=1).\n- סה\"כ הדפסות 'A': 2.\n- תהליכים פעילים שממשיכים ל-i=1: P, C1, C1a.\n\n2. איטרציה i=1:\n- כל אחד מהתהליכים הפעילים (P, C1, C1a) מבצע fork.\n- נוצרים 3 בנים חדשים. עבורם i=1, לכן i%2 != 0.\n- כל אחד מ-3 הבנים הללו מדפיס 'B' ומבצע exit(0).\n- סה\"כ הדפסות 'B': 3.\n- תהליכים פעילים שממשיכים ל-i=2: P, C1, C1a.\n\n3. איטרציה i=2:\n- כל אחד מהתהליכים הפעילים (P, C1, C1a) מבצע fork.\n- נוצרים 3 בנים חדשים (C2, C3, C4). עבורם i=2, לכן i%2 == 0.\n- כל אחד מהם (C2, C3, C4) מבצע fork נוסף (יוצרים את C2a, C3a, C4a).\n- כל ה-6 הללו (הבנים והנכדים של איטרציה זו) מדפיסים 'A'.\n- סה\"כ הדפסות 'A' באיטרציה זו: 6.\n- תהליכים פעילים שמסיימים את הלולאה: P, C1, C1a, C2, C2a, C3, C3a, C4, C4a (סה\"כ 9 תהליכים).\n\n4. סיום (הדפסת 'C'):\n- כל תהליך שמסיים את הלולאה ומגיע לשורת ה-wait מדפיס 'C' פעם אחת לאחר שכל בניו הסתיימו.\n- ישנם 9 תהליכים כאלו.\n\nסיכום:\n- כמות 'A': 2 (מאיטרציה 0) + 6 (מאיטרציה 2) = 8.\n- כמות 'B': 3 (מאיטרציה 1).\n- כמות 'C': 9.\n- סה\"כ תהליכים: תהליך מקורי (1) + בנים מאיטרציה 0 (2) + בנים מאיטרציה 1 (3) + בנים מאיטרציה 2 (6) = 12."}, "difficulty_estimation": "Hard", "_source_file": "0042__Processes__Open__Hard.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:19:41", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Processes", "Fork", "Wait", "Process Tree"], "content": {"text": "נתון הקוד הבא בשפת C. הנח שכל הקריאות למערכת מצליחות, שההדפסות מתבצעות ללא buffering (כלומר יוצאות מיד למסך), ושאין השהיות חיצוניות. ענה על הסעיפים הבאים:\n1. כמה פעמים תודפס האות 'A' וכמה פעמים תודפס האות 'B' על המסך?\n2. תאר את עץ התהליכים שנוצר. עבור כל תהליך, ציין אילו אותיות הוא מדפיס ובאיזה שלב.\n3. האם ייתכן מצב שבו האות 'B' מודפסת לפני כל מופע כלשהו של האות 'A'? נמק את תשובתך על סמך מנגנון הסנכרון בקוד.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int i, status;\n    pid_t pid;\n    for (i = 0; i < 2; i++) {\n        pid = fork();\n        if (pid == 0) {\n            // Child process\n            if (i == 0) {\n                fork();\n            }\n            printf(\"A\");\n        } else {\n            // Parent process\n            waitpid(pid, &status, 0);\n            printf(\"B\");\n        }\n    }\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ניתוח הריצה:\n1. איטרציה i=0:\n- תהליך האב המקורי (P1) מבצע fork ויוצר את P2. \n- P1 נכנס ל-else ומחכה ל-P2 (באמצעות waitpid).\n- P2 (הבן) נכנס ל-if (pid == 0). כיוון ש-i=0, הוא מבצע fork נוסף ויוצר את P3.\n- P2 מדפיס 'A'.\n- P3 (הנכד) נוצר בתוך הבלוק של i=0 ומדפיס 'A'.\n\n2. איטרציה i=1:\n- P2 ו-P3 ממשיכים לאיטרציה הבאה. \n- P2 מבצע fork ויוצר את P4. P2 מחכה ל-P4 ומדפיס 'B'.\n- P4 (הנין) מדפיס 'A' (הוא לא עושה fork כי i=1) ומסיים.\n- P3 מבצע fork ויוצר את P5. P3 מחכה ל-P5 ומדפיס 'B'.\n- P5 (הנין) מדפיס 'A' ומסיים.\n- לאחר ש-P2 מסיים את i=1 ויוצא, P1 (שחיכה לו) מדפיס 'B' וממשיך ל-i=1.\n- P1 (ב-i=1) מבצע fork ויוצר את P6. P1 מחכה ל-P6 ומדפיס 'B'.\n- P6 מדפיס 'A' ומסיים.\n\nסיכום הדפסות:\n- האות 'A' מודפסת ע\"י: P2(i=0), P3(i=0), P4(i=1), P5(i=1), P6(i=1). סה\"כ 5 פעמים.\n- האות 'B' מודפסת ע\"י: P2(i=1), P3(i=1), P1(i=0), P1(i=1). סה\"כ 4 פעמים.\n\nתשובה לסעיף 3:\nלא, לא ייתכן ש-'B' תודפס לפני כל 'A'. בקוד קיים שימוש ב-waitpid המאלץ את האב לחכות לסיום הילד שלו לפני הדפסת 'B'. לדוגמה, P2 ו-P3 מדפיסים 'A' מיד בתחילת הריצה (i=0) עוד לפני שהם יכולים להגיע לשלב ההדפסה של 'B' או לפני ש-P1 יכול להשתחרר מה-wait שלו. כיוון ש-P2 חייב להדפיס 'A' ב-i=0 לפני שהוא בכלל מגיע ל-i=1 או מסיים, ו-P1 מחכה ל-P2, ה-'A' של P2 תמיד תופיע לפני ה-'B' של P1."}, "difficulty_estimation": "Hard", "_source_file": "0043__Processes__Open__Hard.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:20:21", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Processes", "Fork", "Wait", "Process Hierarchy"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בקריאות המערכת fork ו-wait. עליכם לנתח את פעולת התוכנית ולענות על הסעיפים הבאים. הניחו כי כל הקריאות ל-fork מצליחות וכי אין בעיות זיכרון או משאבים. יש לפרט ולנמק את כל שלבי החישוב.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int val = 5;\n    for (int i = 0; i < 2; i++) {\n        if (fork() == 0) {\n            val += 2;\n            if (fork() > 0) {\n                val *= 2;\n                wait(NULL);\n            }\n        } else {\n            wait(NULL);\n            val -= 1;\n        }\n    }\n    printf(\"%d\\n\", val);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "כמה תהליכים סה\"כ (כולל תהליך האב המקורי) ייווצרו במהלך הרצת התוכנית? הציגו את עץ התהליכים (ניתן להשתמש בשמות כמו P0, P1 וכו' כדי לסמן את התהליכים).", "code_snippet": null, "options": null}, {"id": "10.2", "text": "מהם הערכים שיודפסו למסך? יש לציין איזה ערך הודפס על ידי כל תהליך שזיהיתם בסעיף הקודם (לדוגמה: 'תהליך P0 הדפיס X').", "code_snippet": null, "options": null}], "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ניתוח עץ התהליכים:\n1. התחלה: תהליך P0 עם val=5.\n2. איטרציה i=0:\n   - P0 מבצע fork ויוצר את P1. P0 נכנס ל-else, מחכה ל-P1 ומבצע val -= 1 (val=4).\n   - P1 (בן) מבצע val += 2 (val=7). אז P1 מבצע fork נוסף ויוצר את P2. \n   - ב-P1 (אב של P2), התנאי fork()>0 מתקיים: val *= 2 (val=14), מחכה ל-P2.\n   - ב-P2 (בן של P1), התנאי fork()>0 לא מתקיים. P2 ממשיך עם val=7.\nכעת יש 3 תהליכים (P0, P1, P2) שממשיכים לאיטרציה i=1.\n\n3. איטרציה i=1:\n   - כל אחד מ-3 התהליכים משכפל את המבנה של האיטרציה הקודמת:\n   - P0 (val=4) יוצר את P3. P3 יוצר את P4. P0 מחכה ל-P3 ומבצע val -= 1 (val=3).\n   - P3 (בן של P0) מבצע val=4+2=6, יוצר את P4, הופך ל-val=12 ומחכה ל-P4. P4 נשאר val=6.\n   - P1 (val=14) יוצר את P5. P5 יוצר את P6. P1 מחכה ל-P5 ומבצע val -= 1 (val=13).\n   - P5 (בן של P1) מבצע val=14+2=16, יוצר את P6, הופך ל-val=32 ומחכה ל-P6. P6 נשאר val=16.\n   - P2 (val=7) יוצר את P7. P7 יוצר את P8. P2 מחכה ל-P7 ומבצע val -= 1 (val=6).\n   - P7 (בן של P2) מבצע val=7+2=9, יוצר את P8, הופך ל-val=18 ומחכה ל-P8. P8 נשאר val=9.\n\nסיכום:\n10.1: סה\"כ נוצרו 9 תהליכים.\n10.2: הערכים המודפסים הם:\n- P0 מדפיס 3\n- P1 מדפיס 13\n- P2 מדפיס 6\n- P3 מדפיס 12\n- P4 מדפיס 6\n- P5 מדפיס 32\n- P6 מדפיס 16\n- P7 מדפיס 18\n- P8 מדפיס 9"}, "difficulty_estimation": "Hard", "_source_file": "0044__Processes__Open__Hard.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:21:00", "_subject": "Virtualization"}, {"id": 101, "type": "Open", "topic": ["Processes", "Pipes", "Fork", "IPC"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בקריאות מערכת לניהול תהליכים ותקשורת ביניהם. הניחו כי כל קריאות המערכת (fork, pipe, write, read, wait) מצליחות ומתבצעות ללא שגיאות. ענו על הסעיפים הבאים תוך פירוט הנימוקים.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int fd[2];\n    pipe(fd);\n    pid_t p1 = fork();\n\n    if (p1 == 0) {\n        // Child 1 (C1)\n        close(fd[0]);\n        pid_t g1 = fork();\n        if (g1 == 0) {\n            // Grandchild (G)\n            int val = 15;\n            write(fd[1], &val, sizeof(val));\n            printf(\"G\");\n            return 0;\n        }\n        wait(NULL);\n        int val = 25;\n        write(fd[1], &val, sizeof(val));\n        printf(\"C1\");\n        close(fd[1]);\n        return 0;\n    } else {\n        // Parent (P)\n        pid_t p2 = fork();\n        if (p2 == 0) {\n            // Child 2 (C2)\n            close(fd[1]);\n            int res, sum = 0;\n            while(read(fd[0], &res, sizeof(res)) > 0) {\n                sum += res;\n            }\n            printf(\"%d\", sum);\n            close(fd[0]);\n            return 0;\n        }\n        close(fd[0]);\n        close(fd[1]);\n        wait(NULL);\n        wait(NULL);\n        printf(\"P\");\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "101.1", "text": "מה יהיה הפלט המדויק של התוכנית? הסבירו את סדר ההדפסה ואת החישוב שהוביל לתוצאה.", "code_snippet": null, "options": null}, {"id": "101.2", "text": "כמה תהליכים נוצרו בסך הכל במהלך הרצת התוכנית (כולל תהליך האב המקורי)?", "code_snippet": null, "options": null}, {"id": "101.3", "text": "מה יקרה לפלט התוכנית אם נסיר את השורה (close(fd[1] בתהליך האב (השורה שנמצאת תחת הבלוק של ה-Parent)? נמקו.", "code_snippet": null, "options": null}], "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "101.1: הפלט יהיה GC140P. הסבר: תהליך C1 יוצר את G. תהליך G כותב 15 לצינור, מדפיס G ומסתיים. C1 ממתין ל-G (באמצעות wait), ואז כותב 25 לצינור, מדפיס C1 ומסתיים. תהליך C2 קורא מהצינור בלולאה. הוא יקרא את 15 ואז את 25. הלולאה תסתיים רק כאשר כל קצוות הכתיבה של הצינור ייסגרו. קצוות הכתיבה נמצאים אצל G (נסגר בסיום), C1 (נסגר במפורש ובסיום), והאב P. כיוון ש-P סוגר את fd[1] מיד לאחר ה-fork השני, ברגע ש-C1 מסתיים, אין יותר כותבים פתוחים ו-read יחזיר 0. לכן C2 ידפיס את הסכום 40. האב P ממתין לשני ילדיו ומדפיס P בסוף.\n\n101.2: נוצרו 4 תהליכים: האב המקורי (P), הבן הראשון (C1), הנכד (G), והבן השני (C2).\n\n101.3: אם האב לא יסגור את fd[1], התוכנית תיתקע (Deadlock/Hang). תהליך C2 יישאר חסום בקריאת ה-read בתוך הלולאה, כיוון שקיים עדיין קצה כתיבה פתוח (אצל האב P), ולכן מערכת ההפעלה לא תשלח סיגנל EOF (ערך חזרה 0 מ-read). כתוצאה מכך C2 לא ידפיס את הסכום ולא יסתיים, והאב P ימתין לו לנצח ב-wait."}, "difficulty_estimation": "Hard", "_source_file": "0045__Processes__Open__Hard.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:21:22", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Processes", "System Calls", "Memory Isolation"], "content": {"text": "לפניכם קוד בשפת C המשתמש בקריאות המערכת fork ו-waitpid. עליכם לנתח את פעולת הקוד ולענות על הסעיפים הבאים. הניחו שכל קריאות המערכת מצליחות ושאין השהיות חיצוניות מלבד אלו המשתמעות מהקוד. יש לפרט ולנמק את שלבי החישוב.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    int x = 10;\n    for (int i = 0; i < 2; i++) {\n        pid_t pid = fork();\n        if (pid == 0) {\n            x -= 2;\n            if (fork() == 0) {\n                x += 5;\n                printf(\"A: %d\\n\", x);\n                exit(0);\n            }\n            x++;\n            printf(\"B: %d\\n\", x);\n            exit(0);\n        } else {\n            waitpid(pid, NULL, 0);\n            x /= 2;\n        }\n    }\n    printf(\"C: %d\\n\", x);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "כמה תהליכים נוצרו בסך הכל במהלך הרצת התוכנית (כולל תהליך האב המקורי)?", "code_snippet": null, "options": null}, {"id": "10.2", "text": "מהו הפלט של התוכנית? במידה וסדר ההדפסה אינו דטרמיניסטי, ציינו אילו שורות יכולות להתחלף ביניהן והסבירו מדוע.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "כיצד היה משתנה ערכו של x המודפס בשורה המתחילה באות C, לו היינו מחליפים את השורה x /= 2; בשורה x = x - i;?", "code_snippet": null, "options": null}], "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ניתוח הקוד:\n1. סעיף 10.1: האב מבצע לולאה בת 2 איטרציות. בכל איטרציה הוא קורא ל-fork (יצירת ילד) ומחכה לו שיסתיים. כל ילד בתורו קורא ל-fork נוסף (יצירת נכד). \nאיטרציה i=0: אב -> ילד 1 -> נכד 1 (סה\"כ 3 תהליכים עד כה).\nאיטרציה i=1: אב -> ילד 2 -> נכד 2 (עוד 2 תהליכים).\nסה\"כ נוצרו 5 תהליכים.\n\n2. סעיף 10.2: \n- איטרציה i=0: האב מתחיל עם x=10. הילד יורש x=10, מחסיר 2 (x=8). הנכד יורש מהילד x=8, מוסיף 5 ומדפיס A: 13. הילד מוסיף 1 ומדפיס B: 9. האב מחכה לילד ומבצע x=10/2=5.\n- איטרציה i=1: האב כעת עם x=5. הילד השני יורש x=5, מחסיר 2 (x=3). הנכד השני יורש x=3, מוסיף 5 ומדפיס A: 8. הילד השני מוסיף 1 ומדפיס B: 4. האב מחכה לילד ומבצע x=5/2=2 (חלוקת שלמים).\n- סיום: האב מדפיס C: 2.\nסדר ההדפסה: בתוך כל איטרציה, הסדר בין A ל-B אינו דטרמיניסטי כי הילד והנכד רצים במקביל ואין wait ביניהם. אך כל איטרציה חייבת להסתיים לפני שהבאה מתחילה בגלל ה-waitpid של האב. לכן A:13 ו-B:9 יופיעו לפני A:8 ו-B:4.\n\n3. סעיף 10.3: \n- ב-i=0: האב יבצע x = 10 - 0 = 10.\n- ב-i=1: האב יבצע x = 10 - 1 = 9.\nלכן הפלט בשורה C יהיה 9."}, "difficulty_estimation": "Hard", "_source_file": "0046__Processes__Open__Hard.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:21:51", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Processes", "Fork", "Wait", "Orphan Processes"], "content": {"text": "נתון קטע הקוד הבא בשפת C. הנח שכל קריאות המערכת מצליחות, שהתהליכים רצים על מעבד יחיד, ושהפלט של הפונקציה printf נכתב ל-stdout בצורה אטומית (כלומר, לא ייתכן ערבוב תווים בתוך מחרוזת אחת מהדפסות שונות). ענה על הסעיפים הבאים:", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    for (int i = 0; i < 2; i++) {\n        pid_t pid = fork();\n        if (pid == 0) {\n            printf(\"C%d \", i);\n            if (i == 0) {\n                if (fork() == 0) {\n                    printf(\"G \");\n                    return 0;\n                }\n                printf(\"G \");\n            }\n            return 0;\n        } else {\n            printf(\"P%d \", i);\n            wait(NULL);\n        }\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "כמה תהליכים נוצרו סך הכל במהלך ריצת התוכנית (כולל התהליך המקורי)? פרטו אילו תהליכים נוצרו ובאיזה שלב.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "שרטטו את עץ התהליכים (Process Tree) שנוצר במהלך הריצה.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "האם ייתכן שיתקבל הפלט הבא: 'P0 C0 G P1 C1 G '? נמקו את תשובתכם תוך התייחסות למנגנון ה-wait ולתהליכים יתומים (orphans).", "code_snippet": null, "options": null}], "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. נוצרו סה\"כ 4 תהליכים: התהליך המקורי (P), הבן הראשון (C0) שנוצר ב-i=0, הבן השני (C1) שנוצר ב-i=1, והנכד (G) שנוצר על ידי C0.\n2. עץ התהליכים: P הוא השורש. ל-P יש שני בנים ישירים: C0 ו-C1. ל-C0 יש בן אחד: G. חשוב לציין ש-C1 נוצר רק לאחר ש-C0 הסתיים, כיוון ש-P מבצע wait(NULL) בכל איטרציה ומחכה לסיום הבן הנוכחי לפני המעבר לאיטרציה הבאה.\n3. כן, הפלט ייתכן. הסבר: באיטרציה i=0, האב P יוצר את C0 ומחכה לו. C0 מדפיס 'C0', יוצר את G, ומדפיס 'G'. ברגע ש-C0 מסיים (return 0), האב P משתחרר מה-wait וממשיך לאיטרציה i=1. ב-i=1, האב מדפיס 'P1' ויוצר את C1 שמדפיס 'C1'. התהליך G הוא נכד של P ובן של C0. מכיוון ש-C0 לא ביצע wait(NULL) עבור G, התהליך G הופך ליתום (Orphan) וממשיך לרוץ במקביל לאב P. לכן, ה-'G' השני (שהודפס על ידי הנכד) יכול להופיע בכל שלב לאחר ה-fork בתוך C0, ובפרט בסוף הפלט לאחר ש-P ו-C1 כבר סיימו את פעולתם."}, "difficulty_estimation": "Hard", "_source_file": "0047__Processes__Open__Hard.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:22:29", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Processes", "Signals", "Fork"], "content": {"text": "לפניכם קוד בשפת C המשתמש בקריאות מערכת לניהול תהליכים וסיגנלים. הניחו שכל הקריאות למערכת מצליחות, שאין עומס חריג על המערכת, וכי פקודת sleep אכן גורמת לתהליך להמתין כנדרש. שימו לב כי סיגנלים עשויים לקטוע קריאות מערכת חוסמות (כמו sleep).", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <signal.h>\n\nint g_var = 1;\n\nvoid signal_handler(int sig) {\n    if (sig == SIGUSR1) g_var += 3;\n    else if (sig == SIGCHLD) g_var *= 2;\n}\n\nint main() {\n    signal(SIGUSR1, signal_handler);\n    signal(SIGCHLD, signal_handler);\n\n    pid_t p = fork();\n    if (p == 0) { // Child process\n        g_var += 5;\n        if (fork() == 0) { // Grandchild process\n            g_var += 10;\n            kill(getppid(), SIGUSR1);\n            exit(0);\n        }\n        wait(NULL);\n        printf(\"C: %d\\n\", g_var);\n        exit(0);\n    }\n\n    sleep(5);\n    printf(\"P: %d\\n\", g_var);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "מה יהיה הפלט של התוכנית? יש לכתוב את השורות בסדר הופעתן.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "הסבירו בפירוט את השתלשלות האירועים: מדוע כל ערך הודפס כפי שהודפס? התייחסו למרחבי הכתובות, לטיפול בסיגנלים ולסנכרון בין התהליכים.", "code_snippet": null, "options": null}], "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסבר השלבים:\n1. תהליך האב מתחיל עם g_var = 1 ורושם מטפלים לסיגנלים SIGUSR1 ו-SIGCHLD.\n2. האב מבצע fork. נוצר בן (C) עם עותק נפרד של g_var = 1.\n3. הבן מעדכן את g_var שלו ל-6 (1+5).\n4. הבן מבצע fork. נוצר נכד (GC) עם עותק נפרד של g_var = 6.\n5. הנכד מעדכן את g_var שלו ל-16 (6+10) ושולח סיגנל SIGUSR1 לאביו (הבן) באמצעות kill(getppid(), ...).\n6. הבן מקבל את הסיגנל SIGUSR1. המטפל שלו רץ ומעדכן את g_var של הבן ל-9 (6+3).\n7. הנכד מסיים (exit). סיום הנכד שולח סיגנל SIGCHLD לאביו (הבן).\n8. הבן מקבל SIGCHLD. המטפל שלו רץ ומכפיל את g_var שלו: 9 * 2 = 18.\n9. הבן משלים את ה-wait, מדפיס 'C: 18' ומסיים.\n10. סיום הבן שולח סיגנל SIGCHLD לאב.\n11. האב, שהיה ב-sleep, מתעורר עקב קבלת הסיגנל. המטפל של האב רץ ומכפיל את g_var שלו: 1 * 2 = 2.\n12. האב ממשיך להדפסה ומדפיס 'P: 2'.\n\nהפלט הצפוי:\nC: 18\nP: 2"}, "difficulty_estimation": "Hard", "_source_file": "0048__Processes__Open__Hard.json", "_topic_hint": "Processes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:23:25", "_subject": "Virtualization"}, {"id": 5, "type": "CodeAnalysis", "topic": ["Processes", "System Calls"], "content": {"text": "נתונה התוכנית הבאה. כמה פעמים תודפס המחרוזת \"Hello\"?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n\nint main() {\n    if (fork() == 0) {\n        fork();\n        printf(\"Hello\\n\");\n    }\n    return 0;\n}", "options": ["א. 1", "ב. 2", "ג. 3", "ד. 4"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "התהליך הראשי (האב) מבצע fork() ראשון. תהליך האב מקבל מהקריאה את ה-PID של הבן (ערך חיובי), ולכן התנאי fork() == 0 אינו מתקיים עבורו והוא מדלג על הבלוק. תהליך הבן מקבל מהקריאה את הערך 0, ולכן הוא נכנס לתוך בלוק ה-if. בתוך הבלוק, תהליך הבן מבצע fork() נוסף, מה שיוצר תהליך חדש (נכד). בשלב זה, גם הבן וגם הנכד נמצאים בתוך הבלוק וממשיכים לביצוע פקודת ה-printf. לכן, המחרוזת תודפס פעמיים (פעם אחת על ידי הבן ופעם אחת על ידי הנכד)."}, "difficulty_estimation": "Easy", "_source_file": "0049__Processes__CodeAnalysis__Easy.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:23:43", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Processes", "System Calls"], "content": {"text": "נתונה התוכנית הבאה. כמה פעמים תודפס המחרוזת \"Hello\" למסך? הניחו שכל קריאות המערכת מצליחות.", "code_snippet": "int main() {\n    for (int i = 0; i < 2; i++) {\n        fork();\n    }\n    printf(\"Hello\\n\");\n    return 0;\n}", "options": ["א. 2", "ב. 3", "ג. 4", "ד. 6", "ה. 8"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "בכל איטרציה של הלולאה, כל תהליך קיים מבצע fork() ובכך מכפיל את מספר התהליכים. בתחילה יש תהליך אחד (התהליך הראשי). לאחר האיטרציה הראשונה (i=0) ישנם 2 תהליכים. לאחר האיטרציה השנייה (i=1), כל אחד משני התהליכים הקיימים מבצע fork(), ולכן נוצרים 2 תהליכים נוספים, מה שמביא אותנו ל-4 תהליכים בסך הכל. כל אחד מארבעת התהליכים הללו ממשיך לשורת ה-printf ומדפיס את המחרוזת פעם אחת."}, "difficulty_estimation": "Easy", "_source_file": "0050__Processes__CodeAnalysis__Easy.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:23:52", "_subject": "Virtualization"}, {"id": 5, "type": "CodeAnalysis", "topic": ["Processes", "System Calls"], "content": {"text": "נתונה התוכנית הבאה. מה יהיה הפלט של התוכנית? (הנח שכל קריאות המערכת מצליחות, ואין חשיבות לסדר ההדפסה בין התהליכים השונים).", "code_snippet": "int main() {\n    int x = 10;\n    if (fork() == 0) {\n        x += 5;\n    } else {\n        x -= 5;\n    }\n    printf(\"%d \", x);\n    return 0;\n}", "options": ["א. 15 5", "ב. 15", "ג. 5", "ד. 10 10", "ה. 15 10"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "קריאת המערכת fork() יוצרת תהליך בן חדש המהווה העתק של תהליך האב. בתהליך הבן, הערך המוחזר מ-fork() הוא 0, ולכן הוא נכנס לבלוק ה-if ומעדכן את x ל-15. בתהליך האב, הערך המוחזר הוא ה-PID של הבן (גדול מ-0), ולכן הוא נכנס לבלוק ה-else ומעדכן את x ל-5. כיוון שלכל תהליך מרחב זיכרון נפרד, כל אחד מהם מדפיס את הערך המקומי שלו, ומתקבלים שני המספרים 15 ו-5."}, "difficulty_estimation": "Easy", "_source_file": "0051__Processes__CodeAnalysis__Easy.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:24:03", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Processes", "System Calls"], "content": {"text": "נתונה התוכנית הבאה. כמה פעמים תודפס המחרוזת \"OS\" למסך? הניחו שכל קריאות המערכת מצליחות וכי הפלט מרוקן (flushed) מיד לאחר ההדפסה.", "code_snippet": "int main() {\n    for (int i = 0; i < 2; i++) {\n        fork();\n    }\n    printf(\"OS\\n\");\n    return 0;\n}", "options": ["א. 2", "ב. 3", "ג. 4", "ד. 6", "ה. 8"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התוכנית מבצעת לולאה בת שתי איטרציות. בתחילה קיים תהליך אחד. באיטרציה הראשונה (i=0), התהליך מבצע fork ונוצר תהליך בן, כך שישנם 2 תהליכים. באיטרציה השנייה (i=1), כל אחד משני התהליכים הקיימים מבצע fork בעצמו, מה שיוצר שני תהליכים חדשים נוספים. סה\"כ בסיום הלולאה קיימים 4 תהליכים (2^2). כל אחד מארבעת התהליכים הללו ממשיך לשורת ההדפסה ומדפיס \"OS\" פעם אחת, ולכן המחרוזת תודפס 4 פעמים."}, "difficulty_estimation": "Easy", "_source_file": "0052__Processes__CodeAnalysis__Easy.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:24:16", "_subject": "Virtualization"}, {"id": 5, "type": "CodeAnalysis", "topic": ["Processes", "System Calls"], "content": {"text": "כמה פעמים תודפס המילה 'Hello' במהלך הרצת הקוד הבא? הניחו שכל הקריאות למערכת מצליחות.", "code_snippet": "int main() {\n    fork();\n    if (fork() == 0) {\n        fork();\n    }\n    printf(\"Hello\\n\");\n    return 0;\n}", "options": ["א. 3", "ב. 4", "ג. 6", "ד. 8", "ה. 5"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "לאחר ה-fork הראשון ישנם 2 תהליכים. בשורה השנייה, כל אחד מהם מבצע fork נוסף, מה שיוצר 2 תהליכים נוספים (סה\"כ 4 תהליכים בשלב זה). מתוך הארבעה, רק 2 התהליכים שהם 'בנים' של ה-fork השני (אלו שקיבלו את הערך 0) נכנסים לתוך בלוק ה-if ומבצעים fork שלישי. ה-fork השלישי יוצר 2 תהליכים נוספים. לסיכום: 4 תהליכים קיימים לפני ה-if, ועוד 2 נוצרים בתוכו, סה\"כ 6 תהליכים שכל אחד מהם מגיע לשורת ההדפסה."}, "difficulty_estimation": "Easy", "_source_file": "0053__Processes__CodeAnalysis__Easy.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:24:26", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Processes", "System Calls"], "content": {"text": "נתונה התוכנית הבאה בשפת C. כמה פעמים תודפס המילה 'OS' במהלך ריצת התוכנית?\nהניחו כי כל קריאות המערכת מצליחות, וכי כל הדפסה מתבצעת מיד ללא חוצץ (buffer).", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n\nint main() {\n    for (int i = 0; i < 2; i++) {\n        fork();\n        printf(\"OS\\n\");\n    }\n    return 0;\n}", "options": ["א. 2", "ב. 4", "ג. 6", "ד. 8", "ה. 16"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "באיטרציה הראשונה של הלולאה (i=0), מתבצעת קריאת fork אחת שיוצרת תהליך בן. בשלב זה ישנם 2 תהליכים (האב המקורי והבן החדש), וכל אחד מהם מדפיס את המילה 'OS' פעם אחת (סה\"כ 2 הדפסות). באיטרציה השנייה (i=1), כל אחד משני התהליכים הקיימים מבצע fork בעצמו, מה שיוצר 2 תהליכים נוספים (סה\"כ 4 תהליכים רצים כעת). כל ארבעת התהליכים הללו מבצעים את פקודת ההדפסה של האיטרציה השנייה (סה\"כ 4 הדפסות נוספות). לכן, סך כל הפעמים שהמילה תודפס הוא 2 + 4 = 6."}, "difficulty_estimation": "Easy", "_source_file": "0054__Processes__CodeAnalysis__Easy.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:24:52", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Processes", "System Calls"], "content": {"text": "נתונה התוכנית הבאה. כמה פעמים יודפס התו 'X' למסך? הניחו שכל קריאות המערכת מצליחות ותהליכים אינם נכשלים.", "code_snippet": "int main() {\n    if (fork() == 0) {\n        fork();\n        printf(\"X\\n\");\n    }\n    return 0;\n}", "options": ["א. 1", "ב. 2", "ג. 3", "ד. 4", "ה. 0"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "התהליך הראשי (האב) מבצע fork. תהליך האב מקבל ערך הגדול מ-0 ולכן אינו נכנס לבלוק ה-if. תהליך הבן מקבל את הערך 0 ונכנס לבלוק ה-if. בתוך הבלוק, תהליך הבן מבצע fork נוסף, מה שיוצר תהליך חדש (הנכד של התהליך המקורי). כעת, גם תהליך הבן וגם תהליך הנכד נמצאים בתוך הבלוק וממשיכים לשורת ההדפסה. לכן, התו 'X' יודפס פעמיים בסך הכל."}, "difficulty_estimation": "Easy", "_source_file": "0055__Processes__CodeAnalysis__Easy.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:25:05", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Processes", "System Calls"], "content": {"text": "נתונה התוכנית הבאה. כמה פעמים יודפס המחרוזת \"OS\" במהלך הרצת התוכנית? הניחו שכל קריאות המערכת מצליחות.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n\nint main() {\n    fork();\n    if (fork() == 0) {\n        fork();\n    }\n    printf(\"OS\\n\");\n    return 0;\n}", "options": ["א. 2", "ב. 4", "ג. 5", "ד. 6", "ה. 8"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "נבצע מעקב אחר יצירת התהליכים:\n1. התהליך המקורי (P1) מבצע את ה-fork הראשון. נוצר תהליך בן (P2). כעת יש 2 תהליכים.\n2. שני התהליכים (P1, P2) מגיעים לשורת ה-if ומבצעים fork נוסף:\n   - P1 יוצר את P3. ב-P1 ה-fork מחזיר PID חיובי (דילוג על ה-if). ב-P3 ה-fork מחזיר 0 (כניסה ל-if).\n   - P2 יוצר את P4. ב-P2 ה-fork מחזיר PID חיובי (דילוג על ה-if). ב-P4 ה-fork מחזיר 0 (כניסה ל-if).\n3. התהליכים שנכנסו ל-if (הם P3 ו-P4) מבצעים fork שלישי:\n   - P3 יוצר את P5.\n   - P4 יוצר את P6.\n4. כל התהליכים שנוצרו ולא הסתיימו מגיעים לשורת ההדפסה. התהליכים הם: P1, P2, P3, P4, P5, P6. סה\"כ 6 תהליכים, ולכן המחרוזת תודפס 6 פעמים."}, "difficulty_estimation": "Easy", "_source_file": "0056__Processes__CodeAnalysis__Easy.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:25:25", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Processes", "System Calls"], "content": {"text": "נתונה התוכנית הבאה בשפת C. מה יהיה הפלט של התוכנית? הניחו שכל קריאות המערכת מצליחות, וכי הפלט מודפס ברצף ללא רווחים או ירידות שורה.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 0;\n    for (int i = 0; i < 3; i++) {\n        if (fork() == 0) {\n            x++;\n        } else {\n            x--;\n            wait(NULL);\n            break;\n        }\n    }\n    printf(\"%d\", x);\n    return 0;\n}", "options": ["א. 3210", "ב. 310-1", "ג. -1013", "ד. 0", "ה. אף אחת מהתשובות אינה נכונה"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "נעקוב אחר יצירת התהליכים: התהליך הראשי (P0) מתחיל עם x=0. באיטרציה הראשונה (i=0) הוא יוצר בן (P1). P0 מבצע x-- (הופך ל-1-) ומחכה ל-P1. P1 מבצע x++ (הופך ל-1) וממשיך לאיטרציה הבאה. באיטרציה i=1, P1 יוצר בן (P2). P1 מבצע x-- (הופך ל-0) ומחכה ל-P2. P2 מבצע x++ (הופך ל-2) וממשיך לאיטרציה הבאה. באיטרציה i=2, P2 יוצר בן (P3). P2 מבצע x-- (הופך ל-1) ומחכה ל-P3. P3 מבצע x++ (הופך ל-3) ומסיים את הלולאה. P3 הוא הראשון שמגיע להדפסה ומדפיס 3. לאחר מכן P2 מסיים את ה-wait ומדפיס 1. לאחר מכן P1 מסיים את ה-wait ומדפיס 0. לבסוף P0 מסיים את ה-wait ומדפיס 1-. לכן הפלט הוא 310-1."}, "difficulty_estimation": "Medium", "_source_file": "0057__Processes__CodeAnalysis__Medium.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:25:42", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Processes", "System Calls", "Address Space"], "content": {"text": "נתונה התוכנית הבאה בשפת C. הניחו כי כל קריאות המערכת מצליחות, וכי הפונקציה wait(NULL) גורמת לתהליך האב להמתין עד לסיום ביצועו של תהליך בן אחד. מה יהיה הפלט המדויק של התוכנית?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint counter = 0;\n\nint main() {\n    for (int i = 0; i < 2; i++) {\n        if (fork() == 0) {\n            counter++;\n            printf(\"%d\", counter);\n        } else {\n            wait(NULL);\n            counter--;\n            printf(\"%d\", counter);\n        }\n    }\n    return 0;\n}", "options": ["א. 120-10-2", "ב. 1100-1-2", "ג. 120-1-20", "ד. 1210-1-2", "ה. אף אחת מהתשובות אינה נכונה"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "נעקוב אחר ביצוע התהליכים: 1. תהליך האב המקורי (P1) עם counter=0 ו-i=0 מבצע fork. P1 נכנס ל-wait. 2. הבן (P2) עם i=0 מקדם את counter ל-1 ומדפיס '1'. 3. P2 ממשיך ל-i=1 ומבצע fork. P2 נכנס ל-wait. 4. הבן של P2 (נקרא לו P3) עם i=1 מקדם את ה-counter שלו (שהיה 1) ל-2 ומדפיס '2'. P3 מסיים. 5. P2 משתחרר מה-wait, מקטין את ה-counter שלו ל-0 ומדפיס '0'. P2 מסיים. 6. P1 משתחרר מה-wait (של P2), מקטין את ה-counter שלו ל-1- ומדפיס '1-'. 7. P1 ממשיך ל-i=1 ומבצע fork. P1 נכנס ל-wait. 8. הבן החדש (P4) עם i=1 מקדם את ה-counter שלו (שהיה 1-) ל-0 ומדפיס '0'. P4 מסיים. 9. P1 משתחרר מה-wait, מקטין את ה-counter ל-2- ומדפיס '2-'. סה\"כ הפלט: 120-10-2."}, "difficulty_estimation": "Medium", "_source_file": "0058__Processes__CodeAnalysis__Medium.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:25:58", "_subject": "Virtualization"}, {"id": 7, "type": "CodeAnalysis", "topic": ["Processes", "System Calls", "Memory Management"], "content": {"text": "נתונה התוכנית הבאה בשפת C. הניחו שכל קריאות המערכת מצליחות, שהתהליכים רצים לפי סדר הקריאה ל-wait, ושהפלט מודפס למסך ללא השהיה (buffering). מה יהיה הפלט של התוכנית?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint x = 10;\n\nint main() {\n    for (int i = 0; i < 2; i++) {\n        if (fork() == 0) {\n            x += 5;\n            printf(\"%d \", x);\n            return 0;\n        } else {\n            wait(NULL);\n            x += 2;\n        }\n    }\n    printf(\"%d\", x);\n    return 0;\n}", "options": ["א. 15 15 10", "ב. 15 17 14", "ג. 15 22 24", "ד. 15 17 12", "ה. אף אחת מהתשובות אינה נכונה"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "באיטרציה הראשונה (i=0), האב יוצר בן. הבן מקבל עותק של x=10, מבצע x += 5 ומדפיס 15. האב ממתין לסיום הבן (wait) ואז מבצע x += 2, כך שערך x אצלו הופך ל-12. באיטרציה השנייה (i=1), האב יוצר בן נוסף. הבן השני יורש את ערך ה-x הנוכחי של האב (12), מבצע x += 5 ומדפיס 17. האב שוב ממתין ואז מבצע x += 2, כך שערך x אצלו הופך ל-14. בסיום הלולאה, האב מדפיס את ערך ה-x שלו (14). מכיוון שכל תהליך מקבל עותק נפרד של הזיכרון (Copy-on-Write), השינויים של הבנים לא משפיעים על האב ולהיפך, מלבד הירושה ברגע ה-fork. לכן הפלט הכולל הוא 15 17 14."}, "difficulty_estimation": "Medium", "_source_file": "0059__Processes__CodeAnalysis__Medium.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:26:24", "_subject": "Virtualization"}, {"id": 7, "type": "CodeAnalysis", "topic": ["Processes"], "content": {"text": "נתונה התוכנית הבאה בשפת C. הניחו שכל קריאות המערכת מצליחות, ושלא פועלים במערכת תהליכים נוספים פרט לאלו שנוצרים בקוד. תזכורת: כל הדפסה לפלט הסטנדרטי מתבצעת מיד, ללא חוצץ (buffer) הדפסה. איזה מהפלטים הבאים אינו אפשרי?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    if (fork() == 0) {\n        fork();\n        printf(\"1\");\n    } else {\n        wait(NULL);\n        printf(\"2\");\n    }\n    return 0;\n}", "options": ["א. 112", "ב. 121", "ג. 211", "ד. כל הפלטים המוצגים אפשריים"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התהליך הראשי (האב) מבצע fork ויוצר את תהליך הבן (C1). לאחר מכן האב קורא ל-wait, מה שאומר שהוא ימתין עד ש-C1 יסיים את ריצתו לפני שידפיס '2'. תהליך C1 בעצמו מבצע fork ויוצר תהליך נכד (G1). גם C1 וגם G1 מדפיסים '1'. כיוון ש-C1 חייב להדפיס '1' לפני שהוא מסיים את ריצתו, והאב מדפיס '2' רק לאחר סיום C1, הרי שלפחות תו '1' אחד חייב להופיע לפני התו '2' בפלט. לכן הפלט '211' אינו אפשרי (הנכד G1 יכול להדפיס '1' אחרי ה-'2' של האב אם C1 סיים לפניו, אך הבן C1 עצמו חייב להדפיס '1' לפני ה-'2')."}, "difficulty_estimation": "Medium", "_source_file": "0060__Processes__CodeAnalysis__Medium.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:26:59", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Processes", "System Calls"], "content": {"text": "נתון קטע הקוד הבא בשפת C. הניחו כי כל קריאות המערכת מצליחות, וכי הפלט מודפס ישירות למסך ללא שימוש ב-buffer פנימי. מה יהיו הערכים המודפסים על המסך בסיום ריצת התוכנית (הסדר אינו מחייב)?", "code_snippet": "int main() {\n    int x = 0;\n    for (int i = 0; i < 2; i++) {\n        if (fork() == 0) {\n            x += 2;\n        } else {\n            x += 1;\n            wait(NULL);\n        }\n    }\n    printf(\"%d \", x);\n    return 0;\n}", "options": ["א. 2 3 3 4", "ב. 1 2 3 4", "ג. 2 2 4 4", "ד. 0 1 2 3", "ה. אף אחת מהתשובות אינה נכונה"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "נעקוב אחר פיצול התהליכים וערך המשתנה x (הנמצא במרחב הכתובות הנפרד של כל תהליך):\n1. התהליך המקורי (P0) מתחיל עם x=0.\n2. איטרציה ראשונה (i=0): P0 מבצע fork. נוצר בן P1. בבן (P1) התנאי מתקיים ו-x גדל ל-2. באב (P0) התנאי לא מתקיים, x גדל ל-1 והוא ממתין לבנו.\n3. איטרציה שנייה (i=1):\n   - תהליך P1 (שבו x=2) מבצע fork ויוצר את P3. ב-P3 (הבן החדש) x=2+2=4. ב-P1 (האב של P3) x=2+1=3.\n   - לאחר ש-P1 מסיים, P0 ממשיך לאיטרציה השנייה שלו. P0 (שבו x=1) מבצע fork ויוצר את P2. ב-P2 (הבן החדש) x=1+2=3. ב-P0 (האב) x=1+1=2.\n4. בסיום, כל ארבעת התהליכים שנוצרו (P0, P1, P2, P3) מדפיסים את ערך ה-x שלהם: 2, 3, 3, 4."}, "difficulty_estimation": "Medium", "_source_file": "0061__Processes__CodeAnalysis__Medium.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:27:20", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Processes", "System Calls", "Memory Management"], "content": {"text": "נתונה התוכנית הבאה בשפת C. מה יהיה הפלט של התוכנית? הניחו שכל קריאות המערכת מצליחות ושהפלט מודפס מיד ללא חוצץ (buffering).", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint x = 5;\n\nint main() {\n    for (int i = 0; i < 2; i++) {\n        if (fork() == 0) {\n            x += 10;\n            printf(\"%d\", x);\n            return 0;\n        } else {\n            wait(NULL);\n            x -= 2;\n            printf(\"%d\", x);\n        }\n    }\n    return 0;\n}", "options": ["א. 153131", "ב. 1513131", "ג. 155133", "ד. 15151313", "ה. 151331"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "בכל איטרציה של הלולאה, תהליך האב יוצר תהליך בן ומחכה לסיומו בעזרת wait. כיוון שכל תהליך מקבל מרחב כתובות נפרד, השינויים במשתנה הגלובלי x בתוך הבן אינם משפיעים על האב, אך הבן יורש את הערך הנוכחי של x מהאב ברגע ה-fork. באיטרציה הראשונה (i=0): הבן מקבל x=5, מוסיף 10 ומדפיס 15. האב מחכה, מעדכן את ה-x שלו ל-3 (5-2) ומדפיס 3. באיטרציה השנייה (i=1): האב (שה-x שלו הוא 3) יוצר בן חדש. הבן יורש x=3, מוסיף 10 ומדפיס 13. האב מחכה, מעדכן את ה-x שלו ל-1 (3-2) ומדפיס 1. התוצאה המצטברת היא 153131."}, "difficulty_estimation": "Medium", "_source_file": "0062__Processes__CodeAnalysis__Medium.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:27:33", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Processes", "System Calls", "Fork"], "content": {"text": "נתונה התוכנית הבאה בשפת C. הניחו כי כל קריאות המערכת מצליחות, וכי הפלט מודפס מיד למסך (ללא buffering). מה יהיה הפלט של התוכנית?", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    int x = 5;\n    for (int i = 0; i < 2; i++) {\n        if (fork() == 0) {\n            x += 10;\n            printf(\"%d\", x);\n            exit(0);\n        } else {\n            x += 2;\n            wait(NULL);\n        }\n    }\n    printf(\"%d\", x);\n    return 0;\n}", "options": ["א. 15159", "ב. 15179", "ג. 152535", "ד. 151719", "ה. 15177"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "בתחילת התוכנית x=5. באיטרציה הראשונה (i=0), מתבצע fork. הבן הראשון מקבל עותק של x=5, מעדכן אותו ל-15 (x += 10), מדפיס '15' ומסיים (exit). האב באותו זמן מעדכן את ה-x שלו ל-7 (x += 2) ומחכה לסיום הבן. באיטרציה השנייה (i=1), האב (שבו x=7) מבצע fork נוסף. הבן השני מקבל עותק של x=7, מעדכן אותו ל-17 (x += 10), מדפיס '17' ומסיים. האב מעדכן את ה-x שלו ל-9 (x += 2) ומחכה לסיום הבן. בסיום הלולאה, האב מדפיס את הערך הסופי של x שלו, שהוא 9. לכן הפלט המצטבר הוא 15179."}, "difficulty_estimation": "Medium", "_source_file": "0063__Processes__CodeAnalysis__Medium.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:27:45", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Processes", "System Calls", "Memory Management"], "content": {"text": "נתונה התוכנית הבאה בשפת C. מה יהיה הפלט של התוכנית? הניחו שכל קריאות המערכת מצליחות, שההדפסות מתבצעות מיד ללא חוצץ (buffer), ושתהליך אב תמיד ממתין לסיום ילדיו לפני שהוא ממשיך בביצוע.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint val = 5;\n\nint main() {\n    pid_t pid;\n    pid = fork();\n    if (pid == 0) {\n        val += 15;\n        if (fork() == 0) {\n            val += 20;\n            printf(\"%d\", val);\n        } else {\n            wait(NULL);\n            printf(\"%d\", val);\n        }\n    } else {\n        wait(NULL);\n        val += 10;\n        printf(\"%d\", val);\n    }\n    return 0;\n}", "options": ["א. 402015", "ב. 404015", "ג. 402025", "ד. 404025", "ה. 204015"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "לאחר ה-fork הראשון, נוצר תהליך בן (C1) בו המשתנה הגלובלי val הוא 5. C1 מעדכן את val ל-20. לאחר מכן C1 מבצע fork נוסף ויוצר נכד (G1). ב-G1 המשתנה val מתחיל ב-20, מעודכן ל-40 ומודפס. כיוון שלכל תהליך מרחב זיכרון נפרד (Copy on Write), השינוי בנכד לא משפיע על C1. לכן, לאחר ה-wait ב-C1, הוא מדפיס את הערך שלו שהוא 20. תהליך האב המקורי המתין לסיום C1, ולאחר מכן הוסיף 10 לערך המקורי שלו (5) והדפיס 15. התוצאה המשורשרת היא 402015."}, "difficulty_estimation": "Medium", "_source_file": "0064__Processes__CodeAnalysis__Medium.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:27:56", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Processes", "fork", "wait", "Memory Isolation", "Concurrency"], "content": {"text": "נתונה התוכנית הבאה בשפת C. הניחו שכל קריאות המערכת מצליחות, ושאין תהליכים נוספים במערכת מלבד אלו שנוצרים על ידי התוכנית. הניחו כי המערכת אינה משתמשת בחוצצים (buffers) עבור הפלט.", "code_snippet": "1  #include <stdio.h>\n2  #include <unistd.h>\n3  #include <sys/wait.h>\n4  #include <stdlib.h>\n5\n6  int main() {\n7    int x = 1;\n8    pid_t p;\n9    for (int i = 0; i < 2; i++) {\n10     p = fork();\n11     if (p == 0) {\n12       x += 2;\n13       if (i == 1) {\n14         if (fork() == 0) {\n15           x *= 2;\n16           printf(\"C: %d\\n\", x);\n17           exit(0);\n18         }\n19         wait(NULL);\n20       }\n21       printf(\"B: %d\\n\", x);\n22       exit(0);\n23     } else {\n24       x += 1;\n25     }\n26   }\n27   while(wait(NULL) > 0);\n28   printf(\"A: %d\\n\", x);\n29   return 0;\n30 }", "options": null}, "sub_questions": [{"id": "10.1", "text": "כמה תהליכים נוצרו סה\"כ במהלך ריצת התוכנית (כולל התהליך הראשי)? הסבירו את תשובתכם בעזרת תיאור עץ התהליכים.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "ציינו את כל שורות הפלט של התוכנית. האם סדר ההדפסה של השורות קבוע? אם כן - מהו? אם לא - אילו אילוצים קיימים על סדר ההדפסה?", "code_snippet": null, "options": null}, {"id": "10.3", "text": "נניח שמוחקים את שורה 27 מהקוד (לולאת ה-wait). האם במצב זה ייתכן שהשורה \"A: 3\" תודפס לפני השורה \"B: 4\"? נמקו.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: נוצרו 4 תהליכים סה\"כ. התהליך הראשי (P0) מתחיל עם x=1. באיטרציה i=0 הוא יוצר את P1. באיטרציה i=1 הוא יוצר את P2. תהליך P2, כיוון שהוא בבן של האיטרציה השנייה (i=1), יוצר את P3 (נכד של P0).\n\n10.2: שורות הפלט הן: \"B: 3\", \"C: 8\", \"B: 4\", \"A: 3\".\nהסבר הערכים:\n- P1 (נוצר ב-i=0): יורש x=1, מבצע x+=2 ומדפיס \"B: 3\".\n- P0 (אחרי i=0): מבצע x+=1, כעת x=2.\n- P2 (נוצר ב-i=1): יורש x=2, מבצע x+=2, כעת x=4. כיוון ש-i=1, יוצר את P3.\n- P3 (נוצר בתוך P2): יורש x=4, מבצע x*=2, מדפיס \"C: 8\".\n- P2 מחכה ל-P3 (שורה 19) ואז מדפיס \"B: 4\".\n- P0 (אחרי i=1): מבצע x+=1, כעת x=3. מחכה לכל בניו (שורה 27) ומדפיס \"A: 3\".\nאילוצי סדר: \"C: 8\" חייב להופיע לפני \"B: 4\" בגלל ה-wait בשורה 19. \"A: 3\" חייב להופיע אחרון בגלל ה-wait בשורה 27. \"B: 3\" יכול להופיע בכל מקום לפני \"A: 3\".\n\n10.3: כן. אם נסיר את שורה 27, התהליך הראשי (P0) לא יחכה לסיום בניו (P1, P2). לאחר סיום הלולאה הוא יגיע מיד לשורה 28. ייתכן מצב שבו P0 יסיים את הריצה וידפיס \"A: 3\" בזמן ש-P2 עדיין ממתין ל-P3 או טרם הגיע לשורת ההדפסה שלו (מרוץ תהליכים)."}, "difficulty_estimation": "Hard", "_source_file": "0065__Processes__CodeAnalysis__Hard.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:28:19", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Processes", "Fork", "System Calls", "Concurrency"], "content": {"text": "נתונה התוכנית הבאה בשפת C. הריצו את התוכנית, והתהליך שנוצר קיבל את מזהה התהליך (PID) שמספרו 100. \nיש להניח שכל קריאות המערכת שיכולות להצליח הצליחו, לא נוצרים תהליכים בקטעי קוד אחרים במערכת, וכל תהליך חדש מקבל מזהה הגדול ב-1 מהתהליך שנוצר לפניו.\nתזכורת: כל הדפסה לפלט הסטנדרטי מתבצעת מיד (ללא buffer).", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    pid_t root = getpid(); \n    if (fork() || fork()) {\n        if (!fork()) {\n            printf(\"A %d %d\\n\", getpid(), getppid());\n            exit(0);\n        }\n    } else {\n        if (fork() && fork()) {\n            printf(\"B %d %d\\n\", getpid(), getppid());\n        }\n    }\n\n    while(wait(NULL) > 0);\n\n    if (getpid() == root) {\n        printf(\"Root Done: %d\\n\", getpid());\n    }\n\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "כמה תהליכים נוצרו בתוכנית בסך הכל (כולל התהליך הראשי)? הציגו את עץ התהליכים שנוצר.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "כתבו את כל שורות הפלט האפשריות של התוכנית (סדר השורות עשוי להשתנות, אך יש לציין את תוכן השורות במדויק).", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. ניתוח יצירת התהליכים:\n- תהליך 100 מבצע fork() ראשון (שורה 8). נוצר תהליך 101. עבור 100 הביטוי fork() הוא אמת (101), לכן בגלל אופרטור ה-|| הוא מדלג על ה-fork השני ונכנס לבלוק ה-if.\n- תהליך 101 קיבל 0 מה-fork הראשון, לכן הוא מבצע את ה-fork() השני בביטוי ה-||. נוצר תהליך 102. עבור 101 הביטוי השני הוא אמת (102), לכן הוא נכנס לבלוק ה-if. תהליך 102 קיבל 0 ב-fork השני, לכן הביטוי (0 || 0) הוא שקר והוא נכנס לבלוק ה-else.\n- בתוך ה-if (תהליכים 100 ו-101): שניהם מבצעים if(!fork()). תהליך 100 יוצר את 103. תהליך 103 מדפיס 'A 103 100' ויוצא. תהליך 101 יוצר את 104. תהליך 104 מדפיס 'A 104 101' ויוצא.\n- בתוך ה-else (תהליך 102): מבצע fork() && fork(). תהליך 102 יוצר את 105. תהליך 105 מקבל 0 ומפסיק את ה-AND. תהליך 102 מקבל 105 וממשיך ל-fork() השני, בו הוא יוצר את 106. תהליך 102 מקבל 106 (אמת) ומדפיס 'B 102 101'. תהליך 106 מקבל 0 ולא מדפיס.\n- סה\"כ נוצרו 7 תהליכים (100, 101, 102, 103, 104, 105, 106).\n\n2. פלט התוכנית:\nהשורות הבאות יודפסו (הסדר בין השלוש הראשונות עשוי להשתנות, האחרונה תמיד בסוף):\nA 103 100\nA 104 101\nB 102 101\nRoot Done: 100"}, "difficulty_estimation": "Hard", "_source_file": "0066__Processes__CodeAnalysis__Hard.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:28:46", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Processes", "System Calls", "Memory Management", "Concurrency"], "content": {"text": "נתונה התוכנית הבאה בשפת C. הניחו שכל קריאות המערכת מצליחות, שתהליכים אינם נוצרים מחוץ לקוד המוצג, ושתזמון התהליכים (Scheduling) אינו ידוע מראש. הנחה נוספת: הפונקציה fflush(stdout) מבטיחה שהפלט נשלח למסך באופן מיידי.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    int x = 10;\n    for (int i = 0; i < 2; i++) {\n        pid_t pid = fork();\n        if (pid == 0) {\n            x += 5;\n            if (i == 0) {\n                if (fork() == 0) {\n                    x += 10;\n                }\n                x *= 2;\n            }\n            printf(\"%d:%d \", i, x);\n            fflush(stdout);\n            exit(0);\n        } else {\n            x -= 2;\n            waitpid(pid, NULL, 0);\n        }\n    }\n    printf(\"Done:%d\\n\", x);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "כמה תהליכים נוצרו במהלך ריצת התוכנית (כולל התהליך המקורי)? ציירו את עץ התהליכים.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "האם ייתכן שהפלט \"0:50\" יופיע לאחר הפלט \"1:13\"? נמקו את תשובתכם על סמך מנגנון ה-wait בתוכנית.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "מהו הפלט המלא (או הפלטים האפשריים) של התוכנית? יש לפרט את החישוב עבור כל תהליך.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. נוצרו 4 תהליכים בסך הכל: התהליך הראשי (P1), הבן שלו מהאיטרציה הראשונה (P2), הנכד (P3 - הבן של P2), והבן של הראשי מהאיטרציה השנייה (P4).\n\n2. כן, ייתכן שהפלט '0:50' יופיע אחרי '1:13'. הסיבה היא שהתהליך הראשי (P1) מבצע waitpid(pid) רק עבור הבנים הישירים שלו (P2 ו-P4). P1 מחכה ש-P2 יסתיים לפני שהוא ממשיך לאיטרציה הבאה (i=1), אבל P2 עצמו לא מחכה לבן שלו (P3). לכן, ברגע ש-P2 מסיים ומדפיס, P1 יכול להמשיך, ליצור את P4 ולהדפיס '1:13', בזמן ש-P3 עדיין רץ או ממתין לתורו להדפיס.\n\n3. פירוט החישובים:\n- P1 (הראשי): מתחיל עם x=10. ב-i=0 מבצע x-=2 (x=8) ומחכה ל-P2. ב-i=1 מבצע x-=2 (x=6) ומחכה ל-P4. בסוף מדפיס 'Done:6'.\n- P2 (בן של P1, i=0): יורש x=10. מבצע x+=5 (x=15). יוצר את P3. מבצע x*=2 (x=30). מדפיס '0:30' ויוצא.\n- P3 (בן של P2): יורש x=15. מבצע x+=10 (x=25). מבצע x*=2 (x=50). מדפיס '0:50' ויוצא.\n- P4 (בן של P1, i=1): יורש x=8. מבצע x+=5 (x=13). מדפיס '1:13' ויוצא.\n\nסדר ההדפסות: '0:30' חייב להופיע לפני '1:13' (כי P1 מחכה ל-P2). '0:50' יכול להופיע בכל מקום לפני 'Done:6'. 'Done:6' תמיד אחרון.\nפלטים אפשריים לדוגמה: \n- 0:30 0:50 1:13 Done:6\n- 0:50 0:30 1:13 Done:6\n- 0:30 1:13 0:50 Done:6"}, "difficulty_estimation": "Hard", "_source_file": "0067__Processes__CodeAnalysis__Hard.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:29:22", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Processes", "System Calls", "Fork", "Exec", "Concurrency"], "content": {"text": "נתונה התוכנית הבאה בשפת C. הניחו שכל קריאות המערכת מצליחות, שקריאת ה-exec מוצאת את הפקודה echo, ושכל הדפסה מתבצעת באופן מיידי ללא חוצץ (buffer). כמו כן, הניחו כי המערכת אינה יוצרת תהליכים נוספים פרט לאלו המצוינים בקוד.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    printf(\"A\");\n    fflush(stdout);\n    if (fork() && fork()) {\n        fork();\n    } else {\n        if (fork() == 0) {\n            execlp(\"echo\", \"echo\", \"B\", NULL);\n            printf(\"D\");\n            fflush(stdout);\n        }\n    }\n    printf(\"C\");\n    fflush(stdout);\n    while(wait(NULL) > 0);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "כמה תהליכים נוצרו סה\"כ במהלך ריצת התוכנית (כולל התהליך הראשי)? הסבירו בעזרת פירוט שלבי הריצה או עץ תהליכים.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "האם הפלט \"ACCCBCB\" הוא פלט אפשרי עבור ריצה של תוכנית זו? נמקו.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "האם התו 'D' יודפס אי פעם? הסבירו מדוע.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. ניתוח תהליכים: \n- P0 (הראשי) מדפיס A.\n- P0 מבצע fork() ראשון ויוצר את P1. עבור P0 התוצאה אמת, לכן הוא ממשיך ל-fork() השני ויוצר את P2. התנאי (fork && fork) אמת עבור P0 ולכן הוא נכנס לבלוק ה-if ומבצע fork() שלישי ליצירת P3. גם P0 וגם P3 מדפיסים C.\n- P1 (נוצר ב-fork הראשון): עבורו ה-fork הראשון מחזיר 0. בשל אופרטור ה-&& מתבצע short-circuit ו-P1 עובר לבלוק ה-else. שם הוא מבצע fork() ויוצר את P4. P4 מבצע exec ומדפיס B. P1 ממשיך ומדפיס C.\n- P2 (נוצר ב-fork השני): עבורו ה-fork השני מחזיר 0. התנאי (אמת && 0) הוא שקר, לכן P2 עובר לבלוק ה-else. שם הוא מבצע fork() ויוצר את P5. P5 מבצע exec ומדפיס B. P2 ממשיך ומדפיס C.\nסה\"כ תהליכים: P0, P1, P2, P3, P4, P5 - סה\"כ 6 תהליכים.\n\n2. ניתוח פלט: \n- 'A' מודפס פעם אחת (P0).\n- 'C' מודפס 4 פעמים על ידי התהליכים P0, P3, P1, P2.\n- 'B' מודפס פעמיים על ידי התהליכים P4, P5 (באמצעות echo).\nהפלט \"ACCCBCB\" מכיל פעם אחת A, ארבע פעמים C ופעמיים B. כיוון שאין סדר מחייב בין התהליכים השונים (פרט לכך ש-A מודפס ראשון), פלט זה אפשרי.\n\n3. הדפסת 'D':\n- התו 'D' לא יודפס לעולם. התהליכים P4 ו-P5, שהם היחידים שמגיעים לשורה זו, מבצעים קריאת execlp לפני ההדפסה. קריאת exec מחליפה את מרחב הכתובות והקוד של התהליך בקוד של התוכנית echo, ולכן הפקודה printf(\"D\") שמופיעה אחרי ה-exec לא תתבצע לעולם (אלא אם ה-exec נכשל, אך הנחנו שהצליח)."}, "difficulty_estimation": "Hard", "_source_file": "0068__Processes__CodeAnalysis__Hard.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:30:04", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Processes", "System Calls", "fork", "exec", "Wait"], "content": {"text": "נתונה התוכנית הבאה בשפת C. הניחו כי המזהה (PID) של התהליך המריץ את הפונקציה main הוא 100. כל קריאת מערכת שמצליחה מחזירה ערך תקין (לפי התיעוד), ותהליכים חדשים מקבלים מזהה הגדול ב-1 מהמזהה האחרון שהוקצה במערכת. הניחו כי לא נוצרים תהליכים אחרים במערכת בזמן הריצה, וכי הפונקציה printf מדפיסה ישירות למסך ללא שימוש ב-buffer (כאילו בוצע fflush).", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    pid_t pid;\n    printf(\"P%d\\n\", getpid());\n    if (fork() == 0) {\n        if (fork() || fork()) {\n            printf(\"T%d\\n\", getpid());\n        }\n        exit(0);\n    }\n    pid = fork();\n    if (pid == 0) {\n        execlp(\"ls\", \"ls\", NULL);\n        printf(\"E%d\\n\", getpid());\n        exit(1);\n    }\n    waitpid(pid, NULL, 0);\n    printf(\"D%d\\n\", getpid());\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "כמה תהליכים נוצרו בסך הכל במהלך ריצת התוכנית (כולל התהליך הראשי)? פרטו את ה-PID של כל אחד מהם ואת הקשר ביניהם (מי האבא של מי).", "code_snippet": null, "options": null}, {"id": "10.2", "text": "האם ייתכן מצב בו המחרוזת 'D100' תודפס לפני המחרוזת 'T101'? נמקו את תשובתכם.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "נניח כי הקריאה ל-execlp נכשלה (למשל, הקובץ ls לא נמצא). מה יהיו כל ההדפסות של התוכנית במקרה זה? (אין צורך לציין את סדר ההדפסות, אלא רק אילו מחרוזות יופיעו).", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. נוצרו 5 תהליכים בסך הכל:\n- תהליך 100: התהליך הראשי.\n- תהליך 101: נוצר על ידי 100 בשורה 9.\n- תהליך 102: נוצר על ידי 101 בשורה 10 (ב-fork הראשון).\n- תהליך 103: נוצר על ידי 102 בשורה 10 (ב-fork השני, מכיוון שה-fork הראשון החזיר 0 ל-102).\n- תהליך 104: נוצר על ידי 100 בשורה 15.\n\n2. כן, ייתכן. תהליך 100 מבצע waitpid עבור תהליך 104 בלבד. הוא אינו ממתין לסיום של תהליך 101 או צאצאיו (102, 103). לכן, אם תהליך 104 יסיים את פעולתו (ה-ls יסתיים) ותהליך 100 ימשיך להדפסה בשורה 22 לפני שתהליך 101 יספיק להגיע להדפסה בשורה 11, 'D100' יודפס לפני 'T101'.\n\n3. אם execlp נכשל, התהליך (104) לא מוחלף וממשיך לשורה הבאה בקוד. ההדפסות שיופיעו הן:\n- P100 (מהתהליך הראשי בתחילת הריצה).\n- T101 (מתהליך 101, שעובר את תנאי ה-OR בגלל short-circuit).\n- T102 (מתהליך 102, שמבצע את ה-fork השני בתנאי ה-OR).\n- E104 (מתהליך 104, המדפיס הודעת שגיאה לאחר כישלון ה-exec).\n- D100 (מתהליך 100, לאחר שסיים להמתין ל-104)."}, "difficulty_estimation": "Hard", "_source_file": "0069__Processes__CodeAnalysis__Hard.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:30:46", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Processes", "System Calls", "Fork Logic", "Process Tree"], "content": {"text": "נתונה התוכנית הבאה בשפת C. הניחו כי כל קריאות המערכת מצליחות, וכי מזהה התהליך (PID) של התהליך המריץ את main הוא 1000. כל תהליך חדש שנוצר במערכת מקבל PID הגדול ב-1 מה-PID האחרון שניתן. הניחו כי אין תהליכים אחרים שנוצרים במערכת בזמן הריצה. ענו על הסעיפים הבאים.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    int x = 5;\n    pid_t p1, p2;\n\n    p1 = fork();\n    if (p1 > 0) {\n        // Parent block\n        x += 2;\n        if (fork() == 0) {\n            x *= 2;\n            printf(\"Node A: x=%d, PID=%d, PPID=%d\\n\", x, getpid(), getppid());\n            exit(0);\n        }\n        wait(NULL);\n    } else if (p1 == 0) {\n        // Child block\n        x -= 2;\n        p2 = fork();\n        if (p2 > 0) {\n            wait(NULL);\n            x += 10;\n        } else {\n            x += 5;\n            printf(\"Node B: x=%d, PID=%d, PPID=%d\\n\", x, getpid(), getppid());\n            exit(0);\n        }\n        printf(\"Node C: x=%d, PID=%d, PPID=%d\\n\", x, getpid(), getppid());\n        exit(0);\n    }\n\n    wait(NULL);\n    printf(\"Node D: x=%d, PID=%d\\n\", x, getpid());\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "101.1", "text": "ציירו את עץ התהליכים שנוצר במהלך ריצת התוכנית. עבור כל תהליך בעץ ציינו את ה-PID שלו ואת ה-PPID שלו.", "code_snippet": null, "options": null}, {"id": "101.2", "text": "מהו הפלט המלא של התוכנית? במידה וישנם מספר פלטים אפשריים בשל חוסר דטרמיניזם בתזמון, ציינו את כולם או הסבירו את סדר ההדפסה.", "code_snippet": null, "options": null}, {"id": "101.3", "text": "כמה פעמים תודפס המילה \"Node\" בסך הכל?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ניתוח זרימת התוכנית:\n1. תהליך 1000 (P1000) מבצע fork ראשון. נוצר תהליך 1001.\n2. P1000 (הורה): x הופך ל-7. הוא מבצע fork נוסף ויוצר את 1002. \n   - תהליך 1002 (בן של 1000): x הופך ל-14 (7*2). מדפיס 'Node A: x=14, PID=1002, PPID=1000' ויוצא.\n   - P1000 מחכה ל-1002, ואז מחכה ל-1001 (בסוף), ומדפיס 'Node D: x=7, PID=1000'.\n3. תהליך 1001 (בן של 1000): x הופך ל-3. הוא מבצע fork ויוצר את 1003.\n   - תהליך 1003 (בן של 1001): x הופך ל-8 (3+5). מדפיס 'Node B: x=8, PID=1003, PPID=1001' ויוצא.\n   - תהליך 1001 מחכה ל-1003, מעדכן את x ל-13 (3+10), מדפיס 'Node C: x=13, PID=1001, PPID=1000' ויוצא.\n\nסדר הדפסה אפשרי:\nהסדר בין Node A לבין Node B/C תלוי במתזמן, אך Node D תמיד יהיה אחרון עבור P1000. Node C חייב לבוא אחרי Node B. Node A חייב לבוא לפני Node D.\nפלט לדוגמה:\nNode B: x=8, PID=1003, PPID=1001\nNode C: x=13, PID=1001, PPID=1000\nNode A: x=14, PID=1002, PPID=1000\nNode D: x=7, PID=1000\n\nסה\"כ הדפסות של Node: 4 פעמים."}, "difficulty_estimation": "Hard", "_source_file": "0070__Processes__CodeAnalysis__Hard.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:31:06", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Processes", "System Calls", "Buffering", "Fork"], "content": {"text": "נתונה התוכנית הבאה בשפת C. הניחו שכל קריאות המערכת מצליחות, ושכל תהליך שנוצר מסיים את ריצתו כראוי.\nתזכורת: פונקציית printf משתמשת בחוצץ (buffer) עבור הפלט הסטנדרטי. במידה ואין תו ירידת שורה (\\n), החוצץ מועבר בשלמותו לתהליכי בנים בעת ביצוע fork ומתרוקן רק בסיום התהליך או בעת קריאה ל-fflush.", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <stdlib.h>\n\nint main() {\n    printf(\"Start\");\n    if (fork() || fork()) {\n        if (!fork()) {\n            printf(\"1\");\n            exit(0);\n        }\n    } else {\n        printf(\"2\");\n    }\n    while(wait(NULL) > 0);\n    printf(\"End\");\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "כמה תהליכים סה\"כ נוצרו במהלך ריצת התוכנית (כולל התהליך הראשי)?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "רשמו פלט אפשרי אחד של התוכנית והסבירו כיצד מנגנון ה-buffering משפיע על הופעת המילה \"Start\" בפלט.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "כיצד ישתנה מספר הפעמים שהמילה \"Start\" מופיעה בפלט אם נוסיף n\\ לאחר המילה \"Start\" בשורה 7?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: נוצרו 5 תהליכים סה\"כ. תהליך האב P0 יוצר את P1 ב-fork הראשון. P0 נכנס ל-if (בגלל short-circuit). P1 ממשיך ל-fork השני ויוצר את P2. P1 נכנס ל-if ו-P2 נכנס ל-else. בתוך ה-if, תהליך P0 יוצר את P3 ותהליך P1 יוצר את P4.\n\n1.2: פלט אפשרי: Start1Start1Start2EndStartEndStartEnd (הסדר בין התהליכים יכול להשתנות). הסבר: המילה Start נכנסת ל-buffer של P0. כיוון שאין n\\, היא לא מודפסת מיד. כל תהליך שנוצר ב-fork יורש את תוכן ה-buffer. לכן, כל אחד מ-5 התהליכים מחזיק ב-Start ב-buffer שלו ומדפיס אותו בסיום או בתוספת לפלט אחר. P3 ו-P4 מדפיסים Start1, תהליך P2 מדפיס Start2End, ותהליכים P0 ו-P1 מדפיסים StartEnd.\n\n1.3: אם נוסיף n\\, ה-buffer יתרוקן מיד בשורה 7. לכן המילה Start תודפס פעם אחת בלבד על ידי P0 לפני ה-fork הראשון, והבנים יירשו buffer ריק. המילה Start תופיע פעם אחת בלבד בכל הפלט."}, "difficulty_estimation": "Hard", "_source_file": "0071__Processes__CodeAnalysis__Hard.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:31:33", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Processes", "System Calls", "fork", "Short-circuit Evaluation"], "content": {"text": "נתונה התוכנית הבאה בשפת C. הניחו שכל קריאות המערכת מצליחות, אין תהליכים נוספים במערכת שמשפיעים על הריצה, וכל הדפסה מתבצעת באופן מיידי ללא חוצץ (buffer).", "code_snippet": "#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint main() {\n    int x = 0;\n    if (fork() || fork()) {\n        x++;\n        if (!fork()) {\n            x += 2;\n        }\n    } else {\n        x--;\n    }\n    while(wait(NULL) > 0);\n    printf(\"%d \", x);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "כמה תהליכים נוצרו בסך הכל במהלך ריצת התוכנית (כולל התהליך הראשי)? הציגו את עץ התהליכים.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "מהם כל הערכים האפשריים שיוצגו כפלט של התוכנית? הסבירו אילו תהליכים מדפיסים אילו ערכים.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "נניח ונחליף את האופרטור || בשורה 6 באופרטור &&. כמה תהליכים ייווצרו כעת במערכת (כולל התהליך הראשי)?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. סך הכל נוצרו 5 תהליכים:\n- תהליך אב (P1) מבצע fork ראשון. הוא מקבל ערך חיובי ולכן בגלל short-circuit של || הוא לא מבצע את ה-fork השני ונכנס לבלוק ה-if.\n- הבן הראשון (P2) מקבל 0 מה-fork הראשון, ולכן חייב לבצע את ה-fork השני. הוא יוצר את P3.\n- P2 מקבל ערך חיובי מה-fork השני ונכנס לבלוק ה-if.\n- P3 מקבל 0 מה-fork השני ונכנס לבלוק ה-else.\n- בתוך בלוק ה-if, תהליכים P1 ו-P2 מבצעים fork נוסף (P4 ו-P5 בהתאמה). סך הכל 5 תהליכים.\n\n2. הערכים המודפסים הם 1, 1, 3, 3, 1-:\n- P1 ו-P2: מקדמים את x ל-1. ב-fork הפנימי האבא (P1/P2) מקבל PID ולכן ה-if הפנימי לא מתקיים עבורו. הם מדפיסים 1.\n- P4 ו-P5 (הבנים של ה-fork הפנימי): יורשים x=1, נכנסים ל-if הפנימי ומבצעים x += 2. הם מדפיסים 3.\n- P3: נכנס ל-else ומבצע x--. הוא מדפיס 1-.\n\n3. אם נחליף ל-&&, ייווצרו 4 תהליכים:\n- P1 מבצע fork ראשון (P2). P1 ממשיך ל-fork שני (P3). P2 נכשל בתנאי (קיבל 0) ועובר ל-else.\n- P1 מצליח בשני ה-forks ונכנס ל-if. P3 נכשל בתנאי (קיבל 0 ב-fork השני) ועובר ל-else.\n- בתוך ה-if, רק P1 מבצע fork נוסף (P4).\n- סך הכל: P1, P2, P3, P4."}, "difficulty_estimation": "Hard", "_source_file": "0072__Processes__CodeAnalysis__Hard.json", "_topic_hint": "Processes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:31:51", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Threads", "Memory Management"], "content": {"text": "איזה מהמשאבים הבאים משותף (shared) לכל החוטים (threads) השייכים לאותו תהליך?", "code_snippet": null, "options": ["א. המחסנית (Stack)", "ב. משתנים גלובליים ומרחב הכתובות (Global Variables / Address Space)", "ג. אוגרי המעבד (CPU Registers)", "ד. מונה התוכנית (Program Counter)"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "חוטים בתוך אותו תהליך חולקים את אותו מרחב כתובות, הכולל את קטע הנתונים (משתנים גלובליים) והערימה (Heap). לעומת זאת, לכל חוט יש מחסנית (Stack), אוגרים ומונה תוכנית (PC) משלו, המהווים את ההקשר (Context) הייחודי שלו."}, "difficulty_estimation": "Easy", "_source_file": "0073__Threads__MultipleChoice__Easy.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:31:58", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Threads", "Memory Management"], "content": {"text": "איזה מבין המשאבים הבאים משותף לכל החוטים (threads) השייכים לאותו תהליך?", "code_snippet": null, "options": ["א. מחסנית (Stack)", "ב. מונה התוכנית (Program Counter)", "ג. משתנים גלובליים ומרחב הכתובות", "ד. קובץ האוגרים (Register set)"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "חוטים באותו תהליך חולקים את מרחב הכתובות של התהליך, הכולל את קטע הקוד (Code segment) ואת קטע הנתונים (Data segment) שבו נמצאים המשתנים הגלובליים. לעומת זאת, לכל חוט יש הקשר הרצה (execution context) ייחודי הכולל מחסנית משלו, מונה תוכנית משלו וסט אוגרים משלו."}, "difficulty_estimation": "Easy", "_source_file": "0074__Threads__MultipleChoice__Easy.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:32:09", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Threads", "Memory Management"], "content": {"text": "איזה מהמשאבים הבאים משותף (Shared) לכל החוטים (threads) השייכים לאותו תהליך?", "code_snippet": null, "options": ["א. המחסנית (Stack)", "ב. אוגרי המעבד (Registers)", "ג. מונה הפקודות (Program Counter)", "ד. מרחב הכתובות הגלובלי והערימה (Heap)", "ה. אף אחת מהתשובות אינה נכונה"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "חוטים (threads) בתוך אותו תהליך חולקים את מרחב הכתובות של התהליך, הכולל את קטע הקוד, המשתנים הגלובליים והערימה (Heap). לעומת זאת, לכל חוט יש משאבים פרטיים משלו ההכרחיים לניהול זרימת הריצה העצמאית שלו: מחסנית (Stack) עבור משתנים לוקאליים וקריאות לפונקציות, אוגרים (Registers) ומונה פקודות (PC)."}, "difficulty_estimation": "Easy", "_source_file": "0075__Threads__MultipleChoice__Easy.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:32:18", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Threads", "Memory Management"], "content": {"text": "איזה מהמשאבים הבאים משותף (Shared) בדרך כלל בין חוטים (threads) שונים השייכים לאותו תהליך?", "code_snippet": null, "options": ["א. מחסנית (Stack)", "ב. אוגרי המעבד (Registers)", "ג. מרחב הכתובות (Address Space) ומשתנים גלובליים", "ד. מונה הפקודות (Program Counter)", "ה. אף אחת מהתשובות אינה נכונה"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "חוטים השייכים לאותו תהליך חולקים את מרחב הכתובות של התהליך, הכולל את קטע הקוד (Code), המשתנים הגלובליים (Data) והערימה (Heap). לעומת זאת, לכל חוט יש הקשר ריצה (Execution Context) נפרד הכולל מחסנית משלו, אוגרים משלו ומונה פקודות (PC) משלו כדי לאפשר הרצה עצמאית."}, "difficulty_estimation": "Easy", "_source_file": "0076__Threads__MultipleChoice__Easy.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:32:26", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Threads", "Memory Management"], "content": {"text": "מה מהבאים משותף לכל החוטים (threads) השייכים לאותו תהליך?", "code_snippet": null, "options": ["א. המחסנית (Stack)", "ב. אוגרי המעבד (Registers)", "ג. מונה הפקודות (Program Counter)", "ד. מרחב הכתובות ומשתנים גלובליים", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "חוטים באותו תהליך חולקים את מרחב הכתובות, קוד, נתונים (משתנים גלובליים) ומשאבי מערכת כמו קבצים פתוחים. לעומת זאת, לכל חוט יש הקשר ריצה פרטי הכולל מחסנית, אוגרים ומונה פקודות (PC) משלו."}, "difficulty_estimation": "Easy", "_source_file": "0077__Threads__MultipleChoice__Easy.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:32:34", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Threads", "Memory Management"], "content": {"text": "בהינתן קוד C המשתמש בספריית pthreads, איזה מהמשתנים הבאים משותף (shared) ונגיש גם לחוט החישוב הראשי (main thread) וגם לחוט החדש שנוצר?", "code_snippet": "int x = 10;\n\nvoid* my_func(void* arg) {\n    int y = 20;\n    x++;\n    return NULL;\n}\n\nint main() {\n    pthread_t tid;\n    pthread_create(&tid, NULL, my_func, NULL);\n    // ... code ...\n    return 0;\n}", "options": ["א. המשתנה x בלבד", "ב. המשתנה y בלבד", "ג. גם x וגם y", "ד. אף אחד מהמשתנים אינו משותף"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "המשתנה x הוא משתנה גלובלי, ולכן הוא נמצא במקטע הנתונים (Data Segment) המשותף לכל החוטים (threads) באותו תהליך. לעומת זאת, המשתנה y הוא משתנה מקומי המוגדר בתוך פונקציית החוט, ולכן הוא מוקצה על המחסנית (Stack) הפרטית של החוט ואינו משותף לחוטים אחרים."}, "difficulty_estimation": "Easy", "_source_file": "0078__Threads__MultipleChoice__Easy.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:32:47", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Threads", "Memory Management"], "content": {"text": "כאשר מספר חוטים (threads) רצים בתוך אותו תהליך (process), מה מהבאים משותף לכל החוטים?", "code_snippet": null, "options": ["א. המחסנית (Stack) הפרטית של כל חוט.", "ב. ערימת הזיכרון (Heap) והמשתנים הגלובליים.", "ג. אוגרי המעבד (Registers).", "ד. מונה התוכנית (Program Counter)."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "בתוך תהליך, כל החוטים חולקים את אותו מרחב כתובות, הכולל את ה-Heap והמשתנים הגלובליים. לעומת זאת, לכל חוט יש Stack, Registers ו-Program Counter משלו כדי לאפשר הרצה עצמאית של קוד."}, "difficulty_estimation": "Easy", "_source_file": "0079__Threads__MultipleChoice__Easy.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:32:53", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Threads", "Memory Management"], "content": {"text": "איזה מהמשאבים הבאים **אינו** משותף בין חוטי חישוב (threads) השייכים לאותו תהליך?", "code_snippet": null, "options": ["א. משתנים גלובליים (Global variables)", "ב. זיכרון הערימה (Heap memory)", "ג. קוד התוכנית (Code segment)", "ד. המחסנית (Stack)", "ה. כל התשובות האחרות משותפות בין חוטי החישוב"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "לכל חוט חישוב (thread) יש מחסנית (Stack) פרטית משלו וסט רגיסטרים משלו (כולל Program Counter), זאת על מנת לאפשר לכל חוט לנהל את זרימת הפונקציות והמשתנים המקומיים שלו באופן עצמאי. לעומת זאת, חוטי חישוב באותו תהליך חולקים את מרחב הכתובות הכולל את קטע הקוד, הנתונים הגלובליים והערימה."}, "difficulty_estimation": "Easy", "_source_file": "0080__Threads__MultipleChoice__Easy.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:33:00", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Threads", "Concurrency", "Race Conditions"], "content": {"text": "נתונה התוכנית הבאה בשפת C המשתמשת בספריית pthreads. התוכנית יוצרת 10 חוטים (threads), כאשר כל חוט מבצע לולאה המקדמת משתנה גלובלי משותף counter ב-1, כמיליון פעמים. בסיום ריצת כל החוטים, התוכנית מדפיסה את ערכו של counter. מה ניתן לומר על פלט התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint counter = 0;\n\nvoid* thread_func(void* arg) {\n    for (int i = 0; i < 1000000; i++) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[10];\n    for (int i = 0; i < 10; i++) {\n        pthread_create(&threads[i], NULL, thread_func, NULL);\n    }\n    for (int i = 0; i < 10; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    printf(\"%d\\n\", counter);\n    return 0;\n}", "options": ["א. התוכנית תמיד תדפיס 10,000,000.", "ב. התוכנית תדפיס ערך קטן מ-10,000,000 או שווה לו, בשל היעדר סנכרון (Race Condition).", "ג. התוכנית תגרום לשגיאת הרצה (Segmentation Fault) כיוון שחוטים שונים ניגשים לאותו זיכרון בו-זמנית.", "ד. התוכנית תמיד תדפיס 1,000,000 כי המשתנה counter הוא מקומי לכל חוט (Thread Local Storage).", "ה. התוכנית לא תתקמפל כי לא ניתן להשתמש במשתנה גלובלי משותף בתוך פונקציית חוט ללא מילת המפתח volatile."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הפעולה ++counter ברמת שפת C אינה פעולה אטומית (Atomic Operation). ברמת האסמבלי, היא מורכבת בדרך כלל משלוש פקודות: קריאת הערך מהזיכרון לרגיסטר, הוספת 1 לרגיסטר, וכתיבת הערך חזרה לזיכרון. ללא שימוש במנגנוני סנכרון כמו Mutex, ייתכן מצב שבו שני חוטים קוראים את אותו הערך לפני שאחד מהם הספיק לעדכן אותו (Context Switch ביניהם), מה שמוביל לאובדן עדכונים ולערך סופי נמוך מהצפוי (Race Condition). תיאורטית הערך יכול להיות 10,000,000 אם לא התרחש שום מירוץ, אך במערכת מרובת ליבות זה כמעט בלתי אפשרי."}, "difficulty_estimation": "Medium", "_source_file": "0081__Threads__MultipleChoice__Medium.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:33:15", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Threads", "Concurrency", "Memory Layout"], "content": {"text": "נתון הקוד הבא בשפת C, המריץ שני חוטים (threads) המבצעים את אותה הפונקציה. בהנחה שהמערכת מריצה את החוטים במקביל על מעבד מרובה ליבות וללא סנכרון חיצוני, איזו מהטענות הבאות היא הנכונה ביותר לגבי תוצאת ההרצה?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint shared_var = 0;\n\nvoid* increment_task(void* arg) {\n    static int func_static = 0;\n    for (int i = 0; i < 100; i++) {\n        shared_var++;\n        func_static++;\n    }\n    return (void*)(long)func_static;\n}\n\nint main() {\n    pthread_t t1, t2;\n    void *res1, *res2;\n    pthread_create(&t1, NULL, increment_task, NULL);\n    pthread_create(&t2, NULL, increment_task, NULL);\n    pthread_join(t1, &res1);\n    pthread_join(t2, &res2);\n    printf(\"%d, %ld, %ld\\n\", shared_var, (long)res1, (long)res2);\n    return 0;\n}", "options": ["א. הערך של shared_var יהיה בדיוק 200, וערכי ההחזר res1 ו-res2 יהיו 100 ו-200 (בסדר כלשהו).", "ב. הערך של shared_var עשוי להיות קטן מ-200 עקב Race Condition, אך המשתנה func_static הוא מקומי לכל חוט ולכן ערכי ההחזר יהיו תמיד 100.", "ג. המשתנה func_static משותף לשני החוטים, ולכן גם shared_var וגם ערכי ההחזר res1 ו-res2 עשויים להיות מושפעים מ-Race Condition.", "ד. הקוד יגרום לשגיאת הרצה (Runtime Error) כיוון ששני חוטים מנסים לגשת למשתנה static בו-זמנית.", "ה. המשתנה func_static מאותחל מחדש ל-0 בכל פעם שחוט חדש מתחיל את הפונקציה, לכן התוצאה הסופית של shared_var תהיה 200."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "במשתני static המוגדרים בתוך פונקציה, בדומה למשתנים גלובליים, קיים רק עותק אחד בזיכרון המשותף לכל החוטים באותו תהליך (הם מאוחסנים ב-Data Segment). מכיוון ששני החוטים מקדמים את shared_var ואת func_static ללא מנגנון סנכרון (כמו Mutex), שניהם חשופים לבעיית מרוץ (Race Condition). לכן, לא ניתן להבטיח ש-shared_var יגיע ל-200, וערכי ההחזר (שמייצגים את מצב func_static ברגע סיום החוט) אינם מובטחים להיות 100 או 200."}, "difficulty_estimation": "Medium", "_source_file": "0082__Threads__MultipleChoice__Medium.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:33:32", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Threads", "Concurrency", "Race Conditions"], "content": {"text": "בקטע הקוד הבא ב-C, מתכנת מנסה ליצור 5 חוטים (threads) שכל אחד מהם ידפיס את המספר הסידורי שבו הוא נוצר (0 עד 4). מה ניתן לומר על פלט התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nvoid* thread_func(void* arg) {\n    int id = *(int*)arg;\n    printf(\"%d \", id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[5];\n    for (int i = 0; i < 5; i++) {\n        pthread_create(&threads[i], NULL, thread_func, &i);\n    }\n    for (int i = 0; i < 5; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    return 0;\n}", "options": ["א. התוכנית תמיד תדפיס את המספרים 0, 1, 2, 3, 4 לפי הסדר.", "ב. התוכנית תדפיס את המספרים 0, 1, 2, 3, 4 בסדר כלשהו (פרמוטציה), וכל מספר יופיע בדיוק פעם אחת.", "ג. ייתכן שחלק מהערכים יודפסו מספר פעמים וערכים אחרים לא יודפסו כלל, שכן כל החוטים ניגשים לאותה כתובת זיכרון של המשתנה i.", "ד. התוכנית תמיד תדפיס '5 5 5 5 5' כיוון שהלולאה ב-main מסתיימת תמיד לפני שהחוטים מתחילים לרוץ.", "ה. תתרחש שגיאת הידור (Compilation Error) כי לא ניתן להעביר מצביע למשתנה מקומי i לפונקציית החוט."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הבעיה בקוד היא העברת הכתובת של המשתנה הלוקאלי i (באמצעות i&) לכל החוטים. כל החוטים מקבלים מצביע לאותו מיקום בזיכרון. כיוון שה-main thread ממשיך לקדם את i בלולאה בזמן שהחוטים נוצרים ומתחילים את ריצתם, נוצר Race Condition: עד שחוט מסוים ניגש לזיכרון כדי לקרוא את הערך של id, הערך של i כבר עשוי להשתנות על ידי ה-main thread. לכן, ייתכן שחוטים שונים יקראו את אותו הערך (למשל, כולם יקראו 5 אם הלולאה הסתיימה מהר), וערכים מסוימים לא יודפסו כלל."}, "difficulty_estimation": "Medium", "_source_file": "0083__Threads__MultipleChoice__Medium.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:33:47", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Threads", "Concurrency", "Memory Management"], "content": {"text": "נתונה תוכנית C המשתמשת בספריית pthreads ליצירת 5 חוטים (threads). המטרה היא שכל חוט ידפיס את המספר הסידורי שלו (0 עד 4). מה מהבאים מתאר נכונה את התנהגות התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nvoid* thread_func(void* arg) {\n    int val = *((int*)arg);\n    printf(\"%d \", val);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[5];\n    for (int i = 0; i < 5; i++) {\n        pthread_create(&threads[i], NULL, thread_func, &i);\n    }\n    for (int i = 0; i < 5; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    return 0;\n}", "options": ["א. התוכנית תמיד תדפיס את המספרים 0 עד 4 בסדר עולה (0 1 2 3 4).", "ב. התוכנית תמיד תדפיס את המספרים 0 עד 4, אך הסדר עשוי להשתנות בהתאם לתזמון.", "ג. התוכנית עלולה להדפיס מספרים שאינם בטווח 0-5 עקב גישה לזיכרון שאינו מאותחל.", "ד. התוכנית עלולה להדפיס את אותו מספר מספר פעמים (למשל 5 5 5 5 5), כיוון שכל החוטים ניגשים לאותה כתובת זיכרון שערכה משתנה בחוט הראשי.", "ה. התוכנית לא תתקמפל כי לא ניתן להעביר מצביע למשתנה מקומי (i) כארגומנט לחוט."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "הבעיה בתוכנית היא Race Condition על המשתנה i. הפונקציה pthread_create מקבלת מצביע לכתובת הזיכרון של i. כיוון שהחוט הראשי ממשיך לרוץ ולעדכן את i בלולאה, וכל החוטים שנוצרו ניגשים לאותה כתובת זיכרון, ייתכן שעד שחוט מסוים יתחיל לרוץ ויבצע את ה-dereference למצביע, הערך של i כבר השתנה ע\"י החוט הראשי (למשל ל-5 בסיום הלולאה). לכן, ייתכן שיוצגו ערכים כפולים או ערכים שאינם תואמים את הציפייה המקורית."}, "difficulty_estimation": "Medium", "_source_file": "0084__Threads__MultipleChoice__Medium.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:34:04", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Threads", "Concurrency", "Memory Management"], "content": {"text": "נתון קוד ה-C הבא המשתמש בספריית pthreads. מה מהבאים מתאר נכונה את הפלט הצפוי של התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nvoid* thread_func(void* arg) {\n    int* id = (int*)arg;\n    printf(\"%d \", *id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[5];\n    for (int i = 0; i < 5; i++) {\n        pthread_create(&threads[i], NULL, thread_func, &i);\n    }\n    for (int i = 0; i < 5; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    return 0;\n}", "options": ["א. התוכנית תמיד תדפיס את המספרים 0 עד 4 בסדר עולה (0 1 2 3 4).", "ב. התוכנית תמיד תדפיס את המספרים 0 עד 4 בסדר כלשהו.", "ג. התוכנית תמיד תדפיס את המספר 5 חמש פעמים.", "ד. התוכנית עלולה להדפיס מספרים בטווח 0-5, כאשר ייתכן שמספר מסוים יודפס יותר מפעם אחת.", "ה. תתרחש שגיאת הידור (Compilation Error) כי לא ניתן להעביר כתובת של משתנה מקומי לפונקציית החוט."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "הבעיה בקוד היא שכל החוטים (threads) מקבלים מצביע לאותו מיקום בזיכרון - המשתנה המקומי i שנמצא על המחסנית של פונקציית main. כיוון שהחוטים רצים במקביל ללולאת היצירה, ייתכן שערכו של i ישתנה על ידי ה-main thread לפני שחוט מסוים יספיק לקרוא אותו ולהדפיסו. בסיום הלולאה הראשונה i מגיע לערך 5. לכן, הפלט תלוי בתזמון (Race Condition): ייתכן שחלק מהחוטים ידפיסו ערכים ישנים של i, חלק ידפיסו את הערך הנוכחי, וחלק ידפיסו 5 אם הם ירוצו רק לאחר שהלולאה הסתיימה."}, "difficulty_estimation": "Medium", "_source_file": "0085__Threads__MultipleChoice__Medium.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:34:22", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Threads", "Concurrency", "Pthreads", "Race Conditions"], "content": {"text": "לפניך קוד בשפת C המשתמש בספריית pthreads ליצירת 5 חוטים (threads). מה מהבאים מתאר נכונה את ההתנהגות הצפויה של התוכנית בעת הרצתה?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nvoid* thread_func(void* arg) {\n    int val = *(int*)arg;\n    printf(\"%d \", val);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[5];\n    for (int i = 0; i < 5; i++) {\n        pthread_create(&threads[i], NULL, thread_func, &i);\n    }\n    for (int i = 0; i < 5; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    return 0;\n}", "options": ["א. התוכנית תדפיס תמיד את המספרים 0 1 2 3 4 בסדר זה בדיוק.", "ב. התוכנית תדפיס תמיד את המספרים 0 עד 4, אך בסדר שאינו ידוע מראש (פרמוטציה של המספרים).", "ג. ייתכן שחלק מהמספרים יודפסו יותר מפעם אחת, חלק לא יודפסו כלל, וייתכן אף שהמספר 5 יודפס.", "ד. התוכנית תגרום לשגיאת גישה לזיכרון (Segmentation Fault) כיוון שהמשתנה i הוא מקומי לפונקציית main.", "ה. התוכנית לא תעבור קומפילציה כיוון שלא ניתן להעביר את הכתובת של i כארגומנט מסוג void*."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הבעיה בקוד היא מרוץ תהליכים (Race Condition) על המשתנה i. כל חמשת החוטים מקבלים את אותה הכתובת בזיכרון (הכתובת של המשתנה i ב-stack של main). מכיוון שחוט ה-main ממשיך לקדם את i בלולאה בזמן שהחוטים החדשים נוצרים ומתחילים לרוץ, ייתכן שחוט מסוים יקרא את הערך של i רק אחרי שהוא כבר קודם מספר פעמים על ידי ה-main. לכן, ייתכן ששני חוטים יקראו את אותו ערך, או שחוט יקרא את הערך 5 (תנאי העצירה של הלולאה) לפני שהתוכנית תסתיים. הפלט אינו דטרמיניסטי ותלוי בתזמון המעבד."}, "difficulty_estimation": "Medium", "_source_file": "0086__Threads__MultipleChoice__Medium.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:34:35", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Threads", "Concurrency", "Race Condition"], "content": {"text": "נתון הקוד הבא הכתוב בשפת C ומשתמש בספריית pthreads. מה מהבאים מתאר נכונה את התנהגות התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint global_sum = 0;\n\nvoid* thread_func(void* arg) {\n    int val = *(int*)arg;\n    for (int i = 0; i < 1000; i++) {\n        global_sum += val;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[2];\n    for (int i = 1; i <= 2; i++) {\n        pthread_create(&threads[i-1], NULL, thread_func, &i);\n    }\n    for (int i = 0; i < 2; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    printf(\"%d\\n\", global_sum);\n    return 0;\n}", "options": ["א. התוכנית תמיד תדפיס 3000, מכיוון שהלולאה הראשונה רצה עבור i=1 ו-i=2.", "ב. התוכנית תדפיס ערך שבין 1000 ל-3000, אך הערך יהיה תמיד כפולה של 1000.", "ג. הפלט עשוי להיות שונה מ-3000 גם בשל Race Condition על global_sum וגם בשל העברת מצביע למשתנה הלוקאלי i שערכו משתנה ב-main.", "ד. התוכנית תגרום לשגיאת סגמנטציה (Segmentation Fault) כיוון שחוטי המשנה מנסים לגשת לזיכרון של המחסנית של חוט ה-main.", "ה. התוכנית תדפיס תמיד 3000, שכן pthread_join מבצע סנכרון (Memory Barrier) שמבטיח את תקינות הערך של global_sum."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התשובה הנכונה היא ג'. ישנן שתי בעיות סנכרון עיקריות בקוד: 1. Race Condition על המשתנה הגלובלי: הפעולה global_sum += val אינה אטומית. כאשר שני חוטים מנסים לעדכן את המשתנה בו-זמנית, עדכונים עלולים ללכת לאיבוד. 2. Argument Race: הכתובת של המשתנה i מועברת לחוטים. כיוון ש-i משתנה בלולאה ב-main בזמן שהחוטים נוצרים, ייתכן שחוט יקרא את הערך של i מהזיכרון רק לאחר ש-main כבר קידם אותו (למשל ל-2 או ל-3), ולכן val בתוך החוט לא יהיה בהכרח הערך המיועד (1 או 2)."}, "difficulty_estimation": "Medium", "_source_file": "0087__Threads__MultipleChoice__Medium.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:34:56", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Threads", "Concurrency", "Race Conditions"], "content": {"text": "לפניכם קוד בשפת C המשתמש בספריית pthreads. מה ניתן לומר על הפלט של התוכנית בהנחה שהקומפילציה והרצת התהליכונים הצליחו?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nvoid* task(void* arg) {\n    int* val = (int*)arg;\n    for (int i = 0; i < 100; i++) {\n        (*val)++;\n    }\n    return NULL;\n}\n\nint main() {\n    int shared_val = 0;\n    pthread_t threads[10];\n    for (int i = 0; i < 10; i++) {\n        pthread_create(&threads[i], NULL, task, &shared_val);\n    }\n    for (int i = 0; i < 10; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    printf(\"%d\", shared_val);\n    return 0;\n}", "options": ["א. הפלט יהיה תמיד 1000.", "ב. הפלט עשוי להיות קטן מ-1000 עקב מרוץ תהליכונים (Race Condition).", "ג. התוכנית תגרום לשגיאת פילוח (Segmentation Fault) בשל גישה מקבילית של תהליכונים שונים לאותו משתנה מקומי.", "ד. הפלט יהיה תמיד 100, כיוון שכל תהליכון מבצע בדיוק 100 איטרציות ודורס את תוצאות קודמיו.", "ה. הקוד לא יעבור קומפילציה כיוון שהפונקציה pthread_create דורשת העברת משתנה גלובלי בלבד כארגומנט."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הפעולה ++(*val) אינה אטומית. היא מורכבת משלושה שלבים ברמת המכונה: טעינת הערך מהזיכרון לרגיסטר, קידום הערך ברגיסטר, וכתיבת הערך המעודכן חזרה לזיכרון. כאשר מספר תהליכונים ניגשים לאותו משתנה ללא סנכרון (כמו Mutex), תהליכון אחד עלול לקרוא ערך 'ישן' בזמן שתהליכון אחר מעדכן אותו, ובכך לגרום לאובדן עדכונים (Race Condition). לכן, התוצאה הסופית עשויה להיות נמוכה מ-1000. שימוש בכתובת של משתנה מקומי מתוך main הוא תקין במקרה זה כי main ממתינה לסיום התהליכונים בעזרת pthread_join לפני שהיא מסיימת את ריצתה ומפנה את המחסנית."}, "difficulty_estimation": "Medium", "_source_file": "0088__Threads__MultipleChoice__Medium.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:35:19", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Threads", "Race Conditions", "Pthreads", "Memory Management"], "content": {"text": "נתון קוד ה-C הבא המשתמש בספריית pthreads. מה ניתן לומר על פלט התוכנית בסיום ריצתה?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint global_val = 0;\n\nvoid* thread_func(void* arg) {\n    int thread_id = *(int*)arg;\n    global_val += thread_id;\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[3];\n    for (int i = 1; i <= 3; i++) {\n        pthread_create(&threads[i-1], NULL, thread_func, &i);\n    }\n    for (int i = 0; i < 3; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    printf(\"%d\\n\", global_val);\n    return 0;\n}", "options": ["א. הפלט יהיה תמיד 6 (הסכום של 1, 2 ו-3).", "ב. הפלט יהיה תמיד 12 (הערך 4 כפול 3 שרשורים).", "ג. הפלט אינו דטרמיניסטי; הוא עשוי להשתנות בין הרצות שונות עקב גישה לאותה כתובת זיכרון ותחרות על משתנה גלובלי.", "ד. התוכנית תגרום לשגיאת זמן ריצה (Runtime Error) כיוון שלא ניתן לגשת למשתנה מקומי של main מתוך שרשור.", "ה. הפלט יהיה תמיד 0 כיוון שהשינויים בשרשורים מתבצעים על עותק מקומי של global_val."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התשובה הנכונה היא ג'. קיימות כאן שתי בעיות קריטיות: 1. ה-Main thread מעביר לכל השרשורים מצביע (&i) לאותו מיקום בזיכרון שבו נמצא משתנה הלולאה. כיוון שהלולאה ממשיכה לרוץ במקביל להיווצרות השרשורים, עד שהשרשור יבצע dereference למצביע, הערך של i עשוי להשתנות (למשל ל-4). 2. קיימת תחרות (Race Condition) על המשתנה הגלובלי global_val; פעולת ה-increment (+=) אינה אטומית ברמת ה-CPU, וללא שימוש ב-Mutex, עדכונים של שרשורים שונים עלולים 'לדרוס' זה את זה."}, "difficulty_estimation": "Hard", "_source_file": "0089__Threads__MultipleChoice__Hard.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:35:34", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Threads", "Processes", "Synchronization", "fork"], "content": {"text": "נתון תהליך המריץ שני חוטים (Threads) של POSIX. חוט א' נועל Mutex גלובלי ומתחיל בביצוע חישוב ארוך. בזמן שחוט א' מחזיק בנעילה, חוט ב' מבצע קריאה למערכת (system call) מסוג fork(). איזו מהטענות הבאות מתארת נכונה את מצב התהליך הבן שנוצר?", "code_snippet": null, "options": ["א. בתהליך הבן ייווצרו שני חוטים המקבילים לחוטים בתהליך האב, וחוט א' בבן ימשיך להחזיק ב-Mutex.", "ב. בתהליך הבן יהיה קיים רק חוט אחד (העתק של חוט ב'), וה-Mutex יופיע במצב 'נעול' ללא חוט שיכול לשחרר אותו.", "ג. מערכת ההפעלה מזהה שה-Mutex נעול על ידי חוט שלא הועתק לבן, ולכן היא משחררת את ה-Mutex באופן אוטומטי בתהליך הבן.", "ד. הקריאה ל-fork() תחסום את חוט ב' עד שחוט א' ישחרר את ה-Mutex, כדי למנוע חוסר עקביות בזיכרון.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "לפי תקן POSIX, כאשר תהליך מרובה חוטים מבצע fork(), רק החוט שקרא ל-fork() מועתק לתהליך הבן. שאר החוטים אינם קיימים בבן. עם זאת, מרחב הכתובות מועתק כפי שהוא (במנגנון Copy-on-Write), כולל מצבם של אובייקטי סנכרון בזיכרון. לכן, אם Mutex היה נעול באב על ידי חוט שלא הועתק לבן, הוא יישאר נעול בבן לנצח (מצב של Deadlock פוטנציאלי), שכן החוט האחראי לשחרורו אינו קיים בבן."}, "difficulty_estimation": "Hard", "_source_file": "0090__Threads__MultipleChoice__Hard.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:35:58", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Threads", "Processes", "fork", "Synchronization"], "content": {"text": "נתון תהליך המכיל שלושה חוטים (threads) הפועלים במקביל במרחב המשתמש (POSIX threads). חוט א' נועל Mutex גלובלי ומתחיל בביצוע חישוב ארוך. לפני שחוט א' מספיק לשחרר את הנעילה, חוט ב' מבצע קריאה למערכת מסוג fork(). איזה מההיגדים הבאים מתאר בצורה המדויקת ביותר את מצב התהליך הבן (Child Process) שנוצר מיד לאחר הקריאה?", "code_snippet": null, "options": ["א. בתהליך הבן ייווצרו שלושה חוטים המקבילים לאלו שבמקור, וחוט א' בבן ימשיך להחזיק ב-Mutex.", "ב. בתהליך הבן ייווצר רק חוט אחד (העתק של חוט ב'), וה-Mutex יהיה במצב נעול (locked) מבלי שיהיה חוט קיים שיוכל לשחררו.", "ג. בתהליך הבן ייווצר רק חוט אחד (העתק של חוט ב'), ומערכת ההפעלה תזהה שהחוט שנעל את ה-Mutex אינו קיים ותשחרר את הנעילה אוטומטית.", "ד. הקריאה ל-fork() תיחסם על ידי מערכת ההפעלה עד שכל ה-Mutexes במרחב הכתובות ישוחררו על ידי החוטים המחזיקים בהם.", "ה. בתהליך הבן ייווצר רק חוט אחד (העתק של חוט ב'), וכל ה-Mutexes בזיכרון של הבן יאותחלו למצב פתוח (unlocked) כברירת מחדל."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "לפי תקן POSIX, כאשר תהליך מרובה חוטים קורא ל-fork(), רק החוט שביצע את הקריאה מועתק לתהליך הבן. שאר החוטים אינם קיימים בבן. עם זאת, מרחב הכתובות מועתק במלואו, כולל המצב של משתנים גלובליים ואובייקטי סנכרון (כמו Mutexes). מכיוון שה-Mutex הועתק כשהוא במצב 'נעול' והחוט שאמור לשחרר אותו (חוט א') לא הועתק לבן, ה-Mutex יישאר נעול לצמיתות בתוך התהליך הבן. מצב זה נחשב למסוכן ועלול להוביל ל-Deadlock בתהליך הבן."}, "difficulty_estimation": "Hard", "_source_file": "0091__Threads__MultipleChoice__Hard.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:36:13", "_subject": "Virtualization"}, {"id": 101, "type": "MultipleChoice", "topic": ["Threads", "Memory Management", "Pthreads", "Stack vs Heap"], "content": {"text": "שקלו את קטע הקוד הבא הכתוב בשפת C והמשתמש בספריית pthreads. נניח שהקריאה ל-pthread_create מצליחה והמערכת היא מערכת Linux סטנדרטית. מהי הקביעה המדויקת ביותר לגבי הרצת התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n\nvoid* task(void* arg) {\n    int* p = (int*)arg;\n    sleep(1);\n    printf(\"%d\\n\", *p);\n    return NULL;\n}\n\nvoid start_work() {\n    pthread_t t;\n    int local_val = 42;\n    pthread_create(&t, NULL, task, &local_val);\n    // No pthread_join here\n}\n\nint main() {\n    start_work();\n    sleep(2);\n    return 0;\n}", "options": ["א. יודפס תמיד הערך 42, מכיוון שחוטים חולקים את אותו מרחב כתובות והזיכרון נשאר תקף כל עוד התהליך רץ.", "ב. תתרחש בהכרח שגיאת Segmentation Fault מיד עם הניסיון לגשת למשתנה p, כיוון שלכל חוט יש מחסנית נפרדת וגישה למחסנית של חוט אחר חסומה על ידי ה-MMU.", "ג. התנהגות התוכנית אינה מוגדרת (Undefined Behavior). ייתכן שיודפס 42, ייתכן שיודפס ערך זבל, וייתכן שתתרחש שגיאת זיכרון.", "ד. התוכנית לא תעבור קומפילציה כיוון שלא ניתן להעביר כתובת של משתנה מקומי (Local Variable) כארגומנט לפונקציית החוט.", "ה. התוכנית תסתיים מיד לאחר הקריאה ל-start_work מבלי להדפיס דבר, כיוון שסיום הפונקציה שיוצרת את החוט גורר את סיום החוט עצמו."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הסבר: למרות שכל החוטים בתהליך חולקים את אותו מרחב כתובות וירטואלי, לכל חוט יש מחסנית (Stack) פרטית משלו. המשתנה local_val מוקצה על המחסנית של החוט הראשי בזמן ביצוע הפונקציה start_work. ברגע שפונקציה זו מסתיימת, מסגרת המחסנית (Stack Frame) שלה משתחררת וניתן להשתמש בה לקריאות עתידיות. החוט החדש מנסה לגשת לכתובת הזיכרון הזו (Dangling Pointer) לאחר שהפונקציה שיצרה אותו כבר חזרה. כיוון שהתהליך עדיין רץ (בגלל ה-sleep ב-main), הגישה לזיכרון לא תמיד תגרום ל-Segfault (כי הדף בזיכרון עדיין שייך לתהליך), אך התוכן בכתובת זו עלול להשתנות או להיות לא תקף, מה שמוביל להתנהגות לא מוגדרת."}, "difficulty_estimation": "Hard", "_source_file": "0092__Threads__MultipleChoice__Hard.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:36:31", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Threads", "Process Management", "fork", "Synchronization"], "content": {"text": "נתון תהליך מרובה חוטים (Multi-threaded process) המשתמש ב-Mutex גלובלי לצורך סנכרון. אחד מהחוטים (שאינו חוט ה-Main) מבצע קריאה לפונקציה fork() כפי שמתואר בקוד מטה. נניח כי בזמן הקריאה ל-fork(), חוט אחר בתהליך האב (שאינו החוט הקורא ל-fork) מחזיק במנעול ה-lock. מה יקרה בנקודה המסומנת ב-Line X בתוך תהליך הבן?", "code_snippet": "void* thread_func(void* arg) {\n    if (fork() == 0) {\n        // Child process\n        pthread_mutex_lock(&lock); // Line X\n        printf(\"Child acquired lock\\n\");\n        pthread_mutex_unlock(&lock);\n        exit(0);\n    }\n    return NULL;\n}", "options": ["א. תהליך הבן יצליח לתפוס את המנעול מכיוון שכל המנעולים משתחררים אוטומטית בעת fork().", "ב. תהליך הבן יכיל את כל החוטים שהיו באב, ולכן החוט שהחזיק במנעול באב ישחרר אותו גם בבן.", "ג. תהליך הבן ייתקע בקיפאון (Deadlock) ב-Line X, שכן המנעול מועתק במצב 'תפוס' אך החוט שאמור לשחרר אותו אינו קיים בבן.", "ד. תהליך הבן יקרוס (Segmentation Fault) בגישה למנעול שנתפס על ידי חוט שכבר לא קיים.", "ה. מערכת ההפעלה תזהה את המצב ותעביר את הבעלות על המנעול לחוט היחיד שקיים בבן."]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "לפי תקן POSIX, כאשר תהליך מרובה חוטים מבצע fork(), רק החוט שקרא ל-fork() משוכפל בתהליך הבן. שאר החוטים של האב אינם קיימים בבן. עם זאת, מצב הזיכרון (כולל מצב ה-Mutexes) מועתק כפי שהוא (Copy-on-Write). אם חוט אחר באב החזיק במנעול בזמן ה-fork, המנעול יופיע כתפוס בזיכרון של הבן. מכיוון שהחוט שהחזיק במנעול לא קיים בבן כדי לשחרר אותו, כל ניסיון של החוט היחיד בבן לתפוס את המנעול יוביל ל-Deadlock."}, "difficulty_estimation": "Hard", "_source_file": "0093__Threads__MultipleChoice__Hard.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:36:56", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Threads", "Concurrency", "Race Conditions"], "content": {"text": "נתון קטע הקוד הבא בשפת C המשתמש בספריית pthreads. מה מהבאים מתאר נכונה את התנהגות התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n\nvoid* thread_func(void* arg) {\n    int id = *(int*)arg;\n    printf(\"%d \", id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[5];\n    for (int i = 0; i < 5; i++) {\n        pthread_create(&threads[i], NULL, thread_func, &i);\n    }\n    for (int i = 0; i < 5; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    return 0;\n}", "options": ["א. התוכנית תדפיס תמיד את המספרים 0 עד 4 בסדר כלשהו, כאשר כל מספר מופיע בדיוק פעם אחת.", "ב. ייתכן מצב בו יודפס המספר 5, או שמספר מסוים בטווח 0-4 יודפס יותר מפעם אחת.", "ג. השימוש ב-pthread_join מבטיח שכל thread יסיים את ריצתו לפני שהלולאה הבאה של ה-main תתחיל, ולכן הפלט יהיה 0 1 2 3 4.", "ד. התוכנית תגרום לשגיאת זמן ריצה (Runtime Error) כיוון שכל ה-threads מנסים לגשת לאותו זיכרון במקביל."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הבעיה בקוד היא Race Condition על המשתנה i. כל ה-threads מקבלים את אותה הכתובת בזיכרון (&i). בזמן ש-thread מסוים מתעורר וניגש לכתובת הזו כדי לקרוא את הערך (dereference), ה-main thread עשוי כבר לקדם את i בתוך הלולאה. יתרה מכך, i מגיע לערך 5 כדי לצאת מהלולאה הראשונה, ולכן ייתכן שחלק מה-threads (או כולם) יקראו את הערך 5 מהכתובת המשותפת לפני שהם מספיקים להדפיס."}, "difficulty_estimation": "Hard", "_source_file": "0094__Threads__MultipleChoice__Hard.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:37:14", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Threads", "Memory Visibility", "Optimization", "Pthreads"], "content": {"text": "במערכת המשתמשת ב-POSIX Threads (Pthreads), נתון הקוד הבא בשפת C. מהי הטענה המדויקת ביותר לגבי התנהגות התוכנית בעת הרצה על מעבד מרובה ליבות (Multi-core) עם רמת אופטימיזציה גבוהה (למשל O3-)?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nvoid* thread_func(void* arg) {\n    int* p = (int*)arg;\n    while (*p == 0); // Wait for flag to change\n    printf(\"Value changed!\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t t1;\n    int flag = 0;\n    pthread_create(&t1, NULL, thread_func, &flag);\n    \n    // Simulate some work\n    for (volatile int i = 0; i < 1000000; i++);\n    \n    flag = 1;\n    pthread_join(t1, NULL);\n    return 0;\n}", "options": ["א. התוכנית תקינה לחלוטין ותדפיס תמיד את ההודעה, שכן חוטים חולקים את אותו מרחב כתובות והשינוי ב-flag ייראה מיד לחוט t1.", "ב. התוכנית עלולה להיכנס ללולאה אינסופית בגלל אופטימיזציות קומפיילר, שכן ללא סנכרון או שימוש ב-volatile, החוט t1 עשוי לטעון את הערך של flag לרגיסטר פעם אחת בלבד ולא לבדוק שוב את הזיכרון.", "ג. תתרחש שגיאת Segmentation Fault כיוון שחוט t1 מנסה לגשת למחסנית (Stack) של החוט הראשי, דבר שאינו מותר במודל של Kernel-level threads.", "ד. הקריאה ל-pthread_join תגרום ל-Deadlock כיוון שהיא חוסמת את החוט הראשי מלערוך את המשתנה flag.", "ה. התוכנית לא תתקמפל כיוון שלא ניתן להעביר כתובת של משתנה מקומי (flag) כארגומנט לפונקציה pthread_create."]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "במרחב כתובות משותף, חוטים אכן יכולים לגשת לאותם משתנים (כולל משתנים על מחסנית של חוט אחר כל עוד הוא חי). עם זאת, ללא מנגנוני סנכרון (כמו Mutex) או הגדרת המשתנה כ-volatile, הקומפיילר עשוי להניח שערכו של flag אינו משתנה בתוך הלולאה בחוט t1 (כי אין שום קריאה לפונקציה או כתיבה למשתנה בתוך הלולאה). לכן, הקומפיילר עשוי לבצע אופטימיזציה שבה הערך נטען לרגיסטר פעם אחת בלבד לפני הלולאה. במצב כזה, השינוי שביצע החוט הראשי בזיכרון לא יורגש בתוך הלולאה והחוט ייתקע בלולאה אינסופית."}, "difficulty_estimation": "Hard", "_source_file": "0095__Threads__MultipleChoice__Hard.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:37:47", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Threads", "Process Management", "POSIX"], "content": {"text": "נתון קוד C המשתמש בספריית Pthreads. תהליך מסוים יוצר שני תהליכונים (Threads) בנוסף לתהליכון הראשי (Main thread). אחד מהתהליכונים החדשים שנוצרו מבצע קריאה למערכת (System Call) מסוג fork(). איזה מההיגדים הבאים מתאר נכונה את מצב התהליך הבן שנוצר מיד לאחר הקריאה?", "code_snippet": "void* thread_func(void* arg) {\n    pid_t pid = fork();\n    if (pid == 0) {\n        // מה קיים כאן בתוך התהליך הבן?\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, thread_func, NULL);\n    pthread_create(&t2, NULL, some_other_func, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    return 0;\n}", "options": ["א. התהליך הבן יכיל העתק של כל התהליכונים שהיו קיימים בתהליך האב (סה\"כ 3 תהליכונים).", "ב. התהליך הבן יכיל רק תהליכון אחד, שהוא העתק של התהליכון שביצע את הקריאה ל-fork.", "ג. התהליך הבן יכיל רק את התהליכון הראשי (Main thread), וכל שאר התהליכונים יופסקו.", "ד. הפעולה אינה מוגדרת (Undefined behavior) ותלויה במימוש הספציפי של ה-Scheduler של מערכת ההפעלה."]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "לפי תקן POSIX, כאשר תהליך מרובה תהליכונים קורא ל-fork, התהליך הבן שנוצר הוא העתק של תהליך האב מבחינת מרחב הכתובות (Address Space), אך הוא מכיל רק תהליכון אחד בלבד - התהליכון שביצע את הקריאה ל-fork. שאר התהליכונים שהיו קיימים באב אינם נוצרים בבן. זוהי נקודה קריטית כי אם התהליכונים האחרים החזיקו במנעולים (Mutexes) ברגע הקריאה, המנעולים יופיעו כתפוסים בבן אך התהליכון שאמור לשחרר אותם לא קיים שם, מה שעלול להוביל ל-Deadlock."}, "difficulty_estimation": "Hard", "_source_file": "0096__Threads__MultipleChoice__Hard.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:38:08", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Threads", "User-level threads", "Kernel-level threads"], "content": {"text": "במערכת הפעלה מסוימת, תהליך מכיל שלושה חוטים (threads). אחד החוטים מבצע קריאת מערכת חוסמת (blocking system call) לקלט מהמקלדת, כפי שמתואר בקטע הקוד הבא. הסבירו מה יקרה לשני החוטים האחרים באותו תהליך בשני המקרים המפורטים מטה:", "code_snippet": "void* thread_work(void* arg) {\n    char buffer[1024];\n    // הקריאה הבאה חוסמת את החוט עד לקבלת קלט\n    read(STDIN_FILENO, buffer, sizeof(buffer));\n    printf(\"Input received!\\n\");\n    return NULL;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "החוטים ממומשים כחוטים ברמת המשתמש (User-level threads) במודל Many-to-One.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "החוטים ממומשים כחוטים ברמת הגרעין (Kernel-level threads) במודל One-to-One.", "code_snippet": null, "options": null}], "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1. במודל Many-to-One (User-level threads), מערכת ההפעלה (הגרעין) אינה מודעת לקיומם של החוטים ורואה רק תהליך אחד. כאשר חוט אחד מבצע קריאת מערכת חוסמת, הגרעין מעביר את כל התהליך למצב 'ממתין' (Waiting/Blocked). כתוצאה מכך, כל שאר החוטים בתהליך ייחסמו ולא יוכלו להמשיך בביצועם עד שהקריאה תסתיים.\n\n10.2. במודל One-to-One (Kernel-level threads), כל חוט משתמש ממופה לחוט נפרד בתוך הגרעין. במקרה זה, הגרעין מנהל את התזמון של כל חוט בנפרד. לכן, אם חוט אחד נחסם בגלל קריאת מערכת, הגרעין יכול להמשיך לתזמן ולהריץ את שני החוטים האחרים של אותו תהליך ללא הפרעה."}, "difficulty_estimation": "Easy", "_source_file": "0097__Threads__Open__Easy.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:38:19", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Threads", "Concurrency", "Race Conditions"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בספריית pthreads. התוכנית יוצרת שני חוטים (threads) המריצים את הפונקציה `increment` שמקדמת משתנה גלובלי משותף.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint counter = 0;\n\nvoid* increment(void* arg) {\n    for (int i = 0; i < 100; i++) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, increment, NULL);\n    pthread_create(&t2, NULL, increment, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"%d\\n\", counter);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "מהו הערך המקסימלי האפשרי שיודפס על ידי התוכנית? נמקו בקצרה.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "האם ייתכן שהתוכנית תדפיס ערך הנמוך מ-200? אם כן, הסבירו באיזה מצב זה עלול לקרות. אם לא, הסבירו מדוע.", "code_snippet": null, "options": null}], "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1. הערך המקסימלי הוא 200. כל אחד משני החוטים מבצע 100 איטרציות שבהן הוא מקדם את המשתנה הגלובלי counter. במקרה שבו אין חפיפה בין הפעולות (למשל ריצה סדרתית מלאה של חוט אחד ואז השני), כל הקידומים יישמרו.\n10.2. כן, ייתכן ערך נמוך מ-200 בשל מצב מרוץ (Race Condition). הפעולה ++counter אינה אטומית (היא מורכבת מקריאת הערך מהזיכרון, הוספת 1 ברגיסטר, וכתיבה חזרה לזיכרון). אם שני חוטים קוראים את הערך בו-זמנית (למשל 50), שניהם יקדמו אותו ל-51 ויכתבו את אותה התוצאה לזיכרון, מה שיוביל לאובדן של אחד הקידומים."}, "difficulty_estimation": "Easy", "_source_file": "0098__Threads__Open__Easy.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:38:32", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Threads"], "content": {"text": "נתון קטע הקוד הבא בשפת C המשתמש בספריית pthreads. מה יהיה הפלט של התוכנית? הסבר את תשובתך תוך התייחסות למרחב הכתובות המשותף בין חוטים (threads).", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint global_var = 10;\n\nvoid* thread_func(void* arg) {\n    global_var += 5;\n    return NULL;\n}\n\nint main() {\n    pthread_t tid;\n    pthread_create(&tid, NULL, thread_func, NULL);\n    pthread_join(tid, NULL);\n    printf(\"%d\\n\", global_var);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפלט יהיה 15. חוטים (threads) ששייכים לאותו תהליך חולקים את אותו מרחב כתובות, ובפרט את מקטע הנתונים (Data Segment) שבו נמצאים משתנים גלובליים. לכן, כאשר ה-thread שנוצר מעדכן את המשתנה global_var, השינוי משתקף גם ב-thread הראשי (main). הפעולה pthread_join מבטיחה שה-thread הראשי ימתין לסיום ביצוע ה-thread החדש לפני שידפיס את הערך."}, "difficulty_estimation": "Easy", "_source_file": "0099__Threads__Open__Easy.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:38:47", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Threads", "Concurrency", "Memory Management"], "content": {"text": "לפניך קטע קוד בשפת C המשתמש בספריית pthreads. התוכנית מגדירה משתנה גלובלי ומבצעת פעולות עדכון מתוך שני חוטים שונים.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint counter = 0;\n\nvoid* increment_task(void* arg) {\n    for (int i = 0; i < 100; i++) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n\n    pthread_create(&t1, NULL, increment_task, NULL);\n    pthread_create(&t2, NULL, increment_task, NULL);\n\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n\n    printf(\"%d\\n\", counter);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "בהנחה שהריצה מתבצעת באופן תקין וללא הפרעות של מרוץ תהליכים (race conditions), מה יהיה הפלט המודפס למסך?", "code_snippet": null, "options": null}, {"id": "7.2", "text": "הסבר מדוע חוטים (threads) מסוגלים לעדכן את המשתנה counter בצורה כזו, וכיצד התנהגות זו הייתה משתנה אילו היינו משתמשים בתהליכים (processes) ע\"י fork במקום חוטים?", "code_snippet": null, "options": null}], "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1. הפלט יהיה 200. כל אחד משני החוטים מבצע 100 איטרציות של קידום המשתנה counter ב-1.\n7.2. חוטים (threads) השייכים לאותו תהליך חולקים את אותו מרחב כתובות (Address Space), ולכן משתנים גלובליים (הנמצאים במקטע הנתונים) הם משותפים לכולם. אילו היינו משתמשים ב-fork, היה נוצר תהליך בן עם עותק נפרד של מרחב הכתובות (Copy-on-write). במקרה כזה, קידום המשתנה בתהליך הבן לא היה משפיע על המשתנה בתהליך האב, והאב היה מדפיס 0."}, "difficulty_estimation": "Easy", "_source_file": "0100__Threads__Open__Easy.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:39:01", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Threads", "Concurrency", "Memory Management"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בספריית pthreads. מה יהיה הפלט המודפס למסך בסיום ריצת התוכנית? הסבירו את תשובתכם תוך התייחסות לאופן שבו חוטים (threads) חולקים זיכרון.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint shared_val = 100;\n\nvoid* thread_work(void* arg) {\n    shared_val += 50;\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n\n    pthread_create(&t1, NULL, thread_work, NULL);\n    pthread_join(t1, NULL);\n\n    pthread_create(&t2, NULL, thread_work, NULL);\n    pthread_join(t2, NULL);\n\n    printf(\"%d\\n\", shared_val);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפלט יהיה 200. ההסבר לכך טמון בעובדה שחוטים (Threads) השייכים לאותו תהליך חולקים את אותו מרחב כתובות (Address Space), ובפרט את מקטע הנתונים הגלובליים. המשתנה shared_val הוא גלובלי, ולכן כל שינוי שמבצע חוט אחד נראה באופן מיידי לחוטים האחרים. בתוכנית זו: 1. הערך ההתחלתי הוא 100. 2. החוט הראשון (t1) מוסיף 50, והערך הופך ל-150. 3. הפונקציה pthread_join מבטיחה שהחוט הראשון יסיים לפני שהחוט השני יתחיל. 4. החוט השני (t2) מוסיף 50 נוספים לערך הקיים (150), ולכן התוצאה הסופית היא 200."}, "difficulty_estimation": "Easy", "_source_file": "0101__Threads__Open__Easy.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:39:12", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Threads"], "content": {"text": "לפניך קטע קוד בשפת C המשתמש בספריית pthreads. מהן האפשרויות השונות לפלט התוכנית? הסבר/י מדוע ייתכנו מספר אפשרויות והאם קיימת הבטחה לגבי סדר ההדפסה של האותיות A ו-B.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nvoid* thread_func(void* arg) {\n    printf(\"B\");\n    return NULL;\n}\n\nint main() {\n    pthread_t t;\n    pthread_create(&t, NULL, thread_func, NULL);\n    printf(\"A\");\n    pthread_join(t, NULL);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפלט של התוכנית יכול להיות 'AB' או 'BA'. הסיבה לכך היא שברגע שמתבצעת הקריאה ל-pthread_create, נוצר חוט (thread) חדש שמתחיל לרוץ במקביל לחוט הראשי. התזמון (scheduling) של החוטים על ידי מערכת ההפעלה אינו דטרמיניסטי, ולכן אין לדעת מי יבצע את פקודת ה-printf שלו קודם: החוט הראשי שממשיך מיד לאחר הקריאה ל-create, או החוט החדש שנוצר. פקודת ה-pthread_join מבטיחה שהחוט הראשי ימתין לסיום החוט החדש לפני שהתוכנית כולה תסתיים, אך מכיוון שהיא ממוקמת אחרי ה-printf של ה-main, היא אינה משפיעה על סדר ההדפסה היחסי בין A ל-B."}, "difficulty_estimation": "Easy", "_source_file": "0102__Threads__Open__Easy.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:39:27", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Threads", "Shared Memory", "Pthreads"], "content": {"text": "נתון קטע הקוד הבא בשפת C המשתמש בספריית pthreads. הניחו כי כל הקריאות למערכת (system calls) מצליחות וכי התזמון מתבצע כך שהחוט החדש מסיים את ריצתו לפני שהחוט הראשי ממשיך לאחר ה-join. מה יהיה הפלט של התוכנית? הסבירו בקצרה מדוע.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint x = 10;\n\nvoid* thread_func(void* arg) {\n    x += 5;\n    printf(\"Thread: x = %d\\n\", x);\n    return NULL;\n}\n\nint main() {\n    pthread_t tid;\n    pthread_create(&tid, NULL, thread_func, NULL);\n    pthread_join(tid, NULL);\n    x += 2;\n    printf(\"Main: x = %d\\n\", x);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפלט הצפוי הוא:\nThread: x = 15\nMain: x = 17\nהסבר: חוטים (threads) בתוך אותו תהליך חולקים את אותו מרחב כתובות, ולכן המשתנה הגלובלי x משותף לחוט הראשי ולחוט שנוצר. החוט הראשי קורא ל-pthread_join, מה שגורם לו להמתין עד שהחוט החדש יסיים את ביצועו. בתוך thread_func, הערך של x עולה מ-10 ל-15 ומודפס. לאחר סיום החוט, החוט הראשי ממשיך, מוסיף 2 לערך המעודכן (15+2=17) ומדפיס את התוצאה."}, "difficulty_estimation": "Easy", "_source_file": "0103__Threads__Open__Easy.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:39:38", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Threads", "Concurrency", "Race Conditions"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בספריית pthreads. התוכנית יוצרת שני חוטים (threads) שכל אחד מהם מעלה את הערך של משתנה גלובלי משותף counter בתוך לולאה 10,000 פעמים.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0;\n\nvoid* increment(void* arg) {\n    for (int i = 0; i < 10000; i++) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, increment, NULL);\n    pthread_create(&t2, NULL, increment, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"Final counter: %d\\n\", counter);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "מהי התוצאה המקסימלית האפשרית של המשתנה counter בסיום ריצת התוכנית?", "code_snippet": null, "options": null}, {"id": "7.2", "text": "האם מובטח שהפלט של התוכנית יהיה תמיד התוצאה המקסימלית? הסבירו מדוע, והשתמשו במושג \"מרוץ תהליכים\" (Race Condition) בהסברכם.", "code_snippet": null, "options": null}], "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1. התוצאה המקסימלית היא 20,000 (כל אחד משני החוטים מבצע 10,000 פעולות הגדלה).\n7.2. לא, לא מובטח שהפלט יהיה 20,000. הסיבה לכך היא קיום של מרוץ תהליכים (Race Condition). הפעולה ++counter אינה פעולה אטומית (Atomic) ברמת המעבד; היא מורכבת משלושה שלבים: קריאת הערך מהזיכרון לרגיסטר, הוספת 1 ברגיסטר, וכתיבת הערך חזרה לזיכרון. אם מתבצע context switch בין חוטים באמצע שלבים אלו, חוט אחד עלול לקרוא ערך ישן ולדרוס עדכון של חוט אחר, מה שיוביל לכך שחלק מההגדלות יאבדו והתוצאה הסופית תהיה קטנה מ-20,000."}, "difficulty_estimation": "Easy", "_source_file": "0104__Threads__Open__Easy.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:39:57", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Threads", "Concurrency", "Race Conditions", "Memory Layout"], "content": {"text": "לפניכם קוד בשפת C המשתמש בחוטים (Threads). הניחו שהקוד רץ על מערכת מרובת ליבות וכי אין מנגנוני סנכרון נוספים מעבר למה שמופיע בקוד.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0;\n\nvoid* worker(void* arg) {\n    int* local_ptr = (int*)arg;\n    for (int i = 0; i < 100; i++) {\n        counter++;\n        (*local_ptr)++;\n    }\n    return NULL;\n}\n\nint main() {\n    int shared_val = 0;\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, worker, &shared_val);\n    pthread_create(&t2, NULL, worker, &shared_val);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"counter: %d, shared_val: %d\\n\", counter, shared_val);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "מהם הערכים המינימליים והמקסימליים האפשריים שיוצגו עבור counter ו-shared_val בסיום התוכנית? הסבירו בקצרה מדוע.", "code_snippet": null, "options": null}, {"id": "7.2", "text": "הסבירו את ההבדל במיקום בזיכרון בין counter ל-shared_val. האם הבדל זה משנה את רגישות המשתנה shared_val למצבי מרוץ (Race Conditions)?", "code_snippet": null, "options": null}, {"id": "7.3", "text": "כיצד שימוש ב-pthread_mutex_t יכול לפתור את הבעיה? הציגו את השינוי הנדרש בקוד ה-worker בלבד (הניחו כי המיוטקס כבר אותחל גלובלית בשם lock).", "code_snippet": null, "options": null}], "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1. המקסימום עבור שניהם הוא 200 (במקרה של ריצה סדרתית או תזמון מושלם). המינימום הוא 2 (במקרה של Race Condition שבו כל חוט קורא את הערך 0, מקדם ל-1 וכותב, ואז התהליך חוזר על עצמו כך שכל חוט דורס את עבודת השני פרט לפעם אחת). הערכים נובעים מכך שפעולת הקידום אינה אטומית (Load, Increment, Store).\n\n7.2. המשתנה counter הוא גלובלי ולכן נמצא ב-Data Segment. המשתנה shared_val הוכרז ב-main ולכן נמצא על המחסנית (Stack) של חוט ה-main. למרות זאת, כיוון שכתובתו הועברה כארגומנט לחוטים האחרים, לכולם יש גישה לאותו מרחב זיכרון. לכן, shared_val חשוף ל-Race Condition בדיוק כמו counter.\n\n7.3. יש לנעול את המיוטקס לפני הגישה למשתנים המשותפים ולשחרר אחרי:\nvoid* worker(void* arg) {\n    int* local_ptr = (int*)arg;\n    for (int i = 0; i < 100; i++) {\n        pthread_mutex_lock(&lock);\n        counter++;\n        (*local_ptr)++;\n        pthread_mutex_unlock(&lock);\n    }\n    return NULL;\n}"}, "difficulty_estimation": "Medium", "_source_file": "0105__Threads__Open__Medium.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:40:14", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Threads", "Concurrency", "Memory Layout", "Process vs Thread"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בספריית pthreads. הניחו כי כל הקריאות למערכת מצליחות וכי התוכנית רצה על מערכת עם מעבד מרובה ליבות.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint global_var = 0;\n\nvoid* thread_func(void* arg) {\n    int local_var = 0;\n    for (int i = 0; i < 1000; i++) {\n        global_var++;\n        local_var++;\n    }\n    printf(\"%d \", local_var);\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, thread_func, NULL);\n    pthread_create(&t2, NULL, thread_func, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"%d\\n\", global_var);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "מה יהיו הערכים שיודפסו עבור המשתנה local_var על ידי שני החוטים? נמקו.", "code_snippet": null, "options": null}, {"id": "7.2", "text": "מהו טווח הערכים האפשרי שיודפס עבור המשתנה global_var בפקודת ה-printf האחרונה ב-main? הסבירו מדוע.", "code_snippet": null, "options": null}, {"id": "7.3", "text": "נניח ונחליף את יצירת החוטים (pthread_create) ביצירת תהליכים על ידי fork, ואת ה-pthread_join בפקודת wait. כיצד ישתנה הפלט עבור global_var בסוף הריצה של תהליך האב?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1: כל חוט ידפיס 1000. הסבר: המשתנה local_var הוא משתנה מקומי המוקצה על המחסנית (stack). לכל חוט (Thread) יש מחסנית נפרדת משלו, ולכן כל חוט מעדכן עותק פרטי שלו שאינו מושפע מהחוט השני.\n\n7.2: טווח הערכים הוא [1000, 2000]. הסבר: המשתנה global_var נמצא במקטע הנתונים המשותף לכל החוטים באותו תהליך. מכיוון שאין סנכרון (כמו Mutex) על הגישה למשתנה, נוצר מצב מרוץ (Race Condition). בפעולת הקידום (global_var++), חוט אחד עלול לקרוא את הערך, ובזמן שהוא מחשב את התוצאה, החוט השני יקרא את אותו ערך ישן, מה שיגרום לעדכון של אחד מהם 'להידרס'. המינימום הוא 1000 (במקרה שחוט אחד תמיד דורס את השני) והמקסימום הוא 2000 (במקרה שלא היו התנגשויות כלל).\n\n7.3: הפלט עבור global_var בתהליך האב יהיה 0. הסבר: כאשר משתמשים ב-fork, נוצר תהליך חדש עם מרחב כתובות נפרד. למרות שבתחילה הזיכרון מועתק (או משתמש ב-Copy-on-Write), שינויים שמבצע תהליך הבן על משתנה גלובלי אינם משפיעים על המשתנה בזיכרון של תהליך האב. מכיוון שתהליך האב עצמו לא שינה את global_var ב-main, הערך יישאר 0."}, "difficulty_estimation": "Medium", "_source_file": "0106__Threads__Open__Medium.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:40:30", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Threads", "User-level threads", "Kernel-level threads", "Concurrency", "Race Conditions"], "content": {"text": "השאלה הבאה עוסקת בניהול חוטים (threads) במערכות הפעלה ובבעיות סנכרון הנובעות מריצה מקבילית.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "10.1", "text": "נניח תהליך המשתמש בחוטים ברמת המשתמש (User-level threads) במודל Many-to-One. אחד החוטים מבצע קריאת מערכת חוסמת (blocking system call) לקלט מהמקלדת. הסבירו מה יקרה לשאר החוטים באותו תהליך ומדוע. האם המצב היה שונה אילו המערכת הייתה משתמשת בחוטים ברמת הגרעין (Kernel-level threads) במודל One-to-One?", "code_snippet": null, "options": null}, {"id": "10.2", "text": "נתון קטע הקוד הבא המורץ על ידי שני חוטים (Thread A ו-Thread B) החולקים את אותו מרחב כתובות. המשתנה counter הוא גלובלי ומאותחל ל-0. מהו הערך המינימלי האפשרי של counter לאחר ששני החוטים מסיימים את ריצתם? הסבירו בקצרה כיצד ניתן להגיע לערך זה.", "code_snippet": "void* increment(void* arg) {\n    for (int i = 0; i < 100; i++) {\n        int temp = counter;\n        counter = temp + 1;\n    }\n    return NULL;\n}", "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: במודל Many-to-One (חוטים ברמת המשתמש), הגרעין אינו מכיר את החוטים הבודדים ומתייחס לכל התהליך כיחידת תזמון אחת. לכן, כאשר חוט אחד מבצע קריאת מערכת חוסמת, כל התהליך נכנס למצב 'חסום' (Blocked), וכל שאר החוטים בתהליך לא יוכלו לרוץ עד שהקריאה תסתיים. במודל One-to-One (חוטים ברמת הגרעין), כל חוט ממופה לישות תזמון עצמאית בגרעין, ולכן חסימה של חוט אחד אינה מונעת מהגרעין להמשיך לתזמן חוטים אחרים של אותו תהליך.\n\n10.2: הערך המינימלי הוא 2. הסבר: מצב זה קורה עקב Race Condition. נניח שחוט א' קורא את counter=0 לתוך temp ומופסק מיד. חוט ב' רץ 99 פעמים ומסיים (counter=99). כעת חוט א' חוזר, מבצע counter = 0 + 1 ומעדכן את counter ל-1. כעת חוט ב' מתחיל את האיטרציה ה-100 שלו, קורא counter=1 לתוך ה-temp שלו ומופסק. חוט א' ממשיך ורץ את כל 99 האיטרציות הנותרות שלו ומסיים (נניח שעדכן את counter ל-100). לבסוף, חוט ב' חוזר לביצוע האיטרציה האחרונה שלו, מבצע counter = 1 + 1 ודורס את הערך ל-2."}, "difficulty_estimation": "Medium", "_source_file": "0107__Threads__Open__Medium.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:40:52", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Threads", "Concurrency", "User-level vs Kernel-level Threads"], "content": {"text": "נניח מערכת הפעלה התומכת בשני מודלים שונים לניהול חוטים (Threads): מודל Many-to-One (חוטים ברמת המשתמש) ומודל One-to-One (חוטים ברמת הליבה). תהליך מסוים יוצר 4 חוטים. חוט מספר 1 מבצע קריאת מערכת חוסמת (Blocking System Call) לקריאת נתונים מהדיסק, בעוד ששאר החוטים (2, 3, ו-4) מבצעים חישובים מתמטיים.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint counter = 0;\n\nvoid* worker(void* arg) {\n    for (int i = 0; i < 1000000; i++) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, worker, NULL);\n    pthread_create(&t2, NULL, worker, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"Final counter: %d\\n\", counter);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "תאר מה יקרה לחוטים 2, 3 ו-4 בזמן שחוט 1 ממתין לדיסק בכל אחד מהמודלים (Many-to-One ו-One-to-One).", "code_snippet": null, "options": null}, {"id": "7.2", "text": "התייחס לקוד ה-C המצורף. מהי הבעיה הלוגית בקוד זה, ומה יהיה הפלט הצפוי של התוכנית (האם תמיד יודפס 2,000,000)? הסבר מדוע.", "code_snippet": null, "options": null}], "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1: במודל Many-to-One, כל החוטים של התהליך ממופים לישות תזמון אחת בליבה. לכן, כאשר חוט 1 מבצע קריאה חוסמת, הליבה חוסמת את התהליך כולו, וחוטים 2, 3 ו-4 לא יוכלו לרוץ עד שהקריאה תסתיים. במודל One-to-One, כל חוט ממופה לישות תזמון נפרדת בליבה. לכן, רק חוט 1 ייחסם, וחוטים 2, 3 ו-4 יוכלו להמשיך לרוץ במקביל על מעבדים אחרים או בתורות תזמון נפרדים.\n\n7.2: הבעיה בקוד היא מרוץ תהליכים (Race Condition) על המשתנה הגלובלי counter. הפעולה ++counter אינה אטומית (היא מורכבת מקריאה, הוספה וכתיבה). מאחר ששני החוטים ניגשים ומשנים את אותו משתנה ללא סנכרון (למשל ללא Mutex), ייתכן שחוט אחד יקרא ערך ישן לפני שהשני הספיק לעדכן אותו. לכן, הפלט כמעט תמיד יהיה קטן מ-2,000,000, והוא אינו דטרמיניסטי."}, "difficulty_estimation": "Medium", "_source_file": "0108__Threads__Open__Medium.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:41:05", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Threads", "User-level Threads", "Kernel-level Threads", "Blocking I/O"], "content": {"text": "שקלו מערכת המריצה תהליך עם שלושה חוטים (Threads) המבצעים את הפעולות המתוארות בקוד הבא. נניח שחוט 2 מבצע קריאה חוסמת (blocking read) מקובץ גדול הנמצא על הדיסק.", "code_snippet": "void* thread_1_work(void* arg) { \n    while(1) { /* Compute intensive math */ } \n}\n\nvoid* thread_2_work(void* arg) { \n    int fd = open(\"large_file.dat\", O_RDONLY);\n    read(fd, buffer, 1000000); // Blocking I/O call\n    close(fd);\n}\n\nvoid* thread_3_work(void* arg) { \n    printf(\"Status: Working...\\n\"); \n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "במידה והספרייה לניהול חוטים ממומשת במודל Many-to-One (User-level threads), האם חוט 1 יוכל להמשיך בחישוביו בזמן שחוט 2 ממתין לנתונים מהדיסק? נמקו.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "במידה והמערכת משתמשת במודל One-to-One (Kernel-level threads), מה יהיה מצבם של חוט 1 וחוט 3 בזמן שחוט 2 חסום?", "code_snippet": null, "options": null}, {"id": "10.3", "text": "ציינו יתרון אחד של מודל Many-to-One על פני מודל One-to-One, למרות המגבלה שהוצגה בסעיפים הקודמים.", "code_snippet": null, "options": null}], "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: לא, חוט 1 לא יוכל להמשיך לרוץ. במודל Many-to-One, מערכת ההפעלה אינה מודעת לקיום החוטים בתוך התהליך ורואה רק ישות תזמון אחת. כאשר חוט 2 מבצע קריאה חוסמת, הוא מבצע קריאת מערכת (system call) שגורמת לכל התהליך להיכנס למצב Waiting עד לסיום פעולת ה-I/O.\n\n10.2: במודל One-to-One, כל חוט משתמש בישות תזמון נפרדת של הקרנל. לכן, כאשר חוט 2 נחסם על פעולת I/O, רק הוא עובר למצב Waiting. חוט 1 יכול להמשיך לרוץ על המעבד (מצב Running) וחוט 3 יכול להיות מתוזמן להדפסה (מצב Ready/Running).\n\n10.3: יתרון מרכזי של Many-to-One הוא היעילות בניהול החוטים. יצירת חוט, החלפת הקשר (context switch) בין חוטים וסנכרון ביניהם מתבצעים במרחב המשתמש (User-space) ללא צורך במעבר למצב קרנל (trap/kernel mode), מה שהופך את הפעולות הללו למהירות משמעותית בהשוואה לניהול חוטים על ידי הקרנל."}, "difficulty_estimation": "Medium", "_source_file": "0109__Threads__Open__Medium.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:41:17", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Threads", "Concurrency", "Memory Management"], "content": {"text": "לפניך קוד בשפת C המשתמש בספריית pthreads. מטרת התוכנית היא ליצור 5 חוטים (threads), כאשר כל חוט מקבל את המזהה שלו (מספר בין 0 ל-4) ומדפיס אותו.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#define NUM_THREADS 5\n\nvoid* thread_func(void* arg) {\n    int id = *((int*)arg);\n    printf(\"Thread ID: %d\\n\", id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    for (int i = 0; i < NUM_THREADS; i++) {\n        pthread_create(&threads[i], NULL, thread_func, &i);\n    }\n    for (int i = 0; i < NUM_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "הסבר מדוע הקוד לעיל אינו תקין ועלול להדפיס פלט שאינו מכיל את כל המספרים 0 עד 4 (למשל, הדפסה של המספר 5 מספר פעמים).", "code_snippet": null, "options": null}, {"id": "7.2", "text": "הצע שתי דרכים שונות לתיקון הבעיה: אחת המשתמשת בהקצאה דינמית (malloc) ואחת המשתמשת בהעברת ערך ישירות דרך המצביע (Casting), מבלי להשתמש במנגנוני סנכרון כמו Mutex.", "code_snippet": null, "options": null}], "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1: הבעיה היא Race Condition על המשתנה i. כל החוטים מקבלים מצביע לאותה כתובת זיכרון (&i) הנמצאת במחסנית (stack) של פונקציית ה-main. מכיוון שהחוטים רצים במקביל ללולאת ה-for ב-main, ייתכן שעד שחוט מסוים ניגש לזיכרון כדי לקרוא את הערך, הלולאה כבר התקדמה והערך של i השתנה (או אפילו הגיע ל-5, התנאי לעצירת הלולאה).\n\n7.2: דרך א': הקצאה דינמית - בתוך הלולאה נקצה זיכרון עם malloc עבור כל מספר, נשמור בו את i ונעביר את המצביע ל-malloc. החוט יבצע free בסיום. דרך ב': העברת ערך ב-Casting - נמיר את הערך של i לטיפוס void* ונשלח אותו כארגומנט (למשל pthread_create(..., (void*)(long)i)). בתוך החוט נבצע המרה הפוכה מ-void* חזרה ל-int. בצורה זו כל חוט מקבל עותק של הערך בתוך ה-argument pointer עצמו ולא מצביע לכתובת משותפת."}, "difficulty_estimation": "Medium", "_source_file": "0110__Threads__Open__Medium.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:41:35", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Threads", "Concurrency", "Memory Management"], "content": {"text": "סטודנט כתב תוכנית ב-C המשתמשת בחוטים (threads) כדי להדפיס את המזהה של כל חוט. הקוד נראה כך:", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nvoid* print_id(void* arg) {\n    int id = *((int*)arg);\n    printf(\"My ID is: %d\\n\", id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[4];\n    for (int i = 0; i < 4; i++) {\n        pthread_create(&threads[i], NULL, print_id, &i);\n    }\n    for (int i = 0; i < 4; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "הסטודנט הריץ את התוכנית וקיבל את הפלט הבא: \nMy ID is: 1\nMy ID is: 2\nMy ID is: 4\nMy ID is: 4\nהסבירו מדוע התוכנית לא הדפיסה את המספרים 0 עד 3 בסדר כלשהו, ומהי הבעיה בגישה לזיכרון בקוד זה.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "הציעו שתי דרכים שונות לתיקון הבעיה (שינוי הקוד כך שכל חוט ידפיס בוודאות מזהה ייחודי מ-0 עד 3), והסבירו את היתרון/חיסרון של כל אחת.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "אם נזיז את הקריאה ל-pthread_join אל תוך הלולאה הראשונה (מיד לאחר ה-pthread_create), האם הבעיה תיפתר? מה תהיה ההשפעה על זמן הריצה הכולל של התוכנית?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: הבעיה היא race condition על המשתנה i. הסטודנט מעביר לכל חוט מצביע לאותו מיקום בזיכרון (הכתובת של i במחסנית של main). בזמן שהחוטים נוצרים ומתחילים לרוץ, הלולאה ב-main ממשיכה להתקדם ולשנות את הערך של i. לכן, חוט עשוי לקרוא את הערך של i לאחר שהוא כבר גדל. בדוגמה, חוטים מסוימים קראו את אותו ערך, וערך 0 לא נקרא בכלל כי הלולאה התקדמה לפני שהחוט הראשון הספיק לקרוא מהזיכרון.\n\n10.2: דרך א: העברת הערך עצמו על ידי casting. במקום &i, נעביר (void*)(long)i. בחוט נבצע casting חזרה ל-int. יתרון: אין צורך בניהול זיכרון נוסף. חיסרון: מסתמך על כך שגודל מצביע גדול או שווה לגודל int.\nדרך ב: הקצאת מערך של מזהים או הקצאה דינמית (malloc) לכל חוט בנפרד. יתרון: בטוח וגנרי לכל סוג מידע. חיסרון: דורש ניהול זיכרון (שחרור).\n\n10.3: כן, הבעיה תיפתר כי ה-main thread ימתין לסיום כל חוט לפני שיקדם את i באיטרציה הבאה. עם זאת, התוכנית תהפוך לסדרתית לחלוטין (Sequential) ולא יהיה כל ניצול של מקביליות, מה שיבטל את המטרה של שימוש בחוטים."}, "difficulty_estimation": "Medium", "_source_file": "0111__Threads__Open__Medium.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:41:49", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Threads", "User-level threads", "Kernel-level threads", "Concurrency"], "content": {"text": "סטודנט פיתח דפדפן אינטרנט פשוט המשתמש בספריית חוטים (threads) ברמת המשתמש (User-level threads) במימוש של Many-to-One (כלומר, כל חוטי המשתמש ממופים לחוט ליבה יחיד).", "code_snippet": null, "options": null}, "sub_questions": [{"id": "7.1", "text": "מה יקרה כאשר אחד החוטים בדפדפן מבצע קריאת מערכת חוסמת (Blocking system call), כמו למשל קריאת נתונים מהרשת? הסבירו את ההשפעה על שאר החוטים בתהליך.", "code_snippet": null, "options": null}, {"id": "7.2", "text": "כיצד המעבר למודל של חוטי ליבה (Kernel-level threads) במודל One-to-One עשוי לשפר את ביצועי הדפדפן במקרה של פעולות קלט/פלט (I/O)?", "code_snippet": null, "options": null}, {"id": "7.3", "text": "נתון קטע הקוד הבא המשתמש ב-POSIX Threads. מה יהיה הפלט של התוכנית? הסבירו בקצרה את הקשר למרחב הכתובות של חוטים.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint global_val = 20;\n\nvoid* increment_func(void* arg) {\n    global_val += 10;\n    return NULL;\n}\n\nint main() {\n    pthread_t t1;\n    pthread_create(&t1, NULL, increment_func, NULL);\n    pthread_join(t1, NULL);\n    printf(\"Final value: %d\\n\", global_val);\n    return 0;\n}", "options": null}], "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1: במודל Many-to-One, מערכת ההפעלה רואה רק את תהליך הליבה היחיד. כאשר חוט משתמש מבצע קריאת מערכת חוסמת, הליבה מעבירה את כל התהליך למצב המתנה (Waiting/Blocked). כתוצאה מכך, כל שאר החוטים באותו תהליך ייחסמו ולא יוכלו לרוץ, גם אם הם מוכנים לביצוע פעולות חישוב.\n\n7.2: במודל One-to-One, כל חוט משתמש ממופה לחוט ליבה נפרד. אם חוט אחד מבצע קריאת מערכת חוסמת, הליבה חוסמת רק את חוט הליבה הספציפי הזה. המתזמן (Scheduler) של מערכת ההפעלה יכול להמשיך להריץ חוטים אחרים של אותו תהליך על מעבדים פנויים, מה שמאפשר מקביליות אמיתית ושיפור ביצועים.\n\n7.3: הפלט יהיה: Final value: 30. הסיבה היא שחוטים (Threads) בתוך אותו תהליך חולקים את אותו מרחב כתובות, ובפרט הם חולקים את סגמנט הנתונים (Data segment) שבו נמצאים משתנים גלובליים. לכן, השינוי שביצע חוט t1 במשתנה global_val נראה מיד לחוט הראשי (main thread) לאחר סיום הריצה (pthread_join)."}, "difficulty_estimation": "Medium", "_source_file": "0112__Threads__Open__Medium.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:42:02", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Threads", "Synchronization", "Condition Variables", "Deadlock"], "content": {"text": "במערכת הפעלה נתונה, ממומש מנגנון לניהול משאבים משותפים (Tokens). המנגנון מאפשר לתהליכונים לבקש מספר מסוים של אסימונים ולשחרר אותם בסיום השימוש. להלן קוד ה-C המממש את המנגנון באמצעות Pthreads:", "code_snippet": "#include <pthread.h>\n\nint available_tokens = 5;\npthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER;\npthread_cond_t c = PTHREAD_COND_INITIALIZER;\n\nvoid request_tokens(int n) {\n    pthread_mutex_lock(&m);\n    while (available_tokens < n) {\n        pthread_cond_wait(&c, &m);\n    }\n    available_tokens -= n;\n    pthread_mutex_unlock(&m);\n}\n\nvoid release_tokens(int n) {\n    pthread_mutex_lock(&m);\n    available_tokens += n;\n    pthread_cond_signal(&c);\n    pthread_mutex_unlock(&m);\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "הסבר מדוע השימוש ב-pthread_cond_signal בפונקציה release_tokens עלול להוביל למצב של Deadlock או הרעבה (Starvation) במערכת בה פועלים מספר תהליכונים המבקשים כמויות שונות של אסימונים. הדגם באמצעות תרחיש ספציפי.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "נניח שבתור למשתנה התנאי c ממתינים התהליכונים הבאים (לפי סדר הגעתם): T1 (מבקש 6 אסימונים), T2 (מבקש 2 אסימונים). כרגע available_tokens = 1. תהליכון T3 קורא ל-release_tokens(2). תאר את השתלשלות האירועים אם המימוש של pthread_cond_signal מעיר את התהליכון הראשון בתור (FIFO).", "code_snippet": null, "options": null}, {"id": "10.3", "text": "הצע שינוי מינימלי לקוד (שורת קוד אחת) שיפתור את הבעיה שהוצגה בסעיף 10.1, והסבר מדוע פתרון זה יעיל אך עלול להיות יקר מבחינת ביצועים.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: הבעיה נובעת מכך ש-pthread_cond_signal מעיר תהליכון אחד בלבד מהתור. אם התהליכון שהתעורר דורש יותר אסימונים ממה שיש כרגע ב-available_tokens, הוא יחזור לישון בתוך ה-while. הבעיה היא שהאות (signal) 'אבד' - ייתכן שישנם תהליכונים אחרים בתור שדרישתם קטנה יותר ויכלו להמשיך בריצה עם כמות האסימונים הנוכחית, אך הם לא התעוררו. אם כל התהליכונים שמשחררים אסימונים מסתמכים על signal בודד, המערכת עלולה להיתקע (Deadlock) למרות שיש מספיק משאבים.\n\n10.2: תרחיש: 1. available_tokens = 1. תהליכונים T1(6) ו-T2(2) ישנים בתור c. \n2. T3 משחרר 2 אסימונים: available_tokens מעודכן ל-3.\n3. T3 מבצע signal. לפי FIFO, התהליכון T1 מתעורר.\n4. T1 בודק את התנאי: 3 < 6, לכן הוא מבצע שוב wait וחוזר לישון.\n5. המשתנה available_tokens נשאר 3, אך T2 (שצריך רק 2) נשאר לישון כי אף אחד לא העיר אותו. המערכת במצב של Deadlock אם אין תהליכונים נוספים שיבצעו release.\n\n10.3: הפתרון הוא החלפת pthread_cond_signal(&c) ב-pthread_cond_broadcast(&c). פעולה זו תעיר את כל התהליכונים הממתינים. כל אחד מהם יבדוק את התנאי שלו בתורו (תחת הגנת המוטקס). מי שדרישתו נענית ימשיך, ומי שלא יחזור לישון. זה פותר את הבעיה כי מובטח שכל מי שיכול להתקדם יתעורר. החיסרון (Performance Overhead) הוא 'בעיית העדר' (Thundering Herd) - התעוררות המונית של תהליכונים שרובם יחזרו לישון מיד, מה שגורם להקשרים מיותרים (Context Switches) ותחרות על המוטקס."}, "difficulty_estimation": "Hard", "_source_file": "0113__Threads__Open__Hard.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:42:24", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Threads", "Process Management", "Synchronization"], "content": {"text": "לפניך קטע קוד בשפת C המשתמש בספריית pthreads. התוכנית מבצעת יצירת חוט (thread) ולאחר מכן מבצעת fork(). הנח כי כל הקריאות למערכת מצליחות וכי התזמון מתבצע בדיוק כפי שמתואר בהערות (ה-sleep מבטיח סדר פעולות מסוים).", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\npthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;\nint shared_data = 0;\n\nvoid* thread_work(void* arg) {\n    pthread_mutex_lock(&lock);\n    shared_data++;\n    sleep(5); // מחזיק את המנעול לזמן ממושך\n    pthread_mutex_unlock(&lock);\n    return NULL;\n}\n\nint main() {\n    pthread_t t1;\n    pthread_create(&t1, NULL, thread_work, NULL);\n    \n    sleep(1); // מבטיח ש-t1 יספיק לנעול את המוטקס\n\n    if (fork() == 0) {\n        // תהליך הבן\n        printf(\"Child process started...\\n\");\n        pthread_mutex_lock(&lock);\n        printf(\"Child: shared_data = %d\\n\", shared_data);\n        pthread_mutex_unlock(&lock);\n        return 0;\n    }\n\n    wait(NULL);\n    pthread_join(t1, NULL);\n    printf(\"Parent finished.\\n\");\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "האם תהליך הבן יצליח להדפיס את השורה \"Child: shared_data = 1\"? נמק את תשובתך תוך התייחסות למצב החוטים והמנעולים לאחר פעולת ה-fork().", "code_snippet": null, "options": null}, {"id": "10.2", "text": "כיצד ניתן להשתמש בפונקציה pthread_atfork() כדי לפתור את הבעיה שנוצרה? הסבר מה תפקיד כל אחד משלושת ה-handlers (prepare, parent, child).", "code_snippet": null, "options": null}, {"id": "10.3", "text": "נניח והמערכת הייתה משתמשת במודל Many-to-One (User-Level Threads) עבור ספריית ה-pthreads. כיצד הקריאה ל-sleep(5) בתוך thread_work הייתה משפיעה על ביצוע ה-fork() ב-main? הסבר.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: לא, תהליך הבן ייכנס למצב של Deadlock. כאשר מתבצע fork() בתהליך מרובה חוטים, רק החוט שקרא ל-fork() משוכפל לתהליך הבן. עם זאת, כל מצב הזיכרון (כולל המוטקסים) מועתק כפי שהוא. מכיוון שחוט t1 נעל את המוטקס לפני ה-fork, המוטקס בבן מועתק כשהוא במצב 'נעול'. מאחר וחוט t1 לא קיים בתהליך הבן, אין מי שישחרר את המנעול, והקריאה ל-pthread_mutex_lock בבן תחסום לעד.\n\n10.2: הפונקציה pthread_atfork(prepare, parent, child) מאפשרת לרשום פונקציות טיפול שיופעלו סביב ה-fork:\n- prepare: מופעלת בתהליך האב לפני ה-fork. שם ננעל את כל המוטקסים הרלוונטיים.\n- parent: מופעלת בתהליך האב לאחר ה-fork. שם נשחרר את המוטקסים.\n- child: מופעלת בתהליך הבן לאחר ה-fork. שם נשחרר את המוטקסים בתוך הכתובת של הבן (כך שהם יהיו פתוחים לשימוש בבן).\n\n10.3: במודל Many-to-One, כל החוטים של תהליך מסוים ממופים לחוט קרנל יחיד. אם חוט משתמש מבצע קריאת מערכת חוסמת (כמו sleep), הקרנל חוסם את כל תהליך המשתמש. לכן, thread_work יגרום לכל תהליך האב להיחסם ל-5 שניות, וה-main לא יגיע לקריאה ל-fork עד ש-t1 יסיים את ה-sleep וישחרר את המנעול. במקרה כזה, הבעיה מהסעיף הראשון לא תתרחש כי המנעול יהיה משוחרר בזמן ה-fork."}, "difficulty_estimation": "Hard", "_source_file": "0114__Threads__Open__Hard.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:42:49", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Threads", "Synchronization", "Read-Write Locks", "Starvation"], "content": {"text": "לפניך מימוש חלקי בשפת C למנגנון Read-Write Lock המשתמש ב-Mutex וב-Condition Variable. המטרה היא לאפשר למספר קוראים (Readers) לגשת למשאב בו-זמנית, אך לאפשר לכותב (Writer) אחד בלבד גישה בלעדית.\nענה על הסעיפים הבאים תוך פירוט והסבר.", "code_snippet": "typedef struct {\n    int readers;\n    int writer_active;\n    pthread_mutex_t lock;\n    pthread_cond_t cond;\n} rwlock_t;\n\nvoid read_lock(rwlock_t *rw) {\n    pthread_mutex_lock(&rw->lock);\n    while (rw->writer_active)\n        pthread_cond_wait(&rw->cond, &rw->lock);\n    rw->readers++;\n    pthread_mutex_unlock(&rw->lock);\n}\n\nvoid read_unlock(rwlock_t *rw) {\n    pthread_mutex_lock(&rw->lock);\n    rw->readers--;\n    if (rw->readers == 0)\n        pthread_cond_broadcast(&rw->cond);\n    pthread_mutex_unlock(&rw->lock);\n}\n\nvoid write_lock(rwlock_t *rw) {\n    pthread_mutex_lock(&rw->lock);\n    while (rw->writer_active || rw->readers > 0)\n        pthread_cond_wait(&rw->cond, &rw->lock);\n    rw->writer_active = 1;\n    pthread_mutex_unlock(&rw->lock);\n}\n\nvoid write_unlock(rwlock_t *rw) {\n    pthread_mutex_lock(&rw->lock);\n    rw->writer_active = 0;\n    pthread_cond_broadcast(&rw->cond);\n    pthread_mutex_unlock(&rw->lock);\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "האם המימוש הנתון סובל מבעיית הרעבה (Starvation)? אם כן, איזה סוג תהליכונים (קוראים או כותבים) עלול לסבול מהרעבה ובאילו תנאים?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "מדוע נעשה שימוש בלולאת while סביב הקריאה ל-pthread_cond_wait ולא בפקודת if? הסבר מה עלול לקרות אם נחליף את ה-while ב-if.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "נניח שהמערכת פועלת במודל תהליכונים Many-to-One (כלומר, כל תהליכוני המשתמש ממופים לתהליכון קרנל יחיד). תהליכון קורא מחזיק ב-lock ומבצע קריאת מערכת חוסמת (Blocking I/O) כגון read() מדיסק. כיצד הדבר ישפיע על תהליכון כותב הממתין ב-write_lock?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: כן, המימוש סובל מהרעבת כותבים (Writer Starvation). ב-read_lock, קורא חדש נחסם רק אם יש כותב פעיל (writer_active). אם יש קוראים פעילים וכותב ממתין ב-write_lock, קוראים חדשים שיגיעו יצליחו להעלות את rw->readers ולהיכנס למשאב, כי writer_active עדיין 0. אם זרם הקוראים הוא רציף, מספר הקוראים לעולם לא ירד ל-0, והכותב ימתין לנצח.\n\n1.2: השימוש ב-while הכרחי בגלל שתי סיבות: א. Spurious Wakeups - תהליכון עלול להתעורר מה-Condition Variable גם ללא שליחת סיגנל מפורש. ב. Mesa Semantics - ברגע שתהליכון מתעורר ומנסה לנעול את המוטקס מחדש, תהליכון אחר עלול 'להשתחל' ולשנות את התנאי (למשל, כותב אחר תפס את המשאב). לכן, יש לבדוק את התנאי שוב מיד עם החזרה מההמתנה.\n\n1.3: במודל Many-to-One, הקרנל אינו מודע לקיום תהליכוני המשתמש ורואה רק את תהליך ה-LWP היחיד. כאשר תהליכון משתמש מבצע קריאת מערכת חוסמת, כל התהליך (על כל תהליכוניו) נחסם ע\"י הקרנל. לכן, הכותב הממתין לא יוכל לקבל זמן מעבד אפילו אם הקורא סיים את פעולת ה-I/O, עד שהקרנל לא יחזיר את התהליך כולו למצב Ready."}, "difficulty_estimation": "Hard", "_source_file": "0115__Threads__Open__Hard.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:43:16", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Threads", "Process Management", "Synchronization", "Deadlock"], "content": {"text": "במערכות הפעלה מודרניות, השילוב בין יצירת תהליכים (fork) לבין שימוש בחוטים (threads) עשוי להוביל למצבים מורכבים ובעייתיים. לפניכם קוד C המדגים סיטואציה כזו. הניחו כי כל הקריאות למערכת מצליחות וכי התזמון מתבצע בדיוק כפי שמתואר בהערות (sleep).", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\npthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;\n\nvoid* thread_A(void* arg) {\n    pthread_mutex_lock(&lock);\n    printf(\"Thread A: Locked mutex, performing long task...\\n\");\n    sleep(10); \n    pthread_mutex_unlock(&lock);\n    return NULL;\n}\n\nvoid* thread_B(void* arg) {\n    sleep(1); // הבטחה שחוט א' יתפוס את המנעול קודם\n    printf(\"Thread B: Forking now...\\n\");\n    pid_t pid = fork();\n    \n    if (pid == 0) {\n        // תהליך הבן\n        printf(\"Child process: Attempting to lock mutex...\\n\");\n        pthread_mutex_lock(&lock);\n        printf(\"Child process: Success! Locked!\\n\");\n        pthread_mutex_unlock(&lock);\n    } else {\n        // תהליך האב\n        wait(NULL);\n        printf(\"Parent process: Child finished.\\n\");\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, thread_A, NULL);\n    pthread_create(&t2, NULL, thread_B, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "האם תהליך הבן יצליח להדפיס את השורה \"Child process: Success! Locked!\"? נמקו את תשובתכם תוך התייחסות למה שקורה לחוטים (Threads) ולמבני הנתונים בזיכרון בזמן ביצוע fork().", "code_snippet": null, "options": null}, {"id": "10.2", "text": "כיצד מנגנון ה-Copy-on-Write (COW) משפיע על מצב המנעול (mutex) בזיכרון של תהליך הבן ברגע ה-fork?", "code_snippet": null, "options": null}, {"id": "10.3", "text": "הציעו פתרון המשתמש בפונקציה pthread_atfork. הסבירו מה תפקידן של שלוש פונקציות ה-callback (prepare, parent, child) וכיצד הן מונעות את הבעיה שהתגלתה בסעיף 10.1.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: לא, תהליך הבן ייכנס למצב של Deadlock (קיפאון). כאשר מתבצע fork() בתהליך מרובה חוטים, רק החוט שקרא ל-fork() משוכפל בתהליך הבן. כל שאר החוטים (במקרה זה Thread A) אינם קיימים בבן. מכיוון ש-Thread A החזיק במנעול בזמן ה-fork, המנעול מועתק לבן כשהוא במצב 'תפוס' (Locked). מכיוון ש-Thread A לא קיים בבן כדי לשחרר את המנעול, החוט היחיד בבן ימתין לנצח.\n\n10.2: מנגנון ה-COW מבטיח שכל מרחב הכתובות, כולל מצב המנעול בזיכרון, יועתק לוגית לבן. בזיכרון הפיזי, עד שלא יבוצע שינוי, הבן והאב חולקים את אותם דפים. לכן, ביט ה-lock בתוך מבנה הנתונים של ה-mutex יועתק כשהוא דלוק (1). העובדה שמדובר בעותק נפרד (בסופו של דבר) לא עוזרת כאן, כי המצב הפנימי של האובייקט מעיד על כך שהוא תפוס על ידי ישות שאינה קיימת בבן.\n\n10.3: הפונקציה pthread_atfork מאפשרת לרשום פונקציות שירוצו בנקודות זמן קריטיות סביב ה-fork:\n1. prepare: רצה באב לפני ה-fork. עליה לנעול את המנעול (pthread_mutex_lock) כדי להבטיח מצב עקבי.\n2. parent: רצה באב אחרי ה-fork. עליה לשחרר את המנעול (pthread_mutex_unlock).\n3. child: רצה בבן אחרי ה-fork. עליה לשחרר את המנעול או לאתחל אותו מחדש. \nבצורה זו, מובטח שבזמן השכפול המנעול מוחזק ע\"י החוט המבצע, ולכן בבן הוא 'ישתחרר' בצורה מסודרת ע\"י פונקציית ה-child."}, "difficulty_estimation": "Hard", "_source_file": "0116__Threads__Open__Hard.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:43:37", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Threads", "Synchronization", "Process Management", "Deadlock"], "content": {"text": "נתון קטע הקוד הבא בשפת C המשתמש בספריית pthreads ובפקודת המערכת fork. הנח כי התוכנית רצה על מערכת Linux מודרנית וכי כל הקריאות למערכת (pthread_create, fork) מצליחות. ענה על הסעיפים הבאים תוך פירוט ונימוק מלא.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\npthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;\nint counter = 100;\n\nvoid* thread_work(void* arg) {\n    pthread_mutex_lock(&lock);\n    counter += 50;\n    sleep(20); // Hold the lock for a long time\n    pthread_mutex_unlock(&lock);\n    return NULL;\n}\n\nint main() {\n    pthread_t t1;\n    pthread_create(&t1, NULL, thread_work, NULL);\n    \n    sleep(2); // Ensure thread_work starts and acquires the lock\n    \n    pid_t pid = fork();\n    if (pid == 0) {\n        // Child process\n        printf(\"Child: Attempting to lock...\\n\");\n        pthread_mutex_lock(&lock);\n        counter += 10;\n        printf(\"Child counter: %d\\n\", counter);\n        pthread_mutex_unlock(&lock);\n    } else {\n        // Parent process\n        wait(NULL);\n        printf(\"Parent counter: %d\\n\", counter);\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "כמה תהליכים וכמה חוטים (threads) סה\"כ יהיו קיימים במערכת מיד לאחר ביצוע שורת ה-fork? פרט כמה בכל תהליך.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "האם תהליך הבן יצליח להדפיס את השורה \"Child counter: ...\"? הסבר את המנגנון הגורם לכך/מונע זאת.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "נניח שהורדנו את השורה (pthread_mutex_lock(&lock)) ואת ה-unlock מתהליך הבן. מה יהיה הפלט של תהליך האב ומה יהיה הפלט של תהליך הבן? התייחס למנגנון ה-Copy-on-Write.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: לאחר ה-fork יהיו 2 תהליכים. בתהליך האב יהיו 2 חוטים (החוט הראשי והחוט t1 שנוצר). בתהליך הבן יהיה חוט אחד בלבד. זאת מכיוון שעל פי תקן POSIX, כאשר תהליך מרובה חוטים מבצע fork, רק החוט שקרא ל-fork משוכפל לתהליך הבן. שאר החוטים אינם קיימים בבן.\n\n1.2: לא, תהליך הבן לא ידפיס את השורה. הוא ייכנס למצב של Deadlock. הסיבה היא שה-mutex משוכפל כחלק ממרחב הזיכרון של התהליך. מכיוון שבאב החוט t1 החזיק בנעילה בזמן ה-fork, ה-mutex משוכפל לבן כשהוא במצב 'נעול'. אולם, החוט שהחזיק בנעילה (t1) לא קיים בתהליך הבן, ולכן אין אף חוט שיכול לשחרר את הנעילה. החוט היחיד בבן ימתין לנצח ב-pthread_mutex_lock.\n\n1.3: אם נסיר את הנעילה בבן, הבן ידפיס: 'Child counter: 160' (הוא יורש את ה-counter מהאב אחרי ש-t1 כבר הוסיף 50, ואז מוסיף 10 משלו). האב ידפיס: 'Parent counter: 150'. למרות שהמשתנה גלובלי, fork יוצר מרחב כתובות נפרד. בתחילה שני התהליכים מצביעים לאותם דפים פיזיים (Copy-on-Write), אך ברגע שהבן מבצע כתיבה (counter += 10), נוצר עותק פרטי של הדף עבורו, ולכן השינוי בבן לא משפיע על האב."}, "difficulty_estimation": "Hard", "_source_file": "0117__Threads__Open__Hard.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:43:55", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Threads", "Synchronization", "Mutex", "Condition Variables"], "content": {"text": "לפניכם קוד בשפת C המשתמש בספריית pthreads לניהול סנכרון בין תהליכונים. במערכת קיימים שני סוגי תהליכונים: 'Increasers' המעלים מונה משותף, ו-'Checkers' הממתינים שהמונה יגיע לערך סף N ואז מפחיתים ממנו. הנח כי כל הקריאות לפונקציות pthreads מצליחות ושאין בעיות זיכרון.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#define N 5\nint counter = 0;\npthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;\npthread_cond_t cond = PTHREAD_COND_INITIALIZER;\n\nvoid* increaser(void* arg) {\n    for(int i = 0; i < 1000; i++) {\n        pthread_mutex_lock(&lock);\n        counter++;\n        if (counter >= N) {\n            pthread_cond_broadcast(&cond);\n        }\n        pthread_mutex_unlock(&lock);\n    }\n    return NULL;\n}\n\nvoid* checker(void* arg) {\n    pthread_mutex_lock(&lock);\n    while (counter < N) {\n        pthread_cond_wait(&cond, &lock);\n    }\n    counter -= N;\n    pthread_mutex_unlock(&lock);\n    return NULL;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "מה יהיה הערך הסופי של המשתנה הגלובלי `counter` אם נריץ 10 תהליכוני `increaser` ו-2 תהליכוני `checker`, בהנחה שכל התהליכונים סיימו את ביצועם? פרטו את החישוב.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "מדוע נעשה שימוש בלולאת `while` בשורה `while (counter < N)` בתוך פונקציית ה-`checker`? תארו תרחיש ספציפי (interleaving) שבו החלפת ה-`while` ב-`if` תוביל למצב שבו `counter` יהיה שלילי.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "נניח שהחלפנו את `pthread_cond_broadcast` ב-`pthread_cond_signal`. האם ייתכן מצב שבו תהליכון `checker` ימתין לנצח (Deadlock/Starvation) למרות שהתנאי `counter >= N` התקיים בשלב כלשהו? הסבירו.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: כל תהליכון increaser מבצע 1000 הגדלות. ישנם 10 תהליכונים כאלו, לכן סה\"כ יתבצעו 10,000 הגדלות (10 * 1000). כל תהליכון checker מבצע הפחתה אחת של הערך N (שהוא 5). ישנם 2 תהליכונים כאלו, לכן סה\"כ יופחתו 10 (2 * 5). הערך הסופי יהיה: 10,000 - 10 = 9,990.\n\n1.2: השימוש ב-while הכרחי בגלל Mesa Semantics. תרחיש שבו if יכשל: נניח ש-counter=4. שני תהליכוני checker (נקרא להם C1 ו-C2) נכנסים להמתנה ב-cond_wait. תהליכון increaser מעלה את המונה ל-5 וקורא ל-broadcast. שני ה-checkers מתעוררים ומנסים להשיג את ה-mutex. C1 משיג את ה-mutex ראשון, בודק את התנאי (שכבר נבדק לפני ה-wait), מפחית 5 מהמונה (counter=0) ומשחרר את ה-mutex. כעת C2 משיג את ה-mutex. אם היה נעשה שימוש ב-if, הוא היה ממשיך ישר להפחתה ומחסיר 5 מ-0, מה שמוביל ל-counter=-5. שימוש ב-while מכריח את C2 לבדוק שוב את התנאי, לגלות שהוא שוב קטן מ-N ולחזור להמתין.\n\n1.3: כן. במצב שבו יש מספר checkers הממתינים, signal מעיר רק תהליכון אחד. אם התהליכון שהתעורר לא מצליח לסיים את עבודתו (למשל, אם התנאי השתנה שוב לפני שהשיג את ה-lock) או אם ישנם מספר checkers שצריכים להתעורר כדי לצרוך את המשאבים שהצטברו (למשל counter=10), שימוש ב-signal עלול להשאיר checkers אחרים ישנים לנצח למרות שהמשאב זמין. עם זאת, בקוד הספציפי הזה, הבעיה העיקרית ב-signal היא אובדן הודעות (Lost Wakeups) אם ה-signal נשלח כשאין אף אחד שממתין, אך כאן ה-broadcast מבטיח שכל מי שצריך להתעורר יתעורר."}, "difficulty_estimation": "Hard", "_source_file": "0118__Threads__Open__Hard.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:44:21", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Threads", "Process Management", "Synchronization", "Deadlock"], "content": {"text": "נתון קוד בשפת C המשתמש בספריית pthreads. התוכנית מדגימה אינטראקציה בין חוטים (threads) לבין יצירת תהליך חדש באמצעות fork. עליכם לנתח את התנהגות המערכת ולענות על השאלות הבאות. הניחו כי כל הקריאות למערכת מצליחות וכי התזמון מתבצע בדיוק כפי שמתואר ב-sleep.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n#include <sys/wait.h>\n\nint counter = 0;\npthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;\n\nvoid* thread_func(void* arg) {\n    pthread_mutex_lock(&lock);\n    counter++;\n    sleep(10); // מדמה עבודה ממושכת תחת נעילה\n    pthread_mutex_unlock(&lock);\n    return NULL;\n}\n\nint main() {\n    pthread_t t1;\n    pthread_create(&t1, NULL, thread_func, NULL);\n    sleep(1); // מבטיח שהחוט t1 התחיל ונעל את המוטקס\n\n    int pid = fork();\n    if (pid == 0) {\n        // תהליך הבן\n        printf(\"Child: Attempting to lock...\\n\");\n        pthread_mutex_lock(&lock);\n        printf(\"Child: Counter is %d\\n\", counter);\n        pthread_mutex_unlock(&lock);\n        return 0;\n    } else {\n        // תהליך האב\n        wait(NULL);\n        printf(\"Parent: Finished\\n\");\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "האם תהליך הבן ידפיס את השורה \"Child: Counter is 1\"? נמקו את תשובתכם תוך התייחסות למצב ה-Mutex ולמבנה התהליך בבן.", "code_snippet": null, "options": null}, {"id": "7.2", "text": "מה יקרה לתהליך האב במקרה זה? האם הוא יגיע להדפסה \"Parent: Finished\"?", "code_snippet": null, "options": null}, {"id": "7.3", "text": "כיצד שימוש בפונקציה pthread_atfork יכול לפתור את הבעיה? הסבירו את תפקיד שלושת ה-callbacks שהיא מקבלת.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1: לא, תהליך הבן לא ידפיס את השורה. ב-POSIX, כאשר תהליך המכיל מספר חוטים מבצע fork, רק החוט שקרא ל-fork משוכפל לתהליך הבן. החוט thread_func שביצע את הנעילה אינו קיים בבן. עם זאת, ה-fork מעתיק את כל מרחב הכתובות כפי שהוא, כולל את מצב ה-Mutex. מכיוון שהמוטקס היה נעול באב ברגע ה-fork, הוא מועתק כשהוא במצב 'נעול' לבן. כיוון שהחוט היחיד שיכול לשחרר את הנעילה (thread_func) לא קיים בבן, הבן ייכנס למצב של Deadlock בניסיון לנעול את המוטקס.\n\n7.2: תהליך האב לא יסיים את ריצתו. האב קורא ל-wait(NULL) וממתין לסיום תהליך הבן. מכיוון שתהליך הבן תקוע ב-Deadlock ולעולם לא יסתיים, האב יישאר במצב המתנה (Blocked) לנצח.\n\n7.3: הפונקציה pthread_atfork מאפשרת לרשום handlers שירוצו בנקודות זמן קריטיות סביב ה-fork: \n1. prepare: רץ באב לפני ה-fork. שם ננעל את כל המוטקסים כדי להבטיח מצב עקבי.\n2. parent: רץ באב מיד אחרי ה-fork. שם נשחרר את המוטקסים.\n3. child: רץ בבן מיד אחרי ה-fork. שם נשחרר (re-initialize/unlock) את המוטקסים כדי שהבן יתחיל עם מוטקסים פתוחים ויוכל להשתמש בהם."}, "difficulty_estimation": "Hard", "_source_file": "0119__Threads__Open__Hard.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:44:44", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Threads", "Synchronization", "Race Conditions", "Pthreads"], "content": {"text": "לפניכם מימוש בשפת C של מנגנון 'מחסום' (Barrier) המיועד לשימוש על ידי N תהליכונים (Threads). המטרה היא שכל תהליכון ימתין בנקודת המחסום עד שכל ה-N תהליכונים יגיעו אליה, ורק אז כולם ימשיכו בביצוע. המתכנת מעוניין שהמחסום יהיה 'רב-פעמי' (Reusable), כלומר שניתן יהיה להשתמש בו בלולאה.", "code_snippet": "int count = 0;\npthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER;\npthread_cond_t cv = PTHREAD_COND_INITIALIZER;\n\nvoid barrier_wait(int N) {\n    pthread_mutex_lock(&m);\n    count++;\n    if (count == N) {\n        count = 0;\n        pthread_cond_broadcast(&cv);\n    } else {\n        pthread_cond_wait(&cv, &m);\n    }\n    pthread_mutex_unlock(&m);\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "נניח שהתהליכונים מריצים את הפונקציה הבאה: \nvoid* worker(void* arg) {\n    for(int i=0; i<100; i++) {\n        // Do some work\n        barrier_wait(N);\n    }\n    return NULL;\n}\nהסבירו מדוע המימוש הנתון של barrier_wait אינו תקין עבור שימוש חוזר (reusable barrier) ועלול לגרום לקיפאון (Deadlock) או להתנהגות לא צפויה.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "כיצד תופעת ה-Spurious Wakeup משפיעה על הקוד הנתון? הציעו תיקון לקוד הקיים (ברמת הלוגיקה) שפותר גם את בעיית ה-Spurious Wakeup וגם את בעיית השימוש החוזר.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "6.1: הבעיה המרכזית במימוש היא ה-Race Condition שנוצר בין איטרציות שונות של הלולאה. כאשר התהליכון ה-N מגיע, הוא מאפס את count ל-0 ומבצע broadcast. תהליכון 'מהיר' עשוי להתעורר, לסיים את barrier_wait, לבצע את העבודה של האיטרציה הבאה ולקרוא שוב ל-barrier_wait לפני שתהליכון 'איטי' מהאיטרציה הקודמת בכלל הצליח להתעורר או לצאת מהפונקציה. התהליכון המהיר יקדם את count ל-1, בעוד שתהליכונים אחרים עדיין שייכים ל'סיבוב' הקודם. במצב קיצוני, תהליכון מהיר יכול להשלים סיבוב שלם ולגרום ל-broadcast נוסף בזמן שתהליכונים מהסיבוב הקודם עדיין מחכים, מה שיגרום לערבוב של תהליכונים מאיטרציות שונות וסיכוי גבוה לקיפאון (Deadlock) כי ה-count לא ישקף נכונה את מספר המחכים לסיבוב הנוכחי.\n\n6.2: Spurious Wakeup היא תופעה בה תהליכון מתעורר מ-pthread_cond_wait ללא קבלת סיגנל. בקוד הנתון, אם תהליכון מתעורר בטעות לפני ש-count == N, הוא ימשיך לביצוע (Phase 2) למרות ששאר התהליכונים טרם הגיעו. הפתרון המקובל הוא עטיפת ה-wait בלולאת while. \nכדי לפתור את שתי הבעיות (כולל ה-reusable barrier), ניתן להשתמש בטכניקה של 'דורות' (Generations) או Sense-Reversing Barrier. בשיטה זו, מחזיקים משתנה נוסף המייצג את הדור הנוכחי. תהליכון מחכה עד שהדור משתנה: \nvoid barrier_wait(int N) {\n    pthread_mutex_lock(&m);\n    int my_gen = generation;\n    count++;\n    if (count == N) {\n        count = 0;\n        generation++;\n        pthread_cond_broadcast(&cv);\n    } else {\n        while (my_gen == generation)\n            pthread_cond_wait(&cv, &m);\n    }\n    pthread_mutex_unlock(&m);\n}\nכך, גם אם תהליכון מהיר נכנס שוב, הוא יגדיל את count עבור הדור הבא, בעוד שהתהליכונים האיטיים מחכים לשינוי ב-generation."}, "difficulty_estimation": "Hard", "_source_file": "0120__Threads__Open__Hard.json", "_topic_hint": "Threads", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:45:03", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Concurrency", "Race Condition"], "content": {"text": "לפניכם קוד בשפת C המשתמש בספריית pthreads. נניח שכל הקריאות למערכת מצליחות והתוכנית רצה על מערכת עם מעבד מרובה ליבות. מה ניתן לומר על הפלט של התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint count = 0;\n\nvoid* task(void* arg) {\n    for (int i = 0; i < 1000; i++) {\n        count++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, task, NULL);\n    pthread_create(&t2, NULL, task, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"%d\", count);\n    return 0;\n}", "options": ["הפלט יהיה תמיד 1000.", "הפלט יהיה תמיד 2000.", "הפלט יהיה בטווח [2, 2000] ולא ניתן לחיזוי מראש.", "התוכנית לא תעבור קומפילציה כי count הוא משתנה גלובלי."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "הפלט יהיה בטווח [2, 2000] ולא ניתן לחיזוי מראש.", "explanation": "הקוד מדגים מצב מרוץ (Race Condition). הפעולה ++count אינה פעולה אטומית (Atomic Operation) ברמת שפת המכונה; היא מורכבת משלושה שלבים: קריאת הערך מהזיכרון לרגיסטר, הוספת 1, וכתיבת הערך חזרה לזיכרון. מכיוון ששני החוטים (Threads) ניגשים לאותו משתנה גלובלי ומשנים אותו ללא מנגנון סנכרון (כמו Mutex), חוט אחד עלול לקרוא ערך ישן בזמן שהחוט השני מעדכן אותו, ובכך 'לדרוס' את העדכון של החוט השני. לכן, התוצאה הסופית אינה דטרמיניסטית ויכולה להיות כל ערך בין 2 ל-2000 (במקרים קיצוניים של תזמון)."}, "difficulty_estimation": "Easy", "_source_file": "0121__Threads__CodeAnalysis__Easy.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:45:20", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Threads", "Pthreads", "Shared Memory"], "content": {"text": "לפניך קטע קוד בשפת C המשתמש בספריית pthreads. מה יהיה הפלט של התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint shared_val = 5;\n\nvoid* thread_func(void* arg) {\n    int val = *((int*)arg);\n    shared_val += val;\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    int a = 10, b = 20;\n\n    pthread_create(&t1, NULL, thread_func, &a);\n    pthread_join(t1, NULL);\n\n    pthread_create(&t2, NULL, thread_func, &b);\n    pthread_join(t2, NULL);\n\n    printf(\"%d\", shared_val);\n    return 0;\n}", "options": ["5", "15", "25", "35"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "35", "explanation": "התוכנית מתחילה עם משתנה גלובלי shared_val שערכו 5. בשלב הראשון נוצר חוט t1 שמקבל את הערך 10 ומוסיף אותו ל-shared_val. מכיוון שמתבצע pthread_join מיד לאחר מכן, תהליך ה-main עוצר ומחכה ש-t1 יסיים. לאחר ש-t1 מסיים, ערכו של shared_val הוא 15. רק אז נוצר חוט t2 שמקבל את הערך 20 ומוסיף אותו ל-shared_val. שוב מתבצע join ולכן ה-main מחכה ל-t2. בסיום, shared_val שווה ל-35 והוא מודפס למסך. מכיוון שהצטרפות החוטים (join) נעשית באופן סדרתי, אין כאן מצב מרוץ (Race Condition) והתוצאה דטרמיניסטית."}, "difficulty_estimation": "Easy", "_source_file": "0122__Threads__CodeAnalysis__Easy.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:45:35", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Pthreads"], "content": {"text": "מה יהיה הפלט של התוכנית הבאה המשתמשת בספריית pthreads? הניחו כי כל הקריאות לספרייה מצליחות.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint counter = 5;\n\nvoid* task(void* arg) {\n    counter += 10;\n    return NULL;\n}\n\nint main() {\n    pthread_t t1;\n    pthread_create(&t1, NULL, task, NULL);\n    pthread_join(t1, NULL);\n    printf(\"%d\", counter);\n    return 0;\n}", "options": ["5", "10", "15", "ערך לא ידוע עקב Race Condition"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "15", "explanation": "התוכנית יוצרת חוט (Thread) חדש שמבצע את הפונקציה task. פונקציה זו מוסיפה 10 למשתנה הגלובלי counter, שערכו ההתחלתי הוא 5. מכיוון שהתהליך הראשי קורא ל-pthread_join, הוא ממתין לסיום הביצוע של חוט t1 לפני שהוא ממשיך לשורת ההדפסה. לכן, מובטח כי הפעולה בחוט תסתיים לפני ה-printf, והתוצאה תהיה 15. אין כאן Race Condition על אף הגישה למשתנה משותף, כיוון שה-join מסנכרן את סדר הפעולות."}, "difficulty_estimation": "Easy", "_source_file": "0123__Threads__CodeAnalysis__Easy.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:45:45", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Shared Memory"], "content": {"text": "נתון קטע הקוד הבא בשפת C המשתמש בספריית pthreads. מה יהיה הפלט של התוכנית בהנחה שכל הקריאות למערכת מצליחות?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint x = 10;\n\nvoid* thread_func(void* arg) {\n    x += 5;\n    return NULL;\n}\n\nint main() {\n    pthread_t t;\n    pthread_create(&t, NULL, thread_func, NULL);\n    pthread_join(t, NULL);\n    printf(\"%d\", x);\n    return 0;\n}", "options": ["5", "10", "15", "0"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "15", "explanation": "התוכנית מגדירה משתנה גלובלי x המאותחל ל-10. חוטים (threads) באותו תהליך חולקים את אותו מרחב כתובות, ולכן לחוט החדש שנוצר יש גישה ישירה למשתנה x. הפונקציה thread_func מוסיפה 5 לערך של x. הפונקציה pthread_join גורמת לחוט הראשי (main) להמתין עד שהחוט החדש יסיים את פעולתו לפני שהוא ממשיך לשורת ההדפסה. לכן, בזמן הקריאה ל-printf, הערך של x כבר עודכן ל-15."}, "difficulty_estimation": "Easy", "_source_file": "0124__Threads__CodeAnalysis__Easy.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:46:05", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בספריית pthreads. מה יהיה הפלט של התוכנית בהנחה שכל קריאות המערכת מצליחות?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint x = 10;\n\nvoid* my_thread(void* arg) {\n    x = x * 2;\n    return NULL;\n}\n\nint main() {\n    pthread_t t;\n    pthread_create(&t, NULL, my_thread, NULL);\n    pthread_join(t, NULL);\n    printf(\"%d\", x);\n    return 0;\n}", "options": ["10", "20", "0", "הפלט אינו קבוע"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "20", "explanation": "התוכנית מגדירה משתנה גלובלי x המשותף לכל החוטים בתהליך. חוט חדש נוצר ומבצע הכפלה של x ב-2. הפונקציה pthread_join גורמת לחוט הראשי (main) להמתין עד לסיום ביצועו של החוט החדש. לכן, ההדפסה תתבצע רק לאחר ש-x עודכן ל-20."}, "difficulty_estimation": "Easy", "_source_file": "0125__Threads__CodeAnalysis__Easy.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:46:16", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Shared Memory"], "content": {"text": "מה יהיה הפלט של התוכנית הבאה המשתמשת בחוטים (threads)? הניחו שכל הקריאות למערכת מצליחות.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint counter = 10;\n\nvoid* func(void* arg) {\n    counter += 5;\n    return NULL;\n}\n\nint main() {\n    pthread_t t1;\n    pthread_create(&t1, NULL, func, NULL);\n    pthread_join(t1, NULL);\n    printf(\"%d\", counter);\n    return 0;\n}", "options": ["5", "10", "15", "הפלט אינו קבוע"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "15", "explanation": "התוכנית מגדירה משתנה גלובלי בשם counter עם ערך התחלתי 10. בתוך ה-main נוצר חוט (thread) חדש המריץ את הפונקציה func, אשר מוסיפה 5 למשתנה הגלובלי. מכיוון שהתהליך הראשי קורא ל-pthread_join, הוא ממתין עד לסיום ביצוע החוט t1 לפני שהוא ממשיך לשורת ההדפסה. לכן, מובטח שהשינוי למשתנה counter יתבצע לפני ההדפסה, והתוצאה תהיה 15."}, "difficulty_estimation": "Easy", "_source_file": "0126__Threads__CodeAnalysis__Easy.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:46:26", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Concurrency", "Race Conditions"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בספריית pthreads. מהם הערכים האפשריים שיכולים להיות מודפסים ע\"י פקודת ה-printf בסיום ריצת התוכנית?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0;\n\nvoid* thread_func(void* arg) {\n    int temp = counter;\n    counter = temp + 1;\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, thread_func, NULL);\n    pthread_create(&t2, NULL, thread_func, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"%d\", counter);\n    return 0;\n}", "options": ["0", "1", "2", "1 או 2"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "1 או 2", "explanation": "הקוד יוצר שני חוטים (threads) הניגשים לאותו משתנה גלובלי (counter) ללא שימוש במנגנוני סנכרון כמו Mutex. במצב שבו החוטים רצים אחד אחרי השני באופן מלא, הערך הסופי יהיה 2. אולם, ייתכן מצב של Race Condition שבו שני החוטים קוראים את הערך ההתחלתי 0 לתוך המשתנה המקומי temp, שניהם מחשבים temp + 1 = 1, ושניהם כותבים את הערך 1 חזרה למשתנה הגלובלי. במקרה כזה, אחת מההגדלות תאבד והפלט יהיה 1."}, "difficulty_estimation": "Easy", "_source_file": "0127__Threads__CodeAnalysis__Easy.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:46:49", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Threads", "Shared Memory"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בספריית pthreads. מה יהיה הפלט של התוכנית בהנחה שכל קריאות המערכת מצליחות?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint global_var = 20;\n\nvoid* thread_routine(void* arg) {\n    global_var += 30;\n    return NULL;\n}\n\nint main() {\n    pthread_t tid;\n    if (pthread_create(&tid, NULL, thread_routine, NULL) != 0) {\n        return 1;\n    }\n    pthread_join(tid, NULL);\n    printf(\"%d\", global_var);\n    return 0;\n}", "options": ["20", "30", "50", "הפלט אינו דטרמיניסטי"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "50", "explanation": "בניגוד לתהליכים הנוצרים על ידי fork, חוטים (threads) בתוך אותו תהליך חולקים את אותו מרחב כתובות, ובפרט את המשתנים הגלובליים. החוט שנוצר ב-pthread_create ניגש למשתנה global_var ומעדכן אותו ל-50 (20+30). מכיוון שהחוט הראשי קורא ל-pthread_join, הוא ממתין לסיום ביצוע החוט השני לפני שהוא ממשיך להדפסה, ולכן יודפס הערך המעודכן 50."}, "difficulty_estimation": "Easy", "_source_file": "0128__Threads__CodeAnalysis__Easy.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:47:04", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Concurrency", "Memory Sharing", "Pthreads"], "content": {"text": "לפניך קטע קוד בשפת C המשתמש בספריית pthreads. מה מהבאים מתאר נכונה את הפלטים האפשריים של התוכנית? הניחו כי כל הקריאות למערכת מצליחות.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n\nvoid* print_val(void* arg) {\n    int val = *((int*)arg);\n    printf(\"%d\", val);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[3];\n    for (int i = 0; i < 3; i++) {\n        pthread_create(&threads[i], NULL, print_val, &i);\n    }\n    for (int i = 0; i < 3; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    return 0;\n}", "options": ["א. הפלט תמיד יהיה 012 (בסדר כלשהו).", "ב. הפלט תמיד יהיה 333.", "ג. ייתכנו פלטים כמו 123, 333, או 023.", "ד. התוכנית תדפיס תמיד 000 כיוון שזה הערך ההתחלתי של i."]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הבעיה המרכזית בקוד היא שכל שלושת החוטים (threads) מקבלים כארגומנט את הכתובת של אותו משתנה מקומי i (כלומר &i). כיוון שהחוטים רצים במקביל ללולאת ה-main, הערך בכתובת זו עשוי להשתנות על ידי לולאת ה-for בטרם החוט הספיק לקרוא אותו. בסיום הלולאה הראשונה, ערכו של i הוא 3. לכן, כל חוט עשוי לקרוא כל ערך ש-i קיבל במהלך הריצה (0, 1, 2) או את הערך הסופי (3), תלוי בתזמון (scheduling) של החוטים ביחס ללולאה ב-main. לכן פלטים המכילים 3 או חזרות על מספרים הם אפשריים בהחלט."}, "difficulty_estimation": "Medium", "_source_file": "0129__Threads__CodeAnalysis__Medium.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:47:17", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Race Conditions", "Concurrency"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בספריית pthreads. בתוכנית זו, שני חוטים ניגשים למשתנה גלובלי משותף x ומעדכנים אותו ללא שימוש במנגנוני סנכרון (כגון Mutex). מהו הערך המינימלי האפשרי שיודפס על המסך בסיום ריצת התוכנית? הניחו שפעולת העדכון x = x + y מורכבת משלושה שלבים: קריאת הערך של x מהזיכרון לאוגר, הוספת y לאוגר, וכתיבת הערך מהאוגר חזרה לזיכרון.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint x = 10;\n\nvoid* thread_func(void* arg) {\n    int y = *(int*)arg;\n    x = x + y;\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    int val1 = 5, val2 = 10;\n    pthread_create(&t1, NULL, thread_func, &val1);\n    pthread_create(&t2, NULL, thread_func, &val2);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"%d\\n\", x);\n    return 0;\n}", "options": ["א. 10", "ב. 15", "ג. 20", "ד. 25"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הערך ההתחלתי של x הוא 10. חוט t1 אמור להוסיף 5 (סך הכל 15) וחוט t2 אמור להוסיף 10 (סך הכל 20). ללא סנכרון, תיתכן תחרות (Race Condition). הערך המינימלי מתקבל בתרחיש הבא: 1. חוט t1 קורא את הערך x=10 לתוך אוגר מקומי. 2. מתבצעת החלפת הקשר (Context Switch) וחוט t2 רץ במלואו: הוא קורא 10, מוסיף 10 וכותב 20 ל-x. 3. חוט t1 ממשיך מהנקודה שעצר: באוגר שלו עדיין שמור הערך 10, הוא מוסיף לו 5 וכותב את התוצאה 15 לתוך x. פעולה זו דורסת את העדכון של חוט t2. לכן, הערך המינימלי האפשרי הוא 15."}, "difficulty_estimation": "Medium", "_source_file": "0130__Threads__CodeAnalysis__Medium.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:47:49", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Pthreads", "Race Conditions", "Memory Sharing"], "content": {"text": "לפניכם קוד בשפת C המשתמש בספריית pthreads. התוכנית יוצרת שלושה חוטים (threads), כאשר כל חוט אמור להדפיס את אינדקס הלולאה שבו הוא נוצר. מה ניתן לומר על הפלט של התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nvoid* print_id(void* arg) {\n    int id = *(int*)arg;\n    printf(\"%d \", id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[3];\n    for (int i = 0; i < 3; i++) {\n        pthread_create(&threads[i], NULL, print_id, &i);\n    }\n    for (int i = 0; i < 3; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    return 0;\n}", "options": ["א. הפלט יהיה תמיד 0 1 2 בסדר כלשהו.", "ב. הפלט יהיה תמיד 0 1 2 בסדר עולה.", "ג. ייתכן שהפלט יכיל ערכים כפולים (למשל 1 1 2) או את הערך 3.", "ד. הקוד לא יתקמפל עקב ניסיון להעביר מצביע למשתנה מקומי.", "ה. הפלט יהיה תמיד 3 3 3."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הבעיה בקוד נובעת מכך שכל החוטים מקבלים כארגומנט את אותה הכתובת בזיכרון - הכתובת של המשתנה i שנמצא במחסנית של פונקציית ה-main. מכיוון שהחוטים רצים במקביל לחוט הראשי שמקדם את i, נוצר מצב של מרוץ (Race Condition). עד שחוט מסוים מספיק לבצע את ה-dereference למצביע שקיבל, ערכו של i ב-main כבר עשוי להשתנות. במקרה קיצון, אם ה-main מסיים את הלולאה לפני שמי מהחוטים התחיל לפעול, כולם עשויים להדפיס 3 (הערך שבו i עוצר את הלולאה). לכן, ייתכנו כפילויות וערכים מחוץ לטווח המקורי 0-2."}, "difficulty_estimation": "Medium", "_source_file": "0131__Threads__CodeAnalysis__Medium.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:48:15", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Pthreads", "Concurrency", "Race Conditions"], "content": {"text": "לפניך קטע קוד בשפת C המשתמש בספריית pthreads. מה ניתן לומר על הפלט של התוכנית בהרצה טיפוסית במערכת מרובת ליבות?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n\nvoid* thread_func(void* arg) {\n    int id = *(int*)arg;\n    printf(\"%d \", id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[4];\n    for (int i = 0; i < 4; i++) {\n        pthread_create(&threads[i], NULL, thread_func, &i);\n    }\n    for (int i = 0; i < 4; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    return 0;\n}", "options": ["א. הפלט יהיה תמיד 0 1 2 3 (בסדר כלשהו).", "ב. הפלט יהיה תמיד 4 4 4 4.", "ג. הפלט עשוי להכיל ספרות בין 0 ל-4, כאשר ייתכן שספרה מסוימת תודפס יותר מפעם אחת וספרה אחרת לא תודפס כלל.", "ד. התוכנית תגרום לשגיאת סגמנטציה (Segmentation Fault) כיוון שכל החוטים ניגשים לאותו משתנה i."]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הבעיה המרכזית בקוד היא העברת הכתובת של משתנה הלולאה i לכל החוטים. כיוון שכל החוטים חולקים את אותו מרחב כתובות, כל חוט מקבל מצביע לאותו מיקום בזיכרון (המחסנית של main). בזמן שחוט אחד נוצר ומתחיל את ריצתו, הלולאה ב-main ממשיכה לרוץ ומעדכנת את הערך של i. כתוצאה מכך, עד שחוט מסוים ניגש לזיכרון כדי לקרוא את הערך של id, הערך של i עשוי להשתנות. ייתכן שחוט יקרא את הערך 1, 2, 3 או אפילו 4 (אם הלולאה הסתיימה לפני שהחוט ניגש לזיכרון). לכן, הפלט אינו צפוי ויכול לכלול חזרות על מספרים."}, "difficulty_estimation": "Medium", "_source_file": "0132__Threads__CodeAnalysis__Medium.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:48:30", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Pthreads", "Concurrency"], "content": {"text": "לפניך קטע קוד בשפת C המשתמש בספריית pthreads. בהנחה שכל הקריאות למערכת מצליחות, וכי פעולת הקידום (count++) מתבצעת באופן אטומי (כלומר, אין איבוד עדכונים עקב Race Condition), מה יהיה הפלט של התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint count = 0;\n\nvoid* increment(void* arg) {\n    int limit = *(int*)arg;\n    for (int i = 0; i < limit; i++) {\n        count++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2, t3;\n    int val1 = 10, val2 = 20, val3 = 30;\n\n    pthread_create(&t1, NULL, increment, &val1);\n    pthread_join(t1, NULL);\n\n    pthread_create(&t2, NULL, increment, &val2);\n    pthread_create(&t3, NULL, increment, &val3);\n\n    pthread_join(t2, NULL);\n    pthread_join(t3, NULL);\n\n    printf(\"%d\", count);\n    return 0;\n}", "options": ["א. 30", "ב. 50", "ג. 60", "ד. 10", "ה. התוצאה אינה קבועה"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התוכנית מתחילה בביצוע ה-main. החוט הראשון (t1) נוצר עם הערך 10. פקודת ה-pthread_join(t1) גורמת לתהליך הראשי להמתין עד ש-t1 יסיים. בשלב זה count שווה ל-10. לאחר מכן, נוצרים שני חוטים נוספים (t2 ו-t3) כמעט במקביל. t2 מבצע 20 איטרציות ו-t3 מבצע 30 איטרציות. מכיוון שצוין בשאלה שיש להניח שאין Race Condition (פעולות אטומיות), הערך הסופי של count יהיה סכום כל ההוספות שבוצעו על ידי כל החוטים: 10 (מ-t1) + 20 (מ-t2) + 30 (מ-t3) = 60."}, "difficulty_estimation": "Medium", "_source_file": "0133__Threads__CodeAnalysis__Medium.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:48:46", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Pthreads", "Race Conditions", "Shared Memory"], "content": {"text": "לפניך קטע קוד בשפת C המשתמש בספריית pthreads. התוכנית יוצרת שלושה חוטים (threads), כאשר כל אחד מהם אמור להדפיס את המספר שקיבל כארגומנט ולעדכן מונה גלובלי. מה ניתן לומר על פלט התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint counter = 0;\n\nvoid* task(void* arg) {\n    int id = *(int*)arg;\n    printf(\"%d\", id);\n    counter++;\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[3];\n    for (int i = 0; i < 3; i++) {\n        pthread_create(&threads[i], NULL, task, &i);\n    }\n    for (int i = 0; i < 3; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    printf(\" C%d\", counter);\n    return 0;\n}", "options": ["א. הפלט תמיד יהיה הצירוף '012 C3' בסדר כלשהו של הספרות.", "ב. הפלט יהיה תמיד '333 C3'.", "ג. ייתכן שהפלט יכיל את הספרה 3, וייתכן שספרות מסוימות יופיעו יותר מפעם אחת (למשל '133 C2').", "ד. התוכנית תמיד תדפיס '012 C0' כי המונה לא מתעדכן בחוט הראשי.", "ה. תתרחש שגיאת סגמנטציה כיוון שהגישה לכתובת של i אינה מותרת מהחוטים."]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הקוד מדגים שתי בעיות סנכרון נפוצות: 1. העברת מצביע למשתנה מקומי (i) שערכו משתנה בחוט אחר. כל החוטים מקבלים את אותה כתובת בזיכרון. כיוון שהחוט הראשי ממשיך לרוץ ולקדם את i, בזמן שהחוטים החדשים ניגשים לכתובת זו, הערך בה עשוי להיות כל אחד מערכי הלולאה או ערך הסיום (3). לכן ייתכנו כפילויות או הופעה של הספרה 3. 2. קיימת תחרות (Race Condition) על המשתנה הגלובלי counter. הפעולה ++ אינה אטומית, ולכן אם שני חוטים ינסו לעדכן אותו בו-זמנית, ייתכן שעדכון אחד ידרס והערך הסופי יהיה קטן מ-3."}, "difficulty_estimation": "Medium", "_source_file": "0134__Threads__CodeAnalysis__Medium.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:49:10", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Race Conditions", "Concurrency", "Pthreads"], "content": {"text": "לפניך קטע קוד בשפת C המשתמש בספריית pthreads. התוכנית יוצרת שני חוטים (threads) המבצעים כל אחד 100 איטרציות של קידום משתנה גלובלי משותף `counter`. מהו הערך המינימלי האפשרי שיודפס על ידי הפקודה `printf` בסיום ריצת התוכנית?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint counter = 0;\n\nvoid* func(void* arg) {\n    for (int i = 0; i < 100; i++) {\n        int temp = counter;\n        counter = temp + 1;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, func, NULL);\n    pthread_create(&t2, NULL, func, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"%d\\n\", counter);\n    return 0;\n}", "options": ["א. 1", "ב. 2", "ג. 100", "ד. 200"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הפעולה counter = temp + 1 אינה אטומית, ולכן נוצר מרוץ תהליכים (Race Condition). הערך המינימלי האפשרי עבור שני חוטים המבצעים N קידומים כל אחד הוא 2. \nתרחיש לדוגמה המביא לערך 2: \n1. חוט א' קורא את הערך 0 לתוך temp ונרדם.\n2. חוט ב' רץ 99 איטרציות מלאות, ומעדכן את counter ל-99.\n3. חוט א' מתעורר, מחשב 0+1 וכותב ל-counter את הערך 1 (בכך הוא דורס את ה-99 של חוט ב').\n4. חוט ב' מתחיל את האיטרציה ה-100 שלו, קורא את הערך 1 לתוך temp ונרדם.\n5. חוט א' מתעורר ומבצע את כל 99 האיטרציות הנותרות שלו עד הסוף. הערך ב-counter יהיה כעת 100.\n6. חוט ב' מתעורר מהאיטרציה האחרונה שלו, מחשב 1+1 וכותב ל-counter את הערך 2 (בכך הוא דורס את ה-100 של חוט א')."}, "difficulty_estimation": "Medium", "_source_file": "0135__Threads__CodeAnalysis__Medium.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:49:26", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Concurrency", "Race Conditions", "Synchronization"], "content": {"text": "נתון קטע הקוד הבא בשפת C המשתמש בספריית pthreads. מה מהבאים נכון לגבי הפלט המודפס למסך? הניחו שכל הקריאות ל-pthread_create מצליחות ושהתהליכון הראשי (main) ממתין לסיום כל החוטים לפני ההדפסה.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint total = 0;\n\nvoid* task(void* arg) {\n    int val = *(int*)arg;\n    total += val;\n    return NULL;\n}\n\nint main() {\n    pthread_t t[2];\n    int i;\n    for (i = 1; i <= 2; i++) {\n        pthread_create(&t[i-1], NULL, task, &i);\n    }\n    for (int j = 0; j < 2; j++) {\n        pthread_join(t[j], NULL);\n    }\n    printf(\"%d\", total);\n    return 0;\n}", "options": ["א. הפלט יהיה תמיד 3", "ב. הפלט יהיה תמיד 6", "ג. הפלט יכול להיות כל מספר שלם בין 1 ל-6", "ד. הפלט יהיה תמיד 0", "ה. לא ניתן לדעת, התוכנית תמיד תסתיים בשגיאת סגמנטציה (Segmentation Fault)"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הפלט אינו קבוע עקב שתי בעיות סנכרון מרכזיות: 1. העברת משתנה לפי כתובת (Pass by Reference): החוטים מקבלים את הכתובת של משתנה הלולאה i. מכיוון שהם רצים במקביל ללולאה, הערך בכתובת זו עשוי להשתנות לפני שהם קוראים אותו. הערכים האפשריים שחוט יכול לקרוא הם 1, 2, או 3 (הערך של i לאחר סיום הלולאה). 2. מרוץ תהליכונים (Race Condition): הפעולה total += val אינה אטומית (היא מורכבת מקריאה, הוספה וכתיבה). חוט אחד יכול לקרוא את הערך הישן של total, ובזמן שהוא מחשב את הסכום, חוט אחר יעדכן את total, כך שהעדכון של החוט הראשון ידרוס את השני. השילוב של שתי הבעיות מאפשר לקבל כל ערך שלם בטווח 1 עד 6. לדוגמה: אם שני החוטים קראו את הערך i=1 ושניהם קראו total=0, שניהם יכתבו 1 לתוך total והפלט יהיה 1. אם שניהם קראו i=3 ורצו בזה אחר זה, הפלט יהיה 6."}, "difficulty_estimation": "Medium", "_source_file": "0136__Threads__CodeAnalysis__Medium.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:49:56", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Race Conditions", "Pthreads", "Memory Management"], "content": {"text": "לפניכם קוד בשפת C המשתמש בספריית pthreads. הניחו כי כל קריאות המערכת מצליחות, כי התוכנית רצה על מערכת עם מעבד יחיד (Single Core), וכי ה-Scheduler יכול להחליף בין חוטים בכל רגע (Preemptive).", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n\nint global_counter = 0;\n\nvoid* thread_func(void* arg) {\n    int* id_ptr = (int*)arg;\n    int my_id = *id_ptr;\n    int temp = global_counter;\n    usleep(10); // Force potential context switch\n    global_counter = temp + my_id;\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[3];\n    int i;\n    for (i = 0; i < 3; i++) {\n        pthread_create(&threads[i], NULL, thread_func, &i);\n    }\n    for (int j = 0; j < 3; j++) {\n        pthread_join(threads[j], NULL);\n    }\n    printf(\"%d\\n\", global_counter);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "מהו הטווח (מינימום ומקסימום) של הערכים האפשריים שיודפסו על ידי התוכנית? נמקו והדגימו תרחיש קצר עבור כל קצה.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "נניח שנוסיף מנעול (Mutex) סביב הקטע הקריטי בתוך thread_func (שורות 10-12). האם הפלט יהיה בהכרח 3 (0+1+2)? הסבירו.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "הציעו דרך לתקן את הקריאה ל-pthread_create ואת הגישה בתוך thread_func כך שכל חוט יקבל בוודאות את ערך ה-i המקורי שלו (0, 1, או 2) ללא שימוש בהקצאת זיכרון דינמי (malloc).", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. מקסימום: 9. המשתנה i ב-main משותף לכל החוטים דרך הכתובת שלו. עד שהחוטים מספיקים לקרוא את הערך בשורה 9, הלולאה ב-main עשויה להסתיים וערכו של i יהיה 3. אם כל חוט קרא 3 וביצע את העדכון באופן סדרתי (ללא דריסת ערכים), נקבל 3+3+3=9. מינימום: 0. ייתכן שחוט אחד קרא i=0 ושמר temp=0. בזמן שהוא ב-usleep, חוטים אחרים רצו ועדכנו את global_counter לערך כלשהו (למשל 6). כשהחוט הראשון מתעורר, הוא מבצע 0+0 וכותב 0 לתוך global_counter, ובכך דורס את העדכונים האחרים.\n2. לא. המנעול יפתור את ה-Race Condition על global_counter (העדכונים יהיו אטומיים), אך הוא לא פותר את הבעיה שכל החוטים ניגשים לאותה כתובת זיכרון (&i). עדיין ייתכן שכל החוטים יקראו את הערך 3 מהכתובת המשותפת, ולכן הפלט יהיה 9 (אך לא תהיה דריסת זיכרון באמצע).\n3. ניתן להעביר את הערך של i ישירות כארגומנט (Casting) במקום את הכתובת שלו. ב-main: pthread_create(&threads[i], NULL, thread_func, (void*)(long)i); ובפונקציית החוט: int my_id = (int)(long)arg;"}, "difficulty_estimation": "Hard", "_source_file": "0137__Threads__CodeAnalysis__Hard.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:50:24", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Concurrency", "Synchronization", "Race Conditions", "Pthreads"], "content": {"text": "לפניך קוד בשפת C המשתמש בספריית Pthreads. הנח כי כל הקריאות למערכת מצליחות וכי התוכנית רצה על מערכת מרובת ליבות. ענה על הסעיפים הבאים:", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint counter = 0;\n\nvoid* thread_func(void* arg) {\n    int val = *((int*)arg);\n    for (int i = 0; i < 100; i++) {\n        counter++;\n    }\n    printf(\"%d \", val);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[5];\n    for (int i = 0; i < 5; i++) {\n        pthread_create(&threads[i], NULL, thread_func, &i);\n    }\n    for (int i = 0; i < 5; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    printf(\"\\nCounter: %d\\n\", counter);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "זהה שתי בעיות סנכרון/לוגיקה בקוד לעיל הקשורות לעבודה עם חוטים.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "מהו הטווח האפשרי של הערך המודפס עבור המשתנה counter? הסבר בקצרה את הגבול התחתון.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "האם ייתכן שהפלט של התוכנית יכלול את הספרה 5? אם כן, הסבר באילו תנאים. אם לא, הסבר מדוע.", "code_snippet": null, "options": null}], "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. הבעיות הן: א) Race Condition על המשתנה הגלובלי counter כיוון שפעולת ה-increment אינה אטומית. ב) Data Race על המשתנה i - כל החוטים מקבלים מצביע לאותה כתובת זיכרון שערכה משתנה על ידי ה-main thread בזמן שהם מנסים לקרוא ממנה.\n2. הטווח הוא [100, 500]. הגבול התחתון הוא 100: זה קורה למשל אם חוט אחד קורא את הערך 0, מושהה, ובינתיים שאר החוטים מסיימים את עבודתם ומעדכנים את counter ל-400. כאשר החוט הראשון חוזר לפעול, הוא מחזיק בערך המקומי שקרא (0), מקדם אותו וכותב חזרה לזיכרון, ובכך דורס את כל העדכונים הקודמים.\n3. כן, ייתכן שהערך 5 יודפס. הלולאה ב-main רצה מ-0 עד 4. בסיום האיטרציה האחרונה, i מקודם ל-5 והתנאי i < 5 נכשל. אם חוט שנוצר באיטרציה כלשהי ניגש לכתובת arg (שהיא הכתובת של i) רק לאחר שה-main thread סיים את הלולאה, הוא יקרא את הערך 5 וידפיס אותו."}, "difficulty_estimation": "Hard", "_source_file": "0138__Threads__CodeAnalysis__Hard.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:50:45", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Threads", "Concurrency", "Race Conditions", "Pthreads"], "content": {"text": "לפניכם קוד הכתוב בשפת C המשתמש בספריית pthreads. נניח כי כל הקריאות למערכת מצליחות, וכי התוכנית רצה על מערכת המאפשרת פרה-אמפציה (preemption) בכל עת.\n\n1. מהו הטווח האפשרי (מינימום ומקסימום) של הערך המודפס עבור המשתנה counter בסוף התוכנית? הסבירו.\n2. מהן הספרות האפשריות שיכולות להיות מודפסות על ידי פקודת ה-printf בתוך הפונקציה worker? האם הספרה '3' יכולה להופיע? הסבירו.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint counter = 0;\n\nvoid* worker(void* arg) {\n    int val = *(int*)arg;\n    int local = counter;\n    local++;\n    counter = local;\n    printf(\"%d\", val);\n    return NULL;\n}\n\nint main() {\n    pthread_t t[3];\n    for (int i = 0; i < 3; i++) {\n        pthread_create(&t[i], NULL, worker, &i);\n    }\n    for (int i = 0; i < 3; i++) {\n        pthread_join(t[i], NULL);\n    }\n    printf(\" Final: %d\\n\", counter);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. טווח הערכים של counter: המינימום הוא 1 והמקסימום הוא 3. המקסימום (3) מתקבל אם החוטים רצים באופן סדרתי או ללא התערבות בקריאה/כתיבה של counter. המינימום (1) מתקבל במצב של Race Condition: כל שלושת החוטים קוראים את הערך ההתחלתי (0) לתוך המשתנה המקומי local, מקדמים אותו ל-1, ואז כותבים כולם 1 חזרה ל-counter.\n\n2. הספרות האפשריות ב-worker: הספרות הן 0, 1, 2, וגם 3. הסיבה לכך היא שהכתובת של i מועברת לכל החוטים (&i). מכיוון ש-i הוא משתנה מקומי ב-main שמשתנה בלולאה, קיים מרוץ (Race Condition) על ערכו. אם חוט מסוים ניגש לכתובת הזיכרון של i רק לאחר שהלולאה ב-main התקדמה או הסתיימה, הוא יראה את הערך המעודכן. מכיוון שהלולאה רצה עד ש-i שווה ל-3, ייתכן שחוט יקרא את הערך 3 מהכתובת לפני ש-main יצא מהלולאה או בזמן ההמתנה ב-join."}, "difficulty_estimation": "Hard", "_source_file": "0139__Threads__CodeAnalysis__Hard.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:51:02", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Concurrency", "Race Conditions", "Memory Management"], "content": {"text": "עיינו בקוד ה-C הבא המשתמש ב-POSIX Threads. התוכנית רצה על מערכת מרובת ליבות. הניחו שכל קריאות המערכת מצליחות ושספריית הסטנדרט מוגדרת ללא Buffering (כלומר printf מדפיס מיד).", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint g = 0;\n\nvoid* task(void* arg) {\n    int val = *(int*)arg;\n    g = g + 1;\n    printf(\"%d \", val);\n    return NULL;\n}\n\nint main() {\n    pthread_t t[3];\n    for (int i = 0; i < 3; i++) {\n        pthread_create(&t[i], NULL, task, &i);\n    }\n    for (int i = 0; i < 3; i++) {\n        pthread_join(t[i], NULL);\n    }\n    printf(\"! %d\", g);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "מהם הערכים האפשריים שיכולים להיות מודפסים עבור המשתנה val על ידי כל אחד מהחוטים? הסבירו האם הערך 3 יכול להופיע בפלט.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "מהו הטווח האפשרי של ערכים עבור המשתנה g בהדפסה האחרונה (אחרי הסימן '!')? נמקו.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "כיצד ניתן לשנות את שורת הקריאה ל-pthread_create ואת השורה הראשונה בפונקציה task כך שכל חוט ידפיס בוודאות ערך ייחודי (0, 1, 2) ללא שימוש במנגנוני סנכרון (כגון Mutex)?", "code_snippet": null, "options": null}], "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. הערכים האפשריים עבור val הם {0, 1, 2, 3}. הסיבה לכך היא שכל החוטים מקבלים את הכתובת של אותו משתנה מקומי i מהמחסנית של main. כיוון שאין סנכרון, חוט עשוי לקרוא את הערך של i רק לאחר שהחוט הראשי כבר קידם אותו בלולאה. הערך 3 אפשרי בהחלט: אם חוט מסוים מתחיל לבצע את הפונקציה task רק לאחר שהלולאה הראשונה ב-main הסתיימה, הוא יקרא את הערך הנוכחי של i בכתובת שקיבל, שהוא 3 (ערך היציאה מהלולאה).\n\n2. הטווח עבור g הוא [1, 3]. הפעולה g = g + 1 אינה אטומית (מורכבת מקריאה, הוספה וכתיבה). במערכת מרובת ליבות, ייתכן שכל שלושת החוטים יקראו את הערך 0 בו-זמנית, יוסיפו 1 ויכתבו כולם 1 חזרה לזיכרון (Race Condition). במקרה האופטימלי שבו אין התנגשות, כל חוט יקדם את g בתורו והתוצאה תהיה 3.\n\n3. כדי להבטיח שכל חוט יקבל עותק ייחודי של הערך i ללא תלות בשינויים העתידיים של המשתנה ב-main, ניתן להעביר את הערך עצמו באמצעות Casting לטיפוס void* (בהנחה שגודל מצביע מאפשר זאת): \nב-main: pthread_create(&t[i], NULL, task, (void*)(long)i);\nב-task: int val = (int)(long)arg;"}, "difficulty_estimation": "Hard", "_source_file": "0140__Threads__CodeAnalysis__Hard.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:51:27", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Concurrency", "Race Conditions", "Pthreads"], "content": {"text": "לפניך קטע קוד ב-C המשתמש בספריית pthreads. מטרת התוכנית היא ליצור 5 חוטים (threads), כך שכל חוט ידפיס מזהה ייחודי (0 עד 4) שהועבר לו בזמן היצירה. הנח כי כל הקריאות ל-pthread_create ו-pthread_join מצליחות.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#define NUM_THREADS 5\n\nvoid* thread_func(void* arg) {\n    int id = *((int*)arg);\n    printf(\"%d \", id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    for (int i = 0; i < NUM_THREADS; i++) {\n        pthread_create(&threads[i], NULL, thread_func, &i);\n    }\n    for (int i = 0; i < NUM_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "האם הפלט של התוכנית יהיה בהכרח פרמוטציה של המספרים {0, 1, 2, 3, 4}? הסבירו מדוע.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "האם ייתכן מצב בו אחד החוטים ידפיס את הערך 5? נמקו.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "הציעו שינוי מינימלי לקוד (שורות בודדות) שיבטיח שכל חוט ידפיס מזהה ייחודי בין 0 ל-NUM_THREADS-1.", "code_snippet": null, "options": null}], "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. לא, הפלט לא יהיה בהכרח פרמוטציה של 0-4. הבעיה היא שכל החוטים מקבלים את הכתובת של אותו משתנה מקומי i. מכיוון שהחוטים רצים במקביל ללולאת ה-main, ייתכן שערך המשתנה i ישתנה ב-main לפני שחוט מסוים יספיק לקרוא אותו ב-thread_func. זהו Race Condition על המשתנה i.\n2. כן, ייתכן בהחלט. אם לולאת היצירה (הלולאה הראשונה) מסתיימת לפני שאחד החוטים ניגש לזיכרון של i, הערך של i יהיה 5 (תנאי העצירה של הלולאה), וזה מה שהחוט ידפיס.\n3. ישנן שתי דרכים נפוצות לתיקון: א. הקצאת מערך של מזהים (למשל int ids[NUM_THREADS]) והעברת הכתובת של המקום ה-i במערך לכל חוט. ב. העברת הערך של i ישירות על ידי Casting ל-(void*) ב-pthread_create וביצוע Casting חזרה ל-int בתוך ה-thread_func (עובד כי גודל void* בדרך כלל גדול או שווה ל-int)."}, "difficulty_estimation": "Hard", "_source_file": "0141__Threads__CodeAnalysis__Hard.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:51:41", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Threads", "Concurrency", "Race Conditions"], "content": {"text": "נתון קטע הקוד הבא בשפת C. שני חוטים (Threads) נוצרים ומריצים את הפונקציה worker במקביל על מעבד יחיד. המשתנה x הוא גלובלי ומאותחל ל-0. מהו הערך המקסימלי והערך המינימלי האפשריים של x עם סיום ריצת התוכנית? הסבירו את תשובתכם ותארו את סדר הפעולות (interleaving) המוביל לערכים אלו.", "code_snippet": "int x = 0;\n\nvoid* worker(void* arg) {\n    for (int i = 0; i < 100; i++) {\n        int temp = x;\n        temp = temp + 1;\n        x = temp;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, worker, NULL);\n    pthread_create(&t2, NULL, worker, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"%d\", x);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ערך מקסימלי: 200. מתקבל כאשר שני החוטים רצים באופן סדרתי (אחד אחרי השני), כך שכל פעולת קידום מתבצעת על הערך המעודכן ביותר.\nערך מינימלי: 2. תרחיש המביא לתוצאה זו:\n1. חוט א' קורא x=0 עבור האיטרציה הראשונה שלו (i=0) ונעצר.\n2. חוט ב' רץ 99 איטרציות מלאות (i=0 עד i=98), ומעדכן את x ל-99.\n3. חוט א' ממשיך וכותב x=1 (הערך שקרא 0 פלוס 1).\n4. חוט ב' קורא את הערך x=1 עבור האיטרציה האחרונה שלו (i=99) ונעצר.\n5. חוט א' רץ ומסיים את כל 99 האיטרציות הנותרות שלו (מ-i=1 עד i=99), ומעדכן את x ל-100.\n6. חוט ב' ממשיך את האיטרציה האחרונה שלו, מחשב 1+1 וכותב x=2."}, "difficulty_estimation": "Hard", "_source_file": "0142__Threads__CodeAnalysis__Hard.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:52:20", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Threads", "Concurrency", "Race Conditions", "Synchronization", "Pthreads"], "content": {"text": "לפניכם קוד בשפת C המשתמש בחוטים (Threads). הניחו כי כל קריאות המערכת מצליחות וכי התוכנית רצה על מערכת מרובת ליבות המאפשרת הרצה מקבילית אמיתית.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint total = 0;\npthread_mutex_t mtx = PTHREAD_MUTEX_INITIALIZER;\n\nvoid* worker(void* arg) {\n    int id = *(int*)arg;\n    for (int i = 0; i < 100; i++) {\n        if (id % 2 == 0) {\n            total++;\n        } else {\n            pthread_mutex_lock(&mtx);\n            total++;\n            pthread_mutex_unlock(&mtx);\n        }\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[4];\n    for (int i = 0; i < 4; i++) {\n        pthread_create(&threads[i], NULL, worker, &i);\n    }\n    for (int i = 0; i < 4; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    printf(\"%d\\n\", total);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "101.1", "text": "מהו הערך המקסימלי האפשרי שהתוכנית יכולה להדפיס? הסבירו בקצרה.", "code_snippet": null, "options": null}, {"id": "101.2", "text": "האם פלט התוכנית דטרמיניסטי (כלומר, האם תמיד יודפס אותו ערך)? אם לא, ציינו את שתי הסיבות המרכזיות לכך שערכו של total עשוי להשתנות בין הרצות שונות.", "code_snippet": null, "options": null}, {"id": "101.3", "text": "נניח ושינינו את שורת יצירת החוט ל-pthread_create(&threads[i], NULL, worker, (void*)(long)i); ואת קריאת ה-id ל-int id = (int)(long)arg;. האם כעת הפלט יהיה דטרמיניסטי ושווה ל-400? נמקו.", "code_snippet": null, "options": null}], "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. הערך המקסימלי הוא 400. ישנם 4 חוטים וכל אחד מבצע 100 איטרציות של קידום המשתנה total. בתרחיש אידיאלי ללא איבוד עדכונים, הסכום יגיע ל-400.\n2. הפלט אינו דטרמיניסטי משתי סיבות עיקריות:\nא) מרוץ תהליכים על המשתנה i: כל החוטים מקבלים את הכתובת של i בזיכרון של פונקציית main. עד שחוט מתחיל לרוץ וקורא את הערך מהכתובת, הערך של i עשוי להשתנות על ידי הלולאה ב-main (למשל, כל החוטים עשויים לקרוא את הערך 4).\nב) מרוץ תהליכים על total: בתוך פונקציית worker, אם ה-id שנקרא הוא זוגי, הגישה ל-total מתבצעת ללא הגנת Mutex. מכיוון שמספר חוטים יכולים לגשת למשתנה בו-זמנית, עדכונים עלולים ללכת לאיבוד (Lost Update).\n3. לא. למרות שתיקון זה מבטיח שכל חוט יקבל ID ייחודי (0, 1, 2, 3), חוטים 0 ו-2 עדיין יזהו את עצמם כזוגיים (id % 2 == 0) וינסו לקדם את total ללא שימוש במנעול. כתוצאה מכך, עדיין קיים מרוץ תהליכים בין חוט 0 לחוט 2 (ובין שניהם לחוטים האי-זוגיים שמשתמשים במנעול אך לא מונעים מהזוגיים לגשת), ולכן הפלט עדיין לא יהיה דטרמיניסטי ועלול להיות נמוך מ-400."}, "difficulty_estimation": "Hard", "_source_file": "0143__Threads__CodeAnalysis__Hard.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:52:41", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Threads", "Concurrency", "Race Conditions", "Synchronization"], "content": {"text": "לפניכם תוכנית בשפת C המשתמשת בספריית pthreads. המשתנה g הוא משתנה גלובלי המשותף לכל החוטים ומאותחל ל-0. הניחו כי המערכת משתמשת במעבד יחיד וכי אלגוריתם התזמון הוא Preemptive (ניתן להחליף בין חוטים בכל נקודת זמן, כולל באמצע פעולות אריתמטיות של קריאה וכתיבה לזיכרון). מהו הערך המינימלי והערך המקסימלי האפשריים של המשתנה g עם סיום ריצת התוכנית? נמקו את תשובתכם בעזרת תרחיש הרצה (interleaving) מתאים.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint g = 0;\n\nvoid* child_func(void* arg) {\n    int temp = g;\n    g = temp + 1;\n    return NULL;\n}\n\nvoid* parent_func(void* arg) {\n    pthread_t tid;\n    int temp = g;\n    g = temp + 1;\n    pthread_create(&tid, NULL, child_func, NULL);\n    pthread_join(tid, NULL);\n    temp = g;\n    g = temp + 1;\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, parent_func, NULL);\n    pthread_create(&t2, NULL, parent_func, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"%d\\n\", g);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ערך מקסימלי: 6. זהו המקרה שבו כל הפעולות מתבצעות באופן סדרתי ללא הפרעה. כל חוט אב (parent_func) מבצע 3 קידומים של g: אחד ישירות לפני יצירת הבן, אחד על ידי הבן (child_func), ואחד ישירות לאחר ה-join. כיוון שיש שני חוטי אב, מתבצעים 6 קידומים סה\"כ.\n\nערך מינימלי: 3. כדי להגיע למינימום, ננסה לגרום לאובדן עדכונים (lost updates). נניח שחוט אב T1 קורא g=0. אז חוט T2 רץ את כל המסלול שלו (3 קידומים) ומביא את g ל-3. כעת T1 חוזר ומבצע את הכתיבה שלו: g = 0 + 1 = 1. בשלב זה איבדנו את כל העדכונים של T2 והערך הוא 1. כעת T1 יוצר את חוט הבן שלו (C1). כיוון ש-C1 נוצר לאחר ש-T1 כבר כתב 1, C1 יקרא לפחות 1 ויעדכן ל-2. לאחר מכן T1 יבצע join ויקרא את הערך שכתב הבן (2) ויעדכן ל-3. \nלא ניתן להגיע לערך נמוך מ-3 (כמו 2) מכיוון שכל חוט אב מחולק לשני מקטעי קוד שביניהם יש נקודת סנכרון (join). הקידום האחרון של חוט אב תמיד יתבסס על הערך שנכתב על ידי הבן שלו, והבן תמיד יקרא ערך שנכתב לפחות על ידי הקידום הראשון של האב שלו."}, "difficulty_estimation": "Hard", "_source_file": "0144__Threads__CodeAnalysis__Hard.json", "_topic_hint": "Threads", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:53:50", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Race Condition"], "content": {"text": "מהו מצב מרוץ (Race Condition) בהקשר של סנכרון בין תהליכים או חוטים (threads)?", "code_snippet": null, "options": ["א. מצב שבו שני תהליכים מנסים לגשת לאותו קובץ בדיסק בו-זמנית.", "ב. מצב שבו התוצאה הסופית של התוכנית תלויה בתזמון היחסי של ביצוע הפעולות על משאב משותף.", "ג. מצב שבו תהליך אחד נתקע בלולאה אינסופית ומונע מתהליכים אחרים להשתמש במעבד.", "ד. מצב שבו שני תהליכים מחכים זה לזה לצורך קבלת משאב ואינם יכולים להמשיך בביצועם.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. מצב מרוץ (Race Condition) מוגדר כמצב שבו מספר תהליכים או חוטים ניגשים ומשנים נתונים משותפים בו-זמנית, כך שהתוצאה הסופית של החישוב תלויה בסדר הגישה (התזמון) של הישויות השונות למשאב."}, "difficulty_estimation": "Easy", "_source_file": "0145__Synchronization__MultipleChoice__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:53:57", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Critical Section"], "content": {"text": "מהו 'קטע קריטי' (Critical Section) בהקשר של סנכרון בין תהליכים או חוטים (threads)?", "code_snippet": null, "options": ["א. קטע קוד שחייב להתבצע בזמן הקצר ביותר האפשרי כדי לא לעכב את המערכת.", "ב. קטע קוד שבו מתבצעת גישה למשאב משותף, ושאסור ליותר מתהליך אחד לבצעו בו-זמנית.", "ג. קטע קוד שרק למערכת ההפעלה (Kernel) מותר להריץ.", "ד. קטע קוד שבו מתרחשת פסיקת שעון לצורך החלפת הקשר (Context Switch).", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "קטע קריטי הוא חלק בתוכנית שבו מתבצעת גישה למשאבים משותפים (כמו משתנים גלובליים, קבצים או חומרה). כדי למנוע מצבי מרוץ (Race Conditions), יש להבטיח 'מניעה הדדית' (Mutual Exclusion), כלומר שרק תהליך/חוט אחד ישהה בקטע הקריטי שלו בכל רגע נתון."}, "difficulty_estimation": "Easy", "_source_file": "0146__Synchronization__MultipleChoice__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:54:06", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Synchronization", "Concurrency"], "content": {"text": "מהו 'מצב מרוץ' (Race Condition) בהקשר של סנכרון תהליכים?", "code_snippet": null, "options": ["א. מצב שבו שני תהליכים או יותר ניגשים למשאב משותף והתוצאה הסופית תלויה בתזמון הביצוע של הפקודות.", "ב. מצב שבו תהליך אחד ממתין למשאב שמוחזק על ידי תהליך אחר, שממתין למשאב של הראשון.", "ג. מצב שבו תהליך בעל עדיפות נמוכה אינו מצליח לקבל זמן מעבד בגלל תהליכים בעלי עדיפות גבוהה.", "ד. מצב שבו המעבד מבצע החלפת הקשר (context switch) בתדירות גבוהה מדי.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "א'. מצב מרוץ מתרחש כאשר מספר חוטים או תהליכים מבצעים מניפולציה על נתונים משותפים במקביל, והתוצאה הסופית של החישוב תלויה בסדר שבו הגישות בוצעו בפועל. כדי למנוע זאת, יש להשתמש במנגנוני סנכרון כמו Mutex."}, "difficulty_estimation": "Easy", "_source_file": "0147__Synchronization__MultipleChoice__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:54:18", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Synchronization", "Concurrency"], "content": {"text": "מהו \"קטע קריטי\" (Critical Section) בהקשר של סנכרון בין תהליכים או חוטים (threads)?", "code_snippet": null, "options": ["א. חלק בקוד שבו מתבצעת גישה למשאבים משותפים ועלול להיווצר בו Race Condition.", "ב. קטע קוד במערכת ההפעלה שאחראי על ביצוע החלפת הקשר (Context Switch).", "ג. קוד שחייב לרוץ במצב פריבילגי (Kernel Mode) בלבד.", "ד. פונקציה שמבצעת הקצאת זיכרון דינמי עבור תהליך חדש.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "א'. קטע קריטי הוא קטע קוד שבו מתבצעת גישה למשאב משותף (כגון משתנה גלובלי, קובץ או מבנה נתונים). כדי למנוע מצב של מרוץ (Race Condition), עלינו להבטיח שרק תהליך אחד נמצא בקטע הקריטי שלו בו-זמנית (Mutual Exclusion)."}, "difficulty_estimation": "Easy", "_source_file": "0148__Synchronization__MultipleChoice__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:54:25", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Synchronization", "Mutex"], "content": {"text": "מהי המטרה העיקרית של שימוש ב-mutex (מנעול הדדי) במערכת הפעלה?", "code_snippet": null, "options": ["א. לאפשר תקשורת אמינה בין תהליכים שונים.", "ב. למנוע מצב של רעב (starvation) של תהליכים.", "ג. להבטיח שרק תהליך אחד יבצע קטע קוד קריטי בכל רגע נתון.", "ד. לסנכרן את עבודת המעבד עם התקני קלט/פלט.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "ג'. המטרה העיקרית של mutex (מנעול הדדי) היא להגן על קטעים קריטיים של קוד (critical sections) המשתמשים במשאבים משותפים. בכך, הוא מבטיח שרק תהליך או חוט חישוב אחד יוכל לגשת למשאב המשותף ולשנות אותו בכל רגע נתון, ובכך למנוע תנאי מרוץ (race conditions) ולהבטיח עקביות נתונים."}, "difficulty_estimation": "Easy", "_source_file": "0149__Synchronization__MultipleChoice__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:43:51", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Concurrency"], "content": {"text": "מהו 'קטע קריטי' (Critical Section) בהקשר של סנכרון בין תהליכים או חוטים (threads)?", "code_snippet": null, "options": ["א. קטע קוד שחייב להתבצע על ידי המעבד במהירות המרבית ללא השהיות.", "ב. קטע קוד שבו מתבצעת גישה למשאב משותף ושרק חוט/תהליך אחד יכול לבצע בו זמנית.", "ג. קטע קוד המכיל רק פקודות מערכת (System Calls) המיועדות לניהול זיכרון.", "ד. קטע קוד שבו המעבד מבצע פעולות קלט/פלט (I/O) בלבד.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. קטע קריטי הוא חלק בתוכנית שבו ניגשים למשאב משותף (כגון משתנה גלובלי). כדי למנוע מצבי מרוץ (Race Conditions), יש להשתמש במנגנוני סנכרון כדי להבטיח שרק תהליך/חוט אחד ישהה בקטע זה בכל זמן נתון (Mutual Exclusion)."}, "difficulty_estimation": "Easy", "_source_file": "0150__Synchronization__MultipleChoice__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:54:35", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Mutex"], "content": {"text": "מהי מטרתו העיקרית של מנעול (mutex) בסנכרון תהליכים?", "code_snippet": null, "options": ["א. למנוע מצב של קיפאון (deadlock).", "ב. להבטיח גישה בלעדית למשאב משותף (mutual exclusion).", "ג. לאפשר לתהליכים להחליף נתונים ביניהם.", "ד. לוודא שכל התהליכים ירוצו באותו סדר.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. מנעול (mutex) משמש בעיקר להבטחת גישה בלעדית לקטע קריטי (critical section) או למשאב משותף, כדי למנוע תנאי מרוץ (race conditions) ולהבטיח עקביות נתונים. בעוד שהוא יכול להיות חלק מפתרון למניעת קיפאון, זו אינה מטרתו העיקרית בפני עצמה."}, "difficulty_estimation": "Easy", "_source_file": "0151__Synchronization__MultipleChoice__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:43:58", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Critical Section"], "content": {"text": "מהו \"קטע קריטי\" (Critical Section) בהקשר של סנכרון בין תהליכים או חוטים (threads)?", "code_snippet": null, "options": ["א. קטע קוד שזמן הריצה שלו ארוך במיוחד ועלול לעכב את המערכת.", "ב. קטע קוד שבו מתבצעת גישה למשאב משותף ונדרש להבטיח שרק חוט אחד יבצע אותו בכל רגע נתון.", "ג. קטע קוד בתוך ליבת מערכת ההפעלה (kernel) שלא ניתן להפסיק את ריצתו על ידי פסיקה.", "ד. פונקציה שניתן לקרוא לה רק מתוך תהליך יחיד במהלך כל חיי התוכנית.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. קטע קריטי הוא קטע בתוכנית שבו מתבצעת גישה למשאבים משותפים (כגון משתנים גלובליים, מבני נתונים או קבצים). כדי למנוע מצבי מרוץ (race conditions), יש להשתמש במנגנוני סנכרון שיבטיחו מניעה הדדית (mutual exclusion), כך שרק חוט אחד יוכל לשהות בקטע הקריטי בכל זמן נתון."}, "difficulty_estimation": "Easy", "_source_file": "0152__Synchronization__MultipleChoice__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:54:46", "_subject": "Concurrency"}, {"id": 3, "type": "MultipleChoice", "topic": ["Synchronization", "Race Conditions", "Threads"], "content": {"text": "נתונה תוכנית C++ המשתמשת בחוטים (threads) לשם עדכון משתנה גלובלי משותף:\n```cpp\n#include <iostream>\n#include <thread>\n#include <vector>\n\nvolatile int shared_counter = 0; // משתנה משותף\n\nvoid increment_function() {\n    for (int i = 0; i < 100000; ++i) {\n        shared_counter++;\n    }\n}\n\nint main() {\n    std::vector<std::thread> threads;\n    for (int i = 0; i < 2; ++i) {\n        threads.emplace_back(increment_function);\n    }\n\n    for (std::thread& t : threads) {\n        t.join();\n    }\n\n    std::cout << \"Final counter value: \" << shared_counter << std::endl;\n    return 0;\n}\n```\nכאשר מריצים את הקוד לעיל, מהי הטענה הנכונה לגבי ערכו הסופי של `shared_counter`?", "code_snippet": null, "options": ["א. הערך הסופי תמיד יהיה 200000.", "ב. הערך הסופי תמיד יהיה 0.", "ג. הערך הסופי תמיד יהיה קטן מ-200000.", "ד. הערך הסופי אינו מובטח, והוא יכול להיות קטן מ-200000 עקב תנאי מירוץ (race condition).", "ה. הערך הסופי אינו מובטח, והוא יכול להיות גדול מ-200000 עקב תנאי מירוץ (race condition)."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "הקוד מכיל תנאי מירוץ (race condition) על המשתנה המשותף `shared_counter`. פעולת ה-`++` אינה אטומית, אלא מורכבת מכמה שלבים (קריאת הערך הנוכחי, הגדלת הערך, וכתיבת הערך החדש). כאשר שני חוטים מנסים לעדכן את המונה במקביל ללא מנגנון סנכרון (כמו mutex), ייתכן שחוט אחד יקרא את הערך, חוט אחר יקרא את אותו הערך ויעדכן אותו, ואז החוט הראשון יכתוב את הערך המיושן שלו, ובכך 'ידרוס' את העדכון של החוט השני. כתוצאה מכך, חלק מהעדכונים עלולים ללכת לאיבוד, והערך הסופי יהיה קטן מ-200000. הערך אינו מובטח ומשתנה בין הרצות שונות. הוא לא יכול להיות גדול מ-200000, שכן כל פעולה רק אמורה להגדיל את המונה באחד."}, "difficulty_estimation": "Medium", "_source_file": "0153__Synchronization__MultipleChoice__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:44:14", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Synchronization", "Race Condition", "Shared Memory"], "content": {"text": "נתון קטע הקוד הבא המורץ על ידי N חוטים (threads) במקביל. כל חוט מבצע את הפונקציה `thread_func` פעם אחת. המשתנה `counter` הוא גלובלי ומשותף לכל החוטים. מה תהיה התוצאה הסופית של `counter` לאחר שכל N החוטים סיימו את פעולתם?", "code_snippet": "int counter = 0; // משתנה גלובלי\n\nvoid *thread_func(void *arg) {\n    int temp = counter;\n    temp = temp + 1;\n    counter = temp;\n    return NULL;\n}", "options": ["א. בדיוק N", "ב. בדיוק 0", "ג. ערך כלשהו בין 0 ל-N-1 (כולל)", "ד. ערך כלשהו בין 1 ל-N (כולל), אך לרוב פחות מ-N", "ה. לא ניתן לדעת בוודאות, יכול להיות כל ערך שלם חיובי."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "הפעולה `counter++` אינה אטומית. היא מורכבת מקריאה של `counter` (לתוך `temp`), הגדלה של `temp`, וכתיבה בחזרה של `temp` ל-`counter`. כאשר מספר חוטים מבצעים פעולה זו במקביל ללא מנגנון סנכרון (כגון mutex), עלול להיווצר מצב מרוץ (race condition). לדוגמה, חוט אחד קורא את `counter` (נניח 0), אך לפני שהוא מספיק לכתוב בחזרה את הערך המוגדל (1), חוט אחר קורא גם הוא את אותו ערך ישן של `counter` (0). שני החוטים מגדילים את הערך באופן עצמאי ל-1 וכותבים בחזרה, ובכך 'אובדת' אחת ההגדלות – ה-`counter` יעמוד על 1 במקום 2. לכן, התוצאה הסופית של `counter` תהיה לרוב קטנה מ-`N`. במקרה הטוב ביותר (כאשר אין מצב מרוץ כלל, או כאשר N=1), הערך יהיה `N`. במקרה הגרוע ביותר, כאשר N גדול, ובהינתן מצבי מרוץ רבים, הערך יהיה נמוך משמעותית מ-`N`, אך לא יכול להיות פחות מ-1 (אם N גדול או שווה ל-1). לכן, הטווח הנכון הוא בין 1 ל-`N` (כולל), אך בפועל (במערכת מרובת חוטים) לרוב יהיה פחות מ-`N`."}, "difficulty_estimation": "Medium", "_source_file": "0154__Synchronization__MultipleChoice__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:44:29", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Race Conditions", "Mutexes"], "content": {"text": "נתונה פיסת הקוד הבאה:\nאם מספר חוטים (threads) שונים קוראים לפונקציה `increment_shared_counter()` במקביל, איזו מהטענות הבאות נכונה לגבי הערך הסופי של `shared_counter` לאחר שכל החוטים סיימו את ביצועם?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint shared_counter = 0; // משתנה גלובלי משותף\n\nvoid increment_shared_counter() {\n    shared_counter++;\n}", "options": ["א. הערך הסופי של `shared_counter` תמיד יהיה נכון, מכיוון שפעולת הקידום `++` היא אטומית במעבדים מודרניים.", "ב. הערך הסופי של `shared_counter` תמיד יהיה שגוי עקב Race Condition.", "ג. הערך הסופי של `shared_counter` עלול להיות שגוי עקב Race Condition, ונדרש מנגנון סנכרון (לדוגמה, Mutex) כדי להבטיח נכונות.", "ד. המערכת תמיד תקרוס (crash) עקב Race Condition.", "ה. Race Condition אינו רלוונטי במקרה זה מכיוון שאין כתיבה למשתנה מצד מספר חוטים."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "פעולת הקידום `shared_counter++` אינה פעולה אטומית. היא מורכבת משלוש פעולות בסיסיות: קריאת הערך של `shared_counter` מהזיכרון, הגדלת הערך, וכתיבת הערך החדש בחזרה לזיכרון. כאשר מספר חוטים מבצעים פעולה זו במקביל ללא סנכרון, ייתכן שחוט אחד יקרא את הערך, חוט אחר יקרא את אותו ערך לפני שהחוט הראשון הספיק לכתוב את הערך המעודכן, וכתוצאה מכך עדכונים מסוימים עלולים ללכת לאיבוד. מצב זה נקרא Race Condition. כדי למנוע זאת ולהבטיח שהערך הסופי יהיה נכון, יש להגן על הקטע הקריטי (הכולל את פעולת הקידום) באמצעות מנגנון סנכרון כמו Mutex."}, "difficulty_estimation": "Medium", "_source_file": "0155__Synchronization__MultipleChoice__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:44:46", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Mutexes", "Threads"], "content": {"text": "בתוכנית C הכוללת מספר תהליכונים (threads) המעדכנים משתנה משותף `counter`, נעשה שימוש ב-`pthread_mutex_t` בשם `lock` כדי להגן על הקטע הקריטי. איזו מהטענות הבאות נכונה לגבי השימוש ב-`lock`?", "code_snippet": null, "options": ["א. אם תהליכון רוכש את ה-`lock` ולאחר מכן מנסה לרכוש אותו שוב (לפני שחרורו), התוכנית תיכנס ככל הנראה למצב של קיפאון (deadlock).", "ב. תהליכון יכול לשחרר בהצלחה `lock` שנרכש על ידי תהליכון אחר.", "ג. אם תהליכון רוכש את ה-`lock` וקורא ל-`pthread_exit()` מבלי לשחררו, ה-`lock` ישוחרר אוטומטית על ידי המערכת.", "ד. השימוש ב-`pthread_mutex_lock` וב-`pthread_mutex_unlock` מבטיח שהתהליכונים יבצעו את עדכוני `counter` תמיד באותו סדר."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "נכון. עבור mutex רגיל (PTHREAD_MUTEX_NORMAL, שהוא ברירת המחדל), תהליכון המנסה לרכוש mutex שכבר נמצא בבעלותו ייחסם וייכנס למצב של קיפאון (self-deadlock). mutexים רקורסיביים (PTHREAD_MUTEX_RECURSIVE) מאפשרים זאת, אך אינם ברירת המחדל.\n\nלא נכון לגבי ב': ניסיון לשחרר mutex שלא נרכש על ידי התהליכון הקורא הוא התנהגות בלתי מוגדרת (undefined behavior) ובדרך כלל יגרום לשגיאה או קריסה.\n\nלא נכון לגבי ג': אם תהליכון יוצא תוך כדי החזקת mutex, ה-mutex נשאר נעול. זהו מקור נפוץ לבעיות כאשר תהליכונים אחרים ימתינו ל-mutex זה לנצח. mutexים רובסטיים (robust mutexes) מטפלים בתרחיש זה אך אינם ברירת המחדל.\n\nלא נכון לגבי ד': mutexים מבטיחים בלעדיות לקטע קריטי, ובכך מונעים תנאי מרוץ (race conditions) ומבטיחים את נכונות הערך הסופי. עם זאת, הם אינם מבטיחים סדר מסוים שבו תהליכונים יבצעו את הפעולות בתוך הקטע הקריטי."}, "difficulty_estimation": "Medium", "_source_file": "0156__Synchronization__MultipleChoice__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:45:06", "_subject": "Concurrency"}, {"id": 10, "type": "MultipleChoice", "topic": ["Synchronization", "Race Conditions", "Threads"], "content": {"text": "נתון קוד C הבא המשתמש במשתנה גלובלי `counter` ובשני תהליכונים (threads) המנסים להגדיל אותו. המשתנה `counter` מאותחל ל-0. כל אחד משני התהליכונים מגדיל את `counter` 1000 פעמים. מהו הערך הסופי האפשרי של `counter` לאחר ששני התהליכונים סיימו את פעולתם?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0;\n\nvoid* increment_thread(void* arg) {\n    for (int i = 0; i < 1000; i++) {\n        counter++;\n    }\n    return NULL;\n}\n\n// ההנחה היא שפונקציית main יוצרת שני תהליכונים הקוראים ל-increment_thread,\n// ממתינה להם, ואז מדפיסה את counter.", "options": ["א. 2000 בלבד", "ב. כל ערך בין 1 ל-2000 כולל", "ג. כל ערך בין 1000 ל-2000 כולל", "ד. כל ערך בין 1001 ל-2000 כולל", "ה. 0 בלבד"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הבעיה המתוארת היא תנאי מרוץ (Race Condition). הפעולה `counter++` אינה אטומית. היא מורכבת בדרך כלל משלושה שלבים: טעינת הערך של `counter` לתוך אוגר, הגדלת הערך באוגר, ושמירת הערך החדש מהאוגר חזרה ל-`counter`. כאשר שני תהליכונים מבצעים פעולה זו במקביל ללא מנגנוני סנכרון, ייתכנו תרחישי ביצוע שונים.\n\nהערך המקסימלי האפשרי הוא 2000. זה יקרה אם אחד התהליכונים מסיים את כל 1000 ההגדלות שלו לפני שהשני מתחיל, או אם פעולות ה-`load-increment-store` של כל תהליכון מתבצעות באופן כזה שאין איבוד עדכונים.\n\nהערך המינימלי האפשרי הוא 1. תרחיש לדוגמה:\n1. תהליכון A טוען את `counter` (שהוא 0) לאוגר שלו (R_A=0).\n2. תהליכון B טוען את `counter` (שהוא 0) לאוגר שלו (R_B=0).\n3. תהליכון A מגדיל את הערך באוגר שלו ל-1 (R_A=1).\n4. תהליכון B מגדיל את הערך באוגר שלו ל-1 (R_B=1).\n5. תהליכון A שומר את הערך (1) מן האוגר שלו ל-`counter`. כעת `counter` שווה ל-1.\n6. תהליכון B שומר את הערך (1) מן האוגר שלו ל-`counter`. כעת `counter` נשאר שווה ל-1.\nבמקרה זה, שתי פעולות `counter++` גרמו להגדלה אחת בלבד של `counter`. תרחיש קיצוני נוסף לערך מינימלי הוא אם תהליכון A טוען את 0, ואז תהליכון B מבצע את כל 1000 ההגדרות שלו (מעלה את `counter` ל-1000), ואז תהליכון A שומר את הערך 1 (שאותו חישב קודם לכן) חזרה ל-`counter`, הרי ש-`counter` יסיים ב-1.\n\nלכן, הערך הסופי של `counter` יכול להיות כל מספר שלם בין 1 ל-2000, כולל."}, "difficulty_estimation": "Medium", "_source_file": "0157__Synchronization__MultipleChoice__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:45:43", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Synchronization", "Mutexes", "POSIX Threads"], "content": {"text": "חוט ביצוע (thread) מנסה לרכוש מנעול (mutex) מסוג PTHREAD_MUTEX_NORMAL (הגדרת ברירת מחדל של POSIX mutex) שכבר נרכש על ידו, מבלי לשחרר אותו קודם. מהי התוצאה הסבירה ביותר של הניסיון השני לרכישת המנעול?", "code_snippet": null, "options": ["א. החוט ירכוש את המנעול שוב בהצלחה וימשיך בביצוע.", "ב. החוט ייתקע (deadlock) בניסיון הרכישה השני.", "ג. קריאת ה-`pthread_mutex_lock` השנייה תחזיר שגיאה.", "ד. המערכת תבצע החלפת הקשר לחוט אחר ותיתן לו הזדמנות לרכוש את המנעול."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "מנעול מסוג PTHREAD_MUTEX_NORMAL (התנהגות ברירת המחדל של POSIX mutex) אינו מאפשר רכישה חוזרת על ידי אותו חוט שכבר מחזיק בו. אם חוט מנסה לרכוש מנעול כזה פעם שנייה מבלי לשחרר אותו קודם, הוא ייחסם בניסיון הרכישה השני, מה שיוביל ל-deadlock עצמי (self-deadlock). זוהי התנהגות מוגדרת בתקן POSIX כדי למנוע טעויות תכנות נפוצות. מנעולים רקורסיביים (PTHREAD_MUTEX_RECURSIVE) מאפשרים רכישה חוזרת, אך זה לא המקרה כאן."}, "difficulty_estimation": "Medium", "_source_file": "0158__Synchronization__MultipleChoice__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:45:55", "_subject": "Concurrency"}, {"id": 10, "type": "MultipleChoice", "topic": ["Synchronization", "Mutexes", "Deadlock"], "content": {"text": "איזו מהטענות הבאות מתארת נכונה התנהגות של mutex סטנדרטי (non-recursive) בסביבת ריבוי חוטים?", "code_snippet": null, "options": ["א. חוט יכול לנעול mutex פעמיים ברצף (ללא שחרור ביניהם) בהצלחה.", "ב. אם חוט מנסה לנעול mutex שכבר נעול על ידו, הפעולה תגרום ל-deadlock (קיפאון).", "ג. mutex יכול לשמש להגנה על מספר משאבים שונים בו זמנית, כל עוד הם בתוך אותו critical section.", "ד. שחרור mutex שלא ננעל על ידי החוט הנוכחי, או שכבר שוחרר, הוא פעולה חוקית ובטוחה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "mutex סטנדרטי (non-recursive) מיועד להיות נעול רק פעם אחת על ידי חוט מסוים. אם חוט מנסה לנעול mutex שכבר נעול על ידו, הוא ימתין לשחרורו. מכיוון שהחוט עצמו הוא זה שמחזיק את המנעול, הוא לעולם לא ישחרר אותו בזמן שהוא ממתין לנעילה, מה שמוביל ל-deadlock. זוהי תכונה בסיסית של mutexים למניעת נעילה חוזרת (re-entrancy) אלא אם כן הם מוגדרים במפורש כ-recursive mutex. אפשרות א' שגויה מכיוון שזו בדיוק הסיבה ל-deadlock. אפשרות ג' נכונה מבחינת שימוש ב-mutex, אך היא אינה מתארת את 'התנהגות ה-mutex' אלא את אופן יישומו. אפשרות ד' שגויה, שכן ניסיון לשחרר mutex שלא ננעל על ידי החוט הקורא או שכבר שוחרר, מוביל בדרך כלל לשגיאה או התנהגות בלתי מוגדרת."}, "difficulty_estimation": "Medium", "_source_file": "0159__Synchronization__MultipleChoice__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:46:08", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Race Condition", "Mutex"], "content": {"text": "נתונה פיסת קוד המשתמשת בשני תהליכונים (threads) המעדכנים משתנה גלובלי משותף `counter`. כל תהליכון מבצע לולאה של 100,000 איטרציות, ובכל איטרציה מגדיל את `counter` באחד. איזו מהטענות הבאות נכונה לגבי קוד זה?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0; // משתנה גלובלי משותף\n\nvoid* increment(void* arg) {\n    for (int i = 0; i < 100000; i++) {\n        counter++; // פעולה לא אטומית\n    }\n    return NULL;\n}\n\n// פונקציית main (לא מוצגת במלואה) תיצור ותריץ שני תהליכונים שיקראו ל-increment.", "options": ["א. קוד זה יבטיח שהערך הסופי של counter יהיה תמיד 200,000.", "ב. קוד זה עלול לסבול מבעיית Race Condition, וניתן לפתור אותה באמצעות שימוש ב-mutex.", "ג. קוד זה עלול לסבול מבעיית Deadlock, וניתן לפתור אותה באמצעות שימוש בסמפור.", "ד. קוד זה בטוח לשימוש (thread-safe) מכיוון שפעולת ההגדלה counter++ היא אטומית."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הטענה הנכונה היא ב'. פעולת ההגדלה `counter++` אינה אטומית; היא מורכבת מקריאה של הערך הנוכחי של `counter`, הגדלתו באחד, וכתיבת הערך החדש בחזרה לזיכרון. כאשר שני תהליכונים מנסים לבצע פעולה זו במקביל ללא מנגנון סנכרון, ייתכן שתהליכון אחד יקרא את הערך, ותהליכון שני יקרא גם הוא את אותו ערך לפני שהתהליכון הראשון הספיק לכתוב את הערך המעודכן. כתוצאה מכך, אחד העדכונים יאבד, והערך הסופי של `counter` יהיה קטן מ-200,000. מצב זה נקרא Race Condition. הפתרון הנפוץ לבעיה זו הוא הגנה על הקטע הקריטי (critical section) באמצעות mutex, שיבטיח שרק תהליכון אחד יוכל לבצע את פעולת ההגדלה בכל רגע נתון. אין כאן בעיית Deadlock מכיוון שאין תלות מעגלית במשאבים."}, "difficulty_estimation": "Medium", "_source_file": "0160__Synchronization__MultipleChoice__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:46:19", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Deadlock", "Semaphores", "Producer-Consumer"], "content": {"text": "נתונה המחלקה הבאה ב-C המממשת חוצץ מעגלי (bounded buffer) באמצעות סמפורים:\n\n```c\n#include <semaphore.h>\n#include <stdio.h>\n\n#define BUFFER_SIZE 5\n\nint buffer[BUFFER_SIZE];\nint in = 0;\n// int out = 0; // Not directly used in produce, omitted for brevity\n\nsem_t mutex;    // Ensures mutual exclusion for buffer access\nsem_t full;     // Counts number of occupied slots\nsem_t empty;    // Counts number of empty slots\n\nvoid init_semaphores() {\n    sem_init(&mutex, 0, 1);\n    sem_init(&full, 0, 0);\n    sem_init(&empty, 0, BUFFER_SIZE);\n}\n\nvoid produce(int item) {\n    // סדר פעולות שגוי שעלול לגרום לבעיה\n    sem_wait(&mutex);   // 1. תפיסת המנעול ראשונה\n    sem_wait(&empty);   // 2. המתנה למקום פנוי (תוך החזקת המנעול)\n\n    // קטע קריטי: הוספת פריט לחוצץ\n    buffer[in] = item;\n    in = (in + 1) % BUFFER_SIZE;\n\n    sem_post(&full);    // 3. איתות שמקום התמלא\n    sem_post(&mutex);   // 4. שחרור המנעול\n}\n\n// void consume() { ... } // Omitted for brevity\n// int main() { ... } // Omitted for brevity\n```\n\nאיזו בעיה עלולה להיווצר כתוצאה מהמימוש הנתון של הפונקציה `produce`?", "code_snippet": null, "options": ["א. תנאי מרוץ (race condition) בגישה לחוצץ.", "ב. קיפאון (deadlock) כאשר החוצץ מלא.", "ג. הרעבה (starvation) של תהליכי הצרכן.", "ד. בזבוז משאבים עקב busy-waiting.", "ה. אף אחת מהתשובות האחרות אינה נכונה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הבעיה במימוש הפונקציה `produce` נובעת מסדר פעולות ה-`sem_wait`. תהליך יצרן תופס תחילה את ה-`mutex` באמצעות `sem_wait(&mutex)`. לאחר מכן, הוא מנסה להמתין למקום פנוי בחוצץ באמצעות `sem_wait(&empty)`. אם החוצץ מלא (כלומר `empty` שווה ל-0), תהליך היצרן ייחסם בהמתנה ל-`empty` – אך הוא עדיין מחזיק ב-`mutex`.\n\nתהליך צרכן, על מנת לפנות מקום בחוצץ, צריך לגשת לאזור הקריטי, ולשם כך עליו לתפוס את ה-`mutex`. אולם, ה-`mutex` כבר מוחזק על ידי היצרן החסום. מצב זה מוביל לקיפאון (deadlock): היצרן חסום בהמתנה למקום פנוי (שיכול להשתחרר רק על ידי צרכן), והצרכן חסום בהמתנה ל-`mutex` (המוחזק על ידי היצרן החסום). הפתרון הנכון הוא להמתין למקום פנוי (`sem_wait(&empty)`) *לפני* תפיסת ה-`mutex` (`sem_wait(&mutex)`), כך שה-`mutex` לא יוחזק בזמן המתנה למקום בחוצץ. "}, "difficulty_estimation": "Hard", "_source_file": "0161__Synchronization__MultipleChoice__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:46:38", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Reader-Writer Lock", "Starvation", "Concurrency"], "content": {"text": "נתונה מימוש חלקי של מנגנון נעילת קוראים-כותבים (Reader-Writer Lock) ב-C/C++ באמצעות mutex-ים של pthreads. המטרה היא לאפשר לקוראים מרובים לגשת למשאב במקביל, אך לאפשר רק לכותב אחד לגשת למשאב בכל רגע, ולמנוע גישת קוראים בזמן כתיבה.\n\n```c\n#include <pthread.h>\n#include <semaphore.h>\n\n// Global variables\nint readers_count = 0;\npthread_mutex_t mutex_readers; // Protects readers_count\npthread_mutex_t resource_lock; // Protects the shared resource for writers\n\nvoid init() {\n    pthread_mutex_init(&mutex_readers, NULL);\n    pthread_mutex_init(&resource_lock, NULL);\n}\n\nvoid reader_acquire() {\n    pthread_mutex_lock(&mutex_readers);\n    readers_count++;\n    if (readers_count == 1) {\n        pthread_mutex_lock(&resource_lock); // First reader locks resource for writers\n    }\n    pthread_mutex_unlock(&mutex_readers);\n}\n\nvoid reader_release() {\n    pthread_mutex_lock(&mutex_readers);\n    readers_count--;\n    if (readers_count == 0) {\n        pthread_mutex_unlock(&resource_lock); // Last reader unlocks resource for writers\n    }\n    pthread_mutex_unlock(&mutex_readers);\n}\n\nvoid writer_acquire() {\n    pthread_mutex_lock(&resource_lock); // Writer locks the resource\n}\n\nvoid writer_release() {\n    pthread_mutex_unlock(&resource_lock); // Writer unlocks the resource\n}\n```\n\nבהתבסס על הקוד לעיל, איזו מהטענות הבאות נכונה לגבי המימוש?", "code_snippet": null, "options": ["א. המימוש נכון ומבטיח שאין תנאי מרוץ (race conditions) ואין רעב (starvation) עבור אף סוג של תהליכים (קוראים או כותבים).", "ב. המימוש עלול לגרום לתנאי מרוץ כאשר מספר קוראים מנסים להיכנס בו זמנית.", "ג. המימוש עלול לגרום לרעב של כותבים (writer starvation) אם יש זרם קבוע של קוראים.", "ד. המימוש עלול לגרום לרעב של קוראים (reader starvation) אם יש זרם קבוע של כותבים.", "ה. המימוש עלול לגרום למבוי סתום (deadlock) במצבים מסוימים."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג. המימוש עלול לגרום לרעב של כותבים (writer starvation) אם יש זרם קבוע של קוראים.", "explanation": "הסבר: המימוש הנתון הוא סוג של מנגנון קוראים-כותבים המעדיף קוראים. כאשר קורא ראשון מגיע, הוא נועל את המשאב (resource_lock), וחוסם כותבים. קוראים נוספים יכולים להיכנס בחופשיות. הבעיה המרכזית מתרחשת כאשר יש זרם מתמשך של קוראים: כל עוד יש לפחות קורא אחד פעיל, resource_lock נשאר תפוס על ידי קבוצת הקוראים, והכותבים הממתינים על writer_acquire לעולם לא יוכלו לתפוס את המנעול, וכתוצאה מכך יסבלו מרעב (starvation). אין תנאי מרוץ על readers_count מכיוון שהוא מוגן על ידי mutex_readers. אין מבוי סתום מכיוון שאין תלות מעגלית במנעולים, והמנעולים נתפסים ומשוחררים בסדר לינארי פשוט שאינו יוצר מעגל המתנה."}, "difficulty_estimation": "Hard", "_source_file": "0162__Synchronization__MultipleChoice__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:46:59", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Condition Variables", "Starvation", "Concurrency"], "content": {"text": "נתונה תבנית קוד C/C++ לניהול מאגר משאבים משותף. כל תהליך יכול לבקש כמות משתנה של משאבים מהמאגר. אם אין מספיק משאבים זמינים, התהליך ממתין על משתנה התנאי `cond`. כאשר תהליך משחרר משאבים למאגר, הוא צריך להודיע לתהליכים הממתינים.\n\nאיזו קריאה לפונקציית הודעה (notification) יש לבצע בתוך `release_items` כדי למנוע קיפאון (starvation) או חוסר יעילות משמעותי במערכת, בהתחשב בכך שייתכנו תהליכים רבים הממתינים למספרים שונים של משאבים?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For usleep\n\nconst int MAX_ITEMS = 10;\nint available_items = MAX_ITEMS;\npthread_mutex_t mtx = PTHREAD_MUTEX_INITIALIZER;\npthread_cond_t cond = PTHREAD_COND_INITIALIZER;\n\nvoid acquire_items(int num_to_acquire, int thread_id) {\n    pthread_mutex_lock(&mtx);\n    // printf(\"Thread %d requesting %d items. Available: %d\\n\", thread_id, num_to_acquire, available_items);\n    while (available_items < num_to_acquire) {\n        pthread_cond_wait(&cond, &mtx);\n    }\n    available_items -= num_to_acquire;\n    // printf(\"Thread %d acquired %d items. Available: %d\\n\", thread_id, num_to_acquire, available_items);\n    pthread_mutex_unlock(&mtx);\n    // Simulate work outside critical section\n    usleep(100000); // 100 ms\n}\n\nvoid release_items(int num_to_release, int thread_id) {\n    pthread_mutex_lock(&mtx);\n    available_items += num_to_release;\n    // printf(\"Thread %d released %d items. Available: %d\\n\", thread_id, num_to_release, available_items);\n    // איזו קריאה יש לבצע כאן כדי להודיע לתהליכים ממתינים?\n    // א. pthread_cond_signal(&cond);\n    // ב. pthread_cond_broadcast(&cond);\n    // ג. אין צורך בקריאה כלשהי.\n    // ד. כל התשובות האחרות אינן נכונות.\n    pthread_mutex_unlock(&mtx);\n}", "options": ["א. pthread_cond_signal(&cond);", "ב. pthread_cond_broadcast(&cond);", "ג. אין צורך בקריאה כלשהי.", "ד. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "במקרה זה, יש להשתמש ב-`pthread_cond_broadcast(&cond);`. הסיבה לכך היא שתהליכים שונים עשויים להמתין לכמויות שונות של משאבים. כאשר משאבים משוחררים, ייתכן שיותר מתהליך אחד יוכל כעת להמשיך, או שהתהליך היחיד שהתעורר על ידי `pthread_cond_signal` לא יוכל להמשיך (כי עדיין אין מספיק משאבים עבורו, בעוד שתהליך אחר שזקוק לפחות משאבים כן היה יכול). שימוש ב-`pthread_cond_signal` במצב כזה עלול להוביל לקיפאון (starvation) של תהליכים שיכולים היו להמשיך, או לחוסר יעילות משמעותי עקב התעוררויות שווא (spurious wakeups) שאינן מקדמות את המערכת. `pthread_cond_broadcast` מבטיח שכל התהליכים הממתינים יבדקו מחדש את תנאיהם, ומאפשר לכל התהליכים שיכולים להמשיך לעשות זאת, ובכך מונע קיפאון ומבטיח יעילות רבה יותר."}, "difficulty_estimation": "Hard", "_source_file": "0163__Synchronization__MultipleChoice__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:47:29", "_subject": "Concurrency"}, {"id": 10, "type": "MultipleChoice", "topic": ["Synchronization", "Peterson's Algorithm", "Memory Barriers", "Concurrency"], "content": {"text": "נניח מימוש של אלגוריתם פיטרסון (Peterson's Algorithm) עבור שני תהליכים (P0 ו-P1) במערכת מודרנית שבה המעבד או הקומפיילר עשויים לבצע אופטימיזציות של Reordering (שינוי סדר פעולות) לפעולות קריאה וכתיבה לזיכרון. הקוד עבור P0 מוצג להלן. מהי הסכנה העיקרית בהרצת קוד זה ללא שימוש ב-Memory Barriers (מחסומי זיכרון) או במשתנים אטומיים?", "code_snippet": "flag[0] = true;\nturn = 1;\nwhile (flag[1] && turn == 1);\n// Critical Section\nflag[0] = false;", "options": ["א. לא קיימת סכנה, האלגוריתם הוכח מתמטית ולכן יעבוד תמיד ללא קשר לארכיטקטורת החומרה.", "ב. ייתכן מצב שבו שני התהליכים יכנסו לקטע הקריטי בו-זמנית (פגיעה ב-Mutual Exclusion).", "ג. המערכת תיכנס ל-Deadlock ודאי בכל פעם ששני התהליכים ינסו להיכנס לקטע הקריטי יחד.", "ד. התהליכים יסבלו מהרעבה (Starvation) כיוון ש-turn לעולם לא יתעדכן בזמן, אך ה-Mutual Exclusion יישמר."]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "בארכיטקטורות מחשב מודרניות, המעבד או הקומפיילר עשויים לשנות את סדר פעולות הכתיבה והקריאה (Out-of-order execution) כדי לשפר ביצועים. ללא Memory Barriers, ייתכן שהכתיבה ל-flag[0] תתבצע בפועל (או תיראה לשאר הליבות) רק אחרי הקריאה של flag[1] בתוך הלולאה. במצב כזה, שני התהליכים עלולים לראות ש-flag של הצד השני הוא false בו-זמנית, ושניהם ייכנסו לקטע הקריטי יחד, מה שמפר את עקרון ה-Mutual Exclusion."}, "difficulty_estimation": "Hard", "_source_file": "0164__Synchronization__MultipleChoice__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:55:22", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Deadlock", "Condition Variables", "Concurrency", "Multithreading"], "content": {"text": "נתונה תוכנית C++ המממשת מחסום (barrier) ל-`NUM_THREADS` תהליכונים, המיועד לשימוש חוזר במספר סבבים. התהליכונים מבצעים עבודה, מגיעים למחסום, ממתינים שכל שאר התהליכונים יגיעו, ואז ממשיכים. המחסום מוגדר כדלקמן: \n\nמה יקרה כאשר התוכנית תרוץ עם `NUM_THREADS = 3`?", "code_snippet": "#include <iostream>\n#include <vector>\n#include <thread>\n#include <mutex>\n#include <condition_variable>\n#include <chrono>\n\nconst int NUM_THREADS = 3;\nstd::mutex mtx;\nstd::condition_variable cv;\nint arrived_count = 0;\n\nvoid barrier_function() {\n    std::unique_lock<std::mutex> lock(mtx);\n    arrived_count++;\n\n    if (arrived_count == NUM_THREADS) {\n        cv.notify_one(); // נקודת הכשל הפוטנציאלית\n        arrived_count = 0; // איפוס לסבב הבא\n    } else {\n        cv.wait(lock);\n    }\n}\n\nvoid worker_thread() {\n    std::this_thread::sleep_for(std::chrono::milliseconds(10));\n    barrier_function(); // סבב ראשון\n    std::this_thread::sleep_for(std::chrono::milliseconds(10));\n    barrier_function(); // סבב שני\n}\n\nint main() {\n    std::vector<std::thread> threads;\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        threads.emplace_back(worker_thread);\n    }\n    for (auto& t : threads) {\n        t.join();\n    }\n    // This line will likely not be reached due to deadlock\n    // std::cout << \"Main finished.\" << std::endl;\n    return 0;\n}", "options": ["א. התוכנית תרוץ בהצלחה ותסיים את פעולתה כרגיל.", "ב. יתרחש מצב של מרוץ (race condition) אך התוכנית תמיד תסיים בהצלחה.", "ג. יתרחש קיפאון (deadlock) של חלק מהתהליכונים בסבב השני של המחסום.", "ד. יתרחש קיפאון (deadlock) של כל התהליכונים כבר בסבב הראשון של המחסום.", "ה. התוכנית תקרוס עקב גישה לא חוקית לזיכרון."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התשובה הנכונה היא ג'.\nהבעיה טמונה בשימוש ב-`cv.notify_one()` במקום `cv.notify_all()` כאשר `arrived_count == NUM_THREADS` במחסום רב-פעמי.\n\nבסבב הראשון של המחסום:\n1. שלושת התהליכונים (T1, T2, T3) קוראים ל-`barrier_function()`.\n2. `arrived_count` יגיע ל-3. אחד התהליכונים (נניח T3) יגיע ראשון לשלב זה ויקרא ל-`cv.notify_one()`.\n3. `arrived_count` יתאפס ל-0.\n4. `cv.notify_one()` יעיר רק תהליכון אחד מבין שני התהליכונים האחרים שממתינים (T1 או T2). נניח ש-T1 מתעורר.\n5. כעת, T1 ו-T3 ממשיכים לאחר המחסום (T3 כי הוא קרא ל-`notify_one` ולא נכנס ל-`wait`, ו-T1 כי הוא התעורר). T2 נשאר במצב המתנה (waiting) מהסבב הראשון.\n\nבסבב השני של המחסום:\n1. T1 ו-T3 קוראים שוב ל-`barrier_function()`.\n2. `arrived_count` יגיע ל-1 (מ-T1) ואז ל-2 (מ-T3).\n3. T1 ו-T3 ייכנסו למצב המתנה (calling `cv.wait(lock)`), מכיוון ש-`arrived_count` לא יגיע ל-`NUM_THREADS` (שהוא 3). הם ימתינו לתהליכון השלישי.\n4. T2 עדיין ממתין מהסבב הראשון ולעולם לא יתעורר, מכיוון שהאות `notify_one` כבר נשלח בסבב הראשון והוא לא נבחר להתעורר, ואין מי שיעיר אותו שוב. לכן, `arrived_count` לעולם לא יגיע ל-3 בסבב השני.\n5. התוצאה היא ש-T1 ו-T3 ימתינו ללא הגבלת זמן (deadlock), מכיוון שהם ממתינים לתהליכון השלישי (שכבר נמצא בקיפאון מהסבב הראשון), ו-T2 עצמו בקיפאון. זהו קיפאון של חלק מהתהליכונים (T1, T2, T3 כולם בסופו של דבר) שנובע מהשימוש השגוי ב-`notify_one` במקום `notify_all` במחסום רב-פעמי."}, "difficulty_estimation": "Hard", "_source_file": "0165__Synchronization__MultipleChoice__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:47:58", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Concurrency", "Barrier"], "content": {"text": "נתון קטע קוד ב-C המממש מחסום (barrier) עבור מספר קבוע של תהליכים (NUM_THREADS). המחסום מיועד לאפשר לכל התהליכים להגיע לנקודה מסוימת לפני שכולם ממשיכים יחד. איזו מן הטענות הבאות מתארת נכונה בעיה פוטנציאלית בקוד וכיצד ניתן לפתור אותה באופן נכון?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\n#define NUM_THREADS 3 // Small number for easier analysis\n\npthread_mutex_t barrier_mutex = PTHREAD_MUTEX_INITIALIZER;\npthread_cond_t barrier_cond = PTHREAD_COND_INITIALIZER;\nint threads_arrived = 0; // Number of threads that have arrived at the barrier\n\nvoid *worker_thread(void *arg) {\n    long id = (long)arg;\n    printf(\"Thread %ld: Started, doing some work...\\n\", id);\n    sleep(1); // Simulate some work\n\n    pthread_mutex_lock(&barrier_mutex);\n    threads_arrived++;\n    printf(\"Thread %ld: Arrived at barrier. threads_arrived = %d\\n\", id, threads_arrived);\n\n    if (threads_arrived < NUM_THREADS) {\n        pthread_cond_wait(&barrier_cond, &barrier_mutex);\n    } else {\n        printf(\"Thread %ld: Last one, broadcasting!\\n\", id);\n        threads_arrived = 0; // Reset for next use\n        pthread_cond_broadcast(&barrier_cond);\n    }\n    pthread_mutex_unlock(&barrier_mutex);\n\n    printf(\"Thread %ld: Passed barrier, continuing...\\n\", id);\n    // Simulate more work after barrier\n    sleep(1);\n    printf(\"Thread %ld: Finished.\\n\", id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    for (long i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, worker_thread, (void *)i);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"All threads finished.\\n\");\n    return 0;\n}", "options": ["א. הקוד עלול לגרום למצב קיפאון (deadlock) מכיוון ש-pthread_cond_broadcast מעיר רק חלק מהתהליכים, ואילו אחרים נשארים בהמתנה. הפתרון הנכון הוא להשתמש ב-pthread_cond_signal במקום pthread_cond_broadcast.", "ב. הקוד עלול לגרום למצב קיפאון (deadlock). כאשר התהליך האחרון מגיע ומאפס את threads_arrived ל-0 לפני שכל התהליכים שהיו בהמתנה הספיקו להתעורר ולעבור את תנאי ה-if, תהליכים שהתעוררו מאוחר יבדקו threads_arrived < NUM_THREADS (שיהיה 0 < NUM_THREADS) ויכנסו שוב להמתנה בלתי מוגבלת. הפתרון הנכון הוא להשתמש במונה דורות (generation counter) או בשני משתני תנאי כדי למנוע מתהליכים להתעורר ולבדוק תנאי של מחזור עתידי.", "ג. הקוד סובל מבעיית תנאי מירוץ (race condition) בגישה למשתנה threads_arrived מכיוון שהוא אינו מוגן על ידי מנעול. הפתרון הוא לעטוף את כל הגישות ל-threads_arrived בקריאות pthread_mutex_lock ו-pthread_mutex_unlock.", "ד. הקוד אינו מכיל בעיות סנכרון והוא יפעל כראוי בכל התרחישים, שכן pthread_cond_broadcast מבטיח שכל התהליכים יתעוררו."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הבעיה בקוד היא מצב קיפאון (deadlock) פוטנציאלי במחסום. כאשר התהליך האחרון מגיע למחסום, הוא מאפס את threads_arrived ל-0 וקורא ל-pthread_cond_broadcast. pthread_cond_broadcast מעיר את כל התהליכים שממתינים על barrier_cond. תהליכים אלו, לאחר שהתעוררו ותפסו מחדש את המנעול barrier_mutex, בודקים שוב את התנאי `if (threads_arrived < NUM_THREADS)`. מכיוון ש-`threads_arrived` אופס כבר ל-0 על ידי התהליך האחרון, התנאי `0 < NUM_THREADS` יהיה תמיד נכון עבור תהליכים אלו, והם יכנסו שוב ל-`pthread_cond_wait` וימתינו באופן בלתי מוגבל. הם לעולם לא יתעוררו שוב מכיוון שאין תהליכים נוספים שיגיעו למחסום ויקראו ל-`pthread_cond_broadcast` עבור מחזור זה. הפתרון הנפוץ לבעיה זו במחסומים מחזוריים (או במחסומים עם פוטנציאל לשימוש חוזר) הוא שימוש ב\"מונה דורות\" (generation counter) או בשני משתני תנאי. מונה הדורות מבטיח שגם אם תהליך מתעורר מאוחר, הוא לא יבלבל את מחזור המחסום הנוכחי עם מחזור עתידי, אלא ימתין רק אם מונה הדורות שלו אינו תואם למונה הדורות הנוכחי של המחסום."}, "difficulty_estimation": "Hard", "_source_file": "0166__Synchronization__MultipleChoice__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:48:42", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Concurrency", "Condition Variables", "Race Conditions"], "content": {"text": "נתון קטע קוד C++ המייצג חלק ממימוש צרכן בתבנית מפיק-צרכן באמצעות `std::mutex` ו-`std::condition_variable`. הצֶרְכָן ממתין לפריטים בחוצץ משותף. איזו בעיה פוטנציאלית חמורה קיימת במימוש זה של פונקציית הצרכן?", "code_snippet": "#include <mutex>\n#include <condition_variable>\n#include <queue>\n\nstd::mutex mtx;\nstd::condition_variable cv;\nstd::queue<int> buffer; // Assume this is shared and populated by a producer\n\nvoid consumer_func() {\n    std::unique_lock<std::mutex> lock(mtx);\n    if (buffer.empty()) {\n        cv.wait(lock);\n    }\n    // Assume after this point, the consumer attempts to process an item.\n}", "options": ["א. הקוד עלול לגרום ל-deadlock אם הצרכן מתעורר לפני שיש פריטים בחוצץ.", "ב. הקוד סובל מבעיה של \"התעוררות אבודה\" (missed wakeup), שבה הצרכן עלול להמתין ללא הגבלת זמן למרות שיש פריטים בחוצץ.", "ג. הקוד עלול לגרום ל-starvation של המפיק, מכיוון שהצרכן לא משחרר את המנעול בזמן.", "ד. הקוד עלול לגרום ל-race condition על המשתנה `buffer.empty()`, מכיוון שהוא לא מוגן כראוי.", "ה. אין בעיה פוטנציאלית חמורה בקוד, והוא נכון מבחינה לוגית עבור תרחיש בסיסי."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. הבעיה העיקרית כאן היא \"התעוררות אבודה\" (missed wakeup). אם התנאי `buffer.empty()` מתקיים, הצרכן נכנס לבלוק ה-`if`. בין הבדיקה `buffer.empty()` לבין הקריאה ל-`cv.wait(lock)`, ייתכן שהמפיק יוסיף פריט לחוצץ ויקרא ל-`cv.notify_one()`. במקרה כזה, ה-`notify_one` \"נאבד\" מכיוון שהצרכן עדיין לא נכנס למצב המתנה. לאחר מכן, הצרכן יקרא ל-`cv.wait(lock)` וייכנס למצב המתנה, אך לא יקבל את ההתראה שכבר נשלחה, ועלול להמתין ללא הגבלת זמן למרות שיש פריט בחוצץ. הפתרון הנכון הוא לבדוק את התנאי בלולאת `while` (כלומר, `while (buffer.empty()) { cv.wait(lock); }`) או להשתמש בגרסת ה-`wait` שמקבלת פרדיקט (למשל, `cv.wait(lock, []{ return !buffer.empty(); });`), כדי להתמודד גם עם \"התעוררויות שווא\" (spurious wakeups) וגם עם בעיית ה-\"התעוררות אבודה\".\n\nניתוח תשובות אחרות:\nא. deadlock: לא סביר שזה יגרום ל-deadlock באופן ישיר מהקוד הזה. ה-`cv.wait` משחרר את המנעול באופן אטומי לפני הכניסה למצב המתנה, כך שתהליכים אחרים (כמו המפיק) יכולים לתפוס את המנעול. הבעיה כאן היא לא חסימה הדדית.\nג. starvation של המפיק: הצרכן משחרר את המנעול לפני ה-`wait`, כך שהמפיק יכול לתפוס את המנעול ולהוסיף פריטים. הבעיה היא יותר שהצרכן לא יתעורר, לא שהמפיק לא יוכל לייצר.\nד. race condition על `buffer.empty()`: הבדיקה `buffer.empty()` מתבצעת בתוך קטע קריטי (לאחר תפיסת המנעול `lock(mtx)`), כך שאין race condition על הבדיקה עצמה. ה-race condition הוא על ה-timing של ה-`notify_one` ביחס ל-`wait`."}, "difficulty_estimation": "Hard", "_source_file": "0167__Synchronization__MultipleChoice__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:49:09", "_subject": "Concurrency"}, {"id": 10, "type": "MultipleChoice", "topic": ["Synchronization", "Condition Variables", "Race Conditions", "Lost Wakeup"], "content": {"text": "נתון הקוד הבא המממש סנכרון פשוט בין שני תהליכונים (Threads). תהליכון א' ממתין שמשתנה גלובלי בשם ready יהפוך ל-1, ותהליכון ב' מעדכן את ערכו. המשתנים m (מסוג pthread_mutex_t) ו-c (מסוג pthread_cond_t) אותחלו כראוי. איזה מהמשפטים הבאים מתאר בצורה המדויקת ביותר את הבעיה הפוטנציאלית בקוד?", "code_snippet": "// Global variables\nint ready = 0;\npthread_mutex_t m;\npthread_cond_t c;\n\n// Thread A:\npthread_mutex_lock(&m);\nwhile (ready == 0) {\n    pthread_cond_wait(&c, &m);\n}\npthread_mutex_unlock(&m);\n\n// Thread B:\nready = 1;\npthread_cond_signal(&c);", "options": ["א. הקוד תקין לחלוטין; ביצוע pthread_cond_signal ללא נעילת המנעול הוא מותר ותקין תמיד.", "ב. תיתכן בעיית 'Lost Wakeup': תהליכון א' עלול לבדוק את התנאי, למצוא שהוא 0, אך לפני שיקרא ל-wait, תהליכון ב' יעדכן את המשתנה וישלח סיגנל שייאבד.", "ג. הקוד יגרום בהכרח ל-Deadlock כיוון שתהליכון ב' לא משחרר מנעול שלא נעל.", "ד. תהליכון א' עלול להיכנס ללולאה אינסופית בגלל Spurious Wakeup גם אם ready שונה ל-1.", "ה. תהליכון ב' יקרוס (Segmentation Fault) בזמן הקריאה ל-pthread_cond_signal כי המנעול m אינו מוחזק על ידו."]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הבעיה היא היעדר סנכרון על המשתנה המשותף ready בתהליכון ב'. תרחיש אפשרי: תהליכון א' נועל את המנעול, בודק את ready ורואה שהוא 0. לפני ש-א' קורא ל-pthread_cond_wait (שמשחרר את המנעול אטומית), מתבצע context switch. תהליכון ב' מעדכן את ready ל-1 ושולח סיגנל. כיוון שאין אף תהליכון שממתין כרגע על c, הסיגנל הולך לאיבוד. כש-א' חוזר לפעול, הוא קורא ל-wait ונרדם לנצח, למרות ש-ready כבר 1. לכן חובה לעדכן את המשתנה ולשלוח את הסיגנל תחת הגנת המנעול."}, "difficulty_estimation": "Hard", "_source_file": "0168__Synchronization__MultipleChoice__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:55:43", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Semaphores", "Threads"], "content": {"text": "לפניכם קטע קוד בשפת C המשתמש בשני חוטים (threads) לעדכון משתנה גלובלי משותף בשם counter. הסמפור s מאותחל לערך 1.", "code_snippet": "int counter = 0;\nsem_t s;\n\nvoid* increment(void* arg) {\n    for (int i = 0; i < 50; i++) {\n        sem_wait(&s);\n        counter++;\n        sem_post(&s);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    sem_init(&s, 0, 1);\n    pthread_create(&t1, NULL, increment, NULL);\n    pthread_create(&t2, NULL, increment, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"%d\", counter);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "מהו הערך שיודפס בסיום ריצת התוכנית? הסבירו בקצרה מדוע.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "נניח שמתכנת בטעות הסיר את השורה sem_post(&s); מתוך הלולאה. כיצד תשתנה התנהגות התוכנית?", "code_snippet": null, "options": null}], "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: הערך שיודפס הוא 100. כל אחד משני החוטים מבצע 50 איטרציות של הגדלת המשתנה counter. מכיוון שהגישה למשתנה המשותף מוגנת על ידי סמפור בינארי (המשמש כ-Mutex), לא יתרחשו מצבי מרוץ (Race Conditions) וכל העדכונים יישמרו.\n\n10.2: התוכנית תיכנס למצב של קיפאון (Deadlock/Hang). החוט הראשון שיצליח להיכנס לקטע הקריטי יבצע sem_wait ויוריד את ערך הסמפור ל-0. מכיוון שאין sem_post, ערך הסמפור לא יחזור ל-1 לעולם. לכן, באיטרציה השנייה שלו (או כאשר החוט השני ינסה להיכנס), הוא ייחסם ב-sem_wait לנצח."}, "difficulty_estimation": "Easy", "_source_file": "0169__Synchronization__Open__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:55:58", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Race Condition", "Mutex", "Threads"], "content": {"text": "נתונה תוכנית C בה מספר חוטים (threads) ניגשים במקביל למשתנה גלובלי משותף ומגדילים אותו. קטע הקוד הבא מציג את הפונקציה אותה מריץ כל חוט:", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint shared_counter = 0; // משתנה גלובלי משותף\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < 100000; ++i) {\n        shared_counter++; // גישה למשתנה המשותף\n    }\n    return NULL;\n}\n\n// פונקציית main לא הוצגה במלואה, אך היא יוצרת מספר חוטים המריצים את increment_counter", "options": null}, "sub_questions": [{"id": "10.1", "text": "הסבירו מדוע קטע הקוד הנ\"ל עלול להוביל לתוצאה שגויה כאשר מספר חוטים מריצים אותו במקביל. מהו הבעיה המרכזית כאן?", "code_snippet": null, "options": null}, {"id": "10.2", "text": "הציעו פתרון לבעיה באמצעות מנעול (mutex) בסביבת pthreads. כתבו את קטע הקוד המתוקן.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: הבעיה המרכזית היא תנאי מרוץ (Race Condition). הפעולה `shared_counter++` אינה פעולה אטומית. למעשה, היא מתורגמת למספר הוראות מכונה:\n1. קריאת הערך של `shared_counter` מהזיכרון לתוך רגיסטר.\n2. הגדלת הערך ברגיסטר באחד.\n3. כתיבת הערך המעודכן מהרגיסטר בחזרה לזיכרון.\n\nכאשר מספר חוטים מריצים את הפעולות הללו במקביל, ייתכן שחוט אחד יקרא את הערך של `shared_counter`, לפני שחוט אחר הספיק לכתוב את ערכו המעודכן בחזרה. לדוגמה, אם `shared_counter` הוא 10, חוט A קורא 10, חוט B קורא 10. שניהם מגדילים ל-11 ברגיסטר שלהם. חוט A כותב 11, ומיד אחריו חוט B כותב 11. במקרה כזה, למרות שבוצעו שתי פעולות הגדלה, המונה יגדל רק באחד במקום בשניים, מה שיוביל לתוצאה שגויה (פחותה מהצפוי).\n\n10.2: כדי לפתור את בעיית תנאי המרוץ, יש להגן על הגישה למשתנה המשותף `shared_counter` באמצעות מנעול (mutex). מנעול מבטיח שרק חוט אחד יוכל להיכנס לקטע קריטי (Critical Section) מסוים בכל רגע נתון.\nיש לאתחל את המנעול, לנעול אותו לפני הגישה למשתנה המשותף, ולשחרר אותו לאחר מכן.\n\nקוד מתוקן:\n```c\n#include <stdio.h>\n#include <pthread.h>\n\nint shared_counter = 0; // משתנה גלובלי משותף\npthread_mutex_t counter_mutex; // הכרזת על מנעול\n\nvoid* increment_counter_safe(void* arg) {\n    for (int i = 0; i < 100000; ++i) {\n        pthread_mutex_lock(&counter_mutex); // נעל את המנעול\n        shared_counter++;                   // גישה בטוחה למשתנה המשותף\n        pthread_mutex_unlock(&counter_mutex); // שחרר את המנעול\n    }\n    return NULL;\n}\n\n// פונקציית main (לצורך הדגמה, לא חלק מהשאלה המקורית)\n/*\nint main() {\n    pthread_t threads[5];\n    pthread_mutex_init(&counter_mutex, NULL); // אתחול המנעול\n\n    for (int i = 0; i < 5; ++i) {\n        pthread_create(&threads[i], NULL, increment_counter_safe, NULL);\n    }\n\n    for (int i = 0; i < 5; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", shared_counter); // אמור להיות 500000\n    pthread_mutex_destroy(&counter_mutex); // שחרור המנעול\n    return 0;\n}\n*/\n```"}, "difficulty_estimation": "Easy", "_source_file": "0170__Synchronization__Open__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:49:24", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Synchronization", "Mutex", "Race Condition"], "content": {"text": "נתונים שני חוטים (Threads) המריצים את הפונקציה `increment_counter` במקביל. המשתנה `counter` הוא משתנה גלובלי המאותחל ל-0. הנח כי אין אופטימיזציות של הקומפיילר וכי הפעולות מבוצעות בדיוק כפי שהן כתובות.", "code_snippet": "int counter = 0;\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < 100; i++) {\n        int temp = counter;\n        temp = temp + 1;\n        counter = temp;\n    }\n    return NULL;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "מהו השם של התופעה שעלולה לגרום לכך שהערך הסופי של המשתנה `counter` יהיה נמוך מ-200?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "הציעו פתרון המשתמש ב-Mutex (מנעול) על מנת להבטיח שהערך הסופי של `counter` יהיה תמיד 200. יש לכתוב את קטע הקוד הרלוונטי.", "code_snippet": null, "options": null}], "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: התופעה נקראת 'מרוץ תהליכים' (Race Condition). היא מתרחשת כאשר מספר חוטים ניגשים למשאב משותף (במקרה זה המשתנה counter) ומבצעים עליו פעולות של קריאה וכתיבה ללא סנכרון, כך שהתוצאה הסופית תלויה בסדר התזמון של החוטים.\n\n1.2: כדי לפתור זאת, יש להשתמש ב-Mutex שיבטיח שרק חוט אחד נמצא ב'קטע הקריטי' (Critical Section) בכל זמן נתון. \nקוד מוצע:\n\npthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < 100; i++) {\n        pthread_mutex_lock(&lock);\n        int temp = counter;\n        temp = temp + 1;\n        counter = temp;\n        pthread_mutex_unlock(&lock);\n    }\n    return NULL;\n}"}, "difficulty_estimation": "Easy", "_source_file": "0171__Synchronization__Open__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:56:17", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Race Condition", "Mutex"], "content": {"text": "נתון קטע קוד ב-C המציג פונקציה `increment_counter` המופעלת על ידי מספר תהליכונים במקביל. הפונקציה מגדילה מונה גלובלי משותף.", "code_snippet": "int global_counter = 0;\n\nvoid increment_counter() {\n    int temp = global_counter;\n    // Simulate some work\n    // usleep(1000);\n    global_counter = temp + 1;\n}"}, "sub_questions": [{"id": "10.1", "text": "הסבר מדוע קטע הקוד הזה עלול לגרום לבעיית מירוץ (Race Condition) כאשר מספר תהליכונים מפעילים את `increment_counter` במקביל.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "הצג קטע קוד מתוקן המשתמש במנעול (mutex) כדי למנוע את בעיית המירוץ ולהבטיח שהמונה הגלובלי יתעדכן בצורה נכונה. כלול את ההכרזה, האתחול והשחרור של המנעול.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: בעיית מירוץ (Race Condition) מתרחשת כאשר מספר תהליכונים ניגשים למשאב משותף (במקרה זה, `global_counter`) ומנסים לשנות אותו בו-זמנית, והתוצאה הסופית תלויה בסדר הלא-דטרמיניסטי שבו התהליכונים מבצעים את פעולותיהם. בקטע הקוד הנתון, פעולת ההגדלה (`global_counter = temp + 1;`) אינה אטומית. אם שני תהליכונים קוראים את `global_counter` (למשל, שניהם קוראים 0) כמעט באותו זמן, ואז שניהם מגדילים את הערך שקראו ל-1 וכותבים בחזרה, במקום שהמונה יהיה 2, הוא יהיה רק 1. זאת מכיוון שכל אחד מהם עבד על עותק משלו של הערך הישן, וכתב אותו בחזרה מבלי להתחשב בשינויים של תהליכונים אחרים. הוספת `usleep` מדמה עיכוב ומגדילה את הסיכוי לבעיה זו.\n\n10.2: כדי למנוע את בעיית המירוץ, יש להגן על הקטע הקריטי (Critical Section) שבו המשתנה המשותף `global_counter` נקרא ונכתב. נשתמש במנעול (mutex) כדי להבטיח שרק תהליכון אחד יוכל להיכנס לקטע קריטי זה בכל רגע נתון.\n```c\n#include <pthread.h>\n#include <stdio.h>\n// #include <unistd.h> // For usleep, if needed for testing\n\nint global_counter = 0;\npthread_mutex_t counter_mutex; // Declare a mutex\n\nvoid increment_counter() {\n    pthread_mutex_lock(&counter_mutex); // Acquire the lock\n    // Critical Section\n    int temp = global_counter;\n    // Simulate some work (should be minimal in critical section if performance is key)\n    // usleep(1000);\n    global_counter = temp + 1;\n    // End Critical Section\n    pthread_mutex_unlock(&counter_mutex); // Release the lock\n}\n\n// Example of how mutex would be initialized and destroyed in main:\n// int main() {\n//     pthread_mutex_init(&counter_mutex, NULL); // Initialize the mutex\n//     // ... create and join threads that call increment_counter()...\n//     pthread_mutex_destroy(&counter_mutex); // Destroy the mutex\n//     return 0;\n// }\n```\nהסבר:\n1.  **הכרזה ואתחול המנעול**: `pthread_mutex_t counter_mutex;` מכריז על משתנה מנעול. `pthread_mutex_init(&counter_mutex, NULL);` מאתחל אותו לפני השימוש (לרוב בפונקציית `main` או בפונקציית אתחול מערכת). יש לזכור גם לשחרר את המשאבים של המנעול באמצעות `pthread_mutex_destroy()` בסיום השימוש כדי למנוע דליפות זיכרון.\n2.  **נעילה (Lock)**: `pthread_mutex_lock(&counter_mutex);` מבוצעת לפני הכניסה לקטע הקריטי. אם המנעול כבר תפוס על ידי תהליכון אחר, התהליכון הנוכחי ייחסם (יעבור למצב המתנה) עד שהמנעול ישוחרר. זה מבטיח בלעדיות הדדית (mutual exclusion) לקטע הקריטי.\n3.  **שחרור (Unlock)**: `pthread_mutex_unlock(&counter_mutex);` מבוצעת לאחר היציאה מהקטע הקריטי, ומשחררת את המנעול, ובכך מאפשרת לתהליכונים אחרים שחסומים להיכנס לקטע הקריטי."}, "difficulty_estimation": "Easy", "_source_file": "0172__Synchronization__Open__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:49:44", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Race Condition", "Mutex", "Threads"], "content": {"text": "נתון קטע הקוד הבא בשפת C המשתמש בספריית pthreads. הקוד יוצר שני תהליכונים (threads) שכל אחד מהם מגדיל משתנה גלובלי משותף `counter` 100,000 פעמים.\n\nמהו הערך הסופי ה *צפוי* של המונה `counter` לאחר ששני התהליכונים יסיימו את ריצתם? האם ערך זה מובטח תמיד? אם לא, הסבר מדוע וכיצד ניתן לתקן את הבעיה כדי להבטיח שהמונה יגיע לערך הצפוי בכל הרצה, תוך שימוש במנגנון סנכרון מתאים.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0;\n\nvoid *increment(void *arg) {\n    for (int i = 0; i < 100000; i++) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n    pthread_create(&tid1, NULL, increment, NULL);\n    pthread_create(&tid2, NULL, increment, NULL);\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n    printf(\"Final counter: %d\\n\", counter);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הערך הסופי הצפוי של המונה `counter` הוא 200,000 (100,000 מכל תהליכון).\n\nערך זה אינו מובטח תמיד. הבעיה היא תנאי מרוץ (race condition). הפעולה `counter++` אינה פעולה אטומית. היא מורכבת משלוש פעולות בסיסיות: קריאת ערך המונה לתוך רגיסטר, הגדלת הרגיסטר באחד, וכתיבת הערך המעודכן חזרה לזיכרון. כאשר שני תהליכונים מנסים לבצע פעולה זו במקביל, ייתכן תזמון שבו תהליכון אחד קורא את ערך המונה, ואז מופסק לפני שהוא מספיק לכתוב את הערך המעודכן. בזמן זה, התהליכון השני קורא את אותו ערך ישן, מגדיל אותו וכותב אותו בחזרה. התוצאה היא שעדכון אחד אובד, ולכן הערך הסופי יהיה נמוך מ-200,000.\n\nכדי לתקן את הבעיה ולהבטיח שהמונה יגיע לערך הנכון, יש להגן על הגישה למשתנה `counter` באמצעות מנגנון סנכרון, כגון mutex. ה-mutex מבטיח שרק תהליכון אחד יוכל להיכנס לקטע הקריטי (הקוד שמשנה את המונה) בכל רגע נתון. הנה קטע הקוד המתוקן:\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0;\npthread_mutex_t mutex; // Declare a mutex\n\nvoid *increment(void *arg) {\n    for (int i = 0; i < 100000; i++) {\n        pthread_mutex_lock(&mutex);   // Lock the mutex before accessing counter\n        counter++;\n        pthread_mutex_unlock(&mutex); // Unlock the mutex after accessing counter\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n    pthread_mutex_init(&mutex, NULL); // Initialize the mutex\n\n    pthread_create(&tid1, NULL, increment, NULL);\n    pthread_create(&tid2, NULL, increment, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    printf(\"Final counter: %d\\n\", counter);\n\n    pthread_mutex_destroy(&mutex); // Destroy the mutex\n    return 0;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0173__Synchronization__Open__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:49:58", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization"], "content": {"text": "נתון קטע הקוד הבא בשפת C, המבוצע על ידי מספר חוטים במקביל. קטע הקוד מנסה לעדכן משתנה גלובלי משותף בשם `shared_counter`.\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n\nint shared_counter = 0; // משתנה גלובלי משותף\n\nvoid *increment_counter(void *arg) {\n    for (int i = 0; i < 100000; i++) {\n        shared_counter++;\n    }\n    return NULL;\n}\n```\n\n1. הסבר מדוע קטע קוד זה עלול להוביל לתוצאה שגויה (כלומר, לא 200000 אם שני חוטים מריצים אותו). ציין את שם הבעיה הספציפית.\n2. הצע פתרון לבעיה זו באמצעות מנגנון סנכרון מתאים (לדוגמה, מוטקס) וכתוב את קטע הקוד המתוקן עבור הפונקציה `increment_counter`.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint shared_counter = 0; // משתנה גלובלי משותף\n\nvoid *increment_counter(void *arg) {\n    for (int i = 0; i < 100000; i++) {\n        shared_counter++;\n    }\n    return NULL;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "**חלק 1: הסבר הבעיה**\nהבעיה בקטע הקוד הנתון היא 'תנאי מירוץ' (Race Condition). כאשר מספר חוטים מנסים לעדכן את המשתנה `shared_counter` במקביל ללא סנכרון, הפעולה `shared_counter++` אינה אטומית. היא מורכבת משלוש פעולות ברמה נמוכה יותר:\n1.  קריאת הערך הנוכחי של `shared_counter` מהזיכרון.\n2.  הגדלת הערך ב-1.\n3.  כתיבת הערך החדש בחזרה לזיכרון.\nאם שני חוטים קוראים את אותו ערך של `shared_counter` לפני שאחד מהם מספיק לכתוב את הערך המוגדל בחזרה, שני החוטים יגדילו את אותו ערך ורק ההגדלה של אחד מהם תשרוד, מה שיוביל לאובדן עדכונים ולתוצאה סופית שגויה (נמוכה מהצפוי).\n\n**חלק 2: פתרון באמצעות מוטקס**\nכדי לפתור את בעיית תנאי המירוץ, יש להגן על הקטע הקריטי (הפעולה `shared_counter++`) באמצעות מנגנון סנכרון, כגון מוטקס (mutex). מוטקס מבטיח שבכל רגע נתון רק חוט אחד יוכל להיכנס לקטע הקריטי ולעדכן את המשתנה המשותף. יש לאתחל את המוטקס לפני יצירת החוטים ולשחרר אותו בסיום.\n\nלהלן קטע הקוד המתוקן עבור הפונקציה `increment_counter`:\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n\nint shared_counter = 0; // משתנה גלובלי משותף\npthread_mutex_t counter_mutex; // מוטקס להגנה על המונה\n\nvoid *increment_counter_safe(void *arg) {\n    for (int i = 0; i < 100000; i++) {\n        pthread_mutex_lock(&counter_mutex); // נעל את המוטקס לפני כניסה לקטע הקריטי\n        shared_counter++;\n        pthread_mutex_unlock(&counter_mutex); // שחרר את המוטקס לאחר היציאה מהקטע הקריטי\n    }\n    return NULL;\n}\n\n// הערה: בקוד הראשי (main), יש לאתחל ולשחרר את המוטקס:\n// int main() {\n//     pthread_mutex_init(&counter_mutex, NULL);\n//     // קוד ליצירת חוטים והפעלת increment_counter_safe\n//     // לדוגמה:\n//     // pthread_t tid1, tid2;\n//     // pthread_create(&tid1, NULL, increment_counter_safe, NULL);\n//     // pthread_create(&tid2, NULL, increment_counter_safe, NULL);\n//     // pthread_join(tid1, NULL);\n//     // pthread_join(tid2, NULL);\n//     // printf(\"Final counter value: %d\\n\", shared_counter); // אמור להיות 200000\n//     pthread_mutex_destroy(&counter_mutex);\n//     return 0;\n// }\n```", "difficulty_estimation": "Easy"}, "_source_file": "0174__Synchronization__Open__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:50:20", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Race Condition", "Mutex"], "content": {"text": "נתון קטע הקוד הבא ב-C שבו שני תהליכונים (threads) מנסים לעדכן משתנה גלובלי משותף. המשתנה `counter` מאותחל ל-0. כל תהליכון מבצע לולאה שבה הוא מגדיל את `counter` 1000 פעמים.\n\n1. מהי התוצאה הצפויה של `counter` בסיום ריצת שני התהליכונים?\n2. האם התוצאה מובטחת? הסבר מדוע או מדוע לא.\n3. כיצד ניתן לתקן את הקוד כדי להבטיח את התוצאה הנכונה באמצעות mutex? יש לכלול את קטע הקוד המתוקן.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0; // Shared global variable\n\nvoid *increment(void *arg) {\n    for (int i = 0; i < 1000; i++) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_create(&tid1, NULL, increment, NULL);\n    pthread_create(&tid2, NULL, increment, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. התוצאה הצפויה של `counter` בסיום ריצת שני התהליכונים היא 2000. כל תהליכון מגדיל את המונה 1000 פעמים, כך ששני תהליכונים יחד אמורים להגדיל אותו 2000 פעמים.\n\n2. התוצאה אינה מובטחת. זוהי דוגמה למצב מרוץ (Race Condition). פעולת `counter++` אינה אטומית, אלא מורכבת משלושה שלבים:\n   א. קריאת הערך הנוכחי של `counter`.\n   ב. הגדלת הערך שנקרא ב-1.\n   ג. כתיבת הערך החדש בחזרה ל-`counter`.\n   כאשר שני תהליכונים מנסים לבצע פעולה זו במקביל, ייתכן ששניהם יקראו את אותו ערך של `counter`, יגדילו אותו בנפרד, ולאחר מכן יכתבו את הערך המוגדל בחזרה. במצב כזה, אחת ההגדלות 'תאבד', והערך הסופי יהיה קטן מ-2000.\n\n3. כדי לתקן את הקוד ולהבטיח את התוצאה הנכונה, יש להשתמש ב-mutex (מנעול הדדי) כדי להגן על הקטע הקריטי (critical section) שבו המשתנה המשותף `counter` משתנה. ה-mutex יבטיח שרק תהליכון אחד יוכל לגשת לקטע הקריטי בכל רגע נתון. הנה הקוד המתוקן:\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0; // Shared global variable\npthread_mutex_t mutex; // Mutex for synchronization\n\nvoid *increment(void *arg) {\n    for (int i = 0; i < 1000; i++) {\n        pthread_mutex_lock(&mutex); // Lock mutex before accessing critical section\n        counter++;\n        pthread_mutex_unlock(&mutex); // Unlock mutex after accessing critical section\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&mutex, NULL); // Initialize the mutex\n\n    pthread_create(&tid1, NULL, increment, NULL);\n    pthread_create(&tid2, NULL, increment, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    pthread_mutex_destroy(&mutex); // Destroy the mutex\n\n    return 0;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0175__Synchronization__Open__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:50:32", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Race Conditions", "Mutexes"], "content": {"text": "נתון קטע קוד בשפת C שבו מספר תהליכונים (threads) מנסים לעדכן משתנה גלובלי משותף (counter) ללא מנגנוני סנכרון. ענה על השאלות הבאות:", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0;\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < 100000; i++) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tids[2];\n\n    pthread_create(&tids[0], NULL, increment_counter, NULL);\n    pthread_create(&tids[1], NULL, increment_counter, NULL);\n\n    pthread_join(tids[0], NULL);\n    pthread_join(tids[1], NULL);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}"}, "sub_questions": [{"id": "10.1", "text": "מהי הבעיה בקטע הקוד הנתון? הסבר מדוע היא מתרחשת.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "מהו הערך הסופי הצפוי של `counter` אם הקוד היה רץ כהלכה? מהי הפלט הטיפוסי בפועל, ומדוע הוא עשוי להשתנות?", "code_snippet": null, "options": null}, {"id": "10.3", "text": "שנה את קטע הקוד הנתון כך שיסנכרן נכונה את הגישה למשתנה `counter` באמצעות mutexים של POSIX, ויבטיח את הערך הסופי הנכון. הצג את הקוד המתוקן.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: הבעיה בקטע הקוד היא תנאי מרוץ (Race Condition). מספר תהליכונים ניגשים למשתנה המשותף `counter` ומנסים לעדכן אותו בו זמנית. הפעולה `counter++` אינה אטומית; היא מורכבת מכמה פעולות מכונה: קריאת הערך הנוכחי של `counter` מהזיכרון, הגדלתו באחד, וכתיבת הערך החדש בחזרה לזיכרון. כאשר מספר תהליכונים מבצעים פעולות אלו במקביל, ייתכן שתהליכון אחד יקרא את הערך, יבוצע מיתוג הקשר (context switch) לתהליכון אחר שיקרא ויעדכן את אותו ערך, ואז התהליכון הראשון ימשיך ויכתוב את הערך הישן + 1 בחזרה, ובכך ידרוס את העדכון של התהליכון השני. זה מוביל לאיבוד עדכונים.\n\n10.2: הערך הסופי הצפוי של `counter` אם הקוד היה רץ כהלכה הוא 200,000. כל אחד משני התהליכונים מבצע 100,000 הגדלות, ולכן סך ההגדלות אמור להיות 2 * 100,000. הפלט הטיפוסי בפועל יהיה ערך נמוך מ-200,000, למשל 120,000, 150,000, או כל ערך אחר בטווח שבין 0 ל-200,000 (כולל). הערך עשוי להשתנות בין הרצות שונות ואף על אותה מכונה, מכיוון שתזמון התהליכונים אינו דטרמיניסטי, ומספר העדכונים שאבדו תלוי בסדר ובזמני המיתוגים בין התהליכונים.\n\n10.3: כדי לסנכרן נכונה את הגישה למשתנה `counter`, יש להשתמש ב-mutex. ה-mutex מבטיח שרק תהליכון אחד יוכל להיכנס לקטע הקריטי (הגדלת המונה) בכל רגע נתון. יש לאתחל את ה-mutex לפני יצירת התהליכונים ולשחרר אותו בסיום. הנה הקוד המתוקן:\n```c\n#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0;\npthread_mutex_t mutex; // Declare a mutex\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < 100000; i++) {\n        pthread_mutex_lock(&mutex); // Acquire the mutex\n        counter++;\n        pthread_mutex_unlock(&mutex); // Release the mutex\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tids[2];\n\n    pthread_mutex_init(&mutex, NULL); // Initialize the mutex\n\n    pthread_create(&tids[0], NULL, increment_counter, NULL);\n    pthread_create(&tids[1], NULL, increment_counter, NULL);\n\n    pthread_join(tids[0], NULL);\n    pthread_join(tids[1], NULL);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    pthread_mutex_destroy(&mutex); // Destroy the mutex\n\n    return 0;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0176__Synchronization__Open__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:50:54", "_subject": "Concurrency"}, {"id": 7, "type": "Open", "topic": ["Synchronization", "Race Conditions", "Semaphores", "Mutexes"], "content": {"text": "נתונים שני חוטים, `incrementer` ו-`decrementer`, אשר ניגשים למשתנה גלובלי משותף `counter`. החוט `incrementer` מגדיל את `counter` ב-`N` פעמים, והחוט `decrementer` מקטין את `counter` ב-`N` פעמים.\nהציגו את קוד המקור עבור שני החוטים ואת פונקציית `main` המפעילה אותם (ללא סנכרון). הסבירו מדוע קיים מצב מרוץ (race condition) בקוד זה ומה יכול להיות הערך הסופי השגוי של `counter`.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\n#define N 1000000\n\nint counter = 0;\n\nvoid* incrementer(void* arg) {\n    for (int i = 0; i < N; i++) {\n        counter++;\n    }\n    return NULL;\n}\n\nvoid* decrementer(void* arg) {\n    for (int i = 0; i < N; i++) {\n        counter--;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_create(&tid1, NULL, incrementer, NULL);\n    pthread_create(&tid2, NULL, decrementer, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "עדכנו את הקוד שהוצג בסעיף הקודם באמצעות סמפורים (semaphores) או mutexים כך שהערך הסופי של `counter` יהיה תמיד 0. הציגו את הקוד המעודכן והסבירו את השינויים.", "code_snippet": null, "options": null}], "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסבר למצב מרוץ (Race Condition):\nפעולות הגידול (`counter++`) וההקטנה (`counter--`) אינן אטומיות. כל אחת מהן מורכבת בדרך כלל ממספר הוראות מעבד:\n1. טעינת הערך הנוכחי של `counter` מזיכרון לתוך רגיסטר.\n2. ביצוע פעולת הגידול/הקטנה על הרגיסטר.\n3. שמירת הערך המעודכן מהרגיסטר בחזרה לזיכרון ב-`counter`.\n\nמצב מרוץ מתרחש כאשר שני החוטים מנסים לבצע פעולות אלו בו-זמנית, והגישה לזיכרון משתלבת ביניהן באופן לא צפוי. לדוגמה, אם `counter` שווה 0:\n* חוט `incrementer` טוען את `0` לרגיסטר שלו.\n* מתבצע מיתוג הקשר (context switch) לחוט `decrementer`.\n* חוט `decrementer` טוען גם הוא את `0` לרגיסטר שלו.\n* חוט `decrementer` מקטין את הרגיסטר שלו ל`-1` ושומר את `-1` בחזרה ל-`counter`. כעת `counter` שווה `-1`.\n* מתבצע מיתוג הקשר בחזרה לחוט `incrementer`.\n* חוט `incrementer` מגדיל את הרגיסטר שלו ל-`1` (זוכרים, הוא התחיל מ-`0`!).\n* חוט `incrementer` שומר את `1` בחזרה ל-`counter`. כעת `counter` שווה `1`.\n\nבמקרה זה, למרות שבוצעו פעולת גידול אחת ופעולת הקטנה אחת, הערך הסופי אינו `0` אלא `1`. באופן דומה, הערך הסופי יכול להיות `-1`. מכיוון שזה קורה `N` פעמים, הערך הסופי של `counter` יכול להיות כל מספר בין `-N` ל-`N` (כולל), ולא בהכרח `0`.\n\nפתרון באמצעות סמפור (Sub-question 7.1):\nכדי למנוע את מצב המרוץ ולהבטיח ש-`counter` יהיה `0` בסיום, יש להגן על האזור הקריטי (הפעולות `counter++` ו-`counter--`) באמצעות מנגנון סנכרון כמו סמפור בינארי (המשמש כמו mutex). הסמפור יבטיח שרק חוט אחד יוכל לגשת לאזור הקריטי בכל רגע נתון.\n\nקוד מעודכן:\n```c\n#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h> // נדרש עבור סמפורים\n\n#define N 1000000\n\nint counter = 0;\nsem_t mutex; // הכרזת סמפור\n\nvoid* incrementer(void* arg) {\n    for (int i = 0; i < N; i++) {\n        sem_wait(&mutex); // נכנס לאזור הקריטי\n        counter++;\n        sem_post(&mutex); // יוצא מהאזור הקריטי\n    }\n    return NULL;\n}\n\nvoid* decrementer(void* arg) {\n    for (int i = 0; i < N; i++) {\n        sem_wait(&mutex); // נכנס לאזור הקריטי\n        counter--;\n        sem_post(&mutex); // יוצא מהאזור הקריטי\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n    sem_init(&mutex, 0, 1); // אתחול סמפור בינארי לערך 1 (פתוח)\n\n    pthread_create(&tid1, NULL, incrementer, NULL);\n    pthread_create(&tid2, NULL, decrementer, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    sem_destroy(&mutex); // שחרור משאבי הסמפור\n    return 0;\n}\n```\n\nהסבר השינויים:\n1. **הכרזת סמפור:** הוספנו משתנה מסוג `sem_t` בשם `mutex` גלובלי.\n2. **אתחול סמפור:** בפונקציית `main`, קראנו ל-`sem_init(&mutex, 0, 1)` כדי לאתחל את הסמפור. הפרמטר `0` מציין שהסמפור ישמש בין חוטים באותו תהליך, והפרמטר `1` מאתחל אותו כסמפור בינארי (mutex) זמין.\n3. **כניסה לאזור קריטי:** לפני כל גישה ל-`counter` (בתוך הלולאות של `incrementer` ו-`decrementer`), קראנו ל-`sem_wait(&mutex)`. קריאה זו חוסמת את החוט אם הסמפור אינו זמין, ומאפשרת לו להמשיך רק כאשר הסמפור הופך זמין (ואז מקטינה את ערכו).\n4. **יציאה מאזור קריטי:** לאחר סיום הפעולה על `counter`, קראנו ל-`sem_post(&mutex)`. קריאה זו משחררת את הסמפור ומאפשרת לחוט אחר (אם יש כזה שממתין) להיכנס לאזור הקריטי.\n5. **שחרור משאבי סמפור:** בסיום `main`, קראנו ל-`sem_destroy(&mutex)` כדי לשחרר את המשאבים שהוקצו לסמפור.\n\nשינויים אלו מבטיחים בלעדיות הדדית (mutual exclusion) על הגישה למשתנה `counter`, ובכך מונעים את מצב המרוץ ומבטיחים שהערך הסופי של `counter` יהיה תמיד `0`."}, "difficulty_estimation": "Medium", "_source_file": "0177__Synchronization__Open__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:51:18", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Synchronization", "Race Conditions", "Mutexes"], "content": {"text": "נתונה תוכנית C המשתמשת במספר חוטים (threads) כדי להגדיל מונה גלובלי משותף. קטע הקוד הבא מציג את פונקציית החוט (thread function) ואת המונה הגלובלי. ענו על השאלות הבאות:", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <stdlib.h> // For exit\n\nint shared_counter = 0;\n\nvoid* thread_func(void* arg) {\n    int i;\n    for (i = 0; i < 100000; i++) {\n        shared_counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[5];\n    int i;\n\n    for (i = 0; i < 5; i++) {\n        pthread_create(&threads[i], NULL, thread_func, NULL);\n    }\n\n    for (i = 0; i < 5; i++) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", shared_counter);\n\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "א. מהי הבעיה העיקרית בקוד זה בהקשר של סנכרון? הסבירו מדוע הבעיה מתרחשת וכיצד היא יכולה להשפיע על הפלט הסופי של המונה.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "ב. כתבו מחדש את פונקציית ה-`thread_func` ואת קטע הקוד ב-`main` שנדרש לאתחול ולשחרור משאבים, כך שהמונה המשותף יעודכן באופן בטוח ונכון באמצעות מנעול הדדי (mutex). הציגו את הקוד המתוקן במלואו.", "code_snippet": null, "options": null}], "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. הבעיה העיקרית בקוד זה היא תנאי מירוץ (race condition). מספר חוטים מנסים לגשת ולשנות את המשתנה הגלובלי `shared_counter` בו-זמנית ללא מנגנון סנכרון מתאים. פעולת הגידול `shared_counter++` אינה פעולה אטומית. היא מורכבת בדרך כלל משלוש פעולות בסיסיות:\n1.  קריאת הערך הנוכחי של `shared_counter` לתוך אוגר.\n2.  הגדלת הערך באוגר באחד.\n3.  כתיבת הערך החדש מהאוגר בחזרה ל-`shared_counter`.\n\nאם שני חוטים (או יותר) מבצעים פעולות אלה במקביל, ייתכן ששניהם יקראו את אותו ערך ישן של `shared_counter`, יגדילו אותו באחד, ויכתבו בחזרה את אותו ערך (מוגדל באחד) - במקום שכל אחד מהם יגדיל אותו בנפרד. לדוגמה, אם `shared_counter` הוא 10, חוט A קורא 10, חוט B קורא 10. חוט A מגדיל ל-11 וכותב 11. חוט B מגדיל ל-11 וכותב 11. התוצאה הסופית היא 11 במקום 12. כתוצאה מכך, הערך הסופי של `shared_counter` יהיה בדרך כלל נמוך מהערך הצפוי (5 חוטים * 100,000 איטרציות = 500,000).\n\nב. כדי לפתור את בעיית תנאי המירוץ, נשתמש במנעול הדדי (mutex) כדי להגן על הקטע הקריטי, שהוא פעולת הגידול של `shared_counter`. יש לאתחל את המוטקס לפני יצירת החוטים ולשחרר אותו לאחר סיום עבודתם.\n\n**הקוד המתוקן:**\n```c\n#include <stdio.h>\n#include <pthread.h>\n#include <stdlib.h> // For exit\n\nint shared_counter = 0;\npthread_mutex_t counter_mutex; // הצהרה על המוטקס\n\nvoid* thread_func(void* arg) {\n    int i;\n    for (i = 0; i < 100000; i++) {\n        pthread_mutex_lock(&counter_mutex);   // נעילת המוטקס לפני כניסה לקטע הקריטי\n        shared_counter++;                     // הקטע הקריטי\n        pthread_mutex_unlock(&counter_mutex); // שחרור המוטקס לאחר היציאה מהקטע הקריטי\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[5];\n    int i;\n\n    pthread_mutex_init(&counter_mutex, NULL); // אתחול המוטקס\n\n    for (i = 0; i < 5; i++) {\n        pthread_create(&threads[i], NULL, thread_func, NULL);\n    }\n\n    for (i = 0; i < 5; i++) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", shared_counter); // הפלט הצפוי כעת הוא 500000\n\n    pthread_mutex_destroy(&counter_mutex); // שחרור המוטקס\n\n    return 0;\n}\n```\n\n**הסבר:**\nהשימוש ב-`pthread_mutex_lock` וב-`pthread_mutex_unlock` מבטיח שרק חוט אחד יכול להיכנס לקטע הקריטי (שבו `shared_counter` מוגדל) בכל רגע נתון. כאשר חוט אחד נכנס לקטע הקריטי ונועל את המוטקס, כל חוט אחר שינסה להיכנס יחסם (ימתין) עד שהחוט הראשון ישחרר את המוטקס. זה מונע את תנאי המירוץ ומבטיח שפעולת הגידול של המונה תתבצע באופן אטומי מבחינה לוגית, מה שמוביל לערך סופי נכון של `shared_counter`."}, "difficulty_estimation": "Medium", "_source_file": "0178__Synchronization__Open__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:51:38", "_subject": "Concurrency"}, {"id": 7, "type": "Open", "topic": ["Synchronization", "Race Conditions", "Mutexes", "Semaphores"], "content": {"text": "נתון קטע קוד המשתמש בשני חוטים (threads) המבצעים פעולות על משאבים משותפים. כל חוט מטרתו להגדיל מונה גלובלי (shared_counter) ולרשום את ה-ID שלו במערך לוג (log_of_updates) במיקום המתאים לערך המונה *לפני* ההגדלה.\n\nקראו את הקוד בעיון וענו על השאלות הבאות:", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h>\n\n#define NUM_ITERATIONS 50000\n#define NUM_THREADS 2\n#define LOG_ARRAY_SIZE (NUM_ITERATIONS * NUM_THREADS)\n\nint shared_counter = 0;\nint log_of_updates[LOG_ARRAY_SIZE]; // To log which thread updated at which logical step\n\n// Thread IDs for demonstration (0 or 1)\nint thread_ids[NUM_THREADS] = {0, 1};\n\nvoid* thread_routine(void* arg) {\n    int thread_id = *(int*)arg;\n    for (int i = 0; i < NUM_ITERATIONS; ++i) {\n        // Critical section operations\n        int current_index = shared_counter; // Read shared_counter\n        shared_counter++;                   // Increment shared_counter\n        if (current_index < LOG_ARRAY_SIZE) {\n            log_of_updates[current_index] = thread_id; // Write to log_of_updates\n        }\n    }\n    return NULL;\n}\n\n/*\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    printf(\"Starting threads...\n\");\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_routine, &thread_ids[i]);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final shared_counter: %d (Expected: %d)\n\", shared_counter, NUM_ITERATIONS * NUM_THREADS);\n\n    printf(\"First 10 log entries: \");\n    for (int i = 0; i < 10 && i < LOG_ARRAY_SIZE; ++i) {\n        printf(\"%d \", log_of_updates[i]);\n    }\n    printf(\"\\n\");\n    \n    printf(\"Last 10 log entries: \");\n    for (int i = LOG_ARRAY_SIZE - 10; i < LOG_ARRAY_SIZE; ++i) {\n        if (i >= 0) printf(\"%d \", log_of_updates[i]);\n    }\n    printf(\"\\n\");\n\n    return 0;\n}\n*/", "options": null}, "sub_questions": [{"id": "7.1", "text": "הסבירו מדוע קטע הקוד הזה עלול להוביל לתוצאות שגויות. תארו דוגמה קונקרטית לתרחיש ריצה (interleaving) שיגרום לבעיה בערך הסופי של shared_counter ו/או בתוכן המערך log_of_updates.", "code_snippet": null, "options": null}, {"id": "7.2", "text": "כתבו גרסה מתוקנת של הפונקציה `thread_routine` המשתמשת ב-mutex (מנעול) כדי למנוע את הבעיות שתוארו בסעיף הקודם. ציינו היכן יש להצהיר ולאתחל את המנעול.", "code_snippet": null, "options": null}, {"id": "7.3", "text": "כתבו גרסה מתוקנת נוספת של הפונקציה `thread_routine` המשתמשת בסמפור (semaphore) בינארי (או mutex כפי שמומש לעיתים באמצעות סמפור) כדי לפתור את אותן הבעיות. ציינו היכן יש להצהיר ולאתחל את הסמפור.", "code_snippet": null, "options": null}], "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "7.1. **הסבר הבעיה:**\nקטע הקוד סובל מ-Race Condition (מצב מרוץ) עקב גישה לא מסונכרנת למשתנים הגלובליים המשותפים `shared_counter` ו-`log_of_updates` על ידי מספר חוטים במקביל. הפעולות `int current_index = shared_counter; shared_counter++; log_of_updates[current_index] = thread_id;` אינן אטומיות. כלומר, מערכת ההפעלה יכולה להחליף הקשר (context switch) בין חוטים בכל נקודה בביצוע של שלוש הפעולות הללו.\n\n**דוגמה לתרחיש ריצה שיגרום לבעיה:**\nנניח ש-`shared_counter` שווה ל-5 בתחילת האיטרציה.\n1.  **חוט 0 מתוזמן:**\n    *   קורא: `current_index = shared_counter;` (כלומר `current_index = 5;`) \n    *   **החלפת הקשר** לחוט 1.\n2.  **חוט 1 מתוזמן:**\n    *   קורא: `current_index = shared_counter;` (כלומר `current_index = 5;` - שימו לב ש-`shared_counter` עדיין 5)\n    *   מגדיל: `shared_counter++;` (כלומר `shared_counter` הופך ל-6)\n    *   כותב ללוג: `log_of_updates[5] = 1;`\n    *   **החלפת הקשר** לחוט 0.\n3.  **חוט 0 ממשיך:**\n    *   מגדיל: `shared_counter++;` (כלומר `shared_counter` הופך ל-6. **זו טעות!** המונה היה אמור להיות 7 אם שני החוטים היו מבצעים את ההגדלה באופן אטומי)\n    *   כותב ללוג: `log_of_updates[5] = 0;` (**זו טעות!** חוט 0 דרס את הערך שחוט 1 כתב במיקום 5, ובפועל חוט 1 לא \"נרשם\" בלוג כלל במיקום זה, למרות שביצע פעולה). \n\n**השלכות:**\n*   **ערך סופי שגוי של `shared_counter`**: המונה הסופי יהיה נמוך מהצפוי (לדוגמה, במקום 100,000 עבור 2 חוטים ו-50,000 איטרציות לכל אחד, הוא יהיה פחות מכך). במקרה הדוגמה לעיל, במקום 7 הוא 6. אובדן עדכונים.\n*   **תוכן שגוי במערך `log_of_updates`**: חלק מהעדכונים יידרסו על ידי חוטים אחרים, ועלולות להיות כניסות חסרות או שגויות. במקרה הדוגמה לעיל, `log_of_updates[5]` אמור היה להכיל שני עדכונים (אחד מ-0 ואחד מ-1) אך מכיל רק את האחרון שנדרס.\n\n7.2. **פתרון באמצעות Mutex:**\nכדי למנוע את מצב המרוץ, יש להגן על ה-Critical Section (האזור הקריטי) באמצעות Mutex. ה-Critical Section במקרה זה כולל את הקריאה ל-`shared_counter`, ההגדלה שלו, והכתיבה ל-`log_of_updates`.\n\n**הצהרה ואיפוס המנעול:**\nיש להצהיר על משתנה Mutex גלובלי ולאתחל אותו פעם אחת לפני יצירת החוטים (לרוב בפונקציית `main`).\n```c\npthread_mutex_t counter_mutex; // הצהרה גלובלית\n\n// בתוך פונקציית main, לפני יצירת החוטים:\npthread_mutex_init(&counter_mutex, NULL);\n```\n\n**גרסה מתוקנת של `thread_routine`:**\n```c\nvoid* thread_routine_mutex(void* arg) {\n    int thread_id = *(int*)arg;\n    for (int i = 0; i < NUM_ITERATIONS; ++i) {\n        pthread_mutex_lock(&counter_mutex); // נעל את המנעול לפני הכניסה לאזור הקריטי\n\n        // Critical section operations\n        int current_index = shared_counter;\n        shared_counter++;\n        if (current_index < LOG_ARRAY_SIZE) {\n            log_of_updates[current_index] = thread_id;\n        }\n\n        pthread_mutex_unlock(&counter_mutex); // שחרר את המנעול לאחר היציאה מהאזור הקריטי\n    }\n    return NULL;\n}\n```\n\n7.3. **פתרון באמצעות Semaphore בינארי:**\nניתן להשתמש בסמפור בינארי באופן דומה ל-Mutex כדי להגן על אזור קריטי. סמפור בינארי מאותחל לערך 1, וכל קריאה ל-`sem_wait` מקטינה אותו ב-1 (וחוסמת אם הוא 0), וכל קריאה ל-`sem_post` מגדילה אותו ב-1.\n\n**הצהרה ואיפוס הסמפור:**\nיש להצהיר על משתנה Semaphore גלובלי ולאתחל אותו פעם אחת לפני יצירת החוטים (לרוב בפונקציית `main`).\n```c\nsem_t counter_sem; // הצהרה גלובלית\n\n// בתוך פונקציית main, לפני יצירת החוטים:\n// sem_init(sem, pshared, value)\n// pshared = 0: הסמפור משותף לחוטים בתוך אותו תהליך.\n// value = 1: ערך אתחול 1 הופך אותו לסמפור בינארי (כמו mutex).\nsem_init(&counter_sem, 0, 1);\n```\n\n**גרסה מתוקנת של `thread_routine`:**\n```c\nvoid* thread_routine_semaphore(void* arg) {\n    int thread_id = *(int*)arg;\n    for (int i = 0; i < NUM_ITERATIONS; ++i) {\n        sem_wait(&counter_sem); // המתן (acquire) לסמפור לפני הכניסה לאזור הקריטי\n\n        // Critical section operations\n        int current_index = shared_counter;\n        shared_counter++;\n        if (current_index < LOG_ARRAY_SIZE) {\n            log_of_updates[current_index] = thread_id;\n        }\n\n        sem_post(&counter_sem); // שחרר (release) את הסמפור לאחר היציאה מהאזור הקריטי\n    }\n    return NULL;\n}\n```"}, "difficulty_estimation": "Medium", "_source_file": "0179__Synchronization__Open__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:52:07", "_subject": "Concurrency"}, {"id": 7, "type": "Open", "topic": ["Synchronization", "Reader-Writer Problem", "Pthreads"], "content": {"text": "נתונה מערכת המכילה משאב משותף (לדוגמה, מבנה נתונים) אליו ניגשים מספר תהליכונים (threads) משני סוגים: כותבים (Writers) וקוראים (Readers). תהליכונים כותבים משנים את המשאב, ותהליכונים קוראים קוראים אותו בלבד. יש לממש מנגנון סנכרון עבור גישה למשאב המשותף כך שיעמוד בדרישות הבאות:\n1. רק תהליכון כותב אחד יכול לגשת למשאב המשותף בכל רגע נתון.\n2. מספר תהליכונים קוראים יכולים לגשת למשאב המשותף בו זמנית.\n3. אף תהליכון כותב לא יכול לגשת למשאב כאשר תהליכון קורא כלשהו ניגש אליו, ולהיפך (אין גישה בו זמנית של קוראים וכותבים).\n4. לתהליכונים כותבים יש עדיפות: אם תהליכון כותב ממתין לגישה למשאב, אף תהליכון קורא חדש לא יוכל להתחיל לקרוא עד שהכותב יסיים את פעולתו וישחרר את המשאב.\n\nיש להציג את קטעי הקוד הרלוונטיים עבור תהליכון כותב ותהליכון קורא, תוך שימוש במנגנוני סנכרון של POSIX (mutexes ו-condition variables), ולהסביר את פעולת המנגנון.", "code_snippet": null, "options": null}, "sub_questions": null, "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון בעיית קוראים-כותבים עם עדיפות לכותבים באמצעות mutexes ו-condition variables של POSIX:\n\nמשתנים גלובליים לתיאום:\n```c\npthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;\npthread_cond_t reader_cond = PTHREAD_COND_INITIALIZER;\npthread_cond_t writer_cond = PTHREAD_COND_INITIALIZER;\n\nint readers_reading = 0;   // מספר הקוראים הפעילים כרגע\nint writers_writing = 0;   // 1 אם כותב פעיל, 0 אחרת\nint writers_waiting = 0;   // מספר הכותבים הממתינים לגישה\n```\n\nפונקציות כניסה ויציאה עבור תהליכון כותב:\n```c\nvoid writer_entry() {\n    pthread_mutex_lock(&mutex);\n    writers_waiting++;\n    while (readers_reading > 0 || writers_writing > 0) {\n        pthread_cond_wait(&writer_cond, &mutex);\n    }\n    writers_waiting--;\n    writers_writing = 1;\n    pthread_mutex_unlock(&mutex);\n}\n\nvoid writer_exit() {\n    pthread_mutex_lock(&mutex);\n    writers_writing = 0;\n    if (writers_waiting > 0) {\n        pthread_cond_signal(&writer_cond); // מעיר כותב ממתין אחד\n    } else {\n        pthread_cond_broadcast(&reader_cond); // מעיר את כל הקוראים הממתינים\n    }\n    pthread_mutex_unlock(&mutex);\n}\n```\n\nפונקציות כניסה ויציאה עבור תהליכון קורא:\n```c\nvoid reader_entry() {\n    pthread_mutex_lock(&mutex);\n    while (writers_writing > 0 || writers_waiting > 0) {\n        pthread_cond_wait(&reader_cond, &mutex);\n    }\n    readers_reading++;\n    pthread_mutex_unlock(&mutex);\n}\n\nvoid reader_exit() {\n    pthread_mutex_lock(&mutex);\n    readers_reading--;\n    if (readers_reading == 0 && writers_waiting > 0) {\n        pthread_cond_signal(&writer_cond); // אם אין יותר קוראים וכותבים ממתינים, מעיר כותב אחד\n    }\n    pthread_mutex_unlock(&mutex);\n}\n```\n\nהסבר:\n*   **`mutex`**: מגן על הגישה למשתנים המשותפים (`readers_reading`, `writers_writing`, `writers_waiting`) כדי למנוע תנאי מירוץ.\n*   **`readers_reading`**: מונה את מספר הקוראים שנמצאים כרגע בקטע הקריטי. כאשר ערכו אפס, אין קוראים פעילים.\n*   **`writers_writing`**: דגל (0 או 1) המציין אם כותב כלשהו נמצא כרגע בקטע הקריטי. רק כותב אחד יכול להיות פעיל בכל רגע.\n*   **`writers_waiting`**: מונה את מספר הכותבים שממתינים להיכנס לקטע הקריטי. משמש ליישום עדיפות לכותבים.\n\n**היגיון עדיפות לכותבים:**\n1.  **כניסת כותב (`writer_entry`)**: כותב מעלה את `writers_waiting` וממתין אם יש קוראים פעילים (`readers_reading > 0`) או כותב אחר פעיל (`writers_writing > 0`). לאחר מכן, הוא מוריד את `writers_waiting` ומסמן את עצמו ככותב פעיל.\n2.  **כניסת קורא (`reader_entry`)**: קורא ממתין אם יש כותב פעיל (`writers_writing > 0`) או אם יש כותבים ממתינים (`writers_waiting > 0`). תנאי `writers_waiting > 0` הוא המפתח לעדיפות לכותבים – קוראים חדשים לא יורשו להיכנס אם יש כותב שממתין. אם אין כותבים פעילים או ממתינים, הקורא מעלה את `readers_reading` ונכנס לקטע הקריטי.\n3.  **יציאת כותב (`writer_exit`)**: כותב מסיים ומאפס את `writers_writing`. אם יש כותבים ממתינים (`writers_waiting > 0`), הוא מעיר רק אחד מהם באמצעות `pthread_cond_signal(&writer_cond)` כדי לאפשר לכותב הבא להיכנס (שכן רק כותב אחד יכול להיות פעיל). רק אם אין כותבים ממתינים, הוא מעיר את כל הקוראים הממתינים באמצעות `pthread_cond_broadcast(&reader_cond)`.\n4.  **יציאת קורא (`reader_exit`)**: קורא מסיים ומוריד את `readers_reading`. אם הוא היה הקורא האחרון (`readers_reading == 0`) ויש כותבים ממתינים (`writers_waiting > 0`), הוא מעיר כותב אחד באמצעות `pthread_cond_signal(&writer_cond)` כדי לאפשר לכותב להיכנס כעת כשהמשאב פנוי מקוראים."}, "difficulty_estimation": "Medium", "_source_file": "0180__Synchronization__Open__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:52:32", "_subject": "Concurrency"}, {"id": 7, "type": "Open", "topic": ["Synchronization", "Race Condition", "Mutex", "Threads"], "content": {"text": "נתון קטע הקוד הבא המדמה גישה למשתנה גלובלי משותף `balance` על ידי מספר חוטים. חוטים מסוג `deposit_thread` מגדילים את `balance` וחוטים מסוג `withdraw_thread` מקטינים אותו. כל חוט מבצע את הפעולה מספר רב של פעמים. בתום ריצת התוכנית, מצפים שהערך הסופי של `balance` יהיה 0.\n\n1. מהי הבעיה המרכזית בקוד זה בהקשר של מערכות הפעלה מקביליות? הסבר מדוע היא מתרחשת וכיצד היא יכולה להוביל לתוצאה שגויה.\n2. הצע פתרון לבעיה זו באמצעות סמפורים או מנעולים (mutexes) ב-C. הצג את קטע הקוד המתוקן עבור הפונקציות `deposit_thread` ו-`withdraw_thread` ואת האתחול והסיום הנדרשים בפונקציית `main`.\n3. הסבר כיצד הפתרון שלך מונע את הבעיה ומבטיח נכונות.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n\nint balance = 0; // Shared global variable\n\nvoid* deposit_thread(void* arg) {\n    int i;\n    for (i = 0; i < 100000; i++) {\n        balance++;\n    }\n    return NULL;\n}\n\nvoid* withdraw_thread(void* arg) {\n    int i;\n    for (i = 0; i < 100000; i++) {\n        balance--;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2, tid3, tid4;\n\n    pthread_create(&tid1, NULL, deposit_thread, NULL);\n    pthread_create(&tid2, NULL, deposit_thread, NULL);\n    pthread_create(&tid3, NULL, withdraw_thread, NULL);\n    pthread_create(&tid4, NULL, withdraw_thread, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n    pthread_join(tid3, NULL);\n    pthread_join(tid4, NULL);\n\n    printf(\"Final balance: %d\\n\", balance);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "### הסבר לבעיה (שאלה 1):\nהבעיה המרכזית בקוד היא תנאי מרוץ (Race Condition) בגישה למשתנה הגלובלי המשותף `balance`. הפעולות `balance++` ו-`balance--` אינן אטומיות. הן מורכבות ממספר פעולות מכונה ברמה נמוכה יותר (לדוגמה, עבור `balance++`:\n1. קריאת הערך של `balance` מהזיכרון לתוך רגיסטר.\n2. הגדלת הערך ברגיסטר.\n3. כתיבת הערך המעודכן מהרגיסטר בחזרה לזיכרון).\nכאשר מספר חוטים מנסים לבצע פעולות אלו בו-זמנית, ייתכן שחוט אחד יקרא את הערך של `balance`, יבוצע מיתוג הקשר (context switch) לחוט אחר שישנה את `balance`, וכאשר החוט הראשון יחזור לרוץ הוא יכתוב בחזרה ערך שגוי (מבוסס על הערך הישן שקרא לפני שהחוט השני שינה אותו). כתוצאה מכך, חלק מהעדכונים עלולים 'לאבד' (lost updates) והערך הסופי של `balance` יהיה שגוי ולא צפוי, ובדרך כלל לא יהיה 0 כפי שמצופה (שני חוטי הפקדה ושני חוטי משיכה, כל אחד 100,000 פעמים, אמורים לבטל זה את זה).\n\n### קוד מתוקן באמצעות מנעול (mutex) (שאלה 2):\n```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n\npthread_mutex_t balance_mutex; // Mutex for synchronization\nint balance = 0; // Shared global variable\n\nvoid* deposit_thread_sync(void* arg) {\n    int i;\n    for (i = 0; i < 100000; i++) {\n        pthread_mutex_lock(&balance_mutex); // Acquire lock\n        balance++;\n        pthread_mutex_unlock(&balance_mutex); // Release lock\n    }\n    return NULL;\n}\n\nvoid* withdraw_thread_sync(void* arg) {\n    int i;\n    for (i = 0; i < 100000; i++) {\n        pthread_mutex_lock(&balance_mutex); // Acquire lock\n        balance--;\n        pthread_mutex_unlock(&balance_mutex); // Release lock\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2, tid3, tid4;\n\n    pthread_mutex_init(&balance_mutex, NULL); // Initialize mutex\n\n    pthread_create(&tid1, NULL, deposit_thread_sync, NULL);\n    pthread_create(&tid2, NULL, deposit_thread_sync, NULL);\n    pthread_create(&tid3, NULL, withdraw_thread_sync, NULL);\n    pthread_create(&tid4, NULL, withdraw_thread_sync, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n    pthread_join(tid3, NULL);\n    pthread_join(tid4, NULL);\n\n    printf(\"Final balance with sync: %d\\n\", balance);\n\n    pthread_mutex_destroy(&balance_mutex); // Destroy mutex\n    return 0;\n}\n```\n\n### הסבר לפתרון (שאלה 3):\nהפתרון המוצע הוא שימוש במנעול (mutex). מנעול הוא פרימיטיב סנכרון המבטיח הדרה הדדית (mutual exclusion), כלומר, רק חוט אחד יכול להחזיק במנעול בכל רגע נתון. לפני כל גישה למשתנה המשותף `balance` (בין אם לצורך הגדלה או הקטנה), החוט קורא לפונקציה `pthread_mutex_lock(&balance_mutex)` כדי לנעול את המנעול. אם המנעול כבר נעול על ידי חוט אחר, החוט הנוכחי נחסם וממתין עד שהמנעול ישוחרר. לאחר סיום הפעולה על `balance` (הקטע הקריטי), החוט קורא לפונקציה `pthread_mutex_unlock(&balance_mutex)` כדי לשחרר את המנעול, ובכך מאפשר לחוטים אחרים שחסומים לנסות לרכוש אותו. \n\nבצורה זו, פעולות `balance++` ו-`balance--` הופכות לאטומיות מבחינה לוגית: מרגע שחוט נעל את המנעול ועד ששחרר אותו, אף חוט אחר לא יוכל להיכנס לקטע הקריטי ולשנות את `balance`. זה מונע תנאי מרוץ ומבטיח שכל עדכון ל-`balance` יתבצע באופן מלא וללא הפרעה מחוטים אחרים, ובכך מבטיח שהחישוב הסופי של `balance` יהיה נכון (במקרה זה, 0)."}, "difficulty_estimation": "Medium", "_source_file": "0181__Synchronization__Open__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:53:00", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Semaphores", "Concurrency"], "content": {"text": "במערכת הפעלה נתונה, ישנו משאב משותף הנגיש לשני סוגי תהליכים: קוראים (Readers) וכותבים (Writers). עליכם לממש פתרון סנכרון בשפת C באמצעות סמפורים בלבד המקיים את התנאים הבאים:\n1. מספר הקוראים שיכולים לגשת למשאב בו-זמנית מוגבל לכל היותר ל-5.\n2. כותב יכול לגשת למשאב רק אם אין בו קוראים כלל.\n3. בזמן שכותב ניגש למשאב, אף קורא או כותב אחר לא יכול לגשת אליו (בלעדיות).\n4. מניעת הרעבה של כותבים: ברגע שכותב ממתין בתור, קוראים חדשים לא יורשו להיכנס למשאב עד שהכותב יסיים.", "code_snippet": "sem_t mutex;          // Protects read_count\nsem_t resource;       // Controls access to the resource\nsem_t read_limit;     // Limits number of concurrent readers\nsem_t service_queue;  // Prevents writer starvation\nint read_count = 0;\n\n// Initialize semaphores and implement reader() and writer()", "options": null}, "sub_questions": null, "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון עושה שימוש בארבעה סמפורים:\n1. הסמפור service_queue (אותחל ל-1) משמש כ'שומר סף'. גם קוראים וגם כותבים חייבים לעבור דרכו. אם כותב ממתין עליו, קוראים חדשים ייחסמו, מה שמונע הרעבת כותבים.\n2. הסמפור read_limit (אותחל ל-5) מבטיח שלא יותר מ-5 קוראים ישהו במשאב בו-זמנית.\n3. הסמפור resource (אותחל ל-1) מבטיח בלעדיות לכותב. הקורא הראשון שנכנס נועל אותו, והקורא האחרון שיוצא משחרר אותו.\n4. הסמפור mutex (אותחל ל-1) מגן על המשתנה המשותף read_count.\n\nמימוש ה-Writer:\nsem_wait(&service_queue);\nsem_wait(&resource);\n// Writing...\nsem_post(&resource);\nsem_post(&service_queue);\n\nמימוש ה-Reader:\nsem_wait(&service_queue);\nsem_wait(&read_limit);\nsem_wait(&mutex);\nread_count++;\nif (read_count == 1) sem_wait(&resource);\nsem_post(&mutex);\nsem_post(&service_queue);\n\n// Reading...\n\nsem_wait(&mutex);\nread_count--;\nif (read_count == 0) sem_post(&resource);\nsem_post(&mutex);\nsem_post(&read_limit);"}, "difficulty_estimation": "Medium", "_source_file": "0182__Synchronization__Open__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:56:53", "_subject": "Concurrency"}, {"id": 7, "type": "Open", "topic": ["Synchronization"], "content": {"text": "נתון קטע קוד בשפת C המדמה מצב בו מספר תהליכונים (threads) ניגשים למשתנה גלובלי משותף (מונה) ומבצעים עליו פעולת הגדלה. קטע הקוד הנוכחי אינו משתמש במנגנוני סנכרון כלשהם.\n\nא. הסבר/י מדוע קטע קוד זה עלול לייצר תוצאות לא צפויות או שגויות. תאר/י את הבעיה הספציפית העלולה להתרחש.\nב. הצע/י פתרון לקטע הקוד באמצעות שימוש במנעול (mutex) כדי להבטיח שהמונה יוגדל באופן עקבי ונכון. הצג/י את קטע הקוד המתוקן.\nג. הצע/י פתרון נוסף לקטע הקוד באמצעות שימוש בסמפור בינארי (binary semaphore) כדי להבטיח את עקביות המונה. הצג/י את קטע הקוד המתוקן.\nד. השווה/י בקצרה בין שני הפתרונות שהצעת בסעיפים ב' ו-ג' בהקשר של בעיה זו.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\n#define NUM_THREADS 5\n#define ITERATIONS_PER_THREAD 100000\n\nlong long global_counter = 0;\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < ITERATIONS_PER_THREAD; ++i) {\n        global_counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, increment_counter, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final global_counter value: %lld\\n\", global_counter);\n    printf(\"Expected value: %lld\\n\", (long long)NUM_THREADS * ITERATIONS_PER_THREAD);\n\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. הבעיה בקטע הקוד היא תנאי מרוץ (race condition). פעולת ההגדלה של המונה (`global_counter++`) אינה פעולה אטומית (atomic operation). היא מורכבת למעשה משלוש פעולות ברמת המעבד:\n1. קריאת הערך הנוכחי של `global_counter` לתוך רגיסטר.\n2. הגדלת הערך ברגיסטר.\n3. כתיבת הערך המעודכן מהרגיסטר בחזרה ל`global_counter`.\nכאשר מספר תהליכונים מבצעים פעולה זו במקביל ללא סנכרון, ייתכן שתהליכון אחד יקרא את הערך, ותהליכון אחר יספיק לקרוא את אותו הערך, להגדיל אותו ולכתוב אותו בחזרה, לפני שהתהליכון הראשון יכתוב את הערך המוגדל שלו. כתוצאה מכך, חלק מההגדלות \"יאבדו\", והערך הסופי של `global_counter` יהיה נמוך מהצפוי.\n\nב. פתרון באמצעות מנעול (mutex):\nהמנעול מבטיח שרק תהליכון אחד יוכל להיכנס לקטע הקריטי (critical section) בו מתבצעת פעולת ההגדלה של המונה בכל רגע נתון. תהליכונים אחרים שינסו להיכנס יחסמו עד שהתהליכון המחזיק במנעול ישחרר אותו.\nהשינויים כוללים:\n1. הצהרה על משתנה `pthread_mutex_t`.\n2. אתחול המנעול באמצעות `pthread_mutex_init` לפני יצירת התהליכונים.\n3. קריאה ל`pthread_mutex_lock` לפני הכניסה לקטע הקריטי.\n4. קריאה ל`pthread_mutex_unlock` לאחר היציאה מהקטע הקריטי.\n5. השמדת המנעול באמצעות `pthread_mutex_destroy` בסיום.\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n\n#define NUM_THREADS 5\n#define ITERATIONS_PER_THREAD 100000\n\nlong long global_counter = 0;\npthread_mutex_t counter_mutex; // Mutex declaration\n\nvoid* increment_counter_mutex(void* arg) {\n    for (int i = 0; i < ITERATIONS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&counter_mutex);   // Acquire mutex\n        global_counter++;\n        pthread_mutex_unlock(&counter_mutex); // Release mutex\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    pthread_mutex_init(&counter_mutex, NULL); // Initialize mutex\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, increment_counter_mutex, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final global_counter value (with mutex): %lld\\n\", global_counter);\n    printf(\"Expected value: %lld\\n\", (long long)NUM_THREADS * ITERATIONS_PER_THREAD);\n\n    pthread_mutex_destroy(&counter_mutex); // Destroy mutex\n\n    return 0;\n}\n```\n\nג. פתרון באמצעות סמפור בינארי:\nסמפור בינארי יכול לשמש למטרות הדדית (mutual exclusion) בדומה למנעול. סמפור המאותחל ל-1 מאפשר רק לתהליכון אחד לבצע `sem_wait` בהצלחה, בעוד שאחרים יחסמו. `sem_post` משחרר את הסמפור ומאפשר לתהליכון אחר להיכנס.\nהשינויים כוללים:\n1. הצהרה על משתנה `sem_t`.\n2. אתחול הסמפור לערך 1 באמצעות `sem_init` לפני יצירת התהליכונים. הפרמטר השני 0 מציין שהסמפור משותף רק לתהליכונים בתוך אותו תהליך.\n3. קריאה ל`sem_wait` לפני הכניסה לקטע הקריטי (פעולת P).\n4. קריאה ל`sem_post` לאחר היציאה מהקטע הקריטי (פעולת V).\n5. השמדת הסמפור באמצעות `sem_destroy` בסיום.\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h> // For sem_t\n\n#define NUM_THREADS 5\n#define ITERATIONS_PER_THREAD 100000\n\nlong long global_counter = 0;\nsem_t counter_semaphore; // Semaphore declaration\n\nvoid* increment_counter_semaphore(void* arg) {\n    for (int i = 0; i < ITERATIONS_PER_THREAD; ++i) {\n        sem_wait(&counter_semaphore);   // Acquire semaphore (P operation)\n        global_counter++;\n        sem_post(&counter_semaphore); // Release semaphore (V operation)\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    // Initialize semaphore to 1 (binary semaphore)\n    sem_init(&counter_semaphore, 0, 1);\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, increment_counter_semaphore, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final global_counter value (with semaphore): %lld\\n\", global_counter);\n    printf(\"Expected value: %lld\\n\", (long long)NUM_THREADS * ITERATIONS_PER_THREAD);\n\n    sem_destroy(&counter_semaphore); // Destroy semaphore\n\n    return 0;\n}\n```\n\nד. השוואה בין מנעול לסמפור בינארי:\nעבור בעיה ספציפית זו של הדדית (mutual exclusion) עבור קטע קריטי בודד, הן מנעול והן סמפור בינארי מספקים פתרון נכון ויעיל. בפועל, ברוב מערכות ההפעלה המודרניות, מנעולים ממוטבים במיוחד למטרה זו ונוטים להיות קלים ויעילים יותר לשימוש עבור הדדית בלבד.\n**מנעול (Mutex):**\n*   מיועד ספציפית להדדית.\n*   לרוב, רק התהליכון שרכש את המנעול יכול לשחרר אותו (בעל \"בעלות\").\n*   מנגנוני זיהוי שגיאות מובנים (לדוגמה, ניסיון לשחרר מנעול שלא נרכש).\n*   יכול לתמוך בפרוטוקולי עדיפויות (priority inheritance) למניעת priority inversion.\n**סמפור בינארי (Binary Semaphore):**\n*   כלי כללי יותר, שיכול לשמש גם להדדית וגם לסנכרון מורכב יותר (למשל, סמפורי ספירה לתבנית מפיק-צרכן).\n*   כל תהליכון יכול לבצע `sem_post` גם אם לא הוא ביצע `sem_wait` (אין \"בעלות\"). זה יכול להיות יתרון במצבים מסוימים, אך גם מקור לשגיאות.\n*   במקרה של הדדית פשוטה, מנעול עשוי להיות קצת יותר יעיל או בטוח לשימוש עקב הייעוד הספציפי שלו והתכונות הנוספות שהוזכרו."}, "difficulty_estimation": "Medium", "_source_file": "0183__Synchronization__Open__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:53:26", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Semaphores", "Deadlocks"], "content": {"text": "נתונים שלושה חוטים (Threads) המבצעים לולאה אינסופית. המטרה היא להשתמש בסמפורים כדי לסנכרן ביניהם כך שהפלט יהיה תמיד ברצף ABCABC... (כלומר, A תמיד מודפס לפני B, ו-B תמיד לפני C). לפניכם קטעי הקוד של החוטים:", "code_snippet": "// Thread A\nwhile(1) {\n    sem_wait(&s1);\n    printf(\"A\");\n    sem_post(&s2);\n}\n\n// Thread B\nwhile(1) {\n    sem_wait(&s2);\n    printf(\"B\");\n    sem_post(&s3);\n}\n\n// Thread C\nwhile(1) {\n    sem_wait(&s3);\n    printf(\"C\");\n    sem_post(&s1);\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "מהם ערכי האתחול הנדרשים עבור הסמפורים s1, s2, s3 כדי להבטיח שההדפסה הראשונה תהיה 'A' והסדר יישמר לאורך זמן?", "code_snippet": null, "options": null}, {"id": "10.2", "text": "מה יקרה אם נאתחל את כל הסמפורים לערך 0? הסבירו בקצרה.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "נניח ואתחלנו את s1=1, s2=1, s3=1. האם הסדר ABC מובטח? אם לא, תנו דוגמה לפלט אפשרי אחר.", "code_snippet": null, "options": null}], "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1. ערכי האתחול הנדרשים הם s1=1, s2=0, s3=0. אתחול s1 ל-1 מאפשר לחוט A להתחיל מיד. מכיוון ש-s2 ו-s3 הם 0, חוטים B ו-C ייחסמו ב-wait עד שחוט A יבצע post ל-s2, וחוט B יבצע post ל-s3 בהתאמה.\n\n10.2. אם כל הסמפורים יאותחלו ל-0, יתרחש מצב של Deadlock (קיפאון). כל אחד משלושת החוטים ינסה לבצע sem_wait על סמפור שערכו 0 וייחסם, ולא יהיה אף חוט שיבצע sem_post כדי לשחרר אותם.\n\n10.3. לא, הסדר אינו מובטח. אם כל הסמפורים מאותחלים ל-1, כל אחד מהחוטים יכול לעבור את ה-wait הראשון שלו ללא תלות באחרים. במצב כזה קיימת תחרות (Race Condition) על סדר ההדפסה שתלוי בתזמון של מערכת ההפעלה. פלט אפשרי אחר יכול להיות למשל BACBAC או CBA..."}, "difficulty_estimation": "Medium", "_source_file": "0184__Synchronization__Open__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 18:57:08", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Synchronization", "Threads", "Concurrency", "Mutexes", "Condition Variables"], "content": {"text": "נתונה מערכת המורכבת מ-N חוטי עבודה (worker threads) וחוט מתאם יחיד (coordinator thread). המערכת מעבדת משימות בקבוצות (batches). כל קבוצה מכילה סך הכל N * M משימות, כאשר כל חוט עבודה אחראי על עיבוד M משימות מתוך הקבוצה.\nלאחר שכל חוט עבודה סיים לעבד את M המשימות שלו עבור קבוצה מסוימת, הוא חייב להמתין שכל שאר N-1 חוטי העבודה יסיימו גם הם את משימותיהם עבור אותה קבוצה. רק לאחר שכל N חוטי העבודה סיימו את משימותיהם בקבוצה הנוכחית, הם יכולים להתקדם לקבוצה הבאה.\nחוט המתאם אחראי על אתחול קבוצות חדשות. הוא ממתין שכל N חוטי העבודה יסיימו קבוצה אחת לפני שהוא מסמן להם להתחיל את הקבוצה הבאה. התהליך חוזר על עצמו עבור B קבוצות סך הכל.\nממשו את מבנה הנתונים ואת הלוגיקה הנדרשת עבור חוטי העבודה וחוט המתאם, תוך שימוש ב-mutexes ו-condition variables, על מנת להבטיח סנכרון נכון, למנוע תקלות (race conditions, deadlocks) ולאפשר שימוש חוזר במנגנון הסנכרון עבור קבוצות עבודה עוקבות. יש לשים דגש על יעילות ומינימום 'המתנה ערה' (busy-waiting).", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h> // For usleep, to simulate work\n\n// Structure for the synchronization mechanism\ntypedef struct {\n  pthread_mutex_t mutex;\n  pthread_cond_t cv_workers_ready_to_start_batch;          // Coordinator signals workers to start. Workers wait.\n  pthread_cond_t cv_coordinator_notified_of_batch_completion; // Last worker signals coordinator. Coordinator waits.\n  int N;                                // Total number of worker threads\n  int workers_finished_current_batch;   // Counter for workers completing tasks in the *current* batch\n  int current_batch_num;                // The batch number currently being processed by workers (or waiting to be started)\n  int total_batches;                    // Total batches to process for the entire system\n} BatchCoordinator;\n\n// Arguments for worker threads\ntypedef struct {\n  int id;\n  int M; // Number of tasks per worker per batch\n  BatchCoordinator* coordinator;\n} WorkerArgs;\n\n// Function to initialize the BatchCoordinator\nvoid init_batch_coordinator(BatchCoordinator* bc, int N_workers, int total_batches_system) {\n  pthread_mutex_init(&bc->mutex, NULL);\n  pthread_cond_init(&bc->cv_workers_ready_to_start_batch, NULL);\n  pthread_cond_init(&bc->cv_coordinator_notified_of_batch_completion, NULL);\n  bc->N = N_workers;\n  bc->workers_finished_current_batch = 0;\n  bc->current_batch_num = 0; // Initialize to 0, so workers can start batch 0 immediately\n  bc->total_batches = total_batches_system;\n}\n\n// Function to destroy the BatchCoordinator\nvoid destroy_batch_coordinator(BatchCoordinator* bc) {\n  pthread_mutex_destroy(&bc->mutex);\n  pthread_cond_destroy(&bc->cv_workers_ready_to_start_batch);\n  pthread_cond_destroy(&bc->cv_coordinator_notified_of_batch_completion);\n}\n\n// Worker thread function\nvoid* worker_thread_func(void* arg) {\n    WorkerArgs* args = (WorkerArgs*)arg;\n    BatchCoordinator* bc = args->coordinator;\n    int worker_id = args->id;\n    int M = args->M;\n\n    for (int b = 0; b < bc->total_batches; ++b) {\n        // --- Phase 1: Worker waits for coordinator to allow starting batch 'b' ---\n        pthread_mutex_lock(&bc->mutex);\n        while (bc->current_batch_num < b) {\n            pthread_cond_wait(&bc->cv_workers_ready_to_start_batch, &bc->mutex);\n        }\n        pthread_mutex_unlock(&bc->mutex);\n\n        // --- Phase 2: Process M tasks ---\n        // Simulate work (e.g., sleep for a short random time)\n        usleep(rand() % 100000);\n\n        // --- Phase 3: Worker signals completion and (implicitly) waits for others ---\n        pthread_mutex_lock(&bc->mutex);\n        bc->workers_finished_current_batch++;\n\n        if (bc->workers_finished_current_batch == bc->N) {\n            // Last worker to finish. Signal coordinator.\n            pthread_cond_signal(&bc->cv_coordinator_notified_of_batch_completion);\n        }\n        pthread_mutex_unlock(&bc->mutex);\n    }\n    return NULL;\n}\n\n// Coordinator thread function\nvoid* coordinator_thread_func(void* arg) {\n    BatchCoordinator* bc = (BatchCoordinator*)arg;\n\n    for (int b = 0; b < bc->total_batches; ++b) {\n        // Phase 1: Coordinator ensures workers are ready for batch 'b' and signals them.\n        pthread_mutex_lock(&bc->mutex);\n        bc->current_batch_num = b; // Allow workers to start batch 'b'\n        pthread_cond_broadcast(&bc->cv_workers_ready_to_start_batch); // Wake up all workers for batch 'b'\n        pthread_mutex_unlock(&bc->mutex);\n\n        // Simulate coordinator doing some preparatory work for the batch if any\n        usleep(rand() % 50000);\n\n        // Phase 2: Coordinator waits for all workers to finish batch 'b'.\n        pthread_mutex_lock(&bc->mutex);\n        while (bc->workers_finished_current_batch < bc->N) {\n            pthread_cond_wait(&bc->cv_coordinator_notified_of_batch_completion, &bc->mutex);\n        }\n        // All workers finished batch 'b'. Reset counter for the next batch.\n        bc->workers_finished_current_batch = 0;\n        pthread_mutex_unlock(&bc->mutex);\n\n        // Simulate coordinator doing some work between batches\n        usleep(rand() % 50000);\n    }\n    return NULL;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הבעיה דורשת סנכרון דו-שלבי ושימוש חוזר: ראשית, חוטי העבודה צריכים להמתין זה לזה בסיום כל קבוצת משימות. שנית, חוט המתאם צריך לסנכרן את התחלת הקבוצות הבאות עם חוטי העבודה, ולהמתין לסיום הקבוצה הנוכחית לפני שהוא מאפשר את התחלת הבאה.\nלשם כך, נשתמש במבנה `BatchCoordinator` שיכיל:\n1.  `pthread_mutex_t mutex`: מנעול להגנה על משתנים משותפים.\n2.  `pthread_cond_t cv_workers_ready_to_start_batch`: משתנה תנאי שחוטי העבודה ממתינים עליו כדי לקבל אישור מחוט המתאם להתחיל קבוצת משימות חדשה. חוט המתאם מאותת עליו (broadcast).\n3.  `pthread_cond_t cv_coordinator_notified_of_batch_completion`: משתנה תנאי שחוט המתאם ממתין עליו כדי לקבל אישור מחוט העבודה האחרון שסיים את משימותיו בקבוצה הנוכחית. חוט העבודה האחרון מאותת עליו (signal).\n4.  `int N`: מספר חוטי העבודה הכולל.\n5.  `int workers_finished_current_batch`: מונה שסופר כמה חוטי עבודה סיימו את משימותיהם בקבוצה הנוכחית.\n6.  `int current_batch_num`: מספר הקבוצה הנוכחית שמותר לחוטי העבודה לעבד. משמש כ'שער' (turnstile) שמונע מחוטים להתקדם לקבוצה הבאה לפני שהמתאם אישר זאת.\n7.  `int total_batches`: המספר הכולל של קבוצות לעיבוד.\n\n**לוגיקת חוט העבודה (`worker_thread_func`):**\nכל חוט עבודה עובר בלולאה על כל הקבוצות (`b` מ-0 עד `total_batches-1`).\n*   **שלב 1 (המתנה לאישור מהמתאם):** החוט נועל את המוטקס ובודק אם `current_batch_num` שווה למספר הקבוצה הנוכחי `b`. אם `current_batch_num` נמוך מ-`b`, החוט ממתין על `cv_workers_ready_to_start_batch`. כאשר `current_batch_num` מגיע ל-`b` (כלומר, המתאם אישר להתחיל את קבוצה `b`), החוט משתחרר מההמתנה וממשיך.\n*   **שלב 2 (עיבוד משימות):** החוט מבצע את `M` המשימות המוטלות עליו עבור הקבוצה הנוכחית.\n*   **שלב 3 (איתות סיום):** החוט נועל את המוטקס, מגדיל את `workers_finished_current_batch` באחד. אם הוא החוט האחרון שמסיים (כלומר, `workers_finished_current_batch` שווה ל-`N`), הוא מאותת לחוט המתאם באמצעות `cv_coordinator_notified_of_batch_completion`. לאחר מכן הוא משחרר את המוטקס. החוטים אינם ממתינים זה לזה באופן מפורש בשלב זה, אלא ימתינו באופן טבעי לאישור המתאם לקבוצה הבאה בתחילת האיטרציה הבאה של הלולאה.\n\n**לוגיקת חוט המתאם (`coordinator_thread_func`):**\nחוט המתאם גם הוא עובר בלולאה על כל הקבוצות.\n*   **שלב 1 (איתות לחוטים להתחיל):** המתאם נועל את המוטקס, מעדכן את `current_batch_num` למספר הקבוצה הנוכחי `b` (כדי לאפשר לחוטי העבודה להתחיל לעבד אותה), ומשדר איתות (`pthread_cond_broadcast`) על `cv_workers_ready_to_start_batch` כדי להעיר את כל חוטי העבודה הממתינים. לאחר מכן הוא משחרר את המוטקס.\n*   **שלב 2 (המתנה לסיום הקבוצה):** המתאם נועל שוב את המוטקס וממתין על `cv_coordinator_notified_of_batch_completion` עד ש-`workers_finished_current_batch` יגיע ל-`N` (כלומר, כל חוטי העבודה סיימו את הקבוצה). ברגע שכל החוטים סיימו, המתאם מאפס את `workers_finished_current_batch` ל-0 לקראת הקבוצה הבאה, ומשחרר את המוטקס.\n\n**אתחול וסיום:**\n*   פונקציית `init_batch_coordinator` מאתחלת את כל אובייקטי הסנכרון וקובעת את `current_batch_num` ל-0, כך שחוטי העבודה יכולים להתחיל את קבוצה 0 ללא המתנה ראשונית.\n*   פונקציית `destroy_batch_coordinator` משחררת את המשאבים.\n\nפתרון זה מבטיח סנכרון נכון, מונע מצבי מירוץ וקיפאון, ומאפשר שימוש חוזר במנגנון הסנכרון ביעילות (ללא busy-waiting)."}, "difficulty_estimation": "Hard", "_source_file": "0185__Synchronization__Open__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:54:14", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Atomics", "Barriers", "Concurrency"], "content": {"text": "מחסום (Barrier) הוא אובייקט סנכרון המבטיח שכל N החוטים המשתתפים הגיעו לנקודה מסוימת לפני שמישהו מהם ממשיך בביצוע. מימוש נאיבי של מחסום המבוסס על מונה (Counter) ו-Mutex בלבד עלול להיכשל או לגרום לביצועים ירודים כאשר המחסום נמצא בשימוש חוזר (Reusable Barrier) בתוך לולאה. בשאלה זו נבחן את טכניקת ה-Sense Reversal המאפשרת מימוש יעיל ובטוח לשימוש חוזר ללא צורך ב-Locking כבד.", "code_snippet": "#include <stdatomic.h>\n\ntypedef struct {\n    atomic_int count;\n    atomic_int sense;\n    int N;\n} Barrier;\n\nvoid init(Barrier* b, int N) {\n    atomic_init(&b->count, N);\n    atomic_init(&b->sense, 0);\n    b->N = N;\n}\n\nvoid wait(Barrier* b) {\n    // Implementation required\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "הסבירו מדוע מימוש מחסום המבוסס על קידום מונה ובדיקת `if (count == N)` (ללא מנגנון נוסף) אינו בטיחותי לשימוש בתוך לולאה. תארו תרחיש (Race Condition) שבו חוט עלול להתקדם לשלב הבא באופן שגוי.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "השלימו את הקוד עבור הפונקציה `wait` המשתמשת בטכניקת ה-Sense Reversal. עליכם להשתמש בפעולות אטומיות בלבד (`atomic_load`, `atomic_store`, `atomic_fetch_sub`) ולהבטיח שהמחסום ניתן לשימוש חוזר אינסופי ללא אתחול חיצוני.", "code_snippet": "void wait(Barrier* b) {\n    // השלימו כאן\n}", "options": null}], "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: במימוש נאיבי, החוט האחרון שמעלה את המונה ל-N משחרר את שאר החוטים. אם החוטים רצים בלולאה, חוט מהיר במיוחד עשוי לסיים את האיטרציה הנוכחית, להיכנס לאיטרציה הבאה ולהתחיל לשנות את המונה (למשל לאפס אותו או להעלות אותו שוב) לפני שחוטים איטיים יותר הספיקו אפילו לקרוא שהמונה הגיע ל-N. מצב זה יגרום לחוטים האיטיים להיתקע לנצח או לחוט המהיר 'לפרוץ' את המחסום בטרם עת.\n\n10.2: בטכניקת Sense Reversal, אנו משתמשים במשתנה 'sense' גלובלי ובמשתנה מקומי לכל חוט. חוט שנכנס למחסום מחשב מה צריך להיות ה-sense הבא (היפוך של הנוכחי). החוטים ממתינים עד שה-sense הגלובלי ישתנה לערך המבוקש. החוט האחרון שמגיע הוא זה שאחראי לאפס את המונה עבור הסבב הבא ולשנות את ה-sense הגלובלי, ובכך הוא משחרר את כולם.\n\nקוד המימוש:\nvoid wait(Barrier* b) {\n    static _Thread_local int local_sense = 0;\n    local_sense = !local_sense; // היפוך ה-sense המקומי לכל חוט\n    \n    if (atomic_fetch_sub(&b->count, 1) == 1) {\n        // החוט האחרון שהגיע\n        atomic_store(&b->count, b->N); // הכנה לסבב הבא\n        atomic_store(&b->sense, local_sense); // שחרור כל החוטים ע\"י שינוי ה-sense הגלובלי\n    } else {\n        // חוטים שאינם האחרונים מחכים לשינוי ה-sense\n        while (atomic_load(&b->sense) != local_sense) {\n            // Spinning\n        }\n    }\n}"}, "difficulty_estimation": "Hard", "_source_file": "0186__Synchronization__Open__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:57:43", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Synchronization", "Concurrency", "Threads", "Mutexes", "Condition Variables"], "content": {"text": "ממשו אובייקט סנכרון בשם `QuotaGate` אשר מאפשר למכסה קבועה של חוטים, `N`, להיכנס לקטע קריטי. לאחר ש-`N` חוטים נכנסו לקטע הקריטי, כל חוט נוסף שינסה להיכנס יחסם. השער נפתח מחדש (כלומר, מאפשר ל-`N` חוטים חדשים להיכנס) רק לאחר שכל `N` החוטים שהיו בקטע הקריטי יצאו ממנו. יש לממש את האובייקט כך שיהיה ניתן לשימוש חוזר אינסופי.\n\nהשלימו את המימוש של הפונקציות `enter` ו-`exit_quota_gate` עבור מבנה הנתונים `QuotaGate` הנתון, תוך שימוש ב-`pthread_mutex_t` וב-`pthread_cond_t`. עליכם להגדיר את השדות הנדרשים בתוך מבנה `QuotaGate` ולממש גם את פונקציות ה-`init_quota_gate` ו-`destroy_quota_gate`.", "code_snippet": "```c\n#include <pthread.h>\n#include <stdlib.h>\n\n// You need to define the struct QuotaGate and implement its functions.\ntypedef struct {\n    // Define your fields here\n} QuotaGate;\n\n// Initializes the QuotaGate with a given quota N\nvoid init_quota_gate(QuotaGate *gate, int N);\n\n// Destroys the QuotaGate resources\nvoid destroy_quota_gate(QuotaGate *gate);\n\n// Thread calls this to enter the critical section\nvoid enter(QuotaGate *gate);\n\n// Thread calls this to exit the critical section\nvoid exit_quota_gate(QuotaGate *gate);\n```", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון משתמש בשני מונים ובמשתנה תנאי (condition variable) אחד בנוסף למוטקס אחד:\n1.  `N`: המכסה המקסימלית של חוטים המורשים להיכנס לקטע הקריטי בכל מחזור.\n2.  `current_entries`: מונה כמה חוטים כבר נכנסו לקטע הקריטי במחזור הנוכחי. כאשר מונה זה מגיע ל-`N`, חוטים נוספים יחסמו בכניסה.\n3.  `threads_waiting_to_exit`: מונה כמה חוטים מתוך ה-`N` שנכנסו עדיין נמצאים בקטע הקריטי (כלומר, טרם קראו ל-`exit_quota_gate`). כאשר מונה זה מגיע ל-0, זה מצביע על כך שכל החוטים מהמחזור הנוכחי יצאו, וניתן לאפס את השער למחזור הבא.\n4.  `mutex`: מנעול להגנה על המונים ועל גישה למשתנה התנאי.\n5.  `can_enter`: משתנה תנאי עבור חוטים הממתינים להיכנס לקטע הקריטי. חוטים אלו יקבלו איתות כאשר מחזור חדש מתחיל.\n\n**פונקציית `init_quota_gate`**: מאתחלת את המונים ומשתני הסנכרון.\n\n**פונקציית `destroy_quota_gate`**: משחררת את משאבי הסנכרון.\n\n**פונקציית `enter`**:\n*   החוט נועל את המוטקס.\n*   הוא בודק אם `current_entries` שווה ל-`N`. אם כן, זה אומר שמכסת החוטים למחזור הנוכחי כבר נכנסה, ולכן הוא ממתין על `can_enter`.\n*   כאשר החוט מתעורר (כי מחזור חדש התחיל), הוא מגדיל את `current_entries` (כדי לסמן שנכנס חוט נוסף למחזור החדש) ואת `threads_waiting_to_exit` (כדי לסמן שהוא נמצא כעת בתוך הקטע הקריטי).\n*   החוט משחרר את המוטקס.\n\n**פונקציית `exit_quota_gate`**:\n*   החוט נועל את המוטקס.\n*   הוא מקטין את `threads_waiting_to_exit` (כדי לסמן שיצא מהקטע הקריטי).\n*   אם `threads_waiting_to_exit` הגיע ל-0, זה אומר שכל `N` החוטים מהמחזור הקודם יצאו. במקרה זה:\n    *   מאפסים את `current_entries` ל-0, מה שמאפשר לחוטים חדשים להיכנס במחזור הבא.\n    *   שולחים איתות `broadcast` לכל החוטים הממתינים על `can_enter`, כדי לעורר אותם ולאפשר להם להתחיל להיכנס למחזור הבא.\n*   החוט משחרר את המוטקס.\n\nהפתרון מבטיח שאך ורק `N` חוטים ייכנסו בכל מחזור, ושהמחזור הבא יתחיל רק לאחר שכל `N` החוטים הקודמים יצאו. השימוש ב-`pthread_cond_broadcast` מבטיח שכל החוטים הממתינים בכניסה יתעוררו כאשר השער נפתח מחדש, ויכולים להתחרות על הכניסה.\n\n```c\n#include <pthread.h>\n#include <stdlib.h>\n\ntypedef struct {\n    int N;                      // The quota (max threads allowed in critical section per cycle)\n    int current_entries;        // Number of threads that have entered in the current cycle\n    int threads_waiting_to_exit; // Number of threads that are currently inside the critical section from the current cycle\n    pthread_mutex_t mutex;\n    pthread_cond_t can_enter;   // Condition variable for threads waiting to enter\n} QuotaGate;\n\nvoid init_quota_gate(QuotaGate *gate, int N) {\n    gate->N = N;\n    gate->current_entries = 0;\n    gate->threads_waiting_to_exit = 0;\n    pthread_mutex_init(&gate->mutex, NULL);\n    pthread_cond_init(&gate->can_enter, NULL);\n}\n\nvoid destroy_quota_gate(QuotaGate *gate) {\n    pthread_mutex_destroy(&gate->mutex);\n    pthread_cond_destroy(&gate->can_enter);\n}\n\nvoid enter(QuotaGate *gate) {\n    pthread_mutex_lock(&gate->mutex);\n\n    // Wait if N threads have already entered in the current cycle.\n    // This means the current batch is full, and we must wait for it to complete.\n    while (gate->current_entries == gate->N) {\n        pthread_cond_wait(&gate->can_enter, &gate->mutex);\n    }\n\n    gate->current_entries++;\n    gate->threads_waiting_to_exit++; // Increment this when a thread enters, to track how many are still inside\n\n    pthread_mutex_unlock(&gate->mutex);\n}\n\nvoid exit_quota_gate(QuotaGate *gate) {\n    pthread_mutex_lock(&gate->mutex);\n\n    gate->threads_waiting_to_exit--;\n\n    // If this is the last thread from the current cycle to exit,\n    // reset the gate for the next cycle and notify waiting threads.\n    if (gate->threads_waiting_to_exit == 0) {\n        gate->current_entries = 0; // Reset entry count for the next cycle\n        pthread_cond_broadcast(&gate->can_enter); // Wake up all threads waiting to enter\n    }\n\n    pthread_mutex_unlock(&gate->mutex);\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0187__Synchronization__Open__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:54:48", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Threads", "Concurrency", "Mutexes", "Condition Variables", "Barriers"], "content": {"text": "מערכת מרובת חוטים צריכה לעבד פריטים בקבוצות. קיים משאב משותף שיש לאפס (reset) לאחר כל K פריטים שמעובדים. הפעולה `reset_resource()` חייבת להתבצע בדיוק פעם אחת לאחר ש-K פריטים עובדו, וכל החוטים שהשתתפו בעיבוד קבוצה זו חייבים להמתין שהאיפוס יסתיים לפני שימשיכו לעבוד על הקבוצה הבאה. יש לממש את אובייקט הסנכרון `BatchProcessor` ואת הפונקציות `init`, `destroy`, ו-`process_item` תוך שימוש במנעולים (mutexes) ומשתני תנאי (condition variables) בלבד. אין לשנות את חתימת הפונקציה `reset_resource` או להוסיף לה פרמטרים. יש להקפיד על סנכרון נכון, מניעת מצבי מירוץ (race conditions) ומבוי סתום (deadlocks), ולהבטיח קריאה יחידה ל-`reset_resource` בכל K קריאות ל-`process_item`.", "code_snippet": "/* Include headers like <pthread.h> for mutexes and condition variables */\n\n// Function to be called by the system, simulates resource reset\nvoid reset_resource() {\n    // This function simulates work and should be called exactly once\n    // every K calls to process_item.\n    // In a real scenario, this might involve re-initializing a data structure,\n    // resetting a hardware component, etc.\n}\n\ntypedef struct {\n    // TODO: Add fields here\n} BatchProcessor;\n\nvoid init(BatchProcessor *bp, int K) {\n    // TODO: Implement\n}\n\nvoid destroy(BatchProcessor *bp) {\n    // TODO: Implement\n}\n\nvoid process_item(BatchProcessor *bp) {\n    // TODO: Implement\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון משתמש במנגנון מחסום מחזורי (Cyclic Barrier) כדי לסנכרן את החוטים. אובייקט `BatchProcessor` מכיל את השדות הבאים:\n- `K`: גודל הקבוצה הנדרש.\n- `count`: מונה כמה חוטים כבר נכנסו לקריאה ל-`process_item` עבור הקבוצה הנוכחית.\n- `generation`: מונה את מספר הקבוצה הנוכחית. משתנה זה חיוני כדי להבחין בין חוטים הממתינים מקבוצות שונות במקרה של שימוש חוזר באובייקט הסנכרון.\n- `mutex`: מנעול להגנה על המונים (`count`, `generation`) מפני מצבי מירוץ.\n- `cond`: משתנה תנאי המשמש להמתנה ושחרור חוטים.\n\n**מימוש קוד:**\n```c\n#include <pthread.h>\n\n// Function to be called by the system, simulates resource reset\nvoid reset_resource() {\n    // This function simulates work and should be called exactly once\n    // every K calls to process_item.\n    // In a real scenario, this might involve re-initializing a data structure,\n    // resetting a hardware component, etc.\n}\n\ntypedef struct {\n    int K;                  // Batch size\n    int count;              // Number of threads currently in the batch\n    int generation;         // Counter for batch cycles\n    pthread_mutex_t mutex;\n    pthread_cond_t cond;\n} BatchProcessor;\n\nvoid init(BatchProcessor *bp, int K) {\n    bp->K = K;\n    bp->count = 0;\n    bp->generation = 0;\n    pthread_mutex_init(&bp->mutex, NULL);\n    pthread_cond_init(&bp->cond, NULL);\n}\n\nvoid destroy(BatchProcessor *bp) {\n    pthread_mutex_destroy(&bp->mutex);\n    pthread_cond_destroy(&bp->cond);\n}\n\nvoid process_item(BatchProcessor *bp) {\n    pthread_mutex_lock(&bp->mutex);\n\n    int my_generation = bp->generation; \n\n    bp->count++;\n\n    if (bp->count == bp->K) { // This is the K-th thread in the batch\n        reset_resource();\n        bp->count = 0;          // Reset count for next batch\n        bp->generation++;       // Advance generation, signaling batch completion\n        pthread_cond_broadcast(&bp->cond); // Wake up all waiting threads\n    } else { \n        // Not the last thread, wait until the generation advances\n        // (meaning current batch is done and reset by the K-th thread)\n        while (bp->generation == my_generation) {\n            pthread_cond_wait(&bp->cond, &bp->mutex);\n        }\n    }\n\n    pthread_mutex_unlock(&bp->mutex);\n}\n```\n\n**הסבר מפורט:**\n\n**פונקציית `init`:**\nמאתחלת את השדות `K`, `count` (ל-0, משום שאף חוט עדיין לא נכנס לקבוצה הראשונה), `generation` (ל-0, קבוצה ראשונה), ומאתחלת את המנעול ומשתנה התנאי של `pthread`. אתחול נכון של אובייקטי הסנכרון הוא קריטי.\n\n**פונקציית `destroy`:**\nמשחררת את המשאבים של המנעול ומשתנה התנאי. חשוב לבצע זאת כדי למנוע דליפות זיכרון ומשאבי מערכת.\n\n**פונקציית `process_item`:**\n1.  **כניסה לאזור קריטי:** החוט נועל את ה-`mutex` באמצעות `pthread_mutex_lock(&bp->mutex)`. זה מבטיח שרק חוט אחד יוכל לשנות את המונים (`count`, `generation`) בכל רגע נתון, ובכך מונע מצבי מירוץ.\n2.  **שמירת דור (Generation):** החוט שומר את ערך ה-`generation` הנוכחי לתוך משתנה מקומי (`my_generation`). זהו מנגנון חיוני במחסומים מחזוריים. הוא מאפשר לחוטים לדעת לאיזה מחזור (קבוצה) הם שייכים. חוטים מקבוצה קודמת שהתעוררו (אך עדיין לא יצאו מהלולאה) או חוטים מקבוצה עתידית לא יושפעו בטעות מה-`broadcast` הנוכחי, ויוכלו להמתין לדור הנכון שלהם.\n3.  **קידום מונה הקבוצה:** החוט מקדם את המונה `count` (`bp->count++`), המייצג את מספר החוטים שנכנסו לקבוצה הנוכחית.\n4.  **זיהוי החוט האחרון בקבוצה:**\n    *   **`if (bp->count == bp->K)`:** אם ה-`count` שווה ל-`K`, החוט הנוכחי הוא האחרון בקבוצה. זהו החוט שאחראי לבצע את פעולות הסיום של הקבוצה:\n        *   **`reset_resource()`:** קריאה לפונקציית איפוס המשאב. מכיוון שרק החוט ה-K-י מגיע לכאן, מובטח שהפעולה תתבצע בדיוק פעם אחת עבור כל קבוצה של K פריטים.\n        *   **`bp->count = 0;`:** איפוס המונה `count` ל-0, כדי להתחיל לספור את החוטים עבור הקבוצה הבאה.\n        *   **`bp->generation++;`:** קידום מונה ה-`generation`. פעולה זו היא הסימן לכל החוטים הממתינים שהקבוצה הנוכחית הסתיימה, ושהמשאב אופס.\n        *   **`pthread_cond_broadcast(&bp->cond);`:** שידור לכל החוטים הממתינים על משתנה התנאי. כל החוטים שהמתינו (כלומר, הגיעו לפני החוט ה-K-י) יתעוררו ויבדקו את תנאי ההמתנה שלהם.\n5.  **המתנת חוטים שאינם אחרונים:**\n    *   **`else { while (bp->generation == my_generation) { pthread_cond_wait(&bp->cond, &bp->mutex); } }`:** אם החוט אינו החוט ה-K-י, הוא נכנס ללולאת המתנה. הוא ממתין על משתנה התנאי (`pthread_cond_wait`) כל עוד ה-`generation` הנוכחי של האובייקט (`bp->generation`) שווה ל-`my_generation` (הדור שהחוט הזה ראה כשנכנס). תנאי זה מבטיח שהחוט ימתין עד שהחוט ה-K-י יבצע את האיפוס ויקדם את ה-`generation`. כשה-`generation` של האובייקט מתקדם, החוט יודע שהקבוצה שלו הסתיימה ושהמשאב אופס, והוא יכול להמשיך.\n6.  **יציאה מאזור קריטי:** החוט משחרר את ה-`mutex` באמצעות `pthread_mutex_unlock(&bp->mutex)`. כעת הוא יכול להמשיך בעבודתו, בידיעה שהמשאב מוכן לקבוצה הבאה של פריטים."}, "difficulty_estimation": "Hard", "_source_file": "0188__Synchronization__Open__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:55:27", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Semaphores", "Mutexes", "Concurrency", "Starvation"], "content": {"text": "עליכם לממש מנגנון סנכרון עבור משאב משותף המוגבל ל-M משתמשים בו-זמנית. החוטים במערכת מחולקים לשני סוגים: A ו-B. המגבלות הן:\n1. סך כל החוטים (A ו-B יחד) המשתמשים במשאב לא יעלה על M.\n2. מספר החוטים מסוג A המשתמשים במשאב לא יעלה על K (כאשר K < M).\n3. מניעת הרעבה: אם יש חוטים מסוג B הממתינים בתור לכניסה, חוט חדש מסוג A יוכל להיכנס למשאב רק אם נמצאים בו כרגע פחות מ-K-1 חוטים מסוג A (כלומר, עליו להשאיר מקום פוטנציאלי לחוט מסוג B).\n\nעליכם להשתמש בטכניקת 'העברת המקל' (Pass the Baton) על מנת להבטיח את קיום התנאים ומניעת הרעבה, תוך שימוש בסמפורים ומוטקסים בלבד.", "code_snippet": "typedef struct {\n    int M, K;\n    int inA, inB;\n    int waitA, waitB;\n    sem_t lock;\n    sem_t semA;\n    sem_t semB;\n} ResourceControl;\n\nvoid init(ResourceControl *rc, int M, int K);\nvoid enter_A(ResourceControl *rc);\nvoid leave_A(ResourceControl *rc);\nvoid enter_B(ResourceControl *rc);\nvoid leave_B(ResourceControl *rc);", "options": null}, "sub_questions": [{"id": "10.1", "text": "ממשו את פונקציית האתחול init.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "ממשו את הפונקציות enter_A, leave_A, enter_B, leave_B. יש להשתמש בפונקציית עזר release_next המיישמת את לוגיקת העברת המקל.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון משתמש בטכניקת Pass the Baton. הרעיון המרכזי הוא שחוט שנכנס או יוצא בודק אם יש חוטים אחרים שיכולים להיכנס. אם כן, הוא משחרר את הסמפור שלהם מבלי לשחרר את ה-mutex (החוט המשוחרר 'יורש' את ה-mutex). רק אם אין אף חוט שיכול להיכנס, ה-mutex משוחרר.\n\n10.1:\nvoid init(ResourceControl *rc, int M, int K) {\n    rc->M = M; rc->K = K;\n    rc->inA = 0; rc->inB = 0;\n    rc->waitA = 0; rc->waitB = 0;\n    sem_init(&rc->lock, 0, 1);\n    sem_init(&rc->semA, 0, 0);\n    sem_init(&rc->semB, 0, 0);\n}\n\n10.2:\nvoid release_next(ResourceControl *rc) {\n    if (rc->waitB > 0 && (rc->inA + rc->inB < rc->M)) {\n        rc->waitB--; rc->inB++;\n        sem_post(&rc->semB);\n    } else if (rc->waitA > 0 && (rc->inA + rc->inB < rc->M) && (rc->inA < rc->K) && !(rc->waitB > 0 && rc->inA == rc->K - 1)) {\n        rc->waitA--; rc->inA++;\n        sem_post(&rc->semA);\n    } else {\n        sem_post(&rc->lock);\n    }\n}\n\nvoid enter_A(ResourceControl *rc) {\n    sem_wait(&rc->lock);\n    if ((rc->inA + rc->inB < rc->M) && (rc->inA < rc->K) && !(rc->waitB > 0 && rc->inA == rc->K - 1)) {\n        rc->inA++;\n        release_next(rc);\n    } else {\n        rc->waitA++;\n        sem_post(&rc->lock);\n        sem_wait(&rc->semA);\n        release_next(rc);\n    }\n}\n\nvoid leave_A(ResourceControl *rc) {\n    sem_wait(&rc->lock);\n    rc->inA--;\n    release_next(rc);\n}\n\nvoid enter_B(ResourceControl *rc) {\n    sem_wait(&rc->lock);\n    if (rc->inA + rc->inB < rc->M) {\n        rc->inB++;\n        release_next(rc);\n    } else {\n        rc->waitB++;\n        sem_post(&rc->lock);\n        sem_wait(&rc->semB);\n        release_next(rc);\n    }\n}\n\nvoid leave_B(ResourceControl *rc) {\n    sem_wait(&rc->lock);\n    rc->inB--;\n    release_next(rc);\n}"}, "difficulty_estimation": "Hard", "_source_file": "0189__Synchronization__Open__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 18:58:21", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Threads", "Concurrency", "Barriers", "Mutexes", "Condition Variables"], "content": {"text": "במערכות מרובות חוטים, לעיתים קרובות נדרש לסנכרן תהליכים במספר נקודות שונות במהלך ביצועם. נתונים N חוטים, ומטרתנו לממש מחסום דו-שלבי (Two-Phase Barrier) שניתן לשימוש חוזר. המחסום יסנכרן את N החוטים בשני שלבים עוקבים, כך שכל N החוטים חייבים להשלים שלב אחד לפני שמישהו מהם יוכל להתחיל את השלב הבא, וכן לפני שמישהו מהם יוכל להתחיל את השלב הראשון של המחזור הבא.\n\nיש לממש את מבנה הנתונים `TwoPhaseBarrier` ואת הפונקציות הבאות:\n*   `void init_two_phase_barrier(TwoPhaseBarrier *bar, int N)`: מאתחל את המחסום עבור N חוטים.\n*   `void destroy_two_phase_barrier(TwoPhaseBarrier *bar)`: משחרר משאבים של המחסום.\n*   `void phase1_checkin(TwoPhaseBarrier *bar)`: נקודת סנכרון ראשונה. חוט שקורא לפונקציה זו ממתין עד שכל N החוטים האחרים קראו אף הם ל-`phase1_checkin`. רק אז כולם ממשיכים.\n*   `void phase2_checkin(TwoPhaseBarrier *bar)`: נקודת סנכרון שנייה. חוט שקורא לפונקציה זו ממתין עד שכל N החוטים האחרים קראו אף הם ל-`phase2_checkin`. רק אז כולם ממשיכים.\n\nהמחזור של `phase1_checkin` ואז `phase2_checkin` יכול לחזור על עצמו מספר בלתי מוגבל של פעמים.\nהמימוש חייב להיות חסין בפני תנאי מירוץ (race conditions), קיפאון (deadlock), ורעב (starvation).\nהשתמשו באובייקטי סנכרון סטנדרטיים של POSIX Threads (כגון mutex ו-condition variables).", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "המימוש משתמש ב-mutex אחד וב-condition variable אחד כדי לסנכרן את כל N החוטים. המפתח להבטחת פעולה נכונה במחסום דו-שלבי שניתן לשימוש חוזר הוא ניהול מצב המחזור הנוכחי (current_wave) ומונה החוטים שהגיעו (count).\n\n**מבנה `TwoPhaseBarrier`:**\n```c\n#include <pthread.h>\n\ntypedef struct {\n    int N;\n    int count;          // Threads arrived at the current active wave\n    int current_wave;   // 0 for phase1, 1 for phase2. Increments after all threads pass a phase.\n                        // So, it will be 0 when waiting for phase1_checkin, then 1 for phase2_checkin, then 0 again.\n    pthread_mutex_t mutex;\n    pthread_cond_t cond; // Single condition variable is often sufficient for reusable barriers\n} TwoPhaseBarrier;\n```\n\n**פונקציות המימוש:**\n```c\nvoid init_two_phase_barrier(TwoPhaseBarrier *bar, int N) {\n    bar->N = N;\n    bar->count = 0;\n    bar->current_wave = 0; // Start with phase 0 (phase1_checkin)\n    pthread_mutex_init(&bar->mutex, NULL);\n    pthread_cond_init(&bar->cond, NULL);\n}\n\nvoid destroy_two_phase_barrier(TwoPhaseBarrier *bar) {\n    pthread_mutex_destroy(&bar->mutex);\n    pthread_cond_destroy(&bar->cond);\n}\n\n// Internal helper function for both phases\nvoid phase_checkin(TwoPhaseBarrier *bar, int expected_wave) {\n    pthread_mutex_lock(&bar->mutex);\n\n    // Wait if this thread is too fast and arrived for a future wave\n    // Or if it's too slow and arrived for a past wave (should not happen with correct usage)\n    while (bar->current_wave != expected_wave) {\n        pthread_cond_wait(&bar->cond, &bar->mutex);\n    }\n\n    bar->count++;\n    if (bar->count < bar->N) {\n        // Not the last thread, wait for others in the same wave\n        while (bar->current_wave == expected_wave) { // Wait until the current_wave changes (signaling completion)\n            pthread_cond_wait(&bar->cond, &bar->mutex);\n        }\n    } else {\n        // Last thread for this wave\n        bar->count = 0; // Reset for the next wave\n        bar->current_wave = (bar->current_wave + 1) % 2; // Advance to the next wave (0 -> 1, 1 -> 0)\n        pthread_cond_broadcast(&bar->cond); // Wake up all waiting threads\n    }\n    pthread_mutex_unlock(&bar->mutex);\n}\n\nvoid phase1_checkin(TwoPhaseBarrier *bar) {\n    phase_checkin(bar, 0);\n}\n\nvoid phase2_checkin(TwoPhaseBarrier *bar) {\n    phase_checkin(bar, 1);\n}\n```\n\n**לוגיקת הפעולה:**\n1.  **נעילת mutex**: כל חוט נועל את ה-mutex בכניסה לפונקציה כדי להגן על משתני המצב המשותפים.\n2.  **המתנה לשלב הנכון**: \n    *   `while (bar->current_wave != expected_wave)`: חוטים ממתינים כאן אם הם מנסים להיכנס לשלב שאינו השלב הפעיל כרגע. לדוגמה, אם `current_wave` הוא 0 (מצפה ל-`phase1_checkin`) וחוט מנסה לקרוא ל-`phase2_checkin` (עם `expected_wave` של 1), הוא ימתין. זה מונע מחוטים מהירים להקדים את זמנם לשלב הבא או למחזור הבא.\n3.  **קידום מונה והמתנה**: \n    *   `bar->count++`: החוט מקדם את מונה ההגעה לשלב הנוכחי.\n    *   `if (bar->count < bar->N)`: אם זה לא החוט האחרון שהגיע, הוא ממתין על משתנה התנאי. התנאי `while (bar->current_wave == expected_wave)` מבטיח שהחוט ימשיך להמתין עד שהחוט האחרון ישנה את `current_wave` (כלומר, השלב הנוכחי הושלם).\n4.  **החוט האחרון**: \n    *   `else`: אם זהו החוט ה-N שהגיע לשלב, הוא מבצע את הפעולות הבאות:\n        *   `bar->count = 0`: מאפס את המונה עבור השלב הבא.\n        *   `bar->current_wave = (bar->current_wave + 1) % 2`: מקדם את השלב הפעיל. אם היינו בשלב 0, עוברים לשלב 1; אם היינו בשלב 1, חוזרים לשלב 0 עבור המחזור הבא.\n        *   `pthread_cond_broadcast(&bar->cond)`: מעיר את כל החוטים הממתינים על משתנה התנאי. כעת הם יבדקו מחדש את תנאי ההמתנה שלהם וימשיכו (אלו שחיכו באותו שלב).\n5.  **שחרור mutex**: החוט משחרר את ה-mutex ויוצא מהפונקציה.\n\n**הימנעות מבעיות:**\n*   **Race Conditions**: ה-mutex מגן על כל הגישות למשתני המצב המשותפים (`count`, `current_wave`).\n*   **Deadlock**: לא קיים deadlock מכיוון שכל החוטים פועלים באותו אופן, ורק האחרון מביניהם משחרר את כולם. אין תלות מעגלית במשאבים.\n*   **Starvation**: כל החוטים מעוררים באמצעות `pthread_cond_broadcast`, כך שאף חוט לא נשאר תקוע לנצח.\n*   **Reusability**: ה-`current_wave` ואיפוס ה-`count` מבטיחים שהמחסום עובד נכון למחזורים עוקבים.\n\n**הערה**: המימוש מניח שכל N החוטים אכן יקראו ל-`phase1_checkin` ולאחר מכן ל-`phase2_checkin` (בסדר הנכון) במחזור נתון. אם חוט ינסה לדלג על שלב או לקרוא לשלב לא נכון, הוא ימתין עד שה-`current_wave` יתאים לדרישתו."}, "difficulty_estimation": "Hard", "_source_file": "0190__Synchronization__Open__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:42:23", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Synchronization", "Threads", "Concurrency", "Mutexes", "Condition Variables", "Barriers"], "content": {"text": "במערכות הפעלה מרובות-חוטים, לעיתים קרובות נדרש לסנכרן קבוצת חוטים כך שימתינו זה לזה, אך גם ימתינו לתנאי חיצוני מסוים. נתון אובייקט סנכרון בשם `ConditionalTurnstile` אשר מאפשר ל-N חוטים לעבור יחד, אך ורק כאשר תנאי חיצוני (שנקבע על ידי פונקציה אחרת) מתקיים. לאחר שקבוצה של N חוטים עברה, ה-`ConditionalTurnstile` מתאפס ומוכן לקבוצת החוטים הבאה.\n\nהאובייקט `ConditionalTurnstile` יכלול את הפעולות הבאות:\n*   `init(ConditionalTurnstile *ts, int N)`: מאתחל את ה-`Turnstile` עבור N חוטים.\n*   `destroy(ConditionalTurnstile *ts)`: משחרר משאבים.\n*   `wait_for_batch(ConditionalTurnstile *ts)`: חוט הקורא לפעולה זו ממתין עד ש-N חוטים נוספים (כולל הוא עצמו) קראו לפעולה, וכן שתנאי חיצוני מסוים מתקיים. רק אז, כל N החוטים משוחררים בו זמנית.\n*   `set_condition(ConditionalTurnstile *ts, bool condition_state)`: משנה את מצב התנאי החיצוני. אם התנאי הופך ל-`true` בזמן שחוטים ממתינים, והגיעה קבוצה של N חוטים, יש לשחררם.\n\nיש לממש את ה-`ConditionalTurnstile` תוך שימוש במנעולים (mutexes) ומשתני תנאי (condition variables) בלבד, ובאופן יעיל ככל האפשר. יש להקפיד על פתרון נטול קיפאון (deadlock-free) ותנאי מרוץ (race-condition-free).\n\nשימו לב במיוחד לטיפול במצבים הבאים:\n1.  מה קורה אם `set_condition` נקראת כאשר אין חוטים ממתינים?\n2.  מה קורה אם `set_condition` נקראת מספר פעמים ברצף?\n3.  כיצד מבטיחים שכל N החוטים ישוחררו יחד, ושהמונה יתאפס בצורה בטוחה לקבוצה הבאה, תוך כדי מניעת בעיית \"הנוסע הממהר\" (Early-departer problem) עם מחסומים הניתנים לשימוש חוזר?", "code_snippet": "#include <pthread.h>\n#include <stdbool.h>\n#include <stdlib.h>\n\ntypedef struct {\n    int N;                      // Total threads required for a batch\n    int arrived_count;          // Threads that have arrived in the current \"wave\"\n    int passed_count;           // Threads that have passed the barrier in the current \"wave\"\n    int wave;                   // Current wave number for reusability\n    pthread_mutex_t mutex;\n    pthread_cond_t cond_arrival;   // Threads wait here until batch is full AND condition met\n    pthread_cond_t cond_departure; // Threads wait here until all N have departed\n    bool condition_met;         // The external condition state\n} ConditionalTurnstile;\n\nvoid init(ConditionalTurnstile *ts, int N);\nvoid destroy(ConditionalTurnstile *ts);\nvoid wait_for_batch(ConditionalTurnstile *ts);\nvoid set_condition(ConditionalTurnstile *ts, bool condition_state);", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\nהמימוש משתמש באלגוריתם מחסום דו-שלבי (two-phase barrier) בשילוב עם מונה דורות (generation counter) על מנת לאפשר שימוש חוזר במחסום ולמנוע תנאי מרוץ כגון \"הנוסע הממהר\" (early-departer).\n\nמבנה `ConditionalTurnstile`:\n*   `N`: מספר החוטים הנדרשים לקבוצה אחת.\n*   `arrived_count`: מונה את מספר החוטים שהגיעו לשלב הראשון של המחסום בקבוצה הנוכחית.\n*   `passed_count`: מונה את מספר החוטים שעברו את שלב השחרור ומתקדמים לשלב האיפוס בקבוצה הנוכחית.\n*   `wave`: מונה דורות, מזהה איזו קבוצה של חוטים נמצאת כרגע במחסום. מתקדם כל פעם שקבוצה שלמה עוברת.\n*   `mutex`: מנעול להגנה על משתני המצב (`arrived_count`, `passed_count`, `wave`, `condition_met`).\n*   `cond_arrival`: משתנה תנאי עליו ממתינים חוטים בשלב ההגעה, עד שכל `N` החוטים הגיעו וגם `condition_met` נכון.\n*   `cond_departure`: משתנה תנאי עליו ממתינים חוטים בשלב העזיבה, עד שהחוט האחרון בקבוצה איפס את המחסום.\n*   `condition_met`: דגל בוליאני המייצג את מצב התנאי החיצוני.\n\n```c\n#include <pthread.h>\n#include <stdbool.h>\n#include <stdlib.h>\n\ntypedef struct {\n    int N;\n    int arrived_count;\n    int passed_count;\n    int wave;\n    pthread_mutex_t mutex;\n    pthread_cond_t cond_arrival;\n    pthread_cond_t cond_departure;\n    bool condition_met;\n} ConditionalTurnstile;\n\nvoid init(ConditionalTurnstile *ts, int N) {\n    ts->N = N;\n    ts->arrived_count = 0;\n    ts->passed_count = 0;\n    ts->wave = 0;\n    pthread_mutex_init(&ts->mutex, NULL);\n    pthread_cond_init(&ts->cond_arrival, NULL);\n    pthread_cond_init(&ts->cond_departure, NULL);\n    ts->condition_met = false;\n}\n\nvoid destroy(ConditionalTurnstile *ts) {\n    pthread_mutex_destroy(&ts->mutex);\n    pthread_cond_destroy(&ts->cond_arrival);\n    pthread_cond_destroy(&ts->cond_departure);\n}\n\nvoid wait_for_batch(ConditionalTurnstile *ts) {\n    pthread_mutex_lock(&ts->mutex);\n\n    int my_wave = ts->wave; // Captures the current wave number for this thread\n\n    ts->arrived_count++;\n\n    // Phase 1: Arrival - threads wait for N arrivals AND the external condition\n    if (ts->arrived_count == ts->N) { // This is the N-th thread to arrive\n        // The N-th thread waits until the external condition is met\n        while (!ts->condition_met) {\n            pthread_cond_wait(&ts->cond_arrival, &ts->mutex);\n        }\n        // Condition is met, and N threads have arrived. Release all threads in this batch.\n        // No need to increment wave here, it's done by the last departing thread.\n        pthread_cond_broadcast(&ts->cond_arrival);\n    } else { // Not the N-th thread to arrive\n        // Wait until the N-th thread signals that the batch is ready to proceed\n        // and the condition was met. We use 'my_wave' to ensure we wait for the current batch.\n        while (my_wave == ts->wave) {\n            pthread_cond_wait(&ts->cond_arrival, &ts->mutex);\n        }\n    }\n\n    // All N threads have now passed the arrival barrier and are released.\n    // Phase 2: Departure - threads decrement count and wait for the last thread to reset\n    ts->passed_count++;\n\n    if (ts->passed_count == ts->N) { // This is the N-th thread to depart\n        // Reset counts and advance the wave for the next batch\n        ts->arrived_count = 0;\n        ts->passed_count = 0;\n        ts->wave++; // Advance wave for the next batch of threads\n        // Signal all threads waiting in the departure phase that the barrier is reset\n        pthread_cond_broadcast(&ts->cond_departure);\n    } else { // Not the N-th thread to depart\n        // Wait until the last thread of this batch signals that the barrier is reset\n        while (my_wave == ts->wave) {\n            pthread_cond_wait(&ts->cond_departure, &ts->mutex);\n        }\n    }\n\n    pthread_mutex_unlock(&ts->mutex);\n}\n\nvoid set_condition(ConditionalTurnstile *ts, bool condition_state) {\n    pthread_mutex_lock(&ts->mutex);\n    ts->condition_met = condition_state;\n    // If the condition becomes true AND a full batch of threads is waiting,\n    // wake them up. This is crucial if the N-th thread is waiting for the condition.\n    if (condition_state && ts->arrived_count == ts->N) {\n        pthread_cond_broadcast(&ts->cond_arrival);\n    }\n    pthread_mutex_unlock(&ts->mutex);\n}\n```\n\nהסבר:\n\n**פונקציה `init(ConditionalTurnstile *ts, int N)`:**\n*   מאתחלת את המשתנים `N`, `arrived_count` (מונה חוטים שהגיעו), `passed_count` (מונה חוטים שעזבו), `wave` (מונה דורות לשימוש חוזר במחסום), ואת המנעול ומשתני התנאי. `condition_met` מאותחל ל-`false`.\n\n**פונקציה `destroy(ConditionalTurnstile *ts)`:**\n*   משחררת את המשאבים על ידי השמדת המנעול ומשתני התנאי.\n\n**פונקציה `wait_for_batch(ConditionalTurnstile *ts)`:**\n1.  **נעילה ורישום גל הדור:** החוט נועל את המוטקס ושומר את מספר ה\"גל\" (wave) הנוכחי במשתנה מקומי `my_wave`. זה מאפשר לו לזהות מתי המחסום התקדם ל\"גל\" הבא, ומונע תנאי מרוץ במחסום הניתן לשימוש חוזר.\n2.  **שלב ההגעה (Arrival Phase):**\n    *   `ts->arrived_count` מקודם. זהו מונה החוטים שהגיעו למחסום ב\"גל\" הנוכחי.\n    *   **אם החוט הוא החוט ה-N-י שמגיע (`ts->arrived_count == ts->N`):**\n        *   הוא ממתין (באמצעות `pthread_cond_wait` על `cond_arrival`) עד ש-`condition_met` יהפוך ל-`true`. הוא האחראי לשחרר את הקבוצה.\n        *   ברגע שהתנאי מתקיים, הוא משחרר את כל `N-1` החוטים הממתינים (באמצעות `pthread_cond_broadcast` על `cond_arrival`).\n    *   **אם החוט אינו החוט ה-N-י שמגיע (`ts->arrived_count < ts->N`):**\n        *   הוא ממתין (באמצעות `pthread_cond_wait` על `cond_arrival`) כל עוד `my_wave` שווה ל-`ts->wave`. הוא ישוחרר כאשר החוט ה-N-י ישדר `broadcast` וישנה את `my_wave` (על ידי קידום `ts->wave` בשלב העזיבה של הקבוצה).\n3.  **שלב העזיבה (Departure Phase):**\n    *   לאחר שכל `N` החוטים שוחררו משלב ההגעה, הם מקדמים את `ts->passed_count`. זהו מונה החוטים שעברו את שלב השחרור ב\"גל\" הנוכחי.\n    *   **אם החוט הוא החוט ה-N-י שעובר (`ts->passed_count == ts->N`):**\n        *   הוא מאפס את `arrived_count` ו-`passed_count` ל-0. פעולה זו \"מנקה\" את המחסום לקבוצה הבאה.\n        *   הוא מקדם את `ts->wave` (כדי לסמן שהמחסום מוכן לקבוצה הבאה).\n        *   הוא משחרר את כל `N-1` החוטים הממתינים בשלב העזיבה (באמצעות `pthread_cond_broadcast` על `cond_departure`).\n    *   **אם החוט אינו החוט ה-N-י שעובר (`ts->passed_count < ts->N`):**\n        *   הוא ממתין (באמצעות `pthread_cond_wait` על `cond_departure`) כל עוד `my_wave` שווה ל-`ts->wave`. הוא ישוחרר כאשר החוט האחרון יקדם את `ts->wave` ויבצע `broadcast`.\n4.  **שחרור:** החוט משחרר את המוטקס.\n\n**פונקציה `set_condition(ConditionalTurnstile *ts, bool condition_state)`:**\n1.  נועלת את המוטקס.\n2.  מעדכנת את `ts->condition_met` למצב החדש.\n3.  אם `condition_state` הפך ל-`true` וגם `ts->arrived_count` שווה ל-`ts->N` (כלומר, קבוצה מלאה של חוטים ממתינה על `cond_arrival`): היא משחררת את כל החוטים הממתינים על `cond_arrival` (באמצעות `pthread_cond_broadcast`). זה מאפשר לחוט ה-N-י (אם הוא ממתין על התנאי) או לשאר החוטים להתקדם.\n4.  משחררת את המוטקס.\n\n**טיפול במצבים מיוחדים:**\n1.  **`set_condition` נקראת כאשר אין חוטים ממתינים:** הפונקציה תעדכן את `condition_met`. אם `condition_state` הוא `true`, היא תבצע `broadcast` אך לא יהיו חוטים שיושפעו מכך באופן מיידי. החוטים שיגיעו מאוחר יותר ימצאו את `condition_met` כבר כ-`true` ויפעלו בהתאם.\n2.  **`set_condition` נקראת מספר פעמים ברצף:** רק הערך הסופי של `condition_state` יהיה רלוונטי. כל קריאה עשויה לבצע `broadcast` אם התנאי הופך ל-`true` וקבוצה מלאה ממתינה. אין בכך בעיה מבחינת נכונות, שכן `pthread_cond_broadcast` הוא אידמפוטנטי במובן זה של חוטים ממתינים.\n3.  **שחרור `N` חוטים יחד ואיפוס בטוח (מניעת \"הנוסע הממהר\"):**\n    *   מנגנון ה\"גל\" (`wave` counter) ומשתני התנאי `cond_arrival` ו-`cond_departure` מבטיחים זאת.\n    *   `cond_arrival` מבטיח שכל `N` החוטים יגיעו ושהתנאי יתקיים לפני שמישהו ימשיך. החוט ה-N-י הוא זה שמבצע `broadcast` כדי לשחרר את כולם.\n    *   `cond_departure` ומנגנון ה-`passed_count` מבטיחים שכל `N` החוטים יעברו את המחסום לפני ש-`ts->wave` יתקדם שוב. החוט האחרון שעוזב מאפס את המחסום ומקדם את ה\"גל\", ובכך מונע מחוטים מהגל הבא להתחיל לפני שהגל הקודם סיים את כל שלבי המחסום.\n    *   השימוש ב-`my_wave` המקומי בכל חוט מבטיח שחוט שקדם ל\"גל\" הבא לא ישוחרר בטעות על ידי `broadcast` המיועד ל\"גל\" קודם, וכן שחוט שפיגר לא ייתקע לנצח."}, "difficulty_estimation": "Hard", "_source_file": "0191__Synchronization__Open__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:57:16", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Threads", "Concurrency", "Mutexes", "Condition Variables", "Readers-Writers Problem"], "content": {"text": "במערכת הפעלה נתונה, קיים משאב משותף שניתן לגשת אליו ממספר חוטים במקביל. עם זאת, עקב מגבלות חומרה, לכל היותר M חוטים יכולים לגשת למשאב בו-זמנית (M הוא פרמטר אתחול). בנוסף, למשאב יש שני מצבי גישה: 'קריאה' ו-'כתיבה'.\n\n- חוטים במצב 'קריאה' יכולים לגשת למשאב במקביל, כל עוד המספר הכולל של חוטים הניגשים למשאב (קריאה + כתיבה) אינו עולה על M.\n- רק חוט אחד במצב 'כתיבה' יכול לגשת למשאב בכל רגע נתון.\n- אם חוט 'כתיבה' ממתין, אין לאפשר לחוטי 'קריאה' חדשים להתחיל לגשת למשאב (כדי למנוע הרעבה של כותבים).\n- אם חוט 'קריאה' ממתין, יש לאפשר לו להמשיך אם ישנם פחות מ-M חוטים פעילים ואין כותב ממתין.\n\nממשו את מבנה הנתונים `LimitedAccessResource` ואת הפעולות `init`, `destroy`, `acquire_read_access`, `release_read_access`, `acquire_write_access`, ו-`release_write_access` תוך שימוש באובייקטי סנכרון של POSIX (mutexes ו-condition variables). עליכם למנוע מצבי קיפאון (deadlocks) והרעבה (starvation) של כותבים, תוך ניצול מקסימלי של המשאב הנתון (עד M חוטים בו-זמנית).", "code_snippet": "typedef struct {\n    int max_concurrent_slots; // M\n    int active_readers;       // Number of readers currently accessing\n    int active_writer;        // 1 if a writer is active, 0 otherwise\n    int waiting_readers;      // Number of readers waiting\n    int waiting_writers;      // Number of writers waiting\n\n    pthread_mutex_t mutex;\n    pthread_cond_t reader_cond;\n    pthread_cond_t writer_cond;\n} LimitedAccessResource;\n\nvoid init(LimitedAccessResource *res, int M) {\n    // Implement this function\n}\n\nvoid destroy(LimitedAccessResource *res) {\n    // Implement this function\n}\n\nvoid acquire_read_access(LimitedAccessResource *res) {\n    // Implement this function\n}\n\nvoid release_read_access(LimitedAccessResource *res) {\n    // Implement this function\n}\n\nvoid acquire_write_access(LimitedAccessResource *res) {\n    // Implement this function\n}\n\nvoid release_write_access(LimitedAccessResource *res) {\n    // Implement this function\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון משתמש ב-mutex יחיד להגנה על המשתנים המשותפים (מונה קוראים פעילים, כותב פעיל, מוני קוראים וכותבים ממתינים), ובשני משתני תנאי (condition variables): אחד לקוראים ואחד לכותבים. המשתנים `active_readers` ו-`active_writer` עוקבים אחר מספר החוטים הפעילים, בעוד `waiting_readers` ו-`waiting_writers` עוקבים אחר החוטים הממתינים. הפרמטר `max_concurrent_slots` מגדיר את מגבלת ה-M הכוללת.\n\n**מניעת קיפאון (Deadlock Prevention):**\nהפתרון מונע קיפאון על ידי כך שחוט לעולם אינו מקבל חלק מהמשאבים שלו. חוט ממתין עד שכל התנאים לגישה מתקיימים, כולל מספר המקומות הפנויים וכללי העדיפות לכותבים. התלות ההדדית מנוהלת באמצעות משתני התנאי המאפשרים שחרור חוטים ממתינים באופן מבוקר.\n\n**מניעת הרעבה (Starvation Prevention):**\nהפתרון נותן עדיפות לכותבים (Writer Preference) באופן הבא:\n1.  **לכותבים עדיפות על פני קוראים חדשים:** ב-`acquire_read_access`, קורא ממתין אם `waiting_writers > 0` (כלומר, יש כותב שממתין). זה מונע מקוראים חדשים להיכנס ולגרום לכותב להמתין זמן רב.\n2.  **כותבים מתעוררים ראשונים:** ב-`release_read_access` וב-`release_write_access`, אם ישנם כותבים ממתינים (`waiting_writers > 0`) והתנאים מאפשרים לכותב להתקדם (לדוגמה, אין קוראים פעילים ב-`release_read_access` או שהכותב הפעיל סיים ב-`release_write_access`), אז משתנה התנאי של הכותבים (`writer_cond`) מסומן ראשון.\n\n**מקסימום מקביליות (Maximum Concurrency):**\n-   עד M חוטים יכולים לגשת למשאב בו-זמנית, כל עוד הם קוראים, ואין כותב פעיל או ממתין.\n-   `pthread_cond_broadcast` משמש לשחרור קבוצת קוראים בבת אחת כאשר אין כותבים ממתינים, מה שמאפשר למספר קוראים להיכנס למשאב כל עוד יש מקום (`(active_readers + active_writer) < max_concurrent_slots`).\n\n**מימוש הפונקציות:**\n```c\n#include <pthread.h>\n#include <stdlib.h>\n\ntypedef struct {\n    int max_concurrent_slots; // M\n    int active_readers;       // Number of readers currently accessing\n    int active_writer;        // 1 if a writer is active, 0 otherwise\n    int waiting_readers;      // Number of readers waiting\n    int waiting_writers;      // Number of writers waiting\n\n    pthread_mutex_t mutex;\n    pthread_cond_t reader_cond;\n    pthread_cond_t writer_cond;\n} LimitedAccessResource;\n\nvoid init(LimitedAccessResource *res, int M) {\n    res->max_concurrent_slots = M;\n    res->active_readers = 0;\n    res->active_writer = 0;\n    res->waiting_readers = 0;\n    res->waiting_writers = 0;\n    pthread_mutex_init(&res->mutex, NULL);\n    pthread_cond_init(&res->reader_cond, NULL);\n    pthread_cond_init(&res->writer_cond, NULL);\n}\n\nvoid destroy(LimitedAccessResource *res) {\n    pthread_mutex_destroy(&res->mutex);\n    pthread_cond_destroy(&res->reader_cond);\n    pthread_cond_destroy(&res->writer_cond);\n}\n\nvoid acquire_read_access(LimitedAccessResource *res) {\n    pthread_mutex_lock(&res->mutex);\n    res->waiting_readers++;\n    while (res->active_writer > 0 || \n           res->waiting_writers > 0 || \n           (res->active_readers + res->active_writer) >= res->max_concurrent_slots) {\n        pthread_cond_wait(&res->reader_cond, &res->mutex);\n    }\n    res->waiting_readers--;\n    res->active_readers++;\n    pthread_mutex_unlock(&res->mutex);\n}\n\nvoid release_read_access(LimitedAccessResource *res) {\n    pthread_mutex_lock(&res->mutex);\n    res->active_readers--;\n    // If this was the last reader and there are waiting writers, wake up one writer.\n    if (res->active_readers == 0 && res->waiting_writers > 0) {\n        pthread_cond_signal(&res->writer_cond);\n    } else if ((res->active_readers + res->active_writer) < res->max_concurrent_slots) {\n        // If there's still space and no writer is waiting, wake up readers.\n        if (res->waiting_writers == 0) {\n             pthread_cond_broadcast(&res->reader_cond);\n        }\n    }\n    pthread_mutex_unlock(&res->mutex);\n}\n\nvoid acquire_write_access(LimitedAccessResource *res) {\n    pthread_mutex_lock(&res->mutex);\n    res->waiting_writers++;\n    while (res->active_readers > 0 || \n           res->active_writer > 0 || \n           (res->active_readers + res->active_writer) >= res->max_concurrent_slots) {\n        pthread_cond_wait(&res->writer_cond, &res->mutex);\n    }\n    res->waiting_writers--;\n    res->active_writer = 1;\n    pthread_mutex_unlock(&res->mutex);\n}\n\nvoid release_write_access(LimitedAccessResource *res) {\n    pthread_mutex_lock(&res->mutex);\n    res->active_writer = 0;\n    // After a writer leaves, prioritize waiting writers.\n    if (res->waiting_writers > 0) {\n        pthread_cond_signal(&res->writer_cond);\n    } else {\n        // No waiting writers, wake up all waiting readers that can fit.\n        pthread_cond_broadcast(&res->reader_cond);\n    }\n    pthread_mutex_unlock(&res->mutex);\n}\n```", "difficulty_estimation": "Hard"}, "_source_file": "0192__Synchronization__Open__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:58:05", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Synchronization", "Race Conditions", "Mutexes", "Threads"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בחוטים מרובים לקידום מונה גלובלי משותף. עיין בקוד וענה על השאלות הבאות:", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 100000\n\nint counter = 0;\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, increment_counter, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "101.1", "text": "מהו הערך הסופי הצפוי של המונה `counter` לאחר שכל החוטים סיימו את ריצתם, בהנחה שהקוד רץ ללא שגיאות סנכרון?", "code_snippet": null, "options": null}, {"id": "101.2", "text": "האם ערך זה מובטח בפועל בריצת התוכנית הנתונה? אם לא, הסבר מדוע ומהי התופעה המתוארת. תאר בקצרה דוגמה לתזמון חוטים שיוביל לערך שאינו הערך הצפוי.", "code_snippet": null, "options": null}, {"id": "101.3", "text": "תקן את פונקציית `increment_counter` ואת פונקציית `main` כך שהמונה יגיע תמיד לערכו הצפוי, תוך שימוש במנגנון סנכרון `pthread_mutex_t`.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "101.1: הערך הסופי הצפוי של המונה `counter` הוא `NUM_THREADS * INCREMENTS_PER_THREAD`. במקרה זה, `5 * 100000 = 500000`.\n\n101.2: ערך זה אינו מובטח בפועל. התופעה המתוארת היא מצב מרוץ (Race Condition). מצב מרוץ מתרחש כאשר מספר חוטים ניגשים למשאב משותף (במקרה זה, המשתנה `counter`) ומנסים לשנות אותו במקביל, ללא מנגנון סנכרון מתאים, מה שעלול להוביל לתוצאות בלתי צפויות ושגויות. פעולת הקידום `counter++` אינה אטומית; היא מורכבת משלוש פעולות בסיסיות: קריאת הערך הנוכחי של `counter`, הגדלת הערך, וכתיבת הערך החדש בחזרה ל-`counter`. אם שני חוטים או יותר מבצעים פעולות אלה בו זמנית, חלק מהעדכונים עלולים ללכת לאיבוד.\nדוגמה לתזמון שגוי:\n1. חוט A קורא את `counter` (לדוגמה, הערך הוא 100).\n2. חוט B קורא את `counter` (גם הוא קורא את הערך 100, לפני שחוט A הספיק לכתוב בחזרה).\n3. חוט A מגדיל את הערך שקרא (100+1=101) וכותב אותו בחזרה ל-`counter`. כעת `counter` שווה 101.\n4. חוט B מגדיל את הערך שקרא (100+1=101) וכותב אותו בחזרה ל-`counter`. כעת `counter` שווה 101.\nבמקרה זה, למרות שבוצעו שתי פעולות קידום, המונה גדל באחד בלבד במקום בשניים, וקידום אחד אבד.\n\n101.3: כדי לתקן את הקוד ולהבטיח שהמונה יגיע לערכו הצפוי, יש להגן על הקטע הקריטי (הגישה ל-`counter` ושינויו) באמצעות מנגנון סנכרון כמו mutex. התיקון כולל הוספת משתנה mutex גלובלי, אתחולו, נעילתו לפני הגישה למונה ושחרורו לאחריה, ולבסוף השמדתו.\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 100000\n\nint counter = 0;\npthread_mutex_t mutex; // הצהרה על משתנה mutex גלובלי\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&mutex);   // נעילת ה-mutex לפני הגישה לקטע הקריטי\n        counter++;                     // הקטע הקריטי\n        pthread_mutex_unlock(&mutex); // שחרור ה-mutex לאחר היציאה מהקטע הקריטי\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    pthread_mutex_init(&mutex, NULL); // אתחול ה-mutex\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, increment_counter, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n    \n    pthread_mutex_destroy(&mutex); // השמדת ה-mutex\n    return 0;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0193__Synchronization__CodeAnalysis__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:58:22", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Synchronization", "Mutex", "Threads", "Race Conditions"], "content": {"text": "לפניכם קוד בשפת C המשתמש בחוטים (threads) ובמנעול מסוג Mutex. מה יהיה הפלט של התוכנית בהנחה שכל קריאות המערכת מצליחות?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\nint counter = 0;\npthread_mutex_t lock;\n\nvoid* increment_task(void* arg) {\n    for (int i = 0; i < 1000; i++) {\n        pthread_mutex_lock(&lock);\n        counter++;\n        pthread_mutex_unlock(&lock);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_mutex_init(&lock, NULL);\n    \n    pthread_create(&t1, NULL, increment_task, NULL);\n    pthread_create(&t2, NULL, increment_task, NULL);\n    \n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    \n    printf(\"%d\\n\", counter);\n    pthread_mutex_destroy(&lock);\n    return 0;\n}", "options": ["הפלט יהיה תמיד 1000", "הפלט יהיה תמיד 2000", "הפלט יהיה ערך אקראי בין 1000 ל-2000 עקב Race Condition", "התוכנית תיכנס למצב של Deadlock ולא תדפיס דבר"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "הפלט יהיה תמיד 2000", "explanation": "התוכנית יוצרת שני חוטים (threads), כאשר כל אחד מהם מבצע לולאה של 1000 איטרציות המקדמות משתנה גלובלי משותף (counter). מכיוון שפעולת הקידום (counter++) מוקפת בנעילה ושחרור של Mutex (pthread_mutex_lock ו-pthread_mutex_unlock), הקטע הקריטי מוגן. הגנה זו מבטיחה שרק חוט אחד יוכל לגשת למשתנה ולעדכן אותו בכל רגע נתון, ובכך נמנע מצב של Race Condition. לכן, כל 2000 הקידומים (1000 מכל חוט) יתבצעו בהצלחה והתוצאה הסופית תהיה תמיד 2000."}, "difficulty_estimation": "Easy", "_source_file": "0194__Synchronization__CodeAnalysis__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:58:44", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Synchronization", "Race Conditions", "Mutexes", "Threads"], "content": {"text": "נתונה תוכנית C המשתמשת בחוטים (threads) לקידום מונה גלובלי משותף. עיין בקוד וזהה את הבעיה הקיימת.", "code_snippet": "1 #include <stdio.h>\n2 #include <pthread.h>\n3 #include <stdlib.h>\n\n4 #define NUM_THREADS 5\n5 #define INCREMENTS_PER_THREAD 100000\n\n6 int counter = 0;\n\n7 void* increment_counter(void* arg) {\n8   for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n9     counter++;\n10  }\n11  return NULL;\n12}\n\n13 int main() {\n14  pthread_t threads[NUM_THREADS];\n\n15  for (int i = 0; i < NUM_THREADS; ++i) {\n16    if (pthread_create(&threads[i], NULL, increment_counter, NULL) != 0) {\n17      perror(\"Failed to create thread\");\n18      return 1;\n19    }\n20  }\n\n21  for (int i = 0; i < NUM_THREADS; ++i) {\n22    if (pthread_join(threads[i], NULL) != 0) {\n23      perror(\"Failed to join thread\");\n24      return 1;\n25    }\n26  }\n\n27  printf(\"Final counter value: %d\\n\", counter);\n28  printf(\"Expected counter value: %d\\n\", NUM_THREADS * INCREMENTS_PER_THREAD);\n\n29  return 0;\n30}", "options": null}, "sub_questions": [{"id": "8.1", "text": "תאר בקצרה את הבעיה שעלולה להתרחש בהרצת הקוד הנתון, והסבר מדוע ערך המונה הסופי אינו צפוי להיות תמיד שווה לערך המצופה.", "code_snippet": null, "options": null}, {"id": "8.2", "text": "תקן את הקוד המקורי כך שיפעל באופן תקין ויבטיח שכל הקידומים יבוצעו כראוי, כלומר, ערך המונה הסופי יהיה תמיד שווה לערך המצופה. השתמש במנעול (mutex) לצורך הסנכרון. ציין אילו שורות קוד הוספת/שינית ומה תפקידן.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "8.1: הבעיה בקוד הנתון היא \"מצב מרוץ\" (Race Condition). הפעולה `counter++` אינה אטומית, אלא מורכבת משלוש פעולות בסיסיות: קריאת ערך המונה מהזיכרון, הגדלתו באחד, וכתיבת הערך החדש בחזרה לזיכרון. כאשר מספר חוטים מריצים פעולה זו במקביל ללא סנכרון, ייתכן שחוט אחד יקרא את ערך המונה, וטרם יספיק לכתוב את הערך המוגדל, יתזמן המעבד חוט אחר שיקרא גם הוא את אותו ערך ישן. כתוצאה מכך, שני החוטים יבצעו הגדלה אך ערך המונה יוגדל פעם אחת בלבד, וקידומים ילכו לאיבוד. לכן, ערך המונה הסופי יהיה בדרך כלל נמוך מהערך המצופה (NUM_THREADS * INCREMENTS_PER_THREAD).\n\n8.2: כדי לתקן את הבעיה, יש להגן על הגישה למשתנה המשותף `counter` באמצעות מנעול (mutex). יש להכריז על מנעול גלובלי, לאתחל אותו, ולנעול ולשחרר אותו סביב הקטע הקריטי (הגדלת המונה).\n\nהקוד המתוקן ייראה כך:\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n#include <stdlib.h>\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 100000\n\nint counter = 0;\npthread_mutex_t counter_mutex; // שורה חדשה: הכרזה על מנעול\n\nvoid* increment_counter(void* arg) {\n  for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n    pthread_mutex_lock(&counter_mutex);   // שורה חדשה: נעילת המוטקס לפני הגישה לקטע הקריטי\n    counter++;\n    pthread_mutex_unlock(&counter_mutex); // שורה חדשה: שחרור המוטקס לאחר הגישה לקטע הקריטי\n  }\n  return NULL;\n}\n\nint main() {\n  pthread_t threads[NUM_THREADS];\n\n  pthread_mutex_init(&counter_mutex, NULL); // שורה חדשה: אתחול המנעול\n\n  for (int i = 0; i < NUM_THREADS; ++i) {\n    if (pthread_create(&threads[i], NULL, increment_counter, NULL) != 0) {\n      perror(\"Failed to create thread\");\n      return 1;\n    }\n  }\n\n  for (int i = 0; i < NUM_THREADS; ++i) {\n    if (pthread_join(threads[i], NULL) != 0) {\n      perror(\"Failed to join thread\");\n      return 1;\n    }\n  }\n\n  printf(\"Final counter value: %d\\n\", counter);\n  printf(\"Expected counter value: %d\\n\", NUM_THREADS * INCREMENTS_PER_THREAD);\n\n  pthread_mutex_destroy(&counter_mutex); // שורה חדשה: השמדת המנעול\n\n  return 0;\n}\n```\n\n**הסבר לשינויים:**\n1.  **`pthread_mutex_t counter_mutex;`**: הוספנו משתנה גלובלי מסוג `pthread_mutex_t` כדי לייצג את המנעול שיגן על המונה. (שורה 7 בקוד המתוקן)\n2.  **`pthread_mutex_init(&counter_mutex, NULL);`**: אתחלנו את המנעול בתחילת פונקציית `main`. (שורה 22 בקוד המתוקן)\n3.  **`pthread_mutex_lock(&counter_mutex);`**: לפני הגישה למשתנה `counter` בתוך הלולאה בפונקציה `increment_counter`, אנו נועלים את המוטקס. זה מבטיח שרק חוט אחד יכול להיכנס לקטע קריטי זה בכל רגע נתון. (שורה 10 בקוד המתוקן)\n4.  **`pthread_mutex_unlock(&counter_mutex);`**: לאחר שחרור הגישה למשתנה `counter` בתוך הלולאה, אנו משחררים את המוטקס, ומאפשרים לחוטים אחרים להיכנס לקטע הקריטי. (שורה 12 בקוד המתוקן)\n5.  **`pthread_mutex_destroy(&counter_mutex);`**: השמדנו את המנעול בסוף פונקציית `main` כדי לשחרר את המשאבים שהוקצו לו. (שורה 36 בקוד המתוקן)\n\nשינויים אלה מבטיחים שהפעולה `counter++` תתבצע באופן אטומי עבור כל חוט, ומונעים את מצב המרוץ, כך שערך המונה הסופי יהיה תמיד נכון."}, "difficulty_estimation": "Easy", "_source_file": "0195__Synchronization__CodeAnalysis__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:58:42", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Synchronization", "Mutex", "Race Conditions"], "content": {"text": "לפניכם תוכנית בשפת C המשתמשת בשני חוטים (threads) ובסנכרון מסוג מוטקס (mutex) כדי לקדם מונה משותף. עיינו בקוד וענו על הסעיפים הבאים:", "code_snippet": "1  #include <pthread.h>\n2  #include <stdio.h>\n3  \n4  int counter = 0;\n5  pthread_mutex_t mtx;\n6  \n7  void* func(void* arg) {\n8      for (int i = 0; i < 1000; i++) {\n9          pthread_mutex_lock(&mtx);\n10         counter++;\n11         pthread_mutex_unlock(&mtx);\n12     }\n13     return NULL;\n14 }\n15 \n16 int main() {\n17     pthread_t t1, t2;\n18     pthread_mutex_init(&mtx, NULL);\n19     pthread_create(&t1, NULL, func, NULL);\n20     pthread_create(&t2, NULL, func, NULL);\n21     pthread_join(t1, NULL);\n22     pthread_join(t2, NULL);\n23     printf(\"counter = %d\\n\", counter);\n24     pthread_mutex_destroy(&mtx);\n25     return 0;\n26 }", "options": null}, "sub_questions": [{"id": "10.1", "text": "מהו הערך המדויק שיודפס על המסך בסיום ריצת התוכנית?", "code_snippet": null, "options": null}, {"id": "10.2", "text": "נניח כי מחקנו את שורות 9 ו-11 מהקוד (הקריאות ל-lock ול-unlock). מהו הערך המקסימלי שייתכן ויודפס כעת? האם מובטח שהערך יהיה זהה בכל הרצה? הסבירו בקצרה.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: הערך שיודפס הוא 2000. השימוש במוטקס מבטיח שרק חוט אחד יוכל לבצע את פעולת הקידום (שורה 10) בכל רגע נתון. מכיוון שכל אחד משני החוטים מבצע 1000 קידומים, והסנכרון מונע איבוד עדכונים, התוצאה הסופית היא 2000.\n\n10.2: הערך המקסימלי שייתכן ויודפס הוא 2000 (במקרה שבו התזמון במקרה מנע חפיפה בין החוטים). לא, הערך אינו מובטח להיות זהה בכל הרצה. ללא המוטקס, הפעולה counter++ אינה אטומית (היא מורכבת מקריאה, הוספה וכתיבה), ונוצר מצב מרוץ (Race Condition). חוטים עלולים לקרוא את אותו ערך ישן ולדרוס זה את העדכון של זה, מה שיוביל לערך סופי נמוך מ-2000 (הערך המינימלי התיאורטי הוא 2)."}, "difficulty_estimation": "Easy", "_source_file": "0196__Synchronization__CodeAnalysis__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:59:09", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Synchronization", "Race Conditions", "Mutexes", "Threads"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בחוטים (threads) לקידום מונה גלובלי משותף. קמפלו והריצו את התוכנית. ניתן להניח שכל קריאות המערכת הצליחו.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#define NUM_THREADS 5\n#define ITERATIONS_PER_THREAD 100000\n\nint counter = 0;\n\nvoid* thread_func(void* arg) {\n    for (int i = 0; i < ITERATIONS_PER_THREAD; ++i) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "מהו הערך הסופי של המונה (counter) שיוצג בפלט התוכנית? נמקו את תשובתכם והסבירו מדוע יתכן שהערך לא יהיה כמצופה.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "תקנו את התוכנית כך שהמונה יתקדם באופן נכון, כלומר, הערך הסופי שלו יהיה תמיד כמצופה (NUM_THREADS * ITERATIONS_PER_THREAD). השתמשו במנגנון סנכרון מתאים (לדוגמה, mutex). יש לכתוב רק את השינויים הנדרשים בקוד (הוספה/שינוי של משתנים גלובליים, קוד בפונקציה thread_func ובפונקציה main).", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: הערך הסופי של המונה יהיה בדרך כלל קטן מ- NUM_THREADS * ITERATIONS_PER_THREAD (כלומר, קטן מ- 500,000 במקרה זה). הסיבה לכך היא תופעת מרוץ (race condition). פעולת `counter++` אינה אטומית; היא מורכבת משלוש פעולות בסיסיות: קריאת ערך המונה לתוך רגיסטר, הגדלת הערך ברגיסטר, וכתיבת הערך המוגדל חזרה לזיכרון. כאשר מספר חוטים מנסים לבצע פעולה זו במקביל, ייתכן שחוט אחד יקרא את ערך המונה, יופסק לפני הכתיבה, וחוט אחר יבצע את כל פעולת הקידום. כאשר החוט הראשון יחזור לרוץ, הוא יכתוב את הערך שקרא בתחילה ועוד 1, ובכך 'ידרוס' את הקידום שבוצע על ידי החוט השני. זה מוביל לאיבוד עדכונים ולערך סופי נמוך מהצפוי.\n\n10.2: כדי לתקן את בעיית המרוץ, נשתמש במנעול הדדי (mutex) כדי להגן על הקטע הקריטי (הפעולה `counter++`).\n\nשינויים נדרשים בקוד:\n\nהוספת משתנה גלובלי למנעול:\n`pthread_mutex_t mutex;`\n\nבפונקציה `main`:\nאתחול המנעול לפני יצירת החוטים:\n`pthread_mutex_init(&mutex, NULL);`\nשחרור המנעול לאחר סיום החוטים:\n`pthread_mutex_destroy(&mutex);`\n\nבפונקציה `thread_func`:\nנעילת המנעול לפני הגישה למשתנה המשותף ושחרורו מיד לאחר מכן:\n```c\nvoid* thread_func(void* arg) {\n    for (int i = 0; i < ITERATIONS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&mutex);\n        counter++;\n        pthread_mutex_unlock(&mutex);\n    }\n    return NULL;\n}\n```\nקוד מלא מתוקן:\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#define NUM_THREADS 5\n#define ITERATIONS_PER_THREAD 100000\n\nint counter = 0;\npthread_mutex_t mutex;\n\nvoid* thread_func(void* arg) {\n    for (int i = 0; i < ITERATIONS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&mutex);\n        counter++;\n        pthread_mutex_unlock(&mutex);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    pthread_mutex_init(&mutex, NULL);\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    pthread_mutex_destroy(&mutex);\n    return 0;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0197__Synchronization__CodeAnalysis__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:59:07", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Synchronization", "Mutex", "Race Conditions", "Threads"], "content": {"text": "נתון קוד ה-C הבא המשתמש בספריית pthreads. התוכנית מגדירה משתנה גלובלי counter ויוצרת שני חוטים המריצים את הפונקציה increment המקדמת את המונה 1000 פעמים.", "code_snippet": "1 #include <pthread.h>\n2 #include <stdio.h>\n3 \n4 int counter = 0;\n5 pthread_mutex_t lock;\n6 \n7 void* increment(void* arg) {\n8     for (int i = 0; i < 1000; i++) {\n9         pthread_mutex_lock(&lock);\n10        counter++;\n11        pthread_mutex_unlock(&lock);\n12    }\n13    return NULL;\n14 }\n15 \n16 int main() {\n17     pthread_t t1, t2;\n18     pthread_mutex_init(&lock, NULL);\n19     pthread_create(&t1, NULL, increment, NULL);\n20     pthread_create(&t2, NULL, increment, NULL);\n21     pthread_join(t1, NULL);\n22     pthread_join(t2, NULL);\n23     printf(\"%d\\n\", counter);\n24     return 0;\n25 }", "options": null}, "sub_questions": [{"id": "1.1", "text": "מה יהיה הערך המודפס של counter בסיום ריצת התוכנית כפי שהיא?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "נניח שהסרנו את השורות המבצעות נעילה ושחרור של המיוטקס (שורות 9 ו-11). מהו הערך המקסימלי והערך המינימלי האפשריים של counter שיודפסו בסיום הריצה?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: הערך שיודפס הוא 2000. השימוש ב-Mutex בשורות 9 ו-11 מבטיח שרק חוט אחד יוכל לגשת למשתנה המשותף counter בכל רגע נתון. מכיוון שכל חוט מבצע 1000 קידומים, והקידומים מוגנים מפני מרוץ תהליכים, התוצאה הסופית היא 1000 + 1000 = 2000.\n\n1.2: הערך המקסימלי הוא 2000 (במקרה שבו התזמון במקרה מנע התנגשויות). הערך המינימלי הוא 2. הסבר לערך המינימלי: חוט א' קורא את הערך 0 ונעצר לפני הקידום. חוט ב' רץ 999 פעמים ומעדכן את המונה ל-999. חוט א' ממשיך, כותב 1 למונה, ואז קורא את הערך 1 עבור האיטרציה השנייה שלו ונעצר. חוט ב' ממשיך לאיטרציה האחרונה שלו, קורא את הערך 1, וממתין לפני הכתיבה. חוט א' רץ כעת את כל שאר 998 האיטרציות שלו ומסיים (הערך במונה כעת 999). לבסוף חוט ב' חוזר וכותב את הערך 2 (הערך 1 שקרא + 1) למונה."}, "difficulty_estimation": "Easy", "_source_file": "0198__Synchronization__CodeAnalysis__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 18:59:40", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Synchronization", "Threads", "Mutex"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בחוטים (threads) לקידום מונה משותף באמצעות מנגנון סנכרון. עליכם לנתח את הקוד ולענות על השאלה: מה יהיה הערך הסופי של המונה (counter) שיוצג בפלט?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 10\n\nint counter = 0;\npthread_mutex_t mutex;\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&mutex);\n        counter++;\n        pthread_mutex_unlock(&mutex);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    pthread_mutex_init(&mutex, NULL);\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, increment_counter, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    pthread_mutex_destroy(&mutex);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הערך הסופי שיוצג בפלט יהיה 50. ישנם 5 חוטים (NUM_THREADS=5), וכל חוט מגדיל את המונה 10 פעמים (INCREMENTS_PER_THREAD=10). סך הכל יתבצעו 5 * 10 = 50 פעולות הגדלה. השימוש ב-mutex מבטיח שכל פעולת הגדלה של המונה תהיה אטומית, כלומר, לא יהיו מצבי מרוץ (race conditions) שבהם עדכונים אובדים. כל חוט נועל את ה-mutex לפני הגישה למונה, מבצע את ההגדלה, ומשחרר את ה-mutex, ובכך מבטיח גישה בלעדית למשאב המשותף. לכן, כל 50 ההגדלות יבוצעו בהצלחה והמונה יגיע לערכו הסופי הנכון."}, "difficulty_estimation": "Easy", "_source_file": "0199__Synchronization__CodeAnalysis__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:59:17", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Synchronization", "Threads", "Race Conditions", "Mutex"], "content": {"text": "נתונה התוכנית הבאה, המשתמשת במספר חוטים כדי להגדיל מונה משותף. קבוע N מייצג את מספר הפעמים שכל חוט יגדיל את המונה, וקבוע T מייצג את מספר החוטים. ניתן להניח שכל קריאות המערכת הצליחו.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\n#define T 4 // מספר חוטים\n#define N 100000 // מספר הגדלות לכל חוט\n\nint counter = 0;\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < N; ++i) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[T];\n\n    for (int i = 0; i < T; ++i) {\n        pthread_create(&threads[i], NULL, increment_counter, NULL);\n    }\n\n    for (int i = 0; i < T; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "101.1", "text": "מהו טווח הערכים האפשריים (מינימום ומקסימום) שיודפס עבור counter בסוף ריצת התוכנית? הסבירו מדוע.", "code_snippet": null, "options": null}, {"id": "101.2", "text": "תקנו את הקוד הנתון כך שהתוכנית תדפיס תמיד את הערך הנכון (T*N). השתמשו ב-mutexים בלבד. צרפו את הקוד המתוקן והסבירו בקצרה את השינויים.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "101.1: טווח הערכים האפשרי הוא בין N ל- T*N (כולל קצוות). ערך מקסימלי: T*N. זה יקרה אם, במקרה, אף פעם לא יתרחש מצב מרוץ והפעולות על המונה יהיו אטומיות למעשה, כלומר כל הגדלה של המונה תתבצע במלואה לפני שחוט אחר ינסה לגשת אליו. ערך מינימלי: N. זה יקרה עקב מצבי מרוץ (Race Conditions). פעולת 'counter++' אינה אטומית, והיא מתורגמת לקריאה של הערך, הגדלתו, וכתיבתו בחזרה. אם שני חוטים קוראים את אותו ערך של counter בו-זמנית, שניהם יגדילו אותו ויכתבו אותו בחזרה, מה שיגרום לאחת ההגדלות 'להיעלם' או להידרס. במקרה הקיצוני ביותר, כל החוטים (למעט אולי אחד שסיים את כל הגדלותיו) יאבדו את רוב ההגדלות שלהם, ורק N הגדלות (של חוט בודד שסיים את כל פעולותיו) או קצת יותר מזה ישארו במונה הסופי.\n\n101.2: כדי לתקן את מצב המרוץ ולהבטיח שהמונה יגיע תמיד לערך T*N, יש להשתמש ב-mutex כדי להגן על הגישה למשתנה counter. הנה הקוד המתוקן:\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n\n#define T 4 // מספר חוטים\n#define N 100000 // מספר הגדלות לכל חוט\n\nint counter = 0;\npthread_mutex_t mutex; // הגדרת mutex גלובלי\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < N; ++i) {\n        pthread_mutex_lock(&mutex);   // נעילת mutex לפני גישה למונה\n        counter++;\n        pthread_mutex_unlock(&mutex); // שחרור mutex לאחר הגישה למונה\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[T];\n\n    pthread_mutex_init(&mutex, NULL); // אתחול ה-mutex\n\n    for (int i = 0; i < T; ++i) {\n        pthread_create(&threads[i], NULL, increment_counter, NULL);\n    }\n\n    for (int i = 0; i < T; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    pthread_mutex_destroy(&mutex); // השמדת ה-mutex\n\n    return 0;\n}\n```\n\nהשינויים כוללים: (1) הגדרת משתנה `pthread_mutex_t mutex` גלובלי. (2) אתחול ה-mutex באמצעות `pthread_mutex_init` בפונקציה `main`. (3) עטיפת פעולת ההגדלה `counter++` בקריאות `pthread_mutex_lock` ו-`pthread_mutex_unlock` בתוך פונקציית `increment_counter`, מה שמבטיח שרק חוט אחד יוכל לבצע את הפעולה הזו בכל רגע נתון. (4) השמדת ה-mutex באמצעות `pthread_mutex_destroy` בסוף פונקציית `main`."}, "difficulty_estimation": "Easy", "_source_file": "0200__Synchronization__CodeAnalysis__Easy.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 19:59:39", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Synchronization", "Threads", "Race Conditions", "Mutexes"], "content": {"text": "נתונה תוכנית ה-C הבאה המשתמשת בתהליכונים (threads):\nהתוכנית יוצרת שני תהליכונים, כאשר כל אחד מהם מגדיל מונה גלובלי (counter) 100,000 פעמים. קראו את הקוד וענו על השאלות הבאות:\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n\nint counter = 0;\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < 100000; ++i) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_create(&tid1, NULL, increment_counter, NULL);\n    pthread_create(&tid2, NULL, increment_counter, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}\n```\n\n1. מהו הערך הסופי ה_צפוי_ של המשתנה `counter` לאחר ששני התהליכונים סיימו את פעולתם? נמק.\n2. האם הערך ה_מודפס_ בפועל יהיה תמיד זהה לערך הצפוי? אם לא, הסבר מדוע ומהי הבעיה המרכזית כאן.\n3. שנה את הקוד הנתון כך שיבטיח שהערך המודפס יהיה תמיד נכון (כלומר, שווה לערך הצפוי). הצג את הקוד המתוקן והסבר את השינויים שביצעת.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. **ערך צפוי:** כל תהליכון מגדיל את המונה 100,000 פעמים. מכיוון שיש שני תהליכונים, סך כל ההגדלות הוא 2 * 100,000 = 200,000. לכן, הערך הצפוי של `counter` הוא 200,000.\n2. **ערך מודפס בפועל והבעיה:** הערך המודפס בפועל _לא_ יהיה תמיד זהה לערך הצפוי. הבעיה המרכזית כאן היא **תנאי מירוץ (Race Condition)**. הפעולה `counter++` אינה אטומית. היא מורכבת משלוש פעולות ברמה נמוכה יותר:\n    *   קריאת הערך הנוכחי של `counter` לתוך אוגר.\n    *   הגדלת הערך באוגר באחד.\n    *   כתיבת הערך המעודכן מהאוגר חזרה לזיכרון של `counter`.\n    כאשר שני תהליכונים מנסים לבצע את הפעולה הזו בו-זמנית, ייתכן ששניהם יקראו את אותו ערך של `counter` לפני שאחד מהם הספיק לכתוב את הערך המעודכן בחזרה. לדוגמה, אם `counter` הוא 100:\n    *   תהליכון A קורא 100.\n    *   תהליכון B קורא 100.\n    *   תהליכון A מגדיל ל-101 וכותב 101.\n    *   תהליכון B מגדיל ל-101 (מתוך הערך שקרא קודם) וכותב 101.\n    במקרה זה, למרות שבוצעו שתי הגדלות, המונה גדל רק באחד. כתוצאה מכך, הערך הסופי יהיה נמוך מ-200,000.\n3. **קוד מתוקן עם מנגנוני סנכרון:**\n    כדי לפתור את תנאי המירוץ ולהבטיח שהגידול של `counter` יהיה אטומי, נשתמש במנעול (mutex) מסוג `pthread_mutex_t`.\n    הקוד המתוקן:\n    ```c\n    #include <stdio.h>\n    #include <pthread.h>\n\n    int counter = 0;\n    pthread_mutex_t mutex; // הצהרה על מנעול\n\n    void* increment_counter(void* arg) {\n        for (int i = 0; i < 100000; ++i) {\n            pthread_mutex_lock(&mutex);   // נעל את המנעול לפני גישה למשתנה המשותף\n            counter++;\n            pthread_mutex_unlock(&mutex); // שחרר את המנעול לאחר הגישה\n        }\n        return NULL;\n    }\n\n    int main() {\n        pthread_t tid1, tid2;\n\n        pthread_mutex_init(&mutex, NULL); // אתחל את המנעול\n\n        pthread_create(&tid1, NULL, increment_counter, NULL);\n        pthread_create(&tid2, NULL, increment_counter, NULL);\n\n        pthread_join(tid1, NULL);\n        pthread_join(tid2, NULL);\n\n        printf(\"Final counter value: %d\\n\", counter);\n\n        pthread_mutex_destroy(&mutex); // שחרר משאבי מנעול\n        return 0;\n    }\n    ```\n    **הסבר לשינויים:**\n    *   **`pthread_mutex_t mutex;`**: הוספנו הצהרה על משתנה מטיפוס `pthread_mutex_t` שישמש כמנעול.\n    *   **`pthread_mutex_init(&mutex, NULL);`**: בתוך פונקציית `main`, אתחלנו את המנעול לפני יצירת התהליכונים.\n    *   **`pthread_mutex_lock(&mutex);`**: לפני הפעולה `counter++` בקטע הקריטי (critical section) בתוך `increment_counter`, קראנו לפונקציה זו כדי לנעול את המנעול. רק תהליכון אחד יכול להחזיק במנעול בכל רגע נתון.\n    *   **`pthread_mutex_unlock(&mutex);`**: מיד לאחר הפעולה `counter++`, שחררנו את המנעול. זה מאפשר לתהליכונים אחרים לנסות לנעול אותו.\n    *   **`pthread_mutex_destroy(&mutex);`**: בסיום התוכנית, לאחר ששני התהליכונים סיימו והצטרפו חזרה ל-`main`, שחררנו את משאבי המנעול.\n    שינויים אלה מבטיחים שרק תהליכון אחד יגדיל את `counter` בכל רגע נתון, ובכך מונעים את תנאי המירוץ ומבטיחים שהערך הסופי יהיה 200,000."}, "difficulty_estimation": "Medium", "_source_file": "0201__Synchronization__CodeAnalysis__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:00:02", "_subject": "Concurrency"}, {"id": 7, "type": "CodeAnalysis", "topic": ["Synchronization", "Deadlock", "Mutexes", "Pthreads"], "content": {"text": "נתונה התוכנית הבאה, המשתמשת ב-pthreads ובמנעולים (mutexes) כדי לגשת למשאבים משותפים:\n\n", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex1 = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_t mutex2 = PTHREAD_MUTEX_INITIALIZER;\n\nint resource1 = 0;\nint resource2 = 0;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 1: Locked mutex1. Trying to lock mutex2...\\n\");\n    sleep(1); \n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 1: Locked mutex2. Accessing resources.\\n\");\n\n    resource1++;\n    resource2++;\n\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 1: Unlocked mutex2.\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 1: Unlocked mutex1. Exiting.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to lock mutex2...\\n\");\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2: Locked mutex2. Trying to lock mutex1...\\n\");\n    sleep(1); \n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2: Locked mutex1. Accessing resources.\\n\");\n\n    resource1--;\n    resource2--;\n\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 2: Unlocked mutex1.\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2: Unlocked mutex2. Exiting.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_create(&tid1, NULL, thread_func1, NULL);\n    pthread_create(&tid2, NULL, thread_func2, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    printf(\"Main: Final resource1 = %d, resource2 = %d\\n\", resource1, resource2);\n\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n\n    return 0;\n}"}, "sub_questions": [{"id": "7.1", "text": "האם קיים פוטנציאל למצב של קיפאון (Deadlock) בתוכנית זו? אם כן, הסבר מדוע וציין את התנאים ההכרחיים לקיפאון שמתקיימים כאן. אם לא, הסבר מדוע.", "code_snippet": null, "options": null}, {"id": "7.2", "text": "בהנחה שהתוכנית רצה ללא קיפאון ומסיימת את ריצתה בהצלחה, מה יהיו הערכים הסופיים של המשתנים resource1 ו-resource2 בסיום ריצת התוכנית?", "code_snippet": null, "options": null}, {"id": "7.3", "text": "כיצד ניתן למנוע קיפאון בתוכנית זו על ידי שינוי מינימלי בקוד, תוך שמירה על הפונקציונליות המקורית של גישה למשאבים? ציין את השינוי הספציפי ואת ההיגיון מאחוריו.", "code_snippet": null, "options": null}], "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\nא. כן, קיים פוטנציאל למצב של קיפאון (Deadlock) בתוכנית זו.\nההסבר: קיפאון יכול להתרחש כאשר Thread 1 רוכש את mutex1 ולאחר מכן מנסה לרכוש את mutex2, ובמקביל Thread 2 רוכש את mutex2 ולאחר מכן מנסה לרכוש את mutex1. אם התזמון של ריצת התהליכונים מאפשר לכל אחד מהם לרכוש את המנעול הראשון שלו לפני שהשני רכש את שניהם, שניהם יכנסו למצב המתנה אינסופי זה לזה.\nהתנאים ההכרחיים לקיפאון שמתקיימים כאן הם (תנאי קופמן):\n1.  **הדדיות (Mutual Exclusion)**: המנעולים (mutexes) מבטיחים שרק תהליכון אחד יכול להחזיק במשאב (מנעול) בכל רגע נתון.\n2.  **החזק והמתן (Hold and Wait)**: כל תהליכון מחזיק במנעול אחד (לדוגמה, Thread 1 מחזיק ב-mutex1) וממתין למנעול נוסף (mutex2).\n3.  **אי-הפקעה (No Preemption)**: לא ניתן להפקיע מנעול מתהליכון שמחזיק בו; המנעול ישוחרר רק מרצון על ידי התהליכון המחזיק בו.\n4.  **המתנה מעגלית (Circular Wait)**: נוצרת שרשרת המתנה מעגלית: Thread 1 ממתין ל-mutex2 שמוחזק על ידי Thread 2, ו-Thread 2 ממתין ל-mutex1 שמוחזק על ידי Thread 1.\nהקריאות ל-sleep(1) מגבירות את הסיכוי לתזמון שיגרום לקיפאון.\n\nב. בהנחה שהתוכנית רצה ללא קיפאון ומסיימת את ריצתה בהצלחה, שני התהליכונים יבצעו את פעולותיהם באופן מלא.\n*   Thread 1 מגדיל את resource1 ואת resource2 באחד (resource1 = 1, resource2 = 1).\n*   Thread 2 מקטין את resource1 ואת resource2 באחד (resource1 = 0, resource2 = 0).\nלכן, הערכים הסופיים יהיו:\nresource1 = 0\nresource2 = 0\n\nג. ניתן למנוע קיפאון על ידי שבירת תנאי 'המתנה מעגלית' (Circular Wait) באמצעות קביעת סדר קבוע לרכישת המנעולים. השינוי המינימלי ביותר הוא לגרום לשני התהליכונים לרכוש את המנעולים באותו הסדר. לדוגמה, שניהם ירכשו תמיד את mutex1 ואז את mutex2.\n\nשינוי מוצע בקוד (בפונקציה thread_func2 בלבד):\n```c\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1); // שינוי כאן: קודם mutex1\n    printf(\"Thread 2: Locked mutex1. Trying to lock mutex2...\\n\");\n    sleep(1); \n    pthread_mutex_lock(&mutex2); // ואז mutex2\n    printf(\"Thread 2: Locked mutex2. Accessing resources.\\n\");\n\n    resource1--;\n    resource2--;\n\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2: Unlocked mutex2.\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 2: Unlocked mutex1. Exiting.\\n\");\n    return NULL;\n}\n```\nההיגיון מאחורי השינוי: כאשר כל התהליכונים רוכשים את המנעולים באותו סדר (לדוגמה, תמיד mutex1 ואז mutex2), לא יכולה להיווצר המתנה מעגלית. אם תהליכון אחד מחזיק ב-mutex1 וממתין ל-mutex2, אף תהליכון אחר לא יכול להחזיק ב-mutex2 ולחכות ל-mutex1, מכיוון שהוא היה צריך לרכוש קודם את mutex1 (שכבר מוחזק). זה מבטיח שאם יתרחש חסימה, היא תהיה ליניארית ולא מעגלית, ובסופו של דבר אחד מהתהליכונים יתקדם וישחרר את המשאבים."}, "difficulty_estimation": "Medium", "_source_file": "0202__Synchronization__CodeAnalysis__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:42:50", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Synchronization", "Producer-Consumer", "Mutex", "Condition Variables"], "content": {"text": "נתונה תוכנית C הבאה המשתמשת ב-pthreads, mutexes, ו-condition variables. התוכנית מדמה תהליך יצרן-צרכן עם משאב משותף (מונה `count`) וגודל חיץ מוגבל (`MAX_COUNT`).\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n#include <unistd.h> // For usleep\n\n#define MAX_COUNT 5\n#define NUM_OPERATIONS 10\n\nint count = 0;\npthread_mutex_t mutex;\npthread_cond_t cond_producer; // Condition for producer to wait if buffer is full\npthread_cond_t cond_consumer; // Condition for consumer to wait if buffer is empty\n\nvoid* producer(void* arg) {\n    for (int i = 0; i < NUM_OPERATIONS; ++i) {\n        pthread_mutex_lock(&mutex);\n        while (count == MAX_COUNT) {\n            printf(\"Producer waiting (count=%d)...\\n\", count);\n            pthread_cond_wait(&cond_producer, &mutex);\n        }\n        count++;\n        printf(\"Producer: count = %d\\n\", count);\n        pthread_cond_signal(&cond_consumer);\n        pthread_mutex_unlock(&mutex);\n        usleep(100000); // Simulate work\n    }\n    return NULL;\n}\n\nvoid* consumer(void* arg) {\n    for (int i = 0; i < NUM_OPERATIONS; ++i) {\n        pthread_mutex_lock(&mutex);\n        while (count == 0) {\n            printf(\"Consumer waiting (count=%d)...\\n\", count);\n            pthread_cond_wait(&cond_consumer, &mutex);\n        }\n        count--;\n        printf(\"Consumer: count = %d\\n\", count);\n        pthread_cond_signal(&cond_producer);\n        pthread_mutex_unlock(&mutex);\n        usleep(150000); // Simulate work\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t prod_tid, cons_tid;\n\n    pthread_mutex_init(&mutex, NULL);\n    pthread_cond_init(&cond_producer, NULL);\n    pthread_cond_init(&cond_consumer, NULL);\n\n    pthread_create(&prod_tid, NULL, producer, NULL);\n    pthread_create(&cons_tid, NULL, consumer, NULL);\n\n    pthread_join(prod_tid, NULL);\n    pthread_join(cons_tid, NULL);\n\n    printf(\"Final count value: %d\\n\", count);\n\n    pthread_mutex_destroy(&mutex);\n    pthread_cond_destroy(&cond_producer);\n    pthread_cond_destroy(&cond_consumer);\n\n    return 0;\n}\n```\n\nבהתבסס על התוכנית הנתונה:\n1.  מה יהיה הערך הסופי של המשתנה `count` המודפס על ידי התוכנית הראשית (`main`)? נמקו את תשובתכם.\n2.  תארו את אופי הפלט שיופק על ידי התוכנית, והסבירו מדוע הוא כך. (האם הוא דטרמיניסטי? אילו ערכים יכולים להופיע? מה היחס ביניהם?)\n3.  האם קיימת בתוכנית סכנה למצב קיפאון (Deadlock)? נמקו את תשובתכם.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  **ערך סופי של `count`:**\n    הערך הסופי של `count` יהיה 0.\n    **נימוק:**\n    *   גם תהליכון היצרן וגם תהליכון הצרכן מבצעים `NUM_OPERATIONS` פעולות, שכל אחת מהן מגדילה או מקטינה את `count` באחד.\n    *   היצרן מבצע 10 הגדלות (`count++`).\n    *   הצרכן מבצע 10 הקטנות (`count--`).\n    *   הפעולות מוגנות על ידי mutex ומתואמות באמצעות condition variables כך ש-`count` לעולם לא יעבור את `MAX_COUNT` (5) או ירד מתחת ל-0.\n    *   השפעה נטו על `count` היא `10 - 10 = 0`. מכיוון ש-`count` מתחיל מ-0, הוא יחזור ל-0 בסיום כל הפעולות.\n\n2.  **אופי הפלט:**\n    הפלט לא יהיה דטרמיניסטי מבחינת סדר ההודעות \"Producer: count = X\" ו-\"Consumer: count = Y\", אך הוא יהיה דטרמיניסטי מבחינת רצף הערכים הלוגי.\n    *   **אי-דטרמיניסטיות**: סדר ההרצה של תהליכונים תלוי בתזמן מערכת ההפעלה, ולכן סדר ההדפסות מהיצרן והצרכן ישתנה בין הרצות שונות (בנוסף לשימוש ב-`usleep` שמשפיע על התזמון).\n    *   **דטרמיניסטיות לוגית**: \n        *   הודעות \"Producer: count = X\" יציגו ערכים של `count` בין 1 ל-`MAX_COUNT` (כלומר, 1 עד 5).\n        *   הודעות \"Consumer: count = Y\" יציגו ערכים של `count` בין 0 ל-`MAX_COUNT - 1` (כלומר, 0 עד 4).\n        *   כל הדפסה של היצרן תגדיל את `count` באחד, וכל הדפסה של הצרכן תקטין את `count` באחד.\n        *   הודעות \"Producer waiting...\" יופיעו כאשר `count` מגיע ל-`MAX_COUNT` (5) והיצרן מנסה להגדיל אותו שוב, אך נאלץ להמתין שהצרכן יפנה מקום.\n        *   הודעות \"Consumer waiting...\" יופיעו כאשר `count` מגיע ל-0 והצרכן מנסה להקטין אותו שוב, אך נאלץ להמתין שהיצרן ייצר פריט.\n        *   כל הדפסה מתרחשת בתוך critical section (לאחר נעילת ה-mutex), כך שהערך המודפס של `count` יהיה תמיד עקבי לרגע ההדפסה.\n\n3.  **סכנה למצב קיפאון (Deadlock):**\n    לא, לא קיימת סכנה למצב קיפאון (deadlock) בתוכנית זו.\n    **נימוק:**\n    *   נעילת ה-mutex מתבצעת תמיד לפני כניסה לאזור הקריטי ושחרורו מתבצע תמיד לאחר היציאה ממנו. אין מצב של החזקה ב-mutex אחד וניסיון לנעול mutex אחר.\n    *   התהליכונים ממתינים על condition variables (באמצעות `pthread_cond_wait`) אך עושים זאת תוך שחרור אוטומטי של ה-mutex וחזרה לנעול אותו עם קבלת האות. זה מונע מצב שבו תהליכון אחד מחזיק ב-mutex וממתין לאירוע שתהליכון אחר צריך את אותו mutex כדי לייצר/לצרוך, ובכך לא יאפשר לו להתקדם.\n    *   השימוש בלולאות `while` סביב `pthread_cond_wait` הוא הדרך הנכונה לטפל ב-spurious wakeups ומבטיח שהתהליכון ימשיך רק כאשר התנאי באמת מתקיים, מבלי להכניס באג לוגי או deadlock.\n    *   קיים רק mutex אחד וזוג condition variables, וכל תהליכון משתמש בהם בסדר הגיוני: נועל mutex, בודק תנאי, ממתין אם צריך (משחרר mutex), מבצע פעולה, מאותת, ומשחרר mutex. אין פקודות נעילה מרובות בסדר שונה שיכול להוביל ל-deadlock."}, "difficulty_estimation": "Medium", "_source_file": "0203__Synchronization__CodeAnalysis__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:01:06", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Threads"], "content": {"text": "לפניכם קטע קוד המשתמש בסמפורים לתיאום בין שני חוטים (threads). מה יהיה הפלט של התוכנית בהנחה שכל קריאות המערכת מצליחות והחוטים מסיימים את ריצתם כסדרם?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n\nsem_t s1, s2;\nint count = 0;\n\nvoid* threadA(void* arg) {\n    for(int i = 0; i < 2; i++) {\n        sem_wait(&s1);\n        printf(\"A\");\n        count++;\n        sem_post(&s2);\n    }\n    return NULL;\n}\n\nvoid* threadB(void* arg) {\n    for(int i = 0; i < 2; i++) {\n        sem_wait(&s2);\n        printf(\"B\");\n        count++;\n        sem_post(&s1);\n    }\n    return NULL;\n}\n\nint main() {\n    sem_init(&s1, 0, 1);\n    sem_init(&s2, 0, 0);\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, threadA, NULL);\n    pthread_create(&t2, NULL, threadB, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"%d\", count);\n    return 0;\n}", "options": ["א. ABAB4", "ב. BABA4", "ג. AABB4", "ד. התוכנית תיכנס למצב של Deadlock", "ה. ABAB2"]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "הסמפור s1 מאותחל ל-1 והסמפור s2 מאותחל ל-0. חוט A הוא היחיד שיכול להתחיל את הלולאה שלו כי sem_wait(&s1) יצליח מיד. חוט A מדפיס 'A', מעלה את count ל-1, ומבצע sem_post(&s2). כעת הערך של s2 הוא 1, מה שמאפשר לחוט B לבצע sem_wait(&s2), להדפיס 'B', להעלות את count ל-2 ולבצע sem_post(&s1). הסמפורים יוצרים סנכרון מסוג 'פינג-פונג' בין החוטים. מכיוון שכל חוט רץ פעמיים, הפלט יהיה ABAB והערך הסופי של count יהיה 4."}, "difficulty_estimation": "Medium", "_source_file": "0204__Synchronization__CodeAnalysis__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:00:02", "_subject": "Concurrency"}, {"id": 7, "type": "CodeAnalysis", "topic": ["Synchronization", "Threads", "Deadlock"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בספריות `pthread` ו-`stdio`. התוכנית מיועדת לסכם ערכים משותפים באמצעות מספר תהליכונים.\nמה יהיה הערך הסופי של המשתנה `shared_counter` שהודפס על ידי התוכנית, או מה יקרה לתוכנית? (שים לב: `pthread_mutex_t` הוא בדרך כלל mutex לא רקורסיבי, אלא אם צוין אחרת במפורש).", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // לצרכי הדגמה של הקשר, אך לא קריטי לבעיה זו\n\n#define NUM_THREADS 3\n#define NUM_ITERATIONS 1000\n\nlong long shared_counter = 0;\npthread_mutex_t mutex;\n\nvoid* thread_function(void* arg) {\n    for (int i = 0; i < NUM_ITERATIONS; ++i) {\n        pthread_mutex_lock(&mutex);\n        shared_counter++;\n    }\n    pthread_mutex_unlock(&mutex); // שחרור ה-mutex מתבצע מחוץ ללולאה\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    pthread_mutex_init(&mutex, NULL);\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_function, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(&threads[i], NULL);\n    }\n\n    pthread_mutex_destroy(&mutex);\n\n    printf(\"Final shared_counter: %lld\\n\", shared_counter);\n    return 0;\n}", "options": ["א. 0", "ב. 3000", "ג. ערך כלשהו בין 0 ל-3000 (כולל)", "ד. התוכנית תיתקע (Deadlock)", "ה. התוכנית תקרוס (Segmentation Fault)"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "התוכנית תיכנס למצב של Deadlock.\n\n`pthread_mutex_t` כברירת מחדל הוא mutex מסוג `PTHREAD_MUTEX_NORMAL` (לא רקורסיבי). המשמעות היא שתהליכון שמנסה לנעול mutex שכבר נמצא בבעלותו (כלומר, הוא כבר ביצע `pthread_mutex_lock` עליו ולא שחרר אותו עדיין) ייכנס למצב של Deadlock עצמי (self-deadlock).\n\nבפונקציה `thread_function`, כל תהליכון מבצע לולאה `NUM_ITERATIONS` פעמים. בתוך הלולאה, הוא קורא ל-`pthread_mutex_lock(&mutex)`.\n\nבאיטרציה הראשונה של הלולאה (כאשר `i=0`), התהליכון ינעל בהצלחה את ה-mutex.\nבאיטרציה השנייה של הלולאה (כאשר `i=1`), אותו תהליכון ינסה שוב לנעול את אותו ה-mutex. מכיוון שהוא כבר מחזיק ב-mutex והוא מסוג `PTHREAD_MUTEX_NORMAL`, ניסיון נעילה זה ייחסם, והתהליכון ייכנס למצב של Deadlock עצמי. הוא לא יוכל להמשיך לנעול את ה-mutex או לשחרר אותו, מכיוון ששחרור ה-mutex מתבצע רק מחוץ ללולאה.\n\nכל אחד מ-`NUM_THREADS` התהליכונים יגיע למצב Deadlock זה באופן עצמאי. לכן, התוכנית לעולם לא תגיע לשלב שבו היא מדפיסה את הערך הסופי של `shared_counter`, מכיוון שכל התהליכונים ייתקעו בניסיונם השני לנעול את ה-mutex. התוכנית תיתקע ולא תסיים את ריצתה באופן תקין.\n\nהפלט הצפוי הוא שהתוכנית לא תסיים את ריצתה ותיתקע (Deadlock)."}, "difficulty_estimation": "Medium", "_source_file": "0205__Synchronization__CodeAnalysis__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:01:27", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Synchronization", "Threads", "Race Conditions"], "content": {"text": "נתונה התוכנית הבאה, המשתמשת ב-pthreads וב-mutex. יש להניח שכל הקריאות ל-pthread הצליחו.\n\nמהו הערך הסופי של `shared_val` שיודפס על ידי התוכנית? האם הפלט של השורות המודפסות בתוך הפונקציה `worker` (כלומר, 'Thread %ld: shared_val = %d') יהיה דטרמיניסטי? נמק את תשובתך באופן מלא.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n\n#define NUM_THREADS 3\n#define INCREMENTS_PER_THREAD 5\n\nint shared_val = 0;\npthread_mutex_t my_mutex;\n\nvoid* worker(void* arg) {\n    long thread_id = (long)arg;\n\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&my_mutex);\n        shared_val++;\n        pthread_mutex_unlock(&my_mutex);\n        \n        // The printf statement is outside the mutex lock\n        printf(\"Thread %ld: shared_val = %d\\n\", thread_id, shared_val);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    pthread_mutex_init(&my_mutex, NULL);\n\n    for (long i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, worker, (void*)i);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final shared_val: %d\\n\", shared_val);\n    pthread_mutex_destroy(&my_mutex);\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסבר:\n\n1.  **ערך סופי של `shared_val`:**\n    הערך הסופי של `shared_val` שיודפס על ידי התוכנית יהיה **15**.\n    *   ישנם 3 תהליכונים (`NUM_THREADS = 3`).\n    *   כל תהליכון מבצע 5 הגדלות (`INCREMENTS_PER_THREAD = 5`).\n    *   סה\"כ הגדלות אמורות להיות: 3 * 5 = 15.\n    *   פעולת ההגדלה `shared_val++` מוגנת על ידי mutex (באמצעות `pthread_mutex_lock` ו-`pthread_mutex_unlock`). זה מבטיח שכל הגדלה בודדת היא אטומית, ומונע תנאי מרוץ על עדכון המונה עצמו. לכן, כל ההגדלות מבוצעות כראוי והערך הסופי של `shared_val` יהיה מדויק ונכון.\n\n2.  **דטרמיניזם של הפלט בתוך הפונקציה `worker`:**\n    הפלט של השורות המודפסות בתוך הפונקציה `worker` (`printf(\"Thread %ld: shared_val = %d\\n\", thread_id, shared_val);`) **לא יהיה דטרמיניסטי**.\n    *   הקריאה ל-`pthread_mutex_unlock(&my_mutex);` מתרחשת *לפני* הקריאה ל-`printf`.\n    *   משמעות הדבר היא שברגע שתהליכון מסיים להגדיל את `shared_val` ומשחרר את ה-mutex, תהליכון אחר יכול מיד לרכוש את ה-mutex, להגדיל את `shared_val` שוב, ולשחרר אותו. \n    *   בזמן שהתהליכון הראשון ממשיך לשורת ה-`printf` שלו, הערך של `shared_val` עשוי כבר להיות גבוה יותר מכיוון שתהליכונים אחרים הספיקו לעדכן אותו. לכן, הערך של `shared_val` שיודפס בכל שורת `printf` בתוך ה-`worker` יהיה תלוי בסדר הריצה הספציפי של התהליכונים.\n    *   בנוסף, סדר ההדפסה בין התהליכונים אינו מובטח, מה שתורם לאי-דטרמיניסטיות של הפלט הכולל. אין שום מנגנון סנכרון המבטיח ששורת `printf` תופעל מיד לאחר שחרור ה-mutex, או ששני תהליכונים לא ינסו להדפיס בו זמנית, מה שעלול לערבב את הפלט."}, "difficulty_estimation": "Medium", "_source_file": "0206__Synchronization__CodeAnalysis__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:01:48", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Threads"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בסמפורים (Semaphores) לסנכרון בין שני תהליכונים. הניחו שכל הקריאות ל-pthread_create ו-sem_init מצליחות. מה יהיה הפלט של התוכנית?", "code_snippet": "sem_t sem1, sem2;\nint counter = 0;\n\nvoid* threadA(void* arg) {\n    for (int i = 0; i < 5; i++) {\n        sem_wait(&sem1);\n        counter++;\n        printf(\"A%d \", counter);\n        sem_post(&sem2);\n    }\n    return NULL;\n}\n\nvoid* threadB(void* arg) {\n    for (int i = 0; i < 5; i++) {\n        sem_wait(&sem2);\n        counter++;\n        printf(\"B%d \", counter);\n        sem_post(&sem1);\n    }\n    return NULL;\n}\n\nint main() {\n    sem_init(&sem1, 0, 1);\n    sem_init(&sem2, 0, 0);\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, threadA, NULL);\n    pthread_create(&t2, NULL, threadB, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    return 0;\n}", "options": ["א. A1 B2 A3 B4 A5 B6 A7 B8 A9 B10", "ב. A1 A2 A3 A4 A5 B1 B2 B3 B4 B5", "ג. התוכנית תבצע הדפסה אחת ותיכנס למבוי סתום (Deadlock).", "ד. B1 A2 B3 A4 B5 A6 B7 A8 B9 A10", "ה. הפלט אינו דטרמיניסטי ותלוי בסדר הרצת התהליכונים על ידי המעבד."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "הסמפור sem1 מאותחל ל-1, מה שמאפשר לתהליכון A להיכנס לקטע הקריטי ראשון. הסמפור sem2 מאותחל ל-0, ולכן תהליכון B ייחסם בשורה sem_wait(&sem2) עד ש-A יבצע post ל-sem2. לאחר ש-A מעלה את המונה ל-1 ומדפיס 'A1 ', הוא מבצע post ל-sem2 שמשחרר את תהליכון B. כעת B מעלה את המונה ל-2, מדפיס 'B2 ' ומשחרר את A חזרה על ידי post ל-sem1. המבנה הזה יוצר סדר ריצה דטרמיניסטי שבו התהליכונים רצים לסירוגין, ולכן המונה גדל ב-1 בכל הדפסה והאותיות מתחלפות."}, "difficulty_estimation": "Medium", "_source_file": "0207__Synchronization__CodeAnalysis__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 19:00:24", "_subject": "Concurrency"}, {"id": 7, "type": "CodeAnalysis", "topic": ["Synchronization", "Deadlock", "Threads"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בתהליכונים (threads) ובמנעולים (mutexes). עיין בקוד וקבע האם ייתכן מצב של קיפאון (deadlock) במהלך ריצת התוכנית. נמק את תשובתך.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutexA;\npthread_mutex_t mutexB;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to lock mutexA...\\n\");\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 1: Locked mutexA. Trying to lock mutexB...\\n\");\n    sleep(1); // Simulate work or context switch opportunity\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 1: Locked mutexB. Doing work...\\n\");\n    // Critical section\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 1: Unlocked mutexB.\\n\");\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 1: Unlocked mutexA. Exiting.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to lock mutexB...\\n\");\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 2: Locked mutexB. Trying to lock mutexA...\\n\");\n    sleep(1); // Simulate work or context switch opportunity\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 2: Locked mutexA. Doing work...\\n\");\n    // Critical section\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 2: Unlocked mutexA.\\n\");\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 2: Unlocked mutexB. Exiting.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&mutexA, NULL);\n    pthread_mutex_init(&mutexB, NULL);\n\n    printf(\"Main: Creating threads...\\n\");\n    pthread_create(&tid1, NULL, thread_func1, NULL);\n    pthread_create(&tid2, NULL, thread_func2, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    pthread_mutex_destroy(&mutexA);\n    pthread_mutex_destroy(&mutexB);\n\n    printf(\"Main: All threads finished. Exiting.\\n\");\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, ייתכן מצב של קיפאון (deadlock) בתוכנית זו.\n\nהקיפאון יכול להתרחש בתרחיש הבא:\n1.  תהליכון 1 (thread_func1) רוכש את `mutexA`.\n2.  תהליכון 2 (thread_func2) רוכש את `mutexB`.\n3.  כעת, תהליכון 1 מנסה לרכוש את `mutexB` (שכבר מוחזק על ידי תהליכון 2) ונחסם.\n4.  באותו זמן, תהליכון 2 מנסה לרכוש את `mutexA` (שכבר מוחזק על ידי תהליכון 1) ונחסם.\n\nבמצב זה, שני התהליכונים חסומים וכל אחד מהם ממתין למנעול שמוחזק על ידי השני. תנאי הקיפאון מתקיימים: החזקה והמתנה (Hold and Wait), מניעה הדדית (Mutual Exclusion), אין דריסה מוקדמת (No Preemption), והמתנה מעגלית (Circular Wait). הוספת ה-`sleep(1)` בתהליכונים מגדילה את הסיכוי להתרחשות מצב זה על ידי יצירת חלון זמן שבו הסדר הבעייתי יכול להתקיים, אך הוא אפשרי גם בלעדיו בשל חוסר סדר מובטח ברכישת המנעולים."}, "difficulty_estimation": "Medium", "_source_file": "0208__Synchronization__CodeAnalysis__Medium.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:02:02", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Barriers", "Race Conditions"], "content": {"text": "לפניכם קוד המממש מחסום (Barrier) עבור N חוטים (כאשר N > 1). המטרה היא להבטיח שכל N החוטים יסיימו את 'שלב א' (הקריאה ל-do_work_A) לפני שמישהו מהם יתחיל את 'שלב ב' (הקריאה ל-do_work_B). הקוד משתמש בטכניקה הנקראת Chained Signaling בתוך Turnstile כדי לאפשר לחוטים לעבור את המחסום בזה אחר זה. הניחו שכל קריאות המערכת מצליחות וכי do_work_A ו-do_work_B אינן כוללות סנכרון פנימי.", "code_snippet": "sem_t mutex;     // initialized to 1\nsem_t turnstile; // initialized to 0\nint count = 0;\n\nvoid barrier() {\n    // Arrival\n    sem_wait(&mutex);\n    count++;\n    if (count == N) {\n        sem_post(&turnstile);\n    }\n    sem_post(&mutex);\n\n    // The Turnstile\n    sem_wait(&turnstile);\n    sem_post(&turnstile);\n}\n\nvoid* worker(void* arg) {\n    while(1) {\n        do_work_A();\n        barrier();\n        do_work_B();\n        // Point X\n    }\n    return NULL;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "הסבירו מדוע באיטרציה הראשונה של הלולאה, המחסום ימלא את תפקידו וכל החוטים ימתינו זה לזה.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "האם המחסום הנתון הוא Reusable? כלומר, האם מובטח סנכרון תקין גם באיטרציה השנייה והלאה? אם כן - הסבירו מדוע. אם לא - תארו תרחיש (תזמון) שבו חוט מסוים מתחיל את 'שלב ב' של האיטרציה השנייה לפני שחוט אחר סיים את 'שלב א' של אותה איטרציה.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "מהו הערך של הסמפור turnstile כאשר חוט כלשהו נמצא ב-'Point X' באיטרציה הראשונה? כיצד ניתן לתקן את הפונקציה barrier כך שתהיה בטוחה לשימוש חוזר (Reusable) מבלי להשתמש בסמפורים נוספים?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: באיטרציה הראשונה, turnstile מאותחל ל-0. N-1 החוטים הראשונים שיגיעו ל-barrier יגדילו את count אך לא ייכנסו ל-if, ולכן ייחסמו ב-sem_wait בשורה 13. החוט ה-N שיגיע יגדיל את count ל-N, יבצע sem_post ל-turnstile בשורה 9, וישחרר את החוט הראשון. החוט שישתחרר יבצע מיד sem_post בשורה 14 וישחרר את הבא בתור, וכך הלאה (שרשרת). לכן כולם יעברו רק אחרי שהאחרון הגיע.\n\n10.2: המחסום אינו Reusable. הבעיה היא שערך הסמפור turnstile נשאר 1 לאחר שהחוט האחרון עובר (הוא מבצע post בשורה 14 שאיש לא צורך). תרחיש שבירה: חוט T1 מסיים את barrier באיטרציה 1, מסיים את do_work_B במהירות, חוזר לתחילת הלולאה, מסיים את do_work_A של איטרציה 2 ומגיע שוב ל-barrier. מכיוון ש-turnstile הוא 1, T1 יבצע sem_wait ויעבור מיד לשלב ב' של איטרציה 2, למרות שחוטים אחרים אולי עדיין תקועים בשלב ב' של איטרציה 1 או בתחילת איטרציה 2.\n\n10.3: ערך הסמפור turnstile בנקודה X הוא 1. כדי לתקן את המחסום ולהופכו ל-Reusable, יש להוסיף שלב שני (Two-phase barrier) שבו נועלים את ה-turnstile בחזרה. בשיטה זו, לאחר שכל החוטים עברו את ה-turnstile הראשון, הם צריכים להמתין ב-turnstile שני שייפתח רק כאשר כולם סיימו לעבור את הראשון, והחוט האחרון שיעבור את השני יאפס את ה-count וינעל את ה-turnstile (יבצע wait מבלי לבצע post)."}, "difficulty_estimation": "Hard", "_source_file": "0209__Synchronization__CodeAnalysis__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:01:07", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Synchronization", "Deadlock", "Condition Variables", "Mutexes"], "content": {"text": "נתונה תוכנית C המשתמשת בחוטים (threads) לסנכרון גישה למונה משותף `counter`. כל חוט מנסה לקדם את המונה מספר קבוע של פעמים (`INCREMENTS_PER_THREAD`). עם זאת, קיימת הגבלה: חוט יכול לקדם את המונה רק אם ערכו הנוכחי זוגי. אם המונה אי-זוגי, החוט חייב להמתין. לאחר קידום המונה, החוט מאותת לחוטים אחרים. יש לנתח את הקוד ולזהות בעיות סנכרון אפשריות.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <stdlib.h>\n\n#define NUM_THREADS 3\n#define INCREMENTS_PER_THREAD 2\n\nint counter = 0;\npthread_mutex_t mutex;\npthread_cond_t cond_even;\n\nvoid* worker(void* arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&mutex);\n\n        // Wait until counter is even\n        while (counter % 2 != 0) {\n            pthread_cond_wait(&cond_even, &mutex);\n        }\n\n        // Increment counter\n        counter++;\n\n        // Signal that counter has changed.\n        pthread_cond_signal(&cond_even); \n        pthread_mutex_unlock(&mutex);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    long i;\n\n    pthread_mutex_init(&mutex, NULL);\n    pthread_cond_init(&cond_even, NULL);\n\n    for (i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, worker, (void*)i);\n    }\n\n    for (i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    pthread_mutex_destroy(&mutex);\n    pthread_cond_destroy(&cond_even);\n\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "8.1", "text": "האם התוכנית הנתונה עלולה להיכנס למצב של קיפאון (deadlock) או רעב (starvation)? נמקו את תשובתכם והסבירו את התרחיש המוביל לבעיה. מה יהיה הערך הסופי של `counter` במקרה של בעיה?", "code_snippet": null, "options": null}, {"id": "8.2", "text": "תקנו את פונקציית `worker` כך שכל `NUM_THREADS * INCREMENTS_PER_THREAD` הקידומים יבוצעו באופן תקין וללא מצבי מרוץ או קיפאון, ושהתוכנית תסיים את ריצתה. אם תידרשו לשנות או להסיר את אילוץ הזוגיות המקורי כדי להשיג זאת, הסבירו מדוע ואיזה אילוץ חדש (אם בכלל) אתם אוכפים במקומו. ניתן להשתמש רק ב-mutexes ו-condition variables. רשמו את הקוד המתוקן של פונקציית `worker` בלבד.", "code_snippet": "void* worker(void* arg) {\n    // Write your corrected code here\n}", "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "8.1: כן, התוכנית עלולה להיכנס למצב של קיפאון (deadlock). המצב נוצר כדלקמן:\nהמונה `counter` מתחיל מערך 0 (זוגי). חוט כלשהו (נניח חוט A) רוכש את המנעול, בודק שהמונה זוגי (0 % 2 == 0), וממשיך לקדם אותו. המונה הופך ל-1 (אי-זוגי). לאחר מכן, חוט A קורא ל-`pthread_cond_signal(&cond_even)` ומשחרר את המנעול.\nכעת, המונה `counter` שווה ל-1 (אי-זוגי). כל החוטים האחרים, וגם חוט A עצמו בניסיונו הבא לקדם את המונה, ינסו לרכוש את המנעול. לאחר שיצליחו, הם יגיעו ללולאת ה-`while (counter % 2 != 0)`. מכיוון ש-`counter` הוא 1 (אי-זוגי), התנאי נכון, והם יקראו ל-`pthread_cond_wait(&cond_even, &mutex)`.\nהבעיה היא שפעולת הקידום `counter++` תמיד הופכת מספר זוגי לאי-זוגי. כלומר, ברגע שהמונה הופך ל-1, הוא לעולם לא יוכל לחזור להיות זוגי באמצעות פעולת `counter++` תחת האילוץ שרק כאשר הוא זוגי מותר לקדם אותו. אף חוט לא יוכל לקדם את המונה מעבר ל-1, מכיוון שהתנאי \"מונה זוגי\" לעולם לא יתקיים שוב.\nלכן, כל החוטים ימתינו על `cond_even` ללא תקווה שמישהו יאותת להם, והתוכנית תיכנס לקיפאון.\nהערך הסופי של `counter` יהיה 1.\n\n8.2: כדי לאפשר לכל הקידומים להסתיים, יש להסיר את אילוץ הזוגיות המקורי, מכיוון שהוא מוביל לקיפאון אינהרנטי עם פעולת `counter++`. אם נשמור על האילוץ, המונה לעולם לא יוכל לעבור את הערך 1.\nהאילוץ החדש שנוכף הוא פשוט סנכרון נכון של גישה למונה משותף, ללא תלות בזוגיות. המטרה היא להבטיח שכל חוט יקדם את המונה את מספר הפעמים הנדרש, ושהמונה יגיע לערך הסופי הנכון (`NUM_THREADS * INCREMENTS_PER_THREAD`), ללא מצבי מרוץ או קיפאון.\nבמקרה זה, משתנה התנאי `cond_even` אינו נחוץ עוד, שכן אין תנאי מורכב מעבר לגישה בלעדית למשאב. ניתן להשתמש ב-mutex בלבד. אם בכל זאת רוצים להשתמש ב-condition variable, אפשר לאותת על שינוי כלשהו, אך זה אינו הכרחי לתיקון הבעיה הספציפית הזו.\n\nקוד מתוקן (הסרת אילוץ הזוגיות ושימוש ב-mutex בלבד):\n\n```c\nvoid* worker(void* arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&mutex); // נעל את המונה לגישה בלעדית\n        counter++;                 // קדם את המונה\n        pthread_mutex_unlock(&mutex); // שחרר את המנעול\n    }\n    return NULL;\n}\n```\n\nאם נתעקש לשמור על השימוש ב-condition variable (לדוגמה, אם היה אילוץ מורכב יותר):\n```c\nvoid* worker(void* arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&mutex);\n        // אין צורך בלולאת while עם תנאי זוגיות, כי היא הגורם לקיפאון.\n        // אם היה תנאי לגיטימי אחר (למשל, \"מונה קטן מ-X\"), היינו משתמשים בו כאן.\n        counter++;\n        pthread_cond_signal(&cond_even); // מאותת שחל שינוי, למקרה שחוטים אחרים ממתינים לתנאי כלשהו\n        pthread_mutex_unlock(&mutex);\n    }\n    return NULL;\n}\n```\nהתיקון הראשון (שימוש ב-mutex בלבד) הוא הפתרון המינימלי והנכון ביותר לאפשר את השלמת כל הקידומים ללא תלות באילוץ הזוגיות. התיקון השני מראה איך ניתן להשתמש ב-condition variable גם אם התנאי הוסר, אך הוא מיותר במקרה זה."}, "difficulty_estimation": "Hard", "_source_file": "0210__Synchronization__CodeAnalysis__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:02:48", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Synchronization", "Concurrency", "Semaphores", "Reusable Barrier"], "content": {"text": "נתונה התוכנית הבאה המנסה לממש מחסום (Barrier) רב-פעמי. N_THREADS חוטים מקדמים מונה גלובלי משותף shared_counter N_INCREMENTS_PER_THREAD פעמים כל אחד. לאחר כל קידום של המונה, כל החוטים צריכים להגיע למחסום, ורק כאשר כולם הגיעו, הם משוחררים להמשיך לקידום הבא. בסיום התוכנית יודפס הערך הסופי של shared_counter. ניתן להניח שכל קריאות המערכת מצליחות.\n\n", "code_snippet": "1 #include <stdio.h>\n2 #include <pthread.h>\n3 #include <semaphore.h>\n4 #include <unistd.h>\n5\n6 #define N_THREADS 3 // מספר חוטים\n7 #define N_INCREMENTS_PER_THREAD 2 // כמה פעמים כל חוט יקדם את המונה בסך הכל\n8\n9 int shared_counter = 0;\n10 sem_t mutex; // להגנה על shared_counter ו-barrier_count\n11 sem_t barrier_sem; // לחסימת חוטים במחסום\n12 int barrier_count = 0; // מונה חוטים שהגיעו למחסום\n13\n14 void* thread_func(void* arg) {\n15    long tid = (long)arg;\n16\n17    for (int i = 0; i < N_INCREMENTS_PER_THREAD; ++i) {\n18        // --- Critical section for shared_counter ---\n19        sem_wait(&mutex);\n20        shared_counter++;\n21        printf(\"Thread %ld: incremented counter to %d\\n\", tid, shared_counter);\n22        sem_post(&mutex);\n23        // --- End critical section ---\n24\n25        // --- Barrier logic ---\n26        sem_wait(&mutex);\n27        barrier_count++;\n28        if (barrier_count == N_THREADS) {\n29            // Last thread to arrive, release all others\n30            printf(\"Thread %ld: ALL arrived at barrier. Releasing.\\n\", tid);\n31            for (int j = 0; j < N_THREADS; ++j) {\n32                sem_post(&barrier_sem);\n33            }\n34        }\n35        sem_post(&mutex);\n36\n37        sem_wait(&barrier_sem); // Wait for all threads to pass\n38\n39        // --- Post-barrier logic: Reset barrier_count ---\n40        sem_wait(&mutex);\n41        barrier_count--;\n42        if (barrier_count == 0) {\n43            // Last thread to leave resets for next cycle.\n44            // This is where the flaw lies for reusable barriers.\n45            printf(\"Thread %ld: ALL left barrier. Resetting for next cycle.\\n\", tid);\n46        }\n47        sem_post(&mutex);\n48        // --- End barrier logic ---\n49    }\n50    return NULL;\n51}\n52\n53 int main() {\n54    pthread_t threads[N_THREADS];\n55    sem_init(&mutex, 0, 1);\n56    sem_init(&barrier_sem, 0, 0); // Initially closed\n57\n58    for (long i = 0; i < N_THREADS; ++i) {\n59        pthread_create(&threads[i], NULL, thread_func, (void*)i);\n60    }\n61\n62    for (int i = 0; i < N_THREADS; ++i) {\n63        pthread_join(threads[i], NULL);\n64    }\n65\n66    printf(\"Final counter value: %d\\n\", shared_counter);\n67\n68    sem_destroy(&mutex);\n69    sem_destroy(&barrier_sem);\n70    return 0;\n71}"}, "sub_questions": [{"id": "10.1", "text": "הסבירו מדוע המימוש הנתון של המחסום הרב-פעמי אינו עובד בצורה נכונה ועלול להוביל לבעיות. הסבירו את הסיבה העיקרית לכשל זה.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "תארו תזמון ספציפי (לדוגמה, עבור N_THREADS=2 ו-N_INCREMENTS_PER_THREAD=2) שבו מתרחשת הבעיה שתוארה בסעיף הקודם. ציינו בבירור מהו הערך של shared_counter בכל שלב רלוונטי וכיצד הוא מושפע מהכשל במחסום. מהו הערך הסופי המקסימלי של shared_counter שיכול להתקבל במקרה זה?", "code_snippet": null, "options": null}, {"id": "10.3", "text": "תקנו את הפונקציה thread_func כך שהמחסום יעבוד בצורה נכונה ויהיה רב-פעמי. ניתן להוסיף סמפורים ומשתנים גלובליים כנדרש (יש לציין את ערכי האתחול בהערה).", "code_snippet": "void* thread_func(void* arg) {\n    long tid = (long)arg;\n\n    for (int i = 0; i < N_INCREMENTS_PER_THREAD; ++i) {\n        // Critical section for shared_counter\n        sem_wait(&mutex);\n        shared_counter++;\n        printf(\"Thread %ld: incremented counter to %d\\n\", tid, shared_counter);\n        sem_post(&mutex);\n\n        // Barrier logic (corrected)\n        // ... (your corrected code here)\n    }\n    return NULL;\n}", "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: המימוש הנתון של המחסום הרב-פעמי אינו נכון בגלל בעיית ה-'Turnstile' (קרוסלה) או 'Premature Release'. סמפור ה-`barrier_sem` מאותחל ל-0, ולאחר שכל N_THREADS החוטים מגיעים, החוט האחרון קורא ל-`sem_post(&barrier_sem)` N_THREADS פעמים. לאחר מכן, כל חוט קורא ל-`sem_wait(&barrier_sem)` פעם אחת. הבעיה היא שפעולות `sem_post` הן מצטברות. אם חוט מסוים מהיר מאוד, הוא עלול לסיים את מחזור המחסום הנוכחי (כלומר, לבצע את ה-`sem_wait` שלו, להקטין את `barrier_count` ל-0, ולחזור לתחילת הלולאה) ולבצע `sem_wait(&barrier_sem)` עבור האיטרציה הבאה, *לפני* שכל החוטים האחרים סיימו את ה-`sem_wait` שלהם עבור האיטרציה הנוכחית. הדבר מאפשר לחוט המהיר 'לגנוב' `sem_post` שנועד לחוט אחר או לאיטרציה הבאה, ובכך לעבור את המחסום בטרם עת, מבלי שכל החוטים האחרים הגיעו אליו, ומפר את תנאי הסנכרון של המחסום. הדבר עלול להוביל לחסימה (Deadlock) של חוטים אחרים שיחכו ל-`sem_post` שכבר נצרך, או להפרה של סדר הפעולות המתוכנן.\n\n10.2: נניח N_THREADS=2 ו-N_INCREMENTS_PER_THREAD=2. הערך הסופי המצופה של `shared_counter` הוא 4.\n\nתזמון שמוביל לבעיה:\n1.  חוט 0: מבצע `sem_wait(&mutex)`, מקדם `shared_counter` ל-1. מבצע `sem_post(&mutex)`.\n2.  חוט 1: מבצע `sem_wait(&mutex)`, מקדם `shared_counter` ל-2. מבצע `sem_post(&mutex)`.\n3.  חוט 0: מבצע `sem_wait(&mutex)`, מגדיל `barrier_count` ל-1. מבצע `sem_post(&mutex)`.\n4.  חוט 1: מבצע `sem_wait(&mutex)`, מגדיל `barrier_count` ל-2. מכיוון ש-`barrier_count == N_THREADS`, חוט 1 מבצע `sem_post(&barrier_sem)` פעמיים. (ערך `barrier_sem` הופך ל-2). מבצע `sem_post(&mutex)`.\n5.  חוט 0: מבצע `sem_wait(&barrier_sem)`. (ערך `barrier_sem` הופך ל-1). חוט 0 עובר את המחסום. הוא מבצע `sem_wait(&mutex)`, מקטין `barrier_count` ל-1. מבצע `sem_post(&mutex)`.\n6.  **נקודת הכשל**: חוט 0, בהיותו מהיר מאוד, מיד ממשיך לאיטרציה השנייה שלו. הוא מבצע `sem_wait(&mutex)`, מקדם `shared_counter` ל-3. מבצע `sem_post(&mutex)`.\n7.  חוט 0: נכנס שוב ללוגיקת המחסום: מבצע `sem_wait(&mutex)`, מגדיל `barrier_count` ל-2. מכיוון ש-`barrier_count == N_THREADS`, חוט 0 מבצע `sem_post(&barrier_sem)` פעמיים. (ערך `barrier_sem` הופך ל-1 (מה-sem_post שחוט 1 עשה וטרם נצרך) + 2 (מחוט 0) = 3). מבצע `sem_post(&mutex)`.\n8.  חוט 0: מבצע `sem_wait(&barrier_sem)`. (ערך `barrier_sem` הופך ל-2). חוט 0 עובר את המחסום בפעם השנייה.\n9.  בנקודה זו, `shared_counter` הוא 3. חוט 0 סיים את כל פעולות הקידום שלו ועבר את המחסום פעמיים. חוט 1 עדיין לא סיים את האיטרציה הראשונה שלו (הוא תקוע ב-`sem_wait(&barrier_sem)` או בדיוק עבר אותו). כלומר, חוט 0 עבר את המחסום השני לפני שחוט 1 בכלל הגיע למחסום הראשון בפעם השנייה. זה מפר את תנאי המחסום.\n10. חוט 1: לבסוף מבצע `sem_wait(&barrier_sem)`. (ערך `barrier_sem` הופך ל-1). חוט 1 עובר את המחסום. הוא מבצע `sem_wait(&mutex)`, מקטין `barrier_count` ל-0. מבצע `sem_post(&mutex)`.\n11. חוט 1: ממשיך לאיטרציה השנייה שלו. מבצע `sem_wait(&mutex)`, מקדם `shared_counter` ל-4. מבצע `sem_post(&mutex)`.\n12. חוט 1: נכנס ללוגיקת המחסום: מבצע `sem_wait(&mutex)`, מגדיל `barrier_count` ל-1. מבצע `sem_post(&mutex)`.\n13. חוט 1: מבצע `sem_wait(&barrier_sem)`. (ערך `barrier_sem` הופך ל-0). חוט 1 עובר את המחסום. הוא מבצע `sem_wait(&mutex)`, מקטין `barrier_count` ל-0. מבצע `sem_post(&mutex)`.\n\nבמקרה זה, `shared_counter` יגיע ל-4. עם זאת, ייתכן תזמון שבו חוט 1 ייתקע ב-`sem_wait(&barrier_sem)` מכיוון שחוט 0 'גנב' את ה-`sem_post` שנועד לו, מה שיוביל ל-`shared_counter` סופי של 3 (אם חוט 0 מסיים את שתי האיטרציות וחוט 1 נתקע אחרי הקידום הראשון שלו). הערך הסופי המקסימלי של `shared_counter` שעלול להתקבל במקרה של חסימה חלקית הוא `N_THREADS * N_INCREMENTS_PER_THREAD - (מספר החוטים שנתקעו * מספר הקידומים שנותרו להם)`. במקרה של תזמון כשל חמור שבו חוט אחד מסיים את כל הקידומים שלו וחוט אחר נתקע לאחר הקידום הראשון, הערך המקסימלי הוא `(N_INCREMENTS_PER_THREAD * (N_THREADS - 1)) + N_INCREMENTS_PER_THREAD = N_THREADS * N_INCREMENTS_PER_THREAD`. אך אם חוט אחד יכול לעבור את המחסום מספר פעמים מבלי שכולם הגיעו, הדבר עלול לגרום לחוטים אחרים להיתקע. למשל, אם חוט 0 מבצע את כל N_INCREMENTS_PER_THREAD הקידומים שלו וכל המעברים במחסום, וחוט 1 נתקע אחרי הקידום הראשון שלו, אז הערך הסופי יהיה `N_INCREMENTS_PER_THREAD + 1`. לדוגמה, עבור N_THREADS=2 ו-N_INCREMENTS_PER_THREAD=2, הערך המקסימלי שעלול להתקבל הוא 3 (אם חוט 0 מסיים את שתי האיטרציות וחוט 1 נתקע לאחר הקידום הראשון). אם התוכנית הייתה מתרחשת ללא חסימה, הערך הנכון הוא 4.\n\n10.3: תיקון המימוש באמצעות 'Double Turnstile' (קרוסלה כפולה) עם שני סמפורים:\n\nגלובליים (יש לציין ערכי אתחול בהערה):\nsem_t mutex; // Initialized: 1\nsem_t turnstile1; // Initialized: 0\nsem_t turnstile2; // Initialized: 0\nint barrier_count = 0; // Initialized: 0\n\n```c\nvoid* thread_func(void* arg) {\n    long tid = (long)arg;\n\n    for (int i = 0; i < N_INCREMENTS_PER_THREAD; ++i) {\n        // Critical section for shared_counter\n        sem_wait(&mutex);\n        shared_counter++;\n        printf(\"Thread %ld: incremented counter to %d\\n\", tid, shared_counter);\n        sem_post(&mutex);\n\n        // Barrier logic (corrected - Phase 1: All threads arrive at turnstile1)\n        sem_wait(&mutex);\n        barrier_count++;\n        if (barrier_count == N_THREADS) {\n            // Last thread to arrive at turnstile1, open it for all\n            for (int j = 0; j < N_THREADS; ++j) {\n                sem_post(&turnstile1);\n            }\n        }\n        sem_post(&mutex);\n\n        sem_wait(&turnstile1); // Wait for all threads to pass turnstile1\n        // All threads are now past turnstile1\n\n        // Barrier logic (corrected - Phase 2: All threads leave turnstile1 and prepare for next cycle)\n        sem_wait(&mutex);\n        barrier_count--;\n        if (barrier_count == 0) {\n            // Last thread to leave turnstile1, open turnstile2 for all\n            for (int j = 0; j < N_THREADS; ++j) {\n                sem_post(&turnstile2);\n            }\n        }\n        sem_post(&mutex);\n\n        sem_wait(&turnstile2); // Wait for all threads to pass turnstile2 (ensures all left previous phase)\n        // All threads are now past turnstile2, ready for next iteration\n    }\n    return NULL;\n}\n```\n\nבפונקציית `main` יש לשנות את אתחול הסמפורים:\n```c\n// ...\nsem_init(&mutex, 0, 1);\nsem_init(&turnstile1, 0, 0); // סמפור ראשון, סגור בהתחלה\nsem_init(&turnstile2, 0, 0); // סמפור שני, סגור בהתחלה\n// ...\n// יש לשנות את קריאת ה-pthread_create ל-thread_func_corrected אם משנים את שם הפונקציה\n// ...\nsem_destroy(&turnstile1);\nsem_destroy(&turnstile2);\n// ...\n```"}, "difficulty_estimation": "Hard", "_source_file": "0211__Synchronization__CodeAnalysis__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:04:03", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Starvation", "Race Conditions"], "content": {"text": "לפניכם מימוש מוצע למנגנון Read-Write Lock המשתמש בסמפורים. המנגנון נועד לאפשר למספר קוראים (Readers) לקרוא מהמשאב בו-זמנית, אך להבטיח בלעדיות לכותב (Writer) יחיד. הנחו כי כל הסמפורים מאותחלים כראוי (mutex=1, writeBlock=1) וכי המשתנה readersCount מאותחל ל-0.", "code_snippet": "1  sem_t mutex;\n2  sem_t writeBlock;\n3  int readersCount = 0;\n4\n5  void startRead() {\n6    sem_wait(&mutex);\n7    readersCount++;\n8    if (readersCount == 1)\n9      sem_wait(&writeBlock);\n10   sem_post(&mutex);\n11 }\n12\n13 void endRead() {\n14   sem_wait(&mutex);\n15   readersCount--;\n16   if (readersCount == 0)\n17     sem_post(&writeBlock);\n18   sem_post(&mutex);\n19 }\n20\n21 void startWrite() {\n22   sem_wait(&writeBlock);\n23 }\n24\n25 void endWrite() {\n26   sem_post(&writeBlock);\n27 }", "options": null}, "sub_questions": [{"id": "1.1", "text": "האם המימוש הנוכחי עלול לגרום להרעבה (Starvation)? אם כן, של אילו חוטים (קוראים או כותבים) ובאילו תנאים?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "נניח שקיימים שלושה חוטים: R1, R2 (קוראים) ו-W1 (כותב). הציגו סדר פעולות (Interleaving) שבו W1 מגיע בזמן ש-R1 נמצא בקטע הקריטי, אך R2 מצליח להיכנס לקטע הקריטי לפני ש-W1 מתחיל לכתוב.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "מה יקרה אם נעביר את שורה 15 (הורדת המונה) אל מחוץ לבלוק הסנכרון, כלומר מיד אחרי שורה 18? הסבירו את ההשלכה על תקינות הקוד.", "code_snippet": null, "options": null}, {"id": "1.4", "text": "כדי למנוע הרעבת כותבים, מוצע להוסיף סמפור נוסף בשם readTry המאותחל ל-1. היכן יש להוסיף את הקריאות ל-sem_wait ו-sem_post של סמפור זה בפונקציות startRead ו-startWrite?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: המימוש עלול לגרום להרעבת כותבים (Writers). אם יש זרם קבוע של קוראים שנכנסים לקטע הקריטי (startRead) לפני שהקורא האחרון מסיים (endRead), המשתנה readersCount לעולם לא יגיע ל-0, ולכן הסמפור writeBlock לא ישוחרר לעולם עבור הכותב.\n\n1.2: תרחיש אפשרי: \nא. R1 מבצע startRead, נועל את mutex, מקדם ל-1, נועל את writeBlock ומשחרר את mutex.\nב. W1 מבצע startWrite ונעצר (blocked) ב-sem_wait על writeBlock.\nג. R2 מבצע startRead, נועל את mutex, מקדם ל-2. מכיוון ש-2 != 1, הוא מדלג על ה-wait ומשחרר את mutex.\nד. R2 נכנס לקטע הקריטי בזמן ש-W1 עדיין ממתין.\n\n1.3: העברת readersCount-- אל מחוץ ל-mutex תיצור מצב מרוץ (Race Condition). אם שני חוטים יבצעו endRead במקביל, הפעולה האריתמטית (שאינה אטומית) עלולה להסתיים בערך שגוי. בנוסף, הבדיקה if (readersCount == 0) עלולה להתבצע על ערך לא מעודכן, מה שיוביל לכך ש-writeBlock לא ישוחרר לעולם (Deadlock לכותבים) או ישוחרר פעמיים.\n\n1.4: הפתרון למניעת הרעבת כותבים:\nב-startRead: יש להוסיף sem_wait(&readTry) בשורה 5.5 (לפני ה-mutex) ו-sem_post(&readTry) בשורה 10.5 (אחרי שחרור ה-mutex).\nב-startWrite: יש להוסיף sem_wait(&readTry) לפני ה-wait על writeBlock, ו-sem_post(&readTry) מיד לאחר מכן (או בסוף הכתיבה). \nבצורה זו, כותב שמגיע יתפוס את readTry וימנע מקוראים חדשים להיכנס עד שיסיים."}, "difficulty_estimation": "Hard", "_source_file": "0212__Synchronization__CodeAnalysis__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 19:01:41", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Synchronization", "Threads", "Condition Variables", "Deadlock", "Starvation"], "content": {"text": "נתונה התוכנית הבאה, המנהלת מונה משותף `counter` בין מספר סוגי חוטים. המונה מאותחל ל-0. ישנם שלושה סוגים של חוטים:\n*   **Incrementer**: מגדיל את המונה ב-1.\n*   **Decrementer**: מקטין את המונה ב-1.\n*   **Monitor**: מדפיס את ערך המונה.\n\nהתוכנית מנסה ליישם את דרישות הסנכרון הבאות:\n1.  **מניעת ירידה מתחת לאפס**: המונה `counter` לעולם לא יירד מתחת ל-0. חוט Decrementer שמנסה להקטין את המונה כשהוא 0, ימתין.\n2.  **צפייה רק בערכים זוגיים**: חוט Monitor ידפיס את ערך המונה רק אם הוא זוגי. אם המונה אי-זוגי, הוא ימתין.\n3.  **מניעת הרעבה למקטינים (Decrementers)**: אם המונה הוא 0 וישנם חוטי Decrementer שממתינים, חוטי Incrementer צריכים להיחסם באופן זמני עד שהמונה יהפוך לחיובי ולפחות חוט Decrementer אחד יוכל לרוץ.\n\nענו על השאלות הבאות בהתבסס על הקוד הנתון. יש להניח שכל קריאות המערכת הצליחו.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // for sleep\n\n#define NUM_INCREMENTERS 2\n#define NUM_DECREMENTERS 2\n#define NUM_MONITORS 1\n#define ITERATIONS 5\n\nint counter = 0;\npthread_mutex_t mutex;\npthread_cond_t can_decrement; // For decrementers to wait if counter is 0\npthread_cond_t counter_is_even; // For monitors to wait if counter is odd\n\n// To handle starvation for decrementers\nint waiting_decrementers = 0; // Number of decrementers waiting\npthread_cond_t incrementers_block; // For incrementers to wait if decrementers are starving\n\nvoid* incrementer_thread(void* arg) {\n    for (int i = 0; i < ITERATIONS; ++i) {\n        pthread_mutex_lock(&mutex);\n        // FLAW related to starvation avoidance for decrementers.\n        // If there are waiting decrementers and counter is 0, incrementers should wait.\n        // But what if counter is > 0 and decrementers are waiting? They should run first.\n        while (waiting_decrementers > 0 && counter == 0) {\n            printf(\"Incrementer: Waiting due to starving decrementers. Counter: %d\\n\", counter);\n            pthread_cond_wait(&incrementers_block, &mutex);\n        }\n\n        counter++;\n        printf(\"Incrementer: Counter is now %d\\n\", counter);\n        \n        // Signal decrementers if counter became positive\n        pthread_cond_signal(&can_decrement); \n\n        // Signal monitors if counter became even\n        if (counter % 2 == 0) {\n            pthread_cond_broadcast(&counter_is_even);\n        }\n        pthread_mutex_unlock(&mutex);\n        usleep(50000); // Simulate work\n    }\n    return NULL;\n}\n\nvoid* decrementer_thread(void* arg) {\n    for (int i = 0; i < ITERATIONS; ++i) {\n        pthread_mutex_lock(&mutex);\n        waiting_decrementers++; \n\n        while (counter == 0) {\n            printf(\"Decrementer: Waiting, counter is %d\\n\", counter);\n            // Signal incrementers that we are waiting.\n            pthread_cond_signal(&incrementers_block); \n            pthread_cond_wait(&can_decrement, &mutex);\n        }\n        waiting_decrementers--; \n\n        counter--;\n        printf(\"Decrementer: Counter is now %d\\n\", counter);\n\n        // Signal monitors if counter became even (or odd, which means they might need to wait again)\n        if (counter % 2 == 0) {\n            pthread_cond_broadcast(&counter_is_even);\n        }\n        // If decrementer allowed an incrementer to run, signal it.\n        if (waiting_decrementers == 0) { \n            pthread_cond_signal(&incrementers_block);\n        }\n        pthread_mutex_unlock(&mutex);\n        usleep(70000); // Simulate work\n    }\n    return NULL;\n}\n\nvoid* monitor_thread(void* arg) {\n    for (int i = 0; i < (NUM_INCREMENTERS + NUM_DECREMENTERS) * ITERATIONS / 2 + 1; ++i) { // Run for a bit longer\n        pthread_mutex_lock(&mutex);\n        while (counter % 2 != 0) {\n            printf(\"Monitor: Waiting, counter is %d (odd)\\n\", counter);\n            pthread_cond_wait(&counter_is_even, &mutex);\n        }\n        printf(\"Monitor: Current counter is %d (even)\\n\", counter);\n        pthread_mutex_unlock(&mutex);\n        usleep(100000); // Simulate work\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t incrementers[NUM_INCREMENTERS];\n    pthread_t decrementers[NUM_DECREMENTERS];\n    pthread_t monitors[NUM_MONITORS];\n\n    pthread_mutex_init(&mutex, NULL);\n    pthread_cond_init(&can_decrement, NULL);\n    pthread_cond_init(&counter_is_even, NULL);\n    pthread_cond_init(&incrementers_block, NULL);\n\n    for (int i = 0; i < NUM_INCREMENTERS; ++i) {\n        pthread_create(&incrementers[i], NULL, incrementer_thread, NULL);\n    }\n    for (int i = 0; i < NUM_DECREMENTERS; ++i) {\n        pthread_create(&decrementers[i], NULL, decrementer_thread, NULL);\n    }\n    for (int i = 0; i < NUM_MONITORS; ++i) {\n        pthread_create(&monitors[i], NULL, monitor_thread, NULL);\n    }\n\n    for (int i = 0; i < NUM_INCREMENTERS; ++i) {\n        pthread_join(incrementers[i], NULL);\n    }\n    for (int i = 0; i < NUM_DECREMENTERS; ++i) {\n        pthread_join(decrementers[i], NULL);\n    }\n    pthread_join(monitors[0], NULL); // Join monitors[0] assuming only one monitor\n\n    pthread_mutex_destroy(&mutex);\n    pthread_cond_destroy(&can_decrement);\n    pthread_cond_destroy(&counter_is_even);\n    pthread_cond_destroy(&incrementers_block);\n\n    printf(\"Final counter: %d\\n\", counter);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "זהו את כל בעיות הסנכרון (מצבי מרוץ, קיפאון, הרעבה, או התנהגות שגויה לפי הדרישות) בקוד הנתון. עבור כל בעיה, הסבירו מדוע היא מתרחשת ומהן השלכותיה.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "כתבו גרסה מתוקנת לפונקציה `incrementer_thread` אשר פותרת את כל הבעיות שזוהו בסעיף 1.1 הנוגעות להתנהגותה. ניתן להוסיף משתנים גלובליים ואובייקטי סנכרון במידת הצורך (יש לציין את ערכי האתחול בהערה).", "code_snippet": "void* incrementer_thread(void* arg) {\n    // הקוד המתוקן יבוא כאן\n}", "options": null}, {"id": "1.3", "text": "כתבו גרסה מתוקנת לפונקציה `decrementer_thread` אשר פותרת את כל הבעיות שזוהו בסעיף 1.1 הנוגעות להתנהגותה. ניתן להוסיף משתנים גלובליים ואובייקטי סנכרון במידת הצורך (יש לציין את ערכי האתחול בהערה).", "code_snippet": "void* decrementer_thread(void* arg) {\n    // הקוד המתוקן יבוא כאן\n}", "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1.1. **הרעבת מקטינים (Decrementers) בגלל `pthread_cond_signal` במקום `pthread_cond_broadcast`:**\n    *   **הבעיה**: בפונקציה `incrementer_thread`, נעשה שימוש ב-`pthread_cond_signal(&can_decrement)`. אם מספר חוטי Decrementer ממתינים כשהמונה הוא 0, וחוט Incrementer אחד מגדיל את המונה (למשל ל-1), רק חוט Decrementer אחד יתעורר. אם מספר חוטי Decrementer יכולים כעת לרוץ (לדוגמה, המונה הוגדל ל-2 וכל Decrementer מקטין ב-1), שאר חוטי ה-Decrementer יישארו רדומים ויסבלו מהרעבה, גם אם התנאי עבורם התקיים.\n    *   **השלכות**: הרעבה של חוטי Decrementer, שאינם מתעוררים לטפל במונה גם כאשר הוא חיובי ומאפשר זאת.\n\n1.1.2. **לוגיקה שגויה ופוטנציאל לקיפאון (Deadlock) או הרעבה בטיפול במניעת הרעבת מקטינים (דרישה 3):**\n    *   **הבעיה 1 (ב-`decrementer_thread`):** המשתנה `waiting_decrementers` מוגדל לפני הכניסה ללולאת ה-`while` ובאופן כללי לפני שהחוט אכן ממתין. הוא מוקטן רק אחרי היציאה מהלולאה ולפני ההקטנה בפועל. מצב זה יכול להוביל לכך ש-`waiting_decrementers` יכיל ערך שגוי של חוטים שממתינים בפועל. בנוסף, `pthread_cond_signal(&incrementers_block)` נקרא כשהחוט נכנס למצב המתנה, אך זהו `signal` ולא `broadcast`, כך שאם מספר Incrementers ממתינים, רק אחד מהם יתעורר. יתרה מכך, האיתות הזה יכול להיות מוקדם מדי או מאוחר מדי.\n    *   **הבעיה 2 (ב-`decrementer_thread`):** התנאי `if (waiting_decrementers == 0)` שבו נקרא `pthread_cond_signal(&incrementers_block)` בסוף הפונקציה הוא שגוי. חוט Incrementer צריך להיות מסוגל לרוץ לא רק כאשר אין יותר Decrementers ממתינים, אלא גם כאשר המונה חיובי (גם אם יש Decrementers ממתינים, כי הם ממתינים רק אם המונה 0). לוגיקת האיתות כאן לא מכסה את כל המקרים שבהם Incrementers יכולים להמשיך.\n    *   **הבעיה 3 (ב-`incrementer_thread`):** התנאי `while (waiting_decrementers > 0 && counter == 0)` עבור חוטי Incrementer הוא נכון עקרונית מבחינת התזמון, אך בהינתן הבעיות בניהול `waiting_decrementers` ובאיתות, הוא עלול להוביל לקיפאון. לדוגמה, אם כל חוטי ה-Decrementer ממתינים (כי `counter` הוא 0) ו-`waiting_decrementers` נספר באופן שגוי (לדוגמה, הוא נשאר 0 למרות שיש חוטים שממתינים), וכל חוטי ה-Incrementer נחסמים על `incrementers_block` (כי `waiting_decrementers > 0 && counter == 0` מתקיים במקרה אחר), ואין חוט שיכול לאותת להם, תתרחש הרעבה או קיפאון.\n    *   **השלכות**: קיפאון (Deadlock) פוטנציאלי כאשר Incrementers ו-Decrementers חוסמים זה את זה באופן הדדי, או הרעבה של Incrementers כאשר הם נחסמים שלא לצורך או הרעבה של Decrementers אם אין מי שיעיר את Incrementers.\n\n1.1.3. **אי-דיוק בספירת `waiting_decrementers`:**\n    *   **הבעיה**: כפי שתואר בסעיף הקודם, `waiting_decrementers` מוגדל לפני שחוט ה-Decrementer נכנס ל-`pthread_cond_wait` ומוקטן רק אחרי שהוא מתעורר. זה יכול להוביל למצב שבו `waiting_decrementers` כולל חוטים שכרגע לא ממתינים בפועל, או חוטים שרק התעוררו אבל עדיין לא ביצעו את פעולת ההקטנה. זה פוגע באמינות המשתנה.\n    *   **השלכות**: קבלת החלטות שגויות בטיפול בהרעבה, כפי שתואר לעיל, ובכך פגיעה בדרישה 3.\n\n1.2. **גרסה מתוקנת של `incrementer_thread`:**\n```c\nvoid* incrementer_thread(void* arg) {\n    for (int i = 0; i < ITERATIONS; ++i) {\n        pthread_mutex_lock(&mutex);\n        \n        // Incrementers wait ONLY if there are decrementers waiting AND counter is 0.\n        // This gives priority to decrementers when the counter is at its minimum.\n        while (waiting_decrementers > 0 && counter == 0) {\n            printf(\"Incrementer: Waiting due to starving decrementers. Counter: %d\\n\", counter);\n            pthread_cond_wait(&incrementers_block, &mutex);\n        }\n\n        counter++;\n        printf(\"Incrementer: Counter is now %d\\n\", counter);\n        \n        // Use broadcast for can_decrement because multiple decrementers might be able to run now.\n        pthread_cond_broadcast(&can_decrement); \n\n        // Use broadcast for counter_is_even because multiple monitors might be waiting.\n        if (counter % 2 == 0) {\n            pthread_cond_broadcast(&counter_is_even);\n        }\n        pthread_mutex_unlock(&mutex);\n        usleep(50000); // Simulate work\n    }\n    return NULL;\n}\n```\n\n1.3. **גרסה מתוקנת של `decrementer_thread`:**\n```c\nvoid* decrementer_thread(void* arg) {\n    for (int i = 0; i < ITERATIONS; ++i) {\n        pthread_mutex_lock(&mutex);\n        \n        // Increment count BEFORE potentially waiting.\n        waiting_decrementers++; \n        \n        // Signal to potentially blocked incrementers using broadcast.\n        // This is important if this decrementer is the first one to arrive at counter == 0,\n        // and an incrementer might be trying to proceed. It ensures incrementers re-evaluate their condition.\n        pthread_cond_broadcast(&incrementers_block); \n\n        while (counter == 0) {\n            printf(\"Decrementer: Waiting, counter is %d\\n\", counter);\n            pthread_cond_wait(&can_decrement, &mutex);\n        }\n        // Decrement count AFTER being woken up and before actually changing 'counter'.\n        waiting_decrementers--; \n\n        counter--;\n        printf(\"Decrementer: Counter is now %d\\n\", counter);\n\n        // After a decrementer runs, it might have changed the conditions for incrementers.\n        // If 'counter' is now positive OR there are no more decrementers waiting,\n        // incrementers are no longer blocked by the starvation avoidance rule. So, broadcast to them.\n        if (counter > 0 || waiting_decrementers == 0) {\n            pthread_cond_broadcast(&incrementers_block);\n        }\n\n        // Use broadcast for counter_is_even because multiple monitors might be waiting.\n        if (counter % 2 == 0) {\n            pthread_cond_broadcast(&counter_is_even);\n        }\n        pthread_mutex_unlock(&mutex);\n        usleep(70000); // Simulate work\n    }\n    return NULL;\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0213__Synchronization__CodeAnalysis__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:05:23", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Synchronization", "Threads", "Condition Variables", "Mutexes", "Reusable Barrier", "Deadlock"], "content": {"text": "נתונה מחסום (barrier) לשימוש חוזר הממומש באמצעות mutex ו-condition variables. המחסום מיועד לסנכרן N חוטים כך שכולם יגיעו לנקודה מסוימת בתוכנית לפני שמי מהם ימשיך הלאה. לאחר שחרור המחסום, הוא אמור להיות מוכן לשימוש חוזר.\n\nקראו את קוד המחסום והשימוש בו בקוד המצורף:", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\n#define NUM_THREADS 5\n#define NUM_ITERATIONS 3 // How many times threads pass the barrier\n\npthread_mutex_t barrier_mutex = PTHREAD_MUTEX_INITIALIZER;\npthread_cond_t barrier_cond = PTHREAD_COND_INITIALIZER;\nint barrier_count = 0;\nint barrier_threshold = NUM_THREADS;\n\nvoid my_barrier_wait() {\n    pthread_mutex_lock(&barrier_mutex);\n    barrier_count++;\n    if (barrier_count == barrier_threshold) {\n        // Last thread to arrive\n        barrier_count = 0; // Reset for next use\n        pthread_cond_broadcast(&barrier_cond);\n    } else {\n        // Not the last thread, wait\n        pthread_cond_wait(&barrier_cond, &barrier_mutex);\n    }\n    pthread_mutex_unlock(&barrier_mutex);\n}\n\nvoid* thread_func(void* arg) {\n    long tid = (long)arg;\n    for (int i = 0; i < NUM_ITERATIONS; ++i) {\n        printf(\"Thread %ld arrived at barrier for iteration %d.\\n\", tid, i + 1);\n        my_barrier_wait();\n        printf(\"Thread %ld passed barrier for iteration %d.\\n\", tid, i + 1);\n        usleep(10000); // Simulate work after barrier\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    for (long i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, (void*)i);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"All threads finished.\\n\");\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "זהו את הבעיה העיקרית במנגנון הסנכרון של המחסום הנתון, במיוחד בהקשר של שימוש חוזר. הסבירו מדוע זו בעיה ומה ההשלכות שלה (לדוגמה, האם עלול להיווצר Deadlock, Livelock או התנהגות שגויה אחרת).", "code_snippet": null, "options": null}, {"id": "1.2", "text": "תקנו את קוד הפונקציה `my_barrier_wait` כך שיפעל באופן תקין לשימוש חוזר, תוך שימוש באובייקטי סנכרון הקיימים (mutex ו-condition variables) ומינימום שינויים. הציגו את הקוד המתוקן והסבירו את התיקון שלכם.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: הבעיה העיקרית במחסום הנתון היא תנאי מרוץ (race condition) שעלול להתרחש כאשר המחסום מיועד לשימוש חוזר. הבעיה נובעת מהאיפוס המוקדם של `barrier_count` ל-0 על ידי החוט האחרון שהגיע, מיד לאחר קריאה ל-`pthread_cond_broadcast`.\nאם חוט שהתעורר מה-`pthread_cond_wait` (בעקבות ה-broadcast) מתזמן מחדש *לפני* שהוא יצא מהאזור הקריטי (כלומר, לפני ה-`pthread_mutex_unlock`), וחוט אחר (מהמחזור הבא של המחסום, או אפילו חוט שהתעורר מה-broadcast ורץ מהר) מגיע, הוא יראה ש-`barrier_count` כבר אופס ל-0.\nכתוצאה מכך, חוט שהתעורר זה עתה עלול לבדוק שוב את התנאי `barrier_count == barrier_threshold` (או `barrier_count < barrier_threshold`) ולמצוא אותו שוב שגוי עבור המחזור הנוכחי, ולכן יחזור מיד למצב המתנה (wait) עבור המחזור הבא של המחסום. זה יוצר מצב שבו חלק מהחוטים נתקעים במחסום הנוכחי, בעוד אחרים ממשיכים.\nההשלכה היא מצב של Deadlock או Livelock, כאשר חלק מהחוטים נתקעים ב-`pthread_cond_wait` מבלי שאי פעם יגיעו כולם (N חוטים) ל-`barrier_count == barrier_threshold` עבור המחזור שהם נמצאים בו, כיוון שחוטים אחרים כבר 'קפצו' למחזור הבא של המחסום. גם אם לא deadlock מוחלט, התנהגות התוכנית תהיה שגויה ולא תסנכרן את החוטים כנדרש.\n\n1.2: כדי לתקן את הבעיה ולממש מחסום לשימוש חוזר באופן תקין, נשתמש במשתנה נוסף הנקרא 'דור' (`generation` או `phase`). משתנה זה יאפשר לחוטים להבחין בין מחזורי המחסום השונים. רק כאשר החוט האחרון מגיע, הוא יקדם את הדור ויבצע broadcast, ובכך ישחרר את כל החוטים שמחכים לדור הנוכחי. חוטים שהתעוררו חייבים לוודא שהדור שלהם (הדור שהם חיכו לו) אינו תואם יותר לדור הגלובלי, מה שמעיד שהמחסום התקדם.\n\n**קוד מתוקן לפונקציה `my_barrier_wait`:**\n```c\n// יש להוסיף הצהרה גלובלית:\n// int barrier_generation = 0; // Added for reusable barrier\n\nvoid my_barrier_wait() {\n    pthread_mutex_lock(&barrier_mutex);\n    int my_generation = barrier_generation; // לכידת הדור הנוכחי של החוט\n    barrier_count++;\n    if (barrier_count == barrier_threshold) {\n        // החוט האחרון שהגיע\n        barrier_count = 0;           // איפוס המונה\n        barrier_generation++;        // קידום הדור\n        pthread_cond_broadcast(&barrier_cond); // שחרור כל החוטים\n    } else {\n        // לא החוט האחרון, המתן. לולאת while מטפלת בהתעוררויות שווא ומוודאת התקדמות דור.\n        while (my_generation == barrier_generation) {\n            pthread_cond_wait(&barrier_cond, &barrier_mutex);\n        }\n    }\n    pthread_mutex_unlock(&barrier_mutex);\n}\n```\n\n**הסבר התיקון:**\nהוספנו את המשתנה הגלובלי `barrier_generation` ואת המשתנה המקומי `my_generation`.\n1.  כל חוט, בכניסה ל-`my_barrier_wait`, שומר את ערך `barrier_generation` הנוכחי ב-`my_generation` שלו.\n2.  החוט האחרון שמגיע למחסום (כאשר `barrier_count == barrier_threshold`) הוא זה שאחראי לאפס את `barrier_count` *ולקדם* את `barrier_generation`. לאחר מכן הוא מבצע `pthread_cond_broadcast`.\n3.  חוטים אחרים שמחכים ב-`pthread_cond_wait` יתעוררו. כעת, במקום לצאת מיד מהפונקציה, הם בודקים בלולאת `while` האם `my_generation` שלהם עדיין שווה ל-`barrier_generation` הגלובלי. כל עוד הם זהים, זה אומר שהמחסום לא התקדם עבורם, והם יחזרו למצב המתנה (או שזו הייתה התעוררות שווא). רק כאשר `barrier_generation` התקדם (על ידי החוט האחרון), `my_generation` של החוט כבר לא יהיה שווה ל-`barrier_generation` הגלובלי, והחוט יוכל לצאת מהלולאה ולהמשיך.\nתיקון זה מבטיח שכל החוטים ימתינו למחזור הנכון של המחסום ולא יקפצו למחזור הבא בטרם עת, ובכך מונע את תנאי המרוץ ותופעות ה-Deadlock/Livelock הפוטנציאליות בשימוש חוזר במחסום."}, "difficulty_estimation": "Hard", "_source_file": "0214__Synchronization__CodeAnalysis__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:05:52", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Synchronization", "Threads", "Concurrency", "Condition Variables", "Mutexes", "Barriers"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בחוטים (threads) לביצוע משימה הכוללת שני שלבים (Phase A ו-Phase B) באופן מחזורי. כל T החוטים מבצעים N איטרציות.\nהדרישות הן:\n1. חוט אינו יכול להתחיל את Phase B עבור איטרציה מסוימת, אלא אם כן כל T החוטים סיימו את Phase A עבור אותה איטרציה.\n2. בכל רגע נתון, רק חוט אחד יכול להיות ב-Phase B (קטע קריטי).\n\nיש לנתח את הקוד ולענות על השאלות הבאות:", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n#include <stdbool.h>\n\n#define T 3 // Number of threads\n#define N 2 // Number of iterations per thread\n\npthread_mutex_t mutex_phaseA;\npthread_cond_t cond_phaseA_done;\nint phaseA_counter = 0;\n\npthread_mutex_t mutex_phaseB;\n\nint global_work_counter = 0;\n\nvoid* thread_func(void* arg) {\n    long thread_id = (long)arg;\n\n    for (int i = 0; i < N; ++i) {\n        printf(\"Thread %ld: Iteration %d, starting Phase A\\n\", thread_id, i);\n        usleep(1000 * (thread_id + 1)); // Simulate work\n\n        pthread_mutex_lock(&mutex_phaseA);\n        phaseA_counter++;\n        printf(\"Thread %ld: Iteration %d, finished Phase A. phaseA_counter = %d\\n\", thread_id, i, phaseA_counter);\n\n        if (phaseA_counter < T) {\n            pthread_cond_wait(&cond_phaseA_done, &mutex_phaseA);\n        } else {\n            // Last thread to finish Phase A, reset counter and broadcast\n            printf(\"Thread %ld: Iteration %d, ALL threads finished Phase A. Broadcasting!\\n\", thread_id, i);\n            phaseA_counter = 0;\n            pthread_cond_broadcast(&cond_phaseA_done);\n        }\n        pthread_mutex_unlock(&mutex_phaseA);\n\n        // Phase B critical section\n        pthread_mutex_lock(&mutex_phaseB);\n        printf(\"Thread %ld: Iteration %d, entering Phase B critical section. global_work_counter = %d\\n\", thread_id, i, global_work_counter);\n        global_work_counter++;\n        usleep(500 * (T - thread_id)); // Simulate work\n        printf(\"Thread %ld: Iteration %d, exiting Phase B critical section. global_work_counter = %d\\n\", thread_id, i, global_work_counter);\n        pthread_mutex_unlock(&mutex_phaseB);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[T];\n\n    pthread_mutex_init(&mutex_phaseA, NULL);\n    pthread_cond_init(&cond_phaseA_done, NULL);\n    pthread_mutex_init(&mutex_phaseB, NULL);\n\n    for (long i = 0; i < T; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, (void*)i);\n    }\n\n    for (int i = 0; i < T; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final global_work_counter = %d\\n\", global_work_counter);\n\n    pthread_mutex_destroy(&mutex_phaseA);\n    pthread_cond_destroy(&cond_phaseA_done);\n    pthread_mutex_destroy(&mutex_phaseB);\n\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "האם הסנכרון בקוד עונה על הדרישות באופן מלא ונכון? אם לא, זהו את הבעיה(ות) והסבירו מדוע היא(הן) קיימת(ות).", "code_snippet": null, "options": null}, {"id": "1.2", "text": "מה יהיה הערך הסופי של המשתנה global_work_counter כאשר כל החוטים יסיימו את ריצתם? נמקו את תשובתכם.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "נניח שברצוננו להוסיף קריאה לפונקציה `log_iteration_complete()` בדיוק פעם אחת בכל איטרציה, לאחר שכל החוטים סיימו את Phase A אך לפני שמישהו נכנס ל-Phase B. היכן הייתם מוסיפים את הקריאה הזו, ואיזה סנכרון נוסף (אם בכלל) נדרש כדי להבטיח שהיא תיקרא רק פעם אחת לאיטרציה?", "code_snippet": "void log_iteration_complete() {\n    printf(\"--- Iteration complete for all threads ---\\n\");\n}", "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: הסנכרון אינו עונה על הדרישות באופן מלא ונכון, במיוחד עבור תרחיש של שימוש חוזר במחסום (reusable barrier).\nהבעיה העיקרית היא תנאי מרוץ (race condition) כאשר חוטים עוברים למחזור הבא של האיטרציות. כאשר החוט האחרון מגיע ל-Phase A, הוא מאפס את `phaseA_counter` ל-0 ומשדר (`pthread_cond_broadcast`) לכל החוטים הממתינים. כל החוטים הממתינים מתעוררים וממשיכים ל-Phase B.\nעם זאת, החוט האחרון (ששידר) עשוי לסיים את Phase B שלו במהירות, לחזור ללולאת ה-for, ולהתחיל את Phase A עבור האיטרציה הבאה (ולהגדיל את `phaseA_counter` ל-1), וזאת לפני שכל שאר החוטים שהתעוררו הספיקו לצאת מהמחסום של Phase A ולראות ש-`phaseA_counter` אופס. במצב כזה, חוטים אחרים שיגיעו למחסום Phase A באיטרציה הבאה עלולים לראות ערך שגוי של `phaseA_counter` (למשל, 1 במקום 0) או לפספס את ה-broadcast הבא, מה שעלול לגרום לקיפאון (deadlock) או להפרת הדרישה שכל החוטים יסיימו את Phase A לפני שמישהו יתחיל את Phase B עבור אותה איטרציה. כלומר, חוט אחד יכול להתחיל את Phase A של איטרציה `i+1` לפני שכל החוטים סיימו את Phase B של איטרציה `i`.\nמחסום לשימוש חוזר דורש לרוב מנגנון מורכב יותר, כגון שימוש במונה דורות (generation counter) או במחסום כפול (double barrier), כדי לוודא שכל החוטים עזבו את המחסום לפני שהוא מתאפס ומוכן לשימוש חוזר.\n\n1.2: הערך הסופי של `global_work_counter` יהיה T * N.\nההסבר: המשתנה `global_work_counter` מקודם פעם אחת בכל כניסה ל-Phase B. Phase B הוא קטע קריטי המוגן על ידי `mutex_phaseB`, מה שמבטיח שרק חוט אחד יכול לגשת אליו בו-זמנית ושכל הקידומים מתבצעים באופן אטומי ונכון. כל אחד מ-T החוטים מבצע N איטרציות, ובכל איטרציה הוא נכנס ל-Phase B פעם אחת. לפיכך, סך הקידומים יהיה T כפול N. עם T=3 ו-N=2, הערך הסופי יהיה 3 * 2 = 6.\n\n1.3: היינו מוסיפים את הקריאה ל-`log_iteration_complete()` בתוך בלוק ה-`else` (הבלוק שמטפל בחוט האחרון שמגיע ל-Phase A), לפני איפוס המונה `phaseA_counter` ולפני קריאת ה-`pthread_cond_broadcast`.\n\nדוגמה לשינוי הקוד:\n```c\n            if (phaseA_counter < T) {\n                pthread_cond_wait(&cond_phaseA_done, &mutex_phaseA);\n            } else {\n                log_iteration_complete(); // קריאה לפונקציה כאן\n                phaseA_counter = 0;\n                pthread_cond_broadcast(&cond_phaseA_done);\n            }\n```\nאין צורך בסנכרון נוסף עבור `log_iteration_complete()` עצמה. היא נקראת על ידי חוט יחיד (החוט האחרון שמגיע ל-Phase A) כאשר הוא מחזיק את `mutex_phaseA`. זה מבטיח שהפונקציה תיקרא בדיוק פעם אחת בכל איטרציה, ובזמן הנכון (לאחר שכל החוטים סיימו את Phase A ולפני שמישהו נכנס ל-Phase B) ומבלי ליצור תנאי מרוץ נוספים."}, "difficulty_estimation": "Hard", "_source_file": "0215__Synchronization__CodeAnalysis__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:06:36", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Synchronization", "Threads", "Mutex", "Condition Variables", "Semaphores", "Barrier"], "content": {"text": "נתונה תוכנית C הבאה המשתמשת בחוטים (threads) ובמנגנוני סנכרון (mutexes, condition variables, semaphores) לביצוע עבודה מתואמת. התוכנית מיועדת לבצע את השלבים הבאים:\n1.  **שלב ההכנה**: כל חוט מבצע פעולת הכנה מקומית.\n2.  **שלב ההמתנה הגלובלי**: כל החוטים ממתינים זה לזה עד שכולם יסיימו את שלב ההכנה. רק אז הם יכולים להמשיך.\n3.  **שלב העבודה המתואמת**: החוטים מקדמים מונה גלובלי משותף `global_counter` באופן סבבי (thread 0, thread 1, ..., thread N_THREADS-1, ואז שוב thread 0 וכן הלאה), כאשר כל חוט מבצע `K_ITERATIONS` קידומים. \n\nבהינתן N_THREADS=3 ו-K_ITERATIONS=2, ובהנחה שכל קריאות המערכת הצליחו, מה יהיה ערכו הסופי של `global_counter`? האם קיימים מצבי מרוץ (race conditions) או קיפאון (deadlocks) בקוד? פרט את תשובתך באופן מלא ומנומק.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n\n#define N_THREADS 3 \n#define K_ITERATIONS 2 \n\nint global_counter = 0; \n\n// Barrier synchronization\npthread_mutex_t barrier_mutex;\npthread_cond_t barrier_cond;\nint threads_at_barrier = 0;\n\n// Turn-based synchronization\nsem_t turn_semaphores[N_THREADS]; // One semaphore per thread\n\nvoid* worker_thread(void* arg) {\n    long thread_id = (long)arg;\n\n    // Phase 1: Local Setup\n    printf(\"Thread %ld: Starting setup...\\n\", thread_id);\n    // Simulate setup time if needed\n    printf(\"Thread %ld: Setup complete.\\n\", thread_id);\n\n    // Phase 2: Barrier synchronization - wait for all threads to complete setup\n    pthread_mutex_lock(&barrier_mutex);\n    threads_at_barrier++;\n    if (threads_at_barrier == N_THREADS) {\n        printf(\"All threads reached barrier. Signaling...\\n\");\n        pthread_cond_broadcast(&barrier_cond); // Signal all waiting threads\n    } else {\n        while (threads_at_barrier < N_THREADS) {\n            pthread_cond_wait(&barrier_cond, &barrier_mutex); // Wait for signal\n        }\n    }\n    pthread_mutex_unlock(&barrier_mutex);\n    printf(\"Thread %ld: Passed barrier.\\n\", thread_id);\n\n    // Phase 3: Coordinated Work - ordered increment of global_counter\n    for (int i = 0; i < K_ITERATIONS; ++i) {\n        sem_wait(&turn_semaphores[thread_id]); // Wait for my turn\n\n        // Critical section\n        global_counter++;\n        printf(\"Thread %ld: Incrementing global_counter to %d (iteration %d)\\n\", thread_id, global_counter, i);\n\n        sem_post(&turn_semaphores[(thread_id + 1) % N_THREADS]); // Signal next thread\n    }\n\n    printf(\"Thread %ld: Finished all work.\\n\", thread_id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[N_THREADS];\n\n    // Initialize synchronization primitives\n    pthread_mutex_init(&barrier_mutex, NULL);\npthread_cond_init(&barrier_cond, NULL);\n\n    for (int i = 0; i < N_THREADS; ++i) {\n        sem_init(&turn_semaphores[i], 0, 0); // All initially 0\n    }\n    sem_post(&turn_semaphores[0]); // Grant turn to thread 0 to start\n\n    // Create threads\n    for (long i = 0; i < N_THREADS; ++i) {\n        if (pthread_create(&threads[i], NULL, worker_thread, (void*)i) != 0) {\n            perror(\"Failed to create thread\");\n            return 1;\n        }\n    }\n\n    // Join threads\n    for (int i = 0; i < N_THREADS; ++i) {\n        if (pthread_join(threads[i], NULL) != 0) {\n            perror(\"Failed to join thread\");\n            return 1;\n        }\n    }\n\n    printf(\"Main: All threads finished. Final global_counter = %d\\n\", global_counter);\n\n    // Destroy synchronization primitives\n    pthread_mutex_destroy(&barrier_mutex);\npthread_cond_destroy(&barrier_cond);\n    for (int i = 0; i < N_THREADS; ++i) {\n        sem_destroy(&turn_semaphores[i]);\n    }\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "**ערך סופי של global_counter:**\nהערך הסופי של `global_counter` יהיה 6. כל אחד מ-`N_THREADS` החוטים מקדם את המונה `K_ITERATIONS` פעמים. מכיוון שהסנכרון מבטיח שכל קידום מתבצע באופן אטומי ומוגן, כל הקידומים יצטברו בצורה נכונה. לכן, סך הקידומים יהיה `N_THREADS * K_ITERATIONS = 3 * 2 = 6`.\n\n**מצבי מרוץ או קיפאון:**\nהקוד **אינו מכיל מצבי מרוץ או קיפאון** עבור התרחיש המתואר, והוא מסונכרן באופן נכון בשני השלבים:\n\n1.  **שלב ההמתנה הגלובלי (Barrier Synchronization):**\n    *   החוטים משתמשים ב-`pthread_mutex_t` (`barrier_mutex`) וב-`pthread_cond_t` (`barrier_cond`) יחד עם מונה `threads_at_barrier` כדי ליישם מחסום (barrier). \n    *   המונה `threads_at_barrier` מוגן על ידי המוטקס (`barrier_mutex`), מה שמונע מצב מרוץ על עדכון המונה.\n    *   החוט האחרון שמגיע למחסום (כאשר `threads_at_barrier == N_THREADS`) משדר (broadcast) לכל החוטים הממתינים באמצעות `pthread_cond_broadcast`, ובכך משחרר אותם להמשך הריצה.\n    *   שאר החוטים ממתינים באמצעות `pthread_cond_wait` בתוך לולאת `while`, המבטיחה בדיקה חוזרת של התנאי (`threads_at_barrier < N_THREADS`) גם במקרה של התעוררות שווא (spurious wakeup), ובכך מבטיחה שכל החוטים יעברו את המחסום רק כאשר כולם הגיעו אליו.\n    *   אין קיפאון מכיוון שכל החוטים בסופו של דבר יגיעו למחסום, והחוט האחרון ישחרר את כולם.\n\n2.  **שלב העבודה המתואמת (Ordered Processing):**\n    *   החוטים משתמשים במערך של סמפורים (`turn_semaphores`) כדי לאכוף סדר סבבי קפדני בקידום `global_counter`.\n    *   כל סמפור מיועד לחוט ספציפי (חוט `i` ממתין על `turn_semaphores[i]` ומאותת לחוט `(i+1)%N_THREADS` באמצעות `sem_post(&turn_semaphores[(thread_id + 1) % N_THREADS])`).\n    *   הסמפור `turn_semaphores[0]` מאותחל ל-1 ב-`main` כדי לאפשר לחוט 0 להתחיל ראשון, בעוד שאר הסמפורים מאותחלים ל-0.\n    *   דפוס זה מבטיח שרק חוט אחד בכל פעם ניגש ל-`global_counter` ומקדם אותו, ובכך מונע מצב מרוץ על המונה. \n    *   אין קיפאון מכיוון שיש תמיד חוט אחד שיכול להמשיך (זה שהסמפור שלו הוא 1), והוא תמיד יעביר את ה\"תור\" לחוט הבא בסבב."}, "difficulty_estimation": "Hard", "_source_file": "0216__Synchronization__CodeAnalysis__Hard.json", "_topic_hint": "Synchronization", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:07:08", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Mutexes", "Synchronization", "Concurrency"], "content": {"text": "מהי המטרה העיקרית של שימוש ב-mutex במערכת הפעלה?", "code_snippet": null, "options": ["למנוע מצב של קיפאון.", "לאפשר גישה סימולטנית למשאבים משותפים.", "להבטיח בלעדיות לגישה לקטע קריטי.", "לשפר את ביצועי המערכת."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "להבטיח בלעדיות לגישה לקטע קריטי.", "explanation": "mutex נועד להבטיח שרק תהליך או תהליכון אחד יוכל לגשת לקטע קריטי (critical section) מסוים בכל זמן נתון, ובכך למנוע תנאי מרוץ (race conditions) ולהבטיח עקביות נתונים. בעוד ש-mutexים יכולים להיות מעורבים בתנאים שמובילים לקיפאון או להשפיע על ביצועים, מטרתם העיקרית היא אכיפת בלעדיות (mutual exclusion)."}, "difficulty_estimation": "Easy", "_source_file": "0217__Mutexes__MultipleChoice__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:07:14", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Mutexes", "Concurrency", "Synchronization"], "content": {"text": "מטרתו העיקרית של mutex היא לאפשר לחוטים מרובים להיכנס למקטע קריטי בו זמנית.", "code_snippet": null, "options": ["נכון", "לא נכון"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "לא נכון", "explanation": "לא נכון. מטרתו העיקרית של mutex היא להבטיח גישה הדדית בלבדית (mutual exclusion) למקטע קריטי, כלומר, לאפשר לחוט אחד בלבד להיכנס למקטע הקריטי בכל רגע נתון ובכך למנוע תנאי מרוץ."}, "difficulty_estimation": "Easy", "_source_file": "0218__Mutexes__MultipleChoice__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:07:22", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Mutexes", "Synchronization", "Concurrency"], "content": {"text": "מהו התפקיד העיקרי של Mutex במערכת הפעלה?", "code_snippet": null, "options": ["מניעת קיפאון (Deadlock)", "הבטחת הדרה הדדית (Mutual Exclusion)", "תיאום בין תהליכים שונים (Process Coordination)", "הגברת ביצועים של תוכניות מקביליות"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "הבטחת הדרה הדדית (Mutual Exclusion)", "explanation": "התפקיד העיקרי והבסיסי של Mutex הוא להבטיח הדרה הדדית (mutual exclusion) בין תהליכים או ת'רדים. הדרה הדדית מבטיחה שרק תהליך או ת'רד אחד יוכל לגשת לקטע קריטי (critical section) או למשאב משותף בכל רגע נתון, ובכך למנוע מצבי מרוץ (race conditions) ולשמור על עקביות הנתונים. בעוד ש-Mutex יכול להיות כלי במניעת קיפאון או תיאום, אלה אינם תפקידיו העיקריים ישירות, והוא אינו מיועד להגברת ביצועים באופן ישיר (לרוב הוא אף גורם לסריאליזציה ובכך עלול להקטין ביצועים)."}, "difficulty_estimation": "Easy", "_source_file": "0219__Mutexes__MultipleChoice__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:07:29", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Mutexes", "Synchronization", "Concurrency", "Race Conditions"], "content": {"text": "מהי המטרה העיקרית של מנעול הדדי (mutex)?", "code_snippet": null, "options": ["למנוע קיפאון (deadlock).", "להבטיח גישה הוגנת למשאבים משותפים.", "להגן על קטעים קריטיים (critical sections) מפני מצבי מרוץ (race conditions).", "לאפשר למספר תהליכונים לגשת למשאב משותף בו זמנית."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "להגן על קטעים קריטיים (critical sections) מפני מצבי מרוץ (race conditions).", "explanation": "מנעול הדדי (mutex) נועד בראש ובראשונה להבטיח בלעדיות הדדית (mutual exclusion) בקטעים קריטיים של קוד. כאשר תהליכון אחד מחזיק במנעול, תהליכונים אחרים המנסים לרכוש את אותו המנעול נחסמים עד שהמנעול משוחרר. פעולה זו מונעת מצבי מרוץ (race conditions) ודואגת לעקביות של נתונים משותפים. אף על פי שמנעולים יכולים להיות חלק מפתרונות למניעת קיפאון או הרעבה, זו אינה מטרתם העיקרית. הם אינם מאפשרים גישה בו זמנית למשאב משותף, אלא בדיוק ההפך."}, "difficulty_estimation": "Easy", "_source_file": "0220__Mutexes__MultipleChoice__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:07:37", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Mutexes", "Concurrency", "Synchronization"], "content": {"text": "מהי ההתנהגות הסטנדרטית של חוט המנסה לנעול מנעול (mutex) שכבר נמצא ברשותו?", "code_snippet": null, "options": ["החוט נתקע (deadlock) וממתין לעצמו לשחרר את המנעול.", "החוט מצליח לנעול את המנעול שוב (מנעול רקורסיבי).", "הפעולה מחזירה שגיאה.", "החוט ממשיך בביצוע ללא נעילה נוספת."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "החוט נתקע (deadlock) וממתין לעצמו לשחרר את המנעול.", "explanation": "ברוב מימושי המנעולים הסטנדרטיים (למשל, `PTHREAD_MUTEX_NORMAL` ב-pthreads), מנעול אינו רקורסיבי. כאשר חוט מנסה לנעול מנעול שכבר נמצא ברשותו, הוא ינסה לתפוס אותו שוב, אך מאחר שהמנעול כבר נעול על ידו, הוא ימתין לשחרורו, מה שיוביל לקיפאון (deadlock) מכיוון שרק החוט עצמו יכול לשחרר אותו ולכן החוט ממתין לעצמו."}, "difficulty_estimation": "Easy", "_source_file": "0221__Mutexes__MultipleChoice__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:07:45", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Mutexes", "Synchronization", "Concurrency"], "content": {"text": "מהי המטרה העיקרית של מנעול (mutex)?", "code_snippet": null, "options": ["למנוע קיפאון (deadlock).", "להבטיח אי-הדדיות (mutual exclusion) בקטעים קריטיים.", "לאפשר למספר תהליכונים לגשת למשאבים משותפים בו-זמנית.", "לתזמן תהליכונים."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "להבטיח אי-הדדיות (mutual exclusion) בקטעים קריטיים.", "explanation": "מטרתו העיקרית של מנעול (mutex) היא להבטיח שרק תהליכון אחד יוכל לגשת לקטע קריטי (critical section) או למשאב משותף בכל רגע נתון. זה מונע מצבי מרוץ (race conditions) ומבטיח עקביות נתונים. בעוד ששימוש נכון ב-mutexes יכול למנוע סוגים מסוימים של קיפאון, מניעת קיפאון אינה מטרתם העיקרית, ושימוש לא נכון בהם אף יכול לגרום לקיפאון."}, "difficulty_estimation": "Easy", "_source_file": "0222__Mutexes__MultipleChoice__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:07:53", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Mutexes", "Concurrency", "Synchronization", "Critical Section"], "content": {"text": "מהי המטרה העיקרית של שימוש במנעול (mutex) בתכנות מקבילי?", "code_snippet": null, "options": ["למנוע מצב של קיפאון (deadlock)", "להבטיח גישה בלעדית לקטע קריטי", "לשפר את ביצועי התוכנית", "לאפשר תקשורת בין תהליכים"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "להבטיח גישה בלעדית לקטע קריטי", "explanation": "מנעול (mutex) משמש להגנה על קטעים קריטיים, ומוודא שרק חוט ביצוע אחד ייגש אליהם בכל רגע נתון. זהו המנגנון המרכזי למניעת תנאי מרוץ (race conditions) ולהבטחת עקביות הנתונים. מנעולים אינם מונעים קיפאון באופן אוטומטי ואף יכולים לגרום לו אם לא נעשה בהם שימוש נכון. הם גם אינם משפרים ביצועים באופן ישיר ולרוב מוסיפים תקורה, ואינם מיועדים לתקשורת בין תהליכים אלא לסנכרון גישה למשאבים משותפים."}, "difficulty_estimation": "Easy", "_source_file": "0223__Mutexes__MultipleChoice__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:08:01", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Mutexes", "Concurrency", "Synchronization"], "content": {"text": "מה קורה כאשר חוט (thread) מנסה לנעול (lock) מנעול הדדי (mutex) שכבר נתפס על ידי חוט אחר?", "code_snippet": null, "options": ["החוט ממשיך בביצוע מיד.", "החוט נכנס ללולאת המתנה פעילה (busy-wait).", "החוט נחסם (blocks) עד שהמנעול משוחרר.", "התוכנית קורסת."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "החוט נחסם (blocks) עד שהמנעול משוחרר.", "explanation": "כאשר חוט מנסה לרכוש מנעול הדדי (mutex) שכבר נתפס על ידי חוט אחר, החוט המנסה לרכוש את המנעול נכנס למצב חסימה. הוא ימתין עד שהחוט המחזיק במנעול ישחרר אותו, ורק אז יוכל לנסות לרכוש אותו שוב (או שחוט אחר ירכוש אותו קודם, תלוי במדיניות התזמון). מטרת המנעול ההדדי היא להבטיח גישה הדדית בלעדית לקטע קריטי, ולכן חסימה היא ההתנהגות הצפויה והנכונה."}, "difficulty_estimation": "Easy", "_source_file": "0224__Mutexes__MultipleChoice__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:08:09", "_subject": "Concurrency"}, {"id": 6, "type": "MultipleChoice", "topic": ["Synchronization", "Mutexes", "Concurrency"], "content": {"text": "בהינתן מנעול (mutex) מסוג PTHREAD_MUTEX_NORMAL (לא רקורסיבי) שחוט (thread) מסוים כבר מחזיק בו. מה תהיה התוצאה אם אותו חוט ינסה לבצע שוב קריאה ל-`pthread_mutex_lock()` על מנעול זה?", "code_snippet": "pthread_mutex_t m;\n// assume m is initialized as PTHREAD_MUTEX_NORMAL\n// ...\npthread_mutex_lock(&m); // First acquisition\n// ... some critical section work ...\npthread_mutex_lock(&m); // Second acquisition by the same thread", "options": ["הקריאה השנייה ל-`pthread_mutex_lock()` תחזיר שגיאה (לדוגמה, EDEADLK אם המנעול מסוג PTHREAD_MUTEX_ERRORCHECK).", "החוט יחסם באופן מיידי וייכנס למצב של קיפאון (deadlock).", "הקריאה השנייה תצליח, והחוט ירכוש את המנעול שוב מבלי להיחסם.", "המערכת תבצע שחרור אוטומטי של המנעול ולאחר מכן רכישה מחדש."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. כאשר חוט מנסה לרכוש מנעול מסוג `PTHREAD_MUTEX_NORMAL` (שאינו רקורסיבי) שכבר נמצא ברשותו, הקריאה ל-`pthread_mutex_lock()` תגרום לחוט להיחסם. מכיוון שהחוט עצמו מחזיק במנעול, הוא לעולם לא יוכל לשחרר אותו כדי לאפשר לעצמו להמשיך, וכך נוצר מצב של קיפאון (deadlock). סוג המנעול `PTHREAD_MUTEX_ERRORCHECK` היה מחזיר שגיאה (EDEADLK) במצב כזה, אך `PTHREAD_MUTEX_NORMAL` אינו מבצע בדיקה זו ומוביל לחסימה וקיפאון. מנעול מסוג `PTHREAD_MUTEX_RECURSIVE` מאפשר רכישות מרובות על ידי אותו חוט."}, "difficulty_estimation": "Medium", "_source_file": "0225__Mutexes__MultipleChoice__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:08:25", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Mutexes", "Deadlocks"], "content": {"text": "בהינתן מנעול (mutex) שאינו רקורסיבי (non-recursive), חוט המנסה לנעול אותו פעם שנייה מבלי לשחרר אותו קודם לכן, ייכנס למצב של קיפאון (deadlock).", "code_snippet": "pthread_mutex_t my_mutex;\n\nvoid *thread_func(void *arg) {\n    pthread_mutex_lock(&my_mutex); // First lock\n    // ... critical section ...\n    pthread_mutex_lock(&my_mutex); // Second lock by the same thread\n    // ... This line will cause a deadlock ...\n    pthread_mutex_unlock(&my_mutex);\n    pthread_mutex_unlock(&my_mutex);\n    return NULL;\n}\n\nint main() {\n    // Initialize a default (non-recursive) mutex\n    pthread_mutex_init(&my_mutex, NULL);\n    // Assume thread_func is created and run\n    return 0;\n}", "options": ["נכון", "לא נכון"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "נכון", "explanation": "נכון. מנעול (mutex) שאינו רקורסיבי מיועד להבטיח בלעדיות (mutual exclusion) כך שרק חוט אחד יכול להחזיק בו בכל רגע נתון. כאשר חוט מנסה לנעול מנעול שכבר ננעל על ידו (ולא שוחרר), המערכת רואה זאת כניסיון לנעול מנעול תפוס. מכיוון שהחוט עצמו מחזיק במנעול ואינו יכול לשחרר אותו לפני הנעילה הנוספת, הוא ייכנס למצב המתנה אינסופי (deadlock) לעצמו. בניגוד לכך, מנעול רקורסיבי מאפשר לחוט שנועל אותו לנעול אותו שוב ושוב, כל עוד הוא גם משחרר אותו מספר פעמים זהה."}, "difficulty_estimation": "Medium", "_source_file": "0226__Mutexes__MultipleChoice__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:08:35", "_subject": "Concurrency"}, {"id": 6, "type": "MultipleChoice", "topic": ["Synchronization", "Mutexes", "Concurrency"], "content": {"text": "מה יקרה אם תהליך ינסה לנעול מנעול (mutex) לא-רקורסיבי שכבר ננעל על ידו?", "code_snippet": "pthread_mutex_t my_mutex;\n\n// Initialize mutex (e.g., PTHREAD_MUTEX_NORMAL)\npthread_mutex_init(&my_mutex, NULL);\n\n// Thread A acquires the mutex\npthread_mutex_lock(&my_mutex);\n\n// Thread A attempts to acquire the same mutex again\npthread_mutex_lock(&my_mutex); // What happens here?", "options": ["התהליך יכנס למצב קיפאון (deadlock) עם עצמו.", "פונקציית pthread_mutex_lock תחזיר שגיאה (error code).", "המנעול יינעל בהצלחה שוב, והתהליך ימשיך לרוץ.", "מערכת ההפעלה תסיים את ריצת התהליך."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "התהליך יכנס למצב קיפאון (deadlock) עם עצמו.", "explanation": "כאשר תהליך מנסה לנעול מחדש מנעול לא-רקורסיבי (כמו PTHREAD_MUTEX_NORMAL ב-pthreads) שהוא כבר מחזיק בו, המערכת תגרום לתהליך להיחסם בניסיון לרכוש את המנעול. מכיוון שהתהליך עצמו מחזיק במנעול, הוא לעולם לא ישחרר אותו (כי הוא חסום), וכתוצאה מכך הוא יכנס למצב קיפאון עצמי (self-deadlock). מנעולים רקורסיביים (כמו PTHREAD_MUTEX_RECURSIVE) מתוכננים להתמודד עם מצב זה על ידי מעקב אחר מספר הנעילות על ידי אותו תהליך."}, "difficulty_estimation": "Medium", "_source_file": "0227__Mutexes__MultipleChoice__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:08:44", "_subject": "Concurrency"}, {"id": 6, "type": "MultipleChoice", "topic": ["Synchronization", "Mutexes", "Concurrency"], "content": {"text": "נתון קטע הקוד הבא:\n\n```c\npthread_mutex_t my_mutex;\n\nvoid *thread_func(void *arg) {\n    pthread_mutex_lock(&my_mutex);\n    // קטע קריטי 1\n    pthread_mutex_lock(&my_mutex); // ניסיון נעילה שני\n    // קטע קריטי 2\n    pthread_mutex_unlock(&my_mutex);\n    pthread_mutex_unlock(&my_mutex);\n    return NULL;\n}\n\nint main() {\n    pthread_mutex_init(&my_mutex, NULL); // מנעול רגיל (PTHREAD_MUTEX_NORMAL)\n    // ... יצירת והפעלת thread_func בחוט נפרד ...\n    pthread_mutex_destroy(&my_mutex);\n    return 0;\n}\n```\n\nבמידה וחוט יחיד מריץ את הפונקציה `thread_func`, מה יקרה בניסיון הנעילה השני של `my_mutex`?", "code_snippet": "pthread_mutex_t my_mutex;\n\nvoid *thread_func(void *arg) {\n    pthread_mutex_lock(&my_mutex);\n    // קטע קריטי 1\n    pthread_mutex_lock(&my_mutex); // ניסיון נעילה שני\n    // קטע קריטי 2\n    pthread_mutex_unlock(&my_mutex);\n    pthread_mutex_unlock(&my_mutex);\n    return NULL;\n}\n\nint main() {\n    pthread_mutex_init(&my_mutex, NULL); // מנעול רגיל (PTHREAD_MUTEX_NORMAL)\n    // ... יצירת והפעלת thread_func בחוט נפרד ...\n    pthread_mutex_destroy(&my_mutex);\n    return 0;\n}", "options": ["הנעילה השנייה תצליח ללא בעיה.", "התהליך ייכנס למצב קיפאון (deadlock).", "הנעילה השנייה תחזיר שגיאה (error).", "התנהגות בלתי מוגדרת (Undefined behavior)."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "התהליך ייכנס למצב קיפאון (deadlock).", "explanation": "כאשר חוט מנסה לנעול מנעול רגיל (PTHREAD_MUTEX_NORMAL), כפי שמוגדר על ידי `pthread_mutex_init(&my_mutex, NULL)`, שכבר נמצא ברשותו, פונקציית `pthread_mutex_lock` תחסום את החוט ותמתין לשחרור המנעול. מכיוון שהחוט ממתין לעצמו לשחרר את המנעול, הוא לעולם לא יוכל להמשיך ולשחרר אותו, מה שמוביל למצב של קיפאון עצמי (self-deadlock). ישנם סוגי מנעולים אחרים, כמו מנעולים רקורסיביים (PTHREAD_MUTEX_RECURSIVE), המאפשרים נעילה חוזרת על ידי אותו חוט, אך זה אינו המקרה עבור מנעול רגיל. מנעולי מסוג `PTHREAD_MUTEX_ERRORCHECK` היו מחזירים שגיאה במצב זה."}, "difficulty_estimation": "Medium", "_source_file": "0228__Mutexes__MultipleChoice__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:08:58", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Mutexes", "Concurrency"], "content": {"text": "האם מותר לחוט אחד לנעול מנעול (mutex) וחוט אחר לפתוח אותו?", "code_snippet": null, "options": ["נכון", "לא נכון"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "לא נכון", "explanation": "לא נכון. מנעולים סטנדרטיים (כמו `pthread_mutex_t` ב-Pthreads או `std::mutex` ב-C++) מניחים בעלות (ownership): רק החוט שנועל את המנעול רשאי לפתוח אותו. ניסיון לפתוח מנעול מחוט אחר יוביל בדרך כלל להתנהגות בלתי מוגדרת (undefined behavior) או לשגיאת זמן ריצה (runtime error), כתלות במימוש הספציפי של מערכת ההפעלה או הספרייה. תכונה זו נועדה למנוע מצבי מירוץ (race conditions) ושימוש שגוי במשאבים מוגנים."}, "difficulty_estimation": "Medium", "_source_file": "0229__Mutexes__MultipleChoice__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:09:06", "_subject": "Concurrency"}, {"id": 6, "type": "MultipleChoice", "topic": ["Mutexes", "Synchronization", "Deadlocks"], "content": {"text": "נתון מנעול (mutex) סטנדרטי שאינו רקורסיבי. מה יקרה אם תהליך שכבר מחזיק במנעול ינסה לרכוש אותו שוב?", "code_snippet": null, "options": ["א) התהליך ייחסם לצמיתות (deadlock).", "ב) התהליך ירכוש את המנעול בהצלחה.", "ג) הפעולה תחזיר שגיאה.", "ד) ההתנהגות אינה מוגדרת."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א) התהליך ייחסם לצמיתות (deadlock).", "explanation": "בתכנון סטנדרטי של מנעול (mutex) שאינו רקורסיבי, כאשר תהליך שכבר מחזיק במנעול מנסה לרכוש אותו שוב, הוא ינסה לנעול משאב שכבר נעול על ידו. כיוון שהמנעול אינו רקורסיבי, הוא אינו מזהה שהתהליך המנסה לנעול הוא אותו תהליך שכבר מחזיק בו. לכן, התהליך ייחסם וימתין לשחרור המנעול, אך הוא עצמו זה שאמור לשחרר אותו – מה שמוביל למצב של קיפאון (deadlock). מנעולים רקורסיביים מתוכננים להתמודד עם מצב זה על ידי מעקב אחר מספר הרכישות של המנעול על ידי אותו תהליך, אך זו אינה ההתנהגות הסטנדרטית של מנעול שאינו רקורסיבי."}, "difficulty_estimation": "Medium", "_source_file": "0230__Mutexes__MultipleChoice__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:09:17", "_subject": "Concurrency"}, {"id": 6, "type": "MultipleChoice", "topic": ["Synchronization", "Mutexes", "Concurrency"], "content": {"text": "ברוב מימושי המנעולים (mutex) הסטנדרטיים (לדוגמה, `pthread_mutex_t` ב-C/C++), מהי התוצאה הצפויה אם חוט (thread) מנסה לשחרר מנעול אשר נתפס על ידי חוט אחר?", "code_snippet": null, "options": ["המנעול ישוחרר בהצלחה, והחוט המנסה לשחרר יקבל בעלות עליו.", "התוכנית תיתקל בשגיאת זמן ריצה (runtime error) או תתנהג באופן בלתי מוגדר (undefined behavior), שעלול להוביל לקריסה.", "החוט המנסה לשחרר ייחסם עד שהחוט שתפס את המנעול במקור ישחרר אותו.", "המנעול יישאר תפוס, והפעולה תחזיר קוד שגיאה (לדוגמה, `EPERM`) מבלי לגרום לקריסה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "התוכנית תיתקל בשגיאת זמן ריצה (runtime error) או תתנהג באופן בלתי מוגדר (undefined behavior), שעלול להוביל לקריסה.", "explanation": "רוב מימושי המנעולים הסטנדרטיים (כמו `pthread_mutex_t` עם סוג `PTHREAD_MUTEX_NORMAL` או `PTHREAD_MUTEX_DEFAULT`) מבוססים על קונספט של בעלות (ownership), כאשר רק החוט שתפס את המנעול רשאי לשחרר אותו. ניסיון לשחרר מנעול שלא נתפס על ידי החוט הנוכחי מוביל להתנהגות בלתי מוגדרת (undefined behavior) על פי תקן POSIX. התנהגות בלתי מוגדרת זו מתבטאת לעיתים קרובות בשגיאת זמן ריצה, קריסת התוכנית, או מצב לא עקבי. בעוד שסוגי מנעולים מסוימים (כמו `PTHREAD_MUTEX_ERRORCHECK`) יחזירו קוד שגיאה (לדוגמה, `EPERM`) מבלי לגרום לקריסה, זו אינה התנהגות ברירת המחדל או הנפוצה ביותר עבור מנעולים סטנדרטיים שאינם מוגדרים במפורש לבדיקת שגיאות. לכן, התשובה המכילה התנהגות בלתי מוגדרת וקריסה היא הנפוצה והמדויקת ביותר עבור המקרה הכללי."}, "difficulty_estimation": "Medium", "_source_file": "0231__Mutexes__MultipleChoice__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:09:32", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Mutexes", "Synchronization", "Concurrency"], "content": {"text": "מה יקרה אם תהליך (thread) ינסה לנעול מנעול הדדי (mutex) שאינו רקורסיבי (non-recursive) שכבר ננעל על ידו?", "code_snippet": null, "options": ["הפעולה תחזור בהצלחה והתהליך ימשיך בביצוע.", "התהליך יכנס למצב קיפאון (deadlock).", "התהליך יסיים את פעולתו עם שגיאה.", "הפעולה תיכשל ותחזיר קוד שגיאה (לדוגמה, EDEADLK), אך התהליך ימשיך לפעול."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "התהליך יכנס למצב קיפאון (deadlock).", "explanation": "מנעול הדדי שאינו רקורסיבי (non-recursive mutex) מיועד להיות ננעל רק פעם אחת על ידי תהליך נתון. אם אותו תהליך ינסה לנעול אותו שוב, המנעול יתפוס שהוא כבר ננעל. ברוב המימושים הסטנדרטיים (לדוגמה, PTHREAD_MUTEX_NORMAL ב-POSIX), התהליך המנסה לנעול את המנעול יכנס למצב המתנה (block) עד שהמנעול ישוחרר. מכיוון שהתהליך עצמו הוא זה שמחזיק במנעול, והוא נמצא במצב המתנה, הוא לעולם לא ישחרר את המנעול, וכך יכנס למצב של קיפאון עצמי (self-deadlock). במקרים מסוימים (לדוגמה, PTHREAD_MUTEX_ERRORCHECK ב-POSIX), המערכת עשויה לזהות ניסיון זה ולהחזיר קוד שגיאה (כמו EDEADLK) במקום להיכנס לקיפאון, אך עצם הניסיון מצביע על בעיה לוגית חמורה שעלולה להוביל לקיפאון."}, "difficulty_estimation": "Medium", "_source_file": "0232__Mutexes__MultipleChoice__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:09:54", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Mutexes", "Synchronization", "Deadlock"], "content": {"text": "נתון קטע הקוד הבא ב-C/C++. המנעול `m` מאותחל כברירת מחדל (כלומר, מסוג `PTHREAD_MUTEX_NORMAL`). איזו טענה מתארת נכונה את מה שיקרה כאשר תהליך בודד יקרא לפונקציה `func_b` מתוך `main`?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\npthread_mutex_t m; // Global mutex, default type (PTHREAD_MUTEX_NORMAL)\nint shared_data = 0;\n\nvoid func_a() {\n    printf(\"func_a: Attempting to lock mutex...\\n\");\n    pthread_mutex_lock(&m); // Attempt to lock\n    printf(\"func_a: Mutex locked. shared_data = %d\\n\", ++shared_data);\n    pthread_mutex_unlock(&m);\n    printf(\"func_a: Mutex unlocked.\\n\");\n}\n\nvoid func_b() {\n    printf(\"func_b: Attempting to lock mutex...\\n\");\n    pthread_mutex_lock(&m); // First lock\n    printf(\"func_b: Mutex locked. shared_data = %d. Calling func_a...\\n\", ++shared_data);\n    func_a(); // func_a will attempt to lock 'm' again\n    printf(\"func_b: Returned from func_a. shared_data = %d. Unlocking mutex...\\n\", shared_data);\n    pthread_mutex_unlock(&m); // First unlock\n    printf(\"func_b: Mutex unlocked.\\n\");\n}\n\nint main() {\n    pthread_mutex_init(&m, NULL); // Initializes 'm' as PTHREAD_MUTEX_NORMAL\n    printf(\"Main: Calling func_b...\\n\");\n    func_b();\n    printf(\"Main: func_b returned.\\n\");\n    pthread_mutex_destroy(&m);\n    return 0;\n}", "options": ["א. התוכנית תרוץ בהצלחה ותדפיס \"func_b: Mutex unlocked.\" פעמיים.", "ב. התוכנית תרוץ בהצלחה ותדפיס \"func_a: Mutex locked...\" ולאחר מכן \"func_b: Mutex unlocked.\" פעם אחת.", "ג. התוכנית תיכנס למצב של קיפאון (deadlock) כאשר `func_a` תנסה לתפוס את המנעול `m` בפעם השנייה.", "ד. התוכנית תרוץ בהצלחה אך `shared_data` יודפס עם ערך שגוי עקב תנאי מירוץ.", "ה. התוכנית תקרוס (segmentation fault) כאשר `func_a` תנסה לתפוס את המנעול `m` בפעם השנייה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג. התוכנית תיכנס למצב של קיפאון (deadlock) כאשר `func_a` תנסה לתפוס את המנעול `m` בפעם השנייה.", "explanation": "כאשר מנעול מסוג `PTHREAD_MUTEX_NORMAL` (הוא ברירת המחדל כאשר `NULL` מועבר ל-`pthread_mutex_init`) נתפס על ידי תהליך, ובהמשך אותו תהליך מנסה לתפוס את אותו מנעול שוב לפני ששחרר אותו, התהליך ייכנס למצב של קיפאון (deadlock). במקרה זה, `func_b` תופסת את המנעול `m`, ולאחר מכן קוראת ל-`func_a`. בתוך `func_a`, הפונקציה מנסה לתפוס שוב את המנעול `m` שכבר מוחזק על ידי אותו תהליך, מה שגורם לקיפאון. כדי לאפשר תפיסה חוזרת של מנעול על ידי אותו תהליך, יש לאתחל את המנעול כ-`PTHREAD_MUTEX_RECURSIVE`."}, "difficulty_estimation": "Hard", "_source_file": "0233__Mutexes__MultipleChoice__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:10:14", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Mutexes", "Concurrency", "Deadlock", "Synchronization"], "content": {"text": "נתון קטע הקוד הבא ב-C המשתמש ב-POSIX threads וב-mutex:\n```c\n#include <pthread.h>\n#include <stdio.h>\n\npthread_mutex_t mtx = PTHREAD_MUTEX_INITIALIZER;\nint shared_counter = 0;\n\nvoid safe_increment(int val) {\n    pthread_mutex_lock(&mtx);\n    if (val < 0) {\n        printf(\"Invalid value, returning.\\n\");\n        return; // Potential bug: returning without unlocking\n    }\n    shared_counter += val;\n    pthread_mutex_unlock(&mtx);\n}\n\nvoid* thread_routine(void* arg) {\n    for (int i = 0; i < 10000; ++i) {\n        safe_increment(i);\n    }\n    // If this path was taken, it would cause a deadlock:\n    // safe_increment(-1);\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, thread_routine, NULL);\n    pthread_create(&t2, NULL, thread_routine, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    printf(\"Final shared_counter: %d\\n\", shared_counter);\n    return 0;\n}\n```\nבהתייחס לפונקציה `safe_increment`, איזו מהטענות הבאות נכונה לגבי פוטנציאל הבעיות בקוד?", "code_snippet": null, "options": ["א. הקוד נכון לחלוטין ואין בו פוטנציאל לבעיות תזמון (concurrency issues) או קיפאון (deadlock).", "ב. קיים בקוד מצב מרוץ (race condition) על `shared_counter` מכיוון שה-mutex אינו מגן עליו בצורה נכונה.", "ג. קיים בקוד פוטנציאל לקיפאון (deadlock) אם פונקציית `safe_increment` תקרא עם ערך שלילי.", "ד. הקוד עלול לגרום לשחרור כפול של ה-mutex (double unlock) אם פונקציית `safe_increment` תקרא עם ערך שלילי."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התשובה הנכונה היא ג'. בפונקציה `safe_increment`, ה-mutex נתפס באמצעות `pthread_mutex_lock(&mtx)`. אם התנאי `val < 0` מתקיים, הפונקציה מבצעת `return` מוקדם מבלי לשחרר את ה-mutex. במצב כזה, ה-mutex נשאר נעול, וכל ניסיון עתידי של תהליכון אחר (או של אותו תהליכון) לתפוס את ה-mutex באמצעות `pthread_mutex_lock` יחסם לצמיתות, מה שיוביל למצב של קיפאון (deadlock). אין כאן מצב מרוץ על `shared_counter` בתוך הקטע המוגן, וגם לא שחרור כפול של ה-mutex מכיוון ש-`pthread_mutex_unlock` פשוט לא נקרא כלל."}, "difficulty_estimation": "Hard", "_source_file": "0234__Mutexes__MultipleChoice__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:10:31", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Mutexes", "Deadlock", "Concurrency", "Pthreads"], "content": {"text": "נתון קטע הקוד הבא המשתמש בספריית `pthread` ב-C. מה תהיה התוצאה הסבירה ביותר כאשר תהליך יפעיל את הפונקציה `main`?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t my_mutex;\n\nvoid* bar(void* arg) {\n    printf(\"Thread %ld: Entering bar, trying to lock mutex...\\n\", (long)pthread_self());\n    pthread_mutex_lock(&my_mutex);\n    printf(\"Thread %ld: Mutex locked in bar.\\n\", (long)pthread_self());\n    // Do some work\n    sleep(1);\n    pthread_mutex_unlock(&my_mutex);\n    printf(\"Thread %ld: Mutex unlocked in bar.\\n\", (long)pthread_self());\n    return NULL;\n}\n\nvoid* foo(void* arg) {\n    printf(\"Thread %ld: Entering foo, trying to lock mutex...\\n\", (long)pthread_self());\n    pthread_mutex_lock(&my_mutex);\n    printf(\"Thread %ld: Mutex locked in foo.\\n\", (long)pthread_self());\n    \n    // Call bar from foo\n    bar(NULL); // This is the problematic part if bar tries to lock the same mutex again\n    \n    printf(\"Thread %ld: Back in foo, unlocking mutex...\\n\", (long)pthread_self());\n    pthread_mutex_unlock(&my_mutex);\n    printf(\"Thread %ld: Mutex unlocked in foo.\\n\", (long)pthread_self());\n    return NULL;\n}\n\nint main() {\n    pthread_mutex_init(&my_mutex, NULL);\n    pthread_t tid;\n    pthread_create(&tid, NULL, foo, NULL);\n    pthread_join(tid, NULL);\n    pthread_mutex_destroy(&my_mutex);\n    return 0;\n}", "options": ["א. התוכנית תרוץ בהצלחה, תדפיס הודעות מ-`foo` ולאחר מכן מ-`bar` ברצף, ותסיים פעולה.", "ב. התוכנית תיכנס למצב של קיפאון (deadlock) כאשר הפונקציה `bar` תנסה לנעול את המנעול, מכיוון שהמנעול כבר מוחזק על ידי אותו תהליך (thread).", "ג. התוכנית תקרוס עקב פעולת מנעול לא חוקית (invalid mutex operation).", "ד. התוכנית תדפיס הודעת שגיאה אך תמשיך לרוץ, כאשר `bar` לא תצליח לרכוש את המנעול."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "מנעול `pthread_mutex_t` שמאותחל עם תכונות ברירת מחדל (NULL) הוא מנעול מסוג 'רגיל' (PTHREAD_MUTEX_NORMAL). מנעול מסוג זה אינו מאפשר לתהליך (thread) שכבר מחזיק בו לנעול אותו שוב. כאשר `foo` נועלת את `my_mutex` ומיד לאחר מכן קוראת ל-`bar` שבתורה מנסה לנעול את אותו המנעול, התהליך ינסה לנעול מנעול שהוא כבר מחזיק בו. במצב כזה, `pthread_mutex_lock` יגרום לתהליך להיכנס למצב המתנה אינסופי (deadlock), מכיוון שהוא ממתין לשחרור מנעול שהוא עצמו צריך לשחרר."}, "difficulty_estimation": "Hard", "_source_file": "0235__Mutexes__MultipleChoice__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:10:47", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Synchronization", "Mutexes", "Deadlock", "Concurrency"], "content": {"text": "נתון קטע הקוד הבא המשתמש בשני מנעולים (mutexes) ובשני תהליכונים (threads). איזה מהטענות הבאות נכונה לגבי הרצת קוד זה?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex_A;\npthread_mutex_t mutex_B;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to lock mutex_A...\\n\");\n    pthread_mutex_lock(&mutex_A);\n    printf(\"Thread 1: Locked mutex_A. Trying to lock mutex_B...\\n\");\n    sleep(1); // Simulate some work/context switch\n    pthread_mutex_lock(&mutex_B);\n    printf(\"Thread 1: Locked mutex_B. Doing work...\\n\");\n    // Do some work\n    pthread_mutex_unlock(&mutex_B);\n    pthread_mutex_unlock(&mutex_A);\n    printf(\"Thread 1: Unlocked both mutexes.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to lock mutex_B...\\n\");\n    pthread_mutex_lock(&mutex_B);\n    printf(\"Thread 2: Locked mutex_B. Trying to lock mutex_A...\\n\");\n    sleep(1); // Simulate some work/context switch\n    pthread_mutex_lock(&mutex_A);\n    printf(\"Thread 2: Locked mutex_A. Doing work...\\n\");\n    // Do some work\n    pthread_mutex_unlock(&mutex_A);\n    pthread_mutex_unlock(&mutex_B);\n    printf(\"Thread 2: Unlocked both mutexes.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n\n    pthread_mutex_init(&mutex_A, NULL);\n    pthread_mutex_init(&mutex_B, NULL);\n\n    pthread_create(&t1, NULL, thread_func1, NULL);\n    pthread_create(&t2, NULL, thread_func2, NULL);\n\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n\n    pthread_mutex_destroy(&mutex_A);\n    pthread_mutex_destroy(&mutex_B);\n\n    return 0;\n}", "options": ["א. הקוד ירוץ תמיד בהצלחה וידפיס את כל ההודעות ללא בעיות.", "ב. הקוד עלול להיכנס למצב של קיפאון (deadlock).", "ג. הקוד יגרום לשגיאת זמן ריצה (runtime error) מכיוון שמנעול ננעל פעמיים.", "ד. הקוד ירוץ אבל תוצאות העבודה המוגנת עלולות להיות שגויות עקב תנאי מירוץ (race condition).", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ההסבר: מצב של קיפאון (deadlock) עלול להתרחש. תהליכון 1 תופס את mutex_A ומנסה לתפוס את mutex_B. במקביל, תהליכון 2 תופס את mutex_B ומנסה לתפוס את mutex_A. אם שני התהליכונים תופסים את המנעול הראשון שלהם (כל אחד מנעול אחר) לפני שהשני משחרר אותו, שניהם ימתינו זה לזה באופן אינסופי, מה שיוביל לקיפאון. הוספת sleep(1) מגבירה את הסיכוי להתרחשות תרחיש זה."}, "difficulty_estimation": "Hard", "_source_file": "0236__Mutexes__MultipleChoice__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:11:01", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Synchronization", "Mutexes", "Deadlock", "Pthreads"], "content": {"text": "נתונה תוכנית C המשתמשת בספריות pthreads. תהליך (thread) תופס מנעול מסוג pthread_mutex_t שאינו מוגדר כרקרוסיבי (non-recursive). בתוך המקטע הקריטי, התהליך מנסה לתפוס את אותו המנעול בשנית. מהי התוצאה הסבירה ביותר של פעולה זו?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n\npthread_mutex_t my_mutex;\n\nvoid* thread_func(void* arg) {\n    printf(\"Thread trying to lock mutex for the first time.\\n\");\n    pthread_mutex_lock(&my_mutex);\n    printf(\"Thread acquired mutex for the first time. Trying to lock again...\\n\");\n    pthread_mutex_lock(&my_mutex); // This is the problematic line\n    printf(\"Thread acquired mutex for the second time (should not happen with non-recursive mutex).\\n\");\n    pthread_mutex_unlock(&my_mutex);\n    printf(\"Thread unlocked mutex once.\\n\");\n    pthread_mutex_unlock(&my_mutex);\n    printf(\"Thread unlocked mutex twice.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_mutex_init(&my_mutex, NULL); // Default is PTHREAD_MUTEX_NORMAL (non-recursive)\n\n    pthread_t tid;\n    pthread_create(&tid, NULL, thread_func, NULL);\n    pthread_join(tid, NULL);\n\n    pthread_mutex_destroy(&my_mutex);\n    return 0;\n}", "options": ["א. התוכנית תקרוס מיד עם ניסיון התפיסה השנייה של המנעול.", "ב. התהליך ייכנס למצב קיפאון (deadlock) וימתין לעצמו לשחרר את המנעול.", "ג. המנעול ייתפס בהצלחה בפעם השנייה, אך ישוחרר רק לאחר שחרור כפול.", "ד. התוכנית תמשיך לרוץ כרגיל, אך המנעול לא ייתפס שוב והפעולה השנייה תתעלם.", "ה. התנהגות בלתי מוגדרת (undefined behavior) כתוצאה מניסיון תפיסה כפול."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. על פי תקן POSIX, כאשר תהליך מנסה לתפוס מנעול מסוג PTHREAD_MUTEX_NORMAL (שהוא ברירת המחדל ואינו רקרוסיבי) שהוא כבר מחזיק בו, התוצאה המוגדרת היא קיפאון (deadlock). התהליך ימתין לעצמו לשחרר את המנעול, אך מכיוון שהוא זה שמחזיק בו, השחרור לא יקרה והתהליך ייתקע. מנעולים רקרוסיביים (PTHREAD_MUTEX_RECURSIVE) מאפשרים תפיסה חוזרת על ידי אותו תהליך, אך זה לא המקרה כאן. מנעולים מסוג PTHREAD_MUTEX_ERRORCHECK היו מחזירים שגיאה במקרה כזה, אך PTHREAD_MUTEX_NORMAL מוביל לקיפאון."}, "difficulty_estimation": "Hard", "_source_file": "0237__Mutexes__MultipleChoice__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:11:21", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Mutexes", "Deadlock", "Concurrency", "Synchronization"], "content": {"text": "נתון קטע הקוד הבא ב-C++:\n\n```cpp\n#include <mutex>\n#include <iostream>\n#include <thread>\n#include <vector>\n\nstd::mutex global_mtx;\nint counter = 0;\n\nclass MyProcessor {\npublic:\n    void increment_and_log() {\n        global_mtx.lock();\n        counter++;\n        std::cout << \"Counter: \" << counter << std::endl;\n        global_mtx.unlock();\n    }\n\n    void perform_complex_operation() {\n        global_mtx.lock();\n        // Some initial work...\n        std::cout << \"Performing complex operation...\" << std::endl;\n        increment_and_log(); // Calls another function that also tries to lock global_mtx\n        // More work after increment...\n        global_mtx.unlock();\n    }\n};\n\nvoid worker_thread(MyProcessor* proc) {\n    proc->perform_complex_operation();\n}\n\nint main() {\n    MyProcessor processor_obj;\n    std::thread t1(worker_thread, &processor_obj);\n    std::thread t2(worker_thread, &processor_obj);\n    t1.join();\n    t2.join();\n    std::cout << \"Final counter value: \" << counter << std::endl;\n    return 0;\n}\n```\n\nמה יקרה כאשר תוכנית זו תורץ?", "code_snippet": null, "options": ["א. התוכנית תרוץ ללא בעיות ותדפיס את המונה הסופי 2.", "ב. התוכנית תקרוס (crash) עקב שגיאת זמן ריצה (runtime error) הקשורה לנעילה כפולה.", "ג. התוכנית תיכנס למצב של קיפאון (deadlock) כאשר אחד מהתהליכים ינסה לנעול את המוטקס בשנית.", "ד. התוכנית תיכנס למצב של תחרות (race condition) אשר עלול להוביל לערך סופי שגוי של המונה.", "ה. התוכנית תיכנס למצב של קיפאון (deadlock) כאשר שני התהליכים ינסו לנעול את המוטקס בו זמנית."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התשובה הנכונה היא ג'.\nהקוד מדגים שימוש ב-`std::mutex` רגיל, שאינו מוטקס רקורסיבי. מוטקס רגיל אינו מאפשר לאותו תהליך לנעול אותו מספר פעמים. כאשר תהליך מנסה לנעול מוטקס שכבר נמצא בבעלותו, הקריאה ל-`lock()` תיחסם לנצח, מה שמוביל למצב של קיפאון (deadlock) עבור אותו תהליך.\n\nבמקרה זה:\n1.  הפונקציה `perform_complex_operation` נועלת את `global_mtx`.\n2.  בתוך `perform_complex_operation`, נקראת הפונקציה `increment_and_log`.\n3.  הפונקציה `increment_and_log` מנסה לנעול את `global_mtx` *שוב*.\nמכיוון ש-`global_mtx` כבר נעול על ידי אותו תהליך, הקריאה השנייה ל-`global_mtx.lock()` תגרום לתהליך להיכנס למצב המתנה אינסופי (deadlock), מכיוון שלעולם לא ישוחרר על ידי תהליך אחר, והוא עצמו לא יכול לשחרר אותו לפני שתפיסת הנעילה השנייה תושלם. שני התהליכים יגיעו למצב זה, כל אחד בנפרד, וכך התוכנית כולה תיתקע.\nכדי לפתור בעיה זו, ניתן להשתמש ב-`std::recursive_mutex` במקום `std::mutex`, או לתכנן מחדש את הקוד כך שמוטקס לא יילקח פעמיים על ידי אותו תהליך."}, "difficulty_estimation": "Hard", "_source_file": "0238__Mutexes__MultipleChoice__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:11:43", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Mutexes", "Synchronization", "Deadlock", "Pthreads"], "content": {"text": "נתבונן בקטע הקוד הבא ב-C, בו תהליך יחיד מבצע קריאה לפונקציה `funcA`, אשר רוכשת מנעול (mutex) ולאחר מכן קוראת לפונקציה `funcB`. `funcB` מנסה לרכוש את אותו המנעול שכבר נרכש על ידי `funcA` באותו התהליך. בהנחה שהמנעול `my_mutex` מאותחל כ-`PTHREAD_MUTEX_NORMAL` (ברירת המחדל), מה תהיה התוצאה הסבירה ביותר?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\npthread_mutex_t my_mutex; // Global mutex\n\nvoid funcB() {\n    printf(\"funcB: Attempting to acquire mutex...\\n\");\n    pthread_mutex_lock(&my_mutex);\n    printf(\"funcB: Mutex acquired.\\n\");\n    // Critical section for funcB\n    pthread_mutex_unlock(&my_mutex);\n    printf(\"funcB: Mutex released.\\n\");\n}\n\nvoid funcA() {\n    printf(\"funcA: Attempting to acquire mutex...\\n\");\n    pthread_mutex_lock(&my_mutex);\n    printf(\"funcA: Mutex acquired.\\n\");\n    // Call funcB, which tries to acquire the same mutex\n    funcB();\n    printf(\"funcA: After funcB call.\\n\");\n    pthread_mutex_unlock(&my_mutex);\n    printf(\"funcA: Mutex released.\\n\");\n}\n\n// In main, assume a single thread calls funcA() after mutex initialization:\n// pthread_mutex_init(&my_mutex, NULL); // Initializes as PTHREAD_MUTEX_NORMAL\n// funcA();", "options": ["א. התוכנית תרוץ בהצלחה, שכן מנעול רגיל מאפשר רכישה חוזרת על ידי אותו תהליך.", "ב. התוכנית תיכנס למצב של קיפאון (deadlock) כאשר `funcB` תנסה לרכוש את המנעול, מכיוון שהמנעול כבר מוחזק על ידי אותו תהליך ולא ניתן לרכוש אותו שוב.", "ג. `pthread_mutex_lock` בתוך `funcB` תחזיר שגיאה ותוציא את התוכנית מריצה.", "ד. המערכת תזהה שמדובר באותו תהליך ותאפשר ל-`funcB` לרכוש את המנעול באופן מיידי ללא חסימה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הסבר: מנעול מסוג `PTHREAD_MUTEX_NORMAL` אינו מאפשר רכישה חוזרת (reentrant) על ידי אותו התהליך. כאשר `funcA` רוכשת את `my_mutex`, היא הופכת לבעלים של המנעול. כאשר `funcA` קוראת ל-`funcB`, ו-`funcB` מנסה לרכוש את אותו המנעול באמצעות `pthread_mutex_lock`, המנעול כבר מוחזק על ידי אותו תהליך. מכיוון שהמנעול אינו רב-כניסתי (non-recursive), הקריאה ל-`pthread_mutex_lock` בתוך `funcB` תגרום לתהליך לחכות לעצמו לשחרר את המנעול, מה שמוביל למצב של קיפאון (deadlock). כדי למנוע זאת, ניתן להשתמש במנעול מסוג `PTHREAD_MUTEX_RECURSIVE` אשר מאפשר לתהליך לרכוש את אותו המנעול מספר פעמים."}, "difficulty_estimation": "Hard", "_source_file": "0239__Mutexes__MultipleChoice__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:11:58", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Mutexes", "Deadlock", "Concurrency", "Synchronization"], "content": {"text": "נתון קוד C++ הבא המשתמש ב-std::mutex וב-std::thread. מהי הטענה הנכונה ביותר לגבי הרצת התוכנית?", "code_snippet": "#include <iostream>\n#include <thread>\n#include <mutex>\n#include <chrono>\n\nstd::mutex mtx1;\nstd::mutex mtx2;\n\nvoid thread_func_A() {\n    mtx1.lock();\n    std::this_thread::sleep_for(std::chrono::milliseconds(10)); // Simulate work/delay\n    mtx2.lock();\n    std::cout << \"Thread A acquired both locks\\n\";\n    mtx2.unlock();\n    mtx1.unlock();\n}\n\nvoid thread_func_B() {\n    mtx2.lock();\n    std::this_thread::sleep_for(std::chrono::milliseconds(10)); // Simulate work/delay\n    mtx1.lock();\n    std::cout << \"Thread B acquired both locks\\n\";\n    mtx1.unlock();\n    mtx2.unlock();\n}\n\nint main() {\n    std::thread t1(thread_func_A);\n    std::thread t2(thread_func_B);\n    t1.join();\n    t2.join();\n    return 0;\n}", "options": ["א. התוכנית תמיד תרוץ בהצלחה ותדפיס את שתי ההודעות.", "ב. התוכנית תמיד תיכנס למצב של קיפאון (deadlock).", "ג. התוכנית עשויה להיכנס למצב של קיפאון (deadlock), אך אינה מובטחת לעשות זאת.", "ד. התוכנית עלולה לגרום לתנאי מרוץ (race condition) עקב שימוש לא נכון במנעולים.", "ה. התוכנית תרוץ בהצלחה, אך סדר ההדפסה אינו מובטח."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הקוד מדגים תרחיש קלאסי של קיפאון (deadlock). שני התהליכונים (threads) מנסים לתפוס שני מנעולים (mutexes) בסדר הפוך. תהליכון A תופס את mtx1 ואז מנסה לתפוס את mtx2. תהליכון B תופס את mtx2 ואז מנסה לתפוס את mtx1. אם מתזמן המערכת (scheduler) יאפשר לתהליכון A לתפוס את mtx1 ולתהליכון B לתפוס את mtx2 בערך באותו זמן, לפני שאחד מהם מספיק לתפוס את המנעול השני, שניהם ייחסמו ויחכו זה לזה באופן אינסופי. עם זאת, קיפאון אינו מובטח. ייתכן שאחד התהליכונים יספיק לתפוס את שני המנעולים ולשחרר אותם לפני שהתהליכון השני יגיע לנקודת התנגשות, ובמקרה כזה התוכנית תרוץ בהצלחה. לכן, התוכנית עשויה להיכנס לקיפאון, אך זה לא מובטח."}, "difficulty_estimation": "Hard", "_source_file": "0240__Mutexes__MultipleChoice__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:12:14", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Mutexes", "Synchronization", "Race Conditions", "Threads"], "content": {"text": "נתונה תוכנית C פשוטה המשתמשת במשתנה גלובלי משותף `shared_counter` המוגדל על ידי מספר תהליכונים (threads) במקביל.\nא. הסבר מדוע הקוד הנתון עלול להוביל לתוצאות שגויות.\nב. הצע פתרון לבעיה באמצעות שימוש ב-mutex, ועדכן את קטע הקוד בהתאם.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint shared_counter = 0; // משתנה גלובלי משותף\n\nvoid* increment_thread(void* arg) {\n    for (int i = 0; i < 100000; i++) {\n        shared_counter++; // פעולה לא אטומית\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid[2]; // נניח שני תהליכונים\n    \n    // יצירת התהליכונים\n    pthread_create(&tid[0], NULL, increment_thread, NULL);\n    pthread_create(&tid[1], NULL, increment_thread, NULL);\n    \n    // המתנה לסיום התהליכונים\n    pthread_join(tid[0], NULL);\n    pthread_join(tid[1], NULL);\n    \n    printf(\"Final counter value: %d\\n\", shared_counter);\n    \n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. הבעיה בקוד הנתון היא תנאי מרוץ (race condition). הפעולה `shared_counter++` אינה פעולה אטומית. היא מורכבת למעשה משלוש פעולות:\n1. קריאת הערך הנוכחי של `shared_counter` לתוך אוגר.\n2. הגדלת הערך באוגר ב-1.\n3. כתיבת הערך החדש מהאוגר בחזרה ל-`shared_counter`.\nכאשר מספר תהליכונים מבצעים את הפעולה הזו במקביל, ייתכן ששני תהליכונים יקראו את אותו ערך של `shared_counter` לפני שאחד מהם הספיק לכתוב בחזרה את הערך המוגדל. במקרה כזה, הגדלה אחת תאבד, והמונה הסופי יהיה נמוך מהצפוי. לדוגמה, אם `shared_counter` הוא 0, תהליכון A קורא 0, תהליכון B קורא 0. תהליכון A מגדיל ל-1 וכותב 1. תהליכון B מגדיל ל-1 וכותב 1. במקום 2, המונה נשאר 1.\n\nב. כדי לפתור את בעיית תנאי המרוץ, נשתמש ב-mutex (מנעול הדדי). Mutex מבטיח שרק תהליכון אחד יוכל להיכנס לקטע קריטי (critical section) בכל רגע נתון. הקטע הקריטי במקרה זה הוא הפעולה `shared_counter++`.\n\nנאתחל משתנה `pthread_mutex_t`, ננעל אותו לפני הקטע הקריטי ונשחרר אותו אחריו.\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n\nint shared_counter = 0;\npthread_mutex_t counter_mutex; // הצהרה על mutex\n\nvoid* increment_thread_safe(void* arg) {\n    for (int i = 0; i < 100000; i++) {\n        pthread_mutex_lock(&counter_mutex); // נעל את המוטקס\n        shared_counter++;                   // קטע קריטי מוגן\n        pthread_mutex_unlock(&counter_mutex); // שחרר את המוטקס\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid[2];\n    \n    // אתחול המוטקס\n    pthread_mutex_init(&counter_mutex, NULL);\n    \n    // יצירת התהליכונים\n    pthread_create(&tid[0], NULL, increment_thread_safe, NULL);\n    pthread_create(&tid[1], NULL, increment_thread_safe, NULL);\n    \n    // המתנה לסיום התהליכונים\n    pthread_join(tid[0], NULL);\n    pthread_join(tid[1], NULL);\n    \n    printf(\"Final counter value: %d\\n\", shared_counter);\n    \n    // השמדת המוטקס\n    pthread_mutex_destroy(&counter_mutex);\n    \n    return 0;\n}\n```\nבפתרון זה, בכל פעם שתהליכון רוצה לגשת ל-`shared_counter`, הוא מנסה לנעול את `counter_mutex`. אם המוטקס כבר נעול על ידי תהליכון אחר, התהליכון הנוכחי ימתין עד שהמוטקס ישוחרר. לאחר שהפעולה `shared_counter++` הסתיימה, המוטקס משוחרר, ומאפשר לתהליכון אחר לגשת לקטע הקריטי. כך מובטח שרק תהליכון אחד מבצע את ההגדלה בכל רגע נתון, והתוצאה הסופית תהיה נכונה (200,000 במקרה זה)."}, "difficulty_estimation": "Easy", "_source_file": "0241__Mutexes__Open__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:12:37", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Mutexes", "Synchronization", "Race Conditions"], "content": {"text": "נתונה תוכנית C בה מספר חוטים (threads) מנסים לעדכן מונה גלובלי משותף (global shared counter) במקביל. קוד התוכנית מוצג מטה.\nהסבירו מדוע קוד זה עלול להוביל לתוצאות שגויות, והציעו פתרון לבעיה באמצעות שימוש במוטקס (mutex) על ידי הצגת הקוד המתוקן במלואו.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 100000\n\nlong long global_counter = 0;\n\nvoid *thread_function(void *arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; i++) {\n        global_counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    for (int i = 0; i < NUM_THREADS; i++) {\n        pthread_create(&threads[i], NULL, thread_function, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %lld\\n\", global_counter);\n    printf(\"Expected value: %lld\\n\", (long long)NUM_THREADS * INCREMENTS_PER_THREAD);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הבעיה בקוד המקורי היא תנאי מירוץ (race condition). מספר חוטים ניגשים ומשנים את המשתנה המשותף `global_counter` בו זמנית. הפעולה `global_counter++` אינה אטומית; היא מורכבת מקריאת הערך הנוכחי, הגדלתו באחד, וכתיבת הערך החדש בחזרה. אם שני חוטים או יותר מנסים לבצע פעולה זו במקביל, ייתכן שחוט אחד יקרא את הערך, חוט שני יקרא את אותו ערך לפני שהחוט הראשון הספיק לכתוב את הערך המוגדל, ושניהם יגדילו את אותו ערך ויכתבו אותו בחזרה, מה שיוביל לאובדן עדכונים ולתוצאה סופית שגויה (נמוכה מהצפוי).\n\nכדי לפתור את תנאי המירוץ, נשתמש במוטקס (mutex) כדי להבטיח שרק חוט אחד יוכל לגשת לקטע הקריטי (העדכון של `global_counter`) בכל רגע נתון. המוטקס יגן על המשתנה המשותף. לפני עדכון המונה, כל חוט ינעל את המוטקס באמצעות `pthread_mutex_lock`. לאחר העדכון, החוט ישחרר את המוטקס באמצעות `pthread_mutex_unlock`. בנוסף, יש לאתחל את המוטקס לפני השימוש ולשחרר את המשאבים שלו בסיום.\n\nהקוד המתוקן:\n```c\n#include <stdio.h>\n#include <pthread.h>\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 100000\n\nlong long global_counter = 0;\npthread_mutex_t counter_mutex; // הצהרה על מוטקס\n\nvoid *thread_function(void *arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; i++) {\n        pthread_mutex_lock(&counter_mutex); // נעילת המוטקס\n        global_counter++;\n        pthread_mutex_unlock(&counter_mutex); // שחרור המוטקס\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    pthread_mutex_init(&counter_mutex, NULL); // אתחול המוטקס\n\n    for (int i = 0; i < NUM_THREADS; i++) {\n        pthread_create(&threads[i], NULL, thread_function, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %lld\\n\", global_counter);\n    printf(\"Expected value: %lld\\n\", (long long)NUM_THREADS * INCREMENTS_PER_THREAD);\n\n    pthread_mutex_destroy(&counter_mutex); // שחרור משאבי המוטקס\n\n    return 0;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0242__Mutexes__Open__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:12:58", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Mutexes", "Synchronization", "Concurrency"], "content": {"text": "הסבירו את מטרתו של mutex בתכנות מקבילי. ספקו דוגמת קוד פשוטה ב-C/C++ המדגימה כיצד להשתמש ב-mutex כדי להגן על משתנה גלובלי משותף מפני תנאי מירוץ (race conditions).", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "מטרתו העיקרית של mutex (קיצור של Mutual Exclusion) היא להבטיח שרק תהליך או תהליכון אחד יגש לקטע קוד קריטי (critical section) או למשאב משותף בזמן נתון. זה מונע תנאי מירוץ (race conditions) ומוודא עקביות נתונים בסביבה מקבילית. כאשר תהליכון רוצה לגשת למשאב מוגן, הוא מנסה 'לנעול' את ה-mutex (באמצעות `mtx.lock()`). אם ה-mutex פנוי, הוא ננעל והתהליכון ממשיך. אם ה-mutex כבר נעול על ידי תהליכון אחר, התהליכון המבקש ממתין עד שה-mutex ישוחרר. לאחר סיום השימוש במשאב, התהליכון 'משחרר' את ה-mutex (באמצעות `mtx.unlock()`).\n\nדוגמת קוד המדגימה שימוש ב-mutex להגנה על משתנה גלובלי משותף:\n```cpp\n#include <iostream>\n#include <thread>\n#include <mutex>\n\n// משתנה גלובלי משותף\nint shared_counter = 0;\n\n// Mutex להגנה על shared_counter\nstd::mutex mtx;\n\nvoid increment_counter() {\n    for (int i = 0; i < 100000; ++i) {\n        mtx.lock(); // נעל את ה-mutex\n        shared_counter++; // קטע קריטי\n        mtx.unlock(); // שחרר את ה-mutex\n    }\n}\n\nint main() {\n    // צור מספר תהליכונים\n    std::thread t1(increment_counter);\n    std::thread t2(increment_counter);\n\n    // המתן לסיום התהליכונים\n    t1.join();\n    t2.join();\n\n    // הדפס את הערך הסופי\n    std::cout << \"Final counter value: \" << shared_counter << std::endl;\n\n    return 0;\n}\n```\nבדוגמה זו, שני תהליכונים `t1` ו-`t2` מנסים להגדיל משתנה גלובלי `shared_counter` במקביל. ללא ה-mutex, קיימת סבירות גבוהה לתנאי מירוץ ולערך סופי שגוי של `shared_counter`. השימוש ב-`mtx.lock()` ו-`mtx.unlock()` מבטיח שרק תהליכון אחד יגדיל את המונה בכל רגע נתון, ובכך מונע תנאי מירוץ ומבטיח שהערך הסופי יהיה נכון (200,000 במקרה זה)."}, "difficulty_estimation": "Easy", "_source_file": "0243__Mutexes__Open__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:13:15", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Mutexes", "Synchronization", "Concurrency"], "content": {"text": "מהו Mutex (מנעול הדדי) בהקשר של מערכות הפעלה ותכנות מקבילי? הסבר את מטרתו העיקרית ואת שתי הפעולות הבסיסיות הקשורות אליו. מדוע הוא חיוני בתוכניות מרובות חוטים?", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "Mutex (מנעול הדדי) הוא אובייקט סנכרון המשמש בתכנות מקבילי כדי לאכוף בלעדיות הדדית (mutual exclusion) על משאב משותף או קטע קוד קריטי. מטרתו העיקרית היא למנוע תנאי מרוץ (race conditions) ולהבטיח שרק חוט אחד (thread) יוכל לגשת למשאב המוגן בכל רגע נתון.\n\nשתי הפעולות הבסיסיות הקשורות ל-Mutex הן:\n1.  **lock()** (או `acquire()` / `wait()`): כאשר חוט מעוניין לגשת לקטע קוד קריטי או למשאב משותף המוגן על ידי Mutex, הוא מנסה לרכוש את המנעול באמצעות פעולה זו. אם המנעול פנוי, החוט רוכש אותו וממשיך בביצוע. אם המנעול כבר מוחזק על ידי חוט אחר, החוט הנוכחי נחסם (מושהה) וממתין עד שהמנעול ישוחרר.\n2.  **unlock()** (או `release()` / `signal()`): לאחר שחוט סיים את עבודתו עם המשאב המוגן, הוא משחרר את המנעול באמצעות פעולה זו. שחרור המנעול מאפשר לחוטים אחרים הממתינים לרכוש אותו ולהמשיך בביצוע.\n\nMutexים חיוניים בתוכניות מרובות חוטים מכיוון שללא מנגנון סנכרון כזה, גישה בו-זמנית של מספר חוטים לנתונים משותפים עלולה להוביל לחוסר עקביות בנתונים, לתוצאות שגויות ולבאגים קשים לאיתור (תנאי מרוץ). Mutex מבטיח שהנתונים יישארו עקביים ובמצב תקין על ידי מתן גישה מבוקרת ובלעדית לנתונים אלו."}, "difficulty_estimation": "Easy", "_source_file": "0244__Mutexes__Open__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:13:24", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Mutexes", "Synchronization", "Race Conditions"], "content": {"text": "מהו Mutex ומדוע הוא נחוץ במערכות מרובות חוטים? הסבר כיצד Mutex פועל כדי למנוע תנאי מירוץ. הצג דוגמת קוד פשוטה ב-C/C++ הממחישה שימוש ב-Mutex להגנה על מונה משותף המעודכן על ידי מספר חוטים.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "Mutex (קיצור של Mutual Exclusion) הוא מנגנון סנכרון המשמש במערכות מרובות חוטים (multi-threaded) כדי להבטיח שרק חוט אחד יוכל לגשת לקטע קוד קריטי או למשאב משותף (כמו משתנה גלובלי, קובץ, או מבנה נתונים) בכל רגע נתון. זה מונע 'תנאי מירוץ' (race conditions) שבהם סדר הגישה הלא מבוקר של חוטים מרובים למשאב משותף יכול להוביל לתוצאות שגויות או בלתי צפויות. Mutex פועל על ידי מתן 'נעילה' (lock) לחוט המבקש לגשת למשאב. אם המשאב נעול, חוטים אחרים המנסים לגשת אליו ימתינו עד שהחוט הנוכחי ישחרר את הנעילה (unlock).\n\nדוגמת קוד ב-C/C++ הממחישה שימוש ב-Mutex להגנה על מונה משותף:\n\n```c\n#include <iostream>\n#include <pthread.h>\n#include <vector>\n\n// משאב משותף\nint shared_counter = 0;\n\n// Mutex להגנה על המונה המשותף\npthread_mutex_t counter_mutex;\n\n// פונקציית החוט\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < 100000; ++i) {\n        // נעל את המוטקס לפני הגישה לקטע הקריטי\n        pthread_mutex_lock(&counter_mutex);\n        shared_counter++; // קטע קריטי\n        // שחרר את המוטקס לאחר סיום הגישה לקטע הקריטי\n        pthread_mutex_unlock(&counter_mutex);\n    }\n    return NULL;\n}\n\nint main() {\n    // אתחול המוטקס\n    pthread_mutex_init(&counter_mutex, NULL);\n\n    const int NUM_THREADS = 5;\n    std::vector<pthread_t> threads(NUM_THREADS);\n\n    // יצירת והפעלת החוטים\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, increment_counter, NULL);\n    }\n\n    // המתנה לסיום כל החוטים\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    // השמדת המוטקס\n    pthread_mutex_destroy(&counter_mutex);\n\n    // הדפסת הערך הסופי של המונה המשותף\n    std::cout << \"Final shared counter value: \" << shared_counter << std::endl;\n    // הערך הצפוי הוא 5 * 100000 = 500000\n\n    return 0;\n}\n```\nבדוגמה זו, `pthread_mutex_lock` מבטיח שרק חוט אחד יכול להיכנס לקטע שבו `shared_counter` מוגדל. חוטים אחרים שינסו לקרוא ל-`pthread_mutex_lock` כאשר המוטקס כבר נעול, ימתינו עד שהמוטקס ישוחרר על ידי `pthread_mutex_unlock`."}, "difficulty_estimation": "Easy", "_source_file": "0245__Mutexes__Open__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:13:37", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Mutexes", "Synchronization", "Concurrency", "Threads"], "content": {"text": "הסבר/י בקצרה מהו Mutex (מנעול הדדי) ומה מטרתו העיקרית בתכנות מקבילי.\nהדגם/הדגימי באמצעות קטע קוד פשוט ב-C/C++ כיצד ניתן להשתמש ב-Mutex כדי להגן על משאב משותף (לדוגמה, מונה גלובלי) מפני תנאי מירוץ (Race Condition) כאשר מספר תהליכונים (threads) מנסים לגשת אליו ולעדכן אותו בו זמנית.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "Mutex (מנעול הדדי) הוא אובייקט סנכרון בסיסי המשמש להבטחת בלעדיות הדדית (mutual exclusion) בגישה למשאבים משותפים (כמו משתנים גלובליים, מבני נתונים, קבצים ועוד) בסביבת ריבוי תהליכונים (multi-threading).\nמטרתו העיקרית היא למנוע תנאי מירוץ (Race Conditions), מצב שבו מספר תהליכונים ניגשים למשאב משותף בו-זמנית, ולפחות אחד מהם מבצע שינוי, מה שעלול להוביל לתוצאות בלתי צפויות ולא עקביות.\nMutex מבטיח שרק תהליכון אחד יכול \"לנעול\" (lock) את המשאב, לגשת אליו ולבצע עליו פעולות, ולאחר מכן \"לשחרר\" (unlock) אותו. כל תהליכון אחר שינסה לנעול את ה-Mutex כשהוא כבר נעול ימתין עד שהתהליכון הנוכחי ישחרר אותו.\n\nדוגמה לקטע קוד ב-C/C++ המשתמש ב-Mutex להגנה על מונה גלובלי:\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#define NUM_THREADS 5\n#define ITERATIONS_PER_THREAD 100000\n\nint shared_counter = 0;\npthread_mutex_t counter_mutex;\n\n// פונקציית התהליכון המגדילה את המונה המשותף\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < ITERATIONS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&counter_mutex); // נעל את ה-Mutex לפני גישה למשאב המשותף\n        shared_counter++; // אזור קריטי: גישה למשתנה משותף\n        pthread_mutex_unlock(&counter_mutex); // שחרר את ה-Mutex לאחר סיום הגישה\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    // אתחול ה-Mutex\n    if (pthread_mutex_init(&counter_mutex, NULL) != 0) {\n        fprintf(stderr, \"Mutex init failed\\n\");\n        return 1;\n    }\n\n    // יצירת תהליכונים\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        if (pthread_create(&threads[i], NULL, increment_counter, NULL) != 0) {\n            fprintf(stderr, \"Thread creation failed\\n\");\n            return 1;\n        }\n    }\n\n    // המתנה לסיום כל התהליכונים\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    // השמדת ה-Mutex (שחרור משאבי מערכת)\n    pthread_mutex_destroy(&counter_mutex);\n\n    printf(\"Final shared_counter value: %d\\n\", shared_counter);\n    printf(\"Expected value: %d\\n\", NUM_THREADS * ITERATIONS_PER_THREAD);\n\n    return 0;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0246__Mutexes__Open__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:13:59", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Mutexes", "Synchronization", "Race Conditions"], "content": {"text": "הסבר בקצרה מהו Mutex ומדוע הוא נחוץ במערכות מרובות תהליכונים (multithreaded systems). לאחר מכן, נתון קטע קוד המכיל משתנה גלובלי משותף. הוסף לקטע הקוד שימוש ב-Mutex על מנת להבטיח גישה בטוחה למשתנה המשותף ולמנוע תנאי מרוץ (race conditions).", "code_snippet": "```c\n#include <stdio.h>\n#include <pthread.h>\n\nint global_counter = 0;\n\nvoid* increment_thread(void* arg) {\n    for (int i = 0; i < 100000; ++i) {\n        // קטע קריטי: הגדלת global_counter\n        global_counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_create(&tid1, NULL, increment_thread, NULL);\n    pthread_create(&tid2, NULL, increment_thread, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    printf(\"Final counter value: %d\\n\", global_counter);\n\n    return 0;\n}\n```", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "Mutex (קיצור של Mutual Exclusion) הוא מנגנון סנכרון המשמש להגנה על משאבים משותפים במערכות מרובות תהליכונים. מטרתו העיקרית היא למנוע תנאי מרוץ (race conditions) שבהם גישה סימולטנית למשאב משותף עלולה להוביל לתוצאות בלתי צפויות או שגויות. Mutex מבטיח שרק תהליכון אחד יוכל לגשת לקטע קריטי (critical section) של קוד בו מעורב המשאב המשותף בכל רגע נתון. כאשר תהליכון רוצה לגשת למשאב, הוא נועל את ה-mutex. אם ה-mutex כבר נעול על ידי תהליכון אחר, התהליכון המבקש ימתין עד שה-mutex ישוחרר. לאחר סיום השימוש במשאב, התהליכון משחרר את ה-mutex, ומאפשר לתהליכונים אחרים לגשת אליו.\n\nלהלן קטע הקוד המתוקן עם שימוש ב-Mutex:\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n\nint global_counter = 0;\npthread_mutex_t counter_mutex; // הגדרת Mutex\n\nvoid* increment_thread(void* arg) {\n    for (int i = 0; i < 100000; ++i) {\n        pthread_mutex_lock(&counter_mutex); // נעילת Mutex לפני הכניסה לקטע הקריטי\n        global_counter++; // קטע קריטי\n        pthread_mutex_unlock(&counter_mutex); // שחרור Mutex לאחר היציאה מהקטע הקריטי\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&counter_mutex, NULL); // אתחול Mutex\n\n    pthread_create(&tid1, NULL, increment_thread, NULL);\n    pthread_create(&tid2, NULL, increment_thread, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    pthread_mutex_destroy(&counter_mutex); // השמדת Mutex\n\n    printf(\"Final counter value: %d\\n\", global_counter);\n\n    return 0;\n}\n```\n\nבמימוש המתוקן, המשתנה `counter_mutex` מוגדר כ- `pthread_mutex_t`. לפני יצירת התהליכונים, ה-mutex מאותחל באמצעות `pthread_mutex_init`. בתוך הפונקציה `increment_thread`, קריאות ל-`pthread_mutex_lock` ו-`pthread_mutex_unlock` עוטפות את הקטע הקריטי (`global_counter++`). זה מבטיח שרק תהליכון אחד יכול לגשת ל-`global_counter` בכל רגע נתון, ובכך מונע תנאי מרוץ ומבטיח שהערך הסופי של המונה יהיה נכון (200000 במקרה זה). בסיום התוכנית, ה-mutex מושמד באמצעות `pthread_mutex_destroy`."}, "difficulty_estimation": "Easy", "_source_file": "0247__Mutexes__Open__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:14:10", "_subject": "Concurrency"}, {"id": 100, "type": "Open", "topic": ["Mutexes", "Synchronization", "Race Conditions"], "content": {"text": "מהו מנעול הדדי (Mutex) ומה מטרתו העיקרית בתכנות מקבילי? הסבר כיצד שימוש במנעול הדדי יכול למנוע תנאי מירוץ (race conditions) כאשר מספר תהליכים או תהליכונים ניגשים למשאב משותף.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "מנעול הדדי (Mutex) הוא אובייקט סנכרון המשמש להבטחת גישה בלעדית למשאב משותף (critical section) בזמן נתון. מטרתו העיקרית היא למנוע תנאי מירוץ (race conditions), מצב שבו תוצאת הפעלת התוכנית תלויה בסדר הלא צפוי שבו תהליכים או תהליכונים ניגשים ומשנים נתונים משותפים.\n\nכאשר תהליך/תהליכון רוצה לגשת למשאב משותף, הוא מנסה לנעול את המוטקס (acquire/lock). אם המוטקס אינו נעול, התהליך/תהליכון נועל אותו ומקבל גישה בלעדית למשאב. אם המוטקס כבר נעול על ידי תהליך/תהליכון אחר, התהליך/תהליכון המנסה לנעול ימתין עד שהמוטקס ישוחרר. לאחר שהתהליך/תהליכון מסיים את השימוש במשאב המשותף, הוא משחרר את המוטקס (release/unlock), ובכך מאפשר לתהליכים/תהליכונים אחרים לגשת למשאב. מנגנון זה מבטיח שבכל רגע נתון, רק תהליך/תהליכון אחד יכול לגשת לאזור הקריטי, ובכך מונע תנאי מירוץ ומשמר את עקביות הנתונים.", "code_snippet": null}, "difficulty_estimation": "Easy", "_source_file": "0248__Mutexes__Open__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:14:20", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Mutexes", "Deadlocks", "Synchronization"], "content": {"text": "נתונה תוכנית המשתמשת בשני חוטים (threads) ובשני משאבים (resources), R1 ו-R2, שכל אחד מהם מוגן על ידי מנעול (mutex) משלו, `mutex_R1` ו-`mutex_R2` בהתאמה. כל חוט צריך לגשת לשני המשאבים כדי לבצע את פעולתו. הקוד הבא מציג את לוגיקת הגישה למשאבים עבור שני החוטים:\n\n```c\npthread_mutex_t mutex_R1;\npthread_mutex_t mutex_R2;\n\nvoid* thread_func1(void* arg) {\n    pthread_mutex_lock(&mutex_R1);\n    // Do something with R1\n    pthread_mutex_lock(&mutex_R2);\n    // Do something with R1 and R2\n    pthread_mutex_unlock(&mutex_R2);\n    pthread_mutex_unlock(&mutex_R1);\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    pthread_mutex_lock(&mutex_R2);\n    // Do something with R2\n    pthread_mutex_lock(&mutex_R1);\n    // Do something with R1 and R2\n    pthread_mutex_unlock(&mutex_R1);\n    pthread_mutex_unlock(&mutex_R2);\n    return NULL;\n}\n\nint main() {\n    pthread_mutex_init(&mutex_R1, NULL);\n    pthread_mutex_init(&mutex_R2, NULL);\n\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, thread_func1, NULL);\n    pthread_create(&t2, NULL, thread_func2, NULL);\n\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n\n    pthread_mutex_destroy(&mutex_R1);\n    pthread_mutex_destroy(&mutex_R2);\n    return 0;\n}\n```\n\nהאם קיים סיכון לקיפאון (deadlock) בתוכנית זו? אם כן, הסבירו בפירוט מדוע וכיצד ניתן למנוע אותו. אם לא, הסבירו מדוע.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, קיים סיכון לקיפאון (deadlock) בתוכנית זו. קיפאון יתרחש כאשר כל אחד מהחוטים יחזיק במנעול אחד וימתין למנעול השני, שמוחזק על ידי החוט האחר.\n\nהסבר מפורט: ארבעת התנאים לקיפאון מתקיימים במקרה זה:\n1.  **הדרה הדדית (Mutual Exclusion)**: כל מנעול (`mutex_R1`, `mutex_R2`) מגן על משאב אחד ורק חוט אחד יכול להחזיק בו בזמן נתון. תנאי זה מתקיים.\n2.  **החזקה והמתנה (Hold and Wait)**: חוט יכול להחזיק במנעול אחד (לדוגמה, `thread_func1` מחזיק ב-`mutex_R1`) ובמקביל להמתין למנעול אחר (לדוגמה, `thread_func1` ממתין ל-`mutex_R2`). תנאי זה מתקיים.\n3.  **אי-נשללות (No Preemption)**: לא ניתן לשלול מנעול מחוט שמחזיק בו בכוח. המנעול ישוחרר רק מרצון על ידי החוט שמחזיק בו. תנאי זה מתקיים.\n4.  **המתנה מעגלית (Circular Wait)**: קיים מעגל של המתנה. `thread_func1` מחזיק ב-`mutex_R1` וממתין ל-`mutex_R2`. במקביל, `thread_func2` מחזיק ב-`mutex_R2` וממתין ל-`mutex_R1`. נוצר מעגל שבו כל חוט ממתין למשאב שמוחזק על ידי החוט האחר. תנאי זה מתקיים.\n\nתרחיש לדוגמה לקיפאון:\n1.  `thread_func1` מבצע `pthread_mutex_lock(&mutex_R1)` ומצליח לרכוש את `mutex_R1`.\n2.  `thread_func2` מבצע `pthread_mutex_lock(&mutex_R2)` ומצליח לרכוש את `mutex_R2`.\n3.  `thread_func1` מנסה לבצע `pthread_mutex_lock(&mutex_R2)` אך נחסם, מכיוון ש-`mutex_R2` מוחזק על ידי `thread_func2`.\n4.  `thread_func2` מנסה לבצע `pthread_mutex_lock(&mutex_R1)` אך נחסם, מכיוון ש-`mutex_R1` מוחזק על ידי `thread_func1`.\nבשלב זה, שני החוטים חסומים באופן הדדי ואינם יכולים להמשיך, והתוכנית נמצאת בקיפאון.\n\nמניעת קיפאון:\nהדרך הנפוצה למנוע קיפאון זה היא על ידי אכיפת סדר עולמי קבוע לרכישת המנעולים. כלומר, כל החוטים המעורבים חייבים לרכוש את המנעולים באותו סדר. במקרה זה, ניתן להחליט ש-`mutex_R1` תמיד יירכש לפני `mutex_R2`.\n\nדוגמה לתיקון ב-`thread_func2`:\n```c\nvoid* thread_func2_fixed(void* arg) {\n    pthread_mutex_lock(&mutex_R1); // סדר רכישה אחיד: קודם R1\n    pthread_mutex_lock(&mutex_R2); // ואז R2\n    // Do something with R1 and R2\n    pthread_mutex_unlock(&mutex_R2);\n    pthread_mutex_unlock(&mutex_R1);\n    return NULL;\n}\n```\nעם שינוי זה, שני החוטים ינסו לרכוש קודם את `mutex_R1`. רק אחד מהם יצליח, ולאחר מכן ימשיך לרכוש את `mutex_R2`. לאחר שיסיים את העבודה וישחרר את שני המנעולים, החוט השני יוכל להמשיך. באופן זה, תנאי ההמתנה המעגלית נמנע."}, "difficulty_estimation": "Medium", "_source_file": "0249__Mutexes__Open__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:14:41", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Mutexes", "Synchronization", "Deadlocks"], "content": {"text": "הסבר את ההבדל בין mutex רגיל (שאינו רקורסיבי) לבין mutex רקורסיבי. כתוב קטע קוד ב-C שבו שימוש ב-mutex רגיל יוביל לקיפאון (deadlock), אך שימוש ב-mutex רקורסיבי יפתור את הבעיה. הסבר בפירוט מדוע קטע הקוד גורם לקיפאון עם mutex רגיל וכיצד mutex רקורסיבי פותר זאת.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n\n// הגדרת mutex גלובלי\npthread_mutex_t my_mutex;\n\n// פונקציה פנימית המנסה לנעול את ה-mutex\nvoid inner_function() {\n    printf(\"Inner function: Trying to lock mutex...\\n\");\n    pthread_mutex_lock(&my_mutex); // ניסיון נעילה שני על אותו mutex\n    printf(\"Inner function: Mutex locked. Doing work...\\n\");\n    // סימולציה של עבודה\n    pthread_mutex_unlock(&my_mutex);\n    printf(\"Inner function: Mutex unlocked.\\n\");\n}\n\n// פונקציה חיצונית המנסה לנעול את ה-mutex וקוראת לפונקציה הפנימית\nvoid outer_function() {\n    printf(\"Outer function: Trying to lock mutex...\\n\");\n    pthread_mutex_lock(&my_mutex); // ניסיון נעילה ראשון\n    printf(\"Outer function: Mutex locked. Calling inner function...\\n\");\n    inner_function(); // זו תנסה לנעול את אותו mutex שוב\n    printf(\"Outer function: Inner function returned. Doing more work...\\n\");\n    // סימולציה של עבודה נוספת\n    pthread_mutex_unlock(&my_mutex);\n    printf(\"Outer function: Mutex unlocked.\\n\");\n}", "options": null}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ההבדל העיקרי בין mutex רגיל (שאינו רקורסיבי) ל-mutex רקורסיבי טמון באופן שבו הם מטפלים בניסיונות רכישה חוזרים על ידי אותו חוט (thread) שכבר מחזיק ב-mutex.\n\n1.  **Mutex רגיל (PTHREAD_MUTEX_NORMAL):**\n    *   מטרתו העיקרית היא להבטיח בלעדיות הדדית (mutual exclusion) – רק חוט אחד יכול להחזיק בו בזמן נתון.\n    *   אם חוט שכבר מחזיק ב-mutex רגיל מנסה לרכוש אותו שוב (לקרוא ל-`pthread_mutex_lock` עליו), הוא יחסם באופן קבוע (deadlock) או יקבל שגיאה, מכיוון שה-mutex כבר נעול על ידו ואינו מאפשר רכישה חוזרת. אתחול ברירת המחדל של mutex ב-POSIX הוא רגיל: `pthread_mutex_init(&my_mutex, NULL);`\n\n2.  **Mutex רקורסיבי (PTHREAD_MUTEX_RECURSIVE):**\n    *   מאפשר לחוט שכבר מחזיק ב-mutex לרכוש אותו שוב מספר פעמים מבלי להיחסם.\n    *   ה-mutex שומר מונה פנימי של מספר הפעמים שהחוט הנוכחי רכש אותו. כל קריאה ל-`pthread_mutex_lock` מגדילה את המונה, וכל קריאה ל-`pthread_mutex_unlock` מקטינה אותו.\n    *   ה-mutex ישוחרר בפועל (כלומר, יהיה זמין לחוטים אחרים) רק כאשר החוט המחזיק בו יבצע מספר שווה של קריאות `pthread_mutex_unlock` כמספר הקריאות `pthread_mutex_lock` שביצע. אתחול mutex רקורסיבי מתבצע כך:\n        ```c\n        pthread_mutexattr_t attr;\n        pthread_mutexattr_init(&attr);\n        pthread_mutexattr_settype(&attr, PTHREAD_MUTEX_RECURSIVE);\n        pthread_mutex_init(&my_mutex, &attr);\n        pthread_mutexattr_destroy(&attr);\n        ```\n\n**הסבר לקטע הקוד:**\nבקטע הקוד הנתון:\n*   הפונקציה `outer_function` רוכשת את ה-`my_mutex` באמצעות `pthread_mutex_lock(&my_mutex);`\n*   לאחר מכן, `outer_function` קוראת ל-`inner_function`.\n*   הפונקציה `inner_function` מנסה לרכוש את ה-`my_mutex` *שוב* באמצעות `pthread_mutex_lock(&my_mutex);`\n\n**עם mutex רגיל (לאחר אתחול `pthread_mutex_init(&my_mutex, NULL);`):**\n*   כאשר `inner_function` מנסה לנעול את `my_mutex`, ה-mutex כבר נעול על ידי אותו חוט (החוט שמריץ את `outer_function` ואז קורא ל-`inner_function`).\n*   mutex רגיל אינו מאפשר רכישה חוזרת על ידי אותו חוט. לכן, החוט נחסם בניסיון לנעול את ה-mutex, ומכיוון שהוא עצמו מחזיק ב-mutex, הוא לא יוכל לשחרר אותו לעולם. זה מוביל לקיפאון (deadlock) של החוט עם עצמו. התוכנית תיתקע.\n\n**עם mutex רקורסיבי (לאחר אתחול עם `PTHREAD_MUTEX_RECURSIVE`):**\n*   כאשר `inner_function` מנסה לנעול את `my_mutex`, ה-mutex מזהה שהחוט שכבר מחזיק בו מנסה לרכוש אותו שוב.\n*   הפעולה `pthread_mutex_lock` מצליחה, והמונה הפנימי של ה-mutex מוגדל (במקרה זה, מ-1 ל-2).\n*   הפונקציות ממשיכות לפעול כרגיל.\n*   כאשר `inner_function` קוראת ל-`pthread_mutex_unlock`, המונה קטן (מ-2 ל-1).\n*   כאשר `outer_function` קוראת ל-`pthread_mutex_unlock`, המונה קטן שוב (מ-1 ל-0).\n*   רק כשהמונה מגיע ל-0, ה-mutex משוחרר בפועל וחוטים אחרים יכולים לרכוש אותו. במקרה זה, התוכנית תרוץ ללא קיפאון.\n*   לכן, השימוש ב-mutex רקורסיבי פותר את בעיית הקיפאון העצמי במקרה זה."}, "difficulty_estimation": "Medium", "_source_file": "0250__Mutexes__Open__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:15:05", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Mutexes", "Deadlocks", "Synchronization"], "content": {"text": "נתחו את קטע הקוד הבא ב-C++. האם יתכן קיפאון (deadlock) בתוכנית? אם כן, הסבירו מדוע וכיצד ניתן למנוע אותו. אם לא, הסבירו מדוע קיפאון אינו אפשרי.", "code_snippet": "#include <iostream>\n#include <thread>\n#include <mutex>\n#include <chrono>\n\nstd::mutex mutexA;\nstd::mutex mutexB;\n\nint shared_data_A = 0;\nint shared_data_B = 0;\n\nvoid thread_func1() {\n    std::cout << \"Thread 1: Trying to lock mutexA\" << std::endl;\n    mutexA.lock();\n    std::this_thread::sleep_for(std::chrono::milliseconds(100)); // Simulate work\n    std::cout << \"Thread 1: Locked mutexA, trying to lock mutexB\" << std::endl;\n    mutexB.lock();\n    \n    // Critical section\n    shared_data_A++;\n    shared_data_B++;\n    std::cout << \"Thread 1: Acquired both locks. Data A: \" << shared_data_A << \", Data B: \" << shared_data_B << std::endl;\n\n    mutexB.unlock();\n    mutexA.unlock();\n    std::cout << \"Thread 1: Released both locks\" << std::endl;\n}\n\nvoid thread_func2() {\n    std::cout << \"Thread 2: Trying to lock mutexB\" << std::endl;\n    mutexB.lock();\n    std::this_thread::sleep_for(std::chrono::milliseconds(100)); // Simulate work\n    std::cout << \"Thread 2: Locked mutexB, trying to lock mutexA\" << std::endl;\n    mutexA.lock();\n\n    // Critical section\n    shared_data_A++;\n    shared_data_B++;\n    std::cout << \"Thread 2: Acquired both locks. Data A: \" << shared_data_A << \", Data B: \" << shared_data_B << std::endl;\n\n    mutexA.unlock();\n    mutexB.unlock();\n    std::cout << \"Thread 2: Released both locks\" << std::endl;\n}\n\nint main() {\n    std::thread t1(thread_func1);\n    std::thread t2(thread_func2);\n\n    t1.join();\n    t2.join();\n\n    std::cout << \"Final Data A: \" << shared_data_A << \", Final Data B: \" << shared_data_B << std::endl;\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, יתכן קיפאון.\n\nהסבר:\nהקיפאון מתרחש עקב תנאי 'המתנה מעגלית' (Circular Wait) ו'החזקה והמתנה' (Hold and Wait). חוט 1 (thread_func1) מנסה לנעול את mutexA ולאחר מכן את mutexB. חוט 2 (thread_func2) מנסה לנעול את mutexB ולאחר מכן את mutexA.\nתרחיש קיפאון אפשרי הוא שחוט 1 נועל את mutexA וחוט 2 נועל את mutexB. לאחר מכן, חוט 1 מנסה לנעול את mutexB אך נחסם (מכיוון שחוט 2 מחזיק בו), וחוט 2 מנסה לנעול את mutexA אך נחסם (מכיוון שחוט 1 מחזיק בו). שני החוטים חסומים באופן הדדי, כאשר כל אחד מהם מחזיק משאב שהשני דורש, ואינם יכולים להתקדם. זהו קיפאון קלאסי.\n\nפתרון למניעת קיפאון:\nהדרך הנפוצה והיעילה ביותר למנוע קיפאון במצב זה היא להבטיח שכל החוטים ירכשו את המנעולים (mutexes) באותו סדר קבוע. לדוגמה, יש לשנות את thread_func2 כך שגם הוא ירכוש את mutexA לפני mutexB. כלומר, סדר רכישת המנעולים יהיה תמיד mutexA ולאחר מכן mutexB. זה מבטיח שלא ייווצר מצב של המתנה מעגלית."}, "difficulty_estimation": "Medium", "_source_file": "0251__Mutexes__Open__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:15:29", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Mutexes", "Deadlocks", "Synchronization", "Concurrency"], "content": {"text": "נתון קטע הקוד הבא המדמה שני חוטים המנסים לגשת לשני משאבים המוגנים על ידי מוטקסים.\nא. הסבירו מדוע קיים פוטנציאל לקיפאון (deadlock) בקוד זה. פרטו את ארבעת התנאים ההכרחיים לקיום קיפאון והדגימו כיצד הם מתקיימים בתרחיש זה בקוד הנתון.\nב. הציעו פתרון למניעת הקיפאון וכתבו את קטע הקוד המתוקן.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex1 = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_t mutex2 = PTHREAD_MUTEX_INITIALIZER;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 1: Locked mutex1. Trying to lock mutex2...\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 1: Locked mutex2. Critical section...\\n\");\n    // Do some work\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 1: Unlocked mutex2.\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 1: Unlocked mutex1. Exiting.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to lock mutex2...\\n\");\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2: Locked mutex2. Trying to lock mutex1...\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2: Locked mutex1. Critical section...\\n\");\n    // Do some work\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 2: Unlocked mutex1.\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2: Unlocked mutex2. Exiting.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, thread_func1, NULL);\n    pthread_create(&t2, NULL, thread_func2, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n    printf(\"Main: All threads finished.\\n\");\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. פוטנציאל לקיפאון קיים עקב סדר נעילת המוטקסים השונה בין החוטים. אם חוט 1 נועל את mutex1 וחוט 2 נועל את mutex2 בו זמנית (לפני שהשני הספיק לנעול את המוטקס הראשון שלו), שניהם ינסו לנעול את המוטקס שהשני מחזיק, וייכנסו למצב של המתנה אינסופית.\nארבעת התנאים ההכרחיים לקיפאון:\n1.  **מניעה הדדית (Mutual Exclusion):** מתקיים. מוטקס מאפשר גישה למשאב אחד בלבד בכל רגע נתון. אם חוט אחד מחזיק ב-mutex1, חוט אחר לא יכול להשיג אותו.\n2.  **החזק והמתן (Hold and Wait):** מתקיים. חוט 1 מחזיק ב-mutex1 וממתין ל-mutex2. חוט 2 מחזיק ב-mutex2 וממתין ל-mutex1.\n3.  **אי-דריסה (No Preemption):** מתקיים. המוטקסים אינם ניתנים לדריסה (preempt) ורק החוט המחזיק בהם יכול לשחרר אותם.\n4.  **המתנה מעגלית (Circular Wait):** מתקיים. חוט 1 ממתין למשאב (mutex2) המוחזק על ידי חוט 2, וחוט 2 ממתין למשאב (mutex1) המוחזק על ידי חוט 1, ויוצר מעגל המתנה.\n\nב. הפתרון הנפוץ והיעיל למניעת קיפאון במקרה זה הוא אכיפת סדר קבוע וזהה לרכישת המוטקסים (resource ordering) בכל החוטים. לדוגמה, ששני החוטים תמיד ינסו לנעול קודם את mutex1 ואז את mutex2.\n\n**קוד מתוקן:**\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex1 = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_t mutex2 = PTHREAD_MUTEX_INITIALIZER;\n\nvoid* thread_func1_fixed(void* arg) {\n    printf(\"Thread 1: Trying to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1); // נועל קודם את mutex1\n    printf(\"Thread 1: Locked mutex1. Trying to lock mutex2...\\n\");\n    sleep(1); // מדמה עבודה או החלפת הקשר\n    pthread_mutex_lock(&mutex2); // ואז את mutex2\n    printf(\"Thread 1: Locked mutex2. Critical section...\\n\");\n    // Do some work\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 1: Unlocked mutex2.\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 1: Unlocked mutex1. Exiting.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2_fixed(void* arg) {\n    printf(\"Thread 2: Trying to lock mutex1...\\n\"); // גם חוט 2 נועל קודם את mutex1\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2: Locked mutex1. Trying to lock mutex2...\\n\");\n    sleep(1); // מדמה עבודה או החלפת הקשר\n    pthread_mutex_lock(&mutex2); // ואז את mutex2\n    printf(\"Thread 2: Locked mutex2. Critical section...\\n\");\n    // Do some work\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2: Unlocked mutex2.\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 2: Unlocked mutex1. Exiting.\\n\");\n    return NULL;\n}\n\nint main() { \n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, thread_func1_fixed, NULL);\n    pthread_create(&t2, NULL, thread_func2_fixed, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n    printf(\"Main: All threads finished.\\n\");\n    return 0;\n}\n```"}, "difficulty_estimation": "Medium", "_source_file": "0252__Mutexes__Open__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:16:03", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Mutexes", "Condition Variables", "Synchronization", "Producer-Consumer"], "content": {"text": "נתונה בעיית ה-Producer-Consumer, בה מספר יצרנים מוסיפים פריטים למאגר משותף בעל גודל סופי, ומספר צרכנים מוציאים פריטים מהמאגר.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "8.1", "text": "א. נניח שרק Mutex אחד משמש להגנה על המאגר המשותף. הסבר מדוע שימוש ב-Mutex בלבד אינו מספיק לפתרון נכון ויעיל של בעיה זו. תאר תרחישים בהם ייווצרו בעיות.", "code_snippet": null, "options": null}, {"id": "8.2", "text": "ב. תאר כיצד ניתן לשלב Mutex עם Condition Variables (משתני תנאי) כדי לפתור את בעיית ה-Producer-Consumer באופן נכון ויעיל. כלול הסבר על הפעולות העיקריות (wait, signal/broadcast) וכיצד הן עובדות יחד עם ה-Mutex.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון לשאלה 8.1 (סעיף א'):\nשימוש ב-Mutex בלבד אינו מספיק לפתרון בעיית ה-Producer-Consumer מכיוון ש-Mutex מספק רק הגנה על הגישה הקריטית למשאב המשותף (המאגר), אך אינו מאפשר סנכרון מורכב יותר הדורש המתנה על תנאי מסוים. Mutex מאפשר רק חסימה והתעוררות מפורשת של חוטים, אך אינו מאפשר לחוט לישון עד שתנאי מסוים מתקיים.\n\nתרחישים בהם ייווצרו בעיות:\n1.  **צרכן ינסה לצרוך ממאגר ריק:** אם צרכן מנסה להוציא פריט מהמאגר כשהוא ריק, ורק Mutex מגן על הגישה, הצרכן יקבל את ה-Mutex, יגלה שהמאגר ריק, ויאלץ לבצע פעולת busy-waiting (לולאה שבודקת שוב ושוב את מצב המאגר) או לצאת עם שגיאה. busy-waiting מבזבז משאבי מעבד יקרים. בנוסף, אם הצרכן מחזיק ב-Mutex בזמן ה-busy-waiting, הוא מונע מיצרנים לגשת למאגר, ובכך מונע את שינוי המצב (הוספת פריט) שיאפשר לצרכן להמשיך. זה עלול להוביל לקיפאון (deadlock) או לחוסר יעילות קיצוני.\n2.  **יצרן ינסה לייצר למאגר מלא:** באופן דומה, אם יצרן מנסה להכניס פריט למאגר כשהוא מלא, הוא יקבל את ה-Mutex, יגלה שהמאגר מלא, ויאלץ לבצע busy-waiting או לצאת עם שגיאה. גם כאן, החזקת ה-Mutex ב-busy-waiting תמנע מצרכנים לגשת למאגר ולפנות מקום, מה שיוביל לבעיות דומות.\n\nפתרון לשאלה 8.2 (סעיף ב'):\nכדי לפתור את בעיית ה-Producer-Consumer באופן נכון ויעיל, יש לשלב Mutex עם Condition Variables (משתני תנאי).\nה-Mutex ישמש להגנה על הגישה למאגר המשותף ועל משתני המצב שלו (כמו מספר הפריטים במאגר, ראש וזנב המאגר וכו').\nמשתני התנאי ישמשו לאפשר לחוטים להמתין באופן יעיל כאשר תנאי מסוים אינו מתקיים, ולהתעורר כאשר התנאי כן מתקיים, מבלי לבזבז משאבי מעבד ב-busy-waiting.\n\nנשתמש בשני משתני תנאי:\n*   `not_empty`: עבור צרכנים שצריכים להמתין כאשר המאגר ריק.\n*   `not_full`: עבור יצרנים שצריכים להמתין כאשר המאגר מלא.\n\n**התהליך עבור יצרן:**\n1.  היצרן נועל את ה-Mutex כדי להבטיח גישה בלעדית למאגר ולמשתני המצב שלו.\n2.  בתוך לולאה (לטיפול ב-spurious wakeups), היצרן בודק אם המאגר מלא. אם כן, הוא קורא לפעולה `wait(not_full, mutex)`. פעולת `wait` מבצעת באופן אטומי שתי פעולות: היא משחררת את ה-Mutex ומכניסה את החוט למצב שינה, עד שהוא יתעורר על ידי `signal` או `broadcast` על `not_full`. כשהחוט מתעורר, ה-Mutex ננעל מחדש אוטומטית לפני ש-`wait` חוזרת.\n3.  כאשר המאגר אינו מלא, היצרן מוסיף פריט למאגר.\n4.  היצרן קורא לפעולה `signal(not_empty)` (או `broadcast`) כדי להעיר צרכנים שממתינים למאגר שאינו ריק, מכיוון שכעת יש פריט זמין.\n5.  היצרן משחרר את ה-Mutex.\n\n**התהליך עבור צרכן:**\n1.  הצרכן נועל את ה-Mutex כדי להבטיח גישה בלעדית למאגר ולמשתני המצב שלו.\n2.  בתוך לולאה, הצרכן בודק אם המאגר ריק. אם כן, הוא קורא לפעולה `wait(not_empty, mutex)`. פעולה זו מבצעת את אותן פעולות אטומיות כמו אצל היצרן: משחררת את ה-Mutex ומכניסה את החוט למצב שינה, ונועלת את ה-Mutex בחזרה עם ההתעוררות.\n3.  כאשר המאגר אינו ריק, הצרכן מוציא פריט מהמאגר.\n4.  הצרכן קורא לפעולה `signal(not_full)` (או `broadcast`) כדי להעיר יצרנים שממתינים למאגר שאינו מלא, מכיוון שכעת התפנה מקום.\n5.  הצרכן משחרר את ה-Mutex.\n\nהשימוש ב-`wait` בתוך לולאה (לדוגמה `while (buffer_is_full) { wait(not_full, mutex); }`) מבטיח שהתנאי נבדק שוב לאחר ההתעוררות, למקרה שהחוט התעורר מסיבה שאינה קשורה לתנאי (spurious wakeup) או שחוט אחר תפס את המשאב לפניו."}, "difficulty_estimation": "Medium", "_source_file": "0253__Mutexes__Open__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:16:31", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Mutexes", "Synchronization", "Deadlocks", "Concurrency"], "content": {"text": "נתונה תוכנית C++ המשתמשת בשני mutex-ים (mtx1, mtx2) לגישה למשאבים משותפים. קיימים שני תהליכונים (threads) שמנסים לגשת למשאבים אלו. נתח את הקוד הנתון, הסבר מדוע הוא עלול לגרום לקיפאון (deadlock), והצע פתרון לבעיה זו על ידי שינוי מינימלי בקוד, תוך הסבר מדרונותיו של הפתרון.", "code_snippet": "```c++\n#include <iostream>\n#include <thread>\n#include <mutex>\n#include <chrono> // For std::chrono::milliseconds\n\nstd::mutex mtx1;\nstd::mutex mtx2;\n\nvoid thread_func_1() {\n    mtx1.lock();\n    std::cout << \"Thread 1 acquired mtx1\" << std::endl;\n    std::this_thread::sleep_for(std::chrono::milliseconds(100)); // Simulate work\n    mtx2.lock();\n    std::cout << \"Thread 1 acquired mtx2\" << std::endl;\n    // Access shared resources\n    mtx2.unlock();\n    mtx1.unlock();\n    std::cout << \"Thread 1 released mtx1 and mtx2\" << std::endl;\n}\n\nvoid thread_func_2() {\n    mtx2.lock();\n    std::cout << \"Thread 2 acquired mtx2\" << std::endl;\n    std::this_thread::sleep_for(std::chrono::milliseconds(100)); // Simulate work\n    mtx1.lock();\n    std::cout << \"Thread 2 acquired mtx1\" << std::endl;\n    // Access shared resources\n    mtx1.unlock();\n    mtx2.unlock();\n    std::cout << \"Thread 2 released mtx1 and mtx2\" << std::endl;\n}\n\nint main() {\n    std::thread t1(thread_func_1);\n    std::thread t2(thread_func_2);\n\n    t1.join();\n    t2.join();\n\n    std::cout << \"Main finished\" << std::endl;\n    return 0;\n}\n```", "options": null}, "sub_questions": null, "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הקוד הנתון עלול לגרום לקיפאון (deadlock) מכיוון שמתקיימים בו ארבעת התנאים לקיפאון:\n1.  **Mutual Exclusion (מניעה הדדית):** Mutex-ים מטבעם אוכפים מניעה הדדית – רק חוט אחד יכול להחזיק ב-mutex מסוים בכל רגע נתון.\n2.  **Hold and Wait (החזק והמתן):** כל אחד מהתהליכונים מחזיק ב-mutex אחד (T1 מחזיק ב-mtx1, T2 מחזיק ב-mtx2) וממתין לרכישת ה-mutex השני.\n3.  **No Preemption (אי-השתלטות):** לא ניתן לקחת mutex מחוט שמחזיק בו בכוח.\n4.  **Circular Wait (המתנה מעגלית):** T1 ממתין ל-mtx2 שמוחזק על ידי T2, ו-T2 ממתין ל-mtx1 שמוחזק על ידי T1. זהו מעגל המתנה.\n\n**תרחיש לדוגמה לקיפאון:**\n1.  T1 רוכש את `mtx1`.\n2.  T2 רוכש את `mtx2`.\n3.  T1 מנסה לרכוש את `mtx2` ונחסם, כי `mtx2` מוחזק על ידי T2.\n4.  T2 מנסה לרכוש את `mtx1` ונחסם, כי `mtx1` מוחזק על ידי T1.\nשני התהליכונים חסומים זה לזה ולא יוכלו להתקדם, מה שמוביל לקיפאון.\n\n**פתרון מוצע:**\nהפתרון הנפוץ והפשוט ביותר לבעיה זו הוא לוודא שכל התהליכונים רוכשים את ה-mutex-ים באותו סדר. על ידי אכיפת סדר רכישה עקבי (לדוגמה, תמיד `mtx1` ואז `mtx2`), אנו מבטלים את תנאי ה'המתנה מעגלית'.\n\n**שינוי קוד מוצע (שינוי בפונקציה `thread_func_2` בלבד):**\nיש לשנות את הפונקציה `thread_func_2` כך שתבצע את רכישת ה-mutex-ים באותו סדר כמו `thread_func_1`.\nהקוד המתוקן עבור `thread_func_2` ייראה כך:\n```c++\nvoid thread_func_2() {\n    mtx1.lock(); // רכוש mtx1 קודם, כמו ב-thread_func_1\n    std::cout << \"Thread 2 acquired mtx1\" << std::endl;\n    std::this_thread::sleep_for(std::chrono::milliseconds(100));\n    mtx2.lock(); // לאחר מכן רכוש mtx2\n    std::cout << \"Thread 2 acquired mtx2\" << std::endl;\n    // Access shared resources\n    mtx2.unlock();\n    mtx1.unlock();\n    std::cout << \"Thread 2 released mtx1 and mtx2\" << std::endl;\n}\n```\n\n**הסבר על הפתרון:**\nבפתרון זה, שני התהליכונים מנסים לרכוש את `mtx1` קודם, ורק לאחר מכן את `mtx2`. אם T1 רוכש את `mtx1`, אז T2 ייחסם בניסיון לרכוש את `mtx1` עד ש-T1 ישחרר אותו. T1 ימשיך לרכוש את `mtx2`, יבצע את עבודתו וישחרר את שני ה-mutex-ים. רק לאחר ש-T1 ישחרר את `mtx1`, T2 יוכל לרכוש אותו, ולאחר מכן את `mtx2`, ולהמשיך בעבודתו. מצב של המתנה מעגלית נמנע מכיוון שלא יתכן מצב שבו T1 מחכה ל-mtx2 שמוחזק על ידי T2, ובו זמנית T2 מחכה ל-mtx1 שמוחזק על ידי T1 – שניהם תמיד ינסו לרכוש את `mtx1` ראשון, מה ששובר את המעגל."}, "difficulty_estimation": "Medium", "_source_file": "0254__Mutexes__Open__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:16:50", "_subject": "Concurrency"}, {"id": 101, "type": "Open", "topic": ["Mutexes", "Deadlocks", "Synchronization"], "content": {"text": "נתונה פיסת קוד הכוללת שימוש בשני mutex-ים. שני חוטים (threads) מריצים את הפונקציה `do_work` כאשר כל חוט מקבל ערך שונה עבור `id`.\nהאם קיים תרחיש שעלול להוביל לקיפאון (deadlock) בתוכנית זו?\nאם כן, תאר/י תרחיש כזה והסבר/י מדוע הוא מוביל לקיפאון, וכיצד ניתן למנוע אותו.\nאם לא, הסבר/י מדוע קיפאון אינו אפשרי.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex1 = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_t mutex2 = PTHREAD_MUTEX_INITIALIZER;\n\nvoid* do_work(void* arg) {\n    int id = *(int*)arg;\n\n    if (id == 0) {\n        pthread_mutex_lock(&mutex1);\n        printf(\"Thread %d acquired mutex1\\n\", id);\n        sleep(1); // Simulate work or context switch\n        pthread_mutex_lock(&mutex2);\n        printf(\"Thread %d acquired mutex2\\n\", id);\n        // Critical section\n        printf(\"Thread %d in critical section\\n\", id);\n        pthread_mutex_unlock(&mutex2);\n        pthread_mutex_unlock(&mutex1);\n        printf(\"Thread %d released both mutexes\\n\", id);\n    } else { // id == 1\n        pthread_mutex_lock(&mutex2);\n        printf(\"Thread %d acquired mutex2\\n\", id);\n        sleep(1); // Simulate work or context switch\n        pthread_mutex_lock(&mutex1);\n        printf(\"Thread %d acquired mutex1\\n\", id);\n        // Critical section\n        printf(\"Thread %d in critical section\\n\", id);\n        pthread_mutex_unlock(&mutex1);\n        pthread_mutex_unlock(&mutex2);\n        printf(\"Thread %d released both mutexes\\n\", id);\n    }\n    return NULL;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, קיים תרחיש שיוביל לקיפאון (deadlock) בתוכנית זו.\n\n**תיאור התרחיש לקיפאון:**\n1.  חוט 0 (עם `id = 0`) מבצע `pthread_mutex_lock(&mutex1)` ומצליח לרכוש את `mutex1`.\n2.  מתרחש מיתוג הקשר (context switch).\n3.  חוט 1 (עם `id = 1`) מבצע `pthread_mutex_lock(&mutex2)` ומצליח לרכוש את `mutex2`.\n4.  מתרחש מיתוג הקשר (או שחוט 1 ממשיך לרוץ).\n5.  חוט 0 מנסה כעת לבצע `pthread_mutex_lock(&mutex2)`. אך `mutex2` מוחזק כרגע על ידי חוט 1, ולכן חוט 0 נחסם וממתין לשחרורו.\n6.  חוט 1 מנסה כעת לבצע `pthread_mutex_lock(&mutex1)`. אך `mutex1` מוחזק כרגע על ידי חוט 0, ולכן חוט 1 נחסם וממתין לשחרורו.\n\nבשלב זה, שני החוטים חסומים באופן הדדי: חוט 0 ממתין לחוט 1 שישחרר את `mutex2`, וחוט 1 ממתין לחוט 0 שישחרר את `mutex1`. אף אחד מהם לא יכול להמשיך, ולכן נוצר קיפאון.\n\n**הסבר מדוע הוא מוביל לקיפאון (בהתבסס על ארבעת התנאים של Coffman):**\n1.  **Mutual Exclusion (הדרה הדדית):** Mutex-ים מטבעם אוכפים הדרה הדדית; רק חוט אחד יכול להחזיק ב-mutex מסוים בכל רגע נתון. תנאי זה מתקיים.\n2.  **Hold and Wait (החזקה והמתנה):** כל חוט מחזיק במשאב אחד (mutex) בזמן שהוא ממתין לרכישת משאב נוסף. חוט 0 מחזיק ב-`mutex1` וממתין ל-`mutex2`. חוט 1 מחזיק ב-`mutex2` וממתין ל-`mutex1`. תנאי זה מתקיים.\n3.  **No Preemption (אי-הפקעה):** לא ניתן להפקיע mutex מחוט שמחזיק בו; רק החוט שהחזיק בו יכול לשחרר אותו. תנאי זה מתקיים.\n4.  **Circular Wait (המתנה מעגלית):** קיים מעגל של חוטים, כאשר כל חוט במעגל ממתין למשאב שמוחזק על ידי החוט הבא במעגל. במקרה זה, חוט 0 ממתין ל-`mutex2` שמוחזק על ידי חוט 1, וחוט 1 ממתין ל-`mutex1` שמוחזק על ידי חוט 0. זהו מעגל המתנה. תנאי זה מתקיים.\nמכיוון שכל ארבעת התנאים מתקיימים, קיפאון אפשרי.\n\n**כיצד ניתן למנוע קיפאון זה:**\nהדרך הנפוצה והפשוטה ביותר למנוע קיפאון מסוג זה היא להבטיח שכל החוטים ירכשו את ה-mutex-ים באותו סדר עקבי. אם שני החוטים היו מנסים לרכוש קודם את `mutex1` ולאחר מכן את `mutex2` (או להפך, אך באותו סדר עבור שניהם), הקיפאון היה נמנע.\n**תיקון קוד לדוגמה (שני החוטים רוכשים את `mutex1` ואז `mutex2`):**\n```c\nvoid* do_work_fixed(void* arg) {\n    int id = *(int*)arg;\n\n    // Both threads acquire mutex1 then mutex2\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread %d acquired mutex1\\n\", id);\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread %d acquired mutex2\\n\", id);\n\n    // Critical section\n    printf(\"Thread %d in critical section\\n\", id);\n\n    pthread_mutex_unlock(&mutex2);\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread %d released both mutexes\\n\", id);\n    return NULL;\n}\n```\nבמימוש מתוקן זה, גם אם חוט 0 רוכש את `mutex1` ומתרחש מיתוג הקשר, כאשר חוט 1 ינסה לרכוש את `mutex1`, הוא ייחסם. חוט 0 בסופו של דבר ירוץ, ירכוש את `mutex2`, יסיים את הקטע הקריטי, ישחרר את `mutex2` ואז את `mutex1`. רק אז חוט 1 יוכל לרכוש את `mutex1` ולהמשיך."}, "difficulty_estimation": "Medium", "_source_file": "0255__Mutexes__Open__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:17:17", "_subject": "Concurrency"}, {"id": 100, "type": "Open", "topic": ["Mutexes", "Deadlocks", "Synchronization"], "content": {"text": "נתונה מערכת עם שני משאבים משותפים, resource1 ו-resource2, המוגנים על ידי שני מנעולים (mutexes), mutex1 ו-mutex2, בהתאמה. קיימים שני תהליכונים (threads), threadA ו-threadB, המבצעים פעולות הדורשות גישה לשני המשאבים. הקוד הבא מציג את לוגיקת הגישה של כל אחד מהתהליכונים.\n\nא. האם קיים סיכון לקיפאון (deadlock) במערכת זו? נמקו והסבירו את התרחיש המוביל לקיפאון, אם קיים.\nב. אם קיים, הציעו פתרון לקוד המונע קיפאון, והסבירו מדוע הפתרון שלכם עובד.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex1 = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_t mutex2 = PTHREAD_MUTEX_INITIALIZER;\n\nvoid* threadA_func(void* arg) {\n    printf(\"Thread A: Trying to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread A: Locked mutex1. Trying to lock mutex2...\\n\");\n    sleep(1); // Simulate work\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread A: Locked mutex2. Accessing resources.\\n\");\n    // Access resource1 and resource2\n    pthread_mutex_unlock(&mutex2);\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread A: Unlocked mutexes.\\n\");\n    return NULL;\n}\n\nvoid* threadB_func(void* arg) {\n    printf(\"Thread B: Trying to lock mutex2...\\n\");\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread B: Locked mutex2. Trying to lock mutex1...\\n\");\n    sleep(1); // Simulate work\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread B: Locked mutex1. Accessing resources.\\n\");\n    // Access resource1 and resource2\n    pthread_mutex_unlock(&mutex1);\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread B: Unlocked mutexes.\\n\");\n    return NULL;\n}\n\n// Example main function to run these threads:\n/*\nint main() {\n    pthread_t tidA, tidB;\n\n    pthread_create(&tidA, NULL, threadA_func, NULL);\n    pthread_create(&tidB, NULL, threadB_func, NULL);\n\n    pthread_join(tidA, NULL);\n    pthread_join(tidB, NULL);\n\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n\n    return 0;\n}\n*/", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. כן, קיים סיכון לקיפאון (deadlock) במערכת זו. תרחיש אפשרי לקיפאון הוא כדלקמן:\n1.  **תהליכון A** מבצע `pthread_mutex_lock(&mutex1)` ומצליח לנעול את `mutex1`.\n2.  במקביל, **תהליכון B** מבצע `pthread_mutex_lock(&mutex2)` ומצליח לנעול את `mutex2`.\n3.  כעת, **תהליכון A** ממשיך ומנסה לבצע `pthread_mutex_lock(&mutex2)`. מכיוון ש-`mutex2` נעול על ידי תהליכון B, תהליכון A נחסם וממתין לשחרורו.\n4.  במקביל, **תהליכון B** ממשיך ומנסה לבצע `pthread_mutex_lock(&mutex1)`. מכיוון ש-`mutex1` נעול על ידי תהליכון A, תהליכון B נחסם וממתין לשחרורו.\nבשלב זה, שני התהליכונים חסומים וממתינים זה לזה לשחרור המשאב שהשני מחזיק, וכתוצאה מכך אף אחד מהם לא יכול להתקדם. זהו מצב של קיפאון, הנובע מהפרת תנאי ה\"המתנה המעגלית\" (Circular Wait) בשילוב עם שלושת התנאים האחרים לקיפאון (Mutual Exclusion, Hold and Wait, No Preemption).\n\nב. כדי למנוע קיפאון במצב זה, יש לוודא שכל התהליכונים רוכשים את המנעולים באותו סדר קבוע. זה מפר את תנאי ה\"המתנה המעגלית\".\nפתרון אפשרי הוא ששני התהליכונים ינסו לנעול תמיד את `mutex1` ואז את `mutex2`. הנה דוגמה לקוד מתוקן עבור `threadB_func` (יש לוודא שגם `threadA_func` שומר על אותו סדר):\n\n```c\nvoid* threadB_func(void* arg) {\n    printf(\"Thread B: Trying to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1); // סדר הנעילה שונה ל-mutex1 קודם\n    printf(\"Thread B: Locked mutex1. Trying to lock mutex2...\\n\");\n    sleep(1); // Simulate work\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread B: Locked mutex2. Accessing resources.\\n\");\n    // Access resource1 and resource2\n    pthread_mutex_unlock(&mutex2);\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread B: Unlocked mutexes.\\n\");\n    return NULL;\n}\n```\n\n**הסבר הפתרון:**\nעל ידי אכיפת סדר קבוע לרכישת המנעולים (לדוגמה, תמיד `mutex1` ואז `mutex2`), אנו מבטלים את האפשרות למצב של \"המתנה מעגלית\". אם תהליכון A רוכש את `mutex1` ותהליכון B גם מנסה לרכוש את `mutex1`, רק אחד מהם יצליח. השני ימתין עד ש-`mutex1` ישוחרר. לאחר מכן, התהליכון שרכש את `mutex1` ימשיך לרכוש את `mutex2`. אם `mutex2` פנוי, הוא ירכוש אותו ויבצע את עבודתו. אם `mutex2` תפוס (על ידי תהליכון אחר שכבר סיים את `mutex1` ורכש את `mutex2`), הוא ימתין. בכל מקרה, לא ייווצר מצב שבו A מחזיק ב-X וממתין ל-Y, ובמקביל B מחזיק ב-Y וממתין ל-X, מכיוון שכל התהליכונים מנסים לרכוש את המנעולים באותו סדר היררכי. גישה זו מבטיחה שאין שרשרת המתנה מעגלית, ובכך מונעת קיפאון."}, "difficulty_estimation": "Medium", "_source_file": "0256__Mutexes__Open__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:17:35", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Mutexes", "Fairness", "Concurrency"], "content": {"text": "ממשו מנעול הוגן (Fair Mutex) באמצעות mutexים רגילים (pthread_mutex_t) ומשתני תנאי (pthread_cond_t). מנעול הוגן מבטיח שחוטים ירכשו את המנעול לפי הסדר שבו ביקשו אותו (FIFO - First-In, First-Out). כלומר, אם חוט A מבקש את המנעול ואחריו חוט B מבקש אותו, חוט A חייב לרכוש ולשחרר את המנעול לפני שחוט B יוכל לרכוש אותו, גם אם חוט A נדחה (preempted) מיד לאחר בקשתו וחוט B מנסה לרכוש את המנעול.\n\nיש להגדיר את מבנה הנתונים עבור המנעול ההוגן ולממש את הפעולות הבאות: `fair_mutex_init`, `fair_mutex_destroy`, `fair_mutex_lock`, ו-`fair_mutex_unlock`.", "code_snippet": "/* Headers you might need:\n#include <pthread.h>\n#include <stdbool.h>\n#include <stdlib.h>\n*/\n\n\ntypedef struct {\n    // Please define the internal state here\n} fair_mutex_t;\n\nvoid fair_mutex_init(fair_mutex_t *m);\nvoid fair_mutex_destroy(fair_mutex_t *m);\nvoid fair_mutex_lock(fair_mutex_t *m);\nvoid fair_mutex_unlock(fair_mutex_t *m);"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כדי לממש מנעול הוגן בשיטת FIFO, נשתמש במנגנון 'כרטיסים' (tickets). כל חוט המבקש את המנעול מקבל מספר כרטיס ייחודי, והחוטים רוכשים את המנעול לפי הסדר העולה של מספרי הכרטיסים שלהם. נשתמש ב-mutex פנימי (`internal_lock`) כדי להגן על מצב המנעול (מספרי הכרטיסים) ובמשתנה תנאי (`cond`) כדי להשהות חוטים שממתינים לתורם.\n\nמבנה הנתונים `fair_mutex_t` יכלול:\n*   `internal_lock`: mutex רגיל להגנה על השדות הפנימיים של המנעול ההוגן.\n*   `cond`: משתנה תנאי שעליו חוטים ימתינו כאשר אינם בתורם.\n*   `next_ticket`: מונה עולה שמחלק מספרי כרטיסים ייחודיים לכל חוט שמבקש את המנעול.\n*   `serving_ticket`: מונה עולה המציין את מספר הכרטיס של החוט שמותר לו כעת לרכוש את המנעול.\n\n**פעולת `fair_mutex_lock`:**\n1.  החוט רוכש את `internal_lock` כדי לגשת בבטחה לשדות הפנימיים של המנעול ההוגן.\n2.  הוא מקבל מספר כרטיס (`my_ticket`) מתוך `next_ticket` ומקדם את `next_ticket` עבור החוט הבא.\n3.  החוט נכנס ללולאת המתנה: כל עוד `my_ticket` שלו אינו שווה ל-`serving_ticket`, הוא ממתין על משתנה התנאי `cond`. בזמן ההמתנה, `pthread_cond_wait` משחרר את `internal_lock` באופן אטומי ומחזיר אותו עם ההתעוררות.\n4.  כאשר `my_ticket == serving_ticket`, זהו תורו של החוט לרכוש את המנעול. הוא יוצא מהלולאה.\n5.  החוט משחרר את `internal_lock`.\n\n**פעולת `fair_mutex_unlock`:**\n1.  החוט רוכש את `internal_lock`.\n2.  הוא מקדם את `serving_ticket` כדי לאפשר לחוט הבא בתור (בעל הכרטיס הבא) לרכוש את המנעול.\n3.  החוט קורא ל-`pthread_cond_broadcast` כדי להעיר את כל החוטים הממתינים על `cond`. מתוך החוטים שהתעוררו, רק זה ש-`my_ticket` שלו תואם את `serving_ticket` החדש ימשיך.\n4.  החוט משחרר את `internal_lock`.\n\nמימוש זה מבטיח הוגנות FIFO מכיוון שחוטים יכולים לרכוש את המנעול רק כאשר מספר הכרטיס שלהם תואם ל-`serving_ticket`, ו-`serving_ticket` מקודם באופן סדרתי.\n\n```c\n#include <pthread.h>\n#include <stdbool.h>\n#include <stdlib.h>\n\ntypedef struct {\n    pthread_mutex_t internal_lock;      // מגן על המצב הפנימי של המנעול\n    pthread_cond_t  cond;               // משתנה תנאי לחוטים הממתינים\n    int             next_ticket;        // הכרטיס הבא שיחולק\n    int             serving_ticket;     // הכרטיס הנוכחי בתור\n} fair_mutex_t;\n\nvoid fair_mutex_init(fair_mutex_t *m) {\n    pthread_mutex_init(&m->internal_lock, NULL);\n    pthread_cond_init(&m->cond, NULL);\n    m->next_ticket = 0;\n    m->serving_ticket = 0;\n}\n\nvoid fair_mutex_destroy(fair_mutex_t *m) {\n    pthread_mutex_destroy(&m->internal_lock);\n    pthread_cond_destroy(&m->cond);\n}\n\nvoid fair_mutex_lock(fair_mutex_t *m) {\n    pthread_mutex_lock(&m->internal_lock);\n    int my_ticket = m->next_ticket++; // קבל כרטיס וקדם את המונה\n    while (my_ticket != m->serving_ticket) {\n        pthread_cond_wait(&m->cond, &m->internal_lock);\n    }\n    // עכשיו זה התור שלי, אני מחזיק במנעול באופן מרומז\n    pthread_mutex_unlock(&m->internal_lock);\n}\n\nvoid fair_mutex_unlock(fair_mutex_t *m) {\n    pthread_mutex_lock(&m->internal_lock);\n    m->serving_ticket++; // קדם את הכרטיס הבא בתור\n    pthread_cond_broadcast(&m->cond); // העיר את כל החוטים הממתינים לבדוק את תורם\n    pthread_mutex_unlock(&m->internal_lock);\n}\n```\n", "difficulty_estimation": "Hard"}, "_source_file": "0257__Mutexes__Open__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:18:08", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Mutexes", "Synchronization", "Concurrency", "Fairness", "Semaphores", "Atomic Operations"], "content": {"text": "מנעולים סטנדרטיים (כגון `pthread_mutex_t`) מספקים הגנה הדדית (mutual exclusion) אך אינם מבטיחים הוגנות (fairness) בסדר הכניסה לקטע הקריטי. במערכות עם עומס גבוה, חוטים מסוימים עלולים לסבול מהרעבה (starvation) ולעולם לא לזכות במנעול, גם אם הם ממתינים זמן רב.\n\nמטרת שאלה זו היא לממש מנעול הוגן, אשר מבטיח שחוטים ירכשו את המנעול בסדר הגעתם (FIFO – First-In, First-Out). יש להשתמש בסמפורים (`sem_t`) ובפעולות אטומיות (כגון `atomic_uint` מ-C11 או `__sync_fetch_and_add` ב-GCC/Clang) לצורך המימוש, ללא שימוש ישיר ב-`pthread_mutex_t` או `pthread_cond_t`.\n\nהגדירו את מבנה הנתונים עבור המנעול ההוגן (`fair_mutex_t`) ולממש את הפונקציות הבאות: `fair_mutex_init`, `fair_mutex_destroy`, `fair_mutex_lock`, ו-`fair_mutex_unlock`.\n\nהניחו כי מספר החוטים הממתינים במקביל למנעול לא יעלה על `MAX_TICKETS` (קבוע שתגדירו).", "code_snippet": "#include <semaphore.h>\n#include <stdatomic.h>\n\n#define MAX_TICKETS 1024 // Maximum number of unique tickets that can be simultaneously outstanding\n\ntypedef struct fair_mutex {\n    // TODO: Add necessary members for a fair mutex\n} fair_mutex_t;\n\nvoid fair_mutex_init(fair_mutex_t *mutex);\nvoid fair_mutex_destroy(fair_mutex_t *mutex);\nvoid fair_mutex_lock(fair_mutex_t *mutex);\nvoid fair_mutex_unlock(fair_mutex_t *mutex);\n", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כדי לממש מנעול הוגן מסוג FIFO, נשתמש במנגנון \"כרטיסים\" (tickets). כל חוט שמבקש לרכוש את המנעול מקבל מספר כרטיס ייחודי, והחוטים רוכשים את המנעול לפי סדר הכרטיסים. כדי להפוך את המנגנון לחוסם (blocking) במקום ספינינג (spinning), נשתמש במערך של סמפורים, כאשר כל חוט ממתין על הסמפור הספציפי שלו, בהתאם למספר הכרטיס שקיבל.\n\n**מבנה הנתונים:**\n*   `next_ticket` (`atomic_uint`): מונה אטומי המקצה את מספר הכרטיס הבא. כל חוט שמבקש מנעול מקדם מונה זה ומקבל את הערך הקודם ככרטיס שלו.\n*   `now_serving` (`atomic_uint`): מונה אטומי המציין איזה כרטיס תורו להיכנס לקטע הקריטי.\n*   `wait_semaphores[MAX_TICKETS]` (`sem_t`): מערך של סמפורים. חוט שמקבל כרטיס `N` ומגלה שזה עדיין לא תורו (`now_serving != N`), ימתין על הסמפור `wait_semaphores[N % MAX_TICKETS]`. הסמפורים מאותחלים ל-0 (נעולים).\n*   `state_guard` (`sem_t`): סמפור בינארי (מאותחל ל-1) המשמש להגן על הגישה למונים `next_ticket` ו-`now_serving` ועל פעולות ה-`sem_post` בזמן ה-`unlock`, כדי למנוע מצבי מירוץ ולשמור על עקביות המצב הפנימי של המנעול.\n\n**הסבר לפעולות:**\n\n*   `fair_mutex_init`: מאתחל את המונים האטומיים ל-0. מאתחל את `state_guard` ל-1. מאתחל את כל הסמפורים במערך `wait_semaphores` ל-0 (כלומר, כולם נעולים בתחילה).\n\n*   `fair_mutex_destroy`: משחרר את המשאבים של הסמפורים (`sem_destroy`).\n\n*   `fair_mutex_lock`:\n    1.  החוט רוכש את `state_guard` (`sem_wait`) כדי להבטיח גישה יחידה למנגנון הקצאת הכרטיסים ולעדכון המצב.\n    2.  החוט מקבל כרטיס ייחודי על ידי קידום אטומי של `next_ticket` (`atomic_fetch_add`) ושמירת הערך הקודם (`my_ticket`).\n    3.  החוט משחרר את `state_guard` (`sem_post`).\n    4.  החוט בודק אם `my_ticket` שווה ל-`now_serving`. אם כן, זהו תורו של החוט להיכנס מיד לקטע הקריטי (אין צורך להמתין על סמפור). הוא ממשיך בביצוע.\n    5.  אם `my_ticket` אינו שווה ל-`now_serving`, החוט ממתין על הסמפור הספציפי שלו: `sem_wait(&mutex->wait_semaphores[my_ticket % MAX_TICKETS])`. זה חוסם את החוט עד שישוחרר על ידי החוט הקודם בתור.\n\n*   `fair_mutex_unlock`:\n    1.  החוט רוכש את `state_guard` (`sem_wait`) כדי להגן על עדכון המונים ופעולות ה-`sem_post`.\n    2.  החוט מקדם את `now_serving` באופן אטומי (`atomic_fetch_add`), ובכך מסמן שהכרטיס הבא בתור יכול להיכנס לקטע הקריטי.\n    3.  החוט מחשב את מספר הכרטיס של החוט הבא בתור (`next_waiter_ticket = current_ticket + 1`).\n    4.  החוט בודק אם יש חוט שממתין לכרטיס הבא בתור (כלומר, אם `next_waiter_ticket` קטן מ-`next_ticket` הנוכחי, מה שאומר שחוט כבר לקח את הכרטיס הזה והוא ממתין). אם כן, הוא משחרר את הסמפור המתאים (`sem_post`) כדי להעיר את החוט הבא בתור.\n    5.  החוט משחרר את `state_guard` (`sem_post`).\n\n**הערה על `MAX_TICKETS`:** השימוש במודולו (`% MAX_TICKETS`) עלול לגרום לבעיות אם מספר כרטיסים שונים (שאינם נשמרים בו זמנית) ממופים לאותו סמפור בעוד חוטים עדיין ממתינים. בשאלה זו, אנו מניחים ש-`MAX_TICKETS` גדול מספיק כדי למנוע מצב שבו חוטים עם כרטיסים `X` ו-`X + MAX_TICKETS` ממתינים בו-זמנית על אותו סמפור, או שניתן להחשיב את `MAX_TICKETS` כמספר המרבי של חוטים שיכולים להמתין למנעול בכל רגע נתון.", "code_snippet": "#include <semaphore.h>\n#include <stdatomic.h>\n#include <stdio.h>\n\n#define MAX_TICKETS 1024 // Maximum number of unique tickets that can be simultaneously outstanding\n\ntypedef struct fair_mutex {\n    atomic_uint next_ticket; // Next available ticket number\n    atomic_uint now_serving; // Ticket number of the thread currently holding the lock\n    sem_t wait_semaphores[MAX_TICKETS]; // Each thread waits on its specific semaphore\n    sem_t state_guard; // Binary semaphore to protect access to next_ticket, now_serving, and sem_post operations.\n} fair_mutex_t;\n\nvoid fair_mutex_init(fair_mutex_t *mutex) {\n    atomic_init(&mutex->next_ticket, 0);\n    atomic_init(&mutex->now_serving, 0);\n    sem_init(&mutex->state_guard, 0, 1); // Initialize state_guard as a binary semaphore (unlocked)\n    for (int i = 0; i < MAX_TICKETS; ++i) {\n        sem_init(&mutex->wait_semaphores[i], 0, 0); // All waiting semaphores start at 0 (locked)\n    }\n}\n\nvoid fair_mutex_destroy(fair_mutex_t *mutex) {\n    sem_destroy(&mutex->state_guard);\n    for (int i = 0; i < MAX_TICKETS; ++i) {\n        sem_destroy(&mutex->wait_semaphores[i]);\n    }\n}\n\nvoid fair_mutex_lock(fair_mutex_t *mutex) {\n    sem_wait(&mutex->state_guard); // Acquire guard to get a ticket and protect state updates\n    unsigned int my_ticket = atomic_fetch_add(&mutex->next_ticket, 1); // Atomically get next ticket\n    sem_post(&mutex->state_guard); // Release entry gate\n\n    // Check if it's my turn immediately\n    if (my_ticket == atomic_load(&mutex->now_serving)) {\n        // It's my turn, proceed without waiting on a semaphore\n        return;\n    } else {\n        // Not my turn, wait on my specific semaphore\n        sem_wait(&mutex->wait_semaphores[my_ticket % MAX_TICKETS]);\n    }\n}\n\nvoid fair_mutex_unlock(fair_mutex_t *mutex) {\n    sem_wait(&mutex->state_guard); // Acquire guard to update now_serving and potentially post to next waiter\n    unsigned int current_ticket = atomic_load(&mutex->now_serving); // Get current serving ticket\n    atomic_fetch_add(&mutex->now_serving, 1); // Increment now_serving for the next thread\n\n    unsigned int next_waiter_ticket = current_ticket + 1;\n\n    // If there's a thread waiting for the next ticket, unblock it\n    // This check ensures we only post if a thread has already acquired that ticket\n    if (next_waiter_ticket < atomic_load(&mutex->next_ticket)) {\n        sem_post(&mutex->wait_semaphores[next_waiter_ticket % MAX_TICKETS]);\n    }\n    sem_post(&mutex->state_guard); // Release guard\n}\n", "difficulty_estimation": "Hard"}, "_source_file": "0258__Mutexes__Open__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:19:12", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Mutexes", "Synchronization", "Threads", "Concurrency"], "content": {"text": "במערכות הפעלה, מיוטקס (mutex) משמש להבטחת מניעה הדדית לקטע קריטי. עם זאת, מיוטקס רגיל עלול לגרום לקיפאון (deadlock) אם חוט שכבר מחזיק במיוטקס ינסה לרכוש אותו שוב. כדי לפתור בעיה זו, קיים מושג של 'מיוטקס רה-כניסתי' (reentrant mutex), המאפשר לחוט שרכש את המיוטקס לרכוש אותו שוב מספר פעמים מבלי להיחסם, כל עוד הוא גם ישחרר אותו את אותו מספר פעמים.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "הגדירו במדויק את התכונות הנדרשות ממיוטקס רה-כניסתי, בדומה להגדרת תכונות למנעול קוראים-כותבים. התייחסו לנקודות הבאות:\n1. מניעה הדדית (Mutual Exclusion) בין חוטים שונים.\n2. יכולת כניסה חוזרת (Reentrancy) לחוט המחזיק במיוטקס.\n3. שחרור נכון של המיוטקס.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "ממשו מיוטקס רה-כניסתי באמצעות ספריות Pthreads (mutexes ו-condition variables). עליכם להגדיר את מבנה הנתונים של המיוטקס הרה-כניסתי ולממש את הפעולות `init`, `destroy`, `lock` ו-`unlock`. שימו לב שאין להשתמש בפונקציות Pthreads ספציפיות למיוטקס רה-כניסתי (כגון `PTHREAD_MUTEX_RECURSIVE`), אלא לממש את הלוגיקה בעצמכם על בסיס מיוטקסים רגילים ומשתני תנאי.", "code_snippet": " #include <pthread.h>\n #include <stdio.h> // For pthread_self()\n #include <stdlib.h> // For malloc/free\n\n typedef struct {\n     pthread_mutex_t internal_mutex;\n     pthread_cond_t cond;\n     pthread_t owner;\n     int recursion_count;\n } ReentrantMutex;\n\n void reentrant_mutex_init(ReentrantMutex *rm) {\n     // TODO: Implement\n }\n\n void reentrant_mutex_destroy(ReentrantMutex *rm) {\n     // TODO: Implement\n }\n\n void reentrant_mutex_lock(ReentrantMutex *rm) {\n     // TODO: Implement\n }\n\n void reentrant_mutex_unlock(ReentrantMutex *rm) {\n     // TODO: Implement\n }", "options": null}, {"id": "1.3", "text": "הסבירו בקצרה כיצד המימוש שלכם בסעיף הקודם מבטיח את התכונות שהגדרתם בסעיף 1.1.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: הגדרת תכונות למיוטקס רה-כניסתי:\n1.  **מניעה הדדית (Mutual Exclusion):** בכל רגע נתון, רק חוט אחד יכול להיות ה\"בעלים\" של המיוטקס הרה-כניסתי. חוטים אחרים שינסו לרכוש אותו ייחסמו עד שהבעלים הנוכחי ישחרר אותו לחלוטין (כלומר, מונה הכניסות יגיע ל-0).\n2.  **יכולת כניסה חוזרת (Reentrancy):** חוט שכבר רכש את המיוטקס (הוא הבעלים הנוכחי) יכול לבצע קריאות חוזרות ל-`lock` מבלי להיחסם. כל קריאה כזו תגדיל את מונה הכניסות.\n3.  **שחרור נכון (Proper Release):** חוט יכול לשחרר את המיוטקס רק אם הוא הבעלים הנוכחי. כל קריאה ל-`unlock` תפחית את מונה הכניסות. רק כאשר מונה הכניסות מגיע ל-0, המיוטקס נחשב משוחרר לחלוטין, וחוט אחר יכול לרכוש אותו.\n\n1.2: מימוש מיוטקס רה-כניסתי:\n```c\n #include <pthread.h>\n #include <stdio.h> // For pthread_self(), fprintf\n #include <stdlib.h> // For malloc/free\n\n typedef struct {\n     pthread_mutex_t internal_mutex;\n     pthread_cond_t cond;\n     pthread_t owner;\n     int recursion_count;\n } ReentrantMutex;\n\n void reentrant_mutex_init(ReentrantMutex *rm) {\n     pthread_mutex_init(&rm->internal_mutex, NULL);\n     pthread_cond_init(&rm->cond, NULL);\n     rm->owner = 0; // No owner initially (pthread_self() returns non-zero)\n     rm->recursion_count = 0;\n }\n\n void reentrant_mutex_destroy(ReentrantMutex *rm) {\n     // It's good practice to ensure no one holds the lock when destroying.\n     // In a robust system, you might add checks or assert recursion_count == 0.\n     pthread_mutex_destroy(&rm->internal_mutex);\n     pthread_cond_destroy(&rm->cond);\n     rm->owner = 0;\n     rm->recursion_count = 0;\n }\n\n void reentrant_mutex_lock(ReentrantMutex *rm) {\n     pthread_t current_thread = pthread_self();\n\n     pthread_mutex_lock(&rm->internal_mutex);\n\n     if (rm->owner == current_thread) {\n         // Current thread already owns the mutex, just increment count\n         rm->recursion_count++;\n     } else {\n         // Mutex is owned by another thread or unowned.\n         // Wait until it's unowned (recursion_count == 0).\n         while (rm->recursion_count != 0) {\n             pthread_cond_wait(&rm->cond, &rm->internal_mutex);\n         }\n         // Now it's unowned, this thread becomes the owner\n         rm->owner = current_thread;\n         rm->recursion_count = 1;\n     }\n     pthread_mutex_unlock(&rm->internal_mutex);\n }\n\n void reentrant_mutex_unlock(ReentrantMutex *rm) {\n     pthread_t current_thread = pthread_self();\n\n     pthread_mutex_lock(&rm->internal_mutex);\n\n     if (rm->owner != current_thread) {\n         // Error: Thread trying to unlock does not own the mutex.\n         // In a robust system, this would be an assertion failure or return an error code.\n         fprintf(stderr, \"Error: Thread %lu trying to unlock a mutex it doesn't own!\\n\", (unsigned long)current_thread);\n         pthread_mutex_unlock(&rm->internal_mutex);\n         return;\n     }\n\n     rm->recursion_count--;\n\n     if (rm->recursion_count == 0) {\n         // Mutex is now fully released. Reset owner and signal waiting threads.\n         rm->owner = 0; // No owner\n         pthread_cond_broadcast(&rm->cond); // Wake up all waiting threads\n     }\n     pthread_mutex_unlock(&rm->internal_mutex);\n }\n```\n\n1.3: הסבר על עמידה בתכונות:\n1.  **מניעה הדדית:** המימוש משתמש ב-`internal_mutex` כדי להגן על המשתנים הפנימיים `owner` ו-`recursion_count`. רק חוט אחד יכול לשנות או לבדוק את המשתנים הללו בו זמנית. בנוסף, חוט יכול להפוך לבעלים של המיוטקס (`rm->owner = current_thread`) רק כאשר `rm->recursion_count` הוא 0, מה שמבטיח שאין בעלים קודם. כלומר, רק חוט אחד יכול להיות הבעלים של המיוטקס בכל רגע נתון. חוטים אחרים שינסו לרכוש את המיוטקס כשהוא בבעלות חוט אחר (`rm->recursion_count != 0`) ייחסמו על ידי `pthread_cond_wait` עד שהבעלים הנוכחי ישחרר אותו לחלוטין.\n2.  **יכולת כניסה חוזרת:** כאשר חוט קורא ל-`reentrant_mutex_lock` ובודק ש-`rm->owner == current_thread`, הוא מגלה שהוא כבר הבעלים. במקרה זה, במקום להיחסם, הוא פשוט מגדיל את `rm->recursion_count` וממשיך. זה מאפשר לחוט הבעלים להיכנס לקטע הקריטי מספר פעמים.\n3.  **שחרור נכון:** חוט יכול לקרוא ל-`reentrant_mutex_unlock` רק אם `rm->owner == current_thread`. אם חוט אחר מנסה לשחרר, המימוש מזהה זאת (עם הודעת שגיאה) ומונע את השחרור הלא חוקי. כל קריאה ל-`unlock` מקטינה את `rm->recursion_count`. רק כאשר `rm->recursion_count` מגיע ל-0, המיוטקס משוחרר לחלוטין (ה-`owner` מאופס), ו-`pthread_cond_broadcast` נקרא כדי להעיר חוטים ממתינים, המאפשר לחוט חדש לרכוש את המיוטקס."}, "difficulty_estimation": "Hard", "_source_file": "0259__Mutexes__Open__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:19:39", "_subject": "Concurrency"}, {"id": 100, "type": "Open", "topic": ["Mutexes", "Condition Variables", "Synchronization", "Producer-Consumer", "Fairness", "Priority"], "content": {"text": "נתונה בעיית ה-Bounded Buffer (מאגר חסום) עבור מספר מפיקים (Producers) וצרכנים (Consumers). המאגר יכול להכיל עד `BUFFER_SIZE` פריטים. מפיקים מוסיפים פריטים למאגר, וצרכנים מוציאים פריטים מהמאגר. יש לוודא סנכרון נכון כדי למנוע תנאי מרוץ, קיפאון (deadlock) והרעבה (starvation).\n\nבנוסף, נדרש שהמימוש יתעדף צרכנים על פני מפיקים כאשר שניהם ממתינים. כלומר, אם גם צרכנים וגם מפיקים ממתינים לפעולה, הצרכנים יקבלו קדימות בכניסה לקטע הקריטי ובביצוע פעולתם (dequeue) לפני שמפיקים יוכלו להוסיף פריטים (enqueue).\n\nהשלימו את המימוש באמצעות `pthread_mutex_t` ו-`pthread_cond_t` בלבד. עליכם להגדיר את מבנה הנתונים `BoundedBuffer` ולהשלים את הפונקציות `buffer_init`, `buffer_destroy`, `buffer_enqueue`, ו-`buffer_dequeue`.", "code_snippet": "#include <pthread.h>\n#include <stdlib.h>\n#include <stdio.h>\n\n#define BUFFER_SIZE 10\n\ntypedef struct {\n    int buffer[BUFFER_SIZE];\n    int head; // Index of the next item to dequeue\n    int tail; // Index of the next slot to enqueue into\n    int count; // Current number of items in buffer\n\n    pthread_mutex_t mutex;\n    pthread_cond_t not_full; // Signaled when buffer is not full\n    pthread_cond_t not_empty; // Signaled when buffer is not empty\n\n    // Add any additional synchronization variables needed for consumer priority\n    int waiting_consumers;\n\n} BoundedBuffer;\n\nvoid buffer_init(BoundedBuffer *buf);\nvoid buffer_destroy(BoundedBuffer *buf);\nvoid buffer_enqueue(BoundedBuffer *buf, int item);\nint buffer_dequeue(BoundedBuffer *buf);\n"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "המימוש דורש שימוש במוטקס אחד להגנה על מבנה הנתונים של ה-Bounded Buffer, ושני משתני תנאי (Condition Variables): אחד למצב שהמאגר אינו מלא (`not_full`) ואחד למצב שהמאגר אינו ריק (`not_empty`). כדי ליישם את עדיפות הצרכנים, נשתמש במונה `waiting_consumers` אשר יספור כמה צרכנים ממתינים כרגע על משתנה התנאי `not_empty`.\n\n**הסבר מפורט:**\n1.  **`BoundedBuffer` struct:** מכיל את המאגר עצמו, אינדקסים `head` ו-`tail`, מונה `count`, המוטקסים ומשתני התנאי. הוספנו את `waiting_consumers` כדי לעקוב אחר צרכנים ממתינים.\n2.  **`buffer_init`:** מאתחל את כל השדות לערכי ההתחלה שלהם, כולל איפוס המוטקס ומשתני התנאי.\n3.  **`buffer_destroy`:** משחרר את המשאבים של המוטקס ומשתני התנאי.\n4.  **`buffer_enqueue` (מפיק):**\n    *   המפיק נועל את המוטקס.\n    *   הוא בודק את התנאי לכניסה: האם המאגר מלא (`buf->count == BUFFER_SIZE`) או האם יש צרכנים שממתינים (`buf->waiting_consumers > 0`). אם אחד מהתנאים הללו מתקיים, המפיק צריך להמתין.\n    *   המפיק קורא ל-`pthread_cond_wait(&buf->not_full, &buf->mutex)` כדי להמתין. הוא משחרר את המוטקס באופן אוטומטי ונכנס למצב שינה. כשהוא מתעורר, הוא נועל מחדש את המוטקס.\n    *   לאחר שהתנאים מתקיימים, המפיק מוסיף פריט למאגר ומעדכן את המונים.\n    *   לבסוף, הוא מאותת ל-`not_empty` (`pthread_cond_signal`) כדי להעיר צרכן פוטנציאלי שממתין.\n    *   המפיק משחרר את המוטקס.\n5.  **`buffer_dequeue` (צרכן):**\n    *   הצרכן נועל את המוטקס.\n    *   הוא בודק את התנאי לכניסה: האם המאגר ריק (`buf->count == 0`). אם כן, הצרכן מגדיל את `waiting_consumers` וקורא ל-`pthread_cond_wait(&buf->not_empty, &buf->mutex)` כדי להמתין. כשהוא מתעורר, הוא מקטין את `waiting_consumers` ונועל מחדש את המוטקס.\n    *   לאחר שהתנאי מתקיים, הצרכן מוציא פריט מהמאגר ומעדכן את המונים.\n    *   כאן מגיע החלק הקריטי לעדיפות: אם לאחר שהצרכן הוציא פריט, מונה הצרכנים הממתינים (`waiting_consumers`) ירד ל-0, זה אומר שאין יותר צרכנים שממתינים. במצב זה, יש לאפשר למפיקים שחיכו בגלל עדיפות הצרכנים להמשיך. לכן, משתמשים ב-`pthread_cond_broadcast(&buf->not_full)` כדי להעיר את כל המפיקים הממתינים על `not_full`. המפיקים יתעוררו, ינעלו את המוטקס מחדש, ויבדקו שוב את התנאי שלהם (שכעת `waiting_consumers` הוא 0, וייתכן שהמאגר כבר לא מלא).\n    *   הצרכן משחרר את המוטקס ומחזיר את הפריט.\n\n**הקפדה על עדיפות ופתרון בעיות:**\n*   **מניעת תנאי מרוץ:** המוטקס `buf->mutex` מגן על כל הגישה למשתנים המשותפים (`head`, `tail`, `count`, `waiting_consumers`).\n*   **מניעת קיפאון (Deadlock):** הסדר של נעילה ושחרור המוטקס הוא עקבי. אין סדר נעילה מורכב שיכול להוביל לקיפאון.\n*   **מניעת הרעבה (Starvation):** עדיפות הצרכנים מונעת הרעבת צרכנים כאשר מפיקים פעילים. ה-`broadcast` מבטיח שמפיקים לא יורעבו כאשר אין יותר צרכנים ממתינים. השימוש ב-`while` בלולאות ההמתנה מטפל ב-spurious wakeups ומוודא שהתנאי אכן מתקיים לפני ההמשך.\n\n```c\n#include <pthread.h>\n#include <stdlib.h>\n#include <stdio.h>\n\n#define BUFFER_SIZE 10\n\ntypedef struct {\n    int buffer[BUFFER_SIZE];\n    int head; // Index of the next item to dequeue\n    int tail; // Index of the next slot to enqueue into\n    int count; // Current number of items in buffer\n\n    pthread_mutex_t mutex;\n    pthread_cond_t not_full; // Signaled when buffer is not full\n    pthread_cond_t not_empty; // Signaled when buffer is not empty\n\n    int waiting_consumers; // Number of consumers waiting on not_empty\n\n} BoundedBuffer;\n\nvoid buffer_init(BoundedBuffer *buf) {\n    buf->head = 0;\n    buf->tail = 0;\n    buf->count = 0;\n    buf->waiting_consumers = 0;\n    pthread_mutex_init(&buf->mutex, NULL);\n    pthread_cond_init(&buf->not_full, NULL);\n    pthread_cond_init(&buf->not_empty, NULL);\n}\n\nvoid buffer_destroy(BoundedBuffer *buf) {\n    pthread_mutex_destroy(&buf->mutex);\n    pthread_cond_destroy(&buf->not_full);\n    pthread_cond_destroy(&buf->not_empty);\n}\n\nvoid buffer_enqueue(BoundedBuffer *buf, int item) {\n    pthread_mutex_lock(&buf->mutex);\n\n    // Producer waits if buffer is full OR if there are consumers waiting (consumer priority)\n    while (buf->count == BUFFER_SIZE || buf->waiting_consumers > 0) {\n        pthread_cond_wait(&buf->not_full, &buf->mutex);\n    }\n\n    buf->buffer[buf->head] = item;\n    buf->head = (buf->head + 1) % BUFFER_SIZE;\n    buf->count++;\n\n    pthread_cond_signal(&buf->not_empty); // Wake up a waiting consumer\n\n    pthread_mutex_unlock(&buf->mutex);\n}\n\nint buffer_dequeue(BoundedBuffer *buf) {\n    pthread_mutex_lock(&buf->mutex);\n\n    // Consumer waits if buffer is empty\n    while (buf->count == 0) {\n        buf->waiting_consumers++; // Increment count of waiting consumers\n        pthread_cond_wait(&buf->not_empty, &buf->mutex);\n        buf->waiting_consumers--; // Decrement count of waiting consumers after waking up\n    }\n\n    int item = buf->buffer[buf->tail];\n    buf->tail = (buf->tail + 1) % BUFFER_SIZE;\n    buf->count--;\n\n    // If no consumers are waiting, broadcast to all producers (they might be waiting due to consumer priority)\n    // Otherwise, just signal one producer if the buffer was full.\n    // Using broadcast here is safer as producers might be waiting on `waiting_consumers > 0` condition.\n    pthread_cond_broadcast(&buf->not_full);\n\n    pthread_mutex_unlock(&buf->mutex);\n    return item;\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0260__Mutexes__Open__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:20:28", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Mutexes", "Deadlock Prevention", "Fairness", "Synchronization", "Resource Allocation"], "content": {"text": "מערכת ההפעלה מנהלת מערך של N משאבים ייחודיים, `Resource[0]`, `Resource[1]`, ..., `Resource[N-1]`. כל משאב מוגן על ידי מנעול (mutex) משלו. חוטים רבים במערכת נדרשים באופן תדיר לרכוש שני משאבים ספציפיים, נניח `Resource[i]` ו-`Resource[j]` (כאשר `i != j`), לבצע פעולה כלשהי, ולאחר מכן לשחרר אותם.\n\nממשו את הפונקציות `acquire_two_resources(ResourceManager *rm, int i, int j)` ו-`release_two_resources(ResourceManager *rm, int i, int j)`. המימוש צריך לקיים את הדרישות הבאות:\n1. מניעת קיפאון (Deadlock Prevention): המימוש חייב להבטיח שלא יתרחש מצב של קיפאון לעולם.\n2. הוגנות (Fairness): יש להבטיח שאף חוט המבקש לרכוש שני משאבים `i` ו-`j` לא יורעב (starve) ללא הגבלת זמן, בעוד שחוטים אחרים ממשיכים לרכוש ולשחרר משאבים.\n3. יעילות: המימוש צריך למזער המתנה מיותרת ככל הניתן.\n\nהשתמשו באובייקטים מסוג `pthread_mutex_t` ובפעולותיהם בלבד (ללא סמפורים או משתני תנאי).", "code_snippet": "```c\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\ntypedef struct {\n    int N; // Number of resources\n    // Add necessary synchronization primitives here\n} ResourceManager;\n\nvoid init_resource_manager(ResourceManager *rm, int n_resources);\nvoid destroy_resource_manager(ResourceManager *rm);\nvoid acquire_two_resources(ResourceManager *rm, int i, int j);\nvoid release_two_resources(ResourceManager *rm, int i, int j);\n```", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון זה משתמש בשני מנגנוני סנכרון עיקריים כדי לעמוד בדרישות:\n\n1.  **מניעת קיפאון (Deadlock Prevention):** כדי למנוע קיפאון, אנו נוקטים בגישה של רכישת משאבים בסדר קנוני (קבוע). כאשר חוט מבקש לרכוש את משאב `i` ומשאב `j`, הוא תמיד ירכוש קודם את המשאב בעל האינדקס הנמוך יותר, ולאחר מכן את המשאב בעל האינדקס הגבוה יותר. לדוגמה, אם חוט מבקש (3, 7), הוא ירכוש קודם את `resource_locks[3]` ולאחר מכן את `resource_locks[7]`. אם חוט אחר מבקש (7, 3), הוא גם ירכוש קודם את `resource_locks[3]` ואז את `resource_locks[7]`. גישה זו מבטיחה שמעגל המתנה לעולם לא ייווצר, ובכך מונעת קיפאון.\n\n2.  **הוגנות (Fairness):** כדי להבטיח הוגנות ולמנוע הרעבה, אנו משתמשים ב-`request_serializer_mutex` גלובלי. כל חוט המבקש לרכוש זוג משאבים חייב קודם לרכוש את `request_serializer_mutex`. מנעול זה מבטיח שרק חוט אחד בכל רגע נתון יוכל לנסות לרכוש את זוג המשאבים שלו. לאחר שהחוט רכש את `request_serializer_mutex`, הוא ממשיך לרכוש את שני המשאבים הספציפיים שלו בסדר הקנוני שתואר לעיל. רק לאחר ששני המשאבים נרכשו בהצלחה, `request_serializer_mutex` משוחרר. מנגנון זה יוצר תור FIFO (First-In, First-Out) עבור כל הבקשות לרכישת זוגות משאבים, ובכך מבטיח שאף חוט לא יורעב – כל בקשה תקבל את תורה ותטופל בסופו של דבר.\n\n3.  **יעילות:** הפתרון ממזער המתנה מיותרת במובן זה שאחרי שחוט רוכש את `request_serializer_mutex`, הוא ירכוש את המשאבים הנדרשים שלו מיד כשהם פנויים. עם זאת, יש לציין שהשימוש ב-`request_serializer_mutex` גלובלי מפחית את המקביליות האפשרית במערכת, מכיוון שכל בקשות הרכישה נסגרות לסדרה (מועברות בתור אחת אחרי השנייה). לדוגמה, אם חוט אחד מבקש את (R0, R1) וחוט אחר מבקש את (R2, R3) – משאבים שאינם חופפים – הם עדיין יצטרכו לחכות זה לזה ב-`request_serializer_mutex`. זוהי פשרה נפוצה כאשר דורשים הוגנות מחמירה עם מנעולים בלבד, ללא שימוש במשתני תנאי (condition variables) המאפשרים המתנה חכמה יותר.\n\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\ntypedef struct {\n    int N; // Number of resources\n    pthread_mutex_t *resource_locks; // Array of mutexes, one per resource\n    pthread_mutex_t request_serializer_mutex; // Global mutex to ensure fairness for acquisition attempts\n} ResourceManager;\n\n// Initialization function\nvoid init_resource_manager(ResourceManager *rm, int n_resources) {\n    rm->N = n_resources;\n    rm->resource_locks = (pthread_mutex_t *)malloc(sizeof(pthread_mutex_t) * n_resources);\n    if (rm->resource_locks == NULL) {\n        perror(\"Failed to allocate resource_locks\");\n        exit(EXIT_FAILURE);\n    }\n    for (int i = 0; i < n_resources; ++i) {\n        if (pthread_mutex_init(&rm->resource_locks[i], NULL) != 0) {\n            perror(\"Failed to initialize resource mutex\");\n            exit(EXIT_FAILURE);\n        }\n    }\n    if (pthread_mutex_init(&rm->request_serializer_mutex, NULL) != 0) {\n        perror(\"Failed to initialize request serializer mutex\");\n        exit(EXIT_FAILURE);\n    }\n}\n\n// Destruction function\nvoid destroy_resource_manager(ResourceManager *rm) {\n    for (int i = 0; i < rm->N; ++i) {\n        pthread_mutex_destroy(&rm->resource_locks[i]);\n    }\n    free(rm->resource_locks);\n    pthread_mutex_destroy(&rm->request_serializer_mutex);\n}\n\n// Acquire two resources\nvoid acquire_two_resources(ResourceManager *rm, int i, int j) {\n    // Ensure valid indices\n    if (i < 0 || i >= rm->N || j < 0 || j >= rm->N || i == j) {\n        fprintf(stderr, \"Invalid resource indices: %d, %d\\n\", i, j);\n        return;\n    }\n\n    // Use the request_serializer_mutex to ensure fairness for acquisition attempts\n    // This mutex is held for the entire duration of acquiring both resource locks.\n    // This serializes all attempts to acquire a pair of resources.\n    pthread_mutex_lock(&rm->request_serializer_mutex);\n\n    // Acquire resources in canonical order to prevent deadlock\n    int idx1 = (i < j) ? i : j;\n    int idx2 = (i < j) ? j : i;\n\n    pthread_mutex_lock(&rm->resource_locks[idx1]);\n    pthread_mutex_lock(&rm->resource_locks[idx2]);\n\n    // Release the request_serializer_mutex ONLY AFTER both resources are acquired.\n    // This makes the entire acquisition process (for a pair) atomic from the perspective\n    // of other threads trying to acquire any resources.\n    pthread_mutex_unlock(&rm->request_serializer_mutex);\n}\n\n// Release two resources\nvoid release_two_resources(ResourceManager *rm, int i, int j) {\n    // Ensure valid indices\n    if (i < 0 || i >= rm->N || j < 0 || j >= rm->N || i == j) {\n        fprintf(stderr, \"Invalid resource indices: %d, %d\\n\", i, j);\n        return;\n    }\n\n    // Release resources in reverse canonical order (or any order, as release order doesn't cause deadlock)\n    // For consistency, releasing in reverse order of acquisition is good practice.\n    int idx1 = (i < j) ? i : j;\n    int idx2 = (i < j) ? j : i;\n\n    pthread_mutex_unlock(&rm->resource_locks[idx2]);\n    pthread_mutex_unlock(&rm->resource_locks[idx1]);\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0261__Mutexes__Open__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:21:19", "_subject": "Concurrency"}, {"id": 101, "type": "Open", "topic": ["Mutexes", "Synchronization", "Concurrency", "Condition Variables"], "content": {"text": "במערכת מרובת תהליכים, לעיתים קרובות נדרש להגביל את מספר התהליכים שיכולים לגשת לקטע קריטי מסוים בו-זמנית, אך לאו דווקא לאחד בלבד. לדוגמה, קטע קריטי שעושה שימוש במאגר של N חיבורי רשת זמינים. יש לממש אובייקט סנכרון חדש בשם `PermitMutex` שיאפשר לכל היותר N תהליכים להיכנס לקטע קריטי בו-זמנית. כאשר N תהליכים נמצאים בקטע הקריטי, כל תהליך נוסף שינסה להיכנס ימתין עד שאחד מהתהליכים הקיימים יצא. יש להשתמש אך ורק באובייקטי סנכרון מסוג `pthread_mutex_t` ו-`pthread_cond_t`. יש להגדיר את מבנה הנתונים של `PermitMutex` ולממש את הפונקציות `init_permit_mutex()`, `destroy_permit_mutex()`, `acquire_permit()` ו-`release_permit()`.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "המימוש של `PermitMutex` ידרוש מבנה נתונים שיכיל מונה של הרשאות זמינות (`available_permits`), מנעול (`pthread_mutex_t`) להגנה על מונה זה, ומשתנה תנאי (`pthread_cond_t`) לתהליכים הממתינים להרשאה. הנה המימוש:\n\n```c\n#include <pthread.h>\n#include <stdlib.h> // For malloc, free (though not strictly needed for this snippet)\n\ntypedef struct {\n    pthread_mutex_t mutex;\n    pthread_cond_t cond;\n    int available_permits;\n    int max_permits; // Store N for completeness, though not strictly used in logic\n} PermitMutex;\n\n// Initialize the PermitMutex with a maximum number of permits\nvoid init_permit_mutex(PermitMutex *pm, int N) {\n    pthread_mutex_init(&pm->mutex, NULL);\n    pthread_cond_init(&pm->cond, NULL);\n    pm->available_permits = N;\n    pm->max_permits = N; \n}\n\n// Destroy the PermitMutex, releasing associated resources\nvoid destroy_permit_mutex(PermitMutex *pm) {\n    pthread_mutex_destroy(&pm->mutex);\n    pthread_cond_destroy(&pm->cond);\n}\n\n// Acquire a permit (enter critical section if available)\nvoid acquire_permit(PermitMutex *pm) {\n    pthread_mutex_lock(&pm->mutex);\n    // Loop is crucial to handle spurious wakeups and re-check condition\n    while (pm->available_permits == 0) {\n        pthread_cond_wait(&pm->cond, &pm->mutex);\n    }\n    pm->available_permits--;\n    pthread_mutex_unlock(&pm->mutex);\n}\n\n// Release a permit (exit critical section)\nvoid release_permit(PermitMutex *pm) {\n    pthread_mutex_lock(&pm->mutex);\n    pm->available_permits++;\n    // Signal one waiting thread. For this specific problem, signal is generally sufficient\n    // as only one thread can acquire a permit at a time when one becomes available.\n    // In other scenarios, pthread_cond_broadcast might be considered if multiple\n    // threads could simultaneously proceed.\n    pthread_cond_signal(&pm->cond);\n    pthread_mutex_unlock(&pm->mutex);\n}\n```\n\n**הסבר:**\n\n1.  **מבנה `PermitMutex`**: המבנה מכיל `pthread_mutex_t` להבטחת הדדיות (Mutual Exclusion) בעת גישה למשתנים המשותפים, `pthread_cond_t` לתזמון והמתנה של תהליכים, ו-`available_permits` שהוא מונה של ההרשאות הפנויות כרגע.\n\n2.  **`init_permit_mutex(PermitMutex *pm, int N)`**: פונקציה זו מאתחלת את המוטקס, את משתנה התנאי, ומגדירה את מספר ההרשאות הזמינות הראשוני ל-N.\n\n3.  **`acquire_permit(PermitMutex *pm)`**: \n    *   התהליך נועל את המוטקס (`pthread_mutex_lock`) כדי להגן על הגישה ל-`available_permits` ועל הקריאה ל-`pthread_cond_wait`.\n    *   הוא נכנס ללולאת `while (pm->available_permits == 0)`. לולאה זו היא קריטית ממספר סיבות: ראשית, היא מבטיחה שתהליך ימתין *רק* כאשר אין הרשאות זמינות. שנית, היא מטפלת ב\"התעוררויות שווא\" (spurious wakeups) שבהן `pthread_cond_wait` עשוי לחזור למרות שהתנאי עדיין לא מתקיים. הלולאה מבטיחה שהתנאי ייבדק שוב לאחר כל התעוררות.\n    *   אם יש הרשאה זמינה (כלומר, `available_permits > 0`), התהליך מקטין את המונה ב-1 וממשיך בדרכו, לאחר ששחרר את המוטקס (`pthread_mutex_unlock`).\n\n4.  **`release_permit(PermitMutex *pm)`**: \n    *   התהליך נועל את המוטקס.\n    *   הוא מגדיל את `available_permits` ב-1, משמע הרשאה אחת התפנתה.\n    *   הוא קורא ל-`pthread_cond_signal(&pm->cond)` כדי להעיר תהליך אחד הממתין על משתנה התנאי (אם יש כזה). התהליך שהתעורר יוכל כעת לבדוק את התנאי בלולאת ה-`while` שלו ב-`acquire_permit`.\n    *   לבסוף, התהליך משחרר את המוטקס. \n\n**נכונות ודיון:**\n*   **מניעה הדדית מורחבת**: המוטקס מבטיח שהגישה למונה `available_permits` היא הדדית, ומונעת מצבי מירוץ (race conditions) בשינוי ערכו. המונה עצמו מבטיח שכל היותר N תהליכים יחזיקו הרשאה בו-זמנית.\n*   **חופש מקיפאון (Deadlock-free)**: המימוש אינו מכיל תנאים לקיפאון. תהליכים ממתינים רק אם אין הרשאות, ומשתחררים כאשר הרשאה מתפנה. אין תלות מעגלית במשאבים.\n*   **הוגנות (Fairness)**: המימוש עם `pthread_cond_signal` לא מבטיח הוגנות חזקה (לדוגמה, בסדר FIFO) בין התהליכים הממתינים. מערכת ההפעלה קובעת איזה תהליך ממתין יתעורר. עבור הוגנות חזקה יותר, ייתכן שיהיה צורך במנגנוני תור מורכבים יותר או שימוש ב-`pthread_cond_broadcast` יחד עם מונה תהליכים ממתינים, אם כי זה פחות יעיל ויכול להוביל ל\"עדר מתעורר\" (thundering herd) אם רק אחד יכול להמשיך."}, "difficulty_estimation": "Hard", "_source_file": "0262__Mutexes__Open__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:21:46", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Mutexes", "Threads", "Concurrency", "Fairness", "Reentrancy"], "content": {"text": "מנעול הדדי (Mutex) הוא כלי סנכרון בסיסי, אך לרוב הוא אינו תומך בכניסה מחדש (reentrancy) ואינו מבטיח הוגנות (fairness) בסדר רכישת המנעול. מנעול נכנס מחדש מאפשר לחוט שכבר רכש את המנעול לרכוש אותו שוב מבלי להיחסם. מנעול הוגן מבטיח שחוטים ירכשו את המנעול בסדר שבו ביקשו אותו (FIFO).\n\nמטרת שאלה זו היא לממש מנעול הדדי בעל שתי התכונות הללו: כניסה מחדש והוגנות, תוך שימוש במנעולים הדדיים בסיסיים (`pthread_mutex_t`) ומשתני תנאי (`pthread_cond_t`) מספריית `pthreads` בלבד.\n\nיש להשלים את מבנה הנתונים `ReentrantFairMutex` ואת מימוש הפונקציות `rf_mutex_init`, `rf_mutex_destroy`, `rf_mutex_lock`, ו-`rf_mutex_unlock`.\n\nהקפידו על:\n1.  **כניסה מחדש**: חוט שכבר מחזיק במנעול יכול לקרוא ל-`rf_mutex_lock` שוב מבלי להיחסם. כל קריאה ל-`lock` חייבת להיות מותאמת בקריאה ל-`unlock` כדי לשחרר את המנעול באופן סופי.\n2.  **הוגנות**: חוטים ירכשו את המנעול בסדר שבו ביקשו אותו (FIFO).\n3.  **מניעה הדדית**: רק חוט אחד יכול להחזיק במנעול באופן בלעדי (למעט כניסות חוזרות של אותו חוט).", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <stdbool.h> // For bool type\n\n#define INVALID_THREAD_ID (pthread_t)0 // Assuming 0 is not a valid thread ID for pthread_self() or can be used as a sentinel\n\ntypedef struct ReentrantFairMutex {\n    pthread_mutex_t lock_mutex;     // מנעול להגנה על מבנה הנתונים הפנימי\n    pthread_cond_t condition;       // משתנה תנאי להמתנה על המנעול\n    pthread_t owner;                // מזהה החוט שמחזיק במנעול\n    bool is_locked;                 // האם המנעול נעול כרגע על ידי חוט כלשהו?\n    int lock_count;                 // כמה פעמים הבעלים הנוכחי רכש את המנעול\n    unsigned long next_ticket;      // המספר הבא שיינתן לחוט שמבקש להיכנס\n    unsigned long served_ticket;    // המספר של החוט הבא שיקבל את המנעול\n} ReentrantFairMutex;\n\nvoid rf_mutex_init(ReentrantFairMutex *m);\nvoid rf_mutex_destroy(ReentrantFairMutex *m);\nvoid rf_mutex_lock(ReentrantFairMutex *m);\nvoid rf_mutex_unlock(ReentrantFairMutex *m);"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כדי לממש מנעול הדדי נכנס מחדש והוגן, נשתמש בשילוב של מנעול בסיסי (`lock_mutex`) להגנה על המצב הפנימי של המנעול, משתנה תנאי (`condition`) להמתנת חוטים, וכן מנגנון 'כרטיסים' (tickets) להבטחת הוגנות.\n\n**מבנה הנתונים:**\n*   `lock_mutex`: מנעול בסיסי המשמש להגנה על כל הגישה למשתנים הפנימיים של `ReentrantFairMutex`.\n*   `condition`: משתנה תנאי שחוטים ממתינים עליו כאשר המנעול אינו זמין או כאשר הם אינם בתור (לפי מנגנון הכרטיסים).\n*   `owner`: שומר את ה-ID של החוט שמחזיק כרגע במנעול. מאותחל ל-`INVALID_THREAD_ID` כאשר המנעול אינו בשימוש.\n*   `is_locked`: דגל בוליאני המציין אם המנעול נעול כרגע על ידי חוט כלשהו.\n*   `lock_count`: מונה את מספר הפעמים שהחוט הנוכחי המחזיק במנעול רכש אותו. משמש לכניסה מחדש.\n*   `next_ticket`: מונה עולה (מוגן ע\"י `lock_mutex`) הנותן לכל חוט שמבקש את המנעול 'כרטיס' ייחודי.\n*   `served_ticket`: מונה עולה המציין איזה 'כרטיס' כרגע רשאי לרכוש את המנעול.\n\n**מימוש `rf_mutex_init`:**\nמאתחל את כל השדות לערכי ברירת מחדל: המנעול הבסיסי ומשתנה התנאי מאותחלים, `owner` מאופס ל-`INVALID_THREAD_ID`, `is_locked` מוגדר ל-`false`, ו-`lock_count`, `next_ticket`, ו-`served_ticket` מאופסים.\n\n**מימוש `rf_mutex_destroy`:**\nמשחרר את המשאבים של המנעול הבסיסי ומשתנה התנאי.\n\n**מימוש `rf_mutex_lock`:**\n1.  רוכש את `lock_mutex` כדי להגן על המצב הפנימי.\n2.  בודק אם החוט הנוכחי הוא הבעלים של המנעול (עבור כניסה מחדש) באמצעות `is_locked` ו-`owner`.\n    *   אם כן, מקדם את `lock_count` ומשחרר את `lock_mutex`. במקרה זה, החוט כבר מחזיק במנעול, ולכן אינו צריך להמתין.\n    *   אם לא, מקבל 'כרטיס' חדש על ידי קידום `next_ticket`.\n    *   ממתין על `condition` כל עוד: `is_locked` נכון (כלומר, מישהו אחר מחזיק בו) או ה'כרטיס' שלו (`my_ticket`) אינו `served_ticket` (כדי להבטיח הוגנות). תנאי זה מבטיח שהחוט ממתין גם אם המנעול פנוי אך הוא לא הגיע תורו, או אם המנעול תפוס.\n3.  לאחר שהחוט רוכש את המנעול (או ממשיך מכניסה מחדש), הוא מגדיר את `owner` ל-`current_thread`, את `is_locked` ל-`true`, ומאתחל את `lock_count` ל-1 (זו הרכישה הראשונה של המנעול עבור חוט זה).\n4.  משחרר את `lock_mutex`.\n\n**מימוש `rf_mutex_unlock`:**\n1.  רוכש את `lock_mutex` כדי להגן על המצב הפנימי.\n2.  בודק אם החוט הנוכחי הוא אכן הבעלים של המנעול (באמצעות `is_locked` ו-`owner`). אם לא, זו שגיאה, ויש להדפיס הודעה מתאימה.\n3.  מפחית את `lock_count`. כל קריאה ל-`lock` חייבת להיות מותאמת בקריאה ל-`unlock`.\n4.  אם `lock_count` הגיע ל-0, פירושו שהמנעול שוחרר באופן סופי על ידי הבעלים הנוכחי.\n    *   מאפס את `owner` ל-`INVALID_THREAD_ID`.\n    *   מגדיר את `is_locked` ל-`false`.\n    *   מקדם את `served_ticket` כדי לאפשר לחוט הבא בתור לרכוש את המנעול.\n    *   משחרר את כל החוטים הממתינים על `condition` (`pthread_cond_broadcast`) כדי שהחוט בעל ה'כרטיס' התואם יוכל להמשיך. שימוש ב-`broadcast` מבטיח שגם אם חוטים התעוררו מוקדם (spurious wakeup), הם יבדקו שוב את התנאי וימתינו אם אינם בתור, אך החוט הנכון (עם `served_ticket` תואם) יתקדם.\n5.  משחרר את `lock_mutex`.\n\n**הסבר על כניסה מחדש והוגנות:**\n*   **כניסה מחדש**: מתאפשרת על ידי שמירת `owner` ו-`lock_count`. חוט יכול לרכוש את המנעול מספר פעמים כל עוד הוא ה-`owner` הנוכחי, ורק כאשר `lock_count` יורד ל-0 המנעול משוחרר לחוטים אחרים.\n*   **הוגנות**: מושגת באמצעות מנגנון ה'כרטיסים' (`next_ticket` ו-`served_ticket`). כל חוט מקבל מספר עוקב כאשר הוא מנסה לרכוש את המנעול, והוא יכול להמשיך רק כאשר ה-'כרטיס' שלו תואם ל-'כרטיס' ה-`served_ticket` הנוכחי. זה מבטיח סדר FIFO בהשגת המנעול."}, "difficulty_estimation": "Hard", "_source_file": "0263__Mutexes__Open__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:22:33", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Synchronization", "Mutexes", "Threads", "Deadlock", "Concurrency"], "content": {"text": "נתונה ספרייה המכילה שתי פונקציות, `outer_function` ו-`inner_function`, אשר שתיהן ניגשות למשאב משותף כלשהו. הפונקציה `outer_function` קוראת ל-`inner_function` כחלק מפעולתה. שתי הפונקציות חייבות להיות בטוחות לשימוש בריבוי תהליכים (thread-safe) ומוגנות מפני תנאי מירוץ על המשאב המשותף באמצעות מנעול (mutex).\n\n**סעיף 1: ניתוח בעיה**\nהסבירו מדוע שימוש במנעול `pthread_mutex_t` רגיל (שאינו רקורסיבי) יגרום לקיפאון (deadlock) אם `outer_function` תנסה לנעול את המשאב, ואז `inner_function` (שנקראת מתוך `outer_function` על ידי אותו חוט) תנסה לנעול את אותו המשאב שוב.\n\n**סעיף 2: מימוש מנעול רקורסיבי**\nממשו מבנה נתונים בשם `recursive_mutex_t` ואת הפעולות `recursive_mutex_init`, `recursive_mutex_destroy`, `recursive_mutex_lock` ו-`recursive_mutex_unlock` עבורו. המימוש צריך להתנהג כמנעול רקורסיבי, כלומר, חוט שמחזיק כבר במנעול יכול לנעול אותו שוב בהצלחה, אך חייב לשחרר אותו מספר פעמים זהה למספר הפעמים שרכש אותו לפני שחוטים אחרים יוכלו לרכוש אותו. השתמשו אך ורק במנעול `pthread_mutex_t` רגיל, משתנה מצב (condition variable), מונה, ומזהה חוט (`pthread_t`). אין להשתמש ב-`pthread_mutex_t` מסוג `PTHREAD_MUTEX_RECURSIVE` במימוש עצמו.\n\nהקוד עבור ההגדרות והפונקציות הנדרשות:", "code_snippet": "```c\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\ntypedef struct {\n    pthread_mutex_t internal_lock; // Protects owner, count, and cond\n    pthread_cond_t cond;           // For waiting threads\n    pthread_t owner;                // ID of the thread currently holding the lock\n    int count;                      // Recursion count\n} recursive_mutex_t;\n\nvoid recursive_mutex_init(recursive_mutex_t* m);\nvoid recursive_mutex_destroy(recursive_mutex_t* m);\nvoid recursive_mutex_lock(recursive_mutex_t* m);\nvoid recursive_mutex_unlock(recursive_mutex_t* m);\n```"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "**סעיף 1: ניתוח בעיה**\nמנעול `pthread_mutex_t` רגיל הוא מנעול שאינו רקורסיבי. כאשר חוט רוכש מנעול כזה, הוא הופך לבעליו. אם אותו חוט ינסה לרכוש את אותו המנעול שוב, לפני שחרורו, החוט ייחסם וימתין לעצמו שישחרר את המנעול, מה שיוביל לקיפאון עצמי (self-deadlock). בתרחיש הנתון, `outer_function` רוכשת את המנעול. לאחר מכן, `inner_function` (שנקראת על ידי `outer_function`, כלומר על ידי אותו חוט) מנסה לרכוש את אותו המנעול. מכיוון שהמנעול כבר מוחזק על ידי אותו החוט, `inner_function` תחסם, והחוט ייכנס למצב קיפאון.\n\n**סעיף 2: מימוש מנעול רקורסיבי**\nמנעול רקורסיבי מאפשר לאותו חוט לרכוש את המנעול מספר פעמים. הוא שומר מונה של מספר הפעמים שהבעלים הנוכחי רכש אותו. המנעול משוחרר באופן מלא רק כאשר המונה יורד לאפס. המימוש דורש מנעול רגיל להגנה על המצב הפנימי (בעלים, מונה), משתנה מצב להמתנה, מונה ומזהה חוט.\n\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\ntypedef struct {\n    pthread_mutex_t internal_lock; // Protects owner, count, and cond\n    pthread_cond_t cond;           // For waiting threads\n    pthread_t owner;                // ID of the thread currently holding the lock\n    int count;                      // Recursion count\n} recursive_mutex_t;\n\nvoid recursive_mutex_init(recursive_mutex_t* m) {\n    pthread_mutex_init(&m->internal_lock, NULL);\n    pthread_cond_init(&m->cond, NULL);\n    m->owner = 0; // Initialize with a value that pthread_equal will correctly identify as not owned\n    m->count = 0;\n}\n\nvoid recursive_mutex_destroy(recursive_mutex_t* m) {\n    pthread_mutex_destroy(&m->internal_lock);\n    pthread_cond_destroy(&m->cond);\n}\n\nvoid recursive_mutex_lock(recursive_mutex_t* m) {\n    pthread_mutex_lock(&m->internal_lock);\n\n    // If the lock is owned by another thread, wait\n    while (m->count > 0 && !pthread_equal(m->owner, pthread_self())) {\n        pthread_cond_wait(&m->cond, &m->internal_lock);\n    }\n\n    // If the lock is now free or owned by the current thread\n    if (m->count == 0) {\n        m->owner = pthread_self();\n    }\n    m->count++;\n\n    pthread_mutex_unlock(&m->internal_lock);\n}\n\nvoid recursive_mutex_unlock(recursive_mutex_t* m) {\n    pthread_mutex_lock(&m->internal_lock);\n\n    // Error check: attempting to unlock a mutex not owned by the current thread\n    if (!pthread_equal(m->owner, pthread_self())) {\n        fprintf(stderr, \"Error: Attempting to unlock a recursive mutex not owned by current thread!\\n\");\n        pthread_mutex_unlock(&m->internal_lock);\n        return;\n    }\n\n    m->count--;\n\n    // If the count drops to zero, the lock is fully released\n    if (m->count == 0) {\n        m->owner = 0; // Mark as unowned. Value 0 is often used for unowned in pthread_t context.\n        pthread_cond_signal(&m->cond); // Signal one waiting thread\n    }\n\n    pthread_mutex_unlock(&m->internal_lock);\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0264__Mutexes__Open__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:43:15", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Mutexes", "Concurrency", "Race Condition", "Threads"], "content": {"text": "נתונה תוכנית C המשתמשת בחוטים (threads) לביצוע פעולה משותפת. מטרת התוכנית היא להגדיל מונה גלובלי (counter) על ידי שני חוטים. עיין בקוד וזהה את הבעיה העיקרית בו. הסבר מדוע היא מתרחשת וכיצד ניתן לתקן אותה.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h> // For exit\n\nint counter = 0;\npthread_mutex_t my_mutex;\n\nvoid* increment_thread(void* arg) {\n    for (int i = 0; i < 100000; ++i) {\n        // Critical section: incrementing counter\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tids[2];\n\n    pthread_mutex_init(&my_mutex, NULL); // Initialize mutex\n\n    // Create two threads\n    pthread_create(&tids[0], NULL, increment_thread, NULL);\n    pthread_create(&tids[1], NULL, increment_thread, NULL);\n\n    // Wait for threads to finish\n    pthread_join(tids[0], NULL);\n    pthread_join(tids[1], NULL);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    pthread_mutex_destroy(&my_mutex); // Destroy mutex\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הבעיה העיקרית בקוד היא תנאי מרוץ (race condition). שני החוטים מנסים לגשת ולשנות את המונה הגלובלי `counter` במקביל ללא כל מנגנון סנכרון. הפעולה `counter++` אינה אטומית; היא מורכבת משלושה שלבים: קריאת ערך המונה, הגדלתו ב-1, וכתיבת הערך החדש בחזרה לזיכרון. כאשר שני חוטים מבצעים פעולה זו במקביל, ייתכן ששניהם יקראו את אותו ערך של `counter` לפני שאחד מהם יספיק לכתוב את הערך המוגדל בחזרה. לדוגמה, אם `counter` הוא 0, חוט א' קורא 0, חוט ב' קורא 0. חוט א' מגדיל ל-1 וכותב 1. חוט ב' מגדיל ל-1 וכותב 1. התוצאה הסופית תהיה 1 במקום 2. כתוצאה מכך, הערך הסופי של `counter` יהיה בדרך כלל נמוך מ-200,000 (הערך הצפוי של 2 חוטים * 100,000 איטרציות) וישתנה בין הרצות שונות.\n\nכדי לתקן את הבעיה, יש להגן על הקטע הקריטי (הגדלת המונה) באמצעות המוטקס `my_mutex`. יש לנעול את המוטקס לפני הגישה למשתנה המשותף ולשחרר אותו לאחר מכן. התיקון לקוד ייראה כך:\n\n```c\nvoid* increment_thread(void* arg) {\n    for (int i = 0; i < 100000; ++i) {\n        pthread_mutex_lock(&my_mutex);   // נעל את המוטקס לפני הגישה למשתנה המשותף\n        counter++;                       // קטע קריטי\n        pthread_mutex_unlock(&my_mutex); // שחרר את המוטקס לאחר הגישה\n    }\n    return NULL;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0265__Mutexes__CodeAnalysis__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:23:14", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Mutexes", "Concurrency", "Race Conditions", "Threads", "Synchronization"], "content": {"text": "נתונה תוכנית C המשתמשת במספר תהליכונים (threads) כדי להגדיל מונה גלובלי. עיין בקוד הבא. מהו הפלט הצפוי של התוכנית? האם הפלט יהיה תמיד זהה בריצות שונות? אם לא, מדוע? כיצד ניתן לתקן את הקוד כך שהמונה יגיע תמיד לערך הנכון?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <stdlib.h> // For exit\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 100000\n\nint counter = 0;\n\nvoid *increment_counter(void *arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        counter++;\n    }\n    pthread_exit(NULL);\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        if (pthread_create(&threads[i], NULL, increment_counter, NULL) != 0) {\n            perror(\"Failed to create thread\");\n            exit(EXIT_FAILURE);\n        }\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        if (pthread_join(threads[i], NULL) != 0) {\n            perror(\"Failed to join thread\");\n            exit(EXIT_FAILURE);\n        }\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפלט הצפוי התיאורטי של התוכנית הוא 500000 (כלומר, NUM_THREADS * INCREMENTS_PER_THREAD). אולם, בפועל, הפלט יהיה לרוב נמוך יותר מ-500000 וגם לא יהיה זהה בין ריצות שונות של התוכנית. הסיבה לכך היא תנאי מרוץ (Race Condition).\n\nפעולת `counter++` אינה אטומית. היא מורכבת משלוש פעולות ברמה נמוכה יותר (קריאת ערך המונה לתוך רגיסטר, הגדלת הערך ברגיסטר, וכתיבת הערך המעודכן בחזרה לזיכרון). כאשר מספר תהליכונים מבצעים פעולה זו במקביל ללא סנכרון, ייתכן שתהליכון אחד יקרא את ערך המונה, יגדיל אותו, אך לפני שיספיק לכתוב אותו בחזרה לזיכרון, תהליכון אחר יקרא את אותו ערך ישן של המונה. כתוצאה מכך, אחת מההגדלות (increments) תאבד, והמונה לא יגיע לערכו הסופי הנכון.\n\nכדי לתקן את הקוד ולהבטיח שהמונה יגיע תמיד לערך הנכון, יש להשתמש ב-mutex (מנעול הדדי) כדי להגן על הגישה למשתנה המשותף `counter`. יש לאתחל את ה-mutex לפני יצירת התהליכונים, לנעול אותו לפני הגישה ל-`counter++` ולשחרר אותו מיד לאחר מכן, ולבסוף להרוס את ה-mutex בסיום התוכנית. התיקון ייראה כך:\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n#include <stdlib.h>\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 100000\n\nint counter = 0;\npthread_mutex_t mutex; // הצהרה על mutex גלובלי\n\nvoid *increment_counter(void *arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&mutex);   // נעילת ה-mutex לפני גישה למשתנה המשותף\n        counter++;\n        pthread_mutex_unlock(&mutex); // שחרור ה-mutex לאחר הגישה\n    }\n    pthread_exit(NULL);\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    pthread_mutex_init(&mutex, NULL); // אתחול ה-mutex\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        if (pthread_create(&threads[i], NULL, increment_counter, NULL) != 0) {\n            perror(\"Failed to create thread\");\n            exit(EXIT_FAILURE);\n        }\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        if (pthread_join(threads[i], NULL) != 0) {\n            perror(\"Failed to join thread\");\n            exit(EXIT_FAILURE);\n        }\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    pthread_mutex_destroy(&mutex); // השמדת ה-mutex\n    return 0;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0266__Mutexes__CodeAnalysis__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:23:30", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Mutexes", "Concurrency", "Race Conditions"], "content": {"text": "נתונה תוכנית C המשתמשת בשני תהליכונים (threads) כדי להגדיל מונה משותף. עיין בקוד הנתון וענה על השאלות הבאות:", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\nint shared_counter = 0;\n\nvoid* increment_thread(void* arg) {\n    for (int i = 0; i < 100000; ++i) {\n        shared_counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_create(&tid1, NULL, increment_thread, NULL);\n    pthread_create(&tid2, NULL, increment_thread, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    printf(\"Final counter value: %d\\n\", shared_counter);\n\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "101.1", "text": "מהו הפלט הצפוי של התוכנית? האם הוא יהיה תמיד זהה? נמק.", "code_snippet": null, "options": null}, {"id": "101.2", "text": "תאר את הבעיה העיקרית בקוד הנתון וכיצד היא יכולה להתרחש.", "code_snippet": null, "options": null}, {"id": "101.3", "text": "תקן את הקוד הנתון באמצעות mutex כדי להבטיח שהמונה המשותף יגיע לערכו הנכון. כלול את כל השינויים הנדרשים (הצהרה, אתחול, שימוש וסיום) בקוד המתוקן.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון לשאלה 101:\n\n**101.1 פלט צפוי וקביעות:**\nהפלט הצפוי של התוכנית לא יהיה 200000. לרוב, הפלט יהיה ערך נמוך יותר מ-200000, והוא לא יהיה תמיד זהה בין הרצות שונות של התוכנית. הסיבה לכך היא תנאי מרוץ (Race Condition).\n\n**101.2 תיאור הבעיה:**\nהבעיה העיקרית בקוד היא תנאי מרוץ על המשתנה הגלובלי המשותף `shared_counter`. הפעולה `shared_counter++` נראית אטומית, אך בפועל היא מורכבת משלוש פעולות בסיסיות ברמת המעבד (CPU):\n1. קריאת הערך הנוכחי של `shared_counter` מהזיכרון לרג'יסטר.\n2. הגדלת הערך ברג'יסטר באחד.\n3. כתיבת הערך המעודכן מהרג'יסטר בחזרה לזיכרון.\n\nכאשר שני תהליכונים (או יותר) מנסים לבצע את הפעולה הזו בו-זמנית, ייתכן ששניהם יקראו את אותו ערך ישן של `shared_counter` לפני שאחד מהם הספיק לכתוב בחזרה את הערך המעודכן. לדוגמה, אם `shared_counter` הוא 0:\n- תהליכון A קורא 0.\n- תהליכון B קורא 0.\n- תהליכון A מגדיל ל-1 וכותב בחזרה 1.\n- תהליכון B מגדיל ל-1 (מ-0 שקרא) וכותב בחזרה 1.\nבמקרה זה, בוצעו שתי הגדלות, אך המונה הגיע ל-1 במקום ל-2, ואחת ההגדלות 'אבדה'. כתוצאה מכך, הערך הסופי של `shared_counter` יהיה נמוך מהצפוי (200000) ולא יהיה דטרמיניסטי.\n\n**101.3 תיקון הקוד באמצעות mutex:**\nכדי לתקן את הבעיה ולהבטיח שהמונה יגיע לערכו הנכון (200000), יש להשתמש ב-mutex כדי להגן על הגישה לאזור הקריטי (השורה `shared_counter++`). הנה הקוד המתוקן:\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n\nint shared_counter = 0;\npthread_mutex_t counter_mutex; // 1. הצהרה על mutex גלובלי\n\nvoid* increment_thread(void* arg) {\n    for (int i = 0; i < 100000; ++i) {\n        pthread_mutex_lock(&counter_mutex);   // 3. נעילת mutex לפני גישה לאזור הקריטי\n        shared_counter++;                     // האזור הקריטי\n        pthread_mutex_unlock(&counter_mutex); // 3. שחרור mutex לאחר סיום הגישה\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&counter_mutex, NULL); // 2. אתחול ה-mutex לפני יצירת התהליכונים\n\n    pthread_create(&tid1, NULL, increment_thread, NULL);\n    pthread_create(&tid2, NULL, increment_thread, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    printf(\"Final counter value: %d\\n\", shared_counter);\n\n    pthread_mutex_destroy(&counter_mutex); // 4. השמדת ה-mutex בסיום השימוש בו\n    return 0;\n}\n```\n\n**הסבר לתיקון:**\n1.  **הצהרה על mutex**: הוספנו משתנה גלובלי מסוג `pthread_mutex_t` בשם `counter_mutex`. זהו אובייקט הסנכרון שישמש להגנה על המונה.\n2.  **אתחול mutex**: בתוך פונקציית `main`, לפני יצירת התהליכונים, אתחלנו את ה-mutex באמצעות `pthread_mutex_init(&counter_mutex, NULL)`. אתחול זה מכין את ה-mutex לשימוש.\n3.  **נעילה ושחרור mutex**: בתוך פונקציית `increment_thread`, עטפנו את הפעולה `shared_counter++;` בקריאות ל-`pthread_mutex_lock(&counter_mutex)` ו-`pthread_mutex_unlock(&counter_mutex)`. קריאה ל-`lock` מנסה לנעול את ה-mutex; אם הוא כבר נעול על ידי תהליכון אחר, התהליכון הנוכחי ימתין עד שה-mutex ישוחרר. קריאה ל-`unlock` משחררת את ה-mutex. זה מבטיח שרק תהליכון אחד יוכל להיכנס לאזור הקריטי (להגדיל את `shared_counter`) בכל רגע נתון, ובכך מונע את תנאי המרוץ.\n4.  **השמדת mutex**: לאחר שכל התהליכונים סיימו את ריצתם ואין יותר צורך ב-mutex, השמדנו אותו באמצעות `pthread_mutex_destroy(&counter_mutex)` בתוך פונקציית `main`. פעולה זו משחררת את המשאבים שהוקצו ל-mutex."}, "difficulty_estimation": "Easy", "_source_file": "0267__Mutexes__CodeAnalysis__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:23:59", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Mutexes", "Synchronization", "Concurrency", "Threads"], "content": {"text": "נתונה תוכנית C המשתמשת בחוטים (threads) ובמנעול (mutex) כדי לעדכן משתנה גלובלי. קראו את הקוד המצורף וענו על השאלה הבאה:\n\nמה יהיה הערך הסופי המודפס של המשתנה הגלובלי `counter` לאחר שכל החוטים יסיימו את ריצתם, ומהי הסיבה לכך?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h> // For exit\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 100000\n\nint counter = 0;\npthread_mutex_t mtx;\n\nvoid* thread_function(void* arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&mtx); // Acquire mutex\n        counter++;\n        pthread_mutex_unlock(&mtx); // Release mutex\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    pthread_mutex_init(&mtx, NULL); // Initialize mutex\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_function, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    pthread_mutex_destroy(&mtx); // Destroy mutex\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הערך הסופי המודפס של המשתנה `counter` יהיה 500000.\n\nהסיבה לכך היא שהתוכנית משתמשת במנעול (mutex) כדי להגן על פעולת העדכון של המשתנה הגלובלי `counter`. כל חוט מבצע את הפעולה `counter++` בתוך קטע קריטי המוגן על ידי `pthread_mutex_lock` ו-`pthread_mutex_unlock`. מנגנון זה מבטיח שרק חוט אחד יכול לגשת ולשנות את `counter` בכל רגע נתון, ובכך מונע מצב מרוץ (race condition). כתוצאה מכך, כל אחת מ-100,000 ההגדלות שמבצע כל חוט (ישנם 5 חוטים) מבוצעת באופן בטוח ומשתקפת בערך הסופי של `counter`.\n\nחישוב: 5 חוטים * 100,000 הגדלות לכל חוט = 500,000."}, "difficulty_estimation": "Easy", "_source_file": "0268__Mutexes__CodeAnalysis__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:24:11", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Mutexes", "Synchronization", "Concurrency", "Deadlock"], "content": {"text": "נתונה תוכנית C המשתמשת בספריה `pthreads` ומגדילה משתנה גלובלי משותף `global_counter` באמצעות מספר תהליכונים. התוכנית מנסה להגן על הגישה למשתנה המשותף באמצעות mutex. עיין בקוד הנתון וענה על השאלה.\n\nמהי הבעיה העיקרית בקוד הנתון, וכיצד היא תשפיע על ריצת התוכנית ועל הערך הסופי של `global_counter`? כיצד ניתן לתקן את הבעיה?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep (optional, but good practice for real-world code)\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 100000\n\nint global_counter = 0;\npthread_mutex_t counter_mutex;\n\nvoid *thread_function(void *arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&counter_mutex);\n        global_counter++;\n        // חסר שחרור ה-mutex כאן!\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    pthread_mutex_init(&counter_mutex, NULL);\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_function, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", global_counter);\n\n    pthread_mutex_destroy(&counter_mutex);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הבעיה העיקרית בקוד היא שה-mutex ננעל באמצעות `pthread_mutex_lock()` בתוך הלולאה, אך לעולם אינו משוחרר באמצעות `pthread_mutex_unlock()`.\n\n**השפעה על ריצת התוכנית:**\nכאשר תהליכון כלשהו יקבל את ה-mutex בפעם הראשונה, הוא ינעל אותו. מכיוון שזהו mutex רגיל (לא רקורסיבי, שכן הוא מאותחל עם `NULL` attributes), ניסיון לנעול mutex שכבר ננעל על ידי אותו תהליכון (באיטרציה הבאה של הלולאה) יגרום לקיפאון (deadlock) של התהליכון עצמו. אם תהליכונים אחרים ינסו לנעול את ה-mutex לפני שהתהליכון הראשון נתקע, הם פשוט ימתינו ללא הגבלה מכיוון שה-mutex נשאר נעול. כתוצאה מכך, התוכנית כולה תיתקע ולא תסיים את ריצתה.\n\n**השפעה על הערך הסופי של `global_counter`:**\nהתוכנית לא תדפיס ערך סופי כלל מכיוון שהיא תיתקע לפני השורה המדפיסה את הערך. אם איכשהו היא הייתה ממשיכה, הערך הסופי של `global_counter` יהיה שגוי ולא יגיע ל-`NUM_THREADS * INCREMENTS_PER_THREAD` (שהוא הערך המצופה).\n\n**תיקון:**\nיש לשחרר את ה-mutex לאחר כל פעולת הגדלה של המונה. התיקון הוא הוספת השורה `pthread_mutex_unlock(&counter_mutex);` מיד לאחר השורה `global_counter++;` בתוך לולאת ה-`for` בפונקציה `thread_function`. כך הקטע הקריטי יהיה מוגן כראוי וה-mutex ישוחרר לאחר כל גישה למשתנה המשותף, מה שיאפשר לתהליכונים אחרים לגשת אליו.\n\n**קוד מתוקן (קטע רלוונטי):**\n```c\nvoid *thread_function(void *arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&counter_mutex);\n        global_counter++;\n        pthread_mutex_unlock(&counter_mutex); // התיקון\n    }\n    return NULL;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0269__Mutexes__CodeAnalysis__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:24:26", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Mutexes", "Synchronization", "Concurrency", "Deadlock"], "content": {"text": "נתונה תוכנית C המשתמשת בחוטים (threads) ובמנעול (mutex) כדי להגדיל מונה גלובלי. קראו את הקוד וציינו מה יקרה כאשר התוכנית תרוץ. נמקו את תשובתכם.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <stdlib.h> // For exit\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 100000\n\npthread_mutex_t counter_mutex;\nint counter = 0;\n\nvoid* increment_counter(void* arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&counter_mutex);\n        counter++;\n        // Bug: Missing pthread_mutex_unlock(&counter_mutex);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    pthread_mutex_init(&counter_mutex, NULL);\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        if (pthread_create(&threads[i], NULL, increment_counter, NULL) != 0) {\n            perror(\"Failed to create thread\");\n            exit(EXIT_FAILURE);\n        }\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        if (pthread_join(threads[i], NULL) != 0) {\n            perror(\"Failed to join thread\");\n            exit(EXIT_FAILURE);\n        }\n    }\n\n    pthread_mutex_destroy(&counter_mutex);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכנית תיכנס למצב של קיפאון (deadlock). הסיבה לכך היא שבפונקציה `increment_counter`, המנעול `counter_mutex` ננעל באמצעות `pthread_mutex_lock` אך לעולם אינו משוחרר באמצעות `pthread_mutex_unlock`. החוט הראשון שמצליח לנעול את המנעול יבצע את כל האיטרציות שלו בלולאה, אך המנעול יישאר נעול. כל חוט אחר שינסה לנעול את המנעול באמצעות `pthread_mutex_lock` ייחסם וימתין ללא הגבלת זמן לשחרור המנעול. כתוצאה מכך, קריאות `pthread_join` בפונקציית `main` לא יחזרו לעולם עבור החוטים החסומים, והתוכנית תיתקע."}, "difficulty_estimation": "Easy", "_source_file": "0270__Mutexes__CodeAnalysis__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:24:41", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Mutexes", "Concurrency", "Race Condition"], "content": {"text": "נתונה תוכנית C המשתמשת בשני תהליכונים (threads) כדי להגדיל מונה משותף (shared counter). כל תהליכון מגדיל את המונה מספר רב של פעמים. התוכנית מודפסת מטה:\n", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\n#define NUM_THREADS 2\n#define ITERATIONS 100000\n\nint counter = 0;\n\nvoid* increment_thread(void* arg) {\n    for (int i = 0; i < ITERATIONS; ++i) {\n        counter++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, increment_thread, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "מהי הבעיה העיקרית בקוד הנתון? הסבירו בקצרה.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "מהו הערך הסופי הצפוי של המונה (counter) לו התוכנית הייתה רצה באופן תקין וללא בעיות סנכרון?", "code_snippet": null, "options": null}, {"id": "1.3", "text": "האם הערך המודפס בפועל על ידי התוכנית יהיה בהכרח זהה לערך הצפוי? אם לא, תארו ערך אפשרי שונה והסבירו מדוע הוא יכול להתקבל.", "code_snippet": null, "options": null}, {"id": "1.4", "text": "תקנו את הפונקציה `increment_thread` ואת פונקציית `main` כך שישתמשו ב-mutex כדי למנוע את הבעיה שתיארתם. הציגו את הקוד המתוקן של שתי הפונקציות.", "code_snippet": "void* increment_thread(void* arg) {\n    // ... קוד מתוקן כאן ...\n}\n\nint main() {\n    // ... קוד מתוקן כאן ...\n}", "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\n1.1. הבעיה העיקרית בקוד היא תנאי מרוץ (race condition). מספר תהליכונים ניגשים ומשנים משתנה גלובלי משותף (counter) ללא מנגנון סנכרון מתאים. הפעולה `counter++` אינה אטומית ומורכבת ממספר הוראות מכונה (קריאה, הגדלה, כתיבה), ולכן תהליכונים שונים יכולים להפריע זה לזה ולגרום לאובדן עדכונים.\n\n1.2. הערך הסופי הצפוי של המונה (counter) לו התוכנית הייתה רצה באופן תקין הוא: `NUM_THREADS * ITERATIONS = 2 * 100000 = 200000`.\n\n1.3. לא, הערך המודפס בפועל על ידי התוכנית לא יהיה בהכרח זהה לערך הצפוי. סביר מאוד שהוא יהיה נמוך יותר מ-200000. לדוגמה, ייתכן ששני תהליכונים קוראים את הערך של `counter` (למשל, שניהם קוראים 100), שניהם מגדילים אותו ל-101, ושניהם כותבים 101 חזרה. במקרה כזה, שתי פעולות הגדלה תרמו רק להגדלה אחת בפועל, ואיבדנו עדכון אחד. ערך אפשרי יכול להיות כל מספר בין 0 ל-200000 (כולל), אך לרוב יהיה קרוב ל-200000 אך קטן ממנו.\n\n1.4. קוד מתוקן באמצעות mutex:\n```c\n#include <stdio.h>\n#include <pthread.h>\n\n#define NUM_THREADS 2\n#define ITERATIONS 100000\n\nint counter = 0;\npthread_mutex_t mutex; // הצהרה על mutex\n\nvoid* increment_thread(void* arg) {\n    for (int i = 0; i < ITERATIONS; ++i) {\n        pthread_mutex_lock(&mutex);   // נעילת mutex לפני הכניסה לקטע קריטי\n        counter++;                    // קטע קריטי\n        pthread_mutex_unlock(&mutex); // שחרור mutex לאחר היציאה מהקטע הקריטי\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    pthread_mutex_init(&mutex, NULL); // אתחול ה-mutex\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, increment_thread, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    pthread_mutex_destroy(&mutex); // השמדת ה-mutex\n\n    return 0;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0271__Mutexes__CodeAnalysis__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:25:01", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Mutexes", "Concurrency", "Deadlock"], "content": {"text": "נתונה תוכנית C המשתמשת ב-mutex להגנה על משתנה גלובלי משותף (counter). מספר תהליכונים (threads) מנסים לעדכן את המונה באמצעות הפונקציה `update_shared_counter`. נתחו את הקוד וזהו בעיה אפשרית.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For usleep\n\npthread_mutex_t counter_mutex = PTHREAD_MUTEX_INITIALIZER;\nint shared_counter = 0;\n\nvoid* update_shared_counter(void* arg) {\n    pthread_mutex_lock(&counter_mutex); // Acquire lock\n\n    shared_counter++; // Critical section\n\n    if (shared_counter % 5 == 0) {\n        printf(\"Counter reached a multiple of 5: %d (Thread ID: %lu)\\n\", shared_counter, (unsigned long)pthread_self());\n        // BUG: Forgot to unlock the mutex before early return\n        return NULL; // Early exit\n    }\n\n    // Simulate some other work that might take time\n    usleep(10); // Small sleep to increase chance of other threads trying to acquire lock\n\n    pthread_mutex_unlock(&counter_mutex); // Release lock\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[10];\n    for (int i = 0; i < 10; ++i) {\n        pthread_create(&threads[i], NULL, update_shared_counter, NULL);\n    }\n\n    for (int i = 0; i < 10; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", shared_counter);\n    pthread_mutex_destroy(&counter_mutex); // Clean up mutex\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הבעיה: קיפאון (Deadlock).\n\nהסבר:\nהפונקציה `update_shared_counter` נועלת את ה-mutex בתחילתה באמצעות `pthread_mutex_lock`. אם התנאי `shared_counter % 5 == 0` מתקיים, הפונקציה מבצעת יציאה מוקדמת (early return) מבלי לשחרר את ה-mutex. כתוצאה מכך, ה-mutex נשאר נעול. כאשר תהליכון אחר ינסה לגשת לקטע הקריטי (כלומר, יקרא ל-`pthread_mutex_lock`), הוא ייחסם לצמיתות וימתין לשחרור ה-mutex שלעולם לא יגיע, מה שיוביל לקיפאון של התוכנית.\n\nתיקון:\nיש לשחרר את ה-mutex בכל נתיבי היציאה מהפונקציה. יש להוסיף קריאה ל-`pthread_mutex_unlock(&counter_mutex);` לפני שורת ה-`return NULL;` בתוך בלוק ה-`if`.\n\nקוד מתוקן (השינוי בשורה 16):\n```c\n#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For usleep\n\npthread_mutex_t counter_mutex = PTHREAD_MUTEX_INITIALIZER;\nint shared_counter = 0;\n\nvoid* update_shared_counter(void* arg) {\n    pthread_mutex_lock(&counter_mutex); // Acquire lock\n\n    shared_counter++; // Critical section\n\n    if (shared_counter % 5 == 0) {\n        printf(\"Counter reached a multiple of 5: %d (Thread ID: %lu)\\n\", shared_counter, (unsigned long)pthread_self());\n        pthread_mutex_unlock(&counter_mutex); // FIX: Release lock before early return\n        return NULL; // Early exit\n    }\n\n    // Simulate some other work that might take time\n    usleep(10); // Small sleep to increase chance of other threads trying to acquire lock\n\n    pthread_mutex_unlock(&counter_mutex); // Release lock\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[10];\n    for (int i = 0; i < 10; ++i) {\n        pthread_create(&threads[i], NULL, update_shared_counter, NULL);\n    }\n\n    for (int i = 0; i < 10; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", shared_counter);\n    pthread_mutex_destroy(&counter_mutex); // Clean up mutex\n    return 0;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0272__Mutexes__CodeAnalysis__Easy.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:25:22", "_subject": "Concurrency"}, {"id": 7, "type": "CodeAnalysis", "topic": ["Mutexes", "Concurrency", "Race Conditions", "Pthreads"], "content": {"text": "נתונה תוכנית ה-C הבאה המשתמשת ב-pthreads ובמנעולים (mutexes) כדי לעדכן שני משתנים גלובליים משותפים על ידי מספר תהליכונים (threads). נתחו את התוכנית וענו על השאלות הבאות בהנחה שכל קריאות המערכת מצליחות:\n\n1. מהו הערך *הצפוי* הסופי של `shared_counter_a` ושל `shared_counter_b`?\n2. מהם הערכים *האפשריים* הסופיים של `shared_counter_a` ושל `shared_counter_b` לאחר הרצת התוכנית מספר פעמים?\n3. הסבירו את ההבדל בין התנהגות העדכון של `shared_counter_a` לזו של `shared_counter_b`, ומהו הסיכון הטמון בגישה ל-`shared_counter_b` כפי שהיא ממומשת.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n\n#define NUM_THREADS 5\n#define ITERATIONS_PER_THREAD 100000\n\nint shared_counter_a = 0;\nint shared_counter_b = 0;\npthread_mutex_t counter_mutex;\n\nvoid* thread_func(void* arg) {\n    long thread_id = (long)arg;\n    for (int i = 0; i < ITERATIONS_PER_THREAD; ++i) {\n        // Protecting shared_counter_a with mutex\n        pthread_mutex_lock(&counter_mutex);\n        shared_counter_a++;\n        pthread_mutex_unlock(&counter_mutex);\n\n        // Accessing shared_counter_b without mutex\n        shared_counter_b++;\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    pthread_mutex_init(&counter_mutex, NULL);\n\n    for (long i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, (void*)i);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    pthread_mutex_destroy(&counter_mutex);\n\n    printf(\"Final shared_counter_a: %d\\n\", shared_counter_a);\n    printf(\"Final shared_counter_b: %d\\n\", shared_counter_b);\n\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. **ערכים צפויים:**\n   - `shared_counter_a`: כל תהליכון מבצע `ITERATIONS_PER_THREAD` (שהוא 100,000) איטרציות, וישנם `NUM_THREADS` (שהוא 5) תהליכונים. כל עדכון של `shared_counter_a` מוגן על ידי המנעול `counter_mutex`. לכן, הערך הצפוי והנכון של `shared_counter_a` יהיה `NUM_THREADS * ITERATIONS_PER_THREAD = 5 * 100,000 = 500,000`.\n   - `shared_counter_b`: באופן לוגי, גם `shared_counter_b` אמור לעבור את אותו מספר עדכונים: `5 * 100,000 = 500,000`.\n\n2. **ערכים אפשריים:**\n   - `shared_counter_a`: הערך האפשרי היחיד עבור `shared_counter_a` הוא `500,000`. המנעול מבטיח שכל פעולת `shared_counter_a++` תתבצע בצורה אטומית ובטוחה ממירוץ תהליכים.\n   - `shared_counter_b`: הערך האפשרי עבור `shared_counter_b` יהיה בין 1 (אם רק תהליכון אחד הספיק לעדכן אותו לפני שכל השאר סיימו או אם מתזמן המשימות גרם לאובדן כל העדכונים למעט אחד) ל-`500,000` (כולל). כלומר, הוא יכול להיות כל ערך בטווח זה, אך לרוב הוא יהיה נמוך מהערך הצפוי של `500,000`. הוא יכול גם להיות 0 אם אף תהליכון לא הספיק לעדכן אותו (אך זה לא סביר עם `pthread_join`). תיאורטית, הוא יכול להיות גם `500,000` במקרה נדיר מאוד של ריצה חסרת מזל של מתזמן התהליכונים, אך הדבר אינו מובטח ואינו סביר.\n\n3. **הסבר ההבדל והסיכון:**\n   - `shared_counter_a` מוגן על ידי `counter_mutex`. לפני כל פעולת הגדלה (`shared_counter_a++`), התהליכון נועל את המנעול, ולאחר הפעולה הוא משחרר אותו. זה מבטיח שהפעולה `shared_counter_a++` (שהיא למעשה קריאה, הגדלה וכתיבה) תתבצע כאופרציה אטומית, ללא הפרעה מתהליכונים אחרים. לכן, אין מצב מרוץ (race condition) עבור `shared_counter_a`, והערך הסופי שלו תמיד יהיה נכון וצפוי.\n   - `shared_counter_b` אינו מוגן על ידי המנעול. הגישה ל-`shared_counter_b` והגדלתו (`shared_counter_b++`) מתבצעת מחוץ לקטע הקריטי המוגן. פעולת הגדלה `x++` אינה אטומית; היא מורכבת משלושה שלבים: 1. קריאת הערך הנוכחי של `x` לתוך רגיסטר. 2. הגדלת הערך ברגיסטר. 3. כתיבת הערך המעודכן חזרה ל-`x`. כאשר מספר תהליכונים מנסים לבצע פעולה זו בו-זמנית, עלול להיווצר מצב מרוץ. לדוגמה, שני תהליכונים יכולים לקרוא את אותו ערך של `shared_counter_b` (למשל 100), שניהם יגדילו אותו ל-101 ברגיסטרים שלהם, ושניהם יכתבו חזרה 101. במקרה כזה, בוצעו שתי פעולות הגדלה אך `shared_counter_b` גדל רק באחד במקום בשניים. כתוצאה מכך, הערך הסופי של `shared_counter_b` יהיה לרוב נמוך מהערך הצפוי, והוא אינו דטרמיניסטי. הסיכון הוא שהתוכנית תפיק תוצאות שגויות ולא עקביות, מה שעלול להוביל לבאגים קשים לאיתור ביישומים מורכבים יותר."}, "difficulty_estimation": "Medium", "_source_file": "0273__Mutexes__CodeAnalysis__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:25:47", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Mutexes", "Concurrency", "Deadlock", "Threads"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בתהליכונים (threads) ובמנעולים (mutexes) לצורך סנכרון גישה למשאבים משותפים. נתח את הקוד וענה על השאלות הבאות:\n\nהאם התוכנית תרוץ עד לסיומה בהצלחה? אם לא, תאר את התקלה שתתרחש והסבר מדוע היא מתרחשת. במידה ותיארת תקלה, הצע שינוי מינימלי בקוד למניעתה, והסבר כיצד השינוי מונע את התקלה. מהם הערכים הסופיים של shared_resource1 ו-shared_resource2 במידה והתוכנית תרוץ בהצלחה (לאחר התיקון)?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For usleep\n\nint shared_resource1 = 0;\nint shared_resource2 = 0;\n\npthread_mutex_t mutex1 = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_t mutex2 = PTHREAD_MUTEX_INITIALIZER;\n\nvoid* thread_func_A(void* arg) {\n    printf(\"Thread A: Attempting to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread A: Locked mutex1. Sleeping...\\n\");\n    usleep(100); // Simulate work or context switch\n    printf(\"Thread A: Attempting to lock mutex2...\\n\");\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread A: Locked mutex2. Modifying resources...\\n\");\n\n    shared_resource1 += 10;\n    shared_resource2 += 20;\n\n    printf(\"Thread A: Unlocking mutex2...\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread A: Unlocking mutex1...\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread A: Finished.\\n\");\n    return NULL;\n}\n\nvoid* thread_func_B(void* arg) {\n    printf(\"Thread B: Attempting to lock mutex2...\\n\");\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread B: Locked mutex2. Sleeping...\\n\");\n    usleep(100); // Simulate work or context switch\n    printf(\"Thread B: Attempting to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread B: Locked mutex1. Modifying resources...\\n\");\n\n    shared_resource1 += 5;\n    shared_resource2 += 15;\n\n    printf(\"Thread B: Unlocking mutex1...\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread B: Unlocking mutex2...\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread B: Finished.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid[2];\n\n    printf(\"Main: Creating thread A...\\n\");\n    pthread_create(&tid[0], NULL, thread_func_A, NULL);\n    printf(\"Main: Creating thread B...\\n\");\n    pthread_create(&tid[1], NULL, thread_func_B, NULL);\n\n    pthread_join(tid[0], NULL);\n    pthread_join(tid[1], NULL);\n\n    printf(\"Main: Final values: shared_resource1 = %d, shared_resource2 = %d\\n\", shared_resource1, shared_resource2);\n\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכנית לא תרוץ עד לסיומה בהצלחה. סביר מאוד שתתרחש תקלת \"קיפאון\" (Deadlock).\n\n**הסבר לתקלה:**\nקיפאון מתרחש כאשר שני תהליכונים (או יותר) מחזיקים במשאבים שונים וכל אחד מהם ממתין למשאב המוחזק על ידי האחר, כך שאף אחד מהם לא יכול להמשיך. במקרה זה:\n1.  **תהליכון A** מנסה לנעול את `mutex1` ואז את `mutex2`.\n2.  **תהליכון B** מנסה לנעול את `mutex2` ואז את `mutex1`.\n\nבעקבות קריאות ה-`usleep` שמדמות עבודת עיבוד או החלפת קונטקסט, ייתכן תרחיש כזה:\n*   תהליכון A מצליח לנעול את `mutex1`.\n*   מערכת ההפעלה מבצעת החלפת קונטקסט לתהליכון B.\n*   תהליכון B מצליח לנעול את `mutex2`.\n*   כעת, תהליכון A, שמחזיק ב-`mutex1`, מנסה לנעול את `mutex2` אך הוא כבר נעול על ידי תהליכון B. תהליכון A נכנס למצב המתנה.\n*   באותו זמן, תהליכון B, שמחזיק ב-`mutex2`, מנסה לנעול את `mutex1` אך הוא כבר נעול על ידי תהליכון A. תהליכון B נכנס גם הוא למצב המתנה.\n\nשני התהליכונים ממתינים זה לזה לשחרר את המנעול שהם צריכים, וכך הם נכנסים למצב של קיפאון ולא יכולים להמשיך את ריצתם. התוכנית תיתקע ולא תגיע לשורות ההדפסה הסופיות ב-`main`.\n\n**שינוי מינימלי למניעת הקיפאון:**\nכדי למנוע קיפאון, יש לוודא שכל התהליכונים מנסים לנעול את המשאבים באותו סדר. אם כל התהליכונים מנסים לנעול את `mutex1` ואז את `mutex2` (או להפך), לא ייווצר מצב בו תהליכון אחד מחזיק ב-`mutex1` ומחכה ל-`mutex2` בעוד שהשני מחזיק ב-`mutex2` ומחכה ל-`mutex1`.\n\nנשנה את הפונקציה `thread_func_B` כך שתנעל את המנעולים באותו סדר כמו `thread_func_A`:\n\n```c\nvoid* thread_func_B(void* arg) {\n    printf(\"Thread B: Attempting to lock mutex1...\\n\"); // Changed order\n    pthread_mutex_lock(&mutex1); // Changed order\n    printf(\"Thread B: Locked mutex1. Sleeping...\\n\");\n    usleep(100); // Simulate work or context switch\n    printf(\"Thread B: Attempting to lock mutex2...\\n\"); // Changed order\n    pthread_mutex_lock(&mutex2); // Changed order\n    printf(\"Thread B: Locked mutex2. Modifying resources...\\n\");\n\n    shared_resource1 += 5;\n    shared_resource2 += 15;\n\n    printf(\"Thread B: Unlocking mutex2...\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread B: Unlocking mutex1...\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread B: Finished.\\n\");\n    return NULL;\n}\n```\n\n**הסבר כיצד השינוי מונע את התקלה:**\nלאחר השינוי, שני התהליכונים (A ו-B) מנסים לנעול את `mutex1` ואז את `mutex2`. אם תהליכון A נועל את `mutex1`, תהליכון B ימתין עד ש-`mutex1` ישוחרר. לאחר ש-`mutex1` ישוחרר, תהליכון אחר (או A או B) יצליח לנעול אותו, ולאחר מכן ינסה לנעול את `mutex2`. מכיוון ששני המנעולים נרכשים באותו סדר, לא ייווצר מצב מעגלי של המתנה הדדית. תהליכון אחד יסיים את הקטע הקריטי שלו וישחרר את המנעולים, מה שיאפשר לתהליכון השני להמשיך.\n\n**ערכים סופיים לאחר התיקון:**\nלאחר התיקון, התוכנית תרוץ בהצלחה. כל תהליכון יבצע את פעולותיו פעם אחת בתוך קטע קריטי המוגן על ידי שני המנעולים.\n*   `shared_resource1` יוגדל ב-10 (על ידי A) וב-5 (על ידי B). סה\"כ: `0 + 10 + 5 = 15`.\n*   `shared_resource2` יוגדל ב-20 (על ידי A) וב-15 (על ידי B). סה\"כ: `0 + 20 + 15 = 35`.\n\nהערכים הסופיים יהיו: `shared_resource1 = 15`, `shared_resource2 = 35`."}, "difficulty_estimation": "Medium", "_source_file": "0274__Mutexes__CodeAnalysis__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:26:16", "_subject": "Concurrency"}, {"id": 7, "type": "CodeAnalysis", "topic": ["Mutexes", "Concurrency", "Threads", "Race Conditions"], "content": {"text": "נתונה תוכנית C המשתמשת ב-pthreads ובמנעול (mutex) כדי להגן על מונה גלובלי משותף. ענו על השאלות הבאות בהתבסס על הקוד:", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <stdlib.h> // For malloc, free, exit\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 100000\n\nlong long global_counter = 0;\npthread_mutex_t counter_mutex;\n\nvoid* thread_function(void* arg) {\n    int thread_id = *(int*)arg;\n    free(arg); // Free memory allocated for thread_id\n\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&counter_mutex);\n        global_counter++;\n        pthread_mutex_unlock(&counter_mutex);\n    }\n    printf(\"Thread %d finished its increments.\\n\", thread_id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    int *thread_ids[NUM_THREADS]; // To pass unique IDs to threads\n\n    pthread_mutex_init(&counter_mutex, NULL);\n\n    printf(\"Main thread: Starting %d threads...\\n\", NUM_THREADS);\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        thread_ids[i] = malloc(sizeof(int));\n        if (thread_ids[i] == NULL) {\n            perror(\"Failed to allocate memory for thread ID\");\n            exit(EXIT_FAILURE);\n        }\n        *thread_ids[i] = i + 1;\n        if (pthread_create(&threads[i], NULL, thread_function, (void*)thread_ids[i]) != 0) {\n            perror(\"pthread_create failed\");\n            // Clean up allocated memory before exiting\n            for (int j = 0; j <= i; ++j) {\n                if (thread_ids[j] != NULL) free(thread_ids[j]);\n            }\n            pthread_mutex_destroy(&counter_mutex);\n            return 1;\n        }\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Main thread: All threads finished.\\n\");\n    printf(\"Main thread: Final global_counter value: %lld\\n\", global_counter);\n\n    pthread_mutex_destroy(&counter_mutex);\n\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "7.1", "text": "מהו הערך הסופי המובטח של המונה הגלובלי `global_counter` לאחר סיום ריצת כל התהליכונים? נמקו.", "code_snippet": null, "options": null}, {"id": "7.2", "text": "האם סדר הפלט של ההודעות 'Thread X finished its increments.' הוא דטרמיניסטי או לא דטרמיניסטי? נמקו.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. הערך הסופי המובטח של המונה הגלובלי `global_counter` הוא 500000.\n   נימוק: המנעול `counter_mutex` מגן כראוי על הגישה למשתנה המשותף `global_counter`. כל תהליכון מבצע 100,000 הגדלות (INCREMENTS_PER_THREAD), וישנם 5 תהליכונים (NUM_THREADS). מכיוון שכל הגדלה מבוצעת בתוך קטע קריטי המוגן על ידי המנעול, כל הפעולות אטומיות ומונעות מצבי מרוץ. לכן, המונה יגיע לערך הסופי המדויק של 5 * 100,000 = 500,000.\n\n2. סדר הפלט של ההודעות 'Thread X finished its increments.' הוא לא דטרמיניסטי.\n   נימוק: למרות שהמונה הגלובלי מוגן על ידי מנעול, פעולת ההדפסה (`printf`) עצמה מתבצעת *מחוץ* לקטע הקריטי המוגן על ידי `counter_mutex`. תהליכונים שונים רצים במקביל, ומתזמן מערכת ההפעלה קובע את סדר הביצוע שלהם. לכן, אין ערובה לסדר שבו כל תהליכון יסיים את לולאת ההגדלות וידפיס את ההודעה שלו. סדר ההדפסה יכול להשתנות בין הרצות שונות של התוכנית."}, "difficulty_estimation": "Medium", "_source_file": "0275__Mutexes__CodeAnalysis__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:26:41", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Concurrency", "Threads", "Mutexes", "Race Conditions"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בחוטים (threads) ובמנגנון mutex. התוכנית מבצעת שתי סדרות של פעולות הגדלה של מונה משותף: אחת ללא הגנת mutex ואחת עם הגנת mutex.\n\nמה יהיה הפלט הצפוי של התוכנית? הסבירו בפירוט את ההבדל בפלט בין שני המקרים (עם ובלי mutex), וכיצד מנגנון ה-mutex פותר את הבעיה הקיימת במקרה הראשון.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n\n#define NUM_THREADS 5\n#define ITERATIONS_PER_THREAD 100000\n\nint shared_counter = 0;\npthread_mutex_t counter_mutex;\n\nvoid* increment_with_mutex(void* arg) {\n    for (int i = 0; i < ITERATIONS_PER_THREAD; i++) {\n        pthread_mutex_lock(&counter_mutex);\n        shared_counter++;\n        pthread_mutex_unlock(&counter_mutex);\n    }\n    return NULL;\n}\n\nvoid* increment_without_mutex(void* arg) {\n    for (int i = 0; i < ITERATIONS_PER_THREAD; i++) {\n        shared_counter++; // Race condition here\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    int i;\n\n    // Initialize mutex\n    pthread_mutex_init(&counter_mutex, NULL);\n\n    printf(\"Starting threads WITHOUT mutex protection...\\n\");\n    shared_counter = 0; // Reset for the first run\n    for (i = 0; i < NUM_THREADS; i++) {\n        pthread_create(&threads[i], NULL, increment_without_mutex, NULL);\n    }\n    for (i = 0; i < NUM_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    printf(\"Final counter value WITHOUT mutex: %d\\n\", shared_counter);\n\n    printf(\"\\nStarting threads WITH mutex protection...\\n\");\n    shared_counter = 0; // Reset for the second run\n    for (i = 0; i < NUM_THREADS; i++) {\n        pthread_create(&threads[i], NULL, increment_with_mutex, NULL);\n    }\n    for (i = 0; i < NUM_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n    printf(\"Final counter value WITH mutex: %d\\n\", shared_counter);\n\n    // Destroy mutex\n    pthread_mutex_destroy(&counter_mutex);\n\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פלט צפוי:\nStarting threads WITHOUT mutex protection...\nFinal counter value WITHOUT mutex: [ערך כלשהו, לרוב נמוך מ-500000]\n\nStarting threads WITH mutex protection...\nFinal counter value WITH mutex: 500000\n\nהסבר:\n\n1.  **מקרה ללא הגנת mutex (increment_without_mutex):**\n    במקרה זה, מספר חוטים (NUM_THREADS = 5) מנסים להגדיל מונה משותף (`shared_counter`) בו-זמנית, כאשר כל חוט מבצע ITERATIONS_PER_THREAD = 100,000 איטרציות. סך האיטרציות הצפוי הוא 5 * 100,000 = 500,000.\n    עם זאת, הפעולה `shared_counter++` אינה אטומית. היא מורכבת למעשה משלוש פעולות ברמה נמוכה יותר:\n    א. קריאת הערך הנוכחי של `shared_counter` מהזיכרון.\n    ב. הגדלת הערך ביחידה.\n    ג. כתיבת הערך החדש חזרה לזיכרון.\n    כאשר מספר חוטים מבצעים פעולות אלו במקביל, עלול להיווצר תנאי מרוץ (Race Condition). לדוגמה, שני חוטים עשויים לקרוא את אותו ערך של `shared_counter`, שניהם יגדילו אותו, ושניהם יכתבו את הערך המוגדל חזרה, וכתוצאה מכך הגדלה אחת תאבד. לכן, הערך הסופי של `shared_counter` במקרה זה יהיה כמעט תמיד נמוך מ-500,000, והוא ישתנה בין הרצות שונות של התוכנית.\n\n2.  **מקרה עם הגנת mutex (increment_with_mutex):**\n    במקרה זה, אנו משתמשים במנגנון `pthread_mutex_t` (mutex) כדי להגן על הקטע הקריטי (Critical Section), שהוא הפעולה `shared_counter++`.\n    *   לפני שחוט ניגש להגדיל את `shared_counter`, הוא קורא ל-`pthread_mutex_lock(&counter_mutex)`. קריאה זו מבטיחה שרק חוט אחד יכול להיכנס לקטע הקריטי בכל רגע נתון. אם חוט אחר כבר מחזיק את ה-mutex, החוט הנוכחי ייחסם (ימתין) עד שה-mutex ישוחרר.\n    *   לאחר שהחוט סיים את הפעולה בקטע הקריטי (הגדלת המונה), הוא קורא ל-`pthread_mutex_unlock(&counter_mutex)` כדי לשחרר את ה-mutex, ובכך לאפשר לחוט אחר שחוסם להיכנס.\n    מנגנון זה מבטיח שהפעולה `shared_counter++` תבוצע באופן אטומי מבחינת הגישה למונה המשותף. כל הגדלה מבוצעת במלואה על ידי חוט אחד לפני שחוט אחר יכול לגשת למונה. לכן, הערך הסופי של `shared_counter` במקרה זה יהיה תמיד 500,000 (5 חוטים * 100,000 איטרציות לחוט). ה-mutex פותר ביעילות את תנאי המרוץ על ידי אכיפת הדרה הדדית (Mutual Exclusion)."}, "difficulty_estimation": "Medium", "_source_file": "0276__Mutexes__CodeAnalysis__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:27:01", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Mutexes", "Threads", "Concurrency", "Shared Memory"], "content": {"text": "נתונה התוכנית הבאה המשתמשת ב-pthread וב-mutex:\nמטרת התוכנית היא להגדיל מונה גלובלי (shared_counter) על ידי מספר תהליכונים (threads) ולהדפיס את מצבו. ענו על השאלות הבאות בהתבסס על הקוד הנתון:", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For usleep\n\n#define NUM_THREADS 5\n#define NUM_INCREMENTS_PER_THREAD 2\n\nint shared_counter = 0;\npthread_mutex_t counter_mutex;\n\nvoid *thread_func(void *arg) {\n    int i;\n    int thread_id = *(int*)arg;\n    int local_val_at_increment;\n\n    for (i = 0; i < NUM_INCREMENTS_PER_THREAD; i++) {\n        pthread_mutex_lock(&counter_mutex);\n        // Critical section\n        shared_counter++;\n        local_val_at_increment = shared_counter; // Capture value inside critical section\n        pthread_mutex_unlock(&counter_mutex);\n\n        // This print is outside the critical section\n        printf(\"Thread %d: Counter incremented to %d (shared: %d)\\n\",\n               thread_id, local_val_at_increment, shared_counter);\n        usleep(1000); // Simulate some work/delay\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    int thread_ids[NUM_THREADS];\n\n    pthread_mutex_init(&counter_mutex, NULL);\n\n    for (int i = 0; i < NUM_THREADS; i++) {\n        thread_ids[i] = i + 1;\n        pthread_create(&threads[i], NULL, thread_func, &thread_ids[i]);\n    }\n\n    for (int i = 0; i < NUM_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final shared_counter value: %d\\n\", shared_counter);\n\n    pthread_mutex_destroy(&counter_mutex);\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "1.1", "text": "מה יהיה הערך הסופי של המשתנה `shared_counter` בסיום ריצת התוכנית? נמק.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "תארו פלט אפשרי אחד של התוכנית. הסבירו מדוע הערך המודפס תחת \"shared: %d\" בשורה `printf(\"Thread %d: Counter incremented to %d (shared: %d)\\n\", ...)` עשוי להיות שונה מהערך המודפס תחת \"Counter incremented to %d\" באותה שורה.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "האם ייתכנו תנאי מרוץ (race conditions) בתוכנית זו? אם כן, ציינו היכן ומדוע. אם לא, הסבירו מדוע.", "code_snippet": null, "options": null}, {"id": "1.4", "text": "מה יקרה אם נזיז את שורת ה-`printf` (שורה 20 בקוד המקורי) אל תוך ה-critical section, מיד לאחר שורת `local_val_at_increment = shared_counter;` (שורה 17 בקוד המקורי)? תארו פלט אפשרי במקרה זה והסבירו את ההבדל מהמקרה המקורי.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  הערך הסופי של `shared_counter` יהיה 10.\n    ישנם NUM_THREADS (5) תהליכונים, וכל תהליכון מבצע NUM_INCREMENTS_PER_THREAD (2) הגדלות. כל הגדלה של `shared_counter` מוגנת על ידי mutex (`counter_mutex`), מה שמבטיח שכל הגדלה מתבצעת באופן אטומי וללא תנאי מרוץ. לכן, כל 5*2=10 ההגדלות יבוצעו בהצלחה, והמונה יגיע לערך 10.\n\n2.  פלט אפשרי אחד יכול להיות: (הסדר של שורות ה-printf יכול להשתנות)\n    ```\n    Thread 1: Counter incremented to 1 (shared: 1)\n    Thread 2: Counter incremented to 2 (shared: 2)\n    Thread 3: Counter incremented to 3 (shared: 3)\n    Thread 4: Counter incremented to 4 (shared: 4)\n    Thread 5: Counter incremented to 5 (shared: 5)\n    Thread 1: Counter incremented to 6 (shared: 6)\n    Thread 2: Counter incremented to 7 (shared: 7)\n    Thread 3: Counter incremented to 8 (shared: 8)\n    Thread 4: Counter incremented to 9 (shared: 9)\n    Thread 5: Counter incremented to 10 (shared: 10)\n    Final shared_counter value: 10\n    ```\n    \n    עם זאת, ייתכן גם פלט שבו הערך של `shared_counter` המודפס תחת \"shared: %d\" יהיה גבוה יותר מהערך של `local_val_at_increment`. לדוגמה:\n    ```\n    Thread 1: Counter incremented to 1 (shared: 3)\n    Thread 2: Counter incremented to 2 (shared: 3)\n    Thread 3: Counter incremented to 3 (shared: 3)\n    Thread 4: Counter incremented to 4 (shared: 4)\n    Thread 5: Counter incremented to 5 (shared: 5)\n    Thread 1: Counter incremented to 6 (shared: 7)\n    Thread 2: Counter incremented to 7 (shared: 7)\n    Thread 3: Counter incremented to 8 (shared: 8)\n    Thread 4: Counter incremented to 9 (shared: 9)\n    Thread 5: Counter incremented to 10 (shared: 10)\n    Final shared_counter value: 10\n    ```\n    ההבדל נובע מכך ש-`local_val_at_increment` הוא משתנה מקומי לכל קריאה של הלולאה בתהליכון, והוא מקבל את ערכו של `shared_counter` *בזמן* ההגדלה, כאשר ה-mutex נעול. לעומת זאת, `shared_counter` (המודפס כ-\"shared: %d\") הוא משתנה גלובלי, והגישה אליו בשורת ה-`printf` מתבצעת *לאחר* שה-mutex שוחרר. בשלב זה, תהליכונים אחרים יכלו כבר לנעול את ה-mutex, להגדיל את `shared_counter`, ולשחרר אותו שוב, כך שהערך הגלובלי יכול להיות גבוה יותר מזה שנקלט במשתנה המקומי של התהליכון הנוכחי.\n\n3.  לא, לא ייתכנו תנאי מרוץ על המשתנה `shared_counter` בכל הנוגע לפעולת ההגדלה (`shared_counter++`). פעולה זו מוגנת באופן מלא על ידי ה-`counter_mutex`. כל תהליכון חייב לנעול את ה-mutex לפני שהוא ניגש ל-`shared_counter` כדי להגדיל אותו, ומשחרר אותו רק לאחר מכן. זה מבטיח אקסקלוסיביות הדדית (mutual exclusion) עבור הגישה למונה. עם זאת, יש לזכור שפעולת ה-`printf` עצמה אינה מוגנת על ידי ה-mutex, מה שאומר ששורות הפלט מתהליכונים שונים יכולות להתערבב באופן לא צפוי. זו אינה 'תנאי מרוץ' במובן של שינוי לא נכון של נתונים משותפים, אלא 'מרוץ' על משאב הפלט (stdout).\n\n4.  אם נזיז את שורת ה-`printf` אל תוך ה-critical section, מיד לאחר שורת `local_val_at_increment = shared_counter;`, הפלט ישתנה באופן הבא:\n    *   הפלט יהיה תמיד עקבי: הערך המודפס תחת \"Counter incremented to %d\" והערך תחת \"shared: %d\" יהיו תמיד זהים, ויישקפו את הערך של `shared_counter` מיד לאחר הגדלתו על ידי אותו תהליכון.\n    *   שורות הפלט של התהליכונים השונים לא יתערבבו ביניהן. כל שורת `printf` תבוצע במלואה כאשר ה-mutex נעול, מה שיבטיח שאף תהליכון אחר לא יפריע להדפסה או ישנה את `shared_counter` באמצע ההדפסה של תהליכון אחר. הפלט יהיה סדרה של הגדלות, כאשר כל הגדלה וההדפסה שלה מהוות יחידה אטומית.\n    *   הסדר הכרונולוגי של ההגדלות וההדפסה ישקף את סדר רכישת ה-mutex על ידי התהליכונים. לדוגמה:\n        ```\n        Thread 1: Counter incremented to 1 (shared: 1)\n        Thread 2: Counter incremented to 2 (shared: 2)\n        Thread 1: Counter incremented to 3 (shared: 3)\n        Thread 3: Counter incremented to 4 (shared: 4)\n        ...\n        ```\n    ההבדל המרכזי הוא שההדפסה הופכת לחלק מהפעולה האטומית, ובכך מבטיחה עקביות בין הערך המקומי שנקלט לערך הגלובלי בזמן ההדפסה, ומונעת ערבוב של פלט תהליכונים שונים."}, "difficulty_estimation": "Medium", "_source_file": "0277__Mutexes__CodeAnalysis__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:27:32", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Mutexes", "Threads", "Concurrency", "Race Conditions"], "content": {"text": "נתונה התוכנית הבאה, המשתמשת בחוטים (threads) ובמוטקס (mutex) כדי לעדכן משתנה גלובלי משותף. נתון שכל קריאות המערכת מצליחות.\n\nמה יהיה הפלט הסופי של התוכנית? הסבירו מדוע, ומה היה קורה אם המוטקס לא היה בשימוש.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\n#define NUM_THREADS 2\n#define INCREMENTS_PER_THREAD 100000\n\nint counter = 0;\npthread_mutex_t mutex;\n\nvoid* thread_func(void* arg) {\n    int i;\n    for (i = 0; i < INCREMENTS_PER_THREAD; i++) {\n        pthread_mutex_lock(&mutex);\n        counter++;\n        pthread_mutex_unlock(&mutex);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    int i;\n\n    pthread_mutex_init(&mutex, NULL);\n\n    for (i = 0; i < NUM_THREADS; i++) {\n        pthread_create(&threads[i], NULL, thread_func, NULL);\n    }\n\n    for (i = 0; i < NUM_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n\n    pthread_mutex_destroy(&mutex);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפלט הסופי של התוכנית יהיה:\nFinal counter value: 200000\n\n**הסבר:**\n1.  התוכנית מאתחלת משתנה גלובלי `counter` ל-0 ומוטקס `mutex`.\n2.  היא יוצרת שני חוטים (threads), כשכל חוט מבצע את הפונקציה `thread_func`.\n3.  בתוך `thread_func`, כל חוט מבצע לולאה `INCREMENTS_PER_THREAD` (שהוגדר כ-100,000) פעמים.\n4.  בכל איטרציה, החוט קורא ל-`pthread_mutex_lock(&mutex)` כדי לנעול את המוטקס. פעולה זו מבטיחה שרק חוט אחד יכול להיכנס לקטע הקריטי (critical section) שבו `counter` מוגדל.\n5.  לאחר הגדלת `counter` ב-1, החוט קורא ל-`pthread_mutex_unlock(&mutex)` כדי לשחרר את המוטקס, ובכך מאפשר לחוטים אחרים (אם ישנם) לנסות ולרכוש את המוטקס.\n6.  מכיוון שכל אחד משני החוטים מבצע 100,000 הגדלות, ופעולות אלו מוגנות על ידי המוטקס, סך ההגדלות יהיה `2 * 100,000 = 200,000`. המוטקס מונע תנאי מרוץ (race condition) ומבטיח שכל פעולת הגדלה תתבצע באופן אטומי ולא יאבדו עדכונים.\n7.  הקריאות ל-`pthread_join` מבטיחות שהחוט הראשי ימתין לסיום שני חוטי העבודה לפני שישמיד את המוטקס וידפיס את הערך הסופי של `counter`.\n\n**מה היה קורה אם המוטקס לא היה בשימוש:**\nאם קריאות ה-`pthread_mutex_lock` וה-`pthread_mutex_unlock` היו מוסרות מהקוד, היה נוצר תנאי מרוץ (race condition).\nפעולת `counter++` אינה אטומית, והיא מורכבת משלושה שלבים עיקריים ברמת המעבד:\n1.  קריאת הערך הנוכחי של `counter` לתוך אוגר.\n2.  הגדלת הערך באוגר.\n3.  כתיבת הערך החדש מהאוגר חזרה לזיכרון (למשתנה `counter`).\n\nללא מוטקס, חוטים מרובים יכלו לשלב את השלבים הללו באופן לא צפוי. לדוגמה:\n*   חוט א' קורא את `counter` (נניח 5).\n*   חוט ב' קורא את `counter` (גם הוא קורא 5).\n*   חוט א' מגדיל את הערך באוגר שלו ל-6 וכותב 6 חזרה ל-`counter`.\n*   חוט ב' מגדיל את הערך באוגר שלו ל-6 וכותב 6 חזרה ל-`counter`.\n\nבמקרה זה, שתי פעולות הגדלה שהיו אמורות להגדיל את `counter` ב-2, בפועל הגדילו אותו ב-1 בלבד, ובכך אבד עדכון אחד. כתוצאה מכך, הערך הסופי של `counter` היה נמוך מ-200,000 ולא דטרמיניסטי (היה משתנה בין הרצות שונות של התוכנית)."}, "difficulty_estimation": "Medium", "_source_file": "0278__Mutexes__CodeAnalysis__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:27:49", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Mutexes", "Concurrency", "Deadlock", "Threads"], "content": {"text": "נתונה התוכנית הבאה המשתמשת ב-pthreads וב-mutexes כדי לגשת למשאבים משותפים. נתח את התוכנית והסבר: א) מהו הפלט הסופי האפשרי של הערכים resource1 ו-resource2? ב) האם קיימת בעיית תחרות (race condition) או קיפאון (deadlock) בתוכנית? אם כן, הסבר מדוע וכיצד היא עלולה להתרחש.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex1;\npthread_mutex_t mutex2;\n\nint resource1 = 0;\nint resource2 = 0;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 1: Locked mutex1. Trying to lock mutex2...\\n\");\n    sleep(1); // Introduce delay to increase likelihood of deadlock\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 1: Locked mutex2. Updating resources...\\n\");\n    resource1++;\n    resource2++;\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 1: Unlocked mutex2.\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 1: Unlocked mutex1. Exiting.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to lock mutex2...\\n\");\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2: Locked mutex2. Trying to lock mutex1...\\n\");\n    sleep(1); // Introduce delay\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2: Locked mutex1. Updating resources...\\n\");\n    resource1--;\n    resource2--;\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 2: Unlocked mutex1.\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2: Unlocked mutex2. Exiting.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n\n    pthread_mutex_init(&mutex1, NULL);\n    pthread_mutex_init(&mutex2, NULL);\n\n    pthread_create(&t1, NULL, thread_func1, NULL);\n    pthread_create(&t2, NULL, thread_func2, NULL);\n\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n\n    printf(\"Final resource1 value: %d\\n\", resource1);\n    printf(\"Final resource2 value: %d\\n\", resource2);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א) הערכים הסופיים של resource1 ו-resource2 יהיו תלויים בשאלה האם התוכנית מסיימת את ריצתה בהצלחה או נכנסת למצב קיפאון (deadlock). במקרה של קיפאון, התהליכונים לא יסיימו את עדכון המשאבים, והערכים עשויים להישאר 0,0 (או הערכים שהיו להם טרם הקיפאון). אם, מסיבה כלשהי, הקיפאון נמנע (למשל, בגלל תזמון ספציפי מאוד של מערכת ההפעלה שגורם לתהליכון אחד לסיים את כל פעולותיו לפני שהשני מתחיל את ניסיונו לנעול), אז resource1 ו-resource2 יסיימו שניהם עם הערך 0. זאת מכיוון שתהליכון אחד מגדיל את שניהם ב-1, והתהליכון השני מקטין את שניהם ב-1, וכך הם מבטלים זה את זה.\n\nב) כן, קיימת בעיית קיפאון (deadlock) קלאסית בתוכנית. הקיפאון עלול להתרחש באופן הבא:\n1. תהליכון 1 (thread_func1) מבצע `pthread_mutex_lock(&mutex1)` ומצליח לנעול את mutex1.\n2. באותו זמן, תהליכון 2 (thread_func2) מבצע `pthread_mutex_lock(&mutex2)` ומצליח לנעול את mutex2.\n3. כעת, תהליכון 1 מנסה לבצע `pthread_mutex_lock(&mutex2)`. הוא ימתין ללא הגבלת זמן מכיוון ש-mutex2 נעול על ידי תהליכון 2.\n4. במקביל, תהליכון 2 מנסה לבצע `pthread_mutex_lock(&mutex1)`. הוא ימתין ללא הגבלת זמן מכיוון ש-mutex1 נעול על ידי תהליכון 1.\nשני התהליכונים ממתינים זה לזה לשחרור המשאב שהם זקוקים לו, וכל אחד מהם מחזיק במשאב שהשני זקוק לו. מצב זה מוביל לקיפאון, והתוכנית תיתקע ולא תסיים את ריצתה. אין כאן בעיית תחרות (race condition) על עדכון המשאבים resource1 ו-resource2 מכיוון ששניהם מוגנים על ידי שני ה-mutexes יחד, כלומר, כל עדכון מתרחש בתוך קטע קריטי המוגן היטב. הבעיה היא שהקטע הקריטי הזה עצמו עלול לא להיות נגיש לעולם עקב הקיפאון."}, "difficulty_estimation": "Medium", "_source_file": "0279__Mutexes__CodeAnalysis__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:28:15", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Mutexes", "Concurrency", "Race Conditions", "Threads"], "content": {"text": "נתונה התוכנית הבאה, המשתמשת ב-pthreads וב-mutex כדי להגדיל מונה משותף על ידי מספר תהליכונים. נתחו את התוכנית וענו על השאלה.\n\nמהו הערך הסופי האפשרי של המשתנה הגלובלי `counter` לאחר שכל התהליכונים סיימו את ריצתם? נמקו את תשובתכם והסבירו מדוע התוכנית עלולה להפיק תוצאה שונה מהצפוי.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n\n#define NUM_THREADS 5\n#define ITERATIONS_PER_THREAD 100000\n\nint counter = 0;\npthread_mutex_t mutex;\n\nvoid* thread_func(void* arg) {\n    for (int i = 0; i < ITERATIONS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&mutex);\n        // CRITICAL SECTION START\n        int temp = counter;\n        pthread_mutex_unlock(&mutex); // ERROR: Unlocking too early!\n        temp++;\n        counter = temp; // This write is NOT protected\n        // CRITICAL SECTION END (should extend to here)\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    pthread_mutex_init(&mutex, NULL);\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    pthread_mutex_destroy(&mutex);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הערך הסופי הצפוי של המונה, לו ה-mutex היה בשימוש נכון, הוא 500,000 (5 תהליכונים * 100,000 איטרציות כל אחד). עם זאת, עקב מיקום שגוי של קריאת ה-`pthread_mutex_unlock()`, מתקיים תנאי מרוץ (race condition).\n\nהקטע הקריטי, הכולל קריאת ערך ה-`counter` לתוך משתנה מקומי (`temp`), הגדלתו, וכתיבתו בחזרה ל-`counter` הגלובלי, אינו מוגן במלואו. ספציפית, השורה `counter = temp;` מתבצעת *לאחר* שה-mutex כבר שוחרר. משמעות הדבר היא שמספר תהליכונים יכולים לקרוא את אותו ערך של `counter` לתוך המשתנה המקומי שלהם `temp`, להגדיל אותו, ולאחר מכן לכתוב אותו בחזרה ל-`counter` הגלובלי, ובכך לדרוס את העדכונים של תהליכונים אחרים.\n\nלדוגמה, אם `counter` הוא 0:\n1. תהליכון A נועל את ה-mutex, קורא `temp = 0`, ומשחרר את ה-mutex.\n2. תהליכון B נועל את ה-mutex, קורא `temp = 0` (כי תהליכון A עדיין לא כתב בחזרה ל-`counter`), ומשחרר את ה-mutex.\n3. תהליכון A מגדיל את `temp` ל-1, וכותב `counter = 1`.\n4. תהליכון B מגדיל את `temp` ל-1, וכותב `counter = 1`.\n\nבסוף תהליך זה, שתי פעולות הגדלה הביאו לכך שהמונה בערך 1 במקום 2.\n\nלכן, הערך הסופי של `counter` יהיה **קטן מ-500,000**, והוא אינו דטרמיניסטי ותלוי בתיאום התהליכונים על ידי מערכת ההפעלה.\n\nכדי לתקן את הבעיה, יש להזיז את שחרור ה-mutex לסוף הקטע הקריטי, כך שכל פעולת הקריאה-שינוי-כתיבה תהיה מוגנת:\n```c\nvoid* thread_func(void* arg) {\n    for (int i = 0; i < ITERATIONS_PER_THREAD; ++i) {\n        pthread_mutex_lock(&mutex);\n        // CRITICAL SECTION START\n        counter++; // Atomic increment (read-modify-write protected)\n        // CRITICAL SECTION END\n        pthread_mutex_unlock(&mutex);\n    }\n    return NULL;\n}\n```"}, "difficulty_estimation": "Medium", "_source_file": "0280__Mutexes__CodeAnalysis__Medium.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:28:34", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Mutexes", "Synchronization", "Concurrency", "Deadlock"], "content": {"text": "נתונה מערכת מטמון פשוטה בגודל קבוע CACHE_SIZE, המאפשרת אחסון ועדכון של פריטים לפי מפתח-ערך. המערכת משתמשת בשני סוגי מנעולים: מנעול גלובלי cache_mutex להגנה על מבנה המטמון הכללי וחיפוש תאים פנויים/קיימים, ומנעול item_mutex לכל פריט במטמון להגנה על הנתונים הפנימיים שלו (מפתח וערך).\nלהלן מימוש חלקי של המערכת:", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep, if needed for demonstration\n\n#define CACHE_SIZE 5\n\ntypedef struct CacheEntry {\n    int key;\n    int value;\n    pthread_mutex_t item_mutex; // Protects 'value' and 'key' of this specific entry\n    int in_use; // 0 if empty, 1 if in use\n} CacheEntry;\n\nCacheEntry cache[CACHE_SIZE];\npthread_mutex_t cache_mutex = PTHREAD_MUTEX_INITIALIZER; // Protects global cache structure (e.g., 'in_use' flags, finding empty slots)\n\nvoid cache_init() {\n    for (int i = 0; i < CACHE_SIZE; ++i) {\n        cache[i].key = -1;\n        cache[i].value = -1;\n        pthread_mutex_init(&cache[i].item_mutex, NULL);\n        cache[i].in_use = 0;\n    }\n}\n\n// Function to add or update an item in the cache\nvoid cache_put(int key, int value) {\n    pthread_mutex_lock(&cache_mutex); // Lock global cache structure\n\n    int found_idx = -1;\n    for (int i = 0; i < CACHE_SIZE; ++i) {\n        if (cache[i].in_use && cache[i].key == key) {\n            found_idx = i;\n            break;\n        }\n    }\n\n    if (found_idx != -1) {\n        // Item exists, update its value.\n        pthread_mutex_lock(&cache[found_idx].item_mutex); // Lock item\n        cache[found_idx].value = value;\n        pthread_mutex_unlock(&cache[found_idx].item_mutex); // Unlock item\n        pthread_mutex_unlock(&cache_mutex); // Unlock global cache\n        return;\n    }\n\n    // Item does not exist, find an empty slot\n    int empty_idx = -1;\n    for (int i = 0; i < CACHE_SIZE; ++i) {\n        if (!cache[i].in_use) {\n            empty_idx = i;\n            break;\n        }\n    }\n\n    if (empty_idx != -1) {\n        // Found an empty slot\n        pthread_mutex_lock(&cache[empty_idx].item_mutex); // Lock new item slot\n        cache[empty_idx].key = key;\n        cache[empty_idx].value = value;\n        cache[empty_idx].in_use = 1;\n        pthread_mutex_unlock(&cache[empty_idx].item_mutex); // Unlock new item slot\n        pthread_mutex_unlock(&cache_mutex); // Unlock global cache\n        return;\n    }\n\n    // Cache is full. For simplicity, we don't handle eviction here.\n    // In a real scenario, an eviction policy would be applied.\n    pthread_mutex_unlock(&cache_mutex); // Unlock global cache\n    printf(\"Cache is full, cannot add key %d\\n\", key);\n}\n\n// Function to clear all items in the cache\nvoid cache_clear_and_reset() {\n    printf(\"Clearing cache...\\n\");\n    for (int i = 0; i < CACHE_SIZE; ++i) {\n        pthread_mutex_lock(&cache[i].item_mutex); // Acquire item mutex\n        // Simulate some cleanup work for the item\n        usleep(10000); // Simulate work that takes time\n        pthread_mutex_lock(&cache_mutex); // Acquire global cache mutex (PROBLEM HERE)\n        \n        cache[i].key = -1;\n        cache[i].value = -1;\n        cache[i].in_use = 0;\n        \n        pthread_mutex_unlock(&cache_mutex); // Release global cache mutex\n        pthread_mutex_unlock(&cache[i].item_mutex); // Release item mutex\n    }\n    printf(\"Cache cleared.\\n\");\n}"}, "sub_questions": [{"id": "10.1", "text": "הקוד הנ\"ל מכיל בעיה קריטית של סנכרון. תארו איזו בעיה קיימת בקוד וכיצד היא יכולה להתרחש (ציינו ריצה לדוגמה עם מספר חוטים).", "code_snippet": null, "options": null}, {"id": "10.2", "text": "תקנו את הקוד כך שיעבוד באופן תקין. יש להציג את הפונקציה המתוקנת בלבד (cache_clear_and_reset).", "code_snippet": "void cache_clear_and_reset() {\n\n}", "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "10.1: הבעיה בקוד היא קיפאון (Deadlock). הקיפאון יכול להתרחש כאשר חוט אחד מנסה לעדכן פריט קיים במטמון באמצעות cache_put, וחוט אחר מנסה לנקות ולאפס את המטמון באמצעות cache_clear_and_reset.\nפונקציית cache_put רוכשת את המנעולים בסדר: cache_mutex ואז item_mutex (עבור הפריט הספציפי). פונקציית cache_clear_and_reset, לעומת זאת, מנסה לרכוש את המנעולים בסדר הפוך: item_mutex (עבור כל פריט בתורו) ואז cache_mutex. סדר רכישת מנעולים שונה זה, במקביל לגישה למשאבים משותפים, יכול להוביל לקיפאון.\n\nריצה לדוגמה:\nנניח ש-key=1 נמצא ב-cache[0].\n\nחוט 1 (מבצע cache_put(1, 100)):\n1. רוכש את cache_mutex (pthread_mutex_lock(&cache_mutex);)\n2. מוצא את key=1 ב-cache[0].\n3. מנסה לרכוש את cache[0].item_mutex (pthread_mutex_lock(&cache[0].item_mutex);)\n   (בשלב זה, חוט 1 מחזיק ב-cache_mutex וממתין ל-cache[0].item_mutex).\n\nחוט 2 (מבצע cache_clear_and_reset()):\n1. נכנס ללולאה עבור i=0.\n2. רוכש את cache[0].item_mutex (pthread_mutex_lock(&cache[0].item_mutex);)\n   (בשלב זה, חוט 2 מחזיק ב-cache[0].item_mutex וממשיך).\n3. מבצע usleep(10000);\n4. מנסה לרכוש את cache_mutex (pthread_mutex_lock(&cache_mutex);)\n   (בשלב זה, חוט 2 מחזיק ב-cache[0].item_mutex וממתין ל-cache_mutex).\n\nתוצאה: חוט 1 מחזיק ב-cache_mutex וממתין ל-cache[0].item_mutex, בעוד שחוט 2 מחזיק ב-cache[0].item_mutex וממתין ל-cache_mutex. שני החוטים חסומים זה לזה במעגל המתנה, מה שגורם לקיפאון.\n\n10.2: כדי לתקן את הקיפאון, יש להבטיח שכל החוטים רוכשים את המנעולים באותו סדר עקבי. מכיוון ש-cache_put רוכש את cache_mutex ואז item_mutex, יש לשנות את cache_clear_and_reset כך שתפעל באותו סדר. הדרך הנכונה היא לרכוש את cache_mutex פעם אחת בתחילת cache_clear_and_reset, ולשחרר אותו בסוף. בתוך הלולאה, יש לרכוש את item_mutex עבור כל פריט.\n\n```c\nvoid cache_clear_and_reset() {\n    printf(\"Clearing cache...\\n\");\n    pthread_mutex_lock(&cache_mutex); // Acquire global cache mutex ONCE at the beginning\n\n    for (int i = 0; i < CACHE_SIZE; ++i) {\n        pthread_mutex_lock(&cache[i].item_mutex); // Acquire item mutex\n        \n        // Cleanup work for the item\n        cache[i].key = -1;\n        cache[i].value = -1;\n        cache[i].in_use = 0;\n        \n        pthread_mutex_unlock(&cache[i].item_mutex); // Release item mutex\n    }\n    \n    pthread_mutex_unlock(&cache_mutex); // Release global cache mutex ONCE at the end\n    printf(\"Cache cleared.\\n\");\n}\n```\n\nהסבר לתיקון:\nעל ידי רכישת cache_mutex פעם אחת בתחילת הפונקציה cache_clear_and_reset ושחרורו בסוף, אנו מבטיחים שכל גישה לנתוני המטמון הגלובליים (כמו מערך ה-cache עצמו והסטטוס in_use של הפריטים) תהיה מוגנת, וכן שסדר רכישת המנעולים יהיה עקבי: תמיד cache_mutex ואז item_mutex. בדרך זו, לא יכול להיווצר מצב שבו חוט אחד מחכה ל-item_mutex בעודו מחזיק ב-cache_mutex, וחוט אחר מחכה ל-cache_mutex בעודו מחזיק ב-item_mutex. התיקון מבטל את התלות המעגלית ומסיר את פוטנציאל הקיפאון. (ה-usleep הוסר מהקוד המתוקן כי הוא נועד רק לסימולציה של עבודה בהקשר של הבעיה המקורית)."}, "difficulty_estimation": "Hard", "_source_file": "0281__Mutexes__CodeAnalysis__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:29:34", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Mutexes", "Concurrency", "Deadlock", "Linked List"], "content": {"text": "נתונה רשימה מקושרת מוגנת מנעולים, בה כל צומת מכיל מנעול (mutex) משלו (`node_mutex`), ובנוסף קיים מנעול גלובלי (`head_ptr_mutex`) המגן על המצביע לראש הרשימה (`head`). הרשימה מאותחלת על ידי `init_list()`.\n\nלהלן מימוש חלקי של פונקציות `add_node` ו-`remove_node`. פונקציית `add_node` מוסיפה צומת חדש לסוף הרשימה ומשתמשת במנגנון \"נעילה ידנית\" (hand-over-hand locking) באופן סטנדרטי (כלומר, נועלת צומת נוכחי P ואז את הצומת הבא N, ומשחררת את המנעול של P). פונקציית `remove_node` מנסה להסיר צומת בעל ערך נתון.\n\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\ntypedef struct Node {\n    int data;\n    struct Node* next;\n    pthread_mutex_t node_mutex; // Mutex protecting this node's data and next pointer\n} Node;\n\nNode* head = NULL;\npthread_mutex_t head_ptr_mutex; // Mutex protecting the global 'head' pointer\n\nvoid init_list() {\n    pthread_mutex_init(&head_ptr_mutex, NULL);\n    head = NULL;\n}\n\nvoid destroy_list() {\n    Node* current = head;\n    while (current != NULL) {\n        Node* temp = current;\n        current = current->next;\n        pthread_mutex_destroy(&temp->node_mutex);\n        free(temp);\n    }\n    pthread_mutex_destroy(&head_ptr_mutex);\n}\n\n// פונקציה להוספת צומת לסוף הרשימה (מימוש סטנדרטי עם hand-over-hand locking)\nvoid add_node(int data) {\n    Node* new_node = (Node*)malloc(sizeof(Node));\n    if (new_node == NULL) {\n        perror(\"malloc failed\");\n        exit(EXIT_FAILURE);\n    }\n    new_node->data = data;\n    new_node->next = NULL;\n    pthread_mutex_init(&new_node->node_mutex, NULL);\n\n    pthread_mutex_lock(&head_ptr_mutex);\n    if (head == NULL) {\n        head = new_node;\n        pthread_mutex_unlock(&head_ptr_mutex);\n    } else {\n        Node* current = head;\n        pthread_mutex_lock(&current->node_mutex); // Lock current (P)\n        pthread_mutex_unlock(&head_ptr_mutex); // Release head_ptr_mutex\n\n        while (current->next != NULL) {\n            Node* next_node = current->next;\n            pthread_mutex_lock(&next_node->node_mutex); // Lock next (N)\n            pthread_mutex_unlock(&current->node_mutex); // Unlock current (P)\n            current = next_node;\n        }\n        // 'current' is now the last node, holding its mutex (P)\n        current->next = new_node; // Modify P->next\n        pthread_mutex_unlock(&current->node_mutex); // Unlock P\n    }\n}\n\n// פונקציה בעייתית להסרת צומת מהרשימה\n// פונקציה זו משתמשת בסדר נעילה לא עקבי שעלול להוביל לקיפאון (deadlock).\nint remove_node(int value) {\n    pthread_mutex_lock(&head_ptr_mutex);\n    Node* current = head;\n    Node* prev = NULL;\n\n    // טיפול במקרה של הסרת צומת הראש\n    if (current != NULL && current->data == value) {\n        pthread_mutex_lock(&current->node_mutex); // נועלים את צומת הראש (N)\n        head = current->next; // משנים את מצביע ה-head\n        pthread_mutex_unlock(&current->node_mutex); // משחררים את N\n        pthread_mutex_destroy(&current->node_mutex);\n        free(current);\n        pthread_mutex_unlock(&head_ptr_mutex);\n        return 1; // הצומת הוסר\n    }\n\n    // משחררים את מנעול ה-head_ptr_mutex כדי לאפשר פעולות אחרות על ה-head\n    // בזמן שאנו עוברים על הרשימה. (לדוגמה, add_node) \n    pthread_mutex_unlock(&head_ptr_mutex);\n\n    // עוברים על הרשימה למצוא את הצומת להסרה\n    // שימו לב: בשלב זה, אין מנעולי צומת נעולים במהלך המעבר עד למציאת הצומת.\n    current = head;\n    while (current != NULL) {\n        if (current->data == value) {\n            // מצאנו את הצומת (N) שיש להסיר. 'prev' הוא קודמו (P).\n            // סדר נעילה לא עקבי שגורם לקיפאון: נועלים את N ואז את P.\n            pthread_mutex_lock(&current->node_mutex); // נועלים את N\n            if (prev != NULL) {\n                pthread_mutex_lock(&prev->node_mutex); // נועלים את P (סדר הפוך!)\n                prev->next = current->next; // משנים את P->next\n                pthread_mutex_unlock(&prev->node_mutex); // משחררים את P\n            }\n            // אם prev הוא NULL, המשמעות היא ש-current הוא ה-head, \n            // אך מקרה זה אמור להיות מטופל כבר למעלה.\n            pthread_mutex_unlock(&current->node_mutex); // משחררים את N\n            pthread_mutex_destroy(&current->node_mutex);\n            free(current);\n            return 1; // הצומת הוסר\n        }\n        prev = current;\n        current = current->next;\n    }\n\n    return 0; // הצומת לא נמצא\n}\n```", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "מה הבעיה במימוש של פונקציית `remove_node`? תארו סיטואציה ספציפית (עם מספר חוטים ופעולות) שבה הבעיה יכולה להתרחש.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "תקנו את פונקציית `remove_node` כך שתעבוד באופן תקין ותמנע קיפאונות, תוך שמירה על רמת מקביליות גבוהה ככל הניתן (כלומר, השתמשו במנעולי צומת היכן שנדרש).", "code_snippet": "int remove_node(int value) {\n    // כתבו את הקוד המתוקן כאן\n}", "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "### פתרון לשאלה 1:\n\n**1.1. הבעיה במימוש פונקציית `remove_node`:**\nהבעיה במימוש פונקציית `remove_node` היא **קיפאון (deadlock)**. הקיפאון יכול להתרחש כתוצאה מסדר נעילה לא עקבי (inconsistent locking order) בין פונקציות המשתמשות באותם מנעולים.\n\n*   **סדר נעילה ב-`add_node` (ובמעבר סטנדרטי):** פונקציית `add_node` (ובאופן כללי, מעבר על הרשימה תוך שימוש במנגנון hand-over-hand locking) נועלת את מנעול הצומת הקודם (P) לפני שהיא נועלת את מנעול הצומת העוקב (N). כלומר, סדר הנעילה הוא **P ואז N**.\n*   **סדר נעילה ב-`remove_node` (הבעייתי):** פונקציית `remove_node`, במקרה של הסרת צומת שאינו ראש הרשימה, מנסה לנעול קודם את מנעול הצומת שיש להסיר (N) ורק לאחר מכן את מנעול קודמו (P). כלומר, סדר הנעילה הוא **N ואז P**.\n\n**תרחיש קיפאון:**\nנניח רשימה מקושרת עם שלושה צמתים: `A -> B -> C`.\n\n1.  **חוט 1** קורא לפונקציה `add_node(D)` (מנסה להוסיף צומת D לסוף הרשימה).\n    *   חוט 1 נועל את `head_ptr_mutex` ומשחרר אותו.\n    *   הוא נועל את המנעול של צומת A: `pthread_mutex_lock(&A->node_mutex);` (P).\n    *   הוא ממשיך למעבר על הרשימה. הוא מנסה לנעול את המנעול של צומת B: `pthread_mutex_lock(&B->node_mutex);` (N).\n    *   **בנקודה זו, חוט 1 מחזיק את `A->node_mutex` ומנסה לרכוש את `B->node_mutex`.**\n2.  **חוט 2** קורא לפונקציה `remove_node(B)` (מנסה להסיר את צומת B).\n    *   חוט 2 נועל את `head_ptr_mutex` ומשחרר אותו.\n    *   הוא עובר על הרשימה (ללא נעילת מנעולי צמתים בשלב זה) עד שהוא מוצא את צומת B (כאשר `prev` מצביע על A ו-`current` מצביע על B).\n    *   חוט 2 נועל את המנעול של צומת B: `pthread_mutex_lock(&B->node_mutex);` (N).\n    *   **בנקודה זו, חוט 2 מחזיק את `B->node_mutex`.**\n    *   חוט 2 מנסה כעת לנעול את המנעול של צומת A (כי הוא צריך את `prev->node_mutex` כדי לעדכן את `A->next`): `pthread_mutex_lock(&A->node_mutex);` (חוט 2 נחסם על ידי חוט 1, שמחזיק את `A->node_mutex`).\n\n**תוצאה:** נוצר קיפאון. חוט 1 ממתין למנעול של B שמוחזק על ידי חוט 2, וחוט 2 ממתין למנעול של A שמוחזק על ידי חוט 1.\n\n**1.2. תיקון פונקציית `remove_node`:**\nכדי לתקן את הבעיה, יש להבטיח סדר נעילה עקבי עבור כל הפעולות ברשימה. הדרך המקובלת היא להשתמש בסדר \"קודם ואז עוקב\" (P ואז N) כאשר שני מנעולים נדרשים בו-זמנית. המימוש המתוקן משתמש ב-hand-over-hand locking גם במהלך המעבר, וכאשר נמצא הצומת להסרה (N), המנעול של קודמו (P) כבר מוחזק, ואז רוכשים את המנעול של N.\n\n```c\nint remove_node(int value) {\n    pthread_mutex_lock(&head_ptr_mutex);\n    Node* current = head;\n    Node* prev = NULL; // prev will not be used in the fixed head case, but for traversal\n\n    // טיפול במקרה של הסרת צומת הראש\n    if (current != NULL && current->data == value) {\n        pthread_mutex_lock(&current->node_mutex); // נועלים את צומת הראש (N)\n        head = current->next; // משנים את מצביע ה-head\n        pthread_mutex_unlock(&current->node_mutex); // משחררים את N\n        pthread_mutex_destroy(&current->node_mutex);\n        free(current);\n        pthread_mutex_unlock(&head_ptr_mutex);\n        return 1; // הצומת הוסר\n    }\n\n    // אם ראש הרשימה אינו הצומת המבוקש, משחררים את מנעול ה-head_ptr_mutex\n    // ומתחילים מעבר עם hand-over-hand locking.\n    pthread_mutex_unlock(&head_ptr_mutex);\n\n    // מתחילים מעבר על הרשימה\n    current = head; \n    if (current == NULL) {\n        return 0; // הרשימה ריקה או הצומת לא נמצא\n    }\n\n    pthread_mutex_lock(&current->node_mutex); // נועלים את הצומת הראשון (P) לצורך התחלת מעבר\n    \n    while (current != NULL) {\n        Node* next_node = current->next; // N\n        \n        // אם next_node הוא הצומת המבוקש להסרה\n        if (next_node != NULL && next_node->data == value) {\n            pthread_mutex_lock(&next_node->node_mutex); // נועלים את N (כאשר P נעול)\n            current->next = next_node->next; // משנים את P->next\n            pthread_mutex_unlock(&next_node->node_mutex); // משחררים את N\n            pthread_mutex_destroy(&next_node->node_mutex);\n            free(next_node);\n            pthread_mutex_unlock(&current->node_mutex); // משחררים את P\n            return 1; // הצומת הוסר\n        }\n\n        // אם לא מצאנו את הצומת, מתקדמים ב-hand-over-hand locking\n        if (next_node != NULL) {\n            pthread_mutex_lock(&next_node->node_mutex); // נועלים את N\n        }\n        pthread_mutex_unlock(&current->node_mutex); // משחררים את P\n        current = next_node;\n    }\n\n    return 0; // הצומת לא נמצא\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0282__Mutexes__CodeAnalysis__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:31:19", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Synchronization", "Mutexes", "Deadlock", "Concurrency"], "content": {"text": "נתונה מערכת המנהלת שני תורים מקושרים, `listA` ו-`listB`, כאשר כל תור מוגן על ידי מנעול (mutex) משלו. מטרת המערכת היא לאפשר העברת פריטים בין התורים באופן בטוח במקביל. להלן מימוש חלקי של הפונקציות `transfer_A_to_B` ו-`transfer_B_to_A` המיועדות להעביר פריט מתור אחד לשני. קוד העזר לניהול הרשימות (אתחול, הוספה, הסרה) תקין ומוגן על ידי המנעולים של הרשימה המתאימה. שימו לב כי פעולות הוספה והסרה בתוך פונקציות ה-`transfer` מניחות שהמנעול המתאים כבר נתפס על ידי הפונקציה הקוראת ואינן תופסות מנעולים בעצמן.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n#include <unistd.h> // for usleep\n\n// Assume a simple linked list structure for demonstration\ntypedef struct Node {\n    int data;\n    struct Node* next;\n} Node;\n\ntypedef struct {\n    Node* head;\n    pthread_mutex_t mutex;\n    int count; \n} List;\n\n// Global lists (assume they are initialized elsewhere)\nList listA;\nList listB;\n\n// Problematic functions\nvoid transfer_A_to_B() {\n    pthread_mutex_lock(&listA.mutex);\n    // Simulate some work to increase deadlock probability\n    usleep(10000); // 10ms\n\n    int item = -1;\n    // Remove from listA (protected by listA.mutex)\n    if (listA.head != NULL) {\n        Node* temp = listA.head;\n        item = temp->data;\n        listA.head = listA.head->next;\n        free(temp);\n        listA.count--;\n    }\n\n    if (item != -1) {\n        pthread_mutex_lock(&listB.mutex);\n        \n        // Add to listB (protected by listB.mutex)\n        Node* new_node = (Node*)malloc(sizeof(Node));\n        new_node->data = item;\n        new_node->next = NULL;\n        if (listB.head == NULL) {\n            listB.head = new_node;\n        } else {\n            Node* current = listB.head;\n            while (current->next != NULL) {\n                current = current->next;\n            }\n            current->next = new_node;\n        }\n        listB.count++;\n\n        pthread_mutex_unlock(&listB.mutex);\n    }\n    pthread_mutex_unlock(&listA.mutex);\n}\n\nvoid transfer_B_to_A() {\n    pthread_mutex_lock(&listB.mutex);\n    // Simulate some work to increase deadlock probability\n    usleep(10000); // 10ms\n\n    int item = -1;\n    // Remove from listB (protected by listB.mutex)\n    if (listB.head != NULL) {\n        Node* temp = listB.head;\n        item = temp->data;\n        listB.head = listB.head->next;\n        free(temp);\n        listB.count--;\n    }\n\n    if (item != -1) {\n        pthread_mutex_lock(&listA.mutex);\n        \n        // Add to listA (protected by listA.mutex)\n        Node* new_node = (Node*)malloc(sizeof(Node));\n        new_node->data = item;\n        new_node->next = NULL;\n        if (listA.head == NULL) {\n            listA.head = new_node;\n        } else {\n            Node* current = listA.head;\n            while (current->next != NULL) {\n                current = current->next;\n            }\n            current->next = new_node;\n        }\n        listA.count++;\n        \n        pthread_mutex_unlock(&listA.mutex);\n    }\n    pthread_mutex_unlock(&listB.mutex);\n}"}, "sub_questions": [{"id": "1.1", "text": "תארו את הבעיה העיקרית במימוש הנוכחי של פונקציות ההעברה (`transfer_A_to_B` ו-`transfer_B_to_A`). הסבירו כיצד בעיה זו יכולה להתרחש, תוך פירוט רצף פעולות של שני חוטים (threads) לפחות המדגים את הבעיה.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "הציעו תיקון למימוש כך שהבעיה שתוארה בסעיף א' תימנע. כתבו את הקוד המתוקן עבור שתי הפונקציות (`transfer_A_to_B` ו-`transfer_B_to_A`) תוך שמירה על יעילות סבירה.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1. **הבעיה:**\nהבעיה העיקרית במימוש הנוכחי היא קיפאון (Deadlock). קיפאון יכול להתרחש כאשר שני חוטים מנסים לתפוס את המנעולים של `listA` ו-`listB` בסדר הפוך.\n\n**תיאור רצף פעולות המדגים קיפאון:**\nנניח שקיימים שני חוטים, חוט 1 וחוט 2:\n*   **חוט 1** קורא לפונקציה `transfer_A_to_B()`:\n    *   תופס את המנעול של `listA` (`pthread_mutex_lock(&listA.mutex)`).\n    *   מבצע פעולות פנימיות (למשל, `usleep`).\n    *   מנסה לתפוס את המנעול של `listB` (`pthread_mutex_lock(&listB.mutex)`). בשלב זה, אם `listB.mutex` כבר תפוס על ידי חוט אחר, חוט 1 יחסם.\n*   באותו זמן, **חוט 2** קורא לפונקציה `transfer_B_to_A()`:\n    *   תופס את המנעול של `listB` (`pthread_mutex_lock(&listB.mutex)`).\n    *   מבצע פעולות פנימיות (למשל, `usleep`).\n    *   מנסה לתפוס את המנעול של `listA` (`pthread_mutex_lock(&listA.mutex)`). בשלב זה, אם `listA.mutex` כבר תפוס על ידי חוט אחר, חוט 2 יחסם.\n\nבשלב זה, חוט 1 מחזיק במנעול של `listA` וממתין למנעול של `listB` (שמוחזק על ידי חוט 2). במקביל, חוט 2 מחזיק במנעול של `listB` וממתין למנעול של `listA` (שמוחזק על ידי חוט 1). שני החוטים חסומים באופן הדדי ואינם יכולים להתקדם, מה שגורם לקיפאון.\n\n1.2. **תיקון:**\nכדי למנוע קיפאון, יש לאכוף סדר קבוע לרכישת המנעולים. כלומר, כל חוט שצריך לתפוס את שני המנעולים (של `listA` ושל `listB`) יתפוס אותם תמיד באותו סדר (לדוגמה, תמיד קודם את `listA.mutex` ואז את `listB.mutex`). לאחר סיום הפעולות, יש לשחרר את המנעולים בסדר הפוך מהסדר בו נתפסו.\n\n**קוד מתוקן:**\n```c\n// Fixed functions\nvoid transfer_A_to_B() {\n    pthread_mutex_lock(&listA.mutex); // Lock A first (consistent order)\n    pthread_mutex_lock(&listB.mutex); // Then lock B\n    \n    // Simulate some work\n    usleep(10000); // 10ms\n\n    int item = -1;\n    // Remove from listA (protected by listA.mutex)\n    if (listA.head != NULL) {\n        Node* temp = listA.head;\n        item = temp->data;\n        listA.head = listA.head->next;\n        free(temp);\n        listA.count--;\n    }\n\n    if (item != -1) {\n        // Add to listB (protected by listB.mutex)\n        Node* new_node = (Node*)malloc(sizeof(Node));\n        new_node->data = item;\n        new_node->next = NULL;\n        if (listB.head == NULL) {\n            listB.head = new_node;\n        } else {\n            Node* current = listB.head;\n            while (current->next != NULL) {\n                current = current->next;\n            }\n            current->next = new_node;\n        }\n        listB.count++;\n    }\n    \n    pthread_mutex_unlock(&listB.mutex); // Unlock B first (reverse order of locking)\n    pthread_mutex_unlock(&listA.mutex); // Then unlock A\n}\n\nvoid transfer_B_to_A() {\n    pthread_mutex_lock(&listA.mutex); // Lock A first (consistent order)\n    pthread_mutex_lock(&listB.mutex); // Then lock B\n    \n    // Simulate some work\n    usleep(10000); // 10ms\n\n    int item = -1;\n    // Remove from listB (protected by listB.mutex)\n    if (listB.head != NULL) {\n        Node* temp = listB.head;\n        item = temp->data;\n        listB.head = listB.head->next;\n        free(temp);\n        listB.count--;\n    }\n\n    if (item != -1) {\n        // Add to listA (protected by listA.mutex)\n        Node* new_node = (Node*)malloc(sizeof(Node));\n        new_node->data = item;\n        new_node->next = NULL;\n        if (listA.head == NULL) {\n            listA.head = new_node;\n        } else {\n            Node* current = listA.head;\n            while (current->next != NULL) {\n                current = current->next;\n            }\n            current->next = new_node;\n        }\n        listA.count++;\n    }\n    \n    pthread_mutex_unlock(&listB.mutex); // Unlock B first (reverse order of locking)\n    pthread_mutex_unlock(&listA.mutex); // Then unlock A\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0283__Mutexes__CodeAnalysis__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:31:57", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Synchronization", "Mutexes", "Concurrency", "Deadlocks"], "content": {"text": "נתונה מערכת המשתמשת במאגר משותף (buffer) ובמונה משותף (counter). המערכת מוגדרת עם שני mutexes: `buffer_mutex` להגנה על המאגר ו-`counter_mutex` להגנה על המונה. המונה מאותחל ל-0. פונקציות העזר `produce_new_item()`, `add_item_to_buffer()`, `remove_item_from_buffer()`, ו-`consume_item()` בטוחות לשימוש ומתוארות בקצרה (אין צורך לממש אותן). להלן קוד המימוש של פונקציות היצרן (producer) והצרכן (consumer) במערכת, המשתמשות במנעולים אלו:", "code_snippet": "#include <pthread.h>\n\n// Global variables\nint counter = 0; // Tracks number of items in buffer\n// Assume a shared buffer implementation (e.g., array with head/tail)\n// For simplicity, buffer overflow/underflow is not the focus of this question.\n\npthread_mutex_t buffer_mutex; // Protects buffer, head, tail\npthread_mutex_t counter_mutex; // Protects counter\n\n// Assume these helper functions exist and are safe to call\n// (i.e., they don't handle their own synchronization, relying on caller)\nint produce_new_item();\nvoid add_item_to_buffer(int item);\nint remove_item_from_buffer();\nvoid consume_item(int item);\n\n// Producer thread function (buggy)\nvoid* producer(void* arg) {\n    while (1) {\n        int item = produce_new_item();\n\n        pthread_mutex_lock(&buffer_mutex); // Acquire buffer_mutex first\n        add_item_to_buffer(item);\n\n        pthread_mutex_lock(&counter_mutex); // Then acquire counter_mutex\n        counter++;\n        pthread_mutex_unlock(&counter_mutex);\n\n        pthread_mutex_unlock(&buffer_mutex);\n    }\n    return NULL;\n}\n\n// Consumer thread function (buggy)\nvoid* consumer(void* arg) {\n    while (1) {\n        pthread_mutex_lock(&counter_mutex); // Acquire counter_mutex first\n        if (counter > 0) {\n            counter--;\n\n            pthread_mutex_lock(&buffer_mutex); // Then acquire buffer_mutex\n            int item = remove_item_from_buffer();\n            pthread_mutex_unlock(&buffer_mutex);\n            consume_item(item);\n        }\n        pthread_mutex_unlock(&counter_mutex);\n    }\n    return NULL;\n}"}, "sub_questions": [{"id": "1.1", "text": "הקוד המתואר אינו תקין. תארו מה הבעיה וכיצד היא יכולה להתרחש. יש לתאר ריצה ספציפית המדגימה את הבעיה.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "תקנו את הקוד כך שיעבוד באופן תקין וימנע את הבעיה שתוארה. יש להציג את הפונקציות producer ו-consumer המתוקנות.", "code_snippet": "void* producer(void* arg) {\n    // הקוד המתוקן של producer כאן\n}\n\nvoid* consumer(void* arg) {\n    // הקוד המתוקן של consumer כאן\n}", "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1. הבעיה בקוד היא קיפאון (Deadlock).\n   הקיפאון יכול להתרחש כתוצאה מסדר תפיסת מנעולים לא עקבי בין החוטים השונים. נניח שמתרחשת הריצה הבאה:\n   1. חוט יצרן (Producer Thread) מבצע `pthread_mutex_lock(&buffer_mutex)`. כעת הוא מחזיק במנעול `buffer_mutex`.\n   2. מתרחש מעבר הקשר (context switch) לחוט צרכן (Consumer Thread).\n   3. חוט צרכן מבצע `pthread_mutex_lock(&counter_mutex)`. כעת הוא מחזיק במנעול `counter_mutex`.\n   4. חוט צרכן ממשיך ובודק `if (counter > 0)`. נניח ש-`counter` אכן גדול מ-0. הוא מבצע `counter--`.\n   5. חוט צרכן מנסה לבצע `pthread_mutex_lock(&buffer_mutex)`, אך המנעול `buffer_mutex` כבר נתפס על ידי חוט היצרן. חוט הצרכן נחסם וממתין לשחרור `buffer_mutex`.\n   6. מתרחש מעבר הקשר בחזרה לחוט יצרן.\n   7. חוט יצרן מנסה לבצע `pthread_mutex_lock(&counter_mutex)`, אך המנעול `counter_mutex` כבר נתפס על ידי חוט הצרכן. חוט היצרן נחסם וממתין לשחרור `counter_mutex`.\n   בשלב זה, שני החוטים חסומים באופן הדדי: היצרן ממתין לצרכן שישחרר את `counter_mutex`, והצרכן ממתין ליצרן שישחרר את `buffer_mutex`. אף אחד מהם לא יכול להמשיך, והמערכת נכנסת למצב של קיפאון.\n\n1.2. כדי למנוע קיפאון, יש לוודא שכל החוטים תופסים את המנעולים באותו סדר עקבי. נבחר בסדר: תחילה `counter_mutex` ואז `buffer_mutex`. שינוי זה דורש התאמה בפונקציית היצרן.\n\nהקוד המתוקן:\n```c\nvoid* producer(void* arg) {\n    while (1) {\n        int item = produce_new_item();\n\n        pthread_mutex_lock(&counter_mutex); // Acquire counter_mutex first (consistent order)\n        pthread_mutex_lock(&buffer_mutex);  // Then acquire buffer_mutex\n\n        // Both mutexes are now held, ensuring atomicity for counter and buffer update.\n        // In a full producer-consumer, one would also check for buffer full here and use condition variables.\n        add_item_to_buffer(item);\n        counter++;\n\n        pthread_mutex_unlock(&buffer_mutex);\n        pthread_mutex_unlock(&counter_mutex);\n    }\n    return NULL;\n}\n\nvoid* consumer(void* arg) {\n    while (1) {\n        pthread_mutex_lock(&counter_mutex); // Acquire counter_mutex first (consistent order)\n        pthread_mutex_lock(&buffer_mutex);  // Then acquire buffer_mutex\n\n        if (counter > 0) { // Check counter under lock\n            counter--;\n            int item = remove_item_from_buffer();\n            consume_item(item);\n        }\n        // If counter <= 0, buffer is empty. Just unlock and retry.\n        \n        pthread_mutex_unlock(&buffer_mutex);\n        pthread_mutex_unlock(&counter_mutex);\n    }\n    return NULL;\n}\n```", "difficulty_estimation": "Hard"}, "_source_file": "0284__Mutexes__CodeAnalysis__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:32:43", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Mutexes", "Synchronization", "Concurrency", "Deadlock"], "content": {"text": "נתונה מערכת המנהלת חשבונות בנק. כל חשבון מיוצג על ידי מבנה `Account` הכולל מזהה (id), יתרה (balance) ומנעול (mutex) משלו. שתי פונקציות עיקריות מוגדרות: `transfer` המעבירה כסף בין שני חשבונות. המערכת מריצה מספר חוטים במקביל המבצעים פעולות אלו. יש לתאר בקצרה ובבירור כל פתרון ולכתוב קוד ברור.", "code_snippet": "```c\n#include <pthread.h>\n#include <stdio.h>\n\ntypedef struct {\n    int id;\n    int balance;\n    pthread_mutex_t mutex;\n} Account;\n\n// Global accounts (assume these are initialized, e.g., in main or init_accounts)\n// Account accountA; Account accountB;\n\n// Function to transfer 'amount' from 'from' account to 'to' account\nvoid transfer(Account* from, Account* to, int amount) {\n    pthread_mutex_lock(&from->mutex);\n    pthread_mutex_lock(&to->mutex);\n\n    if (from->balance >= amount) {\n        from->balance -= amount;\n        to->balance += amount;\n    }\n\n    pthread_mutex_unlock(&to->mutex);\n    pthread_mutex_unlock(&from->mutex);\n}\n```", "options": null}, "sub_questions": [{"id": "8.1", "text": "הקוד הנ\"ל סובל מבעיה חמורה של קיפאון (Deadlock) אשר עלולה להתרחש בנסיבות מסוימות. תארו ריצה אפשרית (עם מספר חוטים כרצונכם) המדגימה את הבעיה, והסבירו מדוע היא מתרחשת.", "code_snippet": null, "options": null}, {"id": "8.2", "text": "תקנו את פונקציית `transfer` כך שתמנע את בעיית הקיפאון, תוך שמירה על עקרונות הסנכרון הנדרשים (ללא שימוש באובייקטי סנכרון נוספים פרט למנעולים הקיימים). כתבו את הקוד המתוקן.", "code_snippet": "void transfer(Account* from, Account* to, int amount) {\n    // כתבו את הקוד המתוקן כאן\n}", "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "### פתרון לשאלה 8\n\n**8.1 תיאור בעיית הקיפאון:**\n\nהבעיה: קיפאון (Deadlock).\n\nהסבר: קיפאון יכול להתרחש כאשר שני חוטים (threads) מנסים לבצע העברה כספית במקביל, אך בכיוונים מנוגדים. לדוגמה:\n\n1.  **חוט 1 (T1)** מנסה להעביר כסף מחשבון A לחשבון B (כלומר, קורא לפונקציה `transfer(&accountA, &accountB, ...)`. הוא נועל את המנעול של חשבון A (`&accountA.mutex`) בהצלחה.\n2.  **במקביל, חוט 2 (T2)** מנסה להעביר כסף מחשבון B לחשבון A (כלומר, קורא לפונקציה `transfer(&accountB, &accountA, ...)`. הוא נועל את המנעול של חשבון B (`&accountB.mutex`) בהצלחה.\n3.  **כעת T1** מנסה לנעול את המנעול של חשבון B (`&accountB.mutex`), אך מנעול זה כבר נעול על ידי T2. לכן, T1 נכנס למצב המתנה.\n4.  **במקביל, T2** מנסה לנעול את המנעול של חשבון A (`&accountA.mutex`), אך מנעול זה כבר נעול על ידי T1. לכן, T2 נכנס למצב המתנה.\n\nשני החוטים ממתינים זה לזה לשחרור המנעול שהם צריכים, וכתוצאה מכך אף אחד מהם לא יכול להתקדם. זהו מצב קלאסי של קיפאון, כאשר כל חוט מחזיק במשאב (מנעול) וממתין למשאב אחר שמוחזק על ידי חוט אחר.\n\n**8.2 תיקון פונקציית `transfer`:**\n\nכדי למנוע קיפאון במצב זה, יש להקפיד על סדר עקבי של תפיסת המנעולים. דרך נפוצה היא לתפוס את המנעולים על בסיס מזהה ייחודי (כמו `id` במקרה זה, או כתובת זיכרון), מה שמבטיח שכל החוטים ינסו לתפוס את אותם מנעולים באותו סדר, ללא קשר לסדר הטיעונים המקוריים לפונקציה.\n\n**הקוד המתוקן:**\n```c\nvoid transfer(Account* from, Account* to, int amount) {\n    // Handle transfer to/from the same account or null accounts\n    if (from == to || from == NULL || to == NULL) {\n        // No operation needed for same account, or invalid accounts\n        return;\n    }\n\n    pthread_mutex_t *mutex1, *mutex2;\n    // Determine a consistent locking order based on account IDs.\n    // Always lock the account with the smaller ID first.\n    if (from->id < to->id) {\n        mutex1 = &from->mutex;\n        mutex2 = &to->mutex;\n    } else { // to->id < from->id (assuming IDs are unique and not equal)\n        mutex1 = &to->mutex;\n        mutex2 = &from->mutex;\n    }\n\n    // Acquire locks in the consistent order\n    pthread_mutex_lock(mutex1);\n    pthread_mutex_lock(mutex2);\n\n    // Perform the transfer logic on the original 'from' and 'to' accounts\n    if (from->balance >= amount) {\n        from->balance -= amount;\n        to->balance += amount;\n    }\n\n    // Release locks in the reverse order of acquisition (or any order, as long as both are released)\n    pthread_mutex_unlock(mutex2);\n    pthread_mutex_unlock(mutex1);\n}\n```", "difficulty_estimation": "Hard"}, "_source_file": "0285__Mutexes__CodeAnalysis__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:33:13", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Mutexes", "Synchronization", "Concurrency", "Deadlock", "Barrier"], "content": {"text": "נתונה תוכנית C המנסה לממש מחסום (barrier) עבור N חוטים באמצעות מוטקס יחיד ומונה משותף. המטרה היא שכל N החוטים יגיעו לנקודה מסוימת בקוד לפני שמי מהם ימשיך הלאה. נתח את קוד המחסום המוצג להלן. האם הקוד יפעל כמצופה? אם לא, תאר את הבעיה (סוגה, כיצד היא מתרחשת, ומהן השלכותיה) והסבר מדוע היא מתרחשת. לאחר מכן, הצע פתרון נכון או ציין את המנגנונים הדרושים לפתרון נכון.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep, though not strictly needed for the problem demonstration\n\n#define N_THREADS 3 // מספר החוטים במערכת\n\npthread_mutex_t barrier_mutex;\nint thread_count = 0; // מונה משותף לחוטים שהגיעו למחסום\n\nvoid *thread_func(void *arg) {\n    long id = (long)arg;\n    printf(\"Thread %ld: Arrived at barrier point 1.\\n\", id);\n\n    pthread_mutex_lock(&barrier_mutex); // תפוס את המוטקס\n\n    thread_count++; // הגדל את מונה החוטים שהגיעו\n\n    if (thread_count < N_THREADS) {\n        // אם זה לא החוט האחרון שהגיע\n        printf(\"Thread %ld: Waiting for other threads. Current count: %d/%d\\n\", id, thread_count, N_THREADS);\n        while (thread_count < N_THREADS) {\n            // המתן לחוטים אחרים בזמן שהמוטקס תפוס\n            // (פעולה זו היא שורש הבעיה)\n        }\n    } else {\n        // זהו החוט האחרון שהגיע\n        printf(\"Thread %ld: Last thread arrived. Releasing barrier.\\n\", id);\n        thread_count = 0; // אפס את המונה לשימוש עתידי במחסום\n    }\n\n    pthread_mutex_unlock(&barrier_mutex); // שחרר את המוטקס\n    printf(\"Thread %ld: Passed barrier point 1.\\n\", id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[N_THREADS];\n    pthread_mutex_init(&barrier_mutex, NULL);\n\n    for (long i = 0; i < N_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, (void *)i);\n    }\n\n    for (int i = 0; i < N_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    pthread_mutex_destroy(&barrier_mutex);\n    printf(\"All threads finished.\\n\");\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הקוד אינו פועל כמצופה ויוביל למצב של קיפאון (Deadlock). \n\n**הבעיה:**\nחוטים מגיעים למחסום, תופסים את המוטקס `barrier_mutex` ומגדילים את המונה `thread_count`. כל עוד `thread_count` קטן מ-`N_THREADS` (כלומר, הם אינם החוט האחרון שהגיע), החוטים נכנסים ללולאת `while (thread_count < N_THREADS)` **כאשר הם עדיין מחזיקים במוטקס**. \n\n**כיצד זה מוביל לקיפאון:**\nאם `N_THREADS` הוא 3, לדוגמה:\n1.  חוט 0 תופס את `barrier_mutex`, מגדיל את `thread_count` ל-1, ונכנס ללולאת ה-`while` כשהוא מחזיק במוטקס.\n2.  כל שאר `N-1` החוטים ינסו לתפוס את `barrier_mutex` באמצעות `pthread_mutex_lock` אך ייחסמו לעד, מכיוון שהחוט הראשון לעולם לא ישחרר את המוטקס (הוא תקוע בלולאה שמחכה למונה שיגדל, אך המונה לא יכול לגדול כי אף חוט אחר לא יכול לתפוס את המוטקס כדי להגדיל אותו). כתוצאה מכך, המערכת תיכנס למצב של קיפאון.\n\n**השלכות:**\nהתוכנית תיתקע ולא תשלים את ריצתה. החוטים יישארו במצב חסום, והמשאבים שהם תופסים (כמו המוטקס) לא ישוחררו, מה שיכול למנוע מחוטים אחרים במערכת (אפילו אלה שלא קשורים למחסום זה) מלהתקדם אם הם זקוקים למשאבים אלה.\n\n**פתרון נכון:**\nמוטקסים מיועדים להבטחת הדרה הדדית (mutual exclusion) על משאב משותף, אך אינם מיועדים למנגנוני איתות (signaling) והמתנה מורכבים כמו מחסום. עבור מנגנוני איתות והמתנה יעילים, יש להשתמש ב**משתני תנאי (Condition Variables)** בשילוב עם מוטקסים. \n\nפתרון נכון למחסום באמצעות מוטקס ומשתנה תנאי ייראה בערך כך:\n```c\n#include <pthread.h>\n#include <stdio.h>\n\n#define N_THREADS 3\n\npthread_mutex_t barrier_mutex;\npthread_cond_t barrier_cond;\nint thread_count = 0;\n\nvoid *thread_func(void *arg) {\n    long id = (long)arg;\n    printf(\"Thread %ld: Arrived at barrier point 1.\\n\", id);\n\n    pthread_mutex_lock(&barrier_mutex);\n    thread_count++;\n\n    if (thread_count < N_THREADS) {\n        // אם זה לא החוט האחרון, המתן על משתנה התנאי\n        while (thread_count < N_THREADS) { // Loop for spurious wakeups\n            pthread_cond_wait(&barrier_cond, &barrier_mutex);\n        }\n    } else {\n        // זהו החוט האחרון, אפס את המונה ואותת לכל הממתינים\n        thread_count = 0; // Reset for next barrier use\n        pthread_cond_broadcast(&barrier_cond);\n    }\n\n    pthread_mutex_unlock(&barrier_mutex);\n    printf(\"Thread %ld: Passed barrier point 1.\\n\", id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[N_THREADS];\n    pthread_mutex_init(&barrier_mutex, NULL);\n    pthread_cond_init(&barrier_cond, NULL);\n\n    for (long i = 0; i < N_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, (void *)i);\n    }\n\n    for (int i = 0; i < N_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    pthread_mutex_destroy(&barrier_mutex);\n    pthread_cond_destroy(&barrier_cond);\n    printf(\"All threads finished.\\n\");\n    return 0;\n}\n```", "difficulty_estimation": "Hard"}, "_source_file": "0286__Mutexes__CodeAnalysis__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:43:51", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Mutexes", "Deadlock", "Concurrency", "Lazy Initialization", "Singleton"], "content": {"text": "במערכת מרובת חוטים, נדרש לממש אובייקט יחיד (singleton) שמאותחל באופן עצלני (lazy initialization). אובייקט זה, `Logger`, אחראי לרישום הודעות ליומן. בניית אובייקט `Logger` היא פעולה יקרה וארוכה, ודורשת גישה למשאב גלובלי נוסף (לדוגמה, קובץ קונפיגורציה), המוגן על ידי מנעול `config_mutex`.\n\nלהלן המימוש המוצע:\n1. הפונקציה `get_logger()` אחראית להחזיר את מופע ה-`Logger` היחיד, וליצור אותו אם טרם נוצר.\n2. הקונסטרוקטור של `Logger` (הפונקציה `Logger::Logger()`) מבצע את האתחול היקר, ובמהלכו נועל את `config_mutex`.\n\nבנוסף, קיימת פונקציה `update_configuration()` המבצעת עדכון כלשהו בקונפיגורציה, ודורשת גישה לשני המנעולים: תחילה `config_mutex` ולאחר מכן `logger_init_mutex` (מסיבות שאינן רלוונטיות לבעיה, אך נדרשות על ידי לוגיקה פנימית).\n\nנתחו את הקוד הנתון וענו על השאלות הבאות.", "code_snippet": "#include <iostream>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\n// Global mutex for lazy initialization of Logger\npthread_mutex_t logger_init_mutex = PTHREAD_MUTEX_INITIALIZER;\n// Global mutex for configuration access (used by Logger constructor and update_configuration)\npthread_mutex_t config_mutex = PTHREAD_MUTEX_INITIALIZER;\n\nclass Logger {\npublic:\n    Logger() {\n        // Simulate expensive initialization requiring config_mutex\n        pthread_mutex_lock(&config_mutex);\n        std::cout << \"Logger constructor: Acquiring config_mutex for expensive initialization...\" << std::endl;\n        sleep(2); // Simulate long initialization\n        std::cout << \"Logger constructor: Finished expensive initialization and releasing config_mutex.\" << std::endl;\n        pthread_mutex_unlock(&config_mutex);\n    }\n\n    void log(const char* message) {\n        std::cout << \"Log message: \" << message << std::endl;\n    }\n};\n\n// The singleton instance\nLogger* g_logger_instance = NULL;\n\n// Function to get the singleton Logger instance\nLogger* get_logger() {\n    if (g_logger_instance == NULL) { // First check (no lock)\n        pthread_mutex_lock(&logger_init_mutex);\n        if (g_logger_instance == NULL) { // Second check (with lock)\n            std::cout << \"Thread \" << pthread_self() << \": Initializing Logger...\" << std::endl;\n            g_logger_instance = new Logger(); // Calls Logger constructor\n            std::cout << \"Thread \" << pthread_self() << \": Logger initialized.\" << std::endl;\n        }\n        pthread_mutex_unlock(&logger_init_mutex);\n    }\n    return g_logger_instance;\n}\n\n// Another function that needs config_mutex then logger_init_mutex\nvoid update_configuration() {\n    std::cout << \"Thread \" << pthread_self() << \": Entering update_configuration()...\" << std::endl;\n    pthread_mutex_lock(&config_mutex);\n    std::cout << \"Thread \" << pthread_self() << \": Acquired config_mutex in update_configuration().\" << std::endl;\n    sleep(1); // Simulate some work\n    \n    pthread_mutex_lock(&logger_init_mutex); // Potential deadlock here\n    std::cout << \"Thread \" << pthread_self() << \": Acquired logger_init_mutex in update_configuration().\" << std::endl;\n    // Perform configuration update that might involve checking logger state or similar\n    // For simplicity, just simulate work.\n    sleep(1);\n    \n    pthread_mutex_unlock(&logger_init_mutex);\n    std::cout << \"Thread \" << pthread_self() << \": Released logger_init_mutex in update_configuration().\" << std::endl;\n    \n    pthread_mutex_unlock(&config_mutex);\n    std::cout << \"Thread \" << pthread_self() << \": Released config_mutex in update_configuration().\" << std::endl;\n}\n\n// Example thread functions\nvoid* thread_logger_task(void* arg) {\n    Logger* logger = get_logger();\n    logger->log(\"Hello from logger thread!\");\n    return NULL;\n}\n\nvoid* thread_config_task(void* arg) {\n    update_configuration();\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n\n    std::cout << \"Starting threads...\" << std::endl;\n    pthread_create(&t1, NULL, thread_logger_task, NULL);\n    pthread_create(&t2, NULL, thread_config_task, NULL);\n\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n\n    std::cout << \"Threads finished.\" << std::endl;\n\n    // Clean up\n    delete g_logger_instance; // Only if initialized\n    pthread_mutex_destroy(&logger_init_mutex);\n    pthread_mutex_destroy(&config_mutex);\n\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "101.1", "text": "זהו את בעיית הסנכרון הקיימת בקוד. תארו כיצד הבעיה יכולה להתרחש באמצעות רצף אירועים ספציפי הכולל את שני החוטים (t1 ו-t2).", "code_snippet": null, "options": null}, {"id": "101.2", "text": "תקנו את הקוד על מנת לפתור את בעיית הסנכרון שזיהיתם. הסבירו בקצרה את הפתרון שלכם ואת השינויים שביצעתם.", "code_snippet": "/* הכניסו כאן את הקוד המתוקן */", "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "### 101.1 זיהוי הבעיה והסבר:\nהבעיה היא **קיפאון (Deadlock)**. קיפאון יכול להתרחש כאשר שני חוטים או יותר ממתינים זה לזה למשאב שהשני מחזיק בו, ויוצרים מעגל המתנה.\n\n**רצף אירועים המוביל לקיפאון:**\n1.  **חוט t1 (מריץ את `thread_logger_task`):** קורא לפונקציה `get_logger()`. הוא מגלה ש-`g_logger_instance` הוא `NULL`.\n2.  **חוט t1:** נועל את `logger_init_mutex`. (כעת t1 מחזיק ב-`logger_init_mutex`).\n3.  **חוט t1:** מתחיל את יצירת אובייקט `Logger` על ידי קריאה ל-`new Logger()`.\n4.  **חוט t1 (בתוך הקונסטרוקטור של `Logger`):** מנסה לנעול את `config_mutex`. כעת הוא ממתין ל-`config_mutex`.\n\n5.  **חוט t2 (מריץ את `thread_config_task`):** קורא לפונקציה `update_configuration()`.\n6.  **חוט t2:** נועל את `config_mutex`. (כעת t2 מחזיק ב-`config_mutex`).\n7.  **חוט t2:** מנסה לנעול את `logger_init_mutex`. כעת הוא ממתין ל-`logger_init_mutex`.\n\n**תוצאה:**\n*   חוט t1 מחזיק ב-`logger_init_mutex` וממתין ל-`config_mutex`.\n*   חוט t2 מחזיק ב-`config_mutex` וממתין ל-`logger_init_mutex`.\n\nשני החוטים חסומים באופן הדדי, ונוצר מצב של קיפאון. אף אחד מהם לא יכול להמשיך, והתוכנית תיתקע.\n\n### 101.2 תיקון הקוד:\nהבעיה נובעת מכך שהחוטים מנסים לנעול את המנעולים בסדר שונה: `get_logger` נועל את `logger_init_mutex` ואז מנסה לנעול את `config_mutex` (דרך הקונסטרוקטור), בעוד ש-`update_configuration` נועל את `config_mutex` ואז מנסה לנעול את `logger_init_mutex`. כדי למנוע קיפאון, יש להקפיד על סדר אחיד של נעילת מנעולים בכל מקום בתוכנית.\n\n**פתרון:** נשנה את סדר נעילת המנעולים בפונקציה `update_configuration()` כך שתמיד ינעל קודם את `logger_init_mutex` ולאחר מכן את `config_mutex`. לחלופין, ניתן לשנות את הקונסטרוקטור של `Logger` כך שינעל את `config_mutex` רק *לאחר* ש-`logger_init_mutex` שוחרר, אך זה מסובך יותר ודורש שינוי לוגיקה של Double-Checked Locking. הסדר העדיף הוא לשנות את `update_configuration` כדי להתאים לסדר של `get_logger` (או להיפך), תוך שמירה על סדר עקבי.\n\n**שינויים שבוצעו:**\nהקוד של `update_configuration()` שונה כך שסדר נעילת המנעולים יהיה זהה לסדר המרומז ב-`get_logger()` (כלומר, קודם `logger_init_mutex` ואז `config_mutex`).\n\n```c\n#include <iostream>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\n// Global mutex for lazy initialization of Logger\npthread_mutex_t logger_init_mutex = PTHREAD_MUTEX_INITIALIZER;\n// Global mutex for configuration access (used by Logger constructor and update_configuration)\npthread_mutex_t config_mutex = PTHREAD_MUTEX_INITIALIZER;\n\nclass Logger {\npublic:\n    Logger() {\n        // Simulate expensive initialization requiring config_mutex\n        pthread_mutex_lock(&config_mutex); // This is still the internal order for Logger init\n        std::cout << \"Logger constructor: Acquiring config_mutex for expensive initialization...\" << std::endl;\n        sleep(2); // Simulate long initialization\n        std::cout << \"Logger constructor: Finished expensive initialization and releasing config_mutex.\" << std::endl;\n        pthread_mutex_unlock(&config_mutex);\n    }\n\n    void log(const char* message) {\n        std::cout << \"Log message: \" << message << std::endl;\n    }\n};\n\n// The singleton instance\nLogger* g_logger_instance = NULL;\n\n// Function to get the singleton Logger instance\nLogger* get_logger() {\n    if (g_logger_instance == NULL) { // First check (no lock)\n        pthread_mutex_lock(&logger_init_mutex);\n        if (g_logger_instance == NULL) { // Second check (with lock)\n            std::cout << \"Thread \" << pthread_self() << \": Initializing Logger...\" << std::endl;\n            g_logger_instance = new Logger(); // Calls Logger constructor\n            std::cout << \"Thread \" << pthread_self() << \": Logger initialized.\" << std::endl;\n        }\n        pthread_mutex_unlock(&logger_init_mutex);\n    }\n    return g_logger_instance;\n}\n\n// Another function that needs config_mutex then logger_init_mutex\nvoid update_configuration() {\n    std::cout << \"Thread \" << pthread_self() << \": Entering update_configuration()...\" << std::endl;\n    \n    // FIX: Changed lock order to prevent deadlock. \n    // Now it always locks logger_init_mutex first, then config_mutex.\n    pthread_mutex_lock(&logger_init_mutex);\n    std::cout << \"Thread \" << pthread_self() << \": Acquired logger_init_mutex in update_configuration().\" << std::endl;\n    sleep(1); // Simulate some work\n\n    pthread_mutex_lock(&config_mutex);\n    std::cout << \"Thread \" << pthread_self() << \": Acquired config_mutex in update_configuration().\" << std::endl;\n    // Perform configuration update that might involve checking logger state or similar\n    // For simplicity, just simulate work.\n    sleep(1);\n    \n    pthread_mutex_unlock(&config_mutex);\n    std::cout << \"Thread \" << pthread_self() << \": Released config_mutex in update_configuration().\" << std::endl;\n    \n    pthread_mutex_unlock(&logger_init_mutex);\n    std::cout << \"Thread \" << pthread_self() << \": Released logger_init_mutex in update_configuration().\" << std::endl;\n}\n\n// Example thread functions\nvoid* thread_logger_task(void* arg) {\n    Logger* logger = get_logger();\n    logger->log(\"Hello from logger thread!\");\n    return NULL;\n}\n\nvoid* thread_config_task(void* arg) {\n    update_configuration();\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n\n    std::cout << \"Starting threads...\" << std::endl;\n    pthread_create(&t1, NULL, thread_logger_task, NULL);\n    pthread_create(&t2, NULL, thread_config_task, NULL);\n\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n\n    std::cout << \"Threads finished.\" << std::endl;\n\n    // Clean up\n    delete g_logger_instance; // Only if initialized\n    pthread_mutex_destroy(&logger_init_mutex);\n    pthread_mutex_destroy(&config_mutex);\n\n    return 0;\n}\n```\n\n**הערה:** חשוב לציין שהפתרון הזה (שינוי סדר הנעילה ב-`update_configuration`) עובד מכיוון שהוא מייצר סדר נעילה גלובלי אחיד: תמיד `logger_init_mutex` ואז `config_mutex` (או רק אחד מהם). אם היה צורך אמיתי לנעול את `config_mutex` לפני `logger_init_mutex` ב-`update_configuration` מסיבות לוגיות אחרות, היה צריך לשקול פתרונות מורכבים יותר כמו `trylock` או שימוש ב-`std::call_once` ב-C++11 ומעלה כדי להימנע מנעילת `logger_init_mutex` באופן ישיר ב-`get_logger` לאחר האתחול הראשון."}, "difficulty_estimation": "Hard", "_source_file": "0287__Mutexes__CodeAnalysis__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:34:39", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Synchronization", "Mutexes", "Concurrency", "Deadlocks"], "content": {"text": "נתונה מערכת עם שני משאבים משותפים, resourceA ו-resourceB, המיוצגים על ידי משתני int. כל משאב מוגן על ידי מוטקס משלו: mutexA עבור resourceA ו-mutexB עבור resourceB.\nהמערכת כוללת שתי פונקציות: transfer_A_to_B(int amount) ו-transfer_B_to_A(int amount), המיועדות להעביר כמות מסוימת של ערך בין המשאבים באופן מאובטח. כלומר, transfer_A_to_B מפחיתה את amount מ-resourceA ומוסיפה אותו ל-resourceB, ו-transfer_B_to_A מבצעת את הפעולה ההפוכה. שתי הפונקציות מיועדות לרוץ במקביל על ידי חוטים שונים.\nלהלן מימוש הפונקציות:\n\nהקוד המתואר אינו תקין ויכול להוביל לבעיה חמורה כאשר הפונקציות נקראות במקביל על ידי חוטים שונים.\n1. תארו מהי הבעיה וכיצד היא יכולה להתרחש (יש לתאר ריצה ברורה עם מספר חוטים כרצונכם).\n2. תקנו את מימוש הפונקציות transfer_A_to_B ו-transfer_B_to_A כך שיעבדו באופן תקין וימנעו את הבעיה. יש לשנות את סדר תפיסת המוטקסים בלבד, ללא הוספת משתנים או אובייקטי סנכרון נוספים.", "code_snippet": "```c\n#include <pthread.h>\n#include <unistd.h> // for sleep\n\n// משאבים משותפים\nint resourceA = 100;\nint resourceB = 100;\n\n// מוטקסים להגנה על המשאבים\npthread_mutex_t mutexA;\npthread_mutex_t mutexB;\n\n// פונקציה להעברת כמות מ-A ל-B\nvoid transfer_A_to_B(int amount) {\n    pthread_mutex_lock(&mutexA);\n    sleep(1); // מדמה עבודה או החלפת הקשר\n    pthread_mutex_lock(&mutexB);\n\n    resourceA -= amount;\n    resourceB += amount;\n\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n}\n\n// פונקציה להעברת כמות מ-B ל-A\nvoid transfer_B_to_A(int amount) {\n    pthread_mutex_lock(&mutexB);\n    sleep(1); // מדמה עבודה או החלפת הקשר\n    pthread_mutex_lock(&mutexA);\n\n    resourceB -= amount;\n    resourceA += amount;\n\n    pthread_mutex_unlock(&mutexA);\n    pthread_mutex_unlock(&mutexB);\n}\n```"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. הבעיה: קיפאון (Deadlock).\n   הבעיה יכולה להתרחש כאשר שני חוטים מנסים לבצע פעולות העברה במקביל, כאשר כל אחד מהם תופס מוטקס אחד וממתין למוטקס השני שנתפס על ידי החוט האחר. לדוגמה:\n\n   *   **חוט 1** קורא ל-`transfer_A_to_B(10)`:\n       *   תופס את `mutexA`.\n       *   מתבצעת `sleep(1)` (מדמה עבודה או החלפת הקשר).\n   *   **חוט 2** קורא ל-`transfer_B_to_A(10)` (במקביל לחוט 1, בזמן שחוט 1 ב-`sleep`):\n       *   תופס את `mutexB`.\n       *   מתבצעת `sleep(1)` (מדמה עבודה או החלפת הקשר).\n   *   **חוט 1** מנסה כעת לתפוס את `mutexB` אך הוא חסום, מכיוון ש-`mutexB` נתפס על ידי חוט 2.\n   *   **חוט 2** מנסה כעת לתפוס את `mutexA` אך הוא חסום, מכיוון ש-`mutexA` נתפס על ידי חוט 1.\n\n   בנקודה זו, שני החוטים חסומים באופן הדדי וממתינים זה לזה לשחרר את המוטקס שהם זקוקים לו. אף אחד מהם לא יכול להמשיך, והמערכת נכנסת למצב של קיפאון.\n\n2. תיקון: כדי למנוע קיפאון, יש להקפיד על סדר אחיד של תפיסת מוטקסים בכל הפונקציות שצריכות לתפוס מספר מוטקסים. במקרה זה, נקבע שכל הפונקציות יתפסו תמיד את `mutexA` לפני `mutexB`.\n\n   ```c\n// פונקציה להעברת כמות מ-A ל-B (ללא שינוי בסדר תפיסת המוטקסים)\nvoid transfer_A_to_B(int amount) {\n    pthread_mutex_lock(&mutexA);\n    pthread_mutex_lock(&mutexB); // תמיד תופסים את mutexA לפני mutexB\n\n    resourceA -= amount;\n    resourceB += amount;\n\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n}\n\n// פונקציה להעברת כמות מ-B ל-A (תיקון סדר תפיסת המוטקסים)\nvoid transfer_B_to_A(int amount) {\n    pthread_mutex_lock(&mutexA); // תופסים קודם את mutexA\n    pthread_mutex_lock(&mutexB); // ואז את mutexB\n\n    resourceB -= amount;\n    resourceA += amount;\n\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n}\n   ```\n   הסבר לתיקון: על ידי אכיפת סדר קבוע (למשל, תמיד `mutexA` ואז `mutexB`), אנו מבטיחים שלעולם לא ייווצר מצב שבו חוט אחד מחזיק ב-`mutexA` וממתין ל-`mutexB` בעוד חוט אחר מחזיק ב-`mutexB` וממתין ל-`mutexA`. חוטים תמיד ינסו לתפוס את המוטקסים באותו סדר, וכך אם חוט אחד כבר תפס את `mutexA`, כל חוט אחר שינסה לתפוס את `mutexA` יחסם עד ש-`mutexA` ישוחרר, ובכך נמנע את מעגל ההמתנה ההדדית שגורם לקיפאון."}, "difficulty_estimation": "Hard", "_source_file": "0288__Mutexes__CodeAnalysis__Hard.json", "_topic_hint": "Mutexes", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:35:04", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Synchronization", "Semaphores"], "content": {"text": "מהי המטרה העיקרית של סמפור (Semaphore)?", "code_snippet": null, "options": ["א. לניהול תזמון מעבד (CPU scheduling).", "ב. לתקשורת בין תהליכים (IPC).", "ג. לסנכרון גישה למשאבים משותפים.", "ד. להקצאת זיכרון."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "ג'. סמפורים משמשים בעיקר כמנגנון סנכרון המאפשר בקרת גישה למשאבים משותפים (כגון קטעים קריטיים) ופתרון בעיות סנכרון בין תהליכים או חוטים, ובכך מונעים תנאי מרוץ (race conditions)."}, "difficulty_estimation": "Easy", "_source_file": "0289__Semaphores__MultipleChoice__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:35:11", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization", "Mutual Exclusion"], "content": {"text": "מהו הערך ההתחלתי המתאים לסמפור בינארי המשמש להבטחת הדדיות (mutual exclusion) באזור קריטי?", "code_snippet": null, "options": ["א. 0", "ב. 1", "ג. -1", "ד. כל מספר שלם חיובי", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. סמפור בינארי המשמש ל-mutual exclusion (הדדיות) צריך להתחיל עם ערך 1. ערך זה מאפשר לתהליך אחד להיכנס לאזור הקריטי. כאשר תהליך קורא לפעולת wait (או P), ערך הסמפור יורד ל-0, וחוסם כניסה של תהליכים נוספים. כאשר התהליך מסיים וקורא לפעולת signal (או V), ערך הסמפור עולה חזרה ל-1, ומאפשר לתהליך הבא להיכנס."}, "difficulty_estimation": "Easy", "_source_file": "0290__Semaphores__MultipleChoice__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:35:18", "_subject": "Concurrency"}, {"id": 2, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization", "Critical Section"], "content": {"text": "מהו הערך ההתחלתי הנכון של סמפור בינארי המשמש להגנה על קטע קריטי (critical section) יחיד?", "code_snippet": null, "options": ["א. 0", "ב. 1", "ג. -1", "ד. כל ערך חיובי", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הסבר: סמפור בינארי המשמש להדדיות בלעדית (mutual exclusion) על קטע קריטי צריך להיות מאותחל ל-1. זה מאפשר לתהליך אחד בלבד להיכנס לקטע הקריטי על ידי ביצוע פעולת wait (המפחיתה את ערך הסמפור ל-0). תהליכים נוספים שינסו להיכנס יחסמו עד שהתהליך שבקטע הקריטי יבצע פעולת signal (המגדילה את ערך הסמפור בחזרה ל-1)."}, "difficulty_estimation": "Easy", "_source_file": "0291__Semaphores__MultipleChoice__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:35:26", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization"], "content": {"text": "מהי מטרתה העיקרית של פעולת ה-wait (או P) על סמפור?", "code_snippet": null, "options": ["א. להגדיל את ערך הסמפור.", "ב. להקטין את ערך הסמפור, ואם ערכו הופך לשלילי, לחסום את התהליך הקורא.", "ג. לשחרר משאב שהתהליך תפס.", "ד. לאתחל את הסמפור לערך מסוים.", "ה. לאפשר לתהליכים לעקוף את מנגנון הסנכרון."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "פעולת ה-wait (או P) על סמפור נועדה לבקש גישה למשאב או להיכנס לקטע קריטי. היא מקטינה את ערך הסמפור. אם לאחר ההקטנה ערך הסמפור שלילי, המשמעות היא שהמשאב אינו זמין (או הקטע הקריטי תפוס), והתהליך הקורא נחסם עד שפעולת signal תשחרר משאב ותגדיל את ערך הסמפור, מה שיאפשר לתהליך להמשיך."}, "difficulty_estimation": "Easy", "_source_file": "0292__Semaphores__MultipleChoice__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:35:34", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization", "Concurrency"], "content": {"text": "מהו הערך ההתחלתי הנכון לסמפור בינארי המשמש להגנה על קטע קריטי (critical section) מפני כניסה בו זמנית של מספר תהליכים?", "code_snippet": null, "options": ["א. 0", "ב. 1", "ג. -1", "ד. כל מספר חיובי גדול מ-1", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הסמפור הבינארי משמש למנגנון הרחקה הדדית (mutual exclusion). כאשר הוא מוגדר לערך 1, הוא מאפשר לתהליך אחד בלבד להיכנס לקטע הקריטי. התהליך הראשון שנכנס מבצע פעולת wait/P ומקטין את ערך הסמפור ל-0. כל תהליך נוסף שינסה להיכנס יחסם (ייכנס למצב המתנה) עד שהתהליך הראשון יצא ויבצע פעולת signal/V, מה שיחזיר את ערך הסמפור ל-1 ויאפשר לתהליך אחר להיכנס."}, "difficulty_estimation": "Easy", "_source_file": "0293__Semaphores__MultipleChoice__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:35:42", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization"], "content": {"text": "איזה ערך התחלתי יש לתת לסמפור בינארי (binary semaphore) המשמש להגנה על קטע קריטי (critical section) באמצעות מנגנון הדדיות (mutual exclusion)?", "code_snippet": null, "options": ["א. 0", "ב. 1", "ג. -1", "ד. כל ערך חיובי", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. סמפור בינארי המשמש להדדיות (mutual exclusion) על קטע קריטי מאותחל לערך 1. ערך זה מאפשר לתהליך אחד להיכנס לקטע הקריטי (על ידי ביצוע פעולת wait שמקטינה את ערך הסמפור ל-0), ומונע מתהליכים נוספים להיכנס עד שהתהליך הנוכחי יוצא מהקטע הקריטי (על ידי ביצוע פעולת signal שמגדילה את ערך הסמפור חזרה ל-1)."}, "difficulty_estimation": "Easy", "_source_file": "0294__Semaphores__MultipleChoice__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:35:47", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization"], "content": {"text": "מהי המטרה העיקרית של שימוש בסמפור בינארי (binary semaphore) במערכת הפעלה?", "code_snippet": null, "options": ["א. לספור את מספר המשאבים הזמינים במערכת.", "ב. להבטיח גישה בלעדית (mutual exclusion) לקטע קריטי (critical section).", "ג. לתזמן את ביצוע התהליכים (process scheduling).", "ד. לנהל את הקצאת הזיכרון הפיזי (physical memory allocation)."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "סמפור בינארי (המכונה לעיתים גם mutex) משמש בעיקר להבטחת גישה בלעדית לקטע קריטי. מטרתו היא לוודא שרק תהליך אחד יבצע את הקטע הקריטי בכל רגע נתון, ובכך למנוע תנאי מרוץ (race conditions) ולשמור על עקביות הנתונים המשותפים."}, "difficulty_estimation": "Easy", "_source_file": "0295__Semaphores__MultipleChoice__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:35:55", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization", "Mutual Exclusion"], "content": {"text": "מהו הערך ההתחלתי הנכון של סמפור בינארי המשמש להבטחת הדרה הדדית (mutual exclusion)?", "code_snippet": null, "options": ["א. 0", "ב. 1", "ג. -1", "ד. כל ערך חיובי", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "סמפור בינארי המיועד להבטחת הדרה הדדית (mutual exclusion) בין חלקים קריטיים של קוד צריך להיות מאותחל לערך 1. ערך זה מציין שהמשאב פנוי וחוט אחד יכול להיכנס לאזור הקריטי. כאשר חוט נכנס, הוא מבצע פעולת wait (P) שמורידה את ערך הסמפור ל-0, ובכך חוסמת חוטים אחרים מלהיכנס. כאשר החוט יוצא מהאזור הקריטי, הוא מבצע פעולת signal (V) שמחזירה את הערך ל-1, ומאפשרת לחוט אחר להיכנס."}, "difficulty_estimation": "Easy", "_source_file": "0296__Semaphores__MultipleChoice__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:36:02", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization"], "content": {"text": "נתון סמפור מונה (counting semaphore) בשם `resource_access` אשר מאותחל לערך `3`. מספר תהליכים מנסים לגשת למשאב משותף המוגן על ידי סמפור זה. כל תהליך מבצע `wait(&resource_access)` לפני הכניסה לאזור קריטי ו-`signal(&resource_access)` ביציאה ממנו.\nבהינתן ש-2 תהליכים כבר נמצאים בתוך האזור הקריטי, וכעת 5 תהליכים *נוספים* מנסים להיכנס לאזור הקריטי (כלומר, מבצעים `wait()`), מה יהיה ערכו הסופי של הסמפור `resource_access` מיד לאחר שכל 5 התהליכים הנוספים ינסו לבצע `wait()`?", "code_snippet": null, "options": ["א. 1", "ב. 0", "ג. -2", "ד. -4", "ה. אף אחת מהתשובות אינה נכונה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "הסמפור `resource_access` מאותחל לערך 3.\nכאשר 2 תהליכים כבר נמצאים באזור הקריטי, פירוש הדבר שהם ביצעו בהצלחה פעולת `wait()` מבלי לבצע עדיין `signal()`.\nלכן, ערכו של הסמפור יורד ב-2: `3 - 2 = 1`.\n\nכעת, 5 תהליכים *נוספים* מנסים להיכנס לאזור הקריטי (מבצעים `wait()`):\n1. התהליך הראשון מתוך ה-5 מבצע `wait()`: ערך הסמפור יורד ל-`1 - 1 = 0`. תהליך זה נכנס לאזור הקריטי.\n2. התהליך השני מתוך ה-5 מבצע `wait()`: ערך הסמפור יורד ל-`0 - 1 = -1`. תהליך זה נחסם (blocked).\n3. התהליך השלישי מתוך ה-5 מבצע `wait()`: ערך הסמפור יורד ל-`-1 - 1 = -2`. תהליך זה נחסם.\n4. התהליך הרביעי מתוך ה-5 מבצע `wait()`: ערך הסמפור יורד ל-`-2 - 1 = -3`. תהליך זה נחסם.\n5. התהליך החמישי מתוך ה-5 מבצע `wait()`: ערך הסמפור יורד ל-`-3 - 1 = -4`. תהליך זה נחסם.\n\nלכן, הערך הסופי של הסמפור `resource_access` יהיה -4."}, "difficulty_estimation": "Medium", "_source_file": "0297__Semaphores__MultipleChoice__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:36:22", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Semaphores"], "content": {"text": "נתון סמפור (semaphore) בשם S שאותחל לערך 3.\nבמהלך ביצוע התוכנית, התרחשו הפעולות הבאות:\n- 5 קריאות לפונקציה wait(S)\n- 3 קריאות לפונקציה signal(S)\nבהנחה שאין פעולות נוספות על הסמפור וכל הקריאות בוצעו במלואן, מה יהיה ערכו הסופי של הסמפור S?", "code_snippet": null, "options": ["א. 0", "ב. 1", "ג. 2", "ד. -1", "ה. 3"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הסמפור S מאותחל לערך 3.\n\nכל קריאה ל-wait(S) מורידה את ערך הסמפור ב-1. אם ערך הסמפור הופך שלילי, התהליך הקורא נחסם. מספר שלילי מציין כמה תהליכים חסומים ממתינים.\nכל קריאה ל-signal(S) מעלה את ערך הסמפור ב-1. אם ערך הסמפור היה שלילי (כלומר, היו תהליכים חסומים), אחד מהם משוחרר.\n\nנתחיל עם S = 3.\n\nלאחר 5 קריאות wait(S):\n1. S = 2\n2. S = 1\n3. S = 0\n4. S = -1 (תהליך נחסם)\n5. S = -2 (תהליך נוסף נחסם)\nבשלב זה, ערך הסמפור הוא -2, ושני תהליכים חסומים.\n\nלאחר 3 קריאות signal(S):\n1. S = -1 (תהליך אחד משוחרר)\n2. S = 0 (התהליך השני משוחרר)\n3. S = 1 (אין תהליכים חסומים, הערך פשוט עולה)\n\nלכן, ערכו הסופי של הסמפור יהיה 1."}, "difficulty_estimation": "Medium", "_source_file": "0298__Semaphores__MultipleChoice__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:37:05", "_subject": "Concurrency"}, {"id": 4, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization", "Critical Section"], "content": {"text": "נתונה מערכת הפעלה שבה שני תהליכים, P1 ו-P2, מנסים לגשת למשאב משותף X. הם משתמשים בסמפור בינארי בשם `mutex` שאותחל ל-1. להלן קטעי הקוד המתארים את פעולתם:", "code_snippet": "sem_t mutex; // Global semaphore variable\n\nvoid init_sem() {\n    sem_init(&mutex, 0, 1); // Initialize mutex to 1 (binary semaphore)\n}\n\nvoid P1_task() {\n    sem_wait(&mutex); // Wait for the semaphore\n    // Critical Section: Access shared resource X\n    printf(\"Process P1 is accessing shared resource X.\\n\");\n    sem_post(&mutex); // Signal (release) the semaphore\n}\n\nvoid P2_task() {\n    sem_wait(&mutex); // Wait for the semaphore\n    // Critical Section: Access shared resource X\n    printf(\"Process P2 is accessing shared resource X.\\n\");\n    sem_post(&mutex); // Signal (release) the semaphore\n}\n\n// Assuming init_sem() is called once before P1_task and P2_task are run concurrently.", "options": ["א. שני התהליכים יכולים לגשת למשאב X בו-זמנית, מה שיוביל לתנאי מרוץ.", "ב. רק תהליך אחד יכול לגשת למשאב X בכל רגע נתון.", "ג. אחד התהליכים יגרום ל-deadlock עבור התהליך השני.", "ד. הגישה למשאב X אינה מובטחת, וקריאות `sem_wait` עשויות להיכשל.", "ה. הסמפור ימנע גישה למשאב X לצמיתות עבור אחד התהליכים עקב רעב (starvation)."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. סמפור בינארי המאותחל ל-1 משמש כמנעול (mutex) להגנה על קטע קריטי. כאשר תהליך קורא ל-`sem_wait()` (או `P()`), הוא מקטין את ערך הסמפור. אם ערכו הופך ל-0, תהליכים אחרים שיקראו ל-`sem_wait()` יחסמו עד שהתהליך הנוכחי יקרא ל-`sem_post()` (או `V()`) וישחרר את הסמפור. לכן, רק תהליך אחד יכול להימצא בקטע הקריטי (הגישה למשאב X) בכל רגע נתון, ובכך נמנעים תנאי מרוץ ומובטחת הדדיות (mutual exclusion)."}, "difficulty_estimation": "Medium", "_source_file": "0299__Semaphores__MultipleChoice__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:37:28", "_subject": "Concurrency"}, {"id": 4, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization"], "content": {"text": "נתון סמפור `s` שהאותחל לערך `3`.\nשלושה תהליכים (P1, P2, P3) מבצעים את הפעולות הבאות בסדר המתואר:\n1. P1 מבצע `wait(s)`\n2. P2 מבצע `wait(s)`\n3. P3 מבצע `signal(s)`\n4. P1 מבצע `wait(s)`\n5. P2 מבצע `signal(s)`\n\nמהו ערכו הסופי של הסמפור `s` לאחר כל הפעולות הללו?\n(הניחו שפעולות `wait` ו-`signal` הינן אטומיות).", "code_snippet": null, "options": ["א. 0", "ב. 1", "ג. 2", "ד. 3", "ה. 4"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "נבצע מעקב אחר ערך הסמפור `s`:\n1. ערך התחלתי: `s = 3`\n2. P1 מבצע `wait(s)`: `s` יורד ל-`2`.\n3. P2 מבצע `wait(s)`: `s` יורד ל-`1`.\n4. P3 מבצע `signal(s)`: `s` עולה ל-`2`.\n5. P1 מבצע `wait(s)`: `s` יורד ל-`1`.\n6. P2 מבצע `signal(s)`: `s` עולה ל-`2`.\n\nלכן, הערך הסופי של הסמפור `s` הוא `2`."}, "difficulty_estimation": "Medium", "_source_file": "0300__Semaphores__MultipleChoice__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:38:06", "_subject": "Concurrency"}, {"id": 4, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization", "Mutual Exclusion"], "content": {"text": "נתון קטע קוד המשתמש במנגנון סמפור (Semaphore) להגנה על משאב משותף. איזה מההצהרות הבאות מתארת נכונה את מטרת השימוש בסמפור בקטע קוד זה?", "code_snippet": "#include <semaphore.h>\n#include <pthread.h>\n#include <stdio.h>\n\nsem_t mutex;\nint shared_resource = 0;\n\nvoid* thread_func(void* arg) {\n    sem_wait(&mutex); // P operation\n    // Critical section\n    shared_resource++;\n    printf(\"Thread %ld: shared_resource = %d\\n\", (long)pthread_self(), shared_resource);\n    sem_post(&mutex); // V operation\n    return NULL;\n}\n\nint main() {\n    sem_init(&mutex, 0, 1); // Initialize semaphore for mutual exclusion\n    pthread_t t1, t2;\n\n    pthread_create(&t1, NULL, thread_func, NULL);\n    pthread_create(&t2, NULL, thread_func, NULL);\n\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n\n    sem_destroy(&mutex);\n    return 0;\n}", "options": ["א. להבטיח שרק תהליך אחד יבצע את פעולת ההדפסה בכל רגע נתון.", "ב. למנוע מצב שבו שני תהליכים ניגשים למשתנה shared_resource בו-זמנית.", "ג. לסנכרן את סדר ההדפסה של התהליכים כך שתהליך t1 תמיד ידפיס לפני t2.", "ד. להגביל את מספר הפעמים שניתן להגדיל את shared_resource לשניים בלבד.", "ה. לאפשר לתהליכים להמתין זה לזה עד ששניהם יסיימו את הפעולה הקריטית."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הסמפור 'mutex' מאותחל לערך 1, מה שהופך אותו לסמפור בינארי (mutex). הפעולה 'sem_wait(&mutex)' מונעת מתהליכים נוספים להיכנס לקטע הקריטי אם תהליך אחר כבר נמצא בו (מורידה את ערך הסמפור ל-0 וגורמת לתהליכים אחרים להמתין). הפעולה 'sem_post(&mutex)' משחררת את הסמפור ומאפשרת לתהליך ממתין להיכנס (מעלה את ערך הסמפור ל-1). לכן, מטרתו העיקרית היא להבטיח שבכל רגע נתון רק תהליך אחד יוכל לגשת למשתנה המשותף 'shared_resource' ולבצע עליו פעולות, ובכך למנוע תנאי מרוץ (race condition) ולוודא עקביות נתונים. אפשרות א' נכונה חלקית כיוון שההדפסה נמצאת בתוך הקטע הקריטי, אך המטרה העיקרית היא הגנה על המשאב המשותף עצמו."}, "difficulty_estimation": "Medium", "_source_file": "0301__Semaphores__MultipleChoice__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:38:19", "_subject": "Concurrency"}, {"id": 4, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization"], "content": {"text": "נתון סמפור (semaphore) בשם `my_semaphore` אשר איתחלנו לערך 3. חמישה תהליכים (threads) מנסים לבצע פעולת `sem_wait(&my_semaphore)`. כמה תהליכים לכל היותר יוכלו לעבור את פעולת ה-`sem_wait` ולהיכנס לקטע הקריטי באופן מיידי, בטרם יתבצעו פעולות `sem_post` כלשהן?", "code_snippet": "sem_t my_semaphore;\nsem_init(&my_semaphore, 0, 3); // Initial value is 3\n\n// Five threads concurrently try to execute:\n// sem_wait(&my_semaphore);\n// // Critical section code\n// sem_post(&my_semaphore);", "options": ["א. 1", "ב. 2", "ג. 3", "ד. 5", "ה. אף תשובה אינה נכונה"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "סמפור המאותחל לערך N מאפשר ל-N תהליכים להיכנס לקטע קריטי (או להשתמש במשאב) באופן מיידי. במקרה זה, הסמפור אותחל לערך 3, ולכן שלושה תהליכים יוכלו לבצע `sem_wait` בהצלחה ולעבור לקטע הקריטי. התהליכים הרביעי והחמישי יחסמו עד שאחד מהתהליכים שכבר נכנסו יבצע `sem_post` וישחרר 'אישור' (permit)."}, "difficulty_estimation": "Medium", "_source_file": "0302__Semaphores__MultipleChoice__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:38:32", "_subject": "Concurrency"}, {"id": 4, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization"], "content": {"text": "סמפור ספירה (counting semaphore) בשם S מאותחל לערך 2. בהמשך, מתבצעות הפעולות הבאות:\n1. שלושה תהליכים (T1, T2, T3) קוראים לפונקציה sem_wait(&S).\n2. לאחר מכן, שני תהליכים (T4, T5) קוראים לפונקציה sem_post(&S).\n\nבהנחה שהפעולות מתבצעות בסדר זה, מהו הערך הסופי של הסמפור S לאחר שכל הפעולות הושלמו, וכמה תהליכים נשארו חסומים (blocked)?", "code_snippet": null, "options": ["א. ערך סופי של S: 1, מספר תהליכים חסומים: 0", "ב. ערך סופי של S: 0, מספר תהליכים חסומים: 1", "ג. ערך סופי של S: 2, מספר תהליכים חסומים: 0", "ד. ערך סופי של S: -1, מספר תהליכים חסומים: 1", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "נסקור את השלבים והשפעתם על ערך הסמפור ומספר התהליכים החסומים:\n\n1.  **אתחול**: הסמפור S מאותחל לערך 2.\n\n2.  **פעולות sem_wait**: שלושה תהליכים (T1, T2, T3) קוראים ל-sem_wait(&S):\n    *   T1 קורא ל-sem_wait: S יורד ל-1. T1 ממשיך.\n    *   T2 קורא ל-sem_wait: S יורד ל-0. T2 ממשיך.\n    *   T3 קורא ל-sem_wait: S יורד ל-1-. מכיוון שערך הסמפור הפך לשלילי, T3 נחסם.\n    בשלב זה: S = -1, ותהליך אחד (T3) חסום.\n\n3.  **פעולות sem_post**: שני תהליכים (T4, T5) קוראים ל-sem_post(&S):\n    *   T4 קורא ל-sem_post: S עולה ל-0. מכיוון שערך הסמפור היה לא חיובי (0 או שלילי), תהליך אחד חסום (T3) משוחרר (unblocked) ועובר למצב 'מוכן' (ready).\n    *   T5 קורא ל-sem_post: S עולה ל-1. מכיוון שאין תהליכים חסומים כרגע, אף תהליך לא משוחרר.\n\n**מצב סופי**: הערך הסופי של הסמפור S הוא 1. כל התהליכים שנחסמו (רק T3) שוחררו, ולכן אין תהליכים שנשארו חסומים בסוף.\n\nלכן, התשובה הנכונה היא: ערך סופי של S: 1, מספר תהליכים חסומים: 0."}, "difficulty_estimation": "Medium", "_source_file": "0303__Semaphores__MultipleChoice__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:38:49", "_subject": "Concurrency"}, {"id": 4, "type": "MultipleChoice", "topic": ["Semaphores", "Concurrency", "Deadlock"], "content": {"text": "נתון קטע הקוד הבא המשתמש בסמפור בינארי `mutex` להגנה על משאב משותף. מה תהיה התוצאה הסבירה ביותר כאשר שני תהליכים (threads) ינסו להריץ את `thread_func`?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n\nsem_t mutex;\nint shared_data = 0;\n\nvoid* thread_func(void* arg) {\n    sem_wait(&mutex); // P operation\n    shared_data++;\n    printf(\"Thread %ld: shared_data = %d\\n\", (long)arg, shared_data);\n    sem_post(&mutex); // V operation\n    return NULL;\n}\n\nint main() {\n    sem_init(&mutex, 0, 0); // Initializing to 0\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, thread_func, (void*)1);\n    pthread_create(&t2, NULL, thread_func, (void*)2);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    sem_destroy(&mutex);\n    return 0;\n}", "options": ["א. שני התהליכים יגדילו את `shared_data` פעם אחת כל אחד, והערך הסופי יהיה 2.", "ב. אחד התהליכים יגדיל את `shared_data` ל-1, והתהליך השני ימתין ללא הגבלת זמן.", "ג. שני התהליכים יחסמו (block) וייכנסו למצב של קיפאון (deadlock) ולא יוכלו להתקדם.", "ד. התוכנית תקרוס עקב שימוש לא חוקי בסמפור.", "ה. אף אחת מהתשובות האחרות אינה נכונה."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הסמפור `mutex` מאותחל לערך 0. כאשר תהליך מנסה לבצע פעולת `sem_wait` (P) על סמפור שערכו 0, הוא נחסם וממתין עד שערך הסמפור יהפוך לחיובי (על ידי פעולת `sem_post` - V). במקרה זה, שני התהליכים מנסים לבצע `sem_wait` על סמפור שערכו 0. שניהם ייחסמו באופן מיידי, ומכיוון שאף אחד מהם לא יצליח להגיע לפעולת `sem_post` כדי לשחרר את הסמפור, שניהם יישארו חסומים לעד. מצב זה מוביל לקיפאון (deadlock)."}, "difficulty_estimation": "Medium", "_source_file": "0304__Semaphores__MultipleChoice__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:39:05", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization", "Deadlock"], "content": {"text": "נתון קטע הקוד הבא המשתמש בסמפורים (semaphores) לצורך סנכרון בין שני תהליכונים (threads) שונים.\n\n```c\n#include <semaphore.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // for sleep\n\nsem_t sem_R1;\nsem_t sem_R2;\n\nvoid* taskA(void* arg) {\n    printf(\"TaskA: Trying to acquire R1\\n\");\n    sem_wait(&sem_R1);\n    printf(\"TaskA: Acquired R1, trying to acquire R2\\n\");\n    sleep(1); // Simulate work or context switch\n    sem_wait(&sem_R2);\n    printf(\"TaskA: Acquired R2. Critical section.\\n\");\n    // ... do work ...\n    sem_post(&sem_R2);\n    printf(\"TaskA: Released R2.\\n\");\n    sem_post(&sem_R1);\n    printf(\"TaskA: Released R1.\\n\");\n    return NULL;\n}\n\nvoid* taskB(void* arg) {\n    printf(\"TaskB: Trying to acquire R2\\n\");\n    sem_wait(&sem_R2);\n    printf(\"TaskB: Acquired R2, trying to acquire R1\\n\");\n    sleep(1); // Simulate work or context switch\n    sem_wait(&sem_R1);\n    printf(\"TaskB: Acquired R1. Critical section.\\n\");\n    // ... do work ...\n    sem_post(&sem_R1);\n    printf(\"TaskB: Released R1.\\n\");\n    sem_post(&sem_R2);\n    printf(\"TaskB: Released R2.\\n\");\n    return NULL;\n}\n\nint main() {\n    sem_init(&sem_R1, 0, 1); // Binary semaphore for R1\n    sem_init(&sem_R2, 0, 1); // Binary semaphore for R2\n\n    pthread_t tidA, tidB;\n    pthread_create(&tidA, NULL, taskA, NULL);\n    pthread_create(&tidB, NULL, taskB, NULL);\n\n    pthread_join(tidA, NULL);\n    pthread_join(tidB, NULL);\n\n    sem_destroy(&sem_R1);\n    sem_destroy(&sem_R2);\n    return 0;\n}\n```\nבאיזו בעיה, סביר להניח, נתקל בעת הרצת התוכנית עם שני התהליכונים taskA ו-taskB במקביל?", "code_snippet": null, "options": ["א. התוכנית תמיד תסיים את ריצתה ללא בעיות סנכרון.", "ב. אחד מהתהליכונים עלול לסבול מרעב (starvation) ולא לסיים את משימתו.", "ג. התוכנית עלולה להיכנס למצב של קיפאון (deadlock).", "ד. התוכנית עלולה לסבול מתנאי מרוץ (race condition) שיובילו לנתונים שגויים.", "ה. אף אחת מהטענות לעיל אינה נכונה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "ג. קטע הקוד מדגים תרחיש קלאסי של קיפאון (deadlock). תהליכון `taskA` מנסה לתפוס את `sem_R1` ולאחר מכן את `sem_R2`. לעומתו, תהליכון `taskB` מנסה לתפוס את `sem_R2` ולאחר מכן את `sem_R1`. אם `taskA` יתפוס את `sem_R1` ולאחר מכן, עקב החלפת הקשר (context switch) או תזמון, `taskB` יתפוס את `sem_R2`, שני התהליכונים ינסו לתפוס את הסמפור המוחזק על ידי השני. מצב זה יוצר תלות הדדית מעגלית (circular wait) ומוביל לקיפאון, כאשר אף אחד מהתהליכונים לא יוכל להמשיך."}, "difficulty_estimation": "Hard", "_source_file": "0305__Semaphores__MultipleChoice__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:39:42", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Semaphores", "Concurrency", "Deadlock", "Resource Allocation"], "content": {"text": "נתונה מערכת עם N משאבים זהים. M תהליכים (processes) רצים במקביל, וכל אחד מהם זקוק ל-K משאבים כדי לבצע את עבודתו. המשאבים מנוהלים באמצעות סמפור מונה `resources` המאותחל ל-N. קטע הקוד הבא מתאר את לוגיקת רכישת ושחרור המשאבים עבור כל תהליך:", "code_snippet": "semaphore resources = N; // N total resources\n\nvoid process_func() {\n    // Acquire K resources\n    for (int i = 0; i < K; i++) {\n        wait(resources);\n    }\n\n    // Critical section: Use K resources\n    // ... perform work ...\n\n    // Release K resources\n    for (int i = 0; i < K; i++) {\n        signal(resources);\n    }\n}", "options": ["א. הפתרון מבטיח מניעת קיפאון (deadlock-free).", "ב. הפתרון מבטיח מניעת הרעבה (starvation-free).", "ג. הפתרון עשוי להוביל לקיפאון (deadlock) בתנאים מסוימים.", "ד. הפתרון מבטיח הדדית בלעדיות (mutual exclusion) על כל K המשאבים.", "ה. אף אחת מהטענות האחרות אינה נכונה בהכרח."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התשובה הנכונה היא ג'.\n\nהסבר:\nכאשר K > 1 ורכישת המשאבים מתבצעת באופן סדרתי (wait() K פעמים), נוצר סיכון לקיפאון (deadlock). דמיינו תרחיש שבו N=2 משאבים, M=2 תהליכים, וכל תהליך זקוק ל-K=2 משאבים. \n1. תהליך P1 מבצע wait(resources) פעם אחת. ערך הסמפור יורד ל-1.\n2. תהליך P2 מבצע wait(resources) פעם אחת. ערך הסמפור יורד ל-0.\n3. כעת, P1 מנסה לבצע wait(resources) בפעם השנייה, אך ערך הסמפור הוא 0, ולכן P1 נחסם.\n4. P2 מנסה לבצע wait(resources) בפעם השנייה, אך ערך הסמפור הוא 0, ולכן P2 נחסם גם הוא.\n\nבמצב זה, P1 מחזיק במשאב אחד וממתין למשאב נוסף ש-P2 עשוי להחזיק בו, ו-P2 מחזיק במשאב אחד וממתין למשאב נוסף ש-P1 עשוי להחזיק בו. זוהי דוגמה קלאסית לקיפאון מעגלי (circular wait), שהיא אחד מארבעת התנאים ההכרחיים לקיפאון. לכן, הפתרון עשוי להוביל לקיפאון בתנאים מסוימים.\n\n- א. הפתרון אינו מבטיח מניעת קיפאון, כפי שהודגם לעיל.\n- ב. קיפאון מוביל בהכרח להרעבה, ולכן אם קיפאון אפשרי, הפתרון אינו מבטיח מניעת הרעבה.\n- ד. הסמפור `resources` הוא סמפור מונה המגביל את המספר הכולל של משאבים בשימוש ל-N. הוא אינו מבטיח הדדית בלעדיות על *סט של K משאבים* עבור תהליך בודד, במובן שרק תהליך אחד יכול להחזיק K משאבים בכל רגע נתון. לדוגמה, אם N=4 ו-K=2, שני תהליכים יכולים להחזיק 2 משאבים כל אחד בו-זמנית. לכן, טענה זו אינה נכונה.\n- ה. מכיוון שטענה ג' נכונה, טענה ה' אינה נכונה."}, "difficulty_estimation": "Hard", "_source_file": "0306__Semaphores__MultipleChoice__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:40:06", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Semaphores", "Concurrency", "Race Conditions", "Synchronization"], "content": {"text": "נתון קטע הקוד הבא המשתמש בסמפור מסוג POSIX counting semaphore. הסמפור `mutex` מאותחל לערך 1 (בינארי). שני תהליכונים (threads), `thread_func(0)` ו-`thread_func(1)`, מורצים במקביל. נניח שהחלפות הקשר (context switches) יכולות להתרחש בכל נקודה בין פקודות. מהו הערך הסופי *האפשרי* של `shared_data` לאחר ששני התהליכונים סיימו את ריצתם?", "code_snippet": "#include <semaphore.h>\n#include <pthread.h>\n#include <stdio.h>\n\nsem_t mutex;\nint shared_data = 0;\n\nvoid* thread_func(void* arg) {\n    long id = (long)arg;\n\n    // Critical section 1\n    sem_wait(&mutex);\n    shared_data++;\n    sem_post(&mutex);\n\n    // Conditional extra post by thread 0\n    if (id % 2 == 0) {\n        sem_post(&mutex);\n    }\n\n    // Critical section 2\n    sem_wait(&mutex);\n    shared_data--;\n    sem_post(&mutex);\n\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[2];\n\n    sem_init(&mutex, 0, 1); // Initialize as a binary semaphore\n\n    pthread_create(&threads[0], NULL, thread_func, (void*)0);\n    pthread_create(&threads[1], NULL, thread_func, (void*)1);\n\n    pthread_join(threads[0], NULL);\n    pthread_join(threads[1], NULL);\n\n    sem_destroy(&mutex);\n    printf(\"Final shared_data: %d\\n\", shared_data);\n    return 0;\n}", "options": ["א. 0 בלבד", "ב. 1 בלבד", "ג. 0 או -1", "ד. 1 או -1", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ה", "explanation": "הסמפור `mutex` מאותחל ל-1, ונועד לשמש להדדיות (mutual exclusion). עם זאת, סמפור POSIX counting semaphore יכול לקבל ערכים גדולים מ-1 כאשר `sem_post` נקראת יותר פעמים מ-`sem_wait` (בניגוד ל-mutex רגיל שלא ניתן 'לשחרר' אותו יותר מפעם אחת מבלי לנעול אותו שוב). \n\nנתבונן בשני תהליכונים, `T0` (id=0) ו-`T1` (id=1):\n*   כל תהליכון מבצע שתי פעולות `sem_wait` ושתי פעולות `sem_post` על `mutex` עבור גישה ל`shared_data`.\n*   `T0` מבצע פעולת `sem_post` נוספת (בגלל התנאי `id % 2 == 0`).\n\nבסך הכל, `T0` מבצע 2 `wait` ו-3 `post`. `T1` מבצע 2 `wait` ו-2 `post`. \nהמשמעות היא ש-`T0` 'משחרר' את הסמפור פעם אחת יותר מדי. זהו המקור לבעיה ולמגוון תוצאות אפשריות.\n\n**ניתוח אפשרויות לערך `shared_data`:**\nהערך `shared_data` מתחיל ב-0, עובר שני `++` ושני `--`. אם לא היו תנאי מרוץ, הערך הסופי היה 0. אולם, קריאת ה-`sem_post` הנוספת של `T0` יכולה לשבור את ההדדיות.\n\n1.  **מקרה אפשרי: `shared_data` שווה 0 (ללא תנאי מרוץ קריטי על `shared_data`):**\n    אם ה-`sem_post` הנוסף של `T0` מתרחש אחרי ש`T1` כבר ביצע את שני הבלוקים המוגנים שלו, או אם סדר הריצה לא מאפשר כניסה בו זמנית של שני תהליכונים לבלוקים המוגנים על `shared_data`. לדוגמה:\n    *   `T0` מבצע `wait`, `++` (shared_data=1), `post`.\n    *   `T1` מבצע `wait`, `++` (shared_data=2), `post`.\n    *   `T0` מבצע `post` נוסף (mutex=2).\n    *   `T0` מבצע `wait`, `--` (shared_data=1), `post`.\n    *   `T1` מבצע `wait`, `--` (shared_data=0), `post`.\n    בסיום: `shared_data=0`.\n\n2.  **מקרה אפשרי: `shared_data` שווה 1 (עם תנאי מרוץ):**\n    זה קורה כאשר ה-`sem_post` הנוסף של `T0` גורם לערך של `mutex` לעלות ל-2, מה שמאפשר לשני תהליכונים להיכנס לבלוקים מוגנים בו-זמנית. נניח את סדר הפעולות הבא:\n    *   `T0`: `sem_wait` (mutex=0), `shared_data++` (shared_data=1), `sem_post` (mutex=1).\n    *   `T0`: `sem_post` (mutex=2). (כעת `shared_data=1`, `mutex=2`)\n    *   `T1`: `sem_wait` (mutex=1). (T1 נכנס לבלוק הראשון שלו)\n    *   `T0`: `sem_wait` (mutex=0). (T0 נכנס לבלוק השני שלו, בו-זמנית עם T1)\n    *   בנקודה זו, `shared_data=1`. `T1` עומד לבצע `shared_data++` ו-`T0` עומד לבצע `shared_data--`. זהו תנאי מרוץ קלאסי (read-modify-write).\n    *   **אם הכתיבה של `T1` (shared_data++) מתרחשת אחרי הכתיבה של `T0` (shared_data--):**\n        1.  `T1` קורא `shared_data` (1).\n        2.  `T0` קורא `shared_data` (1).\n        3.  `T0` כותב `shared_data=0`.\n        4.  `T1` כותב `shared_data=2`.\n        (בסיום תנאי המרוץ, `shared_data=2`)\n    *   `T1`: `sem_post` (mutex=1).\n    *   `T0`: `sem_post` (mutex=2).\n    *   `T1`: `sem_wait` (mutex=1), `shared_data--` (shared_data=1), `sem_post` (mutex=2).\n    בסיום: `shared_data=1`.\n\n3.  **מקרה אפשרי: `shared_data` שווה -1 (עם תנאי מרוץ):**\n    נמשיך מהנקודה שבה `shared_data=1`, `mutex=0` ושני התהליכונים בבלוקים המוגנים שלהם בו-זמנית.\n    *   **אם הכתיבה של `T0` (shared_data--) מתרחשת אחרי הכתיבה של `T1` (shared_data++):**\n        1.  `T1` קורא `shared_data` (1).\n        2.  `T0` קורא `shared_data` (1).\n        3.  `T1` כותב `shared_data=2`.\n        4.  `T0` כותב `shared_data=0`.\n        (בסיום תנאי המרוץ, `shared_data=0`)\n    *   `T1`: `sem_post` (mutex=1).\n    *   `T0`: `sem_post` (mutex=2).\n    *   `T1`: `sem_wait` (mutex=1), `shared_data--` (shared_data=-1), `sem_post` (mutex=2).\n    בסיום: `shared_data=-1`.\n\nלסיכום, עקב ה-`sem_post` הנוסף של תהליכון 0, הסמפור יכול לעלות לערך הגדול מ-1, מה שמבטל למעשה את ההדדיות ומאפשר לשני תהליכונים להיכנס לאזורים קריטיים בו-זמנית. הדבר מוביל לתנאי מרוץ על המשתנה `shared_data` שיכול להסתיים בערכים שונים. הערכים האפשריים הם 0, 1 או -1. מכיוון שאף אחת מהאפשרויות א-ד לא מכסה את כל המקרים האפשריים, תשובה ה' היא הנכונה."}, "difficulty_estimation": "Hard", "_source_file": "0307__Semaphores__MultipleChoice__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:41:05", "_subject": "Concurrency"}, {"id": 10, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization", "Mutual Exclusion", "Race Conditions"], "content": {"text": "נתון קטע קוד בשפת C המשתמש בסמפור (semaphore) מסוג `sem_t` כדי להגן על אזור קריטי (critical section). מטרת הקוד היא להבטיח הדדיות (mutual exclusion) על המשתנה `shared_data`. הסמפור מאותחל בערך התחלתי של 2. איזו טענה מהבאות נכונה בנוגע להתנהגות הקוד?", "code_snippet": "#include <semaphore.h>\n#include <pthread.h>\n#include <stdio.h>\n\nsem_t mutex;\nint shared_data = 0;\n\nvoid* worker(void* arg) {\n    // Simulate some work\n    // ...\n    sem_wait(&mutex); // P operation\n    \n    // Critical Section\n    shared_data++;\n    printf(\"Thread %ld: shared_data = %d\\n\", (long)pthread_self(), shared_data);\n    \n    sem_post(&mutex); // V operation\n    // Simulate more work\n    // ...\n    return NULL;\n}\n\nint main() {\n    // Initialization of the semaphore\n    sem_init(&mutex, 0, 2); // !!! The subtle point is here !!!\n    \n    // Create multiple threads\n    pthread_t t1, t2, t3;\n    pthread_create(&t1, NULL, worker, NULL);\n    pthread_create(&t2, NULL, worker, NULL);\n    pthread_create(&t3, NULL, worker, NULL);\n    \n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    pthread_join(t3, NULL);\n    \n    sem_destroy(&mutex);\n    printf(\"Final shared_data: %d\\n\", shared_data);\n    return 0;\n}", "options": ["א. המנגנון יעבוד כשורה ויבטיח הדדיות (mutual exclusion).", "ב. המנגנון יוביל למצב של קיפאון (deadlock).", "ג. המנגנון יאפשר כניסה בו-זמנית של עד שני תהליכים לאזור הקריטי, ובכך יפר את הדדיות (mutual exclusion).", "ד. המנגנון יוביל להרעבה (starvation) של תהליכים."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "סמפור בינארי (או mutex) שמטרתו להבטיח הדדיות (mutual exclusion) חייב להיות מאותחל בערך 1. ערך זה מבטיח שרק תהליך אחד יוכל לבצע `sem_wait` בהצלחה ולהיכנס לאזור הקריטי בכל רגע נתון. כאשר הסמפור מאותחל בערך 2, המשמעות היא ששני תהליכים יכולים לבצע `sem_wait` בהצלחה ולהיכנס לאזור הקריטי בו-זמנית. הדבר מפר את עקרון ההדדיות ועלול להוביל לתנאי מרוץ (race condition) על המשתנה `shared_data` או כל משאב משותף אחר באזור הקריטי."}, "difficulty_estimation": "Hard", "_source_file": "0308__Semaphores__MultipleChoice__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:41:21", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization", "Concurrency", "Critical Section"], "content": {"text": "נתונים N תהליכים (threads) זהים, שכל אחד מהם מבצע את קטע הקוד הבא. במערכת קיימים שני סמפורים: `mutex` מאותחל ל-1, ו-`sync_point` מאותחל ל-0. בנוסף, קיים משתנה גלובלי `counter` המאותחל ל-0.\n\n```c\nvoid thread_func() {\n    // שלב 1\n    wait(mutex);\n    counter++;\n    if (counter == N) {\n        signal(sync_point);\n    }\n    signal(mutex);\n\n    // שלב 2\n    wait(sync_point);\n    // קטע קריטי לאחר מחסום (Critical Section after barrier)\n    // ...\n    signal(sync_point);\n}\n```\n\nבהנחה שכל N התהליכים מופעלים בו-זמנית ורצים עד לסיום. איזו מהטענות הבאות נכונה לגבי ההתנהגות של המערכת?", "code_snippet": "void thread_func() {\n    // שלב 1\n    wait(mutex);\n    counter++;\n    if (counter == N) {\n        signal(sync_point);\n    }\n    signal(mutex);\n\n    // שלב 2\n    wait(sync_point);\n    // קטע קריטי לאחר מחסום (Critical Section after barrier)\n    // ...\n    signal(sync_point);\n}", "options": ["א. רק תהליך אחד יצליח לעבור את הקריאה ל-`wait(sync_point)` ושאר התהליכים ייתקעו לנצח.", "ב. כל N התהליכים יצליחו לעבור את הקריאה ל-`wait(sync_point)` ויבצעו את \"הקטע הקריטי לאחר המחסום\" באופן סדרתי (אחד אחרי השני).", "ג. כל N התהליכים יצליחו לעבור את הקריאה ל-`wait(sync_point)` ויבצעו את \"הקטע הקריטי לאחר המחסום\" באופן מקבילי (בו-זמנית).", "ד. קיימת סכנת קיפאון (deadlock) שבה אף תהליך לא יצליח לעבור את הקריאה ל-`wait(sync_point)`.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הסבר:\n1.  **שלב 1 (הכנת המחסום):** כל N התהליכים מתחרים על גישה ל-`mutex` כדי להגדיל את המונה `counter`. המונה `counter` מוגן על ידי `mutex` ומבטיח שכל תהליך יגדיל אותו פעם אחת בדיוק.\n2.  **שחרור המחסום הראשוני:** התהליך ה-N שמגדיל את `counter` יגרום לתנאי `if (counter == N)` להיות אמיתי. תהליך זה יבצע קריאה ל-`signal(sync_point)`, מה שיגדיל את ערך `sync_point` ל-1 (מ-0). כל שאר התהליכים יבצעו `signal(mutex)` וישחררו אותו.\n3.  **שלב 2 (מעבר המחסום):** לאחר מכן, כל N התהליכים מגיעים לקריאה `wait(sync_point)`.\n    *   **התהליך הראשון:** התהליך הראשון שיגיע ל-`wait(sync_point)` וימצא את `sync_point` בערך 1 (שסומן על ידי התהליך ה-N) יצליח לעבור. ערך `sync_point` יירד ל-0. תהליך זה ייכנס ל\"קטע קריטי לאחר מחסום\".\n    *   **התהליכים הנותרים:** כל N-1 התהליכים האחרים יגיעו ל-`wait(sync_point)` וימצאו שערכו 0, ולכן ייתקעו בהמתנה.\n4.  **שחרור סדרתי:** התהליך היחיד שנמצא ב\"קטע קריטי לאחר מחסום\" יסיים את עבודתו ויבצע `signal(sync_point)`. קריאה זו תגדיל את ערך `sync_point` בחזרה ל-1, ותשחרר אחד מהתהליכים הממתינים. תהליך זה ישחרר שוב את `sync_point`, וכך הלאה.\n5.  **מסקנה:** כתוצאה מכך, כל N התהליכים אכן יעברו את המחסום `wait(sync_point)`, אך לא בו-זמנית. הם יעברו אחד אחרי השני, בסדרתיות, מכיוון שכל `signal(sync_point)` מאפשר רק לתהליך אחד נוסף לעבור. זהו אינו מחסום אמיתי (barrier) שמשחרר את כל התהליכים בבת אחת, אלא יותר מנגנון \"טורניקט\" או \"שער\" שמאפשר מעבר סדרתי לאחר שהאירוע הראשוני (כל התהליכים הגיעו לנקודה מסוימת) התרחש. לכן, טענה ב' נכונה."}, "difficulty_estimation": "Hard", "_source_file": "0309__Semaphores__MultipleChoice__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:41:46", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Semaphores", "Concurrency", "Barrier Synchronization", "Deadlock"], "content": {"text": "נתון קטע קוד בשפת C המממש מחסום (barrier) עבור N תהליכים באמצעות סמפורים. המחסום מיועד לשימוש חוזר (reusable). מהי התוצאה הסבירה ביותר כאשר קוד זה מופעל מספר פעמים על ידי אותם N תהליכים?", "code_snippet": "#include <pthread.h>\n#include <semaphore.h>\n#include <stdio.h>\n\n#define N 5 // מספר התהליכים במחסום\n\nsem_t barrier_sem;\npthread_mutex_t count_mutex; // מנעול להגנה על המונה\nint count = 0;\n\n// יש לאתחל את הסמפורים ואת המוטקס לפני השימוש:\n// sem_init(&barrier_sem, 0, 0); // סמפור המחסום מאותחל ל-0\n// pthread_mutex_init(&count_mutex, NULL); // מוטקס מאותחל ל-1\n\nvoid barrier_wait() {\n    pthread_mutex_lock(&count_mutex); // תפוס מנעול\n    count++;\n    if (count == N) {\n        // התהליך האחרון הגיע\n        for (int i = 0; i < N; ++i) {\n            sem_post(&barrier_sem); // שחרר את כל התהליכים\n        }\n    }\n    pthread_mutex_unlock(&count_mutex); // שחרר מנעול\n\n    sem_wait(&barrier_sem); // המתן לשחרור\n}", "options": ["א. התהליכים יסתנכרנו בהצלחה בכל פעם, אך עלולה להיות בעיית רעב (starvation) לחלק מהם.", "ב. התהליכים יסתנכרנו בהצלחה בפעם הראשונה, אך בשימושים חוזרים חלק מהם ימתינו ללא סוף (deadlock).", "ג. התהליכים יסתנכרנו בהצלחה בפעם הראשונה, אך בשימושים חוזרים חלק מהם יעברו את המחסום מוקדם מדי (race condition).", "ד. הקוד יגרום לקיפאון (deadlock) כבר בניסיון הראשון, מכיוון שהתהליך האחרון אינו ממתין על הסמפור."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "תשובה ב' נכונה. בפעם הראשונה, המחסום יפעל כצפוי: כל N התהליכים יגיעו, המונה `count` יגיע ל-N, התהליך האחרון ישלח N אותות (`sem_post`) לסמפור `barrier_sem`, וכל N התהליכים ימתינו (`sem_wait`) ויעברו את המחסום.\nאולם, הקוד אינו מאפס את המונה `count` לאחר שכל התהליכים עברו את המחסום. לכן, בשימוש חוזר (במחזור השני), כאשר התהליכים יקראו שוב ל-`barrier_wait()`, המונה `count` ימשיך לעלות מעבר ל-N. התנאי `if (count == N)` לעולם לא יתקיים שוב לאחר הפעם הראשונה, ולכן אף תהליך לא ישלח אותות ל-`barrier_sem`. כתוצאה מכך, כל התהליכים ימתינו ללא סוף ב-`sem_wait(&barrier_sem)` מבלי לקבל אותות, מה שיוביל לקיפאון (deadlock)."}, "difficulty_estimation": "Hard", "_source_file": "0310__Semaphores__MultipleChoice__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:42:08", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization", "Concurrency"], "content": {"text": "נתונים שני תהליכונים (threads) וסמפור בינארי S המאותחל ל-0.\nלהלן הקוד של כל תהליכון:\n\n```c\n// גלובלי\nSemaphore S = 0; // בינארי\n\n// קוד תהליכון 1 (T1)\nvoid *thread1_func(void *arg) {\n    wait(S);\n    printf(\"A\\n\");\n    return NULL;\n}\n\n// קוד תהליכון 2 (T2)\nvoid *thread2_func(void *arg) {\n    printf(\"B\\n\");\n    signal(S);\n    return NULL;\n}\n```\n\nאיזו מהטענות הבאות נכונה **תמיד** לגבי פלט התוכנית?", "code_snippet": null, "options": ["א. הפלט \"A\" יודפס תמיד לפני הפלט \"B\".", "ב. הפלט \"B\" יודפס תמיד לפני הפלט \"A\".", "ג. התוכנית עלולה להיכנס למצב קיפאון (deadlock).", "ד. ייתכן שהפלט \"A\" יודפס לפני הפלט \"B\".", "ה. גם ב' וגם ג' נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הסמפור S מאותחל ל-0. תהליכון T1 מבצע wait(S) ראשון. מכיוון ש-S הוא 0, T1 ייחסם וימתין. תהליכון T2 יבצע printf(\"B\\n\") ולאחר מכן signal(S). פעולת ה-signal(S) תגרום ל-S לעלות ל-1 (או תבטל חסימה של תהליכון שהיה חסום על S). רק לאחר ש-T2 ביצע signal(S), תהליכון T1 יוכל להמשיך את פעולתו, כלומר רק לאחר ש-T2 הדפיס 'B'. לכן, הפלט 'B' יודפס תמיד לפני הפלט 'A'. אין מצב קיפאון מכיוון ש-T2 תמיד יבצע signal(S) ויאפשר ל-T1 להמשיך, גם אם T1 נחסם קודם לכן."}, "difficulty_estimation": "Hard", "_source_file": "0311__Semaphores__MultipleChoice__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:42:31", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Semaphores", "Synchronization", "Deadlock", "Bounded Buffer"], "content": {"text": "נתונה מערכת המשתמשת במאגר חלופי (bounded buffer) בגודל N, ותהליכי יצרן (producer) וצרכן (consumer). לצורך סנכרון וגישה הדדית למאגר, נעשה שימוש בשלושה סמפורים:\n1.  `mutex`: סמפור בינארי, מאותחל ל-1, לגישה הדדית (mutual exclusion) למאגר.\n2.  `empty`: סמפור סופר, מאותחל ל-N, המייצג את מספר המקומות הפנויים במאגר.\n3.  `full`: סמפור סופר, מאותחל ל-0, המייצג את מספר המקומות המלאים במאגר.\n\nקוד היצרן (producer) נראה כך:\n```c\nvoid producer() {\n    while (true) {\n        // produce item\n        wait(mutex);\n        wait(empty);\n        // add item to buffer\n        signal(full);\n        signal(mutex);\n    }\n}\n```\nוקוד הצרכן (consumer) נראה כך:\n```c\nvoid consumer() {\n    while (true) {\n        wait(full);\n        wait(mutex);\n        // remove item from buffer\n        signal(mutex);\n        signal(empty);\n        // consume item\n    }\n}\n```\nאיזו מהטענות הבאות נכונה לגבי התנהגות המערכת במצב זה?", "code_snippet": null, "options": ["א. המערכת תפעל באופן תקין וללא בעיות סנכרון או קיפאון כלשהן.", "ב. המערכת עלולה להיכנס למצב קיפאון (deadlock) אם המאגר יתמלא לחלוטין.", "ג. המערכת עלולה להיכנס למצב קיפאון (deadlock) אם המאגר יתרוקן לחלוטין.", "ד. המערכת תאפשר גישה בו-זמנית למאגר (race condition) ובכך תפגע בשלמות הנתונים.", "ה. המערכת תמיד תעבוד, אך תהיה לא יעילה בשל סדר הפעולות השגוי בקוד היצרן."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. סדר הפעולות בקוד היצרן שגוי. אם המאגר יתמלא לחלוטין, סמפור `empty` יהיה שווה ל-0. תהליך יצרן שיגיע בשלב זה יבצע `wait(mutex)`, יתפוס את המנעול, ולאחר מכן יבצע `wait(empty)`. מכיוון ש-`empty` הוא 0, היצרן יחסם (block) תוך כדי שהוא מחזיק את ה-`mutex`. כעת, אף תהליך צרכן לא יוכל לגשת למאגר כדי להסיר פריט (ולבצע `signal(empty)`), מכיוון שה-`mutex` תפוס על ידי היצרן החסום. מצב זה יוביל לקיפאון (deadlock). סדר הפעולות הנכון ליצרן הוא: `wait(empty); wait(mutex); // add item; signal(mutex); signal(full);`."}, "difficulty_estimation": "Hard", "_source_file": "0312__Semaphores__MultipleChoice__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:42:46", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Semaphores", "Synchronization", "Concurrency"], "content": {"text": "מהו סמפור (Semaphore) וכיצד הוא משמש לפתרון בעיות סנכרון במערכות הפעלה? הסבירו את שתי הפעולות העיקריות שלו (P/wait ו-V/signal) ותנו דוגמה קצרה לשימוש בסמפור להשגת הדדיות בלעדית (Mutual Exclusion) בקטע קריטי (Critical Section).", "code_snippet": "/* Conceptual C/C++ code demonstrating semaphore usage for mutual exclusion */\n\n// הגדרת סמפור בינארי, מאותחל ל-1\n// (בהתאם לספרייה או מימוש, זה עשוי להיות sem_t mutex; sem_init(&mutex, 0, 1);)\nSemaphore mutex = 1; \n\nvoid critical_section_access() {\n    wait(mutex); // פעולת P: הקטנת הסמפור, המתנה אם ערכו 0\n    \n    // תחילת הקטע הקריטי\n    // קוד שניגש למשאב משותף (לדוגמה: עדכון משתנה גלובלי)\n    // ...\n    // סוף הקטע הקריטי\n    \n    signal(mutex); // פעולת V: הגדלת הסמפור, שחרור תהליכים ממתינים\n}\n\n// בתוכנית מרובת תרדדים, כל תרד יקרא ל-critical_section_access()\n// ויוודא גישה בלעדית למשאב המשותף.", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "סמפור (Semaphore) הוא משתנה שלם (integer variable) המוגן מפני גישה בו-זמנית, ומשמש ככלי סנכרון בסיסי במערכות הפעלה לפתרון בעיות של תחרות (race conditions) והדדיות בלעדית (mutual exclusion) בין תהליכים או תרדדים. הוא מאפשר לשלוט בגישה למשאבים משותפים או לתאם את סדר הפעולות.\n\nשתי הפעולות העיקריות שלו הן:\n1.  **P (או `wait()`)**: פעולה זו מנסה להקטין את ערך הסמפור באחד. אם ערך הסמפור הנוכחי הוא 0, התהליך הקורא לפעולה נחסם וממתין בתור עד שערך הסמפור יהפוך לחיובי (או גדול מ-0) ויתאפשר להקטין אותו. אם ערך הסמפור גדול מ-0, הוא מוקטן מיד והתהליך ממשיך. פעולה זו מבטיחה שרק מספר מוגבל של תהליכים (לפי ערך הסמפור ההתחלתי) יוכלו להמשיך.\n2.  **V (או `signal()`)**: פעולה זו מגדילה את ערך הסמפור באחד. אם ישנם תהליכים החסומים וממתינים על הסמפור (כתוצאה מפעולת P קודמת), אחד מהם ישוחרר ויוכל להמשיך בביצוע (כלומר, לבצע את פעולת ה-P שחסמה אותו).\n\n**דוגמה לשימוש בסמפור להשגת הדדיות בלעדית (Mutual Exclusion) בקטע קריטי:**\nכדי להבטיח שרק תהליך אחד ייכנס לקטע קריטי (חלק בקוד הניגש למשאב משותף) בכל רגע נתון, ניתן להשתמש בסמפור בינארי (סמפור שערכו יכול להיות רק 0 או 1).\n*   מאתחלים סמפור בשם `mutex` (קיצור של mutual exclusion) לערך 1.\n*   לפני הכניסה לקטע הקריטי, כל תהליך מבצע פעולת `wait(mutex)`.\n    *   התהליך הראשון שיבצע `wait(mutex)` יקטין את ערך `mutex` ל-0 וימשיך לקטע הקריטי.\n    *   כל תהליך נוסף שינסה להיכנס לקטע הקריטי (כלומר, יבצע `wait(mutex)`) ימצא את `mutex` בערך 0, ולכן ייחסם וימתין.\n*   לאחר סיום הקטע הקריטי, התהליך שביצע אותו מבצע פעולת `signal(mutex)`.\n    *   פעולה זו מגדילה את ערך `mutex` בחזרה ל-1, ואם ישנם תהליכים ממתינים, אחד מהם ישוחרר ויורשה להיכנס לקטע הקריטי.\n\n**דוגמת קוד:** (כפי שהוצג בשאלה)"}, "difficulty_estimation": "Easy", "_source_file": "0313__Semaphores__Open__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:43:03", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Semaphores", "Concurrency", "Synchronization", "Mutual Exclusion"], "content": {"text": "מהו סמפור? הסבירו את שתי הפעולות העיקריות שלו (P/wait ו-V/signal). כיצד ניתן להשתמש בסמפור להשגת הדדית (mutual exclusion) עבור קטע קריטי?", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "סמפור הוא כלי סנכרון המהווה משתנה שלם, אשר מלבד אתחול, ניתן לגשת אליו רק באמצעות שתי פעולות אטומיות סטנדרטיות: wait() ו-signal().\n\n**פעולות הסמפור:**\n*   **wait() (או P):** פעולה זו מקטינה את ערך הסמפור. אם ערך הסמפור הופך שלילי, התהליך המבצע את הפעולה נחסם (מוכנס לרשימת המתנה) עד שערך הסמפור יהפוך לחיובי (כלומר, משאב יהיה זמין).\n*   **signal() (או V):** פעולה זו מגדילה את ערך הסמפור. אם ישנם תהליכים חסומים הממתינים על סמפור זה, אחד מהם משוחרר (מתעורר) ומוכן לביצוע.\n\n**שימוש בסמפור להשגת הדדית (Mutual Exclusion) עבור קטע קריטי:**\nכדי להבטיח שרק תהליך אחד ייכנס לקטע קריטי בכל רגע נתון, ניתן להשתמש בסמפור בינארי (הנקרא לעיתים קרובות mutex). הנה השלבים:\n1.  **אתחול:** יוצרים סמפור בינארי ומאתחלים את ערכו ל-1. (לדוגמה: `semaphore mutex = 1;`)\n2.  **לפני הכניסה לקטע הקריטי:** כל תהליך שרוצה להיכנס לקטע הקריטי מבצע את פעולת `wait()` על הסמפור. לדוגמה: `wait(mutex);`\n    *   אם `mutex` הוא 1, הוא הופך ל-0 והתהליך נכנס לקטע הקריטי.\n    *   אם `mutex` הוא 0, התהליך נחסם וממתין עד ש-`mutex` יהפוך שוב ל-1.\n3.  **לאחר היציאה מהקטע הקריטי:** כל תהליך שיוצא מהקטע הקריטי מבצע את פעולת `signal()` על הסמפור. לדוגמה: `signal(mutex);`\n    *   פעולה זו מגדילה את ערך `mutex` ל-1, ובכך מאפשרת לתהליך אחר (אם יש כזה ממתין) להיכנס לקטע הקריטי.\n\nבצורה זו, הסמפור מבטיח שרק תהליך אחד יוכל לעבור את ה-`wait(mutex)` ולהיכנס לקטע הקריטי, וכל שאר התהליכים ימתינו מחוץ לו."}, "difficulty_estimation": "Easy", "_source_file": "0314__Semaphores__Open__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:43:14", "_subject": "Concurrency"}, {"id": 7, "type": "Open", "topic": ["Semaphores", "Concurrency", "Synchronization"], "content": {"text": "הסבירו מהו סמפור (Semaphore) וכיצד הוא משמש לסנכרון בין תהליכים (או ת'רדים). פרטו את פעולות הבסיס שלו (`wait`/`P` ו-`signal`/`V`) והדגימו שימוש פשוט בסמפור בינארי (mutex) כדי להגן על קטע קריטי (critical section).", "code_snippet": "/* C/C++ style pseudocode using POSIX semaphores */\n#include <semaphore.h>\n#include <stdio.h>\n\nsem_t mutex; // A binary semaphore (mutex)\n\n// Initialize the semaphore\nvoid init_semaphore() {\n    // sem_init(semaphore, pshared, value)\n    // pshared = 0 for threads in the same process\n    // value = 1 for a binary semaphore (mutex) initially unlocked\n    sem_init(&mutex, 0, 1);\n}\n\n// Function demonstrating critical section protection\nvoid access_critical_section() {\n    // P operation: acquire the lock\n    sem_wait(&mutex);\n\n    // Critical section: code that accesses shared resources\n    printf(\"Thread/Process entered critical section.\\n\");\n    // ... perform operations on shared data ...\n    printf(\"Thread/Process exiting critical section.\\n\");\n\n    // V operation: release the lock\n    sem_post(&mutex);\n}\n\n// Example of how it might be used\nint main() {\n    init_semaphore();\n    // Multiple threads/processes could call access_critical_section()\n    access_critical_section();\n    // ... other calls ...\n    sem_destroy(&mutex); // Clean up the semaphore\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "סמפור הוא כלי סנכרון המאפשר לתהליכים (או ת'רדים) לשתף משאבים מוגבלים או לתאם את פעולותיהם. הוא מורכב ממשתנה שלם (integer variable) שניתן לגשת אליו רק באמצעות שתי פעולות אטומיות (שאינן ניתנות להפרעה): `wait` (הידועה גם כ-`P` או `down`) ו-`signal` (הידועה גם כ-`V` או `up`).\n\n**פעולות הבסיס:**\n1.  **`wait` (או `P`)**: פעולה זו מורידה את ערך הסמפור באחד. אם ערך הסמפור הופך שלילי, התהליך הקורא לפעולה נחסם ונכנס לתור המתנה של הסמפור, עד שיוכל להמשיך. פעולה זו משמשת בדרך כלל לפני כניסה לקטע קריטי או לפני גישה למשאב.\n2.  **`signal` (או `V`)**: פעולה זו מעלה את ערך הסמפור באחד. אם ערך הסמפור קטן או שווה לאפס (מה שמעיד על כך שיש תהליכים חסומים בתור), אחד מהתהליכים החסומים משוחרר ומועבר למצב מוכן (ready). פעולה זו משמשת בדרך כלל לאחר יציאה מקטע קריטי או לאחר שחרור משאב.\n\n**סמפור בינארי (Mutex) והגנה על קטע קריטי:**\nסמפור בינארי הוא סמפור שערכו יכול להיות רק 0 או 1. הוא משמש במיוחד להשגת הדדיות בלעדית (mutual exclusion) בקטעים קריטיים, כלומר להבטיח שרק תהליך אחד יבצע את הקטע הקריטי בכל רגע נתון.\nכדי להגן על קטע קריטי באמצעות סמפור בינארי, יש לאתחל את הסמפור לערך 1. לפני הכניסה לקטע הקריטי, כל תהליך מבצע פעולת `wait` על הסמפור. אם הסמפור הוא 1, הוא הופך ל-0 והתהליך נכנס. אם הסמפור כבר 0 (כי תהליך אחר נמצא בקטע הקריטי), התהליך נחסם. לאחר היציאה מהקטע הקריטי, התהליך מבצע פעולת `signal` על הסמפור, מה שמחזיר את ערכו ל-1 ומשחרר תהליך חסום (אם יש כזה).\n\n**הדגמה בקוד:**\nהקוד המצורף מדגים שימוש בסמפור בינארי (mutex) כדי להגן על קטע קריטי. הסמפור `mutex` מאותחל ל-1. הפונקציה `sem_wait(&mutex)` מנסה לרכוש את המנעול (להיכנס לקטע הקריטי). אם המנעול פנוי (ערך הסמפור 1), הוא הופך ל-0 והתהליך ממשיך. אם המנעול תפוס (ערך הסמפור 0), התהליך נחסם. לאחר סיום העבודה בקטע הקריטי, הפונקציה `sem_post(&mutex)` משחררת את המנעול (מעלה את ערך הסמפור ל-1), ובכך מאפשרת לתהליך אחר להיכנס לקטע הקריטי."}, "difficulty_estimation": "Easy", "_source_file": "0315__Semaphores__Open__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:43:28", "_subject": "Concurrency"}, {"id": 7, "type": "Open", "topic": ["Semaphores", "Concurrency", "Synchronization"], "content": {"text": "מהו סמפור (Semaphore) במערכת הפעלה? הסבר את מטרתו, את שתי הפעולות הבסיסיות שלו (wait/P ו-signal/V), ותאר בקצרה כיצד ניתן להשתמש בו למימוש הדדיות (Mutual Exclusion) ולסנכרון בין תהליכים.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "סמפור הוא משתנה שלם (integer variable) המאפשר שליטה על גישה למשאבים משותפים בין תהליכים מקבילים. הוא משמש לפתרון בעיות סנכרון ותיאום במערכות הפעלה.\n\nהפעולות הבסיסיות של סמפור הן:\n1.  **wait (נקרא גם P או down)**: פעולה זו מקטינה את ערך הסמפור באחד. אם ערך הסמפור הופך שלילי, התהליך המבצע את הפעולה נחסם (מוכנס לרשימת המתנה) עד שסמפור יגדל. פעולה זו היא אטומית.\n2.  **signal (נקרא גם V או up)**: פעולה זו מגדילה את ערך הסמפור באחד. אם יש תהליכים חסומים ברשימת ההמתנה של הסמפור, אחד מהם משוחרר (מועבר למצב מוכן). פעולה זו היא אטומית.\n\nשימושים עיקריים:\n*   **הדדיות (Mutual Exclusion)**: כדי להבטיח שרק תהליך אחד ייכנס לקטע קריטי (critical section) בכל רגע נתון, ניתן להשתמש בסמפור בינארי (מוטקס - mutex) המאותחל ל-1. לפני הכניסה לקטע הקריטי, תהליך יבצע `wait()` על הסמפור. לאחר היציאה מהקטע הקריטי, הוא יבצע `signal()` על הסמפור.\n    ```c\n    semaphore mutex = 1;\n\n    void process() {\n        // ...\n        wait(mutex); // Enter critical section\n        // Critical Section Code\n        signal(mutex); // Exit critical section\n        // ...\n    }\n    ```\n*   **סנכרון (Synchronization)**: סמפורים יכולים לשמש לסנכרון אירועים בין תהליכים. לדוגמה, תהליך א' יכול לאותת לתהליך ב' שאירוע מסוים התרחש. סמפור ספירה (counting semaphore) יכול לאותחל ל-0. תהליך א' יבצע `signal()` כשהאירוע מתרחש, ותהליך ב' יבצע `wait()` לפני שהוא ממשיך, ובכך יבטיח שהאירוע התרחש.\n    ```c\n    semaphore event_occurred = 0; // Initialize to 0\n\n    // Process A\n    void producer() {\n        // ... produce item\n        signal(event_occurred); // Signal that item is ready\n        // ...\n    }\n\n    // Process B\n    void consumer() {\n        // ...\n        wait(event_occurred); // Wait for item to be ready\n        // ... consume item\n    }\n    ```"}, "difficulty_estimation": "Easy", "_source_file": "0316__Semaphores__Open__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:43:39", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Semaphores", "Concurrency", "Mutual Exclusion"], "content": {"text": "הסבירו כיצד ניתן להשתמש בסמפור בינארי (binary semaphore) כדי להבטיח מניעה הדדית (mutual exclusion) עבור קטע קריטי (critical section) בין מספר תהליכונים (threads) המנסים לגשת אליו. תארו את הפעולות הנדרשות ואת הערך ההתחלתי של הסמפור.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "סמפור בינארי הוא סמפור שיכול לקבל רק את הערכים 0 או 1. הוא משמש בדרך כלל למניעה הדדית (mutual exclusion), כלומר להבטיח שרק תהליכון אחד (או תהליך) יוכל לגשת למשאב משותף או להיכנס לקטע קריטי בנקודת זמן נתונה.\n\nכדי להבטיח מניעה הדדית לקטע קריטי באמצעות סמפור בינארי, נבצע את השלבים הבאים:\n1.  **אתחול הסמפור**: ניצור סמפור בינארי אחד ונאתחל אותו לערך 1. ערך זה מציין שהקטע הקריטי פנוי וזמין לכניסה.\n2.  **כניסה לקטע הקריטי**: לפני הכניסה לקטע הקריטי, כל תהליכון המעוניין לגשת אליו יבצע את פעולת ה-`wait()` (או `P()`) על הסמפור. פעולה זו בודקת את ערך הסמפור:\n    *   אם ערך הסמפור הוא 1, הוא מוקטן ל-0, והתהליכון רשאי להיכנס לקטע הקריטי.\n    *   אם ערך הסמפור הוא 0, זה אומר שהקטע הקריטי תפוס על ידי תהליכון אחר. במקרה זה, התהליכון המנסה להיכנס נחסם (מוכנס לתור המתנה) עד שערך הסמפור יחזור ל-1.\n3.  **יציאה מהקטע הקריטי**: לאחר שהתהליכון סיים את עבודתו בתוך הקטע הקריטי, הוא יבצע את פעולת ה-`signal()` (או `V()`) על הסמפור. פעולה זו מגדילה את ערך הסמפור ב-1 (מחזירה אותו ל-1). אם היו תהליכונים חסומים הממתינים על הסמפור, אחד מהם ישוחרר (יועבר למצב 'מוכן') ויוכל לנסות להיכנס לקטע הקריטי.\n\n**דוגמה קוד (C/C++):**\n```c\nsemaphore mutex = 1; // אתחול הסמפור הבינארי ל-1\n\nvoid worker_thread() {\n    // ... עבודה אחרת שהתהליכון מבצע ...\n\n    wait(mutex); // נסה להיכנס לקטע הקריטי (P(mutex))\n\n    // ===================================\n    // קטע קריטי: גישה למשאב משותף\n    // רק תהליכון אחד יכול להיות כאן בו-זמנית\n    // ===================================\n\n    signal(mutex); // צא מהקטע הקריטי (V(mutex))\n\n    // ... עבודה אחרת שהתהליכון מבצע ...\n}\n```\nבצורה זו, הסמפור `mutex` משמש כמנעול. כאשר ערכו 1, המנעול פתוח. כאשר תהליכון נכנס, הוא 'נועל' את המנעול (מציב את הערך 0). תהליכונים אחרים שמגיעים למנעול 'נעול' נחסמים. כאשר התהליכון היוצא 'פותח' את המנעול (מציב את הערך 1), תהליכון חסום אחד יכול להיכנס."}, "difficulty_estimation": "Easy", "_source_file": "0317__Semaphores__Open__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:43:52", "_subject": "Concurrency"}, {"id": 7, "type": "Open", "topic": ["Semaphores", "Concurrency", "Synchronization"], "content": {"text": "הסבירו מהו סמפור (Semaphore) וכיצד הוא משמש לפתרון בעיות סנכרון במערכות הפעלה. תארו את הפעולות הבסיסיות שלו.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "סמפור (Semaphore) הוא משתנה שלם המשמש לפתרון בעיות סנכרון בין תהליכים (או תהליכונים) במערכת הפעלה. הוא מאפשר לתאם גישה למשאבים משותפים ולשלוט על סדר הפעולות. הגישה לסמפור מתבצעת אך ורק באמצעות שתי פעולות אטומיות (בלתי ניתנות להפרעה):\n\n-   **wait() / P()**: פעולה זו מקטינה את ערך הסמפור באחד. אם ערך הסמפור הופך שלילי (או אפס, תלוי במימוש), התהליך המבצע את הפעולה נחסם ומחכה עד שערך הסמפור יהפוך חיובי (כלומר, המשאב יהיה זמין שוב).\n-   **signal() / V()**: פעולה זו מגדילה את ערך הסמפור באחד. אם ישנם תהליכים חסומים הממתינים על הסמפור, אחד מהם משוחרר (מתעורר) וממשיך בביצוע.\n\n**שימושים עיקריים:**\n1.  **הדדיות (Mutual Exclusion)**: סמפור בינארי (שמכונה לעיתים קרובות מוטקס - Mutex) מאותחל ל-1. תהליך מבצע `wait()` לפני כניסה לקטע קריטי (Critical Section) ומבצע `signal()` ביציאה ממנו. זה מבטיח שרק תהליך אחד ייכנס לקטע הקריטי בכל רגע נתון, ובכך מונע מצבי מרוץ (Race Conditions).\n2.  **סנכרון כללי / סדר פעולות**: סמפור ספירה (Counting Semaphore) מאותחל ל-0 או לערך אחר. תהליך אחד מבצע `signal()` כאשר אירוע מסוים מתרחש או כאשר משאב זמין, ותהליך אחר מבצע `wait()` כדי להמתין לאירוע זה או לזמינות המשאב לפני שהוא ממשיך בביצוע. לדוגמה, סנכרון בין מפיק לצרכן."}, "difficulty_estimation": "Easy", "_source_file": "0318__Semaphores__Open__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:44:04", "_subject": "Concurrency"}, {"id": 7, "type": "Open", "topic": ["Semaphores", "Concurrency", "Synchronization"], "content": {"text": "מהו סמפור (Semaphore) ומה תפקידו במערכות הפעלה? הסבירו בקצרה את פעולת הפרימיטיבים P (wait) ו-V (signal).", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "סמפור (Semaphore) הוא כלי סנכרון (Synchronization Tool) המשמש לפתרון בעיות קטע קריטי (Critical Section) ובעיות סנכרון נוספות במערכות הפעלה. הוא משתנה שלם שניתן לגשת אליו (למעט אתחול) רק באמצעות שתי פעולות אטומיות סטנדרטיות: P (wait) ו-V (signal).\n\n**תפקיד הסמפור:**\n*   **הגנה על קטעים קריטיים:** למנוע ממספר תהליכים לגשת בו-זמנית למשאב משותף או לקטע קוד שאינו ניתן לביצוע מקביל.\n*   **סנכרון תהליכים:** לאפשר לתהליכים לתאם את פעולותיהם, למשל, שתהליך אחד ימתין עד שתהליך אחר יסיים משימה מסוימת.\n\n**פעולת הפרימיטיבים:**\n\n*   **פעולת P (או wait):**\n    *   מקטינה את ערך הסמפור באחד.\n    *   אם ערך הסמפור הופך שלילי, התהליך שקרא ל-P נחסם (מוכנס לרשימת המתנה) עד שערך הסמפור יהפוך לא שלילי (כלומר, המשאב יהיה זמין).\n    *   מבטיחה שרק מספר מוגבל של תהליכים (או תהליך אחד עבור סמפור בינארי) יוכלו להיכנס לקטע קריטי או לגשת למשאב בו-זמנית.\n\n*   **פעולת V (או signal):**\n    *   מגדילה את ערך הסמפור באחד.\n    *   אם יש תהליכים חסומים על הסמפור הזה (כלומר, ערכו היה שלילי לפני ההגדלה), אחד מהם משוחרר (מועבר למצב מוכן לריצה).\n    *   מאותתת שתהליך סיים להשתמש במשאב או יצא מקטע קריטי, ובכך מאפשרת לתהליכים אחרים להמשיך."}, "difficulty_estimation": "Easy", "_source_file": "0319__Semaphores__Open__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:44:16", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Semaphores", "Concurrency", "Synchronization"], "content": {"text": "הסבירו מהו סמפור (Semaphore) במערכות הפעלה. תארו את שתי הפעולות העיקריות הקשורות לסמפור, וכיצד ניתן להשתמש בסמפור על מנת לממש מנגנון של Mutual Exclusion (הדדיות בלעדית) בין תהליכים.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "סמפור הוא משתנה שלם (integer variable) המשמש למנגנון סנכרון בין תהליכים (או תהליכונים) במערכת הפעלה. הוא מאפשר לשלוט בגישה למשאבים משותפים ולהבטיח תיאום בין פעולות קונקורנטיות. הגישה למשתנה הסמפור מתבצעת באופן אטומי (atomic), כלומר, הפעולות עליו אינן ניתנות להפרעה.\n\nשתי הפעולות העיקריות הקשורות לסמפור הן:\n1.  **wait()** (או P(), acquire()): פעולה זו מקטינה את ערך הסמפור באחד. אם ערך הסמפור הופך שלילי (או 0 במקרה של סמפור בינארי שכבר ב-0), התהליך הקורא לפעולה נחסם וממתין עד שערך הסמפור יגדל על ידי תהליך אחר. (לרוב, אם הערך הופך שלילי, זה מציין כמה תהליכים ממתינים).\n2.  **signal()** (או V(), release()): פעולה זו מגדילה את ערך הסמפור באחד. אם ישנם תהליכים חסומים הממתינים על סמפור זה, אחד מהם ישוחרר ויוכל להמשיך בביצוע.\n\n**שימוש בסמפור למימוש Mutual Exclusion:**\nכדי לממש Mutual Exclusion (הדדיות בלעדית) לאזור קריטי (Critical Section), נשתמש בסמפור בינארי (הנקרא לעיתים קרובות mutex) המאותחל לערך 1. כל תהליך המעוניין להיכנס לאזור הקריטי יבצע את הפעולות הבאות:\n\n1.  **לפני הכניסה לאזור הקריטי:** יקרא לפעולת `wait()` על הסמפור.\n    *   אם הסמפור היה 1, הוא יהפוך ל-0, והתהליך יורשה להיכנס לאזור הקריטי.\n    *   אם הסמפור היה 0 (כלומר, תהליך אחר כבר נמצא באזור הקריטי), התהליך הקורא ל-`wait()` יחסם וימתין.\n2.  **לאחר היציאה מהאזור הקריטי:** יקרא לפעולת `signal()` על הסמפור.\n    *   פעולה זו תגדיל את ערך הסמפור ל-1 (אם לא היו תהליכים ממתינים) או תשחרר תהליך חסום אחד (אם היו כאלה), שיורשה כעת להיכנס לאזור הקריטי.\n\nבדרך זו, רק תהליך אחד יכול להיכנס לאזור הקריטי בכל רגע נתון, מה שמבטיח Mutual Exclusion."}, "difficulty_estimation": "Easy", "_source_file": "0320__Semaphores__Open__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:44:33", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Synchronization", "Semaphores", "Producer-Consumer"], "content": {"text": "נתון מאגר (buffer) מעגלי בגודל N המשותף למספר תהליכי יצרן (Producers) ותהליכי צרכן (Consumers). תהליכי היצרן מוסיפים פריטים למאגר, ותהליכי הצרכן מוציאים פריטים מהמאגר. בנוסף, קיים תהליך לוגר (Logger) יחיד. תהליך הלוגר צריך לרשום ללוג אך ורק פריטים שכבר הוצאו מהמאגר על ידי תהליך צרכן. עליו להמתין אם אין פריטים שהוצאו וטרם נרשמו ללוג.\n\nיש לממש את הפעולות `produce_item`, `consume_item` ו-`log_item` באמצעות סמפורים (semaphores) ומנעולי הדדיות (mutexes) בלבד, כך שהסנכרון בין התהליכים יתבצע בצורה נכונה. יש להניח שפעולות הוספה/הוצאה למאגר ורישום ללוג (שאינן קשורות לסנכרון) כבר ממומשות ואינן דורשות קוד. ציינו גם את הגדרת המשתנים הגלובליים הנדרשים ואת אתחולם.", "code_snippet": "typedef int item_type; // Placeholder for actual item type\n\n#define N 10 // Buffer size\n\nitem_type buffer[N];\nint head = 0;\nint tail = 0;\n\n// Declare semaphores and mutex here\nsem_t empty_slots;\nsem_t full_slots;\nsem_t consumed_for_logging;\npthread_mutex_t buffer_mutex;\n\n// Function to initialize synchronization primitives\nvoid init_sync_primitives() {\n    sem_init(&empty_slots, 0, N);\n    sem_init(&full_slots, 0, 0);\n    sem_init(&consumed_for_logging, 0, 0);\n    pthread_mutex_init(&buffer_mutex, NULL);\n}\n\n// Function to destroy synchronization primitives (for completeness, not required by question)\nvoid destroy_sync_primitives() {\n    sem_destroy(&empty_slots);\n    sem_destroy(&full_slots);\n    sem_destroy(&consumed_for_logging);\n    pthread_mutex_destroy(&buffer_mutex);\n}\n\nvoid produce_item(item_type item_to_produce) {\n    // Implement producer logic here\n}\n\nitem_type consume_item() {\n    // Implement consumer logic here\n    return 0; // Placeholder return\n}\n\nvoid log_item() {\n    // Implement logger logic here\n}"}, "sub_questions": null, "points": 15, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "הפתרון הנכון כולל שימוש בשלושה סמפורים ובמנעול הדדי אחד:\n\n1.  `empty_slots`: סמפור זה סופר את מספר המקומות הפנויים במאגר. הוא מאותחל ל-N (גודל המאגר) ומנוהל על ידי היצרנים (מבצעים `sem_wait`) והצרכנים (מבצעים `sem_post`).\n2.  `full_slots`: סמפור זה סופר את מספר הפריטים המלאים במאגר. הוא מאותחל ל-0 ומנוהל על ידי היצרנים (מבצעים `sem_post`) והצרכנים (מבצעים `sem_wait`).\n3.  `consumed_for_logging`: סמפור זה סופר את מספר הפריטים שצרכנים הוציאו מהמאגר וטרם נרשמו ללוג. הוא מאותחל ל-0 ומנוהל על ידי הצרכנים (מבצעים `sem_post` לאחר הוצאת פריט) ועל ידי תהליך הלוגר (מבצע `sem_wait`).\n4.  `buffer_mutex`: מנעול הדדי זה משמש להגנה על הגישה למאגר המשותף (הכנסה/הוצאה של פריטים ועדכון מונים `head`, `tail`) כדי למנוע מצבי מירוץ.\n\nהקוד המלא עבור הפעולות הוא כדלקמן:\n\n```c\n#include <semaphore.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\ntypedef int item_type; // Placeholder for actual item type\n\n#define N 10 // Buffer size\n\nitem_type buffer[N];\nint head = 0; // Index for consumer\nint tail = 0; // Index for producer\n\n// Declare semaphores and mutex here\nsem_t empty_slots;\nsem_t full_slots;\nsem_t consumed_for_logging;\npthread_mutex_t buffer_mutex;\n\n// Function to initialize synchronization primitives\nvoid init_sync_primitives() {\n    sem_init(&empty_slots, 0, N); // N empty slots initially\n    sem_init(&full_slots, 0, 0); // 0 full slots initially\n    sem_init(&consumed_for_logging, 0, 0); // 0 consumed items for logging initially\n    pthread_mutex_init(&buffer_mutex, NULL);\n}\n\n// Function to destroy synchronization primitives (for completeness)\nvoid destroy_sync_primitives() {\n    sem_destroy(&empty_slots);\n    sem_destroy(&full_slots);\n    sem_destroy(&consumed_for_logging);\n    pthread_mutex_destroy(&buffer_mutex);\n}\n\nvoid produce_item(item_type item_to_produce) {\n    sem_wait(&empty_slots); // Wait for an empty slot\n\n    pthread_mutex_lock(&buffer_mutex); // Protect buffer access\n    buffer[tail] = item_to_produce;\n    tail = (tail + 1) % N;\n    pthread_mutex_unlock(&buffer_mutex);\n\n    sem_post(&full_slots); // Signal that a slot is full\n}\n\nitem_type consume_item() {\n    item_type consumed_item;\n\n    sem_wait(&full_slots); // Wait for a full slot\n\n    pthread_mutex_lock(&buffer_mutex); // Protect buffer access\n    consumed_item = buffer[head];\n    head = (head + 1) % N;\n    pthread_mutex_unlock(&buffer_mutex);\n\n    sem_post(&empty_slots); // Signal that a slot is empty\n    sem_post(&consumed_for_logging); // Signal that an item has been consumed and is ready for logging\n\n    return consumed_item; // Return the consumed item (conceptually)\n}\n\nvoid log_item() {\n    sem_wait(&consumed_for_logging); // Wait for an item to be consumed and ready for logging\n\n    // Conceptual logging operation (e.g., printf, write to file)\n    // For this problem, we just need to ensure the timing is correct.\n    // printf(\"Logger: An item was consumed and logged.\\n\");\n}\n```\n\n**הסבר:**\n\n*   **תהליך היצרן (`produce_item`):** לפני הוספת פריט, היצרן ממתין (באמצעות `sem_wait(&empty_slots)`) לוודא שיש מקום פנוי במאגר. לאחר מכן, הוא נועל את ה-`buffer_mutex` כדי לגשת למאגר בבטחה, מוסיף את הפריט, משחרר את המנעול, ומסמן (באמצעות `sem_post(&full_slots)`) שיש כעת פריט נוסף במאגר.\n\n*   **תהליך הצרכן (`consume_item`):** לפני הוצאת פריט, הצרכן ממתין (באמצעות `sem_wait(&full_slots)`) לוודא שיש פריט זמין במאגר. לאחר מכן, הוא נועל את ה-`buffer_mutex` כדי לגשת למאגר בבטחה, מוציא את הפריט, משחרר את המנעול, ומסמן (באמצעות `sem_post(&empty_slots)`) שמקום התפנה במאגר. הדבר החשוב כאן הוא שהצרכן גם מסמן (באמצעות `sem_post(&consumed_for_logging)`) פריט נוסף זמין לרישום ללוג, וזאת *לאחר* שהפריט יצא מהמאגר והמנעול שוחרר, כדי לאפשר ללוגר לפעול באופן בלתי תלוי בגישה למאגר.\n\n*   **תהליך הלוגר (`log_item`):** הלוגר ממתין (באמצעות `sem_wait(&consumed_for_logging)`) עד שפריט יוצא מהמאגר על ידי צרכן. רק כאשר יש פריט שהוצא וטרם נרשם, הסמפור מאפשר לו להמשיך ולבצע את פעולת הרישום ללוג. אין צורך במנעול הדדי בלוגר עצמו מכיוון שהוא התהליך היחיד שאמור לבצע את פעולת הרישום ללוג, ואין לו גישה ישירה למאגר המשותף."}, "difficulty_estimation": "Medium", "_source_file": "0321__Semaphores__Open__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:45:12", "_subject": "Concurrency"}, {"id": 101, "type": "Open", "topic": ["Synchronization", "Semaphores", "Concurrency"], "content": {"text": "במערכת הפעלה נתונה, מספר רב של תהליכים (P1, P2, ..., Pn) ניגשים למסד נתונים משותף. קיימות שתי מגבלות סנכרון עיקריות:\n1.  רק עד MAX_CONCURRENT_DB_ACCESS תהליכים יכולים לגשת למסד הנתונים בו-זמנית.\n2.  לפני כל גישה למסד הנתונים, כל תהליך חייב לעדכן מונה גלובלי active_db_queries המייצג את מספר התהליכים הפעילים במסד הנתונים כרגע. עדכון מונה זה (הגדלה או הקטנה) חייב להיות פעולה מוגנת הדדית (mutual exclusion).\nלאחר סיום הגישה למסד הנתונים, התהליך מקטין את המונה active_db_queries ומשחרר את הגישה למסד הנתונים.\n\nנתון קוד C/C++ חלקי עבור פונקציית תהליך (thread_function). עליכם להשלים את הקוד החסר באמצעות סמפורים (semaphores) בלבד, כך שיענה על כל דרישות הסנכרון. בנוסף, הסבירו במילים מדוע הפתרון שלכם נכון וכיצד כל סמפור תורם לסנכרון.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h> // For sleep\n\n#define MAX_CONCURRENT_DB_ACCESS 3\n#define NUM_THREADS 5\n\n// Global variables\nint active_db_queries = 0;\nsem_t db_access_sem; // Semaphore for controlling concurrent DB access\nsem_t mutex_sem;     // Mutex for protecting active_db_queries\n\nvoid *thread_function(void *arg) {\n    int thread_id = *(int *)arg;\n\n    while (1) {\n        printf(\"Thread %d: Waiting to access DB...\\n\", thread_id);\n\n        // Simulate some work before accessing DB\n        sleep(rand() % 2);\n\n        // --- Synchronization Start: Add semaphore logic here ---\n\n        // 1. Acquire mutex for active_db_queries\n        // 2. Increment active_db_queries\n        // 3. Release mutex\n\n        // 4. Acquire access to DB (limited by MAX_CONCURRENT_DB_ACCESS)\n\n        printf(\"Thread %d: Accessing DB. Current active: %d\\n\", thread_id, active_db_queries);\n        // Simulate DB operation\n        sleep(rand() % 3 + 1); // DB operation takes 1-3 seconds\n\n        printf(\"Thread %d: Done with DB access.\\n\", thread_id);\n\n        // 6. Release DB access\n\n        // 7. Acquire mutex for active_db_queries\n        // 8. Decrement active_db_queries\n        // 9. Release mutex\n\n        // --- Synchronization End ---\n\n        // Simulate some work after accessing DB\n        sleep(rand() % 2);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    int thread_ids[NUM_THREADS];\n\n    // Initialize semaphores\n    sem_init(&db_access_sem, 0, MAX_CONCURRENT_DB_ACCESS); // Counting semaphore\n    sem_init(&mutex_sem, 0, 1);                             // Binary semaphore (mutex)\n\n    // Create threads\n    for (int i = 0; i < NUM_THREADS; i++) {\n        thread_ids[i] = i;\n        pthread_create(&threads[i], NULL, thread_function, &thread_ids[i]);\n    }\n\n    // Join threads (in a real scenario, these might run indefinitely)\n    for (int i = 0; i < NUM_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n\n    // Destroy semaphores\n    sem_destroy(&db_access_sem);\n    sem_destroy(&mutex_sem);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 15, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "הפתרון דורש שימוש בשני סמפורים:\n1.  **`db_access_sem`**: סמפור מונה (counting semaphore) שמאתחל לערך `MAX_CONCURRENT_DB_ACCESS`. סמפור זה משמש לשליטה על מספר הגישות המקבילות למסד הנתונים. כל תהליך שרוצה לגשת למסד הנתונים מבצע `sem_wait(&db_access_sem)`. אם הסמפור גדול מ-0, הוא יורד ב-1 והתהליך ממשיך. אם הוא 0, התהליך נחסם עד שתהליך אחר מבצע `sem_post`. לאחר סיום הגישה למסד הנתונים, התהליך מבצע `sem_post(&db_access_sem)` כדי לשחרר מקום עבור תהליכים אחרים.\n2.  **`mutex_sem`**: סמפור בינארי (binary semaphore), או mutex, שמאתחל לערך 1. סמפור זה משמש להבטחת הדרה הדדית (mutual exclusion) על המונה הגלובלי `active_db_queries`. לפני כל פעולת הגדלה או הקטנה של המונה, תהליך מבצע `sem_wait(&mutex_sem)`. זה מבטיח שרק תהליך אחד יכול לעדכן את המונה בכל רגע נתון. לאחר עדכון המונה, התהליך מבצע `sem_post(&mutex_sem)` כדי לשחרר את ה-mutex לתהליכים אחרים.\n\nלהלן הקוד המלא והנכון לפונקציית `thread_function` ולפונקציית `main`:\n#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h> // For sleep\n\n#define MAX_CONCURRENT_DB_ACCESS 3\n#define NUM_THREADS 5\n\n// Global variables\nint active_db_queries = 0;\nsem_t db_access_sem; // Semaphore for controlling concurrent DB access\nsem_t mutex_sem;     // Mutex for protecting active_db_queries\n\nvoid *thread_function(void *arg) {\n    int thread_id = *(int *)arg;\n\n    while (1) {\n        printf(\"Thread %d: Waiting to access DB...\\n\", thread_id);\n\n        // Simulate some work before accessing DB\n        sleep(rand() % 2);\n\n        // --- Synchronization Start ---\n\n        // 1. Acquire mutex for active_db_queries\n        sem_wait(&mutex_sem);\n        // 2. Increment active_db_queries\n        active_db_queries++;\n        printf(\"Thread %d: active_db_queries incremented to %d.\\n\", thread_id, active_db_queries);\n        // 3. Release mutex\n        sem_post(&mutex_sem);\n\n        // 4. Acquire access to DB (limited by MAX_CONCURRENT_DB_ACCESS)\n        sem_wait(&db_access_sem);\n\n        printf(\"Thread %d: Accessing DB. Current active: %d\\n\", thread_id, active_db_queries);\n        // Simulate DB operation\n        sleep(rand() % 3 + 1); // DB operation takes 1-3 seconds\n\n        printf(\"Thread %d: Done with DB access.\\n\", thread_id);\n\n        // 6. Release DB access\n        sem_post(&db_access_sem);\n\n        // 7. Acquire mutex for active_db_queries\n        sem_wait(&mutex_sem);\n        // 8. Decrement active_db_queries\n        active_db_queries--;\n        printf(\"Thread %d: active_db_queries decremented to %d.\\n\", thread_id, active_db_queries);\n        // 9. Release mutex\n        sem_post(&mutex_sem);\n\n        // --- Synchronization End ---\n\n        // Simulate some work after accessing DB\n        sleep(rand() % 2);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    int thread_ids[NUM_THREADS];\n\n    // Initialize semaphores\n    sem_init(&db_access_sem, 0, MAX_CONCURRENT_DB_ACCESS); // Counting semaphore\n    sem_init(&mutex_sem, 0, 1);                             // Binary semaphore (mutex)\n\n    // Create threads\n    for (int i = 0; i < NUM_THREADS; i++) {\n        thread_ids[i] = i;\n        pthread_create(&threads[i], NULL, thread_function, &thread_ids[i]);\n    }\n\n    // Join threads (in a real scenario, these might run indefinitely)\n    for (int i = 0; i < NUM_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n\n    // Destroy semaphores\n    sem_destroy(&db_access_sem);\n    sem_destroy(&mutex_sem);\n\n    return 0;\n}"}, "difficulty_estimation": "Medium", "_source_file": "0322__Semaphores__Open__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:44:34", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Synchronization", "Semaphores", "Concurrency"], "content": {"text": "נתונה מערכת מרובת חוטים בה קיימת מקטע קוד קריטי שיכול להיות מבוצע על ידי מספר חוטים במקביל. יש לממש מנגנון סנכרון המבטיח שבכל רגע נתון, לא יותר מ-K חוטים יבצעו את המקטע הקריטי. השתמשו בסמפורים בלבד. צרפו קוד C/C++ המדגים את השימוש בסמפורים בתוך פונקציה המייצגת את פעולת החוט, והסבירו את הלוגיקה, כולל אתחול הסמפורים ומיקום פעולות ה-wait וה-signal.", "code_snippet": "// Assume semaphore related headers are included (e.g., <semaphore.h>, <pthread.h>)\n// Assume a global semaphore 'resource_access' is declared.\n\nvoid thread_function(int thread_id) {\n    // קוד לפני המקטע הקריטי\n    printf(\"Thread %d attempting to enter critical section.\\n\", thread_id);\n\n    // TODO: הוסף כאן את קריאות ה-wait לסמפור 'resource_access'\n    \n    // המקטע הקריטי (critical section)\n    printf(\"Thread %d entered critical section.\\n\", thread_id);\n    // סימולציה של עבודה במקטע הקריטי\n    sleep(1);\n    printf(\"Thread %d exiting critical section.\\n\", thread_id);\n\n    // TODO: הוסף כאן את קריאות ה-signal לסמפור 'resource_access'\n    \n    // קוד אחרי המקטע הקריטי\n}\n\n// TODO: יש להוסיף אתחול לסמפור הגלובלי 'resource_access' לערך K במיין,\n// וכן אתחול וסיום תהליכונים (threads) ושחרור משאבים.\n// int main() { ... }"}, "sub_questions": null, "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון דורש שימוש בסמפור מונה (counting semaphore). סמפור זה מאותחל לערך K, המייצג את מספר המקומות הפנויים במקטע הקריטי. כל חוט שמעוניין להיכנס למקטע הקריטי מבצע פעולת wait (או P) על הסמפור. פעולה זו מקטינה את מונה הסמפור באחד. אם מונה הסמפור הופך שלילי (כלומר, כל K המקומות תפוסים), החוט נחסם עד שחוט אחר ישחרר מקום. לאחר שהחוט מסיים את ביצוע המקטע הקריטי, הוא מבצע פעולת signal (או V) על הסמפור. פעולה זו מגדילה את מונה הסמפור באחד. אם היו חוטים חסומים שממתינים למקום, אחד מהם ישוחרר ויורשה לו להיכנס למקטע הקריטי.\n\nלהלן מימוש ב-C/C++:\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h> // For sleep\n\n// הגדרת סמפור גלובלי\nsem_t resource_access;\n\nvoid *thread_function(void *arg) {\n    int thread_id = *(int*)arg;\n    \n    // קוד לפני המקטע הקריטי\n    printf(\"חוט %d מנסה להיכנס למקטע הקריטי.\\n\", thread_id);\n\n    // פעולת wait (P) על הסמפור לפני הכניסה למקטע הקריטי\n    // אם מספר המשאבים הפנויים (K) הוא 0, החוט ייחסם כאן.\n    sem_wait(&resource_access);\n    \n    // המקטע הקריטי (critical section)\n    int val;\n    sem_getvalue(&resource_access, &val); // בדיקת ערך הסמפור (לצורך הדגמה)\n    printf(\"חוט %d נכנס למקטע הקריטי. מקומות פנויים נותרו: %d\\n\", thread_id, val);\n    sleep(2); // סימולציה של עבודה במקטע הקריטי\n    printf(\"חוט %d יוצא מהמקטע הקריטי.\\n\", thread_id);\n\n    // פעולת signal (V) על הסמפור לאחר היציאה מהמקטע הקריטי\n    // משחרר \\\"מקום\\\" אחד במקטע הקריטי, ואם יש חוטים חסומים, אחד מהם ישוחרר.\n    sem_post(&resource_access);\n    \n    // קוד אחרי המקטע הקריטי\n    return NULL;\n}\n\nint main() {\n    int N_THREADS = 10; // לדוגמה, 10 חוטים\n    int K_LIMIT = 3;    // לדוגמה, לכל היותר 3 חוטים במקביל\n    pthread_t threads[N_THREADS];\n    int thread_ids[N_THREADS];\n\n    // אתחול הסמפור:\n    // הארגומנט הראשון הוא מצביע לסמפור.\n    // הארגומנט השני הוא 0 אם הסמפור משמש חוטים באותו תהליך, או 1 אם הוא משותף בין תהליכים.\n    // הארגומנט השלישי הוא הערך ההתחלתי של הסמפור, שהוא K_LIMIT במקרה זה.\n    // K_LIMIT מייצג את מספר ה\\\"היתרים\\\" או ה\\\"מקומות\\\" הזמינים במקטע הקריטי.\n    if (sem_init(&resource_access, 0, K_LIMIT) != 0) {\n        perror(\"sem_init failed\");\n        return 1;\n    }\n\n    // יצירת והפעלת החוטים\n    for (int i = 0; i < N_THREADS; i++) {\n        thread_ids[i] = i;\n        if (pthread_create(&threads[i], NULL, thread_function, &thread_ids[i]) != 0) {\n            perror(\"pthread_create failed\");\n            return 1;\n        }\n    }\n\n    // המתנה לסיום החוטים\n    for (int i = 0; i < N_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n\n    // שחרור משאבים - השמדת הסמפור\n    sem_destroy(&resource_access);\n\n    printf(\"כל החוטים סיימו את פעולתם.\\n\");\n\n    return 0;\n}\n```"}, "difficulty_estimation": "Medium", "_source_file": "0323__Semaphores__Open__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:46:17", "_subject": "Concurrency"}, {"id": 101, "type": "Open", "topic": ["Synchronization", "Semaphores", "Producer-Consumer"], "content": {"text": "נתונה מערכת עם חוצץ מעגלי בגודל BUFFER_SIZE (לדוגמה, 10 תאים) שבו מפיקים (Producers) מוסיפים נתונים וצרכנים (Consumers) מסירים נתונים. המטרה היא לממש את הפעולות enqueue (הוספת נתון לחוצץ) ו-dequeue (הסרת נתון מהחוצץ) תוך שימוש בסמפורים בלבד, על מנת להבטיח את הדרישות הבאות:\n1.  גישה הדדית בלעדית (mutual exclusion) לחוצץ עצמו (כלומר, רק תהליך אחד יכול לגשת לחוצץ בכל רגע נתון).\n2.  מפיק ימתין אם החוצץ מלא (כל תאי החוצץ תפוסים).\n3.  צרכן ימתין אם החוצץ ריק (אין נתונים בחוצץ).\n\nא. הגדירו את הסמפורים הנדרשים (שם, סוג – בינארי/מונה – וערך אתחול).\nב. כתבו את קוד ה-C/C++ עבור פונקציות enqueue ו-dequeue המממשות את הדרישות הנ\"ל. יש לכלול את הגדרות הסמפורים ופונקציית אתחול בסיסית.\nג. הסבירו בקצרה מדוע כל סמפור נחוץ ומה תפקידו.", "code_snippet": "#include <semaphore.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#define BUFFER_SIZE 10\n\n// Shared buffer and indices\nint buffer[BUFFER_SIZE];\nint in = 0;  // Next write position\nint out = 0; // Next read position\n\n// Semaphores\nsem_t mutex;    // For mutual exclusion to buffer\nsem_t empty;    // Counts empty slots\nsem_t full;     // Counts full slots\n\n// Initialization function for semaphores and buffer state\nvoid init_buffer_sync() {\n    sem_init(&mutex, 0, 1);             // Binary semaphore, initialized to 1\n    sem_init(&empty, 0, BUFFER_SIZE);   // Counting semaphore, initialized to BUFFER_SIZE\n    sem_init(&full, 0, 0);              // Counting semaphore, initialized to 0\n}\n\n// Producer function to add an item to the buffer\nvoid enqueue(int item) {\n    sem_wait(&empty); // Wait if buffer is full\n    sem_wait(&mutex); // Acquire lock for buffer access\n\n    // Critical section: Add item to buffer\n    buffer[in] = item;\n    in = (in + 1) % BUFFER_SIZE;\n    // printf(\"Producer added: %d\\n\", item); // Optional print for debugging\n\n    sem_post(&mutex); // Release lock\n    sem_post(&full);  // Signal that a slot is now full\n}\n\n// Consumer function to remove an item from the buffer\nint dequeue() {\n    int item;\n    sem_wait(&full);  // Wait if buffer is empty\n    sem_wait(&mutex); // Acquire lock for buffer access\n\n    // Critical section: Remove item from buffer\n    item = buffer[out];\n    out = (out + 1) % BUFFER_SIZE;\n    // printf(\"Consumer removed: %d\\n\", item); // Optional print for debugging\n\n    sem_post(&mutex); // Release lock\n    sem_post(&empty); // Signal that a slot is now empty\n    return item;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. הגדרת סמפורים וערכי אתחול:\nנדרשים שלושה סמפורים:\n1.  mutex: סמפור בינארי (או מנעול).\n    *   תפקיד: להבטיח גישה הדדית בלעדית לחוצץ המשותף (המשתנים buffer, in, out). רק תהליך אחד (מפיק או צרכן) יכול לגשת לחוצץ ולשנות את מצבו בכל רגע נתון.\n    *   ערך אתחול: 1 (כלומר, החוצץ פנוי לגישה).\n2.  empty: סמפור מונה.\n    *   תפקיד: לספור את מספר התאים הריקים בחוצץ. מפיקים מבצעים sem_wait עליו כדי להמתין לתא פנוי, וצרכנים מבצעים sem_post עליו לאחר פינוי תא.\n    *   ערך אתחול: BUFFER_SIZE (מספר התאים הכולל בחוצץ, שכולם ריקים בהתחלה).\n3.  full: סמפור מונה.\n    *   תפקיד: לספור את מספר התאים המלאים בחוצץ. צרכנים מבצעים sem_wait עליו כדי להמתין לתא מלא, ומפיקים מבצעים sem_post עליו לאחר מילוי תא.\n    *   ערך אתחול: 0 (בהתחלה אין תאים מלאים).\n\nב. קוד C/C++ לפונקציות enqueue ו-dequeue:\nהקוד המלא עבור הגדרות הסמפורים, פונקציית האתחול init_buffer_sync, ופונקציות enqueue ו-dequeue כלול בשדה code_snippet של השאלה עצמה.\n\nג. הסבר על נחיצות ותפקיד כל סמפור:\n*   mutex: חיוני למניעת תנאי מרוץ (race conditions) בעת גישה למשתנים המשותפים (buffer, in, out). ללא mutex, שני מפיקים (או שני צרכנים, או מפיק וצרכן) עלולים לנסות לשנות את אותם אינדקסים או תאי חוצץ בו-זמנית, מה שיוביל לשגיאות ולחוסר עקביות בנתונים. הוא מבטיח שרק תהליך אחד נמצא ב\"אזור קריטי\" של גישה לחוצץ בכל רגע נתון.\n*   empty: סמפור זה מונע ממפיקים להוסיף נתונים לחוצץ כשהוא מלא. כאשר מפיק מנסה להוסיף פריט, הוא מוריד את ערך empty. אם empty מגיע ל-0, פירושו שהחוצץ מלא, והמפיק ייחסם עד שצרכן יפנה מקום (יעלה את ערך empty).\n*   full: סמפור זה מונע מצרכנים לנסות להסיר נתונים מחוצץ כשהוא ריק. כאשר צרכן מנסה להסיר פריט, הוא מוריד את ערך full. אם full מגיע ל-0, פירושו שהחוצץ ריק, והצרכן ייחסם עד שמפיק יוסיף פריט (יעלה את ערך full).\n\nהסדר של פעולות ה-sem_wait ו-sem_post הוא קריטי. לדוגמה, אם ב-enqueue נבצע sem_wait(&mutex) לפני sem_wait(&empty), וכל תאי החוצץ יהיו מלאים, המפיק יקבל את המנעול mutex ואז ייחסם בניסיון להוריד את empty. אם באותו זמן צרכן ינסה לגשת לחוצץ כדי לפנות מקום, הוא יצטרך את mutex אך הוא יהיה נעול על ידי המפיק החסום, מה שיוביל למצב של קיפאון (deadlock). לכן, יש להמתין לתנאי המשאב (empty או full) לפני קבלת המנעול לגישה קריטית."}, "difficulty_estimation": "Medium", "_source_file": "0324__Semaphores__Open__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:46:44", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Semaphores", "Synchronization", "Threads"], "content": {"text": "נתונה מערכת עם N חוטים. כל חוט מבצע באופן מחזורי שתי משימות: `Task A` ולאחריה `Task B`. יש דרישת סנכרון לפיה אף חוט לא יכול להתחיל את `Task B` שלו לפני שכל N החוטים סיימו את `Task A` שלהם. כלומר, כל החוטים חייבים להגיע לנקודת מחסום (Barrier) לאחר `Task A` לפני שהם ממשיכים ל`Task B`. מנגנון המחסום צריך להיות ניתן לשימוש חוזר (reusable) עבור המחזורים הבאים.\nכתוב את קוד ה-C/C++ עבור פונקציית `worker_thread` שתממש את ההתנהגות המתוארת, תוך שימוש בסמפורים (semaphores) ובמנעולים (mutexes) בלבד. יש להגדיר את כל המשתנים הגלובליים הנדרשים ולאתחל אותם כראוי. אין להשתמש באובייקטי סנכרון מובנים אחרים (כמו `pthread_barrier_t`).", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון מבוסס על מנגנון \"מחסום דו-שלבי\" (Double Turnstile Barrier), המשתמש בשני סמפורים (turnstiles) ובמנעול (mutex) כדי להבטיח סנכרון נכון ושימוש חוזר.\n\n**1. משתנים גלובליים ואתחול:**\n```c\n#include <pthread.h>\n#include <semaphore.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h> // For sleep (in example tasks)\n\n// הגדרת מספר החוטים הכולל\n#define NUM_THREADS 5 // N לדוגמה\n\nint N = NUM_THREADS;\nint count = 0;\npthread_mutex_t mutex;\nsem_t barrier;\nsem_t barrier_reset;\n\nvoid init_barrier() {\n    pthread_mutex_init(&mutex, NULL);\n    sem_init(&barrier, 0, 0);       // סמפור ראשי (סגור בהתחלה)\n    sem_init(&barrier_reset, 0, 1); // סמפור איפוס (פתוח בהתחלה)\n}\n\nvoid destroy_barrier() {\n    pthread_mutex_destroy(&mutex);\n    sem_destroy(&barrier);\n    sem_destroy(&barrier_reset);\n}\n```\n\n**2. פונקציית `barrier_wait()`:**\nפונקציה זו מממשת את ההמתנה במחסום:\n```c\nvoid barrier_wait() {\n    // שלב 1: איסוף החוטים במחסום הראשון\n    pthread_mutex_lock(&mutex);\n    count++;\n    if (count == N) {\n        // החוט האחרון שהגיע: סוגר את מחסום האיפוס ופותח את המחסום הראשי\n        sem_wait(&barrier_reset); \n        for (int i = 0; i < N; i++) {\n            sem_post(&barrier);\n        }\n    }\n    pthread_mutex_unlock(&mutex);\n    sem_wait(&barrier); // כל החוטים ממתינים כאן עד שהמחסום הראשי ייפתח\n\n    // שלב 2: איפוס המחסום עבור המחזור הבא\n    pthread_mutex_lock(&mutex);\n    count--;\n    if (count == 0) {\n        // החוט האחרון שיוצא: סוגר את המחסום הראשי ופותח את מחסום האיפוס\n        for (int i = 0; i < N; i++) {\n            sem_post(&barrier_reset);\n        }\n    }\n    pthread_mutex_unlock(&mutex);\n    sem_wait(&barrier_reset); // כל החוטים ממתינים כאן עד שמחסום האיפוס ייפתח\n}\n```\n\n**3. פונקציית `worker_thread`:**\nכל חוט מבצע את המשימות שלו ומשתמש ב-`barrier_wait`:\n```c\n// פונקציות לדוגמה למשימות A ו-B (אין צורך לממשן במבחן, רק לצורך הדגמה)\nvoid taskA(int thread_id) {\n    printf(\"Thread %d: Starting Task A\\n\", thread_id);\n    sleep(rand() % 2); // הדמיית עבודה\n    printf(\"Thread %d: Finished Task A\\n\", thread_id);\n}\n\nvoid taskB(int thread_id) {\n    printf(\"Thread %d: Starting Task B\\n\", thread_id);\n    sleep(rand() % 2); // הדמיית עבודה\n    printf(\"Thread %d: Finished Task B\\n\", thread_id);\n}\n\nvoid *worker_thread(void *arg) {\n    int thread_id = *(int *)arg;\n    free(arg); // שחרור הזיכרון שהוקצה למזהה החוט\n\n    while (1) { // לולאה אינסופית עבור מחזורים חוזרים\n        taskA(thread_id);\n        barrier_wait(); // המתן עד שכל N החוטים יסיימו את Task A\n        taskB(thread_id);\n        printf(\"Thread %d: Cycle complete.\\n\", thread_id);\n        sleep(1); // השהייה קטנה לפני המחזור הבא\n    }\n    return NULL;\n}\n```\n\n**הסבר מפורט:**\n\n*   **משתנים גלובליים:**\n    *   `N`: קבוע המגדיר את מספר החוטים הכולל במערכת. יש לאתחל אותו לפני יצירת החוטים.\n    *   `count`: מונה את מספר החוטים שהגיעו לנקודת הסנכרון בשלב הנוכחי. מאופס בכל מחזור.\n    *   `mutex`: מנעול `pthread_mutex_t` המשמש להגנה על הגישה למשתנה `count` המשותף, ובכך מבטיח עדכון אטומי (atomic) של המונה. מאותחל ל-1 (פתוח).\n    *   `barrier`: סמפור `sem_t` המשמש לחסימת חוטים בשלב הראשון של המחסום, עד שכל `N` החוטים מגיעים. מאותחל ל-0 (סגור לחלוטין).\n    *   `barrier_reset`: סמפור `sem_t` נוסף המשמש לחסימת חוטים בשלב השני, ומונע מהם להתחיל מחזור חדש לפני שכל החוטים סיימו את המחזור הקודם. מאותחל ל-1 (פתוח עבור המחזור הראשון).\n\n*   **פעולת `barrier_wait()`:**\n    1.  **שלב ראשון (איסוף):** כל חוט שמגיע קורא ל-`pthread_mutex_lock(&mutex)`, מגדיל את `count`, ומשחרר את ה-`mutex`. כאשר החוט ה-`N` מגיע (כלומר, `count` מגיע ל-`N`), הוא מזהה שהוא האחרון. חוט זה מבצע `sem_wait(&barrier_reset)` כדי \"לסגור\" את שער האיפוס (ובכך למנוע מחזורים עתידיים להתקדם בטרם עת) ולאחר מכן מבצע `sem_post(&barrier)` `N` פעמים. פעולה זו משחררת את כל `N` החוטים שייתכן שממתינים או שיגיעו בקרוב ל-`sem_wait(&barrier)`. כל החוטים, כולל החוט ה-`N`, ממתינים ב-`sem_wait(&barrier)` עד שהסמפור ייפתח.\n    2.  **שלב שני (איפוס):** לאחר שכל החוטים עברו את `sem_wait(&barrier)`, הם נכנסים לשלב השני. כל חוט נועל שוב את ה-`mutex`, מקטין את `count`, ומשחרר את ה-`mutex`. כאשר החוט האחרון שיוצא (כלומר, `count` מגיע ל-`0`) מזהה שהוא האחרון. חוט זה מבצע `sem_post(&barrier_reset)` `N` פעמים כדי \"לפתוח\" מחדש את שער האיפוס עבור המחזור הבא. כל החוטים ממתינים ב-`sem_wait(&barrier_reset)` עד שהסמפור ייפתח. זה מבטיח שכל החוטים סיימו לחלוטין את המחזור הנוכחי (כולל איפוס המונה) לפני שמישהו יתחיל את השלב הראשון של המחזור הבא.\n\n*   **פונקציית `worker_thread`:** כל חוט מבצע בלולאה אינסופית את `taskA`, ולאחר מכן קורא ל-`barrier_wait()` כדי להמתין לשאר החוטים. רק לאחר שכל `N` החוטים סיימו את `taskA` ועברו את המחסום, כולם ממשיכים יחד ל-`taskB`. הדבר מבטיח את דרישת הסנכרון ואת יכולת השימוש החוזר של המחסום."}, "difficulty_estimation": "Medium", "_source_file": "0325__Semaphores__Open__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:47:31", "_subject": "Concurrency"}, {"id": 101, "type": "Open", "topic": ["Synchronization", "Semaphores"], "content": {"text": "מחסום (Barrier) הוא אובייקט סנכרון המיועד ל-N חוטים. כאשר חוט קורא לפעולת `barrier_wait()`, הוא ממתין עד שכל N החוטים קראו לפעולה זו. רק כאשר כל N החוטים הגיעו למחסום, כולם משוחררים בו זמנית וממשיכים בביצוע. המחסום צריך להיות ניתן לשימוש חוזר (reusable), כלומר, לאחר שכל החוטים שוחררו, ניתן להשתמש בו שוב באותו אופן לסנכרון השלב הבא.\nתארו כיצד ניתן לממש מחסום ניתן לשימוש חוזר עבור N חוטים באמצעות סמפורים (POSIX semaphores) ומבנה נתונים פשוט. כתבו את קוד ה-C/C++ עבור הפונקציות `barrier_init()`, `barrier_destroy()` ו-`barrier_wait()`, והסבירו את תפקיד כל סמפור ואת לוגיקת הפעולה של המחסום.", "code_snippet": "```c\n#include <semaphore.h>\n#include <stdlib.h> // For malloc, free (though not directly used in the Barrier struct itself here)\n\ntypedef struct {\n    int N; // Total number of threads for the barrier\n    int count; // Number of threads arrived at the barrier\n    sem_t mutex; // Protects 'count'\n    sem_t turnstile; // Blocks threads until all arrive\n    sem_t turnstile2; // Used to reset the barrier for reuse\n} Barrier;\n\nvoid barrier_init(Barrier *b, int num_threads) {\n    b->N = num_threads;\n    b->count = 0;\n    sem_init(&b->mutex, 0, 1); // Mutex initially open\n    sem_init(&b->turnstile, 0, 0); // Turnstile initially locked\n    sem_init(&b->turnstile2, 0, 1); // Turnstile2 initially open\n}\n\nvoid barrier_destroy(Barrier *b) {\n    sem_destroy(&b->mutex);\n    sem_destroy(&b->turnstile);\n    sem_destroy(&b->turnstile2);\n}\n\nvoid barrier_wait(Barrier *b) {\n    // Phase 1: Gathering threads and releasing them\n    sem_wait(&b->mutex);\n    b->count++;\n    if (b->count == b->N) {\n        sem_wait(&b->turnstile2); // Close turnstile2 to prevent early reset\n        for (int i = 0; i < b->N; i++) {\n            sem_post(&b->turnstile); // Open turnstile to release all threads\n        }\n    }\n    sem_post(&b->mutex);\n\n    sem_wait(&b->turnstile); // All threads wait here until released\n\n    // Phase 2: Resetting the barrier for reuse\n    sem_wait(&b->mutex);\n    b->count--;\n    if (b->count == 0) {\n        for (int i = 0; i < b->N; i++) {\n            sem_post(&b->turnstile2); // Reopen turnstile2 for the next cycle\n        }\n    }\n    sem_post(&b->mutex);\n}\n```", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון מבוסס על מימוש מחסום דו-פאזי (two-phase barrier) באמצעות שני סמפורים (POSIX semaphores) ומונה.\n\n**מבנה הנתונים:**\n*   `N`: מספר החוטים הכולל המשתתפים במחסום.\n*   `count`: מונה העוקב אחר מספר החוטים שהגיעו למחסום בשלב הנוכחי.\n*   `mutex`: סמפור בינארי (או mutex) המשמש להגנה על המונה `count` מפני תנאי מירוץ. מאותחל ל-1 (פתוח).\n*   `turnstile`: סמפור ספירה המאותחל ל-0. חוטים נחסמים עליו עד שכל N החוטים יגיעו. הוא נפתח על ידי החוט האחרון שהגיע.\n*   `turnstile2`: סמפור ספירה המאותחל ל-1. משמש לסנכרון האיפוס של המחסום, כך שרק לאחר שכל N החוטים עברו את המחסום ו\"יצאו\" ממנו, הוא מוכן שוב לשימוש.\n\n**פעולת `barrier_init(Barrier *b, int num_threads)`:**\n*   מאחלת את `N` ל-`num_threads`.\n*   מאחלת את `count` ל-0.\n*   מאחלת את `mutex` ל-1 (פתוח).\n*   מאחלת את `turnstile` ל-0 (סגור).\n*   מאחלת את `turnstile2` ל-1 (פתוח).\n\n**פעולת `barrier_wait(Barrier *b)`:**\n\n**שלב 1: איסוף חוטים והגעה למחסום**\n1.  **`sem_wait(&b->mutex);`**: כל חוט רוכש את ה-`mutex` כדי להגן על הגישה ל-`count`. זה מבטיח שרק חוט אחד מעדכן את `count` בכל רגע נתון.\n2.  **`b->count++;`**: החוט מגדיל את המונה `count`.\n3.  **`if (b->count == b->N)`**: אם זהו החוט ה-N שהגיע למחסום (החוט האחרון):\n    *   **`sem_wait(&b->turnstile2);`**: החוט ה-N סוגר את `turnstile2`. זה מבטיח שאף חוט לא יוכל להיכנס לשלב השני של המחסום (איפוס) לפני שכל החוטים עברו את השלב הראשון. זה מונע מחוטים מהמחזור הבא \"להקדים\" חוטים מהמחזור הנוכחי.\n    *   **`for (int i = 0; i < b->N; i++) { sem_post(&b->turnstile); }`**: החוט ה-N משחרר N פעמים את `turnstile`. פעולה זו פותחת את `turnstile` ומאפשרת לכל N החוטים (כולל הוא עצמו) להמשיך הלאה מהנקודה בה הם חסומים ב-`sem_wait(&b->turnstile)`.\n4.  **`sem_post(&b->mutex);`**: החוט משחרר את ה-`mutex`.\n\n**שלב 2: המתנה לשחרור ואיפוס המחסום**\n5.  **`sem_wait(&b->turnstile);`**: כל החוטים, כולל החוט ה-N, מגיעים לכאן ונחסמים על `turnstile` עד שהוא נפתח על ידי החוט ה-N (בשלב 1). ברגע ש-`turnstile` נפתח, כל החוטים עוברים.\n6.  **`sem_wait(&b->mutex);`**: החוטים רוכשים שוב את ה-`mutex` כדי לעדכן את המונה `count` (כעת הוא משמש לספירת יציאה מהמחסום).\n7.  **`b->count--;`**: החוט מקטין את המונה `count`.\n8.  **`if (b->count == 0)`**: אם זהו החוט האחרון שיוצא מהמחסום (כלומר, כל N החוטים עברו את המחסום ו\"יצאו\" ממנו):\n    *   **`for (int i = 0; i < b->N; i++) { sem_post(&b->turnstile2); }`**: החוט האחרון משחרר N פעמים את `turnstile2`. פעולה זו פותחת מחדש את `turnstile2` ומאפשרת למחסום להיות מוכן לשימוש חוזר בסבב הבא.\n9.  **`sem_post(&b->mutex);`**: החוט משחרר את ה-`mutex`.\n\n**הסבר תפקיד הסמפורים בפתרון זה:**\n*   **`mutex`**: סמפור בינארי המגן על המשתנה `count`. הוא מבטיח שרק חוט אחד יכול לגשת ולשנות את `count` בכל רגע נתון, ובכך מונע תנאי מירוץ.\n*   **`turnstile`**: משמש כ\"שער כניסה\" למחסום. הוא חוסם את כל החוטים עד שכולם יגיעו. רק החוט האחרון (ה-N) פותח אותו N פעמים כדי לשחרר את כל החוטים בו זמנית.\n*   **`turnstile2`**: משמש כ\"שער יציאה\" וכמנגנון איפוס למחסום. הוא מבטיח שכל N החוטים עברו את השלב הראשון של המחסום (כלומר, כולם שוחררו מ-`turnstile`) לפני שהמחסום יתאפס ויהיה מוכן לשימוש חוזר. החוט ה-N סוגר אותו כדי למנוע כניסה מוקדמת לשלב האיפוס, והחוט האחרון שיוצא מהמחסום פותח אותו מחדש."}, "difficulty_estimation": "Medium", "_source_file": "0326__Semaphores__Open__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:47:58", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Synchronization", "Semaphores"], "content": {"text": "מערכת הפעלה מנהלת N מדפסות משותפות המשרתות מספר רב של תהליכונים (threads). כל תהליכון המעוניין להדפיס מסמך חייב לתפוס מדפסת זמינה, להשתמש בה (למשל, לבצע פעולת הדפסה), ולבסוף לשחרר אותה. בכל רגע נתון, רק N תהליכונים יכולים להשתמש במדפסת במקביל. עליך לממש את הפונקציות `acquire_printer()` ו-`release_printer()` תוך שימוש בסמפורים, על מנת להבטיח סנכרון נכון ולמנוע מצב בו יותר מ-N תהליכונים משתמשים במדפסות בו זמנית. הנח כי N הוא מספר שלם חיובי, וכי הסמפורים הדרושים מאותחלים כראוי.", "code_snippet": "#include <semaphore.h>\n\n// Assume 'N_PRINTERS' is defined elsewhere, e.g., #define N_PRINTERS 5\n// Assume 'sem_t available_printers;' is declared globally and initialized with N_PRINTERS.\n\nvoid acquire_printer();\nvoid release_printer();", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כדי לפתור בעיה זו, נשתמש בסמפור מונה (counting semaphore). סמפור זה ישמש לייצוג מספר המדפסות הזמינות. הוא יאותחל לערך N, המייצג את המספר הכולל של המדפסות במערכת.\n\n**מימוש הפונקציות:**\n\n```c\n#include <semaphore.h>\n#include <stdio.h> // for example usage, not strictly required for the functions themselves\n#include <stdlib.h> // for example usage\n#include <unistd.h> // for sleep in example usage\n\n// הגדרה והאתחול של הסמפור יבוצעו מחוץ לפונקציות, לדוגמה:\n// #define N_PRINTERS 5\n// sem_t available_printers;\n// void init_printers_semaphore() {\n//     sem_init(&available_printers, 0, N_PRINTERS); // 0 for shared within a process\n// }\n\nvoid acquire_printer() {\n    sem_wait(&available_printers); // מקטין את ערך הסמפור; אם ערכו 0, התהליכון נחסם.\n}\n\nvoid release_printer() {\n    sem_post(&available_printers); // מגדיל את ערך הסמפור; אם יש תהליכונים חסומים, אחד מהם ישוחרר.\n}\n```\n\n**הסבר:**\n1.  **סמפור `available_printers`**: סמפור זה מאותחל ל-N, שהוא המספר המקסימלי של מדפסות זמינות.\n2.  **פונקציה `acquire_printer()`**: כאשר תהליכון רוצה להדפיס, הוא קורא ל-`sem_wait(&available_printers)`. פעולה זו מנסה להקטין את ערך הסמפור. אם ערך הסמפור גדול מ-0, הוא מוקטן והתהליכון ממשיך. אם ערך הסמפור הוא 0 (כלומר, כל המדפסות תפוסות), התהליכון נחסם וממתין עד שמדפסת תתפנה.\n3.  **פונקציה `release_printer()`**: לאחר שתהליכון מסיים להשתמש במדפסת, הוא קורא ל-`sem_post(&available_printers)`. פעולה זו מגדילה את ערך הסמפור. אם היו תהליכונים חסומים הממתינים למדפסת, אחד מהם (התלוי בלוח הזמנים של מערכת ההפעלה) ישוחרר כעת ויוכל להמשיך להשתמש במדפסת.\n\nמנגנון זה מבטיח שבכל רגע נתון, לא יותר מ-N תהליכונים יוכלו לגשת למדפסות, ובכך נשמר הסנכרון הנדרש."}, "difficulty_estimation": "Medium", "_source_file": "0327__Semaphores__Open__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:48:16", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Semaphores", "Synchronization", "Producer-Consumer"], "content": {"text": "נתונה בעיית המאגר החסום (Bounded Buffer) בגודל `BUFFER_SIZE`. ישנם מספר תהליכי יצרן (Producer) שמוסיפים פריטים למאגר ומספר תהליכי צרכן (Consumer) שמוציאים פריטים מהמאגר.\n\nיש לממש את הפונקציות `producer` ו-`consumer` תוך שימוש בסמפורים בלבד (ללא מנעולים או Mutex-ים אחרים) כדי להבטיח סנכרון נכון בין התהליכים.\n\nיש להגדיר את הסמפורים הנדרשים, לאתחל אותם בערכים המתאימים, ולשלב אותם במימוש הפונקציות. הניחו שקיימת מערכת תומכת בפעולות `sem_init`, `sem_wait`, `sem_post` עבור סמפורים. הניחו שקיימות פונקציות `produce_item()` ו-`consume_item(item)` המבצעות את הלוגיקה העסקית של יצירת וצריכת פריטים בהתאמה, וכן פונקציות `insert_item(item)` ו-`remove_item()` המטפלות בגישה למאגר עצמו (אך יש להגן עליהן באמצעות סמפורים).", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h> // For sleep\n\n#define BUFFER_SIZE 5\n\nint buffer[BUFFER_SIZE];\nint in = 0; // Next empty slot\nint out = 0; // Next item to remove\n\n// Declare semaphores here\n// sem_t ...\n\n// Initialize semaphores\nvoid init_semaphores() {\n    // ...\n}\n\nvoid insert_item(int item) {\n    buffer[in] = item;\n    in = (in + 1) % BUFFER_SIZE;\n    printf(\"Producer inserted item %d. Buffer state: \", item);\n    for (int i=0; i<BUFFER_SIZE; ++i) {\n        printf(\"%d \", buffer[i]);\n    }\n    printf(\"]\\n\");\n}\n\nint remove_item() {\n    int item = buffer[out];\n    buffer[out] = -1; // Mark as empty for clarity\n    out = (out + 1) % BUFFER_SIZE;\n    printf(\"Consumer removed item %d. Buffer state: \", item);\n    for (int i=0; i<BUFFER_SIZE; ++i) {\n        printf(\"%d \", buffer[i]);\n    }\n    printf(\"]\\n\");\n    return item;\n}\n\nvoid *producer(void *param) {\n    int item;\n    while (1) {\n        // ... synchronization logic using semaphores ...\n        item = rand() % 100; // Simulate producing an item\n        insert_item(item);\n        // ... synchronization logic using semaphores ...\n        sleep(1); // Simulate work\n    }\n    return NULL;\n}\n\nvoid *consumer(void *param) {\n    int item;\n    while (1) {\n        // ... synchronization logic using semaphores ...\n        item = remove_item();\n        // ... synchronization logic using semaphores ...\n        sleep(2); // Simulate work\n    }\n    return NULL;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "לפתרון בעיית המאגר החסום באמצעות סמפורים נדרשים שלושה סמפורים:\n1.  **`mutex` (סמפור בינארי / סמפור הדדיות):** מגן על הגישה לקטעים הקריטיים של המאגר (הפונקציות `insert_item` ו-`remove_item`) כדי להבטיח שרק תהליך אחד יבצע שינויים במאגר בכל רגע נתון. ערך אתחול: 1 (המאגר פנוי לגישה).\n2.  **`empty` (סמפור ספירה):** עוקב אחר מספר המקומות הריקים במאגר. תהליך יצרן ימתין על סמפור זה אם אין מקום פנוי. ערך אתחול: `BUFFER_SIZE` (בהתחלה כל המאגר ריק).\n3.  **`full` (סמפור ספירה):** עוקב אחר מספר הפריטים המלאים במאגר. תהליך צרכן ימתין על סמפור זה אם המאגר ריק מפריטים. ערך אתחול: 0 (בהתחלה המאגר ריק מפריטים).\n\nהמימוש של הפונקציות `producer` ו-`consumer` ישתמש בסמפורים אלו באופן הבא:\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h> // For sleep\n\n#define BUFFER_SIZE 5\n\nint buffer[BUFFER_SIZE];\nint in = 0; // Next empty slot\nint out = 0; // Next item to remove\n\nsem_t mutex; // For mutual exclusion\nsem_t empty; // Counts empty slots\nsem_t full;  // Counts full slots\n\n// Initialize buffer items to -1 for clarity (empty)\nvoid init_buffer() {\n    for (int i = 0; i < BUFFER_SIZE; ++i) {\n        buffer[i] = -1;\n    }\n}\n\nvoid init_semaphores() {\n    sem_init(&mutex, 0, 1); // Binary semaphore for mutual exclusion, initial value 1\n    sem_init(&empty, 0, BUFFER_SIZE); // Counting semaphore for empty slots, initial value BUFFER_SIZE\n    sem_init(&full, 0, 0); // Counting semaphore for full slots, initial value 0\n}\n\nvoid insert_item(int item) {\n    buffer[in] = item;\n    in = (in + 1) % BUFFER_SIZE;\n    printf(\"Producer inserted item %d. Buffer state: \", item);\n    for (int i=0; i<BUFFER_SIZE; ++i) {\n        printf(\"%d \", buffer[i]);\n    }\n    printf(\"]\\n\");\n}\n\nint remove_item() {\n    int item = buffer[out];\n    buffer[out] = -1; // Mark as empty for clarity\n    out = (out + 1) % BUFFER_SIZE;\n    printf(\"Consumer removed item %d. Buffer state: \", item);\n    for (int i=0; i<BUFFER_SIZE; ++i) {\n        printf(\"%d \", buffer[i]);\n    }\n    printf(\"]\\n\");\n    return item;\n}\n\nvoid *producer(void *param) {\n    int item;\n    while (1) {\n        item = rand() % 100; // Simulate producing an item\n        \n        sem_wait(&empty); // Wait if buffer is full (no empty slots)\n        sem_wait(&mutex); // Acquire lock for critical section\n        \n        insert_item(item);\n        \n        sem_post(&mutex); // Release lock\n        sem_post(&full);  // Signal that a slot is now full\n        \n        sleep(1); // Simulate work\n    }\n    return NULL;\n}\n\nvoid *consumer(void *param) {\n    int item;\n    while (1) {\n        sem_wait(&full);  // Wait if buffer is empty (no full slots)\n        sem_wait(&mutex); // Acquire lock for critical section\n        \n        item = remove_item();\n        \n        sem_post(&mutex); // Release lock\n        sem_post(&empty); // Signal that a slot is now empty\n        \n        sleep(2); // Simulate work\n    }\n    return NULL;\n}\n```"}, "difficulty_estimation": "Medium", "_source_file": "0328__Semaphores__Open__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:48:40", "_subject": "Concurrency"}, {"id": 7, "type": "Open", "topic": ["Semaphores", "Concurrency", "Resource Management", "Deadlock", "Starvation"], "content": {"text": "מערכת מורכבת מ-N תהליכי עבודה (Worker Threads) ומשני סוגי משאבים משותפים: ResourceA (סה\"כ MAX_A יחידות) ו-ResourceB (סה\"כ MAX_B יחידות). משימות מגיעות באופן דינמי. כל משימה דורשת req_A יחידות מ-ResourceA ו-req_B יחידות מ-ResourceB. תהליך עבודה לוקח משימה וצריך לרכוש את *כל* המשאבים הנדרשים באופן אטומי לפני תחילת המשימה, ולשחרר אותם כולם בסיום. בנוסף, למערכת יש מדיניות שמגבילה את המספר הכולל של *משימות פעילות* (משימות שמחזיקות משאבים ומבצעות כעת) ל-MAX_CONCURRENT_TASKS. כל הפעולות של סמפורים הן POSIX standard (`sem_init`, `sem_wait`, `sem_post`, `sem_getvalue`, `sem_trywait`).\n\nא. כתבו את חתימות הפונקציות `acquire_resources(int req_A, int req_B)` ו-`release_resources(int req_A, int req_B)`.\nב. יישמו את הפונקציות הללו באמצעות סמפורים (מונים ו/או בינאריים/Mutex), תוך הקפדה על הדרישות הבאות:\n   1. לא יוקצו יותר מ-MAX_A יחידות מ-ResourceA ולא יותר מ-MAX_B יחידות מ-ResourceB.\n   2. לא יהיו יותר מ-MAX_CONCURRENT_TASKS משימות פעילות בו זמנית.\n   3. המערכת תהיה נקייה מקיפאון (Deadlock-free).\n   4. מנעו הרעבה (Starvation) ככל הניתן בפתרון שלכם.\nג. הסבירו במפורט כיצד הפתרון שלכם מונע קיפאון והרעבה.", "code_snippet": "/* גלובליים / אתחול */\n#include <semaphore.h>\n#include <unistd.h> // for usleep\n\nsem_t sem_A;\nsem_t sem_B;\nsem_t sem_concurrent;\nsem_t mutex_resource_alloc; // להגנה על הקצאת משאבים מרובים\n\nvoid init_synchronization(int MAX_A, int MAX_B, int MAX_CONCURRENT_TASKS) {\n    sem_init(&sem_A, 0, MAX_A);\n    sem_init(&sem_B, 0, MAX_B);\n    sem_init(&sem_concurrent, 0, MAX_CONCURRENT_TASKS);\n    sem_init(&mutex_resource_alloc, 0, 1);\n}\n\nvoid destroy_synchronization() {\n    sem_destroy(&sem_A);\n    sem_destroy(&sem_B);\n    sem_destroy(&sem_concurrent);\n    sem_destroy(&mutex_resource_alloc);\n}\n\n/* פונקציות שיש לממש */\nvoid acquire_resources(int req_A, int req_B);\nvoid release_resources(int req_A, int req_B);", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\n**א. חתימות הפונקציות:**\n```c\nvoid acquire_resources(int req_A, int req_B);\nvoid release_resources(int req_A, int req_B);\n```\n\n**ב. יישום הפונקציות:**\n```c\nvoid acquire_resources(int req_A, int req_B) {\n    // 1. תפוס מקום למשימה מקבילה. זה מגביל את המספר הכולל של משימות שיכולות לנסות לרכוש משאבים.\n    sem_wait(&sem_concurrent);\n\n    // 2. היכנס לקטע קריטי להקצאת משאבים. זה מבטיח שרק תהליך אחד בכל פעם יבדוק וירכוש משאבים.\n    while (1) {\n        sem_wait(&mutex_resource_alloc);\n\n        int val_A, val_B;\n        // בדוק את כמות המשאבים הזמינים. `sem_getvalue` אינה אטומית עם `sem_wait`.\n        // לכן, אנחנו בתוך critical section המוגן על ידי `mutex_resource_alloc`.\n        sem_getvalue(&sem_A, &val_A);\n        sem_getvalue(&sem_B, &val_B);\n\n        if (val_A >= req_A && val_B >= req_B) {\n            // כל המשאבים זמינים. רכוש אותם.\n            // רכישה ביחידות בודדות בתוך הקטע הקריטי.\n            for (int i = 0; i < req_A; ++i) {\n                sem_wait(&sem_A);\n            }\n            for (int i = 0; i < req_B; ++i) {\n                sem_wait(&sem_B);\n            }\n            sem_post(&mutex_resource_alloc); // שחרר את המוטקס לאחר רכישה מוצלחת\n            break; // יצא מהלולאה, המשאבים נרכשו בהצלחה\n        } else {\n            // המשאבים אינם זמינים במלואם. שחרר את המוטקס זמנית ואז נסה שוב.\n            sem_post(&mutex_resource_alloc);\n            usleep(1000); // המתן זמן קצר כדי למנוע busy-waiting ולאפשר לתהליכים אחרים לנסות\n        }\n    }\n}\n\nvoid release_resources(int req_A, int req_B) {\n    // שחרר יחידות של ResourceA\n    for (int i = 0; i < req_A; ++i) {\n        sem_post(&sem_A);\n    }\n    // שחרר יחידות של ResourceB\n    for (int i = 0; i < req_B; ++i) {\n        sem_post(&sem_B);\n    }\n    // שחרר את המקום של המשימה המקבילה\n    sem_post(&sem_concurrent);\n}\n```\n\n**ג. הסבר על מניעת קיפאון והרעבה:**\n\n**מניעת קיפאון (Deadlock Prevention):**\nקיפאון מתרחש כאשר מתקיימים ארבעה תנאים: מניעה הדדית (Mutual Exclusion), החזקה והמתנה (Hold and Wait), אי-הפקעה (No Preemption), והמתנה מעגלית (Circular Wait). הפתרון המוצע מונע קיפאון על ידי שבירת תנאי ה\"החזקה והמתנה\" וה\"המתנה מעגלית\" באופן הבא:\n\n1.  **מניעת הקצאה חלקית (Acquire All or None):** הפונקציה `acquire_resources` משתמשת בסמפור בינארי `mutex_resource_alloc` כדי להגן על קטע קריטי שבו מתבצעת הבדיקה והרכישה של המשאבים `ResourceA` ו-`ResourceB`. תהליך חייב לרכוש את `mutex_resource_alloc` לפני שהוא יכול לבדוק אם המשאבים זמינים. בתוך הקטע הקריטי, התהליך בודק אם *כל* המשאבים הנדרשים (req_A ו-req_B) זמינים באמצעות `sem_getvalue`. רק אם כל המשאבים זמינים, הוא רוכש אותם (באמצעות לולאות של `sem_wait`). אם לא כל המשאבים זמינים, התהליך משחרר את `mutex_resource_alloc` וחוזר לנסות מאוחר יותר. גישה זו מבטיחה שתהליך רוכש את כל המשאבים הנדרשים לו או אף אחד מהם, ובכך נמנע מצב של \"החזקה והמתנה\" שבו תהליך מחזיק במשאב אחד וממתין למשאב אחר, מה שיכול להוביל לקיפאון. מכיוון שרק תהליך אחד יכול לבצע את שלב הבדיקה והרכישה האטומית בכל רגע נתון, לא ייתכן מצב שבו שני תהליכים יחזיקו חלקים מהמשאבים וימתינו זה לזה באופן מעגלי.\n2.  **מניעת המתנה מעגלית (Circular Wait):** למרות שההקצאה האטומית היא המנגנון העיקרי למניעת קיפאון, אם היינו רוכשים את המשאבים בנפרד, היה נדרש סדר קבוע. בפתרון זה, הסדר שבו נרכשים `sem_A` ואז `sem_B` בתוך הקטע הקריטי תורם גם הוא למניעת המתנה מעגלית, אך כאמור, המנגנון של \"הקצה הכל או כלום\" הוא המשמעותי יותר.\n\n**מניעת הרעבה (Starvation Prevention):**\nסמפורי POSIX (כמו אלה המשמשים כאן) בדרך כלל מיישמים תור המתנה הוגן (FIFO - First-In, First-Out) עבור קריאות `sem_wait`. המשמעות היא שתהליכים שממתינים לסמפור יתעוררו בסדר שבו הם נכנסו לתור ההמתנה. זה מסייע במניעת הרעבה במספר דרכים:\n\n1.  **הוגנות ב-`sem_concurrent`:** תהליכים הממתינים למקום במגבלת המשימות המקבילות (`sem_concurrent`) יקבלו את מקומם בסדר הוגן, מה שמבטיח שכל משימה תקבל בסופו של דבר הזדמנות לנסות לרכוש משאבים.\n2.  **הוגנות ב-`mutex_resource_alloc`:** תהליכים הממתינים להיכנס לקטע הקריטי של הקצאת המשאבים (המוגן על ידי `mutex_resource_alloc`) יקבלו את הגישה בסדר הוגן. זה מבטיח שכל תהליך יקבל הזדמנות לבדוק את זמינות המשאבים.\n3.  **הוגנות בסמפורי המשאבים (`sem_A`, `sem_B`):** כאשר תהליך מצליח להיכנס לקטע הקריטי ומוצא שכל המשאבים זמינים, הוא מבצע סדרת קריאות `sem_wait` כדי לרכוש אותם. אם אחד מהסמפורים הללו נחסם, התהליך ימתין בתור הוגן.\n4.  **הפחתת Busy-Waiting:** השימוש ב-`usleep(1000)` בתוך לולאת ה-`while(1)` כאשר המשאבים אינם זמינים, מפחית את ה-busy-waiting. במקום שתהליך ינסה שוב ושוב באופן מיידי, הוא ממתין זמן קצר, מה שמפנה את המעבד לתהליכים אחרים ומאפשר למשאבים להשתחרר. זה גם נותן לתהליכים אחרים (אשר ממתינים ל-`mutex_resource_alloc`) הזדמנות לרכוש את המוטקס ולנסות את מזלם.\n\nלמרות שהפתרון אינו מבטיח מניעת הרעבה אבסולוטית (לדוגמה, תהליך הדורש כמות גדולה מאוד של משאבים עלול למצוא את עצמו ממתין זמן רב אם משימות קטנות יותר ממשיכות להגיע ולרכוש את המשאבים הזמינים), הוא מקטין משמעותית את הסיכון להרעבה על ידי שילוב של הוגנות מובנית בסמפורי POSIX והפחתת busy-waiting."}, "difficulty_estimation": "Hard", "_source_file": "0329__Semaphores__Open__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:49:37", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Semaphores", "Synchronization", "Producer-Consumer", "Concurrency"], "content": {"text": "נתונה מערכת המטפלת בתהליכי יצרן-צרכן עם חיץ מעגלי חסום בגודל `BUFFER_SIZE`.\nקיימים `P` תהליכי יצרן ו-`C` תהליכי צרכן.\nבנוסף למגבלות הסטנדרטיות של חיץ חסום, קיימת הגבלה נוספת:\nבכל רגע נתון, לכל היותר `MAX_ACTIVE_PRODUCERS` תהליכי יצרן יכולים להיות פעילים במקביל (כלומר, נמצאים בתוך הקטע הקריטי שלהם לייצור פריט, לפני ניסיון הכנסתו לחיץ).\n\nיש לממש את הפונקציות `producer_thread_func()` ו-`consumer_thread_func()` תוך שימוש בסמפורים בלבד, על מנת להבטיח:\n1. גישה בטוחה לחיץ המשותף.\n2. מניעת גלישה (overflow) ותת-גלישה (underflow) בחיץ.\n3. אכיפת המגבלה על מספר היצרנים הפעילים.\n4. מניעת מצבי קיפאון (deadlock) ורעב (starvation).\n\nיש להניח כי `BUFFER_SIZE` ו-`MAX_ACTIVE_PRODUCERS` הם קבועים גלובליים חיוביים, וכי הסמפורים הותחלו כראוי. אין צורך לממש את `produce_item()` או `consume_item()`, אלא רק את לוגיקת הסמפורים.", "code_snippet": "/* Global declarations for buffer and semaphores */\n#include <semaphore.h>\n#include <stdlib.h>\n\n#define BUFFER_SIZE 10\n#define MAX_ACTIVE_PRODUCERS 3\n\nint buffer[BUFFER_SIZE];\nint in = 0;\nint out = 0;\n\nsem_t mutex; /* For mutual exclusion to buffer */\nsem_t empty; /* Counts empty slots in buffer */\nsem_t full;  /* Counts full slots in buffer */\nsem_t active_producers_limit; /* Limits concurrent active producers */\n\n/* Assume semaphores are initialized as follows:\n * sem_init(&mutex, 0, 1);\n * sem_init(&empty, 0, BUFFER_SIZE);\n * sem_init(&full, 0, 0);\n * sem_init(&active_producers_limit, 0, MAX_ACTIVE_PRODUCERS);\n */\n\nvoid *producer_thread_func(void *arg) {\n    int item;\n    while (1) {\n        // Step 1: Limit active producers\n        // Acquire a slot to be an active producer for item production\n        sem_wait(&active_producers_limit);\n\n        // Simulate item production (critical section for production)\n        // This is the phase where the producer is \"actively trying to produce\"\n        item = rand() % 100; // Placeholder for produce_item()\n\n        // Release the active producer slot once item is produced.\n        // This allows another producer to start producing while this one waits for buffer space.\n        sem_post(&active_producers_limit);\n\n        // Step 2: Add item to buffer (standard bounded buffer logic)\n        sem_wait(&empty); // Wait for an empty slot in the buffer\n        sem_wait(&mutex); // Acquire buffer access lock\n\n        buffer[in] = item;\n        in = (in + 1) % BUFFER_SIZE;\n\n        sem_post(&mutex); // Release buffer access lock\n        sem_post(&full);  // Signal that a slot is now full\n\n        // Simulate some delay or other work after adding to buffer\n    }\n    return NULL;\n}\n\nvoid *consumer_thread_func(void *arg) {\n    int item;\n    while (1) {\n        // Step 1: Remove item from buffer (standard bounded buffer logic)\n        sem_wait(&full);  // Wait for a full slot in the buffer\n        sem_wait(&mutex); // Acquire buffer access lock\n\n        item = buffer[out];\n        out = (out + 1) % BUFFER_SIZE;\n\n        sem_post(&mutex); // Release buffer access lock\n        sem_post(&empty); // Signal that a slot is now empty\n\n        // Simulate some delay or other work after consuming\n    }\n    return NULL;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון משתמש בארבעה סמפורים:\n\n1.  `mutex` (סמפור בינארי, מאותחל ל-1): מגן על הגישה לחיץ המשותף (`buffer`, `in`, `out`) כדי להבטיח בלעדיות הדדית (mutual exclusion) בזמן הוספה או הוצאה של פריטים.\n2.  `empty` (סמפור סופר, מאותחל ל-`BUFFER_SIZE`): סופר את מספר המקומות הפנויים בחיץ. יצרנים מבצעים `sem_wait` עליו לפני הוספת פריט, וצרכנים מבצעים `sem_post` עליו לאחר הוצאת פריט.\n3.  `full` (סמפור סופר, מאותחל ל-0): סופר את מספר המקומות התפוסים בחיץ. צרכנים מבצעים `sem_wait` עליו לפני הוצאת פריט, ויצרנים מבצעים `sem_post` עליו לאחר הוספת פריט.\n4.  `active_producers_limit` (סמפור סופר, מאותחל ל-`MAX_ACTIVE_PRODUCERS`): סמפור זה אוכף את המגבלה על מספר היצרנים שיכולים להיות פעילים במקביל בשלב ייצור הפריט. יצרן מבצע `sem_wait` עליו לפני תחילת ייצור הפריט, ומבצע `sem_post` עליו מיד לאחר סיום הייצור, אך לפני הניסיון להכניס את הפריט לחיץ.\n\n**הסבר למימוש ולעמידה בדרישות:**\n\n*   **גישה בטוחה לחיץ המשותף (Mutual Exclusion):** הסמפור `mutex` מבטיח שרק תהליך אחד (יצרן או צרכן) יוכל לגשת לחיץ (`buffer`, `in`, `out`) בכל רגע נתון. הסדר של `sem_wait(&mutex)` ו-`sem_post(&mutex)` מבטיח שהקטע הקריטי (הוספה/הוצאה מהחיץ) מוגן.\n\n*   **מניעת גלישה ותת-גלישה (Overflow/Underflow):**\n    *   הסמפור `empty` מונע מיצרנים להוסיף פריטים לחיץ מלא. יצרן ייחסם על `sem_wait(&empty)` אם אין מקומות פנויים.\n    *   הסמפור `full` מונע מצרכנים להוציא פריטים מחיץ ריק. צרכן ייחסם על `sem_wait(&full)` אם אין פריטים בחיץ.\n\n*   **אכיפת המגבלה על מספר היצרנים הפעילים (`MAX_ACTIVE_PRODUCERS`):**\n    *   הסמפור `active_producers_limit` מאותחל ל-`MAX_ACTIVE_PRODUCERS`. כל יצרן שרוצה להתחיל לייצר פריט מבצע `sem_wait(&active_producers_limit)`. אם מספר היצרנים הפעילים הגיע למגבלה, יצרנים נוספים ייחסמו עד שיצרן פעיל ישחרר את הסמפור.\n    *   המיקום של `sem_post(&active_producers_limit)` מיד לאחר ייצור הפריט ולפני הגישה לחיץ הוא קריטי. הוא מאפשר ליצרן אחר להתחיל לייצר פריט חדש, גם אם היצרן הנוכחי ממתין למקום פנוי בחיץ. זה מגביר את המקביליות וממקסם את ניצולת המעבד עבור שלב הייצור.\n\n*   **מניעת מצבי קיפאון (Deadlock) ורעב (Starvation):**\n    *   הסדר הנכון של פעולות הסמפורים (`sem_wait` לפני `sem_post`, וסדר ספציפי עבור `mutex` ביחס ל-`empty`/`full`) בתבנית יצרן-צרכן הסטנדרטית מונע מצבי קיפאון.\n    *   הוספת הסמפור `active_producers_limit` אינה מציגה מצב קיפאון חדש מכיוון שהוא נרכש ומשוחרר לפני הגישה לסמפורי החיץ (`empty`, `mutex`, `full`), ובכך לא יוצר תלות מעגלית במשאבים.\n    *   השימוש בסמפורים, בהנחה שיישום `sem_wait` הוא הוגן (לרוב FIFO), מסייע במניעת רעב בכך שהוא מבטיח שבסופו של דבר כל תהליך ממתין יקבל גישה למשאב."}, "difficulty_estimation": "Hard", "_source_file": "0330__Semaphores__Open__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:50:29", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Semaphores", "Concurrency", "Resource Allocation", "Deadlock", "Starvation"], "content": {"text": "מערכת הפעלה מנהלת N תאי זיכרון רציפים (בלוקים בגודל יחידה), הממוספרים מ-0 עד N-1. תהליכים שונים צריכים להקצות בלוק של k תאי זיכרון רציפים לשימושם. כלומר, אם תהליך מבקש k תאים, הוא חייב לקבל את התאים `i, i+1, ..., i+k-1` עבור איזה `i` מתאים. לאחר שימוש, הוא משחרר את הבלוק. נניח שכל תא זיכרון מיוצג על ידי סמפור בינארי `sem_t slot_sem[N]` המאופס ל-1 בתחילת הריצה. הקוד הבא מציג ניסיון לממש את פונקציית ההקצאה `acquire_contiguous_slots(int k)`:\n\n1.  זהו את כל הבעיות בקוד המוצג (כגון תנאי מירוץ, קיפאון, רעב, חוסר יעילות). נמקו את תשובתכם.\n2.  כתבו פתרון מתוקן ומלא באמצעות סמפורים (ובמידת הצורך, מנעולים) שימנע את הבעיות שזיהיתם, ימנע קיפאון ורעב, ויאפשר מקסום מקביליות. הציגו את הקוד המלא של הפונקציות `acquire_contiguous_slots(int k)` ו-`release_contiguous_slots(int start_idx, int k)`.\n", "code_snippet": "#define N_SLOTS 10 // מספר כולל של תאי זיכרון\nsem_t slot_sem[N_SLOTS]; // סמפור בינארי לכל תא, מאותחל ל-1\n\n// פונקציית אתחול (נקראת פעם אחת בתחילת הריצה)\nvoid init_resources() {\n    for (int i = 0; i < N_SLOTS; ++i) {\n        sem_init(&slot_sem[i], 0, 1);\n    }\n}\n\n// פונקציה להקצאת k תאי זיכרון רציפים\nint acquire_contiguous_slots(int k) {\n    int start_idx = -1;\n    while (start_idx == -1) { // לולאת busy-wait\n        for (int i = 0; i <= N_SLOTS - k; ++i) {\n            bool all_acquired = true;\n            for (int j = 0; j < k; ++j) {\n                if (sem_trywait(&slot_sem[i+j]) != 0) { // ניסיון לרכוש\n                    all_acquired = false;\n                    // שחרור סמפורים שכבר נרכשו בבלוק הנוכחי\n                    for (int l = 0; l < j; ++l) {\n                        sem_post(&slot_sem[i+l]);\n                    }\n                    break;\n                }\n            }\n            if (all_acquired) {\n                start_idx = i;\n                break; // נמצא בלוק וכולו נרכש\n            }\n        }\n    }\n    return start_idx; // מחזיר את אינדקס ההתחלה של הבלוק\n}\n\n// פונקציה לשחרור k תאי זיכרון רציפים\nvoid release_contiguous_slots(int start_idx, int k) {\n    for (int j = 0; j < k; ++j) {\n        sem_post(&slot_sem[start_idx + j]);\n    }\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\n**1. זיהוי בעיות בקוד המוצג:**\n\n*   **רעב (Starvation):** תהליך עשוי לסבול מרעב. אם תהליך מנסה לרכוש בלוק של k תאים, הוא עשוי שוב ושוב למצוא בלוקים פנויים חלקית, לרכוש אותם, לשחרר אותם (כאשר הוא מגלה שאינו יכול להשלים את הבלוק כולו), ולנסות שוב. בינתיים, תהליכים אחרים (אולי כאלה שמבקשים בלוקים קטנים יותר או בלוקים אחרים) עשויים להצליח לרכוש משאבים. אין מנגנון הוגנות שמבטיח שתהליך יקבל את המשאבים בסופו של דבר.\n*   **Busy-waiting (בזבוז משאבי מעבד):** לולאת ה-`while (start_idx == -1)` החיצונית היא busy-wait. אם אין בלוק זמין באופן מיידי, התהליך ממשיך לבדוק שוב ושוב את כל הבלוקים האפשריים בלולאה אינסופית, ובכך מבזבז משאבי מעבד יקרים במקום להיכנס למצב חסימה ולהמתין לאירוע כלשהו (כמו שחרור בלוק).\n*   **חוסר יעילות:** שחרור ורכישה חוזרים ונשנים של סמפורים בתוך הלולאה הפנימית (כאשר `sem_trywait` נכשל) הוא לא יעיל. בנוסף, כל תהליך מבצע סריקה מלאה של כל תאי הזיכרון בכל איטרציה, גם אם לא היה שינוי משמעותי במצב התאים.\n*   **תנאי מירוץ (Race Conditions) לוגיים:** למרות שפעולות `sem_trywait` ו-`sem_post` הן אטומיות, הלוגיקה הכוללת של איתור בלוק פנוי ורכישתו אינה מוגנת. שני תהליכים יכולים לזהות בו-זמנית את אותו בלוק פנוי או בלוקים חופפים, מה שיוביל לכך שאחד מהם ירכוש חלקית, ישחרר וינסה שוב, או ששניהם יחמיצו בלוק שהיה זמין אם היו מתואמים. זה יכול להחמיר את בעיית הרעב.\n*   **קיפאון (Deadlock):** במקרה זה, הקוד המוצג אינו מוביל ישירות לקיפאון במובן הקלאסי של מעגל המתנה. מכיוון שהוא משתמש ב-`sem_trywait` ומשחרר משאבים מיד עם כישלון, הוא נמנע ממצב של החזקה והמתנה מעגלית. עם זאת, הוא סובל מהבעיות החמורות של רעב ובזבוז משאבים כמפורט לעיל.\n\n**2. פתרון מתוקן:**\n\nהפתרון הנכון דורש מנגנון מרכזי שיגן על תהליך האיתור וההקצאה של הבלוק הרציף. נשתמש במנעול (mutex) כדי להבטיח שרק תהליך אחד יחפש ויקצה בלוק בכל רגע נתון. בנוסף, נשתמש במערך בוליאני כדי לעקוב אחר מצב התאים (פנוי/תפוס) לצורך חיפוש יעיל.\n\n```c\n#include <semaphore.h>\n#include <pthread.h>\n#include <stdbool.h>\n#include <stdio.h>\n\n#define N_SLOTS 10 // מספר כולל של תאי זיכרון\n\nsem_t slot_sem[N_SLOTS]; // סמפור בינארי לכל תא, מאותחל ל-1\npthread_mutex_t allocation_mutex; // מנעול להגנה על לוגיקת ההקצאה/שחרור\nbool is_slot_free[N_SLOTS]; // עוקב אחר מצב פנוי/תפוס של כל תא\npthread_cond_t new_slots_available_cond; // משתנה תנאי להתראה על שחרור תאים\n\n// פונקציית אתחול (נקראת פעם אחת בתחילת הריצה)\nvoid init_resources() {\n    for (int i = 0; i < N_SLOTS; ++i) {\n        sem_init(&slot_sem[i], 0, 1); // כל סמפור מאותחל ל-1\n        is_slot_free[i] = true; // כל התאים פנויים בתחילה\n    }\n    pthread_mutex_init(&allocation_mutex, NULL); // אתחול מנעול\n    pthread_cond_init(&new_slots_available_cond, NULL); // אתחול משתנה תנאי\n}\n\n// פונקציה להקצאת k תאי זיכרון רציפים\nint acquire_contiguous_slots(int k) {\n    int start_idx = -1;\n\n    pthread_mutex_lock(&allocation_mutex); // נכנסים לאזור קריטי\n    while (start_idx == -1) {\n        // סורקים למצוא בלוק רציף פנוי\n        for (int i = 0; i <= N_SLOTS - k; ++i) {\n            bool possible = true;\n            for (int j = 0; j < k; ++j) {\n                if (!is_slot_free[i + j]) {\n                    possible = false;\n                    i = i + j; // מדלגים מעבר לבלוק תפוס\n                    break;\n                }\n            }\n            if (possible) {\n                start_idx = i;\n                // מסמנים את התאים כתפוסים במערך המעקב\n                for (int j = 0; j < k; ++j) {\n                    is_slot_free[i + j] = false;\n                }\n                break; // נמצא בלוק\n            }\n        }\n\n        if (start_idx == -1) {\n            // אם לא נמצא בלוק, ממתינים לשחרור תאים\n            pthread_cond_wait(&new_slots_available_cond, &allocation_mutex);\n        }\n    }\n    pthread_mutex_unlock(&allocation_mutex); // יוצאים מהאזור הקריטי\n\n    // כעת, כשהבלוק סומן כתפוס במערך is_slot_free, רוכשים את הסמפורים הספציפיים.\n    // אנו יודעים שהם פנויים כי ה-allocation_mutex הגן על הלוגיקה.\n    for (int j = 0; j < k; ++j) {\n        sem_wait(&slot_sem[start_idx + j]);\n    }\n\n    return start_idx;\n}\n\n// פונקציה לשחרור k תאי זיכרון רציפים\nvoid release_contiguous_slots(int start_idx, int k) {\n    if (start_idx < 0 || start_idx + k > N_SLOTS) {\n        fprintf(stderr, \"Error: Invalid release range.\\n\");\n        return;\n    }\n\n    // משחררים את הסמפורים הספציפיים\n    for (int j = 0; j < k; ++j) {\n        sem_post(&slot_sem[start_idx + j]);\n    }\n\n    pthread_mutex_lock(&allocation_mutex); // נכנסים לאזור קריטי\n    // מסמנים את התאים כפנויים במערך המעקב\n    for (int j = 0; j < k; ++j) {\n        is_slot_free[start_idx + j] = true;\n    }\n    // מודיעים לתהליכים ממתינים שאולי יש תאים פנויים כעת\n    pthread_cond_broadcast(&new_slots_available_cond); \n    pthread_mutex_unlock(&allocation_mutex); // יוצאים מהאזור הקריטי\n}\n```\n\n**הסבר לפתרון המתוקן:**\n\n1.  **מנעול `allocation_mutex`:** מנעול זה מגן על המצב המשותף של מערך `is_slot_free` ועל לוגיקת החיפוש וההקצאה. הוא מבטיח שרק תהליך אחד בכל פעם יבצע את פעולת החיפוש והסימון של הבלוקים כפנויים/תפוסים, ובכך מונע תנאי מירוץ לוגיים.\n2.  **מערך `is_slot_free`:** מערך בוליאני זה משמש למעקב מהיר ויעיל אחר מצב הפניות של כל תא זיכרון. החיפוש מתבצע על מערך זה תחת הגנת ה-`allocation_mutex`.\n3.  **משתנה תנאי `new_slots_available_cond`:** במקום busy-waiting, תהליכים שלא מוצאים בלוק פנוי נכנסים למצב חסימה באמצעות `pthread_cond_wait`. כאשר תהליך משחרר בלוק (בפונקציה `release_contiguous_slots`), הוא מאותת (באמצעות `pthread_cond_broadcast`) לכל התהליכים הממתינים שאולי יש כעת תאים פנויים, והם מתעוררים כדי לנסות שוב להקצות.\n4.  **רכישת סמפורים בודדים לאחר ההקצאה הלוגית:** לאחר שבלוק רציף זוהה וסומן כתפוס במערך `is_slot_free` (תחת הגנת ה-`allocation_mutex`), התהליך משחרר את ה-`allocation_mutex` ורק אז מבצע `sem_wait` על הסמפורים הספציפיים של התאים בבלוק. פעולה זו בטוחה מכיוון שה-`allocation_mutex` הבטיח שאף תהליך אחר לא יסמן את התאים הללו כתפוסים, ולכן הסמפורים יהיו זמינים לרכישה מיידית (או שהם כבר נרכשו על ידי תהליך זה עצמו, אם היה צורך בכך – אך במקרה זה הם תמיד יהיו זמינים כי ה-`is_slot_free` מגן על כך). גישה זו מונעת קיפאון ומאפשרת מקביליות מקסימלית על ידי כך שהיא משחררת את המנעול המרכזי בזמן השימוש בפועל במשאבים.\n5.  **מניעת רעב:** השימוש ב-`pthread_cond_wait` וב-`pthread_cond_broadcast` בשילוב עם מנעול מבטיח שכל תהליך שממתין יקבל הזדמנות לנסות להקצות בלוק כאשר משאבים משתחררים, ובכך מפחית משמעותית את הסיכון לרעב (בהתחשב בהוגנות של מתזמן התהליכים).\n6.  **יעילות:** נמנע בזבוז משאבי מעבד כתוצאה מ-busy-waiting. החיפוש הופך ליעיל יותר מכיוון שהוא מוגן ואינו מתנגש עם חיפושים של תהליכים אחרים."}, "difficulty_estimation": "Hard", "_source_file": "0331__Semaphores__Open__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:51:35", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Semaphores", "Synchronization", "Producer-Consumer", "Deadlock", "Starvation"], "content": {"text": "נתונה מערכת ייצור המורכבת משני סוגי תהליכים: `Assembler` (מרכיב) ו-`Finisher` (מסיים). תהליכים אלו משתפים ביניהם חוצץ (buffer) בגודל קבוע `BUFFER_SIZE` עבור מוצרים בהרכבה חלקית.\n\n*   **תהליכי `Assembler`:**\n    *   כל תהליך `Assembler` צריך לקבל זרוע רובוטית (`RobotArm`) כדי להרכיב מוצר חלקי. קיימות `R` זרועות רובוטיות זמינות במפעל.\n    *   לאחר הרכבת המוצר החלקי, הוא מוכנס לחוצץ.\n*   **תהליכי `Finisher`:**\n    *   כל תהליך `Finisher` מוציא מוצר חלקי מהחוצץ.\n    *   לאחר מכן, הוא צריך לקבל עמדת בקרת איכות (`QualityControlStation`) כדי לסיים את המוצר. קיימות `Q` עמדות בקרת איכות זמינות במפעל.\n\n**מגבלות נוספות:**\n1.  החוצץ יכול להכיל לכל היותר `BUFFER_SIZE` מוצרים חלקיים.\n2.  כדי למנוע עומס יתר, מספר המוצרים החלקיים הכולל בכל רגע נתון (אלו הנמצאים בחוצץ, בתוספת אלו שמטופלים כרגע על ידי תהליכי `Finisher`) מוגבל ל-`MAX_WIP`.\n\nכתבו את פונקציות `assemble_product()` ו-`finish_product()` המממשות את הלוגיקה של תהליכי ה-`Assembler` וה-`Finisher` בהתאמה, תוך שימוש בסמפורים בלבד. עליכם להגדיף את כל הסמפורים הנדרשים ולציין את ערכי האתחול שלהם.\n\n**שאלה:**\nהאם המימוש שהצעתם עלול לגרום לקיפאון (deadlock) או להרעבה (starvation)? אם כן, הסבירו מדוע וכיצד ניתן לפתור זאת. אם לא, הסבירו מדוע.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\n**הגדרת סמפורים וערכי אתחול:**\n```c\n#include <semaphore.h>\n#include <stdio.h>\n#include <stdlib.h> \n#include <pthread.h>\n#include <unistd.h> \n\n// הגדרות קבועים (לדוגמה)\n#define R 2             // מספר זרועות רובוטיות זמינות\n#define Q 1             // מספר עמדות בקרת איכות זמינות\n#define BUFFER_SIZE 5   // גודל החוצץ המשותף\n#define MAX_WIP 7       // מגבלת מוצרים בהרכבה (Work-In-Progress) הכוללת (בחוצץ + בטיפול)\n\n// סמפורים\nsem_t robotArms;        // סמפור ספירה לאתחול ב-R. שולט בגישה לזרועות רובוטיות.\nsem_t qcStations;       // סמפור ספירה לאתחול ב-Q. שולט בגישה לעמדות בקרת איכות.\nsem_t emptySlots;       // סמפור ספירה לאתחול ב-BUFFER_SIZE. מייצג מקומות פנויים בחוצץ.\nsem_t filledSlots;      // סמפור ספירה לאתחול ב-0. מייצג מקומות תפוסים בחוצץ.\nsem_t buffer_mutex;     // סמפור בינארי (mutex) לאתחול ב-1. להגנה על גישה לחוצץ.\nsem_t wip_limit;        // סמפור ספירה לאתחול ב-MAX_WIP. מגביל את כמות המוצרים בהרכבה הכוללת.\n\n// חוצץ משותף (לדוגמה, מערך פשוט)\nint buffer[BUFFER_SIZE];\nint in = 0, out = 0;\n\n// פונקציית אתחול לסמפורים (תקרא פעם אחת בתוכנית הראשית)\nvoid init_semaphores() {\n    sem_init(&robotArms, 0, R);\n    sem_init(&qcStations, 0, Q);\n    sem_init(&emptySlots, 0, BUFFER_SIZE);\n    sem_init(&filledSlots, 0, 0);\n    sem_init(&buffer_mutex, 0, 1);\n    sem_init(&wip_limit, 0, MAX_WIP);\n}\n```\n\n**פונקציות `assemble_product()` ו-`finish_product()`:**\n\n```c\nvoid assemble_product() {\n    // תהליך מרכיב (Assembler)\n    // 1. קבל חריץ במגבלת ה-WIP הכוללת (מונים מוצר זה כ-WIP מרגע שההרכבה החלה).\n    sem_wait(&wip_limit); \n\n    // 2. קבל זרוע רובוטית.\n    sem_wait(&robotArms); \n    printf(\"Assembler: Acquired Robot Arm, assembling product...\\n\");\n    // simulate_assembly(); // סימולציית הרכבה\n    // 3. שחרר זרוע רובוטית.\n    sem_post(&robotArms); \n\n    // 4. קבל חריץ פנוי בחוצץ.\n    sem_wait(&emptySlots); \n    // 5. קבל מנעול לגישה לחוצץ.\n    sem_wait(&buffer_mutex); \n\n    // הוסף פריט לחוצץ\n    buffer[in] = 1; // ייצוג פשוט של מוצר\n    in = (in + 1) % BUFFER_SIZE;\n    printf(\"Assembler: Product assembled and put into buffer. (WIP slot taken, Robot Arm used)\\n\");\n    \n    // 6. שחרר מנעול לגישה לחוצץ.\n    sem_post(&buffer_mutex); \n    // 7. אותת שהחוצץ מכיל כעת פריט נוסף.\n    sem_post(&filledSlots);  \n}\n\nvoid finish_product() {\n    // תהליך מסיים (Finisher)\n    // 1. קבל חריץ מלא מהחוצץ.\n    sem_wait(&filledSlots); \n    // 2. קבל מנעול לגישה לחוצץ.\n    sem_wait(&buffer_mutex); \n\n    // הוצא פריט מהחוצץ\n    // int product = buffer[out];\n    out = (out + 1) % BUFFER_SIZE;\n    printf(\"Finisher: Took product from buffer.\\n\");\n\n    // 3. שחרר מנעול לגישה לחוצץ.\n    sem_post(&buffer_mutex); \n    // 4. אותת שהחוצץ מכיל כעת חריץ פנוי נוסף.\n    sem_post(&emptySlots); \n\n    // 5. קבל עמדת בקרת איכות.\n    sem_wait(&qcStations); \n    printf(\"Finisher: Acquired QC Station, finishing product...\\n\");\n    // simulate_finishing(product); // סימולציית סיום\n    // 6. שחרר עמדת בקרת איכות.\n    sem_post(&qcStations); \n\n    // 7. המוצר גמור לחלוטין, שחרר את חריץ ה-WIP הגלובלי.\n    sem_post(&wip_limit); \n    printf(\"Finisher: Product finished and released. (WIP slot released, QC Station used)\\n\");\n}\n```\n\n**ניתוח קיפאון (Deadlock) והרעבה (Starvation):**\n\n**קיפאון (Deadlock):**\nהמימוש המוצע אינו צפוי לגרום לקיפאון. קיפאון נוצר כאשר קיימת תלות מעגלית במשאבים בין תהליכים. נבחן את סדר רכישת המשאבים:\n*   **תהליכי `Assembler` רוכשים משאבים בסדר הבא:** `wip_limit` -> `robotArms` (משוחרר) -> `emptySlots` -> `buffer_mutex`.\n*   **תהליכי `Finisher` רוכשים משאבים בסדר הבא:** `filledSlots` -> `buffer_mutex` -> `qcStations` (משוחרר).\n\nאין כאן תלות מעגלית ברכישת משאבים: `buffer_mutex` נרכש תמיד לאחר `emptySlots` (על ידי `Assembler`) או `filledSlots` (על ידי `Finisher`). סדר זה, יחד עם העובדה ש-`wip_limit` נרכש על ידי המרכיב ומשוחרר על ידי המסיים (ומשמש כבקרת זרימה גלובלית ולא כמשאב שנתקע במחזור), מונע מצב של קיפאון. למשל, `Assembler` לא יכול להחזיק ב-`buffer_mutex` ולחכות ל-`emptySlots` כי הוא רוכש את `emptySlots` לפני ה-`buffer_mutex`. באופן דומה, `Finisher` לא יכול להחזיק ב-`buffer_mutex` ולחכות ל-`filledSlots` מסיבה דומה.\n\n**הרעבה (Starvation):**\nמימוש סמפורים סטנדרטי (כמו זה שב-`POSIX semaphores`) בדרך כלל אינו מבטיח הוגנות (fairness) בסדר ההתעוררות של תהליכים הממתינים לסמפור. כאשר מספר תהליכים ממתינים על סמפור (באמצעות `sem_wait`) ותהליך אחר מבצע `sem_post`, מערכת ההפעלה בוחרת איזה תהליך להעיר. ייתכן מצב שבו תהליך מסוים נדחה שוב ושוב לטובת תהליכים אחרים, ובכך הוא \"מורעב\" מגישה למשאב. מצב זה יכול להתרחש עבור כל אחד מהסמפורים: `robotArms`, `qcStations`, `emptySlots`, `filledSlots`, `buffer_mutex`, ו-`wip_limit`. כדי למנוע הרעבה באופן מוחלט, נדרש מנגנון תור הוגן (כמו תור FIFO) הממומש על גבי הסמפורים, אך זהו מימוש מורכב יותר שאינו חלק משימוש בסיסי בסמפורים."}, "difficulty_estimation": "Hard", "_source_file": "0332__Semaphores__Open__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:52:21", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Semaphores", "Synchronization", "Reader-Writer Problem", "Deadlock Prevention", "Starvation Prevention"], "content": {"text": "נתונה מערכת עם משאב משותף אליו ניגשים תהליכי קוראים (Readers) ותהליכי כותבים (Writers).\nמספר קוראים יכולים לגשת למשאב בו זמנית.\nרק כותב אחד יכול לגשת למשאב בכל רגע נתון, ואין קוראים או כותבים אחרים בזמן כתיבה.\nנדרש לממש מדיניות עדיפות לכותבים: אם כותב ממתין, אף קורא חדש לא יוכל להתחיל לקרוא עד שהכותב יסיים את פעולתו (קוראים שכבר קוראים יכולים להמשיך עד לסיום).\nמדיניות זו נועדה למנוע הרעבה (Starvation) של כותבים.\n\nהשלם את קטעי הקוד הבאים עבור הפונקציות reader_task ו-writer_task תוך שימוש בסמפורים בלבד, כך שיענו על הדרישות הנ\"ל.\nהנח שהסמפורים והמשתנים הגלובליים (read_count, write_count) מוגדרים ומאותחלים כראוי.", "code_snippet": "#include <semaphore.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\n// Global semaphores and counters (to be initialized)\nsem_t resource_access;        // Controls access to the shared resource\nsem_t mutex_read_count;     // Protects read_count\nsem_t mutex_write_count;    // Protects write_count\nsem_t readers_queue_block;  // Blocks new readers if writers are waiting\n\nint read_count = 0;   // Number of readers currently reading\nint write_count = 0;  // Number of writers currently writing (should be 0 or 1)\n\n// Shared resource (simplified)\nint shared_data = 0;\n\nvoid reader_task() {\n    // TODO: Implement semaphore logic for reader\n    \n    // Critical Section: Reading\n    printf(\"Reader %lu is reading: %d\\n\", pthread_self(), shared_data);\n    sleep(1); // Simulate reading time\n    \n    // TODO: Implement semaphore logic for reader\n}\n\nvoid writer_task() {\n    // TODO: Implement semaphore logic for writer\n    \n    // Critical Section: Writing\n    shared_data++;\n    printf(\"Writer %lu is writing: %d\\n\", pthread_self(), shared_data);\n    sleep(2); // Simulate writing time\n    \n    // TODO: Implement semaphore logic for writer\n}\n\n// Main function for initialization and thread creation (not part of the answer)\n// int main() {\n//     sem_init(&resource_access, 0, 1);\n//     sem_init(&mutex_read_count, 0, 1);\n//     sem_init(&mutex_write_count, 0, 1);\n//     sem_init(&readers_queue_block, 0, 1);\n//     // ... create threads ...\n//     return 0;\n// }"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\n**1. השלמת קטעי הקוד:**\n\n```c\n#include <semaphore.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\n// Global semaphores and counters (to be initialized)\nsem_t resource_access;        // Controls access to the shared resource\nsem_t mutex_read_count;     // Protects read_count\nsem_t mutex_write_count;    // Protects write_count\nsem_t readers_queue_block;  // Blocks new readers if writers are waiting\n\nint read_count = 0;   // Number of readers currently reading\nint write_count = 0;  // Number of writers currently writing (should be 0 or 1)\n\n// Shared resource (simplified)\nint shared_data = 0;\n\nvoid reader_task() {\n    sem_wait(&readers_queue_block); // Wait if writers are waiting/writing\n    sem_wait(&mutex_read_count);\n    read_count++;\n    if (read_count == 1) { // First reader\n        sem_wait(&resource_access); // Acquire resource_access\n    }\n    sem_post(&mutex_read_count);\n    sem_post(&readers_queue_block); // Allow other readers to pass readers_queue_block\n\n    // Critical Section: Reading\n    printf(\"Reader %lu is reading: %d\\n\", pthread_self(), shared_data);\n    sleep(1); // Simulate reading time\n\n    sem_wait(&mutex_read_count);\n    read_count--;\n    if (read_count == 0) { // Last reader\n        sem_post(&resource_access); // Release resource_access\n    }\n    sem_post(&mutex_read_count);\n}\n\nvoid writer_task() {\n    sem_wait(&mutex_write_count);\n    write_count++;\n    if (write_count == 1) { // First writer\n        sem_wait(&readers_queue_block); // Block new readers from entering\n    }\n    sem_post(&mutex_write_count);\n\n    sem_wait(&resource_access); // Get exclusive access\n\n    // Critical Section: Writing\n    shared_data++;\n    printf(\"Writer %lu is writing: %d\\n\", pthread_self(), shared_data);\n    sleep(2); // Simulate writing time\n\n    sem_post(&resource_access); // Release exclusive access\n\n    sem_wait(&mutex_write_count);\n    write_count--;\n    if (write_count == 0) { // Last writer\n        sem_post(&readers_queue_block); // Allow readers to enter again\n    }\n    sem_post(&mutex_write_count);\n}\n\n// Main function for initialization and thread creation (not part of the answer)\n// int main() {\n//     sem_init(&resource_access, 0, 1);\n//     sem_init(&mutex_read_count, 0, 1);\n//     sem_init(&mutex_write_count, 0, 1);\n//     sem_init(&readers_queue_block, 0, 1);\n//     // ... create threads ...\n//     return 0;\n// }\n```\n\n**2. הסבר על הפתרון ומניעת הרעבה:**\n\nהפתרון המוצע מיישם את בעיית קוראים-כותבים בעדיפות לכותבים, תוך שימוש בארבעה סמפורים בינאריים ושני מונים גלובליים.\n\n**תפקידי הסמפורים והמשתנים הגלובליים:**\n*   `resource_access` (סמפור בינארי, מאותחל ל-1): זהו הסמפור הראשי השולט על הגישה למשאב המשותף עצמו. כותבים חייבים לבצע `sem_wait` עליו כדי לגשת למשאב באופן בלעדי. קוראים משתמשים בו באופן קולקטיבי: הקורא הראשון שנכנס מבצע `sem_wait` והקורא האחרון שיוצא מבצע `sem_post`. זה מבטיח שרק כותב אחד או מספר קוראים יכולים לגשת למשאב, אך לא שניהם יחד.\n*   `mutex_read_count` (סמפור בינארי, מאותחל ל-1): מגן על הגישה למונה `read_count`. הוא מבטיח שרק תהליך אחד בכל רגע נתון יכול לעדכן את `read_count` כדי למנוע תנאי מירוץ (Race Condition) בגישה למונה זה.\n*   `mutex_write_count` (סמפור בינארי, מאותחל ל-1): מגן על הגישה למונה `write_count`. בדומה ל-`mutex_read_count`, הוא מונע תנאי מירוץ בעת עדכון `write_count`.\n*   `readers_queue_block` (סמפור בינארי, מאותחל ל-1): זהו המנגנון העיקרי למתן עדיפות לכותבים ולמניעת הרעבתם. כותב ראשון שמגיע (כלומר `write_count` הופך ל-1) מבצע `sem_wait` על סמפור זה, ובכך חוסם כל קורא חדש מלהיכנס ללולאת הגישה למשאב. רק כאשר הכותב האחרון מסיים (כלומר `write_count` חוזר ל-0), הוא מבצע `sem_post` ובכך מאפשר לקוראים חדשים להמשיך.\n*   `read_count` (מונה שלם, מאותחל ל-0): סופר את מספר הקוראים הפעילים כרגע במשאב המשותף. כאשר הוא מגיע ל-1, הקורא הראשון מנסה לרכוש את `resource_access`. כאשר הוא מגיע ל-0, הקורא האחרון משחרר את `resource_access`.\n*   `write_count` (מונה שלם, מאותחל ל-0): סופר את מספר הכותבים הממתינים או הפעילים (בפועל, רק 0 או 1 פעילים). כאשר הוא מגיע ל-1, הכותב הראשון חוסם את `readers_queue_block`. כאשר הוא חוזר ל-0, הכותב האחרון משחרר את `readers_queue_block`.\n\n**מניעת הרעבה (Starvation) של כותבים:**\n\nהפתרון מונע הרעבה של כותבים באמצעות הסמפור `readers_queue_block` והמונה `write_count`. כאשר כותב מגיע ומגדיל את `write_count` ל-1 (כלומר, הוא הכותב הראשון שמגיע או הראשון שמתחיל לכתוב לאחר תקופה של חוסר כותבים), הוא מבצע `sem_wait(&readers_queue_block)`. פעולה זו חוסמת כל קורא עתידי מלהיכנס לאזור הקריטי של הקוראים. קוראים שכבר נמצאים באזור הקריטי ימשיכו לסיים את עבודתם, וכאשר הקורא האחרון יצא, הוא ישחרר את `resource_access`. בשלב זה, הכותב הממתין יוכל לרכוש את `resource_access` ולהתחיל לכתוב. רק לאחר שהכותב מסיים ו-`write_count` חוזר ל-0, הוא משחרר את `readers_queue_block`, מה שמאפשר לקוראים חדשים להיכנס שוב. בכך, לכותבים יש עדיפות מובהקת על פני קוראים חדשים, ומונעת מצב שבו זרם בלתי פוסק של קוראים ימנע מכותב אי פעם לגשת למשאב."}, "difficulty_estimation": "Hard", "_source_file": "0333__Semaphores__Open__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:53:00", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Semaphores", "Synchronization", "Resource Management", "Starvation Prevention", "Mutual Exclusion"], "content": {"text": "נתונה מערכת בעלת N יחידות עיבוד (לדוגמה, GPU). ישנם שני סוגי משימות:\n1.  **משימות אצווה (Batch Jobs)**: כל משימת אצווה דורשת את כל N יחידות העיבוד באופן בלעדי. רק משימת אצווה אחת יכולה לרוץ בכל רגע נתון.\n2.  **משימות אינטראקטיביות (Interactive Jobs)**: כל משימה אינטראקטיבית דורשת יחידת עיבוד אחת בלבד. מספר משימות אינטראקטיביות יכולות לרוץ במקביל, כל עוד יש יחידות פנויות.\n\nעליכם לתכנן מנגנון סנכרון באמצעות סמפורים בשפת C/C++ אשר יבטיח את הדברים הבאים:\nא.  הקצאת משאבים נכונה: משימות אצווה מקבלות את כל N היחידות, ומשימות אינטראקטיביות מקבלות יחידה אחת.\nב.  הדדיות (Mutual Exclusion): כאשר משימת אצווה רצה, אף משימה אינטראקטיבית אינה יכולה לרוץ, ולהיפך.\nג.  מניעת הרעבה (Starvation Prevention): אף סוג של משימה לא יסבול מהרעבה.\n\nיש לכלול את הגדרות הסמפורים והמשתנים הגלובליים, ואת קוד המבנה של הפונקציות עבור כל סוג משימה (acquire/release).", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\nהבעיה היא וריאציה של בעיית ה\"קוראים והכותבים\" (Readers-Writers Problem) עם העדפה לכותבים (Writer Preference), כאשר משימות אצווה הן ה\"כותבים\" ומשימות אינטראקטיביות הן ה\"קוראים\". ההבדל העיקרי הוא שמשימות אצווה דורשות את כל N היחידות באופן בלעדי, בעוד שמשימות אינטראקטיביות דורשות יחידה אחת בלבד מתוך N היחידות הזמינות. מנגנון העדפה לכותבים (משימות אצווה) מבטיח מניעת הרעבה.\n\n**הגדרות גלובליות:**\n```c\n#include <semaphore.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n\n#define N_UNITS 5 // מספר יחידות העיבוד הכולל\n\n// סמפורים\nsem_t mutex;                 // מגן על המשתנים המשותפים active_interactive_jobs ו-waiting_batch_jobs. אתחול: 1\nsem_t batch_lock;            // מנגנון הדדיות למשימות אצווה מול משימות אינטראקטיביות. אתחול: 1\nsem_t interactive_slots;     // סמפור מונה עבור N היחידות הזמינות למשימות אינטראקטיביות. אתחול: N_UNITS\nsem_t batch_turnstile;       // מנגנון תור למשימות אצווה למניעת הרעבה של משימות אצווה. אתחול: 1\n\n// משתנים משותפים\nint active_interactive_jobs = 0; // מספר משימות אינטראקטיביות פעילות כרגע\nint waiting_batch_jobs = 0;      // מספר משימות אצווה שממתינות לריצה\n```\n\n**קוד עבור משימת אצווה (Batch Job):**\n```c\nvoid batch_job_acquire() {\n    sem_wait(&batch_turnstile);   // 1. נכנסים לתור העדיפות של משימות האצווה (מונע ממשימות אינטראקטיביות חדשות להתחיל אם יש משימות אצווה שממתינות)\n    sem_wait(&mutex);              // 2. מגן על המשתנים המשותפים\n    waiting_batch_jobs++;          // 3. הגדל מונה של משימות אצווה ממתינות\n    sem_post(&mutex);              // 4. שחרר מגן על המשתנים המשותפים\n\n    sem_wait(&batch_lock);         // 5. המתן לקבלת גישה בלעדית לכל N היחידות (משימת אצווה ממתינה עד שמשימות אינטראקטיביות יסיימו)\n    \n    // *** משימת האצווה מבצעת את עבודתה ***\n    printf(\"Batch Job acquired all %d units.\\n\", N_UNITS);\n    sleep(2); // הדמיית עבודה\n    printf(\"Batch Job released all %d units.\\n\", N_UNITS);\n}\n\nvoid batch_job_release() {\n    sem_post(&batch_lock);         // 6. שחרר את הגישה הבלעדית ל-N היחידות\n\n    sem_wait(&mutex);              // 7. מגן על המשתנים המשותפים\n    waiting_batch_jobs--;          // 8. הקטן מונה של משימות אצווה ממתינות\n    sem_post(&mutex);              // 9. שחרר מגן על המשתנים המשותפים\n    sem_post(&batch_turnstile);    // 10. אפשר למשימת האצווה הבאה (או למשימה אינטראקטיבית) לנסות להיכנס\n}\n```\n\n**קוד עבור משימה אינטראקטיבית (Interactive Job):**\n```c\nvoid interactive_job_acquire() {\n    sem_wait(&batch_turnstile);    // 1. נכנסים לתור העדיפות של משימות האצווה (אם משימת אצווה ממתינה, משימה אינטראקטיבית זו תמתין)\n    sem_wait(&mutex);              // 2. מגן על המשתנים המשותפים\n    active_interactive_jobs++;     // 3. הגדל מונה של משימות אינטראקטיביות פעילות\n    if (active_interactive_jobs == 1) { // 4. אם זו המשימה האינטראקטיבית הראשונה\n        sem_wait(&batch_lock);     // 5. חסום משימות אצווה מלהיכנס\n    }\n    sem_post(&mutex);              // 6. שחרר מגן על המשתנים המשותפים\n    sem_post(&batch_turnstile);    // 7. אפשר למשימה אינטראקטיבית הבאה לנסות להיכנס\n\n    sem_wait(&interactive_slots);  // 8. רכוש יחידת עיבוד אחת\n\n    // *** המשימה האינטראקטיבית מבצעת את עבודתה ***\n    printf(\"Interactive Job acquired 1 unit.\\n\");\n    sleep(1); // הדמיית עבודה\n    printf(\"Interactive Job released 1 unit.\\n\");\n}\n\nvoid interactive_job_release() {\n    sem_post(&interactive_slots);  // 9. שחרר יחידת עיבוד אחת\n\n    sem_wait(&mutex);              // 10. מגן על המשתנים המשותפים\n    active_interactive_jobs--;     // 11. הקטן מונה של משימות אינטראקטיביות פעילות\n    if (active_interactive_jobs == 0) { // 12. אם זו המשימה האינטראקטיבית האחרונה\n        sem_post(&batch_lock);     // 13. שחרר את החסימה עבור משימות אצווה\n    }\n    sem_post(&mutex);              // 14. שחרר מגן על המשתנים המשותפים\n}\n```\n\n**הסבר:**\nהפתרון המובא מיישם את תבנית \"קוראים וכותבים עם העדפה לכותבים\", כאשר:\n*   **משימות אצווה** מתנהגות כ\"כותבים\": הן דורשות גישה בלעדית לכל המשאבים (N יחידות)..\n*   **משימות אינטראקטיביות** מתנהגות כ\"קוראים\": הן דורשות יחידה אחת בלבד ויכולות לרוץ במקביל.\n\n1.  `batch_lock`: סמפור בינארי המשמש כמנגנון ההדדיות העיקרי. כאשר משימת אצווה פעילה, היא מחזיקה ב-`batch_lock`, ובכך מונעת ממשימות אינטראקטיביות להיכנס. כאשר משימות אינטראקטיביות פעילות, המשימה האינטראקטיבית הראשונה שרוכשת משאב רוכשת את `batch_lock`, ובכך מונעת ממשימות אצווה להיכנס.\n2.  `interactive_slots`: סמפור מונה המאותחל ל-N_UNITS. הוא מאפשר למשימות אינטראקטיביות לרכוש יחידת עיבוד אחת בכל פעם, עד שמגיעים למגבלה של N יחידות.\n3.  `mutex`: סמפור בינארי המגן על הגישה למשתנים המשותפים `active_interactive_jobs` ו-`waiting_batch_jobs`, אשר סופרים את מספר המשימות הפעילות והממתינות.\n4.  `batch_turnstile`: סמפור בינארי המשמש כמנגנון תור שנותן עדיפות למשימות אצווה. משימת אצווה רוכשת אותו בתחילת דרכה, ומשחררת אותו רק לאחר שרכשה (או המתינה ל-`batch_lock`). משימות אינטראקטיביות חייבות לרכוש ולשחרר אותו גם כן. אם משימת אצווה ממתינה על `batch_turnstile`, משימות אינטראקטיביות חדשות יחסמו שם, ובכך מובטח שמשימות אצווה לא יסבלו מהרעבה ויוכלו להיכנס כאשר המשאבים יתפנו.\n\n**תהליך ריצה:**\n*   **משימת אצווה:** רוכשת את `batch_turnstile` כדי למנוע ממשימות אינטראקטיביות חדשות להיכנס. מגדילה את `waiting_batch_jobs`. ממתינה ל-`batch_lock` (כלומר, ממתינה שכל המשימות האינטראקטיביות הפעילות יסיימו). ברגע ש-`batch_lock` נרכש, היא מקבלת גישה בלעדית לכל N היחידות. בסיום, היא משחררת את `batch_lock`, מקטינה את `waiting_batch_jobs`, ומשחררת את `batch_turnstile`.\n*   **משימה אינטראקטיבית:** רוכשת את `batch_turnstile` (אם משימת אצווה ממתינה על `batch_turnstile`, היא תמתין שם). מגדילה את `active_interactive_jobs`. אם היא המשימה האינטראקטיבית הראשונה שנכנסת, היא רוכשת את `batch_lock` (ובכך חוסמת משימות אצווה מלהיכנס). משחררת את `batch_turnstile` כדי לאפשר למשימות אינטראקטיביות נוספות להיכנס. רוכשת יחידה אחת מ-`interactive_slots`. בסיום, משחררת את יחידת העיבוד, מקטינה את `active_interactive_jobs`, ואם היא המשימה האינטראקטיבית האחרונה, משחררת את `batch_lock`."}, "difficulty_estimation": "Hard", "_source_file": "0334__Semaphores__Open__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:45:28", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Semaphores", "Synchronization", "Deadlock Prevention", "Concurrency"], "content": {"text": "נתבונן במערכת הכוללת שני סוגי משאבים: R1 ו-R2. קיימים N יחידות של R1 ו-M יחידות של R2. תהליכים במערכת צריכים יחידה אחת מכל סוג משאב (יחידה אחת מ-R1 ויחידה אחת מ-R2) כדי לבצע משימה כלשהי. התהליכים מבצעים את הפעולות הבאות ברצף:\n1.  מנסים לרכוש יחידה אחת מ-R1.\n2.  מנסים לרכוש יחידה אחת מ-R2.\n3.  מבצעים את המשימה.\n4.  משחררים את היחידה מ-R1.\n5.  משחררים את היחידה מ-R2.\n\nנתון קטע הקוד הבא המדמה תהליך כזה, כאשר sem_R1 ו-sem_R2 הם סמפורים המייצגים את כמות היחידות הזמינות מכל משאב בהתאמה (ערכם ההתחלתי הוא N ו-M):\n\nא. הסבירו מדוע קיים סיכון למצב של קיפאון (Deadlock) במערכת המתוארת. תארו תרחיש ספציפי שבו יתרחש קיפאון, בהינתן N=1, M=1, ושני תהליכים שמנסים לרכוש משאבים.\nב. הציעו פתרון לבעיית הקיפאון באמצעות סמפורים נוספים או שינוי באופן השימוש בסמפורים הקיימים, כך שהתהליכים יוכלו תמיד לבצע את משימתם ללא חשש מקיפאון, תוך שמירה על רמת מקביליות סבירה. צרפו קטע קוד מתוקן המדגים את הפתרון שלכם. הסבירו מדוע הפתרון שלכם מונע קיפאון ומהם היתרונות/חסרונות של הפתרון שבחרתם.", "code_snippet": "#include <semaphore.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For usleep\n\n// Global semaphores (initialized elsewhere with N and M)\nsem_t sem_R1; // Represents available units of Resource 1\nsem_t sem_R2; // Represents available units of Resource 2\n\nvoid *process_task(void *arg) {\n    long process_id = (long)arg;\n\n    printf(\"Process %ld: Attempting to acquire R1...\\n\", process_id);\n    sem_wait(&sem_R1); // Acquire R1\n    printf(\"Process %ld: Acquired R1. Attempting to acquire R2...\\n\", process_id);\n    \n    // Simulate some delay to increase deadlock probability\n    usleep(100); \n    \n    sem_wait(&sem_R2); // Acquire R2\n    printf(\"Process %ld: Acquired R2. Performing task...\\n\", process_id);\n    \n    // Simulate task execution\n    usleep(500); \n    \n    printf(\"Process %ld: Task complete. Releasing R1 and R2...\\n\", process_id);\n    sem_post(&sem_R1); // Release R1\n    sem_post(&sem_R2); // Release R2\n    \n    printf(\"Process %ld: Resources released.\\n\", process_id);\n    return NULL;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "חלק א' - הסבר לקיפאון:\nמצב של קיפאון (Deadlock) מתרחש כאשר קבוצת תהליכים חוסמים זה את זה ללא הרף, כאשר כל תהליך בקבוצה ממתין למשאב המוחזק על ידי תהליך אחר בקבוצה. במערכת המתוארת, מתקיימים ארבעת התנאים ההכרחיים לקיפאון:\n1.  **הדרה הדדית (Mutual Exclusion):** משאבי R1 ו-R2 ניתנים לרכישה בלעדית. יחידה אחת מכל משאב יכולה להיות מוחזקת על ידי תהליך אחד בלבד בכל רגע נתון.\n2.  **החזקה והמתנה (Hold and Wait):** תהליך יכול להחזיק במשאב אחד (למשל R1) תוך כדי שהוא ממתין למשאב אחר (R2).\n3.  **אי-נשללות (No Preemption):** משאבים אינם נשללים בכוח מתהליכים שמחזיקים בהם; רק התהליך המחזיק יכול לשחררם.\n4.  **המתנה מעגלית (Circular Wait):** תרחיש ספציפי: נניח N=1, M=1 ושני תהליכים P0 ו-P1.\n    *   P0 מבצע sem_wait(&sem_R1) ומצליח לרכוש את יחידת R1.\n    *   P1 מבצע sem_wait(&sem_R2) ומצליח לרכוש את יחידת R2 (בהנחה ש-P0 עוד לא ניסה לרכוש R2, או ש-P1 רץ במקביל).\n    *   כעת, P0 מנסה לבצע sem_wait(&sem_R2) אך נחסם, כיוון ש-R2 מוחזק על ידי P1.\n    *   במקביל, P1 מנסה לבצע sem_wait(&sem_R1) אך נחסם, כיוון ש-R1 מוחזק על ידי P0.\n    *   נוצרה המתנה מעגלית: P0 ממתין ל-P1 ו-P1 ממתין ל-P0. אף אחד מהם לא ישחרר את המשאב שברשותו, והמערכת נכנסת לקיפאון.\n\nחלק ב' - פתרון והסבר:\n\nפתרון מוצע: סמפור גלובלי (Mutex) להבטחת רכישה אטומית של שני המשאבים.\nכדי למנוע קיפאון, נשבור את תנאי 'החזקה והמתנה' על ידי הבטחה שתהליך ירכוש את כל המשאבים הדרושים לו (R1 ו-R2) בפעולה אטומית, או שלא ירכוש אף אחד מהם. ניתן לעשות זאת באמצעות סמפור בינארי (mutex) נוסף, שיגן על קטע הקוד שבו מתבצעת רכישת שני המשאבים. רק תהליך אחד יוכל להיכנס לקטע קריטי זה בכל רגע נתון, ובכך למנוע מצב שבו תהליכים מחזיקים חלק מהמשאבים וממתינים לאחרים.\n\nקוד מתוקן:\n```c\n#include <semaphore.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For usleep\n\n// Global semaphores\nsem_t sem_R1; // Represents available units of Resource 1\nsem_t sem_R2; // Represents available units of Resource 2\nsem_t acquisition_mutex; // New mutex for atomic resource acquisition\n\nvoid *process_task_fixed(void *arg) {\n    long process_id = (long)arg;\n\n    printf(\"Process %ld: Attempting to acquire both R1 and R2...\\n\", process_id);\n    sem_wait(&acquisition_mutex); // Enter critical section for acquisition\n    \n    // Now acquire R1 and R2 within the mutex protection\n    sem_wait(&sem_R1); // Acquire R1\n    sem_wait(&sem_R2); // Acquire R2\n    \n    sem_post(&acquisition_mutex); // Exit critical section for acquisition\n    \n    printf(\"Process %ld: Acquired R1 and R2. Performing task...\\n\", process_id);\n    \n    // Simulate task execution\n    usleep(500); \n    \n    printf(\"Process %ld: Task complete. Releasing R1 and R2...\\n\", process_id);\n    sem_post(&sem_R1); // Release R1\n    sem_post(&sem_R2); // Release R2\n    \n    printf(\"Process %ld: Resources released.\\n\", process_id);\n    return NULL;\n}\n```\n\nהסבר מדוע הפתרון מונע קיפאון:\nהוספת הסמפור acquisition_mutex מבטיחה שרק תהליך אחד יוכל לבצע את רכישת שני המשאבים (R1 ו-R2) בו-זמנית. מרגע שתהליך נכנס לקטע הקריטי המוגן על ידי acquisition_mutex, הוא ירכוש את sem_R1 ואת sem_R2 בזה אחר זה ללא הפרעה מתהליכים אחרים המנסים לרכוש משאבים. רק לאחר שירכוש את שניהם, הוא ישחרר את acquisition_mutex ויאפשר לתהליך אחר לנסות לרכוש.\nפתרון זה שובר את תנאי 'החזקה והמתנה' (Hold and Wait) בכך שהוא מבטיח שתהליך לא יחזיק במשאב אחד (R1) וימתין לאחר (R2) כאשר תהליך אחר יכול להיות במצב דומה. במקום זאת, תהליך ימתין על acquisition_mutex עד שיוכל לרכוש את *כל* המשאבים הדרושים לו לפני שהוא משחרר את ה-mutex. אם אין מספיק משאבים זמינים, הוא ייחסם בתוך ה-mutex (על sem_R1 או sem_R2), אך כיוון שהוא היחיד שמנסה לרכוש באותו רגע, לא תיווצר המתנה מעגלית עם תהליך אחר שמחזיק משאב אחר ומונע ממנו להתקדם.\nהוא גם מונע המתנה מעגלית מכיוון שכל תהליך שמצליח להיכנס לקטע הקריטי של הרכישה מבטיח לעצמו את כל המשאבים. אין מצב שבו תהליך A מחזיק R1 ומחכה ל-R2, ותהליך B מחזיק R2 ומחכה ל-R1, כיוון שרק אחד מהם יכול להיות בקטע הרכישה בו זמנית.\n\nיתרונות וחסרונות של הפתרון:\n*   **יתרונות:**\n    *   **מניעת קיפאון מובטחת:** הפתרון אכן מונע קיפאון ביעילות במקרה זה.\n    *   **פשטות יחסית:** קל להבנה וליישום.\n*   **חסרונות:**\n    *   **הפחתת מקביליות (Reduced Concurrency):** זהו החיסרון המרכזי. רק תהליך אחד יכול לרכוש משאבים (R1 ו-R2) בכל רגע נתון, גם אם יש מספיק יחידות מכל משאב כדי לאפשר לכמה תהליכים לרכוש בו-זמנית מבלי לגרום לקיפאון. לדוגמה, אם N=10 ו-M=10, יכולים להיות 10 תהליכים שמחזיקים R1 ו-10 תהליכים שמחזיקים R2 (אם נרכשו בסדר שונה), אך הפתרון שלנו מאפשר רק לתהליך אחד לרכוש את *זוג* המשאבים בכל רגע. זה מגביל את היכולת של המערכת לנצל את המקביליות הפוטנציאלית.\n    *   **בעיית רעב (Starvation) פוטנציאלית:** אם יש תהליכים רבים, ותהליך מסוים נתקל בחסימה על sem_R1 או sem_R2 בתוך ה-mutex, הוא יחזיק את ה-mutex וימנע מכל שאר התהליכים אפילו לנסות לרכוש משאבים, עד שיצליח או ישחרר (אם היינו משתמשים ב-trywait). במקרה הנוכחי, הוא פשוט ייחסם בתוך ה-mutex על אחד מסמפורי המשאבים, מה שיכול להוביל לחוסר יעילות."}, "difficulty_estimation": "Hard", "_source_file": "0335__Semaphores__Open__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 20:54:42", "_subject": "Concurrency"}, {"id": 7, "type": "Open", "topic": ["Semaphores", "Concurrency", "Deadlock", "Synchronization"], "content": {"text": "נתבונן במערכת המדמה פס ייצור תעשייתי, הכוללת שלושה סוגי עובדים (תהליכונים) ושני חוצצים (buffers) משותפים. עובדי הרכבה (Assemblers) מרכיבים חלקים ומכניסים אותם לחוצץ החלקים המורכבים (assembled_parts_buffer). עובדי בדיקה (Testers) לוקחים חלקים מהחוצץ הראשון, בודקים אותם, ומכניסים אותם לחוצץ החלקים המבוקרים (tested_parts_buffer). לבסוף, עובדי אריזה (Packers) לוקחים חלקים מהחוצץ השני ואורזים אותם. המערכת משתמשת בסמפורים לצורך סנכרון וניהול גישה לחוצצים. גודל כל חוצץ מוגבל.\n\nלפניכם קטע קוד בשפת C/C++ המממש חלק מהלוגיקה של עובד הבדיקה (tester). קטע קוד זה מכיל פגם לוגי.\n\n", "code_snippet": "/* כלולות: <semaphore.h>, <pthread.h>, <stdio.h>, <stdlib.h>, <unistd.h> */\n\n#define BUFFER_SIZE_A 5 // גודל חוצץ חלקים מורכבים\n#define BUFFER_SIZE_T 5 // גודל חוצץ חלקים מבוקרים\n\nsem_t mutex_A, full_A, empty_A; // סמפורים לחוצץ חלקים מורכבים\nsem_t mutex_T, full_T, empty_T; // סמפורים לחוצץ חלקים מבוקרים\n\n// במציאות, אלו יהיו מבני נתונים של חוצצים. לצורך הבעיה, נשתמש במונים פשוטים.\nint assembled_parts_count = 0;\nint tested_parts_count = 0;\n\n// פונקציות assembler ו-packer לא מוצגות במלואן, אך פועלות כצרכן/יצרן סטנדרטי.\n// לדוגמה, assembler:\n/*\nvoid *assembler(void *arg) {\n    while (1) {\n        sem_wait(&empty_A);\n        sem_wait(&mutex_A);\n        assembled_parts_count++;\n        printf(\"Assembler: Added part. Total assembled: %d\\n\", assembled_parts_count);\n        sem_post(&mutex_A);\n        sem_post(&full_A);\n        // ... (השהיה וכו')\n    }\n    return NULL;\n}\n*/\n\n// פונקציית עובד הבדיקה (Tester) - מכילה את הפגם\nvoid *tester(void *arg) {\n    while (1) {\n        // שלב 1: צריכת חלק מורכב מ-assembled_parts_buffer\n        sem_wait(&full_A);  // ממתין לחלק מורכב זמין\n        sem_wait(&mutex_A); // נועל גישה לחוצץ assembled_parts_buffer\n\n        assembled_parts_count--; // צורך חלק\n        printf(\"Tester: Consumed assembled part. Remaining: %d\\n\", assembled_parts_count);\n\n        // מדמה פעולת בדיקה\n        usleep(rand() % 100000 + 50000); \n\n        // שלב 2: ייצור חלק מבוקר והכנסתו ל-tested_parts_buffer\n        // ** פגם לוגי פוטנציאלי מתרחש כאן **\n        sem_wait(&empty_T); // ממתין למקום פנוי בחוצץ tested_parts_buffer\n        sem_wait(&mutex_T); // נועל גישה לחוצץ tested_parts_buffer\n\n        // רק לאחר שקיבלנו את שני הסמפורים לחוצץ T, אנו משחררים את הסמפורים של חוצץ A.\n        sem_post(&mutex_A); // שחרור נעילה לחוצץ assembled_parts_buffer\n        sem_post(&empty_A); // איתות על מקום פנוי בחוצץ assembled_parts_buffer\n\n        tested_parts_count++; // מייצר חלק מבוקר\n        printf(\"Tester: Added tested part. Total tested: %d\\n\", tested_parts_count);\n\n        sem_post(&mutex_T); // שחרור נעילה לחוצץ tested_parts_buffer\n        sem_post(&full_T);  // איתות על חלק מבוקר זמין\n\n        usleep(rand() % 100000 + 50000);\n    }\n    return NULL;\n}", "options": null}, "sub_questions": null, "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הבעיה בקוד של פונקציית ה-`tester` היא פוטנציאל לקיפאון (Deadlock) כתוצאה מסדר שגוי של פעולות `sem_wait` ו-`sem_post`.\n\n**הסבר הקיפאון:**\n1.  **תנאים מקדימים לקיפאון:** נניח שכל המקומות ב-`tested_parts_buffer` מלאים (כלומר, `empty_T` שווה ל-0) ו/או עובדי האריזה (Packers) אינם צורכים מספיק מהר. במקביל, נניח שעובדי ההרכבה (Assemblers) מילאו את רוב ה-`assembled_parts_buffer` (כלומר, `empty_A` קרוב ל-0 או שווה לו).\n2.  **תרחיש קיפאון:**\n    *   תהליכון `tester` כלשהו מצליח לצרוך חלק מורכב מ-`assembled_parts_buffer`. הוא מבצע `sem_wait(&full_A)` ו-`sem_wait(&mutex_A)` בהצלחה, צורך את החלק, ומגיע לשלב 2 בקוד.\n    *   כעת, תהליכון ה-`tester` מנסה להכניס את החלק המבוקר ל-`tested_parts_buffer`. הוא מבצע `sem_wait(&empty_T)`. מכיוון ש-`empty_T` שווה ל-0 (בהתאם לתנאים המקדימים), תהליכון ה-`tester` נכנס למצב חסימה וממתין שמקום יתפנה ב-`tested_parts_buffer`.\n    *   **הבעיה המרכזית:** בזמן שתהליכון ה-`tester` חסום בהמתנה ל-`empty_T`, הוא עדיין מחזיק בסמפור `mutex_A` (הוא לא שחרר אותו עדיין). הוא גם מחזיק בעצם את ה\"חלק\" שצרך מ-`assembled_parts_buffer` (הוא עדיין לא ביצע `sem_post(&empty_A)`).\n    *   כתוצאה מכך:\n        *   **עובדי הרכבה (Assemblers):** אם `assembled_parts_buffer` מלא, או אם `empty_A` קרוב ל-0, עובדי ההרכבה יצטרכו לבצע `sem_wait(&empty_A)`. אם הם יצליחו, הם יצטרכו לבצע `sem_wait(&mutex_A)`. אך `mutex_A` מוחזק על ידי תהליכון ה-`tester` החסום, ולכן עובדי ההרכבה ייחסמו.\n        *   **עובדי אריזה (Packers):** כדי ש-`empty_T` יגדל ויאפשר ל-`tester` להמשיך, עובדי האריזה צריכים לצרוך חלקים מ-`tested_parts_buffer`. אך אם אין חלקים ב-`tested_parts_buffer` (כי ה-`tester` חסום ולא יכול לייצר), או אם הם צריכים לגשת ל-`mutex_T` שגם הוא עלול להיות מוחזק (אם תהליכונים אחרים של `tester` הגיעו לשלב זה וגם הם חסומים על `empty_T` או `mutex_T`), הם לא יוכלו להתקדם.\n    *   נוצר מעגל המתנה: ה-`tester` ממתין ל-`packer` שיפנה מקום ב-`tested_parts_buffer`, אך ה-`packer` לא יכול לפנות מקום כי ה-`tester` לא ייצר, וה-`tester` לא יכול לייצר כי הוא חסום על `empty_T` (תוך כדי שהוא חוסם את ה-`assemblers` מלהתקדם על ידי החזקת `mutex_A`).\n\n**התיקון המוצע:**\nהפתרון הוא לשחרר את הסמפורים של חוצץ `assembled_parts_buffer` מיד לאחר סיום השימוש בהם (כלומר, לאחר צריכת החלק המורכב), ורק לאחר מכן לנסות לרכוש את הסמפורים של חוצץ `tested_parts_buffer`. זה מבטיח שתהליכון ה-`tester` לא יחזיק נעילה מיותרת על משאב אחד (`mutex_A`) בזמן שהוא ממתין למשאב אחר (`empty_T`).\n\n**קוד מתוקן עבור פונקציית `tester`:**\n```c\nvoid *tester(void *arg) {\n    while (1) {\n        // שלב 1: צריכת חלק מורכב מ-assembled_parts_buffer\n        sem_wait(&full_A);  // ממתין לחלק מורכב זמין\n        sem_wait(&mutex_A); // נועל גישה לחוצץ assembled_parts_buffer\n\n        assembled_parts_count--; // צורך חלק\n        printf(\"Tester: Consumed assembled part. Remaining: %d\\n\", assembled_parts_count);\n\n        // שחרור הסמפורים של חוצץ A מיד לאחר השימוש בהם\n        sem_post(&mutex_A); // שחרור נעילה לחוצץ assembled_parts_buffer\n        sem_post(&empty_A); // איתות על מקום פנוי בחוצץ assembled_parts_buffer\n\n        // מדמה פעולת בדיקה\n        usleep(rand() % 100000 + 50000); \n\n        // שלב 2: ייצור חלק מבוקר והכנסתו ל-tested_parts_buffer\n        sem_wait(&empty_T); // ממתין למקום פנוי בחוצץ tested_parts_buffer\n        sem_wait(&mutex_T); // נועל גישה לחוצץ tested_parts_buffer\n\n        tested_parts_count++; // מייצר חלק מבוקר\n        printf(\"Tester: Added tested part. Total tested: %d\\n\", tested_parts_count);\n\n        sem_post(&mutex_T); // שחרור נעילה לחוצץ tested_parts_buffer\n        sem_post(&full_T);  // איתות על חלק מבוקר זמין\n\n        usleep(rand() % 100000 + 50000);\n    }\n    return NULL;\n}\n```\nתיקון זה מבטיח שהתהליכון `tester` ישחרר את המשאבים מחוצץ A לפני שהוא ינסה לרכוש משאבים מחוצץ T, ובכך מונע את התנאי המרכזי לקיפאון בשרשרת זו."}, "difficulty_estimation": "Hard", "_source_file": "0336__Semaphores__Open__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:46:06", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Concurrency", "Threads"], "content": {"text": "נתונה תוכנית C המשתמשת בסמפור (semaphore) לסנכרון גישה למשתנה גלובלי משותף. קראו את הקוד וענו על השאלה.\n\nמה יהיה הערך הסופי של המשתנה הגלובלי `global_counter` לאחר שכל ה-`NUM_THREADS` יסיימו את ריצתן?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n\n#define NUM_THREADS 5\n#define ITERATIONS_PER_THREAD 10\n\nint global_counter = 0;\nsem_t mutex;\n\nvoid *thread_function(void *arg) {\n    for (int i = 0; i < ITERATIONS_PER_THREAD; ++i) {\n        sem_wait(&mutex);\n        global_counter++;\n        sem_post(&mutex);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    // Initialize semaphore to 1 for mutual exclusion\n    sem_init(&mutex, 0, 1);\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_function, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", global_counter);\n\n    sem_destroy(&mutex);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "הסבר: הסמפור `mutex` מאותחל לערך 1 (באמצעות `sem_init(&mutex, 0, 1)`), מה שהופך אותו למעשה למנעול בינארי (mutex). כל תהליך מבצע `sem_wait` לפני הכניסה לקטע הקריטי (הגדלת `global_counter`) ו-`sem_post` לאחר היציאה ממנו. זה מבטיח שרק תהליך אחד יכול לגשת ל-`global_counter` בכל רגע נתון, ובכך מונע תנאי מירוץ (race condition).\n\nמכיוון שכל אחד מ-`NUM_THREADS` (שהוגדר כ-5) התהליכים מבצע את ההגדלה `ITERATIONS_PER_THREAD` (שהוגדר כ-10) פעמים, והגישה מוגנת באופן הנכון, הערך הסופי של `global_counter` יהיה סך כל ההגדלות, כלומר `NUM_THREADS * ITERATIONS_PER_THREAD = 5 * 10 = 50`."}, "difficulty_estimation": "Easy", "_source_file": "0337__Semaphores__CodeAnalysis__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:56:23", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Concurrency", "Threads"], "content": {"text": "נתונה תוכנית C הבאה המשתמשת בסמפורים וב-pthreads. יש לנתח את הקוד ולענות על השאלה: מה יהיה הפלט הסופי של התוכנית? הסבר מדוע.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n\n#define N_ITERATIONS 100000\n\nint counter = 0;\nsem_t mutex; // A semaphore acting as a mutex\n\nvoid* increment_thread(void* arg) {\n    for (int i = 0; i < N_ITERATIONS; ++i) {\n        sem_wait(&mutex); // Acquire lock\n        counter++;\n        sem_post(&mutex); // Release lock\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    // Initialize the semaphore to 1 (binary semaphore for mutual exclusion)\n    sem_init(&mutex, 0, 1);\n\n    pthread_create(&tid1, NULL, increment_thread, NULL);\n    pthread_create(&tid2, NULL, increment_thread, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    sem_destroy(&mutex); // Destroy the semaphore\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכנית מאתחלת מונה גלובלי (counter) ל-0 וסמפור בינארי (mutex) לערך 1. נוצרים שני תהליכונים, שניהם מריצים את הפונקציה increment_thread. כל תהליכון מבצע N_ITERATIONS פעולות הגדלה למונה. קריאות ל-sem_wait(&mutex) לפני הגדלת המונה ול-sem_post(&mutex) לאחריה מבטיחות בלעדיות הדדית (mutual exclusion), כלומר, רק תהליכון אחד יכול לגשת ולשנות את המונה בכל רגע נתון. זה מונע תנאי מירוץ (race conditions).\nמכיוון שכל אחד משני התהליכונים מגדיל את המונה N_ITERATIONS פעמים, והגישה למונה מוגנת באמצעות הסמפור, הערך הסופי של המונה יהיה סך ההגדלות שבוצעו על ידי שני התהליכונים. עם N_ITERATIONS = 100000, כל תהליכון מגדיל את המונה 100,000 פעמים. לכן, הערך הסופי של המונה יהיה 2 * 100000 = 200000.\nהתוכנית תדפיס: \"Final counter value: 200000\"."}, "difficulty_estimation": "Easy", "_source_file": "0338__Semaphores__CodeAnalysis__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:56:34", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Semaphores", "Synchronization", "Threads", "Concurrency"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בסמפור. יש לנתח את קוד התוכנית ולענות על השאלה:\n\nמהו הפלט המובטח (Guaranteed Output) של התוכנית? הסבר מדוע.\n", "code_snippet": "#include <semaphore.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n\nsem_t sem;\n\nvoid* thread_func1(void* arg) {\n    printf(\"A\\n\");\n    sem_post(&sem);\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    sem_wait(&sem);\n    printf(\"B\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    // Initialize semaphore to 0\n    sem_init(&sem, 0, 0);\n\n    pthread_create(&tid1, NULL, thread_func1, NULL);\n    pthread_create(&tid2, NULL, thread_func2, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    sem_destroy(&sem);\n\n    return 0;\n}\n", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפלט המובטח של התוכנית הוא:\nA\nB\n\nההסבר:\n1.  הסמפור 'sem' מאותחל לערך 0. המשמעות היא שבתחילה, כל קריאה ל-`sem_wait` תחסום את התהליך הקורא עד שערך הסמפור יהפוך לחיובי.\n2.  `thread_func1` (הפונקציה של tid1) מדפיסה קודם כל את התו 'A' ולאחר מכן מבצעת `sem_post(&sem)`. פעולה זו מגדילה את ערך הסמפור מ-0 ל-1 (או מכל ערך קודם ב-1).\n3.  `thread_func2` (הפונקציה של tid2) מבצעת קודם כל `sem_wait(&sem)` ולאחר מכן מדפיסה את התו 'B'.\n4.  בגלל ש-`sem_wait` ב-`thread_func2` חייבת להצליח (כלומר, ערך הסמפור חייב להיות גדול מ-0) לפני ש-`thread_func2` יכולה להמשיך ולהדפיס 'B', ופעולת ה-`sem_post` שמעלה את ערך הסמפור מתבצעת רק לאחר הדפסת 'A' ב-`thread_func1`, מובטח ש-'A' תמיד יודפס לפני 'B'.\n5.  אם `thread_func2` תנסה לבצע `sem_wait` לפני ש-`thread_func1` ביצעה `sem_post`, היא תחסם. רק לאחר ש-`thread_func1` תדפיס 'A' ותבצע `sem_post`, ערך הסמפור יעלה ל-1, ו-`thread_func2` תוכל להמשיך (לקרוא `sem_wait`, להקטין את ערך הסמפור ל-0, ואז להדפיס 'B').\n\nלכן, הסדר 'A' ואחריו 'B' מובטח."}, "difficulty_estimation": "Easy", "_source_file": "0339__Semaphores__CodeAnalysis__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:56:48", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Threads", "Concurrency"], "content": {"text": "נתונה תוכנית C המשתמשת בסמפור (Semaphore) כדי לסנכרן גישה למשתנה משותף. קראו את הקוד וענו על השאלה:\n\nמה יהיה הפלט הסופי של התוכנית? נמקו את תשובתכם.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n\n#define NUM_THREADS 2\n#define INCREMENTS_PER_THREAD 5\n\nint counter = 0;\nsem_t sem;\n\nvoid *thread_func(void *arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        sem_wait(&sem); // Wait for semaphore\n        counter++;      // Critical section\n        sem_post(&sem); // Signal semaphore\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    // Initialize semaphore to 1 (mutex)\n    sem_init(&sem, 0, 1);\n\n    // Create threads\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, NULL);\n    }\n\n    // Join threads\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    // Destroy semaphore\n    sem_destroy(&sem);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסמפור `sem` מאותחל לערך 1, מה שהופך אותו למעשה למנעול (mutex). כל חוט (thread) מבצע לולאה 5 פעמים. בכל איטרציה, הוא קורא ל-`sem_wait()` לפני הכניסה לקטע הקריטי (הגדלת `counter`) ו-`sem_post()` לאחר היציאה ממנו. פעולות אלו מבטיחות שרק חוט אחד יכול לגשת למשתנה המשותף `counter` בכל רגע נתון. כתוצאה מכך, פעולת ההגדלה `counter++` היא אטומית ומוגנת מתנאי מירוץ. מכיוון שיש 2 חוטים וכל אחד מגדיל את המונה 5 פעמים, הערך הסופי של `counter` יהיה 2 * 5 = 10. הפלט יהיה:\n`Final counter value: 10`"}, "difficulty_estimation": "Easy", "_source_file": "0340__Semaphores__CodeAnalysis__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:56:58", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Concurrency", "Threads"], "content": {"text": "נתונה תוכנית C המשתמשת בסמפור (semaphore) ובמספר תהליכונים (threads) כדי לגשת למשאב משותף. עיין בקוד המצורף וענה על השאלה:\n\nמה יהיה הערך הסופי של המשתנה `shared_resource` לאחר שכל התהליכונים יסיימו את ריצתם? הסבר מדוע.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n\n#define NUM_THREADS 5\n\nsem_t my_semaphore;\nint shared_resource = 0;\n\nvoid* thread_function(void* arg) {\n    // Wait for the semaphore\n    sem_wait(&my_semaphore);\n\n    // Critical section\n    shared_resource++;\n    printf(\"Thread %ld entered. shared_resource = %d\\n\", (long)arg, shared_resource);\n\n    // Signal the semaphore\n    sem_post(&my_semaphore);\n\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    int i;\n\n    // Initialize the semaphore to 1 (binary semaphore)\n    sem_init(&my_semaphore, 0, 1);\n\n    for (i = 0; i < NUM_THREADS; i++) {\n        pthread_create(&threads[i], NULL, thread_function, (void*)(long)i);\n    }\n\n    for (i = 0; i < NUM_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final shared_resource value: %d\\n\", shared_resource);\n\n    // Destroy the semaphore\n    sem_destroy(&my_semaphore);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הערך הסופי של המשתנה `shared_resource` יהיה 5. הסיבה לכך היא שהסמפור `my_semaphore` מאותחל לערך 1, מה שהופך אותו לסמפור בינארי (או mutex). זה מבטיח שבכל רגע נתון, רק תהליכון אחד יכול להיכנס לקטע הקריטי (החלק בקוד שבין `sem_wait` ל-`sem_post`) ולגשת למשתנה `shared_resource`. פעולת ההגדלה `shared_resource++` מתבצעת באופן אטומי עבור כל תהליכון, כך שאין אובדן של עדכונים עקב תנאי מירוץ (race conditions). מכיוון שישנם 5 תהליכונים (`NUM_THREADS` מוגדר כ-5), וכל אחד מהם מגדיל את המשתנה פעם אחת באופן בטוח, הערך הסופי יהיה 5."}, "difficulty_estimation": "Easy", "_source_file": "0341__Semaphores__CodeAnalysis__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:57:13", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Semaphores", "Synchronization", "Threads", "Concurrency"], "content": {"text": "נתונה תוכנית C המשתמשת בסמפור בינארי (binary semaphore) כדי להגן על קטע קריטי. שני תהליכונים (threads) מריצים את אותה פונקציה, שבה כל אחד מהם מגדיל מונה משותף 5 פעמים. מה יהיה הערך הסופי של המונה המשותף `counter` לאחר ששני התהליכונים יסיימו את ריצתם?", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n\n#define NUM_THREADS 2\n#define INCREMENTS_PER_THREAD 5\n\nint counter = 0;\nsem_t binary_semaphore;\n\nvoid* thread_func(void* arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        sem_wait(&binary_semaphore); // Acquire lock\n        counter++;                   // Critical section\n        sem_post(&binary_semaphore); // Release lock\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    // Initialize binary semaphore to 1 (binary semaphore acting as a mutex)\n    sem_init(&binary_semaphore, 0, 1);\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    sem_destroy(&binary_semaphore);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון:\nהתוכנית יוצרת שני תהליכונים, כאשר כל אחד מהם מבצע 5 הגדלות למונה המשותף `counter`. הסמפור הבינארי `binary_semaphore` מאותחל לערך 1, מה שאומר שהוא פועל כמו מנעול (mutex) ומבטיח שרק תהליכון אחד יכול להיכנס לקטע הקריטי (הגדלת המונה) בכל רגע נתון.\nכל קריאה ל-`sem_wait` משיגה את המנעול, וכל קריאה ל-`sem_post` משחררת אותו. כיוון שהגישה ל-`counter` מוגנת כהלכה על ידי הסמפור, כל פעולת הגדלה היא אטומית ומובטח שלא יתרחשו תנאי מרוץ (race conditions) שישנו את סדר הפעולות או יגרמו לאיבוד עדכונים.\nסה\"כ מספר ההגדלות שיבוצעו הוא: מספר התהליכונים * מספר ההגדלות לכל תהליכון = 2 * 5 = 10.\nלכן, הערך הסופי של `counter` יהיה 10."}, "difficulty_estimation": "Easy", "_source_file": "0342__Semaphores__CodeAnalysis__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:57:24", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Semaphores", "Concurrency", "Synchronization", "Threads"], "content": {"text": "נתונה תוכנית C הבאה המשתמשת בסמפורים. עיין בקוד וענה על השאלה הבאה:\n\nמהו/מהם הפלט/ים האפשרי/ים של התוכנית? נמק את תשובתך.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h> // for sleep\n\nsem_t sem;\nint counter = 0;\n\nvoid *thread_A(void *arg) {\n    // Simulate some work before incrementing\n    sleep(1);\n    counter++;\n    printf(\"Thread A: counter incremented to %d\\n\", counter);\n    sem_post(&sem);\n    return NULL;\n}\n\nvoid *thread_B(void *arg) {\n    printf(\"Thread B: Waiting for semaphore...\\n\");\n    sem_wait(&sem);\n    printf(\"Thread B: Semaphore acquired. Counter value is %d\\n\", counter);\n    return NULL;\n}\n\nint main() {\n    pthread_t tid_a, tid_b;\n\n    // Initialize semaphore to 0\n    sem_init(&sem, 0, 0);\n\n    // Create threads\n    pthread_create(&tid_b, NULL, thread_B, NULL); // Create B first\n    pthread_create(&tid_a, NULL, thread_A, NULL); // Create A second\n\n    // Wait for threads to finish\n    pthread_join(tid_a, NULL);\n    pthread_join(tid_b, NULL);\n\n    sem_destroy(&sem);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסמפור `sem` מאותחל לערך 0. המשמעות היא שכל קריאה ל-`sem_wait` תחסום את התהליך הקורא עד שקריאה ל-`sem_post` תשחרר את הסמפור.\n\nהתהליך הראשי יוצר תחילה את `thread_B` ולאחר מכן את `thread_A`.\n1.  `thread_B` מתחיל לרוץ ומיד קורא ל-`sem_wait(&sem)`. מכיוון שערך הסמפור הוא 0, `thread_B` נחסם וממתין.\n2.  `thread_A` מתחיל לרוץ. הוא מבצע `sleep(1)` (המדמה עבודה כלשהי), מגדיל את `counter` ל-1, ומדפיס את מצב המונה.\n3.  לאחר מכן, `thread_A` קורא ל-`sem_post(&sem)`. פעולה זו מגדילה את ערך הסמפור ל-1 ומשחררת את `thread_B` החסום.\n4.  `thread_B` ממשיך את ריצתו, מדפיס הודעה שהוא שוחרר ואת ערך `counter`. בנקודה זו, `counter` כבר עודכן על ידי `thread_A` ולכן ערכו יהיה 1.\n\nהפלט תמיד יציג את ערך המונה כ-1 כאשר `thread_B` מסיים את המתנתו. הסמפור מבטיח ש-`thread_B` ימתין תמיד ל-`thread_A` שיסיים את עדכון המונה וישחרר את הסמפור.\n\nהפלט האפשרי היחיד (בסדר הדפסה ספציפי) הוא:\nThread B: Waiting for semaphore...\nThread A: counter incremented to 1\nThread B: Semaphore acquired. Counter value is 1\n\nייתכן גם סדר הדפסה אחר בין שתי השורות הראשונות (בהתאם לתיזמון), אך השורה האחרונה תמיד תופיע בסוף ותציג את הערך 1."}, "difficulty_estimation": "Easy", "_source_file": "0343__Semaphores__CodeAnalysis__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:57:41", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Concurrency", "Threads"], "content": {"text": "נתונה תוכנית C המשתמשת בסמפור ובמספר תהליכים (threads). עיין בקוד וקבע מהו הערך הסופי של המשתנה המשותף `shared_counter` לאחר שכל התהליכים יסיימו את ריצתם. הסבר את תשובתך.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n\n#define NUM_THREADS 5\n\nsem_t my_semaphore;\nint shared_counter = 0;\n\nvoid* thread_func(void* arg) {\n    sem_wait(&my_semaphore); // Wait for semaphore\n    \n    // Critical section\n    shared_counter++;\n    printf(\"Thread %ld: shared_counter is now %d\\n\", (long)arg, shared_counter);\n    \n    sem_post(&my_semaphore); // Release semaphore\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    int i;\n\n    // Initialize semaphore to 1 (binary semaphore/mutex)\n    sem_init(&my_semaphore, 0, 1); \n\n    for (i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, (void*)(long)i);\n    }\n\n    for (i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final value of shared_counter: %d\\n\", shared_counter);\n\n    sem_destroy(&my_semaphore);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הערך הסופי של המשתנה `shared_counter` יהיה 5.\n\nהסבר:\nהסמפור `my_semaphore` מאותחל לערך 1 באמצעות `sem_init(&my_semaphore, 0, 1)`. אתחול זה הופך אותו לסמפור בינארי, הפועל למעשה כמו mutex (מנעול).\n\nבפונקציה `thread_func`, כל תהליך מבצע `sem_wait(&my_semaphore)` לפני שהוא נכנס לקטע הקריטי, ומבצע `sem_post(&my_semaphore)` כשהוא יוצא מהקטע הקריטי.\n\nמכיוון שהסמפור מאותחל ל-1, רק תהליך אחד יכול להיכנס לקטע הקריטי (שבו מתבצעת הפעולה `shared_counter++`) בכל רגע נתון. אם תהליך אחר ינסה להיכנס כשהסמפור תפוס, הוא ייחסם בקריאה ל-`sem_wait` עד שהתהליך הנוכחי ישחרר את הסמפור.\n\nפעולה זו מבטיחה שההגדלה של `shared_counter` היא אטומית ומוגנת מתנאי מירוץ. מכיוון שישנם `NUM_THREADS` (שהוגדר כ-5) תהליכים, וכל אחד מהם מגדיל את `shared_counter` בדיוק פעם אחת באופן מסונכרן, הערך הסופי של `shared_counter` יהיה 5."}, "difficulty_estimation": "Easy", "_source_file": "0344__Semaphores__CodeAnalysis__Easy.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 20:57:54", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Semaphores", "Concurrency", "Processes", "IPC"], "content": {"text": "נתונה תוכנית C המשתמשת בסמפור לתיאום בין תהליכים בנים. התוכנית יוצרת מספר תהליכי בן (NUM_CHILDREN = 3), וכל אחד מהם מנסה להיכנס לקטע קריטי המוגן על ידי הסמפור. לאחר הכניסה, התהליך מדפיס הודעה, מדמה עבודה, מדפיס הודעה נוספת ויוצא מהקטע הקריטי.\n\nנתחו את הקוד וענו על השאלות הבאות:", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/wait.h>\n#include <semaphore.h>\n#include <sys/mman.h> // For shared memory with semaphore\n\n#define NUM_CHILDREN 3\n\nsem_t *shared_semaphore; // Pointer to shared semaphore\n\nvoid child_task(int id) {\n    printf(\"Child %d (PID %d): Trying to access resource.\\n\", id, getpid());\n    sem_wait(shared_semaphore); // Acquire lock\n    // Critical Section\n    printf(\"Child %d (PID %d): *** Entered Critical Section ***\\n\", id, getpid());\n    sleep(1); // Simulate work\n    printf(\"Child %d (PID %d): --- Exiting Critical Section ---\\n\", id, getpid());\n    sem_post(shared_semaphore); // Release lock\n    exit(0);\n}\n\nint main() {\n    setbuf(stdout, NULL); // Disable buffering for immediate output\n\n    // Allocate shared memory for the semaphore\n    shared_semaphore = mmap(NULL, sizeof(sem_t), PROT_READ | PROT_WRITE, MAP_SHARED | MAP_ANONYMOUS, -1, 0);\n    if (shared_semaphore == MAP_FAILED) {\n        perror(\"mmap failed\");\n        return 1;\n    }\n\n    // Initialize semaphore for process sharing (1), initial value 1 (mutual exclusion)\n    if (sem_init(shared_semaphore, 1, 1) == -1) {\n        perror(\"sem_init failed\");\n        return 1;\n    }\n\n    pid_t pids[NUM_CHILDREN];\n\n    for (int i = 0; i < NUM_CHILDREN; i++) {\n        pids[i] = fork();\n        if (pids[i] == -1) {\n            perror(\"fork failed\");\n            return 1;\n        } else if (pids[i] == 0) { // Child process\n            child_task(i);\n        }\n    }\n\n    // Parent waits for all children\n    for (int i = 0; i < NUM_CHILDREN; i++) {\n        wait(NULL);\n    }\n\n    printf(\"Parent: All children finished. Cleaning up.\\n\");\n\n    // Destroy the semaphore\n    if (sem_destroy(shared_semaphore) == -1) {\n        perror(\"sem_destroy failed\");\n        return 1;\n    }\n\n    // Unmap shared memory\n    if (munmap(shared_semaphore, sizeof(sem_t)) == -1) {\n        perror(\"munmap failed\");\n        return 1;\n    }\n\n    return 0;\n}"}, "sub_questions": [{"id": "8.1", "text": "מהו פלט אפשרי אחד של התוכנית? ציינו במפורש מה מובטח לגבי סדר ההדפסות של ההודעות '*** Entered Critical Section ***' ו-'--- Exiting Critical Section ---' ביחס זו לזו, ומדוע.", "code_snippet": null, "options": null}, {"id": "8.2", "text": "אם נשנה את ערך האתחול של הסמפור מ-1 ל-NUM_CHILDREN (כלומר, sem_init(shared_semaphore, 1, NUM_CHILDREN)), כיצד זה ישפיע על הפלט ועל מאפייני התיאום בין התהליכים? האם עדיין מובטח שרק תהליך אחד יהיה בקטע הקריטי בכל רגע נתון?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "8.1. פלט אפשרי אחד של התוכנית יכול להיות כדוגמה הבאה (סדר ההודעות 'Trying to access resource' יכול להשתנות, אך סדר הכניסה/יציאה מהקטע הקריטי יהיה תמיד סדרתי):\nChild 0 (PID XXX): Trying to access resource.\nChild 1 (PID YYY): Trying to access resource.\nChild 2 (PID ZZZ): Trying to access resource.\nChild 0 (PID XXX): *** Entered Critical Section ***\nChild 0 (PID XXX): --- Exiting Critical Section ---\nChild 2 (PID ZZZ): *** Entered Critical Section ***\nChild 2 (PID ZZZ): --- Exiting Critical Section ---\nChild 1 (PID YYY): *** Entered Critical Section ***\nChild 1 (PID YYY): --- Exiting Critical Section ---\nParent: All children finished. Cleaning up.\n\nמובטח שרק תהליך אחד יכול להימצא בקטע הקריטי (בין קריאת `sem_wait` לקריאת `sem_post`) בכל רגע נתון. הסיבה לכך היא שהסמפור מאותחל לערך 1, מה שמקנה לו תכונת הדדיות (mutual exclusion). כתוצאה מכך, עבור כל תהליך בן בנפרד, ההודעה '*** Entered Critical Section ***' תמיד תודפס לפני ההודעה '--- Exiting Critical Section ---' של אותו תהליך. בנוסף, מובטח שלא תופיענה שתי הודעות '*** Entered Critical Section ***' ברצף ללא הודעת '--- Exiting Critical Section ---' ביניהן, כלומר, תמיד תהיה זוגיות של כניסה ויציאה מהקטע הקריטי, ותהליך אחד יסיים את הקטע הקריטי לפני שתהליך אחר ייכנס אליו.\n\n8.2. אם נשנה את ערך האתחול של הסמפור ל-NUM_CHILDREN (כלומר, 3), הסמפור יהפוך לסמפור סופר (counting semaphore) המאפשר עד 3 תהליכים להיכנס לקטע הקריטי בו-זמנית.\nההשפעה על הפלט תהיה שכל שלושת תהליכי הבן יוכלו לעבור את קריאת `sem_wait` כמעט מיד, ללא חסימה, ולהיכנס לקטע הקריטי שלהם במקביל. כתוצאה מכך, הפלט של ההודעות '*** Entered Critical Section ***' ו-'--- Exiting Critical Section ---' לא יהיה בהכרח סדרתי (תהליך אחד מסיים לפני שהבא נכנס). לדוגמה, ייתכן שכל שלושת תהליכי הבן ידפיסו את הודעת הכניסה לקטע הקריטי לפני שמישהו מהם ידפיס את הודעת היציאה.\nעדיין מובטח שעבור כל תהליך בן *ספציפי*, הודעת הכניסה שלו תופיע לפני הודעת היציאה שלו. אולם, *לא* מובטח שרק תהליך אחד יהיה בקטע הקריטי בכל רגע נתון; בפועל, עד שלושה תהליכים יכולים להיות שם בו-זמנית. הדדיות (mutual exclusion) אינה נשמרת במקרה זה.\nדוגמה לפלט אפשרי במקרה זה:\nChild 0 (PID XXX): Trying to access resource.\nChild 1 (PID YYY): Trying to access resource.\nChild 2 (PID ZZZ): Trying to access resource.\nChild 0 (PID XXX): *** Entered Critical Section ***\nChild 1 (PID YYY): *** Entered Critical Section ***\nChild 2 (PID ZZZ): *** Entered Critical Section ***\nChild 1 (PID YYY): --- Exiting Critical Section ---\nChild 0 (PID XXX): --- Exiting Critical Section ---\nChild 2 (PID ZZZ): --- Exiting Critical Section ---\nParent: All children finished. Cleaning up."}, "difficulty_estimation": "Medium", "_source_file": "0345__Semaphores__CodeAnalysis__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:58:25", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Semaphores", "Concurrency", "Threads", "Race Conditions"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בסמפורים להגנה על משאב משותף:\n", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n\n#define NUM_THREADS 5\n#define INCREMENTS_PER_THREAD 100000\n\nint counter = 0;\nsem_t mutex; // סמפור בינארי\n\nvoid *thread_func(void *arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        sem_wait(&mutex); // נעל את המשאב\n        counter++;        // קטע קריטי\n        sem_post(&mutex); // שחרר את המשאב\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    // אתחל את הסמפור הבינארי ל-1\n    sem_init(&mutex, 0, 1); // pshared = 0 (בין תהליכונים), value = 1\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, NULL);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    sem_destroy(&mutex); // השמד את הסמפור\n    return 0;\n}"}, "sub_questions": [{"id": "8.1", "text": "מה יהיה הערך הסופי של המונה (`counter`) לאחר שכל התהליכונים יסיימו את ריצתם? נמקו.", "code_snippet": null, "options": null}, {"id": "8.2", "text": "האם קיים תנאי מרוץ (race condition) בקטע הקוד הזה? נמקו.", "code_snippet": null, "options": null}, {"id": "8.3", "text": "נניח שהשורה `sem_init(&mutex, 0, 1);` שונתה ל-`sem_init(&mutex, 0, NUM_THREADS);`. מה יהיה טווח הערכים האפשריים לערך הסופי של המונה (`counter`)? נמקו.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  **ערך סופי של המונה:**\n    הערך הסופי של המונה יהיה `500,000`. ישנם `NUM_THREADS` (5) תהליכונים, וכל תהליכון מבצע `INCREMENTS_PER_THREAD` (100,000) הגדלות. בסך הכל יבוצעו `5 * 100,000 = 500,000` הגדלות. הסמפור `mutex` מאותחל ל-1, ומשמש כסמפור בינארי (או מיוטקס). הקריאות `sem_wait` ו-`sem_post` עוטפות כהלכה את הפעולה `counter++`, המהווה קטע קריטי. זה מבטיח שרק תהליכון אחד יכול לגשת למשתנה `counter` בכל רגע נתון, ובכך מונע אובדן עדכונים וכל ההגדלות נספרות כהלכה.\n\n2.  **תנאי מרוץ (race condition):**\n    לא, לא קיים תנאי מרוץ בקטע הקוד הזה. הפעולה `counter++` היא קטע קריטי מכיוון שהיא כוללת רצף של קריאה, שינוי וכתיבה (טעינת הערך של `counter`, הגדלתו, ואחסון הערך החדש). ללא הגנה, מספר תהליכונים יכלו לקרוא את אותו ערך, לבצע הגדלה, ולכתוב בחזרה את אותו ערך מוגדל, מה שיוביל לאובדן עדכונים. עם זאת, הקריאות ל-`sem_wait(&mutex)` ו-`sem_post(&mutex)` מבטיחות הדדיות (mutual exclusion). רק תהליכון אחד יכול לעבור בהצלחה את `sem_wait` ולהיכנס לקטע הקריטי בכל פעם. תהליכונים אחרים יחסמו עד שהסמפור ישוחרר. זה מבטיח ש-`counter++` מבוצע באופן אטומי ביחס לתהליכונים אחרים, ומונע תנאי מרוץ.\n\n3.  **שינוי אתחול הסמפור ל-`NUM_THREADS`:**\n    אם השורה `sem_init(&mutex, 0, 1);` תשונה ל-`sem_init(&mutex, 0, NUM_THREADS);` (כלומר, `sem_init(&mutex, 0, 5);`), הסמפור יהפוך לסמפור סופר (counting semaphore) שיאפשר עד 5 תהליכונים להיכנס לקטע הקריטי בו זמנית. מכיוון שישנם בדיוק 5 תהליכונים בתוכנית, זה למעשה אומר שאין הגנה של הדדיות על הפעולה `counter++`. הפעולה `counter++` אינה אטומית בפני עצמה, וכאשר מספר תהליכונים יבצעו אותה במקביל, ייווצר תנאי מרוץ. כתוצאה מכך, חלק מההגדלות ילכו לאיבוד.\n    \n    *   **הערך המקסימלי האפשרי:** `NUM_THREADS * INCREMENTS_PER_THREAD = 500,000`. זה יקרה אם, במקרה, מתזמן מערכת ההפעלה יאפשר לתהליכונים לבצע את הפעולה `counter++` בטוריות מלאה, אחד אחרי השני, ללא שילוב שלבי הקריאה/שינוי/כתיבה שלהם.\n    *   **הערך המינימלי האפשרי:** `INCREMENTS_PER_THREAD = 100,000`. זה יכול לקרות אם, עבור כל פעולת `counter++`, כל 5 התהליכונים קוראים את אותו ערך נוכחי של `counter`, ואז כולם מגדילים אותו לערך הבא, וכולם כותבים בחזרה את אותו ערך חדש. בתרחיש קיצוני זה, רק הגדלה אפקטיבית אחת תתרחש עבור כל 5 הגדלות מיועדות. לדוגמה, אם `counter` הוא 0, כל 5 התהליכונים קוראים 0, כולם מחשבים 1, וכולם כותבים 1. ערך המונה הוא כעת 1. אם דפוס זה חוזר על עצמו, לאחר 100,000 \"מחזורים\" כאלה על ידי כל תהליכון, הספירה הכוללת תהיה 100,000.\n    \n    לכן, טווח הערכים האפשריים לערך הסופי של המונה הוא `[100,000, 500,000]`."}, "difficulty_estimation": "Medium", "_source_file": "0346__Semaphores__CodeAnalysis__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:58:48", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Semaphores", "Concurrency", "Threads", "Synchronization"], "content": {"text": "נתונה התוכנית הבאה, המשתמשת בסמפור (semaphore) לצורך סנכרון בין תהליכונים (threads).\nהתוכנית יוצרת מספר תהליכונים, כאשר כל תהליכון מבצע מספר מסוים של פעולות הגדלה על משתנה גלובלי משותף `counter`.\n\nמה יהיה הערך הסופי של המשתנה `counter` לאחר שכל התהליכונים יסיימו את ריצתם? הסבירו את תשובתכם.", "code_snippet": "#include <pthread.h>\n#include <semaphore.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#define NUM_THREADS 3\n#define INCREMENTS_PER_THREAD 100000\n\nint counter = 0;\nsem_t mutex;\n\nvoid* thread_function(void* arg) {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; i++) {\n        sem_wait(&mutex); // Acquire lock\n        counter++;        // Critical section\n        sem_post(&mutex); // Release lock\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n\n    // Initialize semaphore for mutual exclusion (value = 1)\n    if (sem_init(&mutex, 0, 1) != 0) {\n        perror(\"sem_init failed\");\n        exit(EXIT_FAILURE);\n    }\n\n    // Create threads\n    for (int i = 0; i < NUM_THREADS; i++) {\n        if (pthread_create(&threads[i], NULL, thread_function, NULL) != 0) {\n            perror(\"pthread_create failed\");\n            exit(EXIT_FAILURE);\n        }\n    }\n\n    // Join threads\n    for (int i = 0; i < NUM_THREADS; i++) {\n        if (pthread_join(threads[i], NULL) != 0) {\n            perror(\"pthread_join failed\");\n            exit(EXIT_FAILURE);\n        }\n    }\n\n    // Destroy semaphore\n    sem_destroy(&mutex);\n\n    printf(\"Final counter value: %d\\n\", counter);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הערך הסופי של המשתנה `counter` יהיה 300000.\n\nהסבר:\nהתוכנית יוצרת 3 תהליכונים (`NUM_THREADS = 3`), וכל תהליכון מגדיל את המשתנה הגלובלי `counter` מספר קבוע של פעמים (`INCREMENTS_PER_THREAD = 100000`). בסך הכל, צפויות להתבצע 3 * 100000 = 300000 פעולות הגדלה.\n\nהסמפור `mutex` מאותחל לערך 1 (`sem_init(&mutex, 0, 1)`), מה שהופך אותו לסמפור בינארי (מנעול). לפני כל פעולת הגדלה של `counter`, כל תהליכון קורא ל-`sem_wait(&mutex)` כדי לנסות לרכוש את המנעול. אם המנעול זמין (ערך הסמפור הוא 1), התהליכון רוכש אותו (ערך הסמפור יורד ל-0) ונכנס לקטע הקריטי. אם המנעול אינו זמין (ערך הסמפור הוא 0), התהליכון נחסם עד שהמנעול ישוחרר.\n\nלאחר הגדלת `counter`, התהליכון קורא ל-`sem_post(&mutex)` כדי לשחרר את המנעול (ערך הסמפור עולה ל-1). מנגנון זה מבטיח שבכל רגע נתון, רק תהליכון אחד יכול לגשת ולשנות את המשתנה `counter`. הדבר מונע מצב מרוץ (race condition) ומבטיח שכל פעולות ההגדלה יתבצעו כהלכה, ושהערך הסופי של `counter` ישקף את סך כל ההגדלות שבוצעו על ידי כל התהליכונים.\n\nלכן, הערך הסופי יהיה בדיוק סכום ההגדלות: 3 * 100000 = 300000."}, "difficulty_estimation": "Medium", "_source_file": "0347__Semaphores__CodeAnalysis__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:59:01", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Semaphores", "Concurrency", "Threads"], "content": {"text": "נתונה תוכנית C המשתמשת בסמפור סופר (counting semaphore) כדי לווסת גישה למקטע קריטי (critical section) בין מספר תהליכונים (threads). עיין בקוד והשב על השאלות הבאות:\n\n1. מהו המספר המקסימלי של תהליכונים שיכולים להימצא במקטע הקריטי בו-זמנית, וכיצד נקבע מספר זה בקוד?\n2. תארו את רצף האירועים הצפוי בריצת התוכנית, ובפרט את סדר ההדפסות של כניסה ויציאה מהמקטע הקריטי, בהנחה שהמתזמן (scheduler) מעדיף תהליכונים בעלי ID נמוך יותר כאשר מספר תהליכונים מוכנים לריצה. הסבירו מדוע ייתכן שסדר היציאה לא יהיה זהה לסדר הכניסה.\n3. מה יקרה אם נשנה את ערך האתחול של הסמפור `MAX_CONCURRENT_ACCESS` ל-0? תארו את השפעת השינוי על התנהגות התוכנית.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h> // For sleep\n\n#define NUM_THREADS 10\n#define MAX_CONCURRENT_ACCESS 3 // K\n\nsem_t resource_sem;\n\nvoid *worker_thread(void *arg) {\n    long thread_id = (long)arg;\n\n    printf(\"Thread %ld: Waiting to enter critical section...\\n\", thread_id);\n    sem_wait(&resource_sem); // Acquire access\n\n    printf(\"Thread %ld: !!! Entering critical section !!!\\n\", thread_id);\n    sleep(1); // Simulate work in critical section\n    printf(\"Thread %ld: Exiting critical section.\\n\", thread_id);\n\n    sem_post(&resource_sem); // Release access\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    int i;\n\n    // Initialize the semaphore to allow MAX_CONCURRENT_ACCESS threads\n    if (sem_init(&resource_sem, 0, MAX_CONCURRENT_ACCESS) != 0) {\n        perror(\"sem_init failed\");\n        return 1;\n    }\n\n    for (i = 0; i < NUM_THREADS; i++) {\n        if (pthread_create(&threads[i], NULL, worker_thread, (void *)(long)i) != 0) {\n            perror(\"pthread_create failed\");\n            return 1;\n        }\n    }\n\n    for (i = 0; i < NUM_THREADS; i++) {\n        pthread_join(threads[i], NULL);\n    }\n\n    sem_destroy(&resource_sem); // Clean up semaphore\n    printf(\"All threads finished. Main exiting.\\n\");\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. המספר המקסימלי של תהליכונים שיכולים להימצא במקטע הקריטי בו-זמנית הוא 3. מספר זה נקבע על ידי הקבוע `MAX_CONCURRENT_ACCESS` אשר משמש כערך האתחול של הסמפור `resource_sem` בשורה `sem_init(&resource_sem, 0, MAX_CONCURRENT_ACCESS);`. סמפור סופר מאפשר למספר `MAX_CONCURRENT_ACCESS` של תהליכונים לבצע פעולת `sem_wait` בהצלחה לפני שהוא יחסום תהליכונים נוספים.\n\n2. בהנחה שהמתזמן מעדיף תהליכונים בעלי ID נמוך יותר, סדר הכניסה למקטע הקריטי יהיה בדרך כלל: Thread 0, Thread 1, Thread 2. לאחר מכן, תהליכונים אלו יתחילו לבצע את ה-\"עבודה\" שלהם (שינה למשך שנייה). בזמן זה, Thread 3 ימתין בתור לכניסה. כאשר אחד מהתהליכונים הראשונים (לדוגמה Thread 0) יסיים את עבודתו ויבצע `sem_post`, הוא ישחרר מקום במקטע הקריטי, ו-Thread 3 (או הבא בתור בעל ה-ID הנמוך ביותר) ייכנס. כתוצאה מכך, סדר הכניסה הצפוי למקטע הקריטי יהיה 0, 1, 2, ואז 3, 4, 5 וכן הלאה, בקבוצות של 3. סדר היציאה מהמקטע הקריטי אינו בהכרח זהה לסדר הכניסה. הסיבה לכך היא שכל תהליכון מבצע `sleep(1)` בתוך המקטע הקריטי, אך אין ערובה שכל התהליכונים יתחילו את ה-sleep באותו המיקרו-שנייה או שיסיימו אותו באותו סדר. יתכן ש-Thread 0 יסיים את ה-sleep ויצא לפני Thread 1 או Thread 2, גם אם הוא נכנס ראשון. לכן, סדר ההדפסות של 'Exiting critical section' יכול להיות שונה מסדר ה-'Entering critical section'.\n\n3. אם נשנה את ערך האתחול של הסמפור `MAX_CONCURRENT_ACCESS` ל-0, התוכנית תתנהג באופן שונה מהותית. כאשר הסמפור מאותחל ל-0, כל קריאה ראשונה ל-`sem_wait(&resource_sem)` תחסום את התהליכון הקורא, מכיוון שאין היתרים זמינים (הערך של הסמפור הוא 0). כתוצאה מכך, אף תהליכון לא יוכל להיכנס למקטע הקריטי. כל עשרת התהליכונים יבצעו `sem_wait` ויחסמו מיד, והם ימתינו באופן אינסופי (deadlock) מכיוון שאף אחד מהם לא יגיע ל-`sem_post` כדי לשחרר היתר ולאפשר לתהליכונים אחרים להמשיך. התוכנית תיתקע ולא תדפיס אף הודעת כניסה או יציאה מהמקטע הקריטי, למעט הודעות ההתחלה של התהליכונים."}, "difficulty_estimation": "Medium", "_source_file": "0348__Semaphores__CodeAnalysis__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:59:28", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Semaphores", "Concurrency", "Threads", "Mutual Exclusion"], "content": {"text": "נתונה תוכנית C++ המשתמשת בסמפורים (POSIX semaphores) לסנכרון גישה למשתנה משותף. התוכנית יוצרת מספר תהליכונים (threads) שכל אחד מהם מגדיל מונה גלובלי מספר פעמים. נתחו את הקוד וענו: מהו הערך הסופי של המשתנה `shared_counter` לאחר שכל התהליכונים סיימו את ריצתם? נמקו את תשובתכם והסבירו כיצד הסמפור מבטיח את הערך הנכון.", "code_snippet": "#include <iostream>\n#include <thread>\n#include <vector>\n#include <semaphore.h> // For POSIX semaphores\n\n// Global shared counter\nint shared_counter = 0;\n\n// Semaphore for mutual exclusion\nsem_t mutex;\n\n// Number of increments per thread\nconst int INCREMENTS_PER_THREAD = 100000;\n// Number of threads\nconst int NUM_THREADS = 5;\n\nvoid thread_function() {\n    for (int i = 0; i < INCREMENTS_PER_THREAD; ++i) {\n        // Acquire the semaphore (P operation)\n        sem_wait(&mutex);\n\n        // Critical section\n        shared_counter++;\n\n        // Release the semaphore (V operation)\n        sem_post(&mutex);\n    }\n}\n\nint main() {\n    // Initialize the semaphore for mutual exclusion (initial value 1)\n    // 0 means semaphore is shared between threads of a process\n    sem_init(&mutex, 0, 1);\n\n    std::vector<std::thread> threads;\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        threads.emplace_back(thread_function);\n    }\n\n    for (std::thread& t : threads) {\n        t.join();\n    }\n\n    // Destroy the semaphore\n    sem_destroy(&mutex);\n\n    std::cout << \"Final value of shared_counter: \" << shared_counter << std::endl;\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הערך הסופי של המשתנה `shared_counter` יהיה 500,000.\n\nהסבר:\n1.  המשתנה `shared_counter` הוא משאב משותף אליו ניגשים מספר תהליכונים בו-זמנית. ללא סנכרון, פעולת ההגדלה (`shared_counter++`) אינה אטומית ויכולה להוביל למצב מרוץ (race condition), שבו מספר תהליכונים קוראים את אותו ערך, מגדילים אותו, וכותבים בחזרה, וכתוצאה מכך חלק מההגדלות עלולות ללכת לאיבוד והערך הסופי יהיה שגוי.\n2.  התוכנית משתמשת בסמפור בינארי (`mutex`) שמאותחל לערך 1 (`sem_init(&mutex, 0, 1);`). סמפור בינארי עם ערך התחלתי 1 משמש כמעין מנעול (lock) להבטחת הדרה הדדית (mutual exclusion).\n3.  כל תהליכון מבצע קריאה ל-`sem_wait(&mutex)` לפני הכניסה לקטע הקריטי (השורה `shared_counter++;`) וקריאה ל-`sem_post(&mutex)` לאחר היציאה ממנו.\n4.  קריאה ל-`sem_wait` (פעולת P) מקטינה את ערך הסמפור. אם הערך הופך לשלילי, התהליכון נחסם עד שתהליכון אחר יבצע `sem_post`. זה מבטיח שרק תהליכון אחד יכול להחזיק בסמפור (ובכך להיות בקטע הקריטי) בכל רגע נתון.\n5.  קריאה ל-`sem_post` (פעולת V) מגדילה את ערך הסמפור, ומשחררת תהליכון ממתין אם יש כזה.\n6.  בזכות מנגנון ההדרה ההדדית הזה, כל פעולת הגדלה של `shared_counter` מתבצעת באופן אטומי ביחס לתהליכונים האחרים. אין שני תהליכונים שיכולים להגדיל את המונה בו-זמנית.\n7.  לכן, הערך הסופי של `shared_counter` יהיה סכום מדויק של כל ההגדלות שבוצעו על ידי כל התהליכונים.\n8.  החישוב הוא: `NUM_THREADS` (5) * `INCREMENTS_PER_THREAD` (100,000) = 500,000."}, "difficulty_estimation": "Medium", "_source_file": "0349__Semaphores__CodeAnalysis__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 20:59:47", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Semaphores", "Concurrency", "Pthreads"], "content": {"text": "נתונה התוכנית הבאה בשפת C, המשתמשת בסמפורים ובתהליכונים (pthreads). יש לנתח את הקוד ולענות על השאלות הבאות:", "code_snippet": "#include <pthread.h>\n#include <semaphore.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h> // For usleep\n\n#define NUM_THREADS 5\n#define SEM_VALUE 2 // Allow up to 2 threads concurrently\n\nsem_t my_semaphore;\nint g_critical_count = 0; // To track concurrent threads\n\nvoid* thread_func(void* arg) {\n    int id = *(int*)arg;\n    \n    printf(\"Thread %d starting...\\n\", id);\n\n    sem_wait(&my_semaphore); // Acquire semaphore\n\n    // Critical section\n    g_critical_count++;\n    printf(\"Thread %d entered critical section. Current concurrent threads: %d\\n\", id, g_critical_count);\n    usleep(100000); // Simulate work\n    g_critical_count--;\n    printf(\"Thread %d exiting critical section. Current concurrent threads: %d\\n\", id, g_critical_count);\n\n    sem_post(&my_semaphore); // Release semaphore\n\n    printf(\"Thread %d finished.\\n\", id);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    int thread_ids[NUM_THREADS];\n\n    // Initialize semaphore allowing SEM_VALUE concurrent accesses\n    if (sem_init(&my_semaphore, 0, SEM_VALUE) != 0) {\n        perror(\"sem_init failed\");\n        return 1;\n    }\n\n    printf(\"Main: Creating %d threads...\\n\", NUM_THREADS);\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        thread_ids[i] = i + 1;\n        if (pthread_create(&threads[i], NULL, thread_func, &thread_ids[i]) != 0) {\n            perror(\"pthread_create failed\");\n            return 1;\n        }\n    }\n\n    printf(\"Main: All threads created. Waiting for them to finish...\\n\");\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Main: All threads finished.\\n\");\n\n    sem_destroy(&my_semaphore); // Destroy semaphore\n    return 0;\n}"}, "sub_questions": [{"id": "1.1", "text": "מהו פלט אפשרי אחד של התוכנית? (אין צורך לרשום את כל הפלט, אלא דוגמה מייצגת של סדר האירועים וערכי המשתנים המודפסים)", "code_snippet": null, "options": null}, {"id": "1.2", "text": "מהו המספר המקסימלי של תהליכונים שיכולים להימצא בקטע הקריטי (בין קריאות sem_wait ל-sem_post) בו-זמנית? נמקו את תשובתכם.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "האם ייתכן מצב של קיפאון (deadlock) בתוכנית זו? נמקו את תשובתכם.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1. פלט אפשרי של התוכנית:\nהתוכנית יוצרת 5 תהליכונים. הסמפור my_semaphore מאותחל לערך 2. המשמעות היא שעד 2 תהליכונים יכולים להיכנס לקטע הקריטי (הקוד שבין sem_wait ל-sem_post) בו-זמנית. המשתנה g_critical_count עוקב אחר מספר התהליכונים בקטע הקריטי, ולכן ערכו המקסימלי יהיה 2. סדר ההדפסות של 'starting' ו-'finished' עבור התהליכונים יכול להשתנות, אך סדר הכניסה והיציאה מהקטע הקריטי יהיה מוגבל על ידי הסמפור. יש לזכור ש-printf אינה פעולה אטומית, וייתכנו שיבושים קלים בפלט אם שני תהליכונים מנסים להדפיס בו-זמנית, אך המבנה הכללי ישקף את ההגבלה של הסמפור.\n\nדוגמת פלט אפשרי:\nMain: Creating 5 threads...\nThread 1 starting...\nThread 2 starting...\nThread 3 starting...\nThread 4 starting...\nThread 5 starting...\nMain: All threads created. Waiting for them to finish...\nThread 1 entered critical section. Current concurrent threads: 1\nThread 2 entered critical section. Current concurrent threads: 2\nThread 1 exiting critical section. Current concurrent threads: 1\nThread 3 entered critical section. Current concurrent threads: 2\nThread 2 exiting critical section. Current concurrent threads: 1\nThread 4 entered critical section. Current concurrent threads: 2\nThread 1 finished.\nThread 3 exiting critical section. Current concurrent threads: 1\nThread 5 entered critical section. Current concurrent threads: 2\nThread 2 finished.\nThread 4 exiting critical section. Current concurrent threads: 1\nThread 3 finished.\nThread 5 exiting critical section. Current concurrent threads: 0\nThread 4 finished.\nThread 5 finished.\nMain: All threads finished.\n\n1.2. המספר המקסימלי של תהליכונים בקטע הקריטי בו-זמנית הוא 2.\nהסמפור my_semaphore מאותחל לערך SEM_VALUE, שהוא 2. המשמעות היא ששני תהליכונים יכולים לבצע sem_wait בהצלחה ולהיכנס לקטע הקריטי לפני שמישהו יבצע sem_post. ברגע ששני תהליכונים בפנים, כל תהליכון שלישי שינסה לבצע sem_wait יחסם עד שאחד מהתהליכונים שבפנים יבצע sem_post וישחרר את הסמפור. המשתנה g_critical_count, שמתעד את מספר התהליכונים בקטע הקריטי, לעולם לא יעלה על 2, מה שמוכיח את ההגבלה.\n\n1.3. לא, לא ייתכן מצב של קיפאון (deadlock) בתוכנית זו.\nכל קריאה ל-sem_wait תמיד מלווה בקריאה תואמת ל-sem_post בתוך אותה פונקציית תהליכון (thread_func). אין תרחיש שבו תהליכון רוכש את הסמפור ולא משחרר אותו (למשל, עקב מסלול שגיאה שגורם ליציאה מוקדמת או לולאה אינסופית לפני sem_post). אין כאן מספר משאבים הנרכשים בסדר שונה על ידי תהליכונים שונים, שהיא אחת הסיבות הנפוצות לקיפאון. התהליך הראשי (main) רק יוצר וממתין לתהליכונים ומעורבותו בפעולות הסמפור אינה יכולה לגרום לקיפאון עם תהליכוני העבודה. התוכנית מתוכננת בצורה כזו שכל תהליכון רוכש משאב אחד (מקום בסמפור) ומשחרר אותו באופן עקבי, מה שמונע קיפאון."}, "difficulty_estimation": "Medium", "_source_file": "0350__Semaphores__CodeAnalysis__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:00:17", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Semaphores", "Concurrency", "Threads", "Mutual Exclusion"], "content": {"text": "נתונה תוכנית C המשתמשת בסמפור בינארי על מנת להגן על קטע קריטי בו משתנה גלובלי משותף (shared_resource) מעודכן. התוכנית יוצרת 3 תהליכונים (threads) המנסים לגשת לקטע הקריטי. הקוד הבא מציג את לוגיקת התוכנית:\n\n```c\n#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h> // for sleep\n\nsem_t mutex;\nint shared_resource = 0; // A simple shared resource\n\nvoid* thread_function(void* arg) {\n    long thread_id = (long)arg;\n\n    printf(\"Thread %ld trying to enter critical section.\\n\", thread_id);\n    sem_wait(&mutex); // P operation\n\n    // Critical Section\n    shared_resource++;\n    printf(\"Thread %ld entered critical section. shared_resource = %d\\n\", thread_id, shared_resource);\n    sleep(1); // Simulate work\n    shared_resource--;\n    printf(\"Thread %ld exiting critical section. shared_resource = %d\\n\", thread_id, shared_resource);\n\n    sem_post(&mutex); // V operation\n    printf(\"Thread %ld released critical section.\\n\", thread_id);\n\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[3];\n    int i;\n\n    // Initialize semaphore with initial value 1 (for mutual exclusion)\n    sem_init(&mutex, 0, 1);\n\n    for (i = 0; i < 3; i++) {\n        pthread_create(&threads[i], NULL, thread_function, (void*)(long)i);\n    }\n\n    for (i = 0; i < 3; i++) {\n        pthread_join(threads[i], NULL);\n    }\n\n    sem_destroy(&mutex);\n    printf(\"Main: All threads finished. Final shared_resource = %d\\n\", shared_resource);\n\n    return 0;\n}\n```\n\n1. תארו פלט אפשרי אחד של התוכנית. הסבירו מדוע הוא אפשרי.\n2. מה יקרה אם נחליף את השורות `shared_resource--;` ו-`sem_post(&mutex);` כך ש-`sem_post(&mutex);` תבוצע לפני `shared_resource--;` בתוך הפונקציה `thread_function`? האם עלול להיווצר מצב מרוץ (race condition) או חוסר עקביות בנתונים? נמקו.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. **פלט אפשרי והסבר:**\nהסמפור `mutex` מאותחל לערך 1, מה שהופך אותו לסמפור בינארי המשמש להדדיות (mutual exclusion). כלומר, רק תהליכון אחד יכול להיכנס לקטע הקריטי בכל רגע נתון. הפעולה `sem_wait(&mutex)` (המקבילה ל-P) מקטינה את ערך הסמפור וממתינה אם הוא 0. הפעולה `sem_post(&mutex)` (המקבילה ל-V) מגדילה את ערך הסמפור.\nבתוך הקטע הקריטי, `shared_resource` מוגדל ואז מוקטן. מכיוון שרק תהליכון אחד יכול להיות בקטע הקריטי, ערכו של `shared_resource` יעלה ל-1 כאשר תהליכון נכנס, ויחזור ל-0 כאשר הוא יוצא. לכן, הפלט יראה שכל תהליכון נכנס ויוצא מהקטע הקריטי בנפרד, וערך `shared_resource` יהיה תמיד 1 בתוך הקטע הקריטי (לאחר ההגדלה) ו-0 מחוץ לו (לאחר ההקטנה).\n\n**פלט אפשרי לדוגמה:**\n```\nThread 0 trying to enter critical section.\nThread 1 trying to enter critical section.\nThread 2 trying to enter critical section.\nThread 0 entered critical section. shared_resource = 1\nThread 0 exiting critical section. shared_resource = 0\nThread 0 released critical section.\nThread 1 entered critical section. shared_resource = 1\nThread 1 exiting critical section. shared_resource = 0\nThread 1 released critical section.\nThread 2 entered critical section. shared_resource = 1\nThread 2 exiting critical section. shared_resource = 0\nThread 2 released critical section.\nMain: All threads finished. Final shared_resource = 0\n```\n(הערה: סדר ההודעות \"trying to enter critical section\" יכול להשתנות בהתאם לתיזמון של מתזמן התהליכונים, אך סדר הכניסה והיציאה מהקטע הקריטי יהיה מוגן על ידי הסמפור).\n\n2. **השלכות של שינוי סדר הפעולות:**\nאם נחליף את השורות `shared_resource--;` ו-`sem_post(&mutex);` כך ש-`sem_post(&mutex);` תבוצע לפני `shared_resource--;` בתוך הפונקציה `thread_function`, נקבל את הקוד הבא (באופן לוגי):\n```c\n    // ... קוד קודם ...\n    shared_resource++;\n    printf(\"Thread %ld entered critical section. shared_resource = %d\\n\", thread_id, shared_resource);\n    sleep(1); // Simulate work\n\n    sem_post(&mutex); // V operation - הסמפור משוחרר מוקדם מדי!\n    printf(\"Thread %ld released critical section (prematurely).\\n\", thread_id);\n\n    shared_resource--; // פעולה זו מתבצעת כעת מחוץ לקטע הקריטי המוגן!\n    printf(\"Thread %ld exiting critical section. shared_resource = %d\\n\", thread_id, shared_resource);\n    // ... קוד קודם ...\n```\nבמקרה כזה, התהליכון ישחרר את הסמפור (כלומר, יאפשר לתהליכון אחר להיכנס לקטע הקריטי) *לפני* שהוא מסיים את כל העבודה בקטע הקריטי (בפרט, לפני שהוא מקטין את `shared_resource`).\n\nזה יוביל ל:\n*   **מצב מרוץ (Race Condition)**: תהליכון אחד יכול לשחרר את הסמפור, ואז תהליכון אחר יכול להיכנס לקטע הקריטי ולהגדיל את `shared_resource`. אם התהליכון הראשון עדיין לא הספיק להקטין את `shared_resource` לפני שהתהליכון השני מגדיל אותו, ערכו של `shared_resource` יכול להגיע ל-2 (או יותר אם יש יותר תהליכונים), מה שמנוגד להנחת ההדדיות.\n*   **חוסר עקביות בנתונים**: ערך `shared_resource` לא יהיה מוגן כהלכה. הוא יכול להגיע לערכים גבוהים מ-1 בתוך מה שהיה אמור להיות הקטע הקריטי, ובסופו של דבר ערכו הסופי ב-`main` עשוי להיות שונה מ-0, מה שמצביע על שגיאה לוגית. לדוגמה, תהליכון A מגדיל את `shared_resource` ל-1, משחרר את הסמפור. מיד לאחר מכן, תהליכון B נכנס לקטע הקריטי ומגדיל את `shared_resource` ל-2. רק אז תהליכון A ממשיך ומקטין את `shared_resource` ל-1, ואז תהליכון B מקטין אותו ל-0. זה יוצר חוסר עקביות בזמן אמת ופוטנציאל לנתונים שגויים.\n\nהשינוי הזה למעשה מזיז את חלק מהפעולות שהיו אמורות להיות מוגנות על ידי הסמפור אל מחוץ לקטע הקריטי המוגן, ובכך מבטל את מנגנון ההדדיות הרצויה ומציג פגיעות למצבי מרוץ."}, "difficulty_estimation": "Medium", "_source_file": "0351__Semaphores__CodeAnalysis__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:00:38", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Semaphores", "Concurrency", "Threads"], "content": {"text": "נתונה התוכנית הבאה המשתמשת בסמפורים לצורך סנכרון בין שני תהליכונים (threads). ניתן להניח שכל קריאות המערכת מצליחות.", "code_snippet": "#include <pthread.h>\n#include <semaphore.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h> \n\nsem_t semA, semB;\n\nvoid *thread_A_func(void *arg) {\n    for (int i = 0; i < 3; ++i) {\n        sem_wait(&semA);\n        printf(\"A\");\n        fflush(stdout); \n        sem_post(&semB);\n    }\n    return NULL;\n}\n\nvoid *thread_B_func(void *arg) {\n    for (int i = 0; i < 3; ++i) {\n        sem_wait(&semB);\n        printf(\"B\");\n        fflush(stdout); \n        sem_post(&semA);\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t tidA, tidB;\n\n    // Initialize semaphores\n    // semA allows thread A to start (value 1)\n    // semB blocks thread B initially (value 0)\n    sem_init(&semA, 0, 1); // Line 30\n    sem_init(&semB, 0, 0); // Line 31\n\n    pthread_create(&tidA, NULL, thread_A_func, NULL);\n    pthread_create(&tidB, NULL, thread_B_func, NULL);\n\n    pthread_join(tidA, NULL);\n    pthread_join(tidB, NULL);\n\n    sem_destroy(&semA);\n    sem_destroy(&semB);\n\n    printf(\"\\n\"); \n    return 0;\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "מהו הפלט המדויק של התוכנית? נמקו את תשובתכם.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "נניח שהקריאות לאתחול הסמפורים בשורות 30 ו-31 (sem_init) היו משתנות ל- `sem_init(&semA, 0, 0);` ו- `sem_init(&semB, 0, 0);` בהתאמה. מה תהיה השפעת השינוי על ריצת התוכנית? נמקו את תשובתכם.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. התוכנית יוצרת שני תהליכונים, Thread A ו-Thread B, המשתמשים בשני סמפורים (semA, semB) כדי להבטיח סדר הדפסה מתחלף. סמפור semA מאותחל ל-1, מה שמאפשר ל-Thread A להתחיל מיד. סמפור semB מאותחל ל-0, מה שחוסם את Thread B בתחילה.\nThread A מבצע `sem_wait(&semA)`, מדפיס 'A', ואז מבצע `sem_post(&semB)`. פעולה זו מאפשרת ל-Thread B להמשיך.\nThread B מבצע `sem_wait(&semB)`, מדפיס 'B', ואז מבצע `sem_post(&semA)`. פעולה זו מאפשרת ל-Thread A להמשיך.\nהלולאה מתבצעת 3 פעמים בכל תהליכון, וכך נוצרת סדרה של הדפסות מתחלפות. הפלט המדויק יהיה: ABABAB.\n\n2. אם שני הסמפורים יאותחלו ל-0, כלומר `sem_init(&semA, 0, 0);` ו- `sem_init(&semB, 0, 0);`:\nכאשר Thread A יתחיל, הוא יבצע `sem_wait(&semA)`. מכיוון ש-semA מאותחל ל-0, Thread A יחסם מיד וימתין ש-semA יהפוך לחיובי. הוא לעולם לא יגיע לשלב של `sem_post(&semB)`.\nבאופן דומה, כאשר Thread B יתחיל, הוא יבצע `sem_wait(&semB)`. מכיוון ש-semB מאותחל ל-0, Thread B יחסם מיד וימתין ש-semB יהפוך לחיובי. הוא לעולם לא יגיע לשלב של `sem_post(&semA)`.\nכתוצאה מכך, שני התהליכונים יחסמו באופן הדדי לנצח, והתוכנית תיכנס למצב של קיפאון (deadlock) ולא תדפיס דבר."}, "difficulty_estimation": "Medium", "_source_file": "0352__Semaphores__CodeAnalysis__Medium.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:01:03", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Deadlock", "Concurrency", "Resource Management"], "content": {"text": "נתונה מערכת המכילה N יחידות ממשאב A ו-M יחידות ממשאב B (כאשר N, M > 0). קיימים K חוטי עבודה (worker threads) המנסים במקביל לרכוש יחידה אחת מכל משאב (גם A וגם B) על מנת לבצע משימה כלשהי. לאחר סיום המשימה, החוטים משחררים את המשאבים. הקוד הבא מציג את לוגיקת הרכישה והשחרור של המשאבים עבור חוט עבודה יחיד.", "code_snippet": "// גלובליים:\n// sem_t sem_A; // מאותחל ל-N\n// sem_t sem_B; // מאותחל ל-M\n\nvoid worker_thread_func_type1() {\n    // שלב 1: רכישת משאבים\n    sem_wait(&sem_A);\n    sem_wait(&sem_B);\n\n    // שלב 2: ביצוע המשימה (משתמש במשאבים A ו-B)\n    do_task(); // פונקציה המייצגת את העבודה, אינה משפיעה על הסנכרון\n\n    // שלב 3: שחרור משאבים\n    sem_post(&sem_B);\n    sem_post(&sem_A);\n}", "options": null}, "sub_questions": [{"id": "10.1", "text": "הניחו שכל K חוטי העבודה מריצים את הפונקציה `worker_thread_func_type1` בלבד. האם במצב זה עלול להיווצר קיפאון (Deadlock)? נמקו את תשובתכם.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "כעת הניחו שבמערכת קיימים שני סוגים של חוטי עבודה: סוג 1 מריץ את `worker_thread_func_type1` (כפי שמוצג לעיל), וסוג 2 מריץ את הפונקציה `worker_thread_func_type2` הבאה:\n```c\nvoid worker_thread_func_type2() {\n    sem_wait(&sem_B);\n    sem_wait(&sem_A);\n    do_task();\n    sem_post(&sem_A);\n    sem_post(&sem_B);\n}\n```\nהאם במצב זה (כאשר שני הסוגים של החוטים רצים במקביל) עלול להיווצר קיפאון? אם כן, תארו תרחיש ספציפי המוביל לקיפאון והסבירו מדוע הוא מתרחש. אם לא, נמקו מדוע.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "הציעו שינוי מינימלי בקוד של אחת הפונקציות (למשל, `worker_thread_func_type2`), או הוספת סמפור/מנעול נוסף, על מנת למנוע קיפאון במערכת המתוארת בסעיף 2, מבלי לפגוע ביעילות ובמקביליות מעבר לנדרש. הציגו את הקוד המתוקן והסבירו כיצד הוא מונע קיפאון.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון שאלה 10:\n\n**סעיף 10.1:**\nלא, במצב זה לא עלול להיווצר קיפאון. קיפאון (Deadlock) דורש קיום של ארבעה תנאים בו-זמנית: מניעה הדדית (Mutual Exclusion), החזקה והמתנה (Hold and Wait), אי-יכולת לדרוס (No Preemption), והמתנה מעגלית (Circular Wait). במקרה זה, כל חוטי העבודה רוכשים את המשאבים באותו סדר קבוע (קודם A, אחר כך B). סדר רכישה עקבי זה מונע את התנאי של המתנה מעגלית, ולכן לא יכול להתרחש קיפאון.\n\n**סעיף 10.2:**\nכן, במצב זה עלול להיווצר קיפאון. התרחיש הבא מדגים זאת:\n1. חוט עבודה מסוג 1 (T1) מבצע `sem_wait(&sem_A)` ומצליח לרכוש יחידה מ-A.\n2. חוט עבודה מסוג 2 (T2) מבצע `sem_wait(&sem_B)` ומצליח לרכוש יחידה מ-B.\n3. כעת, T1 מנסה לבצע `sem_wait(&sem_B)` אך נחסם מכיוון ש-B נרכש על ידי T2.\n4. במקביל, T2 מנסה לבצע `sem_wait(&sem_A)` אך נחסם מכיוון ש-A נרכש על ידי T1.\nשני החוטים נמצאים כעת במצב של המתנה הדדית (T1 ממתין ל-B שמוחזק על ידי T2, ו-T2 ממתין ל-A שמוחזק על ידי T1), ובכך נוצרת המתנה מעגלית והמערכת נכנסת לקיפאון.\n\n**סעיף 10.3:**\nהפתרון היעיל ביותר והמינימלי ביותר למניעת קיפאון במקרה זה הוא לכפות סדר רכישה גלובלי אחיד על כל חוטי העבודה. נתקן את הפונקציה `worker_thread_func_type2` כך שתבצע את רכישת המשאבים באותו סדר כמו `worker_thread_func_type1` (כלומר, קודם A ואז B).\n\nקוד מתוקן עבור `worker_thread_func_type2`:\n```c\nvoid worker_thread_func_type2_fixed() {\n    // שלב 1: רכישת משאבים (סדר מתוקן)\n    sem_wait(&sem_A);\n    sem_wait(&sem_B);\n\n    // שלב 2: ביצוע המשימה\n    do_task();\n\n    // שלב 3: שחרור משאבים\n    sem_post(&sem_B);\n    sem_post(&sem_A);\n}\n```\nהסבר: על ידי אכיפת סדר רכישה גלובלי אחיד (A ואז B) לכל סוגי החוטים, אנו מבטלים את האפשרות להיווצרות תנאי ההמתנה המעגלית. אם כל החוטים מנסים לרכוש את A ואז את B, חוט אחד עשוי להחזיק ב-A ולהמתין ל-B, אך אף חוט אחר לא יחזיק ב-B וימתין ל-A, מכיוון שכולם ינסו לרכוש את A תחילה. בכך נמנע הקיפאון תוך שמירה על רמת מקביליות גבוהה יחסית, שכן חוטים עדיין יכולים לעבוד במקביל כל עוד הם לא מתחרים על אותם משאבים באופן שיוצר מעגל."}, "difficulty_estimation": "Hard", "_source_file": "0353__Semaphores__CodeAnalysis__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:46:43", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Deadlock", "Resource Allocation", "Concurrency", "Threads"], "content": {"text": "נתונה בעיית הקצאת משאבים במערכת. קיימת בריכה של `NUM_RESOURCES` משאבים זהים ומוגבלים. מספר חוטים (threads) רצים במקביל, וכל חוט נדרש לתפוס `RESOURCES_PER_THREAD` משאבים, לבצע עבודה כלשהי, ולאחר מכן לשחרר את כל המשאבים שתפס.\nלהלן קטע קוד המנסה לממש את לוגיקת העבודה של חוט כזה. שימו לב לערכים של `NUM_RESOURCES`, `RESOURCES_PER_THREAD` ו-`NUM_THREADS`.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h> // For sleep\n\n#define NUM_RESOURCES 5       // Total available resources\n#define RESOURCES_PER_THREAD 3 // Resources each thread needs\n#define NUM_THREADS 3        // Number of threads attempting to acquire resources\n\nsem_t resource_pool; // Initialized to NUM_RESOURCES\n\nvoid* worker_thread(void* arg) {\n    int thread_id = *(int*)arg;\n    printf(\"Thread %d: Attempting to acquire %d resources...\\n\", thread_id, RESOURCES_PER_THREAD);\n\n    for (int i = 0; i < RESOURCES_PER_THREAD; ++i) {\n        sem_wait(&resource_pool);\n        printf(\"Thread %d: Acquired resource #%d.\\n\", thread_id, i + 1);\n        // Introduce a small delay to increase deadlock probability\n        usleep(10000); \n    }\n\n    printf(\"Thread %d: All %d resources acquired. Working...\\n\", thread_id, RESOURCES_PER_THREAD);\n    sleep(1); // Simulate work\n    \n    printf(\"Thread %d: Releasing %d resources.\\n\", thread_id, RESOURCES_PER_THREAD);\n    for (int i = 0; i < RESOURCES_PER_THREAD; ++i) {\n        sem_post(&resource_pool);\n    }\n    return NULL;\n}\n\nint main() {\n    sem_init(&resource_pool, 0, NUM_RESOURCES); // Initialize semaphore with total resources\n\n    pthread_t threads[NUM_THREADS];\n    int tids[NUM_THREADS];\n\n    printf(\"System initialized with %d total resources. Each thread needs %d resources.\\n\", NUM_RESOURCES, RESOURCES_PER_THREAD);\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        tids[i] = i;\n        pthread_create(&threads[i], NULL, worker_thread, &tids[i]);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"All threads finished.\\n\");\n    sem_destroy(&resource_pool);\n    return 0;\n}"}, "sub_questions": [{"id": "10.1", "text": "האם קטע הקוד הנתון יכול להוביל לקיפאון (Deadlock)? אם כן, תארו תרחיש ספציפי (לפי סדר פעולות החוטים) שמוביל לקיפאון והסבירו מדוע הוא מתרחש.", "code_snippet": null, "options": null}, {"id": "10.2", "text": "הציעו תיקון לבעיה שתיארתם בסעיף הקודם. צרפו את קטע הקוד המתוקן עבור הפונקציה `worker_thread` בלבד (כולל הצהרה על משתנים גלובליים חדשים אם נדרש), והסבירו את התיקון שהצעתם.", "code_snippet": null, "options": null}, {"id": "10.3", "text": "האם התיקון שהצעתם בסעיף 2 עלול להציג בעיות חדשות (כגון הרעבה (Starvation) או חוסר יעילות) או טרייד-אופים מסוימים? נמקו.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "סעיף 1: קיפאון (Deadlock)\nכן, קטע הקוד הנתון עלול להוביל לקיפאון.\n\n**תרחיש לדוגמה:**\nבהינתן:\n*   `NUM_RESOURCES = 5` (סה\"כ משאבים זמינים)\n*   `RESOURCES_PER_THREAD = 3` (משאבים שכל חוט צריך)\n*   `NUM_THREADS = 3` (מספר החוטים)\n\n1.  **חוט 0** מבצע `sem_wait` פעם אחת, תופס משאב 1. סמפור `resource_pool` כעת 4.\n2.  **חוט 1** מבצע `sem_wait` פעם אחת, תופס משאב 1. סמפור `resource_pool` כעת 3.\n3.  **חוט 2** מבצע `sem_wait` פעם אחת, תופס משאב 1. סמפור `resource_pool` כעת 2.\n4.  **חוט 0** מבצע `sem_wait` פעם שנייה, תופס משאב 1. סמפור `resource_pool` כעת 1.\n5.  **חוט 1** מבצע `sem_wait` פעם שנייה, תופס משאב 1. סמפור `resource_pool` כעת 0.\n\nבשלב זה, חוט 0 מחזיק 2 משאבים וממתין למשאב שלישי. חוט 1 מחזיק 2 משאבים וממתין למשאב שלישי. חוט 2 מחזיק משאב 1 וממתין למשאב שני.\nהסמפור `resource_pool` הגיע ל-0, כלומר אין יותר משאבים פנויים.\nאף אחד מהחוטים לא יכול להמשיך לתפוס את המשאבים הנותרים לו, ולכן אף אחד מהם לא יכול לשחרר את המשאבים שהוא מחזיק כרגע. נוצר מעגל המתנה (circular wait) בין החוטים, וכולם נשארים חסומים לצמיתות. זהו מצב של קיפאון.\n\nסעיף 2: תיקון מוצע\nכדי למנוע קיפאון במקרה זה, יש לוודא שחוט רוכש את כל המשאבים הנדרשים לו באופן אטומי, או שהוא לא רוכש אף אחד מהם. אחת הדרכים לעשות זאת היא להשתמש במנעול (mutex) נוסף שיגן על שלב רכישת המשאבים. המנעול מבטיח שרק חוט אחד יוכל לנסות לרכוש משאבים בכל רגע נתון.\n\n**קוד מתוקן עבור `worker_thread`:**\n```c\n// הגדרה גלובלית של המנעול החדש\npthread_mutex_t acquisition_lock = PTHREAD_MUTEX_INITIALIZER;\n\nvoid* worker_thread(void* arg) {\n    int thread_id = *(int*)arg;\n    printf(\"Thread %d: Attempting to acquire %d resources (using mutex for atomicity)...\\n\", thread_id, RESOURCES_PER_THREAD);\n\n    // תפוס את המנעול כדי להבטיח רכישה אטומית של כל המשאבים\n    pthread_mutex_lock(&acquisition_lock);\n\n    // המתן לכל המשאבים בזה אחר זה בתוך המנעול\n    for (int i = 0; i < RESOURCES_PER_THREAD; ++i) {\n        sem_wait(&resource_pool); // עלול לחסום כאן, אך המנעול מוחזק\n        printf(\"Thread %d: Acquired resource #%d within mutex.\\n\", thread_id, i + 1);\n        usleep(10000); \n    }\n    \n    // שחרר את המנעול רק לאחר שכל המשאבים נרכשו בהצלחה\n    pthread_mutex_unlock(&acquisition_lock);\n\n    printf(\"Thread %d: All %d resources acquired. Working...\\n\", thread_id, RESOURCES_PER_THREAD);\n    sleep(1); // Simulate work\n    \n    printf(\"Thread %d: Releasing %d resources.\\n\", thread_id, RESOURCES_PER_THREAD);\n    for (int i = 0; i < RESOURCES_PER_THREAD; ++i) {\n        sem_post(&resource_pool);\n    }\n    return NULL;\n}\n// הערה: ב-main() יש לוודא אתחול ושיחרור המנעול: pthread_mutex_init(&acquisition_lock, NULL); ו- pthread_mutex_destroy(&acquisition_lock);\n```\n**הסבר לתיקון:**\nהוספנו מנעול גלובלי (`acquisition_lock`) המגן על הלולאה שבה החוטים רוכשים את המשאבים. כאשר חוט נכנס ללולאת הרכישה, הוא תופס את המנעול `acquisition_lock`. רק לאחר שרכש בהצלחה את כל `RESOURCES_PER_THREAD` המשאבים (כלומר, כל קריאות `sem_wait` בלולאה הסתיימו בהצלחה), הוא משחרר את המנעול.\nגישה זו מונעת קיפאון מכיוון שהיא מבטיחה שרק חוט אחד יכול להימצא בשלב \"ניסיון רכישת כל המשאבים\" בכל רגע נתון. אם חוט מתחיל לרכוש משאבים, אף חוט אחר לא יכול להתחיל תהליך רכישה משלו עד שהחוט הראשון יסיים או יקבל את כל המשאבים שלו וישחרר את המנעול. זה מונע הקצאה חלקית של משאבים לחוטים מרובים שעלולה להוביל למעגל המתנה.\n\nסעיף 3: טרייד-אופים ובעיות פוטנציאליות\nהתיקון שהוצע אכן מונע קיפאון, אך הוא מציג מספר טרייד-אופים ובעיות פוטנציאליות:\n\n1.  **ירידה במקביליות (Reduced Concurrency):** התיקון הופך את שלב רכישת המשאבים לטורי (sequential). רק חוט אחד יכול להיכנס לקטע הקריטי המוגן על ידי `acquisition_lock` ולנסות לרכוש משאבים. גם אם יש מספיק משאבים פנויים בבריכה עבור חוט אחר, הוא לא יוכל להתחיל לרכוש אותם עד שהחוט הנוכחי יסיים את רכישת כל המשאבים שלו וישחרר את `acquisition_lock`. זה עלול להפחית משמעותית את רמת המקביליות וניצול המשאבים במערכת.\n2.  **חוסר יעילות (Inefficiency):** אם חוט תופס את `acquisition_lock` ונקלע למצב שבו הוא ממתין על `sem_wait` (כי אין מספיק משאבים זמינים), הוא ימשיך להחזיק את `acquisition_lock`. במצב כזה, כל שאר החוטים שינסו לרכוש משאבים ייחסמו על `pthread_mutex_lock` ולא יוכלו אפילו לנסות לרכוש משאבים, גם אם חלקם פנויים. זה מבזבז זמן מעבד ומעכב חוטים אחרים שלא לצורך.\n3.  **פוטנציאל להרעבה (Potential for Starvation):** למרות שהפתרון מונע קיפאון, הוא עלול להוביל להרעבה בתרחישים מסוימים. אם יש זרם קבוע של חוטים שמבקשים משאבים, והחוטים שנבחרים על ידי המתזמן (scheduler) הם תמיד אלו שזקוקים למספר רב של משאבים או נתקעים בהמתנה ארוכה בתוך הקטע הקריטי, חוטים אחרים שזקוקים למעט משאבים או יכולים לסיים מהר עלולים להמתין זמן רב באופן בלתי מוגבל.\n\nלסיכום, בעוד שהתיקון מונע קיפאון בצורה יעילה, הוא עושה זאת במחיר של הגבלת המקביליות ופוטנציאל לחוסר יעילות, במיוחד במערכות עם דרישות משאבים מגוונות או עומס גבוה."}, "difficulty_estimation": "Hard", "_source_file": "0354__Semaphores__CodeAnalysis__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:02:18", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Concurrency", "Threads", "Barrier"], "content": {"text": "נתון מימוש של מחסום (Barrier) עבור N_THREADS חוטים, המיועד לשימוש חוזר (reusable barrier). המחסום אמור להבטיח שכל החוטים יגיעו לנקודה מסוימת בתוכנית לפני שמי מהם יוכל להמשיך הלאה. לאחר שכולם עברו, המחסום אמור להתאפס ולהיות מוכן לשימוש חוזר.\n\nיש לנתח את קוד המחסום הנתון ולזהות האם הוא פועל באופן תקין. אם כן, הסבירו מדוע. אם לא, תארו בפירוט את התרחיש הבעייתי (Race Condition / Deadlock / Starvation) והסבירו מדוע הוא מתרחש. בנוסף, הציעו תיקון לקוד שיפתור את הבעיה תוך שימוש בסמפורים בלבד.", "code_snippet": "#include <pthread.h>\n#include <semaphore.h>\n#include <stdio.h>\n#include <unistd.h>\n\n#define N_THREADS 5 // מספר החוטים המשתתפים במחסום\n\nsem_t mutex;         // מנעול להגנה על המונה\nsem_t barrier_sem;   // סמפור לחסימת חוטים\nint count = 0;       // מונה חוטים שהגיעו למחסום\n\nvoid barrier_init() {\n    sem_init(&mutex, 0, 1);\n    sem_init(&barrier_sem, 0, 0); // מאותחל ל-0, כך שחוטים יחסמו מיד\n    count = 0;\n}\n\nvoid barrier_wait() {\n    sem_wait(&mutex);\n    count++;\n    if (count == N_THREADS) {\n        // החוט האחרון שהגיע משחרר את כל החוטים\n        for (int i = 0; i < N_THREADS; ++i) {\n            sem_post(&barrier_sem);\n        }\n        count = 0; // איפוס המונה עבור שימוש חוזר במחסום\n    }\n    sem_post(&mutex);\n\n    sem_wait(&barrier_sem); // כל החוטים ממתינים כאן\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "המימוש הנתון של המחסום אינו פועל באופן תקין לשימוש חוזר. הוא סובל מבעיית \"מצב מרוץ\" (Race Condition) שעלולה לגרום לחוטים לעבור את המחסום בטרם עת, מבלי להמתין לשאר החוטים, ובכך מפרה את תכונת המחסום.\n\n**תיאור התרחיש הבעייתי (Race Condition):**\nנניח ש-N_THREADS = 2 (שני חוטים, T1 ו-T2). המחסום אמור לוודא ששניהם יגיעו לנקודה מסוימת לפני שימשיכו.\n\n1.  T1 קורא ל-`barrier_wait()`: נועל את `mutex`, `count` הופך ל-1, ומשחרר את `mutex`.\n2.  T2 קורא ל-`barrier_wait()`: נועל את `mutex`, `count` הופך ל-2.\n3.  `count == N_THREADS` מתקיים. T2 נכנס לבלוק ה-`if`.\n4.  T2 מבצע לולאה וקורא ל-`sem_post(&barrier_sem)` פעמיים. כעת ערך `barrier_sem` הוא 2.\n5.  T2 מיד מאפס את המונה: `count = 0;`.\n6.  T2 משחרר את `mutex`.\n7.  גם T1 וגם T2 ממשיכים לקרוא ל-`sem_wait(&barrier_sem)`. שניהם יעברו בהצלחה, וערך `barrier_sem` יחזור ל-0.\n8.  **הנקודה הקריטית:** נניח ש-T2 הוא חוט מהיר במיוחד. מיד לאחר שעבר את `sem_wait(&barrier_sem)` עבור המחזור הראשון של המחסום, הוא קורא שוב ל-`barrier_wait()` עבור המחזור השני.\n9.  T2 נועל את `mutex`, `count` הופך ל-1, ומשחרר את `mutex`.\n10. בינתיים, T1 הוא חוט איטי. ייתכן שהוא עדיין מבצע עיבוד כלשהו לאחר שעבר את המחסום הראשון, או שהוא עדיין בדרך לקריאה ל-`barrier_wait()` עבור המחזור השני.\n11. אם T2 ממשיך בריצתו המהירה ומגיע שוב למצב שבו `count == N_THREADS` (לדוגמה, אם T1 עדיין לא הגיע למחסום השני ו-T2 הוא החוט היחיד שהספיק להתקדם), T2 שוב יבצע `sem_post(&barrier_sem)` פעמיים ויאפס את `count`.\n12. כתוצאה מכך, כאשר T1 יגיע בסופו של דבר ל-`barrier_wait()` עבור המחזור השני, הוא ימצא את `barrier_sem` עם ערך חיובי (מכיוון ש-T2 כבר פירסם עבורו מראש). T1 יעבור את המחסום באופן מיידי מבלי להמתין ל-T2, ובכך תכונת המחסום נשברת.\n\nהבעיה נובעת מכך שאיפוס המונה `count = 0;` מתבצע על ידי החוט האחרון שמגיע למחסום, וזאת *לפני* שכל שאר החוטים הספיקו לעבור את `sem_wait(&barrier_sem)`. חוט מהיר יכול להיכנס מחדש למחסום, לאפס את המונה שוב ולשחרר סמפורים עודפים, מה שמאפשר לחוטים לעקוף את המחסום.\n\n**תיקון הקוד (מימוש \"מחסום כפול\" - Double Turnstile Barrier):**\nכדי לפתור בעיה זו ולממש מחסום ניתן לשימוש חוזר, נדרש מנגנון מורכב יותר, המכונה לעיתים \"מחסום כפול\" (Double Turnstile Barrier). מנגנון זה משתמש בשני סמפורים בנוסף למנעול ולמונה, כדי לשלוט בכניסה וביציאה מהמחסום ולהבטיח איפוס נכון.\n\n```c\n#include <pthread.h>\n#include <semaphore.h>\n#include <stdio.h>\n#include <unistd.h>\n\n#define N_THREADS 5 // מספר החוטים המשתתפים במחסום\n\nsem_t mutex;         // מנעול להגנה על המונה\nsem_t turnstile1;    // סמפור למחסום הכניסה (מאותחל ל-0)\nsem_t turnstile2;    // סמפור למחסום היציאה/איפוס (מאותחל ל-1)\nint count = 0;       // מונה חוטים שהגיעו למחסום\n\nvoid barrier_init() {\n    sem_init(&mutex, 0, 1);\n    sem_init(&turnstile1, 0, 0); // חוסם את כולם בהתחלה\n    sem_init(&turnstile2, 0, 1); // מאפשר לחוט אחד לעבור כדי לאפס את השער הבא\n    count = 0;\n}\n\nvoid barrier_wait() {\n    sem_wait(&mutex);\n    count++;\n    if (count == N_THREADS) { // החוט האחרון הגיע\n        sem_wait(&turnstile2); // נועל את turnstile2 כדי למנוע כניסה מוקדמת למחזור הבא\n        for (int i = 0; i < N_THREADS; ++i) {\n            sem_post(&turnstile1); // משחרר את כל החוטים דרך turnstile1\n        }\n    }\n    sem_post(&mutex);\n\n    sem_wait(&turnstile1); // כל החוטים ממתינים כאן (שער כניסה)\n\n    // שלב שני של המחסום (יציאה ואיפוס)\n    sem_wait(&mutex);\n    count--;\n    if (count == 0) { // החוט האחרון שעוזב את המחסום\n        for (int i = 0; i < N_THREADS; ++i) {\n            sem_wait(&turnstile1); // אוסף בחזרה את ההיתרים מ-turnstile1 (סוגר את שער הכניסה)\n        }\n        sem_post(&turnstile2); // משחרר את turnstile2 עבור המחזור הבא\n    }\n    sem_post(&mutex);\n}\n```\n\n**הסבר על התיקון:**\nהתיקון משתמש בשני סמפורים כ\"שערי ביטחון\" (turnstiles).\n*   `turnstile1` משמש לשחרור כל החוטים לאחר שהאחרון הגיע, בדומה לפתרון המקורי.\n*   `turnstile2` משמש כדי לוודא שרק חוט אחד (החוט האחרון שעוזב את המחזור הנוכחי) יכול לאפס את `turnstile1` ולשחרר את השער למחזור הבא. זה מונע מחוטים מהירים להיכנס למחזור הבא לפני שכל החוטים סיימו את המחזור הקודם, ובכך נמנע מצב המרוץ של איפוס מוקדם של המונה והסמפורים העודפים."}, "difficulty_estimation": "Hard", "_source_file": "0355__Semaphores__CodeAnalysis__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:03:13", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Concurrency", "Resource Management", "Deadlock"], "content": {"text": "נתון קטע קוד המדמה מערכת שבה מספר רב של חוטים (threads) מנסים לגשת לבריכת משאבים משותפת המכילה `NUM_RESOURCES` משאבים זהים. בכל פעם, חוט רוצה לתפוס משאב אחד, להשתמש בו, ולשחרר אותו. בנוסף, ישנו מונה גלובלי `total_operations` שמתעד את מספר הפעולות הכולל של תפיסה ושחרור, ועדכון המונה דורש קטע קריטי.\nהקוד הבא מנסה לממש את ההתנהגות הזו באמצעות סמפורים:\n\nנתחו את קטע הקוד הנתון. האם הוא פותר את בעיית הגישה לבריכת המשאבים והעדכון של המונה הגלובלי באופן נכון? אם כן, הסבירו מדוע. אם לא, זהו את הבעיה (או הבעיות) המרכזית, הסבירו אותה בפירוט, והציעו תיקון מינימלי לקוד.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h> // For usleep\n\n#define NUM_RESOURCES 3\n#define NUM_THREADS 5\n#define OPERATIONS_PER_THREAD 2\n\nsem_t resource_pool; // Limits concurrent access to N resources\nsem_t mutex;         // Protects the shared counter\nint total_operations = 0;\n\nvoid use_resource() {\n    // Simulate using the resource\n    usleep(10000); // 10ms\n}\n\nvoid* thread_func(void* arg) {\n    for (int i = 0; i < OPERATIONS_PER_THREAD; ++i) {\n        // Attempt to acquire a resource and update counter\n        sem_wait(&mutex);        // Acquire mutex first\n        sem_wait(&resource_pool); // Then acquire resource slot\n\n        total_operations++;\n        printf(\"Thread %ld acquired resource. Total ops: %d\\n\", (long)arg, total_operations);\n\n        use_resource(); // Use the resource\n\n        sem_post(&resource_pool); // Release resource slot\n        sem_post(&mutex);         // Release mutex last\n    }\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_THREADS];\n    sem_init(&resource_pool, 0, NUM_RESOURCES); // Initialize with N available resources\n    sem_init(&mutex, 0, 1);                   // Initialize mutex for critical section\n\n    printf(\"Starting simulation with %d resources and %d threads...\\n\", NUM_RESOURCES, NUM_THREADS);\n\n    for (long i = 0; i < NUM_THREADS; ++i) {\n        pthread_create(&threads[i], NULL, thread_func, (void*)i);\n    }\n\n    for (int i = 0; i < NUM_THREADS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    printf(\"Simulation finished. Final total operations: %d\\n\", total_operations);\n\n    sem_destroy(&resource_pool);\n    sem_destroy(&mutex);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הקוד הנתון אינו פותר את הבעיה באופן נכון. הבעיה המרכזית בקוד היא סדר רכישת הסמפורים (semaphores) בתוך פונקציית `thread_func`.\n\n**הסבר הבעיה:**\n1.  **מטרת הסמפורים:**\n    *   הסמפור `resource_pool` הוא סמפור סופר (counting semaphore) המאותחל ל-`NUM_RESOURCES`. מטרתו לאפשר ל-`NUM_RESOURCES` חוטים לגשת למשאבים באופן מקביל. כלומר, הוא מגביל את מספר החוטים שיכולים להיות בקטע הקוד שבו הם 'מחזיקים' משאב.\n    *   הסמפור `mutex` הוא סמפור בינארי (binary semaphore) / מנעול (mutex) המאותחל ל-1. מטרתו להגן על המונה המשותף `total_operations` מפני תנאי מירוץ (race conditions), ולוודא שרק חוט אחד מעדכן את המונה בכל רגע נתון.\n\n2.  **סדר הרכישה השגוי:** בקוד הנתון, חוט רוכש קודם את ה-`mutex` (`sem_wait(&mutex);`) ורק לאחר מכן מנסה לרכוש משבצת משאב מ-`resource_pool` (`sem_wait(&resource_pool);`).\n\n3.  **ההשלכות:**\n    *   ברגע שחוט אחד רוכש את ה-`mutex`, אף חוט אחר אינו יכול לרכוש את ה-`mutex` ולהמשיך הלאה. המשמעות היא שרק חוט אחד יכול להיכנס לקטע הקוד שמתחיל ב-`sem_wait(&mutex)` בכל רגע נתון. \n    *   זה הופך למעשה את המערכת למערכת שבה רק חוט אחד יכול לתפוס משאב (ולהיכנס לקטע הקריטי של עדכון המונה) בכל רגע נתון, במקום לאפשר ל-`NUM_RESOURCES` חוטים לתפוס משאבים במקביל. זה מגביל באופן חמור את הקונקרנטיות (concurrency) של המערכת וסותר את מטרת ה-`resource_pool` כסמפור סופר המאפשר גישה מקבילה למספר משאבים.\n    *   במילים אחרות, גם אם ישנם `NUM_RESOURCES` זמינים (לדוגמה, `NUM_RESOURCES=3`) ורק חוט אחד משתמש במשאב, חוטים אחרים לא יוכלו להתחיל בתהליך רכישת המשאב מכיוון שהם יחסמו בניסיון לרכוש את ה-`mutex`.\n    *   אמנם במקרה זה לא ייווצר בהכרח קיפאון (deadlock) קלאסי, אך ייווצר מצב של חוסר יעילות דרמטי וביצועים ירודים, מכיוון שהגישה למשאבים הופכת לטורית (sequential) במקום מקבילית.\n\n**תיקון מינימלי לקוד:**\nכדי לפתור את הבעיה, יש לשנות את סדר רכישת הסמפורים. יש לרכוש את הסמפור `resource_pool` קודם, כדי לאפשר ל-`NUM_RESOURCES` חוטים להיכנס לקטע שבו הם מחזיקים משאב. רק לאחר מכן, בתוך קטע זה, יש לרכוש את ה-`mutex` כדי להגן על עדכון המונה `total_operations` בקטע הקריטי הקצר בלבד.\n\n```c\nvoid* thread_func(void* arg) {\n    for (int i = 0; i < OPERATIONS_PER_THREAD; ++i) {\n        // 1. רכישת משבצת משאב קודם - מאפשר ל-NUM_RESOURCES חוטים להחזיק משאבים במקביל\n        sem_wait(&resource_pool);\n\n        // 2. כעת, עדכון המונה המשותף בתוך קטע קריטי המוגן ע\"י mutex\n        sem_wait(&mutex);\n        total_operations++;\n        printf(\"Thread %ld acquired resource. Total ops: %d\\n\", (long)arg, total_operations);\n        sem_post(&mutex); // שחרור ה-mutex מיד לאחר עדכון המונה\n\n        use_resource(); // 3. שימוש במשאב - יכול להתבצע במקביל ע\"י NUM_RESOURCES חוטים\n\n        // 4. שחרור משבצת המשאב\n        sem_post(&resource_pool);\n    }\n    return NULL;\n}\n```\nהתיקון מבטיח ש-`NUM_RESOURCES` חוטים יכולים להחזיק משאבים במקביל, בעוד שעדכון המונה `total_operations` מוגן כהלכה מפני תנאי מירוץ על ידי ה-`mutex` הנרכש ומשוחרר בקטע קריטי קצר בלבד. זה מאפשר ניצול יעיל של המשאבים ומקסום הקונקרנטיות."}, "difficulty_estimation": "Hard", "_source_file": "0356__Semaphores__CodeAnalysis__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:03:46", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Deadlock", "Concurrency", "Threads"], "content": {"text": "נתונה תוכנית המשתמשת בשלושה סמפורים: sem_A, sem_B (שניהם סמפורים בינאריים, כלומר מאותחלים ל-1), ו-sem_limit (סמפור סופר המאותחל לערך K). התוכנית מריצה במקביל N חוטים, כאשר חלקם מריצים את הפונקציה thread_func_X וחלקם את הפונקציה thread_func_Y.\n\nשימו לב: פעולות ה-printf וה-usleep הוסרו מהקוד לנוחות הניתוח, אך הן אינן משנות את ההתנהגות הסנכרונית הבסיסית.", "code_snippet": "/* הגדרות ואיתחול סמפורים (בדוגמה זו, נניח שהם גלובליים ומאותחלים): */\n/* sem_t sem_A; sem_init(&sem_A, 0, 1); // סמפור בינארי למשאב A */\n/* sem_t sem_B; sem_init(&sem_B, 0, 1); // סמפור בינארי למשאב B */\n/* sem_t sem_limit; sem_init(&sem_limit, 0, K); // סמפור סופר, מאותחל ל-K */\n\nvoid critical_operation(int thread_id, const char* func_name) {\n    // פעולה קריטית הדורשת את שני המשאבים A ו-B\n    // ... (מבצעת עבודה, אינה משנה את מצב הסמפורים)\n}\n\nvoid *thread_func_X(void *arg) {\n    int id = *(int*)arg;\n    sem_wait(&sem_limit);\n    sem_wait(&sem_A);\n    sem_wait(&sem_B);\n\n    critical_operation(id, \"X\");\n\n    sem_post(&sem_B);\n    sem_post(&sem_A);\n    sem_post(&sem_limit);\n    return NULL;\n}\n\nvoid *thread_func_Y(void *arg) {\n    int id = *(int*)arg;\n    sem_wait(&sem_limit);\n    sem_wait(&sem_B);\n    sem_wait(&sem_A);\n\n    critical_operation(id, \"Y\");\n\n    sem_post(&sem_A);\n    sem_post(&sem_B);\n    sem_post(&sem_limit);\n    return NULL;\n}", "options": null}, "sub_questions": [{"id": "101.1", "text": "האם קיפאון (deadlock) אפשרי במערכת זו? אם כן, תאר תרחיש ספציפי המוביל לקיפאון, בהנחה ש-N=4 (סה\"כ 4 חוטים) ו-K=2 (ערך אתחול של sem_limit).", "code_snippet": null, "options": null}, {"id": "101.2", "text": "כיצד המצב ישתנה אם ערך האתחול של sem_limit יהיה K=1? האם קיפאון עדיין אפשרי? הסבר.", "code_snippet": null, "options": null}, {"id": "101.3", "text": "הצע פתרון לבעיית הקיפאון (אם קיימת) על ידי שינוי מינימלי בקוד, והסבר מדוע הפתרון שלך מונע קיפאון. כתוב את הקוד המעודכן עבור הפונקציה ששונתה.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  **האם קיפאון אפשרי כאשר N=4 ו-K=2?**\n    כן, קיפאון אפשרי במערכת זו.\n    \n    **תרחיש ספציפי לקיפאון:**\n    נניח ששני חוטים, T1 (מריץ את thread_func_X) ו-T2 (מריץ את thread_func_Y), מתחילים לרוץ במקביל.\n    *   **שלב 1:** T1 מבצע `sem_wait(&sem_limit)` ומצליח (sem_limit יורד ל-1).\n    *   **שלב 2:** T2 מבצע `sem_wait(&sem_limit)` ומצליח (sem_limit יורד ל-0). כעת, אף חוט נוסף לא יוכל להיכנס לקטע קריטי זה עד ש-T1 או T2 ישחררו את sem_limit.\n    *   **שלב 3:** T1 מבצע `sem_wait(&sem_A)` ומצליח (sem_A יורד ל-0). T1 מחזיק כעת את משאב A.\n    *   **שלב 4:** T2 מבצע `sem_wait(&sem_B)` ומצליח (sem_B יורד ל-0). T2 מחזיק כעת את משאב B.\n    *   **שלב 5:** T1 מנסה לבצע `sem_wait(&sem_B)`, אך sem_B מוחזק על ידי T2. T1 נחסם וממתין ל-sem_B.\n    *   **שלב 6:** T2 מנסה לבצע `sem_wait(&sem_A)`, אך sem_A מוחזק על ידי T1. T2 נחסם וממתין ל-sem_A.\n    \n    כעת, גם T1 וגם T2 חסומים וממתינים למשאב שמוחזק על ידי החוט השני. נוצר מצב של המתנה מעגלית (circular wait), שהיא אחד מארבעת התנאים ההכרחיים לקיפאון. מכיוון שכל התנאים לקיפאון מתקיימים, המערכת תיכנס לקיפאון.\n\n2.  **כיצד המצב ישתנה אם K=1? האם קיפאון עדיין אפשרי?**\n    אם ערך האתחול של `sem_limit` יהיה `K=1`, קיפאון **אינו** אפשרי.\n    \n    **הסבר:**\n    כאשר `sem_limit` מאותחל ל-1, רק חוט אחד יכול לבצע `sem_wait(&sem_limit)` בהצלחה בכל רגע נתון. המשמעות היא שרק חוט אחד יכול להיכנס לקטע הקוד שבו מתבצעות פעולות `sem_wait` עבור `sem_A` ו-`sem_B`. מכיוון שרק חוט אחד יכול לנסות לרכוש את `sem_A` ו-`sem_B`, לא ייתכן מצב שבו שני חוטים מחזיקים משאבים שונים ומנסים לרכוש את המשאב של השני בו-זמנית. `sem_limit` מתפקד למעשה כ-mutex גלובלי עבור הרכישה של `sem_A` ו-`sem_B`, ומבטיח סדרתיות בגישה אליהם, ובכך מונע את תנאי ההמתנה המעגלית.\n\n3.  **פתרון לבעיית הקיפאון וקוד מעודכן:**\n    הפתרון הנפוץ והפשוט ביותר למניעת קיפאון במקרה זה הוא לכפות סדר רכישה אחיד של המשאבים על כל החוטים. אם כל החוטים רוכשים את המשאבים באותו סדר (לדוגמה, תמיד קודם `sem_A` ואז `sem_B`), תנאי ההמתנה המעגלית נמנע.\n    \n    **קוד מעודכן עבור `thread_func_Y`:**\n    ```c\n    void *thread_func_Y_fixed(void *arg) {\n        int id = *(int*)arg;\n        sem_wait(&sem_limit);\n        // סדר רכישת המשאבים שונה כדי להתאים ל-thread_func_X\n        sem_wait(&sem_A); // רכוש את A קודם\n        sem_wait(&sem_B); // ואז רכוש את B\n\n        critical_operation(id, \"Y\");\n\n        sem_post(&sem_B);\n        sem_post(&sem_A);\n        sem_post(&sem_limit);\n        return NULL;\n    }\n    ```\n    \n    **הסבר מדוע הפתרון מונע קיפאון:**\n    על ידי הקפדה על סדר רכישה עקבי (לדוגמה, תמיד `sem_A` ואז `sem_B`), אנו מבטלים את האפשרות להיווצרות המתנה מעגלית. חוט שרוצה לרכוש את `sem_B` חייב קודם לרכוש את `sem_A`. אם `sem_A` כבר מוחזק על ידי חוט אחר, החוט הנוכחי ייחסם בהמתנה ל-`sem_A` ולא יוכל להחזיק את `sem_B` בו-זמנית. באופן זה, לא ייתכן מצב שבו חוט אחד מחזיק את `sem_A` וממתין ל-`sem_B`, בעוד חוט אחר מחזיק את `sem_B` וממתין ל-`sem_A`. זה מונע את תנאי ההמתנה המעגלית ובכך מונע קיפאון."}, "difficulty_estimation": "Hard", "_source_file": "0357__Semaphores__CodeAnalysis__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:04:31", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Concurrency", "Deadlock"], "content": {"text": "נתונה בעיית סנכרון בה שני סוגי תהליכונים (thread_X ו-thread_Y) מנסים לגשת לשני משאבים שיתופיים, המיוצגים על ידי סמפורים בינאריים A ו-B. שני הסמפורים מאותחלים לערך 1. הקוד הבא מתאר את לוגיקת הגישה למשאבים עבור כל סוג תהליכון, וכן את פונקציית main המאתחלת ומפעילה אותם. נתחו את הקוד וענו על השאלות הבאות:\n\n1.  האם הקוד הנתון פותר נכונה את בעיית הסנכרון? אם לא, מהי הבעיה וכיצד היא מתרחשת (תארו תרחיש ספציפי)?\n2.  הציעו פתרון מתוקן לקוד אשר מונע את הבעיה, והסבירו מדוע הוא פותר אותה.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h> // For sleep\n\nsem_t A;\nsem_t B;\n\nvoid* thread_X(void* arg) {\n    printf(\"Thread X: Trying to acquire semaphore A\\n\");\n    sem_wait(&A);\n    printf(\"Thread X: Acquired semaphore A, trying to acquire B\\n\");\n    sleep(1); // Simulate work or context switch\n    sem_wait(&B);\n    printf(\"Thread X: Acquired both A and B\\n\");\n    // Critical section\n    printf(\"Thread X: Releasing semaphores\\n\");\n    sem_post(&B);\n    sem_post(&A);\n    return NULL;\n}\n\nvoid* thread_Y(void* arg) {\n    printf(\"Thread Y: Trying to acquire semaphore B\\n\");\n    sem_wait(&B);\n    printf(\"Thread Y: Acquired semaphore B, trying to acquire A\\n\");\n    sleep(1); // Simulate work or context switch\n    sem_wait(&A);\n    printf(\"Thread Y: Acquired both B and A\\n\");\n    // Critical section\n    printf(\"Thread Y: Releasing semaphores\\n\");\n    sem_post(&A);\n    sem_post(&B);\n    return NULL;\n}\n\nint main() {\n    sem_init(&A, 0, 1);\n    sem_init(&B, 0, 1);\n\n    pthread_t tid_x, tid_y;\n\n    printf(\"Main: Creating threads...\\n\");\n    pthread_create(&tid_x, NULL, thread_X, NULL);\n    pthread_create(&tid_y, NULL, thread_Y, NULL);\n\n    pthread_join(tid_x, NULL);\n    pthread_join(tid_y, NULL);\n\n    sem_destroy(&A);\n    sem_destroy(&B);\n\n    printf(\"Main: Both threads finished (or deadlocked)\\n\");\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הקוד הנתון סובל מבעיית קיפאון (Deadlock). נסביר את התרחיש הבעייתי ואת הפתרון הנכון.\n\n**1. זיהוי הבעיה ותיאור התרחיש הבעייתי:**\nהקוד הנתון אינו פותר נכונה את בעיית הסנכרון והוא מוביל למצב של קיפאון (Deadlock). הסיבה לכך היא ששני סוגי התהליכונים מנסים לרכוש את המשאבים (הסמפורים) בסדר שונה:\n*   `thread_X` מנסה לרכוש את A ואז את B.\n*   `thread_Y` מנסה לרכוש את B ואז את A.\n\nתרחיש ספציפי המוביל לקיפאון:\n1.  `thread_X` מתחיל לרוץ ומבצע בהצלחה `sem_wait(&A)`. כעת `thread_X` מחזיק בסמפור A.\n2.  `thread_X` מבצע `sleep(1)`, מה שמאפשר ל-`thread_Y` לקבל הקצאת מעבד ולהתחיל לרוץ.\n3.  `thread_Y` מתחיל לרוץ ומבצע בהצלחה `sem_wait(&B)`. כעת `thread_Y` מחזיק בסמפור B.\n4.  `thread_Y` מבצע `sleep(1)`.\n5.  כאשר `thread_X` מתעורר מהשינה, הוא מנסה לבצע `sem_wait(&B)`. מכיוון ש-`thread_Y` מחזיק כעת בסמפור B, `thread_X` נחסם וממתין לשחרור B.\n6.  כאשר `thread_Y` מתעורר מהשינה, הוא מנסה לבצע `sem_wait(&A)`. מכיוון ש-`thread_X` מחזיק כעת בסמפור A, `thread_Y` נחסם וממתין לשחרור A.\n\nבשלב זה, `thread_X` מחכה ל-`thread_Y` שישחרר את B, ו-`thread_Y` מחכה ל-`thread_X` שישחרר את A. נוצר מעגל המתנה הדדית (circular wait), והמערכת נכנסת למצב קיפאון. שני התהליכונים חסומים ולא יוכלו להמשיך.\n\n**2. פתרון מתוקן:**\nהדרך הנפוצה למנוע קיפאון במקרה זה היא לוודא שכל התהליכונים מנסים לרכוש את המשאבים באותו סדר קבוע (resource hierarchy). לדוגמה, שניהם ירכשו תמיד את A ואז את B. במימוש זה, אם `thread_X` רוכש את A, הוא ינסה לרכוש את B. אם `thread_Y` גם רוצה את A, הוא יחסם עד ש-`thread_X` ישחרר אותו (לאחר שסיים את כל המקטע הקריטי ושחרר את B ואז את A). כך נמנעת המתנה מעגלית.\n\n**קוד מתוקן לדוגמה (שינוי ב-`thread_Y`):**\n```c\n#include <stdio.h>\n#include <pthread.h>\n#include <semaphore.h>\n#include <unistd.h> // For sleep\n\nsem_t A;\nsem_t B;\n\nvoid* thread_X_corrected(void* arg) { // Renamed for clarity, logic is same as original thread_X\n    printf(\"Thread X (Corrected): Trying to acquire semaphore A\\n\");\n    sem_wait(&A);\n    printf(\"Thread X (Corrected): Acquired semaphore A, trying to acquire B\\n\");\n    sleep(1); // Simulate work or context switch\n    sem_wait(&B);\n    printf(\"Thread X (Corrected): Acquired both A and B\\n\");\n    // Critical section\n    printf(\"Thread X (Corrected): Releasing semaphores\\n\");\n    sem_post(&B);\n    sem_post(&A);\n    return NULL;\n}\n\nvoid* thread_Y_corrected(void* arg) { // Corrected to acquire A then B\n    printf(\"Thread Y (Corrected): Trying to acquire semaphore A\\n\"); // Changed order\n    sem_wait(&A); // Always acquire A first\n    printf(\"Thread Y (Corrected): Acquired semaphore A, trying to acquire B\\n\");\n    sleep(1); // Simulate work or context switch\n    sem_wait(&B);\n    printf(\"Thread Y (Corrected): Acquired both A and B\\n\");\n    // Critical section\n    printf(\"Thread Y (Corrected): Releasing semaphores\\n\");\n    sem_post(&B);\n    sem_post(&A);\n    return NULL;\n}\n\nint main() {\n    sem_init(&A, 0, 1);\n    sem_init(&B, 0, 1);\n\n    pthread_t tid_x, tid_y;\n\n    printf(\"Main: Creating corrected threads...\\n\");\n    pthread_create(&tid_x, NULL, thread_X_corrected, NULL);\n    pthread_create(&tid_y, NULL, thread_Y_corrected, NULL);\n\n    pthread_join(tid_x, NULL);\n    pthread_join(tid_y, NULL);\n\n    sem_destroy(&A);\n    sem_destroy(&B);\n\n    printf(\"Main: Both corrected threads finished successfully\\n\");\n    return 0;\n}\n```\n**הסבר לפתרון המתוקן:**\nעל ידי אכיפת סדר רכישה אחיד (A ואז B) לכל התהליכונים, אנו מבטלים את התנאי של המתנה מעגלית, שהוא אחד מארבעת התנאים ההכרחיים לקיפאון. אם `thread_X` מחזיק ב-A וממתין ל-B, ו-`thread_Y` מנסה לרכוש את A, הוא יחסם ב-`sem_wait(&A)` עד ש-`thread_X` ישחרר את A (לאחר שסיים את כל המקטע הקריטי ושחרר את B ואז את A). כך, אף פעם לא ייווצר מצב שבו `thread_X` מחכה ל-B ו-`thread_Y` מחכה ל-A בו-זמנית."}, "difficulty_estimation": "Hard", "_source_file": "0358__Semaphores__CodeAnalysis__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:05:01", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Producer-Consumer", "Concurrency", "Deadlock", "Starvation"], "content": {"text": "נתון קוד C הבא לבעיית יצרן-צרכן. המערכת משתמשת בחוצץ משותף בגודל קבוע (BUFFER_SIZE). בנוסף לסמפורים הסטנדרטיים (`mutex`, `full`, `empty`), נעשה שימוש בסמפור נוסף `production_limit` המאותחל ל-`MAX_CONCURRENT_PRODUCTION`. מטרת ה-`production_limit` היא להגביל את מספר היצרנים שיכולים *בו-זמנית להיות בשלב של יצירת פריט וניסיון להוסיפו לחוצץ* (כלומר, בין הקריאה הראשונה ל-`sem_wait(&production_limit)` ועד הקריאה האחרונה ל-`sem_post(&production_limit)`). נתחו את הקוד הנתון וענו על השאלות הבאות:", "code_snippet": "#include <semaphore.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n\n#define BUFFER_SIZE 5\n#define MAX_CONCURRENT_PRODUCTION 2 // מספר היצרנים המקסימלי שיכולים להיות בשלב יצירה והוספה\n\nint buffer[BUFFER_SIZE];\nint in = 0;\nint out = 0;\n\nsem_t mutex; // להגנה הדדית על גישה לחוצץ\nsem_t full;  // סופר מקומות מלאים בחוצץ\nsem_t empty; // סופר מקומות פנויים בחוצץ\nsem_t production_limit; // מגביל יצרנים פעילים בו-זמנית\n\n// מדמה יצירת פריט (למשל, עבודה חישובית)\nint produce_item_sim() {\n    // sleep(1); // לדמות עבודה\n    return rand() % 100;\n}\n\n// מדמה צריכת פריט (למשל, עבודה חישובית)\nvoid consume_item_sim(int item) {\n    // sleep(1); // לדמות עבודה\n    (void)item; // למנוע אזהרת משתנה שאינו בשימוש\n}\n\nvoid *producer(void *arg) {\n    int item;\n    for (int i = 0; i < 10; ++i) { // כל יצרן מייצר 10 פריטים\n        // שלב 1: יצירת פריט והוספה לחוצץ, מוגבל ע\"י production_limit\n        sem_wait(&production_limit); // (1) רכישת production_limit\n\n        item = produce_item_sim(); // יצירת הפריט\n\n        sem_wait(&empty); // (2) המתנה למקום פנוי\n        sem_wait(&mutex);  // (3) רכישת mutex לגישה לחוצץ\n\n        // קטע קריטי: הוספת פריט לחוצץ\n        buffer[in] = item;\n        in = (in + 1) % BUFFER_SIZE;\n        printf(\"Producer %ld: Added item %d. Buffer state: full=%d\\n\", (long)arg, item, sem_getvalue(&full));\n\n        sem_post(&mutex); // (4) שחרור mutex\n        sem_post(&full);  // (5) איתות על מקום מלא\n\n        sem_post(&production_limit); // (6) שחרור production_limit\n    }\n    return NULL;\n}\n\nvoid *consumer(void *arg) {\n    int item;\n    for (int i = 0; i < 10; ++i) { // כל צרכן צורך 10 פריטים\n        sem_wait(&full);  // (7) המתנה למקום מלא\n        sem_wait(&mutex);  // (8) רכישת mutex לגישה לחוצץ\n\n        // קטע קריטי: הסרת פריט מהחוצץ\n        item = buffer[out];\n        out = (out + 1) % BUFFER_SIZE;\n        printf(\"Consumer %ld: Removed item %d. Buffer state: full=%d\\n\", (long)arg, item, sem_getvalue(&full));\n\n        sem_post(&mutex);  // (9) שחרור mutex\n        sem_post(&empty); // (10) איתות על מקום פנוי\n\n        consume_item_sim(item); // צריכת הפריט (ניתן לעשות במקביל)\n    }\n    return NULL;\n}\n\nint main() {\n    sem_init(&mutex, 0, 1);\n    sem_init(&full, 0, 0);\n    sem_init(&empty, 0, BUFFER_SIZE);\n    sem_init(&production_limit, 0, MAX_CONCURRENT_PRODUCTION);\n\n    pthread_t prod_threads[3], cons_threads[3];\n\n    for (long i = 0; i < 3; ++i) {\n        pthread_create(&prod_threads[i], NULL, producer, (void *)(i + 1));\n        pthread_create(&cons_threads[i], NULL, consumer, (void *)(i + 1));\n    }\n\n    for (int i = 0; i < 3; ++i) {\n        pthread_join(prod_threads[i], NULL);\n        pthread_join(cons_threads[i], NULL);\n    }\n\n    sem_destroy(&mutex);\n    sem_destroy(&full);\n    sem_destroy(&empty);\n    sem_destroy(&production_limit);\n\n    return 0;\n}\n"}, "sub_questions": [{"id": "1.1", "text": "האם המימוש הנתון משיג באופן נכון את המטרה המיועדת של `production_limit`?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "האם קוד זה מציג פוטנציאל לקיפאון (deadlock) או הרעבה (starvation)? נמקו.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "דונו ברמת המקביליות המושגת על ידי מימוש זה, בהתחשב בתפקידו של `production_limit`.", "code_snippet": null, "options": null}], "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "### פתרון שאלה 1\n\n**1.1 האם המימוש הנתון משיג באופן נכון את המטרה המיועדת של `production_limit`?**\n\nכן, המימוש משיג באופן נכון את המטרה. הסמפור `production_limit` נרכש לפני תחילת שלב יצירת הפריט והוספתו לחוצץ (שורה 1 בקוד היצרן) ומשוחרר רק לאחר סיום כל השלבים הללו, כולל הוספת הפריט בפועל לחוצץ ושחרור הסמפורים `mutex` ו-`full` (שורה 6 בקוד היצרן). המשמעות היא שבכל רגע נתון, לא יותר מ-`MAX_CONCURRENT_PRODUCTION` יצרנים יכולים להיות בו-זמנית בתוך קטע הקוד המוגן על ידי `production_limit`, אשר כולל את `produce_item_sim()`, המתנה למקום פנוי בחוצץ, רכישת מנעול, הוספה לחוצץ, ושחרור מנעולים.\n\n**1.2 האם קוד זה מציג פוטנציאל לקיפאון (deadlock) או הרעבה (starvation)? נמקו.**\n\n**קיפאון (Deadlock):**\nלא, הקוד אינו מציג פוטנציאל לקיפאון. הסמפורים נרכשים ומשוחררים בסדר עקבי:\n*   **יצרן:** `production_limit` -> `empty` -> `mutex`\n*   **צרכן:** `full` -> `mutex`\nאין כאן תלות מעגלית בין הסמפורים. `production_limit` משמש כמעין 'שער כניסה' לשלב היצרן, ואינו יוצר תלות הדדית עם הסמפורים `empty` או `full` באופן שיכול להוביל לקיפאון. יצרן שלוקח `production_limit` אך נחסם על `empty` או `mutex` לא ימנע מצרכן לשחרר `full` או `empty`.\n\n**הרעבה (Starvation):**\nהקוד עצמו אינו מציג מנגנון מובנה המבטיח הוגנות (fairness) בין חוטים, בדומה לסמפורים רגילים שאינם בהכרח הוגנים. עם זאת, אין תרחיש מובהק של הרעבה כתוצאה מכשל לוגי בלוגיקת הסמפורים עצמה. אם חוטים ממתינים בתור לסמפור (כמו `empty` או `mutex`), ייתכן שחוט מסוים יקבל את הסמפור שוב ושוב לפני חוטים אחרים, אך זהו מאפיין כללי של סמפורים ללא תור הוגן, ולא כשל לוגי בפתרון הספציפי. הסמפור `production_limit` עלול לגרום לכך שיצרנים רבים ימתינו מחוץ לקטע המוגן, אך ברגע שהם נכנסים, הם מתמודדים על משאבי החוצץ בצורה סטנדרטית.\n\n**1.3 דונו ברמת המקביליות המושגת על ידי מימוש זה, בהתחשב בתפקידו של `production_limit`.**\n\nהמימוש משפיע על רמת המקביליות בכמה דרכים:\n\n*   **הגבלת יצרנים פעילים:** `production_limit` מגביל את מספר היצרנים שיכולים לבצע את `produce_item_sim()` *וגם* לנסות להוסיף פריטים לחוצץ בו-זמנית ל-`MAX_CONCURRENT_PRODUCTION`. זהו יתרון אם `produce_item_sim()` היא פעולה עתירת משאבים (למשל, CPU או זיכרון) שאיננו רוצים שכל היצרנים יבצעו במקביל ללא הגבלה. אם `MAX_CONCURRENT_PRODUCTION` נמוך מאוד (למשל 1), זה עלול להפחית את המקביליות הכוללת של היצרנים.\n\n*   **הפרדת שלבים:** ה-`produce_item_sim()` מתבצעת כחלק מהקטע המוגן על ידי `production_limit`, אך `consume_item_sim()` מתבצעת מחוץ לכל מנעול או סמפור מיוחד בצרכן. זה מאפשר לצרכנים לצרוך פריטים במקביל ללא הגבלה נוספת מעבר לזמינות הפריטים בחוצץ עצמו. זוהי הפרדה נכונה שממקסמת את המקביליות של פעולת הצריכה.\n\n*   **צוואר בקבוק פוטנציאלי:** אם `MAX_CONCURRENT_PRODUCTION` קטן מ-`BUFFER_SIZE` ומספר היצרנים גדול, ה-`production_limit` יכול להפוך לצוואר בקבוק, שיגביל את קצב הוספת הפריטים לחוצץ, גם אם יש מקומות פנויים רבים בחוצץ (`empty` > 0). מצד שני, אם `MAX_CONCURRENT_PRODUCTION` גדול מדי או שווה למספר היצרנים הכולל, ייתכן שתפקידו של `production_limit` יפחת או יהפוך ללא רלוונטי, וההגבלה העיקרית תהיה על ידי `empty` ו-`mutex` בלבד.\n\nבסך הכל, המימוש מאפשר שליטה עדינה יותר על התנהגות היצרנים, במחיר של פוטנציאל להפחתת מקביליות אם `MAX_CONCURRENT_PRODUCTION` נבחר נמוך מדי ביחס ליכולות המערכת או מספר היצרנים."}, "difficulty_estimation": "Hard", "_source_file": "0359__Semaphores__CodeAnalysis__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:06:04", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Synchronization", "Semaphores", "Deadlock", "Concurrency", "Threads"], "content": {"text": "נתונה תוכנית המשתמשת בשני סמפורים בינאריים, `sem_A` ו-`sem_B`, המאותחלים ל-1, כדי להגן על שני משאבים משותפים. שני סוגי חוטים פועלים במקביל במערכת. חוטים מסוג `thread_A_then_B` מנסים לתפוס את `sem_A` ולאחר מכן את `sem_B`, ואילו חוטים מסוג `thread_B_then_A` מנסים לתפוס את `sem_B` ולאחר מכן את `sem_A`. לאחר תפיסת שני הסמפורים, החוטים מבצעים פעולה כלשהי (כגון עדכון משתנה משותף `shared_counter`) ומשחררים אותם בסדר הפוך. נתון קטע הקוד הבא:\n\nהאם קטע הקוד הנתון יכול להוביל למצב של קיפאון (deadlock)? אם כן, תאר/י תרחיש ספציפי המוביל לקיפאון והסבר/י מדוע הוא מתרחש. בנוסף, הצע/י שינוי מינימלי בקוד כדי למנוע קיפאון, והסבר/י מדוע הפתרון שלך מונע קיפאון.", "code_snippet": "sem_t sem_A; // initialized to 1\nsem_t sem_B; // initialized to 1\nint shared_counter = 0;\n\nvoid* thread_A_then_B(void* arg) {\n    sem_wait(&sem_A);\n    // Simulate some work or context switch\n    // usleep(10000);\n    sem_wait(&sem_B);\n    \n    // Critical section\n    shared_counter++;\n\n    sem_post(&sem_B);\n    sem_post(&sem_A);\n    return NULL;\n}\n\nvoid* thread_B_then_A(void* arg) {\n    sem_wait(&sem_B);\n    // Simulate some work or context switch\n    // usleep(10000);\n    sem_wait(&sem_A);\n    \n    // Critical section\n    shared_counter++;\n\n    sem_post(&sem_A);\n    sem_post(&sem_B);\n    return NULL;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, קטע הקוד הנתון יכול להוביל למצב של קיפאון (deadlock). קיפאון מתרחש כאשר שני חוטים או יותר ממתינים זה לזה באופן בלתי הפיך, כאשר כל אחד מהם מחזיק במשאב שהאחר זקוק לו וממתין למשאב המוחזק על ידי האחר.\n\n**תרחיש קיפאון ספציפי:**\n1.  **חוט `thread_A_then_B` רץ:** הוא מבצע `sem_wait(&sem_A)` ומצליח לתפוס את `sem_A`. בשלב זה, `sem_A` מוחזק על ידו ו-`sem_B` חופשי.\n2.  **מתרחש מעבר הקשר (context switch) לחוט `thread_B_then_A`:**\n3.  **חוט `thread_B_then_A` רץ:** הוא מבצע `sem_wait(&sem_B)` ומצליח לתפוס את `sem_B`. בשלב זה, `sem_B` מוחזק על ידו ו-`sem_A` מוחזק על ידי `thread_A_then_B`.\n4.  **מתרחש מעבר הקשר בחזרה לחוט `thread_A_then_B`:**\n5.  **חוט `thread_A_then_B` מנסה להמשיך:** הוא מנסה לבצע `sem_wait(&sem_B)`. אך `sem_B` מוחזק כעת על ידי `thread_B_then_A`, ולכן `thread_A_then_B` נכנס למצב המתנה על `sem_B`.\n6.  **מתרחש מעבר הקשר בחזרה לחוט `thread_B_then_A`:**\n7.  **חוט `thread_B_then_A` מנסה להמשיך:** הוא מנסה לבצע `sem_wait(&sem_A)`. אך `sem_A` מוחזק כעת על ידי `thread_A_then_B`, ולכן `thread_B_then_A` נכנס למצב המתנה על `sem_A`.\n\nבנקודה זו, שני החוטים נמצאים במצב המתנה הדדית: `thread_A_then_B` ממתין ל-`sem_B` המוחזק על ידי `thread_B_then_A`, ו-`thread_B_then_A` ממתין ל-`sem_A` המוחזק על ידי `thread_A_then_B`. אף אחד מהם לא יכול להמשיך, והמערכת נכנסת לקיפאון.\n\n**פתרון למניעת קיפאון (שינוי מינימלי):**\nכדי למנוע קיפאון במצב כזה, יש להבטיח שכל החוטים תופסים את המשאבים באותו סדר. שינוי זה מונע את התנאי של 'המתנה מעגלית' (Circular Wait), שהוא אחד מארבעת התנאים ההכרחיים לקיפאון (על פי תנאי קופמן). לדוגמה, נוכל לשנות את `thread_B_then_A` כך שתתפוס את `sem_A` לפני `sem_B`.\n\n**קוד מתוקן (שינוי ב-`thread_B_then_A`):**\n```c\nsem_t sem_A; // initialized to 1\nsem_t sem_B; // initialized to 1\nint shared_counter = 0;\n\nvoid* thread_A_then_B(void* arg) {\n    sem_wait(&sem_A);\n    // usleep(10000);\n    sem_wait(&sem_B);\n    \n    shared_counter++;\n\n    sem_post(&sem_B);\n    sem_post(&sem_A);\n    return NULL;\n}\n\nvoid* thread_B_then_A(void* arg) {\n    sem_wait(&sem_A); // שינוי: תופסים את sem_A קודם\n    // usleep(10000);\n    sem_wait(&sem_B); // ואז את sem_B\n    \n    shared_counter++;\n\n    sem_post(&sem_B);\n    sem_post(&sem_A); // משחררים בסדר הפוך: B ואז A\n    return NULL;\n}\n```\n\n**הסבר מדוע הפתרון מונע קיפאון:**\nעל ידי אכיפת סדר תפיסת משאבים אחיד (תמיד קודם `sem_A` ואז `sem_B`) עבור כל החוטים שצריכים את שני המשאבים, אנו מבטלים את האפשרות ל'המתנה מעגלית'. אם חוט אחד תפס את `sem_A` וממתין ל-`sem_B`, החוט השני לא יוכל לתפוס את `sem_B` לפני שהוא תפס את `sem_A` (אשר אולי כבר מוחזק על ידי החוט הראשון). במקרה כזה, החוט השני פשוט ימתין ל-`sem_A` עד שיתפנה, ולא יוכל לתפוס את `sem_B` ולגרום להמתנה מעגלית. כאשר `sem_A` ישוחרר, החוט השני יוכל לתפוס אותו, ואז לתפוס את `sem_B` (אשר יהיה זמין ברגע שהחוט הראשון ישחרר אותו), וכך שניהם יוכלו להשלים את פעולתם ללא קיפאון."}, "difficulty_estimation": "Hard", "_source_file": "0360__Semaphores__CodeAnalysis__Hard.json", "_topic_hint": "Semaphores", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:06:34", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Deadlocks"], "content": {"text": "כדי שיתרחש קיפאון (deadlock), כל ארבעת התנאים של קופמן (הדרה הדדית, החזקה והמתנה, אי-הפקעה, המתנה מעגלית) חייבים להתקיים בו-זמנית.\nנכון / לא נכון", "code_snippet": null, "options": ["נכון", "לא נכון"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "נכון", "explanation": "נכון. קיפאון (deadlock) מתרחש רק כאשר כל ארבעת התנאים של קופמן (הדרה הדדית - Mutual Exclusion, החזקה והמתנה - Hold and Wait, אי-הפקעה - No Preemption, והמתנה מעגלית - Circular Wait) מתקיימים בו-זמנית במערכת. אם אחד מהם אינו מתקיים, קיפאון לא יכול להתרחש."}, "difficulty_estimation": "Easy", "_source_file": "0361__Deadlocks__MultipleChoice__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:06:40", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Deadlocks", "Concurrency", "Processes"], "content": {"text": "קיפאון (deadlock) מתרחש כאשר:", "code_snippet": null, "options": ["תהליך אחד בלבד ממתין למשאב.", "מספר תהליכים ממתינים למשאבים זה מזה בשרשרת מעגלית.", "תהליך ממתין למשאב שאינו קיים.", "תהליך נכנס ללולאה אינסופית."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "מספר תהליכים ממתינים למשאבים זה מזה בשרשרת מעגלית.", "explanation": "קיפאון (deadlock) מתרחש כאשר קבוצה של תהליכים חוסמת זה את זה, כך שכל תהליך בקבוצה ממתין למשאב המוחזק על ידי תהליך אחר באותה קבוצה. תנאי זה ידוע גם כתנאי 'המתנה מעגלית' (Circular Wait), והוא תנאי הכרחי להתרחשות קיפאון, יחד עם שלושה תנאים נוספים: הדרה הדדית, החזקה והמתנה, ואי-הפקעה."}, "difficulty_estimation": "Easy", "_source_file": "0362__Deadlocks__MultipleChoice__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:06:49", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Deadlocks"], "content": {"text": "האם קיפאון (deadlock) יכול להתרחש במערכת ללא המתנה מעגלית (circular wait)?", "code_snippet": null, "options": ["נכון", "לא נכון"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "לא נכון", "explanation": "קיפאון מתרחש רק כאשר מתקיימים ארבעה תנאים הכרחיים: הדרה הדדית (Mutual Exclusion), החזקה והמתנה (Hold and Wait), אי-פקיעה (No Preemption), והמתנה מעגלית (Circular Wait). אם אין המתנה מעגלית, לא ייתכן קיפאון."}, "difficulty_estimation": "Easy", "_source_file": "0363__Deadlocks__MultipleChoice__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:06:56", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Deadlocks"], "content": {"text": "האם הדדיות (Mutual Exclusion) היא תנאי הכרחי לקיומו של קיפאון (Deadlock)?", "code_snippet": null, "options": ["נכון", "לא נכון"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "נכון", "explanation": "נכון. הדדיות (Mutual Exclusion) היא אחד מארבעת התנאים ההכרחיים לקיומו של קיפאון, יחד עם החזקה והמתנה (Hold and Wait), אי-הפקעה (No Preemption) והמתנה מעגלית (Circular Wait). אם תנאי זה לא מתקיים, כלומר משאבים ניתנים לשיתוף, אזי לא ייתכן קיפאון על משאבים אלו."}, "difficulty_estimation": "Easy", "_source_file": "0364__Deadlocks__MultipleChoice__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:07:02", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Deadlocks", "Concurrency"], "content": {"text": "אם אחד מארבעת התנאים ההכרחיים לקיפאון (Deadlock) אינו מתקיים, קיפאון אינו יכול להתרחש.", "code_snippet": null, "options": ["נכון", "לא נכון"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "נכון", "explanation": "נכון. ארבעת התנאים ההכרחיים לקיפאון הם: הדרה הדדית (Mutual Exclusion), החזק והמתן (Hold and Wait), אי-דריסה (No Preemption), והמתנה מעגלית (Circular Wait). אם לפחות אחד מהתנאים הללו לא מתקיים, המערכת מוגנת מפני קיפאון."}, "difficulty_estimation": "Easy", "_source_file": "0365__Deadlocks__MultipleChoice__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:07:09", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Deadlocks"], "content": {"text": "כדי למנוע קיפאון (deadlock), יש צורך לשבור לפחות אחד מארבעת התנאים ההכרחיים להתרחשותו.", "code_snippet": null, "options": ["נכון", "לא נכון"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "נכון", "explanation": "נכון. קיפאון (deadlock) מתרחש רק כאשר כל ארבעת התנאים ההכרחיים (הדרה הדדית, החזקה והמתנה, אי-הפקעה, והמתנה מעגלית) מתקיימים בו-זמנית. לכן, על מנת למנוע קיפאון, יש לשבור או למנוע את התקיימותו של לפחות אחד מהתנאים הללו."}, "difficulty_estimation": "Easy", "_source_file": "0366__Deadlocks__MultipleChoice__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:07:16", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Deadlocks", "Concurrency"], "content": {"text": "אם תנאי 'אי-נתיקה' (No Preemption) אינו מתקיים, כלומר ניתן לבצע נתיקה של משאבים, אזי עדיין ייתכן קיפאון (deadlock).", "code_snippet": null, "options": ["נכון", "לא נכון"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "לא נכון", "explanation": "לא נכון. קיפאון (deadlock) מתרחש רק כאשר כל ארבעת התנאים ההכרחיים מתקיימים: מניעה הדדית (Mutual Exclusion), אחיזה והמתנה (Hold and Wait), אי-נתיקה (No Preemption), והמתנה מעגלית (Circular Wait). אם תנאי 'אי-נתיקה' אינו מתקיים, כלומר ניתן ליטול משאב מחוט שמחזיק בו, אזי אחד מהתנאים ההכרחיים לקיפאון נמנע, ולכן קיפאון אינו יכול להתרחש."}, "difficulty_estimation": "Easy", "_source_file": "0367__Deadlocks__MultipleChoice__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:07:24", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Deadlocks", "Concurrency"], "content": {"text": "איזה מהתנאים הבאים אינו תנאי הכרחי להתרחשות קיפאון (Deadlock)?", "code_snippet": null, "options": ["הדרה הדדית (Mutual Exclusion)", "החזק והמתן (Hold and Wait)", "הקצאה דינמית של משאבים (Dynamic Resource Allocation)", "אי-הפקעה (No Preemption)", "המתנה מעגלית (Circular Wait)"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "הקצאה דינמית של משאבים (Dynamic Resource Allocation)", "explanation": "ארבעת התנאים ההכרחיים לקיפאון (Deadlock) הם: הדרה הדדית, החזק והמתן, אי-הפקעה והמתנה מעגלית. 'הקצאה דינמית של משאבים' אינה אחד מתנאים אלה, אלא מתארת שיטה להקצאת משאבים או התנהגות של המערכת ולא תנאי הכרחי לקיפאון."}, "difficulty_estimation": "Easy", "_source_file": "0368__Deadlocks__MultipleChoice__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:07:33", "_subject": "Concurrency"}, {"id": 10, "type": "MultipleChoice", "topic": ["Deadlocks", "Deadlock Prevention", "Concurrency"], "content": {"text": "איזו מהטענות הבאות לגבי מניעת קיפאון (Deadlock Prevention) נכונה?", "code_snippet": null, "options": ["א. מניעת תנאי 'החזקה והמתנה' (Hold and Wait) על ידי דרישה מחוט לתפוס את כל המשאבים הנדרשים לו בתחילת פעולתו, עלולה להוביל לניצול נמוך של משאבים.", "ב. מניעת תנאי 'אי-דריסה' (No Preemption) קלה ליישום עבור כל סוגי המשאבים.", "ג. מניעת תנאי 'הדרה הדדית' (Mutual Exclusion) אפשרית תמיד על ידי הפיכת כל המשאבים לניתנים לשיתוף.", "ד. מניעת תנאי 'המתנה מעגלית' (Circular Wait) מחייבת בהכרח הגדרת סדר היררכי גלובלי לכל המשאבים במערכת."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "תשובה א' נכונה. אסטרטגיה נפוצה למניעת 'החזקה והמתנה' היא לדרוש מכל תהליך לבקש את כל המשאבים שהוא צריך לפני תחילת ביצועו (או לשחרר את כל המשאבים שהוא מחזיק לפני שהוא מבקש משאבים נוספים). גישה זו עלולה להוביל לכך שמשאבים יישארו תפוסים לזמן ארוך יותר מהנדרש בפועל, או שיידרשו בבת אחת, מה שיפגע ביעילות ויוביל לניצול נמוך של המשאבים. תשובה ב' אינה נכונה מכיוון שמניעת 'אי-דריסה' קשה ליישום עבור משאבים כמו מנעולים (mutexes) שאינם ניתנים לדריסה בקלות. תשובה ג' אינה נכונה מכיוון שלא ניתן למנוע 'הדרה הדדית' מכל המשאבים; חלקם, כמו מדפסת או זיכרון, דורשים גישה בלעדית ולכן אינם ניתנים לשיתוף באופן מלא. תשובה ד' אינה נכונה מכיוון שאף על פי שקביעת סדר היררכי גלובלי היא דרך נפוצה ויעילה למנוע 'המתנה מעגלית', היא אינה הדרך ה'בהכרח' יחידה. ישנן שיטות נוספות כמו דרישת שחרור משאבים לפני בקשת חדשים, אשר גם שוברות את התנאי."}, "difficulty_estimation": "Medium", "_source_file": "0369__Deadlocks__MultipleChoice__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:07:47", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Deadlocks", "Deadlock Prevention", "Starvation"], "content": {"text": "איזו מהטענות הבאות נכונה ביותר לגבי אסטרטגיות מניעת קיפאון ותנאיו?", "code_snippet": null, "options": ["א. קיום של שלושה מתוך ארבעת תנאי קיפאון בהכרח יגרום לקיפאון.", "ב. הפרת תנאי 'החזקה והמתנה' (Hold and Wait) תמיד מונעת קיפאון, אך עלולה לגרום להרעבה.", "ג. הפרת תנאי 'מניעה הדדית' (Mutual Exclusion) אפשרית רק במשאבים הניתנים לשיתוף, ואינה רלוונטית למשאבים בלעדיים.", "ד. המתנה מעגלית (Circular Wait) יכולה להתרחש גם אם לא מתקיים תנאי 'אי-הפקעה' (No Preemption)."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. הפרת תנאי 'החזקה והמתנה' (Hold and Wait) מתבצעת על ידי כך שתהליך יבקש את כל המשאבים הדרושים לו מראש, או ישחרר את כל המשאבים שברשותו אם אינו מצליח לקבל משאב נוסף. אסטרטגיות אלו אכן מונעות קיפאון מכיוון שהן מבטיחות שתנאי 'החזקה והמתנה' לא יתקיים. עם זאת, הן עלולות לגרום להרעבה (starvation) אם תהליך מסוים דורש סט משאבים גדול או פופולרי במיוחד, ואינו מצליח אף פעם להשיג את כולם בבת אחת, או נאלץ לשחרר משאבים שוב ושוב.\n\nא. לא נכון. קיפאון דורש את קיומם של כל ארבעת התנאים (מניעה הדדית, החזקה והמתנה, אי-הפקעה, והמתנה מעגלית). קיום שלושה תנאים בלבד אינו מספיק כדי לגרום לקיפאון.\nג. לא נכון. מניעה הדדית היא תכונה אינהרנטית למשאבים בלעדיים (כמו מדפסת או מנעול). הפרת תנאי זה משמעותה להפוך משאב בלעדי למשותף, מה שלא תמיד אפשרי או רצוי. הטענה שאינה רלוונטית למשאבים בלעדיים אינה נכונה; היא רלוונטית במיוחד עבורם, וכדי למנוע קיפאון על ידי הפרת תנאי זה, נדרש לנסות להפוך אותם למשותפים.\nד. לא נכון. אם תנאי 'אי-הפקעה' (No Preemption) אינו מתקיים (כלומר, מותרת הפקעת משאבים), המערכת יכולה לכפות שחרור משאבים מתהליכים ולהשתמש בהם כדי לשבור מעגלי המתנה. לכן, קיפאון (שדורש את קיומו של תנאי אי-הפקעה) לא יכול להתרחש במצב כזה באופן מתמשך. המתנה מעגלית כשלעצמה יכולה להיווצר לרגע, אך אם מותרת הפקעה, היא לא תוכל להתמשך ולהפוך לקיפאון."}, "difficulty_estimation": "Medium", "_source_file": "0370__Deadlocks__MultipleChoice__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:08:06", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Deadlocks", "Deadlock Prevention", "Resource Management"], "content": {"text": "איזו מהאסטרטגיות הבאות מונעת מצב של קיפאון (deadlock) על ידי שבירת התנאי 'החזק והמתן' (Hold and Wait)?", "code_snippet": null, "options": ["א. לאפשר החרמה (preemption) של משאבים מתהליך המחזיק בהם.", "ב. לדרוש מתהליך לבקש ולקבל את כל המשאבים הנחוצים לו בתחילת ריצתו, לפני שיתחיל לבצע משימות כלשהן.", "ג. להגדיר סדר כולל (total ordering) לכל סוגי המשאבים ולדרוש מכל תהליך לבקש משאבים לפי סדר עולה.", "ד. לוודא כי משאבים מסוימים ניתנים לשימוש על ידי תהליך אחד בלבד בכל רגע נתון."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "תנאי 'החזק והמתן' (Hold and Wait) מתאר מצב שבו תהליך מחזיק במשאב אחד לפחות וממתין למשאבים נוספים המוחזקים על ידי תהליכים אחרים. אסטרטגיה ב' דורשת מתהליכים לבקש את כל המשאבים שלהם מראש. אם כל המשאבים זמינים, הם מוקצים לתהליך, והוא יכול להמשיך. אם לא, התהליך לא מקבל אף משאב וממתין עד שכולם יהיו זמינים. בדרך זו, תהליך לעולם לא יחזיק במשאבים כלשהם בזמן שהוא ממתין למשאבים אחרים, ובכך נשבר תנאי 'החזק והמתן'."}, "difficulty_estimation": "Medium", "_source_file": "0371__Deadlocks__MultipleChoice__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:08:18", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Deadlocks", "Synchronization", "Resource Management"], "content": {"text": "איזו מהטענות הבאות לגבי קיפאון (Deadlock) ושיטות הטיפול בו נכונה?", "code_snippet": null, "options": ["א. שיטות מניעת קיפאון (Deadlock Prevention) תמיד מבטיחות ניצול משאבים אופטימלי.", "ב. אלגוריתם הבנקאי (Banker's Algorithm) הוא דוגמה לשיטת גילוי קיפאון (Deadlock Detection).", "ג. הרעבה (Starvation) לעולם אינה יכולה להתרחש במערכת שבה קיפאון נמנע לחלוטין.", "ד. הפרת תנאי 'מניעה הדדית' (Mutual Exclusion) היא דרך אפשרית למנוע קיפאון, אך אינה ישימה לכל סוגי המשאבים."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "הסבר: \nא. לא נכון. שיטות מניעת קיפאון (לדוגמה, דרישת כל המשאבים מראש או אי-הפקעה) עלולות להוביל לניצול משאבים נמוך מכיוון שהן מחזיקות משאבים שלא בשימוש או מונעות הפקעה יעילה.\nב. לא נכון. אלגוריתם הבנקאי הוא שיטה למניעת קיפאון (Deadlock Avoidance), לא גילוי קיפאון (Deadlock Detection).\nג. לא נכון. הרעבה יכולה להתרחש גם במערכות שמונעות קיפאון (לדוגמה, תהליך בעל עדיפות נמוכה שנדחה באופן תמידי על ידי תהליכים בעלי עדיפות גבוהה יותר, ללא קשר לקיפאון).\nד. נכון. אם ניתן לאפשר למשאב שימוש משותף (לדוגמה, קריאה מקובץ), אין צורך ב'מניעה הדדית' עבורו, ובכך נמנע קיפאון הקשור למשאב זה. עם זאת, עבור משאבים שאינם ניתנים לשיתוף (כמו מדפסת), הפרת תנאי זה אינה אפשרית."}, "difficulty_estimation": "Medium", "_source_file": "0372__Deadlocks__MultipleChoice__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:08:40", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Deadlocks", "Synchronization"], "content": {"text": "נתבונן במערכת הכוללת מספר תהליכים (threads) ושני משאבים (R1 ו-R2), המוגנים על ידי מנעולים (mutex_R1 ו-mutex_R2 בהתאמה). כל תהליך זקוק לשני המשאבים כדי להשלים את פעולתו. איזה מהבאים מהווה שיטה יעילה למניעת קיפאון (deadlock) על ידי שבירת התנאי \"המתנה מעגלית\" (Circular Wait)?", "code_snippet": null, "options": ["א. כל תהליך מנסה לתפוס את mutex_R1, ואם הוא מצליח, הוא מנסה לתפוס את mutex_R2. אם הוא נכשל בתפיסת mutex_R2, הוא משחרר את mutex_R1 ומנסה שוב לאחר המתנה אקראית.", "ב. תהליכים מסוימים תופסים את mutex_R1 ואז את mutex_R2, בעוד שאחרים תופסים את mutex_R2 ואז את mutex_R1.", "ג. כל התהליכים במערכת תמיד תופסים את המנעולים בסדר קבוע ומוגדר מראש, למשל: תמיד mutex_R1 תחילה, ולאחר מכן mutex_R2.", "ד. המערכת אוכפת שכל תהליך יבקש את כל המשאבים שהוא צריך בבת אחת. אם לא ניתן להקצות את כולם, הוא לא מקבל אף אחד מהם."]}, "sub_questions": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התנאי 'המתנה מעגלית' מתקיים כאשר קיימת שרשרת של תהליכים, כאשר כל תהליך בשרשרת ממתין למשאב המוחזק על ידי התהליך הבא בשרשרת, והתהליך האחרון ממתין למשאב המוחזק על ידי התהליך הראשון. קביעת סדר גלובלי קבוע ומוגדר מראש ללקיחת משאבים (כמו תמיד R1 ואז R2) מונעת היווצרות של שרשרת כזו. אם כל התהליכים לוקחים את המשאבים באותו סדר, תהליך שלקח את R2 לא יכול לנסות לקחת את R1 (שכן זה מנוגד לסדר), ובכך נשבר התנאי של המתנה מעגלית. אפשרות א' מתייחסת יותר לשבירת 'החזק והמתן' או הימנעות מקיפאון, ואפשרות ד' שוברת את 'החזק והמתן'. אפשרות ב' היא למעשה תרחיש קלאסי שיוצר קיפאון."}, "difficulty_estimation": "Medium", "_source_file": "0373__Deadlocks__MultipleChoice__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:08:53", "_subject": "Concurrency"}, {"id": 10, "type": "MultipleChoice", "topic": ["Deadlocks", "Synchronization", "Concurrency"], "content": {"text": "איזו מהטענות הבאות נכונה לגבי תנאי קיפאון ומניעתם?", "code_snippet": null, "options": ["א. מניעת הדדיות (Mutual Exclusion) היא תמיד האסטרטגיה היעילה ביותר למניעת קיפאון.", "ב. אם מונעים מתהליכים להחזיק במשאב אחד תוך כדי המתנה למשאב אחר, קיפאון נמנע בהכרח.", "ג. יכולת הקצאת משאבים מחדש (Preemption) מבטיחה מניעת קיפאון לכל סוגי המשאבים.", "ד. אם גרף הקצאת המשאבים אינו מכיל מעגלים, קיפאון עדיין יכול להתרחש אם ישנם מספר מופעים מאותו סוג משאב."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "קיפאון (deadlock) מתרחש רק כאשר כל ארבעת התנאים ההכרחיים מתקיימים: מניעה הדדית (Mutual Exclusion), החזקה והמתנה (Hold and Wait), אי-פקיעה (No Preemption) והמתנה מעגלית (Circular Wait). מניעת אחד מהתנאים הללו מונעת קיפאון. אפשרות ב' מתארת מניעת החזקה והמתנה, ששוברת את אחד התנאים ההכרחיים ובכך מונעת קיפאון. אפשרות א' אינה נכונה מכיוון שלא תמיד ניתן או רצוי למנוע הדדיות (לדוגמה, במשאבים שאינם ניתנים לשיתוף). אפשרות ג' אינה נכונה מכיוון שלא כל המשאבים ניתנים לפקיעה (למשל, מדפסת באמצע הדפסה). אפשרות ד' אינה נכונה מכיוון שמעגל בגרף הקצאת המשאבים (Resource Allocation Graph) הוא תנאי הכרחי לקיפאון, וללא מעגל לא ייתכן קיפאון."}, "difficulty_estimation": "Medium", "_source_file": "0374__Deadlocks__MultipleChoice__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:09:04", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Deadlocks", "Deadlock Prevention", "Concurrency"], "content": {"text": "מערכת הפעלה מתמודדת עם האפשרות לקיפאון (deadlock) בין תהליכים. איזו אסטרטגיה נועדה למנוע באופן ישיר מצב של המתנה מעגלית (circular wait)?", "code_snippet": null, "options": ["א. ויתור על תנאי ההדרה ההדדית (mutual exclusion) על ידי הפיכת כל המשאבים לניתנים לשיתוף.", "ב. דרישה מכל תהליך לבקש את כל המשאבים הנדרשים לו בתחילת פעולתו, או לא לבקש כלל.", "ג. הגדרת סדר מוחלט (total ordering) לכל סוגי המשאבים, ודרישה מכל תהליך לבקש משאבים אך ורק בסדר עולה.", "ד. מתן אפשרות למערכת להפקיע משאבים מתהליך שמחזיק בהם וביקש משאבים נוספים שאינם זמינים."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "המתנה מעגלית (circular wait) מתרחשת כאשר קיימת שרשרת תהליכים, כאשר כל תהליך בשרשרת ממתין למשאב שמוחזק על ידי התהליך הבא בשרשרת. הגדרת סדר מוחלט לקבלת משאבים ודרישה מכל התהליכים לבקש משאבים רק בסדר עולה (למשל, ממשאב R1 למשאב R2, וכו') מונעת באופן ישיר היווצרות של מעגל המתנה. אם תהליך מחזיק במשאב R_i, הוא יכול לבקש רק משאבים R_j כאשר j > i. לכן, לא ניתן ליצור שרשרת שבה תהליך ממתין למשאב שמוחזק על ידי תהליך קודם בשרשרת, ובכך נמנעת המתנה מעגלית. אפשרות א' מונעת הדרה הדדית, ב' מונעת 'החזק והמתן' (hold and wait), ו-ד' מונעת 'אי-הפקעה' (no preemption). כל אלו הן אסטרטגיות למניעת קיפאון, אך ג' היא זו שמכוונת ישירות למניעת המתנה מעגלית."}, "difficulty_estimation": "Medium", "_source_file": "0375__Deadlocks__MultipleChoice__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:09:19", "_subject": "Concurrency"}, {"id": 101, "type": "MultipleChoice", "topic": ["Deadlocks", "Deadlock Avoidance", "Banker's Algorithm"], "content": {"text": "איזה מתנאי הקיפאון הבאים נמנע באופן ישיר על ידי שימוש באלגוריתם בנקאי (Banker's Algorithm)?", "code_snippet": null, "options": ["א. מניעה הדדית (Mutual Exclusion)", "ב. החזק והמתן (Hold and Wait)", "ג. אי-הפקעה (No Preemption)", "ד. המתנה מעגלית (Circular Wait)", "ה. אלגוריתם הבנקאי אינו מפר אף אחד מתנאי הקיפאון באופן ישיר, אלא מונע קיפאון על ידי הבטחת מצב בטוח."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ה", "explanation": "אלגוריתם הבנקאי הוא דוגמה לאסטרטגיית מניעת קיפאון (Deadlock Avoidance). אסטרטגיות מניעה (Avoidance) אינן מפרות אף אחד מארבעת תנאי הקיפאון (מניעה הדדית, החזק והמתן, אי-הפקעה, המתנה מעגלית) באופן ישיר. במקום זאת, הן דורשות מידע מוקדם על דרישות המשאבים של תהליכים ומקצות משאבים באופן דינמי רק אם המערכת נשארת במצב בטוח (safe state). מצב בטוח מבטיח שקיימת סדרה כלשהי של הקצאות משאבים המאפשרת לכל התהליכים לסיים את ביצועם מבלי להיכנס לקיפאון. לכן, האלגוריתם מונע קיפאון על ידי הבטחת מצב בטוח, ולא על ידי הפרת תנאי ספציפי."}, "difficulty_estimation": "Medium", "_source_file": "0376__Deadlocks__MultipleChoice__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:09:40", "_subject": "Concurrency"}, {"id": 10, "type": "MultipleChoice", "topic": ["Deadlocks", "Concurrency", "Synchronization"], "content": {"text": "נתון קטע הקוד הבא בשפת C++ המשתמש בשני מנעולים (mutexes) ובשני תהליכונים (threads). האם קיים סיכון למבוי סתום (deadlock) בקוד זה, ואם כן, מדוע?", "code_snippet": "#include <iostream>\n#include <thread>\n#include <mutex>\n#include <chrono>\n\nstd::mutex mutex_A;\nstd::mutex mutex_B;\n\nvoid thread_func1() {\n    std::cout << \"Thread 1: Trying to acquire mutex_A...\\n\";\n    mutex_A.lock();\n    std::cout << \"Thread 1: Acquired mutex_A. Trying to acquire mutex_B...\\n\";\n    std::this_thread::sleep_for(std::chrono::milliseconds(10)); // Simulate some work/delay\n    mutex_B.lock();\n    std::cout << \"Thread 1: Acquired mutex_B. Doing work...\\n\";\n    std::this_thread::sleep_for(std::chrono::milliseconds(50));\n    mutex_B.unlock();\n    std::cout << \"Thread 1: Released mutex_B.\\n\";\n    mutex_A.unlock();\n    std::cout << \"Thread 1: Released mutex_A.\\n\";\n}\n\nvoid thread_func2() {\n    std::cout << \"Thread 2: Trying to acquire mutex_B...\\n\";\n    mutex_B.lock();\n    std::cout << \"Thread 2: Acquired mutex_B. Trying to acquire mutex_A...\\n\";\n    std::this_thread::sleep_for(std::chrono::milliseconds(10)); // Simulate some work/delay\n    mutex_A.lock();\n    std::cout << \"Thread 2: Acquired mutex_A. Doing work...\\n\";\n    std::this_thread::sleep_for(std::chrono::milliseconds(50));\n    mutex_A.unlock();\n    std::cout << \"Thread 2: Released mutex_A.\\n\";\n    mutex_B.unlock();\n    std::cout << \"Thread 2: Released mutex_B.\\n\";\n}\n\n// Example usage (not part of the snippet for the question):\n// int main() {\n//     std::thread t1(thread_func1);\n//     std::thread t2(thread_func2);\n//     t1.join();\n//     t2.join();\n//     return 0;\n// }", "options": ["א. לא, מכיוון שכל תהליכון משחרר את המנעולים שהוא תפס בסופו של דבר.", "ב. כן, מכיוון ששני התהליכונים מנסים לתפוס את אותם מנעולים בסדר שונה, מה שעלול ליצור מצב של המתנה מעגלית.", "ג. לא, מכיוון שמערכת ההפעלה תזהה ותמנע מבוי סתום באופן אוטומטי.", "ד. כן, אך רק אם אחד התהליכונים יבצע פעולת I/O ארוכה בין תפיסת המנעול הראשון לשני.", "ה. לא, מכיוון ששימוש במנעולים (mutexes) תמיד מונע מבוי סתום."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. מבוי סתום (deadlock) יכול להתרחש בקוד זה. תהליכון 1 מנסה לתפוס את mutex_A ואז את mutex_B. תהליכון 2 מנסה לתפוס את mutex_B ואז את mutex_A. אם תהליכון 1 יתפוס את mutex_A ותהליכון 2 יתפוס את mutex_B בו-זמנית (או בסמיכות זמנים), אז תהליכון 1 ימתין ל-mutex_B שתפוס על ידי תהליכון 2, ותהליכון 2 ימתין ל-mutex_A שתפוס על ידי תהליכון 1. זהו מצב קלאסי של המתנה מעגלית (circular wait) הממלא את כל ארבעת התנאים למבוי סתום: הדרה הדדית (mutual exclusion), אחיזה והמתנה (hold and wait), אי-הפקעה (no preemption), והמתנה מעגלית. זמן ההמתנה הקצר (sleep_for) אינו הכרחי כדי ליצור את התנאים למבוי סתום, אלא רק מגדיל את הסיכוי שהוא יתרחש בפועל."}, "difficulty_estimation": "Hard", "_source_file": "0377__Deadlocks__MultipleChoice__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:09:55", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Deadlocks"], "content": {"text": "נתון קטע הקוד הבא בשפת C++ המכיל שלושה תהליכונים (threads) ושלושה מנעולים (mutexes). כל תהליכון מנסה לתפוס שני מנעולים בסדר מסוים.\n\n```cpp\n#include <iostream>\n#include <thread>\n#include <mutex>\n#include <vector>\n#include <chrono> // For std::this_thread::sleep_for\n\nstd::mutex m1, m2, m3;\n\nvoid thread_func_1() {\n    m1.lock();\n    std::this_thread::sleep_for(std::chrono::milliseconds(10)); // Simulate work\n    m2.lock();\n    // Do some work\n    m2.unlock();\n    m1.unlock();\n}\n\nvoid thread_func_2() {\n    m2.lock();\n    std::this_thread::sleep_for(std::chrono::milliseconds(10)); // Simulate work\n    m3.lock();\n    // Do some work\n    m3.unlock();\n    m2.unlock();\n}\n\nvoid thread_func_3() {\n    m3.lock();\n    std::this_thread::sleep_for(std::chrono::milliseconds(10)); // Simulate work\n    m1.lock();\n    // Do some work\n    m1.unlock();\n    m3.unlock();\n}\n```\n\nבהנחה שכל שלושת התהליכונים מופעלים במקביל, איזו מהטענות הבאות מתארת באופן המדויק ביותר את הסיבה למצב קיפאון פוטנציאלי בקוד הנתון?", "code_snippet": null, "options": ["א. לא ייתכן מצב קיפאון מכיוון שכל מנעול נתפס ומשוחרר בסופו של דבר.", "ב. מצב קיפאון ייתכן, והוא נובע בעיקר מהפרה של תנאי \"החזק והמתן\" (Hold and Wait).", "ג. מצב קיפאון ייתכן, והוא נובע בעיקר מהפרה של תנאי \"המתנה מעגלית\" (Circular Wait).", "ד. מצב קיפאון ייתכן, אך הוא אינו נובע מתנאי קיפאון קלאסיים אלא מתזמון לא נכון של קריאות ל-`sleep_for`.", "ה. מצב קיפאון ייתכן, וניתן למנוע אותו באופן יעיל על ידי הבטחת סדר תפיסה היררכי קבוע של המנעולים (לדוגמה, תמיד M1 ואז M2 ואז M3)."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הסבר: מצב קיפאון (deadlock) ייתכן בקוד הנתון. הוא נובע באופן מובהק מהפרה של תנאי \"המתנה מעגלית\" (Circular Wait). שלושת התהליכונים יוצרים שרשרת המתנה מעגלית: תהליכון 1 תופס את M1 וממתין ל-M2; תהליכון 2 תופס את M2 וממתין ל-M3; תהליכון 3 תופס את M3 וממתין ל-M1. אם כל אחד מהם יתפוס את המנעול הראשון שלו וינסה לתפוס את המנעול השני, כולם ימתינו זה לזה באופן אינסופי.\n\nא. לא נכון. עצם השחרור הסופי של המנעולים אינו מונע קיפאון אם סדר התפיסה מאפשר מעגל המתנה לפני השחרור.\nב. נכון שתנאי \"החזק והמתן\" מתקיים (כל תהליכון מחזיק במנעול אחד וממתין לאחר), אך \"המתנה מעגלית\" היא הסיבה הספציפית והישירה ביותר לקיפאון במקרה זה, ומתארת טוב יותר את דפוס הבעיה.\nד. לא נכון. קריאות ל-`sleep_for` רק מגדילות את הסיכוי שתיווצר הסיטואציה שתוביל לקיפאון, אך הן אינן הגורם היסודי לקיפאון. הגורם הוא סדר תפיסת המנעולים המאפשר המתנה מעגלית.\nה. נכון שזו דרך יעילה למנוע קיפאון על ידי שבירת תנאי ההמתנה המעגלית, אך השאלה מבקשת לתאר באופן המדויק ביותר את הסיבה לקיפאון בקוד הנתון, ולא להציע פתרון."}, "difficulty_estimation": "Hard", "_source_file": "0378__Deadlocks__MultipleChoice__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:10:24", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Deadlocks", "Synchronization", "Resource Allocation"], "content": {"text": "במערכת הפעלה קיימים N תהליכים. קיימים שני סוגי משאבים: ResourceA עם M_A מופעים, ו-ResourceB עם M_B מופעים. כל תהליך זקוק למופע אחד מ-ResourceA ולמופע אחד מ-ResourceB כדי לבצע את משימתו. כל התהליכים מקפידים על סדר קבוע של תפיסת משאבים: תחילה ResourceA, ולאחר מכן ResourceB. \n\nאיזו מהטענות הבאות נכונה בהכרח לגבי מצבי קיפאון (deadlocks) במערכת זו?", "code_snippet": null, "options": ["א. מצב קיפאון בלתי אפשרי, ללא קשר לערכי N, M_A ו-M_B (כל עוד הם חיוביים).", "ב. מצב קיפאון אפשרי אם N גדול יותר מ-M_A וגם מ-M_B.", "ג. מצב קיפאון אפשרי רק אם M_A=1 ו-M_B=1 ו-N>1.", "ד. מצב קיפאון אפשרי אם סכום המופעים הזמינים (M_A + M_B) קטן מ-N + 1.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "התשובה הנכונה היא א'. אחת מארבעת התנאים ההכרחיים למצב קיפאון הוא 'המתנה מעגלית' (Circular Wait). כאשר כל התהליכים מקפידים על סדר קבוע בתפיסת המשאבים (במקרה זה, תמיד ResourceA ואז ResourceB), נמנעת האפשרות ליצירת מעגל המתנה. תהליך שתופס את ResourceB לעולם לא ימתין ל-ResourceA, מכיוון שהוא כבר תפס אותו לפני ResourceB. לכן, לא ניתן ליצור שרשרת המתנה מעגלית שבה תהליך T1 ממתין למשאב שמוחזק על ידי T2, ותהליך T2 ממתין למשאב שמוחזק על ידי T1 (או שרשרת ארוכה יותר). מניעת תנאי 'המתנה מעגלית' מספיקה למניעת מצבי קיפאון, ללא קשר למספר התהליכים או למספר מופעי המשאבים הזמינים (כל עוד קיימים מופעים חיוביים). יש לשים לב כי שיטה זו מונעת קיפאון אך אינה מונעת בהכרח הרעבה (starvation)."}, "difficulty_estimation": "Hard", "_source_file": "0379__Deadlocks__MultipleChoice__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:11:00", "_subject": "Concurrency"}, {"id": 6, "type": "MultipleChoice", "topic": ["Deadlocks", "Concurrency", "C++ STL"], "content": {"text": "נתון קטע הקוד הבא ב-C++ המשתמש ב-`std::mutex`:\n\n```cpp\n#include <iostream>\n#include <thread>\n#include <mutex>\n#include <chrono>\n\nstd::mutex m1, m2;\n\nvoid process_data_A() {\n    m1.lock();\n    std::this_thread::sleep_for(std::chrono::milliseconds(50));\n    m2.lock();\n    std::cout << \"Process A acquired m1 and m2\\n\";\n    // ... critical section ...\n    m2.unlock();\n    m1.unlock();\n}\n\nvoid process_data_B() {\n    m2.lock();\n    std::this_thread::sleep_for(std::chrono::milliseconds(50));\n    m1.lock();\n    std::cout << \"Process B acquired m2 and m1\\n\";\n    // ... critical section ...\n    m1.unlock();\n    m2.unlock();\n}\n\nint main() {\n    std::thread t1(process_data_A);\n    std::thread t2(process_data_B);\n\n    t1.join();\n    t2.join();\n\n    std::cout << \"Main finished.\\n\";\n    return 0;\n}\n```\n\nאיזו מהטענות הבאות מתארת את הדרך *הנכונה והבטוחה ביותר* למנוע מצב קיפאון (deadlock) בקוד זה, תוך שימוש ביכולות ספריית ה-STL ב-C++?", "code_snippet": null, "options": ["א. יש לשנות את סדר נעילת המנעולים בפונקציה `process_data_B` כך שתמיד תנעל את `m1` ואז את `m2`, בדומה ל-`process_data_A`.", "ב. להשתמש ב-`std::lock_guard<std::mutex>` במקום קריאות `lock()` ו-`unlock()` ישירות, אך זה לא ימנע את הקיפאון.", "ג. במקום `lock()` ישיר, יש להשתמש ב-`m1.try_lock()` ו-`m2.try_lock()` ובמקרה של כישלון לשחרר את המנעולים שננעלו ולנסות שוב (backoff).", "ד. בכל אחת מהפונקציות (`process_data_A` ו-`process_data_B`), יש להחליף את הקריאות ל-`m1.lock(); m2.lock();` (או `m2.lock(); m1.lock();`) בקריאה אחת ל-`std::lock(m1, m2);` ולאחר מכן ליצור אובייקטי `std::unique_lock` עם `std::adopt_lock`.", "ה. אין דרך למנוע קיפאון בקוד זה ללא שינוי מהותי בארכיטקטורה של התוכנית."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "הקוד המקורי יכול לגרום למצב קיפאון (deadlock) בשל סדר נעילה שונה של המנעולים בשני התהליכים (`process_data_A` נועלת את `m1` ואז את `m2`, ואילו `process_data_B` נועלת את `m2` ואז את `m1`). אם כל תהליך מצליח לנעול את המנעול הראשון שלו לפני שהשני נועל את המנעול הראשון שלו, שניהם ימתינו זה לזה באופן אינסופי (מצב של 'החזק והמתן' ו'המתנה מעגלית').\n\nא. שינוי סדר הנעילה לשני התהליכים (למשל, תמיד `m1` ואז `m2`) אכן ימנע קיפאון, שכן הוא מבטל את תנאי ה'המתנה מעגלית'. זוהי דרך נכונה למנוע קיפאון, אך לא בהכרח ה'טובה ביותר' או ה'בטוחה ביותר' תוך שימוש ביכולות ספציפיות של ה-STL עבור מצב של נעילת מספר מנעולים במקביל, מכיוון שהיא דורשת הקפדה ידנית על הסדר בכל מקום בקוד.\nב. שימוש ב-`std::lock_guard` משפר את בטיחות הקוד מבחינת שחרור מנעולים אוטומטי (RAII) במקרה של יציאה מהבלוק או זריקת חריגה, אך הוא לא משנה את סדר הנעילה הפוטנציאלי לקיפאון אם הסדר נשאר שונה בין התהליכים.\nג. שימוש ב-`try_lock()` עם backoff הוא אכן אסטרטגיה למניעת קיפאון (על ידי ביטול תנאי ה'החזק והמתן' או 'אין כפייה'), אך היא דורשת מימוש ידני של לוגיקת הניסיון החוזר והיא מורכבת יותר מאשר הפתרון של `std::lock` עבור מצב זה של נעילת מספר מנעולים קבועים.\nד. הפונקציה `std::lock(m1, m2);` היא הפתרון המומלץ והבטוח ביותר בספריית ה-STL של C++ עבור נעילת מספר מנעולים במקביל. היא מבצעת את הנעילה של כל המנעולים באופן אטומי, כלומר, או שכל המנעולים ננעלים בהצלחה, או שאף אחד מהם לא ננעל (ובמקרה כזה היא מנסה שוב). בכך היא מונעת מצב שבו תהליך אחד מחזיק במנעול אחד וממתין למנעול אחר (hold and wait) בעוד תהליך אחר עושה את אותו הדבר בסדר הפוך. לאחר קריאה ל-`std::lock`, יש להשתמש ב-`std::unique_lock` עם `std::adopt_lock` כדי להעביר את הבעלות על המנעולים ל-RAII (Resource Acquisition Is Initialization) ולהבטיח שחרור נכון ואוטומטי של המנעולים בסיום הסקופ.\nה. טענה זו אינה נכונה; קיימות דרכים למנוע קיפאון בקוד זה, כפי שמודגם באפשרויות האחרות."}, "difficulty_estimation": "Hard", "_source_file": "0380__Deadlocks__MultipleChoice__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:11:28", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Deadlocks", "Synchronization", "Concurrency"], "content": {"text": "נתון קטע הקוד הבא המשתמש בשני מנעולים (mutexes), `mutexA` ו-`mutexB`, ובשני תהליכונים, `thread_func1` ו-`thread_func2`. ההנחה היא ששני המנעולים מאותחלים כראוי וששני התהליכונים רצים במקביל. איזה מהטענות הבאות נכונה לגבי קטע קוד זה?", "code_snippet": "#include <pthread.h>\n\n// Assume mutexA and mutexB are initialized globally.\npthread_mutex_t mutexA;\npthread_mutex_t mutexB;\n\nvoid* thread_func1(void* arg) {\n    pthread_mutex_lock(&mutexA);\n    // Critical section 1: uses mutexA\n    pthread_mutex_lock(&mutexB);\n    // Critical section 2: uses mutexA and mutexB\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    pthread_mutex_lock(&mutexB); // Different acquisition order\n    // Critical section 3: uses mutexB\n    pthread_mutex_lock(&mutexA); // Different acquisition order\n    // Critical section 4: uses mutexB and mutexA\n    pthread_mutex_unlock(&mutexA);\n    pthread_mutex_unlock(&mutexB);\n    return NULL;\n}\n// Assume main function creates and runs thread_func1 and thread_func2 concurrently.", "options": ["א. הקוד לעולם לא יגיע למצב של Deadlock, מכיוון שכל תהליכון משחרר את המנעולים בסדר הפוך לסדר שבו תפס אותם.", "ב. הקוד יגיע ל-Deadlock בוודאות בכל הרצה, מכיוון שסדר תפיסת המנעולים שונה בין התהליכונים.", "ג. הקוד עלול להגיע למצב של Deadlock עקב הפרה של תנאי \"אין מניעה מוקדמת\" (No Preemption), כיוון שהמנעולים אינם ניתנים להפקעה.", "ד. הקוד עלול להגיע למצב של Deadlock עקב הפרה של תנאי \"החזקה והמתנה\" (Hold and Wait) ו\"המתנה מעגלית\" (Circular Wait).", "ה. ניתן למנוע את ה-Deadlock בקלות על ידי החלפת כל קריאות `pthread_mutex_lock` ל-`pthread_mutex_trylock`."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "התשובה הנכונה היא ד'.\nהקוד מדגים מצב קלאסי של Deadlock שיכול להתרחש עקב הפרה של שני תנאים הכרחיים ל-Deadlock:\n1.  **החזקה והמתנה (Hold and Wait)**: כל אחד מהתהליכונים תופס מנעול אחד (thread_func1 תופס את mutexA, ו-thread_func2 תופס את mutexB) ולאחר מכן ממתין למנעול נוסף (thread_func1 ממתין ל-mutexB, ו-thread_func2 ממתין ל-mutexA) מבלי לשחרר את המנעול שכבר תפס.\n2.  **המתנה מעגלית (Circular Wait)**: נוצרת שרשרת המתנה מעגלית: thread_func1 ממתין למשאב (mutexB) המוחזק על ידי thread_func2, אשר ממתין בתורו למשאב (mutexA) המוחזק על ידי thread_func1.\nשני התנאים הנוספים ל-Deadlock, **מניעה הדדית (Mutual Exclusion)** ו**אין מניעה מוקדמת (No Preemption)**, מתקיימים באופן טאבוטי במנעולים (mutexes).\n\nא. שגויה. Deadlock אכן יכול להתרחש, כפי שהוסבר לעיל.\nב. שגויה. Deadlock אינו מובטח בכל הרצה; הוא תלוי בתזמון המדויק של פעולות התהליכונים, אך הוא אפשרי מאוד.\nג. שגויה. למרות שתנאי \"אין מניעה מוקדמת\" מתקיים במנעולים (לא ניתן להפקיע מנעול מתהליכון שתפס אותו), הוא אינו הגורם הישיר ל-Deadlock במקרה זה. הבעיה העיקרית נובעת מסדר תפיסת המשאבים השונה בין התהליכונים שמוביל להמתנה מעגלית.\nה. שגויה. שימוש ב-`pthread_mutex_trylock` מאפשר לתהליכון לנסות לתפוס מנעול מבלי להיחסם אם הוא תפוס. זהו כלי שימושי לאיתור וטיפול ב-Deadlock (למשל, על ידי שחרור מנעולים שכבר נתפסו וניסיון חוזר), אך הוא אינו מונע את תנאי ה-Deadlock מלהתקיים מלכתחילה. כדי למנוע Deadlock, נדרשת אסטרטגיה כמו תפיסת מנעולים בסדר קבוע ומוסכם על ידי כל התהליכונים."}, "difficulty_estimation": "Hard", "_source_file": "0381__Deadlocks__MultipleChoice__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:11:51", "_subject": "Concurrency"}, {"id": 6, "type": "MultipleChoice", "topic": ["Deadlocks", "Concurrency", "Synchronization"], "content": {"text": "נתון קטע הקוד הבא המשתמש בשני מנעולים (mutexes) ושני תהליכונים (threads) ב-C++:\n\n```cpp\n#include <iostream>\n#include <thread>\n#include <mutex>\n#include <chrono>\n\nstd::mutex mutexA;\nstd::mutex mutexB;\n\nvoid thread1_func() {\n    std::cout << \"Thread 1: Trying to lock mutexA...\" << std::endl;\n    mutexA.lock();\n    std::cout << \"Thread 1: Locked mutexA. Trying to lock mutexB...\" << std::endl;\n    std::this_thread::sleep_for(std::chrono::milliseconds(100)); // Simulate work\n    mutexB.lock();\n    std::cout << \"Thread 1: Locked mutexB.\" << std::endl;\n    // ... critical section ...\n    mutexB.unlock();\n    mutexA.unlock();\n    std::cout << \"Thread 1: Unlocked mutexA and mutexB.\" << std::endl;\n}\n\nvoid thread2_func() {\n    std::cout << \"Thread 2: Trying to lock mutexB...\" << std::endl;\n    mutexB.lock();\n    std::cout << \"Thread 2: Locked mutexB. Trying to lock mutexA...\" << std::endl;\n    std::this_thread::sleep_for(std::chrono::milliseconds(100)); // Simulate work\n    mutexA.lock();\n    std::cout << \"Thread 2: Locked mutexA.\" << std::endl;\n    // ... critical section ...\n    mutexA.unlock();\n    mutexB.unlock();\n    std::cout << \"Thread 2: Unlocked mutexA and mutexB.\" << std::endl;\n}\n\nint main() {\n    std::thread t1(thread1_func);\n    std::thread t2(thread2_func);\n\n    t1.join();\n    t2.join();\n\n    std::cout << \"Main: All threads finished.\" << std::endl;\n    return 0;\n}\n```\n\nבהתייחס לקטע הקוד לעיל, איזו מהטענות הבאות נכונה ביותר לגבי האפשרות למבוי סתום (deadlock)?", "code_snippet": null, "options": ["א. מבוי סתום אינו אפשרי בקוד זה מכיוון שכל תהליכון מנסה לנעול את המנעולים בזמן אחר.", "ב. מבוי סתום אפשרי, והדרך היחידה למנוע אותו היא להשתמש במנגנון `std::lock` עבור שני המנעולים יחד.", "ג. מבוי סתום אפשרי, והוא נגרם עקב העובדה שכל תהליכון מנסה לנעול את המשאבים בסדר שונה, מה שמהווה הפרה של התנאי \"המתנה מעגלית\" (Circular Wait).", "ד. מבוי סתום אינו אפשרי בקוד זה מכיוון שאין תלות בין המנעולים.", "ה. מבוי סתום אפשרי, אך ניתן למנוע אותו רק על ידי שימוש ב- `try_lock` ובדיקה חוזרת בלולאה עד להשגת שני המנעולים."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הקוד הנתון מדגים תרחיש קלאסי של מבוי סתום (deadlock) העומד בכל ארבעת התנאים ההכרחיים למבוי סתום:\n1.  **Mutual Exclusion (מניעה הדדית)**: המנעולים (`std::mutex`) מספקים מניעה הדדית; רק תהליכון אחד יכול להחזיק במנעול בכל רגע נתון.\n2.  **Hold and Wait (החזק והמתן)**: כל תהליכון תופס מנעול אחד (תהליכון 1 תופס את `mutexA`, תהליכון 2 תופס את `mutexB`) וממתין לתפוס את המנעול השני.\n3.  **No Preemption (אין דריסה)**: המנעולים אינם נלקחים בכוח מהתהליכונים; הם משוחררים רק מרצון על ידי התהליכון שמחזיק בהם.\n4.  **Circular Wait (המתנה מעגלית)**: זהו התנאי המרכזי שמופר כאן. תהליכון 1 מחזיק ב-`mutexA` וממתין ל-`mutexB` (שייתכן ומוחזק על ידי תהליכון 2). תהליכון 2 מחזיק ב-`mutexB` וממתין ל-`mutexA` (שייתכן ומוחזק על ידי תהליכון 1). נוצרת שרשרת המתנה מעגלית: תהליכון 1 ממתין למשאב שתהליכון 2 מחזיק, ותהליכון 2 ממתין למשאב שתהליכון 1 מחזיק. הסיבה העיקרית למצב זה היא הסדר השונה שבו התהליכונים מנסים לנעול את המשאבים.\n\nלכן, טענה ג' נכונה: מבוי סתום אפשרי, והוא נגרם עקב העובדה שכל תהליכון מנסה לנעול את המשאבים בסדר שונה, מה שמהווה הפרה של התנאי \"המתנה מעגלית\"."}, "difficulty_estimation": "Hard", "_source_file": "0382__Deadlocks__MultipleChoice__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:12:13", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Deadlocks", "Synchronization", "Concurrency"], "content": {"text": "נתונה מערכת עם N תהליכים (threads) ו-M מנעולים מסוג `pthread_mutex_t` המאוחסנים במערך `m[M]`. כל תהליך `i` (כאשר `i` נע מ-`0` עד `N-1`) מנסה לרכוש את המנעולים `m[0]` ו-`m[1]`. סדר רכישת המנעולים נקבע כדלקמן:\n\n- אם `i` זוגי, התהליך רוכש קודם את `m[0]` ולאחר מכן את `m[1]`.\n- אם `i` אי-זוגי, התהליך רוכש קודם את `m[1]` ולאחר מכן את `m[0]`.\n\nאיזו מהטענות הבאות נכונה לגבי התרחשות מצב קיפאון (Deadlock) במערכת זו? (הניחו כי M >= 2).", "code_snippet": "pthread_mutex_t m[M]; // M mutexes, M >= 2 assumed\n\nvoid* thread_func(void* arg) {\n    long thread_id = (long)arg;\n\n    if (thread_id % 2 == 0) { // Even threads\n        pthread_mutex_lock(&m[0]);\n        // Simulate some work or context switch\n        // usleep(1);\n        pthread_mutex_lock(&m[1]);\n    } else { // Odd threads\n        pthread_mutex_lock(&m[1]);\n        // Simulate some work or context switch\n        // usleep(1);\n        pthread_mutex_lock(&m[0]);\n    }\n\n    // Critical Section\n    // printf(\"Thread %ld acquired m[0] and m[1]\\n\", thread_id);\n\n    pthread_mutex_unlock(&m[1]); // Unlock in reverse order of acquisition\n    pthread_mutex_unlock(&m[0]);\n    return NULL;\n}", "options": ["א. מצב קיפאון יכול להתרחש רק אם N > M.", "ב. מצב קיפאון יכול להתרחש רק אם M > N.", "ג. מצב קיפאון יכול להתרחש אם N >= 2.", "ד. מצב קיפאון אינו יכול להתרחש כלל בשל אסטרטגיית הרכישה המתחלפת.", "ה. מצב קיפאון יכול להתרחש רק אם N אי-זוגי."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התשובה הנכונה היא ג'. מצב קיפאון (Deadlock) יכול להתרחש אם N >= 2. ננתח מדוע:\n\nהתנאים ההכרחיים למצב קיפאון הם: הדדיות (Mutual Exclusion), החזקה והמתנה (Hold and Wait), אי-הפקעה (No Preemption), והמתנה מעגלית (Circular Wait).\n\n1.  **הדדיות, החזקה והמתנה, אי-הפקעה:** מנעולי `pthread_mutex_t` מספקים את שלושת התנאים הללו באופן טבעי. תהליכים מחזיקים במנעול אחד וממתינים לאחר, ולא ניתן להפקיע מנעול מתהליך שמחזיק בו.\n2.  **המתנה מעגלית:** זהו התנאי הקריטי כאן. נבחן את תהליך 0 ואת תהליך 1:\n    *   **תהליך 0 (thread_id = 0, זוגי):** מנסה לרכוש את `m[0]` ולאחר מכן את `m[1]`.\n    *   **תהליך 1 (thread_id = 1, אי-זוגי):** מנסה לרכוש את `m[1]` ולאחר מכן את `m[0]`.\n\n    אם קיימים לפחות שני תהליכים (כלומר N >= 2), אז יהיה קיים לפחות תהליך אחד זוגי (לדוגמה, תהליך 0) ולפחות תהליך אחד אי-זוגי (לדוגמה, תהליך 1). נניח שתהליך 0 רוכש את `m[0]` ותהליך 1 רוכש את `m[1]`. כעת, תהליך 0 ממתין ל-`m[1]` (שמוחזק על ידי תהליך 1), ותהליך 1 ממתין ל-`m[0]` (שמוחזק על ידי תהליך 0). זהו מצב של המתנה מעגלית קלאסית (AB-BA deadlock).\n\n    ההנחה ש-M >= 2 מבטיחה ש-`m[0]` ו-`m[1]` הם מנעולים שונים וקיימים.\n\n    לכן, ברגע שישנם לפחות שני תהליכים (N >= 2), תמיד יכול להיווצר תרחיש שבו תהליך זוגי ותהליך אי-זוגי יכנסו למצב המתנה מעגלית. התשובות האחרות שגויות מכיוון שהן מציעות תנאים שאינם הכרחיים או שגויים לגבי התרחשות הקיפאון."}, "difficulty_estimation": "Hard", "_source_file": "0383__Deadlocks__MultipleChoice__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:12:56", "_subject": "Concurrency"}, {"id": 1, "type": "MultipleChoice", "topic": ["Deadlocks", "Synchronization", "Concurrency"], "content": {"text": "נתון קטע הקוד הבא בשפת C המציג שני תהליכונים המנסים לרכוש שני משאבים (mutexes) באמצעות אסטרטגיית 'שחרור וניסיון חוזר' (release and retry) כאשר רכישת המשאב השני נכשלת. איזה מבין המשפטים הבאים נכון לגבי קטע קוד זה?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex_resA = PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_t mutex_resB = PTHREAD_MUTEX_INITIALIZER;\n\n// Function to simulate a process acquiring resources\nvoid* acquire_resources(void* arg) {\n    long thread_id = (long)arg;\n    int first_res_id = (thread_id == 0) ? 0 : 1; // Thread 0 tries A then B, Thread 1 tries B then A\n    int second_res_id = (thread_id == 0) ? 1 : 0;\n\n    pthread_mutex_t* first_mutex = (first_res_id == 0) ? &mutex_resA : &mutex_resB;\n    pthread_mutex_t* second_mutex = (second_res_id == 0) ? &mutex_resA : &mutex_resB;\n\n    printf(\"Thread %ld trying to acquire mutex %d\\n\", thread_id, first_res_id);\n    pthread_mutex_lock(first_mutex);\n    printf(\"Thread %ld acquired mutex %d\\n\", thread_id, first_res_id);\n\n    sleep(1); // Simulate some work/hold time\n\n    printf(\"Thread %ld trying to acquire mutex %d\\n\", thread_id, second_res_id);\n    while (pthread_mutex_trylock(second_mutex) != 0) {\n        printf(\"Thread %ld failed to acquire mutex %d, releasing mutex %d and retrying...\\n\", thread_id, second_res_id, first_res_id);\n        pthread_mutex_unlock(first_mutex);\n        sleep(1); // Wait a bit before retrying\n        pthread_mutex_lock(first_mutex);\n        printf(\"Thread %ld re-acquired mutex %d\\n\", thread_id, first_res_id);\n    }\n    printf(\"Thread %ld acquired mutex %d\\n\", thread_id, second_res_id);\n\n    // Critical section\n    printf(\"Thread %ld in critical section with both mutexes\\n\", thread_id);\n    sleep(1);\n\n    pthread_mutex_unlock(second_mutex);\n    pthread_mutex_unlock(first_mutex);\n    printf(\"Thread %ld released both mutexes and finished\\n\", thread_id);\n    return NULL;\n}\n\nint main() {\n    pthread_t t0, t1;\n    pthread_create(&t0, NULL, acquire_resources, (void*)0);\n    pthread_create(&t1, NULL, acquire_resources, (void*)1);\n\n    pthread_join(t0, NULL);\n    pthread_join(t1, NULL);\n\n    printf(\"Main: All threads completed.\\n\");\n    return 0;\n}", "options": ["א. הקוד יכנס למצב קיפאון (deadlock) בוודאות, מכיוון שתנאי \"המתנה מעגלית\" (Circular Wait) מתקיים.", "ב. הקוד לעולם לא יכנס למצב קיפאון, מכיוון שהוא מונע את תנאי \"החזק והמתן\" (Hold and Wait).", "ג. הקוד לעולם לא יכנס למצב קיפאון, מכיוון שהוא מונע את תנאי \"אי-נטילה מוקדמת\" (No Preemption).", "ד. הקוד עלול להיכנס למצב קיפאון, אך רק תחת עומס גבוה מאוד של תהליכונים נוספים.", "ה. הקוד לעולם לא יכנס למצב קיפאון, אך עלול לסבול מרעב (starvation) של אחד התהליכונים לאורך זמן."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הקוד מיישם אסטרטגיה שבה אם תהליכון אינו מצליח לרכוש את המשאב השני הנדרש לו באמצעות `pthread_mutex_trylock`, הוא *משחרר* את המשאב הראשון שהוא מחזיק ומנסה שוב את תהליך הרכישה. פעולה זו מונעת במפורש את תנאי \"החזק והמתן\" (Hold and Wait) הנדרש להיווצרות קיפאון. תנאי זה קובע שתהליך מחזיק במשאב אחד לפחות וממתין לרכישת משאבים נוספים המוחזקים על ידי תהליכים אחרים. על ידי שחרור המשאב הראשון, התהליכון אינו \"מחזיק וממתין\" במובן הבעייתי, ובכך נמנעת היווצרות תלות מעגלית שתוביל לקיפאון. בעוד שאסטרטגיה זו עשויה באופן תיאורטי להוביל לרעב (starvation) - מצב בו תהליכון מסוים נכשל שוב ושוב ברכישת שני המשאבים וממשיך לנסות ללא הצלחה - היא מונעת ביעילות מצב קיפאון (deadlock)."}, "difficulty_estimation": "Hard", "_source_file": "0384__Deadlocks__MultipleChoice__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:13:27", "_subject": "Concurrency"}, {"id": 9, "type": "Open", "topic": ["Deadlocks"], "content": {"text": "נתונות שתי תוכניות (תהליכים/תהליכונים) P1 ו-P2, ושני משאבים R1 ו-R2. כל תוכנית זקוקה לשני המשאבים כדי להשלים את פעולתה.\n\nP1 מבקש תחילה את R1, ואז את R2.\nP2 מבקש תחילה את R2, ואז את R1.\n\nהאם מצב זה עלול להוביל לקיפאון (Deadlock)? אם כן, הסבירו מדוע, תוך התייחסות לארבעת התנאים ההכרחיים לקיומו של קיפאון.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, מצב זה עלול להוביל לקיפאון (Deadlock).\n\nהסבר תוך התייחסות לארבעת התנאים ההכרחיים לקיפאון:\n\n1.  **מניעה הדדית (Mutual Exclusion):** מתקיים. המשאבים R1 ו-R2 הם משאבים שאינם ניתנים לשיתוף (לדוגמה, מנעולים או התקנים בלעדיים), ולכן רק תוכנית אחת יכולה להחזיק כל משאב בכל רגע נתון. אם תוכנית אחת תופסת את R1, תוכנית אחרת לא יכולה לתפוס אותו בו זמנית.\n\n2.  **החזק והמתן (Hold and Wait):** מתקיים. נניח ש-P1 תופס את R1 ו-P2 תופס את R2. כעת, P1 מחזיק ב-R1 וממתין ל-R2 (שמוחזק על ידי P2), ו-P2 מחזיק ב-R2 וממתין ל-R1 (שמוחזק על ידי P1). כל תוכנית מחזיקה משאב אחד לפחות וממתינה למשאב נוסף המוחזק על ידי תוכנית אחרת.\n\n3.  **אי-הפקעה (No Preemption):** מתקיים. מניחים שהמשאבים R1 ו-R2 אינם ניתנים להפקעה. כלומר, ברגע שתוכנית תפסה משאב, היא תשחרר אותו רק מרצונה החופשי לאחר שסיימה את השימוש בו. המערכת לא יכולה לקחת את המשאב מתוכנית בכוח.\n\n4.  **המתנה מעגלית (Circular Wait):** מתקיים. במצב שבו P1 מחזיק ב-R1 וממתין ל-R2, ו-P2 מחזיק ב-R2 וממתין ל-R1, נוצרת שרשרת המתנה מעגלית: P1 ממתין למשאב שמוחזק על ידי P2, ו-P2 ממתין למשאב שמוחזק על ידי P1. כלומר, P1 -> P2 -> P1.\n\nמכיוון שכל ארבעת התנאים יכולים להתקיים בו זמנית בתרחיש זה, קיפאון הוא אפשרי."}, "difficulty_estimation": "Easy", "_source_file": "0385__Deadlocks__Open__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:13:37", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Deadlocks"], "content": {"text": "הגדר מהו קיפאון (deadlock) במערכת הפעלה, ופרט את ארבעת התנאים ההכרחיים לקיומו.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "קיפאון (deadlock) הוא מצב במערכת הפעלה שבו שני תהליכים או יותר חסומים באופן אינסופי, כאשר כל אחד מהם ממתין למשאב שמוחזק על ידי תהליך אחר בקבוצה.\n\nארבעת התנאים ההכרחיים לקיומו של קיפאון הם:\n1.  **מניעה הדדית (Mutual Exclusion)**: לפחות משאב אחד חייב להיות בלתי ניתן לשיתוף, כלומר, רק תהליך אחד יכול להשתמש בו בכל פעם.\n2.  **החזק והמתן (Hold and Wait)**: תהליך חייב להחזיק לפחות משאב אחד, תוך כדי שהוא ממתין למשאבים נוספים שמוחזקים על ידי תהליכים אחרים.\n3.  **אי-נשללות (No Preemption)**: משאבים אינם יכולים להילקח מתהליך בכוח; הם חייבים להשתחרר מרצון על ידי התהליך שמחזיק אותם, רק לאחר שהשלים את השימוש בהם.\n4.  **המתנה מעגלית (Circular Wait)**: חייבת להתקיים שרשרת מעגלית של תהליכים, כאשר כל תהליך בשרשרת ממתין למשאב שמוחזק על ידי התהליך הבא בשרשרת."}, "difficulty_estimation": "Easy", "_source_file": "0386__Deadlocks__Open__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:13:47", "_subject": "Concurrency"}, {"id": 9, "type": "Open", "topic": ["Deadlocks"], "content": {"text": "מהם ארבעת התנאים ההכרחיים לקיום קיפאון (deadlock) במערכת הפעלה? הסבר בקצרה כל אחד מהם.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ארבעת התנאים ההכרחיים לקיום קיפאון הם:\n1.  **מניעה הדדית (Mutual Exclusion):** לפחות משאב אחד במערכת חייב להיות משאב לא שיתופי (non-sharable), כלומר, ניתן לשימוש על ידי תהליך אחד בלבד בכל רגע נתון. אם משאב ניתן לשיתוף, תהליכים יכולים להשתמש בו במקביל ולא ייווצר קיפאון עליו.\n2.  **החזק והמתן (Hold and Wait):** תהליך אחד מחזיק במשאב אחד לפחות וממתין לרכישת משאבים נוספים המוחזקים על ידי תהליכים אחרים.\n3.  **אי-הפקעה (No Preemption):** לא ניתן להפקיע משאב מתהליך המחזיק בו; המשאב חייב להשתחרר באופן וולונטרי על ידי התהליך לאחר שסיים את השימוש בו.\n4.  **המתנה מעגלית (Circular Wait):** קיימת שרשרת מעגלית של תהליכים, כאשר כל תהליך בשרשרת ממתין למשאב המוחזק על ידי התהליך הבא בשרשרת, והתהליך האחרון ממתין למשאב המוחזק על ידי התהליך הראשון."}, "difficulty_estimation": "Easy", "_source_file": "0387__Deadlocks__Open__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:13:55", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Deadlocks"], "content": {"text": "הגדר מהו קיפאון (deadlock) בהקשר של מערכות הפעלה. בנוסף, ציין והסבר בקצרה את ארבעת התנאים ההכרחיים לקיומו של קיפאון.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסבר:\nקיפאון (Deadlock) הוא מצב במערכת הפעלה שבו שני תהליכים (או יותר) חסומים באופן קבוע, כאשר כל אחד מהם ממתין למשאב המוחזק על ידי תהליך אחר שנמצא גם הוא במצב חסימה.\n\nארבעת התנאים ההכרחיים לקיום קיפאון הם:\n1.  **מניעה הדדית (Mutual Exclusion):** לפחות משאב אחד חייב להיות בלתי ניתן לשיתוף, כלומר, רק תהליך אחד יכול להשתמש בו בכל רגע נתון. אם משאב ניתן לשיתוף (כמו קובץ לקריאה בלבד), מניעה הדדית אינה נדרשת וקיפאון אינו יכול להתרחש עבור משאבים כאלה.\n2.  **החזק והמתן (Hold and Wait):** תהליך חייב להחזיק לפחות משאב אחד ובמקביל להמתין למשאבים נוספים המוחזקים על ידי תהליכים אחרים.\n3.  **אי-הפקעה (No Preemption):** משאב לא יכול להילקח בכוח מתהליך שמחזיק בו. הוא חייב להשתחרר באופן וולונטרי על ידי התהליך לאחר שסיים את השימוש בו.\n4.  **המתנה מעגלית (Circular Wait):** קיימת שרשרת מעגלית של תהליכים {P0, P1, ..., Pn} כך ש-P0 ממתין למשאב המוחזק על ידי P1, P1 ממתין למשאב המוחזק על ידי P2, וכן הלאה, עד ש-Pn ממתין למשאב המוחזק על ידי P0."}, "difficulty_estimation": "Easy", "_source_file": "0388__Deadlocks__Open__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:14:03", "_subject": "Concurrency"}, {"id": 9, "type": "Open", "topic": ["Deadlocks", "Operating Systems Concepts"], "content": {"text": "הגדר מהו קיפאון (Deadlock) במערכת הפעלה, וציין את ארבעת התנאים ההכרחיים לקיומו.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסבר: קיפאון (Deadlock) הוא מצב במערכת הפעלה שבו שני תהליכים או יותר חסומים באופן בלתי מוגבל, כאשר כל אחד מהם ממתין למשאב שמוחזק על ידי תהליך אחר שנמצא גם הוא במצב חסימה. כלומר, אף תהליך לא יכול להמשיך בביצועו.\n\nארבעת התנאים ההכרחיים לקיום קיפאון הם:\n1.  **מניעה הדדית (Mutual Exclusion):** לפחות משאב אחד חייב להיות מוחזק במצב לא שיתופי (non-sharable mode), כלומר, רק תהליך אחד יכול להשתמש במשאב זה בזמן נתון.\n2.  **החזק והמתן (Hold and Wait):** תהליך שמחזיק לפחות משאב אחד ממתין לרכישת משאבים נוספים המוחזקים על ידי תהליכים אחרים.\n3.  **אי-הפקעה (No Preemption):** לא ניתן להפקיע משאבים מתהליך שמחזיק בהם; משאב יכול להשתחרר רק באופן וולונטרי על ידי התהליך המחזיק בו, לאחר שהתהליך סיים את משימתו.\n4.  **המתנה מעגלית (Circular Wait):** קיימת קבוצת תהליכים {P0, P1, ..., Pn} כך ש-P0 ממתין למשאב המוחזק על ידי P1, P1 ממתין למשאב המוחזק על ידי P2, ..., Pn-1 ממתין למשאב המוחזק על ידי Pn, ו-Pn ממתין למשאב המוחזק על ידי P0."}, "difficulty_estimation": "Easy", "_source_file": "0389__Deadlocks__Open__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:14:12", "_subject": "Concurrency"}, {"id": 9, "type": "Open", "topic": ["Deadlocks"], "content": {"text": "הסבר בקצרה מהו קיפאון (deadlock) במערכת הפעלה, וציין את ארבעת התנאים ההכרחיים לקיומו.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "קיפאון (deadlock) הוא מצב במערכת הפעלה שבו שני תהליכים או יותר חסומים באופן קבוע וממתינים זה לזה לשחרור משאבים, כאשר כל אחד מהם מחזיק במשאב שהאחר זקוק לו ואינו יכול להמשיך.\n\nארבעת התנאים ההכרחיים לקיומו של קיפאון הם:\n1.  **מניעה הדדית (Mutual Exclusion):** משאב יכול להיות מוחזק על ידי תהליך אחד בלבד בכל רגע נתון. אם תהליך אחר מבקש את המשאב, עליו להמתין עד שהמשאב ישוחרר.\n2.  **החזקה והמתנה (Hold and Wait):** תהליך מחזיק במשאב אחד לפחות וממתין למשאבים נוספים המוחזקים על ידי תהליכים אחרים.\n3.  **אי-הפקעה (No Preemption):** משאבים אינם ניתנים להפקעה. הם יכולים להשתחרר רק באופן וולונטרי על ידי התהליך שמחזיק אותם, לאחר שסיים את השימוש בהם.\n4.  **המתנה מעגלית (Circular Wait):** קיימת שרשרת מעגלית של תהליכים, כאשר כל תהליך בשרשרת ממתין למשאב המוחזק על ידי התהליך הבא בשרשרת."}, "difficulty_estimation": "Easy", "_source_file": "0390__Deadlocks__Open__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:14:21", "_subject": "Concurrency"}, {"id": 9, "type": "Open", "topic": ["Deadlocks"], "content": {"text": "מהו קיפאון (Deadlock) במערכות הפעלה? פרטו את ארבעת התנאים ההכרחיים לקיומו.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "קיפאון (Deadlock) הוא מצב במערכת הפעלה שבו שני תהליכים או יותר חסומים באופן קבוע, כאשר כל אחד מהם ממתין למשאב שמוחזק על ידי תהליך אחר בקבוצה.\n\nארבעת התנאים ההכרחיים לקיום קיפאון הם:\n1.  **מניעה הדדית (Mutual Exclusion):** לפחות משאב אחד חייב להיות בלתי ניתן לשיתוף. כלומר, רק תהליך אחד יכול להשתמש במשאב בכל רגע נתון.\n2.  **החזקה והמתנה (Hold and Wait):** תהליך חייב להחזיק לפחות משאב אחד ובמקביל להמתין למשאבים נוספים שמוחזקים על ידי תהליכים אחרים.\n3.  **אי-נשללות (No Preemption):** משאבים אינם ניתנים לשלילה בכוח. משאב יכול להשתחרר רק באופן יזום על ידי התהליך שמחזיק אותו, לאחר שסיים את השימוש בו.\n4.  **המתנה מעגלית (Circular Wait):** קיימת שרשרת מעגלית של שני תהליכים או יותר, כאשר כל תהליך בשרשרת ממתין למשאב שמוחזק על ידי התהליך הבא בשרשרת."}, "difficulty_estimation": "Easy", "_source_file": "0391__Deadlocks__Open__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:14:29", "_subject": "Concurrency"}, {"id": 9, "type": "Open", "topic": ["Deadlocks"], "content": {"text": "מהו קיפאון (deadlock) בהקשר של מערכות הפעלה, ומהם ארבעת התנאים ההכרחיים לקיומו?", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "קיפאון הוא מצב שבו שני תהליכים או יותר חוסמים זה את זה באופן הדדי, כאשר כל אחד מהם ממתין למשאב שמוחזק על ידי תהליך אחר בקבוצה, ולאף אחד מהם אין את היכולת להמשיך בביצוע. כתוצאה מכך, אף אחד מהתהליכים לא יכול להשלים את משימתו ולשחרר את המשאבים שברשותו.\n\nארבעת התנאים ההכרחיים לקיום קיפאון הם:\n1.  **מניעה הדדית (Mutual Exclusion)**: לפחות משאב אחד חייב להיות בלתי ניתן לשיתוף. כלומר, רק תהליך אחד יכול להשתמש במשאב בכל רגע נתון.\n2.  **החזקה והמתנה (Hold and Wait)**: תהליך חייב להחזיק לפחות במשאב אחד ולהמתין למשאב נוסף שמוחזק על ידי תהליך אחר.\n3.  **אי-נשללות (No Preemption)**: לא ניתן לשלול משאבים מתהליך בכוח. משאב יכול להשתחרר רק באופן יזום על ידי התהליך שמחזיק בו, לאחר שסיים את השימוש בו.\n4.  **המתנה מעגלית (Circular Wait)**: חייבת להתקיים שרשרת מעגלית של תהליכים, כאשר כל תהליך ממתין למשאב שמוחזק על ידי התהליך הבא בשרשרת."}, "difficulty_estimation": "Easy", "_source_file": "0392__Deadlocks__Open__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:14:38", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Deadlocks", "Synchronization", "Concurrency"], "content": {"text": "נתונים שני תהליכונים (threads), P1 ו-P2, המנסים לגשת לשני משאבים משותפים, R1 ו-R2. כל משאב מוגן על ידי מנעול (mutex) נפרד, M1 ו-M2 בהתאמה.\n\nהקוד הבא מציג את אופן הגישה למשאבים על ידי שני התהליכונים:\n\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t M1;\npthread_mutex_t M2;\n\nvoid* thread_func_P1(void* arg) {\n    printf(\"P1: Trying to acquire M1...\\n\");\n    pthread_mutex_lock(&M1);\n    printf(\"P1: Acquired M1. Trying to acquire M2...\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&M2);\n    printf(\"P1: Acquired M2. Critical section...\\n\");\n    // Critical section\n    pthread_mutex_unlock(&M2);\n    printf(\"P1: Released M2.\\n\");\n    pthread_mutex_unlock(&M1);\n    printf(\"P1: Released M1. Exiting.\\n\");\n    return NULL;\n}\n\nvoid* thread_func_P2(void* arg) {\n    printf(\"P2: Trying to acquire M2...\\n\");\n    pthread_mutex_lock(&M2);\n    printf(\"P2: Acquired M2. Trying to acquire M1...\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&M1);\n    printf(\"P2: Acquired M1. Critical section...\\n\");\n    // Critical section\n    pthread_mutex_unlock(&M1);\n    printf(\"P2: Released M1.\\n\");\n    pthread_mutex_unlock(&M2);\n    printf(\"P2: Released M2. Exiting.\\n\");\n    return NULL;\n}\n```\n\n1. האם קיימת אפשרות לקיפאון (deadlock) בתרחיש זה? נמקו והסבירו אילו מתנאי הקיפאון (Mutual exclusion, Hold-and-wait, No preemption, Circular wait) מתקיימים במקרה זה.\n2. הציעו פתרון לבעיית הקיפאון על ידי שינוי הקוד הנתון, והסבירו מדוע הפתרון שלכם מונע קיפאון.", "code_snippet": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. כן, קיימת אפשרות לקיפאון (deadlock) בתרחיש זה. הקיפאון יתרחש אם P1 יתפוס את M1 ו-P2 יתפוס את M2 בו זמנית, ולאחר מכן כל אחד מהם ינסה לתפוס את המנעול השני שמוחזק על ידי האחר.\n\nתנאי הקיפאון המתקיימים הם:\n*   **מניעה הדדית (Mutual exclusion)**: מתקיים. המנעולים M1 ו-M2 הם mutexes, מה שאומר שרק תהליכון אחד יכול להחזיק בכל מנעול נתון בזמן מסוים. אין אפשרות למשאב להישאר משותף לחלוטין.\n*   **החזק והמתן (Hold and Wait)**: מתקיים. תהליכון P1 מחזיק במנעול M1 וממתין למנעול M2. תהליכון P2 מחזיק במנעול M2 וממתין למנעול M1.\n*   **אי-הפקעה (No Preemption)**: מתקיים. המנעולים לא יכולים להילקח בכוח מתהליכון שמחזיק בהם. תהליכון חייב לשחרר את המנעול מרצונו.\n*   **המתנה מעגלית (Circular Wait)**: מתקיים. P1 ממתין למנעול M2 שמוחזק על ידי P2, ו-P2 ממתין למנעול M1 שמוחזק על ידי P1. זה יוצר מעגל המתנה.\n\n2. כדי למנוע קיפאון, ניתן להבטיח סדר קבוע לרכישת המשאבים (מנעולים) על ידי כל התהליכונים. גישה זו שוברת את תנאי ה'המתנה מעגלית'.\n\n**פתרון מוצע**: כל התהליכונים ירכשו את M1 תחילה, ולאחר מכן את M2. לדוגמה, נשנה את הפונקציה `thread_func_P2` כך שתתפוס את M1 לפני M2:\n\n```c\nvoid* thread_func_P2(void* arg) {\n    printf(\"P2: Trying to acquire M1...\\n\");\n    pthread_mutex_lock(&M1); // Changed order\n    printf(\"P2: Acquired M1. Trying to acquire M2...\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&M2); // Changed order\n    printf(\"P2: Acquired M2. Critical section...\\n\");\n    // Critical section\n    pthread_mutex_unlock(&M2);\n    printf(\"P2: Released M2.\\n\");\n    pthread_mutex_unlock(&M1);\n    printf(\"P2: Released M1. Exiting.\\n\");\n    return NULL;\n}\n```\n\n**הסבר מדוע הפתרון מונע קיפאון**: על ידי אכיפת סדר רכישה עקבי (לדוגמה, תמיד M1 ואז M2), אנו מבטיחים שלא תיווצר לעולם שרשרת המתנה מעגלית. אם P1 תופס את M1 וממתין ל-M2, ו-P2 מגיע ומנסה לתפוס את M1, P2 ייחסם על M1 עד ש-P1 ישחרר אותו. P1 יצליח לתפוס את M2, יסיים את הקטע הקריטי, וישחרר את שני המנעולים. רק אז P2 יוכל להמשיך ולתפוס את M1 (ולאחר מכן את M2). מכיוון שאין אפשרות ש-P1 יחזיק את M1 וימתין ל-M2, בעוד P2 יחזיק את M2 וימתין ל-M1, תנאי ה'המתנה מעגלית' נשבר והקיפאון נמנע."}, "difficulty_estimation": "Medium", "_source_file": "0393__Deadlocks__Open__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:15:02", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Deadlocks", "Synchronization", "Concurrency"], "content": {"text": "נתונה פיסת קוד בשפת C++ המממשת שתי פונקציות, `transfer_money` ו-`update_balance`, המשתמשות בשני מנעולים (mutexes) שונים, `lockA` ו-`lockB`. נתחו את הקוד המצורף והסבירו האם קיים סיכון לקיפאון (deadlock). אם כן, תארו מצב שבו קיפאון אכן מתרחש, והציעו פתרון לבעיה. הפתרון צריך למנוע קיפאון תוך שמירה על נכונות הפעולות.", "code_snippet": "#include <mutex>\n#include <thread>\n#include <iostream>\n\nstd::mutex lockA;\nstd::mutex lockB;\n\nvoid transfer_money(int from_account, int to_account, double amount) {\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Trying to lock A for transfer.\" << std::endl;\n    lockA.lock();\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Locked A. Trying to lock B.\" << std::endl;\n    lockB.lock();\n    \n    // Simulate money transfer\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Transferring \" << amount \n              << \" from \" << from_account << \" to \" << to_account << std::endl;\n    \n    lockB.unlock();\n    lockA.unlock();\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Unlocked A and B. Transfer complete.\" << std::endl;\n}\n\nvoid update_balance(int account, double new_balance) {\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Trying to lock B for update.\" << std::endl;\n    lockB.lock();\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Locked B. Trying to lock A.\" << std::endl;\n    lockA.lock();\n\n    // Simulate balance update\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Updating balance for account \" \n              << account << \" to \" << new_balance << std::endl;\n\n    lockA.unlock();\n    lockB.unlock();\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Unlocked B and A. Update complete.\" << std::endl;\n}\n\nint main() {\n    std::thread t1(transfer_money, 101, 102, 50.0);\n    std::thread t2(update_balance, 101, 1000.0);\n\n    t1.join();\n    t2.join();\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ניתוח קיפאון (Deadlock Analysis):\nכן, קיים סיכון לקיפאון בקוד המצורף. קיפאון יכול להתרחש כאשר מתקיימים ארבעת התנאים הבאים:\n1.  **מניעה הדדית (Mutual Exclusion):** המנעולים (`lockA`, `lockB`) מבטיחים שתא אחד בלבד יכול להחזיק משאב מסוים (את המנעול) בכל רגע נתון.\n2.  **החזקה והמתנה (Hold and Wait):** חוט יכול להחזיק במנעול אחד (למשל, `lockA` בפונקציה `transfer_money`) ולהמתין למנעול אחר (למשל, `lockB`).\n3.  **אי-הפקעה (No Preemption):** לא ניתן להפקיע מנעול מחוט שמחזיק בו; רק החוט עצמו יכול לשחרר אותו.\n4.  **המתנה מעגלית (Circular Wait):** זהו התנאי שמופר בקוד הנתון.\n\nתרחיש קיפאון:\nנניח שמתרחש הרצף הבא:\n*   **חוט 1** קורא לפונקציה `transfer_money`. הוא נועל את `lockA`.\n*   **חוט 2** קורא לפונקציה `update_balance`. הוא נועל את `lockB`.\n*   כעת, **חוט 1** מנסה לנעול את `lockB`, אך `lockB` מוחזק על ידי חוט 2. חוט 1 נכנס למצב המתנה.\n*   באותו זמן, **חוט 2** מנסה לנעול את `lockA`, אך `lockA` מוחזק על ידי חוט 1. חוט 2 נכנס למצב המתנה.\nשני החוטים ממתינים זה לזה באופן מעגלי, ולעולם לא יוכלו להמשיך, מה שמוביל לקיפאון.\n\nפתרון:\nהדרך הנפוצה והיעילה ביותר למנוע קיפאון מסוג זה היא לשבור את תנאי \"המתנה מעגלית\" על ידי אכיפת סדר עקבי של רכישת מנעולים. כלומר, כל החוטים שצריכים לנעול את `lockA` וגם את `lockB`, חייבים לנעול אותם תמיד באותו סדר (לדוגמה, תמיד `lockA` ואז `lockB`).\n\nקוד פתרון (השינויים בפונקציה `update_balance`):\n```c++\n#include <mutex>\n#include <thread>\n#include <iostream>\n\nstd::mutex lockA;\nstd::mutex lockB;\n\nvoid transfer_money(int from_account, int to_account, double amount) {\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Trying to lock A for transfer.\" << std::endl;\n    lockA.lock();\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Locked A. Trying to lock B.\" << std::endl;\n    lockB.lock();\n    \n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Transferring \" << amount \n              << \" from \" << from_account << \" to \" << to_account << std::endl;\n    \n    lockB.unlock();\n    lockA.unlock();\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Unlocked A and B. Transfer complete.\" << std::endl;\n}\n\nvoid update_balance(int account, double new_balance) {\n    // פתרון: אכיפת סדר נעילה קבוע: תמיד lockA ואז lockB\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Trying to lock A for update.\" << std::endl;\n    lockA.lock(); // שינוי: נועלים את lockA קודם\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Locked A. Trying to lock B.\" << std::endl;\n    lockB.lock(); // שינוי: נועלים את lockB אחר כך\n\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Updating balance for account \" \n              << account << \" to \" << new_balance << std::endl;\n\n    lockB.unlock();\n    lockA.unlock();\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Unlocked B and A. Update complete.\" << std::endl;\n}\n\nint main() {\n    std::thread t1(transfer_money, 101, 102, 50.0);\n    std::thread t2(update_balance, 101, 1000.0);\n\n    t1.join();\n    t2.join();\n\n    return 0;\n}\n```\nעל ידי אכיפת סדר נעילה עקבי (לדוגמה, תמיד `lockA` ואז `lockB`), אנו מבטיחים שלעולם לא תיווצר המתנה מעגלית. אם חוט 1 מחזיק ב-`lockA` וממתין ל-`lockB`, וחוט 2 מנסה לנעול את `lockB`, הוא יצטרך קודם לנעול את `lockA`. אם `lockA` כבר מוחזק על ידי חוט 1, חוט 2 ימתין ל-`lockA` מבלי להחזיק ב-`lockB`, ובכך נשברת המעגליות.", "difficulty_estimation": "Medium"}, "_source_file": "0394__Deadlocks__Open__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:15:25", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Deadlocks", "Synchronization", "Threads", "Mutexes"], "content": {"text": "נתון קטע קוד בשפת C המשתמש במנגנוני סנכרון של POSIX Threads (pthreads). הקוד כולל שני חוטים (threads) אשר מנסים לגשת לשני משאבים משותפים, resource_A ו-resource_B, כאשר כל משאב מוגן באמצעות מנעול (mutex) משלו, mutex_A ו-mutex_B בהתאמה. החוטים מבצעים פעולות הדורשות גישה לשני המשאבים.\n\nעיין בקוד המצורף וענה על הסעיפים הבאים:\nא. האם קיים פוטנציאל לקיפאון (deadlock) במערכת זו? נמק את תשובתך על ידי זיהוי והסבר ארבעת התנאים ההכרחיים לקיום קיפאון, והצג כיצד הם מתקיימים במקרה זה.\nב. הצע פתרון למניעת קיפאון במערכת זו. הצג את השינויים הנדרשים בקוד (או תאר אותם בפירוט) והסבר כיצד הפתרון שלך מונע את הקיפאון על ידי הפרה של אחד או יותר מהתנאים שצוינו בסעיף א'.", "code_snippet": "pthread_mutex_t mutex_A;\npthread_mutex_t mutex_B;\n\nvoid* thread_func_1(void* arg) {\n    printf(\"Thread 1: Trying to acquire Mutex A...\\n\");\n    pthread_mutex_lock(&mutex_A);\n    printf(\"Thread 1: Acquired Mutex A. Trying to acquire Mutex B...\\n\");\n    // sleep(1); // Simulate work or delay\n    pthread_mutex_lock(&mutex_B);\n    printf(\"Thread 1: Acquired Mutex B. Performing operation...\\n\");\n    // Critical section\n    printf(\"Thread 1: Releasing Mutex B...\\n\");\n    pthread_mutex_unlock(&mutex_B);\n    printf(\"Thread 1: Releasing Mutex A...\\n\");\n    pthread_mutex_unlock(&mutex_A);\n    printf(\"Thread 1: Finished.\\n\");\n    return NULL;\n}\n\nvoid* thread_func_2(void* arg) {\n    printf(\"Thread 2: Trying to acquire Mutex B...\\n\");\n    pthread_mutex_lock(&mutex_B);\n    printf(\"Thread 2: Acquired Mutex B. Trying to acquire Mutex A...\\n\");\n    // sleep(1); // Simulate work or delay\n    pthread_mutex_lock(&mutex_A);\n    printf(\"Thread 2: Acquired Mutex A. Performing operation...\\n\");\n    // Critical section\n    printf(\"Thread 2: Releasing Mutex A...\\n\");\n    pthread_mutex_unlock(&mutex_A);\n    printf(\"Thread 2: Releasing Mutex B...\\n\");\n    pthread_mutex_unlock(&mutex_B);\n    printf(\"Thread 2: Finished.\\n\");\n    return NULL;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. כן, קיים פוטנציאל לקיפאון במערכת זו. הקיפאון יכול להתרחש כאשר חוט 1 תופס את `mutex_A` וחוט 2 תופס את `mutex_B` בו-זמנית, ולאחר מכן כל אחד מהם מנסה לתפוס את המנעול שהשני מחזיק. לדוגמה, חוט 1 תופס את `mutex_A`, ואז מתרחש מיתוג הקשר (context switch) לחוט 2. חוט 2 תופס את `mutex_B`. כעת, חוט 1 מנסה לתפוס את `mutex_B` (שמוחזק על ידי חוט 2) וחוט 2 מנסה לתפוס את `mutex_A` (שמוחזק על ידי חוט 1). שניהם חסומים וממתינים זה לזה.\n\nארבעת התנאים ההכרחיים לקיום קיפאון מתקיימים במקרה זה:\n1.  **מניעה הדדית (Mutual Exclusion)**: מתקיים. המנעולים `mutex_A` ו-`mutex_B` מבטיחים שרק חוט אחד יכול להחזיק בכל מנעול בכל רגע נתון. משאב (המנעול) אינו ניתן לשיתוף.\n2.  **החזק והמתן (Hold-and-Wait)**: מתקיים. כל חוט תופס מנעול אחד (למשל, חוט 1 תופס את `mutex_A`, חוט 2 תופס את `mutex_B`) וממתין למנעול נוסף (חוט 1 ממתין ל-`mutex_B`, חוט 2 ממתין ל-`mutex_A`) בעודו מחזיק במנעול הראשון.\n3.  **אי-הפקעה (No Preemption)**: מתקיים. מנעולים של pthreads אינם ניתנים להפקעה. חוט אינו יכול להילקח ממנו מנעול בכוח; הוא חייב לשחרר אותו מרצונו.\n4.  **המתנה מעגלית (Circular Wait)**: מתקיים. נוצרת שרשרת המתנה מעגלית: חוט 1 מחזיק ב-`mutex_A` וממתין ל-`mutex_B`, בעוד שחוט 2 מחזיק ב-`mutex_B` וממתין ל-`mutex_A`.\n\nב. הפתרון הנפוץ והיעיל ביותר במקרים כאלה הוא למנוע את תנאי \"ההמתנה המעגלית\" על ידי קביעת סדר קבוע לרכישת משאבים. אם כל החוטים ירכשו את המנעולים באותו סדר, המתנה מעגלית לא תוכל להיווצר.\n\n**שינויים בקוד:**\nנשנה את `thread_func_2` כך שתתפוס את המנעולים באותו סדר כמו `thread_func_1`, כלומר, קודם `mutex_A` ואז `mutex_B`.\n\n**קוד מעודכן עבור `thread_func_2`:**\n```c\nvoid* thread_func_2_fixed(void* arg) {\n    printf(\"Thread 2: Trying to acquire Mutex A...\\n\");\n    pthread_mutex_lock(&mutex_A); // Changed order\n    printf(\"Thread 2: Acquired Mutex A. Trying to acquire Mutex B...\\n\");\n    // sleep(1);\n    pthread_mutex_lock(&mutex_B); // Changed order\n    printf(\"Thread 2: Acquired Mutex B. Performing operation...\\n\");\n    // Critical section\n    printf(\"Thread 2: Releasing Mutex B...\\n\");\n    pthread_mutex_unlock(&mutex_B);\n    printf(\"Thread 2: Releasing Mutex A...\\n\");\n    pthread_mutex_unlock(&mutex_A);\n    printf(\"Thread 2: Finished.\\n\");\n    return NULL;\n}\n```\n\n**הסבר כיצד הפתרון מונע קיפאון:**\nפתרון זה מונע את תנאי **המתנה מעגלית (Circular Wait)**. כאשר כל החוטים רוכשים את המנעולים באותו סדר (לדוגמה, תמיד `mutex_A` ואז `mutex_B`), לא ייתכן מצב שבו חוט אחד מחזיק ב-`mutex_A` וממתין ל-`mutex_B`, בעוד חוט אחר מחזיק ב-`mutex_B` וממתין ל-`mutex_A`. אם חוט 1 תפס את `mutex_A`, חוט 2 יצטרך להמתין לשחרור `mutex_A` לפני שיוכל להמשיך לתפוס את `mutex_B`. ברגע שחוט 1 ישחרר את `mutex_A` (לאחר שסיים עם `mutex_B`), חוט 2 יוכל לתפוס אותו, ובכך נשברת השרשרת המעגלית. שלושת התנאים האחרים (מניעה הדדית, החזק והמתן, אי-הפקעה) עדיין עשויים להתקיים, אך מכיוון שכל ארבעת התנאים הכרחיים לקיום קיפאון, הפרה של אחד מהם מספיקה כדי למנוע אותו."}, "difficulty_estimation": "Medium", "_source_file": "0395__Deadlocks__Open__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:15:56", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Deadlocks", "Resource Management", "Concurrency"], "content": {"text": "נניח שיש לנו מערכת עם שני סוגי משאבים: משאב A ומשאב B. במערכת קיימים סך הכל N יחידות ממשאב A ו-M יחידות ממשאב B.\nישנם K תהליכים (P1, P2, ..., PK) המתחרים על המשאבים. כל תהליך Pi דורש a_i יחידות ממשאב A ו-b_i יחידות ממשאב B כדי להשלים את ריצתו. תהליכים מבקשים יחידה אחת של משאב בכל פעם.\n\n1. תארו תרחיש ספציפי (עם דוגמה מספרית קטנה, למשל N=3, M=3, K=2) שבו עלול להתרחש קיפאון (deadlock) במערכת זו. הסבירו מדוע זהו קיפאון תוך התייחסות לארבעת התנאים ההכרחיים לקיפאון.\n2. הציעו אסטרטגיה פשוטה למניעת קיפאון במערכת זו. הסבירו איזו מבין ארבעת התנאים ההכרחיים לקיפאון האסטרטגיה שלכם מונעת, וכיצד היא עושה זאת.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "חלק 1: תרחיש קיפאון\nנניח N=3 יחידות של A, M=3 יחידות של B, ושני תהליכים P1 ו-P2.\nP1 דורש 2 יחידות A ו-2 יחידות B.\nP2 דורש 2 יחידות A ו-2 יחידות B.\n\nתרחיש קיפאון אפשרי:\n1.  P1 מבקש ומקבל יחידה אחת של A. (A_available=2, B_available=3)\n2.  P2 מבקש ומקבל יחידה אחת של B. (A_available=2, B_available=2)\n3.  P1 מבקש ומקבל יחידה אחת של B. (A_available=2, B_available=1)\n4.  P2 מבקש ומקבל יחידה אחת של A. (A_available=1, B_available=1)\n\nבשלב זה:\n*   P1 מחזיק ב-1 יחידת A ו-1 יחידת B. הוא זקוק לעוד 1 יחידת A ועוד 1 יחידת B.\n*   P2 מחזיק ב-1 יחידת A ו-1 יחידת B. הוא זקוק לעוד 1 יחידת A ועוד 1 יחידת B.\n\nהמשאבים הזמינים: 1 יחידת A, 1 יחידת B.\nאף תהליך לא יכול להמשיך:\n*   P1 לא יכול לקבל עוד A (זמין 1, P1 צריך 1) ולא יכול לקבל עוד B (זמין 1, P1 צריך 1).\n*   P2 לא יכול לקבל עוד A (זמין 1, P2 צריך 1) ולא יכול לקבל עוד B (זמין 1, P2 צריך 1).\n\nהתייחסות לארבעת התנאים ההכרחיים לקיפאון:\n1.  מניעה הדדית (Mutual Exclusion): מתקיים. יחידות המשאבים אינן ניתנות לחלוקה (non-shareable) – יחידת A או B יכולה להיות מוחזקת על ידי תהליך אחד בלבד בכל רגע נתון.\n2.  החזקה והמתנה (Hold and Wait): מתקיים. P1 מחזיק יחידת A ויחידת B וממתין ליחידות נוספות. P2 מחזיק יחידת A ויחידת B וממתין ליחידות נוספות.\n3.  אי-דריסה (No Preemption): מתקיים. המשאבים שהוקצו לתהליך אינם נלקחים ממנו בכוח; הם משוחררים רק מרצון על ידי התהליך המחזיק בהם.\n4.  המתנה מעגלית (Circular Wait): מתקיים. P1 ממתין למשאבים ש-P2 מחזיק, ו-P2 ממתין למשאבים ש-P1 מחזיק, ויוצר מעגל המתנה.\n\nחלק 2: אסטרטגיה למניעת קיפאון\nאסטרטגיה פשוטה למניעת קיפאון היא למנוע את תנאי ה\"החזקה והמתנה\" (Hold and Wait).\n\nכיצד?\nנחייב כל תהליך לבקש את כל המשאבים הנדרשים לו (a_i יחידות A ו-b_i יחידות B) בבת אחת בתחילת ריצתו. אם המערכת לא יכולה להקצות את כל המשאבים הנדרשים לתהליך באותו רגע, התהליך לא יקבל אף משאב וימתין (ללא החזקת משאבים) עד שכל המשאבים יהיו זמינים.\n\nהסבר:\nבגישה זו, תהליך לעולם לא יחזיק במשאבים כלשהם ובו זמנית ימתין למשאבים נוספים. הוא יקבל את כל משאביו מראש, או שימתין ללא החזקת משאבים. בכך, אנו מונעים את התנאי \"החזקה והמתנה\", ולכן מונעים קיפאון.\nלדוגמה, בתרחיש הקודם: P1 יבקש 2A ו-2B. אם זמינים, יקבל וירוץ. אם P1 קיבל, אז נותרו 1A ו-1B. P2 יבקש 2A ו-2B, אך לא יוכל לקבל אותם (כי אין מספיק). P2 ימתין עד ש-P1 יסיים וישחרר את משאביו, ורק אז P2 יוכל לקבל את משאביו ולרוץ. בדרך זו, אין קיפאון."}, "difficulty_estimation": "Medium", "_source_file": "0396__Deadlocks__Open__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:16:14", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Deadlocks", "Synchronization"], "content": {"text": "נתונה מערכת עם שני תהליכים (P1, P2) ושני משאבים (R1, R2). כל משאב מיוצג על ידי סמפור בינארי (mutex). התהליכים מנסים לגשת למשאבים בסדר הבא:\n\nP1:\nlock(R1);\nlock(R2);\n// קטע קריטי\nunlock(R2);\nunlock(R1);\n\nP2:\nlock(R2);\nlock(R1);\n// קטע קריטי\nunlock(R1);\nunlock(R2);\n\nא. האם קיים תרחיש שבו יכול להיווצר קיפאון (deadlock) במערכת זו? הסבר בפירוט מדוע, תוך התייחסות לארבעת התנאים ההכרחיים לקיום קיפאון.\nב. אם כן, הצע פתרון למניעת קיפאון עבור המקרה המתואר, תוך שינוי מינימלי בקוד, והסבר כיצד הפתרון שלך מונע את הקיפאון.", "code_snippet": "typedef void Semaphore;\n\n// Assume lock(Semaphore* s) and unlock(Semaphore* s) are defined\n// and implement standard binary semaphore (mutex) operations.\n\nvoid process_P1(Semaphore* R1, Semaphore* R2) {\n    lock(R1);\n    lock(R2);\n    // critical section for P1\n    // ...\n    unlock(R2);\n    unlock(R1);\n}\n\nvoid process_P2(Semaphore* R1, Semaphore* R2) {\n    lock(R2);\n    lock(R1);\n    // critical section for P2\n    // ...\n    unlock(R1);\n    unlock(R2);\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. כן, קיים תרחיש שבו יכול להיווצר קיפאון (deadlock) במערכת זו.\n\nתרחיש לדוגמה:\n1. תהליך P1 מבצע `lock(R1)` ותופס את משאב R1.\n2. תהליך P2 מבצע `lock(R2)` ותופס את משאב R2.\n3. P1 מנסה לבצע `lock(R2)` אך R2 תפוס על ידי P2, ולכן P1 נחסם וממתין ל-R2.\n4. P2 מנסה לבצע `lock(R1)` אך R1 תפוס על ידי P1, ולכן P2 נחסם וממתין ל-R1.\n\nבנקודה זו, P1 מחזיק ב-R1 וממתין ל-R2, בעוד P2 מחזיק ב-R2 וממתין ל-R1. נוצר מעגל המתנה הדדי, והתהליכים נמצאים בקיפאון.\n\nהתנאים ההכרחיים לקיום קיפאון מתקיימים:\n*   **מניעה הדדית (Mutual Exclusion):** הסמפורים הבינאריים מבטיחים שרק תהליך אחד יכול להחזיק במשאב R1 או R2 בכל רגע נתון.\n*   **החזק והמתן (Hold and Wait):** כל תהליך מחזיק במשאב אחד (P1 ב-R1, P2 ב-R2) וממתין למשאב נוסף (P1 ל-R2, P2 ל-R1).\n*   **אי-הפקעה (No Preemption):** לא ניתן להפקיע משאב מתהליך המחזיק בו; רק התהליך עצמו יכול לשחרר אותו.\n*   **המתנה מעגלית (Circular Wait):** P1 ממתין למשאב R2 המוחזק על ידי P2, ו-P2 ממתין למשאב R1 המוחזק על ידי P1. נוצר מעגל המתנה.\n\nב. כדי למנוע קיפאון, ניתן ליישם את אסטרטגיית **סדר משאבים (Resource Ordering)**, המונעת את התנאי של המתנה מעגלית.\nנחליט על סדר גלובלי עבור המשאבים, למשל: R1 < R2.\nכל התהליכים חייבים לבקש משאבים לפי סדר עולה זה.\n\nהשינוי המינימלי בקוד יהיה בתהליך P2, כך שיבקש את R1 לפני R2, בדומה ל-P1:\n\n```c\n// Process P1 (no change)\nvoid process_P1(Semaphore* R1, Semaphore* R2) {\n    lock(R1);\n    lock(R2);\n    // critical section for P1\n    // ...\n    unlock(R2);\n    unlock(R1);\n}\n\n// Process P2 (modified)\nvoid process_P2(Semaphore* R1, Semaphore* R2) {\n    lock(R1); // Changed from lock(R2)\n    lock(R2); // Changed from lock(R1)\n    // critical section for P2\n    // ...\n    unlock(R2);\n    unlock(R1);\n}\n```\n\n**הסבר כיצד הפתרון מונע קיפאון:**\nעל ידי אכיפת סדר בקשת משאבים, אנו מונעים היווצרות של המתנה מעגלית.\nכעת, שני התהליכים (P1 ו-P2) מנסים לתפוס קודם את R1, ורק לאחר מכן את R2.\n*   אם P1 מצליח לתפוס את R1, אז P2 ייחסם כאשר ינסה לתפוס את R1. P1 יוכל להמשיך, לתפוס את R2, לבצע את הקטע הקריטי ולשחרר את R2 ואז את R1. לאחר ש-R1 ישוחרר, P2 יוכל לתפוס אותו ולהמשיך.\n*   אם P2 מצליח לתפוס את R1, אז P1 ייחסם כאשר ינסה לתפוס את R1. P2 יוכל להמשיך, לתפוס את R2, לבצע את הקטע הקריטי ולשחרר את R2 ואז את R1. לאחר ש-R1 ישוחרר, P1 יוכל לתפוס אותו ולהמשיך.\n\nבשני המקרים, לא יכול להיווצר מצב שבו P1 מחכה ל-R2 שמוחזק על ידי P2, ובו זמנית P2 מחכה ל-R1 שמוחזק על ידי P1, מכיוון ששניהם תמיד ינסו לתפוס את R1 קודם. תהליך אחד ישיג את R1 וימשיך, בעוד השני ימתין בסבלנות לשחרורו, ובכך נמנעת המתנה מעגלית."}, "difficulty_estimation": "Medium", "_source_file": "0397__Deadlocks__Open__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:16:43", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Deadlocks", "Deadlock Prevention", "Concurrency"], "content": {"text": "במערכת הפעלה, קיפאון (deadlock) יכול להתרחש כאשר קבוצת תהליכים נחסמת באופן קבוע, כאשר כל תהליך בקבוצה ממתין למשאב שמוחזק על ידי תהליך אחר בקבוצה.\nנתונה מערכת עם שני סוגי משאבים, R1 ו-R2, כאשר מכל סוג קיים מופע יחיד. במערכת רצים שני תהליכים, P1 ו-P2, אשר מבצעים את הקוד הבא:\n\n```c\n// Process P1\nvoid process_P1() {\n    lock(&R1);\n    lock(&R2);\n    // קטע קריטי\n    unlock(&R2);\n    unlock(&R1);\n}\n\n// Process P2\nvoid process_P2() {\n    lock(&R2);\n    lock(&R1);\n    // קטע קריטי\n    unlock(&R1);\n    unlock(&R2);\n}\n```\n\nא) הסבירו כיצד קיפאון יכול להתרחש במערכת זו. תארו רצף אירועים ספציפי שמוביל לקיפאון.\nב) הציעו מנגנון פשוט למניעת קיפאון במערכת זו, תוך התייחסות לאחד מארבעת התנאים למניעת קיפאון. הסבירו את המנגנון שבחרתם והדגימו כיצד הוא מונע את הקיפאון בתרחיש הספציפי הזה.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "חלק א': הסבר על קיפאון\n\nקיפאון יכול להתרחש במערכת זו עקב קיום כל ארבעת התנאים לקיפאון:\n1.  מניעה הדדית (Mutual Exclusion): המשאבים R1 ו-R2 הם משאבים בלעדיים, כלומר רק תהליך אחד יכול להחזיק בכל משאב נתון בזמן מסוים (ה-lock מבטיח זאת).\n2.  החזק והמתן (Hold-and-Wait): תהליך יכול להחזיק במשאב אחד (לדוגמה, P1 מחזיק ב-R1) ובמקביל לבקש משאב נוסף (P1 ממתין ל-R2).\n3.  אי-נשללות (No Preemption): לא ניתן לקחת משאב מתהליך שמחזיק בו בכוח. תהליך משחרר משאב רק מרצונו החופשי (באמצעות unlock).\n4.  המתנה מעגלית (Circular Wait): קיים מעגל של תהליכים, כאשר כל תהליך ממתין למשאב שמוחזק על ידי התהליך הבא במעגל.\n\nרצף אירועים המוביל לקיפאון:\n1.  P1 מבצע lock(&R1): P1 תופס את R1.\n2.  P2 מבצע lock(&R2): P2 תופס את R2.\n3.  P1 מבצע lock(&R2): P1 מנסה לתפוס את R2 אך נחסם, מכיוון ש-R2 מוחזק על ידי P2. P1 ממתין ל-R2.\n4.  P2 מבצע lock(&R1): P2 מנסה לתפוס את R1 אך נחסם, מכיוון ש-R1 מוחזק על ידי P1. P2 ממתין ל-R1.\n\nבשלב זה, P1 מחזיק ב-R1 וממתין ל-R2, בעוד P2 מחזיק ב-R2 וממתין ל-R1. נוצרה המתנה מעגלית, ושני התהליכים חסומים באופן קבוע – קיפאון.\n\nחלק ב': מנגנון למניעת קיפאון\n\nניתן למנוע את הקיפאון על ידי שבירת תנאי ה\"המתנה מעגלית\" (Circular Wait), באמצעות הקפדה על סדר קבוע לרכישת משאבים.\n\nמנגנון: הקצאת סדר גלובלי לכל סוגי המשאבים במערכת. לדוגמה, נקבע ש-R1 יבוא לפני R2 (כלומר, R1 < R2). כל התהליכים במערכת חייבים לבקש משאבים לפי סדר זה. אם תהליך זקוק למשאבים R1 ו-R2, הוא חייב לבקש קודם את R1 ורק אחר כך את R2.\n\nיישום בתרחיש זה:\nנשנה את קוד התהליכים כך ששניהם יבקשו את המשאבים בסדר קבוע (לדוגמה, R1 ואז R2):\n\n```c\n// Process P1 (ללא שינוי)\nvoid process_P1() {\n    lock(&R1);\n    lock(&R2);\n    // קטע קריטי\n    unlock(&R2);\n    unlock(&R1);\n}\n\n// Process P2 (לאחר שינוי)\nvoid process_P2_modified() {\n    lock(&R1); // שינוי: קודם מבקש R1\n    lock(&R2); // ואז מבקש R2\n    // קטע קריטי\n    unlock(&R2);\n    unlock(&R1);\n}\n```\n\nכיצד זה מונע קיפאון:\nננתח שוב את רצף האירועים האפשרי:\n1.  P1 מבצע lock(&R1): P1 תופס את R1.\n2.  P2 מנסה לבצע lock(&R1): P2 נחסם מכיוון ש-R1 מוחזק על ידי P1. P2 ממתין ל-R1.\n3.  P1 מבצע lock(&R2): P1 תופס את R2 (מכיוון ש-P2 חסום על R1, הוא לא יכול לתפוס את R2).\n4.  P1 מסיים את הקטע הקריטי ומשחרר את R2 ואז את R1.\n5.  כאשר R1 משוחרר, P2 (שממתין ל-R1) מקבל את R1.\n6.  P2 ממשיך ומבצע lock(&R2).\n7.  P2 מסיים את הקטע הקריטי ומשחרר את R2 ואז את R1.\n\nבכל תרחיש אפשרי, אחד מהתהליכים יתפוס את R1 ראשון. התהליך השני ייחסם וימתין. התהליך הראשון ימשיך, יתפוס את R2, יסיים את עבודתו וישחרר את שני המשאבים. רק אז התהליך השני יוכל להמשיך. תמיד יהיה תהליך שיסיים את עבודתו וישחרר משאבים, ובכך לא תיווצר המתנה מעגלית ולכן לא יהיה קיפאון."}, "difficulty_estimation": "Medium", "_source_file": "0398__Deadlocks__Open__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:17:04", "_subject": "Concurrency"}, {"id": 8, "type": "Open", "topic": ["Deadlocks", "Synchronization", "Resource Allocation"], "content": {"text": "נתונה מערכת עם שני סוגי משאבים, R1 ו-R2, כאשר כל אחד מהם מוגן על ידי מנעול (mutex_R1, mutex_R2). קיימים N חוטים, וכל חוט נדרש לרכוש את R1 ו-R2 כדי לבצע את משימתו, ולאחר מן לשחרר אותם. מוצגים שני חוטים, חוט A וחוט B, המנסים לרכוש משאבים אלו:\n\n**חוט A:**\n```c\npthread_mutex_lock(&mutex_R1);\npthread_mutex_lock(&mutex_R2);\n// גישה למשאבים R1 ו-R2\npthread_mutex_unlock(&mutex_R2);\npthread_mutex_unlock(&mutex_R1);\n```\n\n**חוט B:**\n```c\npthread_mutex_lock(&mutex_R2);\npthread_mutex_lock(&mutex_R1);\n// גישה למשאבים R1 ו-R2\npthread_mutex_unlock(&mutex_R1);\npthread_mutex_unlock(&mutex_R2);\n```\n\nא. הסבירו מדוע תרחיש זה עלול להוביל לקיפאון (deadlock).\nב. הציעו פתרון למניעת קיפאון זה, וספקו קטע קוד עבור לוגיקת רכישת המשאבים המתוקנת עבור שני החוטים.\nג. דון בתנאי מניעת הקיפאון שהפתרון שלך מטפל בו.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. תרחיש זה עלול להוביל לקיפאון מכיוון שהוא מקיים את כל ארבעת התנאים ההכרחיים לקיפאון:\n1.  **מניעה הדדית (Mutual Exclusion):** כל משאב (mutex_R1 ו-mutex_R2) יכול להיות מוחזק על ידי חוט אחד בלבד בכל רגע נתון. זהו מאפיין מובנה של מנעולים.\n2.  **החזק והמתן (Hold and Wait):** חוט יכול להחזיק במשאב אחד (לדוגמה, חוט A מחזיק ב-mutex_R1) ובמקביל להמתין למשאב אחר (חוט A ממתין ל-mutex_R2).\n3.  **ללא דריסה (No Preemption):** משאבים אינם נלקחים בכוח מחוט שמחזיק בהם; חוט חייב לשחרר את המשאבים מרצונו.\n4.  **המתנה מעגלית (Circular Wait):** תנאי זה מתקיים כאשר קיים מעגל של חוטים, כאשר כל חוט בשרשרת ממתין למשאב המוחזק על ידי החוט הבא בשרשרת. בתרחיש הנתון, אם חוט A רוכש את mutex_R1 וחוט B רוכש את mutex_R2 בו-זמנית (או בסמיכות), אז חוט A ממתין ל-mutex_R2 (שמוחזק על ידי B), וחוט B ממתין ל-mutex_R1 (שמוחזק על ידי A). זה יוצר מעגל המתנה: A ממתין ל-B, ו-B ממתין ל-A.\n\nב. הפתרון למניעת קיפאון זה הוא לכפות סדר רכישה עקבי של המשאבים על כל החוטים. כלומר, כל החוטים ינסו תמיד לרכוש את המשאבים באותו סדר. לדוגמה, כל החוטים ירכשו תמיד את mutex_R1 ואז את mutex_R2. שינוי זה מונע את התנאי של המתנה מעגלית.\n\nלהלן קטע הקוד המתוקן עבור שני החוטים:\n\n```c\npthread_mutex_t mutex_R1; // יש לאתחל את המנעולים\npthread_mutex_t mutex_R2;\n\nvoid *thread_A_func(void *arg) {\n    // ... עבודה כלשהי ...\n    pthread_mutex_lock(&mutex_R1); // תמיד רכוש את R1 ראשון\n    pthread_mutex_lock(&mutex_R2); // ואז את R2\n    // גישה למשאבים R1 ו-R2\n    pthread_mutex_unlock(&mutex_R2);\n    pthread_mutex_unlock(&mutex_R1);\n    // ... עבודה נוספת ...\n    return NULL;\n}\n\nvoid *thread_B_func(void *arg) {\n    // ... עבודה כלשהי ...\n    pthread_mutex_lock(&mutex_R1); // גם חוט B רוכש את R1 ראשון\n    pthread_mutex_lock(&mutex_R2); // ואז את R2\n    // גישה למשאבים R1 ו-R2\n    pthread_mutex_unlock(&mutex_R2);\n    pthread_mutex_unlock(&mutex_R1);\n    // ... עבודה נוספת ...\n    return NULL;\n}\n```\n\nג. הפתרון המוצע מטפל בתנאי מניעת הקיפאון של **המתנה מעגלית (Circular Wait)**. על ידי אכיפת סדר רכישה עקבי וגלובלי (לדוגמה, תמיד R1 ואז R2), אנו מבטיחים שלא יכולה להיווצר שרשרת המתנה מעגלית. אם חוט A מחזיק ב-R1 וממתין ל-R2, וחוט B רוצה גם הוא את R1 ו-R2, הוא יצטרך להמתין ש-R1 ישוחרר על ידי A לפני שיוכל לרכוש אותו. מכיוון שכל החוטים רוכשים את המשאבים באותו סדר, לא ייתכן מצב שחוט A ממתין ל-R2 שמוחזק על ידי B, ובמקביל B ממתין ל-R1 שמוחזק על ידי A, מכיוון ש-B לא היה מנסה לרכוש את R2 לפני שרכש את R1 (שמוחזק על ידי A). כך אנו שוברים את המעגל הפוטנציאלי."}, "difficulty_estimation": "Medium", "_source_file": "0399__Deadlocks__Open__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:17:21", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Deadlocks", "Resource Allocation", "Deadlock Prevention"], "content": {"text": "מערכת הפעלה מנהלת שלושה סוגי משאבים: A, B ו-C. לכל סוג משאב יש מספר מופעים קבוע (לדוגמה: 2 מופעי A, 2 מופעי B, 2 מופעי C). במערכת רצים מספר תהליכים. כל תהליך דורש שני סוגי משאבים שונים כדי להשלים את משימתו. לדוגמה, תהליך P1 זקוק למופע אחד מ-A ומופע אחד מ-B, תהליך P2 זקוק למופע אחד מ-B ומופע אחד מ-C, וכך הלאה.\n\nא. תארו מצב שבו יכול להתרחש קיפאון (deadlock) במערכת כזו. ציינו אילו מהתנאים ההכרחיים לקיפאון (mutual exclusion, hold and wait, no preemption, circular wait) מתקיימים במצב שתיארתם.\nב. הציעו אסטרטגיה למניעת קיפאון במערכת זו. הסבירו כיצד האסטרטגיה שהצעתם שוברת לפחות אחד מהתנאים ההכרחיים לקיפאון.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "חלק א': תיאור מצב קיפאון ותנאים\nנניח שיש לנו 2 מופעים מכל סוג משאב (A, B, C) ושלושה תהליכים: P1, P2, P3.\n*   P1 זקוק למופע אחד מ-A ומופע אחד מ-B.\n*   P2 זקוק למופע אחד מ-B ומופע אחד מ-C.\n*   P3 זקוק למופע אחד מ-C ומופע אחד מ-A.\n\nמצב קיפאון אפשרי:\n1.  P1 רוכש מופע אחד של A.\n2.  P2 רוכש מופע אחד של B.\n3.  P3 רוכש מופע אחד של C.\n\nבשלב זה:\n*   P1 מחזיק ב-A וממתין ל-B.\n*   P2 מחזיק ב-B וממתין ל-C.\n*   P3 מחזיק ב-C וממתין ל-A.\n\nכל תהליך מחזיק במשאב אחד וממתין למשאב אחר שמוחזק על ידי תהליך אחר, ונוצר מעגל המתנה. אף תהליך לא יכול להמשיך, וזהו מצב קיפאון.\n\nהתנאים ההכרחיים לקיפאון המתקיימים במצב זה:\n*   **Mutual Exclusion (מניעה הדדית):** מתקיים. משאבים ניתנים לשימוש בלעדי (מופע של משאב יכול להיות מוחזק רק על ידי תהליך אחד). \n*   **Hold and Wait (החזק והמתן):** מתקיים. כל תהליך מחזיק במשאב אחד (לדוגמה, P1 מחזיק ב-A) וממתין למשאב נוסף (P1 ממתין ל-B) שמוחזק על ידי תהליך אחר.\n*   **No Preemption (אי-הפקעה):** מתקיים. לא ניתן להפקיע משאבים מתהליך שמחזיק בהם בכוח; התהליך חייב לשחרר אותם מרצונו.\n*   **Circular Wait (המתנה מעגלית):** מתקיים. P1 ממתין למשאב שמוחזק על ידי P2, P2 ממתין למשאב שמוחזק על ידי P3, ו-P3 ממתין למשאב שמוחזק על ידי P1. נוצר מעגל סגור של המתנה.\n\nחלק ב': אסטרטגיה למניעת קיפאון\nאחת האסטרטגיות למניעת קיפאון היא לשבור את תנאי **המתנה מעגלית (Circular Wait)** באמצעות **היררכיה של משאבים (Resource Ordering)**.\n\n**תיאור האסטרטגיה:**\nנקצה סדר מספרי גלובלי לכל סוג משאב. לדוגמה: A=1, B=2, C=3. כל תהליך במערכת חייב לבקש משאבים בסדר עולה בלבד. כלומר, אם תהליך זקוק למשאבים מסוג R_i ו-R_j, והמספר הסידורי של R_i קטן מהמספר הסידורי של R_j, אזי התהליך חייב לבקש את R_i לפני R_j.\n\n**הסבר כיצד האסטרטגיה שוברת את תנאי Circular Wait:**\nעם היררכיה של משאבים, לא ייתכן שיתקיים מעגל המתנה. נניח שקיימת שרשרת המתנה מעגלית: P1 ממתין למשאב שמוחזק על ידי P2, P2 ממתין למשאב שמוחזק על ידי P3, ..., Pn ממתין למשאב שמוחזק על ידי P1. אם כל תהליך חייב לבקש משאבים בסדר עולה, אז:\n*   המשאב ש-P1 ממתין לו (שמוחזק על ידי P2) חייב להיות בעל מספר סידורי גבוה יותר מהמשאב ש-P1 מחזיק בו.\n*   המשאב ש-P2 ממתין לו (שמוחזק על ידי P3) חייב להיות בעל מספר סידורי גבוה יותר מהמשאב ש-P2 מחזיק בו.\n*   וכך הלאה, עד Pn.\n\nאם Pn ממתין למשאב שמוחזק על ידי P1, אז המשאב ש-Pn ממתין לו חייב להיות בעל מספר סידורי גבוה יותר מהמשאב ש-Pn מחזיק בו. אך זה אומר שהמשאב ש-P1 מחזיק בו יהיה בעל מספר סידורי גבוה יותר מהמשאב ש-Pn מחזיק בו. בסופו של דבר, אם נלך לאורך המעגל, המשאב הראשון בשרשרת יהיה בעל מספר סידורי גבוה יותר מעצמו, וזו סתירה. לכן, לא ניתן ליצור מעגל המתנה כאשר משאבים נרכשים בסדר היררכי עולה, ובכך נשבר תנאי ה-Circular Wait."}, "difficulty_estimation": "Medium", "_source_file": "0400__Deadlocks__Open__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:17:45", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Deadlocks", "Resource Management", "Synchronization", "Concurrency"], "content": {"text": "נתונה מערכת מרובת חוטים בה קיימים שני סוגי משאבים: Resource A ו-Resource B. ידוע כי קיימים סך הכל `TotalA` יחידות מ-Resource A ו-`TotalB` יחידות מ-Resource B. חוטים במערכת מבצעים פעולות הדורשות כמות מסוימת של יחידות מכל אחד מהמשאבים בו-זמנית (לדוגמה, חוט מבקש `a` יחידות מ-A ו-`b` יחידות מ-B).\n\nעליכם לממש מנהל משאבים (Resource Manager) ב-C/C++ שיספק שתי פונקציות:\n1.  `request_resources(int a, int b)`: חוט קורא לפונקציה זו כדי לבקש `a` יחידות מ-Resource A ו-`b` יחידות מ-Resource B.\n2.  `release_resources(int a, int b)`: חוט קורא לפונקציה זו כדי לשחרר `a` יחידות מ-Resource A ו-`b` יחידות מ-Resource B.\n\nהמימוש שלכם חייב לעמוד בדרישות הבאות:\n*   **מניעת קיפאון (Deadlock Prevention):** המערכת לעולם לא תיכנס למצב קיפאון.\n*   **חופש מרעב (Starvation-Free):** אם בקשה למשאבים יכולה להתמלא בסופו של דבר (כלומר, סך המשאבים הנדרשים זמין במערכת), היא אכן תתמלא בתוך זמן סופי. יש להבטיח הוגנות במידת האפשר.\n*   **מימוש:** השתמשו באובייקטי סנכרון סטנדרטיים של POSIX Threads (כגון mutexes, condition variables, semaphores).\n\nיש לכלול את הגדרת מבנה הנתונים של מנהל המשאבים, פונקציית אתחול, ומימוש מלא של `request_resources` ו-`release_resources`. בנוסף, הסבירו בפירוט כיצד המימוש שלכם מבטיח מניעת קיפאון וחופש מרעב.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון מתבסס על עקרון \"בקש הכל או כלום\" (All-or-nothing) בשילוב עם משתני תנאי (condition variables) כדי למנוע קיפאון ולהבטיח חופש מרעב.\n\n### מבנה הנתונים של מנהל המשאבים:\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\ntypedef struct {\n    int total_A;\n    int total_B;\n    int available_A;\n    int available_B;\n    pthread_mutex_t lock;\n    pthread_cond_t cond;\n} ResourceManager;\n\n// פונקציית אתחול למנהל המשאבים\nvoid init_resource_manager(ResourceManager *rm, int initial_A, int initial_B) {\n    rm->total_A = initial_A;\n    rm->total_B = initial_B;\n    rm->available_A = initial_A;\n    rm->available_B = initial_B;\n    pthread_mutex_init(&rm->lock, NULL);\n    pthread_cond_init(&rm->cond, NULL);\n}\n\n// פונקציית השמדה למנהל המשאבים\nvoid destroy_resource_manager(ResourceManager *rm) {\n    pthread_mutex_destroy(&rm->lock);\n    pthread_cond_destroy(&rm->cond);\n}\n\n// פונקציה לבקשת משאבים\nvoid request_resources(ResourceManager *rm, int a, int b) {\n    pthread_mutex_lock(&rm->lock);\n\n    // חוט ממתין בלולאה כל עוד אין מספיק משאבים משני הסוגים\n    // ה-while loop מבטיח שגם לאחר התעוררות, התנאי נבדק שוב (spurious wakeup)\n    // וכן במקרה שחוט אחר לקח את המשאבים לפנינו.\n    while (rm->available_A < a || rm->available_B < b) {\n        // משחרר את המנעול ונכנס למצב המתנה. כשהוא מתעורר, הוא רוכש את המנעול שוב.\n        pthread_cond_wait(&rm->cond, &rm->lock);\n    }\n\n    // יש מספיק משאבים, מבצעים הקצאה\n    rm->available_A -= a;\n    rm->available_B -= b;\n    printf(\"Thread %lu acquired: A=%d, B=%d. Available: A=%d, B=%d\\n\",\n           pthread_self(), a, b, rm->available_A, rm->available_B);\n\n    pthread_mutex_unlock(&rm->lock);\n}\n\n// פונקציה לשחרור משאבים\nvoid release_resources(ResourceManager *rm, int a, int b) {\n    pthread_mutex_lock(&rm->lock);\n\n    // משחרר את המשאבים ומעדכן את המונים\n    rm->available_A += a;\n    rm->available_B += b;\n    printf(\"Thread %lu released: A=%d, B=%d. Available: A=%d, B=%d\\n\",\n           pthread_self(), a, b, rm->available_A, rm->available_B);\n\n    // מאותת לכל החוטים הממתינים לבדוק שוב את תנאי הבקשה שלהם.\n    // שימוש ב-broadcast חיוני למניעת רעב.\n    pthread_cond_broadcast(&rm->cond);\n\n    pthread_mutex_unlock(&rm->lock);\n}\n```\n\n### הסבר:\n\n**1. מניעת קיפאון (Deadlock Prevention):**\nהמימוש מונע קיפאון על ידי מניעת קיום של התנאי \"החזק והמתן\" (Hold and Wait) וכן על ידי מניעת קיום של \"מעגל המתנה\" (Circular Wait).\n*   **\"בקש הכל או כלום\" (All-or-nothing):** חוט שמבקש משאבים לעולם לא יחזיק חלק מהמשאבים הנדרשים וימתין לאחרים. הוא תמיד ממתין (באמצעות `pthread_cond_wait`) עד שכל המשאבים הנדרשים (גם מ-A וגם מ-B) זמינים עבורו. רק כאשר כל המשאבים זמינים, הוא רוכש אותם באופן אטומי (תחת הגנת המוטקס). מצב זה מבטיח שאף חוט לא יחזיק משאבים בזמן שהוא ממתין למשאבים נוספים, ובכך נמנע התנאי של \"החזק והמתן\".\n*   **נעילה אטומית:** המוטקס `rm->lock` מגן על המשתנים `available_A` ו-`available_B` ועל כל תהליך הבדיקה וההקצאה. זה מבטיח שאף שני חוטים לא יקבלו החלטות סותרות לגבי זמינות המשאבים בו-זמנית, ושפעולת ההקצאה היא אטומית. מכיוון שהקצאת המשאבים היא אטומית וכוללת את כל המשאבים הנדרשים, לא יכול להיווצר מצב של מעגל המתנה שבו חוטים ממתינים זה לזה למשאבים שהם כבר החלו להחזיק.\n\n**2. חופש מרעב (Starvation-Free):**\nהמימוש מבטיח חופש מרעב בזכות השימוש ב-`pthread_cond_broadcast`:\n*   **`pthread_cond_broadcast` ב-`release_resources`:** כאשר חוט משחרר משאבים, הוא קורא ל-`pthread_cond_broadcast`. פעולה זו מעירה את *כל* החוטים הממתינים על משתנה התנאי `cond`.\n*   **בדיקה מחודשת של התנאי:** כל חוט שהתעורר חוזר לבדוק את התנאי בלולאת ה-`while` (`rm->available_A < a || rm->available_B < b`). מאחר שכל המשאבים משוחררים בסופו של דבר, וכל חוט ממתין מקבל הזדמנות לבדוק אם בקשתו יכולה להתמלא, כל בקשה שניתן למלאה (כלומר, יש מספיק משאבים במערכת הכוללת) תתמלא בתוך זמן סופי. אין חוט ספציפי שיכול \"להיתקע\" לנצח בזמן שחוטים אחרים מקבלים משאבים, מכיוון שכל שחרור משאבים נותן לכולם הזדמנות שווה לבדוק את תנאיהם.\n*   **הוגנות:** שימוש ב-`pthread_cond_broadcast` מספק רמה טובה של הוגנות בכך שהוא מאפשר לכל בקשה פוטנציאלית להתמלא, גם אם היא לא הראשונה שהגיעה לתור ההמתנה. זה מונע מצב שבו בקשות קטנות יותר, שיכולות להתמלא מיד עם שחרור משאבים, נחסמות על ידי בקשה גדולה יותר שנמצאת בראש התור אך עדיין לא יכולה להתמלא."}, "difficulty_estimation": "Hard", "_source_file": "0401__Deadlocks__Open__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:18:12", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Deadlocks", "Concurrency", "Resource Management"], "content": {"text": "במערכת הפעלה מרובת תהליכים, נניח שיש לנו N תהליכים (או חוטים) שכל אחד מהם צריך לבצע משימה הדורשת שני סוגי משאבים: 'משאב X' ו'משאב Y'. קיימים `num_X` יחידות של משאב X ו-`num_Y` יחידות של משאב Y במערכת. כל תהליך זקוק ליחידה אחת מכל סוג משאב כדי להשלים את משימתו. התהליכים רוכשים את המשאבים באמצעות מנעולים (mutexes).", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "תארו תרחיש ספציפי (באמצעות סדר פעולות של שני תהליכים לפחות) שבו עלול להתרחש קיפאון (deadlock) במערכת המתוארת. הסבירו מדוע תרחיש זה מוביל לקיפאון תוך התייחסות לארבעת התנאים של קיפאון (מניעה הדדית, החזקה והמתנה, אי-נשללות, המתנה מעגלית).", "code_snippet": null, "options": null}, {"id": "1.2", "text": "הציעו אסטרטגיה למניעת קיפאון במערכת זו. לאחר מכן, כתבו מימוש בפסאודו-קוד (או C/C++) לפונקציות `acquire_resources` ו-`release_resources` עבור תהליך בודד, המשתמשות ב-`pthread_mutex_t` ומיישמות את האסטרטגיה שהצעתם. הניחו ש-`mutex_X` ו-`mutex_Y` הם מנעולים גלובליים המגנים על המשאבים.", "code_snippet": "pthread_mutex_t mutex_X; // מגן על משאב X\npthread_mutex_t mutex_Y; // מגן על משאב Y\n\nvoid acquire_resources() {\n    // יש לממש כאן את לוגיקת רכישת המשאבים עם מניעת קיפאון\n}\n\nvoid release_resources() {\n    // יש לממש כאן את לוגיקת שחרור המשאבים\n}", "options": null}, {"id": "1.3", "text": "נתחו את השפעת האסטרטגיה שהצעתם על רמת המקביליות (concurrency) וניצול המשאבים במערכת. האם יש חסרונות לגישה זו? פרטו.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "### סעיף 1.1: תרחיש קיפאון\nתרחיש קיפאון יכול להתרחש כדלקמן:\n\n**תהליך P1 מבצע:**\n1. `pthread_mutex_lock(&mutex_X);` // P1 רוכש את מנעול X\n\n**תהליך P2 מבצע בו זמנית:**\n1. `pthread_mutex_lock(&mutex_Y);` // P2 רוכש את מנעול Y\n\n**לאחר מכן:**\n2. `pthread_mutex_lock(&mutex_Y);` // P1 מנסה לרכוש את מנעול Y. P1 נחסם כיוון ש-P2 מחזיק ב-Y.\n\n2. `pthread_mutex_lock(&mutex_X);` // P2 מנסה לרכוש את מנעול X. P2 נחסם כיוון ש-P1 מחזיק ב-X.\n\nבשלב זה, P1 מחזיק ב-X וממתין ל-Y, בעוד P2 מחזיק ב-Y וממתין ל-X. זהו מצב של קיפאון.\n\n**הסבר לפי ארבעת התנאים לקיפאון:**\n1.  **מניעה הדדית (Mutual Exclusion):** מתקיים. כל מנעול (mutex) מאפשר לתהליך אחד בלבד להחזיק בו בו-זמנית. משאבים X ו-Y הם בלעדיים.\n2.  **החזקה והמתנה (Hold and Wait):** מתקיים. תהליך P1 מחזיק במנעול X וממתין למנעול Y. תהליך P2 מחזיק במנעול Y וממתין למנעול X.\n3.  **אי-נשללות (No Preemption):** מתקיים. המנעולים אינם ניתנים להילקח בכוח מתהליך שמחזיק בהם; רק התהליך המחזיק יכול לשחרר אותם.\n4.  **המתנה מעגלית (Circular Wait):** מתקיים. P1 ממתין למשאב המוחזק על ידי P2, ו-P2 ממתין למשאב המוחזק על ידי P1. נוצר מעגל המתנה: P1 -> P2 -> P1.\n\n### סעיף 1.2: אסטרטגיה למניעת קיפאון ומימוש\n**אסטרטגיה למניעת קיפאון:** הזמנה סדרתית של משאבים (Resource Ordering).\nעל מנת למנוע קיפאון, נקבע סדר גלובלי לרכישת המשאבים. לדוגמה, כל התהליכים ירכשו תמיד את `mutex_X` לפני `mutex_Y`. גישה זו מבטלת את תנאי ההמתנה המעגלית.\n\n**מימוש הפונקציות:**\n```c\npthread_mutex_t mutex_X; // מגן על משאב X\npthread_mutex_t mutex_Y; // מגן על משאב Y\n\nvoid acquire_resources() {\n    pthread_mutex_lock(&mutex_X); // רוכש תמיד את מנעול X ראשון\n    pthread_mutex_lock(&mutex_Y); // רוכש את מנעול Y שני\n}\n\nvoid release_resources() {\n    pthread_mutex_unlock(&mutex_Y); // משחרר את מנעול Y (בסדר הפוך לרכישה)\n    pthread_mutex_unlock(&mutex_X); // משחרר את מנעול X (בסדר הפוך לרכישה)\n}\n```\n**הערה:** יש לשחרר את המנעולים בסדר הפוך לסדר הרכישה כדי למנוע מצבי מירוץ ולשחרר את המשאבים כראוי.\n\n### סעיף 1.3: ניתוח השפעת האסטרטגיה\n**ניתוח השפעת האסטרטגיה:**\n\n**מקביליות (Concurrency):** אסטרטגיה זו עלולה להפחית את רמת המקביליות במערכת. אם תהליכים רבים זקוקים למשאבים X ו-Y, הם יתחרו כולם על `mutex_X` תחילה. תהליך אחד ירכוש את `mutex_X`, ולאחר מכן את `mutex_Y`. רק לאחר שישחרר את שניהם, יוכל תהליך אחר לרכוש את `mutex_X`. ייתכנו מקרים שבהם `mutex_Y` פנוי, אך תהליך נאלץ להמתין לשחרור `mutex_X` לפני שיוכל לרכוש את `mutex_Y`.\n\n**ניצול משאבים (Resource Utilization):** ניצול המשאבים עלול להיפגע. אם תהליך רוכש את `mutex_X` וממתין זמן רב לרכישת `mutex_Y` (או להיפך, אם הסדר היה הפוך), `mutex_X` יהיה תפוס ללא שימוש יעיל בזמן ההמתנה. זה יכול להוביל למשאבים שאינם בשימוש למרות שהם זמינים, רק בגלל סדר הרכישה הכפוי.\n\n**חסרונות נוספים לגישה זו:**\n1.  **מורכבות ביישום ובאכיפה:** דורש הקפדה קפדנית על סדר הרכישה בכל מקום בקוד שבו נדרשים משאבים אלו. במידה ונוספים משאבים או משתנה הדרישה, יש לעדכן את סדר הרכישה הגלובלי, וכל סטייה מהסדר עלולה להחזיר את בעיית הקיפאון.\n2.  **קשיים בהרחבה (Scalability):** במערכות עם סוגי משאבים רבים, קביעת סדר גלובלי אופטימלי ויעיל יכולה להיות קשה מאוד או בלתי אפשרית לניהול.\n3.  **הגבלת גמישות:** מגביל את הגמישות של התהליכים ברכישת משאבים בהתאם לצרכים הספציפיים שלהם או לזמינות המשאבים, מה שעלול להפחית את היעילות במקרים מסוימים שבהם סדר שונה היה יעיל יותר."}, "difficulty_estimation": "Hard", "_source_file": "0402__Deadlocks__Open__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:18:38", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Deadlocks", "Synchronization", "Concurrency", "Mutexes"], "content": {"text": "נתונה מערכת מרובת חוטים המטפלת בהעברת נתונים בין שני מאגרים (buffers), `bufferA` ו-`bufferB`. לכל מאגר יש מנעול (mutex) משלו: `mutexA` עבור `bufferA` ו-`mutexB` עבור `bufferB`. חוטים שונים עשויים לנסות לגשת למאגרים אלו, כאשר חלקם זקוקים לגישה לשניהם בו-זמנית (לדוגמה, כדי להעביר נתונים מ-A ל-B או מ-B ל-A).\nהקוד הבא מדגים שתי פונקציות, `transfer_A_to_B` ו-`transfer_B_to_A`, המנסות להעביר נתונים בין המאגרים. שימו לב לסדר נעילת המנעולים בכל פונקציה.\n\n1.  **זיהוי בעיה:** האם קיים תרחיש שבו המערכת המתוארת עלולה להיכנס למצב של קיפאון (Deadlock)? אם כן, תארו את התרחיש הספציפי והסבירו אילו מהתנאים ההכרחיים לקיפאון (Mutual Exclusion, Hold and Wait, No Preemption, Circular Wait) מתקיימים במקרה זה.\n2.  **פתרון:** הציעו שינוי בקוד או אסטרטגיה שתמנע את הקיפאון. יש להציג את השינויים בקוד (אם רלוונטי) או לתאר בבירור את האסטרטגיה.\n3.  **הוכחת נכונות:** הסבירו מדוע הפתרון שהצעתם מונע קיפאון, ואיזה מהתנאים ההכרחיים לקיפאון הוא מפר.", "code_snippet": "```c\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutexA;\npthread_mutex_t mutexB;\n\nvoid transfer_A_to_B() {\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread %lu acquired mutexA in A_to_B.\\n\", pthread_self());\n    // Simulate work or data transfer\n    sleep(1);\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread %lu acquired mutexB in A_to_B.\\n\", pthread_self());\n    // Perform data transfer from A to B\n    printf(\"Thread %lu performing A_to_B transfer.\\n\", pthread_self());\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread %lu released both mutexes in A_to_B.\\n\", pthread_self());\n}\n\nvoid transfer_B_to_A() {\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread %lu acquired mutexB in B_to_A.\\n\", pthread_self());\n    // Simulate work or data transfer\n    sleep(1);\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread %lu acquired mutexA in B_to_A.\\n\", pthread_self());\n    // Perform data transfer from B to A\n    printf(\"Thread %lu performing B_to_A transfer.\\n\", pthread_self());\n    pthread_mutex_unlock(&mutexA);\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread %lu released both mutexes in B_to_A.\\n\", pthread_self());\n}\n\n/* Example main function to demonstrate:\nint main() {\n    pthread_mutex_init(&mutexA, NULL);\n    pthread_mutex_init(&mutexB, NULL);\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, (void*(*)(void*))transfer_A_to_B, NULL);\n    pthread_create(&t2, NULL, (void*(*)(void*))transfer_B_to_A, NULL);\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n    pthread_mutex_destroy(&mutexA);\n    pthread_mutex_destroy(&mutexB);\n    return 0;\n}\n*/\n```", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "1.  **זיהוי בעיה:**\n    כן, קיים תרחיש קיפאון.\n    **תרחיש:**\n    נניח ששני חוטים, T1 ו-T2, מופעלים במקביל:\n    *   T1 קורא ל-`transfer_A_to_B()`\n    *   T2 קורא ל-`transfer_B_to_A()`\n    *   **שלב 1:** T1 מבצע `pthread_mutex_lock(&mutexA)` ומצליח לנעול את `mutexA`.\n    *   **שלב 2:** T2 מבצע `pthread_mutex_lock(&mutexB)` ומצליח לנעול את `mutexB`.\n    *   **שלב 3:** T1 מנסה כעת לבצע `pthread_mutex_lock(&mutexB)`. הוא נחסם מכיוון ש-`mutexB` נעול על ידי T2.\n    *   **שלב 4:** T2 מנסה כעת לבצע `pthread_mutex_lock(&mutexA)`. הוא נחסם מכיוון ש-`mutexA` נעול על ידי T1.\n    בנקודה זו, T1 ממתין ל-`mutexB` שנעול על ידי T2, ו-T2 ממתין ל-`mutexA` שנעול על ידי T1. אף אחד מהם לא יכול להמשיך, והמערכת נכנסת לקיפאון.\n\n    **תנאי קיפאון:**\n    *   **מניעה הדדית (Mutual Exclusion):** מתקיים. המנעולים (`mutexA`, `mutexB`) מאפשרים רק לחוט אחד להחזיק בהם בכל רגע נתון.\n    *   **החזק והמתן (Hold and Wait):** מתקיים. T1 מחזיק ב-`mutexA` וממתין ל-`mutexB`. T2 מחזיק ב-`mutexB` וממתין ל-`mutexA`.\n    *   **אי-הפקעה (No Preemption):** מתקיים. המנעולים לא ניתנים להפקעה מחוט שמחזיק בהם; רק החוט עצמו יכול לשחרר אותם.\n    *   **המתנה מעגלית (Circular Wait):** מתקיים. T1 ממתין למשאב שמוחזק על ידי T2, ו-T2 ממתין למשאב שמוחזק על ידי T1, יוצר מעגל המתנה.\n\n2.  **פתרון:**\n    הדרך הנפוצה והפשוטה ביותר למנוע קיפאון במקרה זה היא להבטיח **סדר קבוע של נעילת המשאבים**. כלומר, כל החוטים שזקוקים למספר משאבים ינעלו אותם תמיד באותו סדר. בדוגמה זו, נחליט שכל החוטים ינעלו תמיד את `mutexA` לפני `mutexB`.\n\n    **שינויים בקוד:**\n    ```c\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutexA;\npthread_mutex_t mutexB;\n\nvoid transfer_A_to_B_fixed_order() {\n    pthread_mutex_lock(&mutexA); // Acquire mutexA first\n    printf(\"Thread %lu acquired mutexA in A_to_B_fixed_order.\\n\", pthread_self());\n    sleep(1);\n    pthread_mutex_lock(&mutexB); // Then acquire mutexB\n    printf(\"Thread %lu acquired mutexB in A_to_B_fixed_order.\\n\", pthread_self());\n    // Perform data transfer from A to B\n    printf(\"Thread %lu performing A_to_B transfer.\\n\", pthread_self());\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread %lu released both mutexes in A_to_B_fixed_order.\\n\", pthread_self());\n}\n\nvoid transfer_B_to_A_fixed_order() {\n    pthread_mutex_lock(&mutexA); // Acquire mutexA first, even if it's for B_to_A\n    printf(\"Thread %lu acquired mutexA in B_to_A_fixed_order.\\n\", pthread_self());\n    sleep(1);\n    pthread_mutex_lock(&mutexB); // Then acquire mutexB\n    printf(\"Thread %lu acquired mutexB in B_to_A_fixed_order.\\n\", pthread_self());\n    // Perform data transfer from B to A\n    printf(\"Thread %lu performing B_to_A transfer.\\n\", pthread_self());\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread %lu released both mutexes in B_to_A_fixed_order.\\n\", pthread_self());\n}\n    ```\n\n3.  **הוכחת נכונות:**\n    הפתרון מונע קיפאון על ידי הפרת התנאי של **המתנה מעגלית (Circular Wait)**.\n    כאשר כל החוטים מקפידים על סדר קבוע של נעילת המשאבים (לדוגמה, תמיד `mutexA` ואז `mutexB`), לא ייתכן שחוט אחד (T1) יחזיק ב-`mutexA` וימתין ל-`mutexB`, ובאותו זמן חוט אחר (T2) יחזיק ב-`mutexB` וימתין ל-`mutexA`.\n    אם חוט T1 תופס את `mutexA`, וחוט T2 מנסה לתפוס את `mutexA`, T2 ייחסם. T2 לא יוכל לתפוס את `mutexB` לפני `mutexA` (לפי הכלל החדש של סדר קבוע), ולכן לא יכול להיווצר המצב שבו T2 מחזיק ב-`mutexB` בזמן ש-T1 ממתין לו. הסדר הקבוע מבטיח היררכיה של נעילת משאבים, ובכך מונע היווצרות של מעגל המתנה."}, "difficulty_estimation": "Hard", "_source_file": "0403__Deadlocks__Open__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:47:16", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Deadlocks", "Synchronization", "Resource Management", "Concurrency"], "content": {"text": "במערכת מרובת תהליכונים (threads), קיפאון (deadlock) הוא מצב קריטי שיש למנוע או לטפל בו. שאלה זו בוחנת את הבנתך בגורמים לקיפאון ובדרכים למנוע אותו, תוך התייחסות לתרחיש ספציפי ומימוש קוד.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "a", "text": "תאר בקצרה את ארבעת התנאים ההכרחיים להתרחשות קיפאון במערכת.", "code_snippet": null, "options": null}, {"id": "b", "text": "נתונה מערכת עם שני משאבים משותפים, `ResourceA` ו-`ResourceB`, כאשר כל אחד מהם מוגן על ידי מנעול (mutex) נפרד. במערכת פועלים מספר תהליכוני עבודה (worker threads), וכל תהליכון זקוק לשניהם, `ResourceA` ו-`ResourceB`, כדי לבצע את משימתו. תאר תרחיש ספציפי (באמצעות רצף פעולות או פסאודו-קוד) שבו יכול להתרחש קיפאון במערכת זו. הסבר מדוע תרחיש זה מוביל לקיפאון תוך התייחסות לארבעת התנאים שתיארת בסעיף א'.", "code_snippet": null, "options": null}, {"id": "c", "text": "בהתבסס על התרחיש שתואר בסעיף ב', כתוב פונקציית C/C++ בשם `acquire_both_resources()` המקבלת מצביעים למנעולים של `ResourceA` ו-`ResourceB` (לדוגמה, `pthread_mutex_t*`). הפונקציה צריכה לרכוש את שני המשאבים באופן בטוח, כך שתמנע את הקיפאון שתואר. עליך להשתמש במנעולי `pthread_mutex_t` בלבד. אין לשנות את סדר הרכישה של המנעולים בתוך הפונקציה (כלומר, `ResourceA` ואז `ResourceB`), אך מותר להשתמש בפונקציות נעילה לא חוסמות (לדוגמה, `pthread_mutex_trylock`).", "code_snippet": "void acquire_both_resources(pthread_mutex_t* resA_mutex, pthread_mutex_t* resB_mutex) {\n    // Implement your solution here\n}", "options": null}, {"id": "d", "text": "הסבר איזו אסטרטגיה למניעת קיפאון (Deadlock Prevention) או הימנעות מקיפאון (Deadlock Avoidance) יישמת בסעיף ג'. דון ביתרונות ובחסרונות של אסטרטגיה זו, לרבות השלכותיה על ביצועי המערכת (לדוגמה, רעב או ניצול משאבים).", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "א. ארבעת התנאים ההכרחיים לקיפאון:\n1.  **מניעה הדדית (Mutual Exclusion):** לפחות משאב אחד חייב להיות בלעדי, כלומר, רק תהליך אחד יכול להשתמש בו בכל רגע נתון. אם תהליך אחר מבקש את המשאב, עליו להמתין עד שהתהליך הראשון ישחרר אותו.\n2.  **החזקה והמתנה (Hold and Wait):** תהליך חייב להחזיק לפחות במשאב אחד ובמקביל לבקש משאבים נוספים המוחזקים על ידי תהליכים אחרים.\n3.  **אי-שלילה (No Preemption):** משאבים אינם ניתנים לשלילה בכוח. הם יכולים להשתחרר רק באופן וולונטרי על ידי התהליך שמחזיק בהם, לאחר שסיים את השימוש בהם.\n4.  **המתנה מעגלית (Circular Wait):** קיימת שרשרת מעגלית של שניים או יותר תהליכים, כאשר כל תהליך בשרשרת ממתין למשאב המוחזק על ידי התהליך הבא בשרשרת.\n\nב. תרחיש קיפאון:\nנניח שיש שני תהליכונים, Thread 0 ו-Thread 1.\nהתרחיש הבא יכול להוביל לקיפאון:\n1.  Thread 0 רוכש את `ResourceA`.\n    (`pthread_mutex_lock(&mutexA);`)\n2.  Thread 1 רוכש את `ResourceB`.\n    (`pthread_mutex_lock(&mutexB);`)\n3.  Thread 0 מנסה לרכוש את `ResourceB`. הוא נחסם מכיוון ש-Thread 1 מחזיק בו.\n    (`pthread_mutex_lock(&mutexB);` - Thread 0 נחסם)\n4.  Thread 1 מנסה לרכוש את `ResourceA`. הוא נחסם מכיוון ש-Thread 0 מחזיק בו.\n    (`pthread_mutex_lock(&mutexA);` - Thread 1 נחסם)\n\n**הסבר מדוע תרחיש זה מוביל לקיפאון:**\n*   **מניעה הדדית:** מתקיימת עבור `mutexA` ו-`mutexB`, שכן רק תהליכון אחד יכול להחזיק בכל מנעול בכל רגע נתון.\n*   **החזקה והמתנה:** Thread 0 מחזיק ב-`mutexA` וממתין ל-`mutexB`. Thread 1 מחזיק ב-`mutexB` וממתין ל-`mutexA`.\n*   **אי-שלילה:** המנעולים אינם נשללים בכוח. הם ישוחררו רק כאשר התהליכונים יחליטו לשחרר אותם (וזה לא יקרה כי הם חסומים).\n*   **המתנה מעגלית:** נוצרה שרשרת המתנה מעגלית: Thread 0 ממתין למשאב ש-Thread 1 מחזיק בו (`mutexB`), ו-Thread 1 ממתין למשאב ש-Thread 0 מחזיק בו (`mutexA`).\n\nכל ארבעת התנאים מתקיימים, ולכן המערכת נמצאת בקיפאון.\n\nג. מימוש פונקציית `acquire_both_resources()`:\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\nvoid acquire_both_resources(pthread_mutex_t* resA_mutex, pthread_mutex_t* resB_mutex) {\n    while (1) { // Keep trying until both resources are acquired\n        // Try to acquire ResourceA\n        int resA_locked = pthread_mutex_trylock(resA_mutex);\n\n        if (resA_locked == 0) { // Successfully acquired ResourceA\n            // Try to acquire ResourceB\n            int resB_locked = pthread_mutex_trylock(resB_mutex);\n            if (resB_locked == 0) { // Successfully acquired ResourceB\n                // Both resources acquired, exit loop\n                return;\n            } else { // Could not acquire ResourceB\n                // Release ResourceA and retry\n                pthread_mutex_unlock(resA_mutex);\n                // Optional: Add a small delay to avoid busy-waiting or to allow other threads to progress\n                usleep(1000); // Sleep for 1ms\n            }\n        } else { // Could not acquire ResourceA\n            // Optional: Add a small delay\n            usleep(1000); // Sleep for 1ms\n        }\n    }\n}\n```\n\nד. אסטרטגיה, יתרונות וחסרונות:\nהאסטרטגיה שיושמה היא וריאציה של **מניעת קיפאון (Deadlock Prevention)**, ובפרט, שבירת התנאי של **החזקה והמתנה (Hold and Wait)**.\nבמקום לאפשר לתהליך להחזיק במשאבים שכבר רכש בזמן שהוא ממתין למשאבים נוספים, הפונקציה `acquire_both_resources` מנסה לרכוש את כל המשאבים הנדרשים (במקרה זה, שניים) בו-זמנית או לשחרר את כל המשאבים שכבר נרכשו אם לא ניתן לרכוש את כולם.\nבמקרה הספציפי של המימוש, אם תהליכון מצליח לרכוש את `ResourceA` אך נכשל ברכישת `ResourceB` (כי הוא מוחזק על ידי תהליכון אחר), הוא משחרר את `ResourceA` שהחזיק בו ומנסה שוב. זה מבטיח שאף תהליכון לא יחזיק במשאב אחד וימתין לאחר, ובכך נמנעת ההמתנה המעגלית שמובילה לקיפאון.\n\n**יתרונות:**\n*   **מניעת קיפאון מובטחת:** המנגנון מבטיח שאף תהליכון לא יחזיק במשאב אחד וימתין למשאב אחר, ובכך מונע את התנאי של Hold and Wait ואת הקיפאון.\n*   **פשטות יחסית ליישום:** עבור מספר קטן של משאבים, כמו במקרה זה, קל יחסית ליישם את הלוגיקה של ניסיון רכישה ושחרור.\n\n**חסרונות:**\n*   **רעב (Starvation) פוטנציאלי:** ייתכן שתהליכון מסוים ינסה שוב ושוב לרכוש את המשאבים, אך תמיד ייכשל (לדוגמה, אם יש עומס רב ותהליכונים אחרים תמיד מצליחים לרכוש לפניו). הוספת `usleep()` עוזרת להפחית את הצריכה של CPU אך לא מונעת רעב לחלוטין.\n*   **חוסר יעילות / בזבוז משאבים (Resource Utilization):** המשאבים שנרכשו ונשחררו מיד (כמו `ResourceA` בתרחיש שבו `ResourceB` לא זמין) אינם מנוצלים ביעילות. תהליכון עלול לבצע פעולות רכישה ושחרור רבות לפני שיצליח לרכוש את כל המשאבים הדרושים.\n*   **עלויות ביצועים (Performance Overhead):** השימוש ב-`pthread_mutex_trylock` בלולאה, יחד עם השחרור והניסיון החוזר, יכול להוביל לצריכת CPU גבוהה (busy-waiting) אם המשאבים תפוסים לפרקי זמן ארוכים. הוספת `usleep` מקטינה את הצריכה אך מגדילה את זמן ההמתנה.\n*   **מורכבות עם מספר רב של משאבים:** עבור מספר גדול של משאבים, יישום לוגיקה זו הופך למורכב יותר (לדוגמה, צורך לשחרר מספר משאבים שנרכשו חלקית) ופחות יעיל."}, "difficulty_estimation": "Hard", "_source_file": "0404__Deadlocks__Open__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:19:50", "_subject": "Concurrency"}, {"id": 101, "type": "Open", "topic": ["Deadlocks", "Resource Management", "Banker's Algorithm"], "content": {"text": "נתונה מערכת הפעלה המנהלת שלושה סוגי משאבים: R1, R2, R3. מספר היחידות הכולל מכל סוג משאב הוא: R1=10, R2=5, R3=7.\nבמערכת פועלים ארבעה תהליכים: P0, P1, P2, P3.\nלהלן טבלת הקצאת המשאבים הנוכחית (Allocation) וטבלת הדרישה המקסימלית (Max) של כל תהליך:\n\n**Allocation:**\n| Process | R1 | R2 | R3 |\n|---------|----|----|----|\n| P0      | 0  | 1  | 0  |\n| P1      | 2  | 0  | 0  |\n| P2      | 3  | 0  | 2  |\n| P3      | 2  | 1  | 1  |\n\n**Max:**\n| Process | R1 | R2 | R3 |\n|---------|----|----|----|\n| P0      | 7  | 5  | 3  |\n| P1      | 3  | 2  | 2  |\n| P2      | 9  | 0  | 2  |\n| P3      | 2  | 2  | 2  |\n\nענו על השאלות הבאות בהתבסס על אלגוריתם הבנקאי:", "code_snippet": null, "options": null}, "sub_questions": [{"id": "a", "text": "מהו מצב המשאבים הזמינים כרגע (Available)? האם המצב הנוכחי בטוח? אם כן, הציגו רצף בטוח.", "code_snippet": null, "options": null}, {"id": "b", "text": "נניח שתהליך P1 מבקש משאבים נוספים: (R1=1, R2=0, R3=2). האם ניתן לאשר בקשה זו באופן מיידי? נמקו את תשובתכם.", "code_snippet": null, "options": null}, {"id": "c", "text": "דון במגבלות של אלגוריתם הבנקאי ביישום במערכת הפעלה אמיתית.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "חלק 1: בטיחות המצב ההתחלתי\n\nראשית, נחשב את וקטור המשאבים הזמינים (Available) ואת מטריצת הדרישה (Need).\nסה\"כ משאבים: R1=10, R2=5, R3=7.\nסה\"כ משאבים מוקצים (Allocation Sum):\nR1: 0+2+3+2 = 7\nR2: 1+0+0+1 = 2\nR3: 0+0+2+1 = 3\nוקטור המשאבים המוקצים = (7, 2, 3).\nוקטור המשאבים הזמינים (Available) = סה\"כ משאבים - וקטור המשאבים המוקצים = (10, 5, 7) - (7, 2, 3) = **(3, 3, 4)**.\n\nמטריצת הדרישה (Need = Max - Allocation):\nP0: (7, 5, 3) - (0, 1, 0) = (7, 4, 3)\nP1: (3, 2, 2) - (2, 0, 0) = (1, 2, 2)\nP2: (9, 0, 2) - (3, 0, 2) = (6, 0, 0)\nP3: (2, 2, 2) - (2, 1, 1) = (0, 1, 1)\n\nנפעיל את אלגוריתם הבנקאי לבדיקת בטיחות המצב:\nWork = (3, 3, 4), Finish = [False, False, False, False]\n\n1.  **תהליך P1**: Need(P1)=(1,2,2) <= Work(3,3,4). כן.\n    Work = Work + Allocation(P1) = (3,3,4) + (2,0,0) = (5,3,4)\n    Finish[1] = True\n    רצף בטוח עד כה: <P1>\n\n2.  **תהליך P3**: Need(P3)=(0,1,1) <= Work(5,3,4). כן.\n    Work = Work + Allocation(P3) = (5,3,4) + (2,1,1) = (7,4,5)\n    Finish[3] = True\n    רצף בטוח עד כה: <P1, P3>\n\n3.  **תהליך P0**: Need(P0)=(7,4,3) <= Work(7,4,5). כן.\n    Work = Work + Allocation(P0) = (7,4,5) + (0,1,0) = (7,5,5)\n    Finish[0] = True\n    רצף בטוח עד כה: <P1, P3, P0>\n\n4.  **תהליך P2**: Need(P2)=(6,0,0) <= Work(7,5,5). כן.\n    Work = Work + Allocation(P2) = (7,5,5) + (3,0,2) = (10,5,7)\n    Finish[2] = True\n    רצף בטוח סופי: <P1, P3, P0, P2>\n\nמכיוון שנמצא רצף בטוח שבו כל התהליכים יכולים להשלים את ביצועם, **המצב הנוכחי בטוח**.\n\nחלק 2: בקשת משאבים נוספים מ-P1\n\nתהליך P1 מבקש משאבים נוספים: Request(P1) = (1, 0, 2).\nמצב נוכחי: Available = (3, 3, 4), Allocation(P1) = (2, 0, 0), Need(P1) = (1, 2, 2).\n\nנבדוק את תנאי הבקשה:\n1.  האם Request(P1) <= Need(P1)? כלומר, (1,0,2) <= (1,2,2)? כן (1<=1, 0<=2, 2<=2). הבקשה אינה חורגת מהדרישה המקסימלית שהתהליך הצהיר עליה.\n2.  האם Request(P1) <= Available? כלומר, (1,0,2) <= (3,3,4)? כן (1<=3, 0<=3, 2<=4). יש מספיק משאבים זמינים כדי לספק את הבקשה.\n\nמכיוון ששני התנאים מתקיימים, נדמה הקצאה ונבדוק שוב את בטיחות המצב:\nAvailable' = Available - Request(P1) = (3,3,4) - (1,0,2) = (2,3,2)\nAllocation'(P1) = Allocation(P1) + Request(P1) = (2,0,0) + (1,0,2) = (3,0,2)\nNeed'(P1) = Need(P1) - Request(P1) = (1,2,2) - (1,0,2) = (0,2,0)\n\nמטריצת Need המעודכנת:\nP0: (7, 4, 3)\nP1: (0, 2, 0)\nP2: (6, 0, 0)\nP3: (0, 1, 1)\n\nנפעיל את אלגוריתם הבנקאי עם המצב החדש:\nWork = (2, 3, 2), Finish = [False, False, False, False]\n\n1.  **תהליך P1**: Need(P1)=(0,2,0) <= Work(2,3,2). כן.\n    Work = Work + Allocation'(P1) = (2,3,2) + (3,0,2) = (5,3,4)\n    Finish[1] = True\n    רצף בטוח עד כה: <P1>\n\n2.  **תהליך P3**: Need(P3)=(0,1,1) <= Work(5,3,4). כן.\n    Work = Work + Allocation(P3) = (5,3,4) + (2,1,1) = (7,4,5)\n    Finish[3] = True\n    רצף בטוח עד כה: <P1, P3>\n\n3.  **תהליך P0**: Need(P0)=(7,4,3) <= Work(7,4,5). כן.\n    Work = Work + Allocation(P0) = (7,4,5) + (0,1,0) = (7,5,5)\n    Finish[0] = True\n    רצף בטוח עד כה: <P1, P3, P0>\n\n4.  **תהליך P2**: Need(P2)=(6,0,0) <= Work(7,5,5). כן.\n    Work = Work + Allocation(P2) = (7,5,5) + (3,0,2) = (10,5,7)\n    Finish[2] = True\n    רצף בטוח סופי: <P1, P3, P0, P2>\n\nמכיוון שגם לאחר הקצאת המשאבים לבקשת P1 נמצא רצף בטוח, **ניתן לאשר את הבקשה באופן מיידי**.\n\nחלק 3: מגבלות אלגוריתם הבנקאי במערכת הפעלה אמיתית\n\nאלגוריתם הבנקאי הוא יעיל במניעת קיפאון (deadlock), אך יש לו מספר מגבלות המקשות על יישומו במערכות הפעלה אמיתיות:\n\n1.  **ידיעה מוקדמת של דרישות מקסימליות (Max Needs)**: כל תהליך חייב להצהיר מראש על הדרישה המקסימלית שלו לכל סוג משאב. במקרים רבים, תהליכים אינם יודעים מראש את כל דרישות המשאבים שלהם לאורך כל זמן הריצה.\n2.  **מספר קבוע של תהליכים ומשאבים**: האלגוריתם מניח מספר קבוע של תהליכים ומספר קבוע של יחידות מכל סוג משאב. במערכת הפעלה דינמית, תהליכים נוצרים ומסתיימים כל הזמן, וייתכן שגם משאבים מתווספים או מוסרים. שינויים אלו דורשים עדכון מתמיד של מצב המערכת, מה שמסבך את היישום.\n3.  **שחרור משאבים בסיום**: ההנחה היא שתהליך משחרר את כל המשאבים שהוקצו לו בסיום ביצועו. למרות שזה נכון בדרך כלל, ישנם תהליכים ארוכי טווח שעשויים להחזיק משאבים לזמן רב.\n4.  **תקורה חישובית גבוהה**: בדיקת הבטיחות (Safety Algorithm) צריכה להתבצע בכל פעם שתהליך מבקש משאבים. במערכות עם מספר רב של תהליכים וסוגי משאבים, הדבר עלול להוביל לתקורה חישובית משמעותית ולפגוע בביצועי המערכת.\n5.  **רעב (Starvation)**: למרות שהאלגוריתם מונע קיפאון, הוא אינו מונע בהכרח רעב. תהליך בעל דרישות משאבים גבוהות עלול להידחות שוב ושוב אם הקצאת המשאבים עבורו תוביל למצב לא בטוח, גם אם המשאבים זמינים באופן תיאורטי."}, "difficulty_estimation": "Hard", "_source_file": "0405__Deadlocks__Open__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:20:26", "_subject": "Concurrency"}, {"id": 1, "type": "Open", "topic": ["Deadlocks", "Synchronization", "Resource Management", "Concurrency"], "content": {"text": "נתונה מערכת הפעלה שבה מספר רב של תהליכים ניגשים למספר סוגים שונים של משאבים. נניח שישנם M סוגי משאבים, המסומנים R0, R1, ..., RM-1. לכל סוג משאב יש מופע יחיד (לדוגמה, מדפסת ספציפית, סורק ספציפי). תהליכים צריכים לרכוש גישה למשאבים אלו כדי לבצע את עבודתם. המערכת משתמשת במנעולים (mutexes) כדי להבטיח מניעה הדדית לכל מופע משאב. נתון קטע הקוד הבא המדגים רכישת משאבים על ידי תהליך, כאשר הסדר שבו התהליך רוכש את המשאבים הוא שרירותי:\n\n```c\n// M הוא מספר סוגי המשאבים הכולל במערכת\npthread_mutex_t resource_locks[M]; // מערך מנעולים, אחד לכל סוג משאב\n\nvoid acquire_resources_arbitrary(int resource1_type_id, int resource2_type_id) {\n    // תהליך רוכש משאב ראשון\n    pthread_mutex_lock(&resource_locks[resource1_type_id]);\n    printf(\"Acquired R%d\\n\", resource1_type_id);\n\n    // תהליך רוכש משאב שני\n    pthread_mutex_lock(&resource_locks[resource2_type_id]);\n    printf(\"Acquired R%d\\n\", resource2_type_id);\n\n    // ... שימוש במשאבים ...\n\n    // שחרור משאבים (בסדר הפוך לרכישה, או בכל סדר)\n    pthread_mutex_unlock(&resource_locks[resource2_type_id]);\n    pthread_mutex_unlock(&resource_locks[resource1_type_id]);\n}\n```\n\n1.  הסבירו כיצד מצב של קיפאון (Deadlock) יכול להתרחש במערכת זו. תארו תרחיש ספציפי הכולל שני תהליכים ושני סוגי משאבים (לדוגמה, R0 ו-R1) כדי להדגים את הקיפאון.\n\n2.  הציעו פתרון למניעת קיפאון במערכת זו, על ידי שינוי אופן רכישת המשאבים. ספקו מימוש קוד ב-C/C++ (או פסאודו-קוד) המדגים את הפתרון שלכם, והסבירו איזו משלוש התכונות ההכרחיות לקיפאון נשברת על ידי הפתרון.\n\n3.  דונו בשני חסרונות פוטנציאליים של הפתרון שהצעתם (לדוגמה, השפעה על מקביליות, רעב).", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  **הסבר לקיפאון:**\n    מצב של קיפאון (deadlock) יכול להתרחש במערכת זו כאשר מתקיימים ארבעת התנאים ההכרחיים לקיפאון: מניעה הדדית, החזקה והמתנה, אי-יכולת לדרוס, והמתנה מעגלית.\n    *   **מניעה הדדית (Mutual Exclusion):** תנאי זה מתקיים, שכן כל מופע משאב מוגן על ידי מנעול (mutex), ורק תהליך אחד יכול להחזיק בו זמנית מנעול על משאב ספציפי.\n    *   **החזקה והמתנה (Hold and Wait):** תנאי זה מתקיים, שכן תהליך יכול להחזיק במשאב אחד (על ידי נעילת המוטקס שלו) ובמקביל להמתין לרכישת משאב נוסף (על ידי ניסיון לנעול מוטקס אחר).\n    *   **אי-יכולת לדרוס (No Preemption):** תנאי זה מתקיים, שכן משאבים אינם נלקחים מתהליכים בכוח; הם משוחררים רק מרצון על ידי התהליך שהחזיק בהם.\n    *   **המתנה מעגלית (Circular Wait):** זהו התנאי שעלול להיווצר כתוצאה מהרכישה השרירותית של המשאבים. אם תהליך A רוכש את R_i וממתין ל-R_j, ובמקביל תהליך B רוכש את R_j וממתין ל-R_i, נוצר מעגל המתנה שבו כל תהליך ממתין למשאב המוחזק על ידי התהליך הבא במעגל.\n\n    **תרחיש ספציפי לקיפאון (שני תהליכים, שני משאבים R0, R1):**\n    נניח שיש לנו שני תהליכים, `P1` ו-`P2`, ושני סוגי משאבים `R0` ו-`R1`. שני התהליכים מנסים לרכוש את שני המשאבים.\n    1.  `P1` קורא ל-`acquire_resources_arbitrary(0, 1)`. הוא מבצע `pthread_mutex_lock(&resource_locks[0])` ורוכש את `R0`.\n    2.  מיד לאחר מכן (לפני ש-`P1` רוכש את `R1`), `P2` קורא ל-`acquire_resources_arbitrary(1, 0)`. הוא מבצע `pthread_mutex_lock(&resource_locks[1])` ורוכש את `R1`.\n    3.  כעת, `P1` מנסה לבצע `pthread_mutex_lock(&resource_locks[1])`. `R1` מוחזק על ידי `P2`, ולכן `P1` נחסם וממתין.\n    4.  במקביל, `P2` מנסה לבצע `pthread_mutex_lock(&resource_locks[0])`. `R0` מוחזק על ידי `P1`, ולכן `P2` נחסם וממתין.\n    בשלב זה, `P1` מחזיק ב-`R0` וממתין ל-`R1`, ו-`P2` מחזיק ב-`R1` וממתין ל-`R0`. נוצרה המתנה מעגלית, ושני התהליכים נמצאים בקיפאון.\n\n2.  **פתרון למניעת קיפאון (רכישה בסדר קבוע):**\n    כדי למנוע קיפאון, ניתן לשבור את תנאי ה**המתנה מעגלית** (Circular Wait). הדרך הנפוצה לעשות זאת היא על ידי הטלת סדר גלובלי (Total Ordering) על כל סוגי המשאבים. כלומר, תהליכים חייבים לרכוש משאבים תמיד בסדר עולה (או יורד) של מזהי המשאבים שלהם. לדוגמה, אם יש לנו `M` סוגי משאבים עם מזהים מ-0 עד `M-1`, תהליך שזקוק למשאבים `R_i` ו-`R_j` ירכוש תמיד את המשאב בעל המזהה הנמוך יותר תחילה.\n\n    **מימוש קוד ב-C/C++:**\n    ```c\n    // M הוא מספר סוגי המשאבים הכולל במערכת\n    pthread_mutex_t resource_locks[M]; // מערך מנעולים, אחד לכל סוג משאב\n\n    // פונקציה כללית לרכישת מערך של משאבים בסדר קבוע\n    // resource_types הוא מערך של מזהי סוגי המשאבים הנדרשים\n    // count הוא מספר המשאבים במערך resource_types\n    void acquire_multiple_resources_ordered(int* resource_types, int count) {\n        // צור עותק של המזהים ומין אותם בסדר עולה\n        int* sorted_resource_types = (int*)malloc(sizeof(int) * count);\n        for (int i = 0; i < count; i++) {\n            sorted_resource_types[i] = resource_types[i];\n        }\n\n        // מיון פשוט (לדוגמה, מיון בועות) יכול לשמש כאן\n        for (int i = 0; i < count - 1; i++) {\n            for (int j = i + 1; j < count; j++) {\n                if (sorted_resource_types[i] > sorted_resource_types[j]) {\n                    int temp = sorted_resource_types[i];\n                    sorted_resource_types[i] = sorted_resource_types[j];\n                    sorted_resource_types[j] = temp;\n                }\n            }\n        }\n\n        // רכוש את המשאבים בסדר הממוין\n        for (int i = 0; i < count; i++) {\n            // הימנע מרכישה כפולה אם יש מזהים זהים במערך הממוין (לאחר מיון ובמקרה של קלט עם כפילויות)\n            if (i > 0 && sorted_resource_types[i] == sorted_resource_types[i-1]) {\n                continue;\n            }\n            pthread_mutex_lock(&resource_locks[sorted_resource_types[i]]);\n            printf(\"Acquired R%d\\n\", sorted_resource_types[i]);\n        }\n\n        // ... שימוש במשאבים ...\n\n        // שחרור משאבים בסדר הפוך לרכישה (מומלץ לשחרור נכון של המנעולים)\n        for (int i = count - 1; i >= 0; i--) {\n            if (i < count - 1 && sorted_resource_types[i] == sorted_resource_types[i+1]) {\n                continue;\n            }\n            pthread_mutex_unlock(&resource_locks[sorted_resource_types[i]]);\n            printf(\"Released R%d\\n\", sorted_resource_types[i]);\n        }\n        free(sorted_resource_types);\n    }\n    ```\n\n    **איזו תכונה נשברת:**\n    הפתרון שובר את תנאי ה**המתנה מעגלית** (Circular Wait). על ידי אכיפת סדר גלובלי לרכישת משאבים, לא ניתן ליצור שרשרת המתנה מעגלית. אם תהליך A מחזיק ב-R_i וממתין ל-R_j, ו-R_i < R_j, אז תהליך B לא יכול להחזיק ב-R_j ולהמתין ל-R_i, מכיוון שהוא יצטרך לרכוש את R_i (שהוא בעל מזהה נמוך יותר) לפני שיוכל לרכוש את R_j. כלומר, לא ייתכן מצב שבו תהליך P1 מחכה ל-Rj שמוחזק על ידי P2, ותהליך P2 מחכה ל-Ri שמוחזק על ידי P1, כאשר Ri < Rj. לכן, כל שרשרת המתנה תהיה ליניארית ולא מעגלית, ובכך נמנע קיפאון.\n\n3.  **חסרונות פוטנציאליים של הפתרון:**\n    *   **הפחתת מקביליות (Reduced Concurrency):** הטלת סדר גלובלי על רכישת משאבים עלולה להפחית את רמת המקביליות במערכת. תהליך שזקוק למשאב בעל מזהה גבוה (לדוגמה, R_M-1) אך גם למשאב בעל מזהה נמוך (לדוגמה, R0) חייב לרכוש קודם את R0. אם R0 מוחזק על ידי תהליך אחר, התהליך הראשון ייאלץ להמתין, גם אם R_M-1 פנוי וזמין לשימוש. זה עלול לגרום לתהליכים להחזיק משאבים לזמן ארוך יותר ממה שהיה נחוץ באמת, או להמתין זמן רב למשאבים פנויים, ובכך להפחית את ניצולת המשאבים הכוללת ואת ביצועי המערכת.\n    *   **פוטנציאל לרעב (Potential for Starvation):** למרות שהפתרון מונע קיפאון, הוא עלול לגרום לרעב (starvation) במקרים מסוימים. תהליך שדורש משאבים רבים בעלי מזהים נמוכים מאוד, או משאב בעל מזהה נמוך במיוחד שנמצא בשימוש תדיר, עלול להיתקל בקשיים תמידיים ברכישת המשאבים הללו ולהידחק הצידה שוב ושוב על ידי תהליכים אחרים. לדוגמה, תהליך שזקוק ל-R0 יחכה זמן רב אם ישנם תהליכים רבים אחרים שרוכשים ומשחררים את R0 כל הזמן, גם אם הוא זקוק רק ל-R0 ול-R_M-1, בעוד R_M-1 פנוי. זה אמנם אינו קיפאון, אך עדיין מונע מהתהליך להתקדם בביצועו ללא הגבלת זמן."}, "difficulty_estimation": "Hard", "_source_file": "0406__Deadlocks__Open__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:21:01", "_subject": "Concurrency"}, {"id": 101, "type": "Open", "topic": ["Deadlocks", "Concurrency", "Synchronization", "Mutexes"], "content": {"text": "נתונה מערכת בנקאית הממומשת באמצעות קוד C++ כפי שמוצג להלן. המערכת מאפשרת העברת כספים בין חשבונות שונים. כל חשבון מוגן על ידי מנעול (mutex) משלו כדי להבטיח עקביות במהלך טרנזקציות. פונקציית `transfer` מקבלת מזהי חשבון מקור ויעד וסכום להעברה.", "code_snippet": "#include <iostream>\n#include <thread>\n#include <mutex>\n#include <vector>\n#include <map>\n#include <chrono>\n\n// Assume Account IDs are integers\nstd::map<int, std::mutex> account_locks;\nstd::map<int, double> account_balances;\n\n// Initialize accounts (for example purposes)\nvoid init_accounts(int num_accounts) {\n    for (int i = 0; i < num_accounts; ++i) {\n        account_locks[i]; // Default constructs mutex for each account ID\n        account_balances[i] = 100.0;\n    }\n}\n\n// Transaction function\nvoid transfer(int from_account_id, int to_account_id, double amount) {\n    // Simulate some work before locking\n    std::this_thread::sleep_for(std::chrono::milliseconds(10));\n\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Trying to lock \" << from_account_id << \" and \" << to_account_id << std::endl;\n\n    // Acquire locks for the source and destination accounts\n    account_locks[from_account_id].lock();\n    account_locks[to_account_id].lock();\n\n    // Check for sufficient balance and perform transfer\n    if (account_balances[from_account_id] >= amount) {\n        account_balances[from_account_id] -= amount;\n        account_balances[to_account_id] += amount;\n        std::cout << \"Thread \" << std::this_thread::get_id() << \": Transferred \" << amount\n                  << \" from \" << from_account_id << \" to \" << to_account_id << std::endl;\n    } else {\n        std::cout << \"Thread \" << std::this_thread::get_id() << \": Insufficient balance in \"\n                  << from_account_id << \" to transfer \" << amount << std::endl;\n    }\n\n    // Release locks\n    account_locks[to_account_id].unlock();\n    account_locks[from_account_id].unlock();\n}\n\nint main() {\n    init_accounts(3); // Initialize accounts 0, 1, 2\n\n    // Create multiple threads attempting transfers\n    // This specific combination is designed to demonstrate deadlock potential\n    std::thread t1(transfer, 0, 1, 10.0);\n    std::thread t2(transfer, 1, 0, 20.0);\n    std::thread t3(transfer, 0, 2, 5.0);\n    std::thread t4(transfer, 2, 0, 15.0);\n\n    t1.join();\n    t2.join();\n    t3.join();\n    t4.join();\n\n    std::cout << \"\\nFinal Balances:\" << std::endl;\n    for (int i = 0; i < 3; ++i) {\n        std::cout << \"Account \" << i << \": \" << account_balances[i] << std::endl;\n    }\n\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "a", "text": "האם בקוד הנתון קיים פוטנציאל לדדלוק? אם כן, תארו מצב ספציפי (לדוגמה, עם חוטים T1 ו-T2 ומזהי חשבונות ספציפיים) שבו דדלוק יתרחש. הסבירו בקצרה מדוע זהו דדלוק על בסיס ארבעת התנאים ההכרחיים (מניעה הדדית, החזק והמתן, אי-הפקעה, המתנה מעגלית).", "code_snippet": null, "options": null}, {"id": "b", "text": "הציעו שינוי מינימלי בקוד של פונקציית `transfer` כדי למנוע דדלוק. כתבו את הקוד המתוקן והסבירו בקצרה מדוע השינוי מונע דדלוק.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "### פתרון סעיף א' - זיהוי דדלוק\n\n**כן, בקוד הנתון קיים פוטנציאל לדדלוק.**\n\n**תיאור מצב ספציפי לדדלוק:**\nנניח ששני חוטים, T1 ו-T2, מבצעים טרנזקציות בו-זמנית:\n*   חוט T1 קורא ל-`transfer(0, 1, 10.0)` (מעביר מחשבון 0 לחשבון 1).\n*   חוט T2 קורא ל-`transfer(1, 0, 20.0)` (מעביר מחשבון 1 לחשבון 0).\n\nהתרחיש שיוביל לדדלוק הוא כדלקמן:\n1.  חוט T1 מבצע `account_locks[0].lock()` ותופס את המנעול של חשבון 0.\n2.  חוט T2 מבצע `account_locks[1].lock()` ותופס את המנעול של חשבון 1.\n3.  חוט T1 מנסה לבצע `account_locks[1].lock()` אך המנעול תפוס על ידי T2. T1 נכנס למצב המתנה.\n4.  חוט T2 מנסה לבצע `account_locks[0].lock()` אך המנעול תפוס על ידי T1. T2 נכנס למצב המתנה.\n\nבמצב זה, T1 מחזיק במנעול ש-T2 זקוק לו, ו-T2 מחזיק במנעול ש-T1 זקוק לו. שני החוטים ממתינים זה לזה לנצח, ולכן מתרחש דדלוק.\n\n**הסבר על בסיס ארבעת התנאים ההכרחיים לדדלוק:**\n1.  **מניעה הדדית (Mutual Exclusion):** כל מנעול (mutex) של חשבון יכול להיות מוחזק על ידי חוט אחד בלבד בכל רגע נתון. זה מתקיים בקוד כי `std::mutex` הוא אובייקט סנכרון בלעדי.\n2.  **החזק והמתן (Hold and Wait):** חוטים מחזיקים במשאב אחד (מנעול של חשבון) וממתינים למשאב נוסף שתפוס על ידי חוט אחר. בדוגמה לעיל, T1 מחזיק את מנעול 0 וממתין למנעול 1, ו-T2 מחזיק את מנעול 1 וממתין למנעול 0.\n3.  **אי-הפקעה (No Preemption):** משאבים (מנעולים) אינם ניתנים להפקעה בכוח מחוט שמחזיק בהם. חוט חייב לשחרר אותם מרצונו. זה מתקיים עם `std::mutex`.\n4.  **המתנה מעגלית (Circular Wait):** קיימת שרשרת של חוטים, שבה כל חוט ממתין למשאב שמוחזק על ידי החוט הבא בשרשרת, והחוט האחרון ממתין למשאב שמוחזק על ידי החוט הראשון. בדוגמה שלנו, T1 ממתין ל-T2, ו-T2 ממתין ל-T1, ויוצרים מעגל המתנה.\n\n### פתרון סעיף ב' - מניעת דדלוק\n\nכדי למנוע דדלוק, ניתן להטיל סדר גלובלי על רכישת המשאבים (המנעולים). במקרה זה, נגדיר כי יש לרכוש תמיד את המנעול של החשבון בעל המזהה הקטן יותר, ורק לאחר מכן את המנעול של החשבון בעל המזהה הגדול יותר. זה מבטל את תנאי ה'המתנה מעגלית'.\n\n**קוד `transfer` מתוקן:**\n```c++\nvoid transfer(int from_account_id, int to_account_id, double amount) {\n    std::this_thread::sleep_for(std::chrono::milliseconds(10));\n\n    // קביעת סדר נעילה עקבי על בסיס מזהי החשבונות\n    // תמיד ננעל קודם את המזהה הקטן יותר, ואז את הגדול יותר\n    std::mutex& lock1 = (from_account_id < to_account_id) ? account_locks[from_account_id] : account_locks[to_account_id];\n    std::mutex& lock2 = (from_account_id < to_account_id) ? account_locks[to_account_id] : account_locks[from_account_id];\n\n    int first_id = (from_account_id < to_account_id) ? from_account_id : to_account_id;\n    int second_id = (from_account_id < to_account_id) ? to_account_id : from_account_id;\n\n    std::cout << \"Thread \" << std::this_thread::get_id() << \": Trying to lock \" << first_id << \" then \" << second_id << std::endl;\n\n    // רכישת המנעולים בסדר קבוע\n    lock1.lock();\n    lock2.lock();\n\n    // לאחר הנעילה, נשמור על ההתייחסות המקורית לחשבונות המקור והיעד\n    double* actual_from_balance = &account_balances[from_account_id];\n    double* actual_to_balance = &account_balances[to_account_id];\n\n    // בדיקת יתרה מספקת וביצוע ההעברה\n    if (*actual_from_balance >= amount) {\n        *actual_from_balance -= amount;\n        *actual_to_balance += amount;\n        std::cout << \"Thread \" << std::this_thread::get_id() << \": Transferred \" << amount\n                  << \" from \" << from_account_id << \" to \" << to_account_id << std::endl;\n    } else {\n        std::cout << \"Thread \" << std::this_thread::get_id() << \": Insufficient balance in \"\n                  << from_account_id << \" to transfer \" << amount << std::endl;\n    }\n\n    // שחרור המנעולים בסדר הפוך לסדר הרכישה (פרקטיקה מומלצת)\n    lock2.unlock();\n    lock1.unlock();\n}\n```\n\n**הסבר מדוע השינוי מונע דדלוק:**\nהשינוי מבטל את תנאי ה'המתנה מעגלית' (Circular Wait). על ידי הטלת סדר גלובלי ועקבי לרכישת מנעולים (תמיד קודם המנעול של החשבון בעל המזהה הקטן יותר, ואז את המנעול של החשבון בעל המזהה הגדול יותר), אנו מבטיחים שלעולם לא תיווצר שרשרת המתנה מעגלית. אם חוט T1 מנסה להעביר מ-0 ל-1, וחוט T2 מנסה להעביר מ-1 ל-0, שניהם ינסו לרכוש קודם את המנעול של חשבון 0 (מכיוון ש-0 < 1). החוט שיצליח לתפוס את מנעול 0 ראשון, ימשיך לנסות לתפוס את מנעול 1. החוט השני ימתין למנעול 0. במצב זה, תמיד אחד החוטים יתקדם, ולא ייתכן מצב שבו כל חוט מחזיק במשאב שחוט אחר זקוק לו, ובו בזמן ממתין למשאב שמוחזק על ידי אותו חוט אחר, בסבב מעגלי."}, "difficulty_estimation": "Hard", "_source_file": "0407__Deadlocks__Open__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:21:43", "_subject": "Concurrency"}, {"id": 10, "type": "Open", "topic": ["Deadlocks", "Synchronization", "Concurrency", "Mutexes"], "content": {"text": "נתונה מערכת מרובת תהליכונים (multi-threaded system) הכוללת N תהליכוני עבודה (worker threads) ושני משאבים גלובליים נפרדים: `ResourceX` ו-`ResourceY`. כל אחד מהמשאבים מוגן על ידי מנעול הדדי (mutex) משלו. כל תהליכון במערכת נדרש לרכוש את שני המשאבים, `ResourceX` ו-`ResourceY`, על מנת לבצע משימה יחידה.\nאופן רכישת המשאבים מוגדר באופן הבא:\n*   תהליכונים בעלי מזהה זוגי (even ID) רוכשים תחילה את `ResourceX` ולאחר מכן את `ResourceY`.\n*   תהליכונים בעלי מזהה אי-זוגי (odd ID) רוכשים תחילה את `ResourceY` ולאחר מכן את `ResourceX`.\n\nלהלן קטע קוד המדגים את מבנה המערכת ואת לוגיקת הפעולה של תהליכון בודד:", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex_X;\npthread_mutex_t mutex_Y;\n\nvoid init_resources() {\n    pthread_mutex_init(&mutex_X, NULL);\n    pthread_mutex_init(&mutex_Y, NULL);\n}\n\nvoid destroy_resources() {\n    pthread_mutex_destroy(&mutex_X);\n    pthread_mutex_destroy(&mutex_Y);\n}\n\nvoid* worker_thread(void* arg) {\n    long thread_id = (long)arg;\n\n    if (thread_id % 2 == 0) { // Even ID: acquire X then Y\n        printf(\"Thread %ld: Trying to acquire ResourceX...\\n\", thread_id);\n        pthread_mutex_lock(&mutex_X);\n        printf(\"Thread %ld: Acquired ResourceX. Trying to acquire ResourceY...\\n\", thread_id);\n        // Simulate work or delay to increase deadlock probability\n        sleep(1);\n        pthread_mutex_lock(&mutex_Y);\n        printf(\"Thread %ld: Acquired ResourceY. Performing task...\\n\", thread_id);\n        // Task execution\n        sleep(2);\n        printf(\"Thread %ld: Releasing ResourceY...\\n\", thread_id);\n        pthread_mutex_unlock(&mutex_Y);\n        printf(\"Thread %ld: Releasing ResourceX...\\n\", thread_id);\n        pthread_mutex_unlock(&mutex_X);\n        printf(\"Thread %ld: Task completed.\\n\", thread_id);\n    } else { // Odd ID: acquire Y then X\n        printf(\"Thread %ld: Trying to acquire ResourceY...\\n\", thread_id);\n        pthread_mutex_lock(&mutex_Y);\n        printf(\"Thread %ld: Acquired ResourceY. Trying to acquire ResourceX...\\n\", thread_id);\n        // Simulate work or delay to increase deadlock probability\n        sleep(1);\n        pthread_mutex_lock(&mutex_X);\n        printf(\"Thread %ld: Acquired ResourceX. Performing task...\\n\", thread_id);\n        // Task execution\n        sleep(2);\n        printf(\"Thread %ld: Releasing ResourceX...\\n\", thread_id);\n        pthread_mutex_unlock(&mutex_X);\n        printf(\"Thread %ld: Releasing ResourceY...\\n\", thread_id);\n        pthread_mutex_unlock(&mutex_Y);\n        printf(\"Thread %ld: Task completed.\\n\", thread_id);\n    }\n    return NULL;\n}\n// פונקציית main ליצירת תהליכונים תהיה כאן, אך אינה נחוצה לשאלה", "options": null}, "sub_questions": [{"id": "a", "text": "האם תצורה זו של רכישת משאבים עלולה להוביל למצב של קיפאון (deadlock)? אם כן, הסבירו בפירוט מדוע, תוך התייחסות לארבעת התנאים ההכרחיים לקיפאון של Coffman (מניעה הדדית, החזק והמתן, אי-הפקעה, המתנה מעגלית).", "code_snippet": null, "options": null}, {"id": "b", "text": "הציעו פתרון קוד מתוקן, המונע קיפאון במערכת זו, תוך שמירה על רמת מקביליות סבירה. נמקו את הפתרון שלכם והסבירו כיצד הוא מונע את תנאי הקיפאון הספציפיים שהובילו לבעיה בסעיף הקודם.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "**סעיף א': ניתוח קיפאון**\nכן, תצורה זו של רכישת משאבים עלולה בהחלט להוביל למצב של קיפאון (deadlock). ננתח זאת באמצעות ארבעת התנאים ההכרחיים לקיפאון של Coffman:\n\n1.  **מניעה הדדית (Mutual Exclusion)**: תנאי זה מתקיים. כל אחד מהמשאבים, `ResourceX` ו-`ResourceY`, מוגן על ידי מנעול הדדי (mutex). פירוש הדבר הוא שרק תהליכון אחד יכול להחזיק במנעול של משאב נתון בכל רגע נתון.\n2.  **החזק והמתן (Hold and Wait)**: תנאי זה מתקיים. תהליכונים רוכשים מנעול אחד (למשל, `mutex_X` עבור תהליכון זוגי או `mutex_Y` עבור תהליכון אי-זוגי) ומחזיקים בו, תוך כדי שהם ממתינים למנעול השני שהם צריכים (למשל, `mutex_Y` עבור תהליכון זוגי או `mutex_X` עבור תהליכון אי-זוגי).\n3.  **אי-הפקעה (No Preemption)**: תנאי זה מתקיים. מנעולי `pthread_mutex_t` אינם ניתנים להפקעה. ברגע שתהליכון רוכש מנעול, הוא יחזיק בו עד שישחרר אותו מרצונו.\n4.  **המתנה מעגלית (Circular Wait)**: תנאי זה יכול להתקיים, והוא הגורם הישיר לקיפאון בתצורה זו.\n    *   דמיינו תהליכון זוגי (לדוגמה, `thread_id = 0`) רוכש את `mutex_X`.\n    *   באותו זמן, דמיינו תהליכון אי-זוגי (לדוגמה, `thread_id = 1`) רוכש את `mutex_Y`.\n    *   כעת, `thread_id = 0` מחזיק ב-`mutex_X` ומנסה לרכוש את `mutex_Y` (שמוחזק על ידי `thread_id = 1`).\n    *   במקביל, `thread_id = 1` מחזיק ב-`mutex_Y` ומנסה לרכוש את `mutex_X` (שמוחזק על ידי `thread_id = 0`).\n    *   נוצר מעגל המתנה: `thread_id = 0` ממתין ל-`mutex_Y` שמוחזק על ידי `thread_id = 1`, ו-`thread_id = 1` ממתין ל-`mutex_X` שמוחזק על ידי `thread_id = 0`. שני התהליכונים חסומים זה על ידי זה, והמערכת נכנסת לקיפאון.\n\n**סעיף ב': פתרון למניעת קיפאון**\nהדרך היעילה ביותר למנוע קיפאון במקרה זה היא לשבור את תנאי \"המתנה מעגלית\" על ידי אכיפת סדר עקבי (כלל גלובלי) לרכישת משאבים עבור כל התהליכונים. במקום לאפשר סדרי רכישה שונים, כל התהליכונים ירכשו את המשאבים באותו סדר קבוע.\n\n**קוד מתוקן:**\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex_X;\npthread_mutex_t mutex_Y;\n\nvoid init_resources() {\n    pthread_mutex_init(&mutex_X, NULL);\n    pthread_mutex_init(&mutex_Y, NULL);\n}\n\nvoid destroy_resources() {\n    pthread_mutex_destroy(&mutex_X);\n    pthread_mutex_destroy(&mutex_Y);\n}\n\nvoid* worker_thread_fixed(void* arg) {\n    long thread_id = (long)arg;\n\n    // אכיפת סדר רכישה עקבי לכל התהליכונים: תמיד X ואז Y\n    printf(\"Thread %ld: Trying to acquire ResourceX...\\n\", thread_id);\n    pthread_mutex_lock(&mutex_X);\n    printf(\"Thread %ld: Acquired ResourceX. Trying to acquire ResourceY...\\n\", thread_id);\n    // מדמה עבודה או עיכוב להגברת סבירות לבעיה (כעת למטרת הדגמה בלבד)\n    sleep(1);\n    pthread_mutex_lock(&mutex_Y);\n    printf(\"Thread %ld: Acquired ResourceY. Performing task...\\n\", thread_id);\n    // ביצוע המשימה\n    sleep(2);\n    printf(\"Thread %ld: Releasing ResourceY...\\n\", thread_id);\n    pthread_mutex_unlock(&mutex_Y);\n    printf(\"Thread %ld: Releasing ResourceX...\\n\", thread_id);\n    pthread_mutex_unlock(&mutex_X);\n    printf(\"Thread %ld: Task completed.\\n\", thread_id);\n\n    return NULL;\n}\n// פונקציית main ליצירת תהליכונים תהיה כאן, אך אינה נחוצה לשאלה\n```\n\n**הסבר לפתרון:**\nהפתרון המתוקן אוכף סדר רכישה גלובלי: כל התהליכונים, ללא קשר למזהה שלהם, ינסו לרכוש תחילה את `mutex_X` ולאחר מכן את `mutex_Y`. \nפעולה זו מונעת את תנאי ה\"המתנה מעגלית\". כעת, לא ייתכן מצב שבו תהליכון אחד מחזיק ב-`mutex_X` וממתין ל-`mutex_Y`, בעוד שתהליכון אחר מחזיק ב-`mutex_Y` וממתין ל-`mutex_X`. כל התהליכונים מחכים לאותו משאב ראשון (`mutex_X`), ורק לאחר קבלתו ממשיכים למשאב השני (`mutex_Y`).\nהדבר מבטיח שאם `mutex_X` מוחזק, כל מי שרוצה אותו ימתין לו. אם `mutex_X` פנוי, תהליכון ירכוש אותו, ואז ינסה לרכוש את `mutex_Y`. אם `mutex_Y` תפוס, הוא יחכה, אבל הוא לא יחזיק ב-`mutex_Y` וימתין ל-`mutex_X`, ובכך נשבר המעגל.\nפתרון זה שומר על רמת מקביליות סבירה מכיוון שתהליכונים עדיין יכולים לבצע את משימותיהם במקביל, כל עוד הם לא מתחרים על אותם מנעולים באותו רגע, או אם המנעולים משוחררים במהירות. למרות שיש סדר רכישה מחמיר, עדיין יתכן שתהליכון אחד יחזיק בשני המנעולים ויבצע את משימתו, בזמן שתהליכונים אחרים ממתינים בתור מסודר."}, "difficulty_estimation": "Hard", "_source_file": "0408__Deadlocks__Open__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:47:48", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Deadlocks", "Concurrency", "Mutexes"], "content": {"text": "נתון קטע קוד בשפת C המשתמש בספריות ת'רדים ומנעולים (pthread). שני חוטים (thread_A ו-thread_B) מנסים לגשת למשאבים המוגנים על ידי מנעולים (mutex_X ו-mutex_Y). עיין בקוד המצורף וענה על השאלה הבאה:\n\nהאם קטע קוד זה יכול להוביל למצב של קיפאון (deadlock)? אם כן, הסבר מדוע וכיצד ניתן למנוע אותו. אם לא, הסבר מדוע.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex_X;\npthread_mutex_t mutex_Y;\n\nvoid* thread_A_func(void* arg) {\n    printf(\"Thread A: Attempting to lock mutex_X...\\n\");\n    pthread_mutex_lock(&mutex_X);\n    printf(\"Thread A: Locked mutex_X. Sleeping...\\n\");\n    sleep(1); // Simulate work or delay\n\n    printf(\"Thread A: Attempting to lock mutex_Y...\\n\");\n    pthread_mutex_lock(&mutex_Y);\n    printf(\"Thread A: Locked mutex_Y. Critical section A...\\n\");\n\n    // Critical section A\n    printf(\"Thread A: Releasing mutex_Y...\\n\");\n    pthread_mutex_unlock(&mutex_Y);\n    printf(\"Thread A: Releasing mutex_X...\\n\");\n    pthread_mutex_unlock(&mutex_X);\n    printf(\"Thread A: Exiting.\\n\");\n    return NULL;\n}\n\nvoid* thread_B_func(void* arg) {\n    printf(\"Thread B: Attempting to lock mutex_Y...\\n\");\n    pthread_mutex_lock(&mutex_Y);\n    printf(\"Thread B: Locked mutex_Y. Sleeping...\\n\");\n    sleep(1); // Simulate work or delay\n\n    printf(\"Thread B: Attempting to lock mutex_X...\\n\");\n    pthread_mutex_lock(&mutex_X);\n    printf(\"Thread B: Locked mutex_X. Critical section B...\\n\");\n\n    // Critical section B\n    printf(\"Thread B: Releasing mutex_X...\\n\");\n    pthread_mutex_unlock(&mutex_X);\n    printf(\"Thread B: Releasing mutex_Y...\\n\");\n    pthread_mutex_unlock(&mutex_Y);\n    printf(\"Thread B: Exiting.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t thread_A, thread_B;\n\n    pthread_mutex_init(&mutex_X, NULL);\n    pthread_mutex_init(&mutex_Y, NULL);\n\n    pthread_create(&thread_A, NULL, thread_A_func, NULL);\n    pthread_create(&thread_B, NULL, thread_B_func, NULL);\n\n    pthread_join(thread_A, NULL);\n    pthread_join(thread_B, NULL);\n\n    pthread_mutex_destroy(&mutex_X);\n    pthread_mutex_destroy(&mutex_Y);\n\n    printf(\"Main: Program finished.\\n\");\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, קטע קוד זה יכול להוביל למצב של קיפאון (deadlock). קיפאון הוא מצב שבו שני חוטים או יותר ממתינים זה לזה באופן בלתי הפיך למשאבים שהם צריכים כדי להמשיך.\n\nבמקרה זה, התנאים לקיפאון מתקיימים:\n1.  **מניעה הדדית (Mutual Exclusion)**: המנעולים (mutex_X, mutex_Y) מבטיחים שרק חוט אחד יכול להחזיק במשאב (המנעול) בכל רגע נתון.\n2.  **החזקה והמתנה (Hold and Wait)**: חוט A מחזיק במנעול X וממתין למנעול Y. במקביל, חוט B מחזיק במנעול Y וממתין למנעול X.\n3.  **אין שחרור מוקדם (No Preemption)**: אף חוט לא יכול לקחת בכוח מנעול מחוט אחר. המנעולים משוחררים רק על ידי החוט שתפס אותם.\n4.  **המתנה מעגלית (Circular Wait)**: קיים מעגל המתנה: חוט A ממתין למנעול Y שמוחזק על ידי חוט B, וחוט B ממתין למנעול X שמוחזק על ידי חוט A.\n\n**תרחיש לדוגמה לקיפאון:**\n1.  חוט A נועל את `mutex_X`.\n2.  חוט B נועל את `mutex_Y`.\n3.  חוט A מנסה לנעול את `mutex_Y` אך הוא תפוס על ידי חוט B, ולכן חוט A נחסם וממתין.\n4.  חוט B מנסה לנעול את `mutex_X` אך הוא תפוס על ידי חוט A, ולכן חוט B נחסם וממתין.\nבמצב זה, שני החוטים חסומים באופן הדדי, וכל אחד מהם מחזיק במשאב שהשני זקוק לו, וכך נוצר קיפאון.\n\n**מניעת קיפאון:**\nהדרך הנפוצה ביותר למנוע קיפאון במקרה זה היא על ידי אכיפת סדר קבוע ללקיחת המנעולים. אם כל החוטים ינסו לתפוס את המנעולים באותו סדר (לדוגמה, תמיד קודם `mutex_X` ואז `mutex_Y`), אזי תנאי ההמתנה המעגלית לא יכול להתקיים.\n\n**תיקון הקוד:**\nיש לשנות את הפונקציה `thread_B_func` כך שתנסה לנעול את `mutex_X` לפני `mutex_Y`, בדיוק כמו `thread_A_func`.\n\n**קוד מתוקן לדוגמה עבור `thread_B_func`:**\n```c\nvoid* thread_B_func(void* arg) {\n    printf(\"Thread B: Attempting to lock mutex_X...\\n\");\n    pthread_mutex_lock(&mutex_X); // סדר המנעולים שונה\n    printf(\"Thread B: Locked mutex_X. Sleeping...\\n\");\n    sleep(1);\n\n    printf(\"Thread B: Attempting to lock mutex_Y...\\n\");\n    pthread_mutex_lock(&mutex_Y); // סדר המנעולים שונה\n    printf(\"Thread B: Locked mutex_Y. Critical section B...\\n\");\n\n    printf(\"Thread B: Releasing mutex_Y...\\n\");\n    pthread_mutex_unlock(&mutex_Y);\n    printf(\"Thread B: Releasing mutex_X...\\n\");\n    pthread_mutex_unlock(&mutex_X);\n    printf(\"Thread B: Exiting.\\n\");\n    return NULL;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0409__Deadlocks__CodeAnalysis__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:22:34", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Concurrency"], "content": {"text": "נתון קטע הקוד הבא המשתמש בשני מנעולים (mutexes) ושני תהליכונים (threads). עיין בקוד וענה על השאלה הבאה:\n\nהאם קטע קוד זה עלול להוביל למצב של קיפאון (deadlock)? אם כן, הסבר מהם התנאים שיובילו לקיפאון וכיצד ניתן למנוע אותו.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutexA;\npthread_mutex_t mutexB;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to acquire mutexA...\\n\");\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 1: Acquired mutexA. Trying to acquire mutexB...\\n\");\n    sleep(1); // Simulate some work or context switch\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 1: Acquired mutexB. Critical section.\\n\");\n    // ... critical section ...\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 1: Released mutexes.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to acquire mutexB...\\n\");\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 2: Acquired mutexB. Trying to acquire mutexA...\\n\");\n    sleep(1); // Simulate some work or context switch\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 2: Acquired mutexA. Critical section.\\n\");\n    // ... critical section ...\n    pthread_mutex_unlock(&mutexA);\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 2: Released mutexes.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&mutexA, NULL);\n    pthread_mutex_init(&mutexB, NULL);\n\n    pthread_create(&tid1, NULL, thread_func1, NULL);\n    pthread_create(&tid2, NULL, thread_func2, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    pthread_mutex_destroy(&mutexA);\n    pthread_mutex_destroy(&mutexB);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, קטע הקוד הזה עלול להוביל למצב של קיפאון (deadlock).\n\n**הסבר:**\nקיפאון יכול להתרחש כאשר שני התהליכונים (threads) מנסים לרכוש את המנעולים בסדר הפוך. נניח את התרחיש הבא:\n1.  תהליכון 1 רוכש בהצלחה את `mutexA`.\n2.  מתרחש מעבר הקשר (context switch) לתהליכון 2.\n3.  תהליכון 2 רוכש בהצלחה את `mutexB`.\n4.  תהליכון 2 מנסה לרכוש את `mutexA`, אך הוא נעול על ידי תהליכון 1, ולכן תהליכון 2 נחסם וממתין.\n5.  מתרחש מעבר הקשר בחזרה לתהליכון 1.\n6.  תהליכון 1 מנסה לרכוש את `mutexB`, אך הוא נעול על ידי תהליכון 2, ולכן תהליכון 1 נחסם וממתין.\nבשלב זה, תהליכון 1 ממתין למנעול שמוחזק על ידי תהליכון 2, ותהליכון 2 ממתין למנעול שמוחזק על ידי תהליכון 1. נוצר מעגל המתנה (circular wait) שמוביל לקיפאון. תנאים נוספים לקיפאון המתקיימים כאן הם: מניעה הדדית (mutual exclusion) – כל מנעול יכול להיות מוחזק ע\"י תהליכון אחד בלבד; החזקה והמתנה (hold and wait) – תהליכון מחזיק במשאב אחד וממתין למשאב אחר; וחוסר עקיפה (no preemption) – לא ניתן לקחת מנעול מתהליכון שמחזיק בו בכוח.\n\n**מניעה:**\nהדרך הנפוצה והפשוטה ביותר למנוע קיפאון במקרה זה היא לוודא שכל התהליכונים רוכשים את המנעולים באותו סדר קבוע. לדוגמה, אם שני התהליכונים ירכשו תמיד קודם את `mutexA` ואז את `mutexB`, לא ייווצר מעגל המתנה. הנה דוגמה לשינוי בקוד עבור `thread_func2` כדי למנוע קיפאון:\n\n```c\nvoid* thread_func2_fixed(void* arg) {\n    printf(\"Thread 2: Trying to acquire mutexA...\\n\");\n    pthread_mutex_lock(&mutexA); // Acquire A first\n    printf(\"Thread 2: Acquired mutexA. Trying to acquire mutexB...\\n\");\n    sleep(1);\n    pthread_mutex_lock(&mutexB); // Then B\n    printf(\"Thread 2: Acquired mutexB. Critical section.\\n\");\n    // ... critical section ...\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 2: Released mutexes.\\n\");\n    return NULL;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0410__Deadlocks__CodeAnalysis__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:22:50", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Concurrency", "Mutexes"], "content": {"text": "נתון קוד C הבא המשתמש בספריות `pthread` לניהול תהליכונים ומנעולים. קראו את הקוד וענו על השאלה:\n\nהאם קיפאון (Deadlock) יכול להתרחש בריצת קוד זה? אם כן, הסבירו מדוע וציינו את ארבעת התנאים לקיפאון המתקיימים בקוד. אם לא, הסבירו מדוע.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex1;\npthread_mutex_t mutex2;\n\nvoid* thread_func1(void* arg) {\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 1 acquired mutex1\\n\");\n    sleep(1); // Simulate work\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 1 acquired mutex2\\n\");\n    printf(\"Thread 1 doing work with both mutexes\\n\");\n    pthread_mutex_unlock(&mutex2);\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 1 released both mutexes\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2 acquired mutex2\\n\");\n    sleep(1); // Simulate work\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2 acquired mutex1\\n\");\n    printf(\"Thread 2 doing work with both mutexes\\n\");\n    pthread_mutex_unlock(&mutex1);\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2 released both mutexes\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n\n    pthread_mutex_init(&mutex1, NULL);\n    pthread_mutex_init(&mutex2, NULL);\n\n    pthread_create(&t1, NULL, thread_func1, NULL);\n    pthread_create(&t2, NULL, thread_func2, NULL);\n\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "כן, קיפאון (Deadlock) יכול להתרחש בקוד זה.\n\n**הסבר:**\nהקיפאון יתרחש כאשר התהליכון הראשון (Thread 1) יתפוס את `mutex1` והתהליכון השני (Thread 2) יתפוס את `mutex2`. לאחר מכן, Thread 1 ינסה לתפוס את `mutex2` (שכבר תפוס על ידי Thread 2) ו-Thread 2 ינסה לתפוס את `mutex1` (שכבר תפוס על ידי Thread 1). במצב זה, שני התהליכונים ימתינו זה לזה באופן אינסופי, מה שיוביל לקיפאון.\n\n**ארבעת התנאים לקיפאון המתקיימים בקוד הם:**\n1.  **מניעה הדדית (Mutual Exclusion)**: המנעולים `mutex1` ו-`mutex2` הם משאבים בלעדיים. רק חוט אחד יכול לתפוס כל מנעול בכל רגע נתון. אם חוט אחד תופס מנעול, חוט אחר המנסה לתפוס אותו ייחסם.\n2.  **החזקה והמתנה (Hold and Wait)**: כל חוט (למשל, Thread 1) תופס מנעול אחד (לדוגמה, `mutex1`) וממתין לתפוס מנעול נוסף (במקרה זה, `mutex2`) שמוחזק על ידי חוט אחר, מבלי לשחרר את המנעול שכבר ברשותו.\n3.  **אי-נתיקה (No Preemption)**: לא ניתן לקחת מנעול מחוט שתפס אותו בכוח. חוט חייב לשחרר את המנעול מרצונו לאחר שסיים להשתמש בו.\n4.  **המתנה מעגלית (Circular Wait)**: קיים מעגל המתנה. Thread 1 ממתין ל-Thread 2 שישחרר את `mutex2`, ובמקביל, Thread 2 ממתין ל-Thread 1 שישחרר את `mutex1`. מעגל זה יוצר תלות הדדית שאינה ניתנת לשבירה ללא התערבות חיצונית.\n\n**פתרון למניעת קיפאון (לא נדרש בשאלה אך רלוונטי):**\nכדי למנוע קיפאון במקרה זה, ניתן לוודא שכל התהליכונים תופסים את המנעולים באותו סדר עקבי (לדוגמה, תמיד קודם `mutex1` ואז `mutex2`)."}, "difficulty_estimation": "Easy", "_source_file": "0411__Deadlocks__CodeAnalysis__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:23:04", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Deadlocks", "Concurrency", "Synchronization", "Mutexes"], "content": {"text": "נתון קטע קוד בשפת C המשתמש בשני חוטים (threads) ובשני מנעולים (mutexes). עיין בקוד המצורף וענה על השאלה הבאה:\n\nהאם הקוד הנתון עלול לגרום למצב של קיפאון (Deadlock)? נמק את תשובתך. אם כן, הסבר אילו תנאים לקיפאון מתקיימים, והצע דרך פשוטה למנוע אותו.", "code_snippet": " #include <pthread.h>\n #include <stdio.h>\n #include <unistd.h>\n\n pthread_mutex_t mutex1;\n pthread_mutex_t mutex2;\n\n void* thread_func1(void* arg) {\n     pthread_mutex_lock(&mutex1);\n     sleep(1); // להגברת הסיכוי לקיפאון\n     pthread_mutex_lock(&mutex2);\n     printf(\"Thread 1: In critical section.\\n\");\n     pthread_mutex_unlock(&mutex2);\n     pthread_mutex_unlock(&mutex1);\n     return NULL;\n }\n\n void* thread_func2(void* arg) {\n     pthread_mutex_lock(&mutex2);\n     sleep(1); // להגברת הסיכוי לקיפאון\n     pthread_mutex_lock(&mutex1);\n     printf(\"Thread 2: In critical section.\\n\");\n     pthread_mutex_unlock(&mutex1);\n     pthread_mutex_unlock(&mutex2);\n     return NULL;\n }\n // (פונקציית main מאתחלת את המנעולים ויוצרת את החוטים t1 ו-t2 המריצים את thread_func1 ו-thread_func2 בהתאמה)", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, הקוד הנתון אכן עלול לגרום למצב של קיפאון (Deadlock).\n\n**נימוק - תנאי הקיפאון המתקיימים:**\nקיפאון מתרחש כאשר מתקיימים בו-זמנית ארבעה תנאים:\n1.  **מניעה הדדית (Mutual Exclusion):** תנאי זה מתקיים. המנעולים (`mutex1`, `mutex2`) הם משאבים שאינם ניתנים לשיתוף, ורק חוט אחד יכול להחזיק במנעול נתון בכל רגע. אם חוט אחד תופס מנעול, חוט אחר לא יכול לתפוס אותו עד שהראשון ישחרר אותו.\n2.  **החזקה והמתנה (Hold and Wait):** תנאי זה מתקיים. כל אחד מהחוטים תופס מנעול אחד (חוט 1 תופס את `mutex1`, וחוט 2 תופס את `mutex2`) ולאחר מכן ממתין למנעול השני כדי להמשיך בביצוע הקטע הקריטי.\n3.  **אי-נטילה (No Preemption):** תנאי זה מתקיים. המנעולים אינם ניתנים לנטילה בכוח מחוט שמחזיק בהם. חוט חייב לשחרר את המנעול באופן יזום.\n4.  **המתנה מעגלית (Circular Wait):** תנאי זה מתקיים. נוצרת שרשרת מעגלית של חוטים הממתינים למשאבים המוחזקים על ידי חוטים אחרים בשרשרת. במקרה זה, חוט 1 מחזיק את `mutex1` וממתין ל-`mutex2` (המוחזק על ידי חוט 2), בעוד שחוט 2 מחזיק את `mutex2` וממתין ל-`mutex1` (המוחזק על ידי חוט 1).\n\n**הסבר:** אם חוט 1 מצליח לתפוס את `mutex1` וחוט 2 מצליח לתפוס את `mutex2` בערך באותו זמן (לפני שכל אחד מהם מנסה לתפוס את המנעול השני), אז כל אחד מהם יחזיק במנעול אחד וימתין למנעול השני המוחזק על ידי יריבו, וכך יווצר קיפאון.\n\n**דרך פשוטה למנוע קיפאון:**\nהדרך הפשוטה ביותר למנוע קיפאון במקרה זה היא להבטיח שכל החוטים יתפסו את המנעולים באותו סדר עקבי. לדוגמה, שניהם יתפסו תמיד קודם את `mutex1` ואז את `mutex2`:\n\n```c\n// עבור thread_func1 וגם עבור thread_func2\nvoid* thread_func_fixed(void* arg) {\n    pthread_mutex_lock(&mutex1);\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread: In critical section (fixed order).\\n\");\n    pthread_mutex_unlock(&mutex2);\n    pthread_mutex_unlock(&mutex1);\n    return NULL;\n}\n```\nעל ידי שמירה על סדר קבוע, נמנע את תנאי ההמתנה המעגלית."}, "difficulty_estimation": "Easy", "_source_file": "0412__Deadlocks__CodeAnalysis__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:23:26", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Concurrency"], "content": {"text": "נתון קטע הקוד הבא המשתמש בשני מנעולים (mutexes) ובשני חוטים (threads). האם יכול להתרחש קיפאון (deadlock) בקוד זה? אם כן, הסבירו מדוע, וכיצד ניתן למנוע אותו על ידי שינוי מינימלי בקוד.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutexA;\npthread_mutex_t mutexB;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to acquire mutexA...\\n\");\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 1: Acquired mutexA. Waiting a bit...\\n\");\n    sleep(1); // Simulate work or context switch\n    printf(\"Thread 1: Trying to acquire mutexB...\\n\");\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 1: Acquired mutexB. Doing work...\\n\");\n    // Critical section\n    printf(\"Thread 1: Releasing mutexB...\\n\");\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 1: Releasing mutexA...\\n\");\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 1: Finished.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to acquire mutexB...\\n\");\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 2: Acquired mutexB. Waiting a bit...\\n\");\n    sleep(1); // Simulate work or context switch\n    printf(\"Thread 2: Trying to acquire mutexA...\\n\");\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 2: Acquired mutexA. Doing work...\\n\");\n    // Critical section\n    printf(\"Thread 2: Releasing mutexA...\\n\");\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 2: Releasing mutexB...\\n\");\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 2: Finished.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&mutexA, NULL);\n    pthread_mutex_init(&mutexB, NULL);\n\n    pthread_create(&tid1, NULL, thread_func1, NULL);\n    pthread_create(&tid2, NULL, thread_func2, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    pthread_mutex_destroy(&mutexA);\n    pthread_mutex_destroy(&mutexB);\n\n    printf(\"Main: All threads finished.\\n\");\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "כן, קיפאון (deadlock) יכול להתרחש בקטע קוד זה.\n\n**מדוע קיפאון יכול להתרחש:**\nהקיפאון מתרחש עקב תנאי 'המתנה מעגלית' (Circular Wait) בשילוב עם שלושת התנאים הנוספים לקיפאון:\n1.  **מניעה הדדית (Mutual Exclusion):** המנעולים (mutexA ו-mutexB) מבטיחים שרק חוט אחד יכול להחזיק בהם בכל רגע נתון.\n2.  **החזקה והמתנה (Hold and Wait):**\n    *   חוט 1 תופס את `mutexA` ולאחר מכן מנסה לתפוס את `mutexB`. אם `mutexB` מוחזק על ידי חוט 2, חוט 1 ימתין תוך כדי שהוא מחזיק ב-`mutexA`.\n    *   חוט 2 תופס את `mutexB` ולאחר מכן מנסה לתפוס את `mutexA`. אם `mutexA` מוחזק על ידי חוט 1, חוט 2 ימתין תוך כדי שהוא מחזיק ב-`mutexB`.\n3.  **אי-הפקעה (No Preemption):** חוט אינו יכול להפקיע מנעול מחוט אחר; המנעול ישוחרר רק על ידי החוט שתפס אותו.\n4.  **המתנה מעגלית (Circular Wait):** זהו התנאי המרכזי שגורם לקיפאון במקרה זה. חוט 1 ממתין למשאב (`mutexB`) שמוחזק על ידי חוט 2, בעוד חוט 2 ממתין למשאב (`mutexA`) שמוחזק על ידי חוט 1. נוצר מעגל המתנה שבו אף חוט אינו יכול להתקדם.\n\n**כיצד ניתן למנוע קיפאון:**\nהדרך הנפוצה והפשוטה ביותר למנוע קיפאון במקרה זה היא על ידי אכיפת סדר עקבי וקבוע לרכישת המשאבים (המנעולים). אם כל החוטים ינסו לתפוס את המנעולים באותו סדר, תנאי ההמתנה המעגלית יישבר.\n\n**שינוי קוד מינימלי:**\nיש לשנות את הפונקציה `thread_func2` כך שתתפוס את `mutexA` לפני `mutexB`, בדומה ל-`thread_func1`.\n\n```c\n// ... (שאר הקוד נשאר כפי שהוא)\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to acquire mutexA...\\n\"); // שינוי כאן: תופס קודם את mutexA\n    pthread_mutex_lock(&mutexA);                        // שינוי כאן\n    printf(\"Thread 2: Acquired mutexA. Waiting a bit...\\n\");\n    sleep(1);\n    printf(\"Thread 2: Trying to acquire mutexB...\\n\");\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 2: Acquired mutexB. Doing work...\\n\");\n    // Critical section\n    printf(\"Thread 2: Releasing mutexB...\\n\");\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 2: Releasing mutexA...\\n\");          // שינוי כאן: משחרר את mutexA לבסוף\n    pthread_mutex_unlock(&mutexA);                      // שינוי כאן\n    printf(\"Thread 2: Finished.\\n\");\n    return NULL;\n}\n\n// ... (שאר הקוד נשאר כפי שהוא)\n```"}, "difficulty_estimation": "Easy", "_source_file": "0413__Deadlocks__CodeAnalysis__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:23:45", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Deadlocks", "Concurrency", "Synchronization"], "content": {"text": "נתון קוד C הבא המשתמש בשני מנעולים (mutexes) ובשני תהליכונים (threads). קראו את הקוד בעיון. האם קוד זה עלול להוביל למצב של קיפאון (deadlock)? אם כן, הסבירו מדוע וכיצד ניתן למנוע זאת.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex1;\npthread_mutex_t mutex2;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 1: Locked mutex1. Trying to lock mutex2...\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 1: Locked mutex2. Critical section...\\n\");\n    // Do some work\n    pthread_mutex_unlock(&mutex2);\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 1: Unlocked mutexes.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to lock mutex2...\\n\");\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2: Locked mutex2. Trying to lock mutex1...\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2: Locked mutex1. Critical section...\\n\");\n    // Do some work\n    pthread_mutex_unlock(&mutex1);\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2: Unlocked mutexes.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_mutex_init(&mutex1, NULL);\n    pthread_mutex_init(&mutex2, NULL);\n\n    pthread_t t1, t2;\n    pthread_create(&t1, NULL, thread_func1, NULL);\n    pthread_create(&t2, NULL, thread_func2, NULL);\n\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "כן, קוד זה עלול להוביל למצב של קיפאון (deadlock).\n\n**הסבר:** קיפאון יכול להתרחש בתרחיש הבא:\n1.  Thread 1 תופס בהצלחה את `mutex1`.\n2.  במקביל, Thread 2 תופס בהצלחה את `mutex2`.\n3.  לאחר מכן, Thread 1 מנסה לתפוס את `mutex2`, אך הוא כבר תפוס על ידי Thread 2. לכן, Thread 1 נחסם וממתין ש-Thread 2 ישחרר את `mutex2`.\n4.  באותו זמן, Thread 2 מנסה לתפוס את `mutex1`, אך הוא כבר תפוס על ידי Thread 1. לכן, Thread 2 נחסם וממתין ש-Thread 1 ישחרר את `mutex1`.\n\nכתוצאה מכך, שני התהליכונים ממתינים זה לזה באופן הדדי ואינסופי, וזהו מצב של קיפאון (Circular Wait).\n\n**מניעה:** הדרך הנפוצה והפשוטה ביותר למנוע קיפאון במקרה זה היא להבטיח סדר עקבי של תפיסת מנעולים (consistent locking order) בכל התהליכונים. כלומר, שכל התהליכונים ינסו לתפוס את המנעולים באותו סדר. לדוגמה, שניהם יתפסו קודם את `mutex1` ואז את `mutex2`.\n\n**דוגמה לתיקון (שמירה על סדר `mutex1` ואז `mutex2`):**\n```c\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 1: Locked mutex1. Trying to lock mutex2...\\n\");\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 1: Locked mutex2. Critical section...\\n\");\n    pthread_mutex_unlock(&mutex2);\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 1: Unlocked mutexes.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to lock mutex1...\\n\"); // Changed order\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2: Locked mutex1. Trying to lock mutex2...\\n\"); // Changed order\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2: Locked mutex2. Critical section...\\n\");\n    pthread_mutex_unlock(&mutex2); // Unlocked in correct order\n    pthread_mutex_unlock(&mutex1); // Unlocked in correct order\n    printf(\"Thread 2: Unlocked mutexes.\\n\");\n    return NULL;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0414__Deadlocks__CodeAnalysis__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:24:00", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Concurrency", "Mutexes"], "content": {"text": "השאלה עוסקת בקיפאון (Deadlock). נתון קטע הקוד הבא המשתמש בשני מנעולים (mutexes) ושני תהליכונים (threads).\n\nאנא נתח את הקוד וענה על השאלה הבאה: האם קיפאון יכול להתרחש בקטע קוד זה? אם כן, הסבר מדוע וכיצד הוא מתרחש. אם לא, הסבר מדוע לא.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex1;\npthread_mutex_t mutex2;\n\nvoid* thread_func1(void* arg) {\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 1 acquired mutex1\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 1 acquired mutex2\\n\");\n    \n    // Critical section\n    \n    pthread_mutex_unlock(&mutex2);\n    pthread_mutex_unlock(&mutex1);\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2 acquired mutex2\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2 acquired mutex1\\n\");\n    \n    // Critical section\n    \n    pthread_mutex_unlock(&mutex1);\n    pthread_mutex_unlock(&mutex2);\n    return NULL;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, קיפאון (Deadlock) יכול להתרחש בקטע קוד זה.\n\n**הסבר:**\nקיפאון מתרחש כאשר קבוצה של תהליכים או תהליכונים חוסמת זה את זה, כך שכל אחד ממתין למשאב המוחזק על ידי אחר בקבוצה. ארבעת התנאים ההכרחיים לקיפאון הם:\n1.  **מניעה הדדית (Mutual Exclusion)**: משאבים (כמו מנעולים) ניתנים לשימוש על ידי תהליך אחד בלבד בכל רגע נתון. במקרה זה, `mutex1` ו-`mutex2` מספקים מניעה הדדית.\n2.  **החזקה והמתנה (Hold and Wait)**: תהליך מחזיק במשאב אחד לפחות וממתין למשאב נוסף המוחזק על ידי תהליך אחר. בקוד הנתון, `thread_func1` מחזיק ב-`mutex1` וממתין ל-`mutex2`, בעוד ש-`thread_func2` מחזיק ב-`mutex2` וממתין ל-`mutex1`.\n3.  **אי-הפקעה (No Preemption)**: משאבים אינם ניתנים להפקעה מתהליך שמחזיק בהם; הם משוחררים רק מרצון על ידי התהליך המחזיק בהם. המנעולים בקוד פועלים באופן זה.\n4.  **המתנה מעגלית (Circular Wait)**: קיימת שרשרת סגורה של תהליכים, כאשר כל תהליך בשרשרת ממתין למשאב המוחזק על ידי התהליך הבא בשרשרת. זהו התנאי העיקרי שמוביל לקיפאון כאן.\n\n**תרחיש קיפאון ספציפי:**\nנניח ששני התהליכונים מתחילים לרוץ בו-זמנית:\n1.  `thread_func1` מבצע `pthread_mutex_lock(&mutex1)` בהצלחה, תופס את `mutex1`.\n2.  מיד לאחר מכן (או במקביל), `thread_func2` מבצע `pthread_mutex_lock(&mutex2)` בהצלחה, תופס את `mutex2`.\n3.  כעת, `thread_func1` מחזיק ב-`mutex1` ומגיע לשורה `pthread_mutex_lock(&mutex2)`. מכיוון ש-`mutex2` מוחזק על ידי `thread_func2`, `thread_func1` נכנס למצב המתנה.\n4.  באותו זמן, `thread_func2` מחזיק ב-`mutex2` ומגיע לשורה `pthread_mutex_lock(&mutex1)`. מכיוון ש-`mutex1` מוחזק על ידי `thread_func1`, `thread_func2` נכנס למצב המתנה.\n\nבנקודה זו, `thread_func1` ממתין ל-`mutex2` שמוחזק על ידי `thread_func2`, ו-`thread_func2` ממתין ל-`mutex1` שמוחזק על ידי `thread_func1`. נוצרה המתנה מעגלית, ושני התהליכונים חסומים זה על ידי זה, מה שמוביל לקיפאון. קריאות ה-`sleep(1)` מגבירות את הסבירות שאכן יתרחש מצב כזה על ידי יצירת חלון זמן שבו שני המנעולים יכולים להיתפס על ידי תהליכונים שונים לפני שהם מנסים לתפוס את המנעול השני."}, "difficulty_estimation": "Easy", "_source_file": "0415__Deadlocks__CodeAnalysis__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:24:18", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Concurrency", "Mutexes"], "content": {"text": "נתון קוד C המשתמש בספריות `pthread` ליצירת שני תהליכונים (threads) ושני מנעולים (mutexes). כל תהליכון מנסה לרכוש את שני המנעולים בסדר מסוים. נתחו את הקוד הבא וענו על השאלה:\n\nהאם קיים סיכון לקיפאון (deadlock) בקוד זה? אם כן, הסבירו מדוע וכיצד ניתן למנוע אותו. אם לא, הסבירו מדוע.", "code_snippet": "```c\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutexA;\npthread_mutex_t mutexB;\n\nvoid* thread1_func(void* arg) {\n    printf(\"Thread 1: Trying to lock mutexA...\\n\");\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 1: Locked mutexA. Trying to lock mutexB...\\n\");\n    sleep(1); // Simulate some work or context switch\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 1: Locked mutexB. Doing work...\\n\");\n    // Critical section\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 1: Unlocked mutexA and mutexB. Exiting.\\n\");\n    return NULL;\n}\n\nvoid* thread2_func(void* arg) {\n    printf(\"Thread 2: Trying to lock mutexB...\\n\");\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 2: Locked mutexB. Trying to lock mutexA...\\n\");\n    sleep(1); // Simulate some work or context switch\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 2: Locked mutexA. Doing work...\\n\");\n    // Critical section\n    pthread_mutex_unlock(&mutexA);\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 2: Unlocked mutexB and mutexA. Exiting.\\n\");\n    return NULL;\n}\n\n// main function (not part of the snippet for analysis, but for context)\n// int main() {\n//     pthread_t tid1, tid2;\n//     pthread_mutex_init(&mutexA, NULL);\n//     pthread_mutex_init(&mutexB, NULL);\n\n//     pthread_create(&tid1, NULL, thread1_func, NULL);\n//     pthread_create(&tid2, NULL, thread2_func, NULL);\n\n//     pthread_join(tid1, NULL);\n//     pthread_join(tid2, NULL);\n\n//     pthread_mutex_destroy(&mutexA);\n//     pthread_mutex_destroy(&mutexB);\n//     return 0;\n// }\n```", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "כן, קיים סיכון לקיפאון (deadlock) בקוד זה. הקיפאון יכול להתרחש כאשר תהליכון 1 רוכש בהצלחה את `mutexA` ותהליכון 2 רוכש בהצלחה את `mutexB`. בשלב זה, תהליכון 1 מחזיק ב-`mutexA` וממתין ל-`mutexB` (שמוחזק על ידי תהליכון 2), בעוד שתהליכון 2 מחזיק ב-`mutexB` וממתין ל-`mutexA` (שמוחזק על ידי תהליכון 1). נוצרת כאן המתנה מעגלית.\n\nהתנאים לקיפאון מתקיימים:\n1.  **מניעה הדדית (Mutual Exclusion):** המנעולים מבטיחים שרק תהליכון אחד יכול להחזיק משאב (מנעול) בכל רגע נתון. תנאי זה מתקיים.\n2.  **החזקה והמתנה (Hold and Wait):** כל תהליכון מחזיק במנעול אחד וממתין למנעול נוסף. תהליכון 1 מחזיק ב-`mutexA` וממתין ל-`mutexB`, ותהליכון 2 מחזיק ב-`mutexB` וממתין ל-`mutexA`. תנאי זה מתקיים.\n3.  **אי-הפקעה (No Preemption):** לא ניתן להפקיע מנעול מתהליכון שמחזיק בו בכוח. תנאי זה מתקיים.\n4.  **המתנה מעגלית (Circular Wait):** תהליכון 1 ממתין למשאב שמוחזק על ידי תהליכון 2, ותהליכון 2 ממתין למשאב שמוחזק על ידי תהליכון 1, ויוצר מעגל תלות. תנאי זה מתקיים.\n\n**פתרון למניעת קיפאון:**\nכדי למנוע קיפאון זה, יש להבטיח סדר עקבי ברכישת המנעולים על ידי כל התהליכונים. לדוגמה, שני התהליכונים צריכים לרכוש קודם את `mutexA` ולאחר מכן את `mutexB` (או להיפך, כל עוד הסדר זהה בשניהם).\n\nדוגמה לתיקון:\n```c\nvoid* thread1_func(void* arg) {\n    pthread_mutex_lock(&mutexA);\n    sleep(1);\n    pthread_mutex_lock(&mutexB);\n    // Critical section\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n    return NULL;\n}\n\nvoid* thread2_func(void* arg) {\n    pthread_mutex_lock(&mutexA); // Changed order to match thread1\n    sleep(1);\n    pthread_mutex_lock(&mutexB); // Changed order to match thread1\n    // Critical section\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n    return NULL;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0416__Deadlocks__CodeAnalysis__Easy.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:24:35", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Deadlocks", "Concurrency", "Mutexes", "Threads"], "content": {"text": "נתון קטע הקוד הבא המשתמש בשני מנעולים ושני תהליכונים (threads). נתחו את הקוד וענו על השאלה: האם קטע הקוד עלול להוביל למצב של קיפאון (Deadlock)? נמקו את תשובתכם.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex1;\npthread_mutex_t mutex2;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to acquire mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 1: Acquired mutex1. Trying to acquire mutex2...\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 1: Acquired mutex2. Critical section...\\n\");\n    // Critical section\n    pthread_mutex_unlock(&mutex2);\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 1: Released mutexes.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to acquire mutex2...\\n\");\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2: Acquired mutex2. Trying to acquire mutex1...\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2: Acquired mutex1. Critical section...\\n\");\n    // Critical section\n    pthread_mutex_unlock(&mutex1);\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2: Released mutexes.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&mutex1, NULL);\n    pthread_mutex_init(&mutex2, NULL);\n\n    pthread_create(&tid1, NULL, thread_func1, NULL);\n    pthread_create(&tid2, NULL, thread_func2, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, קטע הקוד עלול להוביל למצב של קיפאון (Deadlock).\n\nקיפאון מתרחש כאשר כל אחד משני התהליכונים (threads) מחזיק במשאב (מנעול) אחד וממתין למשאב השני המוחזק על ידי התהליכון האחר. במקרה זה:\n\n*   **תהליכון 1 (thread_func1)** מנסה לרכוש את `mutex1` ולאחר מכן את `mutex2`.\n*   **תהליכון 2 (thread_func2)** מנסה לרכוש את `mutex2` ולאחר מכן את `mutex1`.\n\n**תרחיש לקיפאון:**\n1.  תהליכון 1 מתחיל לרוץ ורוכש בהצלחה את `mutex1`.\n2.  מתרחש מעבר הקשר (context switch) ותהליכון 2 מתחיל לרוץ.\n3.  תהליכון 2 רוכש בהצלחה את `mutex2`.\n4.  כעת, תהליכון 1 מנסה לרכוש את `mutex2`, אך הוא כבר מוחזק על ידי תהליכון 2. לכן, תהליכון 1 נחסם וממתין לשחרורו.\n5.  תהליכון 2 מנסה לרכוש את `mutex1`, אך הוא כבר מוחזק על ידי תהליכון 1. לכן, תהליכון 2 נחסם וממתין לשחרורו.\n\nבמצב זה, שני התהליכונים חסומים באופן הדדי וכל אחד מהם ממתין למשאב שהשני מחזיק, וכך נוצר קיפאון. הכללת ה-`sleep(1)` בקוד מגבירה את הסיכוי למעבר הקשר כזה שיביא לתרחיש הקיפאון."}, "difficulty_estimation": "Medium", "_source_file": "0417__Deadlocks__CodeAnalysis__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:24:48", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Mutexes", "Concurrency"], "content": {"text": "נתון קטע הקוד הבא המדמה שני חוטים המנסים לבצע פעולות על משאבים שונים. נתחו את הקוד וענו על השאלות:", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n\npthread_mutex_t mutex1;\npthread_mutex_t mutex2;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Attempting to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 1: Locked mutex1. Attempting to lock mutex2...\\n\");\n    usleep(100000); // Simulate some work or context switch\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 1: Locked mutex2. Performing operations...\\n\");\n    // Critical section\n    printf(\"Thread 1: Releasing mutex2...\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 1: Releasing mutex1...\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 1: Exiting.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Attempting to lock mutex2...\\n\");\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2: Locked mutex2. Attempting to lock mutex1...\\n\");\n    usleep(100000); // Simulate some work or context switch\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2: Locked mutex1. Performing operations...\\n\");\n    // Critical section\n    printf(\"Thread 2: Releasing mutex1...\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 2: Releasing mutex2...\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2: Exiting.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t t1, t2;\n\n    pthread_mutex_init(&mutex1, NULL);\n    pthread_mutex_init(&mutex2, NULL);\n\n    pthread_create(&t1, NULL, thread_func1, NULL);\n    pthread_create(&t2, NULL, thread_func2, NULL);\n\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n\n    printf(\"Main: Both threads finished.\\n\");\n    return 0;\n}\n", "options": null}, "sub_questions": [{"id": "a", "text": "האם קטע הקוד הנתון עלול להוביל לקיפאון (Deadlock)? נמקו את תשובתכם תוך התייחסות לתנאים ההכרחיים לקיפאון.", "code_snippet": null, "options": ["כן", "לא"], "solution": {"is_present_in_file": true, "correct_option": "כן", "explanation": "כן, קטע הקוד עלול להוביל לקיפאון (Deadlock). קיפאון יכול להתרחש כאשר מתקיימים ארבעת התנאים ההכרחיים לקיפאון:\n1.  **מניעה הדדית (Mutual Exclusion)**: המנעולים `mutex1` ו-`mutex2` הם משאבים שאינם ניתנים לשיתוף. רק חוט אחד יכול להחזיק במנעול נתון בכל רגע נתון.\n2.  **החזקה והמתנה (Hold and Wait)**: חוט 1 לוכד את `mutex1` ולאחר מכן מנסה לנעול את `mutex2`. במקביל, חוט 2 לוכד את `mutex2` ולאחר מכן מנסה לנעול את `mutex1`. כל חוט מחזיק במשאב אחד (מנעול) וממתין למשאב אחר שמוחזק על ידי חוט אחר.\n3.  **אי-הפקעה (No Preemption)**: לא ניתן להפקיע מנעול מחוט שהחזיק בו; רק החוט עצמו יכול לשחרר אותו באופן יזום באמצעות `pthread_mutex_unlock`.\n4.  **המתנה מעגלית (Circular Wait)**: חוט 1 ממתין למשאב (`mutex2`) שמוחזק על ידי חוט 2, בעוד שחוט 2 ממתין למשאב (`mutex1`) שמוחזק על ידי חוט 1. נוצרת שרשרת המתנה מעגלית.\n\n**תרחיש לדוגמה לקיפאון:**\nא.  חוט 1 מבצע `pthread_mutex_lock(&mutex1)` ומצליח לנעול את `mutex1`.\nב.  חוט 2 מבצע `pthread_mutex_lock(&mutex2)` ומצליח לנעול את `mutex2`.\nג.  חוט 1 מנסה לבצע `pthread_mutex_lock(&mutex2)`, אך `mutex2` נעול על ידי חוט 2, ולכן חוט 1 נחסם ונכנס למצב המתנה.\nד.  חוט 2 מנסה לבצע `pthread_mutex_lock(&mutex1)`, אך `mutex1` נעול על ידי חוט 1, ולכן חוט 2 נחסם ונכנס למצב המתנה.\nבשלב זה, שני החוטים חסומים באופן הדדי וממתינים זה לזה, מה שמוביל לקיפאון."}}, {"id": "b", "text": "הצע פתרון לבעיית הקיפאון בקטע קוד זה. הצג את קטע הקוד המתוקן והסבר בקצרה מדוע הפתרון מונע קיפאון.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h>\n\npthread_mutex_t mutex1;\npthread_mutex_t mutex2;\n\n// Solution: Ensure consistent lock ordering\nvoid* thread_func1_fixed(void* arg) {\n    printf(\"Thread 1 (fixed): Attempting to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 1 (fixed): Locked mutex1. Attempting to lock mutex2...\\n\");\n    usleep(100000);\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 1 (fixed): Locked mutex2. Performing operations...\\n\");\n    // Critical section\n    printf(\"Thread 1 (fixed): Releasing mutex2...\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 1 (fixed): Releasing mutex1...\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 1 (fixed): Exiting.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2_fixed(void* arg) {\n    printf(\"Thread 2 (fixed): Attempting to lock mutex1...\\n\"); // Changed order\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2 (fixed): Locked mutex1. Attempting to lock mutex2...\\n\"); // Changed order\n    usleep(100000);\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2 (fixed): Locked mutex2. Performing operations...\\n\");\n    // Critical section\n    printf(\"Thread 2 (fixed): Releasing mutex2...\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2 (fixed): Releasing mutex1...\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 2 (fixed): Exiting.\\n\");\n    return NULL;\n}\n\nint main_fixed() { // Renamed main to avoid conflict if compiled with original\n    pthread_t t1, t2;\n\n    pthread_mutex_init(&mutex1, NULL);\n    pthread_mutex_init(&mutex2, NULL);\n\n    pthread_create(&t1, NULL, thread_func1_fixed, NULL);\n    pthread_create(&t2, NULL, thread_func2_fixed, NULL);\n\n    pthread_join(t1, NULL);\n    pthread_join(t2, NULL);\n\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n\n    printf(\"Main (fixed): Both threads finished.\\n\");\n    return 0;\n}", "options": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון הנפוץ והפשוט ביותר למניעת קיפאון במקרה זה הוא לוודא שכל החוטים מנסים לתפוס את המנעולים באותו סדר קבוע (Fixed Lock Ordering). על ידי אכיפת סדר קבוע לרכישת מנעולים, אנו מונעים את תנאי ההמתנה המעגלית (Circular Wait).\n\nכפי שמוצג בקטע הקוד המתוקן, גם `thread_func1_fixed` וגם `thread_func2_fixed` מנסים לתפוס קודם את `mutex1` ולאחר מכן את `mutex2`. המשמעות היא שאף פעם לא ייווצר מצב שבו חוט 1 מחזיק את `mutex1` וממתין ל-`mutex2`, בעוד חוט 2 מחזיק את `mutex2` וממתין ל-`mutex1`.\n\n**הסבר מדוע הפתרון מונע קיפאון:**\nאם חוט 1 לוכד את `mutex1`, וחוט 2 מנסה גם הוא לנעול את `mutex1`, חוט 2 יחסם וימתין שחוט 1 ישחרר את `mutex1`. חוט 1, לאחר שינעל את `mutex1`, ימשיך לנעול את `mutex2`. אם `mutex2` פנוי, הוא ינעל אותו ויבצע את פעולותיו. אם `mutex2` היה נעול על ידי חוט אחר (שלא ייתכן שיהיה חוט 2, כי הוא ממתין ל-`mutex1`), חוט 1 היה ממתין לו, אך עדיין לא נוצרת המתנה מעגלית בין חוט 1 לחוט 2. בסופו של דבר, חוט 1 ישחרר את שני המנעולים, ואז חוט 2 יוכל לנעול את `mutex1` ואז את `mutex2` (או להיפך, אם חוט 2 היה הראשון לתפוס את `mutex1`).\n\nבדרך זו, אנו מבטיחים שגם אם חוטים מתחרים על אותם משאבים, הם יעשו זאת בסדר עקבי, ובכך נמנע את היווצרות שרשרת ההמתנה המעגלית, שהיא אחד מארבעת התנאים ההכרחיים לקיפאון."}}], "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": null}, "difficulty_estimation": "Medium", "_source_file": "0418__Deadlocks__CodeAnalysis__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:25:15", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Mutexes", "Concurrency", "Threads"], "content": {"text": "נתון קטע הקוד הבא המדמה שני תהליכונים (threads) המנסים לגשת לשני משאבים (המיוצגים על ידי mutexes).", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutexA;\npthread_mutex_t mutexB;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to acquire Mutex A...\\n\");\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 1: Acquired Mutex A. Trying to acquire Mutex B...\\n\");\n    sleep(1); // Introduce a delay to increase deadlock probability\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 1: Acquired Mutex B. Critical Section 1.\\n\");\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 1: Released Mutex A and B.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to acquire Mutex B...\\n\");\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 2: Acquired Mutex B. Trying to acquire Mutex A...\\n\");\n    sleep(1); // Introduce a delay\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 2: Acquired Mutex A. Critical Section 2.\\n\");\n    pthread_mutex_unlock(&mutexA);\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 2: Released Mutex B and A.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&mutexA, NULL);\n    pthread_mutex_init(&mutexB, NULL);\n\n    pthread_create(&tid1, NULL, thread_func1, NULL);\n    pthread_create(&tid2, NULL, thread_func2, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    pthread_mutex_destroy(&mutexA);\n    pthread_mutex_destroy(&mutexB);\n\n    printf(\"Main: Program finished.\\n\");\n    return 0;\n}"}, "sub_questions": [{"id": "a", "text": "האם קיים סיכוי למצב קיפאון (Deadlock) בקטע קוד זה? נמק את תשובתך על בסיס ארבעת התנאים לקיפאון.", "code_snippet": null, "options": ["כן", "לא"], "solution": {"is_present_in_file": true, "correct_option": "כן", "explanation": "כן, קיים סיכוי למצב קיפאון (Deadlock).\nארבעת התנאים לקיפאון מתקיימים במערכת זו:\n1.  **מניעה הדדית (Mutual Exclusion):** המוטקסים (mutexA, mutexB) מספקים מניעה הדדית, כלומר רק תהליכון אחד יכול להחזיק במוטקס נתון בכל רגע. אם תהליכון מנסה לתפוס מוטקס תפוס, הוא נחסם עד שהמוטקס ישוחרר.\n2.  **החזקה והמתנה (Hold and Wait):** כל תהליכון יכול להחזיק במוטקס אחד (לדוגמה, Thread 1 מחזיק ב-mutexA) ולהמתין למוטקס אחר (Thread 1 ממתין ל-mutexB). במקרה של קיפאון, Thread 1 יחזיק ב-mutexA וימתין ל-mutexB, בעוד Thread 2 יחזיק ב-mutexB וימתין ל-mutexA.\n3.  **אי-שלילה (No Preemption):** המוטקסים לא נשללים בכוח מתהליכון שמחזיק בהם; הם משוחררים רק מרצון על ידי התהליכון שהחזיק בהם. מערכת ההפעלה או תהליכון אחר אינם יכולים לכפות שחרור של מוטקס.\n4.  **המתנה מעגלית (Circular Wait):** תרחיש אפשרי לקיפאון הוא כדלקמן:\n    *   Thread 1 מבצע `pthread_mutex_lock(&mutexA)` ומצליח לתפוס את mutexA.\n    *   מיד לאחר מכן (או תוך כדי ה-`sleep(1)` של Thread 1), Thread 2 מבצע `pthread_mutex_lock(&mutexB)` ומצליח לתפוס את mutexB.\n    *   כעת, Thread 1 מנסה לבצע `pthread_mutex_lock(&mutexB)` אך mutexB מוחזק על ידי Thread 2, ולכן Thread 1 נחסם.\n    *   ובמקביל, Thread 2 מנסה לבצע `pthread_mutex_lock(&mutexA)` אך mutexA מוחזק על ידי Thread 1, ולכן Thread 2 נחסם.\n    *   נוצר מעגל המתנה: Thread 1 ממתין ל-Thread 2 שישחרר את mutexB, ו-Thread 2 ממתין ל-Thread 1 שישחרר את mutexA. אף אחד מהם לא יכול להמשיך, לשחרר את המשאב שברשותו, או להתקדם, וכתוצאה מכך נוצר מצב קיפאון. ה-`sleep(1)` המכוון בקוד מגדיל את הסבירות להתרחשות תרחיש זה על ידי יצירת חלון זמן שבו שני התהליכונים יכולים לתפוס את המוטקס הראשון שלהם לפני שהשני ניסה לתפוס את המוטקס השני."}}], "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": null}, "difficulty_estimation": "Medium", "_source_file": "0419__Deadlocks__CodeAnalysis__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:25:36", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Deadlocks", "Concurrency", "Mutexes", "Threads"], "content": {"text": "נתון קטע הקוד הבא המשתמש במנעולים (mutexes) ובחוטים (threads) לגישה למשאבים משותפים:\n\nהאם קיים סיכון לקיפאון (deadlock) בתוכנית זו? אם כן, הסבר מדוע וכיצד הוא יכול להתרחש.", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutexA;\npthread_mutex_t mutexB;\n\nvoid *thread_func1(void *arg) {\n    printf(\"Thread 1: Attempting to lock Mutex A...\\n\");\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 1: Mutex A locked. Attempting to lock Mutex B...\\n\");\n    sleep(1); // Introduce a delay to increase likelihood of deadlock\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 1: Mutex B locked. Critical section for Thread 1.\\n\");\n\n    // Do some work\n    printf(\"Thread 1: Releasing Mutex B.\\n\");\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 1: Releasing Mutex A.\\n\");\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 1: Exiting.\\n\");\n    return NULL;\n}\n\nvoid *thread_func2(void *arg) {\n    printf(\"Thread 2: Attempting to lock Mutex B...\\n\");\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 2: Mutex B locked. Attempting to lock Mutex A...\\n\");\n    sleep(1); // Introduce a delay\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 2: Mutex A locked. Critical section for Thread 2.\\n\");\n\n    // Do some work\n    printf(\"Thread 2: Releasing Mutex A.\\n\");\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 2: Releasing Mutex B.\\n\");\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 2: Exiting.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&mutexA, NULL);\n    pthread_mutex_init(&mutexB, NULL);\n\n    pthread_create(&tid1, NULL, thread_func1, NULL);\n    pthread_create(&tid2, NULL, thread_func2, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    pthread_mutex_destroy(&mutexA);\n    pthread_mutex_destroy(&mutexB);\n\n    printf(\"Main: All threads finished.\\n\");\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, קיים סיכון לקיפאון (deadlock) בתוכנית זו. קיפאון יכול להתרחש כאשר מתקיימים בו זמנית ארבעה תנאים הכרחיים:\n\n1.  **מניעה הדדית (Mutual Exclusion):** מתקיימת. המנעולים `mutexA` ו-`mutexB` מבטיחים שרק חוט אחד יכול להחזיק כל משאב (מנעול) בכל רגע נתון. אם חוט אחד מחזיק מנעול, חוט אחר המנסה לתפוס אותו ייחסם.\n\n2.  **החזקה והמתנה (Hold and Wait):** מתקיימת. כל חוט תופס מנעול אחד (לדוגמה, `thread_func1` תופס את `mutexA`, ו-`thread_func2` תופס את `mutexB`) וממתין למנעול השני תוך כדי החזקת המנעול הראשון. הם לא משחררים את המשאב שהם כבר מחזיקים.\n\n3.  **אי-הפקעה (No Preemption):** מתקיימת. לא ניתן להפקיע מנעול מחוט שמחזיק בו; חוט חייב לשחרר אותו מרצונו לאחר שסיים להשתמש בו. מערכת ההפעלה אינה יכולה לקחת מנעול מחוט בכוח.\n\n4.  **המתנה מעגלית (Circular Wait):** מתקיימת. חוט 1 (`thread_func1`) מנסה לתפוס את `mutexA` ולאחר מכן את `mutexB`. חוט 2 (`thread_func2`) מנסה לתפוס את `mutexB` ולאחר מכן את `mutexA`. אם חוט 1 תופס את `mutexA` (שורת קוד 11) ומיד לאחר מכן חוט 2 תופס את `mutexB` (שורת קוד 27), אז:\n    *   חוט 1 ימתין ל-`mutexB` שמוחזק על ידי חוט 2 (שורת קוד 14).\n    *   חוט 2 ימתין ל-`mutexA` שמוחזק על ידי חוט 1 (שורת קוד 30).\n    מצב זה יוצר מעגל המתנה שבו כל חוט ממתין למשאב שמוחזק על ידי חוט אחר במעגל, מה שמוביל לקיפאון.\n\nהשימוש בפונקציית `sleep(1)` בתוך כל חוט מגדיל את הסיכוי לכך ששני החוטים יתפסו את המנעולים שלהם (אחד כל אחד) לפני שהם ינסו לתפוס את המנעול השני, ובכך יגיעו למצב של המתנה מעגלית וקיפאון."}, "difficulty_estimation": "Medium", "_source_file": "0420__Deadlocks__CodeAnalysis__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:25:51", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Deadlocks", "Concurrency", "Synchronization", "Mutexes", "Threads"], "content": {"text": "נתון קטע הקוד הבא המשתמש במנעולים (mutexes) ובחוטים (threads) לסינכרון. נתח את הקוד וענה על השאלה:", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutexA;\npthread_mutex_t mutexB;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to lock mutexA...\\n\");\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 1: Locked mutexA. Trying to lock mutexB...\\n\");\n    sleep(1); // Introduce delay to increase likelihood of deadlock\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 1: Locked mutexB. Doing work...\\n\");\n    // Simulate work\n    sleep(1);\n    pthread_mutex_unlock(&mutexB);\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 1: Unlocked mutexA and mutexB. Exiting.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to lock mutexB...\\n\");\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 2: Locked mutexB. Trying to lock mutexA...\\n\");\n    sleep(1); // Introduce delay\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 2: Locked mutexA. Doing work...\\n\");\n    // Simulate work\n    sleep(1);\n    pthread_mutex_unlock(&mutexA);\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 2: Unlocked mutexB and mutexA. Exiting.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&mutexA, NULL);\n    pthread_mutex_init(&mutexB, NULL);\n\n    pthread_create(&tid1, NULL, thread_func1, NULL);\n    pthread_create(&tid2, NULL, thread_func2, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    pthread_mutex_destroy(&mutexA);\n    pthread_mutex_destroy(&mutexB);\n\n    printf(\"Main: Both threads finished.\\n\");\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "a", "text": "האם קטע קוד זה עלול להוביל למצב קיפאון (deadlock)? אם כן, הסבר מדוע וציין אילו מהתנאים ההכרחיים למצב קיפאון מתקיימים בקוד זה.", "code_snippet": null, "options": ["כן", "לא"], "solution": {"is_present_in_file": true, "correct_option": "כן", "explanation": "כן, קטע קוד זה עלול להוביל למצב קיפאון (deadlock). מצב קיפאון מתרחש כאשר שני חוטים או יותר חוסמים זה את זה וכל אחד מהם ממתין למשאב שמוחזק על ידי חוט אחר במעגל. ארבעת התנאים ההכרחיים למצב קיפאון מתקיימים בקוד זה:\n\n1.  **מניעה הדדית (Mutual Exclusion)**: מתקיים. המנעולים `mutexA` ו-`mutexB` מבטיחים שרק חוט אחד יכול להחזיק כל מנעול בזמן נתון. אם חוט אחד לוקח מנעול, חוט אחר לא יכול לקחת אותו עד שהוא ישוחרר.\n\n2.  **החזק והמתן (Hold and Wait)**: מתקיים. חוט `thread_func1` מחזיק את `mutexA` וממתין ל-`mutexB`. במקביל, חוט `thread_func2` מחזיק את `mutexB` וממתין ל-`mutexA`. כל חוט מחזיק במשאב אחד לפחות בזמן שהוא ממתין למשאב נוסף.\n\n3.  **אי-הפקעה (No Preemption)**: מתקיים. לא ניתן להפקיע מנעול מחוט שמחזיק אותו. המנעולים ישוחררו רק מרצונם החופשי של החוטים המחזיקים אותם, באמצעות `pthread_mutex_unlock`.\n\n4.  **המתנה מעגלית (Circular Wait)**: מתקיים. קיים מעגל המתנה: חוט `thread_func1` ממתין ל-`mutexB` שמוחזק על ידי `thread_func2`, וחוט `thread_func2` ממתין ל-`mutexA` שמוחזק על ידי `thread_func1`. זה יוצר תלות מעגלית שמונעת מכל אחד מהחוטים להתקדם.\n\nכתוצאה מכך, אם החוטים ירוצו בסדר קריטי שבו כל אחד מהם יתפוס מנעול אחד וינסה לתפוס את השני, שניהם ייתקעו בהמתנה אינסופית."}}], "points": 15, "solution": null, "difficulty_estimation": "Medium", "_source_file": "0421__Deadlocks__CodeAnalysis__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:26:08", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Deadlocks", "Concurrency", "Synchronization", "Mutexes"], "content": {"text": "נתון קטע הקוד הבא המשתמש במנעולים (mutexes) של pthreads. נתח את הקוד וענה על השאלות:", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex1;\npthread_mutex_t mutex2;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Attempting to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 1: Locked mutex1. Attempting to lock mutex2...\\n\");\n    sleep(1); // Introduce a delay to increase likelihood of deadlock\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 1: Locked mutex2. Critical section...\\n\");\n    // Do some work\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 1: Unlocked mutex2.\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 1: Unlocked mutex1. Exiting.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Attempting to lock mutex2...\\n\");\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2: Locked mutex2. Attempting to lock mutex1...\\n\");\n    sleep(1); // Introduce a delay to increase likelihood of deadlock\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2: Locked mutex1. Critical section...\\n\");\n    // Do some work\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 2: Unlocked mutex1.\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2: Unlocked mutex2. Exiting.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&mutex1, NULL);\n    pthread_mutex_init(&mutex2, NULL);\n\n    printf(\"Main: Creating threads...\\n\");\n    pthread_create(&tid1, NULL, thread_func1, NULL);\n    pthread_create(&tid2, NULL, thread_func2, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n\n    printf(\"Main: All threads finished. Exiting.\\n\");\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "a", "text": "האם עלול להיווצר קיפאון (deadlock) בתוכנית זו?", "code_snippet": null, "options": ["כן", "לא"], "solution": {"is_present_in_file": true, "correct_option": "כן", "explanation": "קיפאון אכן עלול להיווצר. המצב הקלאסי של קיפאון מתרחש כאשר שני חוטים או יותר מנסים לתפוס משאבים (במקרה זה, מנעולים) בסדר הפוך. חוט 1 תופס את `mutex1` ואז מנסה לתפוס את `mutex2`. חוט 2 תופס את `mutex2` ואז מנסה לתפוס את `mutex1`. אם חוט 1 תופס את `mutex1` וחוט 2 תופס את `mutex2` בערך באותו זמן, ואז כל אחד מנסה לתפוס את המנעול השני, שניהם יחסמו וייכנסו למצב של קיפאון (המתנה מעגלית)."}}, {"id": "b", "text": "כיצד ניתן למנוע קיפאון במקרה זה?", "code_snippet": null, "options": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ניתן למנוע קיפאון על ידי אכיפת סדר תפיסת משאבים עקבי (Resource Ordering). כלומר, כל החוטים צריכים לתפוס את המנעולים באותו סדר. לדוגמה, שניהם יתפסו תמיד את `mutex1` קודם ואז את `mutex2`. זה מונע את התנאי של המתנה מעגלית (Circular Wait), שהוא הגורם העיקרי לקיפאון במקרה זה. דרכים נוספות למניעה כוללות: \n1.  **החזקה והמתנה (Hold and Wait):** ניתן למנוע על ידי דרישה מחוט לתפוס את כל המשאבים הדרושים לו בבת אחת, או לשחרר את כל המשאבים שהוא מחזיק לפני שהוא מנסה לתפוס משאב נוסף. במקרה זה, חוט יכול לנסות לתפוס את שני המנעולים באופן אטומי (לדוגמה, באמצעות `pthread_mutex_trylock` עם לוגיקת חזרה ושחרור אם לא הצליח לתפוס את שניהם). \n2.  **אי קדימות (No Preemption):** ניתן להשתמש בשיטות בהן ניתן להפקיע משאב מחוט שמחזיק בו, אך זה פחות נפוץ וקשה ליישום עם מנעולים סטנדרטיים. \n3.  **המתנה מעגלית (Circular Wait):** זוהי הבעיה העיקרית כאן, והיא נמנעת ביעילות על ידי אכיפת סדר תפיסת משאבים."}}], "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": null}, "difficulty_estimation": "Medium", "_source_file": "0422__Deadlocks__CodeAnalysis__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:26:29", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Concurrency", "Mutexes"], "content": {"text": "נתון קטע קוד המדמה תרחיש שבו שני חוטים (threads) מנסים לגשת למשאבים משותפים המוגנים על ידי מנעולים (mutexes). עיין בקוד וענה על השאלות הבאות:", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h> // For usleep\n\npthread_mutex_t mutexA;\npthread_mutex_t mutexB;\n\nvoid *thread_func1(void *arg) {\n    printf(\"Thread 1: Trying to acquire mutexA...\\n\");\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 1: Acquired mutexA. Trying to acquire mutexB...\\n\");\n    // Simulate some work or context switch\n    usleep(100000); // 100ms\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 1: Acquired mutexB. Performing work...\\n\");\n    // Critical section\n    printf(\"Thread 1: Releasing mutexB...\\n\");\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 1: Releasing mutexA...\\n\");\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 1: Exiting.\\n\");\n    return NULL;\n}\n\nvoid *thread_func2(void *arg) {\n    printf(\"Thread 2: Trying to acquire mutexB...\\n\");\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 2: Acquired mutexB. Trying to acquire mutexA...\\n\");\n    // Simulate some work or context switch\n    usleep(100000); // 100ms\n    pthread_mutex_lock(&mutexA);\n    printf(\"Thread 2: Acquired mutexA. Performing work...\\n\");\n    // Critical section\n    printf(\"Thread 2: Releasing mutexA...\\n\");\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 2: Releasing mutexB...\\n\");\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 2: Exiting.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&mutexA, NULL);\n    pthread_mutex_init(&mutexB, NULL);\n\n    printf(\"Main: Creating Thread 1...\\n\");\n    pthread_create(&tid1, NULL, thread_func1, NULL);\n    printf(\"Main: Creating Thread 2...\\n\");\n    pthread_create(&tid2, NULL, thread_func2, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    pthread_mutex_destroy(&mutexA);\n    pthread_mutex_destroy(&mutexB);\n\n    printf(\"Main: All threads finished. Exiting.\\n\");\n    return 0;\n}", "options": null}, "sub_questions": [{"id": "a", "text": "האם קטע הקוד הנתון עלול להוביל למצב של קיפאון (deadlock)? נמק.", "code_snippet": null, "options": ["כן", "לא"], "solution": {"is_present_in_file": true, "correct_option": "כן", "explanation": "כן, קטע הקוד עלול להוביל למצב של קיפאון (deadlock). זהו תרחיש קלאסי של המתנה מעגלית (circular wait), אחד מארבעת התנאים ההכרחיים לקיפאון. חוט 1 מנסה לרכוש את mutexA ואז את mutexB. חוט 2 מנסה לרכוש את mutexB ואז את mutexA. סדר רכישת המנעולים השונה בין החוטים יוצר פוטנציאל לקיפאון."}}, {"id": "b", "text": "אם כן, תאר סדר אירועים אפשרי שיוביל לקיפאון.", "code_snippet": null, "options": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "סדר אירועים אפשרי שיוביל לקיפאון:\n1.  חוט 1 מתחיל לרוץ ורוכש בהצלחה את mutexA.\n2.  מתבצעת החלפת הקשר (context switch) לחוט 2.\n3.  חוט 2 מתחיל לרוץ ורוכש בהצלחה את mutexB.\n4.  חוט 2 מנסה לרכוש את mutexA, אך הוא כרגע מוחזק על ידי חוט 1, ולכן חוט 2 נחסם וממתין.\n5.  מתבצעת החלפת הקשר לחוט 1.\n6.  חוט 1 מנסה לרכוש את mutexB, אך הוא כרגע מוחזק על ידי חוט 2, ולכן חוט 1 נחסם וממתין.\nבשלב זה, שני החוטים חסומים באופן הדדי: חוט 1 ממתין ל-mutexB שמוחזק על ידי חוט 2, וחוט 2 ממתין ל-mutexA שמוחזק על ידי חוט 1. אף אחד מהם לא יכול להמשיך, והמערכת נכנסת לקיפאון."}}, {"id": "c", "text": "הצע שינוי מינימלי בקוד כדי למנוע קיפאון, והסבר מדוע השינוי מונע אותו.", "code_snippet": null, "options": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כדי למנוע קיפאון, יש להבטיח שכל החוטים ירכשו את המנעולים באותו סדר עקבי. שינוי מינימלי יהיה לשנות את סדר רכישת המנעולים באחת מהפונקציות, לדוגמה ב-`thread_func2`, כך שהיא תנסה לרכוש את `mutexA` לפני `mutexB`.\n\n**השינוי המוצע ב-`thread_func2`:**\n```c\nvoid *thread_func2(void *arg) {\n    printf(\"Thread 2: Trying to acquire mutexA...\\n\"); // שינוי סדר\n    pthread_mutex_lock(&mutexA); // שינוי סדר\n    printf(\"Thread 2: Acquired mutexA. Trying to acquire mutexB...\\n\");\n    usleep(100000); // 100ms\n    pthread_mutex_lock(&mutexB);\n    printf(\"Thread 2: Acquired mutexB. Performing work...\\n\");\n    // Critical section\n    printf(\"Thread 2: Releasing mutexB...\\n\");\n    pthread_mutex_unlock(&mutexB);\n    printf(\"Thread 2: Releasing mutexA...\\n\");\n    pthread_mutex_unlock(&mutexA);\n    printf(\"Thread 2: Exiting.\\n\");\n    return NULL;\n}\n```\n\n**הסבר:**\nעל ידי אכיפת סדר רכישה עקבי (לדוגמה, תמיד `mutexA` ואז `mutexB`) עבור כל החוטים, אנו מונעים את תנאי ה'המתנה מעגלית'. אם חוט 1 רוכש את `mutexA` וממתין ל-`mutexB`, וחוט 2 מנסה גם הוא לרכוש את `mutexA` (לפני `mutexB`), חוט 2 יחסם על `mutexA` ולא ירכוש את `mutexB`. בדרך זו, לעולם לא ייווצר מצב שבו חוט 1 מחזיק את `mutexA` וממתין ל-`mutexB` בעוד חוט 2 מחזיק את `mutexB` וממתין ל-`mutexA`. תמיד רק חוט אחד יוכל להחזיק ב-`mutexA` בבת אחת, ובכך נשבר המעגל של התלות ההדדית."}}], "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": null}, "difficulty_estimation": "Medium", "_source_file": "0423__Deadlocks__CodeAnalysis__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:26:48", "_subject": "Concurrency"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Mutexes", "Concurrency"], "content": {"text": "נתון קטע הקוד הבא המדמה הקצאת משאבים בין שני תהליכונים (threads). נתחו את הקוד וענו על השאלות:", "code_snippet": "#include <stdio.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\npthread_mutex_t mutex1;\npthread_mutex_t mutex2;\n\nvoid* thread_func1(void* arg) {\n    printf(\"Thread 1: Trying to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 1: Locked mutex1. Trying to lock mutex2...\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 1: Locked mutex2. Performing work...\\n\");\n    // Critical section\n    printf(\"Thread 1: Unlocking mutex2...\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 1: Unlocking mutex1...\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 1: Finished.\\n\");\n    return NULL;\n}\n\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to lock mutex2...\\n\");\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2: Locked mutex2. Trying to lock mutex1...\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2: Locked mutex1. Performing work...\\n\");\n    // Critical section\n    printf(\"Thread 2: Unlocking mutex1...\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 2: Unlocking mutex2...\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2: Finished.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid1, tid2;\n\n    pthread_mutex_init(&mutex1, NULL);\n    pthread_mutex_init(&mutex2, NULL);\n\n    pthread_create(&tid1, NULL, thread_func1, NULL);\n    pthread_create(&tid2, NULL, thread_func2, NULL);\n\n    pthread_join(tid1, NULL);\n    pthread_join(tid2, NULL);\n\n    pthread_mutex_destroy(&mutex1);\n    pthread_mutex_destroy(&mutex2);\n\n    printf(\"Main: Both threads finished.\\n\");\n    return 0;\n}"}, "sub_questions": [{"id": "a", "text": "האם קיפאון (deadlock) יכול להתרחש בקוד זה? נמקו את תשובתכם.", "code_snippet": null, "options": ["כן", "לא"], "solution": {"is_present_in_file": true, "correct_option": "כן", "explanation": "כן, קיפאון יכול להתרחש בקוד זה. הקוד מדגים את התנאים ההכרחיים לקיפאון (תנאי ה-Coffman):\n1. מניעה הדדית (Mutual Exclusion): המנעולים (mutexes) מספקים גישה בלעדית למשאבים.\n2. החזק והמתן (Hold and Wait): כל תהליכון מחזיק במנעול אחד וממתין למנעול נוסף.\n3. אי-שלילה (No Preemption): לא ניתן לקחת מנעול מתהליכון בכוח.\n4. המתנה מעגלית (Circular Wait): תהליכון 1 מחכה למנעול 2 שתפוס ע\"י תהליכון 2, ותהליכון 2 מחכה למנעול 1 שתפוס ע\"י תהליכון 1."}}, {"id": "b", "text": "אם התשובה לשאלה הקודמת חיובית, תארו סדר אירועים אפשרי המוביל לקיפאון.", "code_snippet": null, "options": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "סדר אירועים אפשרי לקיפאון:\n1. תהליכון 1 (thread_func1) מבצע pthread_mutex_lock(&mutex1) ונועל את mutex1.\n2. מתרחשת החלפת הקשר (context switch).\n3. תהליכון 2 (thread_func2) מבצע pthread_mutex_lock(&mutex2) ונועל את mutex2.\n4. תהליכון 2 מנסה לבצע pthread_mutex_lock(&mutex1) אך נחסם מכיוון ש-mutex1 נעול על ידי תהליכון 1.\n5. מתרחשת החלפת הקשר.\n6. תהליכון 1 מנסה לבצע pthread_mutex_lock(&mutex2) אך נחסם מכיוון ש-mutex2 נעול על ידי תהליכון 2.\nבשלב זה, תהליכון 1 מחכה ל-mutex2 שתפוס על ידי תהליכון 2, ותהליכון 2 מחכה ל-mutex1 שתפוס על ידי תהליכון 1. נוצר קיפאון, ושני התהליכונים יישארו חסומים לעד."}}, {"id": "c", "text": "כיצד ניתן למנוע קיפאון בקוד זה תוך שימוש בשינויים מינימליים? הציגו את השינויים בקוד.", "code_snippet": null, "options": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כדי למנוע קיפאון, יש לוודא שתנאי ההמתנה המעגלית לא יתקיים. הדרך הנפוצה והפשוטה ביותר היא להקצות סדר קבוע לרכישת המשאבים. אם כל התהליכונים ינסו לרכוש את המנעולים באותו סדר (לדוגמה, תמיד mutex1 ואז mutex2), לא ייתכן מצב של המתנה מעגלית.\n\n**שינויים בקוד:**\nיש לשנות את הפונקציה `thread_func2` כך שתנסה לנעול את `mutex1` לפני `mutex2`.\n\n```c\nvoid* thread_func2(void* arg) {\n    printf(\"Thread 2: Trying to lock mutex1...\\n\");\n    pthread_mutex_lock(&mutex1);\n    printf(\"Thread 2: Locked mutex1. Trying to lock mutex2...\\n\");\n    sleep(1); // Simulate work or context switch\n    pthread_mutex_lock(&mutex2);\n    printf(\"Thread 2: Locked mutex2. Performing work...\\n\");\n    // Critical section\n    printf(\"Thread 2: Unlocking mutex2...\\n\");\n    pthread_mutex_unlock(&mutex2);\n    printf(\"Thread 2: Unlocking mutex1...\\n\");\n    pthread_mutex_unlock(&mutex1);\n    printf(\"Thread 2: Finished.\\n\");\n    return NULL;\n}\n```\n\nבשינוי זה, שני התהליכונים מנסים לנעול את `mutex1` ראשון ולאחר מכן את `mutex2`. זה מבטיח שאם `mutex1` נתפס על ידי אחד התהליכונים, התהליכון השני ימתין לו לפני שינסה לתפוס את `mutex2`. רק כאשר `mutex1` פנוי, התהליכון השני יוכל לנעול אותו ולהמשיך לנסות לנעול את `mutex2`. כך נמנעת המתנה מעגלית ולכן קיפאון."}}], "points": 20, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": null}, "difficulty_estimation": "Medium", "_source_file": "0424__Deadlocks__CodeAnalysis__Medium.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:27:09", "_subject": "Concurrency"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Concurrency"], "content": {"text": "במערכת הפעלה נתונה, קיימים N משאבים מסוג יחיד, המסומנים כ- `R_0, R_1, ..., R_{N-1}`. כל משאב מוגן על ידי מנעול `pthread_mutex_t` משלו. חוטים במערכת צריכים לרכוש בו-זמנית שני משאבים ספציפיים, `R_i` ו- `R_j` (כאשר `i` שונה מ- `j`), לבצע עליהם פעולה כלשהי, ולאחר מכן לשחרר אותם. נתון המימוש הראשוני הבא לפונקציות רכישה ושחרור:\n\n", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h> // For usleep\n\n#define N_RESOURCES 5 // לדוגמה, מספר המשאבים במערכת\n\npthread_mutex_t resource_mutexes[N_RESOURCES];\n\nvoid init_resources() {\n    for (int k = 0; k < N_RESOURCES; ++k) {\n        pthread_mutex_init(&resource_mutexes[k], NULL);\n    }\n}\n\nvoid destroy_resources() {\n    for (int k = 0; k < N_RESOURCES; ++k) {\n        pthread_mutex_destroy(&resource_mutexes[k]);\n    }\n}\n\n// פונקציית רכישה ראשונית\nvoid acquire_two_resources_initial(int id1, int id2) {\n    if (id1 == id2 || id1 < 0 || id1 >= N_RESOURCES || id2 < 0 || id2 >= N_RESOURCES) {\n        fprintf(stderr, \"Invalid resource IDs: %d, %d\\n\", id1, id2);\n        exit(1);\n    }\n    printf(\"Thread %lu attempting to acquire R%d then R%d\\n\", pthread_self(), id1, id2);\n    pthread_mutex_lock(&resource_mutexes[id1]);\n    printf(\"Thread %lu acquired R%d, attempting R%d\\n\", pthread_self(), id1, id2);\n    pthread_mutex_lock(&resource_mutexes[id2]);\n    printf(\"Thread %lu acquired R%d and R%d\\n\", pthread_self(), id1, id2);\n}\n\n// פונקציית שחרור ראשונית\nvoid release_two_resources_initial(int id1, int id2) {\n    printf(\"Thread %lu releasing R%d and R%d\\n\", pthread_self(), id1, id2);\n    pthread_mutex_unlock(&resource_mutexes[id2]);\n    pthread_mutex_unlock(&resource_mutexes[id1]);\n}\n\n// פונקציית עבודה לדוגמה\nvoid* thread_func_initial(void* arg) {\n    int* ids = (int*)arg;\n    int r1 = ids[0];\n    int r2 = ids[1];\n\n    acquire_two_resources_initial(r1, r2);\n    // Simulate work\n    usleep(100);\n    release_two_resources_initial(r1, r2);\n    return NULL;\n}\n\n// פונקציית main לדוגמה להדגמת קיפאון\n// int main() {\n//     init_resources();\n//     pthread_t t1, t2;\n//     int ids1[] = {0, 1}; // Thread 1 wants R0, then R1\n//     int ids2[] = {1, 0}; // Thread 2 wants R1, then R0\n//\n//     pthread_create(&t1, NULL, thread_func_initial, (void*)ids1);\n//     pthread_create(&t2, NULL, thread_func_initial, (void*)ids2);\n//\n//     pthread_join(t1, NULL);\n//     pthread_join(t2, NULL);\n//\n//     destroy_resources();\n//     return 0;\n// }\n", "options": null}, "sub_questions": [{"id": "8.1", "text": "האם המימוש הראשוני של `acquire_two_resources_initial` יכול להוביל לקיפאון (deadlock)? אם כן, תאר תרחיש ספציפי שבו קיפאון כזה יתרחש, והסבר מדוע.", "code_snippet": null, "options": null}, {"id": "8.2", "text": "שנה את המימוש של הפונקציות `acquire_two_resources` ו- `release_two_resources` כך שימנעו קיפאון באופן מוחלט, תוך שמירה על העיקרון שחוט תמיד ינסה לרכוש את `id1` *לפני* `id2`. המימוש החדש צריך להיות יעיל ככל האפשר ולא לכלול מנעול גלובלי יחיד שמסרסל את כל הבקשות. השתמש בפעולות סנכרון סטנדרטיות בלבד (כגון `pthread_mutex_t` ופונקציותיה, כולל `trylock`).", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "8.1: כן, המימוש הראשוני יכול להוביל לקיפאון.\n\n**תרחיש לקיפאון:**\nנניח שני חוטים, חוט A וחוט B, ושני משאבים `R_0` ו- `R_1`.\n1.  **חוט A** קורא ל- `acquire_two_resources_initial(0, 1)`:\n    *   חוט A נועל את `resource_mutexes[0]`.\n    *   חוט A מנסה לנעול את `resource_mutexes[1]`.\n2.  **במקביל, חוט B** קורא ל- `acquire_two_resources_initial(1, 0)`:\n    *   חוט B נועל את `resource_mutexes[1]`.\n    *   חוט B מנסה לנעול את `resource_mutexes[0]`.\n\n**הסבר:**\nבנקודה זו:\n*   חוט A מחזיק במנעול של `R_0` וממתין למנעול של `R_1`.\n*   חוט B מחזיק במנעול של `R_1` וממתין למנעול של `R_0`.\n\nזהו מצב של **קיפאון (deadlock)** מכיוון שמתקיימים כל ארבעת התנאים של קיפאון:\n1.  **מניעה הדדית (Mutual Exclusion):** כל משאב מוגן על ידי מנעול, כך שרק חוט אחד יכול להחזיק בו זמנית.\n2.  **החזק והמתן (Hold and Wait):** כל חוט מחזיק במשאב אחד (A מחזיק ב-`R_0`, B מחזיק ב-`R_1`) וממתין למשאב נוסף (A ממתין ל-`R_1`, B ממתין ל-`R_0`).\n3.  **אין שלילה מוקדמת (No Preemption):** לא ניתן לכפות על חוט לשחרר משאב שהוא מחזיק בו.\n4.  **המתנה מעגלית (Circular Wait):** חוט A ממתין למשאב שחוט B מחזיק, וחוט B ממתין למשאב שחוט A מחזיק, ויוצר מעגל המתנה.\n\n8.2: כדי למנוע קיפאון תוך שמירה על סדר הרכישה `id1` ואז `id2`, נשתמש בגישת ה- `trylock` עם מנגנון גיבוי (back-off). הרעיון הוא לנסות לרכוש את המנעולים בסדר הנדרש. אם הרכישה השנייה נכשלת (כי המשאב כבר תפוס), החוט ישחרר את המשאב הראשון שתפס, ימתין זמן קצר (כדי למנוע רעב מיידי ולתת לחוטים אחרים סיכוי), וינסה שוב. זה מפר את תנאי ה-\"החזק והמתן\" ובכך מונע קיפאון.\n\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h> // For usleep\n\n#define N_RESOURCES 5\n#define RETRY_DELAY_US 1000 // 1 מ\"ש\n\npthread_mutex_t resource_mutexes[N_RESOURCES];\n\nvoid init_resources() {\n    for (int k = 0; k < N_RESOURCES; ++k) {\n        pthread_mutex_init(&resource_mutexes[k], NULL);\n    }\n}\n\nvoid destroy_resources() {\n    for (int k = 0; k < N_RESOURCES; ++k) {\n        pthread_mutex_destroy(&resource_mutexes[k]);\n    }\n}\n\n// פונקציית רכישה מתוקנת ללא קיפאון\nvoid acquire_two_resources(int id1, int id2) {\n    if (id1 == id2 || id1 < 0 || id1 >= N_RESOURCES || id2 < 0 || id2 >= N_RESOURCES) {\n        fprintf(stderr, \"Invalid resource IDs: %d, %d\\n\", id1, id2);\n        exit(1);\n    }\n\n    while (1) { // ננסה לרכוש עד שנצליח\n        printf(\"Thread %lu attempting to acquire R%d then R%d\\n\", pthread_self(), id1, id2);\n\n        // ננסה לנעול את המשאב הראשון\n        pthread_mutex_lock(&resource_mutexes[id1]);\n        printf(\"Thread %lu acquired R%d, attempting R%d\\n\", pthread_self(), id1, id2);\n\n        // ננסה לנעול את המשאב השני\n        if (pthread_mutex_trylock(&resource_mutexes[id2]) == 0) {\n            // הצלחנו לנעול את שניהם\n            printf(\"Thread %lu acquired R%d and R%d\\n\", pthread_self(), id1, id2);\n            return;\n        } else {\n            // לא הצלחנו לנעול את המשאב השני, נשחרר את הראשון וננסה שוב\n            printf(\"Thread %lu failed to acquire R%d, releasing R%d and retrying...\\n\", pthread_self(), id2, id1);\n            pthread_mutex_unlock(&resource_mutexes[id1]);\n            usleep(RETRY_DELAY_US + (rand() % 1000)); // השהיה עם רנדומיזציה למניעת רעב\n        }\n    }\n}\n\n// פונקציית שחרור מתוקנת\nvoid release_two_resources(int id1, int id2) {\n    printf(\"Thread %lu releasing R%d and R%d\\n\", pthread_self(), id1, id2);\n    pthread_mutex_unlock(&resource_mutexes[id2]);\n    pthread_mutex_unlock(&resource_mutexes[id1]);\n}\n\n// פונקציית עבודה לדוגמה עם המימוש המתוקן\nvoid* thread_func_fixed(void* arg) {\n    int* ids = (int*)arg;\n    int r1 = ids[0];\n    int r2 = ids[1];\n\n    acquire_two_resources(r1, r2);\n    // Simulate work\n    usleep(100);\n    release_two_resources(r1, r2);\n    return NULL;\n}\n\n// פונקציית main לדוגמה להדגמת פעולה ללא קיפאון\n// int main() {\n//     init_resources();\n//     pthread_t t1, t2;\n//     int ids1[] = {0, 1}; // Thread 1 wants R0, then R1\n//     int ids2[] = {1, 0}; // Thread 2 wants R1, then R0\n//\n//     pthread_create(&t1, NULL, thread_func_fixed, (void*)ids1);\n//     pthread_create(&t2, NULL, thread_func_fixed, (void*)ids2);\n//\n//     pthread_join(t1, NULL);\n//     pthread_join(t2, NULL);\n//\n//     destroy_resources();\n//     return 0;\n// }\n```\n\n**הסבר לפתרון:**\nהפתרון מונע קיפאון על ידי שבירת תנאי ה-\"החזק והמתן\". כאשר חוט מצליח לרכוש את המשאב הראשון (`id1`) אך נכשל ברכישת המשאב השני (`id2`) באמצעות `pthread_mutex_trylock`, הוא אינו ממתין לנצח כשהוא מחזיק במשאב הראשון. במקום זאת, הוא משחרר את המשאב הראשון (`id1`), ממתין זמן קצר (עם תוספת רנדומית כדי למנוע תזמון חוזר שיוביל לרעב), ורק אז מנסה שוב את כל תהליך הרכישה. פעולה זו מבטיחה שחוט לעולם לא יחזיק במשאב אחד ויחסום חוט אחר, בזמן שהוא עצמו ממתין למשאב שחוט אחר מחזיק. בסופו של דבר, אחד החוטים יצליח לרכוש את שני המשאבים, והמערכת תתקדם."}, "difficulty_estimation": "Hard", "_source_file": "0425__Deadlocks__CodeAnalysis__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:28:01", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Resource Ordering"], "content": {"text": "מערכת מורכבת מ-N משאבים גנריים, כאשר כל משאב מוגן על ידי מנעול `pthread_mutex_t` משלו. חוטים במערכת צריכים לבצע פעולות הדורשות גישה בו-זמנית לשני משאבים שונים. לדוגמה, חוט עשוי להזדקק למשאבים `R_i` ו-`R_j` (כאשר `i != j`).\n\nכתוב פונקציה בשם `acquire_two_resources` שתקבל שני אינדקסים של משאבים (`idx1`, `idx2`) ומערך של מצביעים למנעולים (`mutexes`). הפונקציה צריכה לנעול את שני המנעולים המתאימים למשאבים אלו באופן בטוח, כלומר, למנוע קיפאון (deadlock) בכל מקרה.\n\n**דרישות:**\n1.  הפונקציה חייבת למנוע קיפאון.\n2.  הפונקציה צריכה להיות יעילה ככל האפשר.\n3.  אין להשתמש בפעולות אטומיות או אובייקטי סנכרון נוספים מעבר ל-`pthread_mutex_t` ופונקציות הנעילה/שחרור הרגילות שלהן (`pthread_mutex_lock`, `pthread_mutex_unlock`).\n\n**שקול את תרחיש הקיפאון הבא:**\nחוט T1 מנסה לנעול את משאב `R_A` ואז את `R_B`.\nחוט T2 מנסה לנעול את משאב `R_B` ואז את `R_A`.\nאם T1 נועל את `R_A` ו-T2 נועל את `R_B` בו-זמנית, שניהם יחכו זה לזה בנצח.\n\n**קוד התחלתי (להשלמה):**", "code_snippet": "```c\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n// Assume 'num_resources' and 'resource_mutexes' are globally available\n// for simplicity, or passed as part of a context struct.\n// For this question, assume mutexes is an array of pthread_mutex_t pointers.\n\n// Function to initialize N mutexes (not part of the solution, just context)\nvoid init_resource_mutexes(pthread_mutex_t* mutexes[], int N) {\n    for (int i = 0; i < N; ++i) {\n        mutexes[i] = (pthread_mutex_t*) malloc(sizeof(pthread_mutex_t));\n        if (mutexes[i] == NULL) {\n            perror(\"malloc failed\");\n            exit(EXIT_FAILURE);\n        }\n        pthread_mutex_init(mutexes[i], NULL);\n    }\n}\n\n// Function to destroy N mutexes (not part of the solution, just context)\nvoid destroy_resource_mutexes(pthread_mutex_t* mutexes[], int N) {\n    for (int i = 0; i < N; ++i) {\n        pthread_mutex_destroy(mutexes[i]);\n        free(mutexes[i]);\n    }\n}\n\n// TODO: Implement this function to acquire two resources safely\nvoid acquire_two_resources(int idx1, int idx2, pthread_mutex_t* mutexes[]) {\n    // Your implementation here\n}\n\n// TODO: Implement this function to release two resources\nvoid release_two_resources(int idx1, int idx2, pthread_mutex_t* mutexes[]) {\n    // Your implementation here\n}\n```", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסבר לקיפאון בגישה נאיבית:\nגישה נאיבית, שבה חוטים נועלים את המשאבים בסדר שבו הם ניתנים (לדוגמה, `pthread_mutex_lock(mutexes[idx1]); pthread_mutex_lock(mutexes[idx2]);`), עלולה להוביל לקיפאון (deadlock). נניח שחוט T1 מנסה לנעול את משאב R_A ואז את R_B, וחוט T2 מנסה לנעול את משאב R_B ואז את R_A. אם T1 מצליח לנעול את R_A ו-T2 מצליח לנעול את R_B בו-זמנית, אזי T1 ימתין ל-R_B שמוחזק על ידי T2, ו-T2 ימתין ל-R_A שמוחזק על ידי T1. נוצרת שרשרת המתנה מעגלית, והחוטים יישארו במצב קיפאון.\n\nפתרון למניעת קיפאון:\nכדי למנוע קיפאון בתרחיש של רכישת משאבים מרובים, אנו חייבים למנוע את התנאי של \"המתנה מעגלית\" (Circular Wait). הדרך הנפוצה והיעילה ביותר לעשות זאת היא להטיל סדר גלובלי (total order) על המשאבים. כלומר, חוטים חייבים תמיד לרכוש את המשאבים לפי סדר קבוע מראש.\n\nבמקרה שלנו, מכיוון שלכל משאב יש אינדקס מספרי ייחודי, נוכל להשתמש באינדקסים אלה כדי להגדיר את הסדר. הפתרון הוא תמיד לנעול את המנעול של המשאב בעל האינדקס הקטן יותר ראשון, ולאחר מכן לנעול את המנעול של המשאב בעל האינדקס הגדול יותר.\n\nפירוט המימוש:\n1.  **קביעת סדר רכישה:** לפני ביצוע פעולות הנעילה, אנו קובעים מי מהאינדקסים `idx1` ו-`idx2` הוא הקטן ומי הגדול. נגדיר `first_idx` להיות `min(idx1, idx2)` ו-`second_idx` להיות `max(idx1, idx2)`.\n2.  **נעילה לפי סדר:** אנו קוראים ל-`pthread_mutex_lock` עבור `mutexes[first_idx]` ולאחר מכן עבור `mutexes[second_idx]`.\n3.  **שחרור:** בעת שחרור המנעולים, מומלץ לשחרר בסדר הפוך מסדר הנעילה (כלומר, קודם את `second_idx` ואז את `first_idx`), אף על פי שסדר השחרור פחות קריטי למניעת קיפאון.\n\nעל ידי הקפדה על סדר רכישה אחיד זה, מובטח שלא תיווצר שרשרת המתנה מעגלית. אם חוט T1 צריך את R_A ו-R_B, וחוט T2 צריך את R_B ו-R_A, שניהם ינסו קודם לנעול את `min(A,B)` ולאחר מכן את `max(A,B)`. החוט שיצליח לנעול את `min(A,B)` ראשון ימשיך לנעול את `max(A,B)`, ואילו החוט השני ימתין בסבלנות עד ש-`min(A,B)` ישוחרר. אין מצב שבו כל חוט מחזיק במשאב שנדרש על ידי האחר וממתין למשאב המוחזק על ידי האחר, ובכך נמנע קיפאון.\n\n```c\nvoid acquire_two_resources(int idx1, int idx2, pthread_mutex_t* mutexes[]) {\n    // For this problem, we assume idx1 and idx2 are distinct and valid indices.\n    // If idx1 == idx2, locking the same non-recursive mutex twice would cause a deadlock.\n    \n    // Impose an order to prevent deadlock: always lock the smaller index first.\n    int first_idx = (idx1 < idx2) ? idx1 : idx2;\n    int second_idx = (idx1 > idx2) ? idx1 : idx2;\n\n    pthread_mutex_lock(mutexes[first_idx]);\n    pthread_mutex_lock(mutexes[second_idx]);\n}\n\nvoid release_two_resources(int idx1, int idx2, pthread_mutex_t* mutexes[]) {\n    // It's good practice to unlock in the reverse order of locking,\n    // or at least consistently. Here, locking order was first_idx then second_idx.\n    // So, unlock second_idx then first_idx.\n    int first_idx = (idx1 < idx2) ? idx1 : idx2;\n    int second_idx = (idx1 > idx2) ? idx1 : idx2;\n\n    pthread_mutex_unlock(mutexes[second_idx]);\n    pthread_mutex_unlock(mutexes[first_idx]);\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0426__Deadlocks__CodeAnalysis__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:28:27", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Atomic Operations", "Resource Allocation"], "content": {"text": "במערכת נתונה, ישנם שני משאבים מסוגים שונים, `משאב A` ו-`משאב B`. כל משאב קיים במופע יחיד. תהליכים (או חוטים) במערכת נדרשים לרכוש את שני המשאבים, `משאב A` ו-`משאב B`, על מנת לבצע משימה כלשהי. לרשותנו עומדות שתי פעולות אטומיות בלבד: `TestAndSet` ו-`atomic_release`.\n\nהפעולה `TestAndSet(int *lock_ptr)` מבצעת באופן אטומי את הפעולות הבאות: היא קובעת את הערך של `*lock_ptr` ל-1, ומחזירה את ערכו הקודם (לפני השינוי). אם `*lock_ptr` היה 0, המשאב היה פנוי וכעת נתפס. אם `*lock_ptr` היה 1, המשאב כבר היה תפוס.\n\nהפעולה `atomic_release(int *lock_ptr)` מבצעת באופן אטומי את הפעולה הבאה: היא קובעת את הערך של `*lock_ptr` ל-0, ובכך משחררת את המשאב.\n\nנתון קטע הקוד הבא המנסה לרכוש את שני המשאבים:\n", "code_snippet": "extern int TestAndSet(int *lock_ptr);\nextern void atomic_release(int *lock_ptr);\n\n// משתנים גלובליים המייצגים את מצב המשאבים (0 = פנוי, 1 = תפוס)\nint resource_A = 0; \nint resource_B = 0; \n\nvoid acquire_two_resources_naive() {\n    while (TestAndSet(&resource_A) == 1); // נסה לרכוש את משאב A\n    while (TestAndSet(&resource_B) == 1); // נסה לרכוש את משאב B\n}\n\nvoid release_two_resources() {\n    atomic_release(&resource_B);\n    atomic_release(&resource_A);\n}\n", "options": null}, "sub_questions": [{"id": "1.1", "text": "א. נתח את קטע הקוד `acquire_two_resources_naive()` והסבר מדוע הוא עלול לגרום למצב של קיפאון (Deadlock) במערכת. ציין אילו תנאים לקיפאון מתקיימים.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "ב. כתוב מחדש את הפונקציות `acquire_two_resources()` ו-`release_two_resources()` כך שימנעו קיפאון, תוך שימוש אך ורק בפעולות האטומיות `TestAndSet` ו-`atomic_release`. המימוש חייב להבטיח שאם חוט לא מצליח לרכוש את שני המשאבים יחד, הוא לא יחזיק באף אחד מהם (כלומר, לא תתקיים החזקה והמתנה חלקית). קוד המימוש צריך להיות יעיל ככל האפשר.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\nא. ניתוח `acquire_two_resources_naive()` וגורמי קיפאון:\nהפונקציה `acquire_two_resources_naive()` אכן עלולה לגרום למצב של קיפאון (Deadlock) במערכת. קיפאון מתרחש כאשר ארבעה תנאים הכרחיים מתקיימים בו-זמנית:\n\n1.  **מניעה הדדית (Mutual Exclusion)**: תנאי זה מתקיים. פעולות `TestAndSet` מבטיחות שרק חוט אחד יכול להחזיק במשאב A ורק חוט אחד יכול להחזיק במשאב B בכל רגע נתון. אם חוט מנסה לרכוש משאב שכבר תפוס, `TestAndSet` יחזיר 1 והחוט ימשיך בלולאת המתנה פעילה (busy-waiting) עד שהמשאב ישתחרר.\n\n2.  **החזקה והמתנה (Hold and Wait)**: תנאי זה מתקיים. חוט יכול לרכוש את `משאב A` (כלומר, להחזיק בו), ולאחר מכן לנסות לרכוש את `משאב B`. אם `משאב B` תפוס על ידי חוט אחר, החוט הראשון ימתין ל-`משאב B` תוך כדי שהוא ממשיך להחזיק ב-`משאב A`.\n\n3.  **אי-נשללות (No Preemption)**: תנאי זה מתקיים. משאבים אינם נשללים מחוט בכוח. חוט חייב לשחרר את המשאבים מרצונו החופשי באמצעות `atomic_release` לאחר שסיים את השימוש בהם.\n\n4.  **המתנה מעגלית (Circular Wait)**: תנאי זה עלול להיווצר. נניח שני חוטים, T1 ו-T2:\n    *   T1 מבצע בהצלחה `TestAndSet(&resource_A)` (תופס את A).\n    *   T2 מבצע בהצלחה `TestAndSet(&resource_B)` (תופס את B).\n    *   כעת, T1 מנסה לבצע `TestAndSet(&resource_B)`, אך מגלה ש-B תפוס על ידי T2. T1 נכנס למצב המתנה על B.\n    *   בו-זמנית, T2 מנסה לבצע `TestAndSet(&resource_A)`, אך מגלה ש-A תפוס על ידי T1. T2 נכנס למצב המתנה על A.\n    *   במצב זה, T1 ממתין ל-T2 שישחרר את B, ו-T2 ממתין ל-T1 שישחרר את A. נוצרת שרשרת המתנה מעגלית, ושני החוטים נמצאים בקיפאון.\n\nב. מימוש פונקציות `acquire_two_resources()` ו-`release_two_resources()` למניעת קיפאון:\nכדי למנוע קיפאון, נשבור את תנאי ה\"החזקה והמתנה\" על ידי הבטחה שחוט לא יחזיק באף משאב אם הוא לא מצליח לרכוש את כל המשאבים הנדרשים לו באופן מיידי. אסטרטגיה נפוצה לכך היא \"ניסיון וביטול\" (try-and-rollback) או רכישה בסדר קבוע ומוסכם. נבחר באסטרטגיה של רכישה בסדר קבוע (תמיד A ואז B) בשילוב עם מנגנון ביטול:\n\n```c\nvoid acquire_two_resources() {\n    while (1) {\n        // נסה לרכוש את משאב A\n        while (TestAndSet(&resource_A) == 1); // המתן באופן פעיל עד ש-A יהיה פנוי ותפוס אותו\n\n        // משאב A נתפס. כעת נסה לרכוש את משאב B.\n        if (TestAndSet(&resource_B) == 0) {\n            // אם B היה פנוי ונתפס בהצלחה, רכשנו את שני המשאבים.\n            return; // יציאה מהלולאה, שני המשאבים בידינו.\n        } else {\n            // משאב B היה תפוס. שחרר את משאב A וחזור לנסות לרכוש את שניהם מההתחלה.\n            atomic_release(&resource_A);\n            // ניתן להוסיף כאן השהיה קצרה (למשל, thread_yield) כדי למנוע בזבוז משאבי מעבד ב-busy-waiting אגרסיבי,\n            // אך מכיוון שלא ניתנו פרימיטיבים נוספים, נסתפק בלולאה.\n        }\n    }\n}\n\nvoid release_two_resources() {\n    atomic_release(&resource_B); // שחרר את משאב B\n    atomic_release(&resource_A); // שחרר את משאב A\n}\n```\n\n**הסבר לפתרון:**\n\n1.  **מניעת החזקה והמתנה חלקית:** המימוש מבטיח שחוט שרוכש את `משאב A` אך מגלה ש-`משאב B` תפוס, ישחרר מיד את `משאב A` לפני שהוא מנסה שוב. בכך, חוט אף פעם לא יחזיק במשאב אחד (A) וימתין למשאב אחר (B) לזמן בלתי מוגבל. זה שובר את תנאי ה\"החזקה והמתנה\" באופן שמבטיח שחוט לא ייכנס למצב המתנה מעגלית.\n\n2.  **סדר רכישה קבוע:** כל החוטים מנסים לרכוש את המשאבים באותו סדר: תמיד `משאב A` תחילה, ורק לאחר מכן `משאב B`. זהו תנאי מונע קיפאון קלאסי בפני עצמו, אך במקרה שלנו הוא משולב עם מנגנון ה\"ניסיון וביטול\" כדי להתמודד עם מצב שבו המשאב השני אינו זמין מיד. אם כל החוטים ינסו לרכוש A ואז B, לעולם לא תיווצר המתנה מעגלית שבה חוט אחד מחזיק ב-A ומחכה ל-B, וחוט אחר מחזיק ב-B ומחכה ל-A, מכיוון שחוט שיתפוס את B ראשון לעולם לא ינסה לתפוס את A (הוא תמיד ינסה A ואז B).\n\n3.  **חופש מקיפאון:** המימוש מבטיח חופש מקיפאון. גם אם חוטים רבים מתחרים על המשאבים, בסופו של דבר אחד מהם יצליח לתפוס את שניהם, משום שהם משחררים משאבים שהוחזקו חלקית, ובכך מאפשרים לחוטים אחרים להתקדם. אין מצב שבו קבוצת חוטים ממתינה זה לזה באופן בלתי הפיך.\n\n4.  **יעילות (בהינתן המגבלות):** בהיעדר פרימיטיבים כמו `sleep` או `yield`, השימוש ב-`while (TestAndSet(...) == 1);` הוא צורת busy-waiting. למרות שזה לא יעיל מבחינת ניצול מעבד, זהו המימוש היעיל ביותר האפשרי עם הפרימיטיבים האטומיים הנתונים בלבד, מכיוון שאין דרך אחרת להמתין לשחרור משאב מבלי לצרוך זמן מעבד בלולאה."}, "difficulty_estimation": "Hard", "_source_file": "0427__Deadlocks__CodeAnalysis__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:29:10", "_subject": "Concurrency"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Resource Management", "Concurrency"], "content": {"text": "מערכת הפעלה מנהלת שני סוגי משאבים: ResourceA ו-ResourceB. לכל סוג משאב קיים מספר מוגבל של יחידות זמינות. תהליכים במערכת נדרשים לתפוס יחידה אחת מכל סוג משאב (אחת מ-ResourceA ואחת מ-ResourceB) כדי לבצע עבודה מסוימת, ולאחר מכן לשחרר אותם. הקוד הבא מציג מימוש של מנגנון תפיסה ושחרור של המשאבים, ופונקציית תהליך המשתמשת בהם. נתון כי עבור ResourceA ו-ResourceB, מספר היחידות הזמינות ההתחלתי הוא 1 לכל אחד (כלומר, `init_resource(&resourceA, 1);` ו-`init_resource(&resourceB, 1);`), וכי קיימים שני תהליכים (חוטים) הפועלים במקביל.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n#include <unistd.h> // For sleep\n\n// Resource structure definition\ntypedef struct {\n    pthread_mutex_t lock;\n    pthread_cond_t cond;\n    int available_count;\n    int total_count;\n} Resource;\n\n// Global resources (for simplicity in this example)\nResource resourceA;\nResource resourceB;\n\n// Function to initialize a resource\nvoid init_resource(Resource* res, int count) {\n    pthread_mutex_init(&res->lock, NULL);\n    pthread_cond_init(&res->cond, NULL);\n    res->available_count = count;\n    res->total_count = count;\n}\n\n// Function to acquire a resource instance\nvoid acquire_resource(Resource* res) {\n    pthread_mutex_lock(&res->lock);\n    while (res->available_count <= 0) {\n        pthread_cond_wait(&res->cond, &res->lock);\n    }\n    res->available_count--;\n    pthread_mutex_unlock(&res->lock);\n}\n\n// Function to release a resource instance\nvoid release_resource(Resource* res) {\n    pthread_mutex_lock(&res->lock);\n    res->available_count++;\n    pthread_cond_signal(&res->cond); // Signal one waiting thread\n    pthread_mutex_unlock(&res->lock);\n}\n\n// Thread function that attempts to acquire both resources\nvoid* thread_func(void* arg) {\n    long thread_id = (long)arg;\n\n    // Simulate different acquisition orders based on thread ID\n    if (thread_id % 2 == 0) { // Even threads acquire A then B\n        acquire_resource(&resourceA);\n        sleep(1); // Simulate some work or delay\n        acquire_resource(&resourceB);\n        \n        // Simulate critical section work\n        sleep(2);\n\n        release_resource(&resourceB);\n        release_resource(&resourceA);\n    } else { // Odd threads acquire B then A\n        acquire_resource(&resourceB);\n        sleep(1); // Simulate some work or delay\n        acquire_resource(&resourceA);\n        \n        // Simulate critical section work\n        sleep(2);\n\n        release_resource(&resourceA);\n        release_resource(&resourceB);\n    }\n    return NULL;\n}"}, "sub_questions": [{"id": "101.1", "text": "האם ייתכן מצב של קיפאון (Deadlock) במערכת המתוארת? נמקו את תשובתכם בהתבסס על ארבעת התנאים ההכרחיים לקיפאון של קופמן (Coffman Conditions).", "code_snippet": null, "options": null}, {"id": "101.2", "text": "אם אכן ייתכן קיפאון, הציעו שינוי קוד מינימלי למנגנון תפיסת המשאבים שימנע קיפאון, תוך שמירה על עקרונות המניעה ההדדית ושימוש יעיל במשאבים. הציגו את הקוד המעודכן והסבירו מדוע הוא פותר את הבעיה.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. כן, ייתכן מצב של קיפאון (Deadlock) במערכת המתוארת. נבחן את ארבעת התנאים ההכרחיים לקיפאון:\n   א. מניעה הדדית (Mutual Exclusion): מתקיים. כל יחידת משאב (ResourceA או ResourceB) ניתנת לתפיסה בלעדית על ידי תהליך אחד בלבד בכל רגע נתון. המנעולים (`pthread_mutex_t`) והמונה `available_count` מבטיחים זאת.\n   ב. אחיזה והמתנה (Hold and Wait): מתקיים. תהליך (חוט) יכול לתפוס משאב אחד (לדוגמה, ResourceA) ולהמתין לתפיסת משאב נוסף (ResourceB) תוך כדי שהוא מחזיק במשאב הראשון.\n   ג. אי-הפקעה (No Preemption): מתקיים. ברגע שתהליך תפס משאב, המשאב לא יכול להילקח ממנו בכוח; התהליך חייב לשחרר אותו מרצונו.\n   ד. המתנה מעגלית (Circular Wait): מתקיים. בתרחיש של שני חוטים ושתי יחידות משאב (אחת מכל סוג), אם חוט 0 (זוגי) תופס את ResourceA וממתין ל-ResourceB, ובמקביל חוט 1 (אי-זוגי) תופס את ResourceB וממתין ל-ResourceA, נוצר מעגל המתנה. חוט 0 ממתין למשאב שחוט 1 מחזיק, וחוט 1 ממתין למשאב שחוט 0 מחזיק.\n\n2. כדי למנוע קיפאון, ניתן לשנות את הקוד כך שימנע את תנאי ההמתנה המעגלית על ידי אכיפת סדר עקבי לתפיסת המשאבים. כלומר, כל התהליכים יתפסו את ResourceA תחילה, ורק לאחר מכן את ResourceB. שינוי זה מבטיח שלא תיווצר שרשרת המתנה מעגלית.\n\n   הקוד המעודכן לפונקציית `thread_func` ייראה כך:\n   ```c\nvoid* thread_func(void* arg) {\n    long thread_id = (long)arg;\n\n    // כל החוטים תופסים את ResourceA ואז את ResourceB\n    acquire_resource(&resourceA);\n    sleep(1); // לדמות עבודה או עיכוב\n    acquire_resource(&resourceB);\n    \n    // לדמות עבודה בקטע הקריטי\n    sleep(2);\n\n    release_resource(&resourceB);\n    release_resource(&resourceA);\n    \n    return NULL;\n}\n   ```\n   **הסבר לפתרון:**\n   שינוי זה מונע את תנאי ההמתנה המעגלית. כעת, כל החוטים מנסים לתפוס את ResourceA ראשונים. אם יש רק יחידה אחת של ResourceA, רק חוט אחד יצליח לתפוס אותה. חוט זה ימשיך לתפוס את ResourceB. לאחר מכן, הוא ישחרר את שני המשאבים, מה שיאפשר לחוט אחר לתפוס את ResourceA. לעולם לא ייווצר מצב שבו חוט אחד מחזיק ב-ResourceA וממתין ל-ResourceB, בעוד חוט אחר מחזיק ב-ResourceB וממתין ל-ResourceA, מכיוון שכולם מנסים לתפוס את ResourceA קודם. בכך, אנו מבטלים את האפשרות להמתנה מעגלית ושומרים על שאר התנאים ההכרחיים לקיפאון, שהם לגיטימיים במערכות המשתמשות במשאבים משותפים."}, "difficulty_estimation": "Hard", "_source_file": "0428__Deadlocks__CodeAnalysis__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:48:22", "_subject": "Concurrency"}, {"id": 4, "type": "CodeAnalysis", "topic": ["Deadlocks", "Resource Allocation", "Synchronization", "Atomic Operations"], "content": {"text": "מנהל משאבים חסין קיפאון\n\nבמערכת קיימים R משאבים שונים, הממוספרים מ-0 עד R-1. כל משאב מיוצג על ידי משתנה שלם (int) בזיכרון, כאשר 0 מציין שהמשאב פנוי ו-1 מציין שהוא תפוס. מספר רב של חוטים (threads) מתחרים על תפיסת קבוצות של משאבים. כל חוט מעוניין לתפוס קבוצה ספציפית של M משאבים. נדרש לממש פונקציות לתפיסה ולשחרור של קבוצת משאבים באופן שימנע קיפאון (deadlock).\n\nלרשותכם עומדת פקודת חומרה אטומית אחת בלבד: test_and_set. פקודה זו מקבלת מצביע למשתנה שלם, קובעת את ערכו ל-1, ומחזירה את ערכו הקודם באופן אטומי. אם הערך הקודם היה 0, המנעול נתפס בהצלחה. אם היה 1, המנעול כבר היה תפוס.\n\nהבהרה: תיאור הפעולה הוא קוד C לצורך הסבר בלבד. פעולת המעבד מבצעת זאת באופן אטומי ולא בכמה פעולות. אין להשתמש באובייקטי סנכרון או פעולות מעבד אטומיות אחרות מלבד test_and_set.\n\nממשו את הפונקציות acquire_resources_deadlock_safe ו-release_resources תחת ההנחות הבאות:\n1. המשאבים הגלובליים resources מוגדרים ומאותחלים ל-0.\n2. מערך ה-resource_ids המועבר לפונקציית acquire_resources_deadlock_safe ממוין כבר בסדר עולה של מזהי המשאבים.\n3. יש לדאוג למניעת קיפאון (deadlock) וחופש מקיפאון (livelock) ככל הניתן (אך busy-waiting מותר).", "code_snippet": "#include <stdbool.h>\n#include <stdlib.h>\n\n#define MAX_RESOURCES 100 // Example maximum number of resources\nint resources[MAX_RESOURCES]; // Global array of resource states (0: unlocked, 1: locked)\n\n// Atomic hardware instruction (for explanation only)\nint test_and_set(int *lock_ptr) {\n    int old_val = *lock_ptr;\n    *lock_ptr = 1;\n    return old_val;\n}\n\n// Function to initialize resources (e.g., in main)\nvoid init_resources(int num_resources) {\n    for (int i = 0; i < num_resources; ++i) {\n        resources[i] = 0;\n    }\n}\n\n// Implement these two functions:\nvoid acquire_resources_deadlock_safe(int *resource_ids, int count) {\n    // Your implementation here\n}\n\nvoid release_resources(int *resource_ids, int count) {\n    // Your implementation here\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון מבוסס על שתי אסטרטגיות למניעת קיפאון: סדר תפיסת משאבים (Resource Ordering) וגישת 'תפוס הכל או לא כלום' (Acquire All or Nothing).\n\n1.  **סדר תפיסת משאבים (Resource Ordering):** כדי למנוע המתנה מעגלית (Circular Wait), אשר היא אחד מארבעת התנאים ההכרחיים לקיפאון, אנו דורשים מכל החוטים לתפוס את המשאבים בסדר עולה של מזהיהם. ההנחה בשאלה היא שמערך ה-`resource_ids` כבר ממוין, מה שמפשט את המימוש. אם המערך לא היה ממוין, היה צורך למיין אותו בתחילת הפונקציה `acquire_resources_deadlock_safe`.\n\n2.  **'תפוס הכל או לא כלום' (Acquire All or Nothing):** כדי למנוע את תנאי 'החזק והמתן' (Hold and Wait), חוט שמנסה לתפוס קבוצת משאבים חייב להצליח לתפוס את כולם. אם בשלב כלשהו הוא נתקל במשאב תפוס, הוא משחרר את כל המשאבים שתפס עד לאותה נקודה ומתחיל מחדש את ניסיון התפיסה. זה מבטיח שחוט לעולם לא יחזיק במשאב אחד וימתין לאחר, ובכך מונע קיפאון.\n\n**מימוש `acquire_resources_deadlock_safe`:**\nהפונקציה נכנסת ללולאה אינסופית (while true) המייצגת ניסיונות חוזרים ונשנים לתפוס את המשאבים. בתוך הלולאה, היא עוברת על המשאבים לפי הסדר הממוין. עבור כל משאב, היא מנסה לתפוס אותו באמצעות `test_and_set`. אם ה-`test_and_set` מחזיר 0, המשאב נתפס בהצלחה והחוט ממשיך למשאב הבא. אם הוא מחזיר 1 (כלומר המשאב כבר תפוס), החוט מבין שהוא לא יכול להשלים את התפיסה הנוכחית. במקרה זה, הוא משחרר את כל המשאבים שתפס בהצלחה בניסיון הנוכחי (באמצעות לולאה פנימית) ושובר את הלולאה הפנימית כדי להתחיל ניסיון תפיסה חדש מההתחלה.\nלאחר יציאה מהלולאה הפנימית (או אם כל המשאבים נתפסו), נבדק דגל `acquired_all`. אם הוא `true`, כל המשאבים נתפסו בהצלחה והפונקציה מסתיימת. אחרת, הלולאה החיצונית ממשיכה לניסיון תפיסה נוסף.\n\n**מימוש `release_resources`:**\nפונקציה זו פשוט עוברת על כל המשאבים ברשימה ומשחררת אותם על ידי הגדרת ערכם ל-0. פעולה זו בטוחה מכיוון שהחוט הוא הבעלים הבלעדי של המשאבים שהוא משחרר, ולכן אין צורך בפעולה אטומית לשחרור (אך שימוש ב-CAS להגדרת 0 היה גם אפשרי).\n\n**חופש מקיפאון (Livelock):** הפתרון משתמש ב-busy-waiting. במקרים של עומס גבוה, מספר חוטים עלולים לנסות לתפוס משאבים, להיתקל במשאב תפוס, לשחרר ולנסות שוב במהירות, מה שעלול להוביל לבזבוז משאבי מעבד. כדי למזער livelock, ניתן להוסיף השהיה קצרה (למשל, `sched_yield()` או `usleep()`) לפני כל ניסיון חוזר לתפיסת משאבים, אך זה לא נדרש במימוש הבסיסי למניעת קיפאון.\n\n```c\n#include <stdbool.h>\n#include <stdlib.h>\n// For sched_yield() or usleep() if adding backoff\n// #include <sched.h>\n// #include <unistd.h>\n\n#define MAX_RESOURCES 100 \nint resources[MAX_RESOURCES]; \n\n// Atomic hardware instruction (for explanation only)\nint test_and_set(int *lock_ptr) {\n    int old_val = *lock_ptr;\n    *lock_ptr = 1;\n    return old_val;\n}\n\nvoid init_resources(int num_resources) {\n    for (int i = 0; i < num_resources; ++i) {\n        resources[i] = 0;\n    }\n}\n\nvoid acquire_resources_deadlock_safe(int *resource_ids, int count) {\n    while (true) {\n        bool acquired_all = true;\n        for (int i = 0; i < count; ++i) {\n            int res_id = resource_ids[i];\n            if (test_and_set(&resources[res_id]) == 1) {\n                // Failed to acquire this resource.\n                // Must release all resources acquired so far in this attempt\n                // and retry.\n                acquired_all = false;\n                for (int j = 0; j < i; ++j) {\n                    resources[resource_ids[j]] = 0; // Release (safe as owner)\n                }\n                // Optional: Add a short delay (e.g., sched_yield() or usleep()) before retrying to reduce busy-waiting\n                // sched_yield(); // Yield CPU to other threads\n                break; // Break from inner loop, retry outer loop\n            }\n        }\n        if (acquired_all) {\n            break; // Successfully acquired all resources\n        }\n    }\n}\n\nvoid release_resources(int *resource_ids, int count) {\n    for (int i = 0; i < count; ++i) {\n        resources[resource_ids[i]] = 0; // Release (safe as owner)\n    }\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0429__Deadlocks__CodeAnalysis__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:30:12", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Resource Allocation", "Atomic Operations"], "content": {"text": "במערכת מרובת חוטים (threads), קיימים N_RESOURCES משאבים משותפים, ממוספרים מ-0 עד N_RESOURCES-1. מצבו של כל משאב i מיוצג על ידי המשתנה הגלובלי resource_status[i], כאשר 0 מציין משאב פנוי ו-1 מציין משאב תפוס. חוטים נדרשים לרכוש מספר משאבים בו-זמנית על מנת לבצע משימותיהם. לרשותנו עומדת פקודת חומרה אטומית אחת בלבד, compare_and_swap, אשר פועלת באופן הבא: int compare_and_swap(int* ptr, int old_val, int new_val). פקודה זו משווה באופן אטומי את הערך בכתובת ptr לערך old_val. אם הם זהים, היא מחליפה את הערך ב-ptr ל-new_val. הפקודה מחזירה את הערך שהיה ב-ptr *לפני* הניסיון לבצע את ההחלפה. אסור להשתמש באובייקטי סנכרון אחרים (כגון mutexes או semaphores) או בפעולות אטומיות אחרות מלבד compare_and_swap. יש לממש את הפונקציות acquire_multiple_resources ו-release_multiple_resources כך שתמנענה מצב של קיפאון (deadlock) ותאפשרנה רכישה ושחרור תקינים של קבוצת משאבים.", "code_snippet": "#include <stdlib.h>    // For qsort, malloc, free\n#include <unistd.h>    // For usleep (optional for backoff)\n\n// Assume N_RESOURCES is a global constant\n#define N_RESOURCES 10 // Example value, can be any positive integer\n\n// Global array representing resource status\n// 0 = free, 1 = taken\nint resource_status[N_RESOURCES];\n\n// This function represents the atomic hardware instruction compare_and_swap.\n// For implementation, you will use __sync_val_compare_and_swap (GCC intrinsic).\n// int compare_and_swap(int* ptr, int old_val, int new_val); // Conceptual signature\n\n// Helper for qsort (provided for convenience)\nint compare_ints(const void *a, const void *b) {\n    return (*(int*)a - *(int*)b);\n}\n\n// You need to implement these functions:\nvoid acquire_multiple_resources(int* resources_needed, int num_resources) {\n    // Your implementation here\n}\n\nvoid release_multiple_resources(int* resources_held, int num_resources) {\n    // Your implementation here\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון מבוסס על מניעת קיפאון באמצעות עמידה בתנאי הסדר הכולל (Total Ordering) לרכישת משאבים. כאשר חוט נדרש לרכוש מספר משאבים, הוא ינסה לרכוש אותם תמיד באותו סדר קבוע ומוגדר מראש, במקרה זה, לפי מזהה המשאב (ID) בסדר עולה.\n\n**פונקציית `acquire_multiple_resources`:**\n1.  **מיון משאבים:** ראשית, הפונקציה יוצרת עותק מקומי של רשימת המשאבים הנדרשים וממיינת אותם בסדר עולה. זה מבטיח שכל החוטים ינסו לרכוש את אותם משאבים באותו סדר, ובכך נמנע מצב שבו חוטים מחכים זה לזה במעגל (\"hold and wait\" ו-\"circular wait\").\n2.  **לולאת ניסיון-חזרה (Retry Loop):** הפונקציה נכנסת ללולאה אינסופית שמנסה לרכוש את כל המשאבים. לולאה זו נחוצה מכיוון שייתכן שחלק מהמשאבים אינם פנויים בניסיון הראשון.\n3.  **רכישה סדרתית:** בתוך הלולאה, החוט עובר על רשימת המשאבים הממוינת ומנסה לרכוש כל אחד מהם באמצעות `compare_and_swap`. הקריאה `__sync_val_compare_and_swap(&resource_status[resource_id], 0, 1)` מנסה לשנות את מצב המשאב מ-0 (פנוי) ל-1 (תפוס). אם הפעולה מחזירה 0, המשאב נרכש בהצלחה.\n4.  **שחרור והמתנה (Rollback and Back-off):** אם הפעולה מחזירה 1, המשאב כבר היה תפוס על ידי חוט אחר. במקרה זה, החוט נכשל ברכישת המשאב הנוכחי. עליו לשחרר באופן מיידי את כל המשאבים שכבר רכש בניסיון הנוכחי. פעולה זו מונעת את תנאי \"החזק והמתן\" (Hold and Wait) שמוביל לקיפאון. לאחר השחרור, החוט ממתין פרק זמן קצר (באמצעות `usleep`) כדי להפחית עומס ולמנוע מצב של livelock, ואז מנסה לרכוש מחדש את כל המשאבים מההתחלה.\n5.  **הצלחה:** אם החוט הצליח לרכוש את כל המשאבים ברשימה, הוא יוצא מלולאת הניסיון-חזרה.\n\n**פונקציית `release_multiple_resources`:**\nפונקציה זו פשוט עוברת על רשימת המשאבים שהוחזקו ומשחררת אותם. השחרור מתבצע באמצעות `__sync_val_compare_and_swap`, כאשר החוט מוודא שהמשאב אכן היה תפוס (ערך 1) לפני שחרורו (הגדרת ערך 0). אין צורך בסדר מסוים לשחרור, מכיוון שהחוט מחזיק באופן בלעדי במשאבים אלו.\n\n```c\n#include <stdlib.h>    // For qsort, malloc, free\n#include <unistd.h>    // For usleep\n#include <stdio.h>     // For fprintf, exit (error handling)\n\n// Assume N_RESOURCES is a global constant\n#define N_RESOURCES 10 \n\n// Global array representing resource status\n// 0 = free, 1 = taken\nint resource_status[N_RESOURCES];\n\n// Helper for qsort\nint compare_ints(const void *a, const void *b) {\n    return (*(int*)a - *(int*)b);\n}\n\nvoid acquire_multiple_resources(int* resources_needed, int num_resources) {\n    // Create a local sorted copy to ensure fixed acquisition order\n    int* sorted_resources = (int*)malloc(sizeof(int) * num_resources);\n    if (!sorted_resources) {\n        fprintf(stderr, \"Memory allocation failed for sorted_resources.\\n\");\n        exit(EXIT_FAILURE);\n    }\n    for (int i = 0; i < num_resources; ++i) {\n        sorted_resources[i] = resources_needed[i];\n    }\n    qsort(sorted_resources, num_resources, sizeof(int), compare_ints);\n\n    int acquired_count;\n\n    while (1) { // Retry loop for deadlock prevention\n        acquired_count = 0;\n        int failed_to_acquire = 0;\n\n        for (int i = 0; i < num_resources; ++i) {\n            int resource_id = sorted_resources[i];\n            // Try to acquire the resource using compare_and_swap\n            // __sync_val_compare_and_swap(ptr, old_val, new_val) returns the original value of *ptr\n            if (__sync_val_compare_and_swap(&resource_status[resource_id], 0, 1) == 0) {\n                // Successfully acquired\n                acquired_count++;\n            } else {\n                // Resource was already taken\n                failed_to_acquire = 1;\n                break; // Break from inner loop, need to release and retry\n            }\n        }\n\n        if (!failed_to_acquire) {\n            // All resources successfully acquired\n            break; // Exit the retry loop\n        } else {\n            // Failed to acquire all. Release the ones we did acquire (rollback).\n            for (int j = 0; j < acquired_count; ++j) {\n                int resource_id_to_release = sorted_resources[j];\n                // Release using compare_and_swap: set from 1 (taken) to 0 (free)\n                __sync_val_compare_and_swap(&resource_status[resource_id_to_release], 1, 0);\n            }\n            // Optional: small back-off to reduce contention and livelock risk\n            usleep(rand() % 1000); // Sleep for up to 1ms\n        }\n    }\n\n    free(sorted_resources);\n}\n\nvoid release_multiple_resources(int* resources_held, int num_resources) {\n    // Releasing doesn't require a specific order, as we own them exclusively.\n    // We use compare_and_swap to ensure the resource was indeed held by us (value 1)\n    // before setting it to 0 (free).\n    for (int i = 0; i < num_resources; ++i) {\n        int resource_id = resources_held[i];\n        __sync_val_compare_and_swap(&resource_status[resource_id], 1, 0);\n    }\n}\n```", "difficulty_estimation": "Hard"}, "_source_file": "0430__Deadlocks__CodeAnalysis__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:30:52", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Deadlocks", "Concurrency", "Synchronization", "Mutexes"], "content": {"text": "יישום מרובה חוטים מדמה מערכת של N יחידות עיבוד המסודרות בטבעת. כל יחידת עיבוד מוגנת על ידי מנעול (mutex). כדי לבצע משימה, חוט צריך לרכוש שתי יחידות עיבוד סמוכות. נתון קוד המממש את ההתנהגות הזו. ענה על השאלות הבאות:", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h> // For sleep\n\n#define NUM_UNITS 5 // N\n\npthread_mutex_t units_mutex[NUM_UNITS];\n\nvoid* worker_thread(void* arg) {\n    int id = *(int*)arg;\n    int unit1 = id;\n    int unit2 = (id + 1) % NUM_UNITS;\n\n    printf(\"Thread %d trying to acquire unit %d and unit %d\\n\", id, unit1, unit2);\n\n    pthread_mutex_lock(&units_mutex[unit1]);\n    printf(\"Thread %d acquired unit %d\\n\", id, unit1);\n    \n    // Simulate some work or contention\n    usleep(10000); // 10ms\n\n    pthread_mutex_lock(&units_mutex[unit2]);\n    printf(\"Thread %d acquired unit %d and unit %d\\n\", id, unit1, unit2);\n\n    // Simulate work in critical section\n    printf(\"Thread %d working with units %d and %d\\n\", id, unit1, unit2);\n    usleep(50000); // 50ms\n\n    pthread_mutex_unlock(&units_mutex[unit2]);\n    printf(\"Thread %d released unit %d\\n\", id, unit2);\n\n    pthread_mutex_unlock(&units_mutex[unit1]);\n    printf(\"Thread %d released unit %d\\n\", id, unit1);\n\n    free(arg);\n    return NULL;\n}\n\nint main() {\n    pthread_t threads[NUM_UNITS];\n    int* thread_ids[NUM_UNITS];\n\n    for (int i = 0; i < NUM_UNITS; ++i) {\n        pthread_mutex_init(&units_mutex[i], NULL);\n    }\n\n    for (int i = 0; i < NUM_UNITS; ++i) {\n        thread_ids[i] = (int*)malloc(sizeof(int));\n        *thread_ids[i] = i;\n        pthread_create(&threads[i], NULL, worker_thread, thread_ids[i]);\n    }\n\n    for (int i = 0; i < NUM_UNITS; ++i) {\n        pthread_join(threads[i], NULL);\n    }\n\n    for (int i = 0; i < NUM_UNITS; ++i) {\n        pthread_mutex_destroy(&units_mutex[i]);\n    }\n\n    printf(\"All threads finished.\\n\");\n    return 0;\n}"}, "sub_questions": [{"id": "1.1", "text": "האם הקוד הנתון עלול לסבול מקיפאון (Deadlock)? אם כן, הסבר את התנאים המובילים לקיפאון.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "שנה את פונקציית `worker_thread` כדי למנוע קיפאון, תוך שמירה על מניעה הדדית (mutual exclusion) ליחידות הסמוכות והבטחת התקדמות (progress). מותר לך להשתמש רק במערך המנעולים הקיים (`units_mutex`) ואין להוסיף אובייקטי סנכרון חדשים או לשנות את גודל `NUM_UNITS`.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1: כן, הקוד הנתון עלול לסבול מקיפאון. תרחיש קיפאון קלאסי יכול להתרחש כאשר כל החוטים מתחילים לפעול בערך באותו זמן ומנסים לרכוש את המנעולים שלהם.\n\nהקיפאון מתרחש מכיוון שמתקיימים ארבעת התנאים ההכרחיים לקיפאון:\n1.  **מניעה הדדית (Mutual Exclusion):** כל מנעול (`units_mutex[i]`) מגן על יחידת עיבוד אחת וניתן להחזיק בו על ידי חוט אחד בלבד בכל רגע נתון.\n2.  **החזק והמתן (Hold and Wait):** כל חוט רוכש את המנעול הראשון שלו (`units_mutex[id]`) ומחזיק בו, ואז מנסה לרכוש את המנעול השני (`units_mutex[(id+1)%NUM_UNITS]`). בזמן שהוא ממתין למנעול השני, הוא ממשיך להחזיק במנעול הראשון.\n3.  **אין דריסה (No Preemption):** מנעולים אינם ניתנים לדריסה. ברגע שחוט רוכש מנעול, הוא יכול לשחרר אותו רק מרצונו.\n4.  **המתנה מעגלית (Circular Wait):** זהו התנאי הקריטי ביותר במקרה זה. אם כל `NUM_UNITS` החוטים יתחילו בו זמנית, כל חוט `id` ירכוש את `units_mutex[id]`. לאחר מכן, חוט `id` ינסה לרכוש את `units_mutex[(id+1)%NUM_UNITS]`, אשר מוחזק על ידי חוט `(id+1)%NUM_UNITS`. כך נוצרת שרשרת המתנה מעגלית: חוט 0 ממתין למנעול 1 (שמוחזק על ידי חוט 1), חוט 1 ממתין למנעול 2 (שמוחזק על ידי חוט 2), וכן הלאה, עד שחוט `NUM_UNITS-1` ממתין למנעול 0 (שמוחזק על ידי חוט 0). כתוצאה מכך, אף חוט לא יכול להתקדם, וכל המערכת נכנסת לקיפאון.\n\n1.2: כדי למנוע קיפאון, יש לשבור את תנאי ההמתנה המעגלית. הדרך הנפוצה והיעילה ביותר לעשות זאת במקרה זה, תוך שימוש במשאבים הקיימים בלבד, היא על ידי אכיפת סדר רכישת משאבים (Resource Ordering).\nהרעיון הוא להגדיר סדר גלובלי למנעולים ולדרוש מכל החוטים לרכוש אותם לפי סדר זה. במקרה שלנו, נבצע רכישה תמיד מהמנעול בעל האינדקס הנמוך יותר למנעול בעל האינדקס הגבוה יותר.\n\nעבור חוט `id` המבקש את יחידות `unit1_idx = id` ו-`unit2_idx = (id + 1) % NUM_UNITS`:\n1.  אם `unit1_idx < unit2_idx` (לדוגמה, חוט 0 רוצה יחידות 0 ו-1), החוט ירכוש קודם את `units_mutex[unit1_idx]` ואז את `units_mutex[unit2_idx]`.\n2.  אם `unit1_idx > unit2_idx` (המקרה המיוחד של חוט `NUM_UNITS-1` שרוצה יחידות `NUM_UNITS-1` ו-0), החוט ירכוש קודם את `units_mutex[unit2_idx]` (שהוא 0) ואז את `units_mutex[unit1_idx]` (שהוא `NUM_UNITS-1`).\n\nיישום זה מבטיח שאין המתנה מעגלית. אף חוט לא ימתין למשאב שמוחזק על ידי חוט אחר שימתין בעצמו למשאב שמוחזק על ידי החוט הראשון, מכיוון שסדר הרכישה גלובלי ומונע יצירת מעגל. לדוגמה, חוט `NUM_UNITS-1` לא ימתין למשאב 0 שמוחזק על ידי חוט 0, בעוד שחוט 0 ממתין למשאב 1. במקום זאת, חוט `NUM_UNITS-1` ינסה לרכוש קודם את משאב 0 (שמוחזק על ידי חוט 0), יחסם וימתין, בעוד שחוט 0 ירכוש את משאב 0 ולאחר מכן את משאב 1. הסדר המוגדר מראש מבטיח שכל חוט יצליח בסופו של דבר לרכוש את שני המנעולים שלו.\n\nהקוד המעודכן עבור `worker_thread`:\n```c\nvoid* worker_thread(void* arg) {\n    int id = *(int*)arg;\n    int unit1_idx = id;\n    int unit2_idx = (id + 1) % NUM_UNITS;\n\n    int first_lock_idx, second_lock_idx;\n\n    if (unit1_idx < unit2_idx) { \n        first_lock_idx = unit1_idx;\n        second_lock_idx = unit2_idx;\n    } else { // Handles the case where unit1_idx is NUM_UNITS-1 and unit2_idx is 0\n        first_lock_idx = unit2_idx; \n        second_lock_idx = unit1_idx;\n    }\n\n    printf(\"Thread %d trying to acquire unit %d and unit %d (ordered: %d then %d)\\n\", id, unit1_idx, unit2_idx, first_lock_idx, second_lock_idx);\n\n    pthread_mutex_lock(&units_mutex[first_lock_idx]);\n    printf(\"Thread %d acquired unit %d\\n\", id, first_lock_idx);\n    \n    usleep(10000); // 10ms\n\n    pthread_mutex_lock(&units_mutex[second_lock_idx]);\n    printf(\"Thread %d acquired unit %d and unit %d (original: %d and %d)\\n\", id, first_lock_idx, second_lock_idx, unit1_idx, unit2_idx);\n\n    printf(\"Thread %d working with units %d and %d\\n\", id, unit1_idx, unit2_idx);\n    usleep(50000); // 50ms\n\n    pthread_mutex_unlock(&units_mutex[second_lock_idx]);\n    printf(\"Thread %d released unit %d\\n\", id, second_lock_idx);\n\n    pthread_mutex_unlock(&units_mutex[first_lock_idx]);\n    printf(\"Thread %d released unit %d\\n\", id, first_lock_idx);\n\n    free(arg);\n    return NULL;\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0431__Deadlocks__CodeAnalysis__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:31:29", "_subject": "Concurrency"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Deadlocks", "Synchronization", "Concurrency", "Mutexes"], "content": {"text": "מערכת בנקאית מנהלת מספר חשבונות בנק. כל חשבון מיוצג על ידי מבנה BankAccount הכולל יתרה (balance) ומנעול (mutex) להגנה על היתרה. פונקציית transfer_money מיועדת להעביר סכום כסף מחשבון מקור לחשבון יעד. כדי להבטיח עקביות ושלמות הנתונים, הפונקציה נועלת את שני החשבונות המעורבים לפני ביצוע ההעברה ומשחררת אותם לאחריה. נתון קוד המימוש הבא:\n\nבחנו את הקוד לעיל.\n1. האם קיימת אפשרות לקיפאון (Deadlock) במימוש הפונקציה transfer_money? אם כן, תארו את התרחיש המדויק שיוביל לקיפאון ואת תנאי הקיפאון המתקיימים (Mutual Exclusion, Hold and Wait, No Preemption, Circular Wait).\n2. הציעו פתרון לבעיית הקיפאון וכתבו מחדש את פונקציית transfer_money כך שתמנע קיפאונות, תוך שמירה על נכונות וביצועים סבירים.", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h> // For usleep\n\n// Define a BankAccount structure\ntypedef struct {\n    int id;\n    long balance;\n    pthread_mutex_t mutex;\n} BankAccount;\n\n// Function to initialize a bank account\nvoid init_account(BankAccount* account, int id, long initial_balance) {\n    account->id = id;\n    account->balance = initial_balance;\n    pthread_mutex_init(&account->mutex, NULL);\n}\n\n// Function to destroy a bank account\nvoid destroy_account(BankAccount* account) {\n    pthread_mutex_destroy(&account->mutex);\n}\n\n// Function to transfer money between two accounts (BUGGY VERSION)\nvoid transfer_money(BankAccount* source, BankAccount* destination, long amount) {\n    if (source == destination) {\n        return; // Cannot transfer to self\n    }\n\n    // Acquire locks in a potentially problematic order\n    pthread_mutex_lock(&source->mutex);\n    printf(\"Thread %lu locked account %d (source)\\n\", pthread_self(), source->id);\n    \n    // Simulate some work or delay to increase deadlock probability\n    usleep(10000); // 10ms delay\n\n    pthread_mutex_lock(&destination->mutex);\n    printf(\"Thread %lu locked account %d (destination)\\n\", pthread_self(), destination->id);\n\n    if (source->balance >= amount) {\n        source->balance -= amount;\n        destination->balance += amount;\n        printf(\"Transfer %ld from %d to %d successful. Balances: %d=%ld, %d=%ld\\n\", \n               amount, source->id, destination->id, source->id, source->balance, destination->id, destination->balance);\n    } else {\n        printf(\"Transfer %ld from %d to %d failed: insufficient funds.\\n\", amount, source->id, destination->id);\n    }\n\n    pthread_mutex_unlock(&destination->mutex);\n    printf(\"Thread %lu unlocked account %d (destination)\\n\", pthread_self(), destination->id);\n    pthread_mutex_unlock(&source->mutex);\n    printf(\"Thread %lu unlocked account %d (source)\\n\", pthread_self(), source->id);\n}\n", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כן, קיימת אפשרות לקיפאון (Deadlock) במימוש הנוכחי של transfer_money.\n\n**תרחיש הקיפאון:**\nנניח שני חוטים, Thread 1 ו-Thread 2, ושני חשבונות, Account A ו-Account B.\n*   Thread 1 מנסה להעביר כסף מ-Account A ל-Account B (קורא ל-transfer_money(A, B, amount1)).\n*   Thread 2 מנסה להעביר כסף מ-Account B ל-Account A (קורא ל-transfer_money(B, A, amount2)).\n\n**השתלשלות אירועים אפשרית לקיפאון:**\n1.  Thread 1 נועל את mutex של Account A.\n2.  Thread 2 נועל את mutex של Account B.\n3.  Thread 1 מנסה כעת לנעול את mutex של Account B, אך הוא כבר נעול על ידי Thread 2. Thread 1 נחסם וממתין.\n4.  Thread 2 מנסה כעת לנעול את mutex של Account A, אך הוא כבר נעול על ידי Thread 1. Thread 2 נחסם וממתין.\n\nבשלב זה, שני החוטים חסומים וממתינים זה לזה לשחרור המשאב שהם צריכים, ונוצר קיפאון.\n\n**תנאי הקיפאון המתקיימים:**\n*   **מניעה הדדית (Mutual Exclusion):** כל מנעול (mutex) יכול להיות מוחזק על ידי חוט אחד בלבד בכל רגע נתון.\n*   **החזקה והמתנה (Hold and Wait):** כל חוט מחזיק במנעול אחד (למשל, Thread 1 מחזיק ב-mutex של Account A) וממתין למנעול נוסף (למשל, Thread 1 ממתין ל-mutex של Account B).\n*   **אי-הפקעה (No Preemption):** מנעול שהוחזק על ידי חוט לא יכול להילקח ממנו בכוח; הוא חייב לשחרר אותו מרצונו.\n*   **המתנה מעגלית (Circular Wait):** קיים מעגל של חוטים, כאשר כל חוט במעגל ממתין למשאב המוחזק על ידי החוט הבא במעגל. בתרחיש לעיל, Thread 1 ממתין ל-mutex של Account B שמוחזק על ידי Thread 2, ו-Thread 2 ממתין ל-mutex של Account A שמוחזק על ידי Thread 1.\n\n**פתרון מוצע:**\nכדי למנוע קיפאון במקרה של צורך בנעילת מספר משאבים, הגישה הנפוצה היא להבטיח שכל החוטים ירכשו את המשאבים באותו סדר קבוע (Global Ordering). במקרה זה, ניתן להחליט על סדר רכישת מנעולים לפי כתובות הזיכרון של אובייקטי BankAccount, או לפי מזהה ייחודי (ID) אם קיים. הפתרון יכלול השוואה בין כתובות הזיכרון של חשבונות המקור והיעד, ונעילה תמיד של החשבון בעל הכתובת הנמוכה יותר תחילה, ולאחר מכן את החשבון בעל הכתובת הגבוהה יותר.\n\n**מימוש מתוקן של transfer_money:**\n```c\nvoid transfer_money_safe(BankAccount* source, BankAccount* destination, long amount) {\n    if (source == destination) {\n        printf(\"Cannot transfer to self (account %d).\\n\", source->id);\n        return; \n    }\n\n    pthread_mutex_t *first_mutex, *second_mutex;\n    BankAccount *first_account, *second_account;\n\n    // Determine a consistent locking order based on memory addresses\n    // This ensures that all threads attempting to lock these two specific accounts\n    // will always try to acquire them in the same sequence, preventing circular wait.\n    if (source < destination) { // Compare memory addresses of the account objects\n        first_mutex = &source->mutex;\n        second_mutex = &destination->mutex;\n        first_account = source;\n        second_account = destination;\n    } else {\n        first_mutex = &destination->mutex;\n        second_mutex = &source->mutex;\n        first_account = destination;\n        second_account = source;\n    }\n\n    // Acquire locks in the consistent order\n    pthread_mutex_lock(first_mutex);\n    printf(\"Thread %lu locked account %d (first in order)\\n\", pthread_self(), first_account->id);\n\n    // Simulate some work or delay\n    usleep(10000); // 10ms delay\n\n    pthread_mutex_lock(second_mutex);\n    printf(\"Thread %lu locked account %d (second in order)\\n\", pthread_self(), second_account->id);\n\n    // Perform the transfer logic with both locks held\n    // The source and destination pointers remain as they were passed to the function,\n    // only the order of mutex acquisition changes.\n    if (source->balance >= amount) {\n        source->balance -= amount;\n        destination->balance += amount;\n        printf(\"Transfer %ld from %d to %d successful. Balances: %d=%ld, %d=%ld\\n\", \n               amount, source->id, destination->id, source->id, source->balance, destination->id, destination->balance);\n    } else {\n        printf(\"Transfer %ld from %d to %d failed: insufficient funds. Balances: %d=%ld, %d=%ld\\n\", \n               amount, source->id, destination->id, source->id, source->balance, destination->id, destination->balance);\n    }\n\n    // Release locks in reverse order of acquisition (or simply both, order doesn't matter for unlock)\n    pthread_mutex_unlock(second_mutex);\n    printf(\"Thread %lu unlocked account %d (second in order)\\n\", pthread_self(), second_account->id);\n    pthread_mutex_unlock(first_mutex);\n    printf(\"Thread %lu unlocked account %d (first in order)\\n\", pthread_self(), first_account->id);\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0432__Deadlocks__CodeAnalysis__Hard.json", "_topic_hint": "Deadlocks", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:32:09", "_subject": "Concurrency"}, {"id": 5, "type": "MultipleChoice", "topic": ["Memory Management"], "content": {"text": "איזו מבין הפעולות הבאות אחראית להקצאת זיכרון דינמית בשפת C?", "code_snippet": null, "options": ["א. `new`", "ב. `free`", "ג. `malloc`", "ד. `sizeof`", "ה. `delete`"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הפונקציה `malloc` (memory allocate) היא הדרך הסטנדרטית להקצאת זיכרון דינמית בשפת C. היא מקבלת כארגומנט את מספר הבתים שיש להקצות ומחזירה מצביע (pointer) מסוג `void*` לבלוק הזיכרון שהוקצה, או NULL במקרה של כישלון. `new` ו-`delete` הן אופרטורים להקצאה ושחרור זיכרון ב-C++, בהתאמה. `free` משחררת זיכרון שהוקצה באמצעות `malloc`. `sizeof` הוא אופרטור שמחזיר את גודל בבתים של טיפוס או משתנה."}, "difficulty_estimation": "Easy", "_source_file": "0433__Memory_Management__MultipleChoice__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:32:18", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Memory Management"], "content": {"text": "מהו התפקיד העיקרי של יחידת ניהול הזיכרון (MMU)?", "code_snippet": null, "options": ["א. לנהל את תזמון המעבד.", "ב. לתרגם כתובות וירטואליות לכתובות פיזיות.", "ג. לנהל פעולות קלט/פלט.", "ד. לאחסן אוגרי מעבד."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "התפקיד העיקרי של יחידת ניהול הזיכרון (MMU - Memory Management Unit) הוא לתרגם כתובות וירטואליות, בהן משתמשים תהליכים, לכתובות פיזיות בזיכרון הראשי. זהו מרכיב חיוני במימוש זיכרון וירטואלי ובניהול זיכרון בכלל."}, "difficulty_estimation": "Easy", "_source_file": "0434__Memory_Management__MultipleChoice__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:32:25", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Memory Management", "Virtual Memory"], "content": {"text": "אחד היתרונות העיקריים של זיכרון וירטואלי הוא:", "code_snippet": null, "options": ["א. להגדיל את כמות הזיכרון הפיזי הזמין למערכת.", "ב. לאפשר למעבד גישה ישירה לדיסק הקשיח.", "ג. לספק לכל תהליך מרחב כתובות פרטי ומבודד.", "ד. להאיץ את מהירות הגישה לזיכרון הפיזי."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "ג. זיכרון וירטואלי מאפשר לכל תהליך לראות מרחב כתובות לוגי משלו, המבודד ממרחבי הכתובות של תהליכים אחרים, ובכך מספק הגנה ופשטות בניהול זיכרון. הוא אינו מגדיל את הזיכרון הפיזי בפועל, אינו מאפשר גישה ישירה לדיסק, ובדרך כלל אינו מאיץ גישה לזיכרון הפיזי (אלא להיפך, מוסיף שכבת תרגום)."}, "difficulty_estimation": "Easy", "_source_file": "0435__Memory_Management__MultipleChoice__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:32:31", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Memory Management", "Virtual Memory"], "content": {"text": "מהו סוג הכתובת שהמעבד (CPU) מייצר כאשר הוא ניגש לזיכרון?", "code_snippet": null, "options": ["א. כתובת וירטואלית", "ב. כתובת פיזית", "ג. כתובת דיסק", "ד. כתובת יחסית"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "המעבד (CPU) תמיד מייצר כתובות וירטואליות (Virtual Addresses). יחידת ניהול הזיכרון (MMU) היא זו שאחראית לתרגם את הכתובות הוירטואליות לכתובות פיזיות (Physical Addresses) לפני הגישה לזיכרון הפיזי."}, "difficulty_estimation": "Easy", "_source_file": "0436__Memory_Management__MultipleChoice__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:32:38", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Memory Management"], "content": {"text": "מהו התפקיד העיקרי של יחידת ניהול הזיכרון (MMU)?", "code_snippet": null, "options": ["א. הקצאת זיכרון לתהליכים.", "ב. תרגום כתובות וירטואליות לכתובות פיזיות.", "ג. שמירת נתונים בזיכרון מטמון בשימוש תכוף.", "ד. ניהול פעולות קלט/פלט.", "ה. הגנה על המעבד מפני הוראות לא חוקיות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. התפקיד העיקרי של יחידת ניהול הזיכרון (MMU) הוא לתרגם כתובות וירטואליות, המופקות על ידי המעבד, לכתובות פיזיות בזיכרון הראשי. זהו מרכיב חיוני ביישום זיכרון וירטואלי, הגנת זיכרון ומיפוי זיכרון."}, "difficulty_estimation": "Easy", "_source_file": "0437__Memory_Management__MultipleChoice__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:32:45", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Memory Management"], "content": {"text": "מהי פרגמנטציה חיצונית (External Fragmentation)?", "code_snippet": null, "options": ["א. בזבוז זיכרון בתוך בלוק שהוקצה לתהליך, מכיוון שהתהליך דרש פחות מהגודל שהוקצה.", "ב. מצב שבו יש מספיק זיכרון פנוי בסך הכל כדי למלא בקשה חדשה, אך הוא מפוזר בבלוקים קטנים ולא רציפים.", "ג. מצב שבו יש יותר מדי תהליכים בזיכרון הפיזי, מה שגורם להאטה במערכת.", "ד. בזבוז זיכרון הנגרם כתוצאה מהחלפת דפים (paging) תכופה מדי בין הזיכרון הראשי לדיסק.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. פרגמנטציה חיצונית מתרחשת כאשר סך הזיכרון הפנוי מספיק כדי למלא בקשת הקצאה, אך הוא אינו רציף ומפוזר בבלוקים קטנים שאינם יכולים להכיל את הבקשה כולה. אפשרות א' מתארת פרגמנטציה פנימית."}, "difficulty_estimation": "Easy", "_source_file": "0438__Memory_Management__MultipleChoice__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:32:52", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Memory Management", "Paging"], "content": {"text": "איזו סוג של פרגמנטציה קיימת בשיטת ניהול הזיכרון Paging (חלוקה לדפים)?", "code_snippet": null, "options": ["א. פרגמנטציה פנימית בלבד.", "ב. פרגמנטציה חיצונית בלבד.", "ג. גם פרגמנטציה פנימית וגם פרגמנטציה חיצונית.", "ד. אף סוג של פרגמנטציה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "בשיטת Paging, הזיכרון הפיזי מחולק לדפים (frames) בגודל קבוע. תהליכים מחולקים גם הם לדפים (pages) באותו גודל. כאשר תהליך מוקצה לזיכרון, הוא מקבל דפים שלמים. אם גודל התהליך אינו כפולה של גודל הדף, הדף האחרון שהוקצה לתהליך יכיל שטח לא מנוצל – זוהי פרגמנטציה פנימית. פרגמנטציה חיצונית, שהיא חורים קטנים ולא רציפים בין בלוקים מוקצים, אינה מתרחשת ב-Paging מכיוון שכל יחידות ההקצאה (הדפים) הן בגודל קבוע וניתן להשתמש בכל דף פנוי."}, "difficulty_estimation": "Easy", "_source_file": "0439__Memory_Management__MultipleChoice__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:33:00", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Memory Management", "Virtual Memory"], "content": {"text": "מהו התפקיד העיקרי של יחידת ניהול הזיכרון (MMU)?", "code_snippet": null, "options": ["א. ניהול תזמון המעבד.", "ב. תרגום כתובות וירטואליות לכתובות פיזיות.", "ג. טיפול בפעולות קלט/פלט של דיסק.", "ד. אחסון הוראות תוכנית."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "יחידת ניהול הזיכרון (MMU) היא רכיב חומרה שאחראי על תרגום כתובות וירטואליות, בהן משתמשים תהליכים, לכתובות פיזיות בזיכרון הראשי (RAM)."}, "difficulty_estimation": "Easy", "_source_file": "0440__Memory_Management__MultipleChoice__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:33:08", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Memory Management", "Paging", "Fragmentation"], "content": {"text": "איזו משיטות ניהול הזיכרון הבאות פותרת ביעילות את בעיית הפיצול החיצוני (External Fragmentation), אך עלולה להציג פיצול פנימי (Internal Fragmentation)?", "code_snippet": null, "options": ["א. סגמנטציה (Segmentation)", "ב. דפדוף (Paging)", "ג. מחיצות בגודל קבוע (Fixed Partitioning)", "ד. מחיצות בגודל משתנה (Variable Partitioning)", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "דפדוף (Paging) מחלק את הזיכרון הפיזי למסגרות (frames) בגודל קבוע ואת המרחב הלוגי לדפים (pages) באותו גודל. בכך, הוא מבטיח שכל חלקי התהליך יכולים להיות מפוזרים במסגרות לא רציפות בזיכרון הפיזי, ובכך מונע פיצול חיצוני לחלוטין. עם זאת, מכיוון שתהליך אינו חייב למלא בדיוק מספר שלם של דפים, הדף האחרון של התהליך עלול להכיל שטח לא מנוצל, מה שמוביל לפיצול פנימי. סגמנטציה, מחיצות בגודל קבוע ומחיצות בגודל משתנה סובלות מפיצול חיצוני."}, "difficulty_estimation": "Medium", "_source_file": "0441__Memory_Management__MultipleChoice__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:33:16", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Memory Management", "Paging", "Fragmentation"], "content": {"text": "במערכת ניהול זיכרון מבוססת דפדוף (paging), איזו מהטענות הבאות מתארת נכונה את הסיבה העיקרית לפרגמנטציה פנימית (internal fragmentation)?", "code_snippet": null, "options": ["א. היא נגרמת כאשר זיכרון פיזי פנוי מתפזר לגושים קטנים ולא רציפים ברחבי ה-RAM.", "ב. היא נוצרת מכיוון שתהליכים מקבלים הקצאת זיכרון ביחידות של דפים שלמים, וכמעט תמיד הדף האחרון אינו מנוצל במלואו.", "ג. היא מתרחשת כאשר טבלת הדפים (page table) גדולה מדי וצורכת חלק משמעותי מזיכרון ה-RAM.", "ד. היא נגרמת כתוצאה משימוש יתר בשטח ההחלפה (swap space) כאשר ה-RAM מלא.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "פרגמנטציה פנימית במערכת דפדוף מתרחשת מכיוון שהזיכרון מוקצה לתהליכים ביחידות של דפים בגודל קבוע. גם אם תהליך זקוק רק לחלק קטן מהדף האחרון שהוקצה לו, הוא מקבל דף שלם. השטח הנותר באותו דף אינו מנוצל ואינו יכול לשמש תהליכים אחרים, ולכן הוא נחשב לפרגמנטציה פנימית."}, "difficulty_estimation": "Medium", "_source_file": "0442__Memory_Management__MultipleChoice__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:33:25", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Memory Management", "Paging", "Fragmentation"], "content": {"text": "איזו משיטות ניהול הזיכרון הבאות סובלת מפיצול פנימי (internal fragmentation) אך אינה סובלת מפיצול חיצוני (external fragmentation)?", "code_snippet": null, "options": ["א. סגמנטציה (Segmentation)", "ב. דפדוף (Paging)", "ג. ניהול זיכרון רציף (Contiguous Memory Allocation)", "ד. זיכרון מטמון לטבלת דפים (TLB)"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. דפדוף (Paging). בשיטת הדפדוף, הזיכרון מחולק לדפים בגודל קבוע. דף הנתונים האחרון של תהליך עלול להיות לא מלא, מה שגורם לפיצול פנימי. עם זאת, מכיוון שכל הדפים באותו גודל וניתן למקם אותם בכל מסגרת פנויה בזיכרון הפיזי, לא נוצרים חורים בזיכרון שאינם ניתנים לשימוש עקב גודלם, ובכך נמנע פיצול חיצוני. סגמנטציה וניהול זיכרון רציף סובלים מפיצול חיצוני. TLB הוא מנגנון מטמון לטבלאות דפים, לא שיטת ניהול זיכרון בפני עצמה."}, "difficulty_estimation": "Medium", "_source_file": "0443__Memory_Management__MultipleChoice__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:33:33", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Memory Management", "Fragmentation", "Paging", "Segmentation"], "content": {"text": "איזו משיטות ניהול הזיכרון הבאות סובלת מפרגמנטציה פנימית (internal fragmentation) אך אינה סובלת מפרגמנטציה חיצונית (external fragmentation)?", "code_snippet": null, "options": ["א. סגמנטציה (Segmentation)", "ב. דפדוף (Paging)", "ג. הקצאה רציפה (Contiguous Allocation)", "ד. שניהם, סגמנטציה ודפדוף (Both Segmentation and Paging)", "ה. אף אחת מהתשובות אינה נכונה"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "דפדוף (Paging) מחלק את הזיכרון הפיזי למסגרות בגודל קבוע ואת הזיכרון הלוגי לדפים בגודל זהה. כתוצאה מכך, אין פרגמנטציה חיצונית מכיוון שכל מסגרת פנויה שוות ערך לאחרת וניתן להשתמש בה. עם זאת, ייתכן שהדף האחרון של תהליך לא ימלא מסגרת שלמה, מה שמוביל לפרגמנטציה פנימית. סגמנטציה (Segmentation) סובלת מפרגמנטציה חיצונית מכיוון שהסגמנטים הם בגדלים משתנים, אך אינה סובלת מפרגמנטציה פנימית."}, "difficulty_estimation": "Medium", "_source_file": "0444__Memory_Management__MultipleChoice__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:33:41", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Memory Management", "Paging", "Fragmentation"], "content": {"text": "איזו בעיית פרגמנטציה קיימת במערכת ניהול זיכרון המבוססת על דפדוף (Paging)?", "code_snippet": null, "options": ["א. פרגמנטציה חיצונית (External Fragmentation) בלבד.", "ב. פרגמנטציה פנימית (Internal Fragmentation) בלבד.", "ג. גם פרגמנטציה פנימית וגם פרגמנטציה חיצונית.", "ד. ללא בעיות פרגמנטציה כלל.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "בדפדוף, הזיכרון הפיזי מחולק למסגרות (frames) בגודל קבוע, והזיכרון הלוגי מחולק לדפים (pages) באותו גודל. תהליכים מקבלים הקצאה של דפים שלמים. אם תהליך זקוק לפחות זיכרון מהדף האחרון שהוקצה לו, החלק הנותר של הדף אינו בשימוש ומהווה פרגמנטציה פנימית. פרגמנטציה חיצונית, שבה ישנם חללים פנויים קטנים שאינם רציפים ולא מספיק גדולים להכיל יחידת הקצאה, אינה קיימת בדפדוף כי הקצאת הזיכרון היא ביחידות קבועות וקטנות (דפים/מסגרות), והזיכרון הפנוי מנוהל ברמת המסגרת, לא כבלוקים רציפים בגודל משתנה."}, "difficulty_estimation": "Medium", "_source_file": "0445__Memory_Management__MultipleChoice__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:33:48", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Memory Management", "Fragmentation", "Paging", "Segmentation"], "content": {"text": "איזו משיטות ניהול הזיכרון הבאות סובלת בעיקר מפרגמנטציה חיצונית (external fragmentation)?", "code_snippet": null, "options": ["א. דפדוף (Paging)", "ב. פילוח (Segmentation)", "ג. גם דפדוף וגם פילוח", "ד. אף אחת מהתשובות אינה נכונה"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "דפדוף (Paging) סובל מפרגמנטציה פנימית (internal fragmentation) מכיוון שדפים מוקצים בגודל קבוע, וייתכן שהתהליך לא ישתמש בכל הזיכרון בדף האחרון. פילוח (Segmentation) לעומת זאת, סובל מפרגמנטציה חיצונית (external fragmentation) מכיוון שסגמנטים יכולים להיות בגדלים שונים ומשתנים, וכאשר הם משוחררים, נוצרים 'חורים' בגדלים שונים בזיכרון הפיזי, מה שמקשה על מציאת מקום רציף לסגמנטים חדשים, גם אם סך הזיכרון הפנוי מספיק."}, "difficulty_estimation": "Medium", "_source_file": "0446__Memory_Management__MultipleChoice__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:33:56", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Memory Management", "Paging", "Fragmentation"], "content": {"text": "איזה סוג של פרגמנטציה קשור בעיקר למנגנון דפדוף (Paging), ומדוע?", "code_snippet": null, "options": ["א. פרגמנטציה חיצונית, מכיוון שדפים בגדלים שונים אינם יכולים להתאים למסגרות זיכרון.", "ב. פרגמנטציה פנימית, מכיוון שהזיכרון המוקצה לתהליך מגיע ביחידות קבועות (דפים), וייתכן שהדף האחרון של תהליך לא ינוצל במלואו.", "ג. פרגמנטציה חיצונית, מכיוון שעלולים להיווצר חורים קטנים בזיכרון הפיזי בין מסגרות שהוקצו לתהליכים שונים.", "ד. פרגמנטציה פנימית, מכיוון שכל תהליך מקבל בלוק זיכרון בגודל קבוע ללא קשר לגודל בפועל של הנתונים.", "ה. אין פרגמנטציה כלל במנגנון דפדוף."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. במנגנון דפדוף, הזיכרון הווירטואלי והפיזי מחולקים ליחידות בגודל קבוע הנקראות דפים ומסגרות בהתאמה. כאשר תהליך מקבל הקצאת זיכרון, הוא מקבל מספר שלם של דפים. אם גודל התהליך אינו כפולה מדויקת של גודל הדף, הדף האחרון שהוקצה לתהליך לא ינוצל במלואו, מה שמוביל לפרגמנטציה פנימית. פרגמנטציה חיצונית אינה בעיה מרכזית בדפדוף מכיוון שכל המסגרות הן באותו גודל וניתן למלא כל מסגרת פנויה."}, "difficulty_estimation": "Medium", "_source_file": "0447__Memory_Management__MultipleChoice__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:34:05", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Memory Management", "Fragmentation", "Paging", "Segmentation"], "content": {"text": "איזו משיטות ניהול הזיכרון הבאות סובלת בעיקר מפרגמנטציה חיצונית (External Fragmentation)?", "code_snippet": null, "options": ["א. Paging (דפדוף)", "ב. Segmentation (פילוח)", "ג. גם דפדוף וגם פילוח", "ד. לא דפדוף ולא פילוח"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "פרגמנטציה חיצונית מתרחשת כאשר יש מספיק זיכרון פנוי בסך הכל, אך הוא מפוזר בבלוקים קטנים שאינם רציפים, כך שלא ניתן להקצות יחידה גדולה יותר. שיטת הפילוח (Segmentation) מקצה בלוקים בגדלים משתנים עבור סגמנטים, מה שמוביל לפרגמנטציה חיצונית. שיטת הדפדוף (Paging) מחלקת את הזיכרון לבלוקים בגודל קבוע (דפים ומסגרות), ובכך מונעת פרגמנטציה חיצונית אך עלולה לגרום לפרגמנטציה פנימית."}, "difficulty_estimation": "Medium", "_source_file": "0448__Memory_Management__MultipleChoice__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:34:12", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Memory Management", "Paging", "TLB", "Page Faults", "Page Table Walk"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם כתובות וירטואליות בנות 32 ביטים וגודל דף של 4KB. טבלת הדפים היא דו-מפלסית, כאשר כל כניסה בטבלת דפים (PTE) היא בגודל 4 בתים. ה-TLB במערכת הינו בגודל 128 כניסות, אסוציאטיבי מלא (fully associative) ומשתמש במדיניות החלפה LRU. ה-TLB ריק בתחילת הריצה.\n\nתהליך מבצע את הלולאה הבאה:\n```c\nint arr[1024 * 1024 * 2]; // 2M integers\nfor (int i = 0; i < 1024 * 1024 * 2; i++) {\n    arr[i] = i;\n}\n```\nהנח כי הזיכרון הפיזי ריק בתחילת הריצה, וכי המערך `arr` ממוקם בכתובת וירטואלית המתחילה ביישור של דף (page-aligned). כמה אירועים מכל סוג יתרחשו במהלך ביצוע הלולאה?", "code_snippet": "int arr[1024 * 1024 * 2];\nfor (int i = 0; i < 1024 * 1024 * 2; i++) {\n    arr[i] = i;\n}", "options": ["א. 2048 Page Faults, 2048 TLB Misses, 2048 גישות לטבלת דפים (P1) ו-2048 גישות לטבלת דפים (P2).", "ב. 2048 Page Faults, 2048 TLB Misses, 2 גישות לטבלת דפים (P1) ו-2048 גישות לטבלת דפים (P2).", "ג. 2048 Page Faults, 2048 TLB Misses, 4096 גישות לטבלת דפים (סה\"כ).", "ד. 2048 Page Faults, 2048 * 1024 TLB Misses, 4096 גישות לטבלת דפים (סה\"כ).", "ה. אף אחת מהתשובות אינה נכונה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "ניתוח המערכת:\n*   **גודל כתובת וירטואלית:** 32 ביטים.\n*   **גודל דף:** 4KB = 2^12 בתים. לכן, 12 הביטים הפחות משמעותיים (LSB) של הכתובת הווירטואלית הם ה-offset בתוך הדף.\n*   **מספר ביטים ל-VPN (Virtual Page Number):** 32 - 12 = 20 ביטים.\n*   **טבלת דפים דו-מפלסית:** כל כניסה בטבלת דפים (PTE) היא 4 בתים. גודל דף הוא 4KB. לכן, כל טבלת דפים (מפלס 1 או מפלס 2) יכולה להכיל `4096 / 4 = 1024` כניסות.\n    *   `log2(1024) = 10` ביטים. לכן, 10 הביטים הבאים משמשים לאינדקס בטבלת הדפים מפלס 2 (P2), ו-10 הביטים העליונים משמשים לאינדקס בטבלת הדפים מפלס 1 (P1). (P1: 10 ביטים, P2: 10 ביטים, Offset: 12 ביטים).\n\n*   **המערך `arr`:** מכיל `2 * 1024 * 1024` אינטגרים. כל אינטגר הוא 4 בתים.\n    *   גודל המערך הכולל: `2 * 1024 * 1024 * 4` בתים = `8MB`.\n    *   מספר הדפים שהמערך תופס: `8MB / 4KB לדף` = `2048` דפים.\n    *   כל דף מכיל `4KB / 4B לאינטגר` = `1024` אינטגרים.\n*   **גישה למערך:** הלולאה ניגשת לכל אלמנט במערך באופן סדרתי. סך הגישות: `2048 * 1024`.\n*   **TLB:** בגודל 128 כניסות, אסוציאטיבי מלא, LRU, ריק בתחילה.\n\n**חישובים:**\n1.  **Page Faults:**\n    *   המערך משתרע על פני 2048 דפים ייחודיים.\n    *   מכיוון שהזיכרון הפיזי ריק בתחילת הריצה, הגישה הראשונה לכל אחד מ-2048 הדפים הללו תגרום לפסיקת דף (Page Fault).\n    *   **סה\"כ Page Faults: 2048.**\n\n2.  **TLB Misses:**\n    *   עבור כל אחד מ-2048 הדפים הייחודיים, הגישה הראשונה לאינטגר כלשהו באותו דף תגרום ל-TLB Miss.\n    *   לאחר ה-TLB Miss, הכניסה לדף תוכנס ל-TLB. בתוך כל דף ישנם 1024 אינטגרים. לאחר הגישה הראשונה (שהיא Miss), 1023 הגישות הבאות לאינטגרים באותו דף יהיו TLB Hits.\n    *   מדיניות ה-LRU ב-TLB בגודל 128 כניסות: מכיוון שיש 2048 דפים ייחודיים ורק 128 כניסות ב-TLB, ה-TLB יתמלא ויתחיל להחליף כניסות. בגישה סדרתית, בכל פעם שניגשים לדף חדש שאינו ב-TLB (כלומר, הגישה הראשונה לכל אחד מ-2048 הדפים), תתרחש TLB Miss. הגישות הבאות לאותו דף יהיו Hits עד שהדף יוחלף. (הערה: הגישה הראשונה לכל דף תהיה TLB miss, אך כל 1023 הגישות הבאות לאותו דף יהיו TLB hit, כל עוד הדף לא יוחלף מה-TLB. אך מכיוון שעל כל 128 דפים יש החלפה, עדיין רק הגישה הראשונה לכל דף תגרום ל-miss). \n    *   **סה\"כ TLB Misses: 2048** (אחת לכל דף ייחודי).\n\n3.  **גישות לטבלת הדפים (Page Table Accesses):**\n    *   כל TLB Miss גורם לביצוע Page Table Walk.\n    *   **סה\"כ Page Table Walks: 2048.**\n    *   בטבלת דפים דו-מפלסית, כל Page Table Walk דורש שתי גישות לזיכרון:\n        1.  גישה לטבלת הדפים מפלס 1 (P1) כדי למצוא את הבסיס של טבלת הדפים מפלס 2.\n        2.  גישה לטבלת הדפים מפלס 2 (P2) כדי למצוא את ה-PTE של הדף המבוקש.\n    *   המערך משתרע על 2048 דפים. כל טבלת דפים מפלס 2 יכולה למפות 1024 דפים (4MB). לכן, המערך משתרע על פני שתי טבלאות דפים מפלס 2 (ולכן שתי כניסות P1 שונות).\n    *   עבור כל אחד מ-2048 ה-TLB Misses, תבוצע גישה אחת ל-P1 וגישה אחת ל-P2.\n    *   **סה\"כ גישות לטבלת דפים מפלס 1 (P1): 2048.**\n    *   **סה\"כ גישות לטבלת דפים מפלס 2 (P2): 2048.**\n\nלפי החישובים, התשובה המתאימה ביותר היא א'."}, "difficulty_estimation": "Hard", "_source_file": "0449__Memory_Management__MultipleChoice__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:34:53", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Memory Management", "Heap Allocation", "Fragmentation"], "content": {"text": "נתונה מערכת ניהול זיכרון המשתמשת באלגוריתם First-Fit להקצאת זיכרון, ומעגלת כל בקשת הקצאה לגודל הקרוב ביותר שהוא כפולה של 16 בתים. גודל הערימה (heap) הכולל הוא 256 בתים, ובתחילה הוא בלוק פנוי אחד בגודל 256 בתים.\nבוצעו הפעולות הבאות ברצף:\n", "code_snippet": "void* ptr1 = malloc(20);\nvoid* ptr2 = malloc(10);\nvoid* ptr3 = malloc(40);\nvoid* ptr4 = malloc(5);\nfree(ptr2);\nfree(ptr4);\nvoid* ptr5 = malloc(30);", "options": ["א. 0 בתים", "ב. 16 בתים", "ג. 32 בתים", "ד. 128 בתים", "ה. 144 בתים"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "נבחן את מצב הערימה לאחר כל שלב, כאשר כל הקצאה מעוגלת לכפולה הקרובה ביותר של 16 בתים, והאלגוריתם הוא First-Fit:\n\n*   **התחלה**: [F: 256] (בלוק פנוי של 256 בתים)\n*   **1. `malloc(20)`**: מעוגל ל-32 בתים. הערימה: [U: 32 (ptr1)] [F: 224]\n*   **2. `malloc(10)`**: מעוגל ל-16 בתים. הערימה: [U: 32 (ptr1)] [U: 16 (ptr2)] [F: 208]\n*   **3. `malloc(40)`**: מעוגל ל-48 בתים. הערימה: [U: 32 (ptr1)] [U: 16 (ptr2)] [U: 48 (ptr3)] [F: 160]\n*   **4. `malloc(5)`**: מעוגל ל-16 בתים. הערימה: [U: 32 (ptr1)] [U: 16 (ptr2)] [U: 48 (ptr3)] [U: 16 (ptr4)] [F: 144]\n\n*   **5. `free(ptr2)`**: משחרר את הבלוק בגודל 16 בתים. אין איחוד (coalescing) כי הבלוק מוקף בבלוקים תפוסים.\n    הערימה: [U: 32 (ptr1)] [F: 16 (ptr2)] [U: 48 (ptr3)] [U: 16 (ptr4)] [F: 144]\n\n*   **6. `free(ptr4)`**: משחרר את הבלוק בגודל 16 בתים. הבלוק ששוחרר (`ptr4`) צמוד לבלוק הפנוי הגדול (144 בתים), ולכן מתבצע איחוד: [F: 16 (ptr4)] [F: 144] הופך ל- [F: 160].\n    הערימה: [U: 32 (ptr1)] [F: 16 (ptr2)] [U: 48 (ptr3)] [F: 160]\n    הבלוקים הפנויים כעת הם 16 בתים ו-160 בתים.\n\n*   **7. `malloc(30)`**: מעוגל ל-32 בתים. אלגוריתם First-Fit יחפש את הבלוק הפנוי הראשון בגודל מספק.\n    הבלוק הראשון (16 בתים) קטן מדי.\n    הבלוק השני (160 בתים) גדול מספיק. יוקצו ממנו 32 בתים, ויישאר בלוק פנוי של 128 בתים.\n    הערימה: [U: 32 (ptr1)] [F: 16 (ptr2)] [U: 48 (ptr3)] [U: 32 (ptr5)] [F: 128]\n\nבסיום כל הפעולות, קיימים שני בלוקים פנויים: אחד בגודל 16 בתים, ואחד בגודל 128 בתים.\n\n*   **סך הזיכרון הפנוי**: 16 + 128 = 144 בתים.\n*   **הבלוק הפנוי הגדול ביותר**: 128 בתים.\n\nפיצול חיצוני (external fragmentation) מוגדר כסך הזיכרון הפנוי שאינו יכול לשמש להקצאה אחת, כלומר סך הזיכרון הפנוי פחות גודל הבלוק הפנוי הגדול ביותר.\nפיצול חיצוני = (סך הזיכרון הפנוי) - (גודל הבלוק הפנוי הגדול ביותר)\nפיצול חיצוני = 144 - 128 = 16 בתים.\n\nלכן התשובה הנכונה היא ב'."}, "difficulty_estimation": "Hard", "_source_file": "0450__Memory_Management__MultipleChoice__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:35:16", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Memory Management", "Virtual Memory", "Paging", "TLB"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם כתובות וירטואליות בנות 64 ביטים וגודל דף של 4KB. טבלת הדפים היא בעלת 4 רמות. ה-TLB מכיל 128 כניסות ומשתמש במדיניות החלפה LRU. בהתחלה, ה-TLB ריק וכל הדפים אינם נמצאים בזיכרון הפיזי.\n\nכמה החטאות TLB (TLB misses), כמה פסיקות דף (page faults) וכמה גישות זיכרון כוללות (memory accesses) יתרחשו במהלך ביצוע הלולאה הבאה? יש לכלול בגישות הזיכרון גם גישות לטבלאות הדפים וגם גישות לנתונים עצמם. הנח כי עדכון PTE בזיכרון וטעינת ה-PTE ל-TLB נחשבים כגישת זיכרון אחת כל אחד, וכי טעינת דף מהדיסק אינה נחשבת גישת זיכרון.", "code_snippet": "long long *arr = (long long *)0x100000000000; // כתובת וירטואלית התחלתית\nfor (int i = 0; i < 200; ++i) {\n    arr[i * 1024]; // גישה לאיבר\n}", "options": ["א. 200 החטאות TLB, 200 פסיקות דף, 600 גישות זיכרון.", "ב. 200 החטאות TLB, 200 פסיקות דף, 1200 גישות זיכרון.", "ג. 128 החטאות TLB, 200 פסיקות דף, 1000 גישות זיכרון.", "ד. 200 החטאות TLB, 128 פסיקות דף, 800 גישות זיכרון.", "ה. אף אחת מהתשובות האחרות אינה נכונה."]}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": "ה", "explanation": "נתונים:\n*   גודל כתובת וירטואלית: 64 ביטים\n*   גודל דף: 4KB (2^12 בתים)\n*   מבנה טבלת הדפים: 4 רמות\n*   גודל TLB: 128 כניסות, מדיניות LRU\n*   מצב התחלתי: TLB ריק, כל הדפים אינם בזיכרון הפיזי.\n\nניתוח קטע הקוד:\nהלולאה מבצעת 200 איטרציות. בכל איטרציה, מתבצעת גישה לאיבר `arr[i * 1024]`. גודל `long long` הוא 8 בתים. לכן, הגישה היא לכתובת `base_address + (i * 1024 * 8)`. המרווח בין גישות עוקבות הוא `1024 * 8 = 8192` בתים.\nמאחר שגודל הדף הוא 4KB (4096 בתים) והמרווח בין גישות הוא 8192 בתים, כל גישה בלולאה תהיה לדף וירטואלי *שונה* וחדש. כלומר, 200 דפים וירטואליים נפרדים ייגשו במהלך הלולאה.\n\n1.  **החטאות TLB (TLB misses)**:\n    *   200 דפים וירטואליים נפרדים נגשים. גודל ה-TLB הוא 128 כניסות. מכיוון שקבוצת העבודה (200 דפים) גדולה מקיבולת ה-TLB (128 כניסות), וכל גישה היא לדף חדש שלא נגש קודם לכן בלולאה, כל 200 הגישות יגרמו להחטאת TLB. גם לאחר שה-TLB יתמלא (אחרי 128 גישות), כל גישה חדשה לדף תגרום להחלפה של דף אחר (לפי LRU) ולכן תהיה החטאה. מכיוון שהדפים נגשים באופן סדרתי ולא חוזרים על עצמם בתוך 200 הגישות, כל גישה תהיה החטאה.\n    *   **סה\"כ החטאות TLB: 200**.\n\n2.  **פסיקות דף (Page Faults)**:\n    *   נאמר שכל הדפים אינם בזיכרון הפיזי בתחילה. מכיוון שנגשים ל-200 דפים וירטואליים נפרדים, וכל גישה היא לדף חדש עבור הלולאה, כל אחת מ-200 הגישות תגרום לפסיקת דף (page fault) בפעם הראשונה שדף זה נגש.\n    *   **סה\"כ פסיקות דף: 200**.\n\n3.  **גישות זיכרון כוללות (Total Memory Accesses)**:\n    *   כל אחת מ-200 הגישות לזיכרון תגרום גם להחטאת TLB וגם לפסיקת דף.\n    *   כאשר מתרחשת פסיקת דף:\n        1.  ה-CPU מבצע מעבר על טבלת הדפים (page table walk) כדי לאתר את ה-PTE (Page Table Entry). עבור טבלת דפים בעלת 4 רמות, זה דורש **4 גישות קריאה לזיכרון** (ל-PML4, PDPT, PDIR, PT).\n        2.  ה-PTE מציין שהדף אינו נמצא. מערכת ההפעלה מטפלת בפסיקת הדף: טוענת את הדף מהדיסק (לא נחשב גישת זיכרון לפי הנתון), ומעדכנת את ה-PTE בזיכרון הראשי. זוהי **1 גישת כתיבה לזיכרון** (עדכון ה-PTE).\n        3.  מערכת ההפעלה טוענת את ה-PTE החדש ל-TLB. הנח כי פעולה זו נחשבת גם היא ל**1 גישת זיכרון** (לפי הנתון בשאלה).\n        4.  ההוראה המקורית מופעלת מחדש. כעת, בדיקת ה-TLB תמצא את ה-PTE (כיוון שהוא נטען). לאחר מכן, מתבצעת גישה לנתון עצמו. זוהי **1 גישת קריאה לזיכרון**.\n    *   לכן, עבור כל גישה שגורמת לפסיקת דף, מתרחשות `4 (קריאות לטבלאות דפים) + 1 (כתיבת PTE בזיכרון) + 1 (טעינת PTE ל-TLB) + 1 (קריאת נתון)` = **7 גישות זיכרון**.\n    *   סה\"כ גישות זיכרון כוללות = `200 גישות * 7 גישות זיכרון/גישה = 1400 גישות זיכרון`.\n\nהתוצאה היא: 200 החטאות TLB, 200 פסיקות דף, 1400 גישות זיכרון. אף אחת מהאפשרויות א-ד אינה תואמת תוצאה זו.\n\nהתשובה הנכונה היא ה'."}, "difficulty_estimation": "Hard", "_source_file": "0451__Memory_Management__MultipleChoice__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:35:57", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Memory Management", "Paging", "Virtual Memory", "TLB"], "content": {"text": "מערכת הפעלה משתמשת בכתובות וירטואליות בגודל 48 ביטים ובכתובות פיזיות בגודל 40 ביטים. גודל דף הוא 4KB. טבלת הדפים היא בעלת 4 רמות, כאשר כל ערך בטבלת דפים (PTE) הוא בגודל 8 בתים. ה-TLB מלא ומכיל 128 רשומות.\nתהליך מנסה לגשת לראשונה לכתובת וירטואלית מסוימת. ידוע כי הרשומה המתאימה אינה נמצאת ב-TLB (TLB Miss), וגם הדף הפיזי המתאים אינו נמצא בזיכרון הראשי (Page Fault).\nבהנחה שכל דפי טבלת הדפים נמצאים בזיכרון הראשי, וכי לאחר טעינת הדף מהדיסק, מערכת ההפעלה מעדכנת את טבלת הדפים ואת ה-TLB לפני הפעלת הפקודה מחדש.\nכמה גישות לזיכרון הראשי (RAM) נדרשות לכל היותר כדי להשלים בהצלחה פעולת קריאה יחידה לכתובת זו?", "code_snippet": null, "options": ["א. 5", "ב. 6", "ג. 7", "ד. 8", "ה. 9"]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הסבר:\n1.  **TLB Miss**: כאשר ה-MMU מנסה לתרגם את הכתובת הוירטואלית, הוא מגלה שהרשומה אינה ב-TLB. אין גישת זיכרון ל-RAM בשלב זה.\n2.  **Page Table Walk**: ה-MMU (או מערכת ההפעלה) מתחילה לחפש את ה-PTE המתאים בטבלת הדפים. מכיוון שיש 4 רמות, נדרשות 4 גישות לזיכרון הראשי (קריאה של PTE מכל רמה) כדי להגיע ל-PTE הסופי. (4 גישות RAM)\n3.  **Page Fault**: ה-PTE הסופי מצביע על כך שהדף אינו נמצא בזיכרון הפיזי (valid bit = 0).\n4.  **טיפול ב-Page Fault (Page Fault Handler)**:\n    *   מערכת ההפעלה מוצאת מסגרת פיזית פנויה.\n    *   מערכת ההפעלה טוענת את הדף מהדיסק למסגרת הפיזית. פעולה זו אינה נחשבת כגישת RAM (היא גישת דיסק).\n    *   לאחר טעינת הדף, מערכת ההפעלה מעדכנת את ה-PTE הסופי בטבלת הדפים (כתיבה של ה-PTE החדש ל-RAM). (1 גישת RAM)\n    *   מערכת ההפעלה מעדכנת את ה-TLB עם המיפוי החדש. פעולה זו נחשבת פנימית למעבד/MMU ואינה גישת RAM.\n5.  **הפעלה מחדש של הפקודה**: הפקודה המקורית שגרמה ל-Page Fault מופעלת מחדש.\n    *   כעת, ה-TLB מכיל את הרשומה המתאימה (TLB Hit).\n    *   ה-MMU מתרגם את הכתובת באמצעות ה-TLB.\n    *   מתבצעת גישת הקריאה בפועל לנתונים בזיכרון הראשי. (1 גישת RAM)\n\nסה\"כ גישות לזיכרון הראשי: 4 (עבור ה-Page Table Walk) + 1 (עדכון ה-PTE לאחר טעינת הדף) + 1 (גישת הנתונים בפועל) = 6 גישות RAM."}, "difficulty_estimation": "Hard", "_source_file": "0452__Memory_Management__MultipleChoice__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:36:24", "_subject": "Virtualization"}, {"id": 10, "type": "MultipleChoice", "topic": ["Memory Management", "Paging", "Multi-level Page Tables"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בטבלאות דפים רב-שכבתיות עם 3 רמות (P1 -> P2 -> P3 -> דף פיזי). כתובת וירטואלית היא באורך 48 ביטים. גודל דף הוא 4KB. גודל כניסת טבלת דפים (PTE) הוא 8 בתים. תהליך יחיד מקצה לעצמו 16GB של זיכרון וירטואלי, אך משתמש באופן פעיל (כלומר, דפי הנתונים שלו נמצאים בזיכרון פיזי) רק ב-512MB מתוכו. הזיכרון הפעיל מפוזר באופן דליל (sparsely distributed) על פני מרחב הכתובות הוירטואלי. בהנחה שמערכת ההפעלה מקצה טבלאות דפים באופן אופטימלי (כלומר, רק כאשר יש צורך), מהו נפח הזיכרון המינימלי (בבתים) הנדרש לאחסון כל טבלאות הדפים עבור תהליך זה?", "code_snippet": null, "options": ["א. 1,024,000 בתים", "ב. 1,032,000 בתים", "ג. 1,056,768 בתים", "ד. 1,048,576 בתים", "ה. 1,060,864 בתים"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הסבר:\n1.  **חישוב פרמטרים בסיסיים:**\n    *   גודל דף: 4KB = 2^12 בתים. לכן, 12 ביטים משמשים ל-offset בתוך הדף.\n    *   אורך כתובת וירטואלית: 48 ביטים.\n    *   מספר ביטי ה-Virtual Page Number (VPN): 48 - 12 = 36 ביטים.\n    *   גודל כניסת טבלת דפים (PTE): 8 בתים.\n    *   מספר כניסות טבלה לדף טבלה בודד: 4KB / 8 בתים = 512 כניסות.\n    *   מספר ביטים לכל אינדקס בדף טבלת דפים: 2^9 = 512, לכן 9 ביטים לאינדקס.\n\n2.  **חלוקת ביטי ה-VPN בין הרמות:**\n    *   נתונה טבלת דפים בעלת 3 רמות (P1 -> P2 -> P3 -> דף פיזי). זה אומר שה-VPN מחולק לשלושה אינדקסים: I1, I2, I3.\n    *   אינדקס לרמה 1 (I1): 9 ביטים (מצביע לדף P2).\n    *   אינדקס לרמה 2 (I2): 9 ביטים (מצביע לדף P3).\n    *   הביטים הנותרים עבור אינדקס לרמה 3 (I3): 36 - 9 - 9 = 18 ביטים (מצביע לדף נתונים פיזי).\n\n3.  **חישוב מספר דפי נתונים פעילים:**\n    *   זיכרון פעיל: 512MB.\n    *   מספר דפי נתונים = 512MB / 4KB = 2^29 בתים / 2^12 בתים לדף = 2^17 דפים = 131,072 דפים.\n\n4.  **חישוב נפח הזיכרון עבור טבלאות דפים (מלמטה למעלה, בהנחה של הקצאה אופטימלית עבור זיכרון מפוזר):**\n    *   **רמה 3 (P3):**\n        *   כל דף טבלה ברמה 3 מכיל 512 PTEs (כל PTE מצביע לדף נתונים). כלומר, דף P3 אחד יכול לשרת 512 דפי נתונים.\n        *   כדי לטפל ב-2^17 דפי נתונים פעילים, נצטרך: ceil(2^17 / 512) = ceil(2^17 / 2^9) = 2^8 = 256 דפי טבלה ברמה 3.\n        *   נפח זיכרון עבור דפי P3 = 256 * 4KB = 1024KB = 1MB.\n\n    *   **רמה 2 (P2):**\n        *   כל דף טבלה ברמה 2 מכיל 512 PTEs (כל PTE מצביע לדף טבלה ברמה 3). כלומר, דף P2 אחד יכול לשרת 512 דפי P3.\n        *   כדי לטפל ב-256 דפי טבלה ברמה 3, נצטרך: ceil(256 / 512) = 1 דף טבלה ברמה 2.\n        *   נפח זיכרון עבור דפי P2 = 1 * 4KB = 4KB.\n\n    *   **רמה 1 (P1 - טבלת הבסיס):**\n        *   כל דף טבלה ברמה 1 מכיל 512 PTEs (כל PTE מצביע לדף טבלה ברמה 2). כלומר, דף P1 אחד יכול לשרת 512 דפי P2.\n        *   כדי לטפל ב-1 דף טבלה ברמה 2, נצטרך: ceil(1 / 512) = 1 דף טבלה ברמה 1 (זהו דף טבלת הבסיס/השורש).\n        *   נפח זיכרון עבור דפי P1 = 1 * 4KB = 4KB.\n\n5.  **סה\"כ נפח זיכרון לטבלאות דפים:**\n    *   סה\"כ = נפח P1 + נפח P2 + נפח P3\n    *   סה\"כ = 4KB + 4KB + 1024KB = 1032KB.\n    *   המרת לבתים: 1032KB * 1024 בתים/KB = 1,056,768 בתים.\n\nלכן, התשובה הנכונה היא ג'."}, "difficulty_estimation": "Hard", "_source_file": "0453__Memory_Management__MultipleChoice__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:48:54", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Memory Management", "Virtual Memory", "Paging", "TLB"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם כתובות וירטואליות בגודל 48 ביטים. גודל דף הוא 4KB. טבלת הדפים בנויה ב-4 רמות (multi-level page table), כאשר כל רמת טבלה יכולה להכיל 512 כניסות. גודל כניסה בטבלת דפים (PTE) הוא 8 בתים. בנוסף, קיימת יחידת TLB (Translation Lookaside Buffer) עם שיעור פגיעה (hit rate) של 99%. כמה גישות זיכרון RAM בממוצע נדרשות עבור תרגום כתובת וירטואלית אחת וגישה לנתונים בכתובת זו?", "code_snippet": null, "options": ["א. 1.01", "ב. 1.04", "ג. 1.05", "ד. 1.08", "ה. 1.12"]}, "sub_questions": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "הסבר:\nכתובת וירטואלית בגודל 48 ביטים.\nגודל דף 4KB = 2^12 בתים. לכן, 12 ביטים מוקצים ל-offset בתוך הדף.\nמספר הביטים לכתובת דף וירטואלי (VPN) הוא 48 - 12 = 36 ביטים.\nטבלת הדפים בנויה ב-4 רמות, כאשר כל רמה מכילה 512 כניסות. מכיוון ש-512 = 2^9, כל אינדקס ברמת טבלה דורש 9 ביטים.\nבסך הכל, 4 רמות דורשות 4 * 9 = 36 ביטים, מה שמתאים בדיוק לגודל ה-VPN.\n\nחישוב גישות זיכרון:\n1.  **במקרה של פגיעה ב-TLB (TLB Hit Rate = 99%)**:\n    הכתובת הפיזית נמצאת ב-TLB. נדרשת גישת זיכרון אחת בלבד ל-RAM כדי לגשת לנתונים בכתובת הפיזית.\n    מספר גישות זיכרון = 1.\n\n2.  **במקרה של החטאה ב-TLB (TLB Miss Rate = 1 - 0.99 = 1%)**:\n    ה-TLB לא מכיל את הכתובת. יש לבצע מהלך טבלת דפים (page table walk) כדי למצוא את הכתובת הפיזית:\n    -   גישת זיכרון אחת לטבלת הדפים ברמה 1 (P1).\n    -   גישת זיכרון אחת לטבלת הדפים ברמה 2 (P2).\n    -   גישת זיכרון אחת לטבלת הדפים ברמה 3 (P3).\n    -   גישת זיכרון אחת לטבלת הדפים ברמה 4 (P4), אשר מכילה את מספר המסגרת הפיזית (PFN).\n    -   סה\"כ 4 גישות זיכרון עבור תרגום הכתובת.\n    -   לאחר מכן, יש גישת זיכרון אחת ל-RAM כדי לגשת לנתונים.\n    -   סה\"כ גישות זיכרון = 4 (לטבלאות דפים) + 1 (לנתונים) = 5 גישות זיכרון.\n\nחישוב ממוצע גישות זיכרון:\nממוצע גישות = (שיעור פגיעה * גישות בפגיעה) + (שיעור החטאה * גישות בהחטאה)\nממוצע גישות = (0.99 * 1) + (0.01 * 5)\nממוצע גישות = 0.99 + 0.05\nממוצע גישות = 1.04\n\nלכן, התשובה הנכונה היא ב'."}, "difficulty_estimation": "Hard", "_source_file": "0454__Memory_Management__MultipleChoice__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:49:15", "_subject": "Virtualization"}, {"id": 101, "type": "MultipleChoice", "topic": ["Memory Management", "Paging", "Locality", "Virtual Memory"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי מבוסס דפים (demand paging) עם גודל דף של 4KB. תהליך מקצה דינמית מערך דו-ממדי בגודל `int arr[1024][1024]` (כאשר `sizeof(int) = 4` בתים). ההקצאה מתבצעת באופן רציף בזיכרון הוירטואלי והמערך מתחיל בגבול דף. נניח שזיכרון פיזי זמין מוגבל ואינו מסוגל להכיל את כל המערך. שקול את שני קטעי הקוד הבאים לאתחול המערך:\n\n```c\n// קטע קוד א'\nfor (int i = 0; i < 1024; ++i) {\n    for (int j = 0; j < 1024; ++j) {\n        arr[i][j] = i + j;\n    }\n}\n\n// קטע קוד ב'\nfor (int j = 0; j < 1024; ++j) {\n    for (int i = 0; i < 1024; ++i) {\n        arr[i][j] = i + j;\n    }\n}\n```\n\nאיזו טענה נכונה לגבי מספר פסיקות הדף (page faults) שייגרמו על ידי שני קטעי הקוד?", "code_snippet": null, "options": ["א. קטע קוד א' וקטע קוד ב' יגרמו למספר זהה של פסיקות דף, מכיוון שהם ניגשים לאותם נתונים.", "ב. קטע קוד א' יגרום לכ-1024 פסיקות דף, בעוד שקטע קוד ב' יגרום למספר קטן יותר, מכיוון שהוא מנצל טוב יותר את ה-TLB.", "ג. קטע קוד א' יגרום למספר נמוך משמעותית של פסיקות דף בהשוואה לקטע קוד ב', מכיוון שהוא מנצל טוב יותר את לוקליות הנתונים.", "ד. קטע קוד ב' יגרום למספר נמוך משמעותית של פסיקות דף בהשוואה לקטע קוד א', מכיוון שהוא מאפשר טעינה מקבילית של דפים.", "ה. מספר פסיקות הדף תלוי רק באלגוריתם החלפת הדפים ובכמות הזיכרון הפיזי, ולא בסדר הגישה."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "ג. גודל המערך הוא `1024 * 1024 * 4` בתים = 4MB. גודל הדף הוא 4KB.\n\n**קטע קוד א' (גישה לפי שורות - row-major):**\nכל שורה במערך היא בגודל `1024 * 4 = 4096` בתים, שזה בדיוק גודל דף אחד (4KB).\nכאשר קטע קוד א' ניגש לנתונים, הוא קורא את כל הנתונים של שורה מסוימת ברצף. מכיוון שהשורה כולה נכנסת לדף אחד, גישה לשורה תגרום לפסיקת דף אחת בלבד (אם הדף אינו בזיכרון). לאחר מכן, כל הגישות לשאר האיברים באותה שורה יהיו בתוך אותו דף שכבר נטען.\nבסך הכל, יהיו כ-1024 פסיקות דף (אחת לכל שורה), מכיוון שיש 1024 שורות וכל שורה תופסת דף אחר בזיכרון הוירטואלי. זהו ניצול טוב של לוקליות מרחבית (spatial locality).\n\n**קטע קוד ב' (גישה לפי עמודות - column-major):**\nכאשר קטע קוד ב' ניגש לנתונים, הלולאה הפנימית משתנה על `i` עבור `j` קבוע. הגישה היא ל-`arr[0][j]`, `arr[1][j]`, `arr[2][j]`, וכו'.\nכתובת הזיכרון של `arr[i][j]` היא `base + (i * 1024 + j) * sizeof(int)`.\nההפרש בכתובות בין `arr[i][j]` ל-`arr[i+1][j]` הוא `1024 * sizeof(int) = 1024 * 4 = 4096` בתים, שזה בדיוק גודל דף אחד.\nמשמעות הדבר היא שכל גישה ל-`arr[i][j]` כאשר `i` עולה, תהיה כמעט בוודאות בדף זיכרון וירטואלי שונה. מכיוון שיש 1024 שורות, הלולאה הפנימית תנסה לגשת ל-1024 דפים שונים ברצף מהיר.\nאם הזיכרון הפיזי מוגבל (לדוגמה, פחות מ-1024 דפים זמינים), אז עבור כל `i` בלולאה הפנימית, תתרחש ככל הנראה פסיקת דף, מכיוון שהדף הנדרש סביר להניח שהוחלף כבר על ידי דף אחר (במיוחד עם אלגוריתמי החלפת דפים נפוצים כמו LRU).\nלכן, עבור כל `j` (הלולאה החיצונית), הלולאה הפנימית תגרום לכ-1024 פסיקות דף. ובסה\"כ, מספר פסיקות הדף יכול להגיע לכ-`1024 * 1024 = 1,048,576` פסיקות דף.\nזהו ניצול גרוע מאוד של לוקליות מרחבית וגורם למספר עצום של פסיקות דף.\n\nלכן, קטע קוד א' יגרום למספר נמוך משמעותית של פסיקות דף בהשוואה לקטע קוד ב'."}, "difficulty_estimation": "Hard", "_source_file": "0455__Memory_Management__MultipleChoice__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:49:42", "_subject": "Virtualization"}, {"id": 6, "type": "MultipleChoice", "topic": ["Memory Management", "Paging", "Multi-level Page Tables"], "content": {"text": "במערכת הפעלה המשתמשת בזיכרון וירטואלי עם טבלת דפים דו-מפלסית, נתונים הפרטים הבאים:\n*   גודל כתובת וירטואלית: 32 ביטים.\n*   גודל דף: 4 קילובייט (KB).\n*   גודל כניסה בטבלת דפים (PTE): 4 בתים.\n\nכמה זיכרון פיזי *לכל היותר* נדרש עבור טבלאות הדפים בלבד, עבור תהליך המשתמש ב-1 מגהבייט (MB) רציף של זיכרון וירטואלי (החל מכתובת 0)?", "code_snippet": null, "options": ["א. 4 קילובייט (KB)", "ב. 8 קילובייט (KB)", "ג. 12 קילובייט (KB)", "ד. 1 מגהבייט (MB)", "ה. 2 מגהבייט (MB)"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "נחשב את גודל חלקים של הכתובת הוירטואלית ואת מספר הכניסות בכל טבלת דפים:\n*   גודל דף: 4KB = 2^12 בתים. לכן, ה-offset בכתובת הוירטואלית הוא 12 ביטים.\n*   גודל כתובת וירטואלית: 32 ביטים. לכן, מספר הדף הוירטואלי (VPN) הוא 32 - 12 = 20 ביטים.\n*   גודל כניסה בטבלת דפים (PTE): 4 בתים.\n*   מספר הכניסות בטבלת דפים בגודל דף אחד: 4KB / 4 בתים/כניסה = 1024 כניסות.\n*   מכיוון שטבלת הדפים היא דו-מפלסית, ה-VPN (20 ביטים) מתחלק ל-P1 (אינדקס לטבלת דפים מפלס ראשון) ול-P2 (אינדקס לטבלת דפים מפלס שני). כל אחד מהם יכול להיות בגודל log2(1024) = 10 ביטים. (P1=10 ביטים, P2=10 ביטים, סה\"כ 20 ביטים ל-VPN).\n\nהתהליך משתמש ב-1 מגהבייט (MB) זיכרון וירטואלי רציף, החל מכתובת 0:\n*   מספר הדפים הוירטואליים שנדרשים: 1MB / 4KB = 2^20 בתים / 2^12 בתים/דף = 2^8 = 256 דפים.\n*   דפים אלו הם דפים וירטואליים מספר 0 עד 255.\n\nכעת נחשב כמה זיכרון פיזי נדרש עבור טבלאות הדפים בלבד:\n1.  **טבלת דפים מפלס ראשון (P1)**:\n    *   היא מכסה טווח של 1024 * 1024 דפים וירטואליים. \n    *   הדפים 0-255 כולם נופלים תחת הכניסה הראשונה בטבלת הדפים מפלס ראשון (P1[0]).\n    *   לכן, נדרשת טבלת דפים אחת מפלס ראשון. טבלה זו תופסת דף פיזי אחד (4KB).\n2.  **טבלאות דפים מפלס שני (P2)**:\n    *   הכניסה P1[0] מצביעה על טבלת דפים מפלס שני. טבלה זו מכסה את הדפים הוירטואליים 0 עד 1023.\n    *   מכיוון שאנו משתמשים בדפים 0 עד 255, כולם כלולים בטבלה זו.\n    *   לכן, נדרשת טבלת דפים אחת מפלס שני. טבלה זו תופסת דף פיזי אחד (4KB).\n\nסה\"כ זיכרון פיזי הנדרש עבור טבלאות הדפים בלבד הוא: 1 דף (P1) + 1 דף (P2) = 2 דפים.\nסה\"כ זיכרון פיזי: 2 דפים * 4KB/דף = 8KB.\n\nהתשובה הנכונה היא ב'."}, "difficulty_estimation": "Hard", "_source_file": "0456__Memory_Management__MultipleChoice__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:50:09", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Memory Management", "Logical vs. Physical Address"], "content": {"text": "הסבירו מדוע ניהול זיכרון הכרחי במערכת הפעלה מרובת משימות (multiprogramming), ותארו בקצרה את ההבדל בין כתובת לוגית לכתובת פיזית.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "במערכת הפעלה מרובת משימות, מספר תהליכים רצים בו-זמנית ומשתמשים באותו זיכרון פיזי. ניהול זיכרון הכרחי מכמה סיבות עיקריות:\n1.  **הגנה (Protection):** מניעת תהליכים מלגשת או לשנות בטעות או בכוונה את מרחב הזיכרון של תהליכים אחרים או של מערכת ההפעלה עצמה. זה מבטיח יציבות ואבטחה.\n2.  **שיתוף (Sharing):** לאפשר לתהליכים שונים לשתף קטעי קוד או נתונים בזיכרון, מה שחוסך זיכרון ומאפשר תקשורת יעילה בין תהליכים.\n3.  **הקצאה יעילה (Efficient Allocation):** הקצאת זיכרון פיזי לתהליכים בצורה יעילה, תוך ניסיון למזער בזבוז זיכרון (פרגמנטציה) ולמקסם את ניצול הזיכרון.\n4.  **מיקום מחדש (Relocation):** לאפשר למערכת ההפעלה להעמיס תהליכים לכל מקום פנוי בזיכרון הפיזי, ואף להזיז אותם במהלך הריצה, מבלי שהתהליך יצטרך להיות מודע לכך.\n\nההבדל בין כתובת לוגית לכתובת פיזית:\n*   **כתובת לוגית (Logical Address):** זוהי כתובת שנוצרת על ידי ה-CPU (המעבד) עבור תהליך מסוים. היא מתייחסת למיקום בתוך מרחב הכתובות הווירטואלי של התהליך עצמו, והיא אינה בהכרח תואמת למיקום בפועל בזיכרון הפיזי. כל תהליך רואה את עצמו כבעל מרחב כתובות לוגי משלו, המתחיל בדרך כלל ב-0.\n*   **כתובת פיזית (Physical Address):** זוהי הכתובת האמיתית והממשית בזיכרון הראשי (RAM). זו הכתובת אליה ניגשת יחידת ניהול הזיכרון (MMU) והחומרה של הזיכרון. הכתובת הפיזית היא חד-משמעית ומצביעה על מיקום ספציפי בתאי הזיכרון הפיזיים.\nההמרה מכתובת לוגית לפיזית מתבצעת על ידי ה-MMU, בהתבסס על מנגנוני ניהול הזיכרון (כמו דפדוף או סגמנטציה) שמנוהלים על ידי מערכת ההפעלה."}, "difficulty_estimation": "Easy", "_source_file": "0457__Memory_Management__Open__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:50:21", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Memory Management", "Fragmentation"], "content": {"text": "הסבירו את המושגים 'פרגמנטציה פנימית' (Internal Fragmentation) ו'פרגמנטציה חיצונית' (External Fragmentation) בניהול זיכרון. תנו דוגמה קצרה לכל אחד מהמושגים.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פרגמנטציה פנימית (Internal Fragmentation):\nמתרחשת כאשר מקצים בלוק זיכרון גדול יותר מהגודל המבוקש בפועל, והזיכרון העודף בתוך הבלוק אינו בשימוש. הזיכרון המבוזבז נמצא בתוך הבלוק שהוקצה. לדוגמה: במערכת דפדוף (Paging) עם גודל דף של 4KB, אם תהליך זקוק רק ל-3KB עבור דף מסוים, ה-1KB הנותר בתוך אותו דף יהווה פרגמנטציה פנימית.\n\nפרגמנטציה חיצונית (External Fragmentation):\nמתרחשת כאשר יש מספיק זיכרון פנוי בסך הכל כדי לספק בקשה, אך הזיכרון הפנוי מפוזר בבלוקים קטנים ולא רציפים, כך שלא ניתן להקצות בלוק רציף אחד בגודל הנדרש. הזיכרון המבוזבז נמצא מחוץ לכל בלוק שהוקצה. לדוגמה: אם יש לנו 20KB זיכרון פנוי, המחולק לארבעה בלוקים של 5KB כל אחד, ותהליך מבקש 12KB זיכרון רציף, הבקשה תיכשל למרות שסך הזיכרון הפנוי (20KB) גדול מהנדרש (12KB)."}, "difficulty_estimation": "Easy", "_source_file": "0458__Memory_Management__Open__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:50:29", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Memory Management", "Stack", "Heap"], "content": {"text": "הסבירו את ההבדלים העיקריים בין זיכרון ה-Stack לזיכרון ה-Heap בהקשר של ניהול זיכרון במערכות הפעלה. התייחסו לאופן הקצאת הזיכרון, שחרורו, אורך חיי הנתונים ושימושים אופייניים לכל אחד. תנו דוגמת קוד פשוטה ב-C/C++ המדגימה שימוש בשני סוגי הזיכרון.", "code_snippet": "#include <iostream>\n#include <vector> // For dynamic array elements on heap implicitly\n\nvoid exampleFunction() {\n    // Stack allocation: 'x' is allocated on the stack\n    int x = 10;\n    std::cout << \"Stack variable x: \" << x << std::endl;\n\n    // Heap allocation: 'ptr_heap_int' points to memory on the heap\n    int* ptr_heap_int = new int; // Explicit heap allocation\n    *ptr_heap_int = 20;\n    std::cout << \"Heap variable pointed by ptr_heap_int: \" << *ptr_heap_int << std::endl;\n\n    // Another stack allocation: 'arr_stack' is a fixed-size array on the stack\n    int arr_stack[5] = {1, 2, 3, 4, 5};\n    std::cout << \"Stack array element: \" << arr_stack[0] << std::endl;\n\n    // Another heap allocation: 'vec_heap' object itself is on stack,\n    // but its elements are stored on the heap.\n    std::vector<int> vec_heap; \n    vec_heap.push_back(30);\n    std::cout << \"Heap vector element: \" << vec_heap[0] << std::endl;\n\n    // Deallocate explicitly allocated heap memory\n    delete ptr_heap_int;\n    // 'vec_heap' destructor will automatically deallocate its heap memory when it goes out of scope\n}\n\nint main() {\n    exampleFunction();\n    // After exampleFunction returns, all stack-allocated variables within it\n    // (like x, arr_stack, ptr_heap_int pointer, and vec_heap object) are deallocated.\n    // The memory pointed to by ptr_heap_int was explicitly deleted.\n    // The memory used by vec_heap for its elements was implicitly deleted by its destructor.\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "**זיכרון ה-Stack (מחסנית):**\n*   **אופן הקצאה ושחרור:** הקצאה ושחרור אוטומטיים (LIFO - Last-In, First-Out). הזיכרון מוקצה כאשר פונקציה נקראת ומשתנים מקומיים נוצרים, ומשוחרר אוטומטית כאשר הפונקציה מסיימת את ריצתה וחוזרת.\n*   **אורך חיים:** קצר, מוגבל לסקופ (scope) של הפונקציה או הבלוק בו הוגדרו המשתנים.\n*   **גודל:** בדרך כלל קבוע ומוגבל יחסית (נקבע בזמן קומפילציה או בתחילת ריצת התוכנית). ניסיונות להקצות יותר מדי זיכרון על ה-Stack יכולים לגרום ל-Stack Overflow.\n*   **מהירות:** מהיר מאוד, מכיוון שההקצאה פשוטה וכוללת הזזת מצביע (stack pointer).\n*   **שימושים אופייניים:** משתנים מקומיים, פרמטרים של פונקציות, כתובות חזרה מפונקציות (call frames).\n\n**זיכרון ה-Heap (ערימה):**\n*   **אופן הקצאה ושחרור:** הקצאה דינמית וידנית. הזיכרון מוקצה באופן מפורש על ידי המתכנת (באמצעות פונקציות כמו `malloc`/`calloc` ב-C או `new` ב-C++), ודורש שחרור ידני מפורש (באמצעות `free` ב-C או `delete` ב-C++). אי שחרור זיכרון עלול לגרום לדליפות זיכרון (memory leaks).\n*   **אורך חיים:** ארוך, יכול להישאר זמין גם לאחר שהפונקציה שהקצתה אותו סיימה את ריצתה, עד לשחרורו המפורש או סיום התוכנית.\n*   **גודל:** גמיש ולא מוגבל מראש כמו ה-Stack (מוגבל רק על ידי גודל הזיכרון הפיזי/וירטואלי הזמין במערכת).\n*   **מהירות:** איטי יחסית ל-Stack, מכיוון שהקצאה ושחרור דורשים חיפוש של בלוק זיכרון מתאים וניהול מורכב יותר.\n*   **שימושים אופייניים:** אובייקטים ונתונים שגודלם אינו ידוע בזמן קומפילציה, אובייקטים שצריכים לשרוד מעבר לסקופ של פונקציה מסוימת, מבני נתונים דינמיים (רשימות מקושרות, עצים, מערכים דינמיים).\n\n**דוגמת קוד:**\nבקוד המצורף:\n*   `int x` ו-`int arr_stack[5]` מוקצים על ה-Stack. הם קיימים רק כל עוד `exampleFunction` רצה.\n*   `int* ptr_heap_int = new int;` מקצה זיכרון עבור שלם בודד על ה-Heap. המצביע `ptr_heap_int` עצמו מוקצה על ה-Stack, אך הזיכרון אליו הוא מצביע נמצא על ה-Heap. זיכרון זה חייב להיות משוחרר ידנית באמצעות `delete ptr_heap_int;`.\n*   `std::vector<int> vec_heap;` יוצר אובייקט `vector` על ה-Stack. עם זאת, ה-`vector` מנהל באופן פנימי מערך דינמי על ה-Heap עבור האלמנטים שלו. כאשר `vec_heap` יוצא מטווח (scope), ה-destructor שלו משחרר אוטומטית את הזיכרון שהוקצה על ה-Heap עבור האלמנטים."}, "difficulty_estimation": "Easy", "_source_file": "0459__Memory_Management__Open__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:50:47", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Memory Management", "Fragmentation", "Paging", "Segmentation"], "content": {"text": "הסבירו את המושגים של פרגמנטציה פנימית (Internal Fragmentation) ופרגמנטציה חיצונית (External Fragmentation) בניהול זיכרון. עבור כל סוג, ספקו דוגמה קצרה לאופן התרחשותו והציעו טכניקת ניהול זיכרון אחת המסייעת בהפחתתו.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פרגמנטציה פנימית (Internal Fragmentation):\n*   הסבר: מתרחשת כאשר זיכרון מוקצה גדול יותר מהזיכרון הנדרש בפועל, וכתוצאה מכך נותר שטח לא מנוצל בתוך הבלוק שהוקצה.\n*   דוגמה: במערכת המשתמשת בדפדוף (Paging), אם גודל דף הוא 4KB ותהליך זקוק ל-3.5KB, הוא יקבל דף שלם של 4KB. ה-0.5KB הנותרים בתוך הדף אינם מנוצלים על ידי התהליך ומהווים פרגמנטציה פנימית.\n*   הפחתה: ניתן להפחית פרגמנטציה פנימית על ידי שימוש בגדלי דפים (או בלוקים) קטנים יותר, אם כי זה מגדיל את גודל טבלאות הדפים ועשוי להוביל לתקורה (overhead) גבוהה יותר.\n\nפרגמנטציה חיצונית (External Fragmentation):\n*   הסבר: מתרחשת כאשר יש מספיק זיכרון פנוי בסך הכל כדי לספק בקשה, אך הוא מפוזר בבלוקים לא רציפים (חורים), כך שאין בלוק רציף אחד גדול מספיק כדי לעמוד בבקשה.\n*   דוגמה: במערכת המשתמשת בפילוח (Segmentation) או הקצאת זיכרון דינמית (Dynamic Partitioning), לאחר שתהליכים נטענים ונפרקים, נוצרים חורי זיכרון פנויים בגדלים שונים. אם תהליך חדש דורש בלוק זיכרון רציף גדול, ייתכן שלא יוכל להיטען למרות שסך הזיכרון הפנוי מספיק.\n*   הפחתה: טכניקת הדפדוף (Paging) מסייעת רבות בהפחתת פרגמנטציה חיצונית, מכיוון שהיא מאפשרת לטעון את דפי התהליך למסגרות זיכרון פיזיות שאינן רציפות. טכניקה נוספת היא איחוי זיכרון (Compaction), המזיזה בלוקים מוקצים כדי לאסוף את כל הזיכרון הפנוי לבלוק רציף אחד, אך זוהי פעולה יקרה מבחינת ביצועים."}, "difficulty_estimation": "Easy", "_source_file": "0460__Memory_Management__Open__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:50:59", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Memory Management", "Fragmentation"], "content": {"text": "הסבירו מהי פרגמנטציה פנימית (Internal Fragmentation) ופרגמנטציה חיצונית (External Fragmentation) בהקשר של ניהול זיכרון. ציינו גורם אפשרי לכל אחת מהן והציעו דרך אחת לצמצם את הפרגמנטציה החיצונית.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פרגמנטציה פנימית מתרחשת כאשר הזיכרון מוקצה בגושים בגודל קבוע (לדוגמה, דפים), והתהליך או הנתונים אינם ממלאים את הגוש כולו. החלק הנותר בתוך הגוש המוקצה אינו בשימוש אך אינו זמין להקצאות אחרות. גורם אפשרי: הקצאת זיכרון ביחידות בגודל קבוע (למשל, דפים במערכת דפדוף) כאשר בקשות הזיכרון קטנות יותר מגודל היחידה.\n\nפרגמנטציה חיצונית מתרחשת כאשר יש מספיק זיכרון פנוי בסך הכל כדי למלא בקשה, אך הוא מפוזר בבלוקים קטנים ולא רציפים ברחבי הזיכרון, כך שלא ניתן להקצות בלוק רציף אחד בגודל הנדרש. גורם אפשרי: תהליכים נטענים ונפרקים מהזיכרון באופן דינמי, ויוצרים חורים קטנים בין בלוקים תפוסים.\n\nדרך אחת לצמצם פרגמנטציה חיצונית היא באמצעות איחוי (Compaction), שמעביר את כל הבלוקים התפוסים יחד, ובכך מאחד את כל הזיכרון הפנוי לבלוק רציף אחד גדול. דרך נוספת היא שימוש בסגמנטציה או דפדוף, המאפשרים לתהליכים להשתמש בזיכרון לא רציף."}, "difficulty_estimation": "Easy", "_source_file": "0461__Memory_Management__Open__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:51:09", "_subject": "Virtualization"}, {"id": 101, "type": "Open", "topic": ["Memory Management", "Paging", "Virtual Memory"], "content": {"text": "נתונה מערכת הפעלה המשתמשת במנגנון ניהול זיכרון מבוסס דפדוף (paging).\nגודל הדף במערכת הוא 4KB.\nתהליך מסוים ניגש לכתובת וירטואלית `0x1A3B5`.\nבהתאם לטבלת הדפים של התהליך, הדף הוירטואלי הרלוונטי ממופה למסגרת פיזית מספר `0x00F`.\nחשבו את הכתובת הפיזית המתאימה לכתובת הוירטואלית הנתונה ופרטו את שלבי החישוב.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  **חישוב גודל היסט הדף (Page Offset):**\n    גודל הדף הוא 4KB, שזה 4 * 1024 בתים = 4096 בתים.\n    כדי לייצג 4096 ערכים שונים (כתובות בתוך הדף), נדרשים 12 ביטים (2^12 = 4096).\n    לכן, ההיסט (offset) בכתובת הוירטואלית יתפוס את 12 הביטים הפחות משמעותיים (הימניים ביותר).\n\n2.  **פירוק הכתובת הוירטואלית:**\n    הכתובת הוירטואלית הנתונה היא `0x1A3B5`.\n    נמיר אותה לבסיס בינארי: `0x1A3B5` = `0001 1010 0011 1011 0101`.\n    נחלק אותה למספר דף וירטואלי ולהיסט:\n    -   **היסט (Offset):** 12 הביטים הימניים ביותר הם `0011 1011 0101`, שזה בבסיס הקסדצימלי `0x3B5`.\n    -   **מספר דף וירטואלי (Virtual Page Number):** הביטים הנותרים משמאל הם `0001 1010`, שזה בבסיס הקסדצימלי `0x1A`.\n\n3.  **הרכבת הכתובת הפיזית:**\n    נתון שמספר המסגרת הפיזית (Physical Frame Number - PFN) אליו ממופה הדף הוירטואלי `0x1A` הוא `0x00F`.\n    הכתובת הפיזית מורכבת מצירוף מספר המסגרת הפיזית (PFN) וההיסט. ה-PFN מהווה את הביטים המשמעותיים יותר (השמאליים) של הכתובת הפיזית, ואחריו מגיעים ביטי ההיסט.\n    -   PFN (`0x00F`) בבינארי: `0000 1111`\n    -   היסט (`0x3B5`) בבינארי: `0011 1011 0101`\n    נצרף את ה-PFN ל-12 הביטים של ההיסט (כאשר ה-PFN מהווה את הביטים הגבוהים): `0000 1111` (PFN) `0011 1011 0101` (Offset).\n    התוצאה בבינארי היא `0000 1111 0011 1011 0101`.\n    בבסיס הקסדצימלי, זו הכתובת `0x0F3B5`.\n\n    **הכתובת הפיזית הסופית היא `0x0F3B5`.**"}, "difficulty_estimation": "Easy", "_source_file": "0462__Memory_Management__Open__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:51:24", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Memory Management", "Fragmentation"], "content": {"text": "הסבר מהי פרגמנטציה פנימית ומהי פרגמנטציה חיצונית בניהול זיכרון. תאר בקצרה מצב שבו כל אחד מסוגי הפרגמנטציה מתרחש.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פרגמנטציה פנימית (Internal Fragmentation) מתרחשת כאשר זיכרון מוקצה ליחידות בגודל קבוע (לדוגמה, דפים או בלוקים בגודל קבוע), והתהליך זקוק לפחות זיכרון ממה שהוקצה לו. השטח הלא מנוצל בתוך הבלוק המוקצה הוא פרגמנטציה פנימית. לדוגמה: אם גודל דף הוא 4KB ותהליך זקוק ל-3KB, אז 1KB מבוזבז בתוך הדף.\n\nפרגמנטציה חיצונית (External Fragmentation) מתרחשת כאשר יש מספיק זיכרון פנוי בסך הכל כדי לספק בקשה, אך הזיכרון הפנוי מפוזר בבלוקים קטנים ולא רציפים, כך שאף בלוק בודד אינו גדול מספיק כדי לעמוד בבקשה. לדוגמה: במערכת עם הקצאת זיכרון דינמית בגודל משתנה, כאשר תהליכים נטענים ופורקים מהזיכרון, נוצרים 'חורים' קטנים של זיכרון פנוי. תהליך חדש הדורש בלוק זיכרון גדול ורציף לא יוכל להיטען, גם אם סך הזיכרון הפנוי מספיק."}, "difficulty_estimation": "Easy", "_source_file": "0463__Memory_Management__Open__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:51:34", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Memory Management", "Fragmentation"], "content": {"text": "הגדירו מהי 'פרגמנטציה פנימית' (Internal Fragmentation) ומהי 'פרגמנטציה חיצונית' (External Fragmentation) בהקשר של ניהול זיכרון. הסבירו מדוע כל אחד מסוגי הפרגמנטציה הללו מתרחש, ותנו דוגמה לשיטת ניהול זיכרון שעלולה להוביל אליו.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פרגמנטציה פנימית (Internal Fragmentation):\nהגדרה: זיכרון שהוקצה לתהליך אך אינו בשימוש בפועל על ידו, ונשאר ריק בתוך יחידת ההקצאה. זיכרון זה אינו נגיש לתהליכים אחרים.\nהסבר מדוע מתרחשת: מתרחשת כאשר זיכרון מוקצה בגושים בגודל קבוע (לדוגמה, דפים במערכת דפדוף). אם תהליך זקוק לפחות זיכרון מגודל הגוש המוקצה, השארית בתוך הגוש מבוזבזת ואינה ניתנת לשימוש על ידי תהליכים אחרים.\nדוגמה לשיטת ניהול זיכרון: מערכת דפדוף (Paging). לדוגמה, אם גודל דף הוא 4KB ותהליך זקוק רק ל-1KB, אז 3KB בתוך הדף מבוזבזים כפרגמנטציה פנימית.\n\nפרגמנטציה חיצונית (External Fragmentation):\nהגדרה: מצב שבו קיים מספיק זיכרון פנוי במערכת כדי לעמוד בדרישת הקצאה, אך הוא מפוזר בחלקים קטנים ולא רצופים, כך שלא ניתן להקצותו לתהליך הדורש גוש זיכרון רצוף בגודל מסוים.\nהסבר מדוע מתרחשת: מתרחשת כאשר תהליכים נטענים ופורקים זיכרון באופן דינמי, ויוצרים \"חורים\" קטנים של זיכרון פנוי בין אזורים תפוסים. עם הזמן, הזיכרון הפיזי עלול להפוך למקוטע מאוד.\nדוגמה לשיטת ניהול זיכרון: מערכת סגמנטציה (Segmentation) או מערכות המשתמשות בהקצאת זיכרון בגושים בגודל משתנה (Variable-sized partitions) ללא מנגנון איחוי (compaction) יעיל. לדוגמה, אם יש 10MB פנויים בסך הכל, אך הם מפוזרים כעשרה גושים של 1MB, לא ניתן להקצות גוש רצוף של 5MB."}, "difficulty_estimation": "Easy", "_source_file": "0464__Memory_Management__Open__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 21:51:46", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Memory Management", "Virtual Memory", "Paging"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי וב-Paging. המערכת כוללת זיכרון וירטואלי בגודל 2GB, זיכרון פיזי בגודל 512MB, וגודל דף הוא 4KB. כל רשומת טבלת דפים (PTE) כוללת 4 ביטי סטטוס בנוסף לכתובת המסגרת הפיזית (PFN). יש לפרט ולנמק את כל החישובים.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "10.1", "text": "מהו גודל ה-VPN ומהו גודל ה-PFN בביטים?", "code_snippet": null, "options": null}, {"id": "10.2", "text": "מהו הגודל המינימלי של רשומת טבלת דפים (PTE) בבתים, בהנחה שהיא מעוגלת לחזקה הקרובה של 2 בבתים?", "code_snippet": null, "options": null}, {"id": "10.3", "text": "כמה רשומות PTE יכולות להיכנס לדף טבלה בודד?", "code_snippet": null, "options": null}, {"id": "10.4", "text": "כמה רמות נדרשות לטבלת הדפים ההיררכית במערכת זו, וכמה ביטים מכתובת ה-VPN משמשים לכל רמה?", "code_snippet": null, "options": null}, {"id": "10.5", "text": "מהו סך הזיכרון הפיזי שיידרש לטבלת הדפים של תהליך, אם כל המרחב הוירטואלי שלו מאוכלס (fully populated)?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  גודל הזיכרון הווירטואלי הוא 2GB = 2^31 בתים, לכן כתובת וירטואלית היא באורך 31 ביטים. גודל הדף הוא 4KB = 2^12 בתים, לכן ההיסט בתוך הדף הוא 12 ביטים. מכאן, גודל ה-VPN הוא 31 - 12 = 19 ביטים.\n    גודל הזיכרון הפיזי הוא 512MB = 2^29 בתים, לכן כתובת פיזית היא באורך 29 ביטים. ההיסט בתוך המסגרת זהה לזה שבתוך הדף – 12 ביטים. מכאן, גודל ה-PFN הוא 29 - 12 = 17 ביטים.\n2.  רשומת PTE צריכה להכיל את ה-PFN (17 ביטים) ואת ביטי הסטטוס (4 ביטים), סה\"כ 17 + 4 = 21 ביטים. בהנחה שהגודל מעוגל לחזקה הקרובה של 2 בבתים, 21 ביטים דורשים 4 בתים (שכן 2 בתים הם 16 ביטים ואינם מספיקים, ואילו 4 בתים הם 32 ביטים ומספיקים).\n3.  גודל דף הוא 4KB = 4096 בתים. גודל רשומת PTE הוא 4 בתים. לכן, מספר רשומות PTE שיכולות להיכנס לדף טבלה בודד הוא 4096 / 4 = 1024 רשומות.\n4.  גודל ה-VPN הוא 19 ביטים. בכל דף טבלה נכנסות 1024 רשומות, כלומר כל אינדקס ברמת טבלה יכול להיות באורך log2(1024) = 10 ביטים. כדי למפות 19 ביטים נדרשות 2 רמות (19 / 10 = 1.9, מעוגל למעלה). הרמה העליונה (Level 1) תשתמש ב-10 ביטים, והרמה התחתונה (Level 2) תשתמש ב-9 ביטים (19 - 10 = 9).\n5.  עבור טבלת דפים מאוכלסת במלואה:\n    *   רמת טבלת הדפים הראשונה (Page Directory) דורשת דף אחד.\n    *   רמת טבלת הדפים הראשונה מכילה 1024 רשומות. מכיוון שרק 9 ביטים משמשים לאינדקס ברמה השנייה, רק 2^9 = 512 רשומות ברמה הראשונה יצביעו לטבלאות דפים ברמה השנייה. לכן, יהיו 512 טבלאות דפים ברמה השנייה.\n    *   סה\"כ דפים שנדרשים עבור טבלת הדפים: 1 (לרמה 1) + 512 (לרמה 2) = 513 דפים.\n    *   הזיכרון הפיזי הכולל שיידרש הוא 513 דפים * 4KB/דף = 2052KB."}, "difficulty_estimation": "Medium", "_source_file": "0465__Memory_Management__Open__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:52:14", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Memory Management", "Virtual Memory", "Paging", "TLB"], "content": {"text": "נתונה מערכת עם זיכרון וירטואלי של 16MB, זיכרון פיזי של 32MB וגודל דף של 4KB. רשומת טבלת דפים (PTE) מכילה 4 ביטים לסטטוס בנוסף לכתובת המסגרת הפיזית (PFN). זמן גישה לזיכרון הראשי הוא 100ns וזמן גישה ל-TLB הוא 20ns. נתון ששיעור הפגיעה (Hit Rate) ב-TLB הוא 95%.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "10.1", "text": "מהם הגדלים של ה-VPN, ה-PFN ו-Offset בביטים?", "code_snippet": null, "options": null}, {"id": "10.2", "text": "מהו הגודל המינימלי של רשומת טבלת דפים (PTE) בבתים?", "code_snippet": null, "options": null}, {"id": "10.3", "text": "מהו הגודל של טבלת דפים לינארית של תהליך אחד בבתים?", "code_snippet": null, "options": null}, {"id": "10.4", "text": "מהו זמן הגישה האפקטיבי לזיכרון (Effective Access Time - EAT) במערכת זו?", "code_snippet": null, "options": null}], "points": 30, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. חישוב גודל ביטים: \n   זיכרון וירטואלי: 16MB = 2^24 בתים, לכן כתובת וירטואלית היא באורך 24 ביטים.\n   זיכרון פיזי: 32MB = 2^25 בתים, לכן כתובת פיזית היא באורך 25 ביטים.\n   גודל דף: 4KB = 2^12 בתים, לכן ההיסט (Offset) הוא באורך 12 ביטים.\n   VPN (Virtual Page Number): 24 ביטים (VA) - 12 ביטים (Offset) = 12 ביטים.\n   PFN (Physical Frame Number): 25 ביטים (PA) - 12 ביטים (Offset) = 13 ביטים.\n   \n   לכן: VPN = 12 ביטים, PFN = 13 ביטים, Offset = 12 ביטים.\n\n2. גודל רשומת טבלת דפים (PTE):\n   PFN = 13 ביטים.\n   ביטי סטטוס = 4 ביטים.\n   סה\"כ ביטים לרשומת PTE = 13 + 4 = 17 ביטים.\n   כדי לאחסן 17 ביטים, נדרשים מינימום 3 בתים (17 ביטים / 8 ביטים/בית = 2.125, מעוגל למעלה ל-3 בתים).\n   \n   לכן: גודל PTE מינימלי הוא 3 בתים.\n\n3. גודל טבלת דפים לינארית:\n   מספר הדפים הווירטואליים: 2^VPN = 2^12 = 4096 דפים.\n   גודל טבלת הדפים = מספר דפים * גודל PTE.\n   גודל טבלת הדפים = 4096 * 3 בתים = 12288 בתים = 12KB.\n   \n   לכן: גודל טבלת דפים לינארית הוא 12KB.\n\n4. זמן גישה אפקטיבי לזיכרון (EAT):\n   EAT = (שיעור פגיעה ב-TLB * (זמן גישה ל-TLB + זמן גישה לזיכרון)) + (שיעור החטאה ב-TLB * (זמן גישה ל-TLB + 2 * זמן גישה לזיכרון))\n   שיעור פגיעה = 0.95\n   שיעור החטאה = 1 - 0.95 = 0.05\n   זמן גישה ל-TLB = 20ns\n   זמן גישה לזיכרון = 100ns\n   \n   EAT = (0.95 * (20ns + 100ns)) + (0.05 * (20ns + 100ns + 100ns))\n   EAT = (0.95 * 120ns) + (0.05 * 220ns)\n   EAT = 114ns + 11ns\n   EAT = 125ns\n   \n   לכן: זמן הגישה האפקטיבי לזיכרון הוא 125ns."}, "difficulty_estimation": "Medium", "_source_file": "0466__Memory_Management__Open__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:52:33", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Memory Management", "Virtual Memory", "Paging"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם כתובות וירטואליות בגודל 2GB, וזיכרון פיזי בגודל 16GB. גודל דף הוא 8KB. טבלת הדפים היא דו-רמתית (Two-level page table), וגודל כל רשומת טבלת דפים (PTE) הוא 4 בתים. יש לפרט ולנמק את כל החישובים.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "10.1", "text": "כמה ביטים מוקצים לכל אחד מהשדות הבאים בכתובת הווירטואלית: VPN (Virtual Page Number) והיסט (Offset)? כמה ביטים מוקצים ל-PFN (Physical Frame Number) בכתובת הפיזית?", "code_snippet": null, "options": null}, {"id": "10.2", "text": "כמה רשומות (PTEs) יכולות להיכנס לדף בודד של טבלת הדפים? בהתאם לכך, כמה ביטים משמשים לכל רמה בטבלת הדפים הדו-רמתית (VPN1 ו-VPN2)?", "code_snippet": null, "options": null}, {"id": "10.3", "text": "תהליך חדש מבצע הקצאת זיכרון דינמית (malloc) של 10MB. כמה מסגרות פיזיות יתפסו על ידי הנתונים עצמם, וכמה מסגרות יתפסו על ידי טבלאות הדפים הנדרשות כדי למפות זיכרון זה, במקרה המקסימלי (כלומר, כל הדפים וטבלאות הדפים מוצבים בזיכרון פיזי)?", "code_snippet": null, "options": null}], "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  **חישוב ביטים:**\n    *   זיכרון וירטואלי: 2GB = 2^31 בתים, לכן כתובת וירטואלית היא 31 ביטים.\n    *   זיכרון פיזי: 16GB = 2^34 בתים, לכן כתובת פיזית היא 34 ביטים.\n    *   גודל דף: 8KB = 2^13 בתים, לכן ההיסט (Offset) הוא 13 ביטים.\n    *   **VPN**: 31 ביטים (VA) - 13 ביטים (Offset) = 18 ביטים.\n    *   **PFN**: 34 ביטים (PA) - 13 ביטים (Offset) = 21 ביטים.\n\n2.  **רשומות בדף ורמות בטבלה:**\n    *   גודל דף: 8KB = 8192 בתים.\n    *   גודל רשומת PTE: 4 בתים.\n    *   מספר רשומות בדף טבלה: 8192 / 4 = 2048 רשומות.\n    *   2048 = 2^11, לכן כל רמה בטבלת הדפים יכולה למפות 11 ביטים מכתובת ה-VPN.\n    *   יש לנו 18 ביטים ל-VPN וטבלה דו-רמתית:\n        *   רמה שנייה (VPN2 - offset בתוך טבלת דפים של רמה 1): 11 ביטים.\n        *   רמה ראשונה (VPN1 - אינדקס בטבלת הדפים הראשית): 18 - 11 = 7 ביטים.\n\n3.  **הקצאת 10MB זיכרון:**\n    *   **מספר דפים לנתונים:** 10MB = 10 * 1024 KB = 10240 KB.\n    *   גודל דף: 8KB.\n    *   מספר דפים נדרשים לנתונים: 10240KB / 8KB = 1280 דפים.\n    *   לכן, הנתונים עצמם יתפסו **1280 מסגרות פיזיות**.\n\n    *   **מספר דפים לטבלאות הדפים (במקרה המקסימלי):**\n        *   כל דף טבלת דפים ברמה 2 מכיל 2048 רשומות (PTEs).\n        *   כדי למפות 1280 דפים, במקרה המקסימלי, ההקצאה יכולה להתפרס על פני 2 דפי טבלאות ברמה 2 (לדוגמה, אם ההקצאה מתחילה ב-VPN שהינו הרשומה האחרונה בדף טבלה ברמה 2 מסוים, והשאר גולשים לדף הטבלה הבא ברמה 2).\n        *   לכן, נצטרך **2 מסגרות פיזיות** עבור טבלאות הדפים ברמה 2.\n        *   (בהתאם לדוגמאות, הרמה הראשונה של טבלת הדפים, ה-Page Directory, נחשבת כקיימת מראש ואינה נכללת בחישוב ההקצאה החדשה).\n\n    *   **סה\"כ מסגרות פיזיות:** 1280 (לנתונים) + 2 (לטבלאות דפים ברמה 2) = **1282 מסגרות פיזיות**."}, "difficulty_estimation": "Medium", "_source_file": "0467__Memory_Management__Open__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:53:06", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Memory Management", "Virtual Memory", "Paging", "Page Table"], "content": {"text": "נתונה מערכת עם זיכרון וירטואלי של 2GB וזיכרון פיזי של 128GB. גודל דף הוא 8KB.\nבכל רשומת טבלת דפים (PTE) נשמרים 3 ביטים של סטטוס בנוסף למספר מסגרת פיזית (PFN).\nיש לפרט ולנמק את כל החישובים.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "10.1", "text": "מהם הגדלים של ה-VPN וה-PFN (בביטים)?", "code_snippet": null, "options": null}, {"id": "10.2", "text": "מהו גודל רשומת טבלת דפים (PTE) בבתים?", "code_snippet": null, "options": null}, {"id": "10.3", "text": "בהנחה שמערכת ההפעלה משתמשת בטבלת דפים היררכית, וכאשר כל חלק בטבלת הדפים תופס דף אחד בזיכרון הפיזי, כמה רמות דרושות לטבלת הדפים של תהליך, וכמה ביטים בכתובת הווירטואלית מוקצים לכל רמה?", "code_snippet": null, "options": null}, {"id": "10.4", "text": "כמה זיכרון פיזי (בבתים) תתפוס טבלת דפים היררכית של תהליך, במקרה הגרוע ביותר (worst case), אם כל הזיכרון הוירטואלי שלו ממופה?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1. **גודל VPN ו-PFN (בביטים):**\n   *   גודל זיכרון וירטואלי: 2GB = 2^31 בתים. לכן, כתובת וירטואלית היא באורך 31 ביטים.\n   *   גודל זיכרון פיזי: 128GB = 2^37 בתים. לכן, כתובת פיזית היא באורך 37 ביטים.\n   *   גודל דף: 8KB = 2^13 בתים. לכן, ההיסט (Offset) בכתובת הוא באורך 13 ביטים.\n   *   VPN (Virtual Page Number) = אורך כתובת וירטואלית - אורך היסט = 31 - 13 = 18 ביטים.\n   *   PFN (Physical Frame Number) = אורך כתובת פיזית - אורך היסט = 37 - 13 = 24 ביטים.\n\n2. **גודל רשומת טבלת דפים (PTE) בבתים:**\n   *   רשומת PTE מכילה PFN (24 ביטים) ו-3 ביטים של סטטוס.\n   *   סה\"כ ביטים ב-PTE = 24 + 3 = 27 ביטים.\n   *   בדרך כלל, רשומות PTE מעוגלות לגודל של מילה (לרוב 4 בתים = 32 ביטים) לצורך יישור וגישה יעילה.\n   *   לכן, גודל רשומת PTE הוא 4 בתים.\n\n3. **מספר רמות וחלוקת ביטים לטבלת דפים היררכית:**\n   *   גודל דף: 8KB. גודל PTE: 4 בתים.\n   *   מספר רשומות שיכולות להיכנס לדף אחד של טבלת דפים = גודל דף / גודל PTE = 8KB / 4 בתים = 8192 / 4 = 2048 רשומות.\n   *   מספר ביטים לכל אינדקס ברמת טבלת דפים = log2(2048) = 11 ביטים.\n   *   סה\"כ ביטי VPN = 18 ביטים.\n   *   מספר רמות דרושות = ceil(VPN ביטים / ביטים לרמה) = ceil(18 / 11) = 2 רמות.\n   *   חלוקת הביטים (מהרמה העליונה ביותר): \n        *   רמה 1 (מדריך דפים - Page Directory Index): 11 ביטים.\n        *   רמה 2 (טבלת דפים - Page Table Index): 18 - 11 = 7 ביטים.\n        *   (Offset): 13 ביטים.\n        *   סה\"כ ביטי כתובת וירטואלית = 11 (P1) + 7 (P2) + 13 (Offset) = 31 ביטים.\n\n4. **זיכרון פיזי שתתפוס טבלת דפים היררכית (במקרה הגרוע ביותר):**\n   *   במקרה הגרוע ביותר, כל הזיכרון הוירטואלי של התהליך ממופה, כלומר כל 2^18 הדפים הוירטואליים נמצאים בשימוש.\n   *   רמת ה-P1 (מדריך הדפים הראשי) תתפוס דף אחד בזיכרון הפיזי (8KB).\n   *   רמת ה-P1 מכילה 2^11 רשומות (מכיוון שהאינדקס לרמה זו הוא 11 ביטים). במקרה הגרוע, כל הרשומות הללו מצביעות על טבלאות דפים ברמה P2.\n   *   לכן, יהיו 2^11 טבלאות דפים ברמה P2.\n   *   כל טבלת דפים ברמה P2 תופסת דף אחד (8KB) בזיכרון הפיזי.\n   *   סה\"כ זיכרון פיזי עבור טבלאות הדפים:\n        *   1 דף (עבור מדריך P1) + 2^11 דפים (עבור טבלאות P2) \n        *   = 1 + 2048 = 2049 דפים.\n        *   סה\"כ זיכרון פיזי = 2049 דפים * 8KB לדף = 16392KB.\n        *   בבתים: 16392 * 1024 = 16,785,408 בתים."}, "difficulty_estimation": "Medium", "_source_file": "0468__Memory_Management__Open__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:53:31", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Memory Management", "Virtual Memory", "Paging"], "content": {"text": "נתונה מערכת עם זיכרון וירטואלי של 2GB, גודל דף של 8KB, וזיכרון פיזי של 16GB.\nמהם הגדלים של ה-VPN, ה-PFN, וכמה זיכרון פיזי תתפוס טבלת דפים (לינארית) של תהליך, במינימום?\nגודל VPN: ________ גודל PFN: ________ גודל טבלה: ________", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.   **חישוב גודל VPN (Virtual Page Number):**\n    *   זיכרון וירטואלי הוא 2GB. בביטים, זה 2 * 2^30 = 2^31 בתים. לכן, אורך הכתובת הוירטואלית הוא 31 ביטים.\n    *   גודל דף הוא 8KB. בביטים, זה 8 * 2^10 = 2^3 * 2^10 = 2^13 בתים. לכן, אורך ההיסט (Offset) בתוך הדף הוא 13 ביטים.\n    *   גודל ה-VPN הוא אורך הכתובת הוירטואלית פחות אורך ההיסט: 31 ביטים - 13 ביטים = 18 ביטים.\n\n2.   **חישוב גודל PFN (Physical Frame Number):**\n    *   זיכרון פיזי הוא 16GB. בביטים, זה 16 * 2^30 = 2^4 * 2^30 = 2^34 בתים. לכן, אורך הכתובת הפיזית הוא 34 ביטים.\n    *   אורך ההיסט (Offset) זהה לזה שבכתובת הוירטואלית: 13 ביטים.\n    *   גודל ה-PFN הוא אורך הכתובת הפיזית פחות אורך ההיסט: 34 ביטים - 13 ביטים = 21 ביטים.\n\n3.   **חישוב גודל טבלת דפים לינארית (במינימום):**\n    *   מספר הדפים הוירטואליים הכולל בתהליך הוא גודל הזיכרון הוירטואלי חלקי גודל הדף: 2GB / 8KB = (2^31 בתים) / (2^13 בתים) = 2^(31-13) = 2^18 דפים.\n    *   טבלת דפים לינארית מכילה רשומה אחת (PTE) עבור כל דף וירטואלי, ולכן יש בה 2^18 רשומות.\n    *   כל רשומת PTE צריכה להכיל לפחות את ה-PFN. גודל ה-PFN הוא 21 ביטים. כדי לאחסן 21 ביטים, נדרשים 3 בתים (שכן 2 בתים מכילים 16 ביטים ו-3 בתים מכילים 24 ביטים, וזה המספר המינימלי של בתים הנדרש).\n    *   גודל טבלת הדפים הכולל הוא מספר הרשומות כפול גודל רשומה: 2^18 רשומות * 3 בתים/רשומה = 262,144 * 3 בתים = 786,432 בתים.\n    *   להמרה ל-KB: 786,432 בתים / 1024 בתים/KB = 768KB."}, "difficulty_estimation": "Medium", "_source_file": "0469__Memory_Management__Open__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:53:48", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Memory Management", "Virtual Memory", "Paging"], "content": {"text": "נתונה מערכת עם זיכרון וירטואלי של 2GB, גודל דף של 8KB, וזיכרון פיזי של 16GB.\nבהנחה שכל רשומת טבלת דפים (PTE) תופסת 4 בתים, מהם הגדלים של ה-VPN, ה-PFN, וכמה זיכרון פיזי תתפוס טבלת דפים (לינארית) של תהליך, במינימום?\nגודל VPN: ________ גודל PFN: ________ גודל טבלה: ________", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כתובת וירטואלית היא 31 ביטים (זיכרון וירטואלי 2GB = 2^31 בתים).\nגודל ההיסט הוא 13 ביטים (גודל דף 8KB = 2^13 בתים).\nלכן, גודל ה-VPN הוא 31 - 13 = 18 ביטים.\n\nכתובת פיזית היא 34 ביטים (זיכרון פיזי 16GB = 2^34 בתים).\nגודל ההיסט זהה – 13 ביטים.\nלכן, גודל ה-PFN הוא 34 - 13 = 21 ביטים.\n\nלכל תהליך יש 2^18 דפים וירטואליים (2GB / 8KB = 2^31 / 2^13).\nטבלת הדפים הלינארית מכילה 2^18 רשומות.\nכל רשומה תופסת 4 בתים (נתון).\nלכן, גודל הטבלה כולה הוא 2^18 * 4 בתים = 262,144 * 4 בתים = 1,048,576 בתים = 1MB."}, "difficulty_estimation": "Medium", "_source_file": "0470__Memory_Management__Open__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:53:59", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Memory Management", "Virtual Memory", "Paging"], "content": {"text": "נתונה מערכת עם זיכרון וירטואלי בגודל 2GB וזיכרון פיזי בגודל 256MB. גודל דף במערכת הוא 8KB. רשומת טבלת דפים (PTE) כוללת 3 ביטים של סטטוס (לדוגמה, Valid, Dirty, Accessed) בנוסף לביטי ה-PFN. יש לפרט ולנמק את כל החישובים.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "10.1", "text": "מהם הגדלים של ה-VPN (Virtual Page Number) וה-PFN (Physical Frame Number) בביטים?", "code_snippet": null, "options": null}, {"id": "10.2", "text": "מה גודל רשומת טבלת דפים (PTE) בבתים, בהנחה שהיא מעוגלת לגודל מילה סטנדרטי (4 בתים)?", "code_snippet": null, "options": null}, {"id": "10.3", "text": "מה גודל טבלת דפים לינארית (single-level) של תהליך, במידה והיא ממפה את כל הזיכרון הווירטואלי שלו?", "code_snippet": null, "options": null}, {"id": "10.4", "text": "אם המערכת משתמשת בטבלת דפים היררכית בעלת שתי רמות, כמה ביטים משמשים לכל רמה של הכתובת הוירטואלית?", "code_snippet": null, "options": null}, {"id": "10.5", "text": "כמה מסגרות פיזיות יתפסו על ידי טבלת הדפים (היררכית, שתי רמות) של תהליך המשתמש בכל הזיכרון הוירטואלי שהוקצה לו?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  **חישוב גדלי VPN ו-PFN:**\n    *   גודל זיכרון וירטואלי = 2GB = 2^31 בתים. לכן, כתובת וירטואלית היא באורך 31 ביטים.\n    *   גודל זיכרון פיזי = 256MB = 2^28 בתים. לכן, כתובת פיזית היא באורך 28 ביטים.\n    *   גודל דף = 8KB = 2^13 בתים. לכן, ההיסט בתוך הדף (offset) הוא באורך 13 ביטים.\n    *   **VPN** (Virtual Page Number) = אורך כתובת וירטואלית - אורך היסט = 31 - 13 = **18 ביטים**.\n    *   **PFN** (Physical Frame Number) = אורך כתובת פיזית - אורך היסט = 28 - 13 = **15 ביטים**.\n\n2.  **גודל רשומת טבלת דפים (PTE):**\n    *   PTE מכילה PFN ועוד 3 ביטי סטטוס.\n    *   סה\"כ ביטים ל-PTE = 15 (PFN) + 3 (סטטוס) = 18 ביטים.\n    *   בהנחה שה-PTE מעוגלת לגודל מילה סטנדרטי של 4 בתים (32 ביטים) לצורך יישור ויעילות, למרות ש-18 ביטים טכנית יכולים להיכנס ב-3 בתים.\n    *   **גודל PTE = 4 בתים**.\n\n3.  **גודל טבלת דפים לינארית:**\n    *   מספר הדפים הוירטואליים הכולל שצריך למפות: 2GB / 8KB = 2^31 / 2^13 = 2^18 דפים.\n    *   גודל טבלת הדפים הלינארית = מספר דפים * גודל PTE = 2^18 * 4 בתים = 2^20 בתים = **1MB**.\n\n4.  **ביטים לכל רמה בטבלת דפים היררכית (שתי רמות):**\n    *   מספר ביטי ה-VPN הוא 18.\n    *   גודל דף הוא 8KB = 2^13 בתים.\n    *   בכל דף יכולות להיכנס: גודל דף / גודל PTE = 2^13 בתים / 4 בתים = 2^11 = 2048 רשומות.\n    *   לכן, כל רמה בטבלת הדפים יכולה למפות עד 2^11 דפים/טבלאות. כלומר, כל רמה משתמשת ב-11 ביטים לכל היותר.\n    *   מכיוון שיש לנו 18 ביטי VPN, נצטרך שתי רמות:\n        *   רמה עליונה (Page Directory): תשתמש ב-18 - 11 = **7 ביטים**.\n        *   רמה תחתונה (Page Table): תשתמש ב-**11 ביטים**.\n\n5.  **מספר מסגרות פיזיות לטבלת הדפים ההיררכית (שתי רמות):**\n    *   **רמת ה-Page Directory (PD):**\n        *   מכילה 2^7 = 128 רשומות (PTEs). \n        *   גודל ה-PD = 128 רשומות * 4 בתים/רשומה = 512 בתים.\n        *   ה-PD נכנס כולו למסגרת פיזית אחת (512 בתים < 8KB).\n        *   **1 מסגרת** עבור ה-PD.\n    *   **רמות ה-Page Tables (PTs):**\n        *   ישנם 2^7 = 128 מצביעים ב-PD. במקרה שהתהליך משתמש בכל הזיכרון הוירטואלי, כל המצביעים ב-PD תקפים, וכל אחד מצביע ל-PT נפרדת. לכן, יהיו 128 טבלאות PT.\n        *   כל PT מכילה 2^11 = 2048 רשומות.\n        *   גודל כל PT = 2048 רשומות * 4 בתים/רשומה = 8192 בתים = 8KB.\n        *   כל PT תופסת בדיוק מסגרת פיזית אחת.\n        *   סה\"כ מסגרות עבור ה-PTs = 128 PTs * 1 מסגרת/PT = **128 מסגרות**.\n    *   **סה\"כ מסגרות לטבלת הדפים = 1 (PD) + 128 (PTs) = 129 מסגרות**."}, "difficulty_estimation": "Medium", "_source_file": "0471__Memory_Management__Open__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:54:21", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Memory Management", "Virtual Memory", "Paging"], "content": {"text": "נתונה מערכת עם זיכרון וירטואלי של 2GB וגודל דף של 8KB. נתון שבכל דף/חלק של טבלת הדפים נכנסות 1024 רשומות (PTE / PDE), וגודל רשומת טבלת דפים הוא 4 בתים. יש לפרט ולנמק את כל החישובים.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "מהם הגדלים של ה-VPN וה-PFN במערכת זו?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "כמה רמות דרושות לטבלת הדפים במערכת זו, וכמה ביטים בכתובת הווירטואלית משמשים לכל רמה?", "code_snippet": null, "options": null}, {"id": "1.3", "text": "תהליך ביצע הקצאת זיכרון דינמית (malloc) של 10MB. כמה מסגרות יתפסו בזיכרון הראשי בעקבות ביצוע פקודה זו, במקרה המקסימלי?", "code_snippet": null, "options": null}], "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.1. זיכרון וירטואלי של 2GB הוא 2^31 בתים, לכן כתובת וירטואלית היא באורך 31 ביטים. גודל דף הוא 8KB, כלומר 2^13 בתים, לכן ההיסט (Offset) הוא באורך 13 ביטים. מכאן, VPN = 31 - 13 = 18 ביטים.\nגודל רשומת טבלת דפים (PTE) הוא 4 בתים (32 ביטים). בהינתן 5 ביטים של סטטוס (כמקובל במערכות רבות), ה-PFN הוא באורך 32 - 5 = 27 ביטים. (גודל ה-PFN נגזר מגודל ה-PTE ומספר ביטי הסטטוס, ומגדיר את הזיכרון הפיזי המקסימלי הנתמך על ידי ה-PTE).\n\n1.2. מספר הדפים הווירטואליים הכולל בתהליך הוא 2GB / 8KB = 2^31 / 2^13 = 2^18 דפים.\nבכל דף של טבלת הדפים נכנסות 1024 = 2^10 רשומות.\nכדי למפות 2^18 דפים, נצטרך (2^18) / (2^10) = 2^8 רשומות ברמה העליונה. מכיוון ש-2^8 הוא קטן מ-2^10 (מספר הרשומות בדף בודד של טבלת דפים), נצטרך שתי רמות לטבלת הדפים. עבור הרמה התחתונה (ה-VPN התחתון) נשתמש ב-10 ביטים, ועבור הרמה העליונה (ה-VPN העליון) נשתמש ב-8 ביטים. (סה\"כ 10+8=18 ביטים עבור VPN).\n\n1.3. הקצאה של 10MB היא למעשה הקצאה של 10MB / 8KB = (10 * 1024 KB) / 8KB = 10 * 128 = 1280 דפים.\nבמקרה המקסימלי, אם ההקצאה אינה מיושרת לתחילת דף (כלומר, מתחילה באמצע דף ונגמרת באמצע דף אחר), היא יכולה להתפרס על פני 1280 + 1 = 1281 דפים בזיכרון הווירטואלי.\nעבור טבלת הדפים: 1281 רשומות דרושות עבור הדפים שהוקצו. כל דף בטבלת הדפים מכיל 1024 רשומות. לכן, כדי לאחסן 1281 רשומות, נצטרך ⌈1281 / 1024⌉ = 2 דפים של טבלת דפים ברמה השנייה. (2^10 רשומות בדף אחד).\nהדפים הללו עצמם (של טבלת הדפים) צריכים להיות מוקצים בזיכרון הפיזי. הרמה הראשונה של טבלת הדפים (ה-Page Directory) קיימת תמיד ולא נספרת כהקצאה חדשה במקרה זה (אלא אם צוין אחרת).\nסה\"כ מסגרות בזיכרון הראשי במקרה המקסימלי: 1281 (עבור הנתונים) + 2 (עבור דפי טבלת הדפים ברמה השנייה) = 1283 מסגרות."}, "difficulty_estimation": "Medium", "_source_file": "0472__Memory_Management__Open__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 21:54:40", "_subject": "Virtualization"}, {"id": 7, "type": "Open", "topic": ["Memory Management", "Paging", "Virtual Memory", "TLB", "Page Replacement", "Protection"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם מנגנון דפדוף (paging) רב-שכבתי. להלן פרטי המערכת:\n*   גודל מרחב הכתובות הווירטואלי (Virtual Address Space) הוא 48 ביטים.\n*   גודל דף פיזי ולוגי הוא 8KB (כלומר, 2^13 בתים).\n*   טבלאות הדפים הן רב-שכבתיות (Multi-level Page Tables), וכל טבלת דפים ברמה מסוימת נשמרת בדף פיזי אחד בדיוק.\n*   כל כניסה בטבלת דפים (Page Table Entry - PTE) היא בגודל 64 ביטים (8 בתים) ומכילה את מספר המסגרת הפיזית (Physical Frame Number - PFN) וכן 6 ביטי בקרה (Valid, Dirty, Accessed, Read/Write, Execute, Global).\n*   המערכת כוללת TLB בגודל 128 כניסות, שהוא Fully Associative.\n*   זמני גישה:\n    *   גישה ל-TLB: 1 מחזור שעון (CPU cycle).\n    *   גישה לזיכרון ראשי (RAM): 100 מחזורי שעון.\n    *   גישה לזיכרון משני (דיסק): 10^7 מחזורי שעון.\n*   מדיניות החלפת הדפים (Page Replacement Policy) היא LRU.\n", "code_snippet": null, "options": null}, "sub_questions": [{"id": "7.1", "text": "כמה רמות של טבלאות דפים נדרשות במערכת זו כדי למפות את מרחב הכתובות הווירטואלי? פרט את החישוב.", "code_snippet": null, "options": null}, {"id": "7.2", "text": "מהו גודל הזיכרון הפיזי המקסימלי במערכת זו? פרט את החישוב.", "code_snippet": null, "options": null}, {"id": "7.3", "text": "תהליך מנסה לבצע פעולת כתיבה (write) לכתובת וירטואלית מסוימת. תאר את רצף הפעולות שיתרחשו במקרה הגרוע ביותר (worst-case scenario), וחשב את הזמן הכולל שייקח לפעולה זו במחזורי שעון.", "code_snippet": null, "options": null}, {"id": "7.4", "text": "נניח שתהליך מנסה לבצע קוד (fetch instruction) מכתובת וירטואלית שה-PTE שלה מציין Read/Write=1, Execute=0. מה יקרה? הסבר.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון שאלה 7:\n\n7.1: חישוב מספר רמות טבלת הדפים:\n*   גודל מרחב הכתובות הווירטואלי (VA) הוא 48 ביטים.\n*   גודל דף הוא 8KB, כלומר 2^13 בתים. לכן, ההיסט (offset) בתוך הדף הוא 13 ביטים.\n*   מספר הביטים לכתובת הדף הווירטואלי (VPN) הוא: 48 ביטים (VA) - 13 ביטים (offset) = 35 ביטים.\n*   כל כניסה בטבלת דפים (PTE) היא בגודל 8 בתים (64 ביטים).\n*   כל טבלת דפים מאוחסנת בדף פיזי אחד בגודל 8KB. לכן, מספר הכניסות בכל טבלת דפים הוא: 8KB / 8 בתים/PTE = 1024 כניסות (2^10 כניסות).\n*   כל רמה בטבלת הדפים משתמשת ב-10 ביטים מתוך ה-VPN כדי לבחור את הכניסה המתאימה.\n*   מספר הרמות הנדרשות הוא: ceil(35 ביטים / 10 ביטים לרמה) = ceil(3.5) = 4 רמות.\n    *   רמה 1: 10 ביטים\n    *   רמה 2: 10 ביטים\n    *   רמה 3: 10 ביטים\n    *   רמה 4: 5 ביטים\n    (סה\"כ 35 ביטים עבור VPN).\n\n7.2: חישוב גודל הזיכרון הפיזי המקסימלי:\n*   גודל PTE הוא 64 ביטים. 6 ביטים מוקדשים לביטי בקרה (Valid, Dirty, Accessed, Read/Write, Execute, Global).\n*   לכן, מספר הביטים הזמינים עבור מספר המסגרת הפיזית (PFN) הוא: 64 ביטים - 6 ביטים = 58 ביטים.\n*   מספר המסגרות הפיזיות המקסימלי הוא 2^58.\n*   גודל כל מסגרת פיזית הוא 8KB (2^13 בתים).\n*   גודל הזיכרון הפיזי המקסימלי הוא: 2^58 (מספר מסגרות) * 2^13 (גודל מסגרת) = 2^71 בתים.\n\n7.3: עלות גישה לכתובת וירטואלית במקרה הגרוע ביותר:\nמקרה גרוע ביותר כולל:\n1.  **TLB Miss**: הכניסה המבוקשת אינה נמצאת ב-TLB. עלות: 1 מחזור שעון.\n2.  **Page Table Walk עם Page Faults עבור טבלאות הדפים**: כל 4 הרמות של טבלאות הדפים אינן נמצאות בזיכרון הראשי (RAM) ודורשות טעינה מהדיסק.\n    *   עבור כל רמה (4 רמות): גישה לדיסק כדי לטעון את דף טבלת הדפים (10^7 מחזורי שעון) + כתיבת הדף ל-RAM (100 מחזורי שעון) + קריאת ה-PTE מאותו דף ב-RAM (100 מחזורי שעון).\n    *   סה\"כ עבור Page Table Walk: 4 * (10^7 + 100 + 100) = 4 * (10^7 + 200) מחזורי שעון.\n3.  **Page Fault עבור דף הנתונים**: ה-PTE הסופי מצביע על כך שדף הנתונים אינו נמצא ב-RAM (Valid=0).\n    *   נניח שהדף שיש לפנות (victim page) הוא 'מלוכלך' (Dirty=1) ולכן יש לכתוב אותו לדיסק: 10^7 מחזורי שעון (Disk Write).\n    *   טעינת הדף המבוקש מהדיסק ל-RAM: 10^7 מחזורי שעון (Disk Read).\n    *   עדכון ה-PTE המתאים ב-RAM (לציין Valid=1, PFN החדש): 100 מחזורי שעון (RAM Write).\n4.  **גישה בפועל לנתונים**: ביצוע פעולת הכתיבה לכתובת הפיזית ב-RAM: 100 מחזורי שעון (RAM Write).\n\nחישוב סך הזמן הכולל:\n1 (TLB Miss) +\n4 * (10^7 + 200) (Page Table Walk עם 4 Page Faults עבור טבלאות הדפים) +\n10^7 (Disk Write ל-victim page) +\n10^7 (Disk Read לדף המבוקש) +\n100 (עדכון PTE ב-RAM) +\n100 (גישה בפועל לנתונים ב-RAM)\n\n= 1 + 4*10^7 + 800 + 10^7 + 10^7 + 100 + 100\n= (4 + 1 + 1) * 10^7 + (1 + 800 + 100 + 100)\n= 6 * 10^7 + 1001 מחזורי שעון.\n\n7.4: השפעת ביט ה-Execute:\nאם תהליך מנסה לבצע קוד (fetch instruction) מכתובת וירטואלית שה-PTE שלה מציין Execute=0, המערכת תזהה הפרת הרשאה (protection violation). גם אם ביט Read/Write מוגדר כ-1, אין לתהליך הרשאת ביצוע (Execute) באותו דף. במקרה כזה, מערכת ההפעלה תייצר חריגה (exception) כגון 'הפרת סגמנטציה' (segmentation fault) או 'הפרת הגנה' (protection fault), ותסיים את ריצת התהליך הפוגע. זהו מנגנון אבטחה קריטי למניעת הרצת קוד זדוני או לא מורשה מאזורי זיכרון המיועדים לנתונים בלבד."}, "difficulty_estimation": "Hard", "_source_file": "0473__Memory_Management__Open__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:26:53", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Memory Management", "Virtual Memory", "Paging", "TLB", "Page Faults"], "content": {"text": "נתונה מערכת הפעלה המממשת זיכרון וירטואלי באמצעות דפדוף (paging) רב-שכבתי (multi-level paging). פרטי המערכת הם כדלקמן:\n*   מרחב כתובות וירטואלי: 48 ביטים.\n*   מרחב כתובות פיזי: 40 ביטים.\n*   גודל דף: 4KB.\n*   גודל כניסה בטבלת דפים (PTE): 8 בתים.\n\nבנוסף, המערכת משתמשת ב-Translation Lookaside Buffer (TLB) בעל המאפיינים הבאים:\n*   מספר כניסות כולל: 16.\n*   אסוציאטיביות: 4-way set associative.\n*   מדיניות החלפה: LRU (בתוך כל סט).\n*   אינדקס ה-TLB נגזר משני הביטים הפחות משמעותיים (LSB) של מספר הדף הווירטואלי (VPN) המלא.\n\nנתון תהליך המנסה לגשת לראשונה לכתובת הווירטואלית `0x0000_1234_5678_9ABC`.\nהניחו כי טבלאות הדפים של התהליך ריקות לחלוטין (כלומר, כל ביט Valid ב-PTE הוא 0 עבור כל הרמות), וה-TLB ריק לחלוטין לפני הגישה.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "כמה רמות של טבלאות דפים יש במערכת זו? כמה כניסות (PTEs) יכולה להכיל כל טבלת דפים ברמה אחת?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "תארו בפירוט את כל השלבים המתבצעים במערכת (חומרה ותוכנה) מרגע ניסיון הגישה לכתובת הווירטואלית `0x0000_1234_5678_9ABC` ועד להשלמתה או לטיפול בפסיקה. יש לכלול את כל הגישות ל-TLB, לזיכרון הראשי (RAM) ולזיכרון המשני (דיסק), ואת העדכונים הנדרשים (ל-TLB ולטבלאות הדפים). הניחו שנדרשת טעינת דף מהדיסק, וכי זיכרון ה-RAM מלא, כך שיש צורך לפנות דף קיים לדיסק.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "כמה גישות לזיכרון הראשי (RAM), לזיכרון המשני (דיסק), ול-TLB בסך הכל מתבצעות עבור תרגום כתובת יחידה זו, בהתאם לתיאורכם בסעיף ב'?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\n**סעיף 1.1:**\n*   **חישוב גודל היסט הדף (Offset):** גודל דף הוא 4KB = 2^12 בתים. לכן, ההיסט בכתובת הוא 12 ביטים.\n*   **חישוב מספר ביטים של Virtual Page Number (VPN):** מרחב כתובות וירטואלי הוא 48 ביטים. VPN = 48 - 12 = 36 ביטים.\n*   **חישוב מספר כניסות לטבלת דפים ברמה אחת:** כל טבלת דפים מאוחסנת בדף אחד (4KB). גודל כניסה בטבלת דפים (PTE) הוא 8 בתים. לכן, מספר הכניסות בכל טבלת דפים הוא 4KB / 8 בתים = 4096 כניסות (2^12).\n*   **חישוב מספר ביטים שכל רמה בטבלת הדפים ממפה:** כל רמה ממפה 12 ביטים (log2(4096)).\n*   **חישוב מספר רמות:** מספר ביטים של VPN הוא 36. כל רמה ממפה 12 ביטים. לכן, מספר הרמות הוא 36 / 12 = 3 רמות.\n\n**תשובה:** ישנן 3 רמות של טבלאות דפים במערכת. כל טבלת דפים ברמה אחת יכולה להכיל 4096 כניסות.\n\n**סעיף 1.2:**\nהכתובת הווירטואלית היא `0x0000_1234_5678_9ABC`.\n*   **היסט (Offset):** 12 הביטים הפחות משמעותיים: `0x9ABC`.\n*   **מספר הדף הווירטואלי (VPN):** 36 הביטים הנותרים: `0x0000_1234_5678`.\n    *   P1 (אינדקס לרמה 1): 12 הביטים העליונים של ה-VPN: `0x000`.\n    *   P2 (אינדקס לרמה 2): 12 הביטים הבאים של ה-VPN: `0x123`.\n    *   P3 (אינדקס לרמה 3): 12 הביטים התחתונים של ה-VPN: `0x456`.\n*   **אינדקס TLB:** שני הביטים הפחות משמעותיים של ה-VPN (0x0000_1234_5678 בבינארי מסתיים ב-`00`). לכן, אינדקס ה-TLB הוא `00`.\n*   **תג TLB (Tag):** 34 הביטים הנותרים של ה-VPN.\n\n**שלבי הגישה:**\n1.  **חיפוש ב-TLB (חומרה):** ה-MMU מחלצת את ה-VPN ומחשבת את אינדקס ה-TLB (`00`). היא בודקת בסט 00 של ה-TLB האם יש כניסה עם התג המתאים (ה-34 ביטים הנותרים של ה-VPN) וביט Valid דולק. מכיוון שה-TLB ריק, מתרחש **TLB Miss**.\n    *   (1 גישה ל-TLB)\n\n2.  **מעבר על טבלאות הדפים (Page Table Walk - חומרה):** מכיוון שה-TLB Miss, ה-MMU מתחילה בחיפוש בטבלאות הדפים בזיכרון הראשי (RAM) כדי למצוא את ה-PFN המתאים. הניחו שכתובת הבסיס של טבלת הדפים הראשית (P1) נמצאת ברגיסטר CR3.\n    *   **גישה לרמה 1 (P1):** ה-MMU ניגשת לכתובת `CR3 + (P1 * PTE_size)` כדי לקרוא את ה-PTE עבור P1 (`0x000`). מכיוון שכל טבלאות הדפים ריקות (Valid=0), ה-PTE עבור `0x000` יהיה לא חוקי.\n        *   (1 גישה ל-RAM)\n    *   **התרחשות Page Fault:** ה-MMU מזהה שה-PTE אינו חוקי (Valid=0) ומאותת למעבד על **Page Fault**.\n\n3.  **טיפול ב-Page Fault (תוכנה - מערכת ההפעלה):**\n    *   מערכת ההפעלה מקבלת את פסיקת ה-Page Fault. היא מזהה שהדף הווירטואלי `0x0000_1234_5678` אינו קיים בזיכרון הפיזי וגם טבלאות הדפים המובילות אליו אינן מאותחלות.\n    *   **הקצאת דפי טבלאות דפים:** מערכת ההפעלה מקצה דפי זיכרון פיזיים חדשים עבור טבלאות הדפים ברמות P1, P2 ו-P3 (אם הן טרם הוקצו). כיוון שהן ריקות לחלוטין, יש צורך להקצות 3 דפים חדשים ב-RAM עבור טבלאות P1, P2 ו-P3.\n        *   (3 גישות ל-RAM: כתיבה ל-PTE בטבלת P1, כתיבה ל-PTE בטבלת P2, כתיבה ל-PTE בטבלת P3, כדי לעדכן את המצביעים לדפי הטבלאות הבאות ולדף הנתונים).\n    *   **טיפול בדף הנתונים:** מערכת ההפעלה מזהה שגם דף הנתונים עצמו (הדף הממופה ל-VPN `0x0000_1234_5678`) אינו נמצא ב-RAM.\n        *   **פינוי דף קיים (Page-out):** מכיוון שזיכרון ה-RAM מלא, מערכת ההפעלה בוחרת דף קורבן (לפי מדיניות החלפת דפים כלשהי, למשל LRU גלובלי). אם דף הקורבן 'מלוכלך' (Dirty=1), הוא נכתב לדיסק.\n            *   (1 גישה לדיסק: כתיבה של דף קורבן)\n        *   **טעינת הדף המבוקש (Page-in):** מערכת ההפעלה קוראת את דף הנתונים עבור הכתובת הווירטואלית `0x0000_1234_5678` מהדיסק ומטעינה אותו למסגרת הפיזית שהתפנתה (או חדשה).\n            *   (1 גישה לדיסק: קריאה של הדף המבוקש)\n        *   **עדכון טבלת הדפים:** מערכת ההפעלה מעדכנת את ה-PTE המתאים בטבלת הדפים ברמה P3 (עבור P3=`0x456`) עם מספר המסגרת הפיזית (PFN) של הדף החדש, ומגדירה את ביט Valid ל-1, את ביט Dirty ל-0 ואת ביט Access ל-1.\n            *   (1 גישה ל-RAM: כתיבת PTE מעודכן לטבלת P3).\n\n4.  **עדכון TLB (מערכת הפעלה/חומרה):** לאחר שהדף נטען וטבלאות הדפים עודכנו, מערכת ההפעלה מוסיפה את המיפוי החדש (VPN -> PFN) ל-TLB. אם הסט המתאים ב-TLB (סט `00`) מלא, הכניסה ה'פחות בשימוש לאחרונה' (LRU) מוחלפת.\n\n5.  **הפעלה מחדש של הפקודה (חומרה):** הפקודה שגרמה ל-Page Fault מופעלת מחדש.\n    *   **חיפוש חוזר ב-TLB:** ה-MMU שוב מחפשת את ה-VPN ב-TLB. הפעם, המיפוי קיים ומתרחש **TLB Hit**.\n        *   (1 גישה ל-TLB)\n    *   **בניית כתובת פיזית וגישה לנתונים:** ה-MMU מקבלת את ה-PFN מה-TLB, משלבת אותו עם ההיסט (`0x9ABC`) ויוצרת את הכתובת הפיזית. לבסוף, היא ניגשת לזיכרון הראשי כדי לבצע את פעולת ה-read/write המקורית על הנתונים.\n        *   (1 גישה ל-RAM: לנתונים עצמם).\n\n**סעיף 1.3:**\nבהתאם לתיאור המפורט בסעיף ב', סך הגישות עבור תרגום כתובת יחידה זו (כולל הגישה לנתונים עצמם) הן:\n*   **גישות ל-TLB:** 2 (אחת ל-TLB Miss, אחת ל-TLB Hit לאחר הטיפול ב-Page Fault).\n*   **גישות לזיכרון הראשי (RAM):**\n    *   1 (קריאת PTE ראשונית בטבלת P1).\n    *   3 (כתיבת PTEs לעדכון טבלאות P1, P2, P3 במהלך הטיפול ב-Page Fault - יצירת מצביעים לטבלאות הבאות ולדף הנתונים).\n    *   1 (כתיבת PTE מעודכן לטבלת P3 עבור דף הנתונים).\n    *   1 (גישה לנתונים עצמם לאחר התרגום המוצלח).\n    *   **סה\"כ גישות ל-RAM:** 1 + 3 + 1 + 1 = 6 גישות.\n\n*   **גישות לזיכרון המשני (דיסק):**\n    *   1 (כתיבת דף קורבן לדיסק – Page-out).\n    *   1 (קריאת הדף המבוקש מהדיסק – Page-in).\n    *   **סה\"כ גישות לדיסק:** 2 גישות.\n\n**סיכום:**\n*   **TLB:** 2 גישות\n*   **RAM:** 6 גישות\n*   **דיסק:** 2 גישות"}, "difficulty_estimation": "Hard", "_source_file": "0474__Memory_Management__Open__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:27:49", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Memory Management", "Paging", "Virtual Memory", "TLB", "Page Replacement"], "content": {"text": "נתונה מערכת הפעלה 64 ביט המשתמשת בזיכרון וירטואלי עם טבלת דפים היררכית בעלת 4 רמות (כמו ב-x86-64). גודל כתובת וירטואלית הוא 48 ביט, וגודל דף הוא 4KB. כל כניסה בטבלת הדפים (PTE) היא בגודל 8 בתים ומכילה מספר מסגרת פיזית (PFN) באורך 40 ביט ו-4 ביטי סטטוס (Valid, Dirty, Accessed, Global). \nבמערכת קיים TLB בגודל 128 כניסות, בעל אסוציאטיביות של 4 דרכים (4-way set associative), ומשתמש באלגוריתם החלפה LRU. כל כניסה ב-TLB שומרת את ה-VPN המלא, ה-PFN וביטי הגנה (Valid, Dirty, Accessed). \n\nהניחו כי ה-TLB ריק בתחילת הריצה. כמו כן, הניחו שכל טבלאות הדפים הביניים (PML4, PDPT, PD, PT) תמיד נמצאות בזיכרון הפיזי וכניסותיהן תקינות (Valid, Present). Page Fault יתרחש רק אם דף הנתונים עצמו אינו נמצא בזיכרון הפיזי (PTE.Present=0). במקרה של Page Fault, הדף נטען לזיכרון הפיזי, ה-PTE מעודכן (Present=1, Dirty=0, Accessed=1) והגישה ממשיכה. במקרה של TLB Miss, יש לגשת לטבלת הדפים בזיכרון הראשי כדי לבצע את התרגום.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "מהו גודל הזיכרון הפיזי המקסימלי הנתמך על ידי מערכת זו? נמקו.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "עקבו אחר רצף הגישות לכתובות הוירטואליות הבאות (בסדר נתון). עבור כל גישה, ציינו האם מדובר ב-TLB Hit או TLB Miss, האם מתרחש Page Fault, וכמה גישות לזיכרון הראשי (Main Memory) נדרשות עבור תרגום הכתובת (לא כולל הגישה לנתון עצמו).\n\nנתוני מיפוי PFN ראשוניים:\n*   `VPN (0x100_0000_00)` ממופה ל-`PFN 0x1000`, `Present=1`.\n*   `VPN (0x100_0000_01)` ממופה ל-`PFN 0x2000`, `Present=1`.\n*   `VPN (0x100_0000_02)` ממופה ל-`PFN 0x3000`, `Present=1`.\n*   `VPN (0x200_0000_00)` ממופה ל-`PFN 0x4000`, `Present=1`.\n*   `VPN (0x300_0000_00)` ממופה ל-`PFN 0x5000`, `Present=1`.\n*   `VPN (0x400_0000_00)` ממופה ל-`PFN 0x6000`, `Present=0` (גורם ל-Page Fault).\n*   לאחר Page Fault, `VPN (0x400_0000_00)` ממופה ל-`PFN 0x6000`, `Present=1`.\n\nרצף הכתובות הוירטואליות:\n1.  `0x1000_0000_0000`\n2.  `0x1000_0000_1000`\n3.  `0x1000_0000_0000`\n4.  `0x1000_0000_2000`\n5.  `0x2000_0000_0000`\n6.  `0x3000_0000_0000`\n7.  `0x4000_0000_0000`", "code_snippet": null, "options": null}, {"id": "1.3", "text": "תארו את מצב ה-TLB (אילו VPNs נמצאים באילו סטים ובאילו דרכים, ומה סדר ה-LRU בכל סט) לאחר סיום כל הגישות ברצף הנתון בסעיף 2.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "**פתרון:**\n\n**1.1. גודל הזיכרון הפיזי המקסימלי:**\n*   גודל כניסה בטבלת הדפים (PTE) הוא 8 בתים.\n*   מספר מסגרת פיזית (PFN) הוא באורך 40 ביט.\n*   מספר ביטי ה-PFN קובע את מספר המסגרות הפיזיות המקסימלי: 2^40 מסגרות.\n*   גודל דף נתון כ-4KB (2^12 בתים).\n*   גודל הזיכרון הפיזי המקסימלי = מספר המסגרות * גודל דף = 2^40 * 2^12 = 2^52 בתים.\n*   2^52 בתים = 4 פטה-בתים (PB).\n\n**1.2. מעקב אחר רצף הגישות:**\n**חישובים מקדימים:**\n*   כתובת וירטואלית (VA) = 48 ביט.\n*   היסט (Offset) = 12 ביט (מכיוון שגודל דף = 4KB = 2^12).\n*   מספר דף וירטואלי (VPN) = 48 - 12 = 36 ביט.\n*   טבלת דפים היררכית בעלת 4 רמות: כל רמה משתמשת ב- 36 / 4 = 9 ביטים עבור האינדקס שלה (PML4_idx, PDPT_idx, PD_idx, PT_idx).\n*   TLB: 128 כניסות, 4-way set associative.\n*   מספר הסטים ב-TLB = 128 כניסות / 4 דרכים = 32 סטים (2^5 סטים).\n*   אינדקס הסט ב-TLB: 5 הביטים האחרונים של ה-VPN (VPN[4:0]). במקרה זה, אלו 5 הביטים האחרונים של אינדקס טבלת הדפים ברמה האחרונה (PT_idx[4:0]).\n*   תגית (Tag) ב-TLB: שאר ביטי ה-VPN (VPN[35:5]).\n*   מספר גישות זיכרון לתרגום (במקרה של TLB Miss): 4 גישות (אחת לכל רמה בטבלת הדפים: PML4, PDPT, PD, PT).\n\n**פירוט VPN ו-TLB עבור הכתובות:**\n*   `VPN_A = 0x100_0000_00` (PML4=0x1, PDPT=0x0, PD=0x0, PT=0x0). `PT_idx=0x000`. `TLB_set=0` (`00000` בינארי). `TLB_tag=0x100_0000_0`.\n*   `VPN_B = 0x100_0000_01` (PML4=0x1, PDPT=0x0, PD=0x0, PT=0x1). `PT_idx=0x001`. `TLB_set=1` (`00001` בינארי). `TLB_tag=0x100_0000_0`.\n*   `VPN_C = 0x100_0000_02` (PML4=0x1, PDPT=0x0, PD=0x0, PT=0x2). `PT_idx=0x002`. `TLB_set=2` (`00010` בינארי). `TLB_tag=0x100_0000_0`.\n*   `VPN_D = 0x200_0000_00` (PML4=0x2, PDPT=0x0, PD=0x0, PT=0x0). `PT_idx=0x000`. `TLB_set=0` (`00000` בינארי). `TLB_tag=0x200_0000_0`.\n*   `VPN_E = 0x300_0000_00` (PML4=0x3, PDPT=0x0, PD=0x0, PT=0x0). `PT_idx=0x000`. `TLB_set=0` (`00000` בינארי). `TLB_tag=0x300_0000_0`.\n*   `VPN_F = 0x400_0000_00` (PML4=0x4, PDPT=0x0, PD=0x0, PT=0x0). `PT_idx=0x000`. `TLB_set=0` (`00000` בינארי). `TLB_tag=0x400_0000_0`.\n\n**טבלת מעקב:**\n\n| גישה # | כתובת וירטואלית | VPN            | TLB Set | TLB Hit/Miss | Page Fault | גישות לזיכרון (תרגום) | מצב סט 0 (LRU -> MRU) |\n| :----- | :--------------- | :------------- | :------ | :----------- | :--------- | :--------------------- | :------------------------------------ |\n| 1      | `0x1000_0000_0000` | `VPN_A`        | 0       | Miss         | No         | 4                      | {(`VPN_A`)}                         |\n| 2      | `0x1000_0000_1000` | `VPN_B`        | 1       | Miss         | No         | 4                      | {(`VPN_A`)}                         |\n| 3      | `0x1000_0000_0000` | `VPN_A`        | 0       | Hit          | No         | 0                      | {(`VPN_A`)}                         |\n| 4      | `0x1000_0000_2000` | `VPN_C`        | 2       | Miss         | No         | 4                      | {(`VPN_A`)}                         |\n| 5      | `0x2000_0000_0000` | `VPN_D`        | 0       | Miss         | No         | 4                      | {(`VPN_A`), (`VPN_D`)}              |\n| 6      | `0x3000_0000_0000` | `VPN_E`        | 0       | Miss         | No         | 4                      | {(`VPN_A`), (`VPN_D`), (`VPN_E`)}   |\n| 7      | `0x4000_0000_0000` | `VPN_F`        | 0       | Miss         | Yes        | 4                      | {(`VPN_A`), (`VPN_D`), (`VPN_E`), (`VPN_F`)} |\n\n**הסבר למצב סט 0:**\n*   **גישה 1 (VPN_A):** TLB Miss. `VPN_A` נטען לסט 0. מצב: {(`VPN_A`)}. `VPN_A` הוא ה-MRU (Most Recently Used).\n*   **גישה 3 (VPN_A):** TLB Hit. `VPN_A` נשאר בסט 0 והופך שוב ל-MRU. מצב: {(`VPN_A`)}.\n*   **גישה 5 (VPN_D):** TLB Miss. `VPN_D` נטען לסט 0. מצב: {(`VPN_A`), (`VPN_D`)}. `VPN_A` הוא ה-LRU (Least Recently Used), `VPN_D` הוא ה-MRU.\n*   **גישה 6 (VPN_E):** TLB Miss. `VPN_E` נטען לסט 0. מצב: {(`VPN_A`), (`VPN_D`), (`VPN_E`)}. סדר LRU -> MRU: `VPN_A`, `VPN_D`, `VPN_E`.\n*   **גישה 7 (VPN_F):** TLB Miss. סט 0 אינו מלא (יש בו 3 כניסות מתוך 4). `VPN_F` נטען לכניסה הפנויה. מתרחש Page Fault עבור `VPN_F`, הדף נטען וה-PTE מתעדכן. מצב: {(`VPN_A`), (`VPN_D`), (`VPN_E`), (`VPN_F`)}. סדר LRU -> MRU: `VPN_A`, `VPN_D`, `VPN_E`, `VPN_F`.\n\n**1.3. מצב ה-TLB לאחר כל הגישות:**\n\n*   **סט 0 (LRU -> MRU):**\n    *   `VPN_A` (Tag `0x100_0000_0`, PFN `0x1000`)\n    *   `VPN_D` (Tag `0x200_0000_0`, PFN `0x4000`)\n    *   `VPN_E` (Tag `0x300_0000_0`, PFN `0x5000`)\n    *   `VPN_F` (Tag `0x400_0000_0`, PFN `0x6000`)\n\n*   **סט 1 (LRU -> MRU):**\n    *   `VPN_B` (Tag `0x100_0000_0`, PFN `0x2000`)\n\n*   **סט 2 (LRU -> MRU):**\n    *   `VPN_C` (Tag `0x100_0000_0`, PFN `0x3000`)\n\n*   **שאר הסטים ב-TLB (סטים 3-31) ריקים.**"}, "difficulty_estimation": "Hard", "_source_file": "0475__Memory_Management__Open__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:58:15", "_subject": "Virtualization"}, {"id": 11, "type": "Open", "topic": ["Memory Management", "Virtual Memory", "Paging", "TLB", "Page Faults", "Page Replacement"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם המאפיינים הבאים:\n*   כתובת וירטואלית: 48 ביטים\n*   כתובת פיזית: 32 ביטים\n*   גודל דף: 4KB\n*   גודל כניסה בטבלת דפים (PTE): 4 בתים (32 ביטים), המכילה מספר מסגרת פיזית (PFN), וביטים Valid, Dirty, Accessed, וביטי הרשאות קריאה/כתיבה/הרצה.\n*   TLB (Translation Lookaside Buffer): בעל 128 כניסות, ממומש כ-fully associative, ומשתמש במדיניות החלפה LRU. כל כניסה ב-TLB כוללת VPN, PFN, וביטי הרשאות.\n\nתהליך מנסה לבצע פעולת כתיבה לכתובת הווירטואלית `0x0000_1234_5678`.\nתארו באופן מלא ומפורט את תהליך תרגום הכתובת, החל מהגישה הראשונית ועד להשלמת הכתיבה, בהנחה שמדובר ב'מקרה הגרוע ביותר' (worst-case scenario).\nיש לכלול בתיאור:\n1.  פירוט מבנה טבלת הדפים (מספר רמות, חלוקת ביטי ה-VPN).\n2.  כיצד ה-TLB מעורב בתהליך (בכל שלב).\n3.  את כל הגישות לזיכרון הראשי (RAM) ולזיכרון המשני (דיסק) שיתרחשו.\n4.  כיצד מטופלת פסיקת דף (Page Fault) במקרה זה (בהנחה שכל המסגרות הפיזיות בשימוש, ונדרשת החלפת דף 'מלוכלך').\n5.  את השינויים הנדרשים במבני הנתונים (TLB וטבלת הדפים) בעקבות התהליך.\nיש לפרט את כל החישובים הרלוונטיים.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  **פירוק הכתובת הווירטואלית ומבנה טבלת הדפים:**\n    *   גודל כתובת וירטואלית: 48 ביטים.\n    *   גודל דף: 4KB = 2^12 בתים. לכן, 12 הביטים האחרונים של הכתובת הווירטואלית הם ה-Offset בתוך הדף.\n    *   מספר דף וירטואלי (VPN): 48 - 12 = 36 ביטים.\n    *   גודל כניסה בטבלת דפים (PTE): 4 בתים (32 ביטים).\n    *   מספר כניסות PTE בדף בודד: גודל דף / גודל PTE = 4KB / 4 בתים = 1024 כניסות (2^10).\n    *   כל רמה בטבלת הדפים משתמשת ב-10 ביטים מה-VPN.\n    *   מספר רמות נדרש: VPN באורך 36 ביטים. 36 חלקי 10 שווה 3 עם שארית 6. לכן, נדרשות 4 רמות של טבלאות דפים:\n        *   רמה 1: 6 ביטים (המצביעים לטבלת דפים רמה 2)\n        *   רמה 2: 10 ביטים (המצביעים לטבלת דפים רמה 3)\n        *   רמה 3: 10 ביטים (המצביעים לטבלת דפים רמה 4)\n        *   רמה 4: 10 ביטים (המצביעים לדף הפיזי)\n    *   סה\"כ ביטי VPN: 6 + 10 + 10 + 10 = 36 ביטים.\n    *   הכתובת הווירטואלית `0x0000_1234_5678`:\n        *   Offset: `0x678` (12 ביטים).\n        *   VPN: `0x0000_1234_5` (36 ביטים).\n        *   פירוק ה-VPN (בייצוג בינארי של 36 ביטים: `00000000000000010010001101000101`):\n            *   L1 Index (6 ביטים עליונים): `000000` (0)\n            *   L2 Index (10 ביטים הבאים): `0000000100` (4)\n            *   L3 Index (10 ביטים הבאים): `1000110100` (564)\n            *   L4 Index (10 ביטים תחתונים): `0100010101` (277)\n\n2.  **תהליך תרגום הכתובת במקרה הגרוע ביותר:**\n    *   **שלב 1: גישה ל-TLB (TLB Miss)**: ה-CPU מקבל את הכתובת הווירטואלית. הוא מנסה למצוא את ה-VPN (`0x0000_1234_5`) ב-TLB. במקרה הגרוע ביותר, ה-VPN לא נמצא ב-TLB (TLB Miss). זוהי גישת TLB אחת.\n\n    *   **שלב 2: הליכה בטבלת הדפים (Page Table Walk)**: מאחר שה-VPN לא נמצא ב-TLB, מערכת ההפעלה (או חומרת MMU) מבצעת הליכה בטבלאות הדפים המרובות בזיכרון הראשי:\n        *   ה-CPU ניגש לזיכרון הראשי (RAM) כדי לקרוא את ה-PTE המתאים בטבלת הדפים של רמה 1 (כתובת הבסיס של L1 נמצאת ברגיסטר כמו CR3). הוא משתמש ב-L1 Index (0) כדי למצוא את המצביע לטבלת הדפים של רמה 2. (גישת RAM 1).\n        *   ה-CPU ניגש לזיכרון הראשי (RAM) כדי לקרוא את ה-PTE המתאים בטבלת הדפים של רמה 2. הוא משתמש ב-L2 Index (4) כדי למצוא את המצביע לטבלת הדפים של רמה 3. (גישת RAM 2).\n        *   ה-CPU ניגש לזיכרון הראשי (RAM) כדי לקרוא את ה-PTE המתאים בטבלת הדפים של רמה 3. הוא משתמש ב-L3 Index (564) כדי למצוא את המצביע לטבלת הדפים של רמה 4. (גישת RAM 3).\n        *   ה-CPU ניגש לזיכרון הראשי (RAM) כדי לקרוא את ה-PTE המתאים בטבלת הדפים של רמה 4. הוא משתמש ב-L4 Index (277) כדי לקבל את ה-PTE המלא של הדף המבוקש. (גישת RAM 4).\n\n    *   **שלב 3: פסיקת דף (Page Fault)**: במקרה הגרוע ביותר, ה-PTE שנקרא מרמה 4 מצביע על כך שהדף אינו נמצא בזיכרון הפיזי (Valid bit = 0), או שאין לו הרשאות כתיבה עבור הפעולה המבוקשת (Write permission bit = 0). במקרה כזה תתרחש פסיקת דף.\n        *   מערכת ההפעלה מקבלת פסיקת דף.\n        *   **טיפול בפסיקה:**\n            *   מערכת ההפעלה צריכה למצוא מסגרת פיזית פנויה לטעינת הדף. בהנחה שכל המסגרות בשימוש, היא תפעיל אלגוריתם החלפת דפים (לדוגמה, LRU) כדי לבחור דף לפינוי.\n            *   אם הדף הנבחר לפינוי הוא \"מלוכלך\" (Dirty bit = 1), כלומר תוכנו השתנה מאז נטען, יש לכתוב אותו בחזרה לדיסק לפני פינויו. (גישת דיסק 1 – כתיבת דף מלוכלך לדיסק).\n            *   מערכת ההפעלה טוענת את הדף המבוקש מהדיסק לתוך המסגרת הפיזית שהתפנתה. (גישת דיסק 2 – קריאת דף מהדיסק).\n            *   מערכת ההפעלה מעדכנת את ה-PTE המתאים בטבלת הדפים של רמה 4 (אותו PTE שגרם לפסיקה): היא מכניסה את ה-PFN של המסגרת החדשה, קובעת Valid bit = 1, Dirty bit = 0, Accessed bit = 1, ומאפשרת הרשאות כתיבה. (גישת RAM 5 – כתיבה ל-PTE ב-RAM).\n\n    *   **שלב 4: עדכון ה-TLB**: לאחר שהדף נטען וה-PTE עודכן, מערכת ההפעלה מוסיפה את המיפוי החדש (VPN, PFN, הרשאות) ל-TLB. אם ה-TLB מלא, כניסה אחרת (לפי LRU) תפונה. (גישת TLB 2 – כתיבה ל-TLB).\n\n    *   **שלב 5: הפעלת ההוראה מחדש וגישה ל-TLB (TLB Hit)**: ה-CPU מפעיל מחדש את ההוראה שגרמה לפסיקת הדף. הפעם, כאשר הוא ניגש ל-TLB, הוא ימצא את ה-VPN (TLB Hit). (גישת TLB 3 – קריאה מ-TLB).\n\n    *   **שלב 6: גישה פיזית לזיכרון**: ה-CPU משתמש ב-PFN שהתקבל מה-TLB וב-Offset המקורי כדי לגשת לכתובת הפיזית ולבצע את פעולת הכתיבה בפועל. (גישת RAM 6 – כתיבה לזיכרון הפיזי).\n\n3.  **סיכום גישות במקרה הגרוע ביותר:**\n    *   **גישות ל-TLB:** 3 (אחת ל-miss, אחת לכתיבת entry חדש, אחת ל-hit לאחר הטיפול בפסיקה).\n    *   **גישות לזיכרון הראשי (RAM):** 6 (4 להליכה בטבלת הדפים, 1 לעדכון PTE, 1 לכתיבת הנתון בפועל).\n    *   **גישות לדיסק:** 2 (אחת לכתיבת דף מלוכלך מפונה, אחת לקריאת הדף המבוקש)."}, "difficulty_estimation": "Hard", "_source_file": "0476__Memory_Management__Open__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 21:58:55", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Memory Management", "Paging", "Virtual Memory", "Superpages", "TLB", "Fragmentation"], "content": {"text": "נתונה מערכת הפעלה 64-ביט המשתמשת במנגנון זיכרון וירטואלי מבוסס דפדוף (paging). גודל הדף הסטנדרטי הוא 4KB. המערכת משתמשת בטבלת דפים היררכית בת 3 רמות (multi-level page table) למיפוי כתובות וירטואליות לכתובות פיזיות. על מנת לשפר ביצועים עבור אזורי זיכרון גדולים ורציפים, המערכת תומכת גם ב\"דפי-על\" (superpages) בגודל 2MB. דפי-על אלו יכולים למפות אזורים גדולים של זיכרון וירטואלי לבלוקים רציפים גדולים בזיכרון הפיזי, ובכך להפחית את מספר הכניסות בטבלת הדפים ואת מספר הגישות ל-TLB/זיכרון.", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "מבנה PTE: תארו בפירוט את מבנה כניסת טבלת הדפים (PTE) עבור דף סטנדרטי (4KB) ועבור דף-על (2MB). ציינו אילו שדות נדרשים וכיצד הם עשויים להשתנות בין שני סוגי הדפים.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "תהליך תרגום כתובות ו-TLB: הסבירו כיצד מתבצע תרגום כתובות וירטואליות לכתובות פיזיות במערכת זו, תוך התחשבות בקיום שני סוגי הדפים. פרטו את תפקיד ה-TLB בתהליך זה ואילו שינויים או הרחבות נדרשים ב-TLB כדי לתמוך ביעילות בשני גדלי הדפים.", "code_snippet": null, "options": null}, {"id": "1.3", "text": "הקצאת זיכרון ופרגמנטציה: תהליך מבקש להקצות בלוק זיכרון וירטואלי רציף בגודל 8MB. המערכת מנסה להשתמש בדפי-על כדי למפות את הבלוק הזה, אך הזיכרון הפיזי מפוצל (fragmented) מאוד, ואין מסגרות פיזיות רציפות בגודל 2MB זמינות. תארו כיצד מערכת ההפעלה תטפל בבקשת ההקצאה במקרה זה, ומהן ההשלכות הביצועיות של פתרון זה לעומת שימוש בדפי-על.", "code_snippet": null, "options": null}, {"id": "1.4", "text": "הגנה ושיתוף זיכרון: כיצד יכולה התמיכה בדפי-על להשפיע על מנגנוני הגנה על זיכרון ושיתוף זיכרון בין תהליכים? תארו את האתגרים והיתרונות הפוטנציאליים.", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הסבר מפורט:\n\n1.1. מבנה PTE:\n   *   **PTE לדף סטנדרטי (4KB):** כניסה זו תכיל את מספר המסגרת הפיזית (PFN) של דף ה-4KB. בנוסף, היא תכלול ביטים נפוצים כמו: Valid (האם הכניסה חוקית), Present (האם הדף נמצא בזיכרון הפיזי או בדיסק), Dirty (האם הדף שונה), Accessed (האם הדף נוגש), וביטים להרשאות (קריאה, כתיבה, הרצה). מכיוון שזו מערכת 64-ביט, וגודל דף 4KB (12 ביטים להיסט), אז נותרו 52 ביטים למספר הדף הווירטואלי (VPN). בטבלת דפים 3 רמות, כל רמה משתמשת בחלק מביטי ה-VPN. ה-PFN יצטרך להיות מספיק גדול כדי למפות את כל הזיכרון הפיזי. אם נניח זיכרון פיזי של 2^48 בתים (256TB), אז ה-PFN יהיה באורך של 36 ביטים (48-12).\n   *   **PTE לדף-על (2MB):** כניסה זו תהיה ברמה גבוהה יותר בטבלת הדפים (לרוב ברמה השנייה או השלישית, תלוי איך מחלקים את ביטי ה-VPN). במקום PFN של 4KB, היא תכיל PFN של 2MB. כלומר, ההיסט עבור דף-על בגודל 2MB הוא 21 ביטים (2^21 בתים). לכן, ה-PFN יתייחס לבלוק פיזי בגודל 2MB. בנוסף לביטים הסטנדרטיים (Valid, Present, Dirty, Accessed, הרשאות), ייתכן שיידרש ביט נוסף שיציין האם זו כניסה לדף סטנדרטי או לדף-על (Superpage bit), או שניתן להסיק זאת ממיקום ה-PTE בטבלת הדפים (לדוגמה, אם PTE ברמה 2 מצביע ישירות למסגרת פיזית, זהו דף-על). ה-PFN עבור דף-על יהיה קצר יותר ב-9 ביטים (21-12=9) מאשר PFN של דף רגיל, כי הוא מכסה בלוק גדול יותר.\n\n1.2. תהליך תרגום כתובות ו-TLB:\n   *   **תרגום כתובות:** כאשר ה-MMU מקבל כתובת וירטואלית 64-ביט, הוא מפרק אותה לביטי ה-VPN (מספר דף וירטואלי) ולביטי ההיסט (offset).\n       *   עבור דף סטנדרטי (4KB), ה-VPN יחולק לשלושה חלקים (לדוגמה, 9 ביטים לכל רמה, או חלוקה אחרת שתסכם ל-52 ביטים), שישמשו כאינדקסים לטבלאות הדפים ברמות השונות. ה-MMU יגש לטבלת הדפים ברמה 1, ימצא PTE שמצביע לטבלת דפים ברמה 2, משם לטבלת דפים ברמה 3, ובסוף ימצא PTE שמכיל את ה-PFN של דף ה-4KB.\n       *   עבור דף-על (2MB), ההיסט הוא 21 ביטים. ה-VPN יחולק בהתאם. ייתכן שה-PTE המצביע לדף-על נמצא ברמה 2 (לדוגמה, אם הרמה הראשונה והשניה יחד מכסות 21 ביטים). במקרה כזה, ה-MMU יגש לטבלת הדפים ברמה 1, ימצא PTE שמצביע לטבלת דפים ברמה 2, ושם ימצא PTE שמסומן כדף-על ומכיל ישירות את ה-PFN של בלוק ה-2MB. התרגום מסתיים בשלב מוקדם יותר, ללא צורך לגשת לטבלת הרמה הנמוכה ביותר.\n   *   **תפקיד ה-TLB:** ה-TLB (Translation Lookaside Buffer) הוא זיכרון מטמון מהיר של מיפויי כתובות וירטואליות-פיזיות.\n       *   כאשר ה-MMU מקבל כתובת וירטואלית, הוא מנסה למצוא מיפוי ב-TLB.\n       *   כדי לתמוך בשני גדלי הדפים, כל כניסה ב-TLB צריכה לכלול לא רק את ה-VPN וה-PFN, אלא גם את גודל הדף (Page Size bit/field) המשויך למיפוי. זה מאפשר ל-TLB להבחין בין כניסה של דף 4KB לכניסה של דף 2MB.\n       *   **אתגרים ושינויים ב-TLB:**\n           *   **חיפוש:** ה-TLB צריך לתמוך בחיפוש לפי VPN ובגודל הדף. לדוגמה, אם מחפשים VPN מסוים, ה-TLB צריך לבדוק אם יש כניסה עבורו בגודל 4KB או בגודל 2MB.\n           *   **כיסוי (Coverage):** דפי-על מגדילים משמעותית את הכיסוי של ה-TLB. כניסה אחת לדף-על מכסה 512 דפים סטנדרטיים (2MB / 4KB). זה מפחית את שיעור ה-TLB Miss עבור אזורי זיכרון גדולים.\n           *   **מורכבות חומרה:** הוספת שדה גודל הדף והלוגיקה לטיפול בו מגדילה את מורכבות ה-TLB. ייתכנו TLBs נפרדים עבור גדלי דפים שונים, או TLB מאוחד עם לוגיקת חיפוש מורכבת יותר.\n\n1.3. הקצאת זיכרון ופרגמנטציה:\n   *   **טיפול בבקשה:** כאשר תהליך מבקש 8MB רציפים, ומערכת ההפעלה מנסה להקצות אותם כדפי-על אך נתקלת בפרגמנטציה פיזית (אין 2MB רציפים), היא תיאלץ לחזור לשימוש בדפים סטנדרטיים של 4KB. במקרה זה, ה-8MB ימופו באמצעות 2048 דפים סטנדרטיים (8MB / 4KB). כל אחד מהם יקבל מסגרת פיזית נפרדת. טבלת הדפים תצטרך להכיל 2048 כניסות ברמה הנמוכה ביותר עבור בלוק זיכרון זה.\n   *   **השלכות ביצועיות:**\n       *   **גודל טבלת דפים:** במקום 4 כניסות של דפי-על (8MB / 2MB), יהיו 2048 כניסות לדפים סטנדרטיים. זה מגדיל משמעותית את נפח טבלת הדפים בזיכרון.\n       *   **TLB Miss Rate:** כל גישה לכתובת בטווח ה-8MB תצטרך כניסת TLB נפרדת עבור דף 4KB. אם ה-TLB קטן, שיעור ה-TLB Miss יעלה באופן דרמטי, מכיוון ש-2048 כניסות יידרשו במקום 4. כל TLB Miss מוביל לגישות מרובות לזיכרון הראשי (לשלוש רמות טבלת הדפים), מה שמאט את הגישה לזיכרון.\n       *   **Overhead של מערכת ההפעלה:** ניהול 2048 דפים במקום 4 דפי-על דורש יותר משאבי CPU וזיכרון ממערכת ההפעלה (לדוגמה, עבור page faults, ניהול רשימות דפים פנויים).\n       *   **פרגמנטציה פנימית:** למרות שדפי-על מפחיתים פרגמנטציה פנימית כאשר הם מנוצלים במלואם, שימוש בדפים סטנדרטיים עשוי להחמיר פרגמנטציה חיצונית אם לא ניתן להקצות אותם בצורה רציפה. במקרה זה, הבעיה היא פרגמנטציה חיצונית בזיכרון הפיזי שמונעת שימוש בדפי-על.\n\n1.4. הגנה ושיתוף זיכרון:\n   *   **הגנה על זיכרון:**\n       *   **יתרון:** דפי-על מפשטים הגנה על אזורי זיכרון גדולים. במקום להגדיר הרשאות ל-512 דפי 4KB בנפרד, ניתן להגדיר הרשאות (קריאה, כתיבה, הרצה) פעם אחת עבור דף-על שלם. זה מפחית את העומס על מערכת ההפעלה ומפשט את הלוגיקה.\n       *   **אתגר:** אם נדרשת הגנה עדינה יותר בתוך דף-על (לדוגמה, חלק מ-2MB מוגן בכתיבה וחלק לא), לא ניתן לעשות זאת ישירות עם דף-על יחיד. במקרה כזה, יש צורך לפרק את דף-העל לדפים סטנדרטיים ולנהל את ההגנה ברמת ה-4KB, מה שמבטל את יתרונות הביצועים של דף-העל.\n   *   **שיתוף זיכרון:**\n       *   **יתרון:** שיתוף אזורי זיכרון גדולים ורציפים בין תהליכים הופך ליעיל יותר. במקום שכל תהליך ימפה בנפרד אלפי דפים סטנדרטיים, הם יכולים למפות דף-על יחיד לאותו אזור פיזי. זה חוסך מקום בטבלאות הדפים של כל תהליך ומפחית את העומס על ה-TLB.\n       *   **אתגר:** בדומה להגנה, אם תהליכים שונים צריכים גישות שונות (לדוגמה, תהליך אחד קריאה-כתיבה, אחר קריאה בלבד) לאותו אזור בתוך דף-על, או אם רק חלק מדף-העל צריך להיות משותף, אז דף-על יחיד אינו מתאים. יש צורך לפרק אותו לדפים סטנדרטיים ולנהל את השיתוף וההרשאות ברמת ה-4KB. זה דורש לוגיקה מורכבת יותר במערכת ההפעלה כדי להחליט מתי להשתמש בדפי-על ומתי לפצל אותם."}, "difficulty_estimation": "Hard", "_source_file": "0477__Memory_Management__Open__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:28:28", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Memory Management", "Paging", "Virtual Memory", "TLB", "Shared Memory"], "content": {"text": "נתונה מערכת הפעלה מודרנית המשתמשת בזיכרון וירטואלי מבוסס דפדוף (paging) עם מרחב כתובות וירטואלי של 48 ביטים. גודל דף הוא 4KB. כל כניסה בטבלת הדפים (PTE) היא בגודל 8 בתים. המערכת כוללת גם TLB עם 64 כניסות, הפועל בשיטת אסוציאטיביות מלאה (fully associative).\n\nהמערכת תומכת גם בזיכרון משותף (shared memory) בין תהליכים, כאשר דפים המשותפים בין תהליכים ממופים לאותה מסגרת פיזית בזיכרון הפיזי, אך עשויים להופיע בכתובות וירטואליות שונות במרחבי הכתובות של התהליכים השונים.\n\nענו על השאלות הבאות ופרטו את כל החישובים וההנחות:", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "כמה רמות של טבלאות דפים נדרשות במערכת זו כדי למפות את מרחב הכתובות הוירטואלי? מהו גודל טבלת הדפים ברמה העליונה (root page table) בבתים?", "code_snippet": null, "options": null}, {"id": "1.2", "text": "תהליך P1 ניגש לכתובת וירטואלית X, שאינה דף משותף. הדף המכיל את X אינו נמצא ב-TLB, אך הוא נמצא בזיכרון הפיזי (כלומר, ה-PTE שלו מסומן כ-Present=1). תארו את רצף הפעולות המלא מתחילת הגישה לכתובת X ועד לקבלת הנתונים, כולל גישות ל-TLB, לטבלאות הדפים ולזיכרון הפיזי. כמה גישות לזיכרון הראשי (RAM) מתבצעות במקרה זה?", "code_snippet": null, "options": null}, {"id": "1.3", "text": "תהליך P2 ניגש לכתובת וירטואלית Y, הממופה לדף המשותף עם תהליך P3. נניח שהדף המשותף *אינו* ב-TLB של P2 וגם *אינו* נמצא בזיכרון הפיזי (Present=0 ב-PTE). לאחר מכן, תהליך P3 ניגש לאותה כתובת וירטואלית Y (אותו VPN), שגם עבורו הדף המשותף *אינו* ב-TLB. תארו את רצף הפעולות המלא עבור שתי הגישות (של P2 ולאחר מכן P3), כולל גישות ל-TLB, לטבלאות הדפים, לדיסק ולזיכרון הפיזי. כמה גישות לזיכרון הראשי (RAM) ולדיסק מתבצעות בסך הכל עבור שתי הגישות יחד?", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון:\n\n**1.1. חישוב רמות טבלאות הדפים וגודל טבלת הדפים ברמה העליונה:**\n*   גודל מרחב הכתובות הוירטואלי: 48 ביטים.\n*   גודל דף: 4KB = 2^12 בתים. לכן, ההיסט (offset) הוא 12 ביטים.\n*   מספר ביטים עבור מספר הדף הוירטואלי (VPN): 48 - 12 = 36 ביטים.\n*   גודל כניסה בטבלת הדפים (PTE): 8 בתים.\n*   מספר כניסות PTE שיכולות להיכנס לדף אחד: 4KB / 8 בתים/PTE = 512 כניסות (2^9 כניסות).\n*   לכן, כל רמה בטבלת הדפים משתמשת ב-9 ביטים מתוך ה-VPN כדי לאנדקס את הכניסה המתאימה.\n*   מספר רמות טבלאות הדפים הנדרשות: 36 ביטים / 9 ביטים לרמה = 4 רמות.\n*   טבלת הדפים ברמה העליונה (root page table) מכילה 512 כניסות (כיוון שהיא מאוחסנת בדף אחד). גודלה בבתים: 512 כניסות * 8 בתים/כניסה = 4096 בתים = 4KB.\n\n**תשובה:** נדרשות 4 רמות של טבלאות דפים. גודל טבלת הדפים ברמה העליונה הוא 4KB.\n\n**1.2. רצף פעולות עבור גישה לכתובת וירטואלית X (דף פרטי, TLB Miss, Page Table Hit):**\n1.  **גישה ל-TLB:** המעבד מנסה לתרגם את הכתובת הוירטואלית X באמצעות ה-TLB. מכיוון שהדף אינו ב-TLB (TLB Miss), תתרחש החמאה ב-TLB.\n2.  **גישה לטבלאות הדפים (4 רמות):** מערכת ההפעלה תתחיל לעבור על טבלאות הדפים כדי למצוא את ה-PTE המתאים:\n    *   גישה לזיכרון הראשי כדי לקרוא את הכניסה המתאימה מטבלת הדפים ברמה 1.\n    *   גישה לזיכרון הראשי כדי לקרוא את הכניסה המתאימה מטבלת הדפים ברמה 2.\n    *   גישה לזיכרון הראשי כדי לקרוא את הכניסה המתאימה מטבלת הדפים ברמה 3.\n    *   גישה לזיכרון הראשי כדי לקרוא את ה-PTE הסופי מטבלת הדפים ברמה 4. מכיוון שהדף נמצא בזיכרון הפיזי (Present=1), ה-PTE יכיל את מספר המסגרת הפיזית (PFN).\n3.  **עדכון TLB:** ה-PTE שנמצא בטבלאות הדפים יוכנס ל-TLB. מכיוון שה-TLB מלא אסוציאטיבי, הוא יוכנס לאחת הכניסות (בהתאם למדיניות ההחלפה).\n4.  **גישה לזיכרון הפיזי:** המעבד משתמש ב-PFN שהתקבל וב-offset מכתובת X כדי לגשת לכתובת הפיזית ולקבל את הנתונים.\n\n**סה\"כ גישות לזיכרון הראשי (RAM):**\n*   4 גישות לטבלאות הדפים (אחת לכל רמה).\n*   1 גישה לנתונים עצמם.\n*   סה\"כ: 5 גישות לזיכרון הראשי.\n\n**תשובה:** 5 גישות לזיכרון הראשי.\n\n**1.3. רצף פעולות עבור גישות לכתובת וירטואלית Y (דף משותף, TLB Miss, Page Fault):**\n\n**עבור גישת P2 לכתובת Y:**\n1.  **גישה ל-TLB של P2:** המעבד מנסה לתרגם את הכתובת Y. TLB Miss (הדף אינו ב-TLB).\n2.  **גישה לטבלאות הדפים של P2 (4 רמות):** מערכת ההפעלה עוברת על טבלאות הדפים של P2.\n    *   4 גישות לזיכרון הראשי לקריאת ה-PTEs ברמות 1-4.\n    *   ה-PTE הסופי נמצא, אך Present=0 (הדף אינו בזיכרון הפיזי).\n3.  **Page Fault:** מכיוון ש-Present=0, תתרחש פסיקת דף (page fault).\n    *   **טיפול בפסיקת הדף:**\n        *   מערכת ההפעלה בוחרת מסגרת פיזית פנויה (או מפנה אחת, אם אין). נניח שהיא בוחרת מסגרת F.\n        *   מערכת ההפעלה טוענת את תוכן הדף המבוקש מהדיסק למסגרת F. זוהי **גישה לדיסק** (קריאה).\n        *   מערכת ההפעלה מעדכנת את ה-PTE של דף Y בטבלאות הדפים של P2 עם ה-PFN של מסגרת F, ומסמנת Present=1 ו-Dirty=0 (אם הדף לא השתנה).\n        *   **גישה לזיכרון הראשי** לעדכון ה-PTE.\n4.  **עדכון TLB של P2:** ה-PTE המעודכן (VPN של Y, PFN של F) מוכנס ל-TLB של P2.\n5.  **גישה לזיכרון הפיזי:** המעבד משתמש ב-PFN וב-offset כדי לגשת לכתובת הפיזית ולקבל את הנתונים.\n\n**סה\"כ עבור P2:**\n*   גישות ל-RAM: 4 (לטבלאות דפים) + 1 (לעדכון PTE) + 1 (לנתונים) = 6 גישות.\n*   גישות לדיסק: 1 (לטעינת הדף).\n\n**עבור גישת P3 לכתובת Y (אותו דף משותף):**\n1.  **גישה ל-TLB של P3:** המעבד מנסה לתרגם את הכתובת Y. TLB Miss (הדף אינו ב-TLB של P3).\n2.  **גישה לטבלאות הדפים של P3 (4 רמות):** מערכת ההפעלה עוברת על טבלאות הדפים של P3.\n    *   4 גישות לזיכרון הראשי לקריאת ה-PTEs ברמות 1-4. (חשוב לזכור ש-P3 צריך את ה-PTE שלו. הדף *כבר* בזיכרון הפיזי בזכות P2, לכן ה-PTE של P3 יהיה Present=1 ומצביע על אותה מסגרת F). \n    *   מערכת ההפעלה תמצא את ה-PTE המתאים שמצביע על אותה מסגרת פיזית F, עם Present=1.\n3.  **עדכון TLB של P3:** ה-PTE שנמצא (VPN של Y, PFN של F) מוכנס ל-TLB של P3.\n4.  **גישה לזיכרון הפיזי:** המעבד משתמש ב-PFN וב-offset כדי לגשת לכתובת הפיזית ולקבל את הנתונים.\n\n**סה\"כ עבור P3:**\n*   גישות ל-RAM: 4 (לטבלאות דפים) + 1 (לנתונים) = 5 גישות.\n*   גישות לדיסק: 0 (הדף כבר נטען ע\"י P2).\n\n**סה\"כ עבור שתי הגישות יחד:**\n*   סה\"כ גישות לזיכרון הראשי (RAM): 6 (עבור P2) + 5 (עבור P3) = 11 גישות.\n*   סה\"כ גישות לדיסק: 1 (עבור P2) + 0 (עבור P3) = 1 גישה.\n\n**תשובה:** 11 גישות לזיכרון הראשי ו-1 גישה לדיסק."}, "difficulty_estimation": "Hard", "_source_file": "0478__Memory_Management__Open__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:00:50", "_subject": "Virtualization"}, {"id": 1, "type": "Open", "topic": ["Memory Management", "Segmentation", "Paging", "Virtual Memory", "TLB", "Page Fault"], "content": {"text": "נתונה מערכת הפעלה המשלבת ניהול זיכרון באמצעות סגמנטציה ודפדוף (Segmentation with Paging). מרחב הכתובות הוירטואלי הוא בגודל 64 ביט. גודל דף הוא 4KB.\n\nלכל תהליך יש טבלת סגמנטים (Segment Table - ST), כאשר כל כניסה בטבלת הסגמנטים (STE) היא בגודל 64 ביט ומכילה:\n*   כתובת בסיס פיזית לטבלת הדפים של הסגמנט (Page Table Base Address PFN) – מצביע למסגרת הפיזית הראשונה של טבלת הדפים.\n*   אורך הסגמנט בבתים (Segment Length) – מספר הבתים המקסימלי הנגיש בסגמנט.\n*   ביט Valid (V), ביט Read/Write (RW), ביט Execute (X) – שלושה ביטים עבור הרשאות וסטטוס.\n\nכל סגמנט ממופה באמצעות טבלת דפים לינארית משלו. כל כניסה בטבלת הדפים (PTE) היא בגודל 32 ביט ומכילה:\n*   מספר מסגרת פיזית (PFN).\n*   ביט Present (P), ביט Dirty (D), ביט Accessed (A) – שלושה ביטים עבור סטטוס הדף.\n\nבמערכת קיים TLB מאוחד (עבור סגמנטים ודפים) המכיל 128 כניסות, בשיטת מיפוי סט אסוציאטיבי בעל 4 דרכים (4-way set associative).\n\n", "code_snippet": null, "options": null}, "sub_questions": [{"id": "1.1", "text": "פרטו כיצד כתובת וירטואלית מתפרקת למרכיביה (מספר סגמנט, מספר דף בתוך סגמנט, היסט דף). הציגו את מספר הביטים לכל רכיב, ונמקו את גודלם.", "code_snippet": null, "options": null}, {"id": "1.2", "text": "תארו את תהליך תרגום כתובת וירטואלית לכתובת פיזית במערכת זו, כולל כל הבדיקות הנדרשות (לדוגמה, חריגה מגבולות סגמנט, Page Fault, TLB Miss/Hit).", "code_snippet": null, "options": null}, {"id": "1.3", "text": "כמה גישות לזיכרון הראשי (Main Memory) וכמה גישות לדיסק יתבצעו במקרים הבאים, עבור גישת תהליך לכתובת וירטואלית מסוימת לצורך קריאה (Read)? הניחו שבכל מקרה של Page Fault נדרשת החלפת דף קיים בזיכרון, והדף המוחלף מלוכלך (Dirty). יש לכלול את הגישות לדיסק הנדרשות עבור טיפול ב-Page Fault.\nא. TLB Hit, והדף נמצא בזיכרון הפיזי.\nב. TLB Miss, אך הדף נמצא בזיכרון הפיזי.\nג. TLB Miss, והדף אינו נמצא בזיכרון הפיזי (Page Fault).", "code_snippet": null, "options": null}], "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "פתרון לשאלה:\n\n**1.1. פירוק כתובת וירטואלית למרכיביה:**\n*   **גודל כתובת וירטואלית:** 64 ביט.\n*   **גודל דף:** 4KB = 2^12 בתים. לכן, ההיסט בתוך הדף (Page Offset - PO) הוא **12 ביטים**.\n\n*   **גודל כניסה לטבלת דפים (PTE):** 32 ביט. מתוכם 3 ביטים עבור P, D, A. לכן, מספר המסגרת הפיזית (PFN) הוא 32 - 3 = **29 ביטים**.\n    *   מספר ביטים זה מגדיר את גודל הזיכרון הפיזי המקסימלי: 2^29 מסגרות * 2^12 בתים/מסגרת = 2^41 בתים (2 טרה-בייט). כלומר, כל מספר דף בתוך סגמנט (Page Number - PN) חייב להיות מיוצג על ידי לכל היותר 29 ביטים כדי שיוכל להיות ממופה למסגרת פיזית.\n    *   לכן, מספר הדף בתוך סגמנט (PN) הוא **29 ביטים**.\n\n*   **מספר הסגמנט (Segment Number - SN):** נותרו 64 ביט (סה\"כ) - 12 ביט (PO) - 29 ביט (PN) = **23 ביטים**.\n    *   זה מאפשר לכל תהליך עד 2^23 סגמנטים.\n\n**סיכום פירוק הכתובת הוירטואלית:**\n*   **Segment Number (SN): 23 ביטים**\n*   **Page Number (PN): 29 ביטים** (בתוך הסגמנט)\n*   **Page Offset (PO): 12 ביטים**\n\n**בדיקת עקביות עם STE:**\n*   **גודל כניסה לטבלת סגמנטים (STE):** 64 ביט.\n*   **PT_Base (PFN):** 29 ביטים (כפי שנקבע מגודל ה-PTE).\n*   **ביטים V, RW, X:** 3 ביטים.\n*   **נותר עבור Segment Length (SL):** 64 - 29 - 3 = **32 ביטים**.\n    *   לכן, אורך סגמנט מקסימלי (SL) הוא 2^32 בתים (4 ג'יגה-בייט). למרות שכתובת וירטואלית בתוך סגמנט (PN+PO) יכולה לכאורה לייצג 2^41 בתים, שדה ה-SL מגביל בפועל את הגודל המקסימלי של סגמנט ל-4GB.\n\n**1.2. תהליך תרגום כתובת וירטואלית לכתובת פיזית:**\nתהליך התרגום מתבצע באופן הבא:\n\n1.  **פירוק הכתובת הוירטואלית:** ה-CPU מפרק את הכתובת הוירטואלית (64 ביט) למספר סגמנט (SN), מספר דף בתוך סגמנט (PN) והיסט דף (PO) כפי שחושב בסעיף 1.1.\n\n2.  **בדיקת TLB:**\n    *   ה-CPU מנסה למצוא התאמה ב-TLB עבור הזוג (SN, PN).\n    *   **TLB Hit:** אם נמצאה כניסה מתאימה, ה-TLB מחזיר את מספר המסגרת הפיזית (PFN) ישירות, יחד עם ביטי ההרשאות והסטטוס (כגון P,D,A, RW, X). ה-CPU מבצע בדיקות הרשאה (לדוגמה, האם מותר לקרוא לכתובת זו לפי ביט RW). אם הכל תקין, הכתובת הפיזית מחושבת (PFN * Page_Size + PO) ומתבצעת גישה לזיכרון הפיזי. ביט Accessed (A) בכניסת ה-TLB מעודכן, וביט Dirty (D) מעודכן אם הגישה היא כתיבה.\n    *   **TLB Miss:** אם לא נמצאה כניסה מתאימה, ה-CPU ממשיך לגישה לטבלאות בזיכרון הראשי.\n\n3.  **גישה לטבלת הסגמנטים (ST):** (במקרה של TLB Miss)\n    *   ה-CPU משתמש במספר הסגמנט (SN) כדי לאתר את כניסת ה-STE המתאימה בטבלת הסגמנטים. כתובת הבסיס של טבלת הסגמנטים (STBR) נמצאת באוגר מיוחד ב-CPU.\n    *   ה-CPU קורא את ה-STE מכתובת: `STBR + SN * sizeof(STE)`. זוהי גישה לזיכרון הראשי.\n    *   **בדיקת Valid (V):** אם ביט V ב-STE הוא 0, מתרחשת פסיקת סגמנט (Segment Fault) – הסגמנט אינו חוקי.\n    *   **בדיקת אורך סגמנט:** ה-CPU בודק שההיסט בתוך הסגמנט (PN * Page_Size + PO) קטן מאורך הסגמנט (SL) הרשום ב-STE. אם ההיסט גדול או שווה ל-SL, מתרחשת פסיקת סגמנט (Segment Fault) – חריגה מגבולות הסגמנט.\n    *   **בדיקת הרשאות:** ה-CPU בודק את ביטי RW ו-X ב-STE מול סוג הגישה המבוקש (קריאה, כתיבה, הרצה). אם יש הפרת הרשאה, מתרחשת פסיקת הגנה (Protection Fault).\n    *   אם כל הבדיקות עברו בהצלחה, ה-CPU מחלץ את כתובת הבסיס הפיזית של טבלת הדפים של הסגמנט (PT_Base PFN) מה-STE.\n\n4.  **גישה לטבלת הדפים (PT):** (במקרה של TLB Miss)\n    *   ה-CPU משתמש במספר הדף (PN) כדי לאתר את כניסת ה-PTE המתאימה בטבלת הדפים של הסגמנט.\n    *   ה-CPU קורא את ה-PTE מכתובת: `PT_Base_PFN * Page_Size + PN * sizeof(PTE)`. זוהי גישה נוספת לזיכרון הראשי.\n    *   **בדיקת Present (P):** אם ביט P ב-PTE הוא 0, מתרחשת פסיקת דף (Page Fault).\n        *   **טיפול ב-Page Fault:** מערכת ההפעלה משתלטת. היא בוחרת מסגרת פיזית פנויה (או מפנה מסגרת קיימת לפי אלגוריתם החלפה). אם המסגרת המפונה הייתה 'מלוכלכת' (Dirty=1), תוכנה לדיסק. לאחר מכן, הדף המבוקש נטען מהדיסק למסגרת הפיזית החדשה. ה-PTE מעודכן (P=1, D=0, A=1, PFN חדש). ה-TLB מעודכן עם המיפוי החדש. הפקודה שגרמה ל-Page Fault מופעלת מחדש.\n    *   **בדיקת הרשאות:** ה-CPU בודק את ביטי ההרשאה ב-PTE מול סוג הגישה המבוקש. אם יש הפרת הרשאה, מתרחשת פסיקת הגנה.\n    *   אם הכל תקין, ה-CPU מחלץ את מספר המסגרת הפיזית (PFN) מה-PTE. ביט Accessed (A) ב-PTE מעודכן ל-1. אם הגישה היא כתיבה, ביט Dirty (D) ב-PTE מעודכן ל-1.\n    *   ה-TLB מתעדכן עם המיפוי החדש (SN, PN) -> PFN.\n\n5.  **חישוב כתובת פיזית וגישה לזיכרון הפיזי:**\n    *   הכתובת הפיזית מחושבת: `Physical_Address = PFN * Page_Size + PO`.\n    *   ה-CPU ניגש לזיכרון הפיזי בכתובת זו כדי לבצע את הפעולה המבוקשת (קריאה/כתיבה).\n\n**1.3. מספר גישות לזיכרון הראשי ולדיסק:**\n\n**א. TLB Hit, והדף נמצא בזיכרון הפיזי (גישת קריאה):**\n*   **גישות ל-TLB:** 1 (Hit).\n*   **גישות לזיכרון הראשי:** 1 (לנתון/פקודה עצמה). אין צורך לגשת לטבלאות בזיכרון הראשי.\n*   **גישות לדיסק:** 0.\n\n**ב. TLB Miss, אך הדף נמצא בזיכרון הפיזי (גישת קריאה):**\n*   **גישות ל-TLB:** 1 (Miss).\n*   **גישות לזיכרון הראשי:**\n    1.  קריאת STE מזיכרון ראשי (עבור SN).\n    2.  קריאת PTE מזיכרון ראשי (עבור PN).\n    3.  קריאת הנתון/פקודה עצמה מזיכרון ראשי.\n    *   **סה\"כ גישות לזיכרון הראשי: 3.** (לאחר מכן ה-TLB מתעדכן).\n*   **גישות לדיסק:** 0.\n\n**ג. TLB Miss, והדף אינו נמצא בזיכרון הפיזי (Page Fault, גישת קריאה):**\n*   **גישות ל-TLB:** 1 (Miss).\n*   **גישות לזיכרון הראשי:**\n    1.  קריאת STE מזיכרון ראשי (עבור SN).\n    2.  קריאת PTE מזיכרון ראשי (עבור PN) – גורם ל-Page Fault.\n    *   **בטיפול ב-Page Fault (בהנחה של דף מוחלף מלוכלך):**\n        3.  קריאת PTE של הדף המוחלף מזיכרון ראשי (כדי לבדוק P, D, A).\n        4.  קריאת תוכן הדף המוחלף מזיכרון ראשי (כדי לכתוב לדיסק).\n        5.  כתיבת PTE של הדף המוחלף לזיכרון ראשי (לסמן P=0).\n        6.  כתיבת תוכן הדף המבוקש לזיכרון ראשי (לאחר קריאה מהדיסק).\n        7.  כתיבת PTE של הדף המבוקש לזיכרון ראשי (לסמן P=1, D=0, A=1, PFN).\n    8.  קריאת הנתון/פקודה עצמה מזיכרון ראשי (לאחר שהדף נטען והפקודה מופעלת מחדש).\n    *   **סה\"כ גישות לזיכרון הראשי: 8.**\n*   **גישות לדיסק:**\n    1.  כתיבת הדף המוחלף לדיסק (כי הוא Dirty).\n    2.  קריאת הדף המבוקש מהדיסק.\n    *   **סה\"כ גישות לדיסק: 2.**"}, "difficulty_estimation": "Hard", "_source_file": "0479__Memory_Management__Open__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "Open", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:29:31", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Memory Management"], "content": {"text": "נתונה התוכנית הבאה ב-C:\n\nהסבירו בקצרה היכן מאוחסנים המשתנים `global_var`, `stack_var`, והזיכרון שהוקצה עבור `heap_ptr` במרחב הכתובות של התהליך.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\nint global_var = 10;\n\nvoid func() {\n    int stack_var = 20;\n    int* heap_ptr = (int*)malloc(sizeof(int));\n    if (heap_ptr == NULL) {\n        perror(\"malloc failed\");\n        exit(EXIT_FAILURE);\n    }\n    *heap_ptr = 30;\n    printf(\"Global var address: %p\\n\", &global_var);\n    printf(\"Stack var address: %p\\n\", &stack_var);\n    printf(\"Heap var address: %p\\n\", (void*)heap_ptr);\n    free(heap_ptr);\n}\n\nint main() {\n    func();\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "המשתנה `global_var` הוא משתנה גלובלי מאותחל, ולכן הוא מאוחסן בקטע הנתונים (Data Segment) של מרחב הכתובות של התהליך.\nהמשתנה `stack_var` הוא משתנה מקומי לפונקציה `func`, ולכן הוא מאוחסן על המחסנית (Stack) של התהליך.\nהזיכרון שהוקצה באמצעות `malloc` עבור `heap_ptr` (כלומר, המיקום שאליו `heap_ptr` מצביע) מאוחסן בערימה (Heap) של התהליך. `heap_ptr` עצמו (הפוינטר) הוא משתנה מקומי לפונקציה `func` ולכן מאוחסן על המחסנית, אך השאלה התייחסה לזיכרון *שהוקצה עבורו*, כלומר הזיכרון אליו הוא מצביע."}, "difficulty_estimation": "Easy", "_source_file": "0481__Memory_Management__CodeAnalysis__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:02:36", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Memory Management", "Virtual Memory", "Paging", "Heap"], "content": {"text": "נתונה התוכנית הבאה בשפת C:\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n\nint main() {\n    int* arr;\n    // Allocate space for 1000 integers\n    arr = (int*) malloc(1000 * sizeof(int));\n\n    if (arr == NULL) {\n        printf(\"Memory allocation failed!\\n\");\n        return 1;\n    }\n\n    // Access some elements to ensure pages are touched\n    for (int i = 0; i < 10; ++i) {\n        arr[i] = i;\n    }\n\n    printf(\"Array allocated and accessed.\\n\");\n\n    free(arr);\n    return 0;\n}\n```\n\nבהנחה שגודל דף זיכרון במערכת הוא 4KB (קילובייט) וכי `sizeof(int)` הוא 4 בתים.\nכמה דפי זיכרון וירטואליים לכל הפחות נדרשים עבור הנתונים שהוקצו על ידי קריאת `malloc` בשורה 7?\nיש להתעלם מזיכרון הנדרש עבור קוד התוכנית, המחסנית, הערימה (למעט הנתונים שהוקצו ב-malloc), וטבלת הדפים. התייחסו אך ורק לזיכרון שהוקצה ישירות עבור המערך `arr`.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכנית מקצה זיכרון עבור 1000 מספרים שלמים (integers) באמצעות `malloc`.\nגודלו של טיפוס `int` הוא 4 בתים.\nלכן, סך הזיכרון המוקצה למערך `arr` הוא: `1000 * 4 בתים = 4000 בתים`.\n\nגודל דף זיכרון נתון כ-4KB, שזה שווה ל-`4 * 1024 בתים = 4096 בתים`.\n\nמכיוון ש-4000 בתים (הזיכרון המוקצה) קטנים מ-4096 בתים (גודל דף בודד), כל הזיכרון שהוקצה עבור המערך `arr` יכול להיכנס לדף זיכרון וירטואלי אחד בלבד.\n\nלכן, נדרש דף זיכרון וירטואלי אחד לכל הפחות עבור נתוני המערך.", "code_snippet": null}, "difficulty_estimation": "Easy", "_source_file": "0482__Memory_Management__CodeAnalysis__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:02:47", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Memory Management", "Dynamic Memory Allocation", "Memory Leaks"], "content": {"text": "נתונה תוכנית ה-C הבאה. עברו על הקוד וענו על השאלות הבאות:\n1. מה הפלט של התוכנית כאשר היא רצה?\n2. האם קיימת בעיה כלשהי בתוכנית? אם כן, תארו אותה במפורט והסבירו מדוע היא מתרחשת.\n3. הציעו תיקון לבעיה שזיהיתם.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\nvoid allocate_and_print() {\n    int* ptr = (int*)malloc(sizeof(int));\n    if (ptr == NULL) {\n        perror(\"malloc failed\");\n        return;\n    }\n    *ptr = 10;\n    printf(\"Value: %d\\n\", *ptr);\n    // Missing free(ptr);\n}\n\nint main() {\n    for (int i = 0; i < 3; ++i) {\n        allocate_and_print();\n    }\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התוכנית תדפיס:\nValue: 10\nValue: 10\nValue: 10\n\nכן, קיימת בעיה של דליפת זיכרון (memory leak). בפונקציה `allocate_and_print`, אנו מקצים זיכרון באמצעות `malloc` עבור משתנה מסוג `int`. לאחר השימוש בזיכרון והדפסת הערך, הזיכרון שהוקצה אינו משוחרר באמצעות `free`. מכיוון שהפונקציה נקראת בלולאה שלוש פעמים, בכל קריאה מוקצה זיכרון חדש, והזיכרון שהוקצה בקריאות קודמות הופך לבלתי נגיש (unreachable) אך נשאר תפוס, מה שמוביל לדליפת זיכרון. לאורך זמן, בריצות ארוכות או בהקצאות גדולות, הדבר יכול להוביל לצריכת זיכרון מופרזת ואף לקריסת המערכת עקב חוסר בזיכרון זמין.\n\nכדי לתקן את הבעיה, יש לשחרר את הזיכרון שהוקצה באמצעות `free(ptr);` לפני שהפונקציה `allocate_and_print` מסתיימת.\n\nהקוד המתוקן ייראה כך:\n```c\n#include <stdio.h>\n#include <stdlib.h>\n\nvoid allocate_and_print() {\n    int* ptr = (int*)malloc(sizeof(int));\n    if (ptr == NULL) {\n        perror(\"malloc failed\");\n        return;\n    }\n    *ptr = 10;\n    printf(\"Value: %d\\\\n\", *ptr);\n    free(ptr); // תיקון: שחרור הזיכרון\n}\n\nint main() {\n    for (int i = 0; i < 3; ++i) {\n        allocate_and_print();\n    }\n    return 0;\n}\n```"}, "difficulty_estimation": "Easy", "_source_file": "0483__Memory_Management__CodeAnalysis__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:03:06", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Memory Management"], "content": {"text": "נתונה תוכנית ה-C הבאה. ציין עבור כל אחד מהמשתנים הבאים היכן הוא מאוחסן בזיכרון (מחסנית (Stack), ערימה (Heap), או מקטע נתונים (Data Segment / BSS)). הסבר בקצרה את בחירתך:\n1.  `global_var`\n2.  `static_var`\n3.  `local_main_var`\n4.  `local_func_var`\n5.  הזיכרון שהוקצה על ידי `malloc` (שאליו מצביע `heap_ptr`)\n6.  המשתנה `heap_ptr` עצמו", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\nint global_var = 10; // Global variable\nstatic int static_var = 20; // Static global variable\n\nvoid func() {\n    int local_func_var = 30; // Local variable in func\n    printf(\"Address of local_func_var in func: %p\\n\", (void*)&local_func_var);\n}\n\nint main() {\n    int local_main_var = 40; // Local variable in main\n    char* heap_ptr = (char*)malloc(100); // Dynamically allocated memory\n\n    printf(\"Address of global_var: %p\\n\", (void*)&global_var);\n    printf(\"Address of static_var: %p\\n\", (void*)&static_var);\n    printf(\"Address of local_main_var: %p\\n\", (void*)&local_main_var);\n    printf(\"Address of heap_ptr (pointer itself): %p\\n\", (void*)&heap_ptr);\n    printf(\"Address pointed to by heap_ptr (heap memory): %p\\n\", (void*)heap_ptr);\n\n    func();\n\n    free(heap_ptr);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "להלן פירוט מיקום האחסון בזיכרון עבור כל אחד מהמשתנים:\n\n1.  `global_var`: מאוחסן במקטע הנתונים (Data Segment).\n    **הסבר:** זהו משתנה גלובלי מאותחל, והוא נטען לזיכרון כחלק ממקטע הנתונים של התוכנית בזמן טעינה.\n\n2.  `static_var`: מאוחסן במקטע הנתונים (Data Segment).\n    **הסבר:** זהו משתנה סטטי גלובלי מאותחל. משתנים סטטיים (בין אם גלובליים ובין אם מקומיים) מאוחסנים במקטע הנתונים (או במקטע BSS אם אינם מאותחלים), ומחזיקים את ערכם לאורך כל חיי התוכנית.\n\n3.  `local_main_var`: מאוחסן במחסנית (Stack).\n    **הסבר:** זהו משתנה מקומי לפונקציה `main`. משתנים מקומיים (אוטומטיים) נוצרים על המחסנית כאשר הפונקציה נקראת ונמחקים כאשר הפונקציה מסתיימת.\n\n4.  `local_func_var`: מאוחסן במחסנית (Stack).\n    **הסבר:** בדומה ל-`local_main_var`, זהו משתנה מקומי לפונקציה `func` ונוצר על המחסנית כאשר `func` נקראת.\n\n5.  הזיכרון שהוקצה על ידי `malloc` (שאליו מצביע `heap_ptr`): מאוחסן בערימה (Heap).\n    **הסבר:** פונקציית `malloc` משמשת להקצאת זיכרון דינמי בזמן ריצה, וזיכרון זה מוקצה מהערימה. יש לשחרר זיכרון זה במפורש באמצעות `free`.\n\n6.  המשתנה `heap_ptr` עצמו: מאוחסן במחסנית (Stack).\n    **הסבר:** `heap_ptr` הוא משתנה מצביע מקומי לפונקציה `main`. כמו כל משתנה מקומי אחר, הוא מאוחסן על המחסנית. רק הזיכרון שאליו הוא מצביע נמצא בערימה."}, "difficulty_estimation": "Easy", "_source_file": "0484__Memory_Management__CodeAnalysis__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:03:24", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Memory Management", "Heap", "malloc", "free"], "content": {"text": "נתונה התוכנית הבאה בשפת C. עיין בקוד וענה על השאלה:\n\nלאחר ביצוע הקריאה לפונקציה `free(ptr)` בשורה 12, מהו המצב הנכון ביותר לגבי הזיכרון שהיה מצביע אליו `ptr`?", "code_snippet": "#include <stdio.h>\n#include <stdlib.h> // For malloc and free\n\nint main() {\n    int* ptr = (int*) malloc(sizeof(int));\n    if (ptr == NULL) {\n        printf(\"Memory allocation failed!\\n\");\n        return 1;\n    }\n\n    *ptr = 10;\n    printf(\"Value before free: %d\\n\", *ptr);\n\n    free(ptr); // Line 12\n    printf(\"Memory freed.\\n\");\n\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הקריאה לפונקציה `free(ptr)` משחררת את הזיכרון שהוקצה בעבר באמצעות `malloc` בחזרה לבריכת הזיכרון (heap) של התהליך. זיכרון זה מסומן כעת כזמין להקצאות עתידיות על ידי `malloc`. חשוב לציין שהזיכרון אינו מוחזר בהכרח מיד למערכת ההפעלה, אלא נשאר זמין לשימוש פנימי של מנהל הזיכרון של התהליך. הגישה לזיכרון זה לאחר שחרורו (use-after-free) היא התנהגות בלתי מוגדרת (undefined behavior) ויכולה להוביל לקריסות או פרצות אבטחה."}, "difficulty_estimation": "Easy", "_source_file": "0485__Memory_Management__CodeAnalysis__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:03:38", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Memory Management", "Heap", "Memory Leaks", "C/C++"], "content": {"text": "נתונה התוכנית הבאה בשפת C. עיין בקוד וענה על השאלה:\n\nמהי הבעיה העיקרית עם ניהול הזיכרון בתוכנית זו? הסבר בפירוט כיצד הבעיה מתרחשת ומהן ההשלכות האפשריות שלה.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\nvoid allocate_and_print() {\n    int* ptr = (int*)malloc(sizeof(int));\n    if (ptr == NULL) {\n        printf(\"Memory allocation failed!\\n\");\n        return;\n    }\n    *ptr = 100;\n    printf(\"Value: %d\\n\", *ptr);\n    // חסרה קריאה ל-free(ptr);\n}\n\nint main() {\n    allocate_and_print();\n    allocate_and_print();\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 10, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הבעיה העיקרית בתוכנית זו היא דליפת זיכרון (memory leak). הפונקציה `allocate_and_print` מקצה זיכרון על הערימה (heap) באמצעות `malloc` עבור משתנה מסוג `int` אך אינה משחררת אותו באמצעות `free` לפני שהיא מסיימת את ריצתה. בכל פעם שהפונקציה נקראת (כמו במקרה זה, פעמיים מתוך `main`), היא מקצה בלוק זיכרון חדש. המצביע `ptr` הוא משתנה מקומי לפונקציה, וכאשר הפונקציה מסיימת את ריצתה, המצביע הזה נעלם (מפונה מהמחסנית). כתוצאה מכך, הכתובת לבלוק הזיכרון שהוקצה הולכת לאיבוד, והזיכרון נשאר תפוס על הערימה אך אינו נגיש יותר לתוכנית, ולא ניתן לשחררו. לאורך זמן, אם התוכנית הייתה ממשיכה לקרוא לפונקציה זו שוב ושוב, היא הייתה צורכת יותר ויותר זיכרון פנוי מהמערכת, מה שעלול להוביל לחוסר זיכרון (Out Of Memory) ולגרום לקריסת התוכנית או להאט את ביצועי המערכת כולה.", "code_snippet": "// תיקון לבעיית דליפת הזיכרון:\n#include <stdio.h>\n#include <stdlib.h>\n\nvoid allocate_and_print() {\n    int* ptr = (int*)malloc(sizeof(int));\n    if (ptr == NULL) {\n        printf(\"Memory allocation failed!\\n\");\n        return;\n    }\n    *ptr = 100;\n    printf(\"Value: %d\\n\", *ptr);\n    free(ptr); // שחרור הזיכרון שהוקצה\n}\n\nint main() {\n    allocate_and_print();\n    allocate_and_print();\n    return 0;\n}"}, "difficulty_estimation": "Easy", "_source_file": "0486__Memory_Management__CodeAnalysis__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:03:54", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Memory Management", "Stack", "Heap", "Memory Leak", "C/C++"], "content": {"text": "נתונה תוכנית ה-C הבאה. נתח את השימוש בזיכרון בתוכנית זו. ציין אילו סוגי זיכרון (לדוגמה: מחסנית, ערימה, גלובלי) משמשים לאחסון המשתנים השונים, והאם התוכנית סובלת מדליפת זיכרון. אם קיימת דליפת זיכרון, הסבר היכן היא מתרחשת ומדוע.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h> // For malloc and free\n\nvoid allocate_and_lose() {\n    int *data = (int *)malloc(10 * sizeof(int)); // Allocate 40 bytes\n    if (data == NULL) {\n        printf(\"Memory allocation failed!\\n\");\n        return;\n    }\n    // No free(data) here\n}\n\nint main() {\n    int stack_array[5]; // Allocate 20 bytes on stack\n    for (int i = 0; i < 5; ++i) {\n        stack_array[i] = i;\n    }\n\n    int *heap_ptr = (int *)malloc(20 * sizeof(int)); // Allocate 80 bytes\n    if (heap_ptr == NULL) {\n        printf(\"Memory allocation failed!\\n\");\n        return 1;\n    }\n    for (int i = 0; i < 20; ++i) {\n        heap_ptr[i] = i * 2;\n    }\n\n    allocate_and_lose(); // This call will cause a leak\n\n    free(heap_ptr); // Correctly free memory allocated in main\n\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הניתוח: \n1.  **`stack_array`**: משתנה זה הוא מערך מקומי (local array) המוגדר בתוך הפונקציה `main`. הוא מוקצה על **המחסנית (Stack)**. גודלו ידוע בזמן קומפילציה, והוא משוחרר אוטומטית כאשר הפונקציה `main` מסתיימת.\n2.  **`heap_ptr`**: זהו מצביע (pointer) מקומי המוגדר בתוך הפונקציה `main`, ולכן הוא עצמו מוקצה על **המחסנית (Stack)**. אולם, הזיכרון שאליו הוא מצביע (20 אינטגרים) מוקצה באופן דינמי על **הערימה (Heap)** באמצעות קריאה ל-`malloc`. זיכרון זה משוחרר כראוי באמצעות `free(heap_ptr)` לפני סיום התוכנית.\n3.  **`data`** (בתוך הפונקציה `allocate_and_lose`): זהו מצביע מקומי המוגדר בתוך הפונקציה `allocate_and_lose`, ולכן הוא עצמו מוקצה על **המחסנית (Stack)**. הזיכרון שאליו הוא מצביע (10 אינטגרים) מוקצה באופן דינמי על **הערימה (Heap)** באמצעות קריאה ל-`malloc`.\n\n**דליפת זיכרון (Memory Leak):**\nהתוכנית **סובלת מדליפת זיכרון**.\nהדליפה מתרחשת בפונקציה `allocate_and_lose`. בתוך פונקציה זו, מוקצה זיכרון על הערימה באמצעות `malloc` עבור המצביע `data`. אולם, הפונקציה מסתיימת מבלי לבצע קריאה ל-`free(data)`. כתוצאה מכך, הזיכרון שהוקצה על הערימה נשאר תפוס על ידי התהליך, אך המצביע `data` (שהיה על המחסנית) נעלם עם סיום הפונקציה. אין עוד דרך לגשת לזיכרון שהוקצה או לשחרר אותו, ולכן הוא הופך לזיכרון דולף (leaked memory) שאינו בשימוש ואינו ניתן לשחרור עד לסיום התהליך כולו."}, "difficulty_estimation": "Easy", "_source_file": "0487__Memory_Management__CodeAnalysis__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:04:08", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Memory Management", "Stack vs Heap", "Dangling Pointers", "Undefined Behavior"], "content": {"text": "נתונה תוכנית ה-C הבאה. מהי הבעיה העיקרית בקוד הנתון, וכיצד היא קשורה לניהול זיכרון? הסבר מהו הפלט הצפוי של התוכנית (או מדוע הוא אינו מוגדר), וכיצד ניתן לתקן את הקוד כך שיפעל כראוי ויחזיר מערך שלם.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\nint* createArray() {\n    int arr[5]; // Allocated on the stack\n    for (int i = 0; i < 5; i++) {\n        arr[i] = i * 10;\n    }\n    printf(\"Inside createArray: arr[0] = %d\\n\", arr[0]);\n    return arr; // Returning address of a local stack variable\n}\n\nint main() {\n    int* myArray = createArray();\n    printf(\"Back in main: myArray[0] = %d\\n\", myArray[0]);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הבעיה העיקרית בקוד היא ניסיון להחזיר מצביע למערך מקומי שהוקצה על המחסנית (stack). כאשר הפונקציה `createArray` מסיימת את ריצתה, מסגרת המחסנית שלה נמחקת, והזיכרון שהוקצה למערך `arr` הופך להיות לא חוקי. לכן, המצביע `myArray` ב-`main` הוא מצביע תלוי (dangling pointer) המצביע לזיכרון שכבר אינו מובטח להיות תקף או להכיל את הערכים המקוריים. גישה לזיכרון זה היא התנהגות בלתי מוגדרת (Undefined Behavior).\n\n**הפלט הצפוי:**\nהשורה הראשונה `Inside createArray: arr[0] = 0` תמיד תודפס. \nהשורה השנייה `Back in main: myArray[0] = ...` תדפיס ערך בלתי מוגדר. במערכות מסוימות, ייתכן שתראה 0 (אם זיכרון המחסנית לא נדרס מיד), אך זה אינו מובטח. ייתכנו גם קריסות (segmentation fault) או ערכים אקראיים. לכן, הפלט אינו מוגדר ואינו צפוי להיות עקבי.\n\n**תיקון הקוד:**\nכדי לתקן את הקוד, יש להקצות את המערך באופן דינמי על הערימה (heap) באמצעות `malloc` (או `new` ב-C++), ולזכור לשחרר את הזיכרון באמצעות `free` כאשר הוא אינו נחוץ יותר, כדי למנוע דליפת זיכרון.\n\n**קוד מתוקן לדוגמה:**\n```c\n#include <stdio.h>\n#include <stdlib.h> // For malloc and free\n\nint* createArray() {\n    int* arr = (int*)malloc(5 * sizeof(int)); // Allocated on the heap\n    if (arr == NULL) {\n        perror(\"Failed to allocate memory\");\n        exit(EXIT_FAILURE);\n    }\n    for (int i = 0; i < 5; i++) {\n        arr[i] = i * 10;\n    }\n    printf(\"Inside createArray: arr[0] = %d\\n\", arr[0]);\n    return arr; // Returning address of heap-allocated memory\n}\n\nint main() {\n    int* myArray = createArray();\n    if (myArray != NULL) {\n        printf(\"Back in main: myArray[0] = %d\\n\", myArray[0]);\n        free(myArray); // Free the allocated memory\n        myArray = NULL; // Prevent dangling pointer\n    }\n    return 0;\n}\n```", "difficulty_estimation": "Easy"}, "_source_file": "0488__Memory_Management__CodeAnalysis__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:04:26", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Memory Management", "Paging", "Locality of Reference", "Page Faults"], "content": {"text": "נתונה תוכנית C המשתמשת במטריצה דו-ממדית גדולה. המערכת מריצה את התוכנית על מעבד יחיד. גודל דף זיכרון הוא 4KB. גודל משתנה `int` הוא 4 בתים. המטריצה `matrix` מוגדרת כמשתנה גלובלי. נניח שבהתחלה אף דף של המטריצה אינו נמצא בזיכרון הפיזי (כלומר, כל גישה לדף חדש תגרום ל-Page Fault). כמו כן, נניח שגודל הזיכרון הפיזי הזמין לתהליך הוא 100 דפים בלבד, ושמדיניות החלפת הדפים היא LRU (Least Recently Used).\n\nהקוד הבא מראה שתי פונקציות המגשות לאלמנטים במטריצה בסדרים שונים.\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n\n#define ROWS 1024\n#define COLS 1024\n#define PAGE_SIZE_BYTES 4096 // 4 KB\n#define INT_SIZE 4           // size of int in bytes\n\nint matrix[ROWS][COLS]; // Global static array\n\nvoid access_row_major() {\n    for (int i = 0; i < ROWS; ++i) {\n        for (int j = 0; j < COLS; ++j) {\n            matrix[i][j] = i * COLS + j;\n        }\n    }\n}\n\nvoid access_col_major() {\n    for (int j = 0; j < COLS; ++j) {\n        for (int i = 0; i < ROWS; ++i) {\n            matrix[i][j] = i * COLS + j;\n        }\n    }\n}\n\nint main() {\n    access_row_major();\n    access_col_major();\n    return 0;\n}\n```\n\nנתחו את הקוד הנתון וענו על השאלות הבאות:\n1.  כמה Page Faults סך הכל יתרחשו במהלך קריאה לפונקציה `access_row_major()`? נמקו.\n2.  כמה Page Faults סך הכל יתרחשו במהלך קריאה לפונקציה `access_col_major()`? נמקו.\n3.  הסבירו מדוע יש הבדל (אם יש) במספר ה-Page Faults בין שתי הפונקציות, ואיזה עיקרון של ניהול זיכרון מודגם כאן.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": false, "correct_option": null, "explanation": "חישובים מקדימים:\n*   גודל `int`: 4 בתים.\n*   גודל דף: 4096 בתים.\n*   מספר משתני `int` לדף: 4096 / 4 = 1024 משתני `int`.\n*   ממדי המטריצה: `ROWS = 1024`, `COLS = 1024`.\n*   גודל שורה במטריצה: `COLS * INT_SIZE = 1024 * 4 = 4096` בתים. כלומר, שורה אחת תופסת בדיוק דף אחד.\n*   מספר הדפים הכולל של המטריצה: `ROWS` (1024 שורות) * 1 דף לשורה = 1024 דפים.\n*   מספר פריימים פיזיים זמינים: 100.\n*   מדיניות החלפת דפים: LRU.\n\n1.  **Page Faults בפונקציה `access_row_major()`:**\n    בפונקציה זו, הגישה למטריצה מתבצעת בסדר שורה-אחר-שורה (`matrix[i][j]`). מכיוון שכל שורה תופסת בדיוק דף אחד והמטריצה מאוחסנת בזיכרון בסדר שורות (row-major order), גישה ל-`matrix[i][j]` עבור `j` משתנה (כש-`i` קבוע) תמיד תישאר באותו דף. רק כאשר `i` משתנה, אנו עוברים לשורה חדשה, ולכן לדף חדש.\n    *   עבור `i=0`, אנו ניגשים לראשונה לדף 0 (המכיל את `matrix[0][0]` עד `matrix[0][1023]`). זה יגרום ל-Page Fault (PF). הדף נטען לזיכרון הפיזי.\n    *   לאחר מכן, עבור `j=1` עד `COLS-1`, הגישות נשארות באותו דף 0, ולכן לא נגרמים Page Faults נוספים.\n    *   כאשר `i` מתקדם ל-1, אנו ניגשים לראשונה לדף 1 (המכיל את `matrix[1][0]` עד `matrix[1][1023]`). זה יגרום ל-Page Fault.\n    *   דפוס זה חוזר על עצמו עבור כל אחת מ-`ROWS` (1024) השורות. בכל פעם שאנו מתחילים שורה חדשה, אנו ניגשים לדף חדש.\n    *   מכיוון שכל גישה לדף חדש גורמת ל-PF, ופונקציה זו ניגשת ל-1024 דפים שונים באופן סדרתי, יהיו בסך הכל **1024 Page Faults**. מדיניות ה-LRU ומגבלת הזיכרון הפיזי (100 דפים) אינן משפיעות על המספר הכולל במקרה זה, כיוון שהגישה היא סדרתית וכל דף נקרא פעם אחת בלבד. ה-Working Set של הפונקציה הוא דף אחד בלבד.\n\n2.  **Page Faults בפונקציה `access_col_major()`:**\n    בפונקציה זו, הגישה למטריצה מתבצעת בסדר עמודה-אחר-עמודה (`matrix[i][j]`). עבור `j` קבוע, הלולאה הפנימית משנה את `i` מ-0 עד `ROWS-1`. זה אומר שאנו ניגשים ל-`matrix[0][j]`, `matrix[1][j]`, ..., `matrix[1023][j]`.\n    *   כפי שחישבנו, `matrix[i][j]` ו-`matrix[i+1][j]` נמצאים בדפים שונים (דף `i` ודף `i+1` בהתאמה).\n    *   עבור `j=0` (העמודה הראשונה):\n        *   הגישה ל-`matrix[0][0]` גורמת ל-PF (טוען דף 0). \n        *   הגישה ל-`matrix[1][0]` גורמת ל-PF (טוען דף 1). \n        *   ... \n        *   הגישה ל-`matrix[99][0]` גורמת ל-PF (טוען דף 99). בשלב זה, 100 פריימים פיזיים מלאים.\n        *   הגישה ל-`matrix[100][0]` גורמת ל-PF (טוען דף 100, מחליף את דף 0 שהוא ה-LRU).\n        *   דפוס זה ממשיך: כל גישה ל-`matrix[i][0]` (עבור `i` מ-0 עד 1023) תגרום ל-PF. סך הכל 1024 Page Faults עבור העמודה הראשונה.\n        *   בסיום סריקת העמודה הראשונה, הדפים בזיכרון הפיזי הם דפים 924 עד 1023.\n    *   עבור `j=1` (העמודה השנייה):\n        *   הלולאה הפנימית ניגשת שוב לדפים 0, 1, ..., 1023.\n        *   הגישה ל-`matrix[0][1]` פירושה גישה לדף 0. דף 0 יצא מהזיכרון הפיזי במהלך סריקת העמודה הראשונה (הוחלף כאשר `i=100`). לכן, גישה זו תגרום שוב ל-PF. דף 0 ייטען מחדש ויחליף את דף 924 (ה-LRU).\n        *   דפוס זה חוזר על עצמו עבור כל גישה ל-`matrix[i][1]` עבור `i` מ-0 עד 1023. כלומר, 1024 Page Faults נוספים עבור העמודה השנייה.\n    *   מכיוון שהלולאה החיצונית רצה `COLS` (1024) פעמים, ובכל פעם היא גורמת ל-1024 Page Faults, סך הכל יתרחשו `COLS * ROWS` = `1024 * 1024` = **1,048,576 Page Faults**.\n\n3.  **הסבר ההבדל ועיקרון ניהול הזיכרון:**\n    ההבדל הדרמטי במספר ה-Page Faults נובע מעיקרון \"עקרון המקומיות\" (Locality of Reference), ובפרט \"מקומיות מרחבית\" (Spatial Locality).\n    *   **`access_row_major()`** מציגה מקומיות מרחבית מצוינת. היא ניגשת לאלמנטים בזיכרון בסדר רציף (או קרוב לרציף). כאשר דף נטען לזיכרון הפיזי, הוא מכיל את כל הנתונים הנדרשים לגישות הבאות (בתוך אותה שורה). זה ממזער את מספר ה-Page Faults, שכן דף אחד מספיק \"לכסות\" את כל הגישות בשורה אחת. ה-Working Set (קבוצת הדפים הפעילים) של הפונקציה קטן (דף אחד) ומתאים בקלות לזיכרון הפיזי.\n    *   **`access_col_major()`** מציגה מקומיות מרחבית ירודה מאוד. היא ניגשת לאלמנטים בזיכרון בקפיצות גדולות. כל גישה ל-`matrix[i][j]` עבור `i` חדש (כש-`j` קבוע) קופצת לדף חדש לחלוטין. מכיוון שגודל הזיכרון הפיזי (100 דפים) קטן משמעותית ממספר הדפים הכולל של המטריצה (1024 דפים) הנדרשים בכל איטרציה של הלולאה הפנימית, ובכל איטרציה של הלולאה החיצונית אנו סורקים מחדש את כל טווח הדפים של המטריצה, דפים ישנים נזרקים מהזיכרון הפיזי רק כדי להיטען מחדש מיד לאחר מכן. תופעה זו נקראת \"Thrashing\" (סחף דפים), והיא גורמת לירידה חמורה בביצועים עקב מספר עצום של Page Faults ופעולות קריאה/כתיבה לדיסק.\n    העיקרון המודגם הוא חשיבות ה-Spatial Locality (מקומיות מרחבית) ויכולת מערכת ההפעלה לנצל אותה באמצעות טעינת דפים. גישה לא רציפה לזיכרון, במיוחד כאשר ה-Working Set (קבוצת הדפים הפעילים) גדולה מהזיכרון הפיזי הזמין, עלולה להוביל לביצועים גרועים ביותר."}, "difficulty_estimation": "Medium", "_source_file": "0489__Memory_Management__CodeAnalysis__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:05:14", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Memory Management", "Heap", "Virtual Memory", "Paging", "malloc"], "content": {"text": "נתונה התוכנית הבאה, המבצעת הקצאות זיכרון באמצעות `malloc`.\nהניחו כי גודל דף במערכת ההפעלה הוא 4096 בתים (4KB).\nהניחו שכל קריאה ל-`malloc(CHUNK_SIZE)` דורשת מ-`malloc` לנהל בלוק בגודל `CHUNK_SIZE + 16` בתים (כאשר 16 בתים הם עבור מידע פנימי של `malloc` כמו גודל הבלוק, מצביע לבלוק הבא/קודם ב-free list וכו').\nכמו כן, הניחו ש-`malloc` מקצה זיכרון מה-heap, וכי ה-heap גדל בצעדים של דפים שלמים כאשר נדרש זיכרון חדש מהמערכת (כלומר, קריאות `sbrk` או `mmap` של `malloc` מבקשות בלוקים בגודל דף או כפולה של דף).\nהתעלמו מזיכרון הנדרש עבור קוד, נתונים גלובליים ומחסנית, והתמקדו רק בזיכרון הווירטואלי המוקצה ל-heap עבור הנתונים וה-overhead של `malloc`.\nמהו המספר המינימלי של דפי זיכרון וירטואליים שיוקצו ל-heap של התהליך לאחר סיום לולאת ההקצאות?", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define NUM_ALLOCATIONS 100\n#define CHUNK_SIZE 100 // bytes\n\nint main() {\n    void* ptrs[NUM_ALLOCATIONS];\n\n    for (int i = 0; i < NUM_ALLOCATIONS; ++i) {\n        ptrs[i] = malloc(CHUNK_SIZE);\n        if (ptrs[i] == NULL) {\n            perror(\"malloc failed\");\n            return 1;\n        }\n    }\n\n    // Assume the program reaches this point.\n\n    // Cleanup for completeness, not part of the question's analysis point\n    for (int i = 0; i < NUM_ALLOCATIONS; ++i) {\n        free(ptrs[i]);\n    }\n\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "התהליך מבצע 100 הקצאות של 100 בתים כל אחת.\nעל פי הנתון, כל הקצאה של `CHUNK_SIZE` דורשת מ-`malloc` לנהל בלוק בגודל `CHUNK_SIZE + 16` בתים (הכולל את הנתונים ומידע פנימי של `malloc`).\nלכן, כל בלוק זיכרון בפועל שתופס `malloc` הוא בגודל `100 + 16 = 116` בתים.\nהזיכרון הכולל ש-`malloc` צריך לנהל עבור כל ההקצאות הוא `100 * 116 = 11600` בתים.\nמערכת ההפעלה מקצה זיכרון ל-heap בצעדים של דפים שלמים, שגודלם 4096 בתים.\nכדי לספק 11600 בתים, `malloc` יצטרך לבקש מהמערכת מספר דפים שיכיל לפחות כמות זו.\nמספר הדפים הנדרש הוא `ceil(11600 / 4096)`.\n`11600 / 4096 = 2.832...`\nלכן, `malloc` יבקש 3 דפים ממערכת ההפעלה.\n`3 * 4096 = 12288` בתים.\nהמספר המינימלי של דפים וירטואליים שיוקצו ל-heap יהיה 3.\n(הערה: חלק מהזיכרון בתוך הדפים הללו יהיה \"פנוי\" או ישמש לצרכים פנימיים אחרים של `malloc` מעבר לבלוקים המוקצים בפועל, אך מנקודת מבט של דפי זיכרון וירטואליים שהוקצו ל-heap מה-OS, יהיו אלה 3 דפים)."}, "difficulty_estimation": "Medium", "_source_file": "0490__Memory_Management__CodeAnalysis__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:05:37", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Memory Management", "Stack", "Pointers", "Undefined Behavior"], "content": {"text": "נתונה התוכנית הבאה בשפת C.\nהתוכנית מנסה להקצות מערך בתוך פונקציה ולהחזיר מצביע אליו.\n\nהסבירו מהו הפלט הצפוי של התוכנית. אם התוכנית עלולה לקרוס או להתנהג באופן בלתי צפוי, הסבירו מדוע ומה הסיבות לכך בהקשר לניהול זיכרון במערכת ההפעלה.", "code_snippet": "#include <stdio.h>\n\nint* createArray() {\n    int arr[5]; // מערך מקומי המוקצה על המחסנית (stack)\n    for (int i = 0; i < 5; ++i) {\n        arr[i] = i * 10;\n    }\n    printf(\"Inside createArray: arr[0] = %d, address = %p\\n\", arr[0], (void*)arr);\n    return arr; // החזרת כתובת של משתנה מקומי במחסנית\n}\n\nint main() {\n    int* ptr = createArray();\n    printf(\"Inside main: ptr = %p\\n\", (void*)ptr);\n    // ניסיון לגשת לזיכרון לאחר שהפונקציה createArray הסתיימה\n    printf(\"Inside main: *ptr = %d\\n\", *ptr);\n    printf(\"Inside main: ptr[1] = %d\\n\", ptr[1]);\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הבעיה המרכזית בתוכנית זו היא שהפונקציה `createArray` מחזירה מצביע למערך `arr` שהוקצה על המחסנית (stack). כאשר הפונקציה `createArray` מסיימת את ריצתה, מסגרת המחסנית (stack frame) שלה מוסרת (או מסומנת כזמינה לשימוש חוזר). המשמעות היא שהזיכרון שבו שכן המערך `arr` אינו מוקצה עוד באופן חוקי עבור `arr`.\n\n**פלט צפוי והסבר:**\n1.  **הפלט הראשון (מתוך `createArray`):** `Inside createArray: arr[0] = 0, address = <כתובת כלשהי>`\n    *   פלט זה יהיה תקין ומדויק. בתוך הפונקציה `createArray`, המערך `arr` נמצא עדיין בתחום החיים שלו על המחסנית, והגישה אליו תקינה.\n\n2.  **הפלט השני (מתוך `main`):** `Inside main: ptr = <אותה כתובת כמו בפלט הראשון>`\n    *   פלט זה גם יהיה תקין, שכן `ptr` פשוט מקבל ומחזיק את הכתובת שהוחזרה מ-`createArray`. הבעיה אינה בהחזקת הכתובת, אלא בשימוש בה.\n\n3.  **הפלט השלישי והרביעי (מתוך `main`):** `Inside main: *ptr = <ערך בלתי צפוי>`, `Inside main: ptr[1] = <ערך בלתי צפוי>`\n    *   כאן מתרחשת התנהגות בלתי מוגדרת (Undefined Behavior). לאחר ש-`createArray` סיימה, הזיכרון שאליו `ptr` מצביע אינו מוקצה עוד עבור המערך `arr`. הגישה לזיכרון זה היא למעשה גישה לזיכרון תלוי (dangling pointer).\n    *   **הסיבות והתוצאות האפשריות:**\n        *   **הדפסת הערכים המקוריים:** במקרים רבים, במיוחד בתוכניות פשוטות, ייתכן שהזיכרון במחסנית לא יידרס מיד על ידי קריאות פונקציות אחרות. במצב כזה, התוכנית עשויה להדפיס בטעות את הערכים המקוריים (0 ו-10), מה שעלול ליצור אשליה שהקוד תקין. זוהי סכנה גדולה, מכיוון שהתנהגות זו אינה מובטחת ועלולה להשתנות בין ריצות שונות, קומפיילרים שונים או סביבות הפעלה שונות.\n        *   **הדפסת ערכי זבל:** אם הזיכרון שבו שכן `arr` נדרס על ידי נתונים אחרים (לדוגמה, אם פונקציה אחרת נקראה מיד לאחר `createArray` והשתמשה באותו אזור זיכרון במחסנית), אז `*ptr` ו-`ptr[1]` יכילו ערכי זבל.\n        *   **קריסה (Segmentation Fault):** במקרים מסוימים, מערכת ההפעלה או רכיבי זמן ריצה עשויים לזהות ניסיון גישה לזיכרון לא חוקי ולגרום לקריסת התוכנית (לרוב עם שגיאת Segmentation Fault). זה קורה אם הזיכרון סומן כלא נגיש או אם הגישה חורגת מגבולות הזיכרון שהוקצה לתהליך.\n\n**בהקשר לניהול זיכרון במערכת ההפעלה:**\nמערכת ההפעלה מקצה לכל תהליך מרחב כתובות וירטואלי משלו, הכולל בין היתר את מקטע המחסנית (Stack). המחסנית משמשת לאחסון משתנים מקומיים וכתובות חזרה של פונקציות. כאשר פונקציה נקראת, מסגרת מחסנית חדשה נוצרת עבורה. כאשר היא מסיימת, המסגרת שלה 'נמחקת' (כלומר, ה-stack pointer מתעדכן, והזיכרון נחשב לזמין לשימוש עתידי). הגישה לזיכרון זה לאחר ה'מחיקה' היא לגיטימית מבחינת מרחב הכתובות הוירטואלי של התהליך, אך לא חוקית מבחינה לוגית של התוכנית, ועלולה להוביל לשגיאות קשות שקשה לאתר."}, "difficulty_estimation": "Medium", "_source_file": "0491__Memory_Management__CodeAnalysis__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:06:00", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Memory Management", "Dynamic Memory Allocation", "Memory Leaks"], "content": {"text": "נתונה התוכנית הבאה ב-C. התוכנית מקצה זיכרון למערך של N מצביעים למספרים שלמים, ולאחר מכן מקצה זיכרון ל-N מספרים שלמים בודדים ומאתחלת אותם. לבסוף, היא משחררת את הזיכרון שהוקצה למספרים השלמים הבודדים.\n1. תארו מהי בעיית ניהול הזיכרון המרכזית בתוכנית זו.\n2. הציגו את השינוי הנדרש בקוד כדי לתקן את הבעיה.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define N 5\n\nint main() {\n    int **arr_of_ptrs;\n    int i;\n\n    // Allocate memory for N integer pointers\n    arr_of_ptrs = (int **)malloc(N * sizeof(int *));\n    if (arr_of_ptrs == NULL) {\n        perror(\"malloc arr_of_ptrs failed\");\n        return 1;\n    }\n\n    // Allocate memory for N integers and store their addresses\n    for (i = 0; i < N; i++) {\n        arr_of_ptrs[i] = (int *)malloc(sizeof(int));\n        if (arr_of_ptrs[i] == NULL) {\n            perror(\"malloc int failed\");\n            // In a real program, a cleanup of previously allocated memory would be needed here.\n            return 1;\n        }\n        *arr_of_ptrs[i] = i * 10; // Initialize values\n    }\n\n    // Print values (optional)\n    printf(\"Values:\\n\");\n    for (i = 0; i < N; i++) {\n        printf(\"arr_of_ptrs[%d] = %d\\n\", i, *arr_of_ptrs[i]);\n    }\n\n    // Free individual integers\n    for (i = 0; i < N; i++) {\n        free(arr_of_ptrs[i]);\n        arr_of_ptrs[i] = NULL; // Good practice to nullify after freeing\n    }\n\n    // Missing: free(arr_of_ptrs);\n\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "**1. תיאור הבעיה:\n**הבעיה המרכזית בתוכנית היא **דליפת זיכרון (Memory Leak)**.\nהתוכנית מבצעת שתי הקצאות זיכרון דינמיות נפרדות:\nא. `arr_of_ptrs = (int **)malloc(N * sizeof(int *));` - מקצה בלוק זיכרון עבור המערך של המצביעים עצמו.\nב. בתוך הלולאה, `arr_of_ptrs[i] = (int *)malloc(sizeof(int));` - מקצה בלוק זיכרון עבור כל אחד מ-N המספרים השלמים הבודדים.\n\nהלולאה השנייה בתוכנית (`for (i = 0; i < N; i++) { free(arr_of_ptrs[i]); }`) משחררת בהצלחה את כל הזיכרון שהוקצה למספרים השלמים הבודדים.\nאך, בלוק הזיכרון שהוקצה עבור המערך `arr_of_ptrs` עצמו (שנוצר על ידי הקריאה הראשונה ל-`malloc`) **אינו משוחרר לעולם**.\nכתוצאה מכך, הזיכרון הזה נשאר תפוס על ידי התהליך גם לאחר שהפונקציה `main` מסתיימת, והוא אינו זמין לשימוש חוזר על ידי המערכת. זוהי דליפת זיכרון קלאסית, אשר עלולה להצטבר ולגרום לבעיות בביצועי המערכת ובזמינות הזיכרון אם התוכנית רצה לאורך זמן או במחזורים חוזרים.\n\n**2. התיקון הנדרש:\n**כדי לתקן את דליפת הזיכרון, יש להוסיף קריאה ל-`free(arr_of_ptrs);` לאחר שכל המצביעים בתוך המערך שוחררו, ולפני סיום הפונקציה `main`.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define N 5\n\nint main() {\n    int **arr_of_ptrs;\n    int i;\n\n    arr_of_ptrs = (int **)malloc(N * sizeof(int *));\n    if (arr_of_ptrs == NULL) {\n        perror(\"malloc arr_of_ptrs failed\");\n        return 1;\n    }\n\n    for (i = 0; i < N; i++) {\n        arr_of_ptrs[i] = (int *)malloc(sizeof(int));\n        if (arr_of_ptrs[i] == NULL) {\n            perror(\"malloc int failed\");\n            // Proper cleanup for previously allocated arr_of_ptrs[0...i-1] would be here.\n            // For simplicity of this example, we just exit.\n            return 1;\n        }\n        *arr_of_ptrs[i] = i * 10;\n    }\n\n    printf(\"Values:\\n\");\n    for (i = 0; i < N; i++) {\n        printf(\"arr_of_ptrs[%d] = %d\\n\", i, *arr_of_ptrs[i]);\n    }\n\n    for (i = 0; i < N; i++) {\n        free(arr_of_ptrs[i]);\n        arr_of_ptrs[i] = NULL;\n    }\n\n    // תיקון: שחרור הזיכרון שהוקצה למערך arr_of_ptrs עצמו\n    free(arr_of_ptrs);\n\n    return 0;\n}"}, "difficulty_estimation": "Medium", "_source_file": "0492__Memory_Management__CodeAnalysis__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:06:21", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Memory Management", "Paging", "Locality", "Performance"], "content": {"text": "נתונה התוכנית הבאה המאתחלת מטריצה גדולה.\nהמערכת עליה רצה התוכנית משתמשת בזיכרון וירטואלי עם חלוקה לדפים (paging).\nנתונים:\n- גודל דף הוא 4KB.\n- גודל משתנה `int` הוא 4 בתים.\n- המטריצה מאוחסנת בזיכרון באופן רציף (row-major order).\n- המערכת מתחילה עם זיכרון ריק (כלומר, כל גישה לדף בפעם הראשונה תגרום ל-page fault).\n- יש מספיק מסגרות פיזיות (physical frames) להכיל את כל דפי המטריצה.\n\nיש לנתח את קטעי הקוד הבאים ולענות על השאלה.\n\nכמה page faults (לערך) יתרחשו בעת הפעלת הפונקציה `init_matrix_row_major()` וכמה page faults (לערך) יתרחשו בעת הפעלת הפונקציה `init_matrix_col_major()`?\nהסבר מדוע, למרות שמספר ה-page faults הכולל זהה בשני המקרים, הפונקציה `init_matrix_row_major()` תהיה מהירה יותר באופן משמעותי בפועל.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define ROWS 1024\n#define COLS 1024\n\nint matrix[ROWS][COLS]; // Global static allocation\n\nvoid init_matrix_row_major() {\n    for (int i = 0; i < ROWS; ++i) {\n        for (int j = 0; j < COLS; ++j) {\n            matrix[i][j] = i * COLS + j;\n        }\n    }\n}\n\nvoid init_matrix_col_major() {\n    for (int j = 0; j < COLS; ++j) {\n        for (int i = 0; i < ROWS; ++i) {\n            matrix[i][j] = i * COLS + j;\n        }\n    }\n}\n\nint main() {\n    // ניתן להריץ כל אחת מהפונקציות בנפרד\n    // init_matrix_row_major();\n    // init_matrix_col_major();\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "חישוב גודל המטריצה ומספר הדפים:\nגודל המטריצה הכולל: `1024 שורות * 1024 עמודות * 4 בתים/int = 4,194,304 בתים = 4MB`.\nגודל דף: `4KB = 4096 בתים`.\nמספר הדפים הכולל הנדרש למטריצה: `4MB / 4KB = 1024 דפים`.\n\nעל פי הנתונים, המערכת מתחילה עם זיכרון ריק וכל גישה לדף בפעם הראשונה גורמת ל-page fault. בנוסף, יש מספיק מסגרות פיזיות להכיל את כל דפי המטריצה, כלומר דף שנטען לזיכרון הפיזי יישאר שם ולא יוחלף.\nלכן, כל אחד מ-1024 דפי המטריצה ייטען לזיכרון הפיזי בדיוק פעם אחת.\n**מספר ה-page faults הכולל יהיה 1024 עבור שתי הפונקציות.**\n\nהסבר להבדל בביצועים:\n\n1.  **`init_matrix_row_major()`:**\n    *   פונקציה זו ניגשת לאלמנטים בסדר שבו הם מאוחסנים בזיכרון (row-major). כלומר, `matrix[i][j]` ואחריו `matrix[i][j+1]` הם סמוכים בזיכרון.\n    *   גודל שורה: `1024 עמודות * 4 בתים/int = 4096 בתים = 4KB`. כלומר, כל שורה תופסת בדיוק דף אחד.\n    *   כאשר ניגשים ל-`matrix[i][0]` בפעם הראשונה, מתרחש page fault וכל הדף (השורה כולה) נטען לזיכרון הפיזי.\n    *   הגישות הבאות לאלמנטים `matrix[i][1]` עד `matrix[i][1023]` ימצאו את הנתונים כבר בזיכרון הפיזי (ולרוב גם ב-cache) ולא יגרמו ל-page faults נוספים או ל-cache misses רבים.\n    *   הגישות מתבצעות עם לוקליות מרחבית (spatial locality) מצוינת.\n    *   סה\"כ: 1024 page faults, המתרחשים באופן סדרתי (אחד לכל שורה).\n\n2.  **`init_matrix_col_major()`:**\n    *   פונקציה זו ניגשת לאלמנטים בסדר טור-אחרי-טור. כלומר, `matrix[0][j]`, `matrix[1][j]`, `matrix[2][j]` וכן הלאה.\n    *   אלמנטים אלו אינם סמוכים בזיכרון. `matrix[0][j]` נמצא בדף של שורה 0, `matrix[1][j]` נמצא בדף של שורה 1 וכו'. המרחק בין `matrix[i][j]` ל-`matrix[i+1][j]` הוא `1024 * 4 = 4KB`, כלומר בדיוק גודל דף.\n    *   כאשר `j=0`, בלולאה הפנימית (`i`):\n        *   `matrix[0][0]` נגיש - page fault לדף של שורה 0.\n        *   `matrix[1][0]` נגיש - page fault לדף של שורה 1.\n        *   ...\n        *   `matrix[1023][0]` נגיש - page fault לדף של שורה 1023.\n        *   בשלב זה, כל 1024 דפי המטריצה נטענו לזיכרון הפיזי.\n    *   הגישות מתבצעות עם לוקליות מרחבית (spatial locality) ירודה מאוד. בכל איטרציה של הלולאה הפנימית (`i`), אנו קופצים לדף זיכרון אחר.\n    *   למרות שסה\"כ מספר ה-page faults הוא גם 1024, הם מתרחשים כולם ברצף מהיר מאוד בתחילת הביצוע (בעת איפוס הטור הראשון). רצף כה גדול של page faults דורש עבודה רבה ממערכת ה-I/O ומהמעבד (לטיפול בהפרעות) ופוגע קשות בביצועים.\n    *   בנוסף, לוקליות מרחבית ירודה זו גורמת למספר גבוה בהרבה של Cache misses וגם ל-TLB misses רבים (אם ה-TLB אינו גדול מספיק להכיל את כל 1024 הדפים בו זמנית), מה שמאט את הביצועים באופן דרמטי גם לאחר שכל הדפים כבר נטענו לזיכרון הפיזי.\n\n**לסיכום:**\nבשני המקרים יתרחשו 1024 page faults.\nעם זאת, `init_matrix_row_major()` תהיה מהירה יותר באופן משמעותי מכיוון שהיא מנצלת לוקליות מרחבית טובה יותר, מה שמביא לפחות Cache misses ושימוש יעיל יותר ב-TLB, ופיזור טוב יותר של ה-page faults לאורך זמן. לעומתה, `init_matrix_col_major()` סובלת מלוקליות מרחבית ירודה, גורמת ל-1024 page faults כמעט בו-זמנית בתחילת הריצה, וכן למספר רב של Cache/TLB misses לאורך כל הריצה.", "code_snippet": null}, "difficulty_estimation": "Medium", "_source_file": "0493__Memory_Management__CodeAnalysis__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:07:01", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Memory Management", "Paging", "Page Faults", "Locality of Reference"], "content": {"text": "נתונה תוכנית C המשתמשת במערך דו-ממדי גדול. המערכת ההפעלה משתמשת בזיכרון וירטואלי עם דפים בגודל 4KB. נניח שהמערך `int arr[1024][1024];` (כאשר כל `int` הוא בגודל 4 בתים) מאוחסן בזיכרון רציף ומתחיל בכתובת המיושרת לגבול דף.\n\nיש לנתח את שני קטעי הקוד הבאים ולחשב את המספר המינימלי של כשלים בדף (page faults) שיתרחשו עבור כל אחד מהם, בהנחה שכל הדפים של המערך אינם טעונים לזיכרון הפיזי בתחילת הריצה.", "code_snippet": "// Assume int is 4 bytes\n// Array: int arr[1024][1024];\n// Total array size: 1024 * 1024 * 4 bytes = 4,194,304 bytes = 4MB\n// Page size: 4KB = 4096 bytes\n\n// Access Pattern A (row-major)\nvoid pattern_A_access(int arr[1024][1024]) {\n    for (int i = 0; i < 1024; ++i) {\n        for (int j = 0; j < 1024; ++j) {\n            arr[i][j] = i * j;\n        }\n    }\n}\n\n// Access Pattern B (column-major)\nvoid pattern_B_access(int arr[1024][1024]) {\n    for (int j = 0; j < 1024; ++j) {\n        for (int i = 0; i < 1024; ++i) {\n            arr[i][j] = i * j;\n        }\n    }\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "חישובים מקדימים:\nגודל המערך הכולל: 1024 שורות * 1024 עמודות * 4 בתים/int = 4,194,304 בתים = 4MB.\nגודל דף: 4KB = 4096 בתים.\nמספר הדפים הכולל הנדרש למערך: 4MB / 4KB = 1024 דפים.\n\n**ניתוח תבנית גישה A (שורות):**\nב-C, מערכים דו-ממדיים מאוחסנים בזיכרון בסדר שורות (row-major). כלומר, כל האלמנטים של שורה `i` (`arr[i][0]` עד `arr[i][1023]`) מאוחסנים באופן רציף בזיכרון.\nגודל שורה אחת: 1024 איברים * 4 בתים/איבר = 4096 בתים = 1 דף.\nכאשר הלולאה החיצונית קובעת את `i` (מספר השורה), והלולאה הפנימית עוברת על `j` (מספר העמודה), הגישה לאיבר `arr[i][0]` תגרום לכשל דף (page fault) מכיוון שהדף של שורה `i` אינו בזיכרון. הדף הזה (שגודלו 4KB) ייטען לזיכרון הפיזי.\nלאחר מכן, כל הגישות הבאות לאיברים `arr[i][1]` עד `arr[i][1023]` יהיו באותו דף שכבר נטען, ולכן לא יגרמו לכשלי דף נוספים עבור שורה זו.\nכאשר הלולאה החיצונית עוברת לשורה הבאה (`i+1`), הגישה לאיבר `arr[i+1][0]` תגרום שוב לכשל דף, מכיוון שזוהי שורה חדשה הממוקמת בדף חדש.\nמכיוון שיש 1024 שורות במערך, וכל שורה תופסת בדיוק דף אחד, יהיו בסך הכל **1024 כשלי דף** עבור תבנית גישה זו.\n\n**ניתוח תבנית גישה B (עמודות):**\nכאשר הלולאה החיצונית קובעת את `j` (מספר העמודה), והלולאה הפנימית עוברת על `i` (מספר השורה), סדר הגישה הוא `arr[0][j], arr[1][j], ..., arr[1023][j]`.\nמכיוון שמערכים מאוחסנים בסדר שורות, האיבר `arr[i][j]` והאיבר `arr[i+1][j]` נמצאים בשורות שונות לגמרי. למעשה, `arr[i+1][j]` ממוקם 1024 * 4 = 4096 בתים (דף שלם) אחרי `arr[i][j]` בזיכרון.\nלכן, כל גישה לאיבר `arr[i][j]` עבור `i` שונה (עבור `j` קבוע) תהיה לכתובת בזיכרון הנמצאת בדף שונה.\nכתוצאה מכך, עבור כל איטרציה של הלולאה הפנימית (כלומר, עבור כל `i` מ-0 עד 1023), תתרחש ככל הנראה כשל דף חדש.\nבסך הכל, עבור עמודה אחת (`j` קבוע), יהיו 1024 כשלי דף.\nמכיוון שיש 1024 עמודות, המספר הכולל של כשלי דף יהיה 1024 עמודות * 1024 כשלי דף/עמודה = **1,048,576 כשלי דף**."}, "difficulty_estimation": "Medium", "_source_file": "0494__Memory_Management__CodeAnalysis__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:07:26", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Memory Management", "Paging", "TLB", "Cache Locality"], "content": {"text": "נתונה תוכנית C המבצעת סכימה על מערך דו-ממדי גדול של מספרים שלמים. המערכת פועלת עם זיכרון וירטואלי, גודל דף הוא 4KB (קילו-בתים), וגודל ערך `int` הוא 4 בתים. נניח שה-TLB (Translation Lookaside Buffer) קטן מאוד ומכיל מספר מוגבל של תרגומי כתובות (לדוגמה, 4 כניסות). המערך `arr` מוגדר בגודל `N x N` כאשר `N = 1024`.\nשתי פונקציות מוצגות להלן, המבצעות סכימה של כל האיברים במערך.\n\nנתחו איזו פונקציה (sum_row_major או sum_col_major) צפויה לגרום לפחות page faults ופחות TLB misses, והסבירו מדוע. פרטו את כמות ה-page faults וה-TLB misses המשוערת לכל פונקציה.", "code_snippet": "```c\n#include <stdio.h>\n#include <stdlib.h>\n\n#define N 1024 // N x N array\n\nint arr[N][N]; // Global array, initialized with some values\n\nvoid sum_row_major() {\n    long long total_sum = 0;\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            total_sum += arr[i][j];\n        }\n    }\n    printf(\"Row-major sum: %lld\\n\", total_sum);\n}\n\nvoid sum_col_major() {\n    long long total_sum = 0;\n    for (int j = 0; j < N; ++j) {\n        for (int i = 0; i < N; ++i) {\n            total_sum += arr[i][j];\n        }\n    }\n    printf(\"Column-major sum: %lld\\n\", total_sum);\n}\n\n// main function is omitted for brevity, assume it calls these functions\n// and arr is initialized.\n```", "options": null}, "sub_questions": null, "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון מבוסס על הבנת אופן אחסון מערכים דו-ממדיים בזיכרון ב-C וכיצד הוא משפיע על ניצול הזיכרון הווירטואלי (paging, TLB).\n\n1.  **גודל המערך וגודל הדף**:\n    *   המערך `arr` הוא בגודל `N x N` כאשר `N = 1024`.\n    *   גודל המערך הכולל הוא `1024 * 1024 * sizeof(int) = 1024 * 1024 * 4 בתים = 4MB`.\n    *   גודל דף הוא `4KB`.\n    *   מספר הדפים הנדרשים לאחסון המערך הוא `4MB / 4KB = 1024 דפים`.\n    *   מערכי C מאוחסנים בזיכרון בסדר שורה-אחר-שורה (row-major order). כלומר, `arr[i][j]` ו-`arr[i][j+1]` הם סמוכים בזיכרון. שורה אחת של המערך (`arr[i][0]` עד `arr[i][N-1]`) תופסת `N * sizeof(int) = 1024 * 4 = 4096 בתים = 1 דף`.\n\n2.  **ניתוח `sum_row_major()`**:\n    *   הלולאה הפנימית עוברת על `j` מ-`0` עד `N-1` עבור `i` קבוע.\n    *   גישה זו היא `arr[i][0], arr[i][1], ..., arr[i][N-1]`.\n    *   דפוס גישה זה הוא **רציף בזיכרון** (contiguous). כל הגישות בתוך הלולאה הפנימית עבור `i` קבוע הן לאלמנטים סמוכים באותה שורה.\n    *   כאשר ניגשים ל-`arr[i][0]`, אם הדף המכיל אותו אינו בזיכרון הפיזי, תתרחש page fault והדף יוטען. דף זה מכיל את כל השורה `i` (מכיוון ששורה תופסת בדיוק דף אחד).\n    *   לאחר מכן, הגישות ל-`arr[i][1]` עד `arr[i][N-1]` יהיו כולן להיטים באותו דף שכבר נטען, ולכן לא יגרמו ל-page faults נוספים עבור שורה זו.\n    *   באופן דומה, עבור TLB: כאשר `arr[i][0]` נגיש, כתובתו הווירטואלית מתורגמת לכתובת פיזית, והתרגום נשמר ב-TLB. כל שאר הגישות באותה שורה ימצאו את התרגום ב-TLB (TLB hit) מכיוון שהן באותו דף.\n    *   **סה\"כ page faults**: בערך `N` page faults (אחד לכל שורה, שכן כל שורה היא דף חדש).\n    *   **סה\"כ TLB misses**: בערך `N` TLB misses (אחד לכל שורה, שכן כל שורה היא דף חדש).\n\n3.  **ניתוח `sum_col_major()`**:\n    *   הלולאה הפנימית עוברת על `i` מ-`0` עד `N-1` עבור `j` קבוע.\n    *   גישה זו היא `arr[0][j], arr[1][j], ..., arr[N-1][j]`.\n    *   דפוס גישה זה **אינו רציף בזיכרון**. `arr[i][j]` ו-`arr[i+1][j]` נמצאים במרחק של `N * sizeof(int) = 4096 בתים = 1 דף` זה מזה.\n    *   כלומר, כל גישה ל-`arr[i][j]` עבור `i` שונה (בתוך הלולאה הפנימית עבור `j` קבוע) תגרום לגישה לדף זיכרון שונה לגמרי. לדוגמה, `arr[0][j]` נמצא בדף `P0`, `arr[1][j]` נמצא בדף `P1` (שונה מ-`P0`), `arr[2][j]` נמצא בדף `P2` (שונה מ-`P0`, `P1`), וכן הלאה.\n    *   לכן, כמעט כל גישה ל-`arr[i][j]` (עבור `i` משתנה) תגרום ל-page fault, שכן סביר להניח שהדף המבוקש אינו נמצא בזיכרון הפיזי או הוצא ממנו עקב המחסור במקום (כי כל הגישות הקודמות היו לדפים שונים).\n    *   באופן דומה, עבור TLB: מכיוון שכל גישה היא לדף שונה, ובהינתן שה-TLB קטן מאוד (לדוגמה, 4 כניסות), כל גישה כזו תגרום כמעט בוודאות ל-TLB miss. ה-TLB לא יכול להכיל את כל תרגומי הכתובות של `N` דפים שונים בבת אחת, ולכן בכל פעם יהיה צורך לטעון תרגום חדש.\n    *   **סה\"כ page faults**: בערך `N * N` page faults (אחד לכל גישה, שכן כל גישה היא לדף אחר).\n    *   **סה\"כ TLB misses**: בערך `N * N` TLB misses (אחד לכל גישה, שכן כל גישה היא לדף אחר).\n\n4.  **מסקנה**:\n    *   הפונקציה `sum_row_major()` תגרום למספר נמוך בהרבה של page faults ו-TLB misses (בערך `N` מול `N*N`), מכיוון שהיא מנצלת טוב יותר את עקרון **לוקליות המרחב (spatial locality)**. היא ניגשת לנתונים באופן רציף בזיכרון, מה שמאפשר לדפים ולשורות מטמון (cache lines) לשרת מספר רב של גישות.\n    *   הפונקציה `sum_col_major()` סובלת מביצועים גרועים בהרבה מכיוון שהיא מדלגת על פני דפים רבים בכל גישה, מה שמוביל ל-page faults ו-TLB misses רבים."}, "difficulty_estimation": "Medium", "_source_file": "0495__Memory_Management__CodeAnalysis__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:07:56", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Memory Management", "Paging", "Locality"], "content": {"text": "נתונה התוכנית הבאה בשפת C/C++. המערך matrix מוגדר גלובלית, ולכן נמצא בקטע הנתונים (data segment) של התהליך.\nנתוני המערכת:\n*   גודל דף (page size) הוא 4KB.\n*   גודל משתנה `int` הוא 4 בתים.\n*   המערך `matrix` ממוקם באזור זיכרון שבתחילה אינו טעון לזיכרון פיזי (כל הדפים אינם תקפים).\n*   הניחו כי זיכרון פיזי זמין למערך קטן ממספר הדפים הכולל של המערך, כך שמתרחשים חילופי דפים (page replacements).\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n\n#define ROWS 1024\n#define COLS 1024\n\nint matrix[ROWS][COLS]; // Global array\n\nvoid access_row_major() {\n    for (int i = 0; i < ROWS; ++i) {\n        for (int j = 0; j < COLS; ++j) {\n            matrix[i][j] = i * j; // Access row by row\n        }\n    }\n}\n\nvoid access_col_major() {\n    for (int j = 0; j < COLS; ++j) {\n        for (int i = 0; i < ROWS; ++i) {\n            matrix[i][j] = i * j; // Access column by column\n        }\n    }\n}\n\nint main() {\n    // Assume one of the functions is called here:\n    // access_row_major();\n    // OR\n    // access_col_major();\n    return 0;\n}\n```\n\nענו על השאלות הבאות:\n1.  כמה page faults (כשל דף) יתרחשו כאשר הפונקציה `access_row_major()` תתבצע? הסבירו.\n2.  כמה page faults יתרחשו כאשר הפונקציה `access_col_major()` תתבצע? הסבירו.\n3.  איזו תבנית גישה יעילה יותר מבחינת כשל דף ומדוע?", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define ROWS 1024\n#define COLS 1024\n\nint matrix[ROWS][COLS]; // Global array\n\nvoid access_row_major() {\n    for (int i = 0; i < ROWS; ++i) {\n        for (int j = 0; j < COLS; ++j) {\n            matrix[i][j] = i * j; // Access row by row\n        }\n    }\n}\n\nvoid access_col_major() {\n    for (int j = 0; j < COLS; ++j) {\n        for (int i = 0; i < ROWS; ++i) {\n            matrix[i][j] = i * j; // Access column by column\n        }\n    }\n}\n\nint main() {\n    // Assume one of the functions is called here:\n    // access_row_major();\n    // OR\n    // access_col_major();\n    return 0;\n}", "options": null}, "sub_questions": null, "points": 15, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "נתחיל בניתוח גודל המערך וחלוקתו לדפים:\n*   גודל המערך הכולל: `1024 שורות * 1024 עמודות * 4 בתים/שלם = 4,194,304 בתים = 4MB`.\n*   גודל דף: `4KB = 4096 בתים`.\n*   מספר שלמים בדף אחד: `4096 בתים / 4 בתים/שלם = 1024 שלמים`.\n*   מכיוון ש-C מאחסנת מערכים רב-ממדיים בסדר שורה-עיקרי (row-major order), כל שורה במערך `matrix` תופסת בדיוק דף אחד: `1024 שלמים/שורה * 4 בתים/שלם = 4096 בתים = 1 דף`.\n*   סה\"כ דפים למערך: `4MB / 4KB = 1024 דפים`.\n\n**ניתוח `access_row_major()`:**\nהפונקציה ניגשת לאלמנטים בסדר שורה-עיקרי, כלומר, היא משלימה את כל הגישות לשורה `i` לפני שהיא עוברת לשורה `i+1`.\n*   כאשר ניגשים לראשונה לאלמנט כלשהו בשורה `i` (לדוגמה `matrix[i][0]`), יתרחש כשל דף עבור הדף המכיל את שורה `i`. דף זה יוטען לזיכרון הפיזי.\n*   כל הגישות הבאות לאלמנטים באותה שורה (`matrix[i][1]` עד `matrix[i][1023]`) יתבצעו בתוך אותו דף שכבר נטען, ולכן לא יגרמו לכשלי דף נוספים.\n*   כאשר הפונקציה עוברת לשורה הבאה (`i+1`), היא תיגש שוב לדף חדש (דף `i+1`), מה שיגרום לכשל דף נוסף.\n*   מכיוון שיש `ROWS` (1024) שורות, וכל שורה תופסת דף אחד, יתרחשו בסך הכל `1024` כשלי דף.\n\n**ניתוח `access_col_major()`:**\nהפונקציה ניגשת לאלמנטים בסדר עמודה-עיקרי, כלומר, היא משלימה את כל הגישות לעמודה `j` לפני שהיא עוברת לעמודה `j+1`.\n*   כאשר הפונקציה ניגשת לאלמנטים בעמודה `j`, היא ניגשת ל-`matrix[0][j]`, `matrix[1][j]`, ..., `matrix[1023][j]`.\n*   `matrix[0][j]` נמצא בדף 0. `matrix[1][j]` נמצא בדף 1. ... `matrix[1023][j]` נמצא בדף 1023.\n*   בכל פעם שהלולאה הפנימית (`for i`) מתקדמת, היא ניגשת לאלמנט הנמצא בדף שונה.\n*   מכיוון שהזיכרון הפיזי מוגבל (כפי שצוין בשאלה), הדפים שנטענו עבור גישות קודמות באותה עמודה (או בעמודות קודמות) יוחלפו בזיכרון הפיזי לפני שתידרש גישה חוזרת אליהם (בהתאם למדיניות החלפת הדפים). כלומר, סביר מאוד שכל גישה לאלמנט תגרור כשל דף.\n*   לולאת ה-`i` הפנימית מבצעת `ROWS` (1024) גישות, וכל אחת מהן תגרום לכשל דף.\n*   לולאת ה-`j` החיצונית מבצעת `COLS` (1024) איטרציות.\n*   לכן, סך כשלי הדף יהיה `ROWS * COLS = 1024 * 1024 = 1,048,576`.\n\n**השוואת יעילות:**\nהפונקציה `access_row_major()` יעילה בהרבה מבחינת כשלי דף. היא גורמת ל-`1024` כשלי דף, בעוד ש-`access_col_major()` גורמת ל-`1,048,576` כשלי דף.\nהסיבה לכך היא עקרון המיקום המרחבי (spatial locality). המערך מאוחסן בזיכרון בסדר שורה-עיקרי.\n*   `access_row_major()` מנצלת את העובדה שאלמנטים סמוכים בשורה נמצאים באותו דף (או בדפים סמוכים). ברגע שדף נטען, ניתן לגשת לכל האלמנטים שבו ללא כשלי דף נוספים, מה שממזער את מספר כשלי הדף הכולל.\n*   `access_col_major()`, לעומת זאת, קופצת בין דפים שונים עבור כל גישה לאלמנט בעמודה. הדפים הנדרשים לכל עמודה הם הדפים של כל השורות, ובהינתן זיכרון פיזי מוגבל, הדפים האלה יוחלפו כל הזמן, מה שמוביל למספר עצום של כשלי דף וביצועים ירודים."}, "difficulty_estimation": "Medium", "_source_file": "0496__Memory_Management__CodeAnalysis__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:08:34", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Memory Management", "Cache", "Paging", "TLB", "Performance Optimization"], "content": {"text": "נתונה תוכנית C המבצעת פעולות על מטריצה דו-ממדית גדולה. התוכנית מאתחלת את המטריצה ולאחר מכן מבצעת שתי פעולות עיבוד דומות, אך בסדר גישה שונה לזיכרון. יש להניח כי המערכת פועלת על ארכיטקטורת x86-64 עם גודל עמוד זיכרון סטנדרטי (לדוגמה, 4KB) ובעלת זיכרון מטמון (cache) מרובה רמות.\n\n```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n\n#define N 4096 // גודל המטריצה N x N\n\nint matrix[N][N]; // מטריצה גלובלית שלמים\n\nvoid init_matrix() {\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            matrix[i][j] = i + j;\n        }\n    }\n}\n\n// פונקציה 1: סריקה בסדר שורות (row-major)\nvoid process_row_major() {\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            matrix[i][j] *= 2;\n        }\n    }\n}\n\n// פונקציה 2: סריקה בסדר עמודות (column-major)\nvoid process_col_major() {\n    for (int j = 0; j < N; j++) {\n        for (int i = 0; i < N; i++) {\n            matrix[i][j] *= 2;\n        }\n    }\n}\n\nint main() {\n    init_matrix();\n\n    clock_t start, end;\n    double cpu_time_used;\n\n    printf(\"Starting row-major processing...\\n\");\n    start = clock();\n    process_row_major();\n    end = clock();\n    cpu_time_used = ((double) (end - start)) / CLOCKS_PER_SEC;\n    printf(\"Row-major processing took %f seconds.\\n\", cpu_time_used);\n\n    // אתחול מחדש לצורך השוואה הוגנת\n    init_matrix();\n\n    printf(\"Starting column-major processing...\\n\");\n    start = clock();\n    process_col_major();\n    end = clock();\n    cpu_time_used = ((double) (end - start)) / CLOCKS_PER_SEC;\n    printf(\"Column-major processing took %f seconds.\\n\", cpu_time_used);\n\n    return 0;\n}\n```\n\n**שאלות:**\n1. הסבירו מדוע הפונקציה `process_col_major` צפויה להיות איטית באופן משמעותי מ-`process_row_major`. בתשובתכם התייחסו לעקרונות ניהול זיכרון כגון זיכרון מטמון (CPU cache), עמודים (paging) ו-TLB (Translation Lookaside Buffer).\n2. הציעו דרך לשפר את ביצועי הפונקציה `process_col_major` כך שתהיה מהירה יותר, מבלי לשנות את הלוגיקה החישובית שלה (כלומר, היא עדיין צריכה לבצע את אותה פעולה על אותם אלמנטים). כתבו את הקוד המתוקן של הפונקציה.", "code_snippet": null, "options": null}, "sub_questions": null, "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "**הסבר:**\n\n1.  **אופן אחסון מטריצות ב-C:** ב-C, מטריצות דו-ממדיות מאוחסנות בזיכרון בסדר שורות (row-major order). כלומר, כל השלמים בשורה 0 מאוחסנים ברצף, אחריהם כל השלמים בשורה 1 ברצף, וכן הלאה. גישה לאלמנט `matrix[i][j]` ולאחריו `matrix[i][j+1]` תהיה גישה לכתובות זיכרון סמוכות. לעומת זאת, גישה לאלמנט `matrix[i][j]` ולאחריו `matrix[i+1][j]` תהיה גישה לכתובת זיכרון המרוחקת ב-`N * sizeof(int)` בתים.\n\n2.  **זיכרון מטמון (CPU Cache):**\n    *   **`process_row_major`**: הפונקציה הזו סורקת את המטריצה בסדר שורות. כאשר ניגשים ל-`matrix[i][j]`, המעבד טוען לזיכרון המטמון (cache) בלוק של זיכרון (cache line) שמכיל את `matrix[i][j]` ואת האלמנטים הסמוכים לו באותה שורה (כלומר, `matrix[i][j+1]`, `matrix[i][j+2]` וכו'). מכיוון שהלולאה הפנימית ממשיכה לגשת לאלמנטים אלו ברצף, רוב הגישות יהיו \"פגיעות מטמון\" (cache hits), מה שמוביל לביצועים מהירים. זהו ניצול יעיל של עקרון המקומיות המרחבית (spatial locality).\n    *   **`process_col_major`**: הפונקציה הזו סורקת את המטריצה בסדר עמודות. כאשר ניגשים ל-`matrix[i][j]`, המעבד טוען בלוק זיכרון ל-cache. מיד לאחר מכן, הלולאה הפנימית ניגשת ל-`matrix[i+1][j]`. אלמנט זה נמצא בכתובת זיכרון רחוקה מאוד מהקודם (במערך הגלובלי, הוא נמצא `N` שלמים קדימה). סביר מאוד שהאלמנט `matrix[i+1][j]` אינו נמצא באותו בלוק זיכרון שנטען קודם לכן. לכן, כל גישה ל-`matrix[i][j]` עבור `i` שונה כנראה תגרום ל\"החטאת מטמון\" (cache miss) חדשה, שתדרוש טעינה של בלוק זיכרון חדש מהזיכרון הראשי (RAM) ל-cache. פעולה זו איטית בהרבה מגישה ל-cache. זהו ניצול לא יעיל של עקרון המקומיות המרחבית.\n\n3.  **עמודים (Paging) ו-TLB (Translation Lookaside Buffer):**\n    *   **Paging**: המטריצה בגודל `N=4096` מכילה `4096 * 4096` שלמים. אם שלם הוא 4 בתים, גודל המטריצה הוא `4096 * 4096 * 4` בתים, שהם `64 MB`. גודל זה גדול בהרבה מזיכרון המטמון ברמות L1/L2/L3 ברוב המעבדים. בנוסף, הוא עשוי להיות גדול יותר מהזיכרון הפיזי הזמין לתהליך במקרים מסוימים, או לפחות לדרוש עמודים רבים.\n        *   ב-`process_row_major`, גישה רציפה משמעותה שברגע שעמוד מסוים נטען לזיכרון פיזי, ניתן לגשת לכל הנתונים שבו ביעילות, מה שמפחית את מספר \"תקלות העמוד\" (page faults).\n        *   ב-`process_col_major`, גישה לא רציפה עלולה לגרום לכך שכל גישה ל-`matrix[i][j]` (עבור `i` שונה) תהיה בכתובת זיכרון וירטואלית השייכת לעמוד אחר. אם מספר העמודים הפעילים עולה על מספר ה-frames הפנויים בזיכרון הפיזי, תהיה סבירות גבוהה לתקלות עמוד רבות, מה שדורש קריאה מהדיסק ואיטי מאוד.\n    *   **TLB (Translation Lookaside Buffer)**: ה-TLB הוא מטמון קטן ומהיר המאחסן מיפויים מכתובות וירטואליות לכתובות פיזיות.\n        *   ב-`process_row_major`, הגישה הרציפה גורמת לכך שמעט מאוד מיפויי עמודים נדרשים בפרק זמן קצר. סביר להניח שמיפויי העמודים יישארו ב-TLB, מה שימנע חיפוש יקר בטבלאות העמודים (page tables) בזיכרון הראשי.\n        *   ב-`process_col_major`, הגישה המפוזרת על פני עמודים רבים גורמת ל\"החטאות TLB\" (TLB misses) תכופות. כל החטאה דורשת מעבר על טבלאות העמודים, פעולה שלוקחת זמן רב ומוסיפה לעיכוב בביצוע.\n\n**קוד מתוקן (אופטימיזציה):**\n\nכדי לשפר את ביצועי `process_col_major` מבלי לשנות את הלוגיקה החישובית, ניתן להשתמש בטכניקת \"חסימה\" (blocking) או \"אריחים\" (tiling). הרעיון הוא לעבד בלוקים קטנים של המטריצה בכל פעם, כך שהנתונים הרלוונטיים ייכנסו לזיכרון המטמון ויישארו שם עד לסיום עיבוד הבלוק.\n\n```c\n#define BLOCK_SIZE 64 // גודל בלוק אופטימלי תלוי בגודל ה-cache ובגודל ה-cache line. 64 הוא לרוב סביר.\n\n// פונקציה 2 משופרת: סריקה בסדר עמודות באמצעות חסימה (tiling)\nvoid process_col_major_optimized() {\n    for (int block_j = 0; block_j < N; block_j += BLOCK_SIZE) {\n        for (int block_i = 0; block_i < N; block_i += BLOCK_SIZE) {\n            // עיבוד בלוק בגודל BLOCK_SIZE x BLOCK_SIZE\n            for (int j = block_j; j < block_j + BLOCK_SIZE && j < N; j++) {\n                for (int i = block_i; i < block_i + BLOCK_SIZE && i < N; i++) {\n                    matrix[i][j] *= 2;\n                }\n            }\n        }\n    }\n}\n```\n\n**הסבר לאופטימיזציה:**\nהאופטימיזציה משפרת את הניצול של עקרון המקומיות המרחבית והזמנית. במקום לסרוק עמוד שלם (שעלול להיות גדול מאוד) לפני המעבר לעמוד הבא, אנו סורקים \"אריח\" (tile) קטן.\nכאשר אנו מעבדים בלוק `BLOCK_SIZE x BLOCK_SIZE`, הגישה ל-`matrix[i][j]` ולאחר מכן ל-`matrix[i+1][j]` עדיין מדלגת על שורות, אך הפעם הדילוגים מתרחשים בתוך בלוק קטן יחסית. אם `BLOCK_SIZE` נבחר נכון (כך שבלוק של `BLOCK_SIZE * BLOCK_SIZE` אלמנטים יכול להיכנס ל-cache), אז לאחר הגישה הראשונית לאלמנטים בבלוק וטעינתם ל-cache, הגישות הבאות לאותם אלמנטים בתוך הבלוק יהיו מהירות יותר (cache hits). זה מפחית באופן דרמטי את מספר ה-cache misses ואף את ה-TLB misses, שכן העבודה מתרכזת באזור זיכרון קטן יותר בכל פעם. אנו עדיין ניגשים בסדר עמודות בתוך הבלוק, אך מכיוון שהבלוק קטן מספיק כדי להישאר ב-cache, עלות ה-cache misses מצטמצמת משמעותית."}, "difficulty_estimation": "Hard", "_source_file": "0497__Memory_Management__CodeAnalysis__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:09:17", "_subject": "Virtualization"}, {"id": 10, "type": "CodeAnalysis", "topic": ["Memory Management", "Virtual Memory", "Paging", "Address Translation"], "content": {"text": "מערכת הפעלה נתונה משתמשת בזיכרון וירטואלי עם כתובות וירטואליות בנות 32 סיביות, וגודל עמוד (page size) של 4KB. המערכת מיישמת טבלת עמודים דו-שלבית לתרגום כתובות. פורמט הכתובת הווירטואלית מחולק לשלושה חלקים: 10 סיביות עבור אינדקס טבלת ספריות העמודים (Page Directory Index), 10 סיביות עבור אינדקס טבלת העמודים (Page Table Index), ו-12 סיביות עבור היסט בתוך העמוד (Offset).\n\nמבנה כניסה בטבלת עמודים (PTE) מוגדר כדלקמן:\n```c\ntypedef struct {\n    uint32_t present : 1;      // 1: page is in physical memory, 0: not present (page fault)\n    uint32_t rw : 1;           // 1: read/write, 0: read-only\n    uint32_t user_supervisor : 1; // 1: user access allowed, 0: supervisor only\n    uint32_t accessed : 1;     // Set by hardware on access\n    uint32_t dirty : 1;        // Set by hardware on write\n    uint32_t global : 1;       // Global page (TLB won't flush on context switch)\n    uint32_t unused : 6;       // Unused/available for OS use\n    uint32_t frame_addr_high : 20; // High 20 bits of the physical frame address (bits 12-31)\n} pte_t;\n```\n\nהפונקציה `translate_virtual_to_physical` מקבלת את הכתובת הפיזית של בסיס ספריית העמודים (page_directory_base), כתובת וירטואלית לתרגום (virtual_address), ודגל המציין האם הגישה היא גישת כתיבה (is_write_access). עליכם להשלים את מימוש הפונקציה כך שתחזיר את הכתובת הפיזית המתאימה, או קוד שגיאה במקרה של כשל.\n\nהפונקציה צריכה לטפל במקרים הבאים:\n1. **כשל עמוד (Page Fault)**: אם כניסה כלשהי בטבלת העמודים (PTE או PDE) אינה מסומנת כ-'present' (הסיבית present היא 0), יש להחזיר את קוד השגיאה `E_PAGE_FAULT`.\n2. **שגיאת הרשאה (Permission Denied)**: אם מבוצעת גישת כתיבה (is_write_access הוא true) לעמוד המסומן כ'קריאה בלבד' (הסיבית rw היא 0), יש להחזיר את קוד השגיאה `E_PERMISSION_DENIED`.\n3. **תרגום מוצלח**: אם כל הבדיקות עוברות, יש לחשב ולהחזיר את הכתובת הפיזית המלאה.\n\nלצורך פשטות המודל, יש להניח כי `page_directory_base` וכן השדה `frame_addr_high` ב-`pte_t` מכילים כתובות פיזיות שניתן להתייחס אליהן ישירות כאל מצביעים בזיכרון הסימולטבי שלנו (כלומר, אין צורך לדאוג למיפוי זיכרון פיזי לכתובות וירטואליות של הקרנל בתוך הפונקציה עצמה).\n\n```c\n#include <stdint.h>\n\n// Constants for system parameters\n#define PAGE_SIZE 4096 // 4KB\n#define BITS_FOR_OFFSET 12\n#define BITS_FOR_INDEX 10 // (32 - BITS_FOR_OFFSET) / 2 = 10\n\n// Masks for extracting parts of a virtual address\n#define PD_INDEX_MASK 0xFFC00000 // Bits 31-22\n#define PT_INDEX_MASK 0x003FF000 // Bits 21-12\n#define OFFSET_MASK   0x00000FFF // Bits 11-0\n\n// Page Table Entry (PTE) structure (as described in the problem)\ntypedef struct {\n    uint32_t present : 1;      // 1: page is in physical memory, 0: not present (page fault)\n    uint32_t rw : 1;           // 1: read/write, 0: read-only\n    uint32_t user_supervisor : 1; // 1: user access allowed, 0: supervisor only\n    uint32_t accessed : 1;     // Set by hardware on access\n    uint32_t dirty : 1;        // Set by hardware on write\n    uint32_t global : 1;       // Global page (TLB won't flush on context switch)\n    uint32_t unused : 6;       // Unused/available for OS use\n    uint32_t frame_addr_high : 20; // High 20 bits of the physical frame address (bits 12-31)\n} pte_t;\n\n// Error codes (using uint64_t to ensure distinct values from valid 32-bit physical addresses)\n#define E_PAGE_FAULT        ((uint64_t)-1)\n#define E_PERMISSION_DENIED ((uint64_t)-2)\n\n// Function signature to implement\nuint64_t translate_virtual_to_physical(uint64_t page_directory_base, uint32_t virtual_address, int is_write_access) {\n    // השלם את הקוד כאן\n}\n```", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון דורש פירוק של הכתובת הווירטואלית למרכיביה: אינדקס ספריית עמודים (PD_INDEX), אינדקס טבלת עמודים (PT_INDEX) והיסט בתוך העמוד (OFFSET). כל אינדקס משמש לגישה לכניסה המתאימה בטבלת העמודים ברמתה. לאחר מכן, יש לבצע בדיקות תקינות והרשאות בכל שלב.\n\n**שלבי הפתרון:**\n1.  **פירוק כתובת וירטואלית**: באמצעות מסכות והזזות סיביות, מחלצים את ה-PD_INDEX, PT_INDEX וה-OFFSET מה-`virtual_address`.\n    *   PD_INDEX (10 סיביות עליונות): מחושב מסיביות 22-31.\n    *   PT_INDEX (10 סיביות אמצעיות): מחושב מסיביות 12-21.\n    *   OFFSET (12 סיביות תחתונות): מחושב מסיביות 0-11.\n2.  **גישה ל-PDE (Page Directory Entry)**: ה-`page_directory_base` מצביע לתחילת ספריית העמודים. אנו מחשבים את הכתובת של ה-PDE המתאים באמצעות `pd_index` וכופלים בגודל של `pte_t`.\n3.  **בדיקת PDE**:\n    *   אם `pde->present` הוא 0, מחזירים `E_PAGE_FAULT`.\n    *   אם `is_write_access` הוא true וגם `pde->rw` הוא 0, מחזירים `E_PERMISSION_DENIED` (בהנחה שסיבית ה-rw ב-PDE חלה על כל טבלת העמודים שהיא מפנה אליה).\n    *   השדה `pde->frame_addr_high` מכיל את 20 הסיביות העליונות של הכתובת הפיזית של טבלת העמודים מהרמה השנייה. אנו משלבים אותו עם 12 סיביות אפסים (הזזה שמאלה ב-`BITS_FOR_OFFSET`) כדי לקבל את כתובת הבסיס של טבלת העמודים.\n4.  **גישה ל-PTE (Page Table Entry)**: באמצעות כתובת הבסיס של טבלת העמודים ו-`pt_index`, מחשבים את הכתובת של ה-PTE המתאים.\n5.  **בדיקת PTE**:\n    *   אם `pte->present` הוא 0, מחזירים `E_PAGE_FAULT`.\n    *   אם `is_write_access` הוא true וגם `pte->rw` הוא 0, מחזירים `E_PERMISSION_DENIED`.\n    *   השדה `pte->frame_addr_high` מכיל את 20 הסיביות העליונות של הכתובת הפיזית של העמוד בפועל (frame).\n6.  **חישוב כתובת פיזית סופית**: משלבים את 20 הסיביות העליונות של כתובת ה-frame (מתוך `pte->frame_addr_high` לאחר הזזה) עם ה-OFFSET כדי לקבל את הכתובת הפיזית המלאה.\n\n```c\n#include <stdint.h>\n#include <stdio.h> // רק לצורך הדגמה/בדיקה, לא נדרש לפתרון עצמו\n\n// Constants for system parameters\n#define PAGE_SIZE 4096 // 4KB\n#define BITS_FOR_OFFSET 12\n#define BITS_FOR_INDEX 10 // (32 - BITS_FOR_OFFSET) / 2 = 10\n\n// Masks for extracting parts of a virtual address\n#define PD_INDEX_MASK 0xFFC00000 // Bits 31-22\n#define PT_INDEX_MASK 0x003FF000 // Bits 21-12\n#define OFFSET_MASK   0x00000FFF // Bits 11-0\n\n// Page Table Entry (PTE) structure\ntypedef struct {\n    uint32_t present : 1;      // 1: page is in physical memory, 0: not present (page fault)\n    uint32_t rw : 1;           // 1: read/write, 0: read-only\n    uint32_t user_supervisor : 1; // 1: user access allowed, 0: supervisor only\n    uint32_t accessed : 1;     // Set by hardware on access\n    uint32_t dirty : 1;        // Set by hardware on write\n    uint32_t global : 1;       // Global page (TLB won't flush on context switch)\n    uint32_t unused : 6;       // Unused/available for OS use\n    uint32_t frame_addr_high : 20; // High 20 bits of the physical frame address (bits 12-31)\n} pte_t;\n\n// Error codes (using uint64_t to ensure distinct values from valid 32-bit physical addresses)\n#define E_PAGE_FAULT        ((uint64_t)-1)\n#define E_PERMISSION_DENIED ((uint64_t)-2)\n\nuint64_t translate_virtual_to_physical(uint64_t page_directory_base, uint32_t virtual_address, int is_write_access) {\n    // Extract indices and offset\n    uint32_t pd_index = (virtual_address & PD_INDEX_MASK) >> (BITS_FOR_OFFSET + BITS_FOR_INDEX);\n    uint32_t pt_index = (virtual_address & PT_INDEX_MASK) >> BITS_FOR_OFFSET;\n    uint32_t offset   = (virtual_address & OFFSET_MASK);\n\n    // Level 1: Page Directory Entry (PDE)\n    // The page_directory_base points to the start of an array of pte_t\n    // Each entry is sizeof(pte_t) bytes\n    pte_t* pde = (pte_t*)(page_directory_base + (pd_index * sizeof(pte_t)));\n\n    // Check PDE validity\n    if (!pde->present) {\n        return E_PAGE_FAULT;\n    }\n\n    // Check PDE permissions for write access (if PDE itself is read-only)\n    // This check assumes PDE's `rw` bit applies to the entire page table it points to.\n    if (is_write_access && !pde->rw) {\n        return E_PERMISSION_DENIED;\n    }\n\n    // Level 2: Page Table Entry (PTE)\n    // The frame_addr_high of the PDE gives the base physical address of the Page Table\n    uint64_t page_table_base = (uint64_t)pde->frame_addr_high << BITS_FOR_OFFSET;\n    pte_t* pte = (pte_t*)(page_table_base + (pt_index * sizeof(pte_t)));\n\n    // Check PTE validity\n    if (!pte->present) {\n        return E_PAGE_FAULT;\n    }\n\n    // Check PTE permissions for write access\n    if (is_write_access && !pte->rw) {\n        return E_PERMISSION_DENIED;\n    }\n\n    // If all checks pass, calculate physical address\n    uint64_t physical_frame_base = (uint64_t)pte->frame_addr_high << BITS_FOR_OFFSET;\n    uint64_t physical_address = physical_frame_base | offset;\n\n    return physical_address;\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0498__Memory_Management__CodeAnalysis__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:09:57", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Memory Management", "Virtual Memory", "Custom Allocator", "Concurrency", "Synchronization"], "content": {"text": "נתבקשתם לתכנן ולממש מנהל זיכרון (Memory Allocator) מותאם אישית עבור יישום הדורש שליטה מדויקת על הקצאת זיכרון, ביצועים גבוהים, ויכולת פעולה בסביבה מרובת חוטים. המנהל אמור לנהל מאגר זיכרון גדול וקבוע בגודלו, שיוקצה פעם אחת בתחילת ריצת התוכנית באמצעות `mmap`.\n\nדרישות המימוש הן כדלקמן:\n1.  **אתחול (Initialization)**: פונקציה `init_allocator()` שתקצה מאגר זיכרון בגודל קבוע (לדוגמה, 1GB) באמצעות `mmap`. קריאה זו תתבצע פעם אחת בלבד.\n2.  **הקצאה (Allocation)**: פונקציה `void *my_malloc(size_t size)` שתקצה בלוק זיכרון בגודל `size` בתים מתוך המאגר המנוהל. הפונקציה צריכה להחזיר מצביע לאזור הנתונים של הבלוק המוקצה. אם אין מספיק זיכרון, הפונקציה תחזיר `NULL`.\n3.  **שחרור (Deallocation)**: פונקציה `void my_free(void *ptr)` שתשחרר בלוק זיכרון שהוקצה בעבר על ידי `my_malloc`. שחרור כפול או שחרור מצביע לא חוקי צריך להיות מטופל באופן בטוח (לדוגמה, על ידי הדפסת שגיאה).\n4.  **איחוד בלוקים (Coalescing)**: כאשר בלוק משוחרר, יש לאחד אותו עם בלוקים חופשיים סמוכים פיזית (אם קיימים) כדי למנוע פיצול חיצוני (External Fragmentation). בלוקים מאוחדים צריכים ליצור בלוק חופשי גדול יותר.\n5.  **בטיחות חוטים (Thread-Safety)**: המנהל חייב להיות בטוח לשימוש בסביבה מרובת חוטים, כלומר, קריאות מקבילות ל-`my_malloc` ו-`my_free` לא יגרמו לשחיתות נתונים או למצבי מרוץ (Race Conditions).\n6.  **יישור (Alignment)**: הזיכרון המוקצה למשתמש צריך להיות מיושר כראוי (לדוגמה, ליישור של `sizeof(long)` או 8 בתים) כדי למנוע שגיאות גישה לזיכרון.\n7.  **יעילות**: יש לשאוף ליעילות סבירה הן מבחינת זמן הריצה של ההקצאה/שחרור והן מבחינת ניצול הזיכרון (overhead מינימלי למטא-דאטה).\n8.  **הגבלות**: אין להשתמש בפונקציות `malloc`, `free`, `calloc`, `realloc` או `sbrk` בתוך המימוש של מנהל הזיכרון. מותר להשתמש ב-`mmap` וב-`pthread_mutex_t` בלבד.\n\nיש להשלים את הקוד המצורף, כולל הגדרות המבנים ומשתנים גלובליים נדרשים.", "code_snippet": "#include <stddef.h> // For size_t\n#include <sys/mman.h> // For mmap, munmap\n#include <unistd.h> // For sysconf (page size)\n#include <pthread.h> // For pthread_mutex_t\n#include <stdio.h> // For perror, fprintf\n\n#define HEAP_SIZE (1 * 1024 * 1024 * 1024UL) // 1GB\n\n// Global variables for the allocator state\nstatic void *heap_start = NULL;\n// Add necessary synchronization primitives and free list structures here\n\n// Forward declaration for block_header_t\ntypedef struct block_header block_header_t;\n\nstruct block_header {\n    size_t size; // Size of the block (including header and footer). MSB indicates allocated/free.\n    // Add pointers for free list or status flags\n    struct block_header *next_free; // Used only if block is free.\n    struct block_header *prev_free; // Used only if block is free.\n};\n\n// Mutex for thread safety\nstatic pthread_mutex_t allocator_mutex;\n\n// Pointer to the head of the free list\nstatic block_header_t *free_list_head = NULL;\n\n// Initialization function\nvoid init_allocator() {\n    // 1. Initialize mutex (if not static)\n    // 2. mmap the HEAP_SIZE region\n    // 3. Initialize the first block_header_t to cover the entire heap\n    // 4. Add this block to the free list\n}\n\n// Allocation function\nvoid *my_malloc(size_t size) {\n    // 1. Lock the mutex\n    // 2. Adjust size for alignment, header, and footer\n    // 3. Search free list for a suitable block (e.g., best-fit)\n    // 4. If found:\n    //    a. Remove block from free list\n    //    b. Split block if remaining space is large enough for another block\n    //    c. Mark block as allocated (update header and footer)\n    // 5. Unlock mutex\n    // 6. Return pointer to user data area\n}\n\n// Deallocation function\nvoid my_free(void *ptr) {\n    // 1. Lock the mutex\n    // 2. Get block header from ptr\n    // 3. Basic validation (is it valid, is it allocated?)\n    // 4. Mark block as free (update header and footer)\n    // 5. Coalesce with adjacent free blocks (previous and next in memory) using boundary tags\n    // 6. Insert/update block in free list, maintaining address order\n    // 7. Unlock mutex\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפתרון המוצע מממש מנהל זיכרון מותאם אישית המבוסס על רשימה מקושרת כפולה של בלוקים חופשיים (Free List). הבלוקים ברשימה מסודרים לפי כתובת זיכרון עולה, מה שמקל על איחוד בלוקים סמוכים פיזית. כל בלוק זיכרון, בין אם הוא מוקצה או חופשי, מכיל כותרת (Header) ורגל (Footer) עם מידע על גודלו, מה שמאפשר מעבר קדימה ואחורה בין בלוקים פיזיים במאגר הזיכרון.\n\n**מבנה הבלוק (`block_header_t`)**:\n- `size_t size`: גודל הבלוק הכולל (כולל הכותרת והרגל). הסיבית המשמעותית ביותר (MSB) של השדה משמשת כדגל לציון אם הבלוק מוקצה (1) או חופשי (0).\n- `block_header_t *next_free`, `block_header_t *prev_free`: מצביעים לבלוק החופשי הבא והקודם ברשימת הבלוקים החופשיים, בהתאמה. מצביעים אלו רלוונטיים רק כאשר הבלוק חופשי.\n- בנוסף, כל בלוק מכיל `size_t` בסופו (כ'רגל' או 'Boundary Tag') המכיל את גודל הבלוק. זה מאפשר לבלוקים 'להביט לאחור' ולמצוא את הכותרת של הבלוק הפיזי הקודם.\n\n**פונקציות עזר:**\n- `is_allocated(block_header_t *block)`: בודקת אם הבלוק מוקצה על ידי בדיקת ה-MSB של שדה הגודל.\n- `get_block_total_size(block_header_t *block)`: מחזירה את גודל הבלוק האמיתי (ללא דגל ההקצאה).\n- `mark_allocated(block_header_t *block, size_t size)`: מסמנת בלוק כמוקצה ומעדכנת את הכותרת והרגל.\n- `mark_free(block_header_t *block, size_t size)`: מסמנת בלוק כחופשי ומעדכנת את הכותרת והרגל.\n- `remove_from_free_list(block_header_t *block)`: מסירה בלוק מרשימת הבלוקים החופשיים.\n- `insert_into_free_list(block_header_t *block)`: מכניסה בלוק לרשימת הבלוקים החופשיים, תוך שמירה על סדר כתובות עולה.\n- `calculate_aligned_block_size(size_t user_size)`: מחשבת את הגודל הכולל של הבלוק (כולל כותרת, רגל ויישור) הנדרש עבור `user_size` נתון. היא גם מבטיחה גודל מינימלי לבלוק על מנת שיוכל להכיל את המטא-דאטה הדרושה.\n\n**`init_allocator()`**:\n- משתמשת ב-`mmap` כדי להקצות מאגר זיכרון רציף בגודל `HEAP_SIZE`.\n- מאתחלת בלוק חופשי יחיד בגודל המאגר כולו, ומכניסה אותו לרשימת הבלוקים החופשיים.\n\n**`my_malloc(size_t size)`**:\n- נועלת Mutex כדי להבטיח בטיחות חוטים.\n- מחשבת את הגודל הכולל הנדרש לבלוק (כולל מטא-דאטה ויישור).\n- סורקת את רשימת הבלוקים החופשיים (בסטרטגיית Best-Fit) כדי למצוא את הבלוק החופשי הקטן ביותר שיכול להכיל את הבקשה.\n- אם נמצא בלוק מתאים:\n    - מסירה אותו מרשימת הבלוקים החופשיים.\n    - בודקת אם ניתן לפצל את הבלוק: אם הגודל הנותר לאחר ההקצאה מספיק גדול עבור בלוק חופשי חדש (כולל מטא-דאטה מינימלית), הבלוק מפוצל. החלק המוקצה מסומן כמוקצה, והחלק הנותר מסומן כחופשי ומוכנס חזרה לרשימת הבלוקים החופשיים בסדר כתובות.\n    - אם לא ניתן לפצל, הבלוק כולו מוקצה.\n- מחזירה מצביע לאזור הנתונים של הבלוק המוקצה (לאחר הכותרת), ומשחררת את ה-Mutex.\n- אם לא נמצא בלוק מתאים, מחזירה `NULL`.\n\n**`my_free(void *ptr)`**:\n- נועלת Mutex.\n- ממירה את מצביע המשתמש למצביע לכותרת הבלוק.\n- מבצעת בדיקת תקינות בסיסית (האם המצביע בתוך המאגר והאם הבלוק אכן מוקצה) כדי למנוע שחרור כפול או שחרור מצביע לא חוקי.\n- מסמנת את הבלוק כחופשי ומעדכנת את הכותרת והרגל.\n- **איחוד (Coalescing)**:\n    - בודקת את הבלוק הפיזי הקודם: באמצעות הרגל של הבלוק הנוכחי, ניתן למצוא את גודלו של הבלוק הפיזי הקודם, ולפיכך את כותרתו. אם הבלוק הפיזי הקודם חופשי, הוא מאוחד עם הבלוק הנוכחי. הבלוק הקודם מוסר מרשימת הבלוקים החופשיים, וגודלו מעודכן.\n    - בודקת את הבלוק הפיזי הבא: אם הבלוק הפיזי הבא חופשי, הוא מאוחד לתוך הבלוק המאוחד הקיים. הבלוק הבא מוסר מרשימת הבלוקים החופשיים, וגודלו של הבלוק המאוחד מעודכן.\n- לאחר איחודים אפשריים, הבלוק (המאוחד כעת) מוכנס חזרה לרשימת הבלוקים החופשיים, תוך שמירה על סדר כתובות עולה.\n- משחררת את ה-Mutex.\n\nפתרון זה מציע איזון טוב בין יעילות (Best-Fit, רשימה מקושרת כפולה ממוינת, איחוד) לבין מורכבות, ועומד בכל הדרישות, כולל בטיחות חוטים וטיפול בפיצול זיכרון.\n\n```c\n#include <stddef.h> // For size_t\n#include <sys/mman.h> // For mmap, munmap\n#include <unistd.h> // For sysconf (page size)\n#include <pthread.h> // For pthread_mutex_t\n#include <stdio.h> // For perror, fprintf\n\n#define HEAP_SIZE (1 * 1024 * 1024 * 1024UL) // 1GB\n#define MIN_ALLOC_USER_SIZE 16 // Minimum user data size to ensure block can hold pointers for free list\n#define ALIGNMENT sizeof(long) // General alignment for malloc\n\n// Block header structure (for both free and allocated blocks)\ntypedef struct block_header {\n    size_t size; // Size of the block (including header and footer). MSB indicates allocated/free.\n    struct block_header *next_free; // Used only if block is free. Points to next free block in address order.\n    struct block_header *prev_free; // Used only if block is free. Points to previous free block in address order.\n} block_header_t;\n\n// A block also has a footer, which is just a size_t storing the block's total size (without flag).\n// This allows traversing backwards.\n\nstatic void *heap_start = NULL;\nstatic block_header_t *free_list_head = NULL; // Head of the doubly linked list of FREE blocks, sorted by address.\nstatic pthread_mutex_t allocator_mutex = PTHREAD_MUTEX_INITIALIZER; // Statically initialize mutex\n\n// Helper to get the footer pointer for a given block header\nstatic size_t *get_footer(block_header_t *block) {\n    return (size_t *)((char *)block + (block->size & ~(1UL << (sizeof(size_t)*8 - 1))) - sizeof(size_t));\n}\n\n// Helper to check if a block is allocated (MSB of size is set)\nstatic int is_allocated(block_header_t *block) {\n    return (block->size & (1UL << (sizeof(size_t)*8 - 1))) != 0;\n}\n\n// Helper to get the true size of a block (without allocated flag)\nstatic size_t get_block_total_size(block_header_t *block) {\n    return block->size & ~(1UL << (sizeof(size_t)*8 - 1));\n}\n\n// Helper to mark a block as allocated\nstatic void mark_allocated(block_header_t *block, size_t size) {\n    block->size = size | (1UL << (sizeof(size_t)*8 - 1)); // Set MSB\n    *get_footer(block) = size; // Update footer\n}\n\n// Helper to mark a block as free\nstatic void mark_free(block_header_t *block, size_t size) {\n    block->size = size; // Clear MSB\n    *get_footer(block) = size; // Update footer\n}\n\n// Helper to remove a block from the free list\nstatic void remove_from_free_list(block_header_t *block) {\n    if (block->prev_free) {\n        block->prev_free->next_free = block->next_free;\n    } else {\n        free_list_head = block->next_free;\n    }\n    if (block->next_free) {\n        block->next_free->prev_free = block->prev_free;\n    }\n    block->next_free = NULL; // Clear pointers\n    block->prev_free = NULL;\n}\n\n// Helper to insert a block into the free list (maintaining address order)\nstatic void insert_into_free_list(block_header_t *block) {\n    block_header_t *current = free_list_head;\n    block_header_t *prev = NULL;\n\n    while (current != NULL && current < block) {\n        prev = current;\n        current = current->next_free;\n    }\n\n    if (prev == NULL) { // Insert at head\n        block->next_free = free_list_head;\n        if (free_list_head) free_list_head->prev_free = block;\n        free_list_head = block;\n    } else { // Insert in middle or at end\n        block->next_free = current;\n        block->prev_free = prev;\n        prev->next_free = block;\n        if (current) current->prev_free = block;\n    }\n}\n\n// Helper to get actual aligned size needed for user data + header + footer\nstatic size_t calculate_aligned_block_size(size_t user_size) {\n    // Minimum block size must accommodate header, footer, and MIN_ALLOC_USER_SIZE\n    // This ensures that even small user requests result in a block large enough to be split later\n    size_t min_effective_user_size = (user_size < MIN_ALLOC_USER_SIZE) ? MIN_ALLOC_USER_SIZE : user_size;\n    size_t total_size = sizeof(block_header_t) + min_effective_user_size + sizeof(size_t); // Header + user_data + Footer\n    return (total_size + ALIGNMENT - 1) & ~(ALIGNMENT - 1); // Align total block size\n}\n\n// Function to initialize the allocator\nvoid init_allocator() {\n    if (heap_start != NULL) {\n        return; // Already initialized\n    }\n\n    // Allocate the heap using mmap\n    heap_start = mmap(NULL, HEAP_SIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);\n    if (heap_start == MAP_FAILED) {\n        perror(\"mmap failed\");\n        // In a real system, handle this gracefully, perhaps by exiting or throwing an exception.\n        return;\n    }\n\n    // Initialize the first (and only) free block spanning the entire heap\n    block_header_t *initial_block = (block_header_t *)heap_start;\n    mark_free(initial_block, HEAP_SIZE); // Mark free, set size in header and footer\n    initial_block->next_free = NULL;\n    initial_block->prev_free = NULL;\n    free_list_head = initial_block;\n}\n\n// Function to allocate memory\nvoid *my_malloc(size_t size) {\n    if (size == 0) {\n        return NULL;\n    }\n\n    pthread_mutex_lock(&allocator_mutex);\n\n    // Calculate the total block size needed (user_size + header + footer), aligned\n    size_t required_block_total_size = calculate_aligned_block_size(size);\n\n    block_header_t *current = free_list_head;\n    block_header_t *best_fit = NULL; // Best-fit strategy\n\n    // Search for the best-fit free block\n    while (current != NULL) {\n        if (get_block_total_size(current) >= required_block_total_size) {\n            if (best_fit == NULL || get_block_total_size(current) < get_block_total_size(best_fit)) {\n                best_fit = current;\n            }\n        }\n        current = current->next_free;\n    }\n\n    if (best_fit == NULL) {\n        // No suitable block found\n        pthread_mutex_unlock(&allocator_mutex);\n        return NULL;\n    }\n\n    block_header_t *block_to_allocate = best_fit;\n    size_t original_block_total_size = get_block_total_size(block_to_allocate);\n\n    // Remove block_to_allocate from the free list\n    remove_from_free_list(block_to_allocate);\n\n    // Check if the remaining part after allocation is large enough to form a new free block\n    if (original_block_total_size - required_block_total_size >= calculate_aligned_block_size(1)) { // Check against minimal block size\n        // Split the block\n        mark_allocated(block_to_allocate, required_block_total_size); // Mark the allocated part\n\n        block_header_t *new_free_block = (block_header_t *)((char *)block_to_allocate + required_block_total_size);\n        mark_free(new_free_block, original_block_total_size - required_block_total_size); // Mark the new free part\n\n        // Insert the new free block back into the free list, maintaining address order\n        insert_into_free_list(new_free_block);\n    } else {\n        // Not enough space to split, allocate the entire block\n        mark_allocated(block_to_allocate, original_block_total_size);\n    }\n\n    pthread_mutex_unlock(&allocator_mutex);\n    return (void *)((char *)block_to_allocate + sizeof(block_header_t)); // Return pointer to user data area\n}\n\n// Function to free memory\nvoid my_free(void *ptr) {\n    if (ptr == NULL) {\n        return;\n    }\n\n    pthread_mutex_lock(&allocator_mutex);\n\n    // Get the block header from the user pointer\n    block_header_t *block_to_free = (block_header_t *)((char *)ptr - sizeof(block_header_t));\n\n    // Basic validation: ensure it's within our heap and marked as allocated\n    if ((void*)block_to_free < heap_start || (void*)block_to_free >= (char*)heap_start + HEAP_SIZE || !is_allocated(block_to_free)) {\n        fprintf(stderr, \"Error: Attempt to free an invalid or unallocated block at %p.\\n\", ptr);\n        pthread_mutex_unlock(&allocator_mutex);\n        return;\n    }\n\n    // Mark the current block as free\n    size_t current_block_total_size = get_block_total_size(block_to_free);\n    mark_free(block_to_free, current_block_total_size);\n\n    // Attempt to coalesce with physically adjacent free blocks\n\n    // Check previous physical block using its footer\n    block_header_t *prev_phys_block = NULL;\n    if (block_to_free > (block_header_t *)heap_start) { // If not the very first block in the heap\n        size_t *prev_footer_ptr = (size_t *)((char *)block_to_free - sizeof(size_t));\n        size_t prev_phys_size = *prev_footer_ptr; // Get size of previous block from its footer\n        prev_phys_block = (block_header_t *)((char *)block_to_free - prev_phys_size);\n\n        // Ensure prev_phys_block is valid and free\n        if ((void*)prev_phys_block >= heap_start && !is_allocated(prev_phys_block)) {\n            // Merge current block into prev_phys_block\n            remove_from_free_list(prev_phys_block); // Remove prev_phys_block from free list\n            mark_free(prev_phys_block, get_block_total_size(prev_phys_block) + current_block_total_size);\n            block_to_free = prev_phys_block; // Now block_to_free refers to the merged block\n            current_block_total_size = get_block_total_size(block_to_free); // Update size\n        }\n    }\n\n    // Check next physical block\n    block_header_t *next_phys_block = (block_header_t *)((char *)block_to_free + current_block_total_size);\n    if ((void *)next_phys_block < (char *)heap_start + HEAP_SIZE && !is_allocated(next_phys_block)) {\n        // Ensure next_phys_block is valid and free\n        // Merge next_phys_block into block_to_free\n        remove_from_free_list(next_phys_block); // Remove next_phys_block from free list\n        mark_free(block_to_free, get_block_total_size(block_to_free) + get_block_total_size(next_phys_block));\n    }\n\n    // Insert the (potentially merged) block into the free list\n    insert_into_free_list(block_to_free);\n\n    pthread_mutex_unlock(&allocator_mutex);\n}\n```\n"}, "difficulty_estimation": "Hard", "_source_file": "0499__Memory_Management__CodeAnalysis__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:11:13", "_subject": "Virtualization"}, {"id": 8, "type": "CodeAnalysis", "topic": ["Memory Management", "Virtual Memory", "Paging", "TLB"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם טבלאות דפים דו-שכבתיות (two-level page tables).\nמרחב הכתובות הווירטואלי הוא בגודל 32 ביט.\nגודל דף (page size) הוא 4 קילובייט (KB).\nכל כניסה בטבלת דפים (Page Table Entry - PTE) היא בגודל 4 בתים.\nגודל טבלת דפים (הן השכבה הראשונה והן השכבה השנייה) הוא 4 קילובייט.\n\nהמערכת מצוידת ב-TLB (Translation Lookaside Buffer) בגודל 16 כניסות, הפועל בשיטה אסוציאטיבית מלאה (fully associative) עם מדיניות החלפה LRU (Least Recently Used).\nנניח שה-TLB ריק לחלוטין בתחילת ריצת התוכנית.\n\nנתונה תוכנית ה-C הבאה שמבצעת גישה למערך גדול.\nיש לנתח את קטע הקוד ולחשב את:\n1.  מספר ה-TLB misses הכולל שיתרחשו במהלך ריצת הלולאה הפנימית בתוכנית הנתונה.\n2.  מספר הגישות הכולל לטבלאות הדפים (page table walks), כאשר כל \"walk\" כזה כולל גישה לכל רמת טבלת דפים.\nיש להניח שכל הדפים הדרושים נמצאים בזיכרון הפיזי (אין page faults) ושכל הגישות לזיכרון הפיזי, כולל גישות לטבלאות דפים, לוקחות זמן זהה. אין להניח שדפי טבלאות הדפים נשארים ב-CPU cache בין גישות שונות, אלא אם צוין אחרת במפורש.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n\n#define ARRAY_SIZE (1024 * 1024) // 1M integers\n#define PAGE_SIZE (4 * 1024)     // 4KB\n#define INT_SIZE (sizeof(int))   // 4 bytes\n\nint main() {\n    int *arr = (int *)malloc(ARRAY_SIZE * INT_SIZE);\n    if (arr == NULL) {\n        perror(\"malloc failed\");\n        return 1;\n    }\n\n    // Access pattern\n    for (int i = 0; i < 1024; ++i) { // Outer loop\n        for (int j = 0; j < ARRAY_SIZE; j += (PAGE_SIZE / INT_SIZE)) { // Inner loop: Accesses start of each page\n            arr[j] = i; // Write access\n        }\n    }\n\n    free(arr);\n    return 0;\n}", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "נתחיל בניתוח מבנה הזיכרון הווירטואלי והגישה לזיכרון:\n1.  **מבנה כתובת וירטואלית:**\n    *   גודל דף (Page Size) הוא 4KB = 2^12 בתים. לכן, ה-Offset בכתובת הווירטואלית הוא 12 ביטים.\n    *   גודל כניסה בטבלת דפים (PTE) הוא 4 בתים.\n    *   גודל טבלת דפים הוא 4KB. לכן, מספר הכניסות בכל טבלת דפים הוא 4KB / 4 בתים = 1024 כניסות = 2^10 כניסות.\n    *   מספר הביטים הנדרש לכל אינדקס בטבלת דפים (P1 Index ו-P2 Index) הוא 10 ביטים.\n    *   מבנה הכתובת הווירטואלית (32 ביטים): 10 ביטים עבור P1 Index, 10 ביטים עבור P2 Index, ו-12 ביטים עבור Offset.\n\n2.  **גודל המערך וכיסוי דפים:**\n    *   `ARRAY_SIZE = 1024 * 1024` שלמים.\n    *   גודל שלם (`sizeof(int)`) הוא 4 בתים.\n    *   סה\"כ גודל המערך בזיכרון הוא `1024 * 1024 * 4` בתים = `4MB`.\n    *   מספר הדפים שהמערך תופס בזיכרון הווירטואלי הוא `4MB / 4KB = (4 * 1024 * 1024) / (4 * 1024) = 1024` דפים.\n\n3.  **תבנית הגישה לזיכרון (Access Pattern):**\n    *   הלולאה החיצונית רצה 1024 פעמים (`i` מ-0 עד 1023).\n    *   הלולאה הפנימית רצה מ-`j=0` וקופצת בכל פעם ב-`PAGE_SIZE / INT_SIZE`.\n    *   `PAGE_SIZE / INT_SIZE = 4KB / 4 bytes = 1024`.\n    *   כלומר, הלולאה הפנימית ניגשת לאיברים `arr[0]`, `arr[1024]`, `arr[2048]`, וכן הלאה.\n    *   אלו הם בדיוק האיבר הראשון בכל אחד מהדפים של המערך. כל גישה בתוך הלולאה הפנימית מתבצעת לדף ייחודי (כל פעם לדף הבא מתוך 1024 הדפים שהמערך תופס).\n    *   מספר הגישות בלולאה הפנימית הוא `ARRAY_SIZE / (PAGE_SIZE / INT_SIZE) = (1024 * 1024) / 1024 = 1024` גישות.\n\n4.  **חישוב TLB Misses:**\n    *   גודל ה-TLB הוא 16 כניסות.\n    *   בכל איטרציה של הלולאה החיצונית (`i`), הלולאה הפנימית ניגשת ל-1024 דפים ייחודיים שונים בזיכרון.\n    *   מכיוון ש-1024 (מספר הדפים הייחודיים הנגשים) גדול בהרבה מ-16 (גודל ה-TLB), ה-TLB יחווה \"Thrashing\".\n    *   לאחר 16 הגישות הראשונות בלולאה הפנימית (עבור `i` מסוים), ה-TLB יתמלא. בכל גישה נוספת לדף חדש, יתרחש TLB miss ודף ישן (ה-LRU) ייזרק מה-TLB.\n    *   כאשר הלולאה החיצונית מתקדמת לאיטרציה הבאה (`i+1`), ה-TLB מכיל את ה-16 הדפים האחרונים שנגשו אליהם באיטרציה הקודמת של הלולאה הפנימית. אולם, הלולאה הפנימית תתחיל שוב מ-`arr[0]` (דף 0), ותעבור שוב על 1024 הדפים. אף אחד מהדפים הללו לא יימצא ב-TLB מהאיטרציה הקודמת של הלולאה החיצונית, שכן ה-TLB קטן מדי בכדי להחזיק את כל 1024 הדפים לאורך כל איטרציות הלולאה החיצונית.\n    *   לכן, בכל גישה לזיכרון בתוך הלולאה הפנימית, יתרחש TLB miss.\n    *   סה\"כ TLB misses = (מספר איטרציות הלולאה החיצונית) * (מספר גישות בלולאה הפנימית)\n    *   סה\"כ TLB misses = `1024 * 1024 = 1,048,576`.\n\n5.  **חישוב גישות לטבלאות הדפים (Page Table Walks):**\n    *   כל TLB miss גורם לביצוע Page Table Walk.\n    *   עבור טבלת דפים דו-שכבתית, כל Page Table Walk דורש שתי גישות לזיכרון הפיזי:\n        *   גישה אחת לטבלת הדפים של השכבה הראשונה (P1).\n        *   גישה אחת לטבלת הדפים של השכבה השנייה (P2).\n    *   סה\"כ גישות לטבלאות הדפים = (סה\"כ TLB misses) * (מספר גישות זיכרון לכל Page Table Walk).\n    *   סה\"כ גישות לטבלאות הדפים = `1,048,576 * 2 = 2,097,152`."}, "difficulty_estimation": "Hard", "_source_file": "0500__Memory_Management__CodeAnalysis__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:11:48", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Memory Management", "Virtual Memory", "Paging", "TLB", "Page Faults"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי עם חלוקה לדפים (paging) ובמנגנון דפדוף לפי דרישה (demand paging). למערכת יש TLB (Translation Lookaside Buffer) המטמון תרגומי כתובות.\n\n**מאפייני המערכת:**\n*   **מרחב כתובות וירטואלי:** 16 ביטים.\n*   **מרחב כתובות פיזי:** 16 ביטים.\n*   **גודל דף:** 256 בתים (0x100). המשמעות היא שה-offset הוא 8 ביטים, ומספר הדף הווירטואלי (VPN) או הפיזי (PPN) הוא 8 ביטים.\n*   **טבלת דפים (Page Table):** כל כניסה בטבלת הדפים (PTE) מכילה את הביטים הבאים: Valid (V), Dirty (D), Referenced (R) ואת מספר הדף הפיזי (PPN).\n*   **TLB:** מכיל 4 כניסות, אסוציאטיבי מלא (fully associative) ומשתמש במדיניות החלפה LRU (Least Recently Used).\n*   **טיפול בתקלות דף (Page Faults):** כאשר מתרחשת תקלת דף (כלומר, ביט V=0 ב-PTE), מוקצה דף פיזי חדש. לצורך הבעיה, הניחו כי PPN חדשים מוקצים באופן סדרתי החל מ-0x14 (כלומר, 0x14, 0x15, וכו'). ביט V של ה-PTE החדש יוגדר ל-1, וביטי D ו-R יוגדרו ל-0 בתחילה (אלא אם הגישה היא כתיבה, שאז D יוגדר ל-1).\n\n**מצב התחלתי:**\n*   **TLB:** ריק לחלוטין.\n*   **טבלת דפים (חלקית):**\n    | VPN  | V | D | R | PPN   |\n    |------|---|---|---|-------|\n    | 0x00 | 1 | 0 | 0 | 0x10  |\n    | 0x01 | 1 | 0 | 0 | 0x11  |\n    | 0x02 | 0 | 0 | 0 | (לא תקף)|\n    | 0x03 | 1 | 0 | 0 | 0x12  |\n    | 0x04 | 0 | 0 | 0 | (לא תקף)|\n    | 0x05 | 1 | 0 | 0 | 0x13  |\n    (כל שאר ה-VPNs אינם תקפים (V=0) ו-PPN לא מוגדר).\n\n**רצף גישות לזיכרון:**\nעקבו אחר רצף הגישות לזיכרון המפורט בקוד הבא. עבור כל גישה, ציין את הפרטים הבאים:\n1.  הכתובת הווירטואלית (VA) המבוקשת.\n2.  מספר הדף הווירטואלי (VPN) וה-offset.\n3.  האם זו פגיעה (Hit) או החטאה (Miss) ב-TLB? נמק.\n4.  אם זו החטאה ב-TLB, האם זו פגיעה (Hit) או החטאה (Miss) בטבלת הדפים? (כלומר, האם מתרחשת תקלת דף?) נמק.\n5.  הכתובת הפיזית (PA) המתקבלת לאחר התרגום.\n6.  כיצד משתנים מצבי ה-TLB וטבלת הדפים (כולל ביטי V, D, R) כתוצאה מהגישה. הצג את מצב ה-TLB הסופי ואת השינויים בטבלת הדפים הרלוונטיים.\n", "code_snippet": "void simulate_memory_accesses() {\n    // Initial Page Table State (simplified representation):\n    // VPN | Valid | Dirty | Referenced | PPN\n    // ---------------------------------------\n    // 0x00 |   1   |   0   |     0      | 0x10\n    // 0x01 |   1   |   0   |     0      | 0x11\n    // 0x02 |   0   |   0   |     0      | (invalid)\n    // 0x03 |   1   |   0   |     0      | 0x12\n    // 0x04 |   0   |   0   |     0      | (invalid)\n    // 0x05 |   1   |   0   |     0      | 0x13\n    // (Other VPNs are initially invalid)\n\n    // Initial TLB State: Empty\n\n    // Memory Access Sequence:\n    read_memory(0x0050); // Read operation at VA 0x0050\n    write_memory(0x01A0); // Write operation at VA 0x01A0\n    read_memory(0x03F0);  // Read operation at VA 0x03F0\n    read_memory(0x0020);  // Read operation at VA 0x0020\n    write_memory(0x0210); // Write operation at VA 0x0210\n    read_memory(0x05B0);  // Read operation at VA 0x05B0\n    read_memory(0x0150);  // Read operation at VA 0x0150\n    write_memory(0x0270); // Write operation at VA 0x0270\n}\n", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "להלן פירוט הגישות לזיכרון וכיצד הן משפיעות על ה-TLB וטבלת הדפים:\n\n**מצב התחלתי:**\n*   **TLB:** ריק.\n*   **טבלת דפים (PT):**\n    | VPN  | V | D | R | PPN   |\n    |------|---|---|---|-------|\n    | 0x00 | 1 | 0 | 0 | 0x10  |\n    | 0x01 | 1 | 0 | 0 | 0x11  |\n    | 0x02 | 0 | 0 | 0 | N/A   |\n    | 0x03 | 1 | 0 | 0 | 0x12  |\n    | 0x04 | 0 | 0 | 0 | N/A   |\n    | 0x05 | 1 | 0 | 0 | 0x13  |\n\n**מספר דף פיזי פנוי הבא:** 0x14\n\n---\n\n**1. גישה: `read_memory(0x0050)`**\n*   **VA:** 0x0050\n*   **VPN:** 0x00, **Offset:** 0x50\n*   **TLB:** החטאה (Miss) – ה-TLB ריק.\n*   **טבלת דפים:** פגיעה (Hit) – PTE עבור 0x00 (V=1, PPN=0x10). אין תקלת דף. ביט R ב-PTE מוגדר ל-1.\n*   **PA:** 0x1050 (0x10 << 8 | 0x50)\n*   **עדכון מצב:**\n    *   **TLB:** נוספת כניסה (0x00, 0x10, V=1, D=0, R=1). הופכת ל-MRU.\n        TLB: `[(0x00, 0x10, V=1, D=0, R=1)]` (MRU)\n    *   **PT (VPN 0x00):** V=1, D=0, R=1, PPN=0x10\n\n---\n\n**2. גישה: `write_memory(0x01A0)`**\n*   **VA:** 0x01A0\n*   **VPN:** 0x01, **Offset:** 0xA0\n*   **TLB:** החטאה (Miss) – VPN 0x01 אינו ב-TLB.\n*   **טבלת דפים:** פגיעה (Hit) – PTE עבור 0x01 (V=1, PPN=0x11). אין תקלת דף. ביט R ב-PTE מוגדר ל-1, וביט D מוגדר ל-1 (כתיבה).\n*   **PA:** 0x11A0 (0x11 << 8 | 0xA0)\n*   **עדכון מצב:**\n    *   **TLB:** נוספת כניסה (0x01, 0x11, V=1, D=1, R=1). הופכת ל-MRU.\n        TLB: `[(0x00, 0x10, V=1, D=0, R=1) (LRU), (0x01, 0x11, V=1, D=1, R=1) (MRU)]`\n    *   **PT (VPN 0x01):** V=1, D=1, R=1, PPN=0x11\n\n---\n\n**3. גישה: `read_memory(0x03F0)`**\n*   **VA:** 0x03F0\n*   **VPN:** 0x03, **Offset:** 0xF0\n*   **TLB:** החטאה (Miss) – VPN 0x03 אינו ב-TLB.\n*   **טבלת דפים:** פגיעה (Hit) – PTE עבור 0x03 (V=1, PPN=0x12). אין תקלת דף. ביט R ב-PTE מוגדר ל-1.\n*   **PA:** 0x12F0 (0x12 << 8 | 0xF0)\n*   **עדכון מצב:**\n    *   **TLB:** נוספת כניסה (0x03, 0x12, V=1, D=0, R=1). הופכת ל-MRU.\n        TLB: `[(0x00, 0x10, V=1, D=0, R=1) (LRU), (0x01, 0x11, V=1, D=1, R=1), (0x03, 0x12, V=1, D=0, R=1) (MRU)]`\n    *   **PT (VPN 0x03):** V=1, D=0, R=1, PPN=0x12\n\n---\n\n**4. גישה: `read_memory(0x0020)`**\n*   **VA:** 0x0020\n*   **VPN:** 0x00, **Offset:** 0x20\n*   **TLB:** פגיעה (Hit) – VPN 0x00 נמצא ב-TLB. PPN=0x10. ביט R ב-PTE (וב-TLB) מוגדר ל-1 (כבר 1).\n*   **PA:** 0x1020 (0x10 << 8 | 0x20)\n*   **עדכון מצב:**\n    *   **TLB:** הכניסה (0x00, 0x10, V=1, D=0, R=1) מועברת למיקום ה-MRU.\n        TLB: `[(0x01, 0x11, V=1, D=1, R=1) (LRU), (0x03, 0x12, V=1, D=0, R=1), (0x00, 0x10, V=1, D=0, R=1) (MRU)]`\n    *   **PT (VPN 0x00):** ללא שינוי (V=1, D=0, R=1, PPN=0x10).\n\n---\n\n**5. גישה: `write_memory(0x0210)`**\n*   **VA:** 0x0210\n*   **VPN:** 0x02, **Offset:** 0x10\n*   **TLB:** החטאה (Miss) – VPN 0x02 אינו ב-TLB.\n*   **טבלת דפים:** החטאה (Miss) – PTE עבור 0x02 (V=0). **תקלת דף!** מוקצה דף פיזי חדש: PPN 0x14.\n*   **PA:** 0x1410 (0x14 << 8 | 0x10)\n*   **עדכון מצב:**\n    *   **TLB:** נוספת כניסה (0x02, 0x14, V=1, D=1, R=1). הופכת ל-MRU. ה-TLB כעת מלא.\n        TLB: `[(0x01, 0x11, V=1, D=1, R=1) (LRU), (0x03, 0x12, V=1, D=0, R=1), (0x00, 0x10, V=1, D=0, R=1), (0x02, 0x14, V=1, D=1, R=1) (MRU)]`\n    *   **PT (VPN 0x02):** V=1, D=1, R=1, PPN=0x14. (ביט D מוגדר ל-1 עקב פעולת כתיבה).\n    *   **מספר דף פיזי פנוי הבא:** 0x15\n\n---\n\n**6. גישה: `read_memory(0x05B0)`**\n*   **VA:** 0x05B0\n*   **VPN:** 0x05, **Offset:** 0xB0\n*   **TLB:** החטאה (Miss) – VPN 0x05 אינו ב-TLB.\n*   **טבלת דפים:** פגיעה (Hit) – PTE עבור 0x05 (V=1, PPN=0x13). אין תקלת דף. ביט R ב-PTE מוגדר ל-1.\n*   **PA:** 0x13B0 (0x13 << 8 | 0xB0)\n*   **עדכון מצב:**\n    *   **TLB:** ה-TLB מלא. כניסת ה-LRU (0x01, 0x11) מוצאת. נוספת כניסה (0x05, 0x13, V=1, D=0, R=1). הופכת ל-MRU.\n        TLB: `[(0x03, 0x12, V=1, D=0, R=1) (LRU), (0x00, 0x10, V=1, D=0, R=1), (0x02, 0x14, V=1, D=1, R=1), (0x05, 0x13, V=1, D=0, R=1) (MRU)]`\n    *   **PT (VPN 0x05):** V=1, D=0, R=1, PPN=0x13\n\n---\n\n**7. גישה: `read_memory(0x0150)`**\n*   **VA:** 0x0150\n*   **VPN:** 0x01, **Offset:** 0x50\n*   **TLB:** החטאה (Miss) – VPN 0x01 הוצא מה-TLB בצעד הקודם.\n*   **טבלת דפים:** פגיעה (Hit) – PTE עבור 0x01 (V=1, PPN=0x11). אין תקלת דף. ביט R ב-PTE מוגדר ל-1 (כבר 1).\n*   **PA:** 0x1150 (0x11 << 8 | 0x50)\n*   **עדכון מצב:**\n    *   **TLB:** ה-TLB מלא. כניסת ה-LRU (0x03, 0x12) מוצאת. נוספת כניסה (0x01, 0x11, V=1, D=1, R=1). הופכת ל-MRU.\n        TLB: `[(0x00, 0x10, V=1, D=0, R=1) (LRU), (0x02, 0x14, V=1, D=1, R=1), (0x05, 0x13, V=1, D=0, R=1), (0x01, 0x11, V=1, D=1, R=1) (MRU)]`\n    *   **PT (VPN 0x01):** ללא שינוי (V=1, D=1, R=1, PPN=0x11).\n\n---\n\n**8. גישה: `write_memory(0x0270)`**\n*   **VA:** 0x0270\n*   **VPN:** 0x02, **Offset:** 0x70\n*   **TLB:** פגיעה (Hit) – VPN 0x02 נמצא ב-TLB. PPN=0x14. ביט R ב-PTE (וב-TLB) מוגדר ל-1 (כבר 1), וביט D מוגדר ל-1 (כבר 1).\n*   **PA:** 0x1470 (0x14 << 8 | 0x70)\n*   **עדכון מצב:**\n    *   **TLB:** הכניסה (0x02, 0x14, V=1, D=1, R=1) מועברת למיקום ה-MRU.\n        TLB: `[(0x00, 0x10, V=1, D=0, R=1) (LRU), (0x05, 0x13, V=1, D=0, R=1), (0x01, 0x11, V=1, D=1, R=1), (0x02, 0x14, V=1, D=1, R=1) (MRU)]`\n    *   **PT (VPN 0x02):** ללא שינוי (V=1, D=1, R=1, PPN=0x14).\n"}, "difficulty_estimation": "Hard", "_source_file": "0501__Memory_Management__CodeAnalysis__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:12:44", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Memory Management", "Virtual Memory", "Paging", "TLB", "Page Faults"], "content": {"text": "נתונה מערכת זיכרון וירטואלי בעלת המאפיינים הבאים:\n*   כתובות וירטואליות בגודל 32 סיביות.\n*   גודל דף: 4 קילובייט (KB).\n*   טבלת דפים דו-שכבתית (Two-level Page Table).\n    *   אינדקס לטבלת דפי ספריות (Page Directory Index - PDI) בגודל 10 סיביות.\n    *   אינדקס לטבלת דפים (Page Table Index - PTI) בגודל 10 סיביות.\n    *   קיזוז (Offset) בגודל 12 סיביות.\n*   TLB (Translation Lookaside Buffer) בגודל 4 כניסות, אסוציאטיבי מלא (Fully Associative), עם מדיניות החלפה LRU (Least Recently Used). ה-TLB ריק בתחילת הריצה.\n*   כל טבלאות הדפים (Page Directory ו-Page Tables) נמצאות בזיכרון הפיזי ונגישות מיד (כלומר, אין Page Faults בגין גישה לטבלאות דפים).\n*   כל דפי הנתונים (Data Pages) אינם נמצאים בזיכרון הפיזי בתחילת הריצה. גישה ראשונה לדף נתונים כלשהו תגרום ל-Page Fault, ולאחר מכן הדף יטען לזיכרון הפיזי. מסגרות דפים פיזיות (PPNs) מוקצות באופן סדרתי החל מ-PPN 100.\n\nנתונה רשימת הגישות לכתובות וירטואליות הבאות:\n\nעקבו אחר רצף הגישות לזיכרון הווירטואלי הנתון. עבור כל גישה, ציינו האם היא גורמת ל-TLB Hit או TLB Miss, והאם היא גורמת ל-Page Fault.\nבסיום, סכמו את המספר הכולל של TLB Misses ואת המספר הכולל של Page Faults.\nיש לפרט את מצב ה-TLB (אילו כניסות קיימות ובאיזה סדר LRU) בכל שלב.", "code_snippet": "unsigned int addresses[] = {\n    0x00001000,\n    0x00002000,\n    0x00001004,\n    0x00003000,\n    0x00004000,\n    0x00001008,\n    0x00005000,\n    0x0000200C,\n    0x00006000,\n    0x00003010\n};", "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "ניתוח הגישות לזיכרון:\n\nנתונים:\n*   גודל VA: 32 ביט.\n*   גודל דף: 4KB = 2^12 בתים.\n*   Offset: 12 ביט.\n*   VPN (Virtual Page Number) = VA >> 12.\n*   TLB בגודל 4 כניסות, LRU.\n*   בתחילה, TLB ריק.\n*   בתחילה, אף דף נתונים אינו בזיכרון פיזי. PPNs מתחילים מ-100.\n\n| גישה | כתובת וירטואלית | VPN | מצב TLB (VPN:PPN, מהפחות-עדכני ליותר-עדכני) | TLB Hit/Miss | Page Fault? | PPN שהוקצה | הערות                                                                                                    |\n| :--- | :-------------- | :-- | :----------------------------------------- | :----------- | :---------- | :-------- | :------------------------------------------------------------------------------------------------------- |\n| 1    | `0x00001000`    | 1   | `[]`                                       | Miss         | כן          | 100       | דף 1 אינו ב-TLB, אינו בזיכרון. טוענים ל-PPN 100. TLB: `[1:100]`                                          |\n| 2    | `0x00002000`    | 2   | `[1:100]`                                  | Miss         | כן          | 101       | דף 2 אינו ב-TLB, אינו בזיכרון. טוענים ל-PPN 101. TLB: `[1:100, 2:101]`                                   |\n| 3    | `0x00001004`    | 1   | `[2:101, 1:100]`                           | Hit          | לא          |           | דף 1 נמצא ב-TLB. מעדכנים LRU. TLB: `[2:101, 1:100]`                                                      |\n| 4    | `0x00003000`    | 3   | `[2:101, 1:100]`                           | Miss         | כן          | 102       | דף 3 אינו ב-TLB, אינו בזיכרון. טוענים ל-PPN 102. TLB: `[2:101, 1:100, 3:102]`                             |\n| 5    | `0x00004000`    | 4   | `[2:101, 1:100, 3:102]`                    | Miss         | כן          | 103       | דף 4 אינו ב-TLB, אינו בזיכרון. טוענים ל-PPN 103. TLB: `[2:101, 1:100, 3:102, 4:103]`                      |\n| 6    | `0x00001008`    | 1   | `[2:101, 3:102, 4:103, 1:100]`             | Hit          | לא          |           | דף 1 נמצא ב-TLB. מעדכנים LRU. TLB: `[2:101, 3:102, 4:103, 1:100]`                                        |\n| 7    | `0x00005000`    | 5   | `[2:101, 3:102, 4:103, 1:100]`             | Miss         | כן          | 104       | דף 5 אינו ב-TLB, אינו בזיכרון. ה-TLB מלא, מוציאים את 2 (LRU). טוענים ל-PPN 104. TLB: `[3:102, 4:103, 1:100, 5:104]` |\n| 8    | `0x0000200C`    | 2   | `[3:102, 4:103, 1:100, 5:104]`             | Miss         | לא          |           | דף 2 אינו ב-TLB, אך הוא בזיכרון (PPN 101). ה-TLB מלא, מוציאים את 3 (LRU). TLB: `[4:103, 1:100, 5:104, 2:101]` |\n| 9    | `0x00006000`    | 6   | `[4:103, 1:100, 5:104, 2:101]`             | Miss         | כן          | 105       | דף 6 אינו ב-TLB, אינו בזיכרון. ה-TLB מלא, מוציאים את 4 (LRU). טוענים ל-PPN 105. TLB: `[1:100, 5:104, 2:101, 6:105]` |\n| 10   | `0x00003010`    | 3   | `[1:100, 5:104, 2:101, 6:105]`             | Miss         | לא          |           | דף 3 אינו ב-TLB, אך הוא בזיכרון (PPN 102). ה-TLB מלא, מוציאים את 1 (LRU). TLB: `[5:104, 2:101, 6:105, 3:102]` |\n\nסיכום:\n*   סה\"כ גישות: 10\n*   סה\"כ TLB Misses: 8\n*   סה\"כ Page Faults: 7 (עבור VPNs 1, 2, 3, 4, 5, 6)"}, "difficulty_estimation": "Hard", "_source_file": "0502__Memory_Management__CodeAnalysis__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:13:16", "_subject": "Virtualization"}, {"id": 101, "type": "CodeAnalysis", "topic": ["Memory Management", "Dynamic Allocation", "Heap Management", "Fragmentation", "Coalescing"], "content": {"text": "נתונה תוכנית המממשת מנהל זיכרון פשוט משלה, הכולל פונקציות `my_malloc` ו-`my_free`. המנהל משתמש ברשימה מקושרת של בלוקים פנויים. הפונקציה `my_malloc` מיישמת אסטרטגיית \"ההתאמה הראשונה\" (First-Fit) ומפצלת בלוקים גדולים מדי. הפונקציה `my_free` מוסיפה בלוקים פנויים בחזרה לרשימה הממוינת לפי כתובת ומנסה לאחד בלוקים סמוכים פיזית (coalescing) כדי למנוע פיצול חיצוני (external fragmentation).\n\nקראו בעיון את הקוד המצורף וענו על השאלות הבאות:\n\n1.  **זיהוי באג ודוגמה:** תארו תרחיש ספציפי (רצף של קריאות ל-`my_malloc` ו-`my_free` עם גדלים מסוימים) שבו הבאג בפונקציה `my_free` מוביל לפיצול חיצוני שניתן היה למנוע. הסבירו מדוע הפיצול מתרחש בתרחיש שתיארתם.\n2.  **הסבר הבאג:** הסבירו לעומק את שורש הבאג בקוד של `my_free` שגורם לפיצול החיצוני. התייחסו לאופן שבו לולאת האיחוד עובדת ומהי הבעיה בה.\n3.  **תיקון הבאג:** הציעו תיקון לקוד של `my_free` שיפתור את הבאג שתואר לעיל, ויבטיח איחוד מלא של בלוקים סמוכים פיזית. כתבו את קטע הקוד המתוקן.", "code_snippet": "#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h> // For sbrk\n\n// Define block structure\ntypedef struct Block {\n    size_t size; // Total size of the block including header\n    struct Block *next;\n    // Data area starts here\n} Block;\n\n#define BLOCK_HEADER_SIZE sizeof(Block)\n#define ALIGNMENT 8 // Align all allocations to 8 bytes\n\n// Global head of the free list.\nBlock *free_list_head = NULL;\n\n// Helper to align size\nsize_t align_size(size_t size) {\n    return (size + ALIGNMENT - 1) & ~(ALIGNMENT - 1);\n}\n\n// Custom malloc - first fit\nvoid* my_malloc(size_t size) {\n    size = align_size(size);\n    size_t total_required_size = size + BLOCK_HEADER_SIZE;\n\n    Block *current = free_list_head;\n    Block *prev = NULL;\n\n    while (current != NULL) {\n        if (current->size >= total_required_size) {\n            // Found a suitable block\n            if (current->size - total_required_size >= BLOCK_HEADER_SIZE + ALIGNMENT) { // If enough space to split\n                // Split the block\n                Block *new_free_block = (Block*)((char*)current + total_required_size);\n                new_free_block->size = current->size - total_required_size;\n                new_free_block->next = current->next; // The new free block inherits the rest of the list\n\n                current->size = total_required_size; // 'current' is now the allocated block\n\n                // Update the free list: 'new_free_block' replaces 'current'\n                if (prev == NULL) {\n                    free_list_head = new_free_block;\n                } else {\n                    prev->next = new_free_block;\n                }\n            } else { // Not enough space to split, take the whole block\n                // Remove 'current' from the free list\n                if (prev == NULL) {\n                    free_list_head = current->next;\n                } else {\n                    prev->next = current->next;\n                }\n            }\n            current->next = NULL; // Mark allocated block's next as NULL for safety/clarity\n            return (void*)((char*)current + BLOCK_HEADER_SIZE);\n        }\n        prev = current;\n        current = current->next;\n    }\n\n    // No suitable block found, extend heap\n    Block *new_block = (Block*)sbrk(total_required_size);\n    if (new_block == (void*)-1) {\n        return NULL; // sbrk failed\n    }\n    new_block->size = total_required_size;\n    new_block->next = NULL; // This block is fully allocated, not part of free list yet\n\n    return (void*)((char*)new_block + BLOCK_HEADER_SIZE);\n}\n\n// Custom free with merging logic (BUGGY VERSION for the question)\nvoid my_free(void *ptr) {\n    if (ptr == NULL) return;\n\n    Block *block_to_free = (Block*)((char*)ptr - BLOCK_HEADER_SIZE);\n    \n    // Insert the block into the free list, keeping it sorted by address\n    Block *current_node = free_list_head;\n    Block *prev_node = NULL;\n\n    while (current_node != NULL && current_node < block_to_free) {\n        prev_node = current_node;\n        current_node = current_node->next;\n    }\n\n    if (prev_node == NULL) { // Insert at head\n        block_to_free->next = free_list_head;\n        free_list_head = block_to_free;\n    } else { // Insert in middle or at end\n        block_to_free->next = current_node;\n        prev_node->next = block_to_free;\n    }\n\n    // Now, attempt to merge adjacent free blocks in a single pass.\n    // This is where the bug lies for the question.\n    current_node = free_list_head;\n    while (current_node != NULL && current_node->next != NULL) {\n        // Check if current_node and its successor are physically adjacent\n        if ((char*)current_node + current_node->size == (char*)current_node->next) {\n            // Merge current_node and current_node->next\n            current_node->size += current_node->next->size;\n            current_node->next = current_node->next->next; // Skip the merged block\n            // BUG: After merging, current_node is immediately advanced in the next line,\n            // preventing it from checking if the newly enlarged block can merge with its new successor.\n        } \n        current_node = current_node->next; // BUG: This line executes unconditionally, even after a merge.\n    }\n}"}, "sub_questions": null, "points": 25, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "1.  **זיהוי באג ודוגמה:**\n    נניח מצב התחלתי שבו הזיכרון הפנוי מכיל שלושה בלוקים סמוכים פיזית (A, B, C) שמופיעים ברשימה המקושרת בסדר פיזי:\n    `free_list_head -> [Block A, size=X] -> [Block B, size=Y] -> [Block C, size=Z] -> NULL`\n    (כאשר A, B, C הם בלוקים סמוכים פיזית בזיכרון, וגודלם כולל את ה-header). נניח ש-X, Y, Z מספיק גדולים.\n    \n    כאשר לולאת האיחוד ב-`my_free` רצה:\n    1.  `current_node = A`. `current_node->next = B`. נניח ש-A ו-B סמוכים פיזית.\n        *   מתבצע איחוד: `A->size` גדל (לכלול את B), ו-`A->next` מצביע כעת על `C`. הרשימה נראית כעת: `free_list_head -> [Block A+B] -> [Block C] -> NULL`.\n        *   **הבאג:** שורת `current_node = current_node->next;` מתבצעת מיד לאחר האיחוד, מכיוון שהיא מחוץ לתנאי ה-`if`.\n            לכן, `current_node` מקודם ל-`C`.\n    2.  `current_node = C`. `current_node->next = NULL`. הלולאה מסתיימת.\n    \n    **תוצאה:** הבלוקים A ו-B אוחדו בהצלחה לבלוק גדול אחד `A+B`. עם זאת, הבלוק `C` נשאר בלוק נפרד, למרות שהוא סמוך פיזית לבלוק `A+B`. נוצר פיצול חיצוני: במקום בלוק אחד גדול בגודל `X+Y+Z`, יש לנו שני בלוקים: `A+B` ו-`C`. אם נבקש עכשיו `my_malloc(X+Y+Z-BLOCK_HEADER_SIZE)` (גודל שיתאים ל-`A+B+C` אך לא לכל אחד מהם בנפרד), הבקשה תיכשל למרות שיש מספיק זיכרון פנוי בסך הכל.\n\n2.  **הסבר הבאג:**\n    הבאג טמון בלולאת האיחוד ב-`my_free`. כאשר מתבצע איחוד בין `current_node` לבין `current_node->next`, הבלוק `current_node` גדל ו-`current_node->next` מעודכן לדלג על הבלוק שאוחד. הבעיה היא שאחרי האיחוד, ייתכן ש-`current_node` (שגדל) סמוך פיזית גם לבלוק הבא ברשימה (שהיה במקור `current_node->next->next`). אך שורת `current_node = current_node->next;` מתבצעת באופן בלתי מותנה, כלומר, היא תמיד מקדמת את `current_node` לשלב הבא בלולאה, גם אם הרגע בוצע איחוד. כתוצאה מכך, `current_node` (לאחר שגדל) לא נבדק שוב לאפשרות של איחוד עם הבלוק הבא בתור. למעשה, ברגע ש-`current_node` גדל, הוא צריך לנסות שוב לאחד את עצמו עם הבלוק שאליו הוא מצביע כעת (שבמקור היה הבלוק שאחרי הבלוק שאוחד). הקידום הבלתי מותנה של `current_node` לאחר איחוד גורם לכך שרצף של בלוקים סמוכים פיזית יאוחד לכל היותר לשני בלוקים במקום לבלוק אחד גדול ויחיד.\n\n3.  **תיקון הבאג:**\n    כדי לתקן את הבאג, יש לשנות את לולאת האיחוד כך שאחרי איחוד מוצלח, הבלוק `current_node` יישאר באותה עמדה בלולאה וינסה שוב לבצע איחוד עם הבלוק הבא ברשימה. רק אם לא התרחש איחוד, `current_node` יתקדם לבלוק הבא. בכך, בלוק שגדל יוכל להמשיך ולאחד בלוקים סמוכים נוספים ברצף.\n\n    **קוד מתוקן עבור `my_free`:**\n    ```c\n// Custom free with merging logic (FIXED VERSION)\nvoid my_free(void *ptr) {\n    if (ptr == NULL) return;\n\n    Block *block_to_free = (Block*)((char*)ptr - BLOCK_HEADER_SIZE);\n    \n    // Insert the block into the free list, keeping it sorted by address\n    Block *current_node_for_insertion = free_list_head;\n    Block *prev_node_for_insertion = NULL;\n\n    while (current_node_for_insertion != NULL && current_node_for_insertion < block_to_free) {\n        prev_node_for_insertion = current_node_for_insertion;\n        current_node_for_insertion = current_node_for_insertion->next;\n    }\n\n    if (prev_node_for_insertion == NULL) { // Insert at head\n        block_to_free->next = free_list_head;\n        free_list_head = block_to_free;\n    } else { // Insert in middle or at end\n        block_to_free->next = current_node_for_insertion;\n        prev_node_for_insertion->next = block_to_free;\n    }\n\n    // Now, attempt to merge adjacent free blocks.\n    // Iterate and re-check current_node after each merge.\n    Block *current_node = free_list_head; \n    while (current_node != NULL && current_node->next != NULL) {\n        // Check if current_node and its successor are physically adjacent\n        if ((char*)current_node + current_node->size == (char*)current_node->next) {\n            // Merge current_node and current_node->next\n            current_node->size += current_node->next->size;\n            current_node->next = current_node->next->next; // Skip the merged block\n            // IMPORTANT: Do NOT advance current_node here. Re-evaluate it for further merges.\n            // The loop will re-check current_node with its *new* next pointer in the next iteration.\n        } else {\n            // Only advance if no merge happened\n            current_node = current_node->next;\n        }\n    }\n}\n    ```"}, "difficulty_estimation": "Hard", "_source_file": "0503__Memory_Management__CodeAnalysis__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:14:41", "_subject": "Virtualization"}, {"id": 1, "type": "CodeAnalysis", "topic": ["Memory Management", "Virtual Memory", "Page Tables", "Address Translation"], "content": {"text": "נתונה מערכת הפעלה פשוטה המממשת זיכרון וירטואלי עבור תהליכים, כאשר לכל תהליך יש טבלת דפים (page table) משלו. טבלת הדפים מיוצגת כרגע באופן גלובלי לצורך פשטות, והיא מערך של מבנים מסוג `PageTableEntry`. כל כניסה בטבלה מכילה את מספר מסגרת הדף הפיזי (PFN) וביטים נוספים כגון `valid` (האם הדף חוקי) ו-`read_only` (האם הדף מוגן מכתיבה).\n\nהמערכת תומכת בגודל דף קבוע של 4KB. נניח ש-`PAGE_SIZE` מוגדר כ-4096 ו-`PAGE_SHIFT` מוגדר כ-12. הקוד המצורף כולל את הגדרות אלו ואת מבנה ה-`PageTableEntry`.\n\nיש להשלים את הפונקציה `translate_and_access(uint32_t virtual_address, bool is_write)` כך שתבצע את תרגום הכתובת הווירטואלית לכתובת פיזית, תוך כדי טיפול נכון בכשלי דף (page faults) והגנות זיכרון. הפונקציה צריכה לבצע את השלבים הבאים:\n1. חלץ את מספר הדף הווירטואלי (VPN) ואת היסט הדף (offset) מהכתובת הווירטואלית הנתונה. יש לוודא שה-VPN נמצא בטווח חוקי של טבלת הדפים (`PTE_COUNT`). אם לא, יש להדפיס הודעת שגיאה מתאימה ולסיים.\n2. בדוק את כניסת טבלת הדפים המתאימה ל-VPN שהתקבל. אם ביט ה-`valid` של הכניסה כבוי, הדפס הודעת שגיאה המציינת כשל דף מסוג 'Page fault: Invalid page'.\n3. אם הדף חוקי, בדוק את ביט ההגנה `read_only`. אם הפעולה המבוקשת היא כתיבה (`is_write` הוא `true`) וביט `read_only` דלוק, הדפס הודעת שגיאה המציינת כשל דף מסוג 'Page fault: Write to read-only page'.\n4. אם כל הבדיקות עברו בהצלחה, חשב את הכתובת הפיזית המתאימה. הדפס את הכתובת הווירטואלית והפיזית המתורגמת. בנוסף, אם הפעולה הייתה כתיבה, הדפס 'Data written successfully', ואם קריאה, הדפס 'Data read successfully'.\n\nיש להשלים את החלק המסומן ב-`// TODO: Implement this function` בקוד המצורף.", "code_snippet": "#include <stdio.h>\n#include <stdint.h>\n#include <stdbool.h>\n\n#define PAGE_SIZE 4096 // 4KB\n#define PAGE_SHIFT 12\n#define PTE_COUNT (1 << (32 - PAGE_SHIFT)) // For 32-bit virtual addresses\n\n// Page Table Entry structure\ntypedef struct {\n    uint32_t pfn : 20;       // Physical Frame Number (assuming 32-bit physical address, 20 bits for PFN)\n    uint32_t valid : 1;      // Is this page table entry valid?\n    uint32_t read_only : 1;  // Is this page read-only?\n    uint32_t reserved : 10;  // Reserved bits\n} PageTableEntry;\n\n// Simplified Page Table (global for simplicity, in real OS it's per-process)\nPageTableEntry current_page_table[PTE_COUNT];\n\n// Function to simulate initializing a page table entry\nvoid init_pte(uint32_t vpn, uint32_t pfn, bool valid, bool read_only) {\n    if (vpn < PTE_COUNT) {\n        current_page_table[vpn].pfn = pfn;\n        current_page_table[vpn].valid = valid;\n        current_page_table[vpn].read_only = read_only;\n    }\n}\n\n// Function to translate and access a virtual address\nvoid translate_and_access(uint32_t virtual_address, bool is_write) {\n    // TODO: Implement this function\n    // 1. Extract VPN and offset\n    // 2. Check PTE validity\n    // 3. Check write protection\n    // 4. Calculate physical address and print status\n}\n\nint main() {\n    // Initialize some page table entries\n    // VPN 0 -> PFN 100, valid, read/write\n    init_pte(0, 100, true, false);\n    // VPN 1 -> PFN 200, valid, read-only\n    init_pte(1, 200, true, true);\n    // VPN 2 -> PFN 300, valid, read/write (but we won't access it here)\n    init_pte(2, 300, true, false);\n    // VPN 3 -> invalid\n    init_pte(3, 0, false, false);\n\n    printf(\"Testing virtual address translations:\\n\");\n\n    // Test case 1: Valid read access\n    printf(\"\\nTest 1: Read from VA 0x00001234 (VPN 0, Offset 0x234)\\n\");\n    translate_and_access(0x00001234, false);\n\n    // Test case 2: Valid write access\n    printf(\"\\nTest 2: Write to VA 0x00001234 (VPN 0, Offset 0x234)\\n\");\n    translate_and_access(0x00001234, true);\n\n    // Test case 3: Read from read-only page\n    printf(\"\\nTest 3: Read from VA 0x00005678 (VPN 1, Offset 0x1678)\\n\");\n    translate_and_access(0x00005678, false);\n\n    // Test case 4: Write to read-only page (should fail)\n    printf(\"\\nTest 4: Write to VA 0x00005678 (VPN 1, Offset 0x1678)\\n\");\n    translate_and_access(0x00005678, true);\n\n    // Test case 5: Access invalid page (should fail)\n    printf(\"\\nTest 5: Read from VA 0x0000DABC (VPN 3, Offset 0xABC)\\n\");\n    translate_and_access(0x0000DABC, false);\n\n    // Test case 6: Access invalid page (should fail)\n    printf(\"\\nTest 6: Write to VA 0x0000DABC (VPN 3, Offset 0xABC)\\n\n\");\n    translate_and_access(0x0000DABC, true);\n\n    // Test case 7: Access non-existent VPN (should implicitly be invalid)\n    printf(\"\\nTest 7: Read from VA 0x00011000 (VPN 4, Offset 0x0)\\n\");\n    translate_and_access(0x00011000, false);\n\n    return 0;\n}"}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "הפונקציה `translate_and_access` מבצעת את הפעולות הנדרשות לתרגום כתובת וירטואלית לכתובת פיזית, תוך כדי בדיקת הרשאות וטיפול בכשלי דף (page faults).\n\nראשית, היא מחלצת את מספר הדף הווירטואלי (VPN) ואת היסט הדף (offset) מהכתובת הווירטואלית. ה-VPN מתקבל על ידי הזזת הכתובת הווירטואלית ימינה ב-`PAGE_SHIFT` (12 ביטים, שכן גודל דף הוא 4KB). ההיסט מתקבל על ידי ביצוע פעולת AND בין הכתובת הווירטואלית לבין `PAGE_SIZE - 1` (מסכה של 12 הביטים הפחות משמעותיים).\n\nלאחר מכן, הפונקציה בודקת את תקינות ה-VPN (האם הוא בטווח טבלת הדפים). אם הוא מחוץ לטווח, מודפסת הודעת שגיאה מתאימה ומסתיימת הפעולה.\n\nהשלב הבא הוא גישה לכניסה המתאימה בטבלת הדפים (`current_page_table[vpn]`). נבדק ה-`valid` ביט של הכניסה. אם הוא כבוי, הדף אינו קיים בזיכרון הפיזי (או לא הוקצה), ומופק כשל דף מסוג 'Invalid page'.\n\nאם הדף חוקי, נבדקת הרשאת הכתיבה. אם הפעולה המבוקשת היא כתיבה (`is_write` הוא `true`) וביט ה-`read_only` בכניסת טבלת הדפים דלוק, אזי מדובר בניסיון כתיבה לדף מוגן, ומופק כשל דף מסוג 'Write to read-only page'.\n\nאם כל הבדיקות עברו בהצלחה, מחושבת הכתובת הפיזית על ידי שילוב מספר מסגרת הדף הפיזי (PFN) מה-PTE עם היסט הדף. ה-PFN מוזז שמאלה ב-`PAGE_SHIFT` כדי ליצור את החלק העליון של הכתובת הפיזית, ואז מוסיפים אליו את ההיסט.\n\nלבסוף, מודפסת הכתובת הפיזית המתורגמת והודעת סטטוס המציינת אם בוצעה פעולת קריאה או כתיבה מוצלחת.\n\nהקוד המלא של הפונקציה `translate_and_access`:\n```c\nvoid translate_and_access(uint32_t virtual_address, bool is_write) {\n    // 1. Extract VPN and offset\n    uint32_t vpn = virtual_address >> PAGE_SHIFT;\n    uint32_t offset = virtual_address & (PAGE_SIZE - 1);\n\n    // Check if VPN is within bounds of our simplified page table\n    if (vpn >= PTE_COUNT) {\n        printf(\"Page fault: Virtual address 0x%X has an out-of-bounds VPN %u.\\n\", virtual_address, vpn);\n        return;\n    }\n\n    PageTableEntry pte = current_page_table[vpn];\n\n    // 2. Check PTE validity\n    if (!pte.valid) {\n        printf(\"Page fault: Invalid page for virtual address 0x%X (VPN %u).\\n\", virtual_address, vpn);\n        return;\n    }\n\n    // 3. Check write protection\n    if (is_write && pte.read_only) {\n        printf(\"Page fault: Write to read-only page for virtual address 0x%X (VPN %u).\\n\", virtual_address, vpn);\n        return;\n    }\n\n    // 4. If all checks pass, calculate physical address and print status\n    uint32_t physical_address = (pte.pfn << PAGE_SHIFT) | offset;\n    printf(\"Virtual address 0x%X translates to Physical address 0x%X.\\n\", virtual_address, physical_address);\n    if (is_write) {\n        printf(\"Data written successfully.\\n\");\n    } else {\n        printf(\"Data read successfully.\\n\");\n    }\n}\n```"}, "difficulty_estimation": "Hard", "_source_file": "0504__Memory_Management__CodeAnalysis__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "CodeAnalysis", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:15:08", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Virtual Memory", "Memory Management"], "content": {"text": "מהו היתרון העיקרי של שימוש בזיכרון וירטואלי?", "code_snippet": null, "options": ["א. להגדיל את מהירות הגישה לזיכרון הפיזי.", "ב. לאפשר לכל תהליך לראות מרחב כתובות לוגי משלו, שעשוי להיות גדול יותר מהזיכרון הפיזי הזמין.", "ג. למנוע פרגמנטציה פנימית בזיכרון הפיזי.", "ד. לספק למעבד גישה ישירה להתקני קלט/פלט מבלי לערב את הזיכרון הראשי.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. היתרון העיקרי של זיכרון וירטואלי הוא לאפשר לכל תהליך להשתמש במרחב כתובות לוגי עצמאי, שאינו מוגבל על ידי גודל הזיכרון הפיזי הקיים. זה מאפשר להריץ תוכניות גדולות יותר מהזיכרון הפיזי ומספק בידוד והגנה בין תהליכים שונים."}, "difficulty_estimation": "Easy", "_source_file": "0505__Virtual_Memory__MultipleChoice__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:15:17", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Virtual Memory", "Memory Management"], "content": {"text": "מהי המטרה העיקרית של זיכרון וירטואלי?", "code_snippet": null, "options": ["א. להגדיל את מהירות המעבד.", "ב. לאפשר לכל תהליך להשתמש במרחב כתובות זיכרון עצמאי וגדול יותר מהזיכרון הפיזי הזמין.", "ג. למנוע לחלוטין פרגמנטציה פנימית וחיצונית.", "ד. לאחסן את כל קבצי מערכת ההפעלה באופן קבוע בזיכרון הפיזי."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. זיכרון וירטואלי נועד לספק לכל תהליך אשליה של מרחב זיכרון עצמאי וגדול, שלעיתים קרובות גדול יותר מהזיכרון הפיזי הקיים במערכת. זה מאפשר הגנה בין תהליכים, ניצול יעיל יותר של הזיכרון הפיזי ופישוט תכנות היישומים."}, "difficulty_estimation": "Easy", "_source_file": "0506__Virtual_Memory__MultipleChoice__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:15:26", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Virtual Memory"], "content": {"text": "מהו אחד היתרונות המרכזיים של זיכרון וירטואלי?", "code_snippet": null, "options": ["א. להגדיל את מהירות פעולת המעבד (CPU).", "ב. לאפשר לתוכניות להשתמש במרחב כתובות זיכרון גדול יותר ממה שקיים פיזית.", "ג. להפחית את מספר הקריאות למערכת (system calls).", "ד. לשפר את ביצועי כונני ה-SSD."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. זיכרון וירטואלי הוא טכניקה המאפשרת לתוכניות להשתמש במרחב כתובות גדול ורציף, שאינו תלוי בכמות הזיכרון הפיזי הזמין במערכת. הוא משיג זאת על ידי מיפוי כתובות וירטואליות לכתובות פיזיות ושימוש באחסון משני (כמו דיסק) כהרחבה לזיכרון הפיזי."}, "difficulty_estimation": "Easy", "_source_file": "0507__Virtual_Memory__MultipleChoice__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:15:31", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Virtual Memory", "Memory Management"], "content": {"text": "מהי המטרה העיקרית של זיכרון וירטואלי (Virtual Memory)?", "code_snippet": null, "options": ["א. להגדיל את כמות הזיכרון הפיזי הזמין למערכת.", "ב. לאפשר לכל תהליך להשתמש במרחב כתובות לוגי משלו, ולבודד תהליכים אחד מהשני.", "ג. להאיץ את מהירות העיבוד של המעבד על ידי שימוש בזיכרון מטמון (cache).", "ד. לספק דרך מהירה יותר לגשת לקבצים המאוחסנים בדיסק."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. זיכרון וירטואלי מאפשר לכל תהליך להשתמש במרחב כתובות לוגי משלו, שלרוב גדול יותר מהזיכרון הפיזי, ומספק שכבת הפשטה שמבודדת תהליכים זה מזה ומגנה על הזיכרון הפיזי מפני גישה לא חוקית. זה גם מאפשר לטעון רק חלקים מהתהליך לזיכרון הפיזי בעת הצורך."}, "difficulty_estimation": "Easy", "_source_file": "0508__Virtual_Memory__MultipleChoice__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:15:39", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Virtual Memory", "Memory Management"], "content": {"text": "מהו היתרון העיקרי של זיכרון וירטואלי (Virtual Memory)?", "code_snippet": null, "options": ["א. האצת מהירות הגישה לנתונים בזיכרון הפיזי.", "ב. מניעת צורך בשימוש בדיסק הקשיח לאחסון נתונים.", "ג. מתן אשליה של מרחב זיכרון גדול ורציף לכל תהליך, ובידוד בין מרחבי כתובות של תהליכים שונים.", "ד. הקטנת כמות הזיכרון הפיזי הנדרשת להפעלת מערכת ההפעלה.", "ה. כל התשובות האחרות אינן נכונות."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "ג. זיכרון וירטואלי מאפשר למערכת ההפעלה לספק לכל תהליך אשליה של מרחב כתובות פרטי, גדול ורציף, גם אם הזיכרון הפיזי קטן יותר או מפוצל. בנוסף, הוא מאפשר בידוד בין תהליכים, כך שתהליך אחד לא יכול לגשת לזיכרון של תהליך אחר."}, "difficulty_estimation": "Easy", "_source_file": "0509__Virtual_Memory__MultipleChoice__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:15:47", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Virtual Memory", "Memory Management"], "content": {"text": "מהו אחד היתרונות העיקריים של זיכרון וירטואלי?", "code_snippet": null, "options": ["א. הוא מאפשר לתוכניות להשתמש בזיכרון רב יותר מזה הפיזי הקיים במערכת.", "ב. הוא מאיץ את ביצועי המעבד באופן ישיר.", "ג. הוא מפחית את זמן ההחלפה בין תהליכים (context switch).", "ד. הוא משפר את ביצועי הקלט/פלט של המערכת."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "א. זיכרון וירטואלי מאפשר לכל תהליך לראות מרחב כתובות זיכרון גדול ורציף, ובכך מאפשר לתוכניות להשתמש בזיכרון רב יותר מהזיכרון הפיזי הקיים, על ידי שימוש בדיסק כהרחבה לזיכרון הפיזי וניהול יעיל של הזיכרון.", "explanation_hebrew": "א. זיכרון וירטואלי מאפשר לכל תהליך לראות מרחב כתובות זיכרון גדול ורציף, ובכך מאפשר לתוכניות להשתמש בזיכרון רב יותר מהזיכרון הפיזי הקיים, על ידי שימוש בדיסק כהרחבה לזיכרון הפיזי וניהול יעיל של הזיכרון."}, "difficulty_estimation": "Easy", "_source_file": "0510__Virtual_Memory__MultipleChoice__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:15:53", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Virtual Memory"], "content": {"text": "מהי המטרה העיקרית של זיכרון וירטואלי?", "code_snippet": null, "options": ["א. לאפשר לתוכניות להשתמש בזיכרון רב יותר מהזיכרון הפיזי הזמין.", "ב. לספק הגנת זיכרון בין תהליכים שונים.", "ג. לפשט את ניהול הזיכרון עבור המתכנתים על ידי מתן מרחב כתובות לוגי אחיד.", "ד. כל התשובות נכונות.", "ה. אף אחת מהתשובות אינה נכונה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "ד'. זיכרון וירטואלי משיג מספר מטרות חשובות: הוא מאפשר לתוכניות להשתמש במרחב כתובות גדול יותר מהזיכרון הפיזי הזמין (א'), מספק הגנת זיכרון בין תהליכים שונים (ב'), ומפשט את ניהול הזיכרון בכך שכל תהליך מקבל מרחב כתובות וירטואלי פרטי משלו (ג'). לכן, כל התשובות נכונות."}, "difficulty_estimation": "Easy", "_source_file": "0511__Virtual_Memory__MultipleChoice__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:16:00", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Virtual Memory"], "content": {"text": "מהו היתרון העיקרי של זיכרון וירטואלי?", "code_snippet": null, "options": ["א. מגדיל את נפח הזיכרון הפיזי הזמין למערכת.", "ב. מאפשר לתהליכים להשתמש בזיכרון רב יותר ממה שזמין פיזית.", "ג. מאיץ את ביצועי המעבד.", "ד. מונע לחלוטין פרגמנטציה חיצונית.", "ה. אף אחת מהתשובות האחרות אינה נכונה."]}, "sub_questions": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. היתרון העיקרי של זיכרון וירטואלי הוא שהוא מאפשר לתהליכים להשתמש במרחב כתובות לוגי (וירטואלי) גדול יותר מהזיכרון הפיזי הקיים במערכת, ובכך נותן אשליה של זיכרון גדול יותר ומאפשר לטעון רק חלקים רלוונטיים של תהליך לזיכרון הפיזי לפי הצורך."}, "difficulty_estimation": "Easy", "_source_file": "0512__Virtual_Memory__MultipleChoice__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:16:07", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Virtual Memory", "Demand Paging", "Memory Management"], "content": {"text": "מהו היתרון המרכזי של שימוש במנגנון דפדוף לפי דרישה (Demand Paging) במערכות הפעלה מודרניות?", "code_snippet": null, "options": ["א. הוא מבטל לחלוטין את הצורך בזיכרון החלפה (swap space).", "ב. הוא מאפשר טעינה מהירה יותר של תהליכים על ידי טעינת דפים רק כאשר הם נדרשים.", "ג. הוא מקטין את כמות הזיכרון הפיזי הדרושה לכל תהליך באופן קבוע.", "ד. הוא מפחית את פיצול הזיכרון הפנימי (Internal Fragmentation) בזיכרון הראשי.", "ה. הוא משפר את ביצועי גישת הדיסק על ידי שמירת כל הדפים בזיכרון הראשי."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. דפדוף לפי דרישה (Demand Paging) מאפשר למערכת ההפעלה לטעון דפים של תהליך לזיכרון הפיזי רק כאשר הם באמת נדרשים (כלומר, כאשר יש התייחסות אליהם). זה מביא לטעינה מהירה יותר של תהליכים, מכיוון שלא כל התהליך נטען לזיכרון בזמן ההפעלה, וחוסך זיכרון פיזי על ידי שמירת דפים שאינם בשימוש פעיל על הדיסק."}, "difficulty_estimation": "Medium", "_source_file": "0513__Virtual_Memory__MultipleChoice__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:16:17", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Virtual Memory", "Paging", "TLB", "Address Translation"], "content": {"text": "כאשר תהליך ניגש לכתובת וירטואלית, ותרגום הכתובת אינו נמצא ב-TLB (Translation Lookaside Buffer), מהו הצעד הבא שהמערכת תבצע?", "code_snippet": null, "options": ["א. תתרחש מיד תקלת דף (Page Fault).", "ב. המערכת תבדוק את טבלת הדפים (Page Table) בזיכרון הראשי.", "ג. המערכת תטען את הדף מהדיסק לזיכרון הראשי.", "ד. התהליך יופסק (terminated)."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "כאשר מתרחש TLB Miss, המערכת מחפשת את תרגום הכתובת בטבלת הדפים (Page Table) שנמצאת בזיכרון הראשי (RAM). רק אם מתגלה בטבלת הדפים שהדף אינו נמצא בזיכרון הפיזי (כלומר, ה-Present Bit הוא 0), תתרחש תקלת דף (Page Fault). אם הדף נמצא בזיכרון הפיזי, ה-TLB יעודכן והגישה תמשיך."}, "difficulty_estimation": "Medium", "_source_file": "0514__Virtual_Memory__MultipleChoice__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:16:25", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Virtual Memory", "Paging", "TLB", "Memory Management"], "content": {"text": "תהליך מנסה לגשת לכתובת וירטואלית מסוימת. המעבד מחפש את התרגום ב-TLB ומגלה 'פספוס' (TLB miss). לאחר מכן, מערכת ההפעלה מבצעת חיפוש בטבלת הדפים של התהליך ומגלה שהדף קיים בזיכרון הפיזי (RAM) וכי יש לתהליך הרשאה לגשת אליו. מהו הצעד הבא שהמעבד יבצע?", "code_snippet": null, "options": ["א. המעבד יגרום ל-Page Fault, מכיוון שהתרגום לא נמצא ב-TLB.", "ב. המעבד יתרגם את הכתובת הווירטואלית לכתובת פיזית, יטען את התרגום ל-TLB וימשיך בביצוע הפקודה.", "ג. המעבד יגרום ל-Segmentation Fault, כיוון שהתרגום לא נמצא ב-TLB.", "ד. המעבד יבקש ממע' ההפעלה לטעון את הדף מהדיסק לזיכרון הפיזי."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "במקרה של פספוס ב-TLB (TLB miss), המעבד יפנה לטבלת הדפים (Page Table) כדי למצוא את התרגום מהכתובת הווירטואלית לכתובת הפיזית. מכיוון שהדף נמצא בזיכרון הפיזי וקיימות הרשאות גישה, המעבד יבצע את התרגום, יעדכן את ה-TLB עם הרשומה החדשה (כדי לזרז גישות עתידיות לאותו דף), וימשיך בביצוע הפקודה כאילו לא היה פספוס מלכתחילה (אך עם השהיה קלה)."}, "difficulty_estimation": "Medium", "_source_file": "0515__Virtual_Memory__MultipleChoice__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:16:37", "_subject": "Virtualization"}, {"id": 4, "type": "MultipleChoice", "topic": ["Virtual Memory", "Paging", "Demand Paging", "Page Faults"], "content": {"text": "איזו מהטענות הבאות מתארת בצורה הטובה ביותר את היתרון המרכזי של מנגנון דפדוף לפי דרישה (Demand Paging) בזיכרון וירטואלי, המסתמך על Page Faults?", "code_snippet": null, "options": ["א. הוא מאפשר לטעון את כל התוכנית לזיכרון הפיזי מראש, ובכך מונע עיכובים בזמן ריצה.", "ב. הוא מאפשר להריץ תוכניות שגודלן גדול יותר מהזיכרון הפיזי הזמין, על ידי טעינת חלקים מהן רק בעת הצורך.", "ג. הוא מפחית את הצורך ב-TLB (Translation Lookaside Buffer) על ידי אופטימיזציה של גישה לטבלאות דפים.", "ד. הוא מבטיח שכל הנתונים של תהליך יהיו תמיד בזיכרון הפיזי, ובכך משפר את ביצועי ה-CPU.", "ה. הוא מגדיל את ניצול ה-CPU על ידי הקצאת זיכרון פיזי קבוע לכל תהליך, ללא קשר לשימוש בפועל."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב'. דפדוף לפי דרישה מאפשר לטעון דפי זיכרון פיזיים רק כאשר הם נדרשים בפועל (בעת גישה לדף וגרימת Page Fault). יתרון זה מאפשר להריץ תוכניות גדולות יותר מהזיכרון הפיזי הזמין, מכיוון שרק חלק קטן מהתוכנית צריך להיות ב-RAM בכל רגע נתון. זה גם משפר את ניצול הזיכרון הפיזי ומאפשר ריבוי משימות יעיל יותר. שאר האפשרויות אינן נכונות: א' ו-ד' מתארות מצב הפוך מדפדוף לפי דרישה; ג' אינו נכון מכיוון ש-TLB עדיין חיוני לביצועים; ה' אינו יתרון של מנגנון זה ולרוב גם לא המטרה."}, "difficulty_estimation": "Medium", "_source_file": "0516__Virtual_Memory__MultipleChoice__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:16:47", "_subject": "Virtualization"}, {"id": 5, "type": "MultipleChoice", "topic": ["Virtual Memory", "Paging", "Memory Management"], "content": {"text": "מהו התפקיד המרכזי של ה-dirty bit (ביט ה'מלוכלך') ברשומת טבלת דפים (Page Table Entry) במערכת זיכרון וירטואלי?", "code_snippet": null, "options": ["א. לציין אם הדף הנוכחי נמצא בזיכרון הפיזי או בזיכרון המשני (דיסק).", "ב. לציין אם הדף שונה (נכתב אליו) מאז שהובא לזיכרון הפיזי.", "ג. לציין אם לדף יש הרשאות כתיבה (write permission).", "ד. לציין אם הדף נגיש לשימוש על ידי תהליכי משתמש או רק על ידי הליבה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ה-dirty bit משמש כדי לסמן אם דף זיכרון בזיכרון הפיזי שונה (נכתב אליו) מאז שהועלה מהדיסק. מידע זה קריטי עבור אלגוריתמי החלפת דפים (page replacement algorithms). אם דף מלוכלך (dirty), יש לכתוב את תוכנו חזרה לדיסק (לשטח ההחלפה או לקובץ המקורי) לפני שניתן לפנות את מסגרת הזיכרון הפיזי שלו. אם הדף אינו מלוכלך, אין צורך לכתוב אותו לדיסק, מה שחוסך פעולת I/O יקרה."}, "difficulty_estimation": "Medium", "_source_file": "0517__Virtual_Memory__MultipleChoice__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:16:56", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Virtual Memory", "Memory Management", "Process Isolation"], "content": {"text": "איזו מהטענות הבאות מתארת בצורה הטובה ביותר יתרון מרכזי של זיכרון וירטואלי במערכות הפעלה מודרניות?", "code_snippet": null, "options": ["א. מאפשרת ל-CPU לגשת לזיכרון פיזי מהר יותר.", "ב. מגדילה את כמות הזיכרון הפיזי הזמין למערכת.", "ג. מספקת הפרדה והגנה בין מרחבי כתובות של תהליכים שונים.", "ד. מבטלת לחלוטין את הצורך בגישה לדיסק עבור נתוני תהליכים."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "זיכרון וירטואלי מספק לכל תהליך מרחב כתובות פרטי משלו, הממופה לזיכרון פיזי באמצעות טבלאות דפים. מנגנון זה מונע מתהליך אחד לגשת בטעות או בזדון לזיכרון של תהליך אחר, ובכך מספק הפרדה והגנה חיוניות. הוא גם מאפשר להריץ תוכניות גדולות יותר מהזיכרון הפיזי הזמין ומאפשר שיתוף קוד ונתונים בין תהליכים, אך יתרון ההפרדה וההגנה הוא מרכזי ביותר לאמינות ובטיחות המערכת. אפשרות א' אינה נכונה מכיוון שתרגום כתובות מוסיף תקורה, אם כי TLB מפחית אותה. אפשרות ב' אינה נכונה מכיוון שזיכרון וירטואלי אינו מגדיל את הזיכרון הפיזי בפועל, אלא יוצר אשליה של זיכרון גדול יותר. אפשרות ד' אינה נכונה מכיוון שזיכרון וירטואלי עדיין מסתמך על הדיסק (swap space) כדי לנהל דפים שאינם נמצאים ב-RAM."}, "difficulty_estimation": "Medium", "_source_file": "0518__Virtual_Memory__MultipleChoice__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:17:07", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Virtual Memory", "Paging", "TLB", "Page Faults", "Memory Management"], "content": {"text": "כאשר המעבד מנסה לגשת לכתובת וירטואלית, ומתרחש TLB Miss, ולאחר מכן מתברר מטבלת הדפים שהדף אינו נמצא בזיכרון הפיזי (page fault), מהי הפעולה העיקרית שמערכת ההפעלה תבצע כדי לטפל בכך?", "code_snippet": null, "options": ["א. המערכת תבצע החלפת דפים (page replacement) ותעדכן את ה-TLB.", "ב. המערכת תסמן את הדף כ\"לא קיים\" ותסיים את התהליך.", "ג. המערכת תטען את הדף מזיכרון המשני (דיסק) לזיכרון הפיזי, תעדכן את טבלת הדפים וה-TLB, ותאפשר את המשך ביצוע ההוראה.", "ד. המערכת תבקש מהתהליך להקצות זיכרון חדש לדף.", "ה. המערכת תתעלם מהגישה ותמשיך לכתובת הבאה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "כאשר מתרחש page fault, מערכת ההפעלה מטפלת בהפרעה (interrupt) על ידי איתור הדף בזיכרון המשני (דיסק), טעינתו למסגרת פנויה בזיכרון הפיזי (RAM) – ייתכן שתצטרך לבצע החלפת דפים (page replacement) אם אין מסגרות פנויות – עדכון רשומת טבלת הדפים המתאימה כדי שתצביע על המיקום החדש ב-RAM, וכן עדכון ה-TLB (אם הדף נטען למסגרת חדשה או אם ה-TLB עדיין לא הכיל את הרשומה החדשה). לאחר מכן, המערכת חוזרת ומבצעת מחדש את ההוראה שגרמה ל-page fault."}, "difficulty_estimation": "Medium", "_source_file": "0519__Virtual_Memory__MultipleChoice__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:17:21", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Virtual Memory", "Memory Management", "Paging"], "content": {"text": "אחד היתרונות המרכזיים של מנגנון הזיכרון הוירטואלי (Virtual Memory) הוא:", "code_snippet": null, "options": ["א. הגדלת מהירות הגישה לזיכרון הפיזי (RAM).", "ב. מתן אשליה של מרחב זיכרון רציף וגדול לכל תהליך, ללא תלות בזיכרון הפיזי בפועל.", "ג. ביטול מוחלט של הצורך בטעינת קוד תוכניות לזיכרון הראשי.", "ד. מניעת כל סוגי שגיאות הגישה לזיכרון (segmentation faults)."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ב. זיכרון וירטואלי מספק לכל תהליך מרחב כתובות לוגי משלו, שנראה רציף וגדול יותר ממה שקיים בפועל בזיכרון הפיזי. זה מאפשר למערכת ההפעלה למקם דפי זיכרון פיזיים לא רציפים עבור תהליך, ולנהל את הזיכרון בצורה גמישה ויעילה יותר, תוך מתן אשליה של רציפות לתהליך. אפשרות א' אינה נכונה, מכיוון שלרוב זיכרון וירטואלי מוסיף תקורה (overhead) ועלול להאט גישה עקב צורך בחיפושי טבלאות דפים ו-TLB misses. אפשרות ג' אינה נכונה, קוד תוכניות עדיין נטען לזיכרון הראשי. אפשרות ד' אינה נכונה, זיכרון וירטואלי מספק הגנה ועוזר לזהות שגיאות גישה לא חוקיות, אך אינו מונע את התרחשותן באופן מוחלט."}, "difficulty_estimation": "Medium", "_source_file": "0520__Virtual_Memory__MultipleChoice__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-07 22:17:34", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Virtual Memory", "Copy-on-Write", "Paging", "Page Faults"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בזיכרון וירטואלי ובדפים בגודל 4KB. תהליך אב (Parent) מקצה מערך בגודל 1GB ומאתחל אותו. מיד לאחר מכן, תהליך האב מבצע קריאה ל-`fork()`, היוצרת תהליך בן (Child).\nלאחר ה-`fork()`, גם תהליך האב וגם תהליך הבן מבצעים לולאה שלמה על כל המערך בגודל 1GB, וכותבים לכל איבר במערך (לדוגמה: `array[i] = array[i] + 1;`).\nהנח כי המערך כולו היה טעון בזיכרון פיזי לפני קריאת ה-`fork()`, וכי יש מספיק זיכרון פיזי במערכת כדי להכיל את כל הדפים הנדרשים.\nמהו המספר המינימלי של פסיקות דף (page faults) שיתרחשו *עקב פעולות כתיבה* למערך זה, בסך הכל עבור שני התהליכים (אב ובן)?", "code_snippet": null, "options": ["א. 0", "ב. 262,144", "ג. 524,288", "ד. 1,048,576", "ה. לא ניתן לקבוע ללא מידע נוסף"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "ראשית, נחשב את מספר הדפים במערך בגודל 1GB:\n1GB = 1024 MB = 1024 * 1024 KB = 1,048,576 KB.\nמספר הדפים = 1,048,576 KB / 4 KB/דף = 262,144 דפים.\n\nכאשר תהליך האב קורא ל-`fork()`, כל הדפים של המערך משותפים בין האב לבן במצב Copy-on-Write (CoW). המשמעות היא שהדפים יועתקו רק כאשר אחד התהליכים ינסה לכתוב אליהם.\n\nשני התהליכים, האב והבן, מבצעים לולאה שלמה וכותבים לכל איבר במערך. עבור כל דף במערך:\n1.  התהליך הראשון (אב או בן) שיכתוב לאיבר כלשהו בדף זה, יגרום לפסיקת דף CoW. מערכת ההפעלה תיצור עותק פרטי של הדף עבור תהליך זה. זוהי פסיקת דף אחת.\n2.  התהליך השני שיכתוב לאיבר כלשהו באותו דף (שעדיין משותף במובן של כתובת וירטואלית, אך ייתכן שכבר עבר CoW עבור התהליך הראשון), יגרום גם הוא לפסיקת דף CoW. מערכת ההפעלה תיצור עותק פרטי של הדף עבור תהליך זה. זוהי פסיקת דף נוספת.\n\nלכן, כל אחד מ-262,144 הדפים יגרום לשתי פסיקות דף CoW בסך הכל (אחת עבור הכתיבה הראשונה של האב לדף, ואחת עבור הכתיבה הראשונה של הבן לדף). לאחר שדף הפך לפרטי עבור תהליך מסוים, כתיבות נוספות לאותו דף על ידי אותו תהליך לא יגרמו לפסיקות CoW נוספות.\n\nסה\"כ פסיקות דף CoW = 262,144 דפים * 2 פסיקות/דף = 524,288 פסיקות דף."}, "difficulty_estimation": "Hard", "_source_file": "0521__Virtual_Memory__MultipleChoice__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:17:53", "_subject": "Virtualization"}, {"id": 101, "type": "MultipleChoice", "topic": ["Virtual Memory", "Paging", "Page Faults", "Multi-level Page Tables", "TLB"], "content": {"text": "מערכת הפעלה משתמשת בטבלת דפים היררכית בעלת 3 רמות (3-level page table) וכן ב-TLB. תהליך מנסה לגשת לכתובת וירטואלית מסוימת (VA) בכדי לבצע פעולת קריאה. נניח את המצבים הבאים בתחילת הגישה: 1. ה-TLB ריק לגמרי. 2. דף טבלת הדפים ברמה הראשונה (L1 Page Table Page) *נמצא* בזיכרון הפיזי. 3. דף טבלת הדפים ברמה השנייה (L2 Page Table Page) *אינו נמצא* בזיכרון הפיזי. 4. דף טבלת הדפים ברמה השלישית (L3 Page Table Page) *נמצא* בזיכרון הפיזי. 5. דף הנתונים (Data Page) אליו מתייחסת הכתובת VA *אינו נמצא* בזיכרון הפיזי. בהתבסס על תנאים אלו, כמה *פסיקות דף (page faults)* לכל היותר יתרחשו במהלך ניסיון הגישה ל-VA, עד שהנתונים ייטענו לזיכרון הפיזי ויהיו נגישים? (יש להתעלם מפסיקות דף אפשריות שאינן קשורות ישירות לתרגום הכתובת או לטעינת דף הנתונים, למשל עבור מבני נתונים פנימיים של מערכת ההפעלה שאינם חלק מטבלאות הדפים).", "code_snippet": null, "options": ["א. 1", "ב. 2", "ג. 3", "ד. 4", "ה. אף אחת מהתשובות אינה נכונה."]}, "sub_questions": null, "points": 5, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "ננתח את שלבי הגישה לכתובת הוירטואלית:\n1.  **בדיקת TLB**: ה-TLB ריק, ולכן מתרחש TLB Miss. זו אינה פסיקת דף, אלא רק אי-הצלחה בחיפוש במטמון.\n2.  **גישה ל-PTE ברמה 1**: המעבד מנסה לאתר את דף טבלת הדפים ברמה 1 (L1 Page Table Page). נתון שדף זה *נמצא* בזיכרון הפיזי. לכן, אין פסיקת דף בשלב זה. המעבד קורא את ה-PTE המתאים ברמה 1.\n3.  **גישה ל-PTE ברמה 2**: ה-PTE ברמה 1 מפנה לדף טבלת הדפים ברמה 2 (L2 Page Table Page). נתון שדף זה *אינו נמצא* בזיכרון הפיזי. לכן, מתרחשת **פסיקת דף ראשונה**. מערכת ההפעלה מטפלת בפסיקה, טוענת את דף טבלת הדפים ברמה 2 מהדיסק לזיכרון הפיזי, והמעבד יכול כעת לקרוא את ה-PTE המתאים ברמה 2.\n4.  **גישה ל-PTE ברמה 3**: ה-PTE ברמה 2 מפנה לדף טבלת הדפים ברמה 3 (L3 Page Table Page). נתון שדף זה *נמצא* בזיכרון הפיזי. לכן, אין פסיקת דף בשלב זה. המעבד קורא את ה-PTE המתאים ברמה 3.\n5.  **גישה לדף הנתונים**: ה-PTE ברמה 3 מפנה לדף הנתונים (Data Page) עצמו. נתון שדף הנתונים *אינו נמצא* בזיכרון הפיזי. לכן, מתרחשת **פסיקת דף שנייה**. מערכת ההפעלה מטפלת בפסיקה, טוענת את דף הנתונים מהדיסק לזיכרון הפיזי, והמעבד יכול כעת לגשת לנתונים.\n\nבסך הכל, התרחשו 2 פסיקות דף."}, "difficulty_estimation": "Hard", "_source_file": "0522__Virtual_Memory__MultipleChoice__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:18:27", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Virtual Memory", "Paging", "TLB", "Memory Accesses"], "content": {"text": "מערכת הפעלה משתמשת בזיכרון וירטואלי עם כתובות וירטואליות בנות 32 ביט. גודל דף הוא 4KB. טבלת הדפים היא דו-שכבתית, כאשר כל רמת טבלה (גם ה-Page Directory וגם ה-Page Table) מאוחסנת בדף זיכרון אחד. גודל כל כניסה בטבלת הדפים (PTE/PDE) הוא 4 בתים. למערכת קיים TLB בגודל 4 כניסות, המשתמש במדיניות החלפה LRU (Least Recently Used).\nבהנחה שה-TLB ריק בתחילה, וכי כל הדפים הווירטואליים הנדרשים נמצאים בזיכרון הפיזי (אין Page Faults), כמה גישות לזיכרון הפיזי (לצורך טבלת דפים ולצורך הנתונים) יתבצעו בסך הכל עבור סדרת הגישות לכתובות הווירטואליות הבאות?\n\n0x10000, 0x11000, 0x12000, 0x13000, 0x10000, 0x14000, 0x11000", "code_snippet": null, "options": ["א. 15", "ב. 17", "ג. 19", "ד. 21", "ה. 23"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "הסבר:\nכתובת וירטואלית: 32 ביט. גודל דף: 4KB = 2^12 בתים. לכן, 12 הביטים הפחות משמעותיים הם ה-offset בתוך הדף.\nמספר הדף הווירטואלי (VPN) הוא 32-12 = 20 ביט.\nטבלת דפים דו-שכבתית, כאשר כל רמה מאוחסנת בדף אחד (4KB). גודל כניסה 4 בתים.\nמספר כניסות לדף: 4KB / 4 בתים = 1024 = 2^10.\nלכן, 20 ביטים של ה-VPN יחולקו ל-10 ביטים עבור ה-Page Directory Index (PDI) ו-10 ביטים עבור ה-Page Table Index (PTI).\n\nמספר גישות לזיכרון פיזי עבור תרגום כתובת:\n*   TLB Hit: גישה אחת (לנתונים).\n*   TLB Miss (ללא Page Fault): שתי גישות לטבלת הדפים (אחת ל-PDE ב-Page Directory, אחת ל-PTE ב-Page Table), וגישה אחת לנתונים. סך הכל 3 גישות. ה-TLB מתעדכן.\n\nמעקב אחר הגישות וה-TLB (גודל 4, LRU):\nTLB = {} (ריק בתחילה)\n\n1.  **גישה ל-0x10000 (VPN 0x10)**:\n    *   TLB Miss.\n    *   3 גישות לזיכרון (2 לטבלת דפים + 1 לנתונים).\n    *   TLB: {0x10 (MRU)}\n    *   סה\"כ גישות: 3\n\n2.  **גישה ל-0x11000 (VPN 0x11)**:\n    *   TLB Miss.\n    *   3 גישות לזיכרון.\n    *   TLB: {0x10, 0x11 (MRU)}\n    *   סה\"כ גישות: 3 + 3 = 6\n\n3.  **גישה ל-0x12000 (VPN 0x12)**:\n    *   TLB Miss.\n    *   3 גישות לזיכרון.\n    *   TLB: {0x10, 0x11, 0x12 (MRU)}\n    *   סה\"כ גישות: 6 + 3 = 9\n\n4.  **גישה ל-0x13000 (VPN 0x13)**:\n    *   TLB Miss.\n    *   3 גישות לזיכרון.\n    *   TLB: {0x10, 0x11, 0x12, 0x13 (MRU)} (TLB מלא)\n    *   סה\"כ גישות: 9 + 3 = 12\n\n5.  **גישה ל-0x10000 (VPN 0x10)**:\n    *   TLB Hit.\n    *   1 גישה לזיכרון (לנתונים).\n    *   TLB: {0x11, 0x12, 0x13, 0x10 (MRU)} (0x10 הופך ל-MRU)\n    *   סה\"כ גישות: 12 + 1 = 13\n\n6.  **גישה ל-0x14000 (VPN 0x14)**:\n    *   TLB Miss.\n    *   TLB מלא, 0x11 הוא ה-LRU ויוחלף.\n    *   3 גישות לזיכרון.\n    *   TLB: {0x12, 0x13, 0x10, 0x14 (MRU)}\n    *   סה\"כ גישות: 13 + 3 = 16\n\n7.  **גישה ל-0x11000 (VPN 0x11)**:\n    *   TLB Miss.\n    *   TLB מלא, 0x12 הוא ה-LRU ויוחלף.\n    *   3 גישות לזיכרון.\n    *   TLB: {0x13, 0x10, 0x14, 0x11 (MRU)}\n    *   סה\"כ גישות: 16 + 3 = 19\n\nהתשובה הנכונה היא ג. 19."}, "difficulty_estimation": "Hard", "_source_file": "0523__Virtual_Memory__MultipleChoice__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:18:52", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Virtual Memory", "Paging", "Page Tables", "TLB"], "content": {"text": "במערכת הפעלה המשתמשת בזיכרון וירטואלי ובטבלאות דפים מרובות רמות (multi-level page tables), נניח שהכתובת הוירטואלית היא באורך 64 ביט וגודל הדף הוא 4KB. המערכת משתמשת בטבלת דפים בעלת 3 רמות. כל כניסה בטבלת דפים (PTE) היא באורך 8 בתים.\nכאשר מתבצעת גישה לכתובת וירטואלית, מתבצעת בדיקה ראשונית במטמון ה-TLB. אם מתרחש TLB miss, המעבד מבצע הליכה בטבלאות הדפים (page table walk) כדי למצוא את הכתובת הפיזית המתאימה.\nבהנחה שהדף הנדרש כבר נמצא בזיכרון הפיזי (כלומר, אין page fault), וכל רמות טבלת הדפים עצמן נמצאות בזיכרון הראשי (RAM) ונגישות, כמה גישות לזיכרון הראשי (main memory accesses) נדרשות לכל היותר כדי להשלים גישת קריאה אחת לבת בודד מכתובת וירטואלית זו?", "code_snippet": null, "options": ["א. 1", "ב. 2", "ג. 3", "ד. 4", "ה. 5"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ד", "explanation": "ד. 4. כאשר מתרחש TLB miss, המעבד צריך לבצע \"הליכה\" בטבלאות הדפים. במערכת עם 3 רמות של טבלאות דפים, הליך זה דורש: \n1.  גישה לזיכרון הראשי כדי לקרוא את הכניסה בטבלת הדפים ברמה הראשונה (PTE Level 0). \n2.  גישה לזיכרון הראשי כדי לקרוא את הכניסה בטבלת הדפים ברמה השנייה (PTE Level 1). \n3.  גישה לזיכרון הראשי כדי לקרוא את הכניסה בטבלת הדפים ברמה השלישית (PTE Level 2), אשר מכילה את הכתובת הפיזית של הדף הנדרש. \n4.  לאחר מציאת הכתובת הפיזית של הדף, מתבצעת גישה נוספת לזיכרון הראשי כדי לקרוא את הנתון עצמו מהדף הפיזי. \nבסך הכל, נדרשות 3 גישות לזיכרון הראשי עבור ה-page table walk, ועוד גישה אחת עבור הנתון עצמו, מה שמביא לסך של 4 גישות לזיכרון הראשי."}, "difficulty_estimation": "Hard", "_source_file": "0524__Virtual_Memory__MultipleChoice__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:19:08", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Virtual Memory", "Copy-on-Write", "Paging", "Page Faults"], "content": {"text": "תהליך אב (parent process) יוצר תהליך בן (child process) באמצעות קריאת המערכת `fork()`. לאחר מכן, הם חולקים בתחילה דפי זיכרון בשיטת Copy-on-Write (CoW). גודל הדף הוא 4KB. נניח שדף מסוים (דף X) נמצא בזיכרון הפיזי וסומן CoW לאחר ה-`fork()`.\n\nבשלב מאוחר יותר, גם תהליך האב וגם תהליך הבן מנסים לכתוב לדף X (כל אחד כותב לדף בנפרד, ובזמנים שונים). מהו המספר המינימלי של פסיקות דף (page faults) שיתרחשו *עקב פעולות הכתיבה הללו בלבד* על דף X, במערכת המיישמת CoW באופן סטנדרטי?", "code_snippet": null, "options": ["א. 0", "ב. 1", "ג. 2", "ד. 3", "ה. לא ניתן לקבוע ללא מידע נוסף"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ג", "explanation": "התשובה הנכונה היא ג. 2.\nבמערכת המיישמת Copy-on-Write (CoW) באופן סטנדרטי, כאשר תהליך אב מבצע `fork()`, דפי הזיכרון שלו משותפים עם תהליך הבן אך מסומנים במנגנון ניהול הזיכרון (MMU) כקריאה בלבד (read-only) ו-CoW.\nכאשר אחד מהתהליכים (האב או הבן) מנסה לכתוב לדף כזה בפעם הראשונה, מתרחשת פסיקת דף (page fault). מערכת ההפעלה מזהה שהדף מסומן CoW, מקצה מסגרת פיזית חדשה, מעתיקה אליה את תוכן הדף המקורי, ולאחר מכן מעדכנת את טבלת הדפים של התהליך הכותב כך שתצביע על המסגרת החדשה עם הרשאות כתיבה. התהליך השני ממשיך להשתמש בדף המקורי.\nלכן, אם תהליך הבן כותב לדף X ראשון, תתרחש פסיקת דף אחת, ועותק של דף X ייווצר עבור הבן. לאחר מכן, כאשר תהליך האב ינסה לכתוב לדף X (שעבורו הוא עדיין מצביע על הדף המקורי המסומן CoW), תתרחש פסיקת דף נוספת, ועותק נוסף של דף X ייווצר עבור האב. בסך הכל, שתי פסיקות דף ושני עותקים נפרדים של הדף X ייווצרו."}, "difficulty_estimation": "Hard", "_source_file": "0525__Virtual_Memory__MultipleChoice__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:19:24", "_subject": "Virtualization"}, {"id": 101, "type": "MultipleChoice", "topic": ["Virtual Memory", "Paging", "TLB", "Memory Access Time"], "content": {"text": "מערכת הפעלה משתמשת בכתובות וירטואליות בגודל 64 ביט, גודל דף הוא 4KB, וטבלת הדפים היא בת 4 רמות. כל ערך בטבלת הדפים (PTE) הוא בגודל 8 בתים. לזיכרון ה-TLB (Translation Lookaside Buffer) יש שיעור פגיעה (Hit Rate) של 80%. זמן גישה ל-TLB הוא 20 ננו-שניות, וזמן גישה לזיכרון הראשי (RAM) הוא 100 ננו-שניות.\nבהנחה שדף הנתונים המבוקש תמיד נמצא בזיכרון הפיזי, מהו זמן הגישה האפקטיבי הממוצע לנתון בזיכרון?", "code_snippet": null, "options": ["א. 120 ננו-שניות", "ב. 200 ננו-שניות", "ג. 220 ננו-שניות", "ד. 500 ננו-שניות", "ה. 520 ננו-שניות"]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "זמן גישה אפקטיבי ממוצע מחושב כך:\n(שיעור פגיעה ב-TLB * זמן גישה בפגיעה) + (שיעור החמצה ב-TLB * זמן גישה בהחמצה)\n\n1.  **זמן גישה בפגיעה ב-TLB (TLB Hit):**\n    *   גישה ל-TLB: 20 ננו-שניות\n    *   גישה לזיכרון הראשי (לאחר קבלת הכתובת הפיזית מה-TLB): 100 ננו-שניות\n    *   סה\"כ זמן בפגיעה: 20 + 100 = 120 ננו-שניות\n\n2.  **זמן גישה בהחמצה ב-TLB (TLB Miss):**\n    *   גישה ל-TLB (החמצה): 20 ננו-שניות (עלות הבדיקה ב-TLB גם אם היא נכשלת).\n    *   הליכה בטבלת הדפים (Page Table Walk): ישנן 4 רמות בטבלת הדפים. כל רמה דורשת גישה לזיכרון הראשי כדי להביא את ה-PTE המתאים. לכן, 4 * 100 ננו-שניות = 400 ננו-שניות.\n    *   גישה לזיכרון הראשי (לאחר מציאת הכתובת הפיזית בטבלת הדפים): 100 ננו-שניות\n    *   סה\"כ זמן בהחמצה: 20 (TLB) + 400 (Page Table Walk) + 100 (Data Access) = 520 ננו-שניות\n\n3.  **חישוב זמן הגישה האפקטיבי הממוצע:**\n    *   (0.80 * 120 ננו-שניות) + (0.20 * 520 ננו-שניות)\n    *   96 ננו-שניות + 104 ננו-שניות = 200 ננו-שניות"}, "difficulty_estimation": "Hard", "_source_file": "0526__Virtual_Memory__MultipleChoice__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:19:39", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Virtual Memory", "Paging", "TLB", "Page Faults", "Memory Access Patterns"], "content": {"text": "במערכת הפעלה מסוימת, כתובת וירטואלית היא בת 48 ביטים, גודל דף הוא 4KB, וגודל כניסה בטבלת דפים (PTE) הוא 8 בתים. מערכת ההפעלה משתמשת בטבלת דפים מרובת רמות (4 רמות), כאשר כל אינדקס ברמה הוא בן 9 ביטים. ה-TLB הוא אסוציאטיבי לחלוטין (fully associative) עם 64 כניסות ומשתמש באלגוריתם LRU להחלפה. תהליך ניגש באופן סדרתי למערך שלם בגודל `int arr[256 * 1024]` (כלומר, מ-`arr[0]` ועד `arr[256*1024 - 1]`). נניח שהמערך מתחיל בכתובת וירטואלית מיושרת לדף (page-aligned), וכל הדפים המשמשים את המערך אינם נמצאים בזיכרון הפיזי בתחילת הריצה (cold start). כמה סך הכל פספוסי TLB (TLB misses) וכמה סך הכל פסיקות דף (page faults) יתרחשו במהלך הגישה לכל המערך?", "code_snippet": "int arr[256 * 1024];\nfor (int i = 0; i < 256 * 1024; ++i) {\n    arr[i] = i; // Accessing arr[i]\n}", "options": ["א. פספוסי TLB: 256, פסיקות דף: 256", "ב. פספוסי TLB: 256 * 1024, פסיקות דף: 256", "ג. פספוסי TLB: 256 + (256 - 64) * 1024, פסיקות דף: 256", "ד. פספוסי TLB: 256, פסיקות דף: 256 * 4", "ה. אף אחת מהתשובות האחרות אינה נכונה."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "א", "explanation": "חישוב מספר הדפים:\nגודל המערך הוא `256 * 1024` איברים. כל איבר `int` הוא 4 בתים. סך הכל `256 * 1024 * 4 = 1,048,576` בתים (1MB).\nגודל דף הוא 4KB (`4 * 1024 = 4096` בתים).\nמספר הדפים הייחודיים הנדרשים למערך הוא `1MB / 4KB = 1024KB / 4KB = 256` דפים.\n\nפסיקות דף (Page Faults):\nמכיוון שכל 256 הדפים המשמשים את המערך אינם נמצאים בזיכרון הפיזי בתחילת הריצה (cold start), וכל דף ייחודי נגיש לפחות פעם אחת, כל גישה ראשונה לדף תגרום לפסיקת דף. לכן, יתרחשו בדיוק 256 פסיקות דף. כל פסיקת דף טוענת דף אחד לזיכרון הפיזי.\n\nפספוסי TLB (TLB Misses):\nכל דף מכיל `4096 / 4 = 1024` איברי `int`.\nהגישה היא סדרתית מ-`arr[0]` ועד `arr[256*1024 - 1]`.\n\n1.  הגישה הראשונה לכל אחד מ-256 הדפים הייחודיים (לדוגמה, ל-`arr[0]` שהוא בדף 0, ל-`arr[1024]` שהוא בדף 1, וכו') תגרום לפספוס TLB, מכיוון שכניסת טבלת הדפים (PTE) עבור דף זה אינה נמצאת ב-TLB. זה מצטבר ל-256 פספוסי TLB עבור הגישות הראשונות לכל דף.\n2.  לאחר פספוס TLB והטיפול בפסיקת הדף (אם הייתה), ה-PTE של הדף הנדרש נטען ל-TLB.\n3.  ה-TLB מכיל 64 כניסות. לאחר ש-64 הדפים הראשונים (דפים 0 עד 63) נגישים לראשונה, ה-TLB יתמלא. הגישה הראשונה לדף ה-64 (דף מספר 63) תגרום לפספוס TLB ותטען את ה-PTE שלו ל-TLB.\n4.  כאשר ניגשים לדף ה-65 (דף מספר 64), זהו פספוס TLB נוסף. כעת, כניסת ה-LRU ב-TLB (שהיא ה-PTE של דף 0) תפונה, וה-PTE של דף 64 יוכנס במקומה.\n5.  דפוס זה ממשיך: כל גישה ראשונה לדף חדש לאחר שה-TLB התמלא תגרום לפספוס TLB ולפינוי כניסה ב-TLB לפי LRU. עם זאת, מכיוון שהגישה היא סדרתית, וכל 1024 הגישות לאיברים בתוך דף מסוים מתבצעות ברצף לפני המעבר לדף הבא, לאחר שה-PTE של דף נטען ל-TLB, כל 1023 הגישות הנותרות לאיברים באותו דף יהיו פגיעות TLB (TLB hits).\n6.  עד שהתהליך יגיע לדף שה-PTE שלו פונה מה-TLB (לדוגמה, דף 0 פונה כאשר נטען דף 64), התהליך כבר עבר את כל הגישות לדף 0 ולא יחזור אליו יותר בסיבוב זה. לכן, אין פספוסי TLB נוספים עקב פינוי כניסות והצורך בטעינה מחדש של PTE עבור דפים שכבר נגישו בעבר בתוך לולאת הגישה הנוכחית.\n\nלסיכום, סך הכל פספוסי TLB שווים למספר הדפים הייחודיים הנגישים, שהם 256. סך הכל פסיקות דף שוות גם הן למספר הדפים הייחודיים הנגישים, שהם 256.\n\nלכן, התשובה הנכונה היא א'."}, "difficulty_estimation": "Hard", "_source_file": "0527__Virtual_Memory__MultipleChoice__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:20:11", "_subject": "Virtualization"}, {"id": 1, "type": "MultipleChoice", "topic": ["Virtual Memory", "Paging", "TLB", "Address Translation", "Memory Accesses"], "content": {"text": "נתונה מערכת הפעלה המשתמשת בכתובות וירטואליות של 64 ביט, גודל דף של 4KB, ומבנה טבלאות דפים בעל 4 רמות (4-level page table). ה-TLB (Translation Lookaside Buffer) ריק בתחילת ריצת תהליך חדש. נתייחס לפעם הראשונה בה התהליך מבצע את הפעולה הבאה:", "code_snippet": "*(int*)0x00007FFFFFFF0000 = 10;", "options": ["א. הפעולה תוביל ל-page fault מכיוון שה-TLB ריק.", "ב. הפעולה תדרוש בדיוק 5 גישות לזיכרון הראשי (RAM): 4 גישות עבור תרגום הכתובת דרך טבלאות הדפים, וגישה אחת לכתיבת הנתון.", "ג. הפעולה תדרוש בדיוק 4 גישות לזיכרון הראשי (RAM) לצורך תרגום הכתובת בלבד, אך לא תבוצע גישת כתיבה לנתון.", "ד. הפעולה תדרוש גישה אחת בלבד לזיכרון הראשי (RAM) לאחר ה-TLB miss, מכיוון שהדף כבר טעון.", "ה. הפעולה לא תכלול גישות לטבלאות הדפים כלל, מכיוון שהדף כבר נמצא בזיכרון הפיזי."]}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": "ב", "explanation": "התשובה הנכונה היא ב'.\nכאשר הכתובת הוירטואלית `0x00007FFFFFFF0000` נגישה לראשונה:\n1.  **TLB Miss**: ה-TLB ריק, ולכן תתרחש החטאה (miss).\n2.  **Page Table Walk**: המעבד יצטרך לבצע תרגום כתובת דרך טבלאות הדפים. מכיוון שמדובר במערכת 64 ביט עם דפים בגודל 4KB ו-4 רמות של טבלאות דפים, התרגום יכלול 4 גישות לזיכרון הראשי (RAM) כדי לאחזר את רשומות טבלת הדפים השונות (PML4, PDPT, PD, PT) עד למציאת רשומת הדף הסופית (PTE). כל גישה לרמת טבלה היא גישת זיכרון ל-RAM.\n3.  **TLB Update**: לאחר שהכתובת הפיזית נמצאה, ה-TLB יעודכן עם המיפוי החדש.\n4.  **Data Write**: לבסוף, תתבצע גישה נוספת לזיכרון הראשי (RAM) כדי לכתוב את הערך `10` לכתובת הפיזית המתורגמת.\nלכן, סך הכל 4 גישות ל-RAM עבור ה-page table walk + גישה אחת ל-RAM עבור כתיבת הנתון = 5 גישות ל-RAM.\n\nטענה א' שגויה מכיוון ש-TLB miss אינו בהכרח page fault. page fault מתרחש כאשר הדף אינו בזיכרון הפיזי או לא נגיש, ולא רק בגלל שה-TLB ריק.\nטענות ג', ד', ה' שגויות מכיוון שהן אינן מתארות נכונה את מספר הגישות לזיכרון או את התהליך כולו."}, "difficulty_estimation": "Hard", "_source_file": "0528__Virtual_Memory__MultipleChoice__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-07 22:20:32", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Virtual Memory", "Paging", "Memory Management"], "content": {"text": "נתונה מערכת עם זיכרון וירטואלי של 2MB, גודל דף של 4KB, וזיכרון פיזי של 16MB.\nמהם הגדלים של ה-VPN, ה-PFN, וכמה זיכרון פיזי תתפוס טבלת דפים (לינארית) של תהליך, במינימום?\nגודל VPN: ________ גודל PFN: ________ גודל טבלה: ________", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "כתובת וירטואלית היא 21 ביטים (זיכרון וירטואלי 2MB = 2^21 בתים), מתוכם 12 ביטים מייצגים את ההיסט (גודל דף 4KB = 2^12 בתים), לכן נשאר VPN=9 ביטים.\nכתובת פיזית היא 24 ביטים (זיכרון פיזי 16MB = 2^24 בתים), ההיסט זהה – 12 ביטים, לכן נשאר PFN=12 ביטים.\nלכל תהליך יש 512 דפים (2^9) בזיכרון הוירטואלי, כלומר שטבלת הדפים שלו מכילה 512 רשומות. כל רשומה מכילה לפחות 2 בתים (12 ביטים עבור PFN, מעוגל מעלה ל-16 ביטים שהם 2 בתים), לכן הטבלה כולה תתפוס 512 רשומות * 2 בתים/רשומה = 1024 בתים = 1KB."}, "difficulty_estimation": "Easy", "_source_file": "0529__Virtual_Memory__Open__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:20:41", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Virtual Memory", "Memory Management"], "content": {"text": "הסבירו בקצרה מהו זיכרון וירטואלי (Virtual Memory) וציינו שני יתרונות עיקריים בשימוש בו.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "זיכרון וירטואלי הוא מנגנון לניהול זיכרון המאפשר לתהליכים להשתמש במרחב כתובות לוגי גדול יותר ממה שזמין פיזית בזיכרון ה-RAM. הוא יוצר אשליה של זיכרון רציף וגדול לכל תהליך, ומערכת ההפעלה מטפלת במיפוי כתובות וירטואליות לכתובות פיזיות, לרוב באמצעות דפדוף (paging) ושימוש בדיסק כמקום אחסון משני.\n\nשני יתרונות עיקריים בשימוש בזיכרון וירטואלי הם:\n1.  **הרחבת מרחב הכתובות**: מאפשר לתהליכים להשתמש בזיכרון גדול יותר ממה שזמין בזיכרון הפיזי, על ידי שימוש בדיסק כמחסן זמני לחלקים מהזיכרון שאינם בשימוש פעיל.\n2.  **הגנה על זיכרון**: מספק הפרדה בין מרחבי הכתובות של תהליכים שונים, ובכך מונע מתהליך אחד לגשת או לשנות בטעות או בזדון את הזיכרון של תהליך אחר. כל תהליך רואה את הזיכרון שלו כמרחב פרטי."}, "difficulty_estimation": "Easy", "_source_file": "0530__Virtual_Memory__Open__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:20:50", "_subject": "Virtualization"}, {"id": 10, "type": "Open", "topic": ["Virtual Memory", "Memory Management"], "content": {"text": "הסבר בקצרה את המטרה העיקרית של זיכרון וירטואלי (Virtual Memory) במערכות הפעלה, וציין שני יתרונות מרכזיים שהוא מספק.", "code_snippet": null, "options": null}, "sub_questions": null, "points": null, "solution": {"is_present_in_file": true, "correct_option": null, "explanation": "המטרה העיקרית של זיכרון וירטואלי היא לאפשר לתהליכים להשתמש במרחב כתובות גדול יותר מזה הזמין בזיכרון הפיזי, וליצור אשליה של זיכרון רציף ופרטי לכל תהליך.\n\nיתרונות מרכזיים:\n1.  **הרחבת מרחב הכתובות:** מאפשר לתהליכים להשתמש בזיכרון גדול יותר ממה שקיים פיזית במערכת, על ידי שימוש בדיסק כהרחבה לזיכרון הראשי (swapping).\n2.  **הגנה ובידוד:** מספק הפרדה ובידוד בין מרחבי הכתובות של תהליכים שונים, ובכך מונע מתהליך אחד לגשת או לשנות בטעות או בזדון את הזיכרון של תהליך אחר.\n3.  **ניהול זיכרון פשוט יותר למתכנת:** משחרר את המתכנת מהצורך לנהל את הזיכרון הפיזי, ומאפשר לו לכתוב קוד כאילו כל הזיכרון זמין ורציף."}, "difficulty_estimation": "Easy", "_source_file": "0531__Virtual_Memory__Open__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "Open", "_requested_difficulty": "Easy", "_generated_at": "2026-02-07 22:20:58", "_subject": "Virtualization"}]