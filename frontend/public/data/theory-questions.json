[{"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Processes"], "difficulty_estimation": "Easy", "content": {"text": "מהי האשליה העיקרית שמערכת ההפעלה מנסה ליצור עבור תהליכים, בהינתן שישנם מעט מעבדים אך תהליכים רבים?", "code_snippet": null, "options": ["א. שלכל תהליך יש מעבד ייעודי משלו ושהוא רץ במקביל לכל שאר התהליכים.", "ב. שלכל תהליך יש גישה בלעדית לכל הזיכרון הפיזי של המערכת.", "ג. שכל התהליכים נמצאים תמיד במצב \"Running\".", "ד. שלתהליך אין הורה או ילדים קשורים."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, האתגר המרכזי של מערכת ההפעלה הוא שלמרות שיש מעט מעבדים והרבה תהליכים, היא רוצה לתת את האשליה כאילו יש לנו המון מעבדים, וכי הכל רץ במקביל, בו זמנית. זוהי מהות הווירטואליזציה ברמת התהליך, ליצור אשליה של משאבים רבים וזמינות מתמדת. לכן, אפשרות א' היא התשובה הנכונה. אפשרויות ב', ג' ו-ד' שגויות על פי החומר: לתהליך יש מרחב כתובות משלו ולא גישה בלעדית לכל הזיכרון הפיזי; תהליכים עוברים בין מצבים שונים ולא תמיד נמצאים ב-'Running'; ולתהליכים יש קשרי הורה-ילד ונוצרת היררכיה."}, "_source_file": "0001__Virtualization__Processes__MC__Easy.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 16:49:42", "_subject": "Virtualization", "_context_lectures": [2, 4]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Processes"], "difficulty_estimation": "Easy", "content": {"text": "איזו אשליה מרכזית מערכת ההפעלה מנסה ליצור עבור תהליכים, למרות מספר מוגבל של מעבדים פיזיים?", "code_snippet": null, "options": ["א. לכל תהליך מוקצה כל הזיכרון הפיזי של המערכת באופן בלעדי.", "ב. נראה כאילו כל התהליכים רצים בו-זמנית ובמקביל.", "ג. כל תהליך יכול לשנות באופן חופשי את מצבם של תהליכים אחרים.", "ד. לכל התהליכים במערכת יש מספר מזהה (PID) זהה."]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר ההרצאה, האתגר המרכזי של מערכת ההפעלה הוא לתת אשליה כאילו יש לנו המון מעבדים ו'כאילו הכל רץ במקביל, בו זמנית', למרות שיש מעט מעבדים פיזיים והרבה תהליכים. זוהי מהות וירטואליזציית המעבד. אפשרות א' אינה נכונה, שכן לכל תהליך יש מרחב כתובות משלו, אך לא את כל הזיכרון הפיזי באופן בלעדי. אפשרות ג' אינה נכונה, מכיוון שלתהליך אין דרך לשנות תהליך מעבר לתהליך ההורה שלו. אפשרות ד' אינה נכונה, שכן אין שני תהליכים עם אותו מזהה באותה מערכת."}, "_source_file": "0002__Virtualization__Processes__MC__Easy.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 16:49:52", "_subject": "Virtualization", "_context_lectures": [2, 4]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Processes"], "difficulty_estimation": "Easy", "content": {"text": "מהי האשליה שמערכת ההפעלה מנסה ליצור ביחס להרצת תהליכים במחשב, למרות שיש מספר מוגבל של מעבדים?", "code_snippet": null, "options": ["א. שלכל תהליך יש מעבד ייעודי משלו וכל התהליכים רצים בו-זמנית במקביל.", "ב. שלכל תהליך יש גישה בלעדית לכל הזיכרון הפיזי של המחשב.", "ג. שכל הקבצים הפתוחים של תהליך נשמרים באופן קבוע על הדיסק הקשיח גם לאחר סיום התהליך.", "ד. שכל תהליך מקבל מזהה (PID) חדש בכל פעם שהוא עובר למצב 'Ready'."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. מתוך חומר ההרצאה, ב'Lecture 2 (chunk 7)', מצוין כי 'האתגר: יש מעט מעבדים אבל הרבה תהליכים, ומערכת ההפעלה רוצה לתת את האשליה כאילו יש לנו המון מעבדים (כאילו הכל רץ במקביל, בו זמנית)'. מערכת ההפעלה יוצרת אשליה זו על ידי ניהול תזמון המעבד בין התהליכים השונים במהירות גבוהה, מה שגורם למשתמש להרגיש שכל התהליכים פועלים במקביל, למרות שבפועל רק תהליך אחד (או מספר מוגבל של תהליכים, בהתאם למספר המעבדים) רץ בכל רגע נתון."}, "_source_file": "0003__Virtualization__Processes__MC__Easy.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 16:52:30", "_subject": "Virtualization", "_context_lectures": [2, 4]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Processes"], "difficulty_estimation": "Medium", "content": {"text": "על מנת שמערכת ההפעלה תוכל לנהל מספר רב של תהליכים בו-זמנית וליצור אשליה של ריצה מקבילה, היא שומרת מידע רב עבור כל תהליך. איזה מהבאים *אינו* נכון לגבי מאפייני תהליך או המידע שנשמר עליו?", "code_snippet": null, "options": ["א. לכל תהליך יש מרחב כתובות זיכרון משלו, הכולל מקטעים כמו Text (קוד), Data (נתונים גלובליים), Heap (הקצאות דינמיות) ו-Stack (משתנים מקומיים וארגומנטים).", "ב. כל תהליך מקבל מזהה ייחודי (PID) שאינו משותף עם אף תהליך אחר במערכת, וניתן לאחזר גם את מזהה תהליך ההורה שלו.", "ג. מערכת ההפעלה שומרת עבור כל תהליך את מצבו הנוכחי (למשל, Running או Ready), את מצב הרגיסטרים במעבד בעת הקפאתו, ואת רשימת הקבצים הפתוחים שהוא מחזיק.", "ד. תהליך יכול לשנות ישירות את מצב הריצה (state) של כל תהליך אחר במערכת, כל עוד הוא מכיר את ה-PID שלו, ובכך להשפיע על הקצאת המעבד."]}, "solution": {"correct_option": "ד", "explanation": "הטענה הנכונה היא ד' כי היא אינה נכונה. על פי חומר ההרצאה, 'לתהליך אין דרך לשנות תהליך מעבר לתהליך ההורה שלו' (Lecture 4, chunk 2). מערכת ההפעלה היא זו שאחראית לנהל את מצבי התהליכים (Running, Ready) ואת שיבוץ המעבד (scheduling), ולא תהליכים עצמם באופן ישיר. האפשרויות א, ב, ו-ג נכונות: א. לכל תהליך מרחב כתובות משלו הכולל Text, Data, Heap ו-Stack (Lecture 2, chunk 7). ב. לכל תהליך PID ייחודי וניתן לאחזר את ה-PID של ההורה (Lecture 2, chunk 19; Lecture 4, chunk 2). ג. ה-PCB של תהליך מכיל את מצבו הנוכחי (state), מצב הרגיסטרים (CPU context) ורשימת הקבצים הפתוחים (Lecture 2, chunk 19; Lecture 2, chunk 34)."}, "_source_file": "0004__Virtualization__Processes__MC__Medium.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 16:52:46", "_subject": "Virtualization", "_context_lectures": [2, 4]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Processes"], "difficulty_estimation": "Medium", "content": {"text": "כיצד מערכת ההפעלה יוצרת את האשליה שכל התהליכים רצים במקביל, למרות מספר המעבדים המוגבל?", "code_snippet": null, "options": ["א. על ידי מעבר מהיר בין תהליכים, תוך שמירת מצבו (context) של התהליך הנוכחי וטעינת מצבו של התהליך הבא להרצה.", "ב. על ידי הקצאת ליבת מעבד ייעודית לכל תהליך פעיל במערכת.", "ג. על ידי מתן אפשרות לתהליכים לגשת ישירות למרחבי הזיכרון זה של זה.", "ד. על ידי שמירת כל הקוד של התהליכים במקטע זיכרון משותף אחד לגישה מהירה."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין בשיעור מדגיש כי \"האתגר: יש מעט מעבדים אבל הרבה תהליכים, ומערכת ההפעלה רוצה לתת את האשליה כאילו יש לנו המון מעבדים (כאילו הכל רץ במקביל, בו זמנית)\". אשליה זו מושגת באמצעות מנגנון של החלפת הקשר (Context Switching) מהירה. כאשר תהליך מופסק (Descheduled), מערכת ההפעלה שומרת את כל המידע הנדרש עבור הריצה שלו, כולל \"מצב הרגיסטרים במעבד\" ו\"מצב הזיכרון\". לאחר מכן, היא טוענת את המצב השמור של תהליך אחר ונותנת לו לרוץ (Scheduled). מעבר מהיר זה בין תהליכים, תוך שמירה וטעינה של ה-CPU context ומידע נוסף (כמו קבצים פתוחים), יוצר את האשליה של ריצה מקבילית. אפשרות ב' אינה נכונה מכיוון שהיא סותרת את הנתון על מספר מעבדים מוגבל. אפשרות ג' אינה נכונה כיוון שלכל תהליך יש \"מרחב כתובות משלו\", והוא אינו ניגש ישירות לזיכרון של תהליכים אחרים. אפשרות ד' אינה נכונה, קוד של תהליכים נמצא במקטע ה-Text במרחב הכתובות הפרטי של כל תהליך, ולא במקטע זיכרון משותף לכלל הקוד של כל התהליכים."}, "_source_file": "0005__Virtualization__Processes__MC__Medium.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 16:52:59", "_subject": "Virtualization", "_context_lectures": [2, 4]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Processes"], "difficulty_estimation": "Medium", "content": {"text": "על מנת ליצור את האשליה שכל תהליך רץ באופן בלעדי על מעבד משלו ובעל מרחב זיכרון ייעודי, למרות קיומם של מעבדים בודדים וזיכרון פיזי משותף, מערכת ההפעלה מבצעת מספר פעולות. איזה מבין ההיגדים הבאים מתאר נכונה היבט מרכזי באופן שבו היא משיגה 'וירטואליזציה' זו עבור תהליכים?", "code_snippet": null, "options": ["א. מעבר מהיר בין תהליכים על אותו מעבד (Time-Sharing) והקצאת מרחב כתובות וירטואלי נפרד לכל תהליך.", "ב. הקצאת מזהה תהליך (PID) ייחודי לכל תהליך, אשר מבטיח לו גישה בלעדית למעבד.", "ג. מתן אפשרות לתהליכים לנהל באופן ישיר את המעברים שלהם בין מצבי Ready ו-Running.", "ד. אחסון כל המידע הקשור לתהליך (כמו הקשר מעבד, מיקומי זיכרון, וקבצים פתוחים) באופן בלעדי במערכת הקבצים."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. מערכת ההפעלה יוצרת את אשליית ה'וירטואליזציה' של מעבדים וזיכרון על ידי שני מנגנונים עיקריים המוזכרים בחומר:\n1.  **וירטואליזציה של מעבדים (CPU Virtualization)**: החומר מציין \"האתגר: יש מעט מעבדים אבל הרבה תהליכים, ומערכת ההפעלה רוצה לתת את האשליה כאילו יש לנו המון מעבדים (כאילו הכל רץ במקביל, בו זמנית)\". זה מושג באמצעות תזמון (scheduling) ומעבר מהיר בין תהליכים (Time-Sharing) על ידי מערכת ההפעלה, כך שלכל תהליך נדמה שהוא רץ באופן רציף על מעבד משלו.\n2.  **וירטואליזציה של זיכרון (Memory Virtualization)**: החומר קובע במפורש \"לכל תהליך שרץ יש מרחב כתובות משלו (את הזיכרון שלו)\". מערכת ההפעלה מקצה לכל תהליך מרחב כתובות וירטואלי נפרד, המבודד אותו מתהליכים אחרים ומעניק לו אשליה של זיכרון ייעודי.\n\nאפשרויות ב', ג' ו-ד' שגויות:\n*   **ב'**: מזהה תהליך (PID) הוא אכן ייחודי, אך הוא אינו מבטיח גישה בלעדית למעבד; המעבד משותף בין תהליכים רבים, כפי שמשתמע מהצורך ליצור אשליה של ריצה מקבילה.\n*   **ג'**: המעבר בין מצבי תהליך (כמו Ready ו-Running) נשלט על ידי מערכת ההפעלה (\"ברגע שהחלטנו להפסיק את התהליך... ולהריץ תהליך אחר במקומו... מערכת ההפעלה בוחרת את התהליך הבא להרצה\"), ולא על ידי התהליך עצמו.\n*   **ד'**: המידע על התהליך (כמו הקשר מעבד, מיקומי זיכרון וקבצים פתוחים) נשמר ב-PCB (Process Control Block) ובאזורי זיכרון שונים (RAM), ולא באופן בלעדי במערכת הקבצים. מערכת הקבצים אכן מעורבת ביצירת התהליך ובאחסון קוד התוכנית, אך לא בכל המידע התפעולי השוטף של התהליך."}, "_source_file": "0006__Virtualization__Processes__MC__Medium.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 16:53:17", "_subject": "Virtualization", "_context_lectures": [2, 4]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Processes"], "difficulty_estimation": "Hard", "content": {"text": "מערכת ההפעלה יוצרת אשליה עבור תהליכים כאילו הם רצים במקביל ונהנים ממשאבים ייעודיים (כגון מעבד וזיכרון), אף שבפועל קיימים מעבדים פיזיים מעטים וזיכרון פיזי משותף. איזה מבין התיאורים הבאים מסביר בצורה הטובה ביותר כיצד מערכת ההפעלה משיגה אשליה זו, בהתבסס על המידע שנלמד על מאפייני תהליכים ומחזור חייהם?", "code_snippet": null, "options": ["א. באמצעות ניהול מצבי תהליכים (Ready, Running), החלפת הקשר (context switch) הכוללת שמירת מצב המעבד (רגיסטרים) וקבצים פתוחים ב-PCB, והקצאת מרחב כתובות זיכרון נפרד לכל תהליך, מערכת ההפעלה מדמה ריצה מקבילית ומשאבים ייעודיים.", "ב. על ידי יצירת היררכיית תהליכים (אב-בן) ושימוש במזהי תהליכים (PID) ייחודיים, מערכת ההפעלה מאפשרת לכל תהליך לשלוט במשאבי בניו ולקבל עדיפות בגישה למעבד.", "ג. האשליה מושגת בכך שכל תהליך הוא מופע דינמי של תוכנית, ונוצר על ידי שיתוף פעולה בין המעבד, הזיכרון ומערכת הקבצים, מה שמבטיח הקצאה חד פעמית של משאבים בעת היצירה.", "ד. כל תהליך מקבל מרחב כתובות זיכרון משלו המחולק למקטעים (Text, Data, Heap, Stack), ובכך מובטח שכל תהליך יקבל את כל הזיכרון הדרוש לו באופן בלעדי, מה שיוצר את האשליה של מעבדים רבים."]}, "solution": {"correct_option": "א", "explanation": "האפשרות הנכונה היא א'. מערכת ההפעלה אכן יוצרת את האשליה של ריצה מקבילית ומשאבים ייעודיים על ידי מספר מנגנונים מרכזיים המוזכרים בחומר הלימוד:\n1.  **ניהול מצבי תהליכים והחלפת הקשר (Context Switching):** חומר הלימוד מציין כי \"מערכת ההפעלה רוצה לתת את האשליה כאילו יש לנו המון מעבדים (כאילו הכל רץ במקביל, בו זמנית)\". זה מושג באמצעות מעבר בין מצבי Ready ו-Running. כאשר תהליך נבחר לרוץ (scheduled) הוא עובר ל-Running, וכאשר הוא מופסק (descheduled) הוא עובר ל-Ready. תהליך זה כולל שמירה של ה-CPU context (כמו רגיסטרים) ומידע נוסף (כמו קבצים פתוחים ומיקומי זיכרון) ב-PCB (Process Control Block), כפי שצוין בחומר הלימוד \"שמירת מצב הרגיסטרים במעבד כשהקפאנו את אותו התהליך, מצב הזיכרון (המיקומים וכו') שקשורים לאותו תהליך, מה הקבצים הפתוחים שאותו התהליך מחזיק\". זה מאפשר למערכת ההפעלה להחליף תהליכים במהירות ולתת אשליה של ריצה בו-זמנית.\n2.  **מרחב כתובות זיכרון נפרד:** חומר הלימוד מציין במפורש \"לכל תהליך שרץ יש מרחב כתובות משלו (את הזיכרון שלו)\". מרחב כתובות זה מורכב ממקטעים (Text, Data, Heap, Stack) ומבודד כל תהליך מזיכרונם של תהליכים אחרים, ובכך יוצר אשליה של זיכרון ייעודי ובלעדי.\n\nאפשרות ב' שגויה מכיוון שהיררכיית תהליכים ומזהי PID קשורים לזיהוי וקשרי גומלין בין תהליכים, אך אינם מסבירים כיצד נוצרת האשליה של מעבדים רבים או משאבי זיכרון ייעודיים.\nאפשרות ג' שגויה מכיוון שהיא מתארת את הגדרת התהליך כמופע דינמי ואת מרכיבי היצירה שלו, אך לא את המנגנונים ששומרים על אשליית הריצה המקבילית והמשאבים הייעודיים לאורך זמן. ההקצאה אינה \"חד פעמית\".\nאפשרות ד' חלקית נכונה בכך שהיא מזכירה את מרחב הכתובות הנפרד והמקטעים, המהווה חלק מהאשליה של זיכרון ייעודי, אך היא אינה מתייחסת כלל למנגנונים הקשורים למעבד (כמו ניהול מצבים והחלפת הקשר) ובכך אינה מסבירה את האשליה של \"מעבדים רבים\" או ריצה מקבילית."}, "_source_file": "0007__Virtualization__Processes__MC__Hard.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 16:53:32", "_subject": "Virtualization", "_context_lectures": [2, 4]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Processes"], "difficulty_estimation": "Hard", "content": {"text": "כיצד מערכת ההפעלה יוצרת ומקיימת את האשליה של ריצה מקבילה של תהליכים רבים על מעבד יחיד, למרות שרק תהליך אחד יכול לרוץ פיזית בכל רגע נתון?", "code_snippet": null, "options": ["א. מערכת ההפעלה מבצעת החלפת הקשר (context switch) על ידי שמירת כל המידע הנדרש עבור ריצת התהליך הנוכחי (כולל מצב הרגיסטרים, מיקומי זיכרון וקבצים פתוחים) כאשר הוא עובר למצב Ready, וטעינת המידע של התהליך הבא שנבחר להרצה.", "ב. מערכת ההפעלה מקצה לכל תהליך מרחב כתובות זיכרון ייעודי משלו (Text, Data, Heap, Stack), ובכך מונעת הפרעה בין תהליכים ומאפשרת להם לרוץ כאילו הם היחידים במערכת.", "ג. תהליכים מרובים מקבלים מזהים ייחודיים (PID) ונוצרת היררכיית אב-בן, מה שמאפשר למערכת ההפעלה לנהל אותם ביעילות ולהריץ אותם במקביל.", "ד. מערכת ההפעלה מונעת מתהליכים לשנות תהליכים אחרים שאינם תהליך האב שלהם, ובכך מבטיחה עצמאות מלאה בין תהליכים ומונעת תלות הדדית."]}, "solution": {"correct_option": "א", "explanation": "האשליה של ריצה מקבילה של תהליכים רבים על מעבד יחיד מושגת באמצעות מנגנון החלפת הקשר (context switch). כאשר מערכת ההפעלה מחליטה להפסיק את ריצתו של תהליך אחד (המכונה 'Descheduled') ולהעביר אותו ממצב 'Running' למצב 'Ready', היא שומרת את כל המידע הנדרש כדי שתוכל לחדש את ריצתו של התהליך המופסק בדיוק מהמקום בו הופסק. מידע זה, כפי שמצוין בחומר הלימוד, כולל את מצב הרגיסטרים במעבד, מיקומי הזיכרון (כגון ערימה ומחסנית), ורשימת הקבצים הפתוחים של התהליך. לאחר מכן, היא טוענת את המידע השמור של התהליך הבא שנבחר לריצה (המכונה 'Scheduled') ומעבירה אותו ממצב 'Ready' למצב 'Running'. מחזוריות מהירה של פעולות אלו יוצרת את האשליה של ריצה בו-זמנית על מעבד בודד, כפי שמתואר בחומר הלימוד: \"האתגר: יש מעט מעבדים אבל הרבה תהליכים, ומערכת ההפעלה רוצה לתת את האשליה כאילו יש לנו המון מעבדים (כאילו הכל רץ במקביל, בו זמנית)\".\n\nאפשרויות ב', ג' ו-ד' מתארות היבטים שונים של ניהול תהליכים והווירטואליזציה שהמערכת מספקת, אך אינן המנגנון הישיר המאפשר את אשליית הריצה המקבילה על מעבד יחיד:\n- אפשרות ב' מתארת את מרחב הכתובות הפרטי של כל תהליך, אשר אכן תורם לבידוד בין תהליכים, אך אינה מסבירה כיצד הם רצים ב'מקביל' על מעבד אחד.\n- אפשרות ג' מתארת את שימוש במזהים ייחודיים (PID) והיררכיית אב-בן, שהם חשובים לניהול וזיהוי תהליכים, אך אינם המנגנון המייצר את אשליית הריצה המקבילה.\n- אפשרות ד' מתארת הגבלה ביכולת תהליך לשנות תהליכים אחרים, מה שתורם לאבטחה וליציבות המערכת, אך אינה קשורה ישירות ליצירת אשליית הריצה המקבילה על מעבד יחיד."}, "_source_file": "0008__Virtualization__Processes__MC__Hard.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 16:53:49", "_subject": "Virtualization", "_context_lectures": [2, 4]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Processes"], "difficulty_estimation": "Hard", "content": {"text": "בהינתן שמערכת הפעלה יוצרת אשליה של ריבוי מעבדים וזיכרון ייעודי לכל תהליך, על אף שישנם משאבים פיזיים מוגבלים ומשותפים (מעבדים וזיכרון RAM), איזה מבין המנגנונים הבאים הוא הקריטי ביותר לאפשר את אשליית הבידוד המלא בין מרחבי הכתובות של תהליכים שונים?", "code_snippet": null, "options": ["א. ניהול מרחבי כתובות וירטואליים נפרדים לכל תהליך, הממופים לזיכרון הפיזי על ידי מערכת ההפעלה.", "ב. שמירת מצב הרגיסטרים וקבצים פתוחים של תהליך במבנה ה-PCB בעת מעבר הקשר.", "ג. יצירת היררכיית תהליכים (אב-בן) המאפשרת לתהליך הורה לשלוט בבניו.", "ד. הקצאת מקטעי זיכרון קבועים (Text, Data) ודינמיים (Heap, Stack) בתוך מרחב הכתובות של כל תהליך."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין בשיעור קובע כי מערכת ההפעלה רוצה לתת את האשליה 'כאילו הכל רץ במקביל, בו זמנית' וכי 'לכל תהליך שרץ יש מרחב כתובות משלו (את הזיכרון שלו)'. מנגנון זה, של ניהול מרחבי כתובות וירטואליים נפרדים לכל תהליך, הוא המפתח ליצירת אשליית הבידוד המלא בזיכרון. למרות שהזיכרון הפיזי משותף, מערכת ההפעלה ממפה את הכתובות הווירטואליות של כל תהליך לכתובות פיזיות שונות, ובכך מונעת מתהליכים לדרוס זה את זיכרונו של זה ומעניקה לכל תהליך תחושה של זיכרון ייעודי משלו. זוהי הליבה של וירטואליזציית הזיכרון.\n\nאפשרויות אחרות:\nב. שמירת מצב הרגיסטרים וקבצים פתוחים ב-PCB (Process Control Block) היא קריטית עבור מעבר הקשר (Context Switch) ומאפשרת את אשליית הריצה הרציפה של כל תהליך על המעבד, אך היא אינה המנגנון העיקרי לאבטחת בידוד *מרחבי הכתובות* בין תהליכים שונים.\nג. יצירת היררכיית תהליכים (אב-בן) קשורה לניהול תהליכים ולמבנה שלהם במערכת ההפעלה, ואינה נוגעת באופן ישיר למנגנון שאחראי על בידוד מרחבי הכתובות הווירטואליים בין תהליכים.\nד. הקצאת מקטעי זיכרון (Text, Data, Heap, Stack) מתארת את הארגון הפנימי של הזיכרון *בתוך* מרחב הכתובות של תהליך יחיד, אך אינה מסבירה את המנגנון המבטיח את הבידוד *בין* מרחבי הכתובות של תהליכים שונים."}, "_source_file": "0009__Virtualization__Processes__MC__Hard.json", "_topic_hint": "Processes", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 16:54:02", "_subject": "Virtualization", "_context_lectures": [2, 4]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Process Lifecycle"], "difficulty_estimation": "Easy", "content": {"text": "מה המשמעות של תהליך הנמצא במצב \"Running\" במחזור החיים שלו?", "code_snippet": null, "options": ["א. המעבד מריץ כרגע את הפקודות שלו.", "ב. התהליך מוכן לרוץ וממתין למערכת ההפעלה שתשבץ אותו.", "ג. התהליך סיים את ריצתו אך הרשומה שלו עדיין קיימת בטבלת התהליכים.", "ד. התהליך ממתין להשלמת פעולת קלט/פלט."]}, "solution": {"correct_option": "א", "explanation": "לפי חומר ההרצאה (Lecture 2, chunk 34), אם תהליך נמצא במצב \"Running\", המשמעות היא \"שהמעבד מריץ כרגע את הפקודות שלו\". אפשרות ב' מתארת את מצב \"Ready\", שבו התהליך מוכן לרוץ אך עדיין לא שובץ למעבד. אפשרות ג' מתארת תהליך \"זומבי\" (defunct). אפשרות ד' מתארת מצב של המתנה לפעולת קלט/פלט, אשר אינו אחד המצבים העיקריים המתוארים במפורש בחומר ההרצאה בקשר למצב \"Running\"."}, "_source_file": "0010__Virtualization__Process_Lifecycle__MC__Easy.json", "_topic_hint": "Process Lifecycle", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 16:54:10", "_subject": "Virtualization", "_context_lectures": [2, 4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Process Lifecycle"], "difficulty_estimation": "Easy", "content": {"text": "מהו המצב המתאר תהליך שמוכן לרוץ וממתין שמערכת ההפעלה תבחר אותו כדי שירוץ על המעבד?", "code_snippet": null, "options": ["א. Running", "ב. Ready", "ג. Zombie", "ד. Descheduled"]}, "solution": {"correct_option": "ב", "explanation": "לפי חומר ההרצאה (Lecture 2, chunk 34), המצב 'Ready' מתאר תהליך ש'מוכן לרוץ'. מערכת ההפעלה בוחרת את התהליך הבא להרצה מתוך רשימת התהליכים שנמצאים במצב זה. מצב 'Running' מתאר תהליך שרץ כרגע על המעבד. 'Zombie' (Lecture 5, chunk 6) מתאר תהליך שהסתיים אך רשומתו עדיין קיימת בטבלת התהליכים. 'Descheduled' הוא פעולה (לא מצב) שבה תהליך מופסק ועובר למצב 'Ready', ולא מצב בפני עצמו."}, "_source_file": "0011__Virtualization__Process_Lifecycle__MC__Easy.json", "_topic_hint": "Process Lifecycle", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 16:54:22", "_subject": "Virtualization", "_context_lectures": [2, 4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Process Lifecycle"], "difficulty_estimation": "Easy", "content": {"text": "מהי המשמעות של תהליך הנמצא במצב 'Running' (רץ) במחזור החיים שלו?", "code_snippet": null, "options": ["א. המעבד מריץ כרגע את הפקודות של התהליך.", "ב. התהליך מוכן לרוץ אך ממתין לתורו במעבד.", "ג. התהליך סיים את ריצתו אך רשומתו עדיין קיימת בטבלת התהליכים.", "ד. התהליך הופסק באופן יזום והוחזר למחסן ההמתנה."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה (Lecture 2, chunk 34), תהליך הנמצא במצב 'Running' הוא תהליך ש'המעבד מריץ כרגע את הפקודות שלו'.\nאפשרות ב' מתארת תהליך במצב 'Ready'.\nאפשרות ג' מתארת תהליך 'זומבי' (defunct).\nאפשרות ד' מתארת את הפעולה 'Descheduled' שמעבירה תהליך ממצב 'Running' למצב 'Ready', ולא את מצב 'Running' עצמו."}, "_source_file": "0012__Virtualization__Process_Lifecycle__MC__Easy.json", "_topic_hint": "Process Lifecycle", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 16:54:31", "_subject": "Virtualization", "_context_lectures": [2, 4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Process Lifecycle"], "difficulty_estimation": "Medium", "content": {"text": "לפי חומר ההרצאה, מהו המצב שאליו עובר תהליך שהיה במצב Running (רץ) והופסק על ידי פסיקת שעון (timer interrupt), ומה קורה למידע שלו?", "code_snippet": null, "options": ["א. הוא עובר למצב Ready, ומערכת ההפעלה שומרת את ה-CPU context שלו (לדוגמה, ערכי הרגיסטרים) ואת מצב הזיכרון שלו.", "ב. הוא עובר למצב Blocked, וכל המידע הקשור אליו נמחק מהזיכרון כדי לפנות מקום לתהליכים אחרים.", "ג. הוא נשאר במצב Running אך מפסיק לבצע פקודות עד שהמעבד יתפנה.", "ד. הוא הופך לתהליך Zombie, ומחכה שאביו יבצע עליו wait."]}, "solution": {"correct_option": "א", "explanation": "כאשר תהליך במצב Running מופסק על ידי פסיקת שעון (timer interrupt) או קריאת מערכת, הוא עובר למצב Ready. תהליך זה נקרא Descheduled (הוצא מלוח הזמנים). במצב Ready, התהליך מוכן לרוץ אך ממתין לתורו לקבל את המעבד. חשוב לציין שבעת המעבר ממצב Running למצב Ready, מערכת ההפעלה שומרת את כל המידע הנדרש עבור חידוש הריצה של התהליך, כולל ה-CPU context (כמו ערכי הרגיסטרים במעבד) ואת מצב הזיכרון הקשור לתהליך. מידע זה נשמר ב-PCB (Process Control Block) של התהליך ומאפשר למערכת ההפעלה לשחזר את מצבו המדויק ולהמשיך את ריצתו מאותה נקודה מאוחר יותר (כפי שמפורט ב-Lecture 2, chunk 19 ו-chunk 34). אפשרות ב' אינה נכונה מכיוון שהתהליך לא עובר למצב Blocked במקרה זה, ומידע לא נמחק אלא נשמר. אפשרות ג' אינה נכונה מכיוון שהתהליך אינו נשאר במצב Running אם הוא הפסיק לבצע פקודות. אפשרות ד' אינה נכונה מכיוון שתהליך זומבי הוא תהליך שסיים את ריצתו אך רשומתו עדיין קיימת, ואינו תוצאה של פסיקת שעון (כפי שמפורט ב-Lecture 5, chunk 6)."}, "_source_file": "0013__Virtualization__Process_Lifecycle__MC__Medium.json", "_topic_hint": "Process Lifecycle", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 16:54:43", "_subject": "Virtualization", "_context_lectures": [2, 4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Process Lifecycle"], "difficulty_estimation": "Medium", "content": {"text": "מהי הסיבה העיקרית שמערכת הפעלה אינה מפנה באופן אוטומטי תהליכי זומבי (defunct), גם לאחר שסיימו את ריצתם?", "code_snippet": null, "options": ["א. מכיוון שתהליך האב עדיין מצפה לקרוא ל-wait() על תהליך הבן כדי לאסוף את סטטוס הסיום שלו.", "ב. מכיוון שתהליך זומבי נשאר במצב זה עד שתהליך ה-init יאמץ אותו ויפנה אותו.", "ג. כדי לאפשר לתהליכים אחרים לבצע דיבוג (debugging) על מצבו האחרון של התהליך שהסתיים.", "ד. מערכת ההפעלה אינה מזהה תהליכים במצב זומבי ודורשת התערבות ידנית."]}, "solution": {"correct_option": "א", "explanation": "ההסבר מהחומר המצורף (הרצאה 5, קטע 6) קובע במפורש: \"מדוע מערכת ההפעלה לא עושה פינוי לתהליכים שהם זומבים? מכיוון שתהליך האב עלול לעשות לתהליך הבן wait.\" תהליך זומבי הוא תהליך שסיים את ריצתו אך רשומתו עדיין קיימת בטבלת התהליכים. מערכת ההפעלה משאירה את הרשומה הזו עד שתהליך האב יקרא ל-`wait()` כדי לאסוף את קוד היציאה של תהליך הבן. אם מערכת ההפעלה הייתה מפנה את הזומבי אוטומטית, תהליך האב לא היה יכול לקבל מידע זה. לכן, תשובה א' היא הנכונה. תשובה ב' מתארת מצב שבו תהליך הופך ליתום (orphan) לאחר סיום תהליך האב, ואז `init` מפנה אותו, אך זו אינה הסיבה שמערכת ההפעלה אינה מפנה זומבים באופן כללי. תשובות ג' ו-ד' אינן נתמכות בחומר ההרצאה."}, "_source_file": "0014__Virtualization__Process_Lifecycle__MC__Medium.json", "_topic_hint": "Process Lifecycle", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 16:54:55", "_subject": "Virtualization", "_context_lectures": [2, 4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Process Lifecycle"], "difficulty_estimation": "Medium", "content": {"text": "מה מתאר בצורה הטובה ביותר תהליך \"זומבי\" (Zombie Process) במחזור חייו, ומדוע מערכת ההפעלה אינה מנקה אותו מיד?", "code_snippet": null, "options": ["א. תהליך שנמצא במצב \"Ready\" ומוכן לרוץ, אך המערכת מסמנת אותו כ\"defunct\" עד שתהליך האב יקרא לו wait().", "ב. תהליך שהסתיים בהצלחה ושוחרר מזיכרון המערכת, אך מזהה ה-PID שלו נשמר לזמן קצר למטרות תיעוד.", "ג. תהליך שהסתיים, אך רשומת ה-PCB שלו עדיין קיימת בטבלת התהליכים (מסומנת כ-\"defunct\"), מכיוון שתהליך האב שלו עדיין פעיל ועלול לבצע wait() עליו.", "ד. תהליך תקוע במצב \"Running\" שאינו מגיב, ומערכת ההפעלה ממתינה לתהליך האב שיסיים את ריצתו כדי להפוך את הזומבי לבן של init."]}, "solution": {"correct_option": "ג", "explanation": "על פי חומר ההרצאה (Lecture 5, chunk 6), תהליך זומבי הוא \"תהליך שהסתיים אבל הרשומה שלו עדיין קיימת בטבלת התהליכים\" והוא מסומן במילה \"defunct\". הסיבה שמערכת ההפעלה אינה מנקה אותו מיד היא \"מכיוון שתהליך האב עלול לעשות לתהליך הבן wait\". אם תהליך האב עדיין רץ, הוא עשוי לקרוא ל-wait() כדי לאסוף את קוד היציאה של תהליך הבן. לכן, אפשרות ג' מתארת במדויק את המצב והסיבה.\nאפשרויות א' ו-ד' שגויות מכיוון שתהליך זומבי אינו במצב \"Ready\" או \"Running\"; הוא כבר סיים את ריצתו. אפשרות ב' שגויה מכיוון שרשומת ה-PCB עדיין קיימת, והסיבה העיקרית היא לא רק תיעוד אלא הצורך לאפשר לתהליך האב לאסוף מידע."}, "_source_file": "0015__Virtualization__Process_Lifecycle__MC__Medium.json", "_topic_hint": "Process Lifecycle", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 16:55:09", "_subject": "Virtualization", "_context_lectures": [2, 4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Process Lifecycle"], "difficulty_estimation": "Hard", "content": {"text": "תהליך במערכת הפעלה עובר ממצב \"רץ\" (Running) למצב \"מוכן\" (Ready) כאשר הוא נשלף מהמעבד (Descheduled). איזו מהטענות הבאות מתארת בצורה הטובה ביותר את המטרה העיקרית של שמירת הקונטקסט של המעבד (CPU context), כפי שמצוין ב-PCB, בהקשר של מחזור חיי התהליך והווירטואליזציה?", "code_snippet": null, "options": ["א. לאפשר לתהליך לחדש את ריצתו בדיוק מהנקודה שבה הופסק, ובכך לשמר את אשליית הסביבה המבודדת והרציפה שלו.", "ב. למנוע מהתהליך להפוך ל\"זומבי\" לאחר סיום ריצתו.", "ג. לעדכן את שדה ה-state ב-PCB למצב \"Ready\" בצורה יעילה.", "ד. להבטיח שתהליכי הבן שלו לא יהפכו ליתומים במקרה של סיום בלתי צפוי."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין ב-PCB, כולל ה-CPU context (כמו רגיסטרים), נשמר כאשר תהליך מוסר מהמעבד (Descheduled) ועובר למצב Ready. שמירה זו חיונית כדי שכאשר התהליך ייבחר שוב לריצה (Scheduled), ניתן יהיה לשחזר את מצבו המדויק של המעבד (CPU) ואת כל המידע הנדרש (כמו מיקומי זיכרון, קבצים פתוחים) בדיוק כפי שהיה לפני שהופסק. זהו עקרון יסוד בווירטואליזציה של המעבד, שמאפשר לכל תהליך להרגיש כאילו הוא היחיד שרץ על המעבד באופן רציף, למרות שהוא למעשה עובר בין מצבי ריצה והמתנה. אפשרות ב' אינה נכונה מכיוון שמצב זומבי קשור לסיום תהליך ולאי ביצוע wait על ידי האב, לא להסרה מהמעבד. אפשרות ג' אינה נכונה מכיוון שעדכון ה-state הוא פעולה נפרדת ופשוטה יותר משמירת קונטקסט. אפשרות ד' אינה נכונה מכיוון שהיא מתייחסת ליחסי הורה-בן ולטיפול ביתומים, נושא שאינו קשור ישירות לשמירת קונטקסט בעת הסרת תהליך מהמעבד."}, "_source_file": "0016__Virtualization__Process_Lifecycle__MC__Hard.json", "_topic_hint": "Process Lifecycle", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 16:55:23", "_subject": "Virtualization", "_context_lectures": [2, 4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Process Lifecycle"], "difficulty_estimation": "Hard", "content": {"text": "תהליך בן סיים את ריצתו בהצלחה, אך תהליך האב שלו, שעדיין פעיל, אינו מבצע עליו קריאת מערכת wait. בהתבסס על המידע הנתון, מהו המצב בו יימצא תהליך הבן, ומהו המנגנון העיקרי שמערכת ההפעלה תסתמך עליו כדי לוודא שמשאביו יפונו לבסוף, גם אם תהליך האב לעולם לא יקרא ל-wait?", "code_snippet": null, "options": ["א. תהליך הבן יימצא במצב \"זומבי\" (defunct). מערכת ההפעלה תמתין לסיום ריצתו של תהליך האב; ברגע שתהליך האב יסיים, תהליך הבן יאומץ על ידי init, אשר ידאג לפנות את רשומתו.", "ב. תהליך הבן יימצא במצב \"מוכן לריצה\" (Ready). מערכת ההפעלה תזהה חוסר פעילות ותעביר אותו למצב \"מושהה\" (Suspended) ולאחר מכן תפנה את משאביו באופן יזום.", "ג. תהליך הבן יימצא במצב \"רץ\" (Running) אך ללא פקודות לביצוע. מערכת ההפעלה תשלח אות kill -9 לתהליך הבן כדי לפנות את משאביו.", "ד. תהליך הבן יימצא במצב \"זומבי\" (defunct). מערכת ההפעלה תפעיל טיימר מיוחד, ולאחר פרק זמן קצוב תפנה את רשומתו באופן אוטומטי, ללא תלות בתהליך האב או ב-init."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. כאשר תהליך בן מסיים את ריצתו, אך תהליך האב שלו (שעדיין פעיל) אינו מבצע עליו קריאת מערכת wait, תהליך הבן נכנס למצב \"זומבי\" (defunct). במצב זה, תהליך הבן כבר אינו רץ ורוב משאביו שוחררו, אך רשומת ה-PCB שלו (ותוכם מידע כמו קוד היציאה) נשארת בטבלת התהליכים. מערכת ההפעלה אינה מפנה רשומות אלו באופן יזום, כיוון שהיא מצפה שתהליך האב יקרא ל-wait על מנת לאסוף את קוד היציאה ולפנות את הרשומה. אם תהליך האב לעולם לא יקרא ל-wait, הדרך העיקרית לפינוי רשומת הזומבי היא כאשר תהליך האב עצמו יסיים את ריצתו. במקרה כזה, כל תהליכי הבנים שנותרו (כולל הזומבים) מאומצים על ידי תהליך init (תהליך מספר 1), אשר ידוע בכך שהוא דואג לפנות את רשומות הזומבים שלו, ובכך משחרר את ה-PCB של תהליך הבן. אפשרויות ב', ג' ו-ד' אינן נכונות: תהליך שהסתיים אינו יכול להיות במצב \"מוכן לריצה\" או \"רץ\". מערכת ההפעלה אינה מפנה זומבים באופן יזום באמצעות טיימר או אות kill -9 ישירות לתהליך הזומבי, אלא ממתינה לפעולת האב או לסיום האב."}, "_source_file": "0017__Virtualization__Process_Lifecycle__MC__Hard.json", "_topic_hint": "Process Lifecycle", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 16:55:41", "_subject": "Virtualization", "_context_lectures": [2, 4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Process Lifecycle"], "difficulty_estimation": "Hard", "content": {"text": "תהליך P מסיים את ריצתו בהצלחה, אך תהליך האב שלו, אשר עדיין פעיל, אינו מבצע קריאת מערכת wait. כתוצאה מכך, P הופך לתהליך 'זומבי'. בהתייחס למבנה ה-PCB ולמחזור חיי התהליך כפי שתוארו בחומר, איזה רכיב מבין רכיבי ה-PCB הבאים הוא **החיוני ביותר** להישארות התהליך במצב זומבי ולתהליך הפינוי העתידי שלו, ומה הסיבה לכך?", "code_snippet": null, "options": ["א. מצב המעבד (CPU context) ומיקומי הזיכרון (Memory locations) של התהליך, כדי לאפשר למערכת ההפעלה לשחזר את ריצתו במידת הצורך.", "ב. מזהה התהליך (PID) ומזהה תהליך האב (PPID) שלו, יחד עם מצב התהליך ('defunct'), על מנת לאפשר לתהליך האב לבצע עליו wait או ל-init לאמץ ולנקות אותו במקרה הצורך.", "ג. רשימת הקבצים הפתוחים (Open files) ומידע על הרשאות המשתמש הקשורות לתהליך, כדי להבטיח שחרור נכון של משאבי מערכת.", "ד. מצב הריצה (Running) או מוכנות (Ready) של התהליך, יחד עם נתוני התזמון שלו, כדי שמערכת ההפעלה תוכל לשבץ אותו מחדש להרצה."]}, "solution": {"correct_option": "ב", "explanation": "תהליך זומבי הוא תהליך שהסתיים אך הרשומה שלו בטבלת התהליכים (PCB) עדיין קיימת. על פי חומר ההרצאה, הסיבה העיקרית לכך היא שתהליך האב 'עלול לעשות לתהליך הבן wait' על מנת לקבל מידע על סיום הבן. ה-PCB מכיל את מזהה התהליך (PID), את מצבו (state) ואת התהליכים הקשורים אליו (related processes), ובפרט את תהליך האב. לכן, ה-PCB חייב לשמר את מזהה התהליך (PID), את מזהה תהליך האב (PPID) ואת מצבו כ-'defunct' (זומבי). מידע זה חיוני כדי לאפשר לתהליך האב למצוא את התהליך הזומבי ולבצע עליו wait, או במקרה שתהליך האב יסתיים, כדי שתהליך init (אשר על פי החומר, לא משאיר זומבים) יוכל לאמץ את התהליך הזומבי ולפנות את רשומתו. אפשרויות אחרות אינן נכונות: תהליך זומבי אינו מיועד להמשך ריצה ולכן מצב המעבד ומיקומי הזיכרון (אופציה א) אינם נשמרים; קבצים פתוחים ומשאבים אחרים (אופציה ג) משוחררים בדרך כלל עם סיום התהליך; תהליך זומבי אינו במצב Running או Ready (אופציה ד) ואינו מיועד לתזמון מחדש, אלא הוא תהליך שהסתיים."}, "_source_file": "0018__Virtualization__Process_Lifecycle__MC__Hard.json", "_topic_hint": "Process Lifecycle", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 16:56:03", "_subject": "Virtualization", "_context_lectures": [2, 4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Context Switching"], "difficulty_estimation": "Easy", "content": {"text": "מהו אחד מהעדכונים המרכזיים שמערכת ההפעלה מבצעת במעבד במהלך \"החלפת הקשר\" (context switch) בין תהליכים, בהקשר של ניהול זיכרון?", "code_snippet": null, "options": ["א. עדכון ערכי ה-Base&Bounds במעבד.", "ב. עדכון קוד התוכנית בזיכרון הראשי.", "ג. שינוי מצב הריצה של המעבד מ-kernel mode ל-user mode עבור התהליך החדש.", "ד. מחיקת כל הנתונים של התהליך הקודם מהזיכרון."]}, "solution": {"correct_option": "א", "explanation": "המנגנון של \"החלפת הקשר\" (context switch) כולל פעולות שונות שמערכת ההפעלה מבצעת כדי להעביר את השליטה מתהליך אחד לאחר. בהקשר של ניהול זיכרון, חומר ההרצאה מציין במפורש כי \"מערכת ההפעלה שומרת ב-pcb עבור כל תהליך את ה-Base&Bounds שלו... ואז ב-context switch כשמתבצעת החלפה בין תהליכים, מערכת ההפעלה מעדכנת את ה-Base&Bounds במעבד\" (Lecture 2, chunk 15). עדכון רגיסטרים אלו במעבד חיוני כדי שה-MMU יוכל לתרגם כתובות וירטואליות לכתובות פיזיות באופן נכון עבור התהליך החדש, ולוודא שהתהליך לא חורג מגבולות הזיכרון שהוקצו לו. פעולה זו מחייבת הרשאות kernel mode."}, "_source_file": "0019__Virtualization__Context_Switching__MC__Easy.json", "_topic_hint": "Context Switching", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 16:56:17", "_subject": "Virtualization", "_context_lectures": [2, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Context Switching"], "difficulty_estimation": "Easy", "content": {"text": "איזה מידע נשמר או נטען באופן טיפוסי במהלך מנגנון ה-Context Switch (החלפת הקשר) בין תהליכים?", "code_snippet": null, "options": ["א. מצב רגיסטרי המעבד (CPU context), מיקומי זיכרון, וקבצים פתוחים.", "ב. רק כתובת ההתחלה של קוד התוכנית (Text segment).", "ג. רק גודל ה-Stack וה-Heap של התהליך.", "ד. רק כתובות ה-Base וה-Bounds של התהליך בזיכרון הפיזי."]}, "solution": {"correct_option": "א", "explanation": "מנגנון ה-Context Switch נועד לשמור את כל המידע הנדרש עבור ריצתו של תהליך אחד, כדי שניתן יהיה לטעון תהליך אחר, ולאחר מכן לחזור ולהמשיך את התהליך שהופסק מאותה נקודה. לפי חומר ההרצאה (chunk 20), מידע זה כולל את מצב רגיסטרי המעבד (CPU context), מיקומי זיכרון (Memory locations), וקבצים פתוחים (Open files) שהתהליך מחזיק."}, "_source_file": "0020__Virtualization__Context_Switching__MC__Easy.json", "_topic_hint": "Context Switching", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 16:56:25", "_subject": "Virtualization", "_context_lectures": [2, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Context Switching"], "difficulty_estimation": "Easy", "content": {"text": "איזו מהאפשרויות הבאות מתארת בצורה הטובה ביותר את מנגנון ה-Context Switch (החלפת הקשר) במערכת הפעלה?", "code_snippet": null, "options": ["א. העברת השליטה הבלעדית מהמעבד לתהליך משתמש יחיד עד לסיומו.", "ב. שמירת מצבו של תהליך רץ, הוצאתו מהמעבד וטעינת מצבו של תהליך אחר כדי שימשיך לרוץ.", "ג. ביצוע קריאות מערכת (system calls) כדי לאפשר גישה לפעולות מורשות (privileged operations).", "ד. עדכון רגיסטרי ה-Base&Bounds במעבד על מנת להגן על מרחב הזיכרון של תהליכים."]}, "solution": {"correct_option": "ב", "explanation": "מנגנון ה-Context Switch, כפי שמתואר בחומר ההרצאה (Chunk 16), הוא התהליך שבו מערכת ההפעלה 'מוציאה' תהליך אחד מהמעבד, שומרת את מצבו (כפי שמפורט ב-Chunk 20, כולל רישומים, מיקומי זיכרון וקבצים פתוחים), ולאחר מכן 'טוענת' תהליך חדש למעבד כדי שימשיך את ריצתו מהנקודה שבה הופסק. אפשרות ב' מתארת במדויק פעולה זו. אפשרות א' מתארת את רעיון ה-Direct Execution שבו תהליך שולט באופן מלא במעבד עד לסיומו, אך לא את מנגנון ההחלפה עצמו. אפשרות ג' מתארת קריאות מערכת, שהן מנגנון למעבר בין User Mode ל-Kernel Mode וביצוע פעולות מורשות (Chunk 24), אך אינן ההגדרה המלאה של Context Switch. אפשרות ד' מתארת פעולה ספציפית שמתרחשת במהלך Context Switch בהקשר של ניהול זיכרון (עדכון Base&Bounds, Chunk 15), אך אינה תיאור כולל של כל המנגנון."}, "_source_file": "0021__Virtualization__Context_Switching__MC__Easy.json", "_topic_hint": "Context Switching", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 16:56:39", "_subject": "Virtualization", "_context_lectures": [2, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Context Switching"], "difficulty_estimation": "Medium", "content": {"text": "מהי אחת הסיבות המרכזיות לכך שמערכת ההפעלה נדרשת לפעול במצב ליבה (kernel mode) במהלך ביצוע החלפת הקשר (context switch) בין תהליכים?", "code_snippet": null, "options": ["א. עדכון רגיסטרי ה-Base וה-Bounds במעבד, המאפשרים ניהול זיכרון תקין עבור התהליך הנכנס.", "ב. כדי לאפשר לתהליך החדש גישה ישירה ובלתי מוגבלת לכל משאבי המערכת באופן מיידי.", "ג. לשמור את מצב הרגיסטרים של המעבד (CPU context) עבור התהליך היוצא בתוך ה-PCB שלו.", "ד. למנוע מהתהליך הנכנס לבצע פעולות בעלות הרשאות גבוהות לפני שקיבל את השליטה המלאה במעבד."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה (Lecture 6, chunk 15), במהלך החלפת הקשר (context switch), מערכת ההפעלה שומרת ב-PCB של כל תהליך את ה-Base וה-Bounds שלו. כאשר מתבצעת החלפה בין תהליכים, מערכת ההפעלה מעדכנת את רגיסטרי ה-Base וה-Bounds במעבד (רגיסטרים אלו קיימים גם במעבד) כדי להגדיר את מרחב הזיכרון של התהליך החדש. עדכון של שני רגיסטרים אלו במעבד מותר אך ורק במצב ליבה (kernel mode), ולכן זוהי סיבה קריטית לכך שמערכת ההפעלה חייבת לפעול במצב זה בעת ביצוע החלפת הקשר."}, "_source_file": "0022__Virtualization__Context_Switching__MC__Medium.json", "_topic_hint": "Context Switching", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 16:56:52", "_subject": "Virtualization", "_context_lectures": [2, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Context Switching"], "difficulty_estimation": "Medium", "content": {"text": "במהלך החלפת הקשר (context switch) בין תהליכים, איזו פעולה קריטית מבצעת מערכת ההפעלה בנוגע לניהול זיכרון, ומדוע פעולה זו דורשת הרשאות מיוחדות?", "code_snippet": null, "options": ["א. מערכת ההפעלה מעדכנת את רגיסטרי ה-Base וה-Bounds במעבד כדי להבטיח את הגנת הזיכרון של התהליך החדש, ופעולה זו מותרת רק ב-kernel mode.", "ב. מערכת ההפעלה שומרת את כל תוכן הזיכרון של התהליך היוצא לקובץ גיבוי, וזה דורש הרשאות מיוחדות כדי לגשת לדיסק.", "ג. מערכת ההפעלה מקצה מקטעי זיכרון חדשים לחלוטין עבור התהליך הנכנס, וזה דורש הרשאות kernel כדי לשנות את מפת הזיכרון.", "ד. מערכת ההפעלה מאפשרת לתהליך המשתמש לעדכן באופן ישיר את רגיסטרי ה-MMU כדי לייעל את ביצועי הגישה לזיכרון."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. במהלך החלפת הקשר (context switch), מערכת ההפעלה מפסיקה את ריצת התהליך הנוכחי, שומרת את מצבו וטוענת תהליך חדש (על פי chunk 16). חלק קריטי מתהליך זה, כפי שמפורט ב-chunk 15, הוא עדכון רגיסטרי ה-Base וה-Bounds במעבד. רגיסטרים אלו חיוניים לניהול הזיכרון ולהבטחת הגנת הזיכרון של התהליך החדש על ידי ה-MMU. עדכון רגיסטרים אלו הוא פעולה מיוחסת (privileged operation) שמותרת רק ב-kernel mode, ולכן רק מערכת ההפעלה יכולה לבצעה. זה מבטיח שאף תהליך משתמש לא יוכל לשנות את גבולות הזיכרון שלו באופן עצמאי ולגשת לזיכרון של תהליכים אחרים או של ה-kernel.\n\nאפשרויות ב' ו-ג' אינן מתארות את הפעולה הקריטית והספציפית ביותר לניהול זיכרון בהקשר של Base&Bounds ו-kernel mode כפי שמתואר בחומר. שמירת כל תוכן הזיכרון לדיסק אינה חלק סטנדרטי מ-context switch רגיל, והקצאת זיכרון חדש לחלוטין אינה תמיד נדרשת (התהליך הנכנס משתמש במקטעי הזיכרון שהוקצו לו כבר). אפשרות ד' שגויה לחלוטין, שכן היא מציעה שתהליך משתמש יכול לעדכן רגיסטרים של ה-MMU, דבר שמנוגד ישירות לדרישת ה-kernel mode עבור פעולות אלו (chunk 15 ו-24)."}, "_source_file": "0023__Virtualization__Context_Switching__MC__Medium.json", "_topic_hint": "Context Switching", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 16:57:07", "_subject": "Virtualization", "_context_lectures": [2, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Context Switching"], "difficulty_estimation": "Medium", "content": {"text": "מהי הסיבה העיקרית לכך שעדכון רגיסטרי ה-Base וה-Bounds במעבד, כחלק ממנגנון ה-Context Switch, חייב להתבצע במצב Kernel Mode?", "code_snippet": null, "options": ["א. כדי למנוע מתהליך משתמש לשנות את גבולות הזיכרון שהוקצו לו ולגשת לזיכרון של תהליכים אחרים או של מערכת ההפעלה.", "ב. מכיוון שרגיסטרי ה-Base וה-Bounds מכילים מידע קריטי לביצוע System Calls, אשר נגיש רק במצב Kernel Mode.", "ג. כי רק במצב Kernel Mode ניתן לבצע גישה ישירה לזיכרון הפיזי של המחשב.", "ד. מפני שעדכון רגיסטרים אלו דורש השהייה של כל התהליכים האחרים במערכת, פעולה שרק ה-Kernel רשאי לבצע."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה (Lecture 6, chunk 15), עדכון רגיסטרי ה-Base וה-Bounds במעבד מותר רק במצב Kernel Mode. הסיבה לכך היא שרגיסטרים אלו משמשים את יחידת ניהול הזיכרון (MMU) כדי לוודא שכל גישה לזיכרון על ידי תהליך המשתמש נמצאת בתוך גבולות הזיכרון שהוקצו לו. אם תהליך משתמש היה יכול לשנות רגיסטרים אלו באופן עצמאי, הוא היה יכול לעקוף את מנגנון הגנת הזיכרון, לגשת לזיכרון של תהליכים אחרים או של מערכת ההפעלה, ובכך לפגוע באבטחת ויציבות המערכת. לכן, פעולה זו היא פעולה מיוחסת (privileged operation) שרק מערכת ההפעלה יכולה לבצע במצב Kernel Mode במהלך Context Switch, כדי להבטיח את הפרדת הזיכרון והגנתו."}, "_source_file": "0024__Virtualization__Context_Switching__MC__Medium.json", "_topic_hint": "Context Switching", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 16:57:22", "_subject": "Virtualization", "_context_lectures": [2, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Context Switching"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על אתגר השליטה במנגנון ה-Context Switch, ובהתחשב בכך שפעולות קריטיות כמו עדכון רגיסטרי ה-Base&Bounds במעבד מותרות רק ב-kernel mode, איזו מסקנה נכונה לגבי אופן ביצוע החלפת הקשר (Context Switch) על ידי מערכת ההפעלה?", "code_snippet": null, "options": ["א. מערכת ההפעלה יכולה לבצע החלפת הקשר גם ב-User Mode, כל עוד התהליך הרץ לא מבקש פעולה מוגנת.", "ב. על מנת לבצע החלפת הקשר, מערכת ההפעלה חייבת תמיד לעלות ל-Kernel Mode, מכיוון שפעולות קריטיות לניהול תהליכים דורשות הרשאות אלו.", "ג. מנגנון ה-Direct Execution מאפשר למערכת ההפעלה להחליף הקשר על ידי \"הקפאת\" התהליך הרץ ישירות, ללא צורך בשינוי מצב ההרשאה.", "ד. החלפת הקשר מתרחשת רק בתגובה לקריאת מערכת יזומה של התהליך הרץ, ובכך מבטיחה מעבר ל-Kernel Mode לצורך הביצוע."]}, "solution": {"correct_option": "ב", "explanation": "מנגנון ה-Context Switch כולל פעולות שדורשות הרשאות גבוהות, כפי שמצוין בחומר ההרצאה. בפרט, עדכון רגיסטרי ה-Base&Bounds במעבד, אשר הכרחי לניהול זיכרון של התהליך החדש שנטען, מותר רק ב-Kernel Mode. מכאן שמערכת ההפעלה חייבת לעלות למצב Kernel Mode על מנת לבצע את תהליך החלפת ההקשר באופן תקין ובטוח, ובכך להתגבר על אתגר השליטה כשהתהליך הרץ שולט באופן מלא במעבד ב-User Mode. אפשרות א' שגויה כי פעולות קריטיות כמו עדכון Base&Bounds דורשות Kernel Mode תמיד. אפשרות ג' שגויה כי מנגנון Direct Execution מעניק שליטה מלאה לתהליך הרץ, ומערכת ההפעלה אינה יכולה 'להקפיא' אותו ללא מעבר הרשאות. אפשרות ד' שגויה מכיוון שהחלפת הקשר אינה מתרחשת 'רק' בתגובה לקריאת מערכת, וקיימים מנגנונים נוספים (כמו פסיקות תזמון) שמאפשרים למערכת ההפעלה להשיג שליטה ולבצע החלפת הקשר."}, "_source_file": "0025__Virtualization__Context_Switching__MC__Hard.json", "_topic_hint": "Context Switching", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 16:57:43", "_subject": "Virtualization", "_context_lectures": [2, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Context Switching"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על אתגרי מנגנון ה-Context Switch, ובפרט אתגר ה\"שליטה\" של מערכת ההפעלה, איזה מההיגדים הבאים מתאר בצורה המדויקת ביותר את הקושי בשיטת \"Direct Execution\" ואת הפתרון החלקי שקריאות מערכת (System Calls) מציעות בהקשר של ביצוע פעולות פריבילגיות כחלק מהחלפת הקשר?", "code_snippet": null, "options": ["א. בשיטת Direct Execution, מערכת ההפעלה מאבדת שליטה מוחלטת על המעבד בזמן ריצת התהליך, מה שמקשה עליה לבצע עדכוני Base&Bounds ברגיסטרי המעבד במהלך החלפת הקשר, שכן פעולה זו דורשת Kernel Mode. קריאות מערכת מאפשרות לתהליך לעבור מרצון ל-Kernel Mode, ובכך להחזיר זמנית את השליטה למערכת ההפעלה כדי לבצע פעולות אלו.", "ב. שיטת Direct Execution מבטיחה ביצועים אופטימליים בכך שהיא מונעת את הצורך ב-Context Switch תכוף, אך היא דורשת מהתהליכים לבצע את כל פעולות הזיכרון בעצמם. קריאות מערכת מאפשרות למערכת ההפעלה לנהל את הזיכרון עבור התהליכים, אך אינן קשורות ישירות לאתגר השליטה בזמן החלפת הקשר.", "ג. אתגר השליטה ב-Direct Execution נובע מכך שמערכת ההפעלה אינה יכולה לשמור את כל הרגיסטרים ומיקומי הזיכרון של תהליך מושהה. קריאות מערכת פותרות זאת על ידי שמירת מצב התהליך באופן אוטומטי ב-PCB לפני כל מעבר ל-Kernel Mode.", "ד. בשיטת Direct Execution, מערכת ההפעלה חייבת להמתין שהתהליך יסיים את ריצתו לחלוטין לפני שהיא יכולה להחליף תהליך. קריאות מערכת מאפשרות לתהליך להודיע למערכת ההפעלה על רצונו לסיים, ובכך לזרז את החלפת הקשר."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה, בשיטת Direct Execution, כשתהליך רץ, הוא שולט באופן מלא במעבד (chunk 20), מה שיוצר את אתגר ה\"שליטה\" עבור מערכת ההפעלה (chunk 16). קושי זה בא לידי ביטוי בכך שמערכת ההפעלה אינה יכולה לבצע פעולות פריבילגיות, כמו עדכון רגיסטרי ה-Base&Bounds במעבד במהלך Context Switch, פעולה אשר חיונית לניהול הזיכרון ודורשת Kernel Mode (chunk 15). קריאות מערכת (System Calls) מהוות מנגנון שבאמצעותו תהליך יכול לעבור מרצון מ-User Mode ל-Kernel Mode, ובכך להחזיר את השליטה למערכת ההפעלה ולאפשר לה לבצע את הפעולות הפריבילגיות הנדרשות, כולל אלו הקשורות להחלפת הקשר ולניהול זיכרון (chunk 24). התשובות האחרות אינן מדויקות: ב' מטעה לגבי הצורך ב-Context Switch וניהול הזיכרון; ג' אינה מתארת נכונה את אתגר השליטה או את תפקיד קריאות המערכת בשמירת ההקשר; ו-ד' מציגה תפקיד שגוי לקריאות מערכת בהקשר של סיום תהליכים ואינה מתייחסת לעיקר אתגר השליטה בפעולות פריבילגיות."}, "_source_file": "0026__Virtualization__Context_Switching__MC__Hard.json", "_topic_hint": "Context Switching", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 16:58:01", "_subject": "Virtualization", "_context_lectures": [2, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Context Switching"], "difficulty_estimation": "Hard", "content": {"text": "בהתחשב באתגר ה\"שליטה\" בהחלפת הקשר (context switch), ובדרישה לפעולות מיוחסות (privileged operations) כמו עדכון רגיסטרי Base&Bounds במהלך החלפה, איזה מנגנון בלעדי המתואר בחומר הלימוד מאפשר למערכת ההפעלה להשיב לעצמה שליטה מתהליך משתמש רץ ולבצע פעולות אלו?", "code_snippet": null, "options": ["א. התהליך מבצע קריאת מערכת (system call), אשר מעלה את הרשאותיו ומעבירה את המעבד למצב ליבה (kernel mode), ובכך מאפשרת למערכת ההפעלה לבצע את הפעולות המיוחסות הנדרשות להחלפת הקשר.", "ב. מערכת ההפעלה מריצה ללא הרף קוד ברקע במקביל לתהליך המשתמש, ובכך שומרת על שליטה רציפה ומבצעת החלפת קשר בכל עת.", "ג. התהליך הרץ מוריד את הרשאותיו באופן יזום למצב משתמש (user mode) כאשר הוא מגיע לסוף יחידת הזמן שהוקצתה לו, מה שמאפשר למערכת ההפעלה להשתלט.", "ד. מנגנון Direct Execution מבטיח שהתהליך ירוץ עד לסיומו המלא, ורק אז מערכת ההפעלה משיבה לעצמה שליטה לביצוע החלפת קשר."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר הלימוד מציין במפורש כי \"כשנהליך רץ, זה אומר שהמעבד מבצע את הפקודות של אותו תהליך, ולכן בזמן זה מערכת ההפעלה לא רצה\" (Lecture 2, chunk 16), מה שמדגיש את אתגר ה\"שליטה\". על מנת שמערכת ההפעלה תוכל לבצע החלפת הקשר, היא זקוקה לשליטה ולפעולות מיוחסות. המנגנון היחיד המתואר בחומר הלימוד שמאפשר לתהליך משתמש לעבור למצב ליבה (kernel mode) הוא קריאת מערכת (system call): \"ברגע שתהליך מבצע קריאת מערכת – ההרשאות שלו עולות. מתבצעת החלפה מ-user mode ל-kernel mode\" (Lecture 2, chunk 24). במצב ליבה, מערכת ההפעלה יכולה לבצע פעולות מיוחסות כמו עדכון רגיסטרי Base&Bounds במעבד, פעולה ש\"מותר רק ב-kernel mode, לכן רק מערכת ההפעלה יכולה לעשות זאת\" (Lecture 6, chunk 15). לכן, קריאת מערכת היא הדרך המתוארת בחומר שבה מערכת ההפעלה משיבה לעצמה שליטה לביצוע פעולות קריטיות בהחלפת הקשר.\n\nאפשרויות ב', ג' ו-ד' אינן נכונות:\n*   אפשרות ב' סותרת ישירות את הכתוב בחומר לפיו מערכת ההפעלה אינה רצה כאשר תהליך משתמש רץ.\n*   אפשרות ג' מתארת מנגנון של הורדת הרשאות יזומה שאינו מוזכר בחומר הלימוד.\n*   אפשרות ד' מתארת את מנגנון ה-Direct Execution שבו התהליך רץ עד לסיום, והוא אינו מתאר כיצד מערכת ההפעלה משיבה שליטה מתהליך רץ על מנת לבצע החלפת קשר במובן הרחב (הכולל קדם-אמפטיה)."}, "_source_file": "0027__Virtualization__Context_Switching__MC__Hard.json", "_topic_hint": "Context Switching", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 16:58:24", "_subject": "Virtualization", "_context_lectures": [2, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["System Calls"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של מנגנון קריאות המערכת (System Calls) במערכת הפעלה, כפי שתואר בחומר ההרצאה?", "code_snippet": null, "options": ["א. לאפשר לתהליכי משתמש לבצע פעולות מיוחסות (privileged operations) באופן בטוח ומבוקר על ידי מערכת ההפעלה.", "ב. להבטיח שתהליכים לעולם לא יוכלו לגשת לזיכרון ה-kernel.", "ג. לשלוח סיגנלים בין תהליכים שונים לצורך תקשורת.", "ד. לאפשר למערכת ההפעלה לוותר על שליטה במעבד לטובת תהליכי משתמש."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, מנגנון קריאות המערכת (System Calls) נועד לפתור את בעיית האבטחה. הוא מאפשר לתהליכי משתמש, הפועלים במצב משתמש (user mode), לבקש שירותים מוגבלים (privileged operations) ממערכת ההפעלה, הפועלת במצב ליבה (kernel mode). הציטוט הרלוונטי הוא: \"המנגנון של ה-system call עוזר לנו להתמודד עם בעיה אחת מבין השתיים שהיו לנו: בעיית האבטחה נפתרה. ברגע שהוספנו שני מצבים למעבד, ונתנו מנגנון של קריאת מערכת, מנענו גישה של תהליכים לרכיבי חומרה, ותהליך לא יכול לבצע מה שהוא רוצה אבל עדיין יש לו את האפשרות לבקש שירותים ממערכת ההפעלה והיא תבצע זאת עבורו בצורה בטוחה.\" לכן, המטרה העיקרית היא לאפשר גישה בטוחה ומבוקרת למשאבי חומרה ולשירותי מערכת שדורשים הרשאות גבוהות."}, "_source_file": "0028__Virtualization__System_Calls__MC__Easy.json", "_topic_hint": "System Calls", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 16:58:37", "_subject": "Virtualization", "_context_lectures": [2, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["System Calls"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של קריאת מערכת (System Call) במערכת הפעלה, כפי שתואר בחומר ההרצאה?", "code_snippet": "```c\n#include <stdio.h>\n#include <fcntl.h> // For open()\n#include <unistd.h> // For close()\n\nint main() {\n    int fd;\n    // The open() function is a library call that typically\n    // makes a system call to the OS kernel to open a file.\n    fd = open(\"example.txt\", O_CREAT | O_WRONLY, 0644);\n    if (fd == -1) {\n        perror(\"Error opening file\");\n        return 1;\n    }\n    printf(\"File opened successfully with file descriptor: %d\\n\", fd);\n    close(fd); // close() also involves a system call\n    return 0;\n}\n```", "options": ["א. לאפשר לתהליכי משתמש לבצע פעולות מורשות (privileged operations) באופן בטוח, תוך העברת שליטה למצב ליבה (kernel mode).", "ב. להעביר הודעות (signals) בין תהליכים שונים לצורך תקשורת.", "ג. לאפשר גישה ישירה של תהליכי משתמש לטבלת התהליכים (process table) של מערכת ההפעלה.", "ד. לוותר על שימוש במעבד ולהחזיר את השליטה למערכת ההפעלה באופן וולונטרי (yield)."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה (Lecture 2, chunk 28 ו-24), המנגנון של קריאת מערכת (System Call) נועד לפתור את בעיית האבטחה ולאפשר לתהליכים במצב משתמש (user mode) לבקש שירותים מרכיבי חומרה או לבצע פעולות מורשות (privileged operations) בצורה בטוחה. כאשר תהליך מבצע קריאת מערכת, ההרשאות שלו עולות ומתבצעת החלפה ממצב משתמש למצב ליבה (kernel mode), מה שמעביר את השליטה לגרעין מערכת ההפעלה כדי שיבצע את הפעולה המבוקשת בצורה מבוקרת ומאובטחת.\n\nאפשרויות אחרות אינן נכונות:\nב. העברת הודעות (signals) בין תהליכים היא מנגנון נפרד, ובעוד שקריאת מערכת יכולה לשמש לשליחת signal, זו אינה המטרה העיקרית של קריאות מערכת באופן כללי (Lecture 5, chunk 9).\nג. חומר ההרצאה מציין במפורש כי לתהליכי משתמש אין גישה ישירה לטבלת התהליכים (process table) של מערכת ההפעלה; גישה זו שמורה ל-kernel בלבד (Lecture 2, chunk 17).\nד. 'yield' היא קריאת מערכת ספציפית שנועדה לוותר על המעבד באופן וולונטרי, אך זוהי מטרה מאוד ספציפית ואינה המטרה העיקרית והכוללת של כלל קריאות המערכת (Lecture 2, chunk 29)."}, "_source_file": "0029__Virtualization__System_Calls__MC__Easy.json", "_topic_hint": "System Calls", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 16:58:53", "_subject": "Virtualization", "_context_lectures": [2, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["System Calls"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של קריאת מערכת (System Call) עבור תהליך במצב משתמש (User Mode)?", "code_snippet": null, "options": ["א. לאפשר לתהליך לגשת ישירות לרכיבי חומרה.", "ב. להעביר את השליטה למערכת ההפעלה כדי לבצע פעולות מיוחסות (privileged operations) בצורה בטוחה.", "ג. לשלוח אותות (signals) לתהליכים אחרים.", "ד. לעדכן את טבלת התהליכים (process table) בקרנל."]}, "solution": {"correct_option": "ב", "explanation": "קריאת מערכת (System Call) היא מנגנון המאפשר לתהליך הרץ במצב משתמש (User Mode) לבקש ממערכת ההפעלה לבצע עבורו פעולות הדורשות הרשאות מיוחדות (privileged operations), כגון גישה לחומרה, ניהול קבצים או הקצאת זיכרון. כפי שצויין בחומר ההרצאה, ברגע שתהליך מבצע קריאת מערכת, מתבצעת החלפה ממצב משתמש למצב קרנל (kernel mode), מה שמאפשר למערכת ההפעלה לבצע את הפעולה בצורה בטוחה ומבוקרת. מנגנון זה פותר את \"בעיית האבטחה\" בכך שהוא מונע מתהליכים גישה ישירה ומסוכנת למשאבי המערכת, תוך מתן אפשרות לבקש שירותים ממערכת ההפעלה שתבצע אותם עבורם בצורה בטוחה."}, "_source_file": "0030__Virtualization__System_Calls__MC__Easy.json", "_topic_hint": "System Calls", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 16:59:07", "_subject": "Virtualization", "_context_lectures": [2, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["System Calls"], "difficulty_estimation": "Medium", "content": {"text": "מדוע תהליכים במערכת הפעלה נדרשים להשתמש בקריאות מערכת (System Calls) על מנת לבצע פעולות כגון גישה לחומרה או הקצאת זיכרון, במקום לבצען באופן ישיר?", "code_snippet": null, "options": ["א. קריאות מערכת מאפשרות למערכת ההפעלה לשמור על שליטה ובטחון, בכך שהן מונעות מתהליכים גישה ישירה לרכיבי חומרה ומאפשרות להם לבקש שירותים בצורה בטוחה.", "ב. קריאות מערכת משמשות בעיקר לשיפור ביצועים על ידי אופטימיזציה של גישה לזיכרון והפחתת מיתוגי הקשר.", "ג. קריאות מערכת הן הדרך היחידה לתקשר עם תהליכים אחרים במערכת, בדומה לאופן שבו Signals עובדים.", "ד. קריאות מערכת נחוצות רק במערכות הפעלה מודרניות, בעוד שבמערכות הפעלה ישנות יותר תהליכים יכלו לגשת לחומרה באופן חופשי."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. לפי חומר ההרצאה (Chunk 28), מנגנון קריאות המערכת (System Calls) נועד לפתור את 'בעיית האבטחה' במערכת ההפעלה. על ידי הוספת שני מצבים למעבד (User Mode ו-Kernel Mode) ומתן מנגנון של קריאת מערכת, נמנעת גישה ישירה של תהליכים לרכיבי חומרה. תהליכים אינם יכולים לבצע פעולות מיוחסות (privileged operations) באופן עצמאי, אך הם יכולים לבקש שירותים אלו ממערכת ההפעלה, והיא תבצע אותם עבורם בצורה בטוחה במצב ה-Kernel (Chunk 24, 28). אופציה ב' אינה נכונה מכיוון ששיפור ביצועים אינו המטרה העיקרית של קריאות מערכת בהקשר זה. אופציה ג' אינה נכונה מכיוון שקריאות מערכת מיועדות לבקשת שירותים ממערכת ההפעלה ולא לתקשורת ישירה בין תהליכים, בניגוד ל-Signals (Chunk 9). אופציה ד' אינה נכונה מכיוון שהצורך בקריאות מערכת נובע משיקולי אבטחה ושליטה בסיסיים, ולא רק ממאפייני מערכות הפעלה מודרניות; הבעיה של שליטה וגישה לחומרה הייתה קיימת גם בעבר, והמנגנון פותר אותה באופן יסודי."}, "_source_file": "0031__Virtualization__System_Calls__MC__Medium.json", "_topic_hint": "System Calls", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 16:59:22", "_subject": "Virtualization", "_context_lectures": [2, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["System Calls"], "difficulty_estimation": "Medium", "content": {"text": "מהו התפקיד העיקרי של קריאת מערכת (system call) במערכת הפעלה, על פי חומר ההרצאה?", "code_snippet": null, "options": ["א. לאפשר לתהליכי משתמש לבצע פעולות מיוחסות (privileged operations) בצורה בטוחה, על ידי העברת שליטה לגרעין (kernel) ושינוי מצב המעבד.", "ב. לספק גישה ישירה ובלעדית לתהליכי משתמש לטבלת התהליכים (process table) בתוך ה-kernel.", "ג. לשמש כמנגנון תקשורת עיקרי בין תהליכים שונים (inter-process communication) באמצעות שליחת סיגנלים (signals).", "ד. לאפשר לתהליך לוותר מרצון על השימוש במעבד ולהחזיר את השליטה למערכת ההפעלה, כפי שהיה נהוג בגישה השיתופית (cooperative approach)."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, התפקיד העיקרי של קריאת מערכת הוא לפתור את \"בעיית האבטחה\" ולמנוע גישה לא מורשית של תהליכים לרכיבי חומרה. קריאת מערכת מאפשרת לתהליכי משתמש לבקש שירותים מיוחסים (privileged operations), כגון גישה לחומרה או הקצאת זיכרון, ממערכת ההפעלה. תהליך המבצע קריאת מערכת מעביר את השליטה למערכת ההפעלה (ה-kernel) ומשנה את מצב המעבד מ-user mode ל-kernel mode, מה שמאפשר ל-kernel לבצע את הפעולה בצורה בטוחה ומבוקרת עבור התהליך. אפשרות ב' אינה נכונה מכיוון שנאמר במפורש כי \"לנו אין גישה לטבלת התהליכים, זה שייך למערכת ההפעלה ורק ל-kernel יש גישה אליה\". אפשרות ג' אינה נכונה מכיוון שסיגנלים הם מנגנון לתקשורת בין תהליכים או הודעות ממערכת ההפעלה לתהליך, בעוד שקריאות מערכת הן מנגנון רחב יותר לבקשת שירותים מיוחסים. אפשרות ד' מתארת שימוש ספציפי ופחות נהוג כיום (קריאת yield בגישה השיתופית), ולא את התפקיד העיקרי והכללי של קריאות מערכת באבטחה ובניהול משאבים."}, "_source_file": "0032__Virtualization__System_Calls__MC__Medium.json", "_topic_hint": "System Calls", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 16:59:36", "_subject": "Virtualization", "_context_lectures": [2, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["System Calls"], "difficulty_estimation": "Medium", "content": {"text": "איזו בעיה עיקרית מנגנון קריאות המערכת (system calls) בא לפתור במערכת הפעלה?", "code_snippet": null, "options": ["א. לפתור את בעיית האבטחה ולאפשר לתהליכי משתמש לבקש שירותים מוגנים (privileged operations) ממערכת ההפעלה בצורה בטוחה.", "ב. להבטיח שמערכת ההפעלה תשמור על שליטה רציפה במעבד כשתהליך משתמש רץ.", "ג. לאפשר תקשורת ישירה ובטוחה בין תהליכי משתמש שונים (IPC).", "ד. לנהל את טבלת התהליכים (process table) בתוך ה-kernel ולאפשר לתהליכי משתמש לגשת אליה."]}, "solution": {"correct_option": "א", "explanation": "מנגנון קריאות המערכת (system calls) נועד בראש ובראשונה לפתור את בעיית האבטחה. על פי חומר ההרצאה, 'בעיית האבטחה נפתרה. ברגע שהוספנו שני מצבים למעבד, ונתנו מנגנון של קריאת מערכת, מנענו גישה של תהליכים לרכיבי חומרה, ותהליך לא יכול לבצע מה שהוא רוצה אבל עדיין יש לו את האפשרות לבקש שירותים ממערכת ההפעלה והיא תבצע זאת עבורו בצורה בטוחה.' (Lecture 2, chunk 28). קריאות מערכת מאפשרות לתהליכי משתמש לבצע פעולות מוגנות (privileged operations) כמו גישה לחומרה או הקצאת זיכרון, בכך שהן מעבירות את השליטה ל-kernel שמבצע את הפעולה עבור התהליך בצורה בטוחה.\n\nאפשרות ב' שגויה מכיוון שחומר ההרצאה מציין במפורש כי בעיית השליטה הרציפה של מערכת ההפעלה במעבד נותרה בעיה נפרדת שקריאות המערכת לא פותרות באופן ישיר: 'נותרה לנו בעיה שנייה – איך מערכת ההפעלה שומרת על שליטה במעבד? ברגע שתהליך רץ, המעבד מריץ אותו פקודה אחרי פקודה ואז מערכת ההפעלה לא רצה ולא יכולה להריץ קוד.' (Lecture 2, chunk 28).\n\nאפשרות ג' שגויה מכיוון שתקשורת בין תהליכים (IPC) מיוחסת בחומר ההרצאה בעיקר ל-signals: 'סיגנלים יכולים גם לשמש לתקשורת: אם תהליך אחד רוצה להודיע משהו לתהליך אחר (לשלוח סיגנל).' (Lecture 5, chunk 9).\n\nאפשרות ד' שגויה מכיוון שלתהליכי משתמש אין גישה ישירה לטבלת התהליכים (process table) והיא מנוהלת על ידי ה-kernel בלבד: 'לנו אין גישה לטבלת התהליכים, זה שייך למערכת ההפעלה ורק ל-kernel יש גישה אליה.' (Lecture 2, chunk 17). קריאות מערכת מאפשרות לבקש שירותים, לא לגשת ישירות או לנהל מבני נתונים פנימיים של ה-kernel."}, "_source_file": "0033__Virtualization__System_Calls__MC__Medium.json", "_topic_hint": "System Calls", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 16:59:51", "_subject": "Virtualization", "_context_lectures": [2, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["System Calls"], "difficulty_estimation": "Hard", "content": {"text": "למרות שקריאות מערכת (system calls) גורמות למעבר ממצב משתמש (user mode) למצב ליבה (kernel mode), ומאפשרות למערכת ההפעלה לבצע פעולות בשם התהליך המבקש, מדוע מנגנון זה לבדו אינו מספק על מנת להבטיח שליטה רציפה של מערכת ההפעלה במעבד?", "code_snippet": null, "options": ["א. קריאות מערכת פותרות את בעיית האבטחה אך אינן מספקות מנגנון למערכת ההפעלה להחזיר לעצמה שליטה יזומה כאשר תהליך רץ ברצף מבלי לבצע קריאת מערכת.", "ב. קריאות מערכת מיועדות רק לגישה לחומרה ואינן קשורות כלל לשמירת שליטה במעבד.", "ג. מעבר למצב ליבה באמצעות קריאת מערכת מוגבל בזמן וחוזר אוטומטית למצב משתמש לאחר פרק זמן קצר.", "ד. תהליכים במצב משתמש יכולים לעקוף קריאות מערכת ולגשת ישירות למשאבי חומרה, ובכך למנוע שליטה של מערכת ההפעלה."]}, "solution": {"correct_option": "א", "explanation": "הסבר: קריאות מערכת אכן מאפשרות למערכת ההפעלה להשיג שליטה באופן זמני ולבצע פעולות מורשות (privileged operations) בצורה בטוחה, ובכך פותרות את בעיית האבטחה. אולם, כפי שמצוין בחומר ההרצאה, \"נותרה לנו בעיה שנייה – איך מערכת ההפעלה שומרת על שליטה במעבד? ברגע שתהליך רץ, המעבד מריץ אותו פקודה אחרי פקודה ואז מערכת ההפעלה לא רצה ולא יכולה להריץ קוד.\" (Lecture 2, chunk 28). כלומר, אם תהליך רץ במצב משתמש ואינו מבצע קריאת מערכת, מערכת ההפעלה אינה מקבלת שליטה בחזרה באופן יזום. גישת ה-Cooperative approach, שבה תהליכים היו אמורים לבצע קריאות מערכת כמו `yield` כדי לוותר על המעבד, נחשבת לבעייתית מכיוון שהיא \"סומכת יותר מדי על התהליכים\" (Lecture 2, chunk 29). לכן, קריאות מערכת לבדן אינן מספקות שליטה רציפה של מערכת ההפעלה. אפשרות ב' שגויה מכיוון שקריאות מערכת קשורות גם לשמירת שליטה (כמו ב-`yield`) וגם לביצוע פעולות אחרות מעבר לגישה ישירה לחומרה (כמו הקצאת זיכרון או פתיחת קובץ). אפשרות ג' שגויה כיוון שאין הגבלת זמן על שהות הליבה במצב ליבה; הליבה חוזרת למצב משתמש רק לאחר שסיימה את פעולתה. אפשרות ד' שגויה לחלוטין, שכן מנגנון קריאות המערכת והמעבר בין מצבים נועד בדיוק למנוע מתהליכים במצב משתמש לגשת ישירות למשאבי חומרה."}, "_source_file": "0034__Virtualization__System_Calls__MC__Hard.json", "_topic_hint": "System Calls", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:00:06", "_subject": "Virtualization", "_context_lectures": [2, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["System Calls"], "difficulty_estimation": "Hard", "content": {"text": "מנגנון קריאות המערכת (System Calls) מהווה בסיס לפעילות מערכות הפעלה מודרניות. בהתבסס על החומר הנלמד, איזה מההיגדים הבאים מתאר בצורה המדויקת ביותר את תרומתו ומגבלתו של מנגנון קריאות המערכת בהקשר של שליטת מערכת ההפעלה במעבד ובאבטחת המערכת?", "code_snippet": null, "options": ["א. קריאות מערכת פותרות את בעיית האבטחה בכך שהן מאפשרות גישה מבוקרת לפעולות פריבילגיות, אך אינן מבטיחות שמערכת ההפעלה תשמור על שליטה במעבד אם תהליך משתמש לא יבצע אותן באופן יזום, כפי שבא לידי ביטוי בגישה השיתופית.", "ב. קריאות מערכת מבטיחות שמערכת ההפעלה תמיד שומרת על שליטה מלאה במעבד על ידי העברת שליטה ל-kernel בכל עת, ובכך פותרות הן את בעיית האבטחה והן את בעיית השליטה.", "ג. קריאות מערכת משמשות בעיקר לתקשורת בין-תהליכית (IPC) באמצעות סיגנלים, וכך מאפשרות למערכת ההפעלה לקטוע תהליכים ולשמר שליטה.", "ד. קריאות מערכת הן מנגנון מיושן ששימש בעיקר במערכות הפעלה שיתופיות, ואינן רלוונטיות עוד לשמירה על אבטחה או שליטה במערכות הפעלה מודרניות."]}, "solution": {"correct_option": "א", "explanation": "החומר הנלמד מציין במפורש כי \"המנגנון של ה-system call עוזר לנו להתמודד עם בעיה אחת מבין השתיים שהיו לנו: בעיית האבטחה נפתרה... נותרה לנו בעיה שנייה – איך מערכת ההפעלה שומרת על שליטה במעבד?\". כלומר, קריאות מערכת פותרות את בעיית האבטחה בכך שהן מאפשרות לתהליכי משתמש לבקש שירותים פריבילגיים מה-kernel בצורה בטוחה (מעבר מ-user mode ל-kernel mode). עם זאת, הן אינן פותרות את בעיית השליטה הבלתי תלויה של מערכת ההפעלה במעבד, שכן תהליך משתמש עלול להיכנס ללולאה אינסופית מבלי לבצע קריאת מערכת, ובכך למנוע מה-OS להריץ קוד משלה. הגישה השיתופית (Cooperative approach), אשר הסתמכה על קריאות מערכת כמו `yield` כדי שתהליכים יוותרו על המעבד, נחשבת ל\"פחות נהוגה כיום\" ובעייתית בדיוק בגלל שהיא \"סומכים יותר מדי על התהליכים\". לכן, קריאות מערכת תורמות לאבטחה אך אינן מבטיחות שליטה מלאה ועצמאית במעבד."}, "_source_file": "0035__Virtualization__System_Calls__MC__Hard.json", "_topic_hint": "System Calls", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:00:21", "_subject": "Virtualization", "_context_lectures": [2, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["System Calls"], "difficulty_estimation": "Hard", "content": {"text": "על פי חומר ההרצאה, מנגנון קריאות המערכת (system calls) פותר את בעיית האבטחה בכך שהוא מאפשר לתהליכי משתמש לבקש שירותים מורשים מהגרעין בצורה בטוחה. עם זאת, נותרה בעיה נוספת בהקשר לשליטה של מערכת ההפעלה על המעבד. איזו מבין הטענות הבאות מתארת בצורה הטובה ביותר את המגבלה המהותית של קריאות מערכת, כשלעצמן, בשמירה על שליטה רציפה של מערכת ההפעלה על המעבד, כפי שנדון בגישה ה\"שיתופית\" (Cooperative approach)?", "code_snippet": null, "options": ["א. קריאות מערכת תלויות ברצונם הטוב של התהליכים לבצע אותן; תהליך שלא יבצע קריאת מערכת לא יחזיר את השליטה לגרעין.", "ב. קריאות מערכת מבוצעות תמיד במצב משתמש (user mode) ולכן אינן יכולות לשנות את הקשר התהליך.", "ג. קריאות מערכת אינן מסוגלות לגשת לטבלת התהליכים (process table) ולכן אינן יכולות לנהל את תזמון המעבד.", "ד. קריאות מערכת מיועדות רק לתקשורת בין תהליכים (IPC) ואינן קשורות לשליטה על המעבד."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר ההרצאה מציין במפורש שמנגנון קריאות המערכת פותר את בעיית האבטחה על ידי העברת השליטה לגרעין (kernel) במצב מורשה (kernel mode) לביצוע פעולות מסוכנות. אולם, ההרצאה מדגישה כי \"נותרה לנו בעיה שנייה – איך מערכת ההפעלה שומרת על שליטה במעבד?\" ומציגה את הגישה ה\"שיתופית\" (Cooperative approach) כדרך התמודדות. בגישה זו, מערכת ההפעלה סומכת על התהליכים שיבצעו קריאות מערכת (כמו קריאת `yield` שנועדה לוותר על המעבד) או שיתרחשו אירועים, כדי להחזיר את השליטה לגרעין. הבעיה המהותית בגישה זו, כפי שצוין בהרצאה, היא ש\"יש סומכים יותר מדי על התהליכים\". אם תהליך מסוים אינו מבצע קריאות מערכת, או אינו מבצע את קריאת ה-`yield`, מערכת ההפעלה מאבדת את השליטה על המעבד ואינה יכולה לתזמן תהליכים אחרים. לכן, קריאות מערכת כשלעצמן אינן מספיקות להבטחת שליטה רציפה ובלתי תלויה של מערכת ההפעלה על המעבד."}, "_source_file": "0036__Virtualization__System_Calls__MC__Hard.json", "_topic_hint": "System Calls", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:00:40", "_subject": "Virtualization", "_context_lectures": [2, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Signals"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של סיגנלים (signals) במערכת הפעלה, כפי שתוארו בחומר הנלמד?", "code_snippet": null, "options": ["א. לאפשר למערכת ההפעלה להודיע אירועים לתהליכים, או לתהליכים לתקשר ביניהם.", "ב. לטפל באופן בלעדי בפסיקות חומרה (hardware interrupts).", "ג. לוודא שתהליכי בן (child processes) תמיד יסיימו את ריצתם לפני תהליכי אב (parent processes).", "ד. למנוע מצב של לולאה אינסופית בתהליכים."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה (Chunk 9 ו-10), סיגנלים מתוארים כ'אירועים של התהליך, הודעות שמערכת ההפעלה רוצה להודיע לתהליך שלנו' וכן ש'סיגנלים יכולים גם לשמש לתקשורת: אם תהליך אחד רוצה להודיע משהו לתהליך אחר (לשלוח סיגנל)'. לכן, האפשרות הנכונה ביותר היא שאותות מאפשרים למערכת ההפעלה להודיע לתהליכים על אירועים, וכן לתהליכים לתקשר ביניהם."}, "_source_file": "0037__Virtualization__Signals__MC__Easy.json", "_topic_hint": "Signals", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:00:50", "_subject": "Virtualization", "_context_lectures": [4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Signals"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של סיגנלים (Signals) בהקשר של תהליכים במערכת הפעלה?", "code_snippet": null, "options": ["א. לאפשר למערכת ההפעלה להודיע אירועים לתהליכים, או לתהליכים לתקשר ביניהם.", "ב. לנהל את הקצאת הזיכרון בין תהליכים שונים.", "ג. לאפשר לתהליכים לעצור את ביצועם ולעבור למצב המתנה (waiting) באופן יזום בלבד.", "ד. לאבטח את המערכת מפני גישה לא מורשית לקבצים."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה (Chunk 9), סיגנלים מוגדרים כ'אירועים של התהליך, הודעות שמערכת ההפעלה רוצה להודיע לתהליך שלנו'. בנוסף, נכתב ש'סיגנלים יכולים גם לשמש לתקשורת: אם תהליך אחד רוצה להודיע משהו לתהליך אחר (לשלוח סיגנל)'. לכן, המטרה העיקרית של סיגנלים היא להודיע על אירועים לתהליכים ולשמש לתקשורת ביניהם."}, "_source_file": "0038__Virtualization__Signals__MC__Easy.json", "_topic_hint": "Signals", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:01:00", "_subject": "Virtualization", "_context_lectures": [4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Signals"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, מהם סיגנלים (signals) בהקשר של תהליכים במערכת הפעלה?", "code_snippet": null, "options": ["א. אירועים או הודעות שמערכת ההפעלה שולחת לתהליך, או שתהליך אחד שולח לתהליך אחר.", "ב. מנגנון המאפשר לתהליכים לבצע קריאות מערכת (system calls) באופן אסינכרוני.", "ג. סוג מיוחד של תהליכים קלים (lightweight processes) המשמשים לטיפול בפסיקות חומרה.", "ד. חלק מטבלת דפי הזיכרון (page table) של התהליך המשמש לניהול זיכרון וירטואלי."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מגדיר במפורש סיגנלים כ'אירועים של התהליך, הודעות שמערכת ההפעלה רוצה להודיע לתהליך שלנו'. הוא מוסיף ש'סיגנלים יכולים גם לשמש לתקשורת: אם תהליך אחד רוצה להודיע משהו לתהליך אחר (לשלוח סיגנל)'. לכן, אפשרות א' מתארת במדויק את תפקידם ומהותם של הסיגנלים כפי שהוצגו. אפשרויות ב', ג' ו-ד' מתארות מושגים שאינם תואמים את הגדרת הסיגנלים בחומר ההרצאה."}, "_source_file": "0039__Virtualization__Signals__MC__Easy.json", "_topic_hint": "Signals", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:01:15", "_subject": "Virtualization", "_context_lectures": [4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Signals"], "difficulty_estimation": "Medium", "content": {"text": "בהתייחס לטיפול בסיגנלים, אילו מהאפשרויות הבאות מתארת נכונה דרכים למנוע יצירת תהליכי זומבי (zombie processes) באמצעות הסיגנל SIGCHLD?", "code_snippet": "void signal_handler(int signal) {\n    if (signal == SIGCHLD) {\n        int rc = wait(NULL);\n        printf(\"child terminated %d (pid:%d)\\n\", rc, getpid());\n    }\n}\n\nint main(int argc, char *argv[])\n{\n    struct sigaction act;\n    sigemptyset(&act.sa_mask);\n    act.sa_handler = signal_handler;\n    act.sa_flags = 0;\n    \n    sigaction(SIGCHLD, &act, NULL);\n    if (fork()) {\n        while (1);\n    }\n}", "options": ["א. על ידי הגדרת פונקציית מטפל (signal handler) לסיגנל SIGCHLD המבצעת קריאה ל-wait(), או על ידי התעלמות מוחלטת מהסיגנל באמצעות SIG_IGN.", "ב. רק על ידי הגדרת פונקציית מטפל לסיגנל SIGCHLD המבצעת קריאה ל-wait().", "ג. רק על ידי התעלמות מוחלטת מהסיגנל SIGCHLD באמצעות SIG_IGN.", "ד. על ידי שליחת סיגנל SIGKILL לתהליך הבן מיד לאחר יצירתו."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מתאר שתי דרכים עיקריות למנוע יצירת תהליכי זומבי (zombie processes) באמצעות הסיגנל SIGCHLD. הדרך הראשונה היא להגדיר פונקציית מטפל (signal handler) עבור הסיגנל SIGCHLD, שבתוכה מתבצעת קריאה לפונקציית המערכת wait(). קריאה זו גורמת למערכת ההפעלה לאסוף את משאבי התהליך הבן שסיים את ריצתו ולמחוק אותו, כפי שמודגם בקוד המצורף. הדרך השנייה, כפי שצוין בחומר, היא להתעלם מוחלטת מהסיגנל SIGCHLD על ידי הגדרתו ל-SIG_IGN. במקרה זה, מערכת ההפעלה מנקה את התהליך הבן מיד עם סיומו, מבלי להודיע לתהליך האב, ובכך מונעת יצירת זומבים. לכן, תשובה א' היא הנכונה שכן היא כוללת את שתי השיטות הללו. תשובות ב' ו-ג' שגויות מכיוון שהן מציגות רק אחת מהשיטות כבלעדית. תשובה ד' אינה רלוונטית למניעת זומבים באמצעות טיפול ב-SIGCHLD, ואינה מתוארת בחומר כדרך למנוע זומבים בהקשר זה."}, "_source_file": "0040__Virtualization__Signals__MC__Medium.json", "_topic_hint": "Signals", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:01:31", "_subject": "Virtualization", "_context_lectures": [4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Signals"], "difficulty_estimation": "Medium", "content": {"text": "מהי ההקבלה התיאורטית המרכזית של סיגנלים (signals) במערכת ההפעלה, וכיצד הם משמשים לניהול תהליכים, על פי החומר הנלמד?", "code_snippet": null, "options": ["א. סיגנלים הם מנגנון המאפשר למערכת ההפעלה להודיע לתהליכים על אירועים שונים, בדומה לאופן שבו פסיקות (interrupts) מטפלות באירועים ברמת המערכת, ומאפשרים לכל תהליך להגדיר דרכי טיפול מותאמות אישית לאירועים אלו.", "ב. סיגנלים משמשים בעיקר לתקשורת בין-תהליכית (IPC) בלבד, ומאפשרים לתהליכים להחליף נתונים ביניהם בצורה מסונכרנת.", "ג. המטרה העיקרית של סיגנלים היא למנוע מצבי מרוץ (race conditions) בין תהליכים, על ידי נעילה אוטומטית של משאבים משותפים.", "ד. סיגנלים מיועדים לטפל בגישה לא חוקית לזיכרון על ידי תהליכים, ומפעילים שגרות טיפול ייעודיות בתוך הליבה."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. החומר המצוין בהרצאה קובע במפורש כי \"אם נגיד שפסיקה זה כמו אירועים במערכת ההפעלה, אז signals זה אותו דבר עבור תהליכים.\" זה מדגיש את ההקבלה התיאורטית המרכזית בין פסיקות (interrupts), שהן אירועים ברמת המערכת, לבין סיגנלים, שהם אירועים ברמת התהליך. בנוסף, נכתב שלכל תהליך יש \"מעין טבלת אירועים כזו, של משהו שנקרא signal, ולכל אירוע יש קטע קוד שמטפל בו,\" וכי \"אנחנו יכולים להשפיע על הטבלה הזו.\" זה תומך בכך שתהליכים יכולים להגדיר דרכי טיפול מותאמות אישית לאירועים אלו.\nאפשרויות ב', ג' וד' אינן נכונות:\nב. למרות שסיגנלים יכולים לשמש לתקשורת בין-תהליכית (\"סיגנלים יכולים גם לשמש לתקשורת\"), זו אינה מטרתם התיאורטית העיקרית והבלעדית, וההסבר מתעלם מההקבלה לפסיקות.\nג. החומר לא מזכיר כלל את תפקידם של סיגנלים במניעת מצבי מרוץ או נעילת משאבים.\nד. \"גישה לזיכרון לא תקין\" מוזכרת בהקשר של פסיקות המטופלות על ידי מערכת ההפעלה, ולא כשימוש ישיר של סיגנלים המיועדים לטיפול בתוך הליבה עבור תהליכים. סיגנלים הם אירועים ברמת התהליך."}, "_source_file": "0041__Virtualization__Signals__MC__Medium.json", "_topic_hint": "Signals", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:01:48", "_subject": "Virtualization", "_context_lectures": [4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Signals"], "difficulty_estimation": "Medium", "content": {"text": "על פי חומר ההרצאה, מהו תפקידו העיקרי של האות SIGCHLD ושל פונקציית הטיפול (signal handler) בו במניעת תהליכי זומבי?", "code_snippet": "void signal_handler(int signal) {\n    if (signal == SIGCHLD) {\n        int rc = wait(NULL);\n        printf(\"child terminated %d (pid:%d)\\n\", rc, getpid());\n    }\n}\n\nint main(int argc, char *argv[])\n{\n    struct sigaction act;\n    sigemptyset(&act.sa_mask);\n    act.sa_handler = signal_handler;\n    act.sa_flags = 0;\n    \n    sigaction(SIGCHLD, &act, NULL);\n    if (fork()) {\n        while (1);\n    }\n}", "options": ["א. האות SIGCHLD נשלח לתהליך האב כאשר תהליך בן מסיים את ריצתו, ופונקציית הטיפול בו קוראת ל-wait כדי לאסוף את משאבי הבן.", "ב. האות SIGCHLD מורה לתהליך האב להתעלם מסיום ריצת הבן, ובכך מונע היווצרות זומבים באופן אוטומטי ללא צורך בקריאה ל-wait.", "ג. האות SIGCHLD מאפשר לתהליך האב לבטל את תהליך הבן לפני סיומו, ובכך למנוע מצב של זומבי.", "ד. האות SIGCHLD מציין מצב שבו תהליך הבן נכנס ללולאה אינסופית, ופונקציית הטיפול בו מנסה להרוג את הבן."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה, כאשר תהליך בן מסיים את ריצתו, מערכת ההפעלה שולחת אות SIGCHLD לתהליך האב. אם תהליך האב הגדיר פונקציית טיפול (signal handler) עבור אות זה, פונקציה זו תופעל. בתוך פונקציית הטיפול, קריאה לפונקציית המערכת wait (כמו wait(NULL) בדוגמת הקוד) מאפשרת לאסוף את משאבי התהליך הבן שהסתיים, ובכך למנוע את הפיכתו לתהליך זומבי. אפשרות ב' מתארת דרך אחרת למנוע זומבים, על ידי הגדרת התעלמות מהאות (SIG_IGN), שבמקרה כזה מערכת ההפעלה מפנה את משאבי הבן באופן אוטומטי מבלי שהאב יצטרך לקרוא ל-wait. אפשרויות ג' ו-ד' אינן מתארות נכונה את תפקיד ה-SIGCHLD."}, "_source_file": "0042__Virtualization__Signals__MC__Medium.json", "_topic_hint": "Signals", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:02:01", "_subject": "Virtualization", "_context_lectures": [4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Signals"], "difficulty_estimation": "Hard", "content": {"text": "תהליך אב יוצר תהליך בן. מהי ההבחנה התיאורטית המרכזית בין הגדרת הטיפול באות SIGCHLD של תהליך האב ל-SIG_IGN (התעלמות מוחלטת) לבין הגדרת פונקציית מטפל מותאמת אישית (custom handler) שקוראת ל-wait()?", "code_snippet": "void signal_handler(int signal) {\n    if (signal == SIGCHLD) {\n        int rc = wait(NULL);\n        printf(\"child terminated %d (pid:%d)\\n\", rc, getpid());\n    }\n}\n\nint main(int argc, char *argv[])\n{\n    struct sigaction act;\n    sigemptyset(&act.sa_mask);\n    act.sa_handler = signal_handler;\n    act.sa_flags = 0;\n    \n    sigaction(SIGCHLD, &act, NULL);\n    if (fork()) {\n        while (1);\n    }\n}", "options": ["א. בשני המקרים, מערכת ההפעלה מונעת היווצרות תהליכי זומבי, אך רק במקרה של SIG_IGN האב לא מקבל הודעה על סיום הבן.", "ב. במקרה של SIG_IGN, מערכת ההפעלה מונעת זומבים באופן אוטומטי, בעוד שבמקרה של מטפל מותאם אישית, תהליך הזומבי נוצר אך נמחק מיד על ידי קריאת wait().", "ג. במקרה של SIG_IGN, מערכת ההפעלה תמיד תיצור תהליך זומבי כדי להבטיח שהאב יוכל לבדוק את סטטוס הסיום של הבן מאוחר יותר, בעוד שמטפל מותאם אישית מונע זאת.", "ד. ההבדל העיקרי הוא ש-SIG_IGN מאפשר לאב להמשיך לפעול ללא הפרעה, בעוד שמטפל מותאם אישית גורם להשהיה קצרה של האב בזמן ביצוע ה-wait()."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה, בשני המקרים – בין אם תהליך האב מתעלם מסיגנל SIGCHLD באמצעות SIG_IGN, ובין אם הוא מטפל בו באמצעות פונקציית מטפל מותאמת אישית שקוראת ל-wait() – מערכת ההפעלה תדאג למנוע יצירת תהליכי זומבי. ההבדל המהותי והמפורש בחומר ההרצאה הוא שרק במקרה של התעלמות מוחלטת (SIG_IGN), מערכת ההפעלה לא תשלח הודעה לתהליך האב על סיום תהליך הבן, אלא תפנה את משאביו באופן מיידי ושקט. לעומת זאת, כאשר מוגדר מטפל מותאם אישית, הסיגנל נשלח, פונקציית המטפל מופעלת, וקריאת ה-wait() שבתוכה היא זו שמבצעת את ניקוי המשאבים של הבן. האפשרויות האחרות אינן מדויקות: אפשרות ב' אינה מתארת את ההבדל המהותי בנוגע להיווצרות זומבים (החומר מציין ש-SIG_IGN מונע יצירתם מלכתחילה); אפשרות ג' סותרת ישירות את החומר הקובע ש-SIG_IGN מונע זומבים; ואפשרות ד' מתארת תוצאת לוואי ולא את ההבחנה התיאורטית המרכזית בנוגע למנגנון מניעת זומבים והודעות."}, "_source_file": "0043__Virtualization__Signals__MC__Hard.json", "_topic_hint": "Signals", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:02:23", "_subject": "Virtualization", "_context_lectures": [4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Signals"], "difficulty_estimation": "Hard", "content": {"text": "מהי ההבחנה המהותית בין טיפול בסיגנל SIGCHLD באמצעות פונקציית מטפל המבצעת קריאה ל-wait(), לבין הגדרת הטיפול ב-SIGCHLD להתעלמות מוחלטת (באמצעות SIG_IGN)?", "code_snippet": "// signal2.c\nvoid signal_handler(int signal) {\n    if (signal == SIGCHLD) {\n        int rc = wait(NULL);\n        printf(\"child terminated %d (pid:%d)\\n\", rc, getpid());\n    }\n}\n\nint main(int argc, char *argv[])\n{\n    struct sigaction act;\n    sigemptyset(&act.sa_mask);\n    act.sa_handler = signal_handler;\n    act.sa_flags = 0;\n    \n    sigaction(SIGCHLD, &act, NULL);\n    if (fork()) {\n        while (1);\n    }\n}", "options": ["א. בשני המקרים מובטח כי תהליכי זומבי לא ייווצרו, אך רק בשיטת ההתעלמות המוחלטת מערכת ההפעלה מפנה את משאבי תהליך הבן באופן מיידי וללא צורך בהתערבות יזומה של תהליך האב.", "ב. טיפול באמצעות פונקציית מטפל מאפשר לתהליך האב לבצע פעולות נוספות (כמו רישום לוגים או עיבוד נתונים) בתגובה לסיום תהליך הבן, בעוד שבהתעלמות מוחלטת פעולה כזו אינה אפשרית.", "ג. רק שימוש בפונקציית מטפל המבצעת wait() מבטיח ניקוי נכון של משאבי תהליך הבן; התעלמות מוחלטת עלולה להוביל לדליפת משאבים.", "ד. ההבדל העיקרי הוא בביצועים: טיפול באמצעות פונקציית מטפל הוא יקר יותר מבחינת משאבי מערכת מאשר התעלמות מוחלטת."]}, "solution": {"correct_option": "א", "explanation": "ההבדל המהותי טמון באופן שבו מערכת ההפעלה מטפלת בסיום תהליך הבן ובמשאביו. כאשר SIGCHLD מוגדר להתעלמות מוחלטת (SIG_IGN), החומר הלימודי מציין במפורש: \"אך ורק במקרה כזה של התעלמות מסיגנל sigchld, מערכת ההפעלה לא תיוצר זומבים. כלומר, היא מיד תפנה אותו ורק לא תודיע לו, כי הוא רואה שאנחנו מתעלמים מ-sigchld.\" משמעות הדבר היא שמערכת ההפעלה מבצעת ניקוי מיידי של משאבי תהליך הבן ללא שליחת הסיגנל לתהליך האב וללא צורך שהאב יקרא ל-wait(). לעומת זאת, כאשר מוגדרת פונקציית מטפל המבצעת קריאה ל-wait(), מערכת ההפעלה אכן שולחת את הסיגנל SIGCHLD לתהליך האב (כלומר, מודיעה לו), ופונקציית המטפל של האב היא זו שמבצעת את הקריאה ל-wait() כדי לאסוף את משאבי הבן ולמנוע זומבי. לכן, רק במקרה של התעלמות מוחלטת, מערכת ההפעלה מבצעת את הניקוי באופן עצמאי ומיידי, ללא מעורבות או התראה לתהליך האב. אפשרות ב' מתארת תוצאה או יכולת הנגזרת מההבדל המהותי (היכולת לבצע פעולות נוספות בזכות קבלת הסיגנל), אך אפשרות א' מתארת את המנגנון הבסיסי השונה בין שתי הגישות."}, "_source_file": "0044__Virtualization__Signals__MC__Hard.json", "_topic_hint": "Signals", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:02:50", "_subject": "Virtualization", "_context_lectures": [4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Signals"], "difficulty_estimation": "Hard", "content": {"text": "בהתייחס לטיפול בסיגנל SIGCHLD למניעת תהליכי זומבי, כפי שתואר בחומר הקורס, מהי הטענה הנכונה ביותר לגבי ההבדל המהותי בין הגדרת הטיפול ב-SIGCHLD כ-SIG_IGN לבין שימוש בפונקציית טיפול (signal handler) ייעודית המבצעת קריאה ל-`wait()`?", "code_snippet": "void signal_handler(int signal) {\n    if (signal == SIGCHLD) {\n        int rc = wait(NULL);\n        printf(\"child terminated %d (pid:%d)\\n\", rc, getpid());\n    }\n}\n\nint main(int argc, char *argv[])\n{\n    struct sigaction act;\n    sigemptyset(&act.sa_mask);\n    act.sa_handler = signal_handler;\n    act.sa_flags = 0;\n    \n    sigaction(SIGCHLD, &act, NULL); // Setting a custom handler\n    if (fork()) {\n        while (1);\n    }\n    // Contrast this with: sigaction(SIGCHLD, &(struct sigaction){.sa_handler = SIG_IGN, .sa_flags = 0}, NULL); \n}", "options": ["א. כאשר SIGCHLD מוגדר כ-SIG_IGN, מערכת ההפעלה מבצעת את איסוף המשאבים של תהליך הבן באופן אוטומטי ואינה שולחת את הסיגנל לתהליך האב כלל, בעוד שעם handler, תהליך האב מקבל את הסיגנל ואחראי לקרוא ל-`wait()`.", "ב. בשני המקרים, תהליך האב מקבל את הסיגנל SIGCHLD, אך רק במקרה של SIG_IGN מערכת ההפעלה מונעת מצב זומבי באופן אוטומטי ללא צורך בקריאה ל-`wait()`.", "ג. השימוש ב-SIG_IGN מונע מצב זומבי ביעילות רבה יותר מכיוון שהוא מאפשר לתהליך האב להמשיך בפעילותו ללא הפרעה, בניגוד ל-handler הדורש הקפצה של הקשר (context switch) לביצוע.", "ד. ההבדל העיקרי הוא ש-SIG_IGN מאפשר לתהליך האב לשלוח סיגנלים נוספים לתהליך הבן גם לאחר סיומו, בעוד ש-handler מונע זאת."]}, "solution": {"correct_option": "א", "explanation": "האפשרות הנכונה היא א'. חומר הקורס מציין במפורש: \"אך ורק במקרה כזה של התעלמות מסיגנל sigchld, מערכת ההפעלה לא תיוצר זומבים. כלומר, היא מיד תפנה אותו ורק לא תודיע לו, כי הוא רואה שאנחנו מתעלמים מ-sigchld.\" \nמשמעות הדבר היא שכאשר SIGCHLD מוגדר כ-SIG_IGN, מערכת ההפעלה מטפלת באיסוף משאבי תהליך הבן באופן אוטומטי לחלוטין ואינה שולחת את הסיגנל לתהליך האב כלל (כלומר, האב אינו מקבל התראה). לעומת זאת, כאשר מוגדרת פונקציית טיפול (handler) עבור SIGCHLD, מערכת ההפעלה אכן שולחת את הסיגנל לתהליך האב, והאב נדרש לבצע קריאה ל-`wait()` בתוך ה-handler כדי לאסוף את משאבי הבן ולמנוע מצב זומבי.\nאפשרות ב' שגויה מכיוון שהיא טוענת שבשני המקרים האב מקבל את הסיגנל, בניגוד למצוין בחומר לגבי SIG_IGN.\nאפשרות ג' עשויה להכיל היבטים של יעילות, אך אינה מתארת את ההבדל המהותי כפי שהודגש בחומר, וההסבר על \"הקפצת הקשר\" אינו מפורט במובן זה בחומר הקורס.\nאפשרות ד' שגויה לחלוטין מכיוון שלא ניתן לשלוח סיגנלים לתהליך שסיים את פעולתו."}, "_source_file": "0045__Virtualization__Signals__MC__Hard.json", "_topic_hint": "Signals", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:03:15", "_subject": "Virtualization", "_context_lectures": [4, 5]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["CPU Scheduling"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, מהו הפתרון המוצע לניצול יעיל יותר של המעבד במצב שבו תהליך מבצע פעולות קלט/פלט וגורם לזמן מעבד מבוזבז?", "code_snippet": null, "options": ["א. פירוק התהליך למספר \"ג'ובים\" קטנים ועצמאיים, המאפשר חפיפה בביצוע עם תהליכים אחרים.", "ב. הגדלת העדיפות של תהליכים עתירי קלט/פלט על מנת שיסיימו מהר יותר.", "ג. שימוש באלגוריתם תזמון מסוג Round Robin עם חלון זמן קצר מאוד.", "ד. הקצאת מעבד ייעודי לטיפול בפעולות קלט/פלט בלבד."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה (Lecture 3, chunk 16) מתאר מצב בו זמן מעבד מבוזבז כאשר תהליך ממתין לפעולות קלט/פלט. הפתרון המוצע לבעיה זו הוא לשנות את ההתייחסות לתהליך אחד ארוך. במקום זאת, מפרקים את התהליך למספר \"ג'ובים\" קטנים יותר, שכל אחד מהם מייצג מקטע עבודה קצר (לדוגמה, תהליך A באורך 30 מילישניות עם I/O כל 10 מילישניות מפורק ל-3 ג'ובים של 10 מילישניות: A1, A2, A3). גישה זו מאפשרת למתזמן (כדוגמת SRTF המוזכרת בהרצאה) לבצע \"חפיפה\" (overlap) יעילה יותר בין ג'ובים שונים, כלומר, להריץ תהליך אחר (כמו B בדוגמה) בזמן שאחד מהג'ובים הקטנים של התהליך המקורי ממתין לקלט/פלט, ובכך לנצל טוב יותר את זמן המעבד."}, "_source_file": "0046__Virtualization__CPU_Scheduling__MC__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:03:25", "_subject": "Virtualization", "_context_lectures": [8, 2, 3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["CPU Scheduling"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, מהו הפתרון המוצע לבעיית בזבוז זמן מעבד הנגרמת כאשר תהליך מבצע פעולות קלט/פלט תקופתיות?", "code_snippet": null, "options": ["א. פיצול התהליך למספר תתי-ג'ובים קצרים יותר, המאפשרים למתזמן לבצע חפיפה (overlap) עם תהליכים אחרים בזמן ההמתנה לקלט/פלט.", "ב. שימוש באלגוריתם תזמון מסוג SRTF בלבד, ללא כל שינוי במבנה התהליכים.", "ג. הגדלת ה-Quantum (פרוסת הזמן) של המעבד כדי למזער את מספר החלפות ההקשר (context switches).", "ד. מתן עדיפות גבוהה יותר לתהליכי קלט/פלט על מנת שיסיימו את פעולותיהם מהר יותר."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מתאר כי הבעיה של בזבוז זמן מעבד כאשר תהליך מבצע פעולות קלט/פלט תקופתיות נפתרת על ידי שינוי ההתייחסות לתהליך. במקום להתייחס אליו כאל ג'וב אחד ארוך, הוא מפוצל למספר תתי-ג'ובים קצרים יותר. גישה זו מאפשרת למתזמן (לדוגמה, SRTF) לבצע חפיפה (overlap) ולתזמן תהליכים אחרים לרוץ בזמנים שבהם התהליך המקורי ממתין לפעולות הקלט/פלט שלו, ובכך מנוצל זמן המעבד בצורה יעילה יותר. האפשרויות האחרות אינן הפתרון הספציפי שהוצג בחומר ההרצאה לבעיה זו."}, "_source_file": "0047__Virtualization__CPU_Scheduling__MC__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:03:37", "_subject": "Virtualization", "_context_lectures": [8, 2, 3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["CPU Scheduling"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, מהי הגישה המוצעת לשיפור ניצול המעבד במצב שבו תהליך מבצע פעולות קלט/פלט וגורם לזמן מעבד מבוזבז?", "code_snippet": null, "options": ["א. לפרק את התהליך למספר \"תת-ג'ובים\" עצמאיים המגיעים בזמנים שונים, ובכך לאפשר חפיפה בתזמון.", "ב. להשתמש תמיד באלגוריתם תזמון מסוג SRTF, ללא קשר למאפייני התהליכים.", "ג. להגדיל את חלון הזמן (time slice) עבור תהליכים המבצעים פעולות קלט/פלט.", "ד. להקפיא את התהליך הממתין לפעולת קלט/פלט ולהעביר את השליטה המלאה במעבד למערכת ההפעלה באופן בלעדי."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה (chunk 16) מתאר את הבעיה של ניצול מעבד מבוזבז כאשר תהליך ממתין לפעולות קלט/פלט. הפתרון המוצע הוא \"שינוי פשוט בנתונים שלנו\": במקום להתייחס לתהליך אחד ארוך, יש לפרק אותו למספר ג'ובים קצרים יותר (לדוגמה, תהליך A באורך 30 מילישניות עם I/O כל 10 מילישניות יפורק ל-3 ג'ובים בני 10 מילישניות כל אחד). גישה זו מאפשרת למתזמן לבצע חפיפה יעילה יותר בין ג'ובים, ובכך לנצל את זמן המעבד שבו התהליך המקורי היה ממתין לפעולות קלט/פלט, כפי שמודגם בתרשים: CPU: A1 B A2 B A3 B. תשובה ב' אינה נכונה מכיוון שהשימוש ב-SRTF מוזכר כדוגמה למתזמן שניתן להשתמש בו עם הגישה החדשה, אך לא כפתרון העיקרי או הבלעדי לבעיה זו. תשובות ג' ו-ד' אינן מוזכרות כפתרונות לבעיה זו בחומר ההרצאה הנתון."}, "_source_file": "0048__Virtualization__CPU_Scheduling__MC__Easy.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:03:52", "_subject": "Virtualization", "_context_lectures": [8, 2, 3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["CPU Scheduling"], "difficulty_estimation": "Medium", "content": {"text": "לפי חומר ההרצאה, מהי המטרה העיקרית של פירוק ג'וב המבצע פעולות קלט/פלט למספר ג'ובים קטנים יותר (תת-ג'ובים) בהקשר של תזמון מעבד?", "code_snippet": null, "options": ["א. לאפשר חפיפה יעילה יותר (overlap) בין חלקי הג'וב לבין ג'ובים אחרים, ובכך להפחית את זמן הסרק של המעבד ולשפר את ניצולו.", "ב. להפחית את כמות ה-context switches הנדרשים במהלך ריצת הג'וב המקורי.", "ג. לפשט את לוגיקת המתזמן (scheduler) ולהימנע מטיפול מורכב בפעולות קלט/פלט.", "ד. לאפשר למתזמן (SRTF) לזהות בקלות רבה יותר את זמן הריצה הכולל של הג'וב המקורי."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מתאר מצב שבו ג'וב (A) מבצע פעולות קלט/פלט, מה שמוביל לזמן סרק של המעבד אף על פי שקיימים ג'ובים אחרים (B) שיכולים לרוץ. הפתרון המוצג הוא לשנות את ההתייחסות לג'וב A: במקום להתייחס אליו כג'וב אחד ארוך שכולל המתנות ל-I/O, מפרקים אותו למספר תת-ג'ובים קצרים יותר (לדוגמה, A1, A2, A3 שכל אחד אורך 10 מילישניות). על ידי כך, המתזמן יכול לבצע חפיפה (overlap) בין תת-ג'ובים אלו לבין ג'ובים אחרים (כמו B), ובכך למלא את חלונות הזמן שבהם A ממתין לפעולות קלט/פלט. פעולה זו מפחיתה באופן משמעותי את זמן הסרק של המעבד ומשפרת את ניצולו הכולל, כפי שמודגם בתרשים: CPU: A1 B A2 B A3 B. לכן, המטרה העיקרית היא לאפשר חפיפה יעילה יותר ולשפר את ניצול המעבד."}, "_source_file": "0049__Virtualization__CPU_Scheduling__MC__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:04:07", "_subject": "Virtualization", "_context_lectures": [8, 2, 3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["CPU Scheduling"], "difficulty_estimation": "Medium", "content": {"text": "לפי חומר ההרצאה, איזו בעיה מרכזית בתזמון מעבדים נפתרת על ידי פירוק ג'וב בודד (הכולל פעולות קלט/פלט) למספר תת-ג'ובים קטנים יותר, ושימוש במתזמן כמו SRTF?", "code_snippet": null, "options": ["א. זה מאפשר למתזמן למלא חלונות זמן מבוזבזים (wasted CPU time) שנוצרו עקב המתנה של ג'וב לפעולות קלט/פלט, ובכך להגדיל את ניצול המעבד.", "ב. זה מבטיח הוגנות טובה יותר בין ג'ובים שונים ומונע מצב של הרעבה (starvation) עבור ג'ובים קצרים.", "ג. זה מקטין את כמות ה-context switches הנדרשים ומפחית את התקורה (overhead) של מערכת ההפעלה.", "ד. זה מפשט את לוגיקת המתזמן ומאפשר לו לקבל החלטות מהירות יותר ללא צורך בידע מוקדם על זמני I/O."]}, "solution": {"correct_option": "א", "explanation": "החומר מתאר מצב שבו ג'וב (A) ממתין לפעולות קלט/פלט, מה שיוצר חלונות זמן מבוזבזים במעבד שאינם מנוצלים, גם אם יש ג'ובים אחרים (B) שמוכנים לרוץ. הפתרון המוצע הוא לשנות את ההתייחסות לג'וב A, ולפרק אותו למספר תת-ג'ובים קצרים יותר (לדוגמה, A1, A2, A3, כל אחד באורך 10ms, במקום ג'וב אחד באורך 30ms עם הפסקות I/O). גישה זו מאפשרת למתזמן (כמו SRTF) לבצע חפיפה (overlap) בריצה של תת-הג'ובים של A עם ג'ובים אחרים (B), ובכך למלא את חלונות הזמן שבהם A היה ממתין לפעולות קלט/פלט. התוצאה היא ניצול טוב יותר של המעבד והפחתה משמעותית של זמן מעבד מבוזבז, כפי שמודגם בתרשים: CPU: A1 B A2 B A3 B."}, "_source_file": "0050__Virtualization__CPU_Scheduling__MC__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:04:20", "_subject": "Virtualization", "_context_lectures": [8, 2, 3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["CPU Scheduling"], "difficulty_estimation": "Medium", "content": {"text": "לפי חומר ההרצאה, איזו גישה מוצעת לפתרון בעיית בזבוז זמן המעבד הנגרמת מהמתנה של תהליכים לפעולות קלט/פלט (I/O), וכיצד היא משפרת את ניצולת המעבד?", "code_snippet": null, "options": ["א. פיצול תהליך יחיד למספר תת-ג'ובים עצמאיים, כאשר כל תת-ג'וב נחשב לג'וב נפרד עם זמן הגעה וזמן ריצה משלו, מה שמאפשר למתזמן (כמו SRTF) לבצע חפיפה יעילה יותר עם תהליכים אחרים במהלך המתנות לקלט/פלט.", "ב. תזמון תהליך אחר לרוץ בזמן שתהליך ראשון ממתין לקלט/פלט, אך ללא שינוי בדרך ההתייחסות לג'ובים, מה שעדיין עלול להותיר חלונות זמן ריקים במעבד.", "ג. שימוש במנגנון Direct Execution כדי לתת לתהליך יחיד שליטה מלאה במעבד עד לסיומו, ובכך למנוע את הצורך בהחלפות תהליכים תכופות.", "ד. הסתמכות בלעדית על הידע המוקדם של זמן הריצה הכולל של כל ג'וב כדי לתזמן אותם בסדר אופטימלי ללא הפרעות, תוך התעלמות מהצורך בחפיפה במהלך I/O."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מתאר בעיה של בזבוז זמן מעבד, גם כאשר מתזמנים תהליך אחר לרוץ בזמן שתהליך ממתין לפעולת קלט/פלט (I/O). הסיבה היא שגם לאחר שתהליך ה-I/O מסתיים, אם לשני התהליכים נותר זמן ריצה דומה, המתזמן עשוי להמשיך לתזמן את התהליך השני, ולהשאיר חלון זמן ריק שאינו מנוצל (כפי שמתואר ב-Lecture 3, chunk 15). הפתרון המוצע, כפי שמצוין ב-Lecture 3, chunk 16, הוא לשנות את ההתייחסות לתהליך: במקום לראות בו ג'וב אחד ארוך שכולל המתנות ל-I/O, יש לפצל אותו למספר תת-ג'ובים קצרים ועצמאיים. כל תת-ג'וב מייצג מקטע ריצה של CPU בין פעולות I/O. על ידי טיפול בכל תת-ג'וב כג'וב נפרד עם זמן הגעה וזמן ריצה משלו, המתזמן (כמו SRTF) יכול לבצע חפיפה (overlap) יעילה יותר עם ג'ובים אחרים, ולמלא את חלונות הזמן שהיו מבוזבזים בעבר. לכן, אפשרות א' מתארת במדויק את הגישה וההסבר שניתנו בחומר ההרצאה."}, "_source_file": "0051__Virtualization__CPU_Scheduling__MC__Medium.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:04:38", "_subject": "Virtualization", "_context_lectures": [8, 2, 3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["CPU Scheduling"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על החומר שהוצג, כאשר תהליך יחיד (לדוגמה, 'A') מבצע פעולות קלט/פלט לסירוגין ומשאיר את המעבד במצב המתנה, הוצג פתרון שבו התהליך מפוצל למספר \"תתי-ג'ובים\" (לדוגמה, A1, A2, A3) כאשר כל תת-ג'וב מייצג מקטע ריצה של המעבד בין פעולות קלט/פלט. מדוע פיצול זה, בשילוב עם מתזמן מסוג SRTF, מאפשר ניצול טוב יותר של המעבד וחפיפה יעילה יותר בין ג'ובים, גם אם סך זמן הריצה של התהליך המקורי נשאר זהה?", "code_snippet": null, "options": ["א. פיצול התהליך לתתי-ג'ובים מאפשר למתזמן SRTF לראות כל מקטע ריצה כג'וב חדש ועצמאי המגיע בזמן שונה, ובכך להפעיל את לוגיקת התזמון המונעת שלו (preemptive) בצורה אגרסיבית יותר כאשר תת-ג'וב חדש (או תת-ג'וב שסיים I/O) מגיע, ולהחליף תהליך אחר בעל זמן ריצה ארוך יותר שרץ כרגע.", "ב. פיצול התהליך מקטין את זמן ה-I/O הכולל של התהליך, ובכך מפחית את חלונות הזמן הריקים שבהם המעבד אינו מנוצל.", "ג. מתזמן SRTF אינו יכול לתזמן תהליכים בעלי פעולות קלט/פלט אלא אם הם מפוצלים, ולכן הפיצול הוא תנאי הכרחי להפעלתו.", "ד. הפיצול מאפשר למערכת ההפעלה להקצות יותר זיכרון לתהליך A, ובכך להפחית את הצורך ב-page faults ובהמתנה לדיסק."]}, "solution": {"correct_option": "א", "explanation": "הפתרון לניצול מעבד טוב יותר, כפי שהוצג בחומר הלימוד (Lecture 3, chunk 16), טמון בהתייחסות לתהליך A, שמבצע פעולות קלט/פלט לסירוגין, לא כאל ג'וב יחיד וארוך, אלא כאל סדרה של תתי-ג'ובים קצרים (לדוגמה, A1, A2, A3), שכל אחד מהם מייצג מקטע ריצה של המעבד. כל תת-ג'וב כזה נחשב לג'וב עצמאי המגיע בזמן שונה (כאשר מקטע ה-CPU הקודם הסתיים או ה-I/O הסתיים). מתזמן מסוג SRTF (Shortest Remaining Time First) הוא מתזמן מונע (preemptive). כאשר תת-ג'וב חדש (כמו A2 או A3) \"מגיע\" או תת-ג'וב קיים (כמו A1) מסיים את פעולת הקלט/פלט שלו והופך להיות כשיר לריצה, המתזמן בודק את זמן הריצה שנותר לו ואת זמן הריצה שנותר לתהליך שרץ כרגע (לדוגמה, B). אם לתת-הג'וב של A יש זמן ריצה קצר יותר ממה שנותר לתהליך B, המתזמן SRTF יבצע החלפת הקשר (context switch) ויריץ את תת-הג'וב של A. זה מאפשר למתזמן למלא את חלונות הזמן שבהם התהליך המקורי A היה ממתין לפעולות קלט/פלט, ובכך למקסם את ניצול המעבד ולבצע חפיפה (overlap) יעילה יותר בין ג'ובים שונים, כפי שמודגם בתרשים \"CPU: A1 B A2 B A3 B\" בחומר. האפשרויות האחרות אינן נכונות: ב' שגויה מכיוון שהפיצול אינו מקטין את זמן ה-I/O הכולל; ג' שגויה מכיוון ש-SRTF יכול לתזמן תהליכים עם I/O, הפיצול הוא לשיפור היעילות; ד' שגויה מכיוון שהיא מתייחסת לניהול זיכרון (page faults) ואינה קשורה ישירות לפתרון בעיית תזמון המעבד על ידי פיצול ג'ובים."}, "_source_file": "0052__Virtualization__CPU_Scheduling__MC__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:04:57", "_subject": "Virtualization", "_context_lectures": [8, 2, 3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["CPU Scheduling"], "difficulty_estimation": "Hard", "content": {"text": "בהתייחס לבעיית בזבוז זמן מעבד הנגרמת על ידי תהליכים בעלי פעולות קלט/פלט תקופתיות, כפי שתוארה בחומר הקורס, ובהינתן שאלגוריתם תזמון קיים כמו SRTF ממשיך לשמש, איזה שינוי מהותי באופן שבו המתזמן 'רואה' את ה-workload הוא הכרחי כדי לאפשר חפיפה יעילה יותר בין ג'ובים ולמקסם את ניצול המעבד?", "code_snippet": null, "options": ["א. פיצול תהליך יחיד בעל פעולות קלט/פלט למספר 'תת-ג'ובים' נפרדים, כאשר כל תת-ג'וב נתפס על ידי המתזמן כג'וב עצמאי עם זמני הגעה וריצה משלו.", "ב. הגדלת תדירות ה-context switches באופן כללי כדי לאפשר לתהליכים רבים יותר להתחלף במהירות.", "ג. הענקת עדיפות גבוהה יותר לתהליכים המבצעים פעולות קלט/פלט על מנת שיסיימו את המתנתם מהר יותר.", "ד. שימוש בטכניקת Direct Execution כדי לאפשר לתהליכים לרוץ ללא הפרעה עד לסיום פעולת הקלט/פלט שלהם."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר הקורס מתאר מצב שבו תהליך כמו A מבצע פעולות קלט/פלט תקופתיות, מה שגורם לזמני המתנה ובזבוז של זמן מעבד. המתזמן מנסה בתחילה להריץ תהליכים אחרים (כמו B) בזמן ש-A ממתין, אך מודגם שגם זה לא מספיק כדי למנוע חלונות זמן ריקים במעבד. הפתרון המוצע, כפי שמצוין בבירור ב'Lecture 3 (chunk 16)', אינו דורש שינוי באלגוריתם התזמון עצמו (לדוגמה, SRTF ממשיך לשמש), אלא שינוי מהותי באופן שבו ה-workload מוצג למתזמן. במקום לראות את A כג'וב יחיד וארוך, הוא מפוצל למספר 'תת-ג'ובים' קצרים יותר (לדוגמה, A1, A2, A3), כאשר כל אחד מהם נתפס כג'וב עצמאי עם דרישות זמן ריצה והגעה משלו. גישה זו מאפשרת למתזמן לבצע 'חפיפה' (overlap) יעילה יותר, כלומר, כאשר תת-ג'וב אחד של A ממתין לקלט/פלט, המתזמן יכול להריץ תת-ג'וב אחר של A (אם זמין) או ג'וב אחר (B), ובכך למלא את חלונות הזמן הריקים ולמקסם את ניצול המעבד. האפשרויות האחרות אינן מתארות את הפתרון הספציפי והמהותי שהוצג בחומר הקורס לבעיה זו: הגדלת תדירות context switches (ב') לבדה לא פותרת את בעיית ה-I/O wait באופן אסטרטגי. הענקת עדיפות (ג') לא בהכרח מאפשרת חפיפה יעילה של זמן מעבד בזמן המתנת קלט/פלט. ו-Direct Execution (ד') היא ההפך הגמור, מכיוון שהיא מונעת החלפה ותזמון מחדש במהלך ריצת תהליך, ובכך מחמירה את בעיית ניצול המעבד."}, "_source_file": "0053__Virtualization__CPU_Scheduling__MC__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:05:25", "_subject": "Virtualization", "_context_lectures": [8, 2, 3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["CPU Scheduling"], "difficulty_estimation": "Hard", "content": {"text": "על פי חומר ההרצאה, בתרחיש שבו תהליך (A) מבצע פעולות קלט/פלט תקופתיות, והמתזמן (כמו SRTF) מתקשה למנוע בזבוז זמן מעבד כאשר תהליכים אחרים (B) זמינים לריצה, הוצג פתרון שבו תהליך A מפוצל ל\"ג'ובים משניים\" (sub-jobs). מהו ההבדל המהותי בגישה זו המאפשר למתזמן למלא את זמני ההמתנה של A לפעולות קלט/פלט בתהליכים אחרים, ובכך לשפר את ניצול המעבד?", "code_snippet": null, "options": ["א. הפיצול מאפשר למתזמן לראות כל חלק של A כג'וב עצמאי עם זמן ריצה קצר ידוע (למשל, 10ms), ובכך לתזמן תהליכים אחרים (B) באופן אופטימלי לרוץ בזמני ההמתנה של A לקלט/פלט.", "ב. הפיצול מאלץ את תהליך A לוותר על המעבד באופן יזום בכל פעם שהוא מתחיל פעולת קלט/פלט, ללא תלות ביכולות המתזמן.", "ג. הפיצול מאפשר להשתמש באלגוריתם תזמון חדש ומתקדם יותר מ-SRTF, אשר תוכנן במיוחד לטפל בג'ובים מפוצלים.", "ד. הפיצול מפחית את העומס על זיכרון המטמון (cache) של המעבד, ובכך מקצר את זמני הגישה לנתונים ומפנה יותר זמן מעבד לתהליכים אחרים."]}, "solution": {"correct_option": "א", "explanation": "הפתרון המוצג בחומר ההרצאה מתבסס על שינוי באופן שבו המתזמן תופס את התהליך (A). במקום לראות את A כג'וב ארוך אחד, הוא נשבר ל\"ג'ובים משניים\" קצרים ועצמאיים (לדוגמה, כל אחד באורך 10 מילישניות), כאשר ידוע מראש שכל אחד מהם מסתיים בפעולת קלט/פלט. גישה זו, כפי שצוין בשיעור, מאפשרת למתזמן לזהות באופן יעיל את הנקודות שבהן A ייכנס למצב המתנה לקלט/פלט. בכך, המתזמן יכול לתזמן תהליכים אחרים (כמו B) לרוץ בחלונות זמן אלו, ובכך למנוע בזבוז זמן מעבד ולשפר את ניצול המעבד הכולל. חומר ההרצאה מציין במפורש \"נשתמש באותו מתזמן (SRTF) אבל עם חפיפה של ג'ובים (overlap)\", מה שמפריך את אפשרות ג'. אפשרות ב' אינה נכונה מכיוון שהשינוי הוא באופן שבו המתזמן רואה את הג'ובים, לא שינוי בהתנהגות יזומה של התהליך A. אפשרות ד' אינה רלוונטית לפתרון שהוצג בחומר ההרצאה בנוגע לניצול מעבד בזמני המתנה לקלט/פלט."}, "_source_file": "0054__Virtualization__CPU_Scheduling__MC__Hard.json", "_topic_hint": "CPU Scheduling", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:05:42", "_subject": "Virtualization", "_context_lectures": [8, 2, 3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Scheduling Algorithms"], "difficulty_estimation": "Easy", "content": {"text": "מהו המנגנון העיקרי שבו משתמש אלגוריתם תזמון \"הגרלה\" (Lottery scheduling) כדי להקצות זמן מעבד באופן פרופורציונלי?", "code_snippet": null, "options": ["א. בחירת התהליך בעל ערך ה-PASS הנמוך ביותר ועדכון ערך ה-STRIDE שלו.", "ב. הקצאת \"כרטיסים\" (tickets) לתהליכים וביצוע הגרלה אקראית לבחירת התהליך הבא.", "ג. ריצת תהליכים בסדר הגעתם (First-Come, First-Served) מתחילתם ועד סופם.", "ד. חלוקת תהליכים ארוכים לתתי-תהליכים קצרים לצורך חפיפה עם פעולות קלט/פלט."]}, "solution": {"correct_option": "ב", "explanation": "אלגוריתם תזמון \"הגרלה\" (Lottery scheduling) הוא מתזמן מסוג \"חלוקה פרופורציונלית\" (proportional share). המנגנון העיקרי שלו מבוסס על הקצאת \"כרטיסים\" (tickets) לכל תהליך. ככל שלתהליך יש יותר כרטיסים, כך גדל הסיכוי שלו לזכות בהגרלה ולקבל את זמן המעבד. בכל פעם שיש לבחור תהליך לריצה, מתבצעת \"הגרלה\" אקראית, והתהליך שזוכה מקבל את זמן המעבד. אפשרות א' מתארת את מנגנון ה-Stride scheduling. אפשרות ג' מתארת את אלגוריתם FCFS. אפשרות ד' מתייחסת לטיפול בתהליכי קלט/פלט באמצעות פיצול ג'ובים, ולא למנגנון ליבה של תזמון פרופורציונלי."}, "_source_file": "0055__Virtualization__Scheduling_Algorithms__MC__Easy.json", "_topic_hint": "Scheduling Algorithms", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:05:55", "_subject": "Virtualization", "_context_lectures": [3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Scheduling Algorithms"], "difficulty_estimation": "Easy", "content": {"text": "מהו המנגנון העיקרי שבו משתמש אלגוריתם תזמון ה-\"Lottery scheduling\" כדי להקצות זמן מעבד באופן פרופורציונלי?", "code_snippet": null, "options": ["א. על ידי בחירת התהליך עם ערך ה-PASS הנמוך ביותר.", "ב. על ידי חלוקת \"כרטיסים\" (Tickets) לתהליכים ועריכת הגרלה.", "ג. על ידי הרצת הג'וב שהגיע ראשון עד לסיומו.", "ד. על ידי פיצול ג'ובים לתת-ג'ובים קטנים יותר."]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר ההרצאה, אלגוריתם ה-Lottery scheduling מקצה זמן מעבד באופן פרופורציונלי על ידי הקצאת 'כרטיסי הגרלה' (Tickets) לתהליכים. לאחר מכן, נערכת 'הגרלה' ובוחרים ג'וב מנצח. ככל שלתהליך יש יותר כרטיסים, כך גדל הסיכוי שלו להיבחר ולקבל את זמן המעבד. אפשרות א' מתארת את מנגנון ה-stride scheduling. אפשרות ג' מתארת תזמון מסוג First-Come, First-Served. אפשרות ד' מתארת טכניקה לטיפול בקלט/פלט, למשל בשילוב עם SRTF, ולא את מנגנון ההקצאה הפרופורציונלית של Lottery scheduling."}, "_source_file": "0056__Virtualization__Scheduling_Algorithms__MC__Easy.json", "_topic_hint": "Scheduling Algorithms", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:06:04", "_subject": "Virtualization", "_context_lectures": [3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Scheduling Algorithms"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, מהו העיקרון המרכזי שבו מתזמן \"הגרלה\" (Lottery scheduling) משתמש כדי להקצות זמן מעבד באופן פרופורציונלי לתהליכים?", "code_snippet": null, "options": ["א. הוא מקצה \"כרטיסי הגרלה\" (tickets) לתהליכים ובוחר באופן אקראי זוכה, כאשר לתהליכים עם יותר כרטיסים יש סיכוי גבוה יותר להיבחר.", "ב. הוא עוקב אחר ערך \"PASS\" וערך \"STRIDE\" עבור כל תהליך, ובוחר להריץ את התהליך עם ערך ה-PASS הנמוך ביותר.", "ג. הוא תמיד מריץ את התהליך עם זמן הריצה הנותר הקצר ביותר.", "ד. הוא מריץ תהליכים לפי סדר הגעתם, מתחילתם ועד סופם."]}, "solution": {"correct_option": "א", "explanation": "מתזמן \"הגרלה\" (Lottery scheduling) פועל באמצעות הקצאת \"כרטיסי הגרלה\" (tickets) לכל תהליך. בכל פעם שיש צורך לבחור תהליך לריצה, מתבצעת הגרלה אקראית. ככל שלתהליך מסוים יש יותר כרטיסים, כך גדל הסיכוי שלו לזכות בהגרלה ולקבל זמן מעבד. באופן זה, מושגת הקצאה פרופורציונלית של זמן המעבד בהתאם למספר הכרטיסים של כל תהליך. אפשרות ב' מתארת את אלגוריתם Stride scheduling. אפשרות ג' מתארת את אלגוריתם SRTF (Shortest Remaining Time First) המוזכר בחומר. אפשרות ד' מתארת אלגוריתם מסוג FCFS (First-Come, First-Served)."}, "_source_file": "0057__Virtualization__Scheduling_Algorithms__MC__Easy.json", "_topic_hint": "Scheduling Algorithms", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:06:18", "_subject": "Virtualization", "_context_lectures": [3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Scheduling Algorithms"], "difficulty_estimation": "Medium", "content": {"text": "איזו טענה מתארת באופן הטוב ביותר את הגישה הייחודית של אלגוריתם תזמון Stride Scheduling לחלוקה פרופורציונלית של זמן מעבד, בהשוואה לאלגוריתם Lottery Scheduling?", "code_snippet": null, "options": ["א. הוא מבטיח חלוקה פרופורציונלית מדויקת יותר לאורך זמן על ידי מעקב דטרמיניסטי אחר זמן הריצה היחסי של כל תהליך באמצעות ערכי PASS ו-STRIDE.", "ב. הוא מאפשר לתהליכים 'לנפח' באופן זמני את חלקם בזמן המעבד על ידי הוספה דינמית של ערכים ל-STRIDE שלהם.", "ג. הוא מסתמך על בחירה אקראית של תהליך לריצה מתוך קבוצה של תהליכים זמינים, כאשר ההסתברות תלויה במספר ה'כרטיסים' שברשותו.", "ד. הוא מותאם במיוחד למצבים שבהם זמן הריצה של כל ג'וב אינו ידוע מראש, ומחלק את זמן המעבד באופן שווה בין כל התהליכים."]}, "solution": {"correct_option": "א", "explanation": "האלגוריתם Stride Scheduling משתמש בערכים דטרמיניסטיים (PASS ו-STRIDE) כדי להבטיח חלוקה פרופורציונלית של זמן המעבד. לכל ג'וב מוגדר ערך STRIDE, המייצג את חלקו היחסי, וערך PASS שמתעד כמה זמן הוא רץ עד כה. המתזמן בוחר תמיד את הג'וב עם ערך ה-PASS הנמוך ביותר, ולאחר הריצה מוסיף את ערך ה-STRIDE שלו ל-PASS שלו. גישה זו, כפי שמתוארת בחומר ההרצאה ('כשנרצה לבחור ג'וב לריצה, נבחר את הג'וב עם ה-pass הנמוך ביותר, ואז כל ריצה נוסיף את ה- stride שלו לערך ה-pass שלו'), מובילה לחלוקה פרופורציונלית מדויקת ודטרמיניסטית לאורך זמן. לעומת זאת, Lottery Scheduling מסתמך על בחירה אקראית באמצעות 'כרטיסים' (אפשרות ג'), ו'ניפוח כרטיסים' (Ticket inflation) הוא מנגנון השייך ל-Lottery ולא ל-Stride (אפשרות ב'). ההנחה בחומר ההרצאה היא שזמני הריצה ידועים עבור האלגוריתמים הנידונים (אפשרות ד' שגויה)."}, "_source_file": "0058__Virtualization__Scheduling_Algorithms__MC__Medium.json", "_topic_hint": "Scheduling Algorithms", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:06:33", "_subject": "Virtualization", "_context_lectures": [3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Scheduling Algorithms"], "difficulty_estimation": "Medium", "content": {"text": "מהו ההבדל העיקרי בין אלגוריתם תזמון Lottery Scheduling לבין אלגוריתם Stride Scheduling בדרך שבה הם מקצים זמן מעבד באופן פרופורציונלי?", "code_snippet": null, "options": ["א. Lottery Scheduling משתמש בהגרלה אקראית של כרטיסים, בעוד ש-Stride Scheduling משתמש בערכי PASS ו-STRIDE כדי להבטיח תזמון דטרמיניסטי.", "ב. Lottery Scheduling מתמקד במניעת רעבון (starvation), בעוד ש-Stride Scheduling מתמקד בהקטנת זמן ההמתנה הממוצע.", "ג. Stride Scheduling דורש ידע מוקדם על משך הריצה המדויק של כל ג'וב, בעוד ש-Lottery Scheduling אינו דורש זאת.", "ד. Lottery Scheduling מאפשר לג'ובים להגדיל או להקטין באופן זמני את מספר הכרטיסים שלהם (ticket inflation), בעוד ש-Stride Scheduling אינו תומך במנגנון גמישות דומה."]}, "solution": {"correct_option": "א", "explanation": "ההבדל העיקרי והמהותי בין שני האלגוריתמים טמון במנגנון התזמון שלהם. Lottery Scheduling הוא אלגוריתם הסתברותי המקצה זמן מעבד באופן פרופורציונלי על ידי בחירה אקראית של ג'וב מנצח מתוך מאגר כרטיסים (Tickets), כאשר הסיכוי לזכות פרופורציונלי למספר הכרטיסים שבידי הג'וב. לעומת זאת, Stride Scheduling הוא אלגוריתם דטרמיניסטי המבטיח הקצאה פרופורציונלית על ידי ניהול ערכי PASS ו-STRIDE לכל ג'וב. הוא בוחר תמיד את הג'וב עם ערך ה-PASS הנמוך ביותר, ולאחר הרצתו מעדכן את ערך ה-PASS שלו על ידי הוספת ה-STRIDE שלו. שיטה זו מבטיחה תזמון מדויק וצפוי יותר לאורך זמן, בניגוד לאקראיות של Lottery Scheduling. אפשרות ד' מתארת תכונה של Lottery Scheduling שאינה קיימת ב-Stride Scheduling, אך היא אינה ההבדל העיקרי במנגנון הליבה של הקצאה פרופורציונלית, אלא תוספת גמישות."}, "_source_file": "0059__Virtualization__Scheduling_Algorithms__MC__Medium.json", "_topic_hint": "Scheduling Algorithms", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:06:45", "_subject": "Virtualization", "_context_lectures": [3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Scheduling Algorithms"], "difficulty_estimation": "Medium", "content": {"text": "באלגוריתם תזמון Stride Scheduling, כיצד מושגת הקצאת זמן מעבד פרופורציונלית בין תהליכים שונים, ומה המשמעות של ערך ה-STRIDE?", "code_snippet": null, "options": ["א. תהליך בעל ערך STRIDE נמוך יותר יקבל זמן מעבד רב יותר, מכיוון שערך ה-PASS שלו יגדל לאט יותר, מה שיגרום לו להיבחר לעיתים קרובות יותר.", "ב. תהליך בעל ערך STRIDE גבוה יותר יקבל זמן מעבד רב יותר, מכיוון שערך ה-PASS שלו יגדל מהר יותר, מה שיבטיח לו עדיפות בבחירה הבאה.", "ג. ערך ה-STRIDE קובע את משך הזמן שתהליך ירוץ בכל פעם שהוא נבחר, ללא קשר לערך ה-PASS.", "ד. הקצאת זמן המעבד נקבעת באופן אקראי על בסיס ערך ה-STRIDE, בדומה לאלגוריתם Lottery Scheduling."]}, "solution": {"correct_option": "א", "explanation": "אלגוריתם Stride Scheduling נועד להקצות זמן מעבד באופן פרופורציונלי. לכל תהליך מוגדר ערך STRIDE וערך PASS (שמתחיל מ-0). בכל פעם שיש לבחור תהליך לריצה, נבחר התהליך בעל ערך ה-PASS הנמוך ביותר. לאחר ריצת התהליך, ערך ה-STRIDE שלו מתווסף לערך ה-PASS שלו. משמעות הדבר היא שתהליך בעל ערך STRIDE נמוך יותר יגרום לערך ה-PASS שלו לגדול בקצב איטי יותר, ולכן הוא יישאר עם ערך PASS נמוך יחסית למשך זמן רב יותר, מה שיגדיל את הסיכויים שלו להיבחר שוב ושוב. כפי שמצוין בחומר ההרצאה: 'אם A יהיה בעל ערך 100 ו-B יהיה בעל ערך 200, אז זה אומר שנרצה להריץ את A פי 2 פעמים כל פעם שנריץ את B'. לפיכך, STRIDE נמוך יותר מקנה עדיפות גבוהה יותר וזמן מעבד רב יותר, ואילו STRIDE גבוה יותר פירושו פחות זמן מעבד. האלגוריתם פועל באופן דטרמיניסטי ולא אקראי כמו Lottery Scheduling."}, "_source_file": "0060__Virtualization__Scheduling_Algorithms__MC__Medium.json", "_topic_hint": "Scheduling Algorithms", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:07:02", "_subject": "Virtualization", "_context_lectures": [3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Scheduling Algorithms"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על החומר שהוצג אודות אלגוריתמי תזמון פרופורציונליים, Lottery Scheduling ו-Stride Scheduling, איזה מהיתרונות הבאים מתאר בצורה המדויקת ביותר את Stride Scheduling בהשוואה ל-Lottery Scheduling, במיוחד בהקשר של השגת הקצאת זמן מעבד יחסית מדויקת וצפויה על פני פרקי זמן קצרים?", "code_snippet": null, "options": ["א. Stride Scheduling מאפשר לתהליכים להוסיף או להוריד לעצמם כרטיסים באופן זמני (Ticket Inflation), מה שמגביר את הגמישות בתגובה לשינויים בעומס.", "ב. Stride Scheduling מבטיח חלוקה פרופורציונלית של זמן המעבד באופן דטרמיניסטי ומדויק יותר לאורך פרקי זמן קצרים, בניגוד לאופי ההסתברותי של Lottery Scheduling.", "ג. Stride Scheduling מטפל ביעילות רבה יותר בתהליכי קלט/פלט על ידי פיצול אוטומטי של ג'ובים לתת-ג'ובים קצרים יותר המאפשרים חפיפה.", "ד. Stride Scheduling מונע לחלוטין מצבי רעב (starvation) עבור תהליכים בעלי עדיפות נמוכה או מעט כרטיסים, מה שאינו מובטח ב-Lottery Scheduling."]}, "solution": {"correct_option": "ב", "explanation": "החומר המצורף מתאר את Lottery Scheduling כאלגוריתם שבו הבחירה נעשית 'באופן אקראי' על ידי 'כרטיסי הגרלה', מה שמקנה לתהליכים 'עדיפות גבוהה יותר (עם יחס מסוים)' או 'נבחר בהם בהסתברות גבוהה יותר'. אופי זה של בחירה אקראית, גם אם הוא פרופורציונלי בטווח הארוך, עלול לגרום לחוסר דיוק ואי-צפיות בהקצאת זמן המעבד בפרקי זמן קצרים. לעומת זאת, Stride Scheduling מתואר כאלגוריתם דטרמיניסטי שבו 'נבחר את הג'וב עם ה-pass הנמוך ביותר, ואז כל ריצה נוסיף את ה- stride שלו לערך ה-pass שלו'. מנגנון זה מבטיח התקדמות פרופורציונלית עקבית ומדויקת יותר של כל התהליכים, ובכך משיג חלוקה צפויה ומדויקת יותר של זמן המעבד גם בפרקי זמן קצרים.\n\nא. אפשרות זו שגויה. 'Ticket Inflation' היא תכונה המתוארת בחומר בהקשר של Lottery Scheduling, לא Stride Scheduling.\nג. אפשרות זו שגויה. הטיפול בתהליכי קלט/פלט על ידי פיצול ג'ובים לתת-ג'ובים מוזכר בחומר כ'גישה נפוצה' עבור מתזמן SRTF, ולא כתכונה ייחודית או אוטומטית של Stride Scheduling.\nד. אפשרות זו שגויה. אף שהאופי הדטרמיניסטי של Stride Scheduling הופך אותו לעמיד יותר בפני רעב מאשר Lottery Scheduling (שבו תהליך בעל כרטיסים מעטים יכול תיאורטית לא להיבחר לזמן מה), החומר אינו דן במפורש במושג 'רעב' עבור אף אחד מהאלגוריתמים, וכן הטענה 'מונע לחלוטין' היא חזקה מדי ולרוב אינה מדויקת במערכות מורכבות ללא תיאור מפורט נוסף."}, "_source_file": "0061__Virtualization__Scheduling_Algorithms__MC__Hard.json", "_topic_hint": "Scheduling Algorithms", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:07:21", "_subject": "Virtualization", "_context_lectures": [3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Scheduling Algorithms"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על אלגוריתמי התזמון הפרופורציונליים שהוצגו בחומר השיעור, איזה מהם מבטיח חלוקה מדויקת ועקבית יותר של זמן המעבד ביחס לשיעורים המוגדרים, בפרקי זמן קצרים יחסית, ומדוע?", "code_snippet": null, "options": ["א. תזמון הגרלה (Lottery scheduling), מכיוון שהוא מאפשר התאמה דינמית של כרטיסים (ticket inflation) ובכך מגיב במהירות לדרישות משתנות.", "ב. תזמון פסע (Stride scheduling), מכיוון שהוא מבוסס על ערכי PASS ו-STRIDE דטרמיניסטיים, אשר מבטיחים בחירה עקבית של התהליך עם ה-PASS הנמוך ביותר.", "ג. תזמון הגרלה (Lottery scheduling), מכיוון שההסתברות לבחירת תהליך מחושבת מחדש בכל קוואנטה, מה שמבטיח התכנסות מהירה ליחסים הרצויים.", "ד. תזמון פסע (Stride scheduling), מכיוון שהוא מאפשר פירוק תהליכים לתת-משימות (sub-jobs) ובכך מאפשר חפיפה יעילה יותר של פעולות קלט/פלט."]}, "solution": {"correct_option": "ב", "explanation": "תזמון פסע (Stride scheduling) מבטיח חלוקה מדויקת ועקבית יותר של זמן המעבד בפרקי זמן קצרים מכיוון שהוא אלגוריתם דטרמיניסטי. הוא עוקב אחר ערכי ה-PASS של כל ג'וב, המציינים כמה זמן הג'וב כבר רץ באופן יחסי. בכל נקודת החלטה, המתזמן בוחר את הג'וב עם ערך ה-PASS הנמוך ביותר ומוסיף ל-PASS שלו את ערך ה-STRIDE שלו. מנגנון זה מבטיח שהיחסים הפרופורציונליים יישמרו באופן עקבי ומיידי, ללא התלות באקראיות של הגרלה, כפי שקורה בתזמון הגרלה (Lottery scheduling). בעוד שתזמון הגרלה מתכנס ליחסים הרצויים לאורך זמן רב, בטווחים קצרים הוא עלול להציג סטיות בשל אופיו ההסתברותי. תזמון פסע, לעומת זאת, שומר על פרופורציה מדויקת בכל בחירה. אפשרויות א' ו-ג' מתארות היבטים של תזמון הגרלה אך אינן מדגישות דיוק בטווח קצר כמו תזמון פסע. אפשרות ד' מתייחסת לטכניקה המשמשת עם מתזמנים כמו SRTF כדי לטפל בקלט/פלט, ולא למנגנון הליבה של תזמון פסע לחלוקה פרופורציונלית."}, "_source_file": "0062__Virtualization__Scheduling_Algorithms__MC__Hard.json", "_topic_hint": "Scheduling Algorithms", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:07:37", "_subject": "Virtualization", "_context_lectures": [3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Scheduling Algorithms"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על תיאור אלגוריתמי התזמון Lottery Scheduling ו-Stride Scheduling בחומר השיעור, מהו ההבדל המהותי במנגנון הפנימי שלהם אשר משפיע על אופן מימוש ההקצאה הפרופורציונלית של זמן המעבד?", "code_snippet": null, "options": ["א. תזמון Lottery משתמש במנגנון 'כרטיסים' (Tickets) המאפשר העברה והגדלה דינמית של כרטיסים בין תהליכים, בעוד שתזמון Stride מסתמך על ערכי PASS ו-STRIDE קבועים מראש ללא יכולת שינוי.", "ב. תזמון Stride מבטיח הקצאה פרופורציונלית דטרמיניסטית ומדויקת על ידי מעקב אחר זמן הריצה המצטבר של כל תהליך באמצעות ערך ה-PASS, ובחירה עקבית של התהליך עם ה-PASS הנמוך ביותר, בניגוד לתזמון Lottery המבוסס על בחירה אקראית והסתברותית.", "ג. תזמון Lottery דורש ידע מוקדם על זמן הריצה הכולל של כל ג'וב כדי לחשב את מספר הכרטיסים שיש להקצות לו, בעוד שתזמון Stride אינו דורש מידע זה.", "ד. תזמון Stride מתמודד טוב יותר עם תהליכי קלט/פלט (I/O-bound jobs) על ידי פיצול ג'ובים לתת-ג'ובים קטנים יותר, בעוד שתזמון Lottery אינו מספק מנגנון דומה."]}, "solution": {"correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. תזמון Stride מתואר כאלגוריתם דטרמיניסטי: הוא עוקב באופן עקבי אחר ערך ה-PASS של כל ג'וב, המייצג את כמות הזמן שהג'וב רץ עד כה (באופן יחסי), ותמיד בוחר את הג'וב עם ערך ה-PASS הנמוך ביותר. לאחר מכן, ערך ה-PASS של הג'וב הנבחר מתעדכן על ידי הוספת ערך ה-STRIDE שלו. מנגנון זה מבטיח הקצאה פרופורציונלית מדויקת וצפויה לאורך זמן. לעומת זאת, תזמון Lottery מתבסס על מנגנון הסתברותי ואקראי: הוא מקצה 'כרטיסים' לג'ובים, ובכל נקודת זמן מבצע 'הגרלה' אקראית כדי לבחור את הג'וב הבא שירוץ. למרות שהוא משיג הקצאה פרופורציונלית בממוצע לאורך זמן, ההחלטות הבודדות הן אקראיות.\n\nא' שגויה מכיוון שאמנם Lottery מאפשר גמישות עם כרטיסים (העברה והגדלה), אך ההבדל המהותי אינו רק ביכולת השינוי, אלא בטבע האלגוריתם עצמו – הסתברותי מול דטרמיניסטי. Stride מיועד להבטיח פרופורציה מדויקת באמצעות מנגנון דטרמיניסטי של מעקב ובחירה.\nג' שגויה מכיוון שהחומר מציין הנחה כללית ש'אנחנו יודעים את זמן הריצה של כל ג'וב' עבור האלגוריתמים הנדונים, ולא דרישה ספציפית לאחד מהם. בנוסף, הקצאת הכרטיסים ב-Lottery או ערכי ה-STRIDE ב-Stride נועדו להקצאה פרופורציונלית, לאו דווקא על בסיס זמן ריצה כולל.\nד' שגויה מכיוון שהתמודדות עם תהליכי קלט/פלט (I/O-bound jobs) על ידי פיצול ג'ובים לתת-ג'ובים הוזכרה בחומר השיעור בהקשר של שיפור ניצול המעבד עם מתזמן ה-SRTF, ולא כמאפיין ייחודי או מבדיל בין Lottery ל-Stride."}, "_source_file": "0063__Virtualization__Scheduling_Algorithms__MC__Hard.json", "_topic_hint": "Scheduling Algorithms", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:07:59", "_subject": "Virtualization", "_context_lectures": [3]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Memory Management"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, מהי הנחת יסוד מפשטת מרכזית של אלגוריתם ה-\"free list\" כפי שתואר בתחילה כ\"פשוט ויעיל\"?", "code_snippet": null, "options": ["א. כל הבלוקים בזיכרון הם בגודל שווה.", "ב. הזיכרון מחולק תמיד למקטעים בגודל קבוע של 4KB.", "ג. המשתמש תמיד משחרר זיכרון באותו סדר שבו הקצה אותו.", "ד. הכתובות של בלוקים פנויים סמוכים תמיד נבדלות בביט אחד."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מתאר את אלגוריתם ה-\"free list\" הפשוט כיעיל מאוד כאשר הוא מניח ש\"נחלק את הזיכרון לבלוקים ונחזיק רשימה מקושרת שתגיד לנו מה הבלוקים פנוי.\" ובמיוחד מציין ש\"כל הבלוקים באותו גודל\". הנחה זו מפשטת מאוד את הניהול, שכן אין צורך לנהל גדלים משתנים או למיין את הרשימה. בהמשך ההרצאה מצוין כי אם מנסים להחיל את אותם כללים על גדלים משתנים, זה הופך להיות בעייתי.\nאפשרות ב' אינה נכונה, שכן גודל הבלוקים (100MB בדוגמה) אינו קבוע ל-4KB.\nאפשרות ג' אינה נכונה, שכן ההרצאה מציינת בהקשר של ניהול ערימה (heap) ש\"המשתמש יכול להקצות זיכרון ולשחרר אותו בסדר אחר\".\nאפשרות ד' מתייחסת למאפיין של אלגוריתם \"Buddy Allocation\" ולא של \"free list\" הפשוט."}, "_source_file": "0064__Virtualization__Memory_Management__MC__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:08:08", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Memory Management"], "difficulty_estimation": "Easy", "content": {"text": "איזו תכונה מהותית מייחדת את אלגוריתם ניהול הזיכרון \"free list\" כאשר הזיכרון מחולק לחלקים שווים בגודלם?", "code_snippet": null, "options": ["א. כל הבלוקים הפנויים ברשימה הם באותו גודל, מה שמפשט את ניהול הרשימה.", "ב. האלגוריתם דורש מבנה נתונים מורכב כדי לעקוב אחר גדלים שונים של בלוקים.", "ג. הוא יעיל במיוחד לטיפול בבקשות הקצאת זיכרון בגדלים משתנים מאוד.", "ד. הבעיה העיקרית שלו היא איחוד (coalesce) של בלוקים פנויים סמוכים בגדלים משתנים."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין מתאר את אלגוריתם \"free list\" שבו הזיכרון מחולק לחלקים שווים בגודלם. הוא מציין במפורש: \"כל הבלוקים באותו גודל\" ו-\"לא צריך למיין את הרשימה\", מה שמדגיש את פשטות הניהול הנובעת מכך שכל הפריטים ברשימה זהים בגודלם. אפשרות ב' אינה נכונה מכיוון שמבנה הנתונים פשוט כאשר הגדלים קבועים. אפשרות ג' אינה נכונה, שכן החומר מציין ששיטה זו \"לא מציאותית\" ו\"בעייתית\" עבור גדלים משתנים. אפשרות ד' מתייחסת לבעיה שאלגוריתמים כמו Buddy Allocation באים לפתור, ואינה רלוונטית ל-free list עם בלוקים בגודל קבוע, שם איחוד בלוקים לא נדרש באותה צורה."}, "_source_file": "0065__Virtualization__Memory_Management__MC__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:08:18", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Memory Management"], "difficulty_estimation": "Easy", "content": {"text": "איזו טענה נכונה לגבי אלגוריתם ניהול הזיכרון \"free list\" כאשר כל חלקי הזיכרון הם בגודל שווה?", "code_snippet": null, "options": ["א. הוא מאוד יעיל ופשוט ליישום וניהול.", "ב. הוא מתאים במיוחד לטיפול בבקשות הקצאה בגדלים משתנים.", "ג. הוא פותר ביעילות את בעיית איחוד שטחי הזיכרון הפנויים (coalesce) על ידי פיצול הזיכרון.", "ד. הוא דורש מבנה נתונים מורכב לניהול רשימת הבלוקים הפנויים."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, כאשר אלגוריתם 'free list' מנהל זיכרון המחולק לחלקים שווים בגודלם, הוא מתואר כ'מאוד יעיל וזה מאוד פשוט'. זאת מכיוון שכל הבלוקים זהים בגודלם, מה שמפשט את תהליך ההקצאה והשחרור ואינו דורש מיון או מבני נתונים מורכבים. אפשרות ב' אינה נכונה, מכיוון שהחומר מציין במפורש כי האלגוריתם הופך לבעייתי כאשר מנסים להחיל את אותם הכללים על גדלים משתנים. אפשרות ג' אינה נכונה, שכן Buddy Allocation הוא האלגוריתם שבא לפתור את בעיית ה-coalesce על ידי פיצול הזיכרון. אפשרות ד' אינה נכונה, מכיוון שהפשטות של האלגוריתם במקרה של בלוקים שווים בגודלם אומרת שאין צורך במבנה נתונים מורכב, אלא רק רשימה מקושרת פשוטה של בלוקים פנויים."}, "_source_file": "0066__Virtualization__Memory_Management__MC__Easy.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:08:26", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Memory Management"], "difficulty_estimation": "Medium", "content": {"text": "איזו בעיה מרכזית באלגוריתמי ניהול זיכרון נפתרת ביעילות על ידי שיטת Buddy Allocation, וכיצד היא עושה זאת?", "code_snippet": null, "options": ["א. בעיית ה-coalesce (איחוד שטחי זיכרון), על ידי פיצול הזיכרון לבלוקים בגודל חזקת 2 ואיחוד קל של בלוקים שכנים פנויים.", "ב. בעיית ההקצאה של בלוקים בגודל קבוע בלבד, בכך שהיא מאפשרת הקצאת זיכרון בכל גודל נתון.", "ג. בעיית ה-internal fragmentation (פיצול פנימי), על ידי הקצאת הזיכרון בדיוק בגודל המבוקש ללא בזבוז.", "ד. בעיית ניהול רשימת הבלוקים הפנויים (free list) המסובכת, על ידי שימוש במבנה נתונים פשוט המכיל רק מצביעים."]}, "solution": {"correct_option": "א", "explanation": "שיטת Buddy Allocation נועדה לפתור ביעילות את בעיית ה-coalesce (איחוד שטחי זיכרון פנויים קטנים לבלוקים גדולים יותר), שהיא סוג של פיצול חיצוני. האלגוריתם עובד על ידי פיצול הזיכרון לבלוקים בגודל חזקת 2. כאשר משתמש מבקש זיכרון, המערכת מפצלת בלוק גדול יותר לשני \"חברים\" (buddies) בגודל חזקת 2, עד שמגיעה לגודל המתאים (או הקרוב ביותר בחזקת 2). היתרון המרכזי הוא שבעת שחרור זיכרון, קל מאוד לזהות את ה\"חבר\" של הבלוק המשתחרר (באמצעות שינוי ביט אחד בכתובת). אם שני ה\"חברים\" פנויים, ניתן לאחד אותם מיידית לבלוק גדול יותר, ובכך להפחית פיצול חיצוני ולשפר את ניצול הזיכרון."}, "_source_file": "0067__Virtualization__Memory_Management__MC__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:08:40", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Memory Management"], "difficulty_estimation": "Medium", "content": {"text": "איזו טכניקה לניהול זיכרון מתוארת בחומר ההרצאה כפתרון לבעיית ה-coalesce (איחוד שטחי זיכרון פנויים) על ידי פיצול הזיכרון לחצאים ואיחוד בלוקים שכנים כאשר הם משתחררים?", "code_snippet": null, "options": ["א. Buddy Allocation", "ב. Free List עם בלוקים בגודל קבוע", "ג. Slab Allocation", "ד. Free List עם בלוקים בגודל משתנה"]}, "solution": {"correct_option": "א", "explanation": "הסבר: שיטת Buddy Allocation נועדה במיוחד לפתור את בעיית ה-coalesce, שהיא איחוד בלוקים פנויים סמוכים לבלוק גדול יותר. לפי חומר ההרצאה, בשיטה זו, כאשר זיכרון מבוקש, הוא מפוצל לחצאים שוב ושוב עד שמגיעים לבלוק בגודל מתאים. כאשר בלוק משוחרר, המערכת בודקת את ה\"שכן\" (buddy) שלו – בלוק בגודל זהה שכתובתו נבדלת בביט אחד בלבד. אם גם השכן פנוי, שני הבלוקים מאוחדים לבלוק אחד גדול יותר (למשל, שני בלוקים של 8KB יאוחדו ל-16KB), ובכך נמנעת פיצול פנימי ומקודמת יצירת בלוקים גדולים ורציפים. שיטות ה-Free List, בין אם עם בלוקים בגודל קבוע או משתנה, אינן מתוארות כבעלות מנגנון מובנה וברור לפתרון בעיית ה-coalesce בצורה זו, ו-Slab Allocation מתמקדת בהקצאת אובייקטים בגודל קבוע ולא בפתרון כללי ל-coalesce של זיכרון כללי."}, "_source_file": "0068__Virtualization__Memory_Management__MC__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:08:54", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Memory Management"], "difficulty_estimation": "Medium", "content": {"text": "בהתבסס על חומר ההרצאה, מהו היתרון המרכזי של אלגוריתם Buddy Allocation בהשוואה לניהול זיכרון באמצעות רשימת בלוקים פנויים בגודל קבוע, במיוחד בהקשר של התמודדות עם פיצול זיכרון?", "code_snippet": null, "options": ["א. היכולת להקצות זיכרון למקטעים בגדלים משתנים ללא צורך במבנה נתונים מורכב.", "ב. מניעת Overheads של ניהול זיכרון (כמו header) עבור כל בלוק שהוקצה.", "ג. התמודדות יעילה עם בעיית איחוד שטחי זיכרון פנויים סמוכים (coalesce) ויצירת בלוקים גדולים יותר.", "ד. הקצאת זיכרון מהירה יותר עבור אובייקטים קטנים וקבועים בגודלם, כמו אלו המשמשים את ליבת מערכת ההפעלה."]}, "solution": {"correct_option": "ג", "explanation": "על פי חומר ההרצאה, אלגוריתם Buddy Allocation \"בא לפתור את הבעיה של coalesce (איחוד שטחי זיכרון בודדים ופנויים)\". שיטה זו מפצלת בלוקי זיכרון גדולים לבלוקים קטנים יותר לפי הצורך, וברגע שבלוקים שכנים פנויים הם מאוחדים בחזרה ליצירת בלוקים גדולים יותר. בכך, Buddy Allocation מתמודד ביעילות עם פיצול זיכרון חיצוני ומאפשר הקצאות גדולות יותר. רשימת בלוקים פנויים בגודל קבוע, לעומת זאת, מתוארת כלא מציאותית עבור גדלים משתנים ועלולה לסבול ממצבים בהם לא ניתן להקצות זיכרון נדרש למרות שיש מספיק זיכרון פנוי בסך הכל, עקב פיצול."}, "_source_file": "0069__Virtualization__Memory_Management__MC__Medium.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:09:12", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Memory Management"], "difficulty_estimation": "Hard", "content": {"text": "איזה אלגוריתם ניהול זיכרון תוכנן במיוחד כדי לטפל ביעילות בפרגמנטציה חיצונית על ידי פישוט איחודם של בלוקי זיכרון פנויים סמוכים, ומהו המנגנון העיקרי שלו להשגת מטרה זו?", "code_snippet": null, "options": ["א. Free List עם בלוקים בגודל קבוע – הוא שומר רשימה של בלוקים פנויים זהים בגודלם, ולכן אינו מתמודד עם פרגמנטציה חיצונית באמצעות איחוד, אלא מונע אותה על ידי מבנה קבוע.", "ב. Buddy Allocation – הוא מפצל את הזיכרון לבלוקים בגדלים שהם חזקות של 2, ומאפשר איחוד מהיר של בלוקים שכנים פנויים על ידי בדיקת ביט בכתובת הזיכרון שלהם.", "ג. Slab Allocation – הוא מקצה בלוקים בגודל קבוע עבור אובייקטים ספציפיים, מה שמפחית פרגמנטציה פנימית אך אינו מיועד לפתור ביעילות פרגמנטציה חיצונית רחבה באמצעות איחוד בלוקים בגדלים שונים.", "ד. Free List עם בלוקים בגודל משתנה – הוא שומר כתובת וגודל לכל בלוק פנוי, אך איחוד בלוקים סמוכים דורש סריקה מורכבת של הרשימה או מבנה נתונים מורכב יותר למציאת שכנים, ואינו \"מפושט\" כפי שמתואר."]}, "solution": {"correct_option": "ב", "explanation": "האלגוריתם Buddy Allocation תוכנן במפורש כדי לפתור את בעיית ה-coalesce (איחוד שטחי זיכרון בודדים ופנויים), שהיא הדרך להתמודד עם פרגמנטציה חיצונית. לפי חומר ההרצאה, הוא מפצל את הזיכרון לבלוקים בגדלים שהם חזקות של 2. כאשר משתמש מפנה בלוק, האלגוריתם בודק את ה\"חבר\" (buddy) שלו – בלוק שכתובתו נבדלת בביט אחד בלבד. אם גם ה\"חבר\" פנוי, ניתן לאחד אותם במהירות לבלוק גדול יותר, ובכך לפשט מאוד את תהליך האיחוד ולשחזר שטחי זיכרון גדולים יותר. אפשרות א' (Free List עם בלוקים בגודל קבוע) אינה דורשת איחוד במובן של coalesce מכיוון שכל הבלוקים באותו גודל; היא מונעת פרגמנטציה חיצונית מורכבת אך אינה \"פותרת\" אותה באמצעות איחוד יעיל של בלוקים שונים. אפשרות ג' (Slab Allocation) מתמקדת בהקצאה יעילה של אובייקטים קטנים וקבועי גודל, בעיקר כדי להפחית פרגמנטציה פנימית וניהול תקורה, אך אינה מציעה מנגנון יעיל לפישוט איחוד בלוקים פנויים בגדלים משתנים. אפשרות ד' (Free List עם בלוקים בגודל משתנה) אכן סובלת מפרגמנטציה חיצונית ודורשת איחוד, אך חומר ההרצאה מציין שהרשימה המקושרת הופכת \"מורכבת יותר\" ואינו מתאר מנגנון \"מפושט\" לאיחוד, בניגוד ל-Buddy Allocation."}, "_source_file": "0070__Virtualization__Memory_Management__MC__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:09:31", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Memory Management"], "difficulty_estimation": "Hard", "content": {"text": "נתאר מצב שבו מערכת ההפעלה מבצעת הקצאות זיכרון רבות בגדלים שונים, ולאחר מכן משחררת אותן בסדר אקראי. כתוצאה מכך, הזיכרון הפיזי מתפצל למקטעים פנויים קטנים ולא רציפים, בעוד שנדרשת הקצאה גדולה יותר שאינה יכולה להתבצע למרות שסך הזיכרון הפנוי מספק. בהתבסס על חומר ההרצאה, איזה אלגוריתם לניהול זיכרון מציע פתרון מובנה ויעיל ביותר לבעיה זו של פיצול זיכרון חיצוני (External Fragmentation), באמצעות איחוד (coalesce) של שטחי זיכרון פנויים?", "code_snippet": null, "options": ["א. אלגוריתם Buddy Allocation", "ב. אלגוריתם Free List עם בלוקים בגודל קבוע", "ג. אלגוריתם Free List עם בלוקים בגודל משתנה", "ד. שימוש ב-Slab Allocator"]}, "solution": {"correct_option": "א", "explanation": "השאלה מתארת מצב של פיצול זיכרון חיצוני (External Fragmentation), שבו יש מספיק זיכרון פנוי בסך הכל, אך הוא מפוצל למקטעים קטנים ולא רציפים שאינם מאפשרים הקצאה של בלוק גדול. חומר ההרצאה מציין במפורש כי אלגוריתם Buddy Allocation 'בא לפתור את הבעיה של coalesce (איחוד שטחי זיכרון בודדים ופנויים)'. האלגוריתם מפצל בלוקים לגדלים שהם חזקות של 2, וכאשר בלוק משתחרר, הוא בודק את ה'שכן' שלו (buddy) ואם גם הוא פנוי, הם מאוחדים לבלוק גדול יותר. מנגנון זה נועד במיוחד להתמודד עם פיצול חיצוני על ידי איחוד שטחים פנויים.\n\nאפשרויות אחרות:\nב. אלגוריתם Free List עם בלוקים בגודל קבוע הוא פשוט ויעיל אך אינו מציאותי לטיפול בבקשות בגדלים משתנים, והוא סובל מפיצול פנימי אם גודל הבקשה קטן מגודל הבלוק. הוא אינו מיועד לאיחוד בלוקים פנויים בגדלים שונים לצורך יצירת בלוקים גדולים יותר.\nג. אלגוריתם Free List עם בלוקים בגודל משתנה מתמודד עם גדלים משתנים, אך חומר ההרצאה מציין במפורש שהוא 'יכול לקרות מצב שחלקנו את מה שיצא למשל יש חלק של 10kb יש חלק של 5kb ואחריו תפוס ואחריו 5kb פנוי. ונניח שהמשתמש מבקש 15kb, אין לזיכרון כנל לתת לו.' זהו תיאור מובהק של פיצול חיצוני, והחומר אינו מפרט מנגנון מובנה ויעיל לאיחוד בלוקים עבורו, אלא רק מציין שהרשימה תהיה 'יותר מורכבת'.\nד. Slab Allocator מיועד להקצאת אובייקטים בגודל קבוע ונפוץ (לרוב עבור אובייקטים של ליבת המערכת) ואינו פתרון כללי לניהול זיכרון משתנה בגדלים שונים או לטיפול בפיצול חיצוני של זיכרון כללי."}, "_source_file": "0072__Virtualization__Memory_Management__MC__Hard.json", "_topic_hint": "Memory Management", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:10:14", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Fragmentation"], "difficulty_estimation": "Easy", "content": {"text": "מהו המצב המתואר כ\"קיטוע פנימי\" (Internal Fragmentation) במערכות הפעלה?", "code_snippet": null, "options": ["א. מצב שבו מערכת ההפעלה מקצה למשתמש יותר זיכרון ממה שהוא ביקש, מה שמוביל לבזבוז.", "ב. מצב שבו יש מספיק זיכרון פנוי בסך הכל, אך הוא מפוזר במקטעים קטנים ולא רציפים, ולכן לא ניתן להקצותו לבקשה גדולה.", "ג. מצב שבו תהליכים ארוכים אינם מקבלים זמן מעבד בגלל הגעת תהליכים קצרים רבים.", "ד. מצב שבו הזיכרון הפיזי מנוצל במלואו, ולא נשאר שום זיכרון פנוי עבור תהליכים חדשים."]}, "solution": {"correct_option": "א", "explanation": "קיטוע פנימי (Internal Fragmentation) מתרחש כאשר מערכת ההפעלה מקצה למשתמש יחידת זיכרון גדולה יותר מהכמות המדויקת שביקש. העודף הלא מנוצל בתוך היחידה המוקצית נחשב לבזבוז. חומר ההרצאה מגדיר זאת במפורש: \"מצב בו אנחנו נותנים למשתמש יותר זיכרון ממה שהוא ביקש. זה בזבוז.\" אפשרות ב' מתארת קיטוע חיצוני, ואפשרויות ג' ו-ד' מתארות מצבים אחרים שאינם קיטוע זיכרון."}, "_source_file": "0073__Virtualization__Fragmentation__MC__Easy.json", "_topic_hint": "Fragmentation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:10:22", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Fragmentation"], "difficulty_estimation": "Easy", "content": {"text": "מהו קיטוע פנימי (internal fragmentation) בהקשר של ניהול זיכרון במערכת הפעלה?", "code_snippet": null, "options": ["א. מצב שבו המערכת מקצה למשתמש יותר זיכרון ממה שביקש בפועל, מה שמוביל לבזבוז.", "ב. מצב שבו יש מספיק זיכרון פנוי לטפל בבקשה מסוימת, אך הוא מפוצל למקטעים קטנים ומרוחקים.", "ג. בעיה המתרחשת כאשר תהליכים ארוכים אינם מקבלים זמן מעבד עקב תהליכים קצרים המגיעים כל הזמן.", "ד. מצב שבו זיכרון פיזי מומר לזיכרון וירטואלי כדי לאפשר ליותר תהליכים לרוץ במקביל."]}, "solution": {"correct_option": "א", "explanation": "האפשרות הנכונה היא א'. על פי חומר ההרצאה, קיטוע פנימי (internal fragmentation) מוגדר כ\"מצב בו אנחנו נותנים למשתמש יותר זיכרון ממה שהוא ביקש. זה בזבוז.\" מצב זה מתרחש כאשר מערכת ההפעלה מקצה בלוק זיכרון גדול יותר מהכמות המדויקת שנדרשה על ידי המשתמש, וכתוצאה מכך חלק מבלוק הזיכרון המוקצה נשאר בלתי מנוצל."}, "_source_file": "0074__Virtualization__Fragmentation__MC__Easy.json", "_topic_hint": "Fragmentation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:10:34", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Fragmentation"], "difficulty_estimation": "Easy", "content": {"text": "מהו קיטוע פנימי (internal fragmentation) בהקשר של ניהול זיכרון, על פי חומר ההרצאה?", "code_snippet": null, "options": ["א. מצב שבו מערכת ההפעלה מקצה למשתמש יותר זיכרון ממה שביקש בפועל.", "ב. מצב שבו קיים מספיק זיכרון פנוי בסך הכל, אך הוא מפוצל למקטעים קטנים ולא רציפים.", "ג. מצב שבו תהליך מסוים אינו מקבל זמן מעבד או משאבים אחרים לתקופה ארוכה.", "ד. פעולה של פיצול בלוק זיכרון פנוי גדול לשני בלוקים קטנים יותר, האחד עבור הבקשה והשני נשאר פנוי."]}, "solution": {"correct_option": "א", "explanation": "קיטוע פנימי (internal fragmentation) מוגדר בחומר ההרצאה כ\"מצב בו אנחנו נותנים למשתמש יותר זיכרון ממה שהוא ביקש. זה בזבוז.\" (Lecture 6, chunk 9 ו-8). אפשרות א' מתארת במדויק הגדרה זו. אפשרות ב' מתארת קיטוע חיצוני (external fragmentation). אפשרות ג' מתארת תופעת הרעבה (starvation) של תהליכים, ואילו אפשרות ד' מתארת פעולת פיצול (split) בניהול זיכרון, שהיא טכניקה ולא סוג של קיטוע פנימי בפני עצמו."}, "_source_file": "0075__Virtualization__Fragmentation__MC__Easy.json", "_topic_hint": "Fragmentation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:10:42", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Fragmentation"], "difficulty_estimation": "Medium", "content": {"text": "מהו המאפיין העיקרי של קיטוע פנימי (internal fragmentation) בניהול זיכרון במערכת הפעלה?", "code_snippet": null, "options": ["א. מצב שבו מערכת ההפעלה מקצה למשתמש יותר זיכרון ממה שהוא ביקש בפועל, מה שמוביל לבזבוז.", "ב. מצב שבו יש מספיק זיכרון פנוי בסך הכל כדי למלא בקשה, אך הוא מפוזר במקטעים לא רציפים ולכן לא ניתן להקצותו.", "ג. מצב שבו תהליכים ארוכי טווח אינם מקבלים זמן מעבד מספיק בגלל הגעת תהליכים קצרים יותר.", "ד. מצב שבו הזיכרון הפיזי קטן משמעותית מהזיכרון הוירטואלי שמערכת ההפעלה מספקת לתהליכים."]}, "solution": {"correct_option": "א", "explanation": "קיטוע פנימי (internal fragmentation) מוגדר במפורש בחומר ההרצאה כמצב שבו 'אנחנו נותנים למשתמש יותר זיכרון ממה שהוא ביקש. זה בזבוז.' (הרצאה 6, קטע 9, וגם הרצאה 6, קטע 8). אפשרות א' מתארת בדיוק מצב זה. אפשרות ב' מתארת קיטוע חיצוני (external fragmentation), כפי שמוסבר בהרצאה 9, קטע 2 ובהרצאה 5, קטע 30. אפשרות ג' מתייחסת לבעיית הרעבה (starvation), כפי שמוסבר בהרצאה 9, קטע 2. אפשרות ד' מתארת את עקרון הכללי של וירטואליזציה של זיכרון, אך לא את המאפיין הספציפי של קיטוע פנימי."}, "_source_file": "0076__Virtualization__Fragmentation__MC__Medium.json", "_topic_hint": "Fragmentation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:10:58", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Fragmentation"], "difficulty_estimation": "Medium", "content": {"text": "איזו מהטענות הבאות מתארת נכונה סוג של קיטוע זיכרון (fragmentation) כפי שהוגדר בחומר ההרצאה?", "code_snippet": null, "options": ["א. קיטוע פנימי (internal fragmentation) מתרחש כאשר מערכת ההפעלה מקצה למשתמש יותר זיכרון ממה שביקש בפועל.", "ב. קיטוע חיצוני (external fragmentation) מתרחש כאשר כל הזיכרון הפנוי בוטל לחלוטין ואין אפשרות להקצות זיכרון נוסף.", "ג. בדפדוף (paging) קיימת בעיה מובנית של קיטוע חיצוני (external fragmentation).", "ד. פעולת ה-coalesce משמשת לפיצול בלוק זיכרון גדול לשני בלוקים קטנים יותר."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר ההרצאה מגדיר במפורש 'internal fragmentation' כמצב בו 'אנחנו נותנים למשתמש יותר זיכרון ממה שהוא ביקש. זה בזבוז.' (הרצאה 6, קטע 9). \n\nאפשרויות אחרות אינן נכונות: \nב. זוהי אינה ההגדרה של קיטוע חיצוני. קיטוע חיצוני מתאר מצב בו יש מספיק זיכרון פנוי בסך הכל, אך הוא מפוזר במקטעים קטנים שאינם רציפים, כך שלא ניתן לספק בקשה לבלוק גדול ורציף (הרצאה 9, קטע 2; הרצאה 5, קטע 30).\nג. חומר ההרצאה קובע במפורש כי הטענה שבדפדוף יש בעיה של קיטוע חיצוני 'לא נכונה' (הרצאה 9, קטע 2).\nד. פעולת ה-coalesce משמשת לאיחוד שטחי זיכרון סמוכים פנויים לשטח אחד גדול יותר, בעוד שפיצול בלוק זיכרון מתבצע באמצעות פעולת split (הרצאה 5, קטע 32)."}, "_source_file": "0077__Virtualization__Fragmentation__MC__Medium.json", "_topic_hint": "Fragmentation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:11:10", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Fragmentation"], "difficulty_estimation": "Medium", "content": {"text": "מהו המאפיין העיקרי של קיטוע חיצוני (external fragmentation) בניהול זיכרון?", "code_snippet": null, "options": ["א. קיים מספיק זיכרון פנוי בסך הכל כדי למלא בקשה, אך הוא מפוזר במקטעים קטנים ולא רציפים.", "ב. מערכת ההפעלה מקצה לתהליך יותר זיכרון ממה שהוא ביקש בפועל.", "ג. זיכרון מתבזבז בגלל שתהליך ממתין למשאב ואינו יכול להשתמש בזיכרון שהוקצה לו.", "ד. סך הזיכרון הפיזי הזמין קטן מסך הזיכרון הווירטואלי המבוקש על ידי כל התהליכים יחד."]}, "solution": {"correct_option": "א", "explanation": "קיטוע חיצוני (external fragmentation) מתאר מצב שבו יש מספיק זיכרון פנוי בסך הכל כדי למלא בקשת הקצאה מסוימת, אך זיכרון זה אינו זמין כבלוק רציף אחד אלא מפוזר במקטעים קטנים ולא סמוכים. כפי שצויין בחומר ההרצאה, 'קיטוע חיצוני קורה כאשר יש לנו שטח מסוים של זיכרון שאנחנו מנהלים וכל מיני קטעים בו תפוסים בצורה כזו שנשאר לנו זיכרון פנוי אבל לא מספיק, למשל עבור הקצאה גדולה שרוצה הרבה זיכרון אבל אנחנו לא יכולים לספק אותה למרות שסך כל הזיכרון כן מספיק, זה קורה בגלל שהזיכרון הפנוי שלנו קטוע ומחולק לכל מיני מקטעים קטנים כך שיש לנו הרבה זיכרון פנוי אבל כל חלק הוא קטן מדי'.\nאפשרות ב' מתארת קיטוע פנימי (internal fragmentation), שבו המערכת מקצה יותר זיכרון ממה שהמשתמש ביקש. אפשרויות ג' ו-ד' אינן מתארות קיטוע זיכרון באופן ישיר."}, "_source_file": "0078__Virtualization__Fragmentation__MC__Medium.json", "_topic_hint": "Fragmentation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:11:20", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Fragmentation"], "difficulty_estimation": "Hard", "content": {"text": "נתון כי מערכת הפעלה משתמשת בוירטואליזציה של הזיכרון כדי לאפשר למספר רב של תהליכים, שלכל אחד מהם מוקצה מרחב כתובות וירטואלי גדול (למשל 4GB), לרוץ בו-זמנית על זיכרון פיזי מוגבל (למשל 8GB). איזו טענה לגבי בעיות קיטוע (fragmentation) במערכת כזו היא הנכונה ביותר לפי חומר ההרצאה?", "code_snippet": null, "options": ["א. קיטוע פנימי (internal fragmentation) הוא בעיה בלתי נמנעת עקב הקצאת זיכרון ביחידות בגודל קבוע, בעוד שקיטוע חיצוני (external fragmentation) נמנע במידה רבה תודות ליכולת של הזיכרון הווירטואלי למפות דפים פיזיים לא רציפים למרחב כתובות וירטואלי רציף.", "ב. קיטוע חיצוני (external fragmentation) הוא הבעיה העיקרית, שכן ריבוי תהליכים המשתמשים בזיכרון וירטואלי גורם ליצירת 'חורים' רבים בזיכרון הפיזי שקשה לאחד אותם.", "ג. קיטוע פנימי (internal fragmentation) וגם קיטוע חיצוני (external fragmentation) אינם מהווים בעיה משמעותית בזיכרון וירטואלי, מכיוון שמערכת ההפעלה יכולה לאחד (coalesce) שטחי זיכרון פנויים באופן דינמי.", "ד. הבעיה המרכזית אינה קיטוע אלא הרעבה (starvation) של תהליכים ארוכים, מכיוון שהזיכרון הווירטואלי נותן עדיפות לתהליכים קצרים יותר."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה, קיטוע פנימי (internal fragmentation) מתרחש כאשר 'אנחנו נותנים למשתמש יותר זיכרון ממה שהוא ביקש. זה בזבוז.' בזיכרון וירטואלי, הממומש לרוב באמצעות דפדוף (paging), זיכרון מוקצה ביחידות בגודל קבוע (דפים). אם תהליך זקוק לפחות מזיכרון של דף שלם, יתרת הדף מבוזבזת, וזהו קיטוע פנימי. לעומת זאת, חומר ההרצאה קובע במפורש כי 'טענה: בדפדוף יש בעיה של קיטוע חיצוני (external fragmentation). הטענה לא נכונה.' הסיבה לכך היא שוירטואליזציית הזיכרון מאפשרת למפות דפים פיזיים שאינם רציפים לתוך מרחב כתובות וירטואלי רציף עבור התהליך, ובכך נמנעת הבעיה של זיכרון פנוי מפוצל שאינו מספיק לבקשה גדולה למרות שסך הזיכרון הפנוי מספיק. אפשרויות ב', ג' ו-ד' אינן נכונות: ב' סותרת ישירות את הנאמר לגבי קיטוע חיצוני בדפדוף; ג' שגויה משום שקיטוע פנימי אכן קיים בזיכרון וירטואלי, ו'איחוד' (coalesce) רלוונטי יותר לניהול בלוקים בגודל משתנה ולא לטיפול בקיטוע חיצוני בזיכרון וירטואלי; ו-ד' מתייחסת לבעיית הרעבה (starvation), שהיא בעיית תזמון מעבדים ולא בעיית קיטוע זיכרון."}, "_source_file": "0079__Virtualization__Fragmentation__MC__Hard.json", "_topic_hint": "Fragmentation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:11:40", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Fragmentation"], "difficulty_estimation": "Hard", "content": {"text": "בהתחשב בתפקידה של וירטואליזציית הזיכרון, ובפרט מנגנון הדפדוף (paging), בניהול זיכרון המערכת, איזו מהטענות הבאות מתארת נכונה את סוגי הקיטוע (fragmentation) שעלולים להיווצר או להימנע?", "code_snippet": null, "options": ["א. וירטואליזציית הזיכרון באמצעות דפדוף פותרת לחלוטין את בעיית הקיטוע החיצוני אך עלולה להציג קיטוע פנימי, כיוון שתהליכים מקבלים דפי זיכרון בגודל קבוע גם אם אינם מנצלים את כולם.", "ב. וירטואליזציית הזיכרון באמצעות דפדוף פותרת לחלוטין את בעיית הקיטוע הפנימי, אך מחמירה את בעיית הקיטוע החיצוני עקב הצורך בניהול טבלת דפים מורכבת.", "ג. וירטואליזציית הזיכרון אינה משפיעה על סוגי הקיטוע, שכן קיטוע הוא תמיד בעיה של הזיכרון הפיזי בלבד, ללא קשר לאופן שבו מערכת ההפעלה מציגה אותו לתהליכים.", "ד. וירטואליזציית הזיכרון באמצעות דפדוף גורמת הן לקיטוע פנימי והן לקיטוע חיצוני, שכן היא מחלקת את הזיכרון למקטעים קטנים רבים."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר ההרצאה מציין במפורש כי \"טענה: בדפדוף יש בעיה של קיטוע חיצוני (external fragmentation). הטענה לא נכונה.\" כלומר, מנגנון הדפדוף (paging), שהוא ליבת וירטואליזציית הזיכרון, מונע קיטוע חיצוני. הסיבה לכך היא שהזיכרון הפיזי מחולק למסגרות (frames) בגודל קבוע, וניתן להקצות כל מסגרת פנויה לכל דף וירטואלי, ללא צורך ברצף פיזי. לעומת זאת, חומר ההרצאה מגדיר קיטוע פנימי כ\"מצב בו אנחנו נותנים למשתמש יותר זיכרון ממה שהוא ביקש. זה בזבוז.\" בדפדוף, תהליכים מקבלים יחידות זיכרון בגודל קבוע (דפים). אם תהליך זקוק לזיכרון שאינו כפולה מדויקת של גודל הדף, הדף האחרון שהוקצה לו לא ינוצל במלואו, מה שמוביל לקיטוע פנימי."}, "_source_file": "0080__Virtualization__Fragmentation__MC__Hard.json", "_topic_hint": "Fragmentation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:11:58", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Fragmentation"], "difficulty_estimation": "Hard", "content": {"text": "וירטואליזציית זיכרון מאפשרת לתהליכים להאמין כי עומד לרשותם מרחב כתובות רציף וגדול, גם כאשר הזיכרון הפיזי מפוצל. בהתחשב בכך ששיטת הדפדוף (paging), המהווה מימוש נפוץ לוירטואליזציה זו, אינה סובלת מקיטוע חיצוני כפי שצויין בחומר הלימוד, איזה סוג של קיטוע נחשב ל*פשרה* או *תוצאה אופיינית* של ניהול זיכרון המבוסס על יחידות הקצאה בגודל קבוע (כדוגמת דפים) במערכות מודרניות?", "code_snippet": null, "options": ["א. קיטוע פנימי (Internal fragmentation), מכיוון שיחידות הקצאה בגודל קבוע (כמו דפים) מובילות לעיתים קרובות לחלל לא מנוצל בתוך הבלוק המוקצה האחרון של תהליך.", "ב. קיטוע חיצוני (External fragmentation), מכיוון שהזיכרון הפיזי מתפזר לאורך זמן, מה שמקשה על מציאת בלוקים רציפים גדולים.", "ג. אף סוג של קיטוע, שכן וירטואליזציית הזיכרון מבטלת לחלוטין את בעיות הקיטוע.", "ד. גם קיטוע פנימי וגם קיטוע חיצוני, מכיוון שוירטואליזציה רק מסווה את בעיית הקיטוע, אך אינה פותרת אותה מהיסוד."]}, "solution": {"correct_option": "א", "explanation": "החומר מציין במפורש כי \"בדפדוף יש בעיה של קיטוע חיצוני (external fragmentation). הטענה לא נכונה.\" (Lecture 9, chunk 2). משמעות הדבר היא שדפדוף, כמימוש נפוץ של וירטואליזציית זיכרון המשתמש ביחידות בגודל קבוע (דפים), פותר את בעיית הקיטוע החיצוני. עם זאת, החומר מגדיר קיטוע פנימי כ\"מצב בו אנחנו נותנים למשתמש יותר זיכרון ממה שהוא ביקש. זה בזבוז.\" (Lecture 6, chunk 9). כאשר מערכת ההפעלה מקצה זיכרון לתהליך באמצעות דפים בגודל קבוע, ייתכן שהחלק האחרון של הזיכרון המוקצה לא ינוצל במלואו, מכיוון שגודל הנתונים של התהליך אינו בהכרח כפולה מדויקת של גודל הדף. שטח לא מנוצל זה בתוך הדף האחרון מהווה קיטוע פנימי, וזוהי פשרה אופיינית בשיטות ניהול זיכרון המבוססות על הקצאה ביחידות קבועות."}, "_source_file": "0081__Virtualization__Fragmentation__MC__Hard.json", "_topic_hint": "Fragmentation", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:12:17", "_subject": "Virtualization", "_context_lectures": [9, 5, 6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Virtual Memory"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, כיצד נקראת יחידת הזיכרון אליה מחולק הזיכרון הוירטואלי של תהליך לחלקים שווים?", "code_snippet": null, "options": ["א. דף (Page)", "ב. מסגרת (Page Frame)", "ג. סגמנט (Segment)", "ד. שטח כתובות (Address Space)"]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מציין במפורש: \"לוקחים את הזיכרון הוירטואלי של התהליך ומחלקים אותו לחלקים שווים. לכל חלק אנחנו קוראים **דף**.\" (Lecture 6, chunk 25 ו-26). 'מסגרת' (Page Frame) היא יחידה בזיכרון הפיזי, 'סגמנט' אינו היחידה שבה מתבצעת חלוקה שווה של הזיכרון הוירטואלי לפי החומר, ו'שטח כתובות' הוא מרחב הזיכרון הכולל, לא היחידה הקטנה אליה הוא מחולק."}, "_source_file": "0082__Virtualization__Virtual_Memory__MC__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:12:26", "_subject": "Virtualization", "_context_lectures": [6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Virtual Memory"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של וירטואליזציית זיכרון (Virtual Memory) במערכת הפעלה?", "code_snippet": null, "options": ["א. לאפשר לכל תהליך גישה למרחב זיכרון גדול יותר ממה שקיים פיזית במחשב.", "ב. לפשט את ניהול הזיכרון על ידי שימוש במנגנון base&bounds.", "ג. להבטיח שכל 4GB של זיכרון וירטואלי לתהליך יהיו תמיד טעונים בזיכרון הפיזי (RAM).", "ד. למנוע גישה בלתי מורשית לדיסק הקשיח על ידי תהליכים."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, וירטואליזציית זיכרון נועדה לאפשר למערכת ההפעלה לספק לכל תהליך '4GB של זיכרון' (chunk 10), למרות ש'בפועל אין לנו מספיק זיכרון לכך'. הזיכרון הוירטואלי הוא 'זיכרון שלא באמת קיים' פיזית במלואו, אלא ממופה לזיכרון פיזי ולעיתים אף לדיסק הקשיח. כך, תהליכים יכולים לפעול כאילו יש להם מרחב כתובות גדול מאוד מבלי לדרוש את כל המשאבים הפיזיים בו זמנית. תשובה ב' אינה נכונה מכיוון ש'אין לנו בכלל base&bounds' בווירטואליזציית זיכרון (chunk 25). תשובה ג' אינה נכונה משום ש'רוב התהליכים לא משתמשים ביותר מ-1GB ולכן לא צריך להחזיק את כל השטח הזה בזיכרון אם לא משתמשים בו' ו'חלק מהזיכרון של התהליכים מופנה להארד-דיסק' (chunk 10). תשובה ד' אינה נכונה מכיוון שהמטרה העיקרית היא לא מניעת גישה לדיסק הקשיח, אלא ניהול זיכרון יעיל המשתמש גם בדיסק הקשיח."}, "_source_file": "0083__Virtualization__Virtual_Memory__MC__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:12:36", "_subject": "Virtualization", "_context_lectures": [6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Virtual Memory"], "difficulty_estimation": "Easy", "content": {"text": "על פי החומר הנלמד, באיזו יחידה בסיסית מערכת ההפעלה מחלקת את מרחב הכתובות הווירטואלי של תהליך?", "code_snippet": null, "options": ["א. סגמנטים", "ב. בלוקים", "ג. דפים", "ד. מסגרות"]}, "solution": {"correct_option": "ג", "explanation": "החומר הנלמד מציין במפורש כי מערכת ההפעלה לוקחת את הזיכרון הוירטואלי של התהליך ומחלקת אותו לחלקים שווים, ולכל חלק כזה אנו קוראים 'דף'. 'מסגרת' היא יחידת חלוקה של הזיכרון הפיזי, ולא של הזיכרון הוירטואלי. 'סגמנטים' מתייחסים לשיטת ניהול זיכרון שאינה בשימוש בזיכרון וירטואלי המבוסס על דפים (כפי שצוין שאין יותר base&bounds). 'בלוקים' הוא מונח כללי ואינו היחידה הספציפית לחלוקת הזיכרון הוירטואלי."}, "_source_file": "0084__Virtualization__Virtual_Memory__MC__Easy.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:12:46", "_subject": "Virtualization", "_context_lectures": [6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Virtual Memory"], "difficulty_estimation": "Medium", "content": {"text": "במערכת הפעלה המשתמשת בזיכרון וירטואלי, מהו תפקידו העיקרי של רכיב ה-MMU (Memory Management Unit) ואיזה מבנה נתונים הוא מנצל לביצוע תפקיד זה?", "code_snippet": null, "options": ["א. ה-MMU אחראי לתרגום כתובות וירטואליות לכתובות פיזיות, והוא נעזר ב\"טבלת הדפים\" (Page Table) של התהליך לצורך כך.", "ב. ה-MMU אחראי להקצות 4GB של זיכרון פיזי לכל תהליך, והוא משתמש ברגיסטרי base&bounds כדי לוודא גישה חוקית.", "ג. ה-MMU אחראי לניהול הדיסק הקשיח כהרחבה לזיכרון הפיזי, והוא משתמש במבנה נתונים ייעודי לניהול קבצים.", "ד. ה-MMU אחראי לחלוקת הזיכרון הפיזי לדפים שווים בגודלם, והוא שומר את המידע הזה ב-kernel."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה, ה-MMU (Memory Management Unit) הוא רכיב חומרה שתפקידו לקבל כתובת וירטואלית ולתרגם אותה לכתובת פיזית (chunk 14). לצורך תרגום זה, ה-MMU נעזר ב\"טבלת הדפים\" (Page Table), שהיא מבנה נתונים הנשמר עבור כל תהליך ב-kernel ומכיל את המיפויים בין דפים וירטואליים למסגרות פיזיות (chunk 28). אפשרויות ב', ג' ו-ד' מתארות תפקידים שאינם התפקיד העיקרי של ה-MMU או שהן שגויות בפרטים לגבי אופן פעולת הזיכרון הווירטואלי (למשל, ביטול השימוש ב-base&bounds בזיכרון וירטואלי, chunk 25)."}, "_source_file": "0085__Virtualization__Virtual_Memory__MC__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:12:58", "_subject": "Virtualization", "_context_lectures": [6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Virtual Memory"], "difficulty_estimation": "Medium", "content": {"text": "מהי הסיבה העיקרית לשימוש במנגנון הזיכרון הוירטואלי על ידי מערכת ההפעלה, וכיצד היא מאפשרת זאת לכל תהליך?", "code_snippet": null, "options": ["א. לאפשר לכל תהליך לקבל מרחב כתובות גדול ועצמאי (לדוגמה, 4GB) גם כשיש פחות זיכרון פיזי זמין, על ידי חלוקת הזיכרון הוירטואלי לדפים ושימוש בטבלאות מיפוי לזיכרון הפיזי.", "ב. לייעל את השימוש בזיכרון הפיזי על ידי אחסון כל הנתונים החשובים בכונן הקשיח (הארד-דיסק) בלבד, ובכך לפנות את ה-RAM לשימושים אחרים של מערכת ההפעלה.", "ג. להחליף את מנגנון ה-base&bounds במנגנון המאפשר לתהליכים לגשת ישירות לכל הזיכרון הפיזי במערכת ללא צורך בתרגום כתובות.", "ד. לאבטח את הזיכרון על ידי מניעת גישה של תהליכים למרחבי זיכרון של תהליכים אחרים, אך רק כאשר כל הזיכרון הוירטואלי של התהליך נמצא במלואו בזיכרון הפיזי."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. הזיכרון הוירטואלי מאפשר למערכת ההפעלה לספק לכל תהליך מרחב כתובות גדול ועצמאי (לדוגמה, 4GB), גם אם בפועל אין מספיק זיכרון פיזי זמין לכל התהליכים יחד. כפי שצוין בחומר ההרצאה: \"אנחנו כביכול מספקים לכל תהליך 4GB של זיכרון כשבפועל אין לנו מספיק זיכרון לכך. הדבר נעשה ע\"י וירטואליזציה של הזיכרון\". מערכת ההפעלה משיגה זאת על ידי חלוקת מרחב הכתובות הוירטואלי של התהליך לחלקים שווים הנקראים \"דפים\", וחלוקת הזיכרון הפיזי ל\"מסגרות דפים\" (כפי שמתואר ב\"לוקחים את הזיכרון הוירטואלי של התהליך ומחלקים אותו לחלקים שווים. לכל חלק אנחנו קוראים דף\"). היא מחזיקה \"טבלאות דפים\" (mappings) הממפות כתובות וירטואליות לכתובות פיזיות (\"מערכת ההפעלה מחזיקה מיפויים\"). רכיב ה-MMU משתמש בטבלאות אלו לתרגום כתובות בזמן אמת. תשובה ב' שגויה מכיוון שאף על פי שהארד-דיסק משמש כמקום אחסון נוסף (swapping), מטרת הזיכרון הוירטואלי אינה לאחסן *את כל* הנתונים החשובים שם או לפנות RAM לשימושים אחרים באופן בלעדי. תשובה ג' שגויה כי הזיכרון הוירטואלי אכן מחליף את מנגנון ה-base&bounds, אך הוא דורש תרגום כתובות על ידי ה-MMU ואינו מאפשר גישה ישירה לזיכרון הפיזי. תשובה ד' שגויה חלקית: הזיכרון הוירטואלי אכן מספק בידוד ואבטחה בין תהליכים, אך הוא עושה זאת ללא קשר לשאלה אם כל הזיכרון הוירטואלי של התהליך נמצא במלואו בזיכרון הפיזי או שחלקו נמצא בהארד-דיסק."}, "_source_file": "0086__Virtualization__Virtual_Memory__MC__Medium.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:13:16", "_subject": "Virtualization", "_context_lectures": [6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Virtual Memory"], "difficulty_estimation": "Hard", "content": {"text": "מערכת ההפעלה מממשת זיכרון וירטואלי כדי לספק לכל תהליך אשליה של מרחב כתובות רציף וגדול (לדוגמה, 4GB), אף שבפועל הזיכרון הפיזי מוגבל ומפוצל, וחלקים ממרחב הכתובות הוירטואלי כלל אינם קיימים בזיכרון הפיזי או נמצאים על דיסק. בהקשר זה, מהו התפקיד המהותי ביותר של **טבלת הדפים** (Page Table) בשיתוף עם ה-**MMU**, המאפשר למערכת ההפעלה לנהל ביעילות את המשאב הפיזי המוגבל ולהגן על תהליכים זה מזה?", "code_snippet": null, "options": ["א. טבלת הדפים מאפשרת ל-MMU לתרגם כל כתובת וירטואלית לכתובת פיזית מדויקת, ללא צורך שהדפים הוירטואליים יהיו רציפים בזיכרון הפיזי, ובכך מונעת גישה בלתי חוקית של תהליך אחד לזיכרון של תהליך אחר.", "ב. טבלת הדפים משמשת בעיקר לאחסון קוד התהליך והמחסנית שלו, ומאפשרת ל-MMU לאתר אותם במהירות כאשר התהליך מופעל, ובכך משפרת את מהירות הטעינה של תהליכים חדשים.", "ג. טבלת הדפים מאפשרת למערכת ההפעלה להגדיל את נפח הזיכרון הפיזי הזמין על ידי שימוש בדיסק הקשיח כהרחבה ישירה של ה-RAM, ללא כל תלות ב-MMU.", "ד. טבלת הדפים מבטיחה שכל 4GB הווירטואליים של תהליך יוקצו באופן רציף בזיכרון הפיזי ברגע שהתהליך נטען, תוך שימוש ב-base&bounds כדי לאכוף גבולות אלו."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'.\n\n**הסבר עבור א' (נכון):** החומר המצוין בשיעור מסביר כי זיכרון וירטואלי מחלק את מרחב הכתובות של תהליך ל'דפים' (pages) ואת הזיכרון הפיזי ל'מסגרות' (page frames). טבלת הדפים היא מבנה נתונים לכל תהליך, הנשמרת בקרנל, ותפקידה העיקרי הוא למפות דפים וירטואליים למסגרות פיזיות. ה-MMU (Memory Management Unit) הוא רכיב חומרה המשתמש בטבלת הדפים כדי לתרגם כתובת וירטואלית לכתובת פיזית. יכולת המיפוי הזו מאפשרת לדפים וירטואליים להיות מפוזרים באופן לא רציף בזיכרון הפיזי, ובכך מנוצלים ביעילות מקטעי זיכרון פנויים קטנים. יתרה מכך, ה-MMU בודק חוקיות גישה (לדוגמה, אם תהליך ניגש לכתובת שאסור לו), ומייצר שגיאה במקרה של גישה בלתי חוקית, ובכך מספק הגנה בין תהליכים שונים.\n\n**הסבר עבור ב' (לא נכון):** החומר מציין במפורש ש\"לא מעניין את מערכת ההפעלה אם זה קוד/מחסנית/ערימה\" בהקשר של חלוקת הזיכרון לדפים. טבלת הדפים ממפה כל חלק ממרחב הכתובות הווירטואלי (ללא קשר לסוגו) לזיכרון הפיזי. תפקידה העיקרי אינו שיפור מהירות טעינה ספציפית, אלא ניהול תרגום כתובות והגנה.\n\n**הסבר עבור ג' (לא נכון):** אכן, מערכת ההפעלה יכולה להשתמש בדיסק הקשיח כמקום אחסון נוסף לדפים (swapping/paging), אך היא אינה מגדילה את נפח הזיכרון הפיזי (RAM), אלא יוצרת אשליה של זיכרון גדול יותר. יתרה מכך, תרגום כתובות לדפים שנמצאים על הדיסק עדיין מתבצע באמצעות ה-MMU (שמייצר Page Fault כאשר הדף אינו ב-RAM), כך שאינה פועלת \"ללא כל תלות ב-MMU\".\n\n**הסבר עבור ד' (לא נכון):** החומר מציין במפורש ש\"עכשיו אין לנו בכלל base&bounds\" וכי הזיכרון הווירטואלי מתחלק לדפים שאינם בהכרח רציפים בזיכרון הפיזי. המטרה של זיכרון וירטואלי היא בדיוק לאפשר הקצאה לא רציפה בזיכרון הפיזי וכן לא לטעון את כל 4GB של תהליך בבת אחת אם אינם בשימוש."}, "_source_file": "0088__Virtualization__Virtual_Memory__MC__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:13:47", "_subject": "Virtualization", "_context_lectures": [6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Virtual Memory"], "difficulty_estimation": "Hard", "content": {"text": "תהליך מנסה לגשת לכתובת זיכרון וירטואלית מסוימת. רכיב ה-MMU (Memory Management Unit) ניגש לטבלת הדפים של התהליך כדי לבצע את התרגום הנדרש, ומגלה שהדף הוירטואלי המכיל את הכתובת אינו ממופה כרגע למסגרת פיזית בזיכרון הראשי (RAM), אלא נמצא על הדיסק הקשיח (או אינו טעון כלל). מהי התוצאה המיידית של גילוי זה על ידי ה-MMU וכיצד מערכת ההפעלה צפויה לטפל במצב זה?", "code_snippet": null, "options": ["א. ה-MMU יפעיל פסיקת \"כשל דף\" (Page Fault), ומערכת ההפעלה תטפל בפסיקה על ידי טעינת הדף מהדיסק הקשיח למסגרת פנויה בזיכרון הפיזי, ועדכון טבלת הדפים.", "ב. ה-MMU ינסה לתרגם ישירות את הכתובת הווירטואלית לכתובת פיזית על הדיסק הקשיח, ויבצע גישה ישירה לדיסק כדי לאחזר את הנתונים.", "ג. התהליך יופסק באופן מיידי על ידי מערכת ההפעלה עקב ניסיון גישה בלתי חוקית לזיכרון.", "ד. מערכת ההפעלה תקצה לתהליך מרחב זיכרון וירטואלי חדש בגודל 4GB ותעתיק אליו את הנתונים הקיימים של התהליך."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. תפקידו העיקרי של ה-MMU הוא לתרגם כתובות וירטואליות לכתובות פיזיות בעזרת טבלת הדפים של התהליך. כאשר ה-MMU מגלה שטבלת הדפים מצביעה על כך שהדף הוירטואלי אינו טעון כרגע בזיכרון הפיזי (RAM) – מצב המכונה \"כשל דף\" (Page Fault) – הוא אינו מבצע גישה ישירה לדיסק. במקום זאת, ה-MMU מפעיל פסיקה (interrupt) המכונה \"כשל דף\". מערכת ההפעלה, כחלק מטיפול בפסיקה זו, לוקחת אחריות על טעינת הדף הנדרש מהדיסק הקשיח (שבו הוא מאוחסן, כפי שמצוין בחומר הלימוד כי \"חלק מהזיכרון של התהליכים מופנה להארד-דיסק\") למסגרת פיזית פנויה ב-RAM. לאחר הטעינה, מערכת ההפעלה מעדכנת את טבלת הדפים של התהליך כך שתשקף את המיקום הפיזי החדש של הדף, ואז מאפשרת לתהליך להמשיך בביצוע הפקודה שגרמה לכשל הדף. אפשרות ב' שגויה מכיוון שה-MMU הוא רכיב חומרה המטפל בתרגום כתובות ל-RAM ואינו מבצע פעולות קלט/פלט ישירות לדיסק. אפשרות ג' שגויה מכיוון שגישה זו אינה \"בלתי חוקית\"; היא כתובת וירטואלית לגיטימית שהתהליך רשאי לגשת אליה, אך היא פשוט אינה זמינה כרגע ב-RAM. אפשרות ד' שגויה מכיוון שמרחב הכתובות הוירטואלי של התהליך הוא קבוע, והבעיה אינה יצירת מרחב חדש אלא מיפוי דפים קיימים לזיכרון הפיזי."}, "_source_file": "0089__Virtualization__Virtual_Memory__MC__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:14:01", "_subject": "Virtualization", "_context_lectures": [6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Virtual Memory"], "difficulty_estimation": "Hard", "content": {"text": "בהינתן שתהליכים מרובים פועלים בו-זמנית, וכל אחד מהם רואה מרחב זיכרון וירטואלי של 4GB, בעוד שהזיכרון הפיזי הכולל במערכת מוגבל בהרבה, מהו התפקיד התיאורטי המהותי של טבלת הדפים (Page Table) הייעודית לכל תהליך, מעבר לתרגום כתובות גרידא, המאפשר למערכת ההפעלה לקיים אשליה זו ולנהל את משאבי הזיכרון ביעילות?", "code_snippet": null, "options": ["א. טבלת הדפים מספקת מיפוי גמיש בין דפים וירטואליים שאינם בהכרח רציפים לבין מסגרות פיזיות שאינן בהכרח רציפות (או למיקומי דיסק), ובכך מאפשרת למערכת ההפעלה לנהל פיצול זיכרון וניצול יתר, ולשמר את אשליית מרחב כתובות גדול, ייעודי ורציף לכל תהליך.", "ב. טבלת הדפים אוכפת הגנת זיכרון בכך שהיא מבטיחה שכל תהליך יוכל לגשת רק למרחב הווירטואלי שלו בגודל 4GB.", "ג. טבלת הדפים משרתת בעיקר אופטימיזציה של מהירות גישה לזיכרון על ידי שמירת תרגומי כתובות וירטואליות-לפיזיות ב-MMU.", "ד. טבלת הדפים מבטלת את הצורך בזיכרון פיזי על ידי מיפוי כל הכתובות הווירטואליות ישירות לדיסק הקשיח."]}, "solution": {"correct_option": "א", "explanation": "האפשרות הנכונה היא א'. החומר המצויין בשיעור מדגיש כי זיכרון וירטואלי הוא אשליה (\"זיכרון שלא באמת קיים\") שבה כל תהליך חושב שיש לו 4GB, בעוד שהזיכרון הפיזי מוגבל. מערכת ההפעלה מנהלת זאת באמצעות \"מיפויים\" (Lecture 6, chunk 10). זיכרון וירטואלי מחולק ל\"דפים\" וזיכרון פיזי ל\"מסגרות\" (Lecture 6, chunk 26). טבלת הדפים, הייעודית לכל תהליך, היא מבנה הנתונים השומר את המיפויים הללו (Lecture 6, chunk 28). תפקידה המהותי הוא לאפשר מיפוי גמיש של דפים וירטואליים למסגרות פיזיות שאינן חייבות להיות רציפות, או אפילו לדיסק הקשיח (\"חלק מהזיכרון של התהליכים מופנה להארד-דיסק\", \"יכול גם להיות שתהליך בכלל לא יהיה בשום מקום\") (Lecture 6, chunk 10), ובכך לטפל בפיצול זיכרון ולאפשר ניצול יתר (oversubscription) של הזיכרון הפיזי. זהו המנגנון המרכזי המאפשר את אשליית מרחב הכתובות הגדול, הייעודי והרציף לכל תהליך.\n\nאפשרות ב' אינה התפקיד התיאורטי המהותי ביותר בהקשר לשאלה. הגנת זיכרון היא תוצאה חשובה של מנגנון הזיכרון הווירטואלי וה-MMU (Lecture 6, chunk 14), אך המיפוי הגמיש הוא זה שמאפשר מלכתחילה את האשליה של 4GB לכל תהליך על זיכרון פיזי מוגבל.\n\nאפשרות ג' מתארת למעשה את תפקידו של ה-TLB (Translation Lookaside Buffer), שהוא מטמון בתוך ה-MMU, ולא את התפקיד העיקרי של טבלת הדפים עצמה בהקשר של יצירת האשליה וניהול משאבים.\n\nאפשרות ד' שגויה לחלוטין. החומר מציין ש\"חלק מהזיכרון של התהליכים מופנה להארד-דיסק\" (Lecture 6, chunk 10), לא כולו, וכי ה-RAM הפיזי עדיין קיים ומשמש (Lecture 6, chunk 28). הדיסק הקשיח משמש כהרחבה או אזור החלפה (swap space), לא כתחליף מלא לזיכרון הפיזי."}, "_source_file": "0090__Virtualization__Virtual_Memory__MC__Hard.json", "_topic_hint": "Virtual Memory", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:14:22", "_subject": "Virtualization", "_context_lectures": [6]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Paging"], "difficulty_estimation": "Easy", "content": {"text": "מהו תפקידו העיקרי של ה-MMU (Memory Management Unit) בתהליך הדפדוף?", "code_snippet": null, "options": ["א. תרגום כתובת וירטואלית לכתובת פיזית.", "ב. קביעת גודל הדף בזיכרון הווירטואלי.", "ג. ניהול מזהי התהליכים (PIDs) במערכת ההפעלה.", "ד. שמירת קוד התהליכים בזיכרון הפיזי."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, ה-MMU הוא הרכיב העיקרי שעוזר בתהליך התרגום מכתובת וירטואלית לכתובת פיזית. הוא לוקח כתובת וירטואלית (המחולקת למספר דף והיסט), משתמש במספר הדף כדי למצוא את מספר המסגרת המתאים בטבלת הדפים, ומשלב אותו עם ההיסט ליצירת הכתובת הפיזית. שאר האפשרויות אינן מתארות את תפקידו העיקרי של ה-MMU."}, "_source_file": "0091__Virtualization__Paging__MC__Easy.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:14:30", "_subject": "Virtualization", "_context_lectures": [4, 5, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Paging"], "difficulty_estimation": "Easy", "content": {"text": "על פי חומר ההרצאה, מהו תפקידו העיקרי של רכיב ה-MMU בתהליך הדפדוף?", "code_snippet": null, "options": ["א. תרגום כתובות וירטואליות לכתובות פיזיות.", "ב. קביעת מספר הביטים לכתובת וירטואלית.", "ג. אחסון טבלת הדפים של כל תהליך בזיכרון.", "ד. פיצול טבלת הדפים לחלקים בגודל דף."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, ה-MMU הוא הרכיב העיקרי המסייע בתהליך תרגום הכתובות. ההרצאה מציינת במפורש: 'הרכיב שעוזר לנו בתהליך התרגום הוא ה-MMU שמתבצע המרה מכתובת וירטואלית לכתובת פיזית שבה הנתונים הרצויים נמצאים.' תפקידו של ה-MMU הוא לקחת את מספר הדף הווירטואלי, לפנות איתו לטבלת הדפים ולקבל ממנה את מספר המסגרת המתאים (PFN), ובכך להשלים את הכתובת הפיזית יחד עם ההיסט."}, "_source_file": "0092__Virtualization__Paging__MC__Easy.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:14:41", "_subject": "Virtualization", "_context_lectures": [4, 5, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Paging"], "difficulty_estimation": "Easy", "content": {"text": "מהו התפקיד העיקרי של יחידת ניהול הזיכרון (MMU) בתהליך הדפדוף?", "code_snippet": null, "options": ["א. לבצע המרה מכתובת וירטואלית לכתובת פיזית.", "ב. לנהל את מזהי התהליכים (PIDs) במערכת.", "ג. לאחסן את טבלת הדפים של התהליך בזיכרון.", "ד. לקבוע את גודל מרחב הכתובות הוירטואלי של תהליך."]}, "solution": {"correct_option": "א", "explanation": "ההסבר הנכון הוא שאחד מתפקידיו העיקריים של ה-MMU (Memory Management Unit) הוא לתרגם כתובות וירטואליות לכתובות פיזיות. כפי שמצוין בחומר ההרצאה, \"הרכיב שעוזר לנו בתהליך התרגום הוא ה-**mmu** שמתבצע המרה מכתובת וירטואלית לכתובת פיזית שבה הנתונים הרצויים נמצאים.\" ה-MMU משתמש בטבלת הדפים של התהליך כדי למצוא את המסגרת הפיזית המתאימה לדף הוירטואלי, אך תפקידו המרכזי הוא ביצוע התרגום עצמו."}, "_source_file": "0093__Virtualization__Paging__MC__Easy.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:14:51", "_subject": "Virtualization", "_context_lectures": [4, 5, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Paging"], "difficulty_estimation": "Medium", "content": {"text": "מהו התפקיד העיקרי של יחידת ניהול הזיכרון (MMU) בתהליך תרגום כתובת וירטואלית לכתובת פיזית, על בסיס טבלת הדפים של תהליך?", "code_snippet": null, "options": ["א. ה-MMU מפרק את הכתובת הוירטואלית למספר דף וירטואלי (VPN) ולהיסט. את ההיסט הוא מעביר כפי שהוא, ואת ה-VPN הוא מנצל כדי לאתר בטבלת הדפים את מספר המסגרת הפיזית (PFN) המתאימה.", "ב. ה-MMU משתמש בכתובת הוירטואלית כולה כדי לחשב ישירות את הכתובת הפיזית, ללא צורך בטבלת דפים.", "ג. ה-MMU משתמש בהיסט כדי למצוא את מספר הדף הוירטואלי, ורק לאחר מכן פונה לטבלת הדפים כדי לקבל את הכתובת הפיזית המלאה.", "ד. ה-MMU אחראי רק על הקצאת דפים חדשים לזיכרון הפיזי, ואינו מעורב בתהליך תרגום כתובות קיים."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה, ה-MMU הוא הרכיב שמבצע את ההמרה מכתובת וירטואלית לכתובת פיזית. הוא עושה זאת על ידי פירוק הכתובת הוירטואלית לשני חלקים: מספר הדף הוירטואלי (VPN) וההיסט (Offset). ההיסט נשאר ללא שינוי (מתורגם כמו שהוא), בעוד שמספר הדף הוירטואלי משמש כאינדקס לטבלת הדפים של התהליך. מטבלת הדפים, ה-MMU מאחזר את רשומת הדף (PTE) המתאימה, ומתוכה הוא משיג את מספר המסגרת הפיזית (PFN). שילוב ה-PFN עם ההיסט יוצר את הכתובת הפיזית הסופית. האפשרויות האחרות אינן מתארות נכונה את מנגנון התרגום כפי שתואר בחומר."}, "_source_file": "0094__Virtualization__Paging__MC__Medium.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:15:04", "_subject": "Virtualization", "_context_lectures": [4, 5, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Paging"], "difficulty_estimation": "Medium", "content": {"text": "מהו התפקיד המרכזי של ה-MMU (Memory Management Unit) בתהליך תרגום כתובת וירטואלית לכתובת פיזית במערכת הפעלה המשתמשת בדפדוף (paging)?", "code_snippet": null, "options": ["א. ה-MMU מפרק את הכתובת הוירטואלית למספר דף וירטואלי (VPN) ולהיסט, ומשתמש במספר הדף הוירטואלי כדי לאתר בטבלת הדפים את מספר המסגרת הפיזית (PFN), תוך השארת ההיסט ללא שינוי.", "ב. ה-MMU משתמש בכתובת הוירטואלית כולה כדי לחפש ישירות בזיכרון הפיזי ללא צורך בטבלת דפים.", "ג. ה-MMU אחראי על הקצאת זיכרון וירטואלי לתהליכים חדשים ועל ניהול ה-PID שלהם בלבד.", "ד. ה-MMU משנה הן את מספר הדף הוירטואלי והן את ההיסט על מנת ליצור כתובת פיזית חדשה לחלוטין."]}, "solution": {"correct_option": "א", "explanation": "ההסבר הנכון הוא א'. על פי חומר ההרצאה, ה-MMU הוא הרכיב שמבצע את ההמרה מכתובת וירטואלית לכתובת פיזית. הוא עושה זאת על ידי פירוק הכתובת הוירטואלית לשני חלקים: מספר הדף הוירטואלי (VPN) וההיסט (Offset). ההיסט נשאר ללא שינוי בתהליך התרגום (\"ההיסט מתורגם כמו שהוא\"), בעוד שמספר הדף הוירטואלי משמש כאינדקס לטבלת הדפים של התהליך. מטבלת הדפים, ה-MMU משיג את מספר המסגרת הפיזית (PFN) המתאים לדף הוירטואלי. ה-PFN יחד עם ההיסט הבלתי משונה יוצרים יחד את הכתובת הפיזית הסופית בזיכרון."}, "_source_file": "0095__Virtualization__Paging__MC__Medium.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:15:15", "_subject": "Virtualization", "_context_lectures": [4, 5, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Paging"], "difficulty_estimation": "Medium", "content": {"text": "איזה מהתיאורים הבאים מתאר בצורה המדויקת ביותר את תפקיד ה-MMU בתהליך תרגום כתובת וירטואלית לכתובת פיזית במערכת הפעלה המשתמשת בדפדוף (paging)?", "code_snippet": null, "options": ["א. ה-MMU מחלק את הכתובת הווירטואלית למספר דף וירטואלי (VPN) ולהיסט. ההיסט נשאר ללא שינוי ומשמש כהיסט בכתובת הפיזית, בעוד שמספר הדף הווירטואלי משמש לאיתור רשומת טבלת הדפים (PTE) המתאימה, ממנה מופק מספר המסגרת הפיזית (PFN) ליצירת הכתובת הפיזית הסופית.", "ב. ה-MMU משתמש בכתובת הווירטואלית כולה כאינדקס לטבלת דפים אחת גדולה, אשר מכילה מיפוי ישיר מכל כתובת וירטואלית ספציפית לכתובת פיזית מקבילה.", "ג. ה-MMU אחראי רק על שמירת טבלת הדפים בזיכרון, בעוד שתרגום הכתובות בפועל מבוצע על ידי המעבד באמצעות חישוב מתמטי המבוסס על גודל הדף.", "ד. ה-MMU מחלק את הכתובת הווירטואלית למספר דף וירטואלי ולהיסט, ולאחר מכן מחליף את שניהם במספר מסגרת פיזית חדש המתקבל מטבלת הדפים."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. לפי חומר ההרצאה, ה-MMU הוא הרכיב שמבצע את ההמרה מכתובת וירטואלית לכתובת פיזית. הוא עושה זאת על ידי חלוקת הכתובת הווירטואלית לשני חלקים: מספר דף וירטואלי (VPN) והיסט (offset). ההיסט מתורגם 'כמו שהוא' (כלומר נשאר זהה בכתובת הפיזית) ומשולב עם מספר המסגרת הפיזית. מספר הדף הווירטואלי (VPN) משמש את ה-MMU לפנות לטבלת הדפים של התהליך. מטבלת הדפים, ברשומת הדף המתאימה (PTE), מופק מספר המסגרת הפיזית (PFN). לבסוף, ה-PFN משולב עם ההיסט כדי ליצור את הכתובת הפיזית המלאה. אפשרויות ב', ג' ו-ד' מתארות תהליכים שגויים או תפקידים שאינם של ה-MMU כפי שתוארו בחומר ההרצאה."}, "_source_file": "0096__Virtualization__Paging__MC__Medium.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:15:28", "_subject": "Virtualization", "_context_lectures": [4, 5, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Paging"], "difficulty_estimation": "Hard", "content": {"text": "מדוע טבלת דפים ליניארית (Linear Page Table) נחשבת לפתרון לא מעשי במערכות הפעלה מודרניות, גם כאשר תהליכים רבים מנצלים רק חלק קטן ממרחב הכתובות הוירטואלי העצום שלהם?", "code_snippet": null, "options": ["א. ה-MMU אינו יכול לאנדקס ביעילות טבלת דפים ליניארית גדולה בשל מגבלות חומרה בתהליך התרגום עצמו.", "ב. עלות ההחלפה בין הקשרים (Context Switching) בין תהליכים הופכת לגבוהה מדי, מכיוון שנדרש לטעון מחדש טבלאות דפים ענקיות.", "ג. טבלת דפים ליניארית דורשת הקצאת בלוק זיכרון פיזי רציף גדול עבור טבלת הדפים של כל תהליך, ללא קשר לניצול הזיכרון הוירטואלי בפועל, מה שמוביל לבזבוז משמעותי של זיכרון פיזי.", "ד. רשומות טבלת הדפים (PTEs) עצמן צורכות כוח עיבוד רב מדי מהמעבד במהלך תרגום הכתובות עקב מורכבותן."]}, "solution": {"correct_option": "ג", "explanation": "הבעיה המרכזית בטבלת דפים ליניארית, כפי שנדון בחומר השיעור, היא גודלה. במערכת 32 ביט, מרחב הכתובות הוירטואלי הוא 4GB. אם גודל הדף הוא, לדוגמה, 4KB (2^12 בתים), אזי קיימים 2^20 דפים וירטואליים. אם כל רשומת טבלת דפים (PTE) דורשת, נניח, 4 בתים, אזי טבלת דפים ליניארית מלאה תתפוס 2^20 * 4 בתים = 4MB של זיכרון פיזי. זיכרון זה, בסך 4MB, חייב להיות מוקצה עבור טבלת הדפים של *כל* תהליך, ללא קשר לשאלה האם התהליך מנצל בפועל את כל 4GB ממרחב הכתובות הוירטואלי שלו. רוב התהליכים מנצלים רק חלק קטן מהזיכרון הוירטואלי הפוטנציאלי שלהם. לכן, טבלת דפים ליניארית תוביל לבזבוז עצום של זיכרון פיזי לצורך אחסון טבלאות דפים שרובן ריקות (מכילות רשומות לא תקפות עבור דפים וירטואליים שאינם בשימוש). זו הסיבה שההרצאה מציינת שהיא 'לא בשימוש'."}, "_source_file": "0097__Virtualization__Paging__MC__Hard.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:15:43", "_subject": "Virtualization", "_context_lectures": [4, 5, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Paging"], "difficulty_estimation": "Hard", "content": {"text": "למרות שטבלת דפים ליניארית נחשבת לגרסה בסיסית ונוחה, מדוע היא אינה נמצאת בשימוש במערכות הפעלה סטנדרטיות כיום, כפי שמרמז חומר ההרצאה?", "code_snippet": null, "options": ["א. צריכת זיכרון גבוהה מדי לאחסון טבלת הדפים עצמה, במיוחד במרחבי כתובות וירטואליים גדולים.", "ב. מורכבות יתרה ביישום רכיב ה-MMU לתרגום כתובות באמצעותה.", "ג. חוסר יכולת לתמוך בריבוי תהליכים בעלי טבלאות דפים נפרדות.", "ד. קושי בטיפול בהיסט כתובת (offset) בתוך הדף."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מציין שטבלת דפים ליניארית \"אינה בשימוש\" מיד לפני שהוא מתחיל לדון בחישוב כמות הזיכרון שטבלה כזו תופסת במערכת סטנדרטית של 32 ביט עם מרחב כתובות וירטואלי של 4GB. הקישור בין שתי האמירות הללו מרמז שהסיבה העיקרית לאי-השימוש בטבלאות דפים ליניאריות היא צריכת זיכרון גבוהה מדי עבור אחסון טבלת הדפים עצמה, במיוחד כאשר מרחב הכתובות הוירטואלי גדול (כמו 4GB במערכת 32 ביט). האפשרויות האחרות אינן נתמכות בחומר ההרצאה: ה-MMU מתואר כמנגנון פשוט יחסית לתרגום כתובות, החומר מציין שלכל תהליך יש טבלת דפים משלו, וההיסט מתורגם ישירות ללא שינוי."}, "_source_file": "0098__Virtualization__Paging__MC__Hard.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:15:59", "_subject": "Virtualization", "_context_lectures": [4, 5, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Paging"], "difficulty_estimation": "Hard", "content": {"text": "במערכת הפעלה 32 ביט, המשתמשת במרחב כתובות וירטואלי של 4GB, נניח שגודל דף הוא 4KB. בהתחשב בכך שכל רשומת טבלת דפים (PTE) דורשת 4 בתים לאחסון, מהו גודלה הכולל של טבלת דפים ליניארית עבור תהליך בודד?", "code_snippet": null, "options": ["א. 1MB", "ב. 4MB", "ג. 16MB", "ד. 256MB"]}, "solution": {"correct_option": "ב", "explanation": "התשובה הנכונה היא ב'.\nכדי לחשב את גודלה הכולל של טבלת דפים ליניארית, עלינו לדעת כמה דפים וירטואליים קיימים ומה גודל כל רשומת טבלת דפים (PTE).\n\n1.  **חישוב מספר הדפים הוירטואליים:**\n    *   מרחב הכתובות הוירטואלי הכולל הוא 4GB, שזה 2^32 בתים (כפי שצוין בחומר הלימוד: \"מחשב 32 ביט- זה אומר שמרחב הכתובות שלו הוא 32 ביטים כלומר כל כתובת וירטואלית היא 32 ביטים, כלומר 4GB\").\n    *   גודל דף הוא 4KB, שזה 2^12 בתים.\n    *   מספר הדפים הוירטואליים = מרחב כתובות כולל / גודל דף = 2^32 בתים / 2^12 בתים = 2^(32-12) = 2^20 דפים.\n    *   (חומר הלימוד מציין ש\"לאיזה מספר דף הוא ניגש... כמות הביטים שיש בכתובת הוירטואלית תלויה במרחב הכתובות של התהליך\" ו\"ההיסט תלוי בגודל הדף – מספר הביטים לייצוג ההיסט הוא לוג 2 של גודל הדף\", מה שמאפשר לחשב את מספר הדפים הווירטואליים על ידי חלוקת מרחב הכתובות הכולל בגודל הדף).\n\n2.  **חישוב גודל טבלת הדפים:**\n    *   גודל כל רשומת טבלת דפים (PTE) נתון כ-4 בתים.\n    *   גודל טבלת הדפים הליניארית הכולל = מספר הדפים הוירטואליים * גודל כל רשומת PTE = 2^20 דפים * 4 בתים/לרשומה = 2^20 * 2^2 בתים = 2^22 בתים.\n    *   2^22 בתים שווה ל-4 מגה-בתים (4MB), שכן 2^20 בתים הם 1MB.\n    *   (חומר הלימוד מזכיר ש\"טבלת דפים ליניארית... יש בה את כל הרשומות ששייכות לתהליך כלשהו והן יושבות ברצף\" ו\"אם נחשב כמה זיכרון תופסת טבלת דפים ליניארית כזו (גם טבלת הדפים צריכה מקום בו היא תאוחסן)\").\n\nלכן, גודלה הכולל של טבלת דפים ליניארית עבור תהליך בודד במקרה זה הוא 4MB."}, "_source_file": "0099__Virtualization__Paging__MC__Hard.json", "_topic_hint": "Paging", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:16:20", "_subject": "Virtualization", "_context_lectures": [4, 5, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Page Tables"], "difficulty_estimation": "Easy", "content": {"text": "מהי הסיבה העיקרית לשימוש בטבלת דפים רב-שכבתית (Multi-Level Page Table) במערכות הפעלה?", "code_snippet": null, "options": ["א. לחסוך בזיכרון פיזי על ידי אי הקצאת רשומות עבור חלקי מרחב כתובות וירטואליים שאינם בשימוש.", "ב. להאיץ את תהליך תרגום הכתובות הוירטואליות לכתובות פיזיות.", "ג. לאפשר שימוש במרחב כתובות וירטואלי גדול יותר ממה שמתאפשר עם טבלת דפים שטוחה.", "ד. לפשט את עבודת יחידת ניהול הזיכרון (MMU)."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מציין כי 'רוב התהליכים לא משתמשים בכל הזיכרון של מרחב הכתובות שלהם' וכי הרעיון הוא 'נציא את כל השטח האפור, נצמצם אותו לפחות רשומות'. כמו כן, נכתב במפורש 'Entire page of entries invalid? Don't allocate it'. כל אלה מצביעים על כך שהמטרה העיקרית של טבלת דפים רב-שכבתית היא לחסוך בזיכרון פיזי על ידי אי-הקצאה של טבלאות דפים שלמות עבור חלקי מרחב כתובות וירטואליים שאינם בשימוש. אפשרות ב' אינה נכונה, מכיוון שטבלאות רב-שכבתיות לרוב מוסיפות צעדי גישה לזיכרון ובכך מאטות את התרגום. אפשרות ג' אינה הסיבה העיקרית, למרות שהיא מאפשרת ניהול יעיל יותר של מרחבי כתובות גדולים. אפשרות ד' אינה נכונה, שכן ה-MMU הופך להיות היררכי ומורכב יותר, כפי שמצוין בטקסט: 'ה-mmu שלנו נהיה היררכי'."}, "_source_file": "0100__Virtualization__Page_Tables__MC__Easy.json", "_topic_hint": "Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:16:31", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Page Tables"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של שימוש בטבלת דפים היררכית (Multi-Level Page Table) במערכות הפעלה?", "code_snippet": null, "options": ["א. לחסוך בזיכרון פיזי על ידי אי-הקצאת טבלאות דפים עבור חלקים לא בשימוש במרחב הכתובות הוירטואלי.", "ב. להגדיל את מהירות הגישה לזיכרון על ידי צמצום מספר הגישות לטבלת הדפים.", "ג. לאפשר לתהליכים לגשת לזיכרון פיזי גדול יותר ממה שזמין במערכת.", "ד. לפשט את תהליך תרגום הכתובות עבור יחידת ניהול הזיכרון (MMU)."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מציין כי רוב טבלת הדפים אינה בשימוש עבור תהליכים רבים, וכי רעיון טבלת דפים היררכית (Multi-Level Page Table) הוא 'לצמצם אותו לפחות רשומות' ו'אם דף שלם של רשומות אינו חוקי? אל תקצה אותו'. המטרה העיקרית היא לחסוך בזיכרון פיזי על ידי כך שהמערכת לא מקצה מקום בזיכרון לטבלאות דפים עבור אזורים במרחב הכתובות הוירטואלי של התהליך שאינם בשימוש. אפשרויות ב' ו-ד' אינן נכונות מכיוון שטבלאות דפים היררכיות דווקא מגדילות את מספר הגישות לזיכרון לצורך תרגום כתובות ומסבכות את תהליך התרגום עבור ה-MMU. אפשרות ג' מתארת את הרעיון הכללי של זיכרון וירטואלי, אך לא את היתרון הספציפי של טבלת דפים היררכית."}, "_source_file": "0101__Virtualization__Page_Tables__MC__Easy.json", "_topic_hint": "Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:16:41", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Page Tables"], "difficulty_estimation": "Easy", "content": {"text": "מהי הסיבה העיקרית לשימוש בטבלת דפים רב-שכבתית (Multi-Level Page Table) במערכות הפעלה?", "code_snippet": null, "options": ["א. כדי לחסוך בזיכרון פיזי המשמש לאחסון טבלת הדפים עצמה.", "ב. כדי להאיץ את תהליך תרגום הכתובות הוירטואליות לכתובות פיזיות.", "ג. כדי לאפשר לתהליכים לגשת ליותר זיכרון וירטואלי ממה שקיים בזיכרון הפיזי.", "ד. כדי לפשט את המימוש של החלפת הקשר (Context Switching) בין תהליכים."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין בשיעור מדגיש כי רוב התהליכים אינם משתמשים בכל מרחב הכתובות הוירטואלי שלהם, מה שמוביל לכך שחלקים נרחבים מטבלת הדפים אינם בשימוש (ה'שטח האפור'). הרעיון של טבלת דפים רב-שכבתית (Multi-Level Page Table) נועד לטפל בבעיה זו על ידי צמצום מספר הרשומות והימנעות מהקצאת זיכרון פיזי לחלקי טבלת דפים שאינם רלוונטיים או אינם בשימוש. על ידי פיצול טבלת הדפים ליחידות בגודל דף ומעקב אחריהן באמצעות 'page directory', ניתן להימנע מהקצאת דף שלם של רשומות אם הוא אינו חוקי או אינו בשימוש, ובכך לחסוך משמעותית בזיכרון הפיזי שנדרש לטבלת הדפים עצמה."}, "_source_file": "0102__Virtualization__Page_Tables__MC__Easy.json", "_topic_hint": "Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:16:50", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Page Tables"], "difficulty_estimation": "Medium", "content": {"text": "מהו היתרון המרכזי של שימוש בטבלת דפים רב-שכבתית (Multi-Level Page Table) בהשוואה לטבלת דפים חד-שכבתית?", "code_snippet": null, "options": ["א. הפחתה משמעותית של כמות הזיכרון הפיזי הנדרשת לאחסון טבלאות הדפים, במיוחד עבור תהליכים שאינם מנצלים את כל מרחב הכתובות הוירטואלי שלהם.", "ב. האצת תהליך תרגום הכתובות הוירטואליות לכתובות פיזיות על ידי ה-MMU.", "ג. פישוט מנגנון ניהול הזיכרון במערכת ההפעלה.", "ד. הגדלה של כמות הדפים הפיזיים (physical frames) הזמינים במערכת."]}, "solution": {"correct_option": "א", "explanation": "טבלת דפים חד-שכבתית דורשת הקצאת רשומות לכל מרחב הכתובות הוירטואלי של תהליך, גם אם חלקים גדולים ממנו אינם בשימוש (השטחים ה'אפורים' המוזכרים בחומר הלימוד). הדבר מוביל לבזבוז משמעותי של זיכרון פיזי. טבלת דפים רב-שכבתית, המאורגנת במבנה דמוי עץ וכוללת Page Directory, מאפשרת למערכת ההפעלה לא להקצות דפים שלמים של רשומות טבלאות דפים עבור אזורים לא מנוצלים במרחב הכתובות הוירטואלי. כפי שנאמר בחומר: 'אם דף שלם של רשומות אינו חוקי, אין צורך להקצות אותו'. יתרון זה מוביל לחיסכון ניכר בזיכרון הפיזי הנדרש לניהול טבלאות הדפים. אפשרות ב' אינה נכונה מכיוון שטבלת דפים רב-שכבתית בדרך כלל דורשת יותר גישות לזיכרון (עבור ה-Page Directory ולאחר מכן עבור ה-Page Table עצמו), מה שעלול להאט את תהליך התרגום. אפשרויות ג' ו-ד' אינן נכונות מכיוון שהן אינן היתרון המרכזי או שהן שגויות במהותן."}, "_source_file": "0103__Virtualization__Page_Tables__MC__Medium.json", "_topic_hint": "Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:17:06", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Page Tables"], "difficulty_estimation": "Medium", "content": {"text": "מהו היתרון העיקרי של שימוש בטבלת דפים היררכית (Multi-Level Page Table) בהשוואה לטבלת דפים ברמה אחת?", "code_snippet": null, "options": ["א. הקטנת צריכת הזיכרון הפיזי הנדרש לאחסון טבלאות הדפים, על ידי אי הקצאת רשומות לאזורים לא מנוצלים במרחב הכתובות הוירטואלי.", "ב. פישוט לוגיקת תרגום הכתובות של יחידת ניהול הזיכרון (MMU).", "ג. שיפור קצב הפגיעות (hit rate) במטמון ה-TLB.", "ד. אפשרות לניהול מרחבי כתובות וירטואליים גדולים יותר באופן ישיר ויעיל."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין בשיעור מדגיש כי רוב התהליכים אינם מנצלים את כל מרחב הכתובות הוירטואלי שלהם, מה שמוביל לשטחים 'אפורים' (דפים לא בשימוש) בטבלת הדפים. הרעיון המרכזי מאחורי טבלת דפים היררכית (Multi-Level Page Table) הוא 'להוציא את כל השטח האפור, לצמצם אותו לפחות רשומות' ו'אם דף שלם של רשומות אינו חוקי, אל תקצה אותו'. בכך, היתרון העיקרי הוא חיסכון משמעותי בזיכרון הפיזי הנדרש לאחסון טבלאות הדפים, על ידי כך שלא מקצים זיכרון לחלקי טבלת דפים המכסים אזורים לא מנוצלים במרחב הכתובות הוירטואלי."}, "_source_file": "0104__Virtualization__Page_Tables__MC__Medium.json", "_topic_hint": "Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:17:19", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Page Tables"], "difficulty_estimation": "Medium", "content": {"text": "מהי הסיבה העיקרית לשימוש בטבלת דפים היררכית (Multi-Level Page Table) במערכות הפעלה מודרניות?", "code_snippet": null, "options": ["א. כדי להפחית את מספר הגישות לזיכרון הפיזי במהלך תרגום כתובות.", "ב. כדי לאפשר שימוש בדפים בגדלים שונים עבור אזורים שונים במרחב הכתובות הוירטואלי.", "ג. כדי לחסוך בזיכרון פיזי על ידי אי-הקצאת טבלאות דפים שלמות (או חלקים מהן) עבור אזורים ריקים או לא מנוצלים במרחב הכתובות הוירטואלי של התהליך.", "ד. כדי להגביל את גודל מרחב הכתובות הוירטואלי שכל תהליך יכול להשתמש בו."]}, "solution": {"correct_option": "ג", "explanation": "ההסבר: טבלאות דפים היררכיות (Multi-Level Page Tables) נועדו לטפל בבעיה שבה רוב מרחב הכתובות הוירטואלי של תהליך אינו בשימוש, כפי שצוין בחומר הלימוד: \"רוב התהליכים לא משתמשים בכל הזיכרון של מרחב הכתובות שלהם. רעיון: נציא את כל השטח האפור, נצמצם אותו לפחות רשומות\". במקום להקצות רשומות טבלה לכל כתובת וירטואלית אפשרית (גם אם אינה בשימוש), המבנה ההיררכי מאפשר ל-Page Directory להצביע רק לחלקי טבלת הדפים הרלוונטיים. אם אזור שלם במרחב הכתובות הוירטואלי אינו בשימוש (כלומר, \"Entire page of entries invalid?\"), אין צורך להקצות את טבלת הדפים המלאה עבורו בזיכרון הפיזי (\"Don't allocate it\"), ובכך נחסך זיכרון רב."}, "_source_file": "0105__Virtualization__Page_Tables__MC__Medium.json", "_topic_hint": "Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:17:30", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Page Tables"], "difficulty_estimation": "Hard", "content": {"text": "על פי החומר הנלמד, מהי ההשלכה המרכזית והמורכבת ביותר של מעבר מטבלת דפים ברמה אחת (Single-Level Page Table) למבנה טבלת דפים רב-שכבתית (Multi-Level Page Table), בהתחשב הן בניהול הזיכרון והן בתהליך תרגום הכתובות?", "code_snippet": null, "options": ["א. חיסכון משמעותי בזיכרון פיזי עבור מרחבי כתובות דלילים (sparse), אך עלייה במספר הגישות לזיכרון הפיזי הדרושות לתרגום כל כתובת וירטואלית לכתובת פיזית.", "ב. הגדלה קבועה של צריכת הזיכרון הפיזי עבור טבלאות הדפים, תוך הפחתה במספר הגישות לזיכרון הפיזי הנדרשות לתרגום כתובות.", "ג. אין שינוי מהותי בצריכת הזיכרון הפיזי, אך שיפור משמעותי במהירות תרגום הכתובות בשל מבנה הנתונים דמוי העץ.", "ד. פישוט תהליך תרגום הכתובות ב-MMU והפחתת זמן השהיה, תוך שמירה על רמת זיכרון פיזי דומה לטבלה ברמה אחת."]}, "solution": {"correct_option": "א", "explanation": "החומר המציין כי \"רוב התהליכים לא משתמשים בכל הזיכרון של מרחב הכתובות שלהם\" וכי הרעיון הוא \"נציא את כל השטח האפור, נצמצם אותו לפחות רשומות\" וכן \"Entire page of entries invalid? Don't allocate it\" מדגיש את החיסכון בזיכרון פיזי עבור מרחבי כתובות דלילים (sparse address spaces) על ידי אי-הקצאה של דפים לא בשימוש בטבלת הדפים. יחד עם זאת, ההסבר על ה-MMU שנהיה היררכי (\"לוקח מספר מסוים לרמה הראשונה, מספר אחר לרמה השנייה וכן הלאה\") ועל הצורך לגשת לזיכרון כדי למצוא את הדף הספציפי, מצביע בבירור על כך שתרגום כתובת וירטואלית לכתובת פיזית דורש כעת מספר גישות לזיכרון הפיזי (לדוגמה, גישה לספריית הדפים ואז לטבלת הדפים עצמה), מה שמגדיל את זמן השהיה (latency). לכן, אופציה א' מתארת נכונה את הטרייד-אוף המרכזי של מבנה טבלת דפים רב-שכבתית."}, "_source_file": "0106__Virtualization__Page_Tables__MC__Hard.json", "_topic_hint": "Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:17:46", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Page Tables"], "difficulty_estimation": "Hard", "content": {"text": "בהקשר של טבלאות דפים היררכיות (Multi-Level Page Tables), חומר ההרצאה מציין שגם לאחר הפיכת טבלת הדפים למבנה עץ ושימוש ב-Page Directory, ה-Page Directory עצמו עלול להיות 'עצום' ולתפוס שטח זיכרון רב (למשל, 128 דפים). איזו אסטרטגיה מוצעת בחומר ההרצאה כדי להמשיך ולצמצם את צריכת הזיכרון עבור מבנה טבלת הדפים במקרה זה?", "code_snippet": null, "options": ["א. הקטנת גודל הדף הפיזי (page size) כדי לאפשר יותר דפים בזיכרון הפיזי.", "ב. הוספת רמה היררכית נוספת למבנה טבלת הדפים, כלומר יצירת 'מדריך למדריך' (directory to the directory).", "ג. שימוש בטבלאות דפים הפוכות (Inverted Page Tables) במקום טבלאות דפים היררכיות.", "ד. אחסון כל ה-Page Directory בזיכרון מטמון (cache) ייעודי ב-MMU."]}, "solution": {"correct_option": "ב", "explanation": "חומר ההרצאה מציין בפירוש כי למרות שטבלאות דפים היררכיות נועדו לצמצם את שטח הזיכרון הלא מנוצל על ידי אי-הקצאת דפים אפורים, ה-Page Directory עצמו יכול לתפוס שטח רב ('עצום', 'תופס 128 דפים'). כדי לטפל בבעיה זו, מוצעת האפשרות 'Can add a directory to the directory!', כלומר, הוספת רמה היררכית נוספת. גישה זו מאפשרת לצמצם עוד יותר את ההקצאה על ידי אי-הקצאה של חלקים ב-Page Directory עצמו, בדומה לאופן שבו ה-Page Directory המקורי אינו מקצה טבלאות דפים שלמות שאינן בשימוש. אפשרויות אחרות אינן מוזכרות כפתרון לבעיה ספציפית זו בחומר ההרצאה, או שהן אינן פתרון מבני לגודל ה-Page Directory."}, "_source_file": "0108__Virtualization__Page_Tables__MC__Hard.json", "_topic_hint": "Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:18:15", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Multi-level Page Tables"], "difficulty_estimation": "Easy", "content": {"text": "מהו היתרון המרכזי בשימוש בטבלאות דפים היררכיות (Multi-Level Page Tables) בהשוואה לטבלת דפים ברמה אחת?", "code_snippet": null, "options": ["א. חיסכון משמעותי בזיכרון פיזי על ידי אי-הקצאת רשומות טבלה עבור חלקי מרחב הכתובות הוירטואלי שאינם בשימוש.", "ב. האצת זמן הגישה לזיכרון הפיזי עבור כל תרגום כתובת.", "ג. פישוט ארכיטקטורת יחידת ניהול הזיכרון (MMU).", "ד. תמיכה במספר גדול יותר של דפים וירטואליים בכל תהליך."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין בשיעור מסביר כי הרעיון המרכזי מאחורי טבלאות דפים היררכיות (Multi-Level Page Tables) הוא לצמצם את כמות הזיכרון הפיזי הנדרש לטבלאות הדפים עצמן. נאמר במפורש: \"רוב התהליכים לא משתמשים בכל הזיכרון של מרחב הכתובות שלהם. רעיון: נציא את כל השטח האפור, נצמצם אותו לפחות רשומות.\" וכן \"No need to allocate!\" עבור דפים לא תקפים או לא בשימוש. זה מוביל לחיסכון בזיכרון פיזי, ובכך הופך את אפשרות א' לנכונה ביותר."}, "_source_file": "0109__Virtualization__Multi-level_Page_Tables__MC__Easy.json", "_topic_hint": "Multi-level Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:18:25", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Multi-level Page Tables"], "difficulty_estimation": "Easy", "content": {"text": "מהי הסיבה העיקרית לשימוש בטבלאות דפים רב-שכבתיות (Multi-Level Page Tables) במערכות הפעלה?", "code_snippet": null, "options": ["א. חיסכון בזיכרון פיזי על ידי אי-הקצאת דפי טבלה עבור חלקים לא בשימוש של מרחב הכתובות הווירטואלי.", "ב. האצת תהליך תרגום הכתובות מכתובת וירטואלית לפיזית.", "ג. הגדלת גודל מרחב הכתובות הווירטואלי הזמין לכל תהליך.", "ד. פישוט ניהול הזיכרון על ידי ביטול הצורך במטמון TLB."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מציין במפורש כי 'רוב התהליכים לא משתמשים בכל הזיכרון של מרחב הכתובות שלהם. רעיון: נציא את כל השטח האפור, נצמצם אותו לפחות רשומות.' וכן 'Entire page of entries invalid? Don't allocate it'. טבלאות דפים רב-שכבתיות מאפשרות למערכת ההפעלה לא להקצות זיכרון פיזי עבור טבלאות דפים (או חלקים מהן) של אזורים ממרחב הכתובות הווירטואלי שאינם בשימוש, ובכך לחסוך באופן משמעותי בזיכרון. האפשרויות האחרות אינן נכונות: טבלאות רב-שכבתיות דווקא מוסיפות גישות זיכרון בתהליך התרגום (ולכן לא מאיצות), אינן מגדילות את גודל מרחב הכתובות הווירטואלי הכולל, ואינן מבטלות את הצורך ב-TLB (אלא ה-TLB נחוץ יותר כדי למזער את עלות הביצועים שלהן)."}, "_source_file": "0110__Virtualization__Multi-level_Page_Tables__MC__Easy.json", "_topic_hint": "Multi-level Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:18:37", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Multi-level Page Tables"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של שימוש בטבלאות דפים היררכיות (Multi-Level Page Tables) במערכות הפעלה?", "code_snippet": null, "options": ["א. לחסוך בזיכרון על ידי אי-הקצאת רשומות טבלה עבור חלקים לא מנוצלים במרחב הכתובות הוירטואלי.", "ב. להאיץ את תהליך תרגום הכתובות הוירטואליות לכתובות פיזיות.", "ג. לפשט את ניהול הזיכרון עבור תהליכים מרובים הפועלים במקביל.", "ד. לאפשר תמיכה בגדלים גדולים יותר של זיכרון פיזי (RAM)."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מציין במפורש כי המטרה העיקרית של טבלאות דפים היררכיות היא 'לצמצם אותו לפחות רשומות' ו'לא להקצות' דפים שלמים של רשומות אם הם לא בשימוש (שטח אפור). רוב התהליכים אינם משתמשים בכל מרחב הכתובות הוירטואלי שלהם, ולכן טבלאות דפים היררכיות מאפשרות לחסוך בזיכרון על ידי אי-הקצאת טבלאות דפים עבור חלקים לא מנוצלים אלה."}, "_source_file": "0111__Virtualization__Multi-level_Page_Tables__MC__Easy.json", "_topic_hint": "Multi-level Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:18:49", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Multi-level Page Tables"], "difficulty_estimation": "Medium", "content": {"text": "מהו היתרון העיקרי של שימוש במבנה טבלת דפים היררכית (Multi-Level Page Table) בהשוואה לטבלת דפים לינארית (Single-Level Page Table)?", "code_snippet": null, "options": ["א. חיסכון משמעותי בזיכרון פיזי על ידי אי-הקצאת דפים עבור אזורים לא מנוצלים במרחב הכתובות הוירטואלי של תהליך.", "ב. האצת תהליך תרגום הכתובות הוירטואליות לכתובות פיזיות.", "ג. תמיכה במרחבי כתובות וירטואליים גדולים יותר באופן מהותי.", "ד. פישוט המורכבות של יחידת ניהול הזיכרון (MMU)."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין בשיעור מדגיש כי רוב התהליכים אינם מנצלים את כל מרחב הכתובות הוירטואלי שלהם. הרעיון המרכזי מאחורי טבלאות דפים היררכיות הוא \"לצמצם אותו לפחות רשומות\" על ידי אי-הקצאת זיכרון פיזי לדפים שלמים של רשומות בטבלת הדפים שאינן בשימוש. לדוגמה, מצוין \"Entire page of entries invalid? Don't allocate it. No need to allocate!\". לכן, היתרון העיקרי הוא חיסכון משמעותי בזיכרון פיזי. אפשרויות ב' ו-ד' שגויות, שכן תרגום כתובות בדרך כלל איטי יותר (דורש מספר גישות לזיכרון) וה-MMU מורכב יותר. אפשרות ג' היא תוצאה עקיפה של חיסכון בזיכרון, אך היתרון הישיר והמוצהר הוא החיסכון עצמו עבור מרחבי כתובות דלילים."}, "_source_file": "0112__Virtualization__Multi-level_Page_Tables__MC__Medium.json", "_topic_hint": "Multi-level Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:19:00", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Multi-level Page Tables"], "difficulty_estimation": "Medium", "content": {"text": "מהי הסיבה העיקרית שבגללה מערכות הפעלה משתמשות בטבלאות דפים היררכיות (Multi-Level Page Tables)?", "code_snippet": null, "options": ["א. כדי להאיץ את תהליך תרגום הכתובות הוירטואליות לכתובות פיזיות.", "ב. כדי לצמצם את כמות הזיכרון הפיזי הנדרש לאחסון טבלאות הדפים עצמן, במיוחד עבור אזורים לא מנוצלים במרחב הכתובות הוירטואלי.", "ג. כדי לאפשר גמישות רבה יותר בהגדרת גדלי דפים שונים עבור תהליכים שונים.", "ד. כדי לפשט את ארגון הזיכרון הפיזי ולמנוע פיצול חיצוני (external fragmentation)."]}, "solution": {"correct_option": "ב", "explanation": "החומר המצוין מדגיש כי רוב התהליכים אינם משתמשים בכל הזיכרון של מרחב הכתובות הוירטואלי שלהם, וכי הרעיון הוא 'נציא את כל השטח האפור, נצמצם אותו לפחות רשומות'. טבלאות דפים היררכיות, כמו ה-Multi-Level Page Table, נועדו לחסוך בזיכרון על ידי הפיכת טבלת הדפים למבנה דמוי עץ ואי-הקצאה של דפים שלמים של רשומות שאינם בשימוש (כפי שמתואר ב'No need to allocate!'). ה-page directory מכיל מצביעים רק לחלקים הרלוונטיים של טבלת הדפים, ובכך נמנעת הקצאת זיכרון מיותרת."}, "_source_file": "0113__Virtualization__Multi-level_Page_Tables__MC__Medium.json", "_topic_hint": "Multi-level Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:19:12", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Multi-level Page Tables"], "difficulty_estimation": "Medium", "content": {"text": "מהו היתרון העיקרי של שימוש בטבלת דפים רב-שכבתית (Multi-Level Page Table) בהשוואה לטבלת דפים שטוחה (Single-Level Page Table), כפי שמתואר בחומר ההרצאה?", "code_snippet": null, "options": ["א. חיסכון משמעותי בזיכרון פיזי על ידי אי-הקצאה של טבלאות דפים שלמות עבור אזורים לא מנוצלים במרחב הכתובות הוירטואלי.", "ב. הגדלה מהירה יותר של מרחב הכתובות הוירטואלי מעבר למה שניתן להשיג בטבלה שטוחה.", "ג. שיפור ביצועים בתרגום כתובות באמצעות הפחתת מספר הגישות לזיכרון הראשי עבור כל תרגום.", "ד. תמיכה מובנית בזיכרון וירטואלי בגדלים שונים (Variable Page Sizes) ללא צורך במנגנונים נוספים."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מציין במפורש כי רוב התהליכים אינם מנצלים את כל מרחב הכתובות הוירטואלי שלהם. הרעיון המרכזי מאחורי טבלאות דפים רב-שכבתיות הוא \"נצמצם אותו לפחות רשומות\" ו-\"Don't allocate it\" כאשר \"Entire page of entries invalid?\". מבנה זה, המכונה גם \"עץ\" או \"היררכי\", מאפשר למערכת ההפעלה לא להקצות זיכרון פיזי לטבלאות דפים שלמות (או לחלקים מהן) שאינן בשימוש. לדוגמה, אם חלק גדול ממרחב הכתובות אינו ממופה, אין צורך להקצות Page Table עבורו, ורשומת ה-Page Directory המתאימה תצביע על חוסר תוקף. זה מוביל לחיסכון משמעותי בזיכרון פיזי, שהיה מוקצה לטבלאות דפים בגישה שטוחה עבור אזורים אלו."}, "_source_file": "0114__Virtualization__Multi-level_Page_Tables__MC__Medium.json", "_topic_hint": "Multi-level Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:19:26", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Multi-level Page Tables"], "difficulty_estimation": "Hard", "content": {"text": "על אף שמנגנון טבלאות דפים היררכיות (Multi-level Page Tables) נועד לחסוך בזיכרון על ידי אי-הקצאת רשומות דפים שאינן בשימוש, מהו אחד האתגרים המשמעותיים שעדיין נותרים בגישה זו, כפי שמשתמע במפורש מחומר ההרצאה?", "code_snippet": null, "options": ["א. ספריית הדפים (page directory) עצמה עלולה לתפוס נפח זיכרון פיזי גדול מאוד, כפי שצוין שהיא יכולה לתפוס \"128 דפים\" בדוגמה מסוימת.", "ב. תהליך תרגום הכתובת הוירטואלית דורש מספר רב יותר של גישות לזיכרון הפיזי, מה שפוגע בביצועים.", "ג. מורכבות חומרת ה-MMU גדלה באופן דרמטי בשל הצורך לנהל היררכיה של טבלאות.", "ד. פיצול (fragmentation) הזיכרון הפיזי גדל כיוון שטבלאות הדפים מפוזרות על פני דפים שונים ב-RAM."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר ההרצאה מציין במפורש: \"אנחנו חסכנו זיכרון, אבל לא מספיק. נשים לב שה-page directory תופס יותר מדי, הוא תופס 128 דפים.\" הדבר מדגיש כי למרות שמנגנון טבלאות דפים היררכיות חוסך בזיכרון על ידי אי-הקצאת טבלאות דפים שלמות שאינן בשימוש, ספריית הדפים (page directory) עצמה יכולה להיות גדולה מאוד ולצרוך כמות משמעותית של זיכרון פיזי, ובכך להוות עדיין עלות זיכרון משמעותית.\nאפשרויות ב', ג' ו-ד' מתארות בעיות או מאפיינים אפשריים של טבלאות דפים היררכיות, אך הן אינן מודגשות במפורש בחומר ההרצאה כ\"אתגר משמעותי\" הקשור ישירות לחיסכון בזיכרון, באותו אופן שבו הודגשה צריכת הזיכרון של ספריית הדפים עצמה. אפשרות ב' מתארת פגיעה בביצועים ולא עלות זיכרון ישירה של המנגנון. אפשרויות ג' ו-ד' אינן נתמכות במפורש על ידי חומר ההרצאה שסופק."}, "_source_file": "0115__Virtualization__Multi-level_Page_Tables__MC__Hard.json", "_topic_hint": "Multi-level Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:19:42", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Multi-level Page Tables"], "difficulty_estimation": "Hard", "content": {"text": "טבלאות דפים מרובות רמות (Multi-Level Page Tables) תוכננו במטרה לחסוך בזיכרון על ידי הימנעות מהקצאת רשומות עבור אזורים לא בשימוש במרחב הכתובות הוירטואלי של תהליך. עם זאת, איזה היבט, כפי שהודגש בחומר ההרצאה, מהווה אתגר או מגבלה בהקשר של צריכת זיכרון על ידי מבני התרגום עצמם?", "code_snippet": null, "options": ["א. ה-Page Directory עצמו יכול להיות גדול מאוד ולצרוך כמות משמעותית של זיכרון פיזי, למרות החיסכון בדפי טבלאות דפים פנימיים.", "ב. כל רשומה בטבלת הדפים (PTE) דורשת כעת מספר רב יותר של ביטים כדי לייצג כתובת פיזית, מה שמגדיל את גודל הטבלה הכולל.", "ג. הצורך לאחסן מצביעים לדפי טבלאות דפים ב-Page Directory מוביל להכפלה של הזיכרון הנדרש עבור כל דף וירטואלי ממופה.", "ד. מערכת ההפעלה נדרשת לבצע סריקה מתמדת של ה-Page Directory כדי לזהות ולשחרר דפי טבלאות דפים ריקים, מה שיוצר תקורה משמעותית בזיכרון."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. חומר ההרצאה מציין במפורש כי בעוד שטבלאות דפים מרובות רמות נועדו לחסוך בזיכרון על ידי אי-הקצאת דפי טבלאות דפים עבור אזורים לא מנוצלים במרחב הכתובות הוירטואלי ('נציא את כל השטח האפור, נצמצם אותו לפחות רשומות'), ה-Page Directory עצמו עלול להיות גדול מאוד. ההרצאה מציינת: 'אם נסתכל עכשיו על הזיכרון, נראה שה-page directory table שלנו הוא עצום... אנחנו חסכנו זיכרון, אבל לא מספיק. נשים לב שה-page directory תופס יותר מדי, הוא תופס 128 דפים.' זה מדגיש שה-Page Directory עצמו מהווה תקורה בזיכרון, ולמרות שהגישה ההיררכית חוסכת זיכרון באופן כללי, היא אינה מבטלת לחלוטין את צריכת הזיכרון על ידי מבני התרגום."}, "_source_file": "0116__Virtualization__Multi-level_Page_Tables__MC__Hard.json", "_topic_hint": "Multi-level Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:19:57", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Multi-level Page Tables"], "difficulty_estimation": "Hard", "content": {"text": "מהי הסיבה העיקרית לשימוש בטבלאות דפים היררכיות (Multi-Level Page Tables) במערכות הפעלה מודרניות, וכיצד היא מושגת?", "code_snippet": null, "options": ["א. חיסכון בזיכרון פיזי על ידי אי-הקצאת דפי טבלאות דפים עבור חלקים לא מנוצלים במרחב הכתובות הוירטואלי, במיוחד עבור תהליכים שאינם משתמשים בכל הזיכרון שלהם.", "ב. האצת תהליך תרגום הכתובות הוירטואליות לכתובות פיזיות על ידי צמצום מספר הגישות לזיכרון.", "ג. פישוט ניהול הזיכרון הוירטואלי והרחבת מרחב הכתובות הוירטואלי האפשרי לתהליך יחיד.", "ד. שיפור אבטחת המערכת על ידי בידוד מרחבי כתובות של תהליכים שונים ומניעת גישה בלתי מורשית."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. טבלאות דפים היררכיות (Multi-Level Page Tables) הוצגו במטרה לחסוך בזיכרון פיזי המשמש לאחסון טבלאות הדפים עצמן. רוב התהליכים אינם מנצלים את כל מרחב הכתובות הוירטואלי העצום העומד לרשותם. בטבלת דפים ליניארית (שטוחה), יהיה צורך להקצות רשומות לכל דף וירטואלי אפשרי, גם אם אינו בשימוש, מה שמוביל לבזבוז זיכרון משמעותי עבור 'שטחים אפורים' ובלתי מנוצלים. טבלאות דפים היררכיות פותרות זאת על ידי חלוקת טבלת הדפים ליחידות בגודל דף (page-sized units) ושימוש ב'מדריך דפים' (page directory) כדי לעקוב אחריהן. אם דף שלם של רשומות בטבלת הדפים אינו תקף (כלומר, הטווח המקביל במרחב הכתובות הוירטואלי אינו בשימוש), אין צורך להקצות אותו כלל בזיכרון הפיזי. החומר המצוין בפירוש: 'רוב התהליכים לא משתמשים בכל הזיכרון של מרחב הכתובות שלהם. רעיון: נציא את כל השטח האפור, נצמצם אותו לפחות רשומות.' וכן 'Entire page of entries invalid? Don't allocate it. No need to allocate!' מה שמאשש את מטרת החיסכון בזיכרון.\n\nאפשרויות ב', ג', ו-ד' אינן נכונות: \nב. האצת תהליך תרגום הכתובות אינה הסיבה העיקרית. למעשה, טבלאות דפים היררכיות דורשות מספר גישות לזיכרון (לדוגמה, גישה למדריך הדפים ולאחר מכן לטבלת הדפים הספציפית) כדי לבצע תרגום כתובת, מה שעלול להאט את התהליך בהשוואה לטבלה ליניארית ללא מטמון. האצה מושגת בדרך כלל באמצעות TLB (Translation Lookaside Buffer).\nג. בעוד שטבלאות דפים היררכיות מאפשרות תמיכה במרחבי כתובות וירטואליים גדולים בצורה יעילה יותר מבחינת זיכרון, המטרה העיקרית היא חיסכון בזיכרון עבור טבלאות הדפים עצמן. ניהול הזיכרון אינו הופך לפשוט יותר; הוא למעשה מורכב יותר מבחינה מבנית.\nד. שיפור אבטחת המערכת ובידוד תהליכים הם יתרונות בסיסיים של מנגנון הדפדוף (paging) באופן כללי, ולא מאפיין ספציפי או יתרון ייחודי של המבנה ההיררכי של טבלאות הדפים. המבנה ההיררכי מתמקד ביעילות ניהול טבלת הדפים עצמה."}, "_source_file": "0117__Virtualization__Multi-level_Page_Tables__MC__Hard.json", "_topic_hint": "Multi-level Page Tables", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:20:14", "_subject": "Virtualization", "_context_lectures": [7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["TLB"], "difficulty_estimation": "Easy", "content": {"text": "מהי הפעולה הראשונה שמבצע ה-MMU כאשר מתרחשת גישה לזיכרון וירטואלי, בהקשר ל-TLB?", "code_snippet": null, "options": ["א. בודק אם המיפוי לכתובת הוירטואלית קיים ב-TLB.", "ב. ניגש ישירות לטבלת הדפים כדי למצוא את המיפוי לכתובת הפיזית.", "ג. מעדכן את ה-TLB במיפוי חדש שהתגלה בטבלת הדפים.", "ד. יוצר trap למערכת ההפעלה עקב חוסר מיפוי."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, בכל פעם שיש גישה לזיכרון וירטואלי, ה-MMU \"קודם יבדוק את ה-TLB\". רק אם המיפוי לא קיים ב-TLB (כלומר 'miss'), אז הוא יבצע את התהליך הארוך יותר של חיפוש בטבלת הדפים. לכן, הפעולה הראשונה היא תמיד בדיקת ה-TLB."}, "_source_file": "0118__Virtualization__TLB__MC__Easy.json", "_topic_hint": "TLB", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:20:23", "_subject": "Virtualization", "_context_lectures": [8, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["TLB"], "difficulty_estimation": "Easy", "content": {"text": "מהו השלב הראשון בחיפוש כתובת פיזית על ידי ה-MMU כאשר ניגשים לזיכרון וירטואלי?", "code_snippet": null, "options": ["א. ה-MMU ניגש ישירות לטבלת הדפים (Page Table) כדי למצוא את המיפוי.", "ב. ה-MMU בודק תחילה את ה-TLB (Translation Lookaside Buffer) עבור המיפוי הנדרש.", "ג. ה-MMU שולח trap למערכת ההפעלה כדי שהיא תמצא את המיפוי.", "ד. ה-MMU מחשב את ה-PFN (Page Frame Number) ישירות מהכתובת הוירטואלית."]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר ההרצאה, בכל פעם שיש גישה לזיכרון, ה-MMU \"קודם יבדוק את ה-tlb\". ה-TLB הוא רכיב חומרה מהיר במעבד המשמש כמטמון למיפויי כתובות וירטואליות לפיזיות. בדיקתו תחילה מאפשרת קיצור משמעותי בזמן הגישה לזיכרון אם המיפוי כבר קיים בו (TLB hit)."}, "_source_file": "0119__Virtualization__TLB__MC__Easy.json", "_topic_hint": "TLB", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:20:32", "_subject": "Virtualization", "_context_lectures": [8, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["TLB"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של ה-TLB (Translation Lookaside Buffer) במערכת הפעלה?", "code_snippet": null, "options": ["א. לקצר את זמן הגישה לזיכרון הפיזי על ידי שמירת מיפויי כתובות וירטואליות לכתובות פיזיות.", "ב. לאחסן נתונים של דפים שנגשו אליהם לאחרונה מהדיסק.", "ג. לנהל את סדר הגישה לדפים בטבלת הדפים (page table) עבור תהליכים שונים.", "ד. להבטיח שכל הדפים של תהליך מסוים יהיו בזיכרון הפיזי באופן רציף."]}, "solution": {"correct_option": "א", "explanation": "ה-TLB הוא מטמון חומרה מהיר הממוקם במעבד, ותפקידו העיקרי הוא לשמש כזיכרון מטמון (cache) למיפויי כתובות וירטואליות לכתובות פיזיות שנעשה בהן שימוש לאחרונה. מטרתו היא לקצר את זמן הגישה לזיכרון על ידי הימנעות מהצורך לבצע חיפוש ארוך בטבלת הדפים בכל גישה לזיכרון וירטואלי. אם המיפוי נמצא ב-TLB (TLB hit), הגישה מהירה מאוד. אם המיפוי אינו נמצא (TLB miss), הוא נשלף מטבלת הדפים ולאחר מכן מעודכן ב-TLB לשימוש עתידי, כפי שמתואר בחומר הלימוד: 'מה ש-tlb נותן לנו זה קיצור בגישות לזיכרון'."}, "_source_file": "0120__Virtualization__TLB__MC__Easy.json", "_topic_hint": "TLB", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:20:42", "_subject": "Virtualization", "_context_lectures": [8, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["TLB"], "difficulty_estimation": "Medium", "content": {"text": "מהי המטרה העיקרית של הוספת מזהה ASID (Address Space ID) לרשומות ה-TLB?", "code_snippet": null, "options": ["א. כדי לאפשר ל-TLB להחזיק רשומות רק עבור דפים הנמצאים בזיכרון הפיזי (RAM).", "ב. כדי למנוע מצב של TLB miss כאשר מתרחש context switch בין תהליכים שונים.", "ג. כדי להבחין בין רשומות TLB השייכות לתהליכים שונים ולאפשר שמירת רשומות של מספר תהליכים במקביל.", "ד. כדי לקצר את תהליך החיפוש בטבלת הדפים במקרה של TLB miss."]}, "solution": {"correct_option": "ג", "explanation": "ה-ASID (Address Space ID) מתווסף לכל רשומה ב-TLB על מנת לזהות לאיזה תהליך (מרחב כתובות) הרשומה שייכת. פתרון זה מאפשר ל-MMU להבחין בין רשומות TLB השייכות לתהליכים שונים. כאשר מתבצע context switch בין תהליכים, ה-TLB לא צריך להתרוקן לחלוטין. במקום זאת, ה-MMU יכול להשתמש ב-ASID כדי לוודא שרשומות ה-TLB הרלוונטיות לתהליך הנוכחי הן אלה שנעשה בהן שימוש, תוך התעלמות מרשומות של תהליכים אחרים שעדיין נמצאות במטמון. זה משפר את הביצועים על ידי שמירת מיפויים של תהליכים שונים במקביל ב-TLB ומניעת הצורך לטעון אותם מחדש לאחר כל החלפת קשר. אפשרות א' מתייחסת ל-Present bit, ואפשרויות ב' ו-ד' אינן המטרה העיקרית או המדויקת של ה-ASID."}, "_source_file": "0121__Virtualization__TLB__MC__Medium.json", "_topic_hint": "TLB", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:20:54", "_subject": "Virtualization", "_context_lectures": [8, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["TLB"], "difficulty_estimation": "Medium", "content": {"text": "חומר הלימוד מציין: \"אם נעשה עכשיו context switch, הבעיה תהיה ש-TLB לא יהיה מעודכן עבור התהליך הנוכחי.\" מהו הפתרון העיקרי המתואר בחומר הלימוד להתמודדות עם בעיה זו ב-TLB?", "code_snippet": null, "options": ["א. לרוקן את כל רשומות ה-TLB עם כל החלפת קשר (context switch).", "ב. להוסיף לכל רשומה ב-TLB מזהה מרחב כתובות (ASID) כדי להבחין בין רשומות של תהליכים שונים.", "ג. להגדיל באופן משמעותי את נפח ה-TLB כך שיוכל להכיל מיפויים מכל התהליכים הפועלים.", "ד. לדרוש מכל התהליכים להשתמש באותו מרחב כתובות וירטואלי כדי למנוע התנגשויות."]}, "solution": {"correct_option": "ב", "explanation": "חומר הלימוד מציין במפורש כי הפתרון לבעיה שבה ה-TLB אינו מעודכן לאחר החלפת קשר הוא: \"נוסיף לכל רשומה ב-TLB מזהה נוסף שנקרא ASID (address space id) שיציין לאיזה תהליך הרשומה הזו שייכת וכך ניתן להבדיל בין רשומות של תהליכים שונים.\" פתרון זה מאפשר ל-TLB להחזיק מיפויים מתהליכים שונים במקביל מבלי לרוקן את תוכנו, ובכך משפר את הביצועים. האפשרויות האחרות אינן מתוארות כפתרון בחומר הלימוד, או שהן אינן יעילות/אפשריות."}, "_source_file": "0122__Virtualization__TLB__MC__Medium.json", "_topic_hint": "TLB", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:21:06", "_subject": "Virtualization", "_context_lectures": [8, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["TLB"], "difficulty_estimation": "Medium", "content": {"text": "מהו הרצף הנכון של פעולות ה-MMU בעת גישה לכתובת וירטואלית, אם המיפוי אינו נמצא ב-TLB (TLB miss), אך הדף הוירטואלי אכן נמצא בזיכרון הפיזי (RAM)?", "code_snippet": null, "options": ["א. ה-MMU ניגש לטבלת הדפים, מוצא את המיפוי, בודק שה-Present bit הוא 1, מעדכן את ה-TLB, וממשיך בגישה לזיכרון הפיזי.", "ב. ה-MMU יוצר Trap למערכת ההפעלה באופן מיידי, מכיוון שהמיפוי לא נמצא ב-TLB.", "ג. ה-MMU ניגש לטבלת הדפים, מוצא את המיפוי, בודק שה-Present bit הוא 0, ורק אז מעדכן את ה-TLB.", "ד. ה-MMU מעדכן את ה-TLB עם מיפוי ריק, ויוצר Trap למערכת ההפעלה."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, כאשר מתרחש TLB miss, ה-MMU אינו יוצר trap מיד אלא ממשיך לחפש את המיפוי בטבלת הדפים (Lecture 7, chunk 29). אם המיפוי נמצא בטבלת הדפים וה-Present bit שלו הוא 1 (כפי שמשתמע מהשאלה שהדף נמצא בזיכרון הפיזי), אז ה-MMU מתרגם את הכתובת, מעדכן את ה-TLB עם המיפוי החדש כדי לזרז גישות עתידיות לאותו דף, ורק אז ממשיך בגישה לזיכרון הפיזי (Lecture 8, chunk 10). לכן, אפשרות א' היא הנכונה.\nאפשרות ב' שגויה מכיוון ש-TLB miss אינו גורם ל-trap מיידי; ה-MMU מנסה תחילה לגשת לטבלת הדפים. אפשרות ג' שגויה מכיוון שאם ה-Present bit הוא 0, הדף אינו ב-RAM, וזה מוביל ל-trap (Page Fault) ולא לעדכון ה-TLB עם רשומה כזו (ה-TLB מחזיק רק רשומות עם Present bit=1). אפשרות ד' שגויה מכיוון שה-TLB מתעדכן במיפויים תקינים ולא ב\"מיפויים ריקים\", ו-trap אינו תוצאה ודאית של TLB miss."}, "_source_file": "0123__Virtualization__TLB__MC__Medium.json", "_topic_hint": "TLB", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:21:18", "_subject": "Virtualization", "_context_lectures": [8, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["TLB"], "difficulty_estimation": "Hard", "content": {"text": "תהליך מנסה לגשת לכתובת זיכרון וירטואלית. ה-MMU מבצע את פעולת התרגום. בהינתן הרצף הבא:\n1. בדיקה ב-TLB מניבה 'TLB miss'.\n2. ה-MMU ניגש לטבלת הדפים ומוצא את ה-Page Table Entry (PTE) המתאים.\n3. ה-'Present bit' ב-PTE זה מוגדר ל-0.\n\nמהי התוצאה המיידית של רצף אירועים זה, ומה קורה בהמשך?", "code_snippet": "for (int i = 0; i < 10; i++; ++i) {\n  ++a[i];\n}", "options": ["א. ה-MMU יוצר 'trap' למערכת ההפעלה, כיוון שהדף אינו נמצא בזיכרון הפיזי (RAM), וה-TLB אינו מתעדכן במיפוי זה.", "ב. ה-MMU מעדכן את ה-TLB במיפוי שנמצא בטבלת הדפים, ולאחר מכן מערכת ההפעלה מטפלת ב'page fault'.", "ג. ה-MMU ממשיך לחפש את המיפוי ברמת טבלת דפים גבוהה יותר, ורק אם לא ימצא שם, ייווצר 'trap'.", "ד. התהליך מופסק באופן מיידי על ידי החומרה כיוון שניסה לגשת לכתובת לא חוקית."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה (Lecture 8, chunk 10), כאשר ה-MMU ניגש לטבלת הדפים עקב 'TLB miss' ומוצא PTE שה-'Present bit' שלו מוגדר ל-0, משמעות הדבר היא שהדף אינו נמצא בזיכרון הפיזי (RAM). במצב כזה, ה-MMU אינו יכול לתרגם את הכתובת הווירטואלית לכתובת פיזית תקינה, ולכן הוא יוצר 'trap' למערכת ההפעלה. תפקיד ה-'trap' הוא להודיע למערכת ההפעלה על האירוע, ולאפשר לה לטפל בו (לדוגמה, לטעון את הדף מהדיסק לזיכרון). בנוסף, ה-TLB מחזיק רק רשומות שה-'Present bit' שלהן הוא 1, ולכן מיפוי עם 'Present bit' 0 לא יעודכן ב-TLB. אפשרות ב' שגויה מכיוון שה-TLB אינו מתעדכן במיפויים שבהם ה-'Present bit' הוא 0 (Lecture 8, chunk 10). אפשרות ג' שגויה מכיוון שה-'Present bit' מוגדר ב-PTE עצמו, וערך 0 מצביע על היעדר הדף בזיכרון הפיזי, ולא על צורך בחיפוש נוסף בטבלת דפים. אפשרות ד' שגויה מכיוון שהחומרה יוצרת 'trap' למערכת ההפעלה, המאפשר למערכת ההפעלה לטפל במצב, במקום להפסיק את התהליך באופן מיידי וללא התערבות."}, "_source_file": "0124__Virtualization__TLB__MC__Hard.json", "_topic_hint": "TLB", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:21:33", "_subject": "Virtualization", "_context_lectures": [8, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["TLB"], "difficulty_estimation": "Hard", "content": {"text": "תהליך P1 רץ, ולאחר מכן מתרחש context switch לתהליך P2. תהליך P2 מבצע כעת גישה לכתובת וירטואלית. בהתחשב בכך שה-TLB מכיל רשומות עם מזהה ASID (Address Space ID) עבור תהליכים שונים, וכי הדף הפיזי המתאים לכתובת הוירטואלית הנדרשת על ידי P2 אינו נמצא כרגע בזיכרון הפיזי (כלומר, ה-Present bit עבור ה-PTE המתאים בטבלת הדפים של P2 הוא 0), מהו הרצף הנכון של האירועים שיגרמו ל-MMU להעלות Trap למערכת ההפעלה?", "code_snippet": null, "options": ["א. ה-MMU יבצע בדיקת TLB, יקבל TLB miss (עקב ASID שאינו תואם או אי-קיום רשומה), יגש לטבלת הדפים של P2, ימצא שה-Present bit של הדף הוא 0, ויעלה Trap למערכת ההפעלה.", "ב. ה-MMU יזהה מיידית את חוסר הדף בזיכרון הפיזי עוד לפני גישה ל-TLB, ויעלה Trap.", "ג. ה-MMU יבצע בדיקת TLB, יקבל TLB hit (בזכות רשומה קודמת של תהליך P1 ללא התחשבות ב-ASID), ואז יגש לכתובת פיזית שגויה ויעלה Trap.", "ד. ה-MMU יבצע בדיקת TLB, יקבל TLB miss, יעדכן את ה-TLB עם מיפוי חדש מתוך טבלת הדפים (למרות שהדף אינו ב-RAM), ורק אז ינסה לגשת לזיכרון הפיזי ויקבל Trap."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. להלן ההסבר המפורט, בהתבסס על חומר ההרצאה:\n\n1.  **בדיקת TLB ראשונית:** חומר ההרצאה קובע במפורש ש\"בכל פעם שיש גישה לזיכרון, [ה-MMU] קודם יבדוק את ה-tlb\". לכן, כל גישה לכתובת וירטואלית מתחילה בבדיקת ה-TLB.\n\n2.  **TLB miss עקב ASID:** השאלה מציינת שה-TLB מכיל רשומות עם ASID. כאשר מתרחש context switch מ-P1 ל-P2, ה-TLB עשוי להכיל רשומות של P1 או רשומות קודמות של P2. אם קיימת רשומה עבור הכתובת הוירטואלית אך ה-ASID שלה אינו תואם ל-P2 הנוכחי, או שאין רשומה כלל עבור כתובת זו של P2, יתקבל **TLB miss**. ה-ASID מונע מצב של \"TLB hit\" שגוי על רשומה של תהליך אחר, כפי שמצוין בחומר: \"נוסיף לכל רשומה ב-tlb מזהה נוסף שנקרא ASID (address space id) שיציין לאיזה תהליך הרשומה הזו שייכת וכך ניתן להבדיל בין רשומות של תהליכים שונים.\"\n\n3.  **גישה לטבלת הדפים:** לאחר TLB miss, ה-MMU יגש לטבלת הדפים כדי למצוא את המיפוי. \"אם המיפוי לא קיים [ב-TLB], נעשה את התהליך הארוך (נלך לחפש בטבלת הדפים)\".\n\n4.  **בדיקת Present bit:** בטבלת הדפים, ה-MMU ימצא את ה-PTE המתאים לכתובת הוירטואלית ויבדוק את ה-Present bit שלו. \"ה-mmu ניגש לטבלת הדפים ומחפש את המיפוי שם, ובודק את ה-present bit\".\n\n5.  **העלאת Trap:** מכיוון שהשאלה קובעת שה-Present bit הוא 0, משמעות הדבר היא שהדף אינו נמצא בזיכרון הפיזי (RAM). במצב זה, \"ה-mmu יוצר trap למערכת ההפעלה\".\n\n**מדוע שאר האפשרויות שגויות:**\n*   **ב.** שגויה מכיוון שה-MMU תמיד בודק את ה-TLB תחילה לפני שהוא מנסה \"לזהות\" משהו לגבי מצב הדף בזיכרון הפיזי.\n*   **ג.** שגויה מכיוון שהשימוש ב-ASID מונע TLB hit עבור רשומות של תהליכים אחרים (כמו P1) לאחר context switch. ללא ASID, אפשרות זו הייתה יכולה להיות נכונה.\n*   **ד.** שגויה מכיוון שה-TLB לא מתעדכן עם מיפוי של דף שאינו נמצא ב-RAM (כלומר, ה-Present bit שלו הוא 0). חומר ההרצאה מציין ש\"ה-tlb מחזיק רק רשומות שה-present bit שלהן הוא 1\" וכי עדכון ה-TLB מתבצע \"אחרי שנמצא את המיפוי\" (משמע, מיפוי חוקי לדף ב-RAM)."}, "_source_file": "0125__Virtualization__TLB__MC__Hard.json", "_topic_hint": "TLB", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:21:54", "_subject": "Virtualization", "_context_lectures": [8, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["TLB"], "difficulty_estimation": "Hard", "content": {"text": "בהינתן מערכת הפעלה שאינה מיישמת מזהי מרחב כתובות (ASID) עבור רשומות ה-TLB, איזו פעולה קריטית סביר שתתבצע על ה-TLB במהלך החלפת הקשר (context switch) כדי להבטיח את תקינות תרגום הכתובות עבור התהליך החדש?", "code_snippet": null, "options": ["א. ה-TLB יישטף (flushed) לחלוטין מכל הרשומות שלו.", "ב. ה-MMU יבדוק את ה-Present Bit של כל רשומת TLB לפני השימוש בה.", "ג. ה-TLB יאוחזר מהזיכרון הראשי עבור התהליך החדש.", "ד. מערכת ההפעלה תעדכן באופן סלקטיבי רק את רשומות ה-TLB השייכות לדפים פעילים."]}, "solution": {"correct_option": "א", "explanation": "החומר המצוין בשיעור קובע כי \"אם נעשה עכשיו context switch, הבעיה תהיה ש-tlb לא יהיה מעודכן עבור התהליך הנוכחי. הפתרון לכך: נוסיף לכל רשומה ב-tlb מזהה נוסף שנקרא ASID (address space id) שיציין לאיזה תהליך הרשומה הזו שייכת וכך ניתן להבדיל בין רשומות של תהליכים שונים.\" מכאן נובע, שאם מערכת אינה משתמשת ב-ASID, ה-TLB יכיל מיפויים השייכים לתהליך הקודם. כדי למנוע שימוש במיפויים שגויים אלו עבור התהליך החדש, יש צורך לנקות (לשטוף) את כל רשומות ה-TLB. פעולה זו מבטיחה שהתהליך החדש יתחיל עם TLB \"נקי\" ממיפויים שגויים, גם אם זה כרוך ביותר TLB misses בתחילה. שאר האפשרויות אינן פתרון לבעיה זו: בדיקת ה-Present Bit רלוונטית לשאלה האם הדף בזיכרון הפיזי ולא לאיזה תהליך הוא שייך; אחזור TLB מהזיכרון הראשי אינו מנגנון קיים עבור מטמון; ועדכון סלקטיבי אינו אפשרי ללא מזהה תהליך (כמו ASID) ברשומות ה-TLB עצמן, שכן המערכת לא תוכל להבחין אילו רשומות רלוונטיות לתהליך החדש."}, "_source_file": "0126__Virtualization__TLB__MC__Hard.json", "_topic_hint": "TLB", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:22:10", "_subject": "Virtualization", "_context_lectures": [8, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Copy-on-Write"], "difficulty_estimation": "Easy", "content": {"text": "מהו היתרון העיקרי של מנגנון ה-Copy-on-Write (CoW) בהקשר של יצירת תהליכים חדשים (באמצעות `fork`)?", "code_snippet": null, "options": ["א. הוא מאפשר לשתף את כל הזיכרון בין תהליכי אב ובן לצמיתות, ללא צורך בהעתקה כלשהי.", "ב. הוא מפחית את צריכת הזיכרון הפיזי על ידי דחיית שכפול דפי זיכרון עד לניסיון כתיבה אליהם.", "ג. הוא מאיץ את קריאת הנתונים מהדיסק על ידי טעינה מראש של דפים סמוכים.", "ד. הוא מבטיח שכל תהליך יקבל עותק מלא ופרטי של הזיכרון מיד לאחר ה-`fork`."]}, "solution": {"correct_option": "ב", "explanation": "החומר המצוין בשיעור 4 (chunk 4) מתאר את מנגנון ה-Copy-on-Write באופן מפורש: \"אם זה עותק, לא צריך לשכפל בפועל את הזיכרון, זו פעולה יקרה. במקום זה ניתן לחסוך את ההעתקה הזו, ולהגדיר שהזיכרון הזה משותף לשני התהליכים (האב והבן), עד שאחד התהליכים יעשה פעולת write. רק בנקודה הזו, מערכת ההפעלה מוצאת מקום חדש בזיכרון, יוצרת עותק של מה שהיה בו ומשנה את מה שהתהליך רצה לשנות.\"\nלכן, היתרון העיקרי של CoW הוא חיסכון בזיכרון פיזי על ידי דחיית שכפול דפים עד לרגע שבו אחד התהליכים (אב או בן) מנסה לשנות את תוכן הדף. אפשרויות א' ו-ד' מתארות מצבים שאינם תואמים את CoW, ואפשרות ג' מתייחסת לטכניקות אופטימיזציה של דיסק שאינן קשורות ישירות ל-CoW."}, "_source_file": "0127__Virtualization__Copy-on-Write__MC__Easy.json", "_topic_hint": "Copy-on-Write", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:22:20", "_subject": "Virtualization", "_context_lectures": [8, 9, 4, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Copy-on-Write"], "difficulty_estimation": "Easy", "content": {"text": "מהי המטרה העיקרית של מנגנון Copy-on-Write (CoW) ביצירת תהליך חדש (למשל, באמצעות `fork`)?", "code_snippet": null, "options": ["א. למנוע שכפול מיידי של זיכרון בין תהליך אב לבן, ובכך לחסוך פעולה יקרה.", "ב. לאפשר לתהליכים שונים לכתוב לאותו דף זיכרון משותף בו זמנית ללא יצירת עותקים.", "ג. להבטיח שכל דפי הזיכרון של תהליך הבן ישוכפלו באופן מלא מיד עם יצירתו.", "ד. לטעון דפי זיכרון מהדיסק ל-RAM בצורה מקובצת (clustering) כאשר מתרחש Page Fault."]}, "solution": {"correct_option": "א", "explanation": "ההסבר הנכון הוא א'. כפי שמוסבר בחומר ההרצאה (הרצאה 4, קטע 4), מנגנון ה-Copy-on-Write נועד לשפר ביצועים על ידי מניעת שכפול מיידי ויקר של כל זיכרון התהליך בעת יצירת תהליך חדש (למשל, באמצעות `fork`). במקום זאת, תהליך האב והבן חולקים את אותו זיכרון פיזי. שכפול הזיכרון מתרחש רק כאשר אחד התהליכים מנסה לבצע פעולת כתיבה (write) לדף משותף, ורק אז נוצר עותק חדש של אותו דף ספציפי עבור התהליך הכותב. זה חוסך את הצורך להעתיק את כל הזיכרון אם התהליך הבן לא משנה את כל הדפים או משנה רק מעטים."}, "_source_file": "0128__Virtualization__Copy-on-Write__MC__Easy.json", "_topic_hint": "Copy-on-Write", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:22:30", "_subject": "Virtualization", "_context_lectures": [8, 9, 4, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Copy-on-Write"], "difficulty_estimation": "Easy", "content": {"text": "מהו העיקרון המרכזי של מנגנון Copy-on-Write (CoW) במערכות הפעלה, כפי שתואר בחומר הקורס?", "code_snippet": null, "options": ["א. הזיכרון משוכפל באופן מלא ובבת אחת עם יצירת תהליך חדש, כדי למנוע עיכובים עתידיים.", "ב. הזיכרון משותף בין תהליכים ללא קשר לפעולות כתיבה, ומערכת ההפעלה מטפלת בקונפליקטים.", "ג. הזיכרון משוכפל רק כאשר אחד התהליכים (האב או הבן) מנסה לבצע פעולת כתיבה (write) לדף משותף.", "ד. הזיכרון משוכפל מיד עם יצירת תהליך חדש על ידי fork, אך רק הדפים הפעילים ביותר."]}, "solution": {"correct_option": "ג", "explanation": "על פי חומר הקורס (Lecture 4, chunk 4), מנגנון Copy-on-Write (CoW) נועד לשפר ביצועים על ידי הימנעות משכפול מיידי של זיכרון בעת יצירת תהליך חדש (שכפול של תהליך קיים). במקום זאת, הזיכרון מוגדר כמשותף בין התהליכים (האב והבן). השכפול בפועל של דף זיכרון מתרחש רק \"עד שאחד התהליכים יעשה פעולת write. אם אחד התהליכים יבוא וישנה משהו בזיכרון... רק בנקודה הזו, מערכת ההפעלה מוצאת מקום חדש בזיכרון, יוצרת עותק של מה שהיה בו ומשנה את מה שהתהליך רצה לשנות\". לכן, התשובה הנכונה היא שהזיכרון משוכפל רק בעת ניסיון כתיבה לדף משותף."}, "_source_file": "0129__Virtualization__Copy-on-Write__MC__Easy.json", "_topic_hint": "Copy-on-Write", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:22:40", "_subject": "Virtualization", "_context_lectures": [8, 9, 4, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Copy-on-Write"], "difficulty_estimation": "Medium", "content": {"text": "מהי המטרה העיקרית של מנגנון ה-Copy-on-Write (CoW) בהקשר של יצירת תהליכים חדשים (לדוגמה, באמצעות fork())?", "code_snippet": null, "options": ["א. למנוע שכפול מיידי ויקר של זיכרון התהליך האב לתהליך הבן, ולאפשר שיתוף דפים עד שאחד התהליכים יבצע פעולת כתיבה.", "ב. לאחד את טבלאות הדפים של תהליך האב והבן לדף אחד בלבד, ובכך לחסוך מקום בזיכרון הפיזי.", "ג. לשפר את ביצועי הגישה לדיסק על ידי דחיית כתיבת דפים שהשתנו לדיסק עד שיתאספו מספיק שינויים.", "ד. להבטיח שכל תהליך בן יקבל עותק מלא ופרטי של כל דפי הזיכרון של האב מיד עם יצירתו, כדי למנוע התנגשויות."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. מנגנון ה-Copy-on-Write (CoW) נועד לשפר ביצועים ולחסוך במשאבי זיכרון בעת יצירת תהליכים חדשים (לדוגמה, באמצעות `fork()`). במקום לשכפל באופן מיידי את כל זיכרון האב לתהליך הבן, שהיא פעולה יקרה, מערכת ההפעלה מאפשרת לשני התהליכים לשתף את אותם דפי זיכרון פיזיים. שכפול בפועל של הדף מתבצע רק כאשר אחד התהליכים (האב או הבן) מנסה לבצע פעולת כתיבה על דף משותף זה. בשלב זה, מערכת ההפעלה יוצרת עותק פרטי של הדף עבור התהליך המבצע את הכתיבה, ומשנה את טבלת הדפים שלו כך שתצביע על העותק החדש. זאת כפי שמתואר בחומר ההרצאה: 'אחד הדברים שמערכת ההפעלה עושה בשביל לשפר ביצועים: אם זה עותק, לא צריך לשכפל בפועל את הזיכרון, זו פעולה יקרה. במקום זה ניתן לחסוך את ההעתקה הזו, ולהגדיר שהזיכרון הזה משותף לשני התהליכים (האב והבן), עד שאחד התהליכים יעשה פעולת write' (הרצאה 4, קטע 4).\nאפשרויות ב', ג' ו-ד' אינן נכונות:\nאפשרות ב' מתייחסת לאיחוד טבלאות דפים, בעוד שלכל תהליך יש טבלת דפים משלו (הרצאה 7, קטע 1). CoW אינו מאחד טבלאות דפים, אלא משנה את המיפויים בדפים בודדים לפי הצורך.\nאפשרות ג' מתארת מנגנון לשיפור ביצועי הגישה לדיסק באמצעות קיבוץ כתיבות (clustering), שאינו קשור ישירות ל-CoW אלא למנגנוני ניהול דיסק אחרים (הרצאה 8, קטע 41).\nאפשרות ד' מתארת את המצב ש-CoW נועד למנוע – שכפול מלא ומיידי של הזיכרון, שהיא פעולה יקרה ולא יעילה."}, "_source_file": "0130__Virtualization__Copy-on-Write__MC__Medium.json", "_topic_hint": "Copy-on-Write", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:22:57", "_subject": "Virtualization", "_context_lectures": [8, 9, 4, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Copy-on-Write"], "difficulty_estimation": "Medium", "content": {"text": "כיצד מנגנון Copy-on-Write (CoW) משפר את ביצועי מערכת ההפעלה בעת יצירת תהליך חדש (fork)?", "code_snippet": null, "options": ["א. הוא מונע שכפול פיזי מיידי של כל זיכרון תהליך האב לתהליך הבן, ובמקום זאת משתף דפים עד שאחד התהליכים מנסה לשנות אותם.", "ב. הוא טוען דפים מהדיסק ל-RAM בקבוצות גדולות יותר, ובכך מקטין את מספר פעולות הקריאה לדיסק.", "ג. הוא מאפשר לכל תהליך גישה בלעדית לטבלת דפים משלו, ובכך מבטיח הפרדה מלאה בזיכרון מרגע ה-fork.", "ד. הוא שומר דפים שהשתנו בזיכרון ומבצע כתיבה לדיסק רק כאשר מצטברים מספיק שינויים."]}, "solution": {"correct_option": "א", "explanation": "מנגנון Copy-on-Write (CoW) מיועד לשפר ביצועים בעת יצירת תהליך חדש באמצעות קריאת המערכת `fork`. במקום לשכפל באופן מיידי את כל מרחב הזיכרון של תהליך האב עבור תהליך הבן (שהיא פעולה יקרה), CoW מאפשר לשני התהליכים לשתף את אותם דפים פיזיים בזיכרון. השיתוף נמשך עד שאחד מהתהליכים (האב או הבן) מנסה לבצע פעולת כתיבה (write) לדף משותף. רק בנקודה זו, מערכת ההפעלה יוצרת עותק פרטי של הדף עבור התהליך המבקש לכתוב, ובכך נמנעת העתקה מיותרת של נתונים שאינם משתנים. אפשרות ב' ו-ד' מתארות מנגנונים של קיבוץ קריאות וכתיבות לדיסק (clustering), ואילו אפשרות ג' אינה מתארת את היתרון הספציפי של CoW, אלא היבט כללי של הפרדת טבלאות דפים, תוך התעלמות מהשיתוף הראשוני של הדפים הפיזיים."}, "_source_file": "0131__Virtualization__Copy-on-Write__MC__Medium.json", "_topic_hint": "Copy-on-Write", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:23:07", "_subject": "Virtualization", "_context_lectures": [8, 9, 4, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Copy-on-Write"], "difficulty_estimation": "Medium", "content": {"text": "בהקשר של יצירת תהליכים חדשים באמצעות `fork`, מהו העיקרון המרכזי של מנגנון Copy-on-Write (CoW)?", "code_snippet": null, "options": ["א. הזיכרון של תהליך האב ותהליך הבן משותף בתחילה, ועותק נפרד נוצר רק כאשר אחד מהם מנסה לבצע פעולת כתיבה לדף זיכרון משותף.", "ב. כל דפי הזיכרון של תהליך האב משוכפלים מיד לזיכרון נפרד עבור תהליך הבן בעת קריאה ל-`fork`.", "ג. רק דפים המכילים קוד הניתן לקריאה בלבד משותפים בין האב לבן, בעוד שדפי נתונים משוכפלים מיד.", "ד. מנגנון CoW מאפשר טעינה מקדימה של דפים מהדיסק ל-RAM כדי להאיץ את יצירת התהליך."]}, "solution": {"correct_option": "א", "explanation": "האפשרות הנכונה היא א'. מנגנון Copy-on-Write (CoW) נועד לשפר ביצועים בעת יצירת תהליכים חדשים (כמו ב-`fork`) על ידי הימנעות משכפול מיידי ויקר של כל זיכרון האב. במקום זאת, הזיכרון משותף בין תהליך האב לתהליך הבן. העותק הנפרד נוצר רק בנקודה שבה אחד התהליכים מנסה לשנות (לכתוב ל-) דף זיכרון משותף. כפי שמצוין בחומר ההרצאה (Lecture 4, chunk 4): 'אם זה עותק, לא צריך לשכפל בפועל את הזיכרון, זו פעולה יקרה. במקום זה ניתן לחסוך את ההעתקה הזו, ולהגדיר שהזיכרון הזה משותף לשני התהליכים (האב והבן), עד שאחד התהליכים יעשה פעולת write.' אפשרות ב' מתארת את המצב ללא CoW, שבו כל הזיכרון משוכפל מיד. אפשרות ג' אינה מדויקת, שכן CoW חל על כל דפי הזיכרון המשותפים ואינו מוגבל רק לדפים הניתנים לקריאה בלבד. אפשרות ד' מתייחסת לטעינת דפים מהדיסק, שאינה קשורה ישירות לעיקרון הפעולה של CoW בעת `fork`."}, "_source_file": "0132__Virtualization__Copy-on-Write__MC__Medium.json", "_topic_hint": "Copy-on-Write", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:23:19", "_subject": "Virtualization", "_context_lectures": [8, 9, 4, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Copy-on-Write"], "difficulty_estimation": "Hard", "content": {"text": "מערכת הפעלה המיישמת מנגנון Copy-on-Write (CoW) יוצרת תהליכי בן (child processes) על ידי שיתוף דפי זיכרון עם תהליך האב (parent process). בהתחשב בכך, איזו מהפעולות הבאות מהווה את המנגנון המרכזי שמופעל ברגע שתהליך בן מנסה לבצע פעולת כתיבה (write) לדף זיכרון משותף עם האב?", "code_snippet": null, "options": ["א. מערכת ההפעלה מבצעת page fault, מאתרת דף פיזי חדש, מעתיקה את תוכן הדף המשותף לדף החדש, ומעדכנת את טבלת הדפים של תהליך הבן כדי שתצביע על הדף החדש.", "ב. ה-MMU מזהה את ניסיון הכתיבה, מוחק את הדף המשותף מהזיכרון הפיזי, וטוען עותק חדש וריק של הדף מהדיסק עבור תהליך הבן.", "ג. תהליך הבן מקבל הודעת שגיאה (segmentation fault) והפעולה נכשלת, מכיוון שדפים משותפים אסורים בכתיבה.", "ד. מערכת ההפעלה מעדכנת ישירות את טבלת הדפים של תהליך הבן כך שהדף המשותף יהפוך להיות פרטי (private) ויאפשר כתיבה, ללא צורך בהעתקת תוכן."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. מנגנון Copy-on-Write (CoW) פועל כך: כאשר תהליך בן נוצר באמצעות fork, דפי הזיכרון של האב והבן משותפים, אך הם מסומנים כקריאה בלבד (read-only) עבור הבן. ברגע שתהליך הבן מנסה לכתוב לדף כזה, מתרחשת הפרה של הרשאת הזיכרון, מה שגורם ל-page fault. מערכת ההפעלה מיירטת את ה-page fault, מאתרת דף פיזי חדש פנוי, מעתיקה אליו את תוכן הדף המשותף המקורי, ולאחר מכן מעדכנת את טבלת הדפים (page table) של תהליך הבן כך שה-Page Table Entry (PTE) הרלוונטי יצביע על הדף הפיזי החדש והפרטי שלו. רק אז מתאפשרת פעולת הכתיבה לדף החדש. תהליך זה מתואר בחומר הלימוד: \"רק בנקודה הזו, מערכת ההפעלה מוצאת מקום חדש בזיכרון, יוצרת עותק של מה שהיה בו ומשנה את מה שהתהליך רצה לשנות.\" אפשרות ב' שגויה מכיוון שאין מחיקה של הדף המשותף או טעינה מהדיסק (במיוחד כשהחומר מציין שאין swapping). אפשרות ג' שגויה כיוון שמטרת CoW היא לאפשר כתיבה תוך שמירה על הפרדה. אפשרות ד' שגויה כיוון ששינוי מצביע בטבלת הדפים ללא העתקה פיזית של הנתונים יגרום לכך שהאב והבן יראו תוכן שונה מבלי שהנתונים הועתקו בפועל, וזה נוגד את עקרון הבידוד."}, "_source_file": "0133__Virtualization__Copy-on-Write__MC__Hard.json", "_topic_hint": "Copy-on-Write", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:23:38", "_subject": "Virtualization", "_context_lectures": [8, 9, 4, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Copy-on-Write"], "difficulty_estimation": "Hard", "content": {"text": "תהליך אב יוצר תהליכי בן באמצעות קריאת המערכת `fork`. נניח שלתהליך האב יש קוד בגודל 10 דפים בזיכרון ועוד 5 דפים של מחסנית. כמו כן, נתון שכל טבלת דפים תופסת דף אחד בזיכרון הפיזי. בהתבסס על מנגנון ה-Copy-on-Write (CoW), מהי כמות הזיכרון הפיזי המינימלית הנוספת שנדרשת *מיד* עם יצירת תהליך בן חדש, לפני שמתבצעות פעולות כתיבה כלשהן על ידי הבן?", "code_snippet": null, "options": ["א. דף אחד (עבור טבלת הדפים של הבן).", "ב. 6 דפים (דף אחד לטבלת הדפים ו-5 דפים למחסנית משוכפלת).", "ג. 16 דפים (10 דפים לקוד, 5 דפים למחסנית, ודף אחד לטבלת הדפים).", "ד. 15 דפים (10 דפים לקוד ו-5 דפים למחסנית)."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. מנגנון ה-Copy-on-Write (CoW) נועד לשפר ביצועים ולחסוך זיכרון פיזי בעת יצירת תהליכים חדשים באמצעות `fork`. במקום לשכפל באופן מיידי את כל זיכרון תהליך האב (כולל קוד ומחסנית) עבור תהליך הבן, CoW מאפשר לשני התהליכים לשתף את אותם דפים פיזיים בזיכרון. שכפול בפועל של דף מתרחש רק כאשר אחד התהליכים (האב או הבן) מנסה לבצע פעולת כתיבה לאותו דף, ובנקודה זו נוצר עותק של הדף הספציפי. לכן, מיד לאחר יצירת תהליך בן, הדפים המכילים את הקוד (10 דפים) והמחסנית (5 דפים) משותפים עם האב ואינם דורשים הקצאת זיכרון פיזי חדש. הדבר היחיד שכל תהליך בן חייב לקבל באופן ייחודי מיד עם יצירתו הוא טבלת דפים משלו, אשר על פי הנתון תופסת דף אחד בזיכרון הפיזי. לפיכך, הזיכרון הפיזי המינימלי הנוסף הנדרש עבור תהליך הבן הוא דף אחד בלבד עבור טבלת הדפים שלו."}, "_source_file": "0134__Virtualization__Copy-on-Write__MC__Hard.json", "_topic_hint": "Copy-on-Write", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:23:59", "_subject": "Virtualization", "_context_lectures": [8, 9, 4, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Copy-on-Write"], "difficulty_estimation": "Hard", "content": {"text": "בהינתן מערכת הפעלה המיישמת מנגנון Copy-on-Write (CoW) בעת יצירת תהליך בן באמצעות `fork()`. תהליך אב כולל 10 דפי קוד ו-5 דפי מחסנית. טבלת הדפים של תהליך נכנסת לדף זיכרון פיזי אחד. מהי כמות הזיכרון הפיזי המינימלית, במונחי דפים, שתהליך הבן יצרוך *מיד* לאחר קריאה ל-`fork()` (לפני ביצוע פעולות כתיבה כלשהן)?", "code_snippet": null, "options": ["א. דף אחד, המיועד לטבלת הדפים של תהליך הבן בלבד.", "ב. 6 דפים, הכוללים את טבלת הדפים ואת המחסנית.", "ג. 15 דפים, הכוללים את דפי הקוד והמחסנית של תהליך האב.", "ד. 11 דפים, הכוללים את דפי הקוד של תהליך האב וטבלת הדפים של תהליך הבן."]}, "solution": {"correct_option": "א", "explanation": "מנגנון Copy-on-Write (CoW) נועד לחסוך שכפול מיותר של דפי זיכרון יקרים בעת יצירת תהליך בן באמצעות `fork()`. במקום לשכפל מיד את כל דפי הזיכרון של האב (קוד, נתונים, מחסנית), תהליך הבן מקבל גישה לדפים הפיזיים המשותפים עם האב. השכפול בפועל של הדף מתבצע רק כאשר אחד התהליכים (האב או הבן) מנסה לבצע פעולת כתיבה לדף משותף.\n\nעם זאת, לכל תהליך חייבת להיות טבלת דפים משלו ('לכל תהליך יש טבלת דפים משלו'). טבלת הדפים הזו היא הכרחית למיפוי מרחב הכתובות הווירטואלי הייחודי של כל תהליך לזיכרון הפיזי. לכן, גם עם CoW, תהליך הבן יצרוך מיד דף זיכרון פיזי אחד עבור טבלת הדפים שלו, כפי שצוין גם בחומר הלימוד ('כל תהליך שנוצר גם צריך דף עבור טבלת הדפים שלו').\n\nדפי הקוד והמחסנית (10 ו-5 דפים בהתאמה) אינם משוכפלים מיד; הם משותפים בין האב לבן עד שמתבצעת פעולת כתיבה. לכן, כמות הזיכרון הפיזי המינימלית שתהליך הבן יצרוך מיד היא דף אחד בלבד עבור טבלת הדפים שלו."}, "_source_file": "0135__Virtualization__Copy-on-Write__MC__Hard.json", "_topic_hint": "Copy-on-Write", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:24:16", "_subject": "Virtualization", "_context_lectures": [8, 9, 4, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Address Space"], "difficulty_estimation": "Easy", "content": {"text": "מהם שני החלקים העיקריים המרכיבים כתובת וירטואלית לצורך תרגום כתובות?", "code_snippet": null, "options": ["א. מספר דף וירטואלי (VPN) והיסט (Offset)", "ב. מספר מסגרת פיזית (PFN) והיסט (Offset)", "ג. אינדקס ספריית דפים (Page Directory Index) ואינדקס טבלת דפים (Page Table Index)", "ד. גודל מרחב כתובות וירטואלי וגודל דף"]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה (במיוחד בפרקים 6.32 ו-7.19), כתובת וירטואלית מורכבת משני חלקים עיקריים: מספר הדף הוירטואלי (VPN) וההיסט (Offset). ה-VPN מצביע על הדף הוירטואלי הספציפי בזיכרון, וההיסט מציין את המיקום בתוך אותו דף. לדוגמה, בפרק 6.32 מוצגת כתובת וירטואלית המחולקת במפורש ל-VPN ול-Offset. אפשרויות ב', ג' ו-ד' אינן מתארות את שני החלקים העיקריים של הכתובת הוירטואלית עצמה; מספר מסגרת פיזית (PFN) הוא חלק מהכתובת הפיזית המתורגמת, ואינדקסים של ספריות וטבלאות דפים הם חלוקה פנימית של ה-VPN במקרה של טבלאות דפים רב-שכבתיות."}, "_source_file": "0136__Virtualization__Address_Space__MC__Easy.json", "_topic_hint": "Address Space", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:24:26", "_subject": "Virtualization", "_context_lectures": [5, 6, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Address Space"], "difficulty_estimation": "Easy", "content": {"text": "במערכת הפעלה המשתמשת בטבלאות דפים (paging), למה מחולקת בדרך כלל כתובת וירטואלית?", "code_snippet": null, "options": ["א. מספר דף וירטואלי (VPN) והיסט בתוך הדף (Offset).", "ב. מספר מסגרת פיזית (PFN) וגודל הזיכרון הפיזי.", "ג. כתובת התחלה של התוכנית וכתובת סיום של התוכנית.", "ד. גודל ה-Stack וגודל ה-Heap."]}, "solution": {"correct_option": "א", "explanation": "במערכת הפעלה המשתמשת בטבלאות דפים (paging), כתובת וירטואלית מחולקת לשני חלקים עיקריים: מספר דף וירטואלי (VPN) והיסט (Offset) בתוך הדף. ה-VPN משמש לאיתור הרשומה המתאימה בטבלת הדפים, שממנה נגזר מספר המסגרת הפיזית (PFN). ההיסט נשאר ללא שינוי ומשמש לאיתור המיקום הספציפי בתוך המסגרת הפיזית. חלוקה זו מתוארת בחומר ההרצאה, לדוגמה, במבנה הכתובת הוירטואלית המוצג ב-Lecture 6 (chunk 32) כ- \"VPN | Offset\". אפשרויות ב', ג' ו-ד' אינן מתארות את החלוקה הבסיסית של כתובת וירטואלית למטרות paging."}, "_source_file": "0137__Virtualization__Address_Space__MC__Easy.json", "_topic_hint": "Address Space", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:24:37", "_subject": "Virtualization", "_context_lectures": [5, 6, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Address Space"], "difficulty_estimation": "Easy", "content": {"text": "כיצד מחולקת כתובת וירטואלית על ידי יחידת ניהול הזיכרון (MMU) לצורך תרגום כתובות?", "code_snippet": null, "options": ["א. אינדקס ספריית דפים (Page Directory Index) ואינדקס טבלת דפים (Page Table Index)", "ב. מספר דף וירטואלי (VPN) והיסט (Offset)", "ג. מספר מסגרת פיזית (PFN) והיסט (Offset)", "ד. מצביע מחסנית (Stack Pointer) ומונה תוכנית (Program Counter)"]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר ההרצאה (Lecture 6, chunk 32), כתובת וירטואלית מחולקת לשני חלקים עיקריים: מספר דף וירטואלי (VPN) המזהה את הדף הוירטואלי, והיסט (Offset) המציין את המיקום בתוך הדף. חלוקה זו מאפשרת ל-MMU לאתר את הדף המתאים בטבלת הדפים ולאחר מכן למצוא את המיקום המדויק בתוך המסגרת הפיזית. אפשרות א' מתארת חלוקה נוספת של ה-VPN במקרה של טבלאות דפים היררכיות (Multi-Level Page Table), אך החלוקה הבסיסית ביותר של כתובת וירטואלית היא ל-VPN והיסט. אפשרות ג' מתארת את רכיבי הכתובת הפיזית, לא הוירטואלית. אפשרות ד' מתייחסת לרגיסטרים של המעבד ואינה קשורה לחלוקת כתובת וירטואלית לצורך תרגום."}, "_source_file": "0138__Virtualization__Address_Space__MC__Easy.json", "_topic_hint": "Address Space", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:24:47", "_subject": "Virtualization", "_context_lectures": [5, 6, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Address Space"], "difficulty_estimation": "Medium", "content": {"text": "מהי הסיבה העיקרית לשימוש בטבלת דפים היררכית (Multi-Level Page Table) במערכת ניהול זיכרון (MMU)?", "code_snippet": null, "options": ["א. כדי להפחית את כמות הזיכרון הפיזי הנדרשת לאחסון טבלת הדפים עצמה, במיוחד עבור מרחבי כתובות דלילים.", "ב. כדי להאיץ את תהליך התרגום של כל כתובת וירטואלית לכתובת פיזית.", "ג. כדי לאפשר לתהליכים שונים לחלוק את אותם דפים פיזיים ללא בעיות הגנה.", "ד. כדי להגדיל את הגודל הכולל של מרחב הכתובות הוירטואלי שתהליך יכול לגשת אליו."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מתאר את טבלת הדפים ההיררכית (Multi-Level Page table) כמבנה דמוי עץ, שבו ה-'page directory' מכיל מצביעים לכל החלקים של ה-'page table' (Lecture 7, chunk 16). מבנה היררכי זה נועד בעיקר לנהל ביעילות מרחבי כתובות וירטואליים גדולים. במקום שכל טבלת הדפים תהיה חייבת לשהות כולה בזיכרון הפיזי (מה שדורש כמות עצומה של זיכרון עבור מרחבי כתובות גדולים), טבלה רב-שכבתית מאפשרת לטעון לזיכרון הפיזי רק את החלקים הרלוונטיים של טבלת הדפים (כלומר, ה-'page directory' וטבלאות הדפים הספציפיות לאזורי זיכרון וירטואלי פעילים). זה מפחית באופן משמעותי את טביעת הרגל של טבלאות הדפים בזיכרון הפיזי, במיוחד כאשר מרחב הכתובות הוירטואלי של תהליך הוא דליל (כלומר, לא כל הדפים הווירטואליים ממופים או נמצאים בשימוש). לכן, אפשרות א' נכונה.\n\nאפשרות ב' אינה נכונה מכיוון שבדרך כלל, חיפוש רב-שכבתי כרוך במספר גישות לזיכרון (אחת עבור ה-'page directory', ואז אחת או יותר עבור טבלאות הדפים), מה שיכול להיות איטי יותר מחיפוש חד-שכבתי.\nאפשרות ג' מתארת תכונה כללית של דפדוף (paging), אך טבלאות דפים רב-שכבתיות אינן משפרות באופן ספציפי את השיתוף או ההגנה מעבר למה שטבלאות חד-שכבתיות מציעות; ההגנה מנוהלת באמצעות ביטים בתוך רשומות טבלת הדפים (PTEs).\nאפשרות ד' גם אינה נכונה. גודל מרחב הכתובות הוירטואלי נקבע על ידי מספר הביטים בכתובת הוירטואלית. בעוד שטבלאות דפים רב-שכבתיות מאפשרות לנהל מרחבי כתובות וירטואליים גדולים מאוד, הן אינן מגדילות את הגודל הטבוע; במקום זאת, הן הופכות את ניהול המרחבים הגדולים הללו לפרקטי על ידי חיסכון בזיכרון פיזי עבור טבלאות הדפים עצמן."}, "_source_file": "0139__Virtualization__Address_Space__MC__Medium.json", "_topic_hint": "Address Space", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:25:02", "_subject": "Virtualization", "_context_lectures": [5, 6, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Address Space"], "difficulty_estimation": "Medium", "content": {"text": "בהינתן מערכת המשתמשת בטבלת דפים רב-שכבתית (Multi-Level Page Table), עם מרחב כתובות וירטואלי בגודל 1GB, גודל דף של 512 בתים, ו-128 רשומות PTEs בכל דף, מהו מספר הביטים המוקצה לכל אחד מהרכיבים הבאים בכתובת וירטואלית: Offset, Page Table Index, ו-Page Directory Index?", "code_snippet": null, "options": ["א. Offset: 9 ביטים, Page Table Index: 7 ביטים, Page Directory Index: 14 ביטים.", "ב. Offset: 9 ביטים, Page Table Index: 14 ביטים, Page Directory Index: 7 ביטים.", "ג. Offset: 5 ביטים, Page Table Index: 7 ביטים, Page Directory Index: 18 ביטים.", "ד. Offset: 9 ביטים, Page Table Index: 8 ביטים, Page Directory Index: 13 ביטים."]}, "solution": {"correct_option": "א", "explanation": "הסבר מפורט:\n1.  **חישוב גודל ה-Offset:** גודל ה-Offset נקבע על ידי גודל הדף. גודל דף של 512 בתים הוא 2 בחזקת 9 (2^9), ולכן ה-Offset דורש 9 ביטים.\n2.  **חישוב גודל ה-VPN (Virtual Page Number):** מרחב הכתובות הוירטואלי הוא 1GB, שזה 2 בחזקת 30 (2^30) בתים. לכן, הכתובת הוירטואלית היא באורך 30 ביטים. גודל ה-VPN הוא סך הביטים בכתובת הוירטואלית פחות גודל ה-Offset: 30 - 9 = 21 ביטים.\n3.  **חישוב גודל ה-Page Table Index:** נתון שיש 128 רשומות PTEs בכל דף. 128 הוא 2 בחזקת 7 (2^7), ולכן ה-Page Table Index דורש 7 ביטים.\n4.  **חישוב גודל ה-Page Directory Index:** ה-Page Directory Index הוא יתר הביטים של ה-VPN לאחר שחישבנו את ה-Page Table Index: 21 - 7 = 14 ביטים.\n\nלכן, החלוקה הנכונה היא: Offset: 9 ביטים, Page Table Index: 7 ביטים, Page Directory Index: 14 ביטים. חלוקה זו תואמת במדויק לדוגמא המופיעה ב-Lecture 7, chunk 24, המדגימה את פירוק הכתובת הוירטואלית."}, "_source_file": "0140__Virtualization__Address_Space__MC__Medium.json", "_topic_hint": "Address Space", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:25:16", "_subject": "Virtualization", "_context_lectures": [5, 6, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Address Space"], "difficulty_estimation": "Medium", "content": {"text": "בהתבסס על קטע הקוד וההסברים שסופקו בחומר ההרצאה, היכן יאוחסן התוכן שאליו מצביע המשתנה `z` (כלומר `*z`) במרחב הכתובות הוירטואלי של התהליך?", "code_snippet": "int x;\nint main(int argc, char *argv[]) {\n    int y;\n    int *z = malloc(sizeof(int));\n}", "options": ["א. באזור ה-Text, שכן הוא מייצג קטע קוד של התוכנית.", "ב. באזור ה-Data, שכן הוא משתנה גלובלי או קבוע.", "ג. באזור ה-Stack, שכן המשתנה `z` עצמו הוא משתנה מקומי לפונקציה `main`.", "ד. באזור ה-Heap, שכן הזיכרון עבורו הוקצה באופן דינאמי באמצעות `malloc`."]}, "solution": {"correct_option": "ד", "explanation": "התשובה הנכונה היא ד'. על פי חומר ההרצאה (Lecture 5, chunk 24), המשתנה `z` עצמו הוא משתנה מקומי ולכן מאוחסן ב-Stack. עם זאת, התוכן שאליו מצביע `z` (כלומר `*z`) מוקצה באופן דינאמי באמצעות הפונקציה `malloc`. זיכרון המוקצה באופן דינאמי בזמן ריצה באמצעות `malloc` מאוחסן באזור ה-Heap של מרחב הכתובות הוירטואלי של התהליך. אפשרויות א' וב' שגויות מכיוון ש-`*z` אינו קוד ואינו משתנה גלובלי או קבוע. אפשרות ג' שגויה מכיוון שה-Stack מאחסן משתנים מקומיים וארגומנטים לפונקציות, אך לא את הזיכרון הדינאמי שאליו מצביע משתנה מקומי זה."}, "_source_file": "0141__Virtualization__Address_Space__MC__Medium.json", "_topic_hint": "Address Space", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:25:30", "_subject": "Virtualization", "_context_lectures": [5, 6, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Address Space"], "difficulty_estimation": "Hard", "content": {"text": "בהינתן מערכת המשתמשת בטבלת דפים היררכית (Multi-Level Page Table) כמתואר בחומר הלימוד, עם מרחב כתובות וירטואלי של 1GB (2^30), גודל דף של 512B (2^9), ו-128 רשומות לכל דף טבלת דפים (PTEs per page), מהו היתרון המרכזי של מבנה היררכי זה, בהשוואה לטבלת דפים בודדת (Single-Level Page Table) עבור מרחב כתובות וירטואלי בעל שימוש דליל (sparse)?", "code_snippet": null, "options": ["א. חיסכון משמעותי בזיכרון פיזי על ידי אי-הקצאת דפי טבלת דפים עבור חלקים לא בשימוש של מרחב הכתובות הוירטואלי.", "ב. קיצור זמן הגישה לזיכרון פיזי באמצעות צמצום מספר הגישות לטבלאות הדפים.", "ג. הגדלת מספר הדפים הפיזיים הזמינים למערכת על ידי שימוש יעיל יותר בביטים של הכתובת הווירטואלית.", "ד. פישוט תהליך ניהול ההחלפה (swapping) בין זיכרון פיזי לדיסק."]}, "solution": {"correct_option": "א", "explanation": "חומר הלימוד מתאר את טבלת הדפים ההיררכית (Multi-Level Page Table) כבעלת מבנה דמוי עץ, כאשר ה-Page Directory מכיל מצביעים לחלקים שונים של טבלת הדפים. יתרון מפתח של מבנה זה, במיוחד עבור מרחבי כתובות וירטואליים המשמשים באופן דליל (כלומר, רק חלקים קטנים ממרחב הכתובות הוירטואלי בשימוש פעיל), הוא היכולת שלא להקצות זיכרון פיזי עבור טבלאות דפים שלמות שאינן בשימוש. לדוגמה, אם אזור מסוים של מרחב הכתובות הוירטואלי אינו ממופה לשום דבר, אין צורך להקצות את דפי טבלת הדפים התואמים לו. אפשרות ב' שגויה מכיוון שטבלת דפים היררכית דווקא מגדילה את מספר הגישות לזיכרון לצורך תרגום כתובות (לדוגמה, גישה ל-Page Directory ולאחר מכן ל-Page Table). אפשרויות ג' ו-ד' אינן יתרונות ישירים או מרכזיים של מבנה טבלת דפים היררכית כפי שמתואר בחומר."}, "_source_file": "0142__Virtualization__Address_Space__MC__Hard.json", "_topic_hint": "Address Space", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:25:51", "_subject": "Virtualization", "_context_lectures": [5, 6, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Address Space"], "difficulty_estimation": "Hard", "content": {"text": "בהינתן המאפיינים הבאים עבור מרחב כתובות וירטואלי במערכת המשתמשת בטבלת דפים היררכית (Multi-Level Page Table), ובהנחה שכל טבלאות הדפים מאוכלסות במלואן:\n*   גודל מרחב כתובות וירטואלי: 16KB\n*   גודל דף: 32B\n*   גודל רשומת טבלת דפים (PTE): 2B\n*   ב-Page Directory יש 32 רשומות, וגודל כל רשומה בה הוא 2 בתים.\n\nמהו סך הזיכרון (בבתים) הנדרש לאחסון כל מבני טבלת הדפים (ה-Page Directory וכל טבלאות הדפים מהרמה השנייה) עבור תהליך בודד?", "code_snippet": null, "options": ["א. 1088 בתים", "ב. 512 בתים", "ג. 1024 בתים", "ד. 64 בתים"]}, "solution": {"correct_option": "א", "explanation": "כדי לחשב את סך הזיכרון הנדרש למבני טפי הדפים, עלינו לנתח את חלוקת הביטים בכתובת הוירטואלית ולחשב את גודל כל רמה בטבלה ההיררכית:\n\n1.  **חישוב ביטי הכתובת הוירטואלית וההיסט:**\n    *   מרחב כתובות וירטואלי: 16KB = 2^14 בתים. לכן, כתובת וירטואלית היא באורך 14 ביטים.\n    *   גודל דף: 32B = 2^5 בתים. לכן, ההיסט (Offset) הוא באורך 5 ביטים.\n    *   מספר ביטים ל-Virtual Page Number (VPN): 14 ביטים (סה\"כ) - 5 ביטים (היסט) = 9 ביטים.\n\n2.  **חישוב ביטי ה-Page Directory Index:**\n    *   נתון שב-Page Directory יש 32 רשומות. 32 = 2^5. לכן, ה-Page Directory Index הוא באורך 5 ביטים.\n\n3.  **חישוב ביטי ה-Page Table Index:**\n    *   מכיוון שה-VPN הוא 9 ביטים וה-Page Directory Index הוא 5 ביטים, הרי שה-Page Table Index הוא 9 ביטים - 5 ביטים = 4 ביטים.\n    *   כל טבלת דפים ברמה השנייה מכילה 2^4 = 16 רשומות PTE.\n\n4.  **חישוב גודל ה-Page Directory:**\n    *   מספר רשומות ב-Page Directory: 32.\n    *   גודל רשומה ב-Page Directory: 2 בתים (לפי הנתון).\n    *   גודל ה-Page Directory = 32 רשומות * 2 בתים/רשומה = 64 בתים.\n\n5.  **חישוב גודל טבלאות הדפים ברמה השנייה:**\n    *   מספר טבלאות דפים ברמה השנייה: מכיוון שה-Page Directory מאוכלס במלואו, ישנן 32 טבלאות דפים ברמה השנייה (אחת לכל רשומה ב-Page Directory).\n    *   גודל טבלת דפים אחת ברמה השנייה: 16 רשומות PTE * 2 בתים/PTE = 32 בתים.\n    *   גודל כולל של כל טבלאות הדפים ברמה השנייה = 32 טבלאות * 32 בתים/טבלה = 1024 בתים.\n\n6.  **סך הזיכרון הנדרש:**\n    *   סה\"כ = גודל ה-Page Directory + גודל טבלאות הדפים ברמה השנייה = 64 בתים + 1024 בתים = 1088 בתים.\n\nלכן, התשובה הנכונה היא א'."}, "_source_file": "0143__Virtualization__Address_Space__MC__Hard.json", "_topic_hint": "Address Space", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:26:14", "_subject": "Virtualization", "_context_lectures": [5, 6, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Virtualization", "topic": ["Address Space"], "difficulty_estimation": "Hard", "content": {"text": "בהתבסס על מערכת זיכרון וירטואלי המשתמשת בטבלת דפים היררכית (Multi-Level Page Table), נתונים הפרטים הבאים:\n*   מרחב כתובות וירטואלי: 1GB (2³⁰)\n*   גודל דף: 512B (2⁹)\n*   מספר רשומות PTEs לכל דף: 128 (2⁷)\nבהינתן חלוקה זו, כמה רשומות (entries) יכולה להכיל טבלת ה-Page Directory?", "code_snippet": null, "options": ["א. 2¹⁴", "ב. 2²¹", "ג. 2⁷", "ד. 2⁹"]}, "solution": {"correct_option": "א", "explanation": "הסבר:\n1.  מרחב הכתובות הוירטואלי הוא 1GB, כלומר 2 בחזקת 30 בתים, ולכן כתובת וירטואלית מיוצגת על ידי 30 ביטים.\n2.  גודל הדף הוא 512B, כלומר 2 בחזקת 9 בתים, ולכן ההיסט (Offset) דורש 9 ביטים.\n3.  מספר הביטים של ה-Virtual Page Number (VPN) הוא סך הביטים פחות ביטי ההיסט: 30 - 9 = 21 ביטים.\n4.  המערכת משתמשת בטבלת דפים היררכית (Multi-Level Page Table). הנתון \"מספר רשומות PTEs לכל דף: 128 (2⁷)\" אומר שכל טבלת דפים מהרמה השנייה (Page Table), שנמצאת בעצמה בדף זיכרון אחד, יכולה להכיל 2 בחזקת 7 רשומות. משמעות הדבר היא שאינדקס ה-Page Table (החלק ב-VPN שמצביע על רשומה בתוך טבלת דפים ספציפית) דורש 7 ביטים.\n5.  את יתרת הביטים של ה-VPN משמשים לאינדקס ה-Page Directory. מספר הביטים לאינדקס ה-Page Directory הוא: 21 (VPN ביטים) - 7 (Page Table Index ביטים) = 14 ביטים.\n6.  מספר הרשומות שיכולה להכיל טבלת ה-Page Directory הוא 2 בחזקת מספר הביטים של האינדקס שלה. לכן, 2 בחזקת 14 רשומות.\nהאפשרות הנכונה היא א'."}, "_source_file": "0144__Virtualization__Address_Space__MC__Hard.json", "_topic_hint": "Address Space", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:26:33", "_subject": "Virtualization", "_context_lectures": [5, 6, 7]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Threads"], "difficulty_estimation": "Easy", "content": {"text": "מהי ההתנהגות של חוט (thread) שקורא לפונקציה `pthread_join`?", "code_snippet": null, "options": ["א. החוט הקורא הופך חסום (blocked) וממתין עד שהחוט שצוין כארגומנט יסיים את ריצתו.", "ב. החוט הקורא ממשיך לרוץ במקביל לחוט שצוין, ללא המתנה.", "ג. החוט הקורא מסיים את התהליך כולו באופן מיידי.", "ד. החוט הקורא מבטל את ריצת החוט שצוין ומסיים אותו."]}, "solution": {"correct_option": "א", "explanation": "כפי שנלמד בחומר ההרצאה, כאשר חוט קורא לפונקציה `pthread_join(th, ...)`, החוט הקורא (החוט שביצע את הקריאה) הופך להיות חסום (blocked) והוא ממתין עד שהחוט שצוין כארגומנט (`th`) יסיים את ריצתו. רק לאחר שהחוט הממתין לו מסיים, החוט הקורא ממשיך בביצוע השורות הבאות בקוד. אפשרות ב' אינה נכונה מכיוון ש-`pthread_join` היא פונקציית המתנה. אפשרות ג' אינה נכונה מכיוון שסיום תהליך שלם אינו ההתנהגות הישירה של `pthread_join`. אפשרות ד' מתארת את `pthread_cancel` ולא את `pthread_join`."}, "_source_file": "0145__Concurrency__Threads__MC__Easy.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:26:42", "_subject": "Concurrency", "_context_lectures": [10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Threads"], "difficulty_estimation": "Easy", "content": {"text": "איזו מהטענות הבאות נכונה לגבי הפונקציה `pthread_join`?", "code_snippet": null, "options": ["א. כל חוט יכול לעשות join לכל חוט אחר באותו תהליך.", "ב. רק חוט אב יכול לעשות join לחוט ילד.", "ג. קריאה ל-`pthread_join` גורמת לחוט שאליו מצטרפים להיחסם.", "ד. הפונקציה `pthread_join` משמשת ליצירת חוט חדש בתהליך."]}, "solution": {"correct_option": "א", "explanation": "החומר המצורף מציין במפורש: \"כל חוט יכול לעשות join לכל חוט אחר באותו תהליך, ולא צריך יחסי אב וילדים.\" לכן, אפשרות א' נכונה. אפשרות ב' שגויה מכיוון שאין צורך ביחסי אב-ילד. אפשרות ג' שגויה, שכן החוט שקורא ל-`pthread_join` הוא זה שנחסם וממתין, ולא החוט שאליו מצטרפים. אפשרות ד' שגויה, `pthread_join` ממתינה לסיום חוט קיים, בעוד ש-`pthread_create` היא הפונקציה ליצירת חוט חדש."}, "_source_file": "0146__Concurrency__Threads__MC__Easy.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:26:50", "_subject": "Concurrency", "_context_lectures": [10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Threads"], "difficulty_estimation": "Easy", "content": {"text": "מהי ההשפעה העיקרית של קריאה לפונקציה `pthread_join` על החוט המבצע את הקריאה?", "code_snippet": "int pthread_join(\n    pthread_t th,\n    void **thread_return);", "options": ["א. החוט המבצע את הקריאה ממשיך בריצה רגילה במקביל לחוט שעבורו נקראה הפונקציה.", "ב. החוט המבצע את הקריאה נחסם (blocked) וממתין עד שהחוט שעבורו נקראה הפונקציה יסיים את ריצתו.", "ג. החוט שעבורו נקראה הפונקציה נחסם באופן מיידי וממתין לאישור מהחוט המבצע את הקריאה.", "ד. החוט המבצע את הקריאה מסיים את ריצתו באופן מיידי."]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר ההרצאה, כאשר חוט מבצע קריאה לפונקציה `pthread_join`, הוא 'הופך להיות blocked כלומר הוא נחסם והוא מחכה' עד שהחוט שעבורו נקראה הפונקציה יסיים את ריצתו. רק לאחר שהחוט הממתין לו מסיים, החוט הקורא ממשיך בביצוע. האפשרויות האחרות אינן מתארות נכונה את התנהגות `pthread_join`."}, "_source_file": "0147__Concurrency__Threads__MC__Easy.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:27:00", "_subject": "Concurrency", "_context_lectures": [10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Threads"], "difficulty_estimation": "Medium", "content": {"text": "איזו טענה נכונה לגבי השימוש בפונקציה pthread_join בהקשר של חוטים באותו תהליך?", "code_snippet": null, "options": ["א. רק חוטים שנוצרו על ידי חוט האב יכולים להצטרף (join) אליו.", "ב. כל חוט בתהליך יכול להצטרף (join) לכל חוט אחר באותו תהליך, ללא צורך ביחסי אב וילד.", "ג. קריאה ל-pthread_join חוסמת את החוט הקורא רק אם לחוט המצטרף יש ערך החזר.", "ד. pthread_join משמשת בעיקר לביטול חוטים (cancel threads) ואינה גורמת לחסימה."]}, "solution": {"correct_option": "ב", "explanation": "התשובה הנכונה היא ב'. לפי חומר ההרצאה, 'כל חוט יכול לעשות join לכל חוט אחר באותו תהליך, ולא צריך יחסי אב וילדים'. אפשרות א' אינה נכונה מכיוון שהיא מציגה הגבלה של יחסי אב-ילד שאינה קיימת עבור pthread_join. אפשרות ג' אינה נכונה מכיוון שקריאה ל-pthread_join תמיד חוסמת את החוט הקורא עד שהחוט המיועד מסתיים, ללא קשר לשאלה אם יש ערך החזר או אם הוא נאסף, כפי שמצוין בחומר: 'הופך להיות blocked כלומר הוא נחסם והוא מחכה'. אפשרות ד' אינה נכונה מכיוון ש-pthread_join נועדה להמתין לסיום חוטים ולחסום את החוט הקורא, בעוד שביטול חוטים מתבצע באמצעות פונקציה אחרת (pthread_cancel)."}, "_source_file": "0148__Concurrency__Threads__MC__Medium.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:27:14", "_subject": "Concurrency", "_context_lectures": [10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Threads"], "difficulty_estimation": "Medium", "content": {"text": "איזו מהטענות הבאות מתארת בצורה הנכונה ביותר את אופן הפעולה והמאפיינים של הפונקציה `pthread_join`?", "code_snippet": "pthread_t thread_id;\nvoid *thread_result;\n\n// ... יצירת thread_id ...\n\nint status = pthread_join(thread_id, &thread_result);\n// לאחר שורה זו, thread_id סיים את ריצתו, וערך ההחזר שלו נמצא ב-thread_result", "options": ["א. חוט המבצע קריאה ל-`pthread_join` נחסם (blocked) וממתין עד שהחוט שאליו הוא מצטרף (th) יסיים את ריצתו. כל חוט בתוך התהליך יכול לבצע join לכל חוט אחר באותו תהליך.", "ב. הפונקציה `pthread_join` מאפשרת לחוט הקורא להמשיך בריצתו באופן אסינכרוני תוך כדי בדיקה תקופתית אם החוט שאליו הוא מצטרף סיים, בדומה ל-busy-waiting.", "ג. `pthread_join` יכולה להתבצע רק על ידי חוט האב (parent thread) שייצר את חוט הילד (child thread), ובכך לקבל את ערך ההחזר שלו.", "ד. קריאה ל-`pthread_join` תמיד גורמת לסיום מיידי של התהליך כולו ברגע שהחוט שאליו הצטרפו סיים, ללא קשר לסטטוס של חוטים אחרים בתהליך."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה, כאשר חוט מבצע קריאה ל-`pthread_join`, 'הוא הופך להיות blocked כלומר הוא נחסם והוא מחכה' עד שהחוט המיועד יסיים את ריצתו. בנוסף, חומר ההרצאה מציין במפורש כי 'כל חוט יכול לעשות join לכל חוט אחר באותו תהליך, ולא צריך יחסי אב וילדים'.\n\nתשובה ב' שגויה מכיוון ש-`pthread_join` היא קריאה חוסמת (blocking) ולא אסינכרונית או מבוססת busy-waiting. busy-waiting הוא מנגנון סנכרון שונה המוצג בחומר ההרצאה (במנגנון הדגלים), אך אינו קשור לאופן הפעולה של `pthread_join`.\n\nתשובה ג' שגויה מכיוון שחומר ההרצאה קובע במפורש כי 'כל חוט יכול לעשות join לכל חוט אחר באותו תהליך, ולא צריך יחסי אב וילדים', מה שמפריך את הטענה שרק חוט אב יכול לבצע join על חוט ילד.\n\nתשובה ד' שגויה מכיוון ש-`pthread_join` גורמת לחוט הקורא להמתין לחוט ספציפי אחד בלבד, ואינה גורמת בהכרח לסיום מיידי של התהליך כולו. סיום התהליך תלוי בגורמים אחרים, כמו קריאה ל-`exit()` מכל חוט, או במקרה מיוחד של `pthread_exit` מהחוט הראשי הממתין לסיום כל החוטים האחרים, אך לא `pthread_join`."}, "_source_file": "0149__Concurrency__Threads__MC__Medium.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:27:31", "_subject": "Concurrency", "_context_lectures": [10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Threads"], "difficulty_estimation": "Medium", "content": {"text": "איזו מהטענות הבאות מתארת נכונה את פעולת הפונקציה pthread_join?", "code_snippet": null, "options": ["א. הפונקציה גורמת לחוט הקורא להיחסם (blocked) עד שהחוט המיועד (target thread) מסיים את ריצתו.", "ב. הפונקציה מאפשרת לחוט אב בלבד להמתין לסיום ריצתם של חוטי הבן שלו.", "ג. הפונקציה מיועדת ליצירת חוט חדש בתוך התהליך הנוכחי.", "ד. הפונקציה מביאה לסיום מיידי של החוט המיועד, ללא קשר למצב ריצתו."]}, "solution": {"correct_option": "א", "explanation": "התשובה הנכונה היא א'. על פי חומר ההרצאה (Lecture 10, chunk 31), כאשר חוט מבצע קריאה ל-pthread_join, הוא \"הופך להיות blocked כלומר הוא נחסם והוא מחכה\" עד שהחוט שהועבר כארגומנט יסיים את ריצתו. טענה ב' אינה נכונה, מכיוון שחומר ההרצאה מציין במפורש: \"כל חוט יכול לעשות join לכל חוט אחר באותו תהליך, ולא צריך יחסי אב וילדים\" (Lecture 10, chunk 32). טענה ג' אינה נכונה; pthread_join משמשת להמתנה לסיום חוט קיים, ולא ליצירת חוט חדש (לשם כך קיימת pthread_create). טענה ד' אינה נכונה; pthread_join אינה מביאה לסיום מיידי של חוט, אלא ממתינה לסיום הטבעי שלו או לסיום מבוקר על ידי pthread_exit. הפסקת חוט באופן מיידי מתבצעת על ידי pthread_cancel."}, "_source_file": "0150__Concurrency__Threads__MC__Medium.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:27:41", "_subject": "Concurrency", "_context_lectures": [10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Threads"], "difficulty_estimation": "Hard", "content": {"text": "נתון קטע הקוד הבא:\n```c\n#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n\nvoid* worker_thread(void* arg) {\n    printf(\"Worker thread: Starting work...\\n\");\n    sleep(5); // Simulate long computation\n    printf(\"Worker thread: Done.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid;\n    printf(\"Main thread: Creating worker thread.\\n\");\n    pthread_create(&tid, NULL, worker_thread, NULL);\n    printf(\"Main thread: Calling pthread_exit().\\n\");\n    pthread_exit(NULL); // Key point\n    printf(\"Main thread: This line will not be reached.\\n\");\n    return 0;\n}\n```\nבהתבסס על קטע הקוד שלעיל והבנתך את אופן פעולת `pthread_exit()` כאשר הוא נקרא מהחוט הראשי, מה תהיה התוצאה הסופית של התהליך?", "code_snippet": "#include <pthread.h>\n#include <stdio.h>\n#include <unistd.h>\n\nvoid* worker_thread(void* arg) {\n    printf(\"Worker thread: Starting work...\\n\");\n    sleep(5); // Simulate long computation\n    printf(\"Worker thread: Done.\\n\");\n    return NULL;\n}\n\nint main() {\n    pthread_t tid;\n    printf(\"Main thread: Creating worker thread.\\n\");\n    pthread_create(&tid, NULL, worker_thread, NULL);\n    printf(\"Main thread: Calling pthread_exit().\\n\");\n    pthread_exit(NULL); // Key point\n    printf(\"Main thread: This line will not be reached.\\n\");\n    return 0;\n}", "options": ["א. התהליך יסתיים מיד לאחר קריאת `pthread_exit()` בחוט הראשי, ולפני שהחוט `worker_thread` יסיים את פעולתו.", "ב. התהליך ימשיך לרוץ עד שכל החוטים שאינם החוט הראשי (במקרה זה, `worker_thread`) יסיימו את פעולתם, ורק אז התהליך יסתיים.", "ג. הקריאה ל-`pthread_exit()` בחוט הראשי תגרום לשגיאת זמן ריצה (runtime error) מכיוון שחוט ראשי אינו יכול לצאת לפני שכל החוטים הצאצאים שלו סיימו.", "ד. החוט הראשי ימתין באופן פעיל (busy-wait) עד ש-`worker_thread` יסיים את פעולתו, ואז התהליך יסתיים."]}, "solution": {"correct_option": "ב", "explanation": "החומר המצורף מציין במפורש: \"מקרה אחד מיוחד: כשהחוט הראשי קורא ל-()pthread_exit, כלומר כאשר החוט הראשי מסתיים ע\"י הקריאה הזו, הוא לא מסיים את התהליך. מערכת ההפעלה מחכה עד שכל החוטים בתהליך הזה יסיימו ורק אז התהליך יסתיים. כלומר, כאשר החוט הראשי קורא לקריאה זו, הוא מסיים מבלי לסיים את התהליך.\" בהתאם לכך, בקטע הקוד הנתון, החוט הראשי קורא ל-`pthread_exit(NULL)` אך התהליך כולו לא יסתיים מיד. במקום זאת, מערכת ההפעלה תאפשר לחוט `worker_thread` להמשיך בריצתו ולסיים את פעולתו (כולל ההמתנה של 5 השניות). רק לאחר שכל החוטים שאינם הראשי (במקרה זה, `worker_thread`) יסיימו, התהליך כולו יסתיים. זאת בניגוד לקריאה ל-`exit()` מכל חוט, שהייתה גורמת לסיום מיידי של כל התהליך וכל החוטים שבו."}, "_source_file": "0151__Concurrency__Threads__MC__Hard.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:27:57", "_subject": "Concurrency", "_context_lectures": [10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Threads"], "difficulty_estimation": "Hard", "content": {"text": "בהינתן תהליך המכיל מספר חוטים (threads), כולל חוט ראשי (main thread) וחוטי עבודה (worker threads), ובהתבסס על מנגנוני הסיום וההמתנה של חוטים, איזו מהטענות הבאות נכונה ביותר?", "code_snippet": null, "options": ["א. חוט עבודה יכול להמתין לסיום של חוט עבודה אחר באמצעות pthread_join, וזאת ללא קשר ליחסי אב-בן ביניהם. אם החוט הראשי יקרא ל-pthread_exit, הוא יסיים את פעולתו אך התהליך ימתין לסיום כל חוטי העבודה לפני שיסתיים.", "ב. רק החוט הראשי יכול להמתין לסיום של חוטי עבודה באמצעות pthread_join. אם חוט כלשהו, כולל החוט הראשי, יקרא ל-exit(), רק אותו חוט יסיים את פעולתו בעוד שאר החוטים ימשיכו לרוץ עד לסיום טבעי או קריאה ל-pthread_exit מצידם.", "ג. במימוש של User Threads, מערכת ההפעלה מודעת לכל החוטים הפועלים בתוך תהליך ומבצעת את תזמונם, אך היא אינה מאפשרת לחוטים להמתין זה לזה באמצעות pthread_join כיוון שאין להם מזהים ייחודיים ברמת הליבה.", "ד. קריאה ל-pthread_join תמיד חוסמת את התהליך כולו עד שהחוט המיועד מסתיים. אם החוט הראשי קורא ל-pthread_exit, כל החוטים האחרים בתהליך יסיימו באופן מיידי כדי למנוע מצב של חוטים יתומים."]}, "solution": {"correct_option": "א", "explanation": "הטענה הנכונה ביותר היא א'. לפי חומר ההרצאה (chunk 32), 'כל חוט יכול לעשות join לכל חוט אחר באותו תהליך, ולא צריך יחסי אב וילדים'. זה מאשר שחוט עבודה יכול להמתין לחוט עבודה אחר. בנוסף, חומר ההרצאה (chunk 40) מציין במפורש כי 'כאשר החוט הראשי קורא ל-()pthread_exit... הוא לא מסיים את התהליך. מערכת ההפעלה מחכה עד שכל החוטים בתהליך הזה יסיימו ורק אז התהליך יסתיים'.\n\nטענה ב' אינה נכונה מכיוון ש'כל חוט יכול לעשות join לכל חוט אחר' (chunk 32), ולא רק החוט הראשי. כמו כן, 'exit() on any thread will exit all threads!' (chunk 40), ולא רק החוט הקורא.\n\nטענה ג' אינה נכונה מכיוון שבמימוש של User Threads, 'מערכת ההפעלה לא מכירה חוטים, אלא רק תהליכים' (chunk 17), ולכן היא אינה מודעת לכל החוטים ואינה מתזמנת אותם ברמת הליבה.\n\nטענה ד' אינה נכונה מכיוון ש-pthread_join חוסם את ה'חוט שביצע את הקריאה' (chunk 31) ולא את התהליך כולו. כמו כן, כפי שהוזכר לעיל, קריאה ל-pthread_exit מהחוט הראשי גורמת למערכת ההפעלה להמתין לסיום כל החוטים, ולא לסיום מיידי שלהם."}, "_source_file": "0152__Concurrency__Threads__MC__Hard.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:28:15", "_subject": "Concurrency", "_context_lectures": [10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Threads"], "difficulty_estimation": "Hard", "content": {"text": "בהתייחס למימוש חוטים ברמת המשתמש (User Threads), מהי ההשלכה העיקרית על תהליך המכיל חוטים כאלה, כאשר אחד מחוטיו מבצע קריאת מערכת חוסמת (blocking system call)?", "code_snippet": null, "options": ["א. רק החוט שביצע את הקריאה החוסמת ייחסם, וספריית החוטים ברמת המשתמש תעביר את בקרת המעבד לחוט משתמש אחר באותו התהליך.", "ב. התהליך כולו ייחסם, שכן מבחינת מערכת ההפעלה, היא רואה רק את התהליך כיחידת ביצוע אחת ואינה מודעת לחוטים הפנימיים שלו.", "ג. מערכת ההפעלה תזהה את החסימה ותמיר באופן אוטומטי את חוט המשתמש לחוט ליבה, כדי לאפשר לחוטים אחרים באותו תהליך להמשיך לרוץ.", "ד. ספריית החוטים תבקש ממערכת ההפעלה לבצע קריאת מערכת לא חוסמת במקום, כדי למנוע את חסימת התהליך."]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר ההרצאה, במימוש חוטים ברמת המשתמש (User Threads), 'מערכת ההפעלה לא מכירה חוטים, אלא רק תהליכים והיא מנהלת תהליכים'. המשמעות היא שמבחינת מערכת ההפעלה, 'אין דבר כזה חוטים, יש תהליך שמריץ דבר אחד בכל רגע נתון'. כאשר חוט משתמש אחד מבצע קריאת מערכת חוסמת (blocking system call), מערכת ההפעלה רואה זאת כפעולה חוסמת של התהליך כולו, שכן היא אינה מבחינה בחוטים בודדים בתוך התהליך. לכן, התהליך כולו ייחסם עד להשלמת קריאת המערכת, וזוהי הסיבה המצוינת בחומר ההרצאה כ'חיסרון בגישה' במקרים של 'פעולה שהיא blocking'."}, "_source_file": "0153__Concurrency__Threads__MC__Hard.json", "_topic_hint": "Threads", "_requested_type": "MultipleChoice", "_requested_difficulty": "Hard", "_generated_at": "2026-02-14 17:28:38", "_subject": "Concurrency", "_context_lectures": [10, 11]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Multi-core Processors"], "difficulty_estimation": "Easy", "content": {"text": "מהו אחד היתרונות המרכזיים של תזמון מעבדים מרובי תורים (Multi-queue multiprocessor scheduling) במערכות מרובות ליבות, כפי שמתואר בחומר הלימוד?", "code_snippet": null, "options": ["א. הוא מאפשר לכל המעבדים לשתף תור עבודה יחיד ביעילות.", "ב. הוא משפר באופן טבעי את ה-cache affinity (זיקת מטמון).", "ג. הוא מבטל את הצורך בחוטי ליבה (kernel threads).", "ד. הוא מפחית את מספר ה-context switches הנדרשים בין תהליכים שונים."]}, "solution": {"correct_option": "ב", "explanation": "על פי חומר הלימוד (Lecture 15, chunk 29), אחד היתרונות המרכזיים של תזמון מעבדים מרובי תורים (Multi-queue multiprocessor scheduling) הוא שיש לו 'cache affinity באופן טבעי: ברגע שג'וב מסוים מגיע, הוא מקבל תור, משויך למעבד ותמיד הוא יורץ על אותו המעבד.' יתרון זה מודגש כפתרון לבעיות שהיו בתזמונים קודמים בהקשר של זיקת מטמון. אפשרות א' אינה נכונה מכיוון שתזמון מרובה תורים פירושו שלכל מעבד יש תור משלו, ולא תור משותף. אפשרויות ג' ו-ד' אינן מוזכרות כיתרונות מרכזיים או ישירים של שיטה זו בחומר הלימוד."}, "_source_file": "0154__Concurrency__Multi-core_Processors__MC__Easy.json", "_topic_hint": "Multi-core Processors", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:28:48", "_subject": "Concurrency", "_context_lectures": [10, 12, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Multi-core Processors"], "difficulty_estimation": "Easy", "content": {"text": "איזו גישת תזמון במערכות מרובות מעבדים (multi-core processors) משפרת באופן טבעי את ה-cache affinity?", "code_snippet": null, "options": ["א. תזמון המעביר ג'ובים בין מעבדים שונים בכל קוואנטה.", "ב. תזמון המשתמש בתור משימות יחיד עבור כל המעבדים.", "ג. תזמון מרובה תורים למעבדים (Multi-queue multiprocessor scheduling), שבו לכל מעבד יש תור משלו.", "ד. תזמון שבו כל חוט (thread) מומר לתהליך (process) נפרד לפני ריצה."]}, "solution": {"correct_option": "ג", "explanation": "על פי חומר ההרצאה, תזמון מרובה תורים למעבדים (Multi-queue multiprocessor scheduling) מטפל בבעיית ה-cache affinity באופן טבעי. בגישה זו, לכל מעבד יש תור משלו, וברגע שג'וב מגיע הוא משויך לתור של מעבד ספציפי ורץ תמיד על אותו המעבד. דבר זה מבטיח שהנתונים שהג'וב משתמש בהם יישארו במטמון הפרטי של אותו מעבד (cache affinity), ובכך משפר את ביצועי המערכת. לעומת זאת, גישות כמו תזמון המעביר ג'ובים בין מעבדים (כמו SQMS שהוזכר כבעל cache affinity גרוע) פוגעות ב-cache affinity."}, "_source_file": "0155__Concurrency__Multi-core_Processors__MC__Easy.json", "_topic_hint": "Multi-core Processors", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:28:58", "_subject": "Concurrency", "_context_lectures": [10, 12, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Multi-core Processors"], "difficulty_estimation": "Easy", "content": {"text": "מהו היתרון העיקרי בשמירה על 'זיקת מטמון' (cache affinity) במערכת מרובת ליבות?", "code_snippet": null, "options": ["א. שיפור ביצועים על ידי גישה מהירה יותר לנתונים מהמטמון המקומי של המעבד.", "ב. הפחתת עומס החלפת ההקשר (context switch) בין תהליכים.", "ג. פישוט התקשורת בין תהליכים (IPC).", "ד. הבטחת מקביליות אמיתית לכל ה-threads במערכת."]}, "solution": {"correct_option": "א", "explanation": "על פי חומר ההרצאה, 'אידיאלית, היינו רוצים תזמון כזה ששומר על cache affinity (כלומר שתהליך ירוץ על המעבד הראשון שהריץ אותו)'. הסיבה לכך היא שלכל מעבד במערכת מרובת ליבות יש מטמון (cache L1) פרטי ומהיר משלו. שמירה על זיקת מטמון מבטיחה שהתהליך ימשיך לרוץ על אותו מעבד, וכך הנתונים שהוא זקוק להם יימצאו כבר במטמון המקומי והמהיר של אותו מעבד. זה מוביל ל'זיכרון של התוכנית שלנו נראה מהיר', ובכך לשיפור בביצועים, מכיוון ש'אם כל פעם שהיינו קוראים מהזיכרון, המעבד באמת היה ניגש לזיכרון, הביצועים שלנו היו גרועים'."}, "_source_file": "0156__Concurrency__Multi-core_Processors__MC__Easy.json", "_topic_hint": "Multi-core Processors", "_requested_type": "MultipleChoice", "_requested_difficulty": "Easy", "_generated_at": "2026-02-14 17:29:11", "_subject": "Concurrency", "_context_lectures": [10, 12, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Multi-core Processors"], "difficulty_estimation": "Medium", "content": {"text": "בתזמון תהליכים במעבדים מרובי ליבות, מדוע שמירה על \"זיקת מטמון\" (cache affinity) נחשבת ליתרון משמעותי?", "code_snippet": null, "options": ["א. היא מפחיתה את הצורך בנעילות (locks) בין מעבדים שונים, מכיוון שכל תהליך משויך למעבד קבוע.", "ב. היא מבטיחה שנתונים שבהם התהליך השתמש בעבר יישארו במטמון הפרטי של המעבד, ובכך משפרת את ביצועי הגישה לזיכרון.", "ג. היא מאפשרת לכל תהליך לגשת לזיכרון הראשי (RAM) בקצב מהיר יותר, על ידי עקיפת מגבלות רוחב הפס של ה-BUS.", "ד. היא מאפשרת למערכת ההפעלה להריץ מספר תהליכים במקביל על ליבות שונות, ובכך להשיג מקביליות אמיתית."]}, "solution": {"correct_option": "ב", "explanation": "שמירה על זיקת מטמון (cache affinity) פירושה שתהליך ירוץ ככל הניתן על אותו מעבד שהריץ אותו בעבר. היתרון בכך נובע מהעובדה שבמערכות מרובות ליבות, לכל מעבד יש מטמון (cache) פרטי משלו. כאשר תהליך רץ על מעבד מסוים, הנתונים וההוראות שבהם הוא משתמש נטענים למטמון הפרטי של אותו מעבד. אם התהליך עובר למעבד אחר, הוא מאבד את הנתונים הללו מהמטמון הישן, ונדרש לטעון אותם מחדש למטמון של המעבד החדש. טעינה מחדש של נתונים מהזיכרון הראשי (RAM) היא פעולה יקרה ואיטית יחסית (כמה עשרות מחזורי שעון, ושימוש ב-BUS). לכן, שמירה על זיקת מטמון ממקסמת את הסיכוי שהנתונים הרלוונטיים לתהליך כבר יהיו זמינים במטמון המקומי של המעבד, ובכך משפרת משמעותית את ביצועי הגישה לזיכרון ומאיצה את ביצוע התהליך. אפשרות א' מתארת יתרון של Multi-queue multiprocessor scheduling, אשר באופן טבעי משיג cache affinity, אך זו אינה הסיבה הישירה לחשיבות ה-cache affinity עצמה. אפשרויות ג' ו-ד' אינן קשורות ישירות ליתרון הספציפי של cache affinity."}, "_source_file": "0157__Concurrency__Multi-core_Processors__MC__Medium.json", "_topic_hint": "Multi-core Processors", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:29:26", "_subject": "Concurrency", "_context_lectures": [10, 12, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Multi-core Processors"], "difficulty_estimation": "Medium", "content": {"text": "על פי חומר ההרצאה, מהו היתרון העיקרי של תזמון מעבדים מרובי תורים (Multi-queue Multiprocessor Scheduling) בסביבת מעבדים מרובי ליבות?", "code_snippet": null, "options": ["א. הוא מבטיח cache affinity טבעי, שכן כל ג'וב משויך למעבד ספציפי ורץ עליו באופן קבוע.", "ב. הוא מפחית את הצורך במנעולים (locks) באופן מוחלט בכל מצבי הוספת ג'ובים לתורים.", "ג. הוא משפר באופן משמעותי את ניצול רוחב הפס של ה-BUS בין המעבדים לזיכרון הראשי.", "ד. הוא מאפשר לג'וב יחיד לרוץ במקביל על מספר ליבות שונות בו-זמנית."]}, "solution": {"correct_option": "א", "explanation": "חומר ההרצאה מציין במפורש את היתרונות של תזמון מעבדים מרובי תורים (Multi-queue multiprocessor scheduling). אחד היתרונות המודגשים ביותר הוא שיש 'cache affinity באופן טבעי: ברגע שג'וב מסוים מגיע, הוא מקבל תור, משויך למעבד ותמיד הוא יורץ על אותו המעבד'. זוהי תכונה קריטית לביצועים בסביבת מעבדים מרובי ליבות, כיוון שכל ליבה מצוידת ב-cache פרטי משלה (L1), ושמירה על ג'וב על אותה ליבה מונעת את הצורך בטעינה מחדש של נתונים מהזיכרון הראשי האיטי יותר. אפשרות ב' אינה נכונה לחלוטין מכיוון שהחומר מציין ש'מדי פעם כשמוסיפים באופן מקבילי ייתכן שיידרש מנעול'. אפשרות ג' אינה נתמכת בחומר ההרצאה כיתרון של תזמון זה. אפשרות ד' אינה נכונה, שכן תזמון מרובה תורים משייך ג'וב למעבד ספציפי, ולא מאפשר לג'וב יחיד לרוץ על מספר ליבות במקביל (אלא אם מדובר בחוטים שונים של אותו ג'וב)."}, "_source_file": "0158__Concurrency__Multi-core_Processors__MC__Medium.json", "_topic_hint": "Multi-core Processors", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:29:38", "_subject": "Concurrency", "_context_lectures": [10, 12, 15]}, {"id": 1, "type": "MultipleChoice", "subject": "Concurrency", "topic": ["Multi-core Processors"], "difficulty_estimation": "Medium", "content": {"text": "איזה מהיתרונות הבאים של תזמון מרובה תורים (Multi-queue multiprocessor scheduling) במערכות מרובות ליבות תורם ישירות לשיפור ביצועי המערכת על ידי ניצול יעיל של זיכרון המטמון (cache)?", "code_snippet": null, "options": ["א. שיפור ה-cache affinity על ידי הבטחה שתהליך ירוץ על אותו מעבד אליו שויך בתחילה, ובכך מקטין את הצורך בטעינת נתונים מחדש מזיכרון הראשי.", "ב. הפחתה משמעותית של הצורך במנגנוני נעילה (locks) בין מעבדים שונים, כיוון שכל מעבד מנהל תור עבודה משלו.", "ג. אפשרות למעבר מהיר ויעיל יותר של תהליכים בין מעבדים שונים כדי לאזן עומסים באופן דינמי.", "ד. הקטנת העלות של יצירת חוטים חדשים (kernel threads) ושל החלפת הקשר (context switch) ביניהם."]}, "solution": {"correct_option": "א", "explanation": "תזמון מרובה תורים (Multi-queue multiprocessor scheduling) מקצה לכל מעבד תור עבודה משלו. ברגע שתהליך משויך לתור של מעבד מסוים, הוא ירוץ באופן עקבי על אותו מעבד. עקביות זו מבטיחה שימור של \"cache affinity\", כלומר, הנתונים שהתהליך השתמש בהם בעבר נשארים במטמון הפרטי (L1 cache) של אותו מעבד. כתוצאה מכך, פחות נדרש לגשת לזיכרון הראשי (RAM) האיטי יותר, והתהליך יכול לגשת לנתונים שלו במהירות גבוהה יותר מהמטמון, מה שמשפר משמעותית את ביצועי המערכת. אפשרויות ב', ג' ו-ד' מתארות היבטים אחרים או שגויים: אפשרות ב' היא אכן יתרון של השיטה אך אינה קשורה ישירות לניצול המטמון. אפשרות ג' מתארת פעולה שמנוגדת ל-cache affinity ופוגעת בביצועים. אפשרות ד' מתייחסת לעלות של חוטים, שאינה קשורה ישירות לשיטת התזמון או ל-cache affinity."}, "_source_file": "0159__Concurrency__Multi-core_Processors__MC__Medium.json", "_topic_hint": "Multi-core Processors", "_requested_type": "MultipleChoice", "_requested_difficulty": "Medium", "_generated_at": "2026-02-14 17:29:51", "_subject": "Concurrency", "_context_lectures": [10, 12, 15]}]